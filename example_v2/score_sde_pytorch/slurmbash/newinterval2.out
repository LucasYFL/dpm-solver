4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[W socket.cpp:426] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
2023-05-11 23:08:58.740718: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-11 23:08:58.740718: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-11 23:08:59.261431: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-05-11 23:08:59.261432: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-05-11 23:09:04.022033: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/cudnn/11.7-v8.7.0/lib64:/sw/pkgs/arc/cuda/11.7.1/lib64:/opt/slurm/lib64::
2023-05-11 23:09:04.022032: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/cudnn/11.7-v8.7.0/lib64:/sw/pkgs/arc/cuda/11.7.1/lib64:/opt/slurm/lib64::
2023-05-11 23:09:04.025211: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/cudnn/11.7-v8.7.0/lib64:/sw/pkgs/arc/cuda/11.7.1/lib64:/opt/slurm/lib64::
2023-05-11 23:09:04.025211: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/cudnn/11.7-v8.7.0/lib64:/sw/pkgs/arc/cuda/11.7.1/lib64:/opt/slurm/lib64::
2023-05-11 23:09:04.025234: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-05-11 23:09:04.025244: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']
caused by: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_18SourceLocationImplE']
  warnings.warn(f"unable to load libtensorflow_io_plugins.so: {e}")
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']
caused by: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_18SourceLocationImplE']
  warnings.warn(f"unable to load libtensorflow_io_plugins.so: {e}")
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']
caused by: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN3tsl13GcsFileSystemE']
  warnings.warn(f"file system plugins are not loaded: {e}")
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']
caused by: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN3tsl13GcsFileSystemE']
  warnings.warn(f"file system plugins are not loaded: {e}")
10

22

[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
64
64
I0511 23:09:15.685574 22485033404224 main.py:64] Conditional: True
W0511 23:09:30.893633 22520016189248 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/dpm_deep_I2/checkpoints-meta/checkpoint.pth. Returned the same state as input
W0511 23:09:30.901220 22485033404224 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/dpm_deep_I2/checkpoints-meta/checkpoint.pth. Returned the same state as input
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0511 23:09:33.085331 22520016189248 losses.py:105] Sde loss
I0511 23:09:33.085736 22520016189248 losses.py:108] Fewer: 4
I0511 23:09:33.085821 22520016189248 losses.py:127] (0.6308, 1]
I0511 23:09:33.085886 22520016189248 losses.py:105] Sde loss
I0511 23:09:33.085925 22520016189248 losses.py:108] Fewer: 4
I0511 23:09:33.085958 22520016189248 losses.py:127] (0.6308, 1]
I0511 23:09:33.086003 22520016189248 run_lib.py:130] Starting training loop at step 0.
I0511 23:09:33.092139 22485033404224 losses.py:105] Sde loss
I0511 23:09:33.092660 22485033404224 losses.py:108] Fewer: 4
I0511 23:09:33.092853 22485033404224 losses.py:127] (0.6308, 1]
I0511 23:09:33.093747 22485033404224 losses.py:105] Sde loss
I0511 23:09:33.093823 22485033404224 losses.py:108] Fewer: 4
I0511 23:09:33.093888 22485033404224 losses.py:127] (0.6308, 1]
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0511 23:09:33.093962 22485033404224 run_lib.py:130] Starting training loop at step 0.
[2023-05-11 23:09:33,367] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:09:33,367] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:09:33,589] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing get_timestep_embedding
[2023-05-11 23:09:33,589] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing get_timestep_embedding
[2023-05-11 23:09:33,603] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing get_timestep_embedding (RETURN_VALUE)
[2023-05-11 23:09:33,603] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing get_timestep_embedding (RETURN_VALUE)
[2023-05-11 23:09:33,605] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:09:33,605] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:09:33,605] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:09:33,605] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:09:33,672] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:09:33,672] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:09:35,791] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-05-11 23:09:35,794] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
/usr//usrbin//binld/:ld :skipping  skippingincompatible  incompatible/ usr//usrlib//liblibcuda.so/ libcuda.sowhen  whensearching  searchingfor  for- lcuda-
lcuda/
usr//usrbin//binld/:ld :skipping  skippingincompatible  incompatible/ usr//usrlib//liblibc.so/ libc.sowhen  whensearching  searchingfor  for- lc-
lc
[2023-05-11 23:09:38,436] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-05-11 23:09:38,436] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-05-11 23:09:38,438] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:09:38,438] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
/usr//usrbin//binld/:ld :skipping  skippingincompatible  incompatible/ usr//usrlib//liblibcuda.so/ libcuda.sowhen  whensearching  searchingfor  for- lcuda-
lcuda/
usr//usrbin//binld/:ld :skipping  skippingincompatible  incompatible/ usr//usrlib//liblibc.so/ libc.sowhen  whensearching  searchingfor  for- lc-
lc
[2023-05-11 23:09:39,554] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __getitem__
[2023-05-11 23:09:39,554] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __getitem__
[2023-05-11 23:09:39,568] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _get_abs_string_index
[2023-05-11 23:09:39,568] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _get_abs_string_index
[2023-05-11 23:09:39,570] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __len__
[2023-05-11 23:09:39,570] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __len__
[2023-05-11 23:10:08,345] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:08,345] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:08,389] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:08,390] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:08,392] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:08,392] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:08,392] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:08,394] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:09,776] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-05-11 23:10:09,776] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:10:11,079] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-05-11 23:10:11,079] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torch/_inductor/compile_fx.py:90: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torch/_inductor/compile_fx.py:90: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
[2023-05-11 23:10:11,614] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-05-11 23:10:11,614] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-05-11 23:10:11,653] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:11,653] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:10:12,693] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-05-11 23:10:12,710] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:12,755] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-05-11 23:10:12,769] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:12,795] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-11 23:10:12,797] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-11 23:10:12,798] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:12,798] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:12,798] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:10:12,799] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-11 23:10:12,800] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-11 23:10:12,802] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:12,802] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:12,802] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:10:12,815] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-05-11 23:10:12,818] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
/usr//usrbin//binld/:ld :skipping  skippingincompatible  incompatible/ usr//usrlib//liblibcuda.so/ libcuda.sowhen  whensearching  searchingfor  for- lcuda-
lcuda/
usr//usrbin//binld/:ld :skipping  skippingincompatible  incompatible/ usr//usrlib//liblibc.so/ libc.sowhen  when searching for -lc
searching for -lc
[2023-05-11 23:10:13,418] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-05-11 23:10:13,418] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-05-11 23:10:13,418] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:13,418] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:13,425] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:13,425] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:13,471] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:13,471] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:13,471] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:13,471] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:13,472] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:13,472] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:13,617] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-05-11 23:10:13,620] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-05-11 23:10:13,709] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-05-11 23:10:13,711] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-05-11 23:10:13,997] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-05-11 23:10:14,002] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-05-11 23:10:14,025] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:14,030] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:14,154] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-05-11 23:10:14,160] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-05-11 23:10:14,169] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:14,174] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:14,178] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:14,181] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:14,219] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:14,220] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:14,220] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:14,223] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:14,223] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:14,224] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:14,360] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-05-11 23:10:14,364] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-05-11 23:10:14,446] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-05-11 23:10:14,451] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-05-11 23:10:14,738] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-05-11 23:10:14,749] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-05-11 23:10:14,772] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:14,780] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:14,904] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-05-11 23:10:14,910] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-05-11 23:10:14,918] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:14,924] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:14,926] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:14,933] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:14,972] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:14,972] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:14,973] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:14,979] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:14,979] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:14,980] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:15,111] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-05-11 23:10:15,120] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-05-11 23:10:15,195] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-05-11 23:10:15,203] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-05-11 23:10:15,478] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-05-11 23:10:15,490] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-05-11 23:10:15,507] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:15,519] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:15,645] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-05-11 23:10:15,657] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-05-11 23:10:15,659] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:15,668] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:15,671] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:15,680] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:15,716] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:15,716] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:15,716] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:15,728] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:15,729] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:15,729] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:15,863] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-05-11 23:10:15,878] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-05-11 23:10:15,947] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-05-11 23:10:15,963] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-05-11 23:10:16,228] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-05-11 23:10:16,248] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-05-11 23:10:16,258] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:16,276] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:16,386] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-05-11 23:10:16,400] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:16,406] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-05-11 23:10:16,409] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:16,420] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:16,429] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:16,455] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:16,456] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:16,456] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:16,476] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:16,476] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:16,477] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:16,602] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-05-11 23:10:16,625] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-05-11 23:10:16,691] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-05-11 23:10:16,714] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-05-11 23:10:16,979] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-05-11 23:10:17,003] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-05-11 23:10:17,006] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:17,030] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:17,134] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-05-11 23:10:17,149] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:17,157] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:17,159] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-05-11 23:10:17,173] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:17,181] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:17,201] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:17,201] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:17,201] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:17,224] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:17,224] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:17,225] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:17,338] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-05-11 23:10:17,365] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-05-11 23:10:17,424] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-05-11 23:10:17,451] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-05-11 23:10:17,727] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-05-11 23:10:17,757] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:17,757] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-05-11 23:10:17,787] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:17,886] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-05-11 23:10:17,900] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:17,908] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:17,915] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-05-11 23:10:17,928] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:17,936] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:17,950] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:17,951] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:17,951] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:17,979] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:17,980] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:17,980] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:18,088] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-05-11 23:10:18,119] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-05-11 23:10:18,170] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-05-11 23:10:18,202] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-05-11 23:10:18,722] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-05-11 23:10:18,751] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:18,760] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-05-11 23:10:18,789] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:18,883] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-05-11 23:10:18,897] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:18,907] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:18,923] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-05-11 23:10:18,936] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:18,945] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:18,992] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:18,992] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:18,993] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1510400 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:19,000] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:19,001] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:19,001] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1510400 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:19,166] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-05-11 23:10:19,175] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:10:19,912] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-05-11 23:10:19,912] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-05-11 23:10:20,211] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-05-11 23:10:20,212] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-05-11 23:10:20,247] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:20,247] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
/usr/bin/ld: skipping incompatible //usrusr//binlib//ldlibcuda.so:  whenskipping  searchingincompatible  for/ usr-/lcudalib
//libcuda.sousr /whenbin /searchingld :for  skipping- lcudaincompatible
 //usrusr//binlib//ldlibc.so:  whenskipping  searchingincompatible  for/ usr-/lclib
/libc.so when searching for -lc
//usrusr//binbin//ldld::  skippingskipping  incompatibleincompatible  //usrusr//liblib//libcuda.solibcuda.so  whenwhen  searchingsearching  forfor  --lcudalcuda

//usrusr//binbin//ldld::  skippingskipping incompatible  incompatible/ usr//usrlib//liblibc.so/ libc.sowhen  whensearching  searchingfor  for- lc-
lc
[2023-05-11 23:10:21,057] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-05-11 23:10:21,057] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-05-11 23:10:21,072] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:21,072] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:21,257] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-11 23:10:21,257] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-11 23:10:21,260] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-11 23:10:21,260] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-11 23:10:21,261] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:21,261] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:21,261] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:21,261] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:21,261] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:10:21,261] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:10:21,278] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-05-11 23:10:21,278] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-05-11 23:10:21,587] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-05-11 23:10:21,587] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-05-11 23:10:21,587] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:21,588] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:21,594] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:21,594] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:21,645] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:21,645] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:21,645] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:21,645] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:21,646] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2492416 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    1709056 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:21,646] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2492416 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    1709056 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:22,042] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-05-11 23:10:22,047] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-05-11 23:10:22,090] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:22,095] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:10:22,959] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-05-11 23:10:22,970] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-05-11 23:10:23,022] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-05-11 23:10:23,033] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-05-11 23:10:23,352] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-05-11 23:10:23,357] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:23,362] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-05-11 23:10:23,365] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:23,384] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-11 23:10:23,385] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-11 23:10:23,387] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:23,387] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:23,387] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:10:23,389] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-11 23:10:23,390] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-11 23:10:23,391] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:23,392] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:23,392] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:10:23,403] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-05-11 23:10:23,407] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-05-11 23:10:23,716] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-05-11 23:10:23,716] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:23,718] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-05-11 23:10:23,718] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:23,721] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:23,724] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:23,845] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:23,846] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:23,846] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:23,847] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:23,848] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:23,848] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:23,973] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-05-11 23:10:23,974] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
/usr//usrbin//binld/:ld :skipping  skippingincompatible  incompatible/ usr//usrlib//liblibcuda.so/ libcuda.sowhen  whensearching  searchingfor  for- lcuda-
lcuda/
usr//usrbin//binld/:ld :skipping  skippingincompatible  incompatible/ usr//usrlib//liblibc.so/ libc.sowhen  whensearching  searchingfor  for- lc-
lc
[2023-05-11 23:10:24,624] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-05-11 23:10:24,624] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-05-11 23:10:25,126] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 25
[2023-05-11 23:10:25,126] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 25
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:10:28,624] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 25
[2023-05-11 23:10:28,643] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 25
[2023-05-11 23:10:28,657] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:28,677] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:31,399] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-11 23:10:31,402] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-11 23:10:31,402] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-11 23:10:31,403] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:31,403] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:31,403] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:10:31,404] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-11 23:10:31,405] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:31,405] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:31,405] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:10:31,420] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 26
[2023-05-11 23:10:31,422] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 26
[2023-05-11 23:10:31,430] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 26
[2023-05-11 23:10:31,431] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:31,432] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 26
[2023-05-11 23:10:31,433] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:31,437] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:31,438] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:31,480] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:31,480] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:31,480] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:31,481] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:31,482] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:31,482] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:31,882] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 27
[2023-05-11 23:10:31,885] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 27
[2023-05-11 23:10:31,930] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:31,931] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:32,475] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 27
[2023-05-11 23:10:32,475] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 27
[2023-05-11 23:10:32,524] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 28
[2023-05-11 23:10:32,524] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 28
[2023-05-11 23:10:32,864] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 28
[2023-05-11 23:10:32,864] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 28
[2023-05-11 23:10:32,867] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:32,867] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:32,875] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:32,875] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:32,991] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:32,991] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:32,991] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:32,994] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:32,994] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:32,994] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:33,115] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 29
[2023-05-11 23:10:33,118] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 29
[2023-05-11 23:10:33,172] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 29
[2023-05-11 23:10:33,175] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 29
[2023-05-11 23:10:33,678] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 30
[2023-05-11 23:10:33,679] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 30
[2023-05-11 23:10:33,827] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 30
[2023-05-11 23:10:33,828] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 30
[2023-05-11 23:10:33,861] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:33,862] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:33,869] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:33,870] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:33,916] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:33,916] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:33,916] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:33,917] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:33,917] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:33,918] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:34,608] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 31
[2023-05-11 23:10:34,617] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 31
[2023-05-11 23:10:34,650] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:34,659] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:34,802] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 31
[2023-05-11 23:10:34,813] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 31
[2023-05-11 23:10:34,854] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 32
[2023-05-11 23:10:34,865] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 32
[2023-05-11 23:10:34,873] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 32
[2023-05-11 23:10:34,876] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:34,882] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:34,884] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 32
[2023-05-11 23:10:34,887] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:34,893] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:34,995] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:34,995] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:34,996] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:35,007] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:35,007] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:35,008] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:35,123] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 33
[2023-05-11 23:10:35,135] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 33
[2023-05-11 23:10:35,181] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 33
[2023-05-11 23:10:35,193] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 33
[2023-05-11 23:10:35,688] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 34
[2023-05-11 23:10:35,700] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 34
[2023-05-11 23:10:35,837] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 34
[2023-05-11 23:10:35,848] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 34
[2023-05-11 23:10:35,872] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:35,880] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:35,882] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:35,891] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:35,923] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:35,923] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:35,924] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:35,934] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:35,934] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:35,934] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:36,314] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 35
[2023-05-11 23:10:36,328] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 35
[2023-05-11 23:10:36,354] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:36,368] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:36,502] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 35
[2023-05-11 23:10:36,521] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 35
[2023-05-11 23:10:36,552] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 36
[2023-05-11 23:10:36,570] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 36
[2023-05-11 23:10:36,570] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 36
[2023-05-11 23:10:36,573] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:36,580] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:36,589] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 36
[2023-05-11 23:10:36,592] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:36,599] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:36,701] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:36,701] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:36,702] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:36,721] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:36,721] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:36,722] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:36,831] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 37
[2023-05-11 23:10:36,851] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 37
[2023-05-11 23:10:36,888] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 37
[2023-05-11 23:10:36,908] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 37
[2023-05-11 23:10:37,387] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 38
[2023-05-11 23:10:37,405] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 38
[2023-05-11 23:10:37,530] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 38
[2023-05-11 23:10:37,548] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 38
[2023-05-11 23:10:37,564] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:37,573] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:37,582] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:37,591] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:37,619] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:37,620] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:37,620] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:37,638] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:37,638] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:37,639] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:38,015] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 39
[2023-05-11 23:10:38,036] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 39
[2023-05-11 23:10:38,056] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:38,077] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:38,204] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 39
[2023-05-11 23:10:38,226] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 39
[2023-05-11 23:10:38,252] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 40
[2023-05-11 23:10:38,270] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 40
[2023-05-11 23:10:38,273] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:38,274] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 40
[2023-05-11 23:10:38,280] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:38,292] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 40
[2023-05-11 23:10:38,295] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:38,301] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:38,392] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:38,393] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:38,394] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:38,415] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:38,416] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:38,416] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:38,521] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 41
[2023-05-11 23:10:38,544] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 41
[2023-05-11 23:10:38,579] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 41
[2023-05-11 23:10:38,603] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 41
[2023-05-11 23:10:39,091] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 42
[2023-05-11 23:10:39,112] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 42
[2023-05-11 23:10:39,228] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 42
[2023-05-11 23:10:39,250] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 42
[2023-05-11 23:10:39,260] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:39,269] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:39,282] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:39,293] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:39,311] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:39,311] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:39,312] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:39,335] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:39,335] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:39,336] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:40,007] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 43
[2023-05-11 23:10:40,042] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 43
[2023-05-11 23:10:40,050] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:40,083] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:40,196] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 43
[2023-05-11 23:10:40,229] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 43
[2023-05-11 23:10:40,243] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 44
[2023-05-11 23:10:40,261] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 44
[2023-05-11 23:10:40,263] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:40,270] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:40,277] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 44
[2023-05-11 23:10:40,295] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 44
[2023-05-11 23:10:40,297] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:40,304] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:40,382] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:40,382] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:40,383] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:40,418] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:40,419] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:40,419] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:40,509] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 45
[2023-05-11 23:10:40,547] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 45
[2023-05-11 23:10:40,568] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 45
[2023-05-11 23:10:40,607] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 45
[2023-05-11 23:10:41,081] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 46
[2023-05-11 23:10:41,120] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 46
[2023-05-11 23:10:41,224] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 46
[2023-05-11 23:10:41,256] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:41,264] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 46
[2023-05-11 23:10:41,265] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:41,296] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:41,305] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:41,308] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:41,308] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:41,308] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:41,348] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:41,348] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:41,349] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:41,711] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 47
[2023-05-11 23:10:41,752] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:41,754] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 47
[2023-05-11 23:10:41,796] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:41,901] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 47
[2023-05-11 23:10:41,946] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 47
[2023-05-11 23:10:41,950] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 48
[2023-05-11 23:10:41,968] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 48
[2023-05-11 23:10:41,971] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:41,978] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:41,995] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 48
[2023-05-11 23:10:42,014] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 48
[2023-05-11 23:10:42,017] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:42,024] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:42,094] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:42,094] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:42,095] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:42,137] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:42,137] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:42,138] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:42,219] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 49
[2023-05-11 23:10:42,261] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 49
[2023-05-11 23:10:42,274] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 49
[2023-05-11 23:10:42,317] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 49
[2023-05-11 23:10:42,790] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 50
[2023-05-11 23:10:42,834] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 50
[2023-05-11 23:10:42,930] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 50
[2023-05-11 23:10:42,963] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:42,972] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:42,976] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 50
[2023-05-11 23:10:43,009] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:43,016] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:43,016] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:43,017] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:43,018] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:43,061] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:43,061] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:43,061] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:43,401] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 51
[2023-05-11 23:10:43,442] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:43,448] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 51
[2023-05-11 23:10:43,490] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:43,595] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 51
[2023-05-11 23:10:43,643] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 51
[2023-05-11 23:10:43,644] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 52
[2023-05-11 23:10:43,662] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 52
[2023-05-11 23:10:43,665] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:43,672] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:43,693] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 52
[2023-05-11 23:10:43,712] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 52
[2023-05-11 23:10:43,715] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:43,722] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:43,795] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:43,795] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:43,795] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:43,843] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:43,844] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:43,844] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:43,922] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 53
[2023-05-11 23:10:43,971] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 53
[2023-05-11 23:10:43,978] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 53
[2023-05-11 23:10:44,027] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 53
[2023-05-11 23:10:44,478] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 54
[2023-05-11 23:10:44,529] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 54
[2023-05-11 23:10:44,622] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 54
[2023-05-11 23:10:44,655] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:44,665] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:44,675] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 54
[2023-05-11 23:10:44,709] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:44,718] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:44,727] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:44,727] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:44,728] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2623488 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:44,780] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:44,781] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:44,781] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2623488 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:45,475] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 55
[2023-05-11 23:10:45,530] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:45,536] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 55
[2023-05-11 23:10:45,593] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:10:46,521] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 55
[2023-05-11 23:10:46,589] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 56
[2023-05-11 23:10:46,621] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 55
[2023-05-11 23:10:46,689] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 56
[2023-05-11 23:10:46,924] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 56
[2023-05-11 23:10:46,927] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:46,983] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-11 23:10:46,985] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-11 23:10:46,986] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:46,986] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:46,986] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:10:47,003] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 57
[2023-05-11 23:10:47,025] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 56
[2023-05-11 23:10:47,029] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:47,053] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-11 23:10:47,055] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-11 23:10:47,056] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:47,056] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:47,056] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:10:47,072] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 57
[2023-05-11 23:10:47,310] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 57
[2023-05-11 23:10:47,310] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:47,317] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:47,362] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:47,362] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:47,363] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:47,380] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 57
[2023-05-11 23:10:47,381] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:47,387] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:47,436] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:47,436] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:47,437] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:47,777] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 58
[2023-05-11 23:10:47,823] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:47,850] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 58
[2023-05-11 23:10:47,897] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:10:48,558] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 58
[2023-05-11 23:10:48,608] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 59
[2023-05-11 23:10:48,630] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 58
[2023-05-11 23:10:48,681] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 59
[2023-05-11 23:10:48,934] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 59
[2023-05-11 23:10:48,937] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:48,946] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:48,989] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:48,989] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:48,990] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:49,009] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 59
[2023-05-11 23:10:49,012] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:49,021] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:49,063] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:49,063] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:49,064] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:49,382] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 60
[2023-05-11 23:10:49,423] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:49,456] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 60
[2023-05-11 23:10:49,498] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:49,578] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 60
[2023-05-11 23:10:49,629] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 61
[2023-05-11 23:10:49,649] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 61
[2023-05-11 23:10:49,652] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:49,655] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 60
[2023-05-11 23:10:49,660] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:49,707] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 61
[2023-05-11 23:10:49,709] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:49,709] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:49,710] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:49,726] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 61
[2023-05-11 23:10:49,729] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:49,737] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:49,786] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:49,786] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:49,787] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:50,105] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 62
[2023-05-11 23:10:50,145] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:50,173] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 62
[2023-05-11 23:10:50,213] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:50,288] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 62
[2023-05-11 23:10:50,337] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 63
[2023-05-11 23:10:50,356] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 63
[2023-05-11 23:10:50,359] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:50,359] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 62
[2023-05-11 23:10:50,366] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:50,408] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 63
[2023-05-11 23:10:50,412] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:50,412] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:50,412] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:50,428] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 63
[2023-05-11 23:10:50,431] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:50,438] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:50,485] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:50,485] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:50,486] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:50,821] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 64
[2023-05-11 23:10:50,861] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:50,888] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 64
[2023-05-11 23:10:50,928] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:51,003] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 64
[2023-05-11 23:10:51,051] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 65
[2023-05-11 23:10:51,069] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 65
[2023-05-11 23:10:51,071] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:51,073] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 64
[2023-05-11 23:10:51,078] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:51,120] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:51,120] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:51,120] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:51,121] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 65
[2023-05-11 23:10:51,139] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 65
[2023-05-11 23:10:51,141] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:51,148] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:51,191] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:51,191] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:51,192] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:51,512] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 66
[2023-05-11 23:10:51,554] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:51,584] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 66
[2023-05-11 23:10:51,628] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:51,710] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 66
[2023-05-11 23:10:51,760] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 67
[2023-05-11 23:10:51,779] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 67
[2023-05-11 23:10:51,782] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:51,783] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 66
[2023-05-11 23:10:51,789] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:51,831] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 67
[2023-05-11 23:10:51,834] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:51,834] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:51,835] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:51,849] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 67
[2023-05-11 23:10:51,851] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:51,858] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:51,899] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:51,900] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:51,900] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:52,221] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 68
[2023-05-11 23:10:52,261] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:52,283] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 68
[2023-05-11 23:10:52,323] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:52,406] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 68
[2023-05-11 23:10:52,457] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 69
[2023-05-11 23:10:52,472] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 68
[2023-05-11 23:10:52,478] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 69
[2023-05-11 23:10:52,481] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:52,488] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:52,523] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 69
[2023-05-11 23:10:52,536] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:52,537] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:52,537] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:52,543] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 69
[2023-05-11 23:10:52,546] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:52,553] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:52,601] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:52,601] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:52,602] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:52,944] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 70
[2023-05-11 23:10:52,984] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:53,008] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 70
[2023-05-11 23:10:53,048] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:53,126] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 70
[2023-05-11 23:10:53,173] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 71
[2023-05-11 23:10:53,190] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 71
[2023-05-11 23:10:53,193] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 70
[2023-05-11 23:10:53,193] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:53,201] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:53,241] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 71
[2023-05-11 23:10:53,244] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:53,244] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:53,245] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:53,258] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 71
[2023-05-11 23:10:53,261] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:53,269] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:53,310] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:53,311] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:53,311] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:53,998] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 72
[2023-05-11 23:10:54,040] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:54,080] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 72
[2023-05-11 23:10:54,122] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:54,190] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 72
[2023-05-11 23:10:54,242] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 73
[2023-05-11 23:10:54,260] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 73
[2023-05-11 23:10:54,262] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:54,267] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 72
[2023-05-11 23:10:54,271] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:54,314] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 73
[2023-05-11 23:10:54,326] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:54,326] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:54,327] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2623488 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:54,332] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 73
[2023-05-11 23:10:54,334] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:54,342] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:54,400] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:54,401] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:54,401] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2623488 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:54,783] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 74
[2023-05-11 23:10:54,839] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:54,857] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 74
[2023-05-11 23:10:54,911] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:10:55,839] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 74
[2023-05-11 23:10:55,900] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 74
[2023-05-11 23:10:55,907] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 75
[2023-05-11 23:10:55,967] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 75
[2023-05-11 23:10:56,237] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 75
[2023-05-11 23:10:56,241] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:56,290] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-11 23:10:56,291] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-11 23:10:56,293] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:56,293] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:56,293] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:10:56,299] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 75
[2023-05-11 23:10:56,303] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:56,309] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 76
[2023-05-11 23:10:56,324] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-11 23:10:56,326] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-11 23:10:56,327] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:56,327] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:56,327] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:10:56,343] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 76
[2023-05-11 23:10:56,617] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 76
[2023-05-11 23:10:56,618] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:56,625] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:56,652] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 76
[2023-05-11 23:10:56,652] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:56,659] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:56,673] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:56,673] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:56,674] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:56,706] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:56,707] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:56,707] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:57,073] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 77
[2023-05-11 23:10:57,101] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 77
[2023-05-11 23:10:57,117] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:57,144] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:10:57,863] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 77
[2023-05-11 23:10:57,889] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 77
[2023-05-11 23:10:57,913] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 78
[2023-05-11 23:10:57,936] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 78
[2023-05-11 23:10:58,229] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 78
[2023-05-11 23:10:58,232] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:58,242] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:58,255] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 78
[2023-05-11 23:10:58,258] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:58,268] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:58,286] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:58,286] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:58,287] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:58,311] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:58,311] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:58,312] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:58,704] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 79
[2023-05-11 23:10:58,715] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 79
[2023-05-11 23:10:58,746] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:58,757] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:58,900] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 79
[2023-05-11 23:10:58,911] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 79
[2023-05-11 23:10:58,948] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 80
[2023-05-11 23:10:58,957] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 80
[2023-05-11 23:10:58,967] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 80
[2023-05-11 23:10:58,969] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:58,976] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 80
[2023-05-11 23:10:58,977] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:58,978] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:58,986] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:59,019] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:59,019] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:59,020] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:59,027] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:59,028] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:59,028] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:59,411] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 81
[2023-05-11 23:10:59,413] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 81
[2023-05-11 23:10:59,453] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:59,455] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:10:59,607] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 81
[2023-05-11 23:10:59,608] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 81
[2023-05-11 23:10:59,657] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 82
[2023-05-11 23:10:59,657] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 82
[2023-05-11 23:10:59,675] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 82
[2023-05-11 23:10:59,676] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 82
[2023-05-11 23:10:59,678] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:59,679] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:10:59,687] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:59,687] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:10:59,733] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:59,733] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:10:59,733] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:59,733] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:10:59,734] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:10:59,734] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:00,123] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 83
[2023-05-11 23:11:00,129] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 83
[2023-05-11 23:11:00,163] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:00,169] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:00,310] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 83
[2023-05-11 23:11:00,317] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 83
[2023-05-11 23:11:00,357] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 84
[2023-05-11 23:11:00,365] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 84
[2023-05-11 23:11:00,375] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 84
[2023-05-11 23:11:00,378] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:00,383] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 84
[2023-05-11 23:11:00,385] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:00,386] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:00,394] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:00,432] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:00,432] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:00,433] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:00,440] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:00,440] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:00,441] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:00,834] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 85
[2023-05-11 23:11:00,848] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 85
[2023-05-11 23:11:00,875] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:00,888] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:01,018] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 85
[2023-05-11 23:11:01,032] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 85
[2023-05-11 23:11:01,065] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 86
[2023-05-11 23:11:01,079] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 86
[2023-05-11 23:11:01,084] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 86
[2023-05-11 23:11:01,086] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:01,094] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:01,098] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 86
[2023-05-11 23:11:01,100] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:01,108] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:01,136] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:01,136] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:01,137] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:01,150] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:01,150] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:01,151] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:01,527] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 87
[2023-05-11 23:11:01,548] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 87
[2023-05-11 23:11:01,570] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:01,590] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:01,722] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 87
[2023-05-11 23:11:01,742] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 87
[2023-05-11 23:11:01,772] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 88
[2023-05-11 23:11:01,790] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 88
[2023-05-11 23:11:01,792] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 88
[2023-05-11 23:11:01,793] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:01,801] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:01,811] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 88
[2023-05-11 23:11:01,814] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:01,822] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:01,847] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:01,847] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:01,848] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:01,867] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:01,867] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:01,867] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:02,623] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 89
[2023-05-11 23:11:02,668] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:02,670] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 89
[2023-05-11 23:11:02,713] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:02,822] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 89
[2023-05-11 23:11:02,866] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 89
[2023-05-11 23:11:02,870] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 90
[2023-05-11 23:11:02,888] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 90
[2023-05-11 23:11:02,890] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:02,897] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:02,913] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 90
[2023-05-11 23:11:02,931] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 90
[2023-05-11 23:11:02,933] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:02,938] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:02,939] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:02,939] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:02,941] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:02,982] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:02,982] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:02,983] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:03,328] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 91
[2023-05-11 23:11:03,368] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:03,378] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 91
[2023-05-11 23:11:03,419] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:03,525] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 91
[2023-05-11 23:11:03,577] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 92
[2023-05-11 23:11:03,578] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 91
[2023-05-11 23:11:03,596] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 92
[2023-05-11 23:11:03,599] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:03,607] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:03,630] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 92
[2023-05-11 23:11:03,649] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 92
[2023-05-11 23:11:03,651] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:03,653] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:03,654] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:03,654] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:03,660] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:03,707] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:03,707] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:03,708] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:04,053] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 93
[2023-05-11 23:11:04,094] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:04,111] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 93
[2023-05-11 23:11:04,152] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:04,243] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 93
[2023-05-11 23:11:04,292] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 94
[2023-05-11 23:11:04,304] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 93
[2023-05-11 23:11:04,312] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 94
[2023-05-11 23:11:04,315] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:04,322] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:04,353] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 94
[2023-05-11 23:11:04,373] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 94
[2023-05-11 23:11:04,375] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:04,382] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:04,440] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:04,440] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:04,440] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:04,503] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:04,503] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:04,504] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:04,571] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 95
[2023-05-11 23:11:04,634] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 95
[2023-05-11 23:11:04,996] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 95
[2023-05-11 23:11:05,055] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 95
[2023-05-11 23:11:05,502] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 96
[2023-05-11 23:11:05,570] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 96
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:11:07,688] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 96
[2023-05-11 23:11:07,720] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:07,842] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 96
[2023-05-11 23:11:07,874] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:19,703] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-11 23:11:19,704] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-11 23:11:19,705] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:19,705] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:19,705] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:11:19,721] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 97
[2023-05-11 23:11:19,731] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 97
[2023-05-11 23:11:19,731] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:19,737] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:19,771] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-11 23:11:19,772] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-11 23:11:19,773] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:19,774] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:19,774] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:11:19,780] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:19,780] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:19,780] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:19,790] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 97
[2023-05-11 23:11:19,799] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 97
[2023-05-11 23:11:19,800] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:19,805] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:19,847] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:19,848] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:19,848] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:20,166] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 98
[2023-05-11 23:11:20,214] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:20,244] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 98
[2023-05-11 23:11:20,292] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:20,384] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 98
[2023-05-11 23:11:20,436] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 99
[2023-05-11 23:11:20,455] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 99
[2023-05-11 23:11:20,458] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:20,464] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 98
[2023-05-11 23:11:20,467] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:20,517] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 99
[2023-05-11 23:11:20,519] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:20,519] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:20,520] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:20,535] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 99
[2023-05-11 23:11:20,538] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:20,546] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:20,592] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:20,592] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:20,592] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:20,903] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 100
[2023-05-11 23:11:20,947] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:20,980] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 100
[2023-05-11 23:11:21,023] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:11:21,712] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 100
[2023-05-11 23:11:21,775] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 101
[2023-05-11 23:11:21,787] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 100
[2023-05-11 23:11:21,806] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 101
[2023-05-11 23:11:21,810] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:21,829] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:21,853] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 101
[2023-05-11 23:11:21,874] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:21,874] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:21,875] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:21,884] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 101
[2023-05-11 23:11:21,887] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:21,906] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:21,953] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:21,954] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:21,954] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:22,263] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 102
[2023-05-11 23:11:22,305] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:22,352] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 102
[2023-05-11 23:11:22,394] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:22,466] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 102
[2023-05-11 23:11:22,536] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 103
[2023-05-11 23:11:22,558] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 102
[2023-05-11 23:11:22,561] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 103
[2023-05-11 23:11:22,565] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:22,573] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:22,620] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:22,620] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:22,621] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:22,625] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 103
[2023-05-11 23:11:22,649] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 103
[2023-05-11 23:11:22,652] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:22,660] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:22,706] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:22,707] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:22,707] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:23,386] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 104
[2023-05-11 23:11:23,427] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:23,492] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 104
[2023-05-11 23:11:23,535] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:23,587] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 104
[2023-05-11 23:11:23,654] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 105
[2023-05-11 23:11:23,678] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 105
[2023-05-11 23:11:23,682] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:23,690] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:23,692] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 104
[2023-05-11 23:11:23,735] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:23,735] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:23,736] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:23,756] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 105
[2023-05-11 23:11:23,781] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 105
[2023-05-11 23:11:23,784] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:23,791] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:23,837] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:23,838] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:23,838] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:24,129] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 106
[2023-05-11 23:11:24,171] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:24,239] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 106
[2023-05-11 23:11:24,282] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:24,333] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 106
[2023-05-11 23:11:24,407] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 107
[2023-05-11 23:11:24,433] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 107
[2023-05-11 23:11:24,437] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:24,446] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:24,457] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 106
[2023-05-11 23:11:24,499] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:24,499] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:24,500] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:24,530] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 107
[2023-05-11 23:11:24,557] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 107
[2023-05-11 23:11:24,561] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:24,570] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:24,617] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:24,617] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:24,618] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:24,896] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 108
[2023-05-11 23:11:24,937] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:25,015] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 108
[2023-05-11 23:11:25,055] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:25,089] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 108
[2023-05-11 23:11:25,153] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 109
[2023-05-11 23:11:25,180] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 109
[2023-05-11 23:11:25,183] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:25,192] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:25,212] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 108
[2023-05-11 23:11:25,242] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:25,242] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:25,243] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:25,280] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 109
[2023-05-11 23:11:25,306] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 109
[2023-05-11 23:11:25,309] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:25,318] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:25,370] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:25,371] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:25,371] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:25,654] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 110
[2023-05-11 23:11:25,694] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:25,780] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 110
[2023-05-11 23:11:25,822] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:25,844] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 110
[2023-05-11 23:11:25,907] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 111
[2023-05-11 23:11:25,931] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 111
[2023-05-11 23:11:25,934] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:25,942] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:25,973] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 110
[2023-05-11 23:11:25,987] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:25,988] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:25,988] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:26,037] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 111
[2023-05-11 23:11:26,061] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 111
[2023-05-11 23:11:26,064] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:26,071] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:26,119] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:26,119] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:26,120] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:26,385] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 112
[2023-05-11 23:11:26,427] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:26,533] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 112
[2023-05-11 23:11:26,575] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:26,589] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 112
[2023-05-11 23:11:26,661] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 113
[2023-05-11 23:11:26,687] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 113
[2023-05-11 23:11:26,691] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:26,699] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:26,734] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 112
[2023-05-11 23:11:26,746] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:26,746] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:26,747] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:26,803] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 113
[2023-05-11 23:11:26,827] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 113
[2023-05-11 23:11:26,830] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:26,838] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:26,884] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:26,884] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:26,885] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:27,134] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 114
[2023-05-11 23:11:27,175] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:27,283] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 114
[2023-05-11 23:11:27,326] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:27,336] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 114
[2023-05-11 23:11:27,405] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 115
[2023-05-11 23:11:27,430] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 115
[2023-05-11 23:11:27,434] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:27,442] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:27,488] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 114
[2023-05-11 23:11:27,494] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:27,494] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:27,495] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:27,558] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 115
[2023-05-11 23:11:27,582] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 115
[2023-05-11 23:11:27,586] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:27,594] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:27,642] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:27,642] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:27,643] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:27,886] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 116
[2023-05-11 23:11:27,926] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:28,030] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 116
[2023-05-11 23:11:28,069] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:28,076] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 116
[2023-05-11 23:11:28,140] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 117
[2023-05-11 23:11:28,165] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 117
[2023-05-11 23:11:28,169] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:28,177] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:28,224] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 116
[2023-05-11 23:11:28,239] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:28,239] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:28,240] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2623488 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:28,291] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 117
[2023-05-11 23:11:28,316] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 117
[2023-05-11 23:11:28,319] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:28,328] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:28,392] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:28,392] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:28,393] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2623488 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:28,678] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 118
[2023-05-11 23:11:28,726] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:28,831] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 118
[2023-05-11 23:11:28,878] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:29,338] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 118
[2023-05-11 23:11:29,413] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 119
[2023-05-11 23:11:29,439] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 119
[2023-05-11 23:11:29,443] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:29,453] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:29,503] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 118
[2023-05-11 23:11:29,506] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:29,506] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:29,507] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:29,576] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 119
[2023-05-11 23:11:29,600] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 119
[2023-05-11 23:11:29,603] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:29,613] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:29,662] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:29,662] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:29,663] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:29,903] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 120
[2023-05-11 23:11:29,950] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:30,053] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 120
[2023-05-11 23:11:30,099] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:30,505] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 120
[2023-05-11 23:11:30,573] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 121
[2023-05-11 23:11:30,606] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 121
[2023-05-11 23:11:30,609] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:30,655] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:30,662] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 120
[2023-05-11 23:11:30,700] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:30,701] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:30,701] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:30,725] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 121
[2023-05-11 23:11:30,751] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 121
[2023-05-11 23:11:30,754] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:30,773] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:30,819] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:30,819] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:30,820] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:31,553] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 122
[2023-05-11 23:11:31,594] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:31,663] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 122
[2023-05-11 23:11:31,703] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:31,746] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 122
[2023-05-11 23:11:31,811] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 123
[2023-05-11 23:11:31,835] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 123
[2023-05-11 23:11:31,839] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:31,846] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:31,855] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 122
[2023-05-11 23:11:31,892] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:31,893] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:31,893] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:31,920] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 123
[2023-05-11 23:11:31,944] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 123
[2023-05-11 23:11:31,948] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:31,955] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:32,002] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:32,002] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:32,003] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:32,302] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 124
[2023-05-11 23:11:32,344] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:32,416] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 124
[2023-05-11 23:11:32,458] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:32,505] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 124
[2023-05-11 23:11:32,575] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 125
[2023-05-11 23:11:32,599] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 125
[2023-05-11 23:11:32,603] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:32,610] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:32,617] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 124
[2023-05-11 23:11:32,655] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:32,655] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:32,656] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:32,683] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 125
[2023-05-11 23:11:32,706] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 125
[2023-05-11 23:11:32,710] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:32,717] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:32,763] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:32,763] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:32,764] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:33,055] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 126
[2023-05-11 23:11:33,096] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:33,169] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 126
[2023-05-11 23:11:33,211] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:33,259] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 126
[2023-05-11 23:11:33,327] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 127
[2023-05-11 23:11:33,353] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 127
[2023-05-11 23:11:33,357] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:33,366] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:33,373] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 126
[2023-05-11 23:11:33,417] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:33,417] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:33,418] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:33,442] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 127
[2023-05-11 23:11:33,466] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 127
[2023-05-11 23:11:33,470] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:33,478] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:33,529] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:33,530] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:33,530] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:33,814] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 128
[2023-05-11 23:11:33,854] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:33,922] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 128
[2023-05-11 23:11:33,965] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:34,011] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 128
[2023-05-11 23:11:34,077] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 129
[2023-05-11 23:11:34,101] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 129
[2023-05-11 23:11:34,104] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:34,112] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:34,123] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 128
[2023-05-11 23:11:34,159] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:34,160] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:34,160] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:34,189] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 129
[2023-05-11 23:11:34,213] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 129
[2023-05-11 23:11:34,217] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:34,225] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:34,274] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:34,275] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:34,275] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:34,570] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 130
[2023-05-11 23:11:34,610] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:34,681] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 130
[2023-05-11 23:11:34,721] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:34,764] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 130
[2023-05-11 23:11:34,828] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 131
[2023-05-11 23:11:34,852] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 131
[2023-05-11 23:11:34,856] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:34,863] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:34,875] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 130
[2023-05-11 23:11:34,911] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:34,911] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:34,912] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:34,943] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 131
[2023-05-11 23:11:34,968] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 131
[2023-05-11 23:11:34,971] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:34,979] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:35,027] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:35,027] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:35,028] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:35,316] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 132
[2023-05-11 23:11:35,358] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:35,434] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 132
[2023-05-11 23:11:35,475] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:35,519] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 132
[2023-05-11 23:11:35,584] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 133
[2023-05-11 23:11:35,607] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 133
[2023-05-11 23:11:35,610] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:35,618] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:35,629] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 132
[2023-05-11 23:11:35,663] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:35,663] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:35,664] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:35,694] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 133
[2023-05-11 23:11:35,717] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 133
[2023-05-11 23:11:35,720] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:35,728] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:35,774] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:35,774] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:35,775] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:36,057] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 134
[2023-05-11 23:11:36,098] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:36,172] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 134
[2023-05-11 23:11:36,214] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:36,257] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 134
[2023-05-11 23:11:36,324] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 135
[2023-05-11 23:11:36,351] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 135
[2023-05-11 23:11:36,354] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:36,362] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:36,373] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 134
[2023-05-11 23:11:36,412] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:36,412] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:36,413] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:36,441] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 135
[2023-05-11 23:11:36,466] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 135
[2023-05-11 23:11:36,469] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:36,477] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:36,528] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:36,528] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:36,529] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:36,804] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 136
[2023-05-11 23:11:36,845] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:36,919] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 136
[2023-05-11 23:11:36,961] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:37,000] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 136
[2023-05-11 23:11:37,064] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 137
[2023-05-11 23:11:37,088] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 137
[2023-05-11 23:11:37,091] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:37,098] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:37,112] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 136
[2023-05-11 23:11:37,160] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:37,160] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:37,161] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2623488 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:37,179] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 137
[2023-05-11 23:11:37,204] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 137
[2023-05-11 23:11:37,208] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:37,215] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:37,277] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:37,278] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:37,278] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2623488 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:37,598] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 138
[2023-05-11 23:11:37,645] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:37,713] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 138
[2023-05-11 23:11:37,763] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:38,193] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 138
[2023-05-11 23:11:38,264] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 139
[2023-05-11 23:11:38,295] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 139
[2023-05-11 23:11:38,299] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:38,315] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:38,337] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 138
[2023-05-11 23:11:38,365] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:38,365] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:38,366] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:38,406] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 139
[2023-05-11 23:11:38,438] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 139
[2023-05-11 23:11:38,442] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:38,458] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:38,507] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:38,508] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:38,508] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:39,210] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 140
[2023-05-11 23:11:39,258] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:39,350] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 140
[2023-05-11 23:11:39,399] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:39,817] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 140
[2023-05-11 23:11:39,884] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 141
[2023-05-11 23:11:39,915] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 141
[2023-05-11 23:11:39,918] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:39,940] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:39,956] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 140
[2023-05-11 23:11:39,986] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:39,986] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:39,986] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:40,023] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 141
[2023-05-11 23:11:40,054] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 141
[2023-05-11 23:11:40,057] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:40,080] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:40,130] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:40,130] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:40,131] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:40,395] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 142
[2023-05-11 23:11:40,438] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:40,549] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 142
[2023-05-11 23:11:40,590] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:40,595] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 142
[2023-05-11 23:11:40,662] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 143
[2023-05-11 23:11:40,686] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 143
[2023-05-11 23:11:40,690] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:40,698] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:40,744] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:40,744] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:40,745] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:40,745] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 142
[2023-05-11 23:11:40,809] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 143
[2023-05-11 23:11:40,833] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 143
[2023-05-11 23:11:40,837] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:40,845] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:40,892] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:40,893] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:40,893] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:41,139] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 144
[2023-05-11 23:11:41,180] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:41,303] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 144
[2023-05-11 23:11:41,345] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 144
[2023-05-11 23:11:41,348] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:41,414] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 145
[2023-05-11 23:11:41,441] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 145
[2023-05-11 23:11:41,445] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:41,454] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:41,502] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:41,502] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:41,503] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:41,510] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 144
[2023-05-11 23:11:41,577] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 145
[2023-05-11 23:11:41,601] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 145
[2023-05-11 23:11:41,604] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:41,613] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:41,659] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:41,659] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:41,660] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:41,896] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 146
[2023-05-11 23:11:41,936] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:42,058] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 146
[2023-05-11 23:11:42,091] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 146
[2023-05-11 23:11:42,100] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:42,158] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 147
[2023-05-11 23:11:42,183] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 147
[2023-05-11 23:11:42,187] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:42,195] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:42,245] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:42,245] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:42,246] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:42,264] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 146
[2023-05-11 23:11:42,333] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 147
[2023-05-11 23:11:42,359] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 147
[2023-05-11 23:11:42,363] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:42,372] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:42,425] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:42,425] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:42,426] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:42,650] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 148
[2023-05-11 23:11:42,689] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:42,824] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 148
[2023-05-11 23:11:42,842] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 148
[2023-05-11 23:11:42,864] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:42,905] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 149
[2023-05-11 23:11:42,929] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 149
[2023-05-11 23:11:42,932] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:42,940] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:42,986] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:42,986] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:42,987] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:43,018] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 148
[2023-05-11 23:11:43,086] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 149
[2023-05-11 23:11:43,111] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 149
[2023-05-11 23:11:43,115] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:43,124] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:43,174] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:43,174] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:43,175] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:43,395] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 150
[2023-05-11 23:11:43,438] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:43,584] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 150
[2023-05-11 23:11:43,592] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 150
[2023-05-11 23:11:43,624] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:43,656] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 151
[2023-05-11 23:11:43,680] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 151
[2023-05-11 23:11:43,683] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:43,692] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:43,737] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:43,737] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:43,738] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:43,776] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 150
[2023-05-11 23:11:43,841] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 151
[2023-05-11 23:11:43,864] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 151
[2023-05-11 23:11:43,867] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:43,876] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:43,923] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:43,923] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:43,924] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:44,127] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 152
[2023-05-11 23:11:44,170] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:44,330] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 152
[2023-05-11 23:11:44,335] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 152
[2023-05-11 23:11:44,374] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-11 23:11:44,402] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 153
[2023-05-11 23:11:44,428] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 153
[2023-05-11 23:11:44,432] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:44,438] torch._dynamo.convert_frame: [WARNING] torch._dynamo hit config.cache_size_limit (64)
   function: 'forward' (/gpfs/accounts/qingqu_root/qingqu1/yifulu/dpm-solver/example_v2/score_sde_pytorch/models/layerspp.py:242)
   reasons:  ___check_obj_id(self, 22480494281728)
to diagnose recompilation issues, see https://pytorch.org/docs/master/dynamo/troubleshooting.html.
[2023-05-11 23:11:44,438] torch._dynamo.convert_frame: [INFO] converting frame raised unsupported, leaving it unconverted
[2023-05-11 23:11:44,529] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 152
[2023-05-11 23:11:44,577] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:44,592] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 153
[2023-05-11 23:11:44,616] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 153
[2023-05-11 23:11:44,619] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:44,624] torch._dynamo.convert_frame: [WARNING] torch._dynamo hit config.cache_size_limit (64)
   function: 'forward' (/gpfs/accounts/qingqu_root/qingqu1/yifulu/dpm-solver/example_v2/score_sde_pytorch/models/layerspp.py:242)
   reasons:  ___check_obj_id(self, 22515493405312)
to diagnose recompilation issues, see https://pytorch.org/docs/master/dynamo/troubleshooting.html.
[2023-05-11 23:11:44,624] torch._dynamo.convert_frame: [INFO] converting frame raised unsupported, leaving it unconverted
[2023-05-11 23:11:44,641] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:11:44,690] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:44,690] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:44,690] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:44,757] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:44,758] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:44,758] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:11:44,814] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 154
[2023-05-11 23:11:44,872] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 154
[2023-05-11 23:11:44,884] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 154
[2023-05-11 23:11:44,941] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 154
[2023-05-11 23:11:45,385] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 155
[2023-05-11 23:11:45,462] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 155
[2023-05-11 23:11:45,537] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 155
[2023-05-11 23:11:45,569] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:45,576] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-11 23:11:45,581] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-11 23:11:45,582] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:45,582] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:45,582] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:11:45,607] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 156
[2023-05-11 23:11:45,610] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 155
[2023-05-11 23:11:45,642] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:45,649] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-11 23:11:45,654] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-11 23:11:45,655] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:11:45,655] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:11:45,656] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:11:45,682] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 156
[2023-05-11 23:11:45,932] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 156
[2023-05-11 23:11:45,933] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:11:46,011] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 156
[2023-05-11 23:11:46,011] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[2023-05-11 23:11:53,570] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 156
[2023-05-11 23:11:53,570] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 156
[2023-05-11 23:11:53,916] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 156
[2023-05-11 23:11:53,917] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 156
[2023-05-11 23:11:53,918] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 26
[2023-05-11 23:11:53,918] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 26
[2023-05-11 23:11:53,929] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 26
[2023-05-11 23:11:53,933] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 155
[2023-05-11 23:11:53,934] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 26
[2023-05-11 23:11:53,938] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 155
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:11:54,967] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 155
[2023-05-11 23:11:54,972] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 155
[2023-05-11 23:11:54,976] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 154
[2023-05-11 23:11:54,980] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 154
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:11:55,748] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 154
[2023-05-11 23:11:55,754] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 154
[2023-05-11 23:11:55,817] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 23
[2023-05-11 23:11:55,817] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 23
[2023-05-11 23:11:55,827] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 23
[2023-05-11 23:11:55,827] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 23
[2023-05-11 23:11:55,827] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 153
[2023-05-11 23:11:55,827] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 153
[2023-05-11 23:11:55,858] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 153
[2023-05-11 23:11:55,858] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 153
[2023-05-11 23:11:55,863] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 152
[2023-05-11 23:11:55,864] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 152
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:11:57,388] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 152
[2023-05-11 23:11:57,397] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 151
[2023-05-11 23:11:57,418] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 151
[2023-05-11 23:11:57,422] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 150
[2023-05-11 23:11:57,463] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 152
[2023-05-11 23:11:57,472] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 151
[2023-05-11 23:11:57,493] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 151
[2023-05-11 23:11:57,497] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 150
[2023-05-11 23:11:58,233] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 150
[2023-05-11 23:11:58,236] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 149
[2023-05-11 23:11:58,257] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 149
[2023-05-11 23:11:58,261] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 148
[2023-05-11 23:11:58,299] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 150
[2023-05-11 23:11:58,301] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 149
[2023-05-11 23:11:58,322] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 149
[2023-05-11 23:11:58,326] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 148
[2023-05-11 23:11:58,573] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 148
[2023-05-11 23:11:58,576] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 147
[2023-05-11 23:11:58,596] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 147
[2023-05-11 23:11:58,601] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 146
[2023-05-11 23:11:58,637] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 148
[2023-05-11 23:11:58,640] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 147
[2023-05-11 23:11:58,661] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 147
[2023-05-11 23:11:58,665] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 146
[2023-05-11 23:11:58,915] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 146
[2023-05-11 23:11:58,917] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 145
[2023-05-11 23:11:58,939] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 145
[2023-05-11 23:11:58,944] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 144
[2023-05-11 23:11:58,978] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 146
[2023-05-11 23:11:58,981] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 145
[2023-05-11 23:11:59,001] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 145
[2023-05-11 23:11:59,006] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 144
[2023-05-11 23:11:59,272] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 144
[2023-05-11 23:11:59,274] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 143
[2023-05-11 23:11:59,295] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 143
[2023-05-11 23:11:59,300] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 142
[2023-05-11 23:11:59,330] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 144
[2023-05-11 23:11:59,332] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 143
[2023-05-11 23:11:59,353] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 143
[2023-05-11 23:11:59,357] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 142
[2023-05-11 23:11:59,613] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 142
[2023-05-11 23:11:59,616] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 141
[2023-05-11 23:11:59,636] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 141
[2023-05-11 23:11:59,641] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 140
[2023-05-11 23:11:59,673] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 142
[2023-05-11 23:11:59,675] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 141
[2023-05-11 23:11:59,696] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 141
[2023-05-11 23:11:59,700] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 140
[2023-05-11 23:11:59,958] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 140
[2023-05-11 23:11:59,961] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 139
[2023-05-11 23:11:59,991] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 139
[2023-05-11 23:12:00,017] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 140
[2023-05-11 23:12:00,019] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 139
[2023-05-11 23:12:00,024] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 138
[2023-05-11 23:12:00,049] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 139
[2023-05-11 23:12:00,061] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 138
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:12:01,083] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 138
[2023-05-11 23:12:01,088] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 57
[2023-05-11 23:12:01,104] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 57
[2023-05-11 23:12:01,105] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 138
[2023-05-11 23:12:01,105] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 137
[2023-05-11 23:12:01,109] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 57
[2023-05-11 23:12:01,128] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 57
[2023-05-11 23:12:01,129] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 137
[2023-05-11 23:12:01,460] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 137
[2023-05-11 23:12:01,481] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 137
[2023-05-11 23:12:01,542] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 136
[2023-05-11 23:12:01,542] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 136
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:12:02,800] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 136
[2023-05-11 23:12:02,809] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 136
[2023-05-11 23:12:02,867] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 135
[2023-05-11 23:12:02,867] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 135
[2023-05-11 23:12:02,887] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 135
[2023-05-11 23:12:02,887] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 135
[2023-05-11 23:12:02,891] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 134
[2023-05-11 23:12:02,893] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 134
[2023-05-11 23:12:03,219] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 134
[2023-05-11 23:12:03,221] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 134
[2023-05-11 23:12:03,222] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 133
[2023-05-11 23:12:03,223] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 133
[2023-05-11 23:12:03,243] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 133
[2023-05-11 23:12:03,244] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 133
[2023-05-11 23:12:03,249] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 132
[2023-05-11 23:12:03,250] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 132
[2023-05-11 23:12:03,574] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 132
[2023-05-11 23:12:03,575] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 132
[2023-05-11 23:12:03,577] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 131
[2023-05-11 23:12:03,577] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 131
[2023-05-11 23:12:03,597] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 131
[2023-05-11 23:12:03,598] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 131
[2023-05-11 23:12:03,602] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 130
[2023-05-11 23:12:03,602] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 130
[2023-05-11 23:12:03,912] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 130
[2023-05-11 23:12:03,913] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 130
[2023-05-11 23:12:03,914] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 129
[2023-05-11 23:12:03,915] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 129
[2023-05-11 23:12:03,935] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 129
[2023-05-11 23:12:03,935] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 129
[2023-05-11 23:12:03,940] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 128
[2023-05-11 23:12:03,940] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 128
[2023-05-11 23:12:04,269] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 128
[2023-05-11 23:12:04,270] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 128
[2023-05-11 23:12:04,271] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 127
[2023-05-11 23:12:04,272] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 127
[2023-05-11 23:12:04,293] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 127
[2023-05-11 23:12:04,294] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 127
[2023-05-11 23:12:04,298] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 126
[2023-05-11 23:12:04,300] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 126
[2023-05-11 23:12:04,612] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 126
[2023-05-11 23:12:04,614] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 125
[2023-05-11 23:12:04,615] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 126
[2023-05-11 23:12:04,617] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 125
[2023-05-11 23:12:04,634] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 125
[2023-05-11 23:12:04,637] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 125
[2023-05-11 23:12:04,640] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 124
[2023-05-11 23:12:04,641] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 124
[2023-05-11 23:12:04,958] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 124
[2023-05-11 23:12:04,959] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 124
[2023-05-11 23:12:05,916] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 123
[2023-05-11 23:12:05,916] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 123
[2023-05-11 23:12:05,936] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 123
[2023-05-11 23:12:05,936] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 123
[2023-05-11 23:12:05,941] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 122
[2023-05-11 23:12:05,941] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 122
[2023-05-11 23:12:06,269] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 122
[2023-05-11 23:12:06,269] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 122
[2023-05-11 23:12:06,271] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 121
[2023-05-11 23:12:06,272] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 121
[2023-05-11 23:12:06,292] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 121
[2023-05-11 23:12:06,292] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 121
[2023-05-11 23:12:06,297] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 120
[2023-05-11 23:12:06,297] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 120
[2023-05-11 23:12:06,610] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 120
[2023-05-11 23:12:06,612] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 120
[2023-05-11 23:12:06,613] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 119
[2023-05-11 23:12:06,614] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 119
[2023-05-11 23:12:06,641] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 119
[2023-05-11 23:12:06,642] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 119
[2023-05-11 23:12:06,654] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 118
[2023-05-11 23:12:06,656] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 118
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:12:07,686] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 118
[2023-05-11 23:12:07,690] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 76
[2023-05-11 23:12:07,692] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 118
[2023-05-11 23:12:07,696] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 76
[2023-05-11 23:12:07,712] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 76
[2023-05-11 23:12:07,713] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 117
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:12:08,172] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 76
[2023-05-11 23:12:08,173] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 117
[2023-05-11 23:12:08,258] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 117
[2023-05-11 23:12:08,329] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 116
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:12:08,719] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 117
[2023-05-11 23:12:08,735] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 116
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:12:09,988] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 116
[2023-05-11 23:12:09,999] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 115
[2023-05-11 23:12:10,022] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 115
[2023-05-11 23:12:10,027] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 114
[2023-05-11 23:12:10,076] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 116
[2023-05-11 23:12:10,087] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 115
[2023-05-11 23:12:10,109] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 115
[2023-05-11 23:12:10,114] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 114
[2023-05-11 23:12:10,360] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 114
[2023-05-11 23:12:10,363] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 113
[2023-05-11 23:12:10,385] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 113
[2023-05-11 23:12:10,389] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 112
[2023-05-11 23:12:10,450] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 114
[2023-05-11 23:12:10,453] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 113
[2023-05-11 23:12:10,472] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 113
[2023-05-11 23:12:10,477] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 112
[2023-05-11 23:12:10,706] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 112
[2023-05-11 23:12:10,708] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 111
[2023-05-11 23:12:10,729] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 111
[2023-05-11 23:12:10,733] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 110
[2023-05-11 23:12:10,795] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 112
[2023-05-11 23:12:10,797] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 111
[2023-05-11 23:12:10,820] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 111
[2023-05-11 23:12:10,825] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 110
[2023-05-11 23:12:11,055] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 110
[2023-05-11 23:12:11,057] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 109
[2023-05-11 23:12:11,080] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 109
[2023-05-11 23:12:11,085] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 108
[2023-05-11 23:12:11,151] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 110
[2023-05-11 23:12:11,153] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 109
[2023-05-11 23:12:11,175] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 109
[2023-05-11 23:12:11,180] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 108
[2023-05-11 23:12:11,414] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 108
[2023-05-11 23:12:11,417] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 107
[2023-05-11 23:12:11,436] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 107
[2023-05-11 23:12:11,441] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 106
[2023-05-11 23:12:11,503] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 108
[2023-05-11 23:12:11,505] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 107
[2023-05-11 23:12:11,525] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 107
[2023-05-11 23:12:11,529] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 106
[2023-05-11 23:12:11,753] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 106
[2023-05-11 23:12:11,756] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 105
[2023-05-11 23:12:11,777] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 105
[2023-05-11 23:12:11,782] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 104
[2023-05-11 23:12:11,848] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 106
[2023-05-11 23:12:11,851] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 105
[2023-05-11 23:12:11,871] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 105
[2023-05-11 23:12:11,875] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 104
[2023-05-11 23:12:12,101] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 104
[2023-05-11 23:12:12,104] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 103
[2023-05-11 23:12:12,125] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 103
[2023-05-11 23:12:12,130] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 102
[2023-05-11 23:12:12,198] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 104
[2023-05-11 23:12:12,201] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 103
[2023-05-11 23:12:12,224] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 103
[2023-05-11 23:12:12,228] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 102
[2023-05-11 23:12:12,454] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 102
[2023-05-11 23:12:12,456] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 101
[2023-05-11 23:12:12,478] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 101
[2023-05-11 23:12:12,482] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 100
[2023-05-11 23:12:12,548] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 102
[2023-05-11 23:12:12,550] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 101
[2023-05-11 23:12:12,571] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 101
[2023-05-11 23:12:12,575] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 100
[2023-05-11 23:12:12,800] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 100
[2023-05-11 23:12:12,802] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 99
[2023-05-11 23:12:12,819] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 99
[2023-05-11 23:12:12,823] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 98
[2023-05-11 23:12:12,892] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 100
[2023-05-11 23:12:12,894] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 99
[2023-05-11 23:12:12,917] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 99
[2023-05-11 23:12:12,921] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 98
[2023-05-11 23:12:13,471] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 98
[2023-05-11 23:12:13,474] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 97
[2023-05-11 23:12:13,484] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 97
[2023-05-11 23:12:13,488] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 96
[2023-05-11 23:12:13,574] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 98
[2023-05-11 23:12:13,577] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 97
[2023-05-11 23:12:13,587] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 97
[2023-05-11 23:12:13,591] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 96
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:12:14,306] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 96
[2023-05-11 23:12:14,313] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 95
[2023-05-11 23:12:14,442] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 96
[2023-05-11 23:12:14,449] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 95
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:12:14,973] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 95
[2023-05-11 23:12:14,976] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 94
[2023-05-11 23:12:14,993] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 94
[2023-05-11 23:12:14,997] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 93
[2023-05-11 23:12:15,111] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 95
[2023-05-11 23:12:15,114] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 94
[2023-05-11 23:12:15,132] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 94
[2023-05-11 23:12:15,137] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 93
[2023-05-11 23:12:15,296] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 93
[2023-05-11 23:12:15,298] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 92
[2023-05-11 23:12:15,315] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 92
[2023-05-11 23:12:15,324] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 91
[2023-05-11 23:12:15,442] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 93
[2023-05-11 23:12:15,445] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 92
[2023-05-11 23:12:15,459] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 92
[2023-05-11 23:12:15,465] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 91
[2023-05-11 23:12:15,611] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 91
[2023-05-11 23:12:15,614] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 90
[2023-05-11 23:12:15,630] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 90
[2023-05-11 23:12:15,635] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 89
[2023-05-11 23:12:15,746] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 91
[2023-05-11 23:12:15,748] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 90
[2023-05-11 23:12:15,765] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 90
[2023-05-11 23:12:15,770] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 89
[2023-05-11 23:12:15,918] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 89
[2023-05-11 23:12:15,920] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 88
[2023-05-11 23:12:15,935] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 88
[2023-05-11 23:12:15,940] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 87
[2023-05-11 23:12:16,053] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 89
[2023-05-11 23:12:16,055] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 88
[2023-05-11 23:12:16,071] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 88
[2023-05-11 23:12:16,076] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 87
[2023-05-11 23:12:16,229] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 87
[2023-05-11 23:12:16,232] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 86
[2023-05-11 23:12:16,249] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 86
[2023-05-11 23:12:16,254] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 85
[2023-05-11 23:12:16,371] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 87
[2023-05-11 23:12:16,373] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 86
[2023-05-11 23:12:16,390] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 86
[2023-05-11 23:12:16,394] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 85
[2023-05-11 23:12:16,540] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 85
[2023-05-11 23:12:16,542] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 84
[2023-05-11 23:12:16,557] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 84
[2023-05-11 23:12:16,562] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 83
[2023-05-11 23:12:16,679] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 85
[2023-05-11 23:12:16,681] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 84
[2023-05-11 23:12:16,697] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 84
[2023-05-11 23:12:16,701] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 83
[2023-05-11 23:12:16,841] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 83
[2023-05-11 23:12:16,843] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 82
[2023-05-11 23:12:16,858] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 82
[2023-05-11 23:12:16,862] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 81
[2023-05-11 23:12:16,980] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 83
[2023-05-11 23:12:16,982] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 82
[2023-05-11 23:12:16,998] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 82
[2023-05-11 23:12:17,002] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 81
[2023-05-11 23:12:17,146] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 81
[2023-05-11 23:12:17,148] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 80
[2023-05-11 23:12:17,164] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 80
[2023-05-11 23:12:17,169] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 79
[2023-05-11 23:12:17,306] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 81
[2023-05-11 23:12:17,309] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 80
[2023-05-11 23:12:17,326] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 80
[2023-05-11 23:12:17,331] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 79
[2023-05-11 23:12:17,614] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 79
[2023-05-11 23:12:17,616] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 78
[2023-05-11 23:12:17,632] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 78
[2023-05-11 23:12:17,636] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 77
[2023-05-11 23:12:17,916] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 79
[2023-05-11 23:12:17,918] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 78
[2023-05-11 23:12:17,934] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 78
[2023-05-11 23:12:17,938] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 77
[2023-05-11 23:12:18,232] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 77
[2023-05-11 23:12:18,235] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 75
[2023-05-11 23:12:18,265] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 75
[2023-05-11 23:12:18,289] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 74
[2023-05-11 23:12:18,422] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 77
[2023-05-11 23:12:18,424] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 75
[2023-05-11 23:12:18,453] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 75
[2023-05-11 23:12:18,466] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 74
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:12:20,691] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 74
[2023-05-11 23:12:20,878] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 74
[2023-05-11 23:12:23,825] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 73
[2023-05-11 23:12:23,848] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 73
[2023-05-11 23:12:23,852] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 72
[2023-05-11 23:12:23,999] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 73
[2023-05-11 23:12:24,029] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 73
[2023-05-11 23:12:24,034] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 72
[2023-05-11 23:12:24,512] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 72
[2023-05-11 23:12:24,516] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 71
[2023-05-11 23:12:24,532] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 71
[2023-05-11 23:12:24,536] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 70
[2023-05-11 23:12:24,693] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 72
[2023-05-11 23:12:24,697] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 71
[2023-05-11 23:12:24,713] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 71
[2023-05-11 23:12:24,717] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 70
[2023-05-11 23:12:24,815] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 70
[2023-05-11 23:12:24,817] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 69
[2023-05-11 23:12:24,833] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 69
[2023-05-11 23:12:24,837] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 68
[2023-05-11 23:12:25,006] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 70
[2023-05-11 23:12:25,008] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 69
[2023-05-11 23:12:25,025] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 69
[2023-05-11 23:12:25,030] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 68
[2023-05-11 23:12:25,129] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 68
[2023-05-11 23:12:25,132] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 67
[2023-05-11 23:12:25,148] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 67
[2023-05-11 23:12:25,152] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 66
[2023-05-11 23:12:25,327] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 68
[2023-05-11 23:12:25,329] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 67
[2023-05-11 23:12:25,345] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 67
[2023-05-11 23:12:25,350] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 66
[2023-05-11 23:12:25,441] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 66
[2023-05-11 23:12:25,443] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 65
[2023-05-11 23:12:25,458] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 65
[2023-05-11 23:12:25,462] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 64
[2023-05-11 23:12:25,631] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 66
[2023-05-11 23:12:25,634] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 65
[2023-05-11 23:12:25,649] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 65
[2023-05-11 23:12:25,654] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 64
[2023-05-11 23:12:25,739] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 64
[2023-05-11 23:12:25,741] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 63
[2023-05-11 23:12:25,758] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 63
[2023-05-11 23:12:25,762] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 62
[2023-05-11 23:12:25,942] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 64
[2023-05-11 23:12:25,944] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 63
[2023-05-11 23:12:25,961] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 63
[2023-05-11 23:12:25,965] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 62
[2023-05-11 23:12:26,050] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 62
[2023-05-11 23:12:26,053] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 61
[2023-05-11 23:12:26,069] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 61
[2023-05-11 23:12:26,075] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 60
[2023-05-11 23:12:26,261] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 62
[2023-05-11 23:12:26,264] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 61
[2023-05-11 23:12:26,280] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 61
[2023-05-11 23:12:26,285] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 60
[2023-05-11 23:12:26,367] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 60
[2023-05-11 23:12:26,369] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 59
[2023-05-11 23:12:26,384] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 59
[2023-05-11 23:12:26,388] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 58
[2023-05-11 23:12:26,568] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 60
[2023-05-11 23:12:26,570] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 59
[2023-05-11 23:12:26,586] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 59
[2023-05-11 23:12:26,590] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 58
[2023-05-11 23:12:26,666] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 58
[2023-05-11 23:12:26,668] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 56
[2023-05-11 23:12:26,689] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 56
[2023-05-11 23:12:26,693] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 55
[2023-05-11 23:12:26,878] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 58
[2023-05-11 23:12:26,880] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 56
[2023-05-11 23:12:26,902] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 56
[2023-05-11 23:12:26,907] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 55
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:12:29,265] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 55
[2023-05-11 23:12:29,493] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 55
[2023-05-11 23:12:30,729] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 54
[2023-05-11 23:12:30,868] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 54
[2023-05-11 23:12:30,871] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 53
[2023-05-11 23:12:30,964] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 54
[2023-05-11 23:12:30,994] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 53
[2023-05-11 23:12:30,995] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 52
[2023-05-11 23:12:31,020] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 52
[2023-05-11 23:12:31,025] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 51
[2023-05-11 23:12:31,114] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 54
[2023-05-11 23:12:31,118] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 53
[2023-05-11 23:12:31,246] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 53
[2023-05-11 23:12:31,248] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 52
[2023-05-11 23:12:31,267] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 52
[2023-05-11 23:12:31,271] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 51
[2023-05-11 23:12:31,661] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 51
[2023-05-11 23:12:31,668] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 50
[2023-05-11 23:12:31,804] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 50
[2023-05-11 23:12:31,807] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 49
[2023-05-11 23:12:31,904] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 51
[2023-05-11 23:12:31,911] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 50
[2023-05-11 23:12:31,920] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 49
[2023-05-11 23:12:31,921] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 48
[2023-05-11 23:12:31,940] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 48
[2023-05-11 23:12:31,944] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 47
[2023-05-11 23:12:32,056] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 50
[2023-05-11 23:12:32,060] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 49
[2023-05-11 23:12:32,181] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 49
[2023-05-11 23:12:32,182] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 48
[2023-05-11 23:12:32,199] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 48
[2023-05-11 23:12:32,203] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 47
[2023-05-11 23:12:32,249] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 47
[2023-05-11 23:12:32,254] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 46
[2023-05-11 23:12:32,391] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 46
[2023-05-11 23:12:32,394] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 45
[2023-05-11 23:12:32,498] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 47
[2023-05-11 23:12:32,503] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 46
[2023-05-11 23:12:32,505] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 45
[2023-05-11 23:12:32,506] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 44
[2023-05-11 23:12:32,522] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 44
[2023-05-11 23:12:32,528] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 43
[2023-05-11 23:12:32,639] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 46
[2023-05-11 23:12:32,642] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 45
[2023-05-11 23:12:32,756] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 45
[2023-05-11 23:12:32,757] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 44
[2023-05-11 23:12:32,773] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 44
[2023-05-11 23:12:32,777] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 43
[2023-05-11 23:12:32,813] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 43
[2023-05-11 23:12:32,820] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 42
[2023-05-11 23:12:32,958] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 42
[2023-05-11 23:12:32,961] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 41
[2023-05-11 23:12:33,081] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 41
[2023-05-11 23:12:33,082] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 40
[2023-05-11 23:12:33,082] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 43
[2023-05-11 23:12:33,088] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 42
[2023-05-11 23:12:33,099] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 40
[2023-05-11 23:12:33,103] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 39
[2023-05-11 23:12:33,234] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 42
[2023-05-11 23:12:33,237] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 41
[2023-05-11 23:12:33,353] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 41
[2023-05-11 23:12:33,354] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 40
[2023-05-11 23:12:33,369] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 40
[2023-05-11 23:12:33,375] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 39
[2023-05-11 23:12:33,402] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 39
[2023-05-11 23:12:33,407] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 38
[2023-05-11 23:12:33,541] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 38
[2023-05-11 23:12:33,544] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 37
[2023-05-11 23:12:33,664] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 39
[2023-05-11 23:12:33,670] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 38
[2023-05-11 23:12:33,805] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 38
[2023-05-11 23:12:33,808] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 37
[2023-05-11 23:12:33,923] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 37
[2023-05-11 23:12:33,925] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 36
[2023-05-11 23:12:33,941] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 36
[2023-05-11 23:12:33,945] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 35
[2023-05-11 23:12:34,164] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 37
[2023-05-11 23:12:34,166] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 36
[2023-05-11 23:12:34,183] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 36
[2023-05-11 23:12:34,187] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 35
[2023-05-11 23:12:34,248] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 35
[2023-05-11 23:12:34,253] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 34
[2023-05-11 23:12:34,481] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 35
[2023-05-11 23:12:34,487] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 34
[2023-05-11 23:12:34,621] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 34
[2023-05-11 23:12:34,624] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 33
[2023-05-11 23:12:34,737] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 33
[2023-05-11 23:12:34,739] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 32
[2023-05-11 23:12:34,754] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 32
[2023-05-11 23:12:34,758] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 31
[2023-05-11 23:12:34,893] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 34
[2023-05-11 23:12:34,896] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 33
[2023-05-11 23:12:35,018] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 33
[2023-05-11 23:12:35,019] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 32
[2023-05-11 23:12:35,036] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 32
[2023-05-11 23:12:35,041] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 31
[2023-05-11 23:12:35,060] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 31
[2023-05-11 23:12:35,066] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 30
[2023-05-11 23:12:35,211] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 30
[2023-05-11 23:12:35,214] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 29
[2023-05-11 23:12:35,332] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 29
[2023-05-11 23:12:35,333] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 28
[2023-05-11 23:12:35,348] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 28
[2023-05-11 23:12:35,351] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 31
[2023-05-11 23:12:35,352] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 27
[2023-05-11 23:12:35,356] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 30
[2023-05-11 23:12:35,492] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 30
[2023-05-11 23:12:35,495] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 29
[2023-05-11 23:12:35,608] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 29
[2023-05-11 23:12:35,609] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 28
[2023-05-11 23:12:35,624] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 28
[2023-05-11 23:12:35,630] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 27
[2023-05-11 23:12:35,640] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 27
[2023-05-11 23:12:35,645] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 25
[2023-05-11 23:12:35,781] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 25
[2023-05-11 23:12:35,784] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 24
[2023-05-11 23:12:35,900] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 24
[2023-05-11 23:12:35,902] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 22
[2023-05-11 23:12:35,926] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 22
[2023-05-11 23:12:35,927] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 27
[2023-05-11 23:12:35,933] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 25
[2023-05-11 23:12:35,937] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 21
[2023-05-11 23:12:36,076] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 25
[2023-05-11 23:12:36,080] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 24
[2023-05-11 23:12:36,202] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 24
[2023-05-11 23:12:36,204] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 22
[2023-05-11 23:12:36,228] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 22
[2023-05-11 23:12:36,239] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 21
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:12:36,905] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 21
[2023-05-11 23:12:36,916] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 20
[2023-05-11 23:12:36,933] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 20
[2023-05-11 23:12:36,938] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 19
[2023-05-11 23:12:37,221] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 21
[2023-05-11 23:12:37,232] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 20
[2023-05-11 23:12:37,249] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 20
[2023-05-11 23:12:37,252] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 19
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:12:38,003] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 19
[2023-05-11 23:12:38,048] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 18
[2023-05-11 23:12:38,327] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 19
[2023-05-11 23:12:38,343] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 18
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:12:40,193] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 18
[2023-05-11 23:12:40,485] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 18
[2023-05-11 23:12:40,910] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-05-11 23:12:40,927] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-05-11 23:12:40,930] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 17
[2023-05-11 23:12:41,203] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-05-11 23:12:41,221] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-05-11 23:12:41,224] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 17
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:12:41,961] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 17
[2023-05-11 23:12:41,968] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 16
[2023-05-11 23:12:42,259] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 17
[2023-05-11 23:12:42,266] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 16
[2023-05-11 23:12:42,454] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 16
[2023-05-11 23:12:42,459] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 15
[2023-05-11 23:12:42,679] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 15
[2023-05-11 23:12:42,683] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 14
[2023-05-11 23:12:42,743] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 16
[2023-05-11 23:12:42,748] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 15
[2023-05-11 23:12:42,815] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 14
[2023-05-11 23:12:42,818] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 13
[2023-05-11 23:12:42,969] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 15
[2023-05-11 23:12:42,973] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 14
[2023-05-11 23:12:43,031] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 13
[2023-05-11 23:12:43,035] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 12
[2023-05-11 23:12:43,110] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 14
[2023-05-11 23:12:43,114] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 13
[2023-05-11 23:12:43,173] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 12
[2023-05-11 23:12:43,176] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 11
[2023-05-11 23:12:43,340] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 13
[2023-05-11 23:12:43,343] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 12
[2023-05-11 23:12:43,401] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 11
[2023-05-11 23:12:43,404] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 10
[2023-05-11 23:12:43,477] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 12
[2023-05-11 23:12:43,480] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 11
[2023-05-11 23:12:43,533] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 10
[2023-05-11 23:12:43,537] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 9
[2023-05-11 23:12:43,692] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 11
[2023-05-11 23:12:43,695] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 10
[2023-05-11 23:12:43,746] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 9
[2023-05-11 23:12:43,749] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 8
[2023-05-11 23:12:43,827] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 10
[2023-05-11 23:12:43,830] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 9
[2023-05-11 23:12:43,879] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 8
[2023-05-11 23:12:43,883] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 7
[2023-05-11 23:12:44,053] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 9
[2023-05-11 23:12:44,056] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 8
[2023-05-11 23:12:44,104] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 7
[2023-05-11 23:12:44,107] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 6
[2023-05-11 23:12:44,194] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 8
[2023-05-11 23:12:44,197] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 7
[2023-05-11 23:12:44,243] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 6
[2023-05-11 23:12:44,246] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 5
[2023-05-11 23:12:44,414] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 7
[2023-05-11 23:12:44,417] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 6
[2023-05-11 23:12:44,458] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 5
[2023-05-11 23:12:44,462] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-05-11 23:12:44,545] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 6
[2023-05-11 23:12:44,548] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 5
[2023-05-11 23:12:44,590] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-05-11 23:12:44,593] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-05-11 23:12:44,759] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 5
[2023-05-11 23:12:44,762] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-05-11 23:12:44,803] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-05-11 23:12:44,806] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-05-11 23:12:44,892] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-05-11 23:12:44,895] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-05-11 23:12:44,936] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-05-11 23:12:45,109] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-05-11 23:12:45,112] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-05-11 23:12:45,247] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
I0511 23:12:45.560075 22485033404224 run_lib.py:146] step: 0, training_loss: 9.96031e-01
[2023-05-11 23:12:45,595] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-11 23:12:45,595] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-11 23:12:45,599] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-11 23:12:45,599] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-11 23:12:45,600] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:45,600] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:45,600] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:45,600] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:45,600] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:45,600] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:45,611] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 157
[2023-05-11 23:12:45,611] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 157
[2023-05-11 23:12:45,648] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 157
[2023-05-11 23:12:45,648] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:45,650] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 157
[2023-05-11 23:12:45,650] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:45,654] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:12:45,655] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:12:45,768] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:45,768] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:45,769] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:12:45,770] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:45,770] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:45,771] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:12:45,812] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 158
[2023-05-11 23:12:45,814] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 158
//usrusr//binbin//ldld::  skippingskipping  incompatibleincompatible  //usrusr//liblib//libcuda.solibcuda.so  whenwhen  searchingsearching  forfor  --lcudalcuda

//usrusr//binbin//ldld::  skippingskipping  incompatibleincompatible  //usrusr//liblib//libc.solibc.so  whenwhen  searchingsearching  forfor  --lclc

[2023-05-11 23:12:46,426] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 158
[2023-05-11 23:12:46,429] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 158
[2023-05-11 23:12:46,657] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 159
[2023-05-11 23:12:46,662] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 159
[2023-05-11 23:12:47,095] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 159
[2023-05-11 23:12:47,127] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:47,135] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-11 23:12:47,136] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-11 23:12:47,137] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:47,138] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:47,138] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:47,147] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 160
[2023-05-11 23:12:47,159] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 160
[2023-05-11 23:12:47,159] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:47,164] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:12:47,288] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:47,288] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:47,288] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:12:47,334] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 161
[2023-05-11 23:12:47,386] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 161
[2023-05-11 23:12:47,577] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 159
[2023-05-11 23:12:47,608] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:47,615] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 162
[2023-05-11 23:12:47,616] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-11 23:12:47,617] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-11 23:12:47,618] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:47,618] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:47,619] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:47,628] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 160
[2023-05-11 23:12:47,643] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 160
[2023-05-11 23:12:47,644] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:47,648] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:12:47,761] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:47,762] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:47,762] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:12:47,807] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 161
[2023-05-11 23:12:47,856] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 161
[2023-05-11 23:12:48,093] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 162
[2023-05-11 23:12:48,199] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 162
[2023-05-11 23:12:48,217] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 162
[2023-05-11 23:12:48,231] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:48,238] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:12:48,249] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:48,256] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:12:48,361] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:48,361] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:48,362] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:12:48,378] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:48,378] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:48,379] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:12:48,409] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 163
[2023-05-11 23:12:48,425] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 163
[2023-05-11 23:12:48,460] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 163
[2023-05-11 23:12:48,475] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 163
[2023-05-11 23:12:48,691] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 164
[2023-05-11 23:12:48,704] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 164
[2023-05-11 23:12:48,807] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 164
[2023-05-11 23:12:48,821] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 164
[2023-05-11 23:12:48,838] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:48,844] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:12:48,852] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:48,858] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:12:48,955] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:48,955] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:48,955] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:12:48,969] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:48,969] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:48,970] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:12:48,998] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 165
[2023-05-11 23:12:49,014] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 165
[2023-05-11 23:12:49,049] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 165
[2023-05-11 23:12:49,065] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 165
[2023-05-11 23:12:49,293] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 166
[2023-05-11 23:12:49,311] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 166
[2023-05-11 23:12:49,418] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 166
[2023-05-11 23:12:49,435] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 166
[2023-05-11 23:12:49,450] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:49,456] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:12:49,466] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:49,472] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:12:49,566] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:49,566] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:49,567] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:12:49,580] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:49,581] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:49,581] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:12:49,609] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 167
[2023-05-11 23:12:49,624] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 167
[2023-05-11 23:12:49,659] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 167
[2023-05-11 23:12:49,674] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 167
[2023-05-11 23:12:49,892] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 168
[2023-05-11 23:12:49,905] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 168
[2023-05-11 23:12:50,010] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 168
[2023-05-11 23:12:50,027] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 168
[2023-05-11 23:12:50,042] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:50,049] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:12:50,058] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:50,065] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:12:50,171] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:50,172] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:50,172] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:12:50,189] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:50,189] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:50,190] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:12:50,218] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 169
[2023-05-11 23:12:50,236] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 169
[2023-05-11 23:12:50,271] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 169
[2023-05-11 23:12:50,288] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 169
[2023-05-11 23:12:50,509] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 170
[2023-05-11 23:12:50,528] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 170
[2023-05-11 23:12:50,624] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 170
[2023-05-11 23:12:50,643] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 170
[2023-05-11 23:12:50,655] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:50,662] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:12:50,674] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:50,680] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:12:50,773] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:50,774] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:50,774] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:12:50,790] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:50,790] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:50,790] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:12:50,817] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 171
[2023-05-11 23:12:50,835] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 171
[2023-05-11 23:12:50,869] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 171
[2023-05-11 23:12:50,885] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 171
[2023-05-11 23:12:51,107] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 172
[2023-05-11 23:12:51,125] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 172
[2023-05-11 23:12:51,230] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 172
[2023-05-11 23:12:51,247] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 172
[2023-05-11 23:12:51,262] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:51,268] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:12:51,279] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:51,285] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:12:51,388] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:51,389] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:51,389] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:12:51,407] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:51,408] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:51,408] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:12:51,435] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 173
[2023-05-11 23:12:51,454] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 173
[2023-05-11 23:12:51,487] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 173
[2023-05-11 23:12:51,504] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 173
[2023-05-11 23:12:51,717] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 174
[2023-05-11 23:12:51,738] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 174
[2023-05-11 23:12:51,836] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 174
[2023-05-11 23:12:51,858] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 174
[2023-05-11 23:12:51,868] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:51,874] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-11 23:12:51,877] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-11 23:12:51,879] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:51,879] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:51,879] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:51,890] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:51,890] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 175
[2023-05-11 23:12:51,895] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-11 23:12:51,899] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-11 23:12:51,900] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:51,900] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:51,900] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:51,911] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 175
[2023-05-11 23:12:51,927] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 175
[2023-05-11 23:12:51,927] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:51,936] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-11 23:12:51,939] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-11 23:12:51,940] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:51,940] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:51,941] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:51,946] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 175
[2023-05-11 23:12:51,947] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:51,951] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 176
[2023-05-11 23:12:51,956] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-11 23:12:51,959] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-11 23:12:51,960] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:51,960] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:51,960] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:51,971] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 176
[2023-05-11 23:12:51,982] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 176
[2023-05-11 23:12:51,982] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:51,992] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:12:51,999] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 176
[2023-05-11 23:12:52,000] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:52,009] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:12:52,107] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:52,107] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:52,107] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:12:52,126] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:52,126] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:52,126] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:12:52,153] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 177
[2023-05-11 23:12:52,172] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 177
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-11 23:12:52,761] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 177
[2023-05-11 23:12:52,778] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 177
[2023-05-11 23:12:52,994] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 178
[2023-05-11 23:12:53,015] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 178
[2023-05-11 23:12:53,447] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 178
[2023-05-11 23:12:53,468] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 178
[2023-05-11 23:12:53,478] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:53,486] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-11 23:12:53,487] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-11 23:12:53,488] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:53,488] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:53,489] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:53,498] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 179
[2023-05-11 23:12:53,499] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:53,507] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-11 23:12:53,508] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-11 23:12:53,509] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:53,509] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:53,509] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:53,514] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 179
[2023-05-11 23:12:53,514] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:53,518] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 179
[2023-05-11 23:12:53,524] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-11 23:12:53,529] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-11 23:12:53,530] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:53,531] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:53,531] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:53,535] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 179
[2023-05-11 23:12:53,535] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:53,543] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 180
[2023-05-11 23:12:53,545] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-11 23:12:53,550] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-11 23:12:53,551] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:53,551] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:53,551] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:53,564] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 180
[2023-05-11 23:12:53,892] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 180
[2023-05-11 23:12:53,892] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:53,903] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-11 23:12:53,908] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-11 23:12:53,909] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:53,910] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:53,910] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:53,911] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 180
[2023-05-11 23:12:53,912] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:53,923] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-11 23:12:53,925] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 181
[2023-05-11 23:12:53,928] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-11 23:12:53,929] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:53,929] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:53,929] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:53,942] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 181
[2023-05-11 23:12:54,281] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 181
[2023-05-11 23:12:54,281] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:54,293] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:12:54,294] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 181
[2023-05-11 23:12:54,294] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:54,306] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:12:54,413] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:54,413] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:54,414] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:12:54,428] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:54,428] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:54,428] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:12:54,461] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 182
[2023-05-11 23:12:54,475] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 182
[2023-05-11 23:12:54,518] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 182
[2023-05-11 23:12:54,532] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 182
[2023-05-11 23:12:54,753] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 183
[2023-05-11 23:12:54,771] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 183
[2023-05-11 23:12:54,881] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 183
[2023-05-11 23:12:54,896] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 183
[2023-05-11 23:12:54,912] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:54,917] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-11 23:12:54,922] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-11 23:12:54,923] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:54,923] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:54,923] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:54,927] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:54,932] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-11 23:12:54,936] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 184
[2023-05-11 23:12:54,937] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-11 23:12:54,938] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:54,938] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:54,938] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:54,951] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 184
[2023-05-11 23:12:55,303] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 184
[2023-05-11 23:12:55,303] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:55,315] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 184
[2023-05-11 23:12:55,316] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
I0511 23:12:55.349556 22485033404224 run_lib.py:167] step: 0, eval_loss: 9.97117e-01
[2023-05-11 23:12:55,366] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-11 23:12:55,371] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-11 23:12:55,372] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:55,372] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:55,372] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:55,378] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-11 23:12:55,382] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-11 23:12:55,383] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:55,384] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:55,384] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:55,402] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 185
[2023-05-11 23:12:55,410] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 185
[2023-05-11 23:12:55,432] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 185
[2023-05-11 23:12:55,433] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:55,441] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 185
[2023-05-11 23:12:55,442] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:55,455] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-11 23:12:55,459] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-11 23:12:55,460] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:55,460] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:55,460] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:55,463] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-11 23:12:55,467] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-11 23:12:55,469] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:55,469] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:55,469] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:55,486] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 186
[2023-05-11 23:12:55,496] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 186
[2023-05-11 23:12:55,516] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 186
[2023-05-11 23:12:55,516] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:55,526] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 186
[2023-05-11 23:12:55,526] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:55,526] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-11 23:12:55,530] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-11 23:12:55,531] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:55,531] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:55,531] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:55,536] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-11 23:12:55,540] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-11 23:12:55,541] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:55,541] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:55,541] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:55,555] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 187
[2023-05-11 23:12:55,565] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 187
[2023-05-11 23:12:55,583] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 187
[2023-05-11 23:12:55,583] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:55,593] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 187
[2023-05-11 23:12:55,593] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:55,605] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-11 23:12:55,609] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-11 23:12:55,611] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:55,611] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:55,611] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:55,612] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-11 23:12:55,617] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-11 23:12:55,618] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:55,618] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:55,619] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:55,636] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 188
[2023-05-11 23:12:55,643] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 188
[2023-05-11 23:12:55,665] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 188
[2023-05-11 23:12:55,666] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:55,673] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 188
[2023-05-11 23:12:55,673] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:55,677] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-11 23:12:55,682] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-11 23:12:55,684] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:55,684] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:55,684] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:55,685] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-11 23:12:55,690] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-11 23:12:55,691] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:12:55,691] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:12:55,692] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:12:55,710] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 189
[2023-05-11 23:12:55,720] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 189
[2023-05-11 23:12:55,737] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 189
[2023-05-11 23:12:55,738] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:55,747] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 189
[2023-05-11 23:12:55,748] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:12:55,839] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 189
[2023-05-11 23:12:55,848] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 189
[2023-05-11 23:12:56,187] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 189
[2023-05-11 23:12:56,194] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 189
[2023-05-11 23:12:56,201] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 188
[2023-05-11 23:12:56,207] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 188
[2023-05-11 23:12:56,563] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 188
[2023-05-11 23:12:56,563] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 188
[2023-05-11 23:12:56,586] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 187
[2023-05-11 23:12:56,587] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 187
[2023-05-11 23:12:56,941] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 187
[2023-05-11 23:12:56,942] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 187
[2023-05-11 23:12:56,952] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 186
[2023-05-11 23:12:56,952] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 186
[2023-05-11 23:12:57,302] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 186
[2023-05-11 23:12:57,303] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 186
[2023-05-11 23:12:57,326] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 185
[2023-05-11 23:12:57,326] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 185
[2023-05-11 23:12:57,682] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 185
[2023-05-11 23:12:57,683] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 185
I0511 23:13:20.905018 22485033404224 run_lib.py:146] step: 50, training_loss: 9.85721e-01
I0511 23:13:45.518388 22485033404224 run_lib.py:146] step: 100, training_loss: 9.56317e-01
I0511 23:13:45.679626 22485033404224 run_lib.py:167] step: 100, eval_loss: 9.63496e-01
I0511 23:14:09.395203 22485033404224 run_lib.py:146] step: 150, training_loss: 8.87408e-01
I0511 23:14:33.177502 22485033404224 run_lib.py:146] step: 200, training_loss: 7.93317e-01
I0511 23:14:33.341581 22485033404224 run_lib.py:167] step: 200, eval_loss: 8.31370e-01
I0511 23:14:57.668158 22485033404224 run_lib.py:146] step: 250, training_loss: 6.81692e-01
I0511 23:15:21.442091 22485033404224 run_lib.py:146] step: 300, training_loss: 5.60334e-01
I0511 23:15:21.603601 22485033404224 run_lib.py:167] step: 300, eval_loss: 6.32910e-01
I0511 23:15:45.389147 22485033404224 run_lib.py:146] step: 350, training_loss: 4.41331e-01
[2023-05-11 23:16:04,504] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing get_timestep_embedding
[2023-05-11 23:16:04,507] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing get_timestep_embedding
[2023-05-11 23:16:04,520] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing get_timestep_embedding (RETURN_VALUE)
[2023-05-11 23:16:04,522] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:04,522] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:04,523] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:16:04,524] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing get_timestep_embedding (RETURN_VALUE)
[2023-05-11 23:16:04,526] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:04,526] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:04,526] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:16:04,559] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 190
[2023-05-11 23:16:04,563] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 190
[2023-05-11 23:16:05,149] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 190
[2023-05-11 23:16:05,149] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 190
[2023-05-11 23:16:05,149] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:05,149] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:05,175] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-11 23:16:05,175] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-11 23:16:05,178] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-11 23:16:05,178] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-11 23:16:05,179] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:05,179] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:05,179] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:16:05,180] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:05,180] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:05,180] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:16:05,204] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 191
[2023-05-11 23:16:05,204] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 191
[2023-05-11 23:16:05,551] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 191
[2023-05-11 23:16:05,551] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 191
[2023-05-11 23:16:05,551] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:05,551] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:05,596] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:16:05,596] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:16:05,723] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:05,723] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:05,723] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:16:05,725] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:05,725] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:05,726] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:16:05,851] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 192
[2023-05-11 23:16:05,855] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 192
[2023-05-11 23:16:06,293] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 192
[2023-05-11 23:16:06,294] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 192
[2023-05-11 23:16:06,825] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 193
[2023-05-11 23:16:06,833] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 193
[2023-05-11 23:16:09,011] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 193
[2023-05-11 23:16:09,044] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:09,069] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 193
[2023-05-11 23:16:09,103] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:12,786] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-11 23:16:12,787] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-11 23:16:12,788] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:12,788] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:12,788] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:16:12,804] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 194
[2023-05-11 23:16:12,824] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-11 23:16:12,825] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-11 23:16:12,826] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:12,826] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:12,827] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:16:12,843] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 194
[2023-05-11 23:16:13,112] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 194
[2023-05-11 23:16:13,113] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:13,119] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:16:13,149] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 194
[2023-05-11 23:16:13,150] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:13,156] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:16:13,238] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:13,238] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:13,239] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:16:13,277] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:13,277] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:13,278] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:16:13,367] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 195
[2023-05-11 23:16:13,408] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 195
[2023-05-11 23:16:13,426] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 195
[2023-05-11 23:16:13,466] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 195
[2023-05-11 23:16:13,952] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 196
[2023-05-11 23:16:13,994] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 196
[2023-05-11 23:16:14,095] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 196
[2023-05-11 23:16:14,128] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:14,135] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 196
[2023-05-11 23:16:14,136] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:16:14,168] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:14,175] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:16:14,252] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:14,252] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:14,252] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:16:14,292] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:14,292] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:14,293] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:16:14,382] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 197
[2023-05-11 23:16:14,425] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 197
[2023-05-11 23:16:14,439] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 197
[2023-05-11 23:16:14,482] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 197
[2023-05-11 23:16:14,967] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 198
[2023-05-11 23:16:15,014] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 198
[2023-05-11 23:16:15,106] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 198
[2023-05-11 23:16:15,139] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:15,146] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:16:15,152] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 198
[2023-05-11 23:16:15,185] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:15,192] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:16:15,262] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:15,262] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:15,263] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:16:15,311] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:15,312] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:15,312] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:16:15,393] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 199
[2023-05-11 23:16:15,445] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 199
[2023-05-11 23:16:15,451] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 199
[2023-05-11 23:16:15,504] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 199
[2023-05-11 23:16:15,979] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 200
[2023-05-11 23:16:16,034] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 200
[2023-05-11 23:16:16,118] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 200
[2023-05-11 23:16:16,151] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:16,158] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:16:16,171] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 200
[2023-05-11 23:16:16,204] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:16,211] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:16:16,275] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:16,276] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:16,276] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:16:16,332] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:16,332] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:16,333] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:16:16,407] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 201
[2023-05-11 23:16:16,465] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 201
[2023-05-11 23:16:16,466] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 201
[2023-05-11 23:16:16,525] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 201
[2023-05-11 23:16:16,985] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 202
[2023-05-11 23:16:17,048] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 202
[2023-05-11 23:16:17,186] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 202
[2023-05-11 23:16:17,219] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:17,227] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:16:17,348] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:17,348] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:17,349] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:16:17,473] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 202
[2023-05-11 23:16:17,480] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 203
[2023-05-11 23:16:17,507] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:17,515] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:16:17,640] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:17,640] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:17,641] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:16:17,776] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 203
[2023-05-11 23:16:17,834] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 203
[2023-05-11 23:16:17,896] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 203
[2023-05-11 23:16:18,350] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 204
[2023-05-11 23:16:18,426] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 204
[2023-05-11 23:16:18,500] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 204
[2023-05-11 23:16:18,534] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:18,543] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:16:18,576] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 204
[2023-05-11 23:16:18,611] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:18,620] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:16:18,674] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:18,674] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:18,675] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:16:18,743] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:18,744] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:18,744] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:16:18,801] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 205
[2023-05-11 23:16:18,855] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 205
[2023-05-11 23:16:18,870] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 205
[2023-05-11 23:16:18,926] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 205
[2023-05-11 23:16:19,369] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 206
[2023-05-11 23:16:19,453] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 206
[2023-05-11 23:16:19,519] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 206
[2023-05-11 23:16:19,554] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:19,562] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:16:19,605] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 206
[2023-05-11 23:16:19,640] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:19,649] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:16:19,690] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:19,690] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:19,691] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:16:19,770] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:19,770] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:19,771] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:16:19,816] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 207
[2023-05-11 23:16:19,871] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 207
[2023-05-11 23:16:19,897] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 207
[2023-05-11 23:16:19,952] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 207
[2023-05-11 23:16:20,379] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 208
[2023-05-11 23:16:20,474] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 208
[2023-05-11 23:16:20,527] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 208
[2023-05-11 23:16:20,561] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:20,568] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-11 23:16:20,572] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-11 23:16:20,573] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:20,573] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:20,574] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:16:20,600] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 209
[2023-05-11 23:16:20,625] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 208
[2023-05-11 23:16:20,659] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:20,666] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-11 23:16:20,670] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-11 23:16:20,672] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:20,672] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:20,672] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:16:20,700] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 209
[2023-05-11 23:16:20,962] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 209
[2023-05-11 23:16:20,962] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:20,987] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-11 23:16:20,991] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-11 23:16:20,992] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:20,992] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:20,992] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:16:21,018] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 210
[2023-05-11 23:16:21,053] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 209
[2023-05-11 23:16:21,053] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:21,079] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-11 23:16:21,083] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-11 23:16:21,084] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:21,084] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:21,084] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:16:21,109] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 210
[2023-05-11 23:16:21,371] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 210
[2023-05-11 23:16:21,372] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:21,397] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:16:21,463] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 210
[2023-05-11 23:16:21,464] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:21,489] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:16:21,519] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:21,519] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:21,520] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:16:21,613] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:21,613] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:21,614] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:16:21,653] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 211
[2023-05-11 23:16:21,748] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 211
[2023-05-11 23:16:22,114] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 211
[2023-05-11 23:16:22,202] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 211
[2023-05-11 23:16:22,629] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 212
[2023-05-11 23:16:22,723] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 212
[2023-05-11 23:16:24,835] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 212
[2023-05-11 23:16:24,869] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:24,928] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 212
[2023-05-11 23:16:24,962] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:37,039] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-11 23:16:37,041] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-11 23:16:37,042] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:37,042] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:37,042] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:16:37,062] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 213
[2023-05-11 23:16:37,154] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-11 23:16:37,155] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-11 23:16:37,156] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:37,156] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:37,156] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:16:37,173] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 213
[2023-05-11 23:16:37,384] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 213
[2023-05-11 23:16:37,385] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:37,411] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-11 23:16:37,416] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-11 23:16:37,418] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:37,418] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:37,418] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:16:37,444] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 214
[2023-05-11 23:16:37,495] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 213
[2023-05-11 23:16:37,496] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:37,521] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-11 23:16:37,526] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-11 23:16:37,528] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:37,528] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:37,528] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:16:37,555] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 214
[2023-05-11 23:16:37,776] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 214
[2023-05-11 23:16:37,776] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:37,800] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-11 23:16:37,805] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-11 23:16:37,807] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:37,807] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:37,807] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:16:37,832] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 215
[2023-05-11 23:16:37,890] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 214
[2023-05-11 23:16:37,891] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:37,915] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-11 23:16:37,920] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-11 23:16:37,921] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:37,922] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:37,922] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:16:37,947] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 215
[2023-05-11 23:16:38,163] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 215
[2023-05-11 23:16:38,163] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:38,199] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:16:38,276] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 215
[2023-05-11 23:16:38,277] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:38,312] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-11 23:16:38,314] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:38,314] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:38,315] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:16:38,429] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:38,430] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:38,430] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-11 23:16:38,443] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 216
[2023-05-11 23:16:38,509] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 216
[2023-05-11 23:16:38,561] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 216
[2023-05-11 23:16:38,626] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 216
[2023-05-11 23:16:39,028] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 217
[2023-05-11 23:16:39,135] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 217
[2023-05-11 23:16:39,176] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 217
[2023-05-11 23:16:39,208] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:39,214] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-11 23:16:39,219] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-11 23:16:39,220] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:39,220] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:39,220] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:16:39,245] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 218
[2023-05-11 23:16:39,282] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 217
[2023-05-11 23:16:39,315] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:39,322] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-11 23:16:39,326] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-11 23:16:39,328] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-11 23:16:39,328] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-11 23:16:39,328] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-11 23:16:39,354] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 218
[2023-05-11 23:16:39,583] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 218
[2023-05-11 23:16:39,584] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:39,698] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 218
[2023-05-11 23:16:39,699] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-11 23:16:39,720] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 218
[2023-05-11 23:16:39,795] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 218
[2023-05-11 23:16:40,080] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 218
[2023-05-11 23:16:40,082] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 194
[2023-05-11 23:16:40,099] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 194
[2023-05-11 23:16:40,102] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 217
[2023-05-11 23:16:40,154] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 218
[2023-05-11 23:16:40,156] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 194
[2023-05-11 23:16:40,172] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 194
[2023-05-11 23:16:40,176] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 217
[2023-05-11 23:16:40,637] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 217
[2023-05-11 23:16:40,645] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 216
[2023-05-11 23:16:41,106] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 217
[2023-05-11 23:16:41,113] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 216
[2023-05-11 23:16:41,577] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 216
[2023-05-11 23:16:41,623] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 215
[2023-05-11 23:16:41,631] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 216
[2023-05-11 23:16:41,677] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 215
[2023-05-11 23:16:41,982] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 215
[2023-05-11 23:16:42,028] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 214
[2023-05-11 23:16:42,033] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 215
[2023-05-11 23:16:42,067] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 214
[2023-05-11 23:16:42,383] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 214
[2023-05-11 23:16:42,410] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 213
[2023-05-11 23:16:42,416] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 214
[2023-05-11 23:16:42,426] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 213
[2023-05-11 23:16:42,430] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 212
[2023-05-11 23:16:42,441] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 213
[2023-05-11 23:16:42,453] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 213
[2023-05-11 23:16:42,457] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 212
[2023-05-11 23:16:43,140] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 212
[2023-05-11 23:16:43,147] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 211
[2023-05-11 23:16:43,180] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 212
[2023-05-11 23:16:43,188] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 211
[2023-05-11 23:16:43,619] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 211
[2023-05-11 23:16:43,637] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 210
[2023-05-11 23:16:43,660] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 211
[2023-05-11 23:16:43,678] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 210
[2023-05-11 23:16:43,994] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 210
[2023-05-11 23:16:44,004] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 209
[2023-05-11 23:16:44,037] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 210
[2023-05-11 23:16:44,048] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 209
[2023-05-11 23:16:44,355] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 209
[2023-05-11 23:16:44,360] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 208
[2023-05-11 23:16:44,396] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 209
[2023-05-11 23:16:44,401] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 208
[2023-05-11 23:16:44,497] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 208
[2023-05-11 23:16:44,501] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 207
[2023-05-11 23:16:44,538] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 208
[2023-05-11 23:16:44,541] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 207
[2023-05-11 23:16:44,624] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 207
[2023-05-11 23:16:44,630] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 206
[2023-05-11 23:16:44,665] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 207
[2023-05-11 23:16:44,671] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 206
[2023-05-11 23:16:44,758] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 206
[2023-05-11 23:16:44,761] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 205
[2023-05-11 23:16:44,798] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 206
[2023-05-11 23:16:44,801] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 205
[2023-05-11 23:16:44,876] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 205
[2023-05-11 23:16:44,882] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 204
[2023-05-11 23:16:44,917] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 205
[2023-05-11 23:16:44,922] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 204
[2023-05-11 23:16:45,007] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 204
[2023-05-11 23:16:45,010] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 203
[2023-05-11 23:16:45,045] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 204
[2023-05-11 23:16:45,048] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 203
[2023-05-11 23:16:45,115] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 203
[2023-05-11 23:16:45,120] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 202
[2023-05-11 23:16:45,154] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 203
[2023-05-11 23:16:45,159] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 202
[2023-05-11 23:16:45,239] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 202
[2023-05-11 23:16:45,242] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 201
[2023-05-11 23:16:45,278] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 202
[2023-05-11 23:16:45,281] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 201
[2023-05-11 23:16:45,349] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 201
[2023-05-11 23:16:45,354] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 200
[2023-05-11 23:16:45,386] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 201
[2023-05-11 23:16:45,391] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 200
[2023-05-11 23:16:45,473] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 200
[2023-05-11 23:16:45,476] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 199
[2023-05-11 23:16:45,511] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 200
[2023-05-11 23:16:45,514] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 199
[2023-05-11 23:16:45,586] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 199
[2023-05-11 23:16:45,592] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 198
[2023-05-11 23:16:45,624] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 199
[2023-05-11 23:16:45,629] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 198
[2023-05-11 23:16:45,721] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 198
[2023-05-11 23:16:45,724] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 197
[2023-05-11 23:16:45,759] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 198
[2023-05-11 23:16:45,762] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 197
[2023-05-11 23:16:45,837] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 197
[2023-05-11 23:16:45,843] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 196
[2023-05-11 23:16:45,878] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 197
[2023-05-11 23:16:45,884] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 196
[2023-05-11 23:16:45,971] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 196
[2023-05-11 23:16:45,974] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 195
[2023-05-11 23:16:46,007] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 196
[2023-05-11 23:16:46,010] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 195
[2023-05-11 23:16:46,079] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 195
[2023-05-11 23:16:46,084] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 193
[2023-05-11 23:16:46,115] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 195
[2023-05-11 23:16:46,120] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 193
[2023-05-11 23:16:46,203] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 193
[2023-05-11 23:16:46,206] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 192
[2023-05-11 23:16:46,239] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 193
[2023-05-11 23:16:46,242] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 192
[2023-05-11 23:16:46,311] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 192
[2023-05-11 23:16:46,346] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 192
[2023-05-11 23:16:46,353] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 191
[2023-05-11 23:16:46,367] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 191
[2023-05-11 23:16:46,708] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 191
[2023-05-11 23:16:46,720] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 191
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0511 23:16:51.781267 22485033404224 run_lib.py:146] step: 400, training_loss: 3.22768e-01
I0511 23:16:51.949451 22485033404224 run_lib.py:167] step: 400, eval_loss: 4.06139e-01
I0511 23:17:16.044407 22485033404224 run_lib.py:146] step: 450, training_loss: 2.13030e-01
I0511 23:17:41.014908 22485033404224 run_lib.py:146] step: 500, training_loss: 1.20449e-01
I0511 23:17:41.178507 22485033404224 run_lib.py:167] step: 500, eval_loss: 2.03019e-01
I0511 23:18:05.175522 22485033404224 run_lib.py:146] step: 550, training_loss: 4.97400e-02
I0511 23:18:29.063987 22485033404224 run_lib.py:146] step: 600, training_loss: 1.57575e-02
I0511 23:18:29.227519 22485033404224 run_lib.py:167] step: 600, eval_loss: 5.64176e-02
I0511 23:18:53.608162 22485033404224 run_lib.py:146] step: 650, training_loss: 5.41058e-03
I0511 23:19:17.318774 22485033404224 run_lib.py:146] step: 700, training_loss: 3.23132e-03
I0511 23:19:17.478932 22485033404224 run_lib.py:167] step: 700, eval_loss: 9.60866e-03
I0511 23:19:41.196899 22485033404224 run_lib.py:146] step: 750, training_loss: 2.70125e-03
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0511 23:20:05.680404 22485033404224 run_lib.py:146] step: 800, training_loss: 1.94304e-03
I0511 23:20:05.842340 22485033404224 run_lib.py:167] step: 800, eval_loss: 2.51747e-03
I0511 23:20:29.565541 22485033404224 run_lib.py:146] step: 850, training_loss: 1.89318e-03
I0511 23:20:53.300459 22485033404224 run_lib.py:146] step: 900, training_loss: 1.74006e-03
I0511 23:20:53.460874 22485033404224 run_lib.py:167] step: 900, eval_loss: 1.77674e-03
I0511 23:21:17.787370 22485033404224 run_lib.py:146] step: 950, training_loss: 1.69817e-03
I0511 23:21:41.531271 22485033404224 run_lib.py:146] step: 1000, training_loss: 1.78398e-03
I0511 23:21:41.693008 22485033404224 run_lib.py:167] step: 1000, eval_loss: 1.39177e-03
I0511 23:22:05.430720 22485033404224 run_lib.py:146] step: 1050, training_loss: 1.69145e-03
I0511 23:22:29.151699 22485033404224 run_lib.py:146] step: 1100, training_loss: 1.52774e-03
I0511 23:22:29.311424 22485033404224 run_lib.py:167] step: 1100, eval_loss: 1.28182e-03
I0511 23:22:53.639459 22485033404224 run_lib.py:146] step: 1150, training_loss: 1.49706e-03
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0511 23:23:17.451254 22485033404224 run_lib.py:146] step: 1200, training_loss: 1.48746e-03
I0511 23:23:17.615381 22485033404224 run_lib.py:167] step: 1200, eval_loss: 1.08556e-03
I0511 23:23:41.321153 22485033404224 run_lib.py:146] step: 1250, training_loss: 1.40669e-03
I0511 23:24:05.737318 22485033404224 run_lib.py:146] step: 1300, training_loss: 1.38405e-03
I0511 23:24:05.898689 22485033404224 run_lib.py:167] step: 1300, eval_loss: 9.41305e-04
I0511 23:24:29.593905 22485033404224 run_lib.py:146] step: 1350, training_loss: 1.28136e-03
I0511 23:24:53.309005 22485033404224 run_lib.py:146] step: 1400, training_loss: 1.41267e-03
I0511 23:24:53.467811 22485033404224 run_lib.py:167] step: 1400, eval_loss: 1.07006e-03
I0511 23:25:17.779587 22485033404224 run_lib.py:146] step: 1450, training_loss: 1.51047e-03
I0511 23:25:41.506175 22485033404224 run_lib.py:146] step: 1500, training_loss: 1.63791e-03
I0511 23:25:41.666823 22485033404224 run_lib.py:167] step: 1500, eval_loss: 1.28043e-03
I0511 23:26:05.385107 22485033404224 run_lib.py:146] step: 1550, training_loss: 1.39648e-03
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0511 23:26:29.884817 22485033404224 run_lib.py:146] step: 1600, training_loss: 1.35747e-03
I0511 23:26:30.048371 22485033404224 run_lib.py:167] step: 1600, eval_loss: 1.08553e-03
I0511 23:26:53.787384 22485033404224 run_lib.py:146] step: 1650, training_loss: 1.39118e-03
I0511 23:27:17.530135 22485033404224 run_lib.py:146] step: 1700, training_loss: 1.11049e-03
I0511 23:27:17.689802 22485033404224 run_lib.py:167] step: 1700, eval_loss: 9.32381e-04
I0511 23:27:42.071974 22485033404224 run_lib.py:146] step: 1750, training_loss: 1.48176e-03
I0511 23:28:05.815235 22485033404224 run_lib.py:146] step: 1800, training_loss: 1.18519e-03
I0511 23:28:05.977395 22485033404224 run_lib.py:167] step: 1800, eval_loss: 8.35460e-04
I0511 23:28:29.708698 22485033404224 run_lib.py:146] step: 1850, training_loss: 1.20795e-03
I0511 23:28:54.089077 22485033404224 run_lib.py:146] step: 1900, training_loss: 1.24756e-03
I0511 23:28:54.250629 22485033404224 run_lib.py:167] step: 1900, eval_loss: 9.03642e-04
I0511 23:29:18.060235 22485033404224 run_lib.py:146] step: 1950, training_loss: 1.21308e-03
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0511 23:29:41.939081 22485033404224 run_lib.py:146] step: 2000, training_loss: 1.15446e-03
I0511 23:29:42.103522 22485033404224 run_lib.py:167] step: 2000, eval_loss: 1.06066e-03
I0511 23:30:05.904204 22485033404224 run_lib.py:146] step: 2050, training_loss: 1.11689e-03
I0511 23:30:30.402982 22485033404224 run_lib.py:146] step: 2100, training_loss: 9.05054e-04
I0511 23:30:30.563267 22485033404224 run_lib.py:167] step: 2100, eval_loss: 1.02197e-03
I0511 23:30:54.379358 22485033404224 run_lib.py:146] step: 2150, training_loss: 1.32254e-03
I0511 23:31:18.195299 22485033404224 run_lib.py:146] step: 2200, training_loss: 9.83420e-04
I0511 23:31:18.355635 22485033404224 run_lib.py:167] step: 2200, eval_loss: 1.15062e-03
I0511 23:31:42.751557 22485033404224 run_lib.py:146] step: 2250, training_loss: 1.00616e-03
I0511 23:32:06.568644 22485033404224 run_lib.py:146] step: 2300, training_loss: 1.00724e-03
I0511 23:32:06.730548 22485033404224 run_lib.py:167] step: 2300, eval_loss: 1.15815e-03
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0511 23:32:30.615329 22485033404224 run_lib.py:146] step: 2350, training_loss: 1.36198e-03
I0511 23:32:55.131170 22485033404224 run_lib.py:146] step: 2400, training_loss: 9.06161e-04
I0511 23:32:55.294649 22485033404224 run_lib.py:167] step: 2400, eval_loss: 8.66145e-04
I0511 23:33:19.086496 22485033404224 run_lib.py:146] step: 2450, training_loss: 1.32903e-03
I0511 23:33:42.884500 22485033404224 run_lib.py:146] step: 2500, training_loss: 1.07356e-03
I0511 23:33:43.046981 22485033404224 run_lib.py:167] step: 2500, eval_loss: 9.10185e-04
I0511 23:34:07.455073 22485033404224 run_lib.py:146] step: 2550, training_loss: 1.16406e-03
I0511 23:34:31.265265 22485033404224 run_lib.py:146] step: 2600, training_loss: 9.18886e-04
I0511 23:34:31.425419 22485033404224 run_lib.py:167] step: 2600, eval_loss: 1.02676e-03
I0511 23:34:55.220672 22485033404224 run_lib.py:146] step: 2650, training_loss: 1.01179e-03
I0511 23:35:19.606262 22485033404224 run_lib.py:146] step: 2700, training_loss: 1.16276e-03
I0511 23:35:19.766650 22485033404224 run_lib.py:167] step: 2700, eval_loss: 9.04532e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0511 23:35:43.675110 22485033404224 run_lib.py:146] step: 2750, training_loss: 1.09781e-03
I0511 23:36:07.498531 22485033404224 run_lib.py:146] step: 2800, training_loss: 9.19547e-04
I0511 23:36:07.662184 22485033404224 run_lib.py:167] step: 2800, eval_loss: 1.04771e-03
I0511 23:36:31.777590 22485033404224 run_lib.py:146] step: 2850, training_loss: 9.26380e-04
I0511 23:36:55.901559 22485033404224 run_lib.py:146] step: 2900, training_loss: 8.16560e-04
I0511 23:36:56.061276 22485033404224 run_lib.py:167] step: 2900, eval_loss: 8.14683e-04
I0511 23:37:19.802448 22485033404224 run_lib.py:146] step: 2950, training_loss: 9.28189e-04
I0511 23:37:43.555782 22485033404224 run_lib.py:146] step: 3000, training_loss: 9.45649e-04
I0511 23:37:43.718271 22485033404224 run_lib.py:167] step: 3000, eval_loss: 7.55731e-04
I0511 23:38:08.098260 22485033404224 run_lib.py:146] step: 3050, training_loss: 1.01861e-03
I0511 23:38:31.869404 22485033404224 run_lib.py:146] step: 3100, training_loss: 9.25550e-04
I0511 23:38:32.028689 22485033404224 run_lib.py:167] step: 3100, eval_loss: 9.85409e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0511 23:38:55.862215 22485033404224 run_lib.py:146] step: 3150, training_loss: 1.28422e-03
I0511 23:39:20.273663 22485033404224 run_lib.py:146] step: 3200, training_loss: 9.48861e-04
I0511 23:39:20.436320 22485033404224 run_lib.py:167] step: 3200, eval_loss: 8.18253e-04
I0511 23:39:44.160029 22485033404224 run_lib.py:146] step: 3250, training_loss: 8.36904e-04
I0511 23:40:07.884631 22485033404224 run_lib.py:146] step: 3300, training_loss: 8.99551e-04
I0511 23:40:08.044591 22485033404224 run_lib.py:167] step: 3300, eval_loss: 9.95679e-04
I0511 23:40:32.385635 22485033404224 run_lib.py:146] step: 3350, training_loss: 8.64974e-04
I0511 23:40:56.118903 22485033404224 run_lib.py:146] step: 3400, training_loss: 8.29313e-04
I0511 23:40:56.280485 22485033404224 run_lib.py:167] step: 3400, eval_loss: 1.08496e-03
I0511 23:41:20.022168 22485033404224 run_lib.py:146] step: 3450, training_loss: 9.56202e-04
I0511 23:41:44.374113 22485033404224 run_lib.py:146] step: 3500, training_loss: 9.83250e-04
I0511 23:41:44.535039 22485033404224 run_lib.py:167] step: 3500, eval_loss: 9.41565e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0511 23:42:08.336350 22485033404224 run_lib.py:146] step: 3550, training_loss: 9.44787e-04
I0511 23:42:32.101811 22485033404224 run_lib.py:146] step: 3600, training_loss: 8.82146e-04
I0511 23:42:32.263814 22485033404224 run_lib.py:167] step: 3600, eval_loss: 5.77125e-04
I0511 23:42:56.344186 22485033404224 run_lib.py:146] step: 3650, training_loss: 7.97459e-04
I0511 23:43:20.095955 22485033404224 run_lib.py:146] step: 3700, training_loss: 8.60155e-04
I0511 23:43:20.256304 22485033404224 run_lib.py:167] step: 3700, eval_loss: 8.33469e-04
I0511 23:43:44.039434 22485033404224 run_lib.py:146] step: 3750, training_loss: 1.00653e-03
I0511 23:44:08.109466 22485033404224 run_lib.py:146] step: 3800, training_loss: 1.19206e-03
I0511 23:44:08.269464 22485033404224 run_lib.py:167] step: 3800, eval_loss: 7.02594e-04
I0511 23:44:32.025895 22485033404224 run_lib.py:146] step: 3850, training_loss: 1.27343e-03
I0511 23:44:55.786783 22485033404224 run_lib.py:146] step: 3900, training_loss: 1.19196e-03
I0511 23:44:55.946618 22485033404224 run_lib.py:167] step: 3900, eval_loss: 8.34328e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0511 23:45:19.779132 22485033404224 run_lib.py:146] step: 3950, training_loss: 9.34071e-04
I0511 23:45:43.914767 22485033404224 run_lib.py:146] step: 4000, training_loss: 8.73790e-04
I0511 23:45:44.077725 22485033404224 run_lib.py:167] step: 4000, eval_loss: 6.37557e-04
I0511 23:46:07.827586 22485033404224 run_lib.py:146] step: 4050, training_loss: 9.99038e-04
I0511 23:46:31.540929 22485033404224 run_lib.py:146] step: 4100, training_loss: 7.73472e-04
I0511 23:46:31.699913 22485033404224 run_lib.py:167] step: 4100, eval_loss: 6.41032e-04
I0511 23:46:56.100258 22485033404224 run_lib.py:146] step: 4150, training_loss: 1.02343e-03
I0511 23:47:19.890831 22485033404224 run_lib.py:146] step: 4200, training_loss: 9.11828e-04
I0511 23:47:20.053511 22485033404224 run_lib.py:167] step: 4200, eval_loss: 8.13820e-04
I0511 23:47:43.841160 22485033404224 run_lib.py:146] step: 4250, training_loss: 8.44460e-04
I0511 23:48:08.100628 22485033404224 run_lib.py:146] step: 4300, training_loss: 9.28609e-04
I0511 23:48:08.262923 22485033404224 run_lib.py:167] step: 4300, eval_loss: 6.77252e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0511 23:48:32.251695 22485033404224 run_lib.py:146] step: 4350, training_loss: 9.80214e-04
I0511 23:48:56.067915 22485033404224 run_lib.py:146] step: 4400, training_loss: 9.94810e-04
I0511 23:48:56.231872 22485033404224 run_lib.py:167] step: 4400, eval_loss: 1.07198e-03
I0511 23:49:20.925242 22485033404224 run_lib.py:146] step: 4450, training_loss: 8.09697e-04
I0511 23:49:44.709083 22485033404224 run_lib.py:146] step: 4500, training_loss: 7.27829e-04
I0511 23:49:44.869907 22485033404224 run_lib.py:167] step: 4500, eval_loss: 1.05417e-03
I0511 23:50:08.619993 22485033404224 run_lib.py:146] step: 4550, training_loss: 9.20478e-04
I0511 23:50:33.200213 22485033404224 run_lib.py:146] step: 4600, training_loss: 7.82767e-04
I0511 23:50:33.361578 22485033404224 run_lib.py:167] step: 4600, eval_loss: 8.74673e-04
I0511 23:50:57.139574 22485033404224 run_lib.py:146] step: 4650, training_loss: 8.69065e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0511 23:51:21.007052 22485033404224 run_lib.py:146] step: 4700, training_loss: 8.92263e-04
I0511 23:51:21.168632 22485033404224 run_lib.py:167] step: 4700, eval_loss: 7.80087e-04
I0511 23:51:45.446722 22485033404224 run_lib.py:146] step: 4750, training_loss: 7.95203e-04
I0511 23:52:09.743908 22485033404224 run_lib.py:146] step: 4800, training_loss: 9.16004e-04
I0511 23:52:09.905380 22485033404224 run_lib.py:167] step: 4800, eval_loss: 6.92169e-04
I0511 23:52:33.710940 22485033404224 run_lib.py:146] step: 4850, training_loss: 8.23708e-04
I0511 23:52:57.528033 22485033404224 run_lib.py:146] step: 4900, training_loss: 8.82388e-04
I0511 23:52:57.689772 22485033404224 run_lib.py:167] step: 4900, eval_loss: 6.71661e-04
I0511 23:53:22.267964 22485033404224 run_lib.py:146] step: 4950, training_loss: 8.09340e-04
I0511 23:53:46.087179 22485033404224 run_lib.py:146] step: 5000, training_loss: 8.29097e-04
I0511 23:53:46.248463 22485033404224 run_lib.py:167] step: 5000, eval_loss: 8.29640e-04
I0511 23:54:10.052613 22485033404224 run_lib.py:146] step: 5050, training_loss: 8.46178e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0511 23:54:34.689753 22485033404224 run_lib.py:146] step: 5100, training_loss: 9.15043e-04
I0511 23:54:34.853040 22485033404224 run_lib.py:167] step: 5100, eval_loss: 7.64112e-04
I0511 23:54:58.603854 22485033404224 run_lib.py:146] step: 5150, training_loss: 7.66631e-04
I0511 23:55:22.353531 22485033404224 run_lib.py:146] step: 5200, training_loss: 8.03477e-04
I0511 23:55:22.514615 22485033404224 run_lib.py:167] step: 5200, eval_loss: 7.34585e-04
I0511 23:55:46.973164 22485033404224 run_lib.py:146] step: 5250, training_loss: 9.96071e-04
I0511 23:56:10.702399 22485033404224 run_lib.py:146] step: 5300, training_loss: 1.03334e-03
I0511 23:56:10.861363 22485033404224 run_lib.py:167] step: 5300, eval_loss: 6.61096e-04
I0511 23:56:34.574972 22485033404224 run_lib.py:146] step: 5350, training_loss: 6.23372e-04
I0511 23:56:58.931098 22485033404224 run_lib.py:146] step: 5400, training_loss: 7.68432e-04
I0511 23:56:59.091888 22485033404224 run_lib.py:167] step: 5400, eval_loss: 6.72467e-04
I0511 23:57:22.798844 22485033404224 run_lib.py:146] step: 5450, training_loss: 7.14705e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0511 23:57:46.621667 22485033404224 run_lib.py:146] step: 5500, training_loss: 8.91552e-04
I0511 23:57:46.783832 22485033404224 run_lib.py:167] step: 5500, eval_loss: 8.04981e-04
I0511 23:58:11.221051 22485033404224 run_lib.py:146] step: 5550, training_loss: 6.15177e-04
I0511 23:58:34.959385 22485033404224 run_lib.py:146] step: 5600, training_loss: 6.59642e-04
I0511 23:58:35.121492 22485033404224 run_lib.py:167] step: 5600, eval_loss: 5.00906e-04
I0511 23:58:58.831634 22485033404224 run_lib.py:146] step: 5650, training_loss: 8.43641e-04
I0511 23:59:22.865417 22485033404224 run_lib.py:146] step: 5700, training_loss: 5.59206e-04
I0511 23:59:23.025171 22485033404224 run_lib.py:167] step: 5700, eval_loss: 7.68696e-04
I0511 23:59:47.062135 22485033404224 run_lib.py:146] step: 5750, training_loss: 1.02057e-03
I0512 00:00:10.795754 22485033404224 run_lib.py:146] step: 5800, training_loss: 9.28283e-04
I0512 00:00:10.957211 22485033404224 run_lib.py:167] step: 5800, eval_loss: 5.51506e-04
I0512 00:00:34.648132 22485033404224 run_lib.py:146] step: 5850, training_loss: 9.78973e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 00:00:59.086899 22485033404224 run_lib.py:146] step: 5900, training_loss: 9.82976e-04
I0512 00:00:59.250229 22485033404224 run_lib.py:167] step: 5900, eval_loss: 7.25392e-04
I0512 00:01:22.970741 22485033404224 run_lib.py:146] step: 5950, training_loss: 7.01500e-04
I0512 00:01:46.744216 22485033404224 run_lib.py:146] step: 6000, training_loss: 7.70672e-04
I0512 00:01:46.903934 22485033404224 run_lib.py:167] step: 6000, eval_loss: 8.94701e-04
I0512 00:02:11.336658 22485033404224 run_lib.py:146] step: 6050, training_loss: 5.78121e-04
I0512 00:02:35.059799 22485033404224 run_lib.py:146] step: 6100, training_loss: 6.81653e-04
I0512 00:02:35.220125 22485033404224 run_lib.py:167] step: 6100, eval_loss: 7.51585e-04
I0512 00:02:58.958465 22485033404224 run_lib.py:146] step: 6150, training_loss: 6.65660e-04
I0512 00:03:23.310969 22485033404224 run_lib.py:146] step: 6200, training_loss: 7.06556e-04
I0512 00:03:23.469651 22485033404224 run_lib.py:167] step: 6200, eval_loss: 6.55369e-04
I0512 00:03:47.203661 22485033404224 run_lib.py:146] step: 6250, training_loss: 7.76003e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 00:04:11.027932 22485033404224 run_lib.py:146] step: 6300, training_loss: 6.43081e-04
I0512 00:04:11.190632 22485033404224 run_lib.py:167] step: 6300, eval_loss: 6.29078e-04
I0512 00:04:35.299971 22485033404224 run_lib.py:146] step: 6350, training_loss: 6.88491e-04
I0512 00:04:59.048997 22485033404224 run_lib.py:146] step: 6400, training_loss: 6.74274e-04
I0512 00:04:59.209522 22485033404224 run_lib.py:167] step: 6400, eval_loss: 7.11930e-04
I0512 00:05:23.003652 22485033404224 run_lib.py:146] step: 6450, training_loss: 7.80490e-04
I0512 00:05:47.417514 22485033404224 run_lib.py:146] step: 6500, training_loss: 5.85971e-04
I0512 00:05:47.579387 22485033404224 run_lib.py:167] step: 6500, eval_loss: 7.89915e-04
I0512 00:06:11.376079 22485033404224 run_lib.py:146] step: 6550, training_loss: 7.83833e-04
I0512 00:06:35.169659 22485033404224 run_lib.py:146] step: 6600, training_loss: 8.14373e-04
I0512 00:06:35.330113 22485033404224 run_lib.py:167] step: 6600, eval_loss: 7.33031e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 00:06:59.517955 22485033404224 run_lib.py:146] step: 6650, training_loss: 8.14029e-04
I0512 00:07:23.683697 22485033404224 run_lib.py:146] step: 6700, training_loss: 7.61795e-04
I0512 00:07:23.848108 22485033404224 run_lib.py:167] step: 6700, eval_loss: 6.50494e-04
I0512 00:07:47.648512 22485033404224 run_lib.py:146] step: 6750, training_loss: 8.82325e-04
I0512 00:08:11.451295 22485033404224 run_lib.py:146] step: 6800, training_loss: 7.80678e-04
I0512 00:08:11.611976 22485033404224 run_lib.py:167] step: 6800, eval_loss: 5.98629e-04
I0512 00:08:36.161070 22485033404224 run_lib.py:146] step: 6850, training_loss: 5.30973e-04
I0512 00:08:59.963867 22485033404224 run_lib.py:146] step: 6900, training_loss: 7.87479e-04
I0512 00:09:00.125264 22485033404224 run_lib.py:167] step: 6900, eval_loss: 5.90524e-04
I0512 00:09:23.934585 22485033404224 run_lib.py:146] step: 6950, training_loss: 6.73944e-04
I0512 00:09:48.436937 22485033404224 run_lib.py:146] step: 7000, training_loss: 7.87340e-04
I0512 00:09:48.597058 22485033404224 run_lib.py:167] step: 7000, eval_loss: 4.36008e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 00:10:12.449370 22485033404224 run_lib.py:146] step: 7050, training_loss: 7.20443e-04
I0512 00:10:36.232599 22485033404224 run_lib.py:146] step: 7100, training_loss: 7.30486e-04
I0512 00:10:36.394305 22485033404224 run_lib.py:167] step: 7100, eval_loss: 8.37821e-04
I0512 00:11:00.846953 22485033404224 run_lib.py:146] step: 7150, training_loss: 7.12571e-04
I0512 00:11:24.631854 22485033404224 run_lib.py:146] step: 7200, training_loss: 8.33720e-04
I0512 00:11:24.792304 22485033404224 run_lib.py:167] step: 7200, eval_loss: 7.74871e-04
I0512 00:11:48.603898 22485033404224 run_lib.py:146] step: 7250, training_loss: 5.43828e-04
I0512 00:12:13.018438 22485033404224 run_lib.py:146] step: 7300, training_loss: 7.57779e-04
I0512 00:12:13.179822 22485033404224 run_lib.py:167] step: 7300, eval_loss: 6.17868e-04
I0512 00:12:36.938566 22485033404224 run_lib.py:146] step: 7350, training_loss: 7.21148e-04
I0512 00:13:00.682477 22485033404224 run_lib.py:146] step: 7400, training_loss: 5.39934e-04
I0512 00:13:00.845586 22485033404224 run_lib.py:167] step: 7400, eval_loss: 7.21505e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 00:13:25.348551 22485033404224 run_lib.py:146] step: 7450, training_loss: 6.84548e-04
I0512 00:13:49.070577 22485033404224 run_lib.py:146] step: 7500, training_loss: 9.82381e-04
I0512 00:13:49.233359 22485033404224 run_lib.py:167] step: 7500, eval_loss: 5.55552e-04
I0512 00:14:12.960380 22485033404224 run_lib.py:146] step: 7550, training_loss: 7.85531e-04
I0512 00:14:37.286272 22485033404224 run_lib.py:146] step: 7600, training_loss: 7.40619e-04
I0512 00:14:37.447854 22485033404224 run_lib.py:167] step: 7600, eval_loss: 7.68625e-04
I0512 00:15:01.149823 22485033404224 run_lib.py:146] step: 7650, training_loss: 8.07195e-04
I0512 00:15:24.865978 22485033404224 run_lib.py:146] step: 7700, training_loss: 6.03011e-04
I0512 00:15:25.027653 22485033404224 run_lib.py:167] step: 7700, eval_loss: 7.58074e-04
I0512 00:15:48.756598 22485033404224 run_lib.py:146] step: 7750, training_loss: 7.34518e-04
I0512 00:16:13.068193 22485033404224 run_lib.py:146] step: 7800, training_loss: 4.12641e-04
[2023-05-12 00:16:13,101] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing get_timestep_embedding
[2023-05-12 00:16:13,101] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing get_timestep_embedding
[2023-05-12 00:16:13,118] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing get_timestep_embedding (RETURN_VALUE)
[2023-05-12 00:16:13,118] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing get_timestep_embedding (RETURN_VALUE)
[2023-05-12 00:16:13,120] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:13,120] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:13,120] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:13,120] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:13,120] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-12 00:16:13,120] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-12 00:16:13,157] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 219
[2023-05-12 00:16:13,157] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 219
[2023-05-12 00:16:13,773] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 219
[2023-05-12 00:16:13,773] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 219
[2023-05-12 00:16:13,774] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:13,774] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:13,841] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-12 00:16:13,841] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-12 00:16:13,845] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-12 00:16:13,845] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-12 00:16:13,846] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:13,846] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:13,846] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:13,846] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:13,846] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-12 00:16:13,846] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-12 00:16:13,857] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 220
[2023-05-12 00:16:13,859] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 220
[2023-05-12 00:16:14,202] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 220
[2023-05-12 00:16:14,203] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:14,204] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 220
[2023-05-12 00:16:14,205] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:14,260] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-12 00:16:14,260] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-12 00:16:14,383] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:14,384] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:14,384] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-12 00:16:14,386] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:14,386] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:14,387] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-12 00:16:14,433] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 221
[2023-05-12 00:16:14,433] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 221
[2023-05-12 00:16:14,864] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 221
[2023-05-12 00:16:14,864] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 221
[2023-05-12 00:16:15,100] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 222
[2023-05-12 00:16:15,103] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 222
[2023-05-12 00:16:17,224] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 222
[2023-05-12 00:16:17,256] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:17,308] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 222
[2023-05-12 00:16:17,341] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:31,915] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-12 00:16:31,917] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-12 00:16:31,918] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:31,918] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:31,918] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-12 00:16:31,928] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 223
[2023-05-12 00:16:32,199] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-12 00:16:32,201] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-12 00:16:32,202] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:32,202] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:32,202] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-12 00:16:32,211] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 223
[2023-05-12 00:16:32,228] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 223
[2023-05-12 00:16:32,228] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:32,234] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-12 00:16:32,350] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:32,351] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:32,351] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-12 00:16:32,397] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 224
[2023-05-12 00:16:32,449] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 224
[2023-05-12 00:16:32,519] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 223
[2023-05-12 00:16:32,520] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:32,525] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-12 00:16:32,644] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:32,644] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:32,645] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-12 00:16:32,690] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 225
[2023-05-12 00:16:32,691] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 224
[2023-05-12 00:16:32,744] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 224
[2023-05-12 00:16:32,815] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 225
[2023-05-12 00:16:32,847] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:32,854] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-12 00:16:32,971] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:32,971] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:32,972] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-12 00:16:32,982] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 225
[2023-05-12 00:16:33,015] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 226
[2023-05-12 00:16:33,065] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 226
[2023-05-12 00:16:33,099] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 225
[2023-05-12 00:16:33,130] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:33,137] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-12 00:16:33,251] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:33,251] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:33,252] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-12 00:16:33,298] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 226
[2023-05-12 00:16:33,305] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 227
[2023-05-12 00:16:33,349] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 226
[2023-05-12 00:16:33,426] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 227
[2023-05-12 00:16:33,456] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:33,463] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-12 00:16:33,579] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:33,579] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:33,580] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-12 00:16:33,583] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 227
[2023-05-12 00:16:33,625] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 228
[2023-05-12 00:16:33,679] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 228
[2023-05-12 00:16:33,707] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 227
[2023-05-12 00:16:33,739] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:33,746] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-12 00:16:33,866] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:33,866] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:33,867] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-12 00:16:33,913] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 228
[2023-05-12 00:16:33,924] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 229
[2023-05-12 00:16:33,963] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 228
[2023-05-12 00:16:34,044] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 229
[2023-05-12 00:16:34,075] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:34,082] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-12 00:16:34,200] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 229
[2023-05-12 00:16:34,201] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:34,201] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:34,201] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-12 00:16:34,244] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 230
[2023-05-12 00:16:34,295] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 230
[2023-05-12 00:16:34,319] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 229
[2023-05-12 00:16:34,349] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:34,355] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-12 00:16:34,464] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:34,465] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:34,465] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-12 00:16:34,510] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 230
[2023-05-12 00:16:34,531] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 231
[2023-05-12 00:16:34,562] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 230
[2023-05-12 00:16:34,653] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 231
[2023-05-12 00:16:34,685] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:34,692] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-12 00:16:34,803] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 231
[2023-05-12 00:16:34,815] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:34,816] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:34,816] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-12 00:16:34,864] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 232
[2023-05-12 00:16:34,918] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 232
[2023-05-12 00:16:34,930] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 231
[2023-05-12 00:16:34,961] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:34,967] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-12 00:16:35,084] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:35,084] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:35,085] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-12 00:16:35,128] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 232
[2023-05-12 00:16:35,156] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 233
[2023-05-12 00:16:35,177] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 232
[2023-05-12 00:16:35,274] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 233
[2023-05-12 00:16:35,305] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:35,311] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-12 00:16:35,409] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 233
[2023-05-12 00:16:35,422] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:35,422] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:35,422] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-12 00:16:35,467] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 234
[2023-05-12 00:16:35,518] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 234
[2023-05-12 00:16:35,530] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 233
[2023-05-12 00:16:35,561] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:35,567] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-12 00:16:35,687] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:35,688] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:35,688] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-12 00:16:35,734] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 234
[2023-05-12 00:16:35,761] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 235
[2023-05-12 00:16:35,786] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 234
[2023-05-12 00:16:35,886] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 235
[2023-05-12 00:16:35,917] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:35,923] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-12 00:16:36,022] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 235
[2023-05-12 00:16:36,038] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:36,038] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:36,038] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-12 00:16:36,084] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 236
[2023-05-12 00:16:36,136] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 236
[2023-05-12 00:16:36,145] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 235
[2023-05-12 00:16:36,175] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:36,181] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-12 00:16:36,293] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:36,293] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:36,294] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-12 00:16:36,335] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 236
[2023-05-12 00:16:36,370] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 237
[2023-05-12 00:16:36,385] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 236
[2023-05-12 00:16:36,489] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 237
[2023-05-12 00:16:36,521] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:36,527] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-12 00:16:36,531] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-12 00:16:36,532] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:36,532] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:36,532] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-12 00:16:36,544] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 238
[2023-05-12 00:16:36,622] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 237
[2023-05-12 00:16:36,745] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 237
[2023-05-12 00:16:36,776] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:36,782] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-12 00:16:36,786] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-12 00:16:36,787] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:36,787] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:36,787] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-12 00:16:36,799] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 238
[2023-05-12 00:16:36,891] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 238
[2023-05-12 00:16:36,891] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:36,912] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-12 00:16:36,915] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-12 00:16:36,916] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:36,917] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:36,917] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-12 00:16:36,928] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 239
[2023-05-12 00:16:37,143] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 238
[2023-05-12 00:16:37,144] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:37,164] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-12 00:16:37,168] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-12 00:16:37,169] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:37,169] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:37,169] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-12 00:16:37,180] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 239
[2023-05-12 00:16:37,267] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 239
[2023-05-12 00:16:37,268] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:37,302] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-12 00:16:37,416] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:37,416] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:37,416] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-12 00:16:37,461] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 240
[2023-05-12 00:16:37,519] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 239
[2023-05-12 00:16:37,520] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:37,541] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-12 00:16:37,662] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:37,662] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:37,663] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-12 00:16:37,709] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 240
[2023-05-12 00:16:37,890] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 240
[2023-05-12 00:16:38,127] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 241
[2023-05-12 00:16:38,134] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 240
[2023-05-12 00:16:38,368] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 241
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-12 00:16:40,609] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 241
[2023-05-12 00:16:40,641] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:40,877] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 241
[2023-05-12 00:16:40,908] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:54,781] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-12 00:16:54,783] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-12 00:16:54,784] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:54,784] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:54,784] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-12 00:16:54,794] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 242
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-12 00:16:55,278] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 242
[2023-05-12 00:16:55,278] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-12 00:16:55,278] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:55,279] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-12 00:16:55,280] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:55,280] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:55,280] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-12 00:16:55,290] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 242
[2023-05-12 00:16:55,484] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-12 00:16:55,490] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-12 00:16:55,491] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:55,491] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:55,491] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-12 00:16:55,506] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 243
[2023-05-12 00:16:55,793] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 242
[2023-05-12 00:16:55,793] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:55,817] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-12 00:16:55,822] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-12 00:16:55,823] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:55,823] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:55,824] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-12 00:16:55,836] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 243
[2023-05-12 00:16:55,845] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 243
[2023-05-12 00:16:55,845] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:55,867] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-12 00:16:55,872] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-12 00:16:55,873] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:55,873] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:55,873] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-12 00:16:55,887] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 244
[2023-05-12 00:16:56,171] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 243
[2023-05-12 00:16:56,172] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:56,194] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-12 00:16:56,200] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-12 00:16:56,201] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:56,201] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:56,201] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-12 00:16:56,215] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 244
[2023-05-12 00:16:56,217] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 244
[2023-05-12 00:16:56,218] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:56,291] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-12 00:16:56,415] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:56,416] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:56,416] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-12 00:16:56,464] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 245
[2023-05-12 00:16:56,524] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 245
[2023-05-12 00:16:56,553] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 244
[2023-05-12 00:16:56,553] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:56,598] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-12 00:16:56,719] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:56,719] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:56,720] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-12 00:16:56,762] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 245
[2023-05-12 00:16:56,766] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 246
[2023-05-12 00:16:56,815] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 245
[2023-05-12 00:16:56,893] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 246
[2023-05-12 00:16:56,923] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:56,929] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-12 00:16:56,933] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-12 00:16:56,935] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:56,935] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:56,935] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-12 00:16:56,947] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 247
[2023-05-12 00:16:57,049] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 246
[2023-05-12 00:16:57,176] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 246
[2023-05-12 00:16:57,207] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:57,213] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-12 00:16:57,219] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-12 00:16:57,220] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-12 00:16:57,220] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-12 00:16:57,220] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-12 00:16:57,234] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 247
[2023-05-12 00:16:57,281] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 247
[2023-05-12 00:16:57,281] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-12 00:16:57,577] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 247
[2023-05-12 00:16:57,578] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
I0512 00:16:57.640779 22485033404224 run_lib.py:167] step: 7800, eval_loss: 7.10040e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 00:17:21.305975 22485033404224 run_lib.py:146] step: 7850, training_loss: 7.38164e-04
I0512 00:17:44.926221 22485033404224 run_lib.py:146] step: 7900, training_loss: 8.51509e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 00:17:45.237101 22485033404224 run_lib.py:167] step: 7900, eval_loss: 7.52014e-04
I0512 00:18:09.318706 22485033404224 run_lib.py:146] step: 7950, training_loss: 8.51581e-04
I0512 00:18:33.033339 22485033404224 run_lib.py:146] step: 8000, training_loss: 7.45996e-04
I0512 00:18:33.193582 22485033404224 run_lib.py:167] step: 8000, eval_loss: 4.88703e-04
I0512 00:18:56.899878 22485033404224 run_lib.py:146] step: 8050, training_loss: 4.50303e-04
I0512 00:19:21.257476 22485033404224 run_lib.py:146] step: 8100, training_loss: 8.62714e-04
I0512 00:19:21.418902 22485033404224 run_lib.py:167] step: 8100, eval_loss: 6.76561e-04
I0512 00:19:45.140780 22485033404224 run_lib.py:146] step: 8150, training_loss: 7.36545e-04
I0512 00:20:08.892619 22485033404224 run_lib.py:146] step: 8200, training_loss: 7.04494e-04
I0512 00:20:09.053975 22485033404224 run_lib.py:167] step: 8200, eval_loss: 7.80119e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 00:20:32.831722 22485033404224 run_lib.py:146] step: 8250, training_loss: 5.75593e-04
I0512 00:20:56.878019 22485033404224 run_lib.py:146] step: 8300, training_loss: 8.70630e-04
I0512 00:20:57.038949 22485033404224 run_lib.py:167] step: 8300, eval_loss: 8.48607e-04
I0512 00:21:20.731592 22485033404224 run_lib.py:146] step: 8350, training_loss: 6.38823e-04
I0512 00:21:44.428993 22485033404224 run_lib.py:146] step: 8400, training_loss: 7.08342e-04
I0512 00:21:44.589209 22485033404224 run_lib.py:167] step: 8400, eval_loss: 6.02650e-04
I0512 00:22:08.893612 22485033404224 run_lib.py:146] step: 8450, training_loss: 6.67727e-04
I0512 00:22:32.588406 22485033404224 run_lib.py:146] step: 8500, training_loss: 6.65666e-04
I0512 00:22:32.747853 22485033404224 run_lib.py:167] step: 8500, eval_loss: 8.32503e-04
I0512 00:22:56.460641 22485033404224 run_lib.py:146] step: 8550, training_loss: 7.84617e-04
I0512 00:23:20.829994 22485033404224 run_lib.py:146] step: 8600, training_loss: 5.35054e-04
I0512 00:23:20.990181 22485033404224 run_lib.py:167] step: 8600, eval_loss: 6.51453e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 00:23:44.862219 22485033404224 run_lib.py:146] step: 8650, training_loss: 5.68957e-04
I0512 00:24:08.656553 22485033404224 run_lib.py:146] step: 8700, training_loss: 7.95868e-04
I0512 00:24:08.819873 22485033404224 run_lib.py:167] step: 8700, eval_loss: 7.49105e-04
I0512 00:24:33.324633 22485033404224 run_lib.py:146] step: 8750, training_loss: 8.00898e-04
I0512 00:24:57.131165 22485033404224 run_lib.py:146] step: 8800, training_loss: 7.60983e-04
I0512 00:24:57.293294 22485033404224 run_lib.py:167] step: 8800, eval_loss: 6.63089e-04
I0512 00:25:21.085810 22485033404224 run_lib.py:146] step: 8850, training_loss: 6.14258e-04
I0512 00:25:45.488384 22485033404224 run_lib.py:146] step: 8900, training_loss: 7.86999e-04
I0512 00:25:45.650038 22485033404224 run_lib.py:167] step: 8900, eval_loss: 6.62135e-04
I0512 00:26:09.429594 22485033404224 run_lib.py:146] step: 8950, training_loss: 6.07660e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 00:26:33.287925 22485033404224 run_lib.py:146] step: 9000, training_loss: 6.14944e-04
I0512 00:26:33.451100 22485033404224 run_lib.py:167] step: 9000, eval_loss: 8.42036e-04
I0512 00:26:57.685955 22485033404224 run_lib.py:146] step: 9050, training_loss: 6.92947e-04
I0512 00:27:21.897188 22485033404224 run_lib.py:146] step: 9100, training_loss: 6.81208e-04
I0512 00:27:22.058866 22485033404224 run_lib.py:167] step: 9100, eval_loss: 4.89548e-04
I0512 00:27:45.876168 22485033404224 run_lib.py:146] step: 9150, training_loss: 6.82295e-04
I0512 00:28:09.659376 22485033404224 run_lib.py:146] step: 9200, training_loss: 8.40881e-04
I0512 00:28:09.819907 22485033404224 run_lib.py:167] step: 9200, eval_loss: 5.33198e-04
I0512 00:28:34.409958 22485033404224 run_lib.py:146] step: 9250, training_loss: 7.36557e-04
I0512 00:28:58.176420 22485033404224 run_lib.py:146] step: 9300, training_loss: 8.20137e-04
I0512 00:28:58.338022 22485033404224 run_lib.py:167] step: 9300, eval_loss: 7.36274e-04
I0512 00:29:22.077965 22485033404224 run_lib.py:146] step: 9350, training_loss: 7.60702e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 00:29:46.511069 22485033404224 run_lib.py:146] step: 9400, training_loss: 6.76104e-04
I0512 00:29:46.675415 22485033404224 run_lib.py:167] step: 9400, eval_loss: 5.05040e-04
I0512 00:30:10.444170 22485033404224 run_lib.py:146] step: 9450, training_loss: 9.09977e-04
I0512 00:30:34.199039 22485033404224 run_lib.py:146] step: 9500, training_loss: 8.40270e-04
I0512 00:30:34.361724 22485033404224 run_lib.py:167] step: 9500, eval_loss: 5.05133e-04
I0512 00:30:58.758417 22485033404224 run_lib.py:146] step: 9550, training_loss: 6.55392e-04
I0512 00:31:22.447023 22485033404224 run_lib.py:146] step: 9600, training_loss: 6.06860e-04
I0512 00:31:22.609207 22485033404224 run_lib.py:167] step: 9600, eval_loss: 6.17065e-04
I0512 00:31:46.328906 22485033404224 run_lib.py:146] step: 9650, training_loss: 6.13107e-04
I0512 00:32:10.682872 22485033404224 run_lib.py:146] step: 9700, training_loss: 7.62391e-04
I0512 00:32:10.841995 22485033404224 run_lib.py:167] step: 9700, eval_loss: 5.65433e-04
I0512 00:32:34.553295 22485033404224 run_lib.py:146] step: 9750, training_loss: 7.01976e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 00:32:58.383758 22485033404224 run_lib.py:146] step: 9800, training_loss: 7.01904e-04
I0512 00:32:58.547024 22485033404224 run_lib.py:167] step: 9800, eval_loss: 6.55159e-04
I0512 00:33:22.611191 22485033404224 run_lib.py:146] step: 9850, training_loss: 8.65494e-04
I0512 00:33:46.639880 22485033404224 run_lib.py:146] step: 9900, training_loss: 7.19649e-04
I0512 00:33:46.802311 22485033404224 run_lib.py:167] step: 9900, eval_loss: 5.80888e-04
I0512 00:34:10.561813 22485033404224 run_lib.py:146] step: 9950, training_loss: 5.87796e-04
I0512 00:34:34.294165 22485033404224 run_lib.py:146] step: 10000, training_loss: 7.35359e-04
I0512 00:34:36.338171 22485033404224 run_lib.py:167] step: 10000, eval_loss: 6.28312e-04
I0512 00:35:01.889510 22485033404224 run_lib.py:146] step: 10050, training_loss: 7.30003e-04
I0512 00:35:25.587545 22485033404224 run_lib.py:146] step: 10100, training_loss: 6.59483e-04
I0512 00:35:25.747913 22485033404224 run_lib.py:167] step: 10100, eval_loss: 7.75194e-04
I0512 00:35:49.813726 22485033404224 run_lib.py:146] step: 10150, training_loss: 6.61342e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 00:36:13.980947 22485033404224 run_lib.py:146] step: 10200, training_loss: 9.07954e-04
I0512 00:36:14.144186 22485033404224 run_lib.py:167] step: 10200, eval_loss: 6.11509e-04
I0512 00:36:37.878920 22485033404224 run_lib.py:146] step: 10250, training_loss: 9.18566e-04
I0512 00:37:01.970898 22485033404224 run_lib.py:146] step: 10300, training_loss: 7.48918e-04
I0512 00:37:02.132633 22485033404224 run_lib.py:167] step: 10300, eval_loss: 6.41488e-04
I0512 00:37:26.174418 22485033404224 run_lib.py:146] step: 10350, training_loss: 6.20226e-04
I0512 00:37:49.915268 22485033404224 run_lib.py:146] step: 10400, training_loss: 8.61949e-04
I0512 00:37:50.075770 22485033404224 run_lib.py:167] step: 10400, eval_loss: 4.52352e-04
I0512 00:38:14.134256 22485033404224 run_lib.py:146] step: 10450, training_loss: 6.97700e-04
I0512 00:38:38.151749 22485033404224 run_lib.py:146] step: 10500, training_loss: 6.12178e-04
I0512 00:38:38.311614 22485033404224 run_lib.py:167] step: 10500, eval_loss: 6.42671e-04
I0512 00:39:02.024884 22485033404224 run_lib.py:146] step: 10550, training_loss: 5.77627e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 00:39:25.844859 22485033404224 run_lib.py:146] step: 10600, training_loss: 6.13321e-04
I0512 00:39:26.009257 22485033404224 run_lib.py:167] step: 10600, eval_loss: 5.50537e-04
I0512 00:39:50.126869 22485033404224 run_lib.py:146] step: 10650, training_loss: 8.34455e-04
I0512 00:40:14.222162 22485033404224 run_lib.py:146] step: 10700, training_loss: 6.93428e-04
I0512 00:40:14.382153 22485033404224 run_lib.py:167] step: 10700, eval_loss: 5.97510e-04
I0512 00:40:38.111917 22485033404224 run_lib.py:146] step: 10750, training_loss: 7.85815e-04
I0512 00:41:02.198895 22485033404224 run_lib.py:146] step: 10800, training_loss: 6.72106e-04
I0512 00:41:02.360936 22485033404224 run_lib.py:167] step: 10800, eval_loss: 7.29405e-04
I0512 00:41:26.444865 22485033404224 run_lib.py:146] step: 10850, training_loss: 5.77465e-04
I0512 00:41:50.223315 22485033404224 run_lib.py:146] step: 10900, training_loss: 6.60180e-04
I0512 00:41:50.384915 22485033404224 run_lib.py:167] step: 10900, eval_loss: 7.06622e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 00:42:14.529088 22485033404224 run_lib.py:146] step: 10950, training_loss: 7.95414e-04
I0512 00:42:38.654489 22485033404224 run_lib.py:146] step: 11000, training_loss: 8.09836e-04
I0512 00:42:38.819067 22485033404224 run_lib.py:167] step: 11000, eval_loss: 7.14744e-04
I0512 00:43:02.622947 22485033404224 run_lib.py:146] step: 11050, training_loss: 7.86413e-04
I0512 00:43:26.854315 22485033404224 run_lib.py:146] step: 11100, training_loss: 9.06707e-04
I0512 00:43:27.016766 22485033404224 run_lib.py:167] step: 11100, eval_loss: 6.54919e-04
I0512 00:43:51.097217 22485033404224 run_lib.py:146] step: 11150, training_loss: 6.71735e-04
I0512 00:44:14.871999 22485033404224 run_lib.py:146] step: 11200, training_loss: 6.00076e-04
I0512 00:44:15.032788 22485033404224 run_lib.py:167] step: 11200, eval_loss: 4.00615e-04
I0512 00:44:39.219410 22485033404224 run_lib.py:146] step: 11250, training_loss: 6.90467e-04
I0512 00:45:03.311028 22485033404224 run_lib.py:146] step: 11300, training_loss: 8.32936e-04
I0512 00:45:03.471781 22485033404224 run_lib.py:167] step: 11300, eval_loss: 7.24941e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 00:45:27.376374 22485033404224 run_lib.py:146] step: 11350, training_loss: 9.10507e-04
I0512 00:45:51.186243 22485033404224 run_lib.py:146] step: 11400, training_loss: 7.73503e-04
I0512 00:45:51.348376 22485033404224 run_lib.py:167] step: 11400, eval_loss: 6.00512e-04
I0512 00:46:15.964343 22485033404224 run_lib.py:146] step: 11450, training_loss: 5.52548e-04
I0512 00:46:39.769202 22485033404224 run_lib.py:146] step: 11500, training_loss: 5.27147e-04
I0512 00:46:39.931035 22485033404224 run_lib.py:167] step: 11500, eval_loss: 6.74323e-04
I0512 00:47:03.705478 22485033404224 run_lib.py:146] step: 11550, training_loss: 7.25238e-04
I0512 00:47:27.827800 22485033404224 run_lib.py:146] step: 11600, training_loss: 7.34045e-04
I0512 00:47:27.989879 22485033404224 run_lib.py:167] step: 11600, eval_loss: 5.84294e-04
I0512 00:47:52.084060 22485033404224 run_lib.py:146] step: 11650, training_loss: 7.70973e-04
I0512 00:48:15.799914 22485033404224 run_lib.py:146] step: 11700, training_loss: 5.43476e-04
I0512 00:48:15.961652 22485033404224 run_lib.py:167] step: 11700, eval_loss: 5.44698e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 00:48:40.080402 22485033404224 run_lib.py:146] step: 11750, training_loss: 6.62947e-04
I0512 00:49:04.206068 22485033404224 run_lib.py:146] step: 11800, training_loss: 9.80598e-04
I0512 00:49:04.367220 22485033404224 run_lib.py:167] step: 11800, eval_loss: 7.41667e-04
I0512 00:49:28.115620 22485033404224 run_lib.py:146] step: 11850, training_loss: 7.62935e-04
I0512 00:49:52.173184 22485033404224 run_lib.py:146] step: 11900, training_loss: 5.79954e-04
I0512 00:49:52.334363 22485033404224 run_lib.py:167] step: 11900, eval_loss: 6.49864e-04
I0512 00:50:16.374054 22485033404224 run_lib.py:146] step: 11950, training_loss: 7.86542e-04
I0512 00:50:40.146562 22485033404224 run_lib.py:146] step: 12000, training_loss: 8.42954e-04
I0512 00:50:40.306157 22485033404224 run_lib.py:167] step: 12000, eval_loss: 6.09228e-04
I0512 00:51:04.343289 22485033404224 run_lib.py:146] step: 12050, training_loss: 7.45494e-04
I0512 00:51:28.366698 22485033404224 run_lib.py:146] step: 12100, training_loss: 8.05840e-04
I0512 00:51:28.525592 22485033404224 run_lib.py:167] step: 12100, eval_loss: 6.42363e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 00:51:52.313993 22485033404224 run_lib.py:146] step: 12150, training_loss: 6.72469e-04
I0512 00:52:16.025159 22485033404224 run_lib.py:146] step: 12200, training_loss: 6.31749e-04
I0512 00:52:16.186179 22485033404224 run_lib.py:167] step: 12200, eval_loss: 5.01956e-04
I0512 00:52:40.580817 22485033404224 run_lib.py:146] step: 12250, training_loss: 8.22326e-04
I0512 00:53:04.342315 22485033404224 run_lib.py:146] step: 12300, training_loss: 8.20749e-04
I0512 00:53:04.502444 22485033404224 run_lib.py:167] step: 12300, eval_loss: 8.15658e-04
I0512 00:53:28.233822 22485033404224 run_lib.py:146] step: 12350, training_loss: 7.73207e-04
I0512 00:53:52.254139 22485033404224 run_lib.py:146] step: 12400, training_loss: 6.96797e-04
I0512 00:53:52.414742 22485033404224 run_lib.py:167] step: 12400, eval_loss: 6.86517e-04
I0512 00:54:16.452482 22485033404224 run_lib.py:146] step: 12450, training_loss: 7.21558e-04
I0512 00:54:40.177212 22485033404224 run_lib.py:146] step: 12500, training_loss: 6.80520e-04
I0512 00:54:40.337560 22485033404224 run_lib.py:167] step: 12500, eval_loss: 7.40057e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 00:55:04.503510 22485033404224 run_lib.py:146] step: 12550, training_loss: 6.07953e-04
I0512 00:55:28.614639 22485033404224 run_lib.py:146] step: 12600, training_loss: 7.48678e-04
I0512 00:55:28.776294 22485033404224 run_lib.py:167] step: 12600, eval_loss: 8.02384e-04
I0512 00:55:52.492268 22485033404224 run_lib.py:146] step: 12650, training_loss: 6.87857e-04
I0512 00:56:16.502274 22485033404224 run_lib.py:146] step: 12700, training_loss: 5.92235e-04
I0512 00:56:16.663770 22485033404224 run_lib.py:167] step: 12700, eval_loss: 5.32095e-04
I0512 00:56:40.711364 22485033404224 run_lib.py:146] step: 12750, training_loss: 8.72989e-04
I0512 00:57:04.443962 22485033404224 run_lib.py:146] step: 12800, training_loss: 5.00554e-04
I0512 00:57:04.602771 22485033404224 run_lib.py:167] step: 12800, eval_loss: 7.82182e-04
I0512 00:57:28.645973 22485033404224 run_lib.py:146] step: 12850, training_loss: 6.02913e-04
I0512 00:57:52.665555 22485033404224 run_lib.py:146] step: 12900, training_loss: 6.24967e-04
I0512 00:57:52.825214 22485033404224 run_lib.py:167] step: 12900, eval_loss: 8.03096e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 00:58:16.614637 22485033404224 run_lib.py:146] step: 12950, training_loss: 7.36106e-04
I0512 00:58:40.334858 22485033404224 run_lib.py:146] step: 13000, training_loss: 7.37348e-04
I0512 00:58:40.496916 22485033404224 run_lib.py:167] step: 13000, eval_loss: 6.92696e-04
I0512 00:59:04.971036 22485033404224 run_lib.py:146] step: 13050, training_loss: 6.91725e-04
I0512 00:59:28.776560 22485033404224 run_lib.py:146] step: 13100, training_loss: 8.00325e-04
I0512 00:59:28.938577 22485033404224 run_lib.py:167] step: 13100, eval_loss: 6.13358e-04
I0512 00:59:52.715971 22485033404224 run_lib.py:146] step: 13150, training_loss: 5.02846e-04
I0512 01:00:17.138775 22485033404224 run_lib.py:146] step: 13200, training_loss: 6.46516e-04
I0512 01:00:17.302071 22485033404224 run_lib.py:167] step: 13200, eval_loss: 6.17164e-04
I0512 01:00:41.074890 22485033404224 run_lib.py:146] step: 13250, training_loss: 8.10439e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 01:01:04.964384 22485033404224 run_lib.py:146] step: 13300, training_loss: 5.26968e-04
I0512 01:01:05.129158 22485033404224 run_lib.py:167] step: 13300, eval_loss: 5.83612e-04
I0512 01:01:29.579738 22485033404224 run_lib.py:146] step: 13350, training_loss: 6.94943e-04
I0512 01:01:54.012703 22485033404224 run_lib.py:146] step: 13400, training_loss: 7.17766e-04
I0512 01:01:54.174726 22485033404224 run_lib.py:167] step: 13400, eval_loss: 4.46665e-04
I0512 01:02:18.151810 22485033404224 run_lib.py:146] step: 13450, training_loss: 6.71404e-04
I0512 01:02:42.527202 22485033404224 run_lib.py:146] step: 13500, training_loss: 7.34700e-04
I0512 01:02:42.689842 22485033404224 run_lib.py:167] step: 13500, eval_loss: 6.05184e-04
I0512 01:03:07.051712 22485033404224 run_lib.py:146] step: 13550, training_loss: 5.92679e-04
I0512 01:03:30.950007 22485033404224 run_lib.py:146] step: 13600, training_loss: 6.62203e-04
I0512 01:03:31.112550 22485033404224 run_lib.py:167] step: 13600, eval_loss: 6.33301e-04
I0512 01:03:55.218243 22485033404224 run_lib.py:146] step: 13650, training_loss: 6.06287e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 01:04:19.417183 22485033404224 run_lib.py:146] step: 13700, training_loss: 4.71759e-04
I0512 01:04:19.581455 22485033404224 run_lib.py:167] step: 13700, eval_loss: 6.47689e-04
I0512 01:04:43.378568 22485033404224 run_lib.py:146] step: 13750, training_loss: 6.02798e-04
I0512 01:05:07.544925 22485033404224 run_lib.py:146] step: 13800, training_loss: 8.03430e-04
I0512 01:05:07.707788 22485033404224 run_lib.py:167] step: 13800, eval_loss: 6.19729e-04
I0512 01:05:31.850554 22485033404224 run_lib.py:146] step: 13850, training_loss: 9.39085e-04
I0512 01:05:55.604157 22485033404224 run_lib.py:146] step: 13900, training_loss: 6.89810e-04
I0512 01:05:55.763778 22485033404224 run_lib.py:167] step: 13900, eval_loss: 6.48179e-04
I0512 01:06:19.504730 22485033404224 run_lib.py:146] step: 13950, training_loss: 5.10612e-04
I0512 01:06:43.847631 22485033404224 run_lib.py:146] step: 14000, training_loss: 5.55384e-04
I0512 01:06:44.006677 22485033404224 run_lib.py:167] step: 14000, eval_loss: 4.36763e-04
I0512 01:07:07.707573 22485033404224 run_lib.py:146] step: 14050, training_loss: 8.57754e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 01:07:31.501596 22485033404224 run_lib.py:146] step: 14100, training_loss: 6.15283e-04
I0512 01:07:31.665905 22485033404224 run_lib.py:167] step: 14100, eval_loss: 4.63687e-04
I0512 01:07:55.735615 22485033404224 run_lib.py:146] step: 14150, training_loss: 5.79394e-04
I0512 01:08:19.844399 22485033404224 run_lib.py:146] step: 14200, training_loss: 5.25849e-04
I0512 01:08:20.006412 22485033404224 run_lib.py:167] step: 14200, eval_loss: 6.52232e-04
I0512 01:08:43.747348 22485033404224 run_lib.py:146] step: 14250, training_loss: 8.11952e-04
I0512 01:09:07.784200 22485033404224 run_lib.py:146] step: 14300, training_loss: 6.63490e-04
I0512 01:09:07.944507 22485033404224 run_lib.py:167] step: 14300, eval_loss: 7.25904e-04
I0512 01:09:31.983507 22485033404224 run_lib.py:146] step: 14350, training_loss: 7.45165e-04
I0512 01:09:55.730139 22485033404224 run_lib.py:146] step: 14400, training_loss: 5.12090e-04
I0512 01:09:55.892359 22485033404224 run_lib.py:167] step: 14400, eval_loss: 7.68404e-04
I0512 01:10:19.947669 22485033404224 run_lib.py:146] step: 14450, training_loss: 5.36249e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 01:10:44.141768 22485033404224 run_lib.py:146] step: 14500, training_loss: 6.91840e-04
I0512 01:10:44.305846 22485033404224 run_lib.py:167] step: 14500, eval_loss: 4.70169e-04
I0512 01:11:08.045701 22485033404224 run_lib.py:146] step: 14550, training_loss: 9.44007e-04
I0512 01:11:32.114350 22485033404224 run_lib.py:146] step: 14600, training_loss: 7.36018e-04
I0512 01:11:32.276576 22485033404224 run_lib.py:167] step: 14600, eval_loss: 6.30713e-04
I0512 01:11:56.306018 22485033404224 run_lib.py:146] step: 14650, training_loss: 7.02724e-04
I0512 01:12:20.019861 22485033404224 run_lib.py:146] step: 14700, training_loss: 5.93532e-04
I0512 01:12:20.181122 22485033404224 run_lib.py:167] step: 14700, eval_loss: 5.94353e-04
I0512 01:12:44.190069 22485033404224 run_lib.py:146] step: 14750, training_loss: 6.84984e-04
I0512 01:13:08.205487 22485033404224 run_lib.py:146] step: 14800, training_loss: 7.62547e-04
I0512 01:13:08.366829 22485033404224 run_lib.py:167] step: 14800, eval_loss: 6.62869e-04
I0512 01:13:32.079510 22485033404224 run_lib.py:146] step: 14850, training_loss: 7.47819e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 01:13:55.884270 22485033404224 run_lib.py:146] step: 14900, training_loss: 5.82825e-04
I0512 01:13:56.047119 22485033404224 run_lib.py:167] step: 14900, eval_loss: 6.92296e-04
I0512 01:14:20.408581 22485033404224 run_lib.py:146] step: 14950, training_loss: 7.28521e-04
I0512 01:14:44.064849 22485033404224 run_lib.py:146] step: 15000, training_loss: 6.97101e-04
I0512 01:14:44.225433 22485033404224 run_lib.py:167] step: 15000, eval_loss: 7.48848e-04
I0512 01:15:07.906305 22485033404224 run_lib.py:146] step: 15050, training_loss: 5.43603e-04
I0512 01:15:31.892323 22485033404224 run_lib.py:146] step: 15100, training_loss: 4.80379e-04
I0512 01:15:32.052838 22485033404224 run_lib.py:167] step: 15100, eval_loss: 6.44743e-04
I0512 01:15:56.035998 22485033404224 run_lib.py:146] step: 15150, training_loss: 8.12443e-04
I0512 01:16:19.715751 22485033404224 run_lib.py:146] step: 15200, training_loss: 5.88721e-04
I0512 01:16:19.877682 22485033404224 run_lib.py:167] step: 15200, eval_loss: 6.72996e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 01:16:44.007489 22485033404224 run_lib.py:146] step: 15250, training_loss: 5.69486e-04
I0512 01:17:08.135005 22485033404224 run_lib.py:146] step: 15300, training_loss: 8.64372e-04
I0512 01:17:08.296954 22485033404224 run_lib.py:167] step: 15300, eval_loss: 7.33331e-04
I0512 01:17:32.041679 22485033404224 run_lib.py:146] step: 15350, training_loss: 5.60395e-04
I0512 01:17:56.165440 22485033404224 run_lib.py:146] step: 15400, training_loss: 7.52277e-04
I0512 01:17:56.328106 22485033404224 run_lib.py:167] step: 15400, eval_loss: 8.80562e-04
I0512 01:18:20.347532 22485033404224 run_lib.py:146] step: 15450, training_loss: 7.00083e-04
I0512 01:18:44.100043 22485033404224 run_lib.py:146] step: 15500, training_loss: 8.34003e-04
I0512 01:18:44.261453 22485033404224 run_lib.py:167] step: 15500, eval_loss: 5.08197e-04
I0512 01:19:08.282096 22485033404224 run_lib.py:146] step: 15550, training_loss: 7.21199e-04
I0512 01:19:32.291373 22485033404224 run_lib.py:146] step: 15600, training_loss: 7.19883e-04
I0512 01:19:32.451339 22485033404224 run_lib.py:167] step: 15600, eval_loss: 5.94215e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 01:19:56.215495 22485033404224 run_lib.py:146] step: 15650, training_loss: 5.69856e-04
I0512 01:20:19.918903 22485033404224 run_lib.py:146] step: 15700, training_loss: 6.53233e-04
I0512 01:20:20.009267 22485033404224 run_lib.py:167] step: 15700, eval_loss: 4.75052e-04
I0512 01:20:44.412897 22485033404224 run_lib.py:146] step: 15750, training_loss: 6.93523e-04
I0512 01:21:08.138772 22485033404224 run_lib.py:146] step: 15800, training_loss: 6.67511e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 01:21:08.486793 22485033404224 run_lib.py:167] step: 15800, eval_loss: 6.68911e-04
I0512 01:21:32.225970 22485033404224 run_lib.py:146] step: 15850, training_loss: 6.10394e-04
I0512 01:21:56.325590 22485033404224 run_lib.py:146] step: 15900, training_loss: 5.01368e-04
I0512 01:21:56.487206 22485033404224 run_lib.py:167] step: 15900, eval_loss: 5.95439e-04
I0512 01:22:20.532511 22485033404224 run_lib.py:146] step: 15950, training_loss: 5.22441e-04
I0512 01:22:44.262898 22485033404224 run_lib.py:146] step: 16000, training_loss: 8.04869e-04
I0512 01:22:44.424547 22485033404224 run_lib.py:167] step: 16000, eval_loss: 5.14608e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 01:23:08.564313 22485033404224 run_lib.py:146] step: 16050, training_loss: 5.55202e-04
I0512 01:23:32.670516 22485033404224 run_lib.py:146] step: 16100, training_loss: 6.90444e-04
I0512 01:23:32.831936 22485033404224 run_lib.py:167] step: 16100, eval_loss: 5.18244e-04
I0512 01:23:56.548458 22485033404224 run_lib.py:146] step: 16150, training_loss: 5.89994e-04
I0512 01:24:20.603301 22485033404224 run_lib.py:146] step: 16200, training_loss: 6.76986e-04
I0512 01:24:20.763624 22485033404224 run_lib.py:167] step: 16200, eval_loss: 6.89991e-04
I0512 01:24:44.794523 22485033404224 run_lib.py:146] step: 16250, training_loss: 7.88961e-04
I0512 01:25:08.502114 22485033404224 run_lib.py:146] step: 16300, training_loss: 6.39489e-04
I0512 01:25:08.662386 22485033404224 run_lib.py:167] step: 16300, eval_loss: 7.72934e-04
I0512 01:25:32.653955 22485033404224 run_lib.py:146] step: 16350, training_loss: 7.65226e-04
I0512 01:25:56.648777 22485033404224 run_lib.py:146] step: 16400, training_loss: 5.20517e-04
I0512 01:25:56.810041 22485033404224 run_lib.py:167] step: 16400, eval_loss: 6.34175e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 01:26:20.580171 22485033404224 run_lib.py:146] step: 16450, training_loss: 7.12869e-04
I0512 01:26:44.631275 22485033404224 run_lib.py:146] step: 16500, training_loss: 4.86722e-04
I0512 01:26:44.792526 22485033404224 run_lib.py:167] step: 16500, eval_loss: 5.75289e-04
I0512 01:27:08.836748 22485033404224 run_lib.py:146] step: 16550, training_loss: 5.27216e-04
I0512 01:27:32.522387 22485033404224 run_lib.py:146] step: 16600, training_loss: 8.02693e-04
I0512 01:27:32.682295 22485033404224 run_lib.py:167] step: 16600, eval_loss: 7.65850e-04
I0512 01:27:56.369383 22485033404224 run_lib.py:146] step: 16650, training_loss: 6.67304e-04
I0512 01:28:20.330821 22485033404224 run_lib.py:146] step: 16700, training_loss: 6.03604e-04
I0512 01:28:20.491124 22485033404224 run_lib.py:167] step: 16700, eval_loss: 6.30937e-04
I0512 01:28:44.472970 22485033404224 run_lib.py:146] step: 16750, training_loss: 7.88277e-04
I0512 01:29:08.163695 22485033404224 run_lib.py:146] step: 16800, training_loss: 6.42908e-04
I0512 01:29:08.325547 22485033404224 run_lib.py:167] step: 16800, eval_loss: 6.11897e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 01:29:32.478450 22485033404224 run_lib.py:146] step: 16850, training_loss: 8.39053e-04
I0512 01:29:56.537868 22485033404224 run_lib.py:146] step: 16900, training_loss: 8.29227e-04
I0512 01:29:56.699513 22485033404224 run_lib.py:167] step: 16900, eval_loss: 5.60488e-04
I0512 01:30:20.380726 22485033404224 run_lib.py:146] step: 16950, training_loss: 6.40932e-04
I0512 01:30:44.391081 22485033404224 run_lib.py:146] step: 17000, training_loss: 6.38422e-04
I0512 01:30:44.551225 22485033404224 run_lib.py:167] step: 17000, eval_loss: 6.42944e-04
I0512 01:31:08.549896 22485033404224 run_lib.py:146] step: 17050, training_loss: 5.32499e-04
I0512 01:31:32.232141 22485033404224 run_lib.py:146] step: 17100, training_loss: 6.27475e-04
I0512 01:31:32.392613 22485033404224 run_lib.py:167] step: 17100, eval_loss: 6.20453e-04
I0512 01:31:56.410689 22485033404224 run_lib.py:146] step: 17150, training_loss: 7.52144e-04
I0512 01:32:20.412155 22485033404224 run_lib.py:146] step: 17200, training_loss: 5.39659e-04
I0512 01:32:20.573249 22485033404224 run_lib.py:167] step: 17200, eval_loss: 8.23813e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 01:32:44.338440 22485033404224 run_lib.py:146] step: 17250, training_loss: 6.61013e-04
I0512 01:33:08.376766 22485033404224 run_lib.py:146] step: 17300, training_loss: 6.34198e-04
I0512 01:33:08.538924 22485033404224 run_lib.py:167] step: 17300, eval_loss: 5.45287e-04
I0512 01:33:32.581195 22485033404224 run_lib.py:146] step: 17350, training_loss: 6.15453e-04
I0512 01:33:56.299237 22485033404224 run_lib.py:146] step: 17400, training_loss: 6.31941e-04
I0512 01:33:56.459767 22485033404224 run_lib.py:167] step: 17400, eval_loss: 5.75774e-04
I0512 01:34:20.179910 22485033404224 run_lib.py:146] step: 17450, training_loss: 5.87663e-04
I0512 01:34:44.554716 22485033404224 run_lib.py:146] step: 17500, training_loss: 7.76710e-04
I0512 01:34:44.716295 22485033404224 run_lib.py:167] step: 17500, eval_loss: 5.36215e-04
I0512 01:35:08.469356 22485033404224 run_lib.py:146] step: 17550, training_loss: 7.21392e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 01:35:32.302708 22485033404224 run_lib.py:146] step: 17600, training_loss: 6.01568e-04
I0512 01:35:32.468301 22485033404224 run_lib.py:167] step: 17600, eval_loss: 6.23881e-04
I0512 01:35:56.540074 22485033404224 run_lib.py:146] step: 17650, training_loss: 5.58702e-04
I0512 01:36:20.688415 22485033404224 run_lib.py:146] step: 17700, training_loss: 8.62461e-04
I0512 01:36:20.850066 22485033404224 run_lib.py:167] step: 17700, eval_loss: 5.55788e-04
I0512 01:36:44.524560 22485033404224 run_lib.py:146] step: 17750, training_loss: 6.78157e-04
I0512 01:37:08.541414 22485033404224 run_lib.py:146] step: 17800, training_loss: 4.74949e-04
I0512 01:37:08.702286 22485033404224 run_lib.py:167] step: 17800, eval_loss: 6.90251e-04
I0512 01:37:32.755333 22485033404224 run_lib.py:146] step: 17850, training_loss: 5.29673e-04
I0512 01:37:56.437712 22485033404224 run_lib.py:146] step: 17900, training_loss: 5.93960e-04
I0512 01:37:56.598305 22485033404224 run_lib.py:167] step: 17900, eval_loss: 6.57887e-04
I0512 01:38:20.647691 22485033404224 run_lib.py:146] step: 17950, training_loss: 7.27004e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 01:38:44.882623 22485033404224 run_lib.py:146] step: 18000, training_loss: 5.12443e-04
I0512 01:38:45.044505 22485033404224 run_lib.py:167] step: 18000, eval_loss: 6.20152e-04
I0512 01:39:08.800819 22485033404224 run_lib.py:146] step: 18050, training_loss: 6.01626e-04
I0512 01:39:32.930863 22485033404224 run_lib.py:146] step: 18100, training_loss: 6.06440e-04
I0512 01:39:33.091379 22485033404224 run_lib.py:167] step: 18100, eval_loss: 5.95099e-04
I0512 01:39:57.261550 22485033404224 run_lib.py:146] step: 18150, training_loss: 6.35178e-04
I0512 01:40:20.962705 22485033404224 run_lib.py:146] step: 18200, training_loss: 8.62402e-04
I0512 01:40:21.123655 22485033404224 run_lib.py:167] step: 18200, eval_loss: 7.69302e-04
I0512 01:40:44.878192 22485033404224 run_lib.py:146] step: 18250, training_loss: 4.36042e-04
I0512 01:41:09.385373 22485033404224 run_lib.py:146] step: 18300, training_loss: 6.46828e-04
I0512 01:41:09.546835 22485033404224 run_lib.py:167] step: 18300, eval_loss: 7.82114e-04
I0512 01:41:33.278889 22485033404224 run_lib.py:146] step: 18350, training_loss: 6.18928e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 01:41:57.071493 22485033404224 run_lib.py:146] step: 18400, training_loss: 7.72604e-04
I0512 01:41:57.234687 22485033404224 run_lib.py:167] step: 18400, eval_loss: 7.92585e-04
I0512 01:42:21.267387 22485033404224 run_lib.py:146] step: 18450, training_loss: 6.55387e-04
I0512 01:42:45.295595 22485033404224 run_lib.py:146] step: 18500, training_loss: 7.62670e-04
I0512 01:42:45.456002 22485033404224 run_lib.py:167] step: 18500, eval_loss: 6.20534e-04
I0512 01:43:09.131802 22485033404224 run_lib.py:146] step: 18550, training_loss: 7.72731e-04
I0512 01:43:33.137573 22485033404224 run_lib.py:146] step: 18600, training_loss: 6.65703e-04
I0512 01:43:33.300034 22485033404224 run_lib.py:167] step: 18600, eval_loss: 5.13540e-04
I0512 01:43:57.321455 22485033404224 run_lib.py:146] step: 18650, training_loss: 5.21872e-04
I0512 01:44:21.019030 22485033404224 run_lib.py:146] step: 18700, training_loss: 7.63051e-04
I0512 01:44:21.179549 22485033404224 run_lib.py:167] step: 18700, eval_loss: 5.38351e-04
I0512 01:44:45.186589 22485033404224 run_lib.py:146] step: 18750, training_loss: 7.76471e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 01:45:09.316385 22485033404224 run_lib.py:146] step: 18800, training_loss: 4.95363e-04
I0512 01:45:09.478759 22485033404224 run_lib.py:167] step: 18800, eval_loss: 6.56691e-04
I0512 01:45:33.168351 22485033404224 run_lib.py:146] step: 18850, training_loss: 6.94777e-04
I0512 01:45:57.234163 22485033404224 run_lib.py:146] step: 18900, training_loss: 6.88113e-04
I0512 01:45:57.394879 22485033404224 run_lib.py:167] step: 18900, eval_loss: 7.23205e-04
I0512 01:46:21.384483 22485033404224 run_lib.py:146] step: 18950, training_loss: 6.64993e-04
I0512 01:46:45.105886 22485033404224 run_lib.py:146] step: 19000, training_loss: 8.83423e-04
I0512 01:46:45.267451 22485033404224 run_lib.py:167] step: 19000, eval_loss: 7.11006e-04
I0512 01:47:08.997412 22485033404224 run_lib.py:146] step: 19050, training_loss: 4.06308e-04
I0512 01:47:33.332752 22485033404224 run_lib.py:146] step: 19100, training_loss: 7.46773e-04
I0512 01:47:33.494467 22485033404224 run_lib.py:167] step: 19100, eval_loss: 5.02589e-04
I0512 01:47:57.176113 22485033404224 run_lib.py:146] step: 19150, training_loss: 7.33299e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 01:48:20.940862 22485033404224 run_lib.py:146] step: 19200, training_loss: 5.21315e-04
I0512 01:48:21.101704 22485033404224 run_lib.py:167] step: 19200, eval_loss: 6.34438e-04
I0512 01:48:45.551228 22485033404224 run_lib.py:146] step: 19250, training_loss: 7.69245e-04
I0512 01:49:09.231008 22485033404224 run_lib.py:146] step: 19300, training_loss: 7.16994e-04
I0512 01:49:09.391557 22485033404224 run_lib.py:167] step: 19300, eval_loss: 6.35369e-04
I0512 01:49:33.069702 22485033404224 run_lib.py:146] step: 19350, training_loss: 7.61369e-04
I0512 01:49:57.058783 22485033404224 run_lib.py:146] step: 19400, training_loss: 5.60783e-04
I0512 01:49:57.218659 22485033404224 run_lib.py:167] step: 19400, eval_loss: 4.62218e-04
I0512 01:50:21.174283 22485033404224 run_lib.py:146] step: 19450, training_loss: 8.18264e-04
I0512 01:50:44.853160 22485033404224 run_lib.py:146] step: 19500, training_loss: 4.57954e-04
I0512 01:50:45.013966 22485033404224 run_lib.py:167] step: 19500, eval_loss: 5.47624e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 01:51:09.062690 22485033404224 run_lib.py:146] step: 19550, training_loss: 5.65435e-04
I0512 01:51:33.145560 22485033404224 run_lib.py:146] step: 19600, training_loss: 5.61514e-04
I0512 01:51:33.307080 22485033404224 run_lib.py:167] step: 19600, eval_loss: 5.33500e-04
I0512 01:51:57.004165 22485033404224 run_lib.py:146] step: 19650, training_loss: 7.63842e-04
I0512 01:52:21.104187 22485033404224 run_lib.py:146] step: 19700, training_loss: 6.60741e-04
I0512 01:52:21.265692 22485033404224 run_lib.py:167] step: 19700, eval_loss: 7.84503e-04
I0512 01:52:45.330242 22485033404224 run_lib.py:146] step: 19750, training_loss: 6.64450e-04
I0512 01:53:09.076134 22485033404224 run_lib.py:146] step: 19800, training_loss: 6.81218e-04
I0512 01:53:09.237755 22485033404224 run_lib.py:167] step: 19800, eval_loss: 8.33456e-04
I0512 01:53:33.306504 22485033404224 run_lib.py:146] step: 19850, training_loss: 5.75798e-04
I0512 01:53:57.331941 22485033404224 run_lib.py:146] step: 19900, training_loss: 7.02665e-04
I0512 01:53:57.494144 22485033404224 run_lib.py:167] step: 19900, eval_loss: 5.54489e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 01:54:21.324363 22485033404224 run_lib.py:146] step: 19950, training_loss: 8.59067e-04
I0512 01:54:45.072779 22485033404224 run_lib.py:146] step: 20000, training_loss: 5.53640e-04
I0512 01:54:47.541574 22485033404224 run_lib.py:167] step: 20000, eval_loss: 6.46325e-04
I0512 01:55:13.351582 22485033404224 run_lib.py:146] step: 20050, training_loss: 8.47065e-04
I0512 01:55:37.129016 22485033404224 run_lib.py:146] step: 20100, training_loss: 6.41809e-04
I0512 01:55:37.290353 22485033404224 run_lib.py:167] step: 20100, eval_loss: 5.23719e-04
I0512 01:56:01.459824 22485033404224 run_lib.py:146] step: 20150, training_loss: 7.47037e-04
I0512 01:56:25.262925 22485033404224 run_lib.py:146] step: 20200, training_loss: 7.05624e-04
I0512 01:56:25.427055 22485033404224 run_lib.py:167] step: 20200, eval_loss: 5.43142e-04
I0512 01:56:49.578411 22485033404224 run_lib.py:146] step: 20250, training_loss: 6.43046e-04
I0512 01:57:13.652723 22485033404224 run_lib.py:146] step: 20300, training_loss: 5.84280e-04
I0512 01:57:13.813688 22485033404224 run_lib.py:167] step: 20300, eval_loss: 7.39243e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 01:57:37.659017 22485033404224 run_lib.py:146] step: 20350, training_loss: 4.98795e-04
I0512 01:58:01.841085 22485033404224 run_lib.py:146] step: 20400, training_loss: 9.48987e-04
I0512 01:58:02.004278 22485033404224 run_lib.py:167] step: 20400, eval_loss: 4.48650e-04
I0512 01:58:25.960079 22485033404224 run_lib.py:146] step: 20450, training_loss: 7.94131e-04
I0512 01:58:49.588891 22485033404224 run_lib.py:146] step: 20500, training_loss: 5.47348e-04
I0512 01:58:49.748588 22485033404224 run_lib.py:167] step: 20500, eval_loss: 6.54701e-04
I0512 01:59:13.698355 22485033404224 run_lib.py:146] step: 20550, training_loss: 4.61550e-04
I0512 01:59:37.223108 22485033404224 run_lib.py:146] step: 20600, training_loss: 5.61565e-04
I0512 01:59:37.384289 22485033404224 run_lib.py:167] step: 20600, eval_loss: 6.40020e-04
I0512 02:00:01.178504 22485033404224 run_lib.py:146] step: 20650, training_loss: 5.89890e-04
I0512 02:00:25.022045 22485033404224 run_lib.py:146] step: 20700, training_loss: 7.26601e-04
I0512 02:00:25.181649 22485033404224 run_lib.py:167] step: 20700, eval_loss: 6.94917e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 02:00:48.766995 22485033404224 run_lib.py:146] step: 20750, training_loss: 6.91364e-04
I0512 02:01:12.638977 22485033404224 run_lib.py:146] step: 20800, training_loss: 6.33246e-04
I0512 02:01:12.799229 22485033404224 run_lib.py:167] step: 20800, eval_loss: 5.65945e-04
I0512 02:01:36.721300 22485033404224 run_lib.py:146] step: 20850, training_loss: 7.58053e-04
I0512 02:02:00.242304 22485033404224 run_lib.py:146] step: 20900, training_loss: 7.78530e-04
I0512 02:02:00.400246 22485033404224 run_lib.py:167] step: 20900, eval_loss: 6.92535e-04
I0512 02:02:24.209674 22485033404224 run_lib.py:146] step: 20950, training_loss: 6.23925e-04
I0512 02:02:48.025964 22485033404224 run_lib.py:146] step: 21000, training_loss: 6.04596e-04
I0512 02:02:48.184341 22485033404224 run_lib.py:167] step: 21000, eval_loss: 8.14894e-04
I0512 02:03:11.688002 22485033404224 run_lib.py:146] step: 21050, training_loss: 5.71070e-04
I0512 02:03:35.516578 22485033404224 run_lib.py:146] step: 21100, training_loss: 5.27393e-04
I0512 02:03:35.676172 22485033404224 run_lib.py:167] step: 21100, eval_loss: 6.71474e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 02:03:59.278846 22485033404224 run_lib.py:146] step: 21150, training_loss: 5.50683e-04
I0512 02:04:23.156184 22485033404224 run_lib.py:146] step: 21200, training_loss: 5.94379e-04
I0512 02:04:23.316655 22485033404224 run_lib.py:167] step: 21200, eval_loss: 6.91547e-04
I0512 02:04:47.163158 22485033404224 run_lib.py:146] step: 21250, training_loss: 5.44688e-04
I0512 02:05:10.698460 22485033404224 run_lib.py:146] step: 21300, training_loss: 5.64409e-04
I0512 02:05:10.858359 22485033404224 run_lib.py:167] step: 21300, eval_loss: 6.55071e-04
I0512 02:05:34.645362 22485033404224 run_lib.py:146] step: 21350, training_loss: 5.49629e-04
I0512 02:05:58.163904 22485033404224 run_lib.py:146] step: 21400, training_loss: 6.96134e-04
I0512 02:05:58.323516 22485033404224 run_lib.py:167] step: 21400, eval_loss: 6.24225e-04
I0512 02:06:22.191703 22485033404224 run_lib.py:146] step: 21450, training_loss: 8.53564e-04
I0512 02:06:46.049280 22485033404224 run_lib.py:146] step: 21500, training_loss: 8.24288e-04
I0512 02:06:46.208885 22485033404224 run_lib.py:167] step: 21500, eval_loss: 5.64255e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 02:07:09.806655 22485033404224 run_lib.py:146] step: 21550, training_loss: 8.81840e-04
I0512 02:07:33.709503 22485033404224 run_lib.py:146] step: 21600, training_loss: 4.69776e-04
I0512 02:07:33.871736 22485033404224 run_lib.py:167] step: 21600, eval_loss: 7.42319e-04
I0512 02:07:57.805201 22485033404224 run_lib.py:146] step: 21650, training_loss: 5.73640e-04
I0512 02:08:21.348172 22485033404224 run_lib.py:146] step: 21700, training_loss: 8.22605e-04
I0512 02:08:21.508235 22485033404224 run_lib.py:167] step: 21700, eval_loss: 5.44467e-04
I0512 02:08:45.306890 22485033404224 run_lib.py:146] step: 21750, training_loss: 6.97824e-04
I0512 02:09:09.151324 22485033404224 run_lib.py:146] step: 21800, training_loss: 7.86335e-04
I0512 02:09:09.311962 22485033404224 run_lib.py:167] step: 21800, eval_loss: 7.16011e-04
I0512 02:09:32.826686 22485033404224 run_lib.py:146] step: 21850, training_loss: 7.14058e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 02:09:56.812020 22485033404224 run_lib.py:146] step: 21900, training_loss: 5.20451e-04
I0512 02:09:56.973838 22485033404224 run_lib.py:167] step: 21900, eval_loss: 5.39304e-04
I0512 02:10:20.573031 22485033404224 run_lib.py:146] step: 21950, training_loss: 5.94882e-04
I0512 02:10:44.506084 22485033404224 run_lib.py:146] step: 22000, training_loss: 8.83549e-04
I0512 02:10:44.668076 22485033404224 run_lib.py:167] step: 22000, eval_loss: 6.77803e-04
I0512 02:11:08.600377 22485033404224 run_lib.py:146] step: 22050, training_loss: 6.37794e-04
I0512 02:11:32.168349 22485033404224 run_lib.py:146] step: 22100, training_loss: 6.96162e-04
I0512 02:11:32.329052 22485033404224 run_lib.py:167] step: 22100, eval_loss: 7.56674e-04
I0512 02:11:56.229208 22485033404224 run_lib.py:146] step: 22150, training_loss: 6.31845e-04
I0512 02:12:20.103742 22485033404224 run_lib.py:146] step: 22200, training_loss: 5.59408e-04
I0512 02:12:20.264331 22485033404224 run_lib.py:167] step: 22200, eval_loss: 6.19282e-04
I0512 02:12:43.843530 22485033404224 run_lib.py:146] step: 22250, training_loss: 6.23148e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 02:13:07.797566 22485033404224 run_lib.py:146] step: 22300, training_loss: 5.62930e-04
I0512 02:13:07.960413 22485033404224 run_lib.py:167] step: 22300, eval_loss: 5.12338e-04
I0512 02:13:31.543492 22485033404224 run_lib.py:146] step: 22350, training_loss: 5.98704e-04
I0512 02:13:55.515999 22485033404224 run_lib.py:146] step: 22400, training_loss: 6.75248e-04
I0512 02:13:55.677229 22485033404224 run_lib.py:167] step: 22400, eval_loss: 6.75917e-04
I0512 02:14:19.598500 22485033404224 run_lib.py:146] step: 22450, training_loss: 7.32639e-04
I0512 02:14:43.218305 22485033404224 run_lib.py:146] step: 22500, training_loss: 7.15324e-04
I0512 02:14:43.378312 22485033404224 run_lib.py:167] step: 22500, eval_loss: 6.49161e-04
I0512 02:15:07.266017 22485033404224 run_lib.py:146] step: 22550, training_loss: 6.32091e-04
I0512 02:15:31.180015 22485033404224 run_lib.py:146] step: 22600, training_loss: 6.16163e-04
I0512 02:15:31.340843 22485033404224 run_lib.py:167] step: 22600, eval_loss: 7.16335e-04
I0512 02:15:54.965650 22485033404224 run_lib.py:146] step: 22650, training_loss: 7.32185e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 02:16:18.968775 22485033404224 run_lib.py:146] step: 22700, training_loss: 5.79641e-04
I0512 02:16:19.131195 22485033404224 run_lib.py:167] step: 22700, eval_loss: 6.02463e-04
I0512 02:16:43.082387 22485033404224 run_lib.py:146] step: 22750, training_loss: 8.79649e-04
I0512 02:17:06.666244 22485033404224 run_lib.py:146] step: 22800, training_loss: 6.30435e-04
I0512 02:17:06.825533 22485033404224 run_lib.py:167] step: 22800, eval_loss: 5.59593e-04
I0512 02:17:30.682975 22485033404224 run_lib.py:146] step: 22850, training_loss: 7.19900e-04
I0512 02:17:54.248016 22485033404224 run_lib.py:146] step: 22900, training_loss: 6.46693e-04
I0512 02:17:54.407030 22485033404224 run_lib.py:167] step: 22900, eval_loss: 7.66860e-04
I0512 02:18:18.244610 22485033404224 run_lib.py:146] step: 22950, training_loss: 6.49555e-04
I0512 02:18:42.090008 22485033404224 run_lib.py:146] step: 23000, training_loss: 4.56392e-04
I0512 02:18:42.250984 22485033404224 run_lib.py:167] step: 23000, eval_loss: 6.53729e-04
I0512 02:19:05.773005 22485033404224 run_lib.py:146] step: 23050, training_loss: 6.20865e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 02:19:29.668738 22485033404224 run_lib.py:146] step: 23100, training_loss: 5.59814e-04
I0512 02:19:29.829697 22485033404224 run_lib.py:167] step: 23100, eval_loss: 5.13265e-04
I0512 02:19:53.383304 22485033404224 run_lib.py:146] step: 23150, training_loss: 7.31192e-04
I0512 02:20:17.266140 22485033404224 run_lib.py:146] step: 23200, training_loss: 5.51425e-04
I0512 02:20:17.425195 22485033404224 run_lib.py:167] step: 23200, eval_loss: 7.16025e-04
I0512 02:20:41.288047 22485033404224 run_lib.py:146] step: 23250, training_loss: 6.66925e-04
I0512 02:21:04.834771 22485033404224 run_lib.py:146] step: 23300, training_loss: 5.49341e-04
I0512 02:21:04.995450 22485033404224 run_lib.py:167] step: 23300, eval_loss: 6.54632e-04
I0512 02:21:28.806000 22485033404224 run_lib.py:146] step: 23350, training_loss: 4.32384e-04
I0512 02:21:52.634980 22485033404224 run_lib.py:146] step: 23400, training_loss: 6.23328e-04
I0512 02:21:52.796197 22485033404224 run_lib.py:167] step: 23400, eval_loss: 7.52292e-04
I0512 02:22:16.309983 22485033404224 run_lib.py:146] step: 23450, training_loss: 4.87942e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 02:22:40.239823 22485033404224 run_lib.py:146] step: 23500, training_loss: 5.81664e-04
I0512 02:22:40.398576 22485033404224 run_lib.py:167] step: 23500, eval_loss: 6.40387e-04
I0512 02:23:04.274035 22485033404224 run_lib.py:146] step: 23550, training_loss: 8.05130e-04
I0512 02:23:27.822557 22485033404224 run_lib.py:146] step: 23600, training_loss: 6.39453e-04
I0512 02:23:27.909579 22485033404224 run_lib.py:167] step: 23600, eval_loss: 1.46095e-03
I0512 02:23:51.759556 22485033404224 run_lib.py:146] step: 23650, training_loss: 6.85482e-04
I0512 02:24:15.583486 22485033404224 run_lib.py:146] step: 23700, training_loss: 7.21396e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 02:24:15.932915 22485033404224 run_lib.py:167] step: 23700, eval_loss: 7.08756e-04
I0512 02:24:39.488746 22485033404224 run_lib.py:146] step: 23750, training_loss: 5.82131e-04
I0512 02:25:03.376507 22485033404224 run_lib.py:146] step: 23800, training_loss: 7.74869e-04
I0512 02:25:03.536731 22485033404224 run_lib.py:167] step: 23800, eval_loss: 7.02300e-04
I0512 02:25:26.930958 22485033404224 run_lib.py:146] step: 23850, training_loss: 4.63779e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 02:25:50.987715 22485033404224 run_lib.py:146] step: 23900, training_loss: 5.55478e-04
I0512 02:25:51.149470 22485033404224 run_lib.py:167] step: 23900, eval_loss: 5.56758e-04
I0512 02:26:15.015751 22485033404224 run_lib.py:146] step: 23950, training_loss: 6.02388e-04
I0512 02:26:38.574307 22485033404224 run_lib.py:146] step: 24000, training_loss: 5.45253e-04
I0512 02:26:38.734094 22485033404224 run_lib.py:167] step: 24000, eval_loss: 6.22012e-04
I0512 02:27:02.552998 22485033404224 run_lib.py:146] step: 24050, training_loss: 5.52304e-04
I0512 02:27:26.138017 22485033404224 run_lib.py:146] step: 24100, training_loss: 6.76291e-04
I0512 02:27:26.298479 22485033404224 run_lib.py:167] step: 24100, eval_loss: 5.87828e-04
I0512 02:27:50.215400 22485033404224 run_lib.py:146] step: 24150, training_loss: 6.63036e-04
I0512 02:28:14.121989 22485033404224 run_lib.py:146] step: 24200, training_loss: 5.75010e-04
I0512 02:28:14.282577 22485033404224 run_lib.py:167] step: 24200, eval_loss: 6.35902e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 02:28:37.940336 22485033404224 run_lib.py:146] step: 24250, training_loss: 5.12440e-04
I0512 02:29:01.899137 22485033404224 run_lib.py:146] step: 24300, training_loss: 6.36013e-04
I0512 02:29:02.061931 22485033404224 run_lib.py:167] step: 24300, eval_loss: 7.61698e-04
I0512 02:29:26.034724 22485033404224 run_lib.py:146] step: 24350, training_loss: 6.99231e-04
I0512 02:29:49.617501 22485033404224 run_lib.py:146] step: 24400, training_loss: 7.03740e-04
I0512 02:29:49.778020 22485033404224 run_lib.py:167] step: 24400, eval_loss: 5.86931e-04
I0512 02:30:13.667198 22485033404224 run_lib.py:146] step: 24450, training_loss: 6.56159e-04
I0512 02:30:37.566901 22485033404224 run_lib.py:146] step: 24500, training_loss: 6.27504e-04
I0512 02:30:37.727473 22485033404224 run_lib.py:167] step: 24500, eval_loss: 8.60413e-04
I0512 02:31:01.308681 22485033404224 run_lib.py:146] step: 24550, training_loss: 6.77741e-04
I0512 02:31:25.228111 22485033404224 run_lib.py:146] step: 24600, training_loss: 9.99667e-04
I0512 02:31:25.389669 22485033404224 run_lib.py:167] step: 24600, eval_loss: 5.77485e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 02:31:49.045677 22485033404224 run_lib.py:146] step: 24650, training_loss: 6.32708e-04
I0512 02:32:12.943205 22485033404224 run_lib.py:146] step: 24700, training_loss: 5.58516e-04
I0512 02:32:13.104798 22485033404224 run_lib.py:167] step: 24700, eval_loss: 7.04957e-04
I0512 02:32:37.087914 22485033404224 run_lib.py:146] step: 24750, training_loss: 7.66040e-04
I0512 02:33:00.713594 22485033404224 run_lib.py:146] step: 24800, training_loss: 8.38317e-04
I0512 02:33:00.873323 22485033404224 run_lib.py:167] step: 24800, eval_loss: 5.72860e-04
I0512 02:33:24.750445 22485033404224 run_lib.py:146] step: 24850, training_loss: 7.81033e-04
I0512 02:33:48.304493 22485033404224 run_lib.py:146] step: 24900, training_loss: 9.04115e-04
I0512 02:33:48.464266 22485033404224 run_lib.py:167] step: 24900, eval_loss: 5.07590e-04
I0512 02:34:12.367530 22485033404224 run_lib.py:146] step: 24950, training_loss: 5.67640e-04
I0512 02:34:36.303383 22485033404224 run_lib.py:146] step: 25000, training_loss: 4.97415e-04
I0512 02:34:36.462889 22485033404224 run_lib.py:167] step: 25000, eval_loss: 5.37502e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 02:35:00.114867 22485033404224 run_lib.py:146] step: 25050, training_loss: 8.12330e-04
I0512 02:35:24.042633 22485033404224 run_lib.py:146] step: 25100, training_loss: 6.07268e-04
I0512 02:35:24.204359 22485033404224 run_lib.py:167] step: 25100, eval_loss: 6.91674e-04
I0512 02:35:48.053864 22485033404224 run_lib.py:146] step: 25150, training_loss: 4.96570e-04
I0512 02:36:11.582559 22485033404224 run_lib.py:146] step: 25200, training_loss: 7.36698e-04
I0512 02:36:11.742644 22485033404224 run_lib.py:167] step: 25200, eval_loss: 6.47872e-04
I0512 02:36:35.580980 22485033404224 run_lib.py:146] step: 25250, training_loss: 5.95091e-04
I0512 02:36:59.398324 22485033404224 run_lib.py:146] step: 25300, training_loss: 6.01203e-04
I0512 02:36:59.558212 22485033404224 run_lib.py:167] step: 25300, eval_loss: 3.96720e-04
I0512 02:37:23.082122 22485033404224 run_lib.py:146] step: 25350, training_loss: 6.02946e-04
I0512 02:37:46.919258 22485033404224 run_lib.py:146] step: 25400, training_loss: 6.62108e-04
I0512 02:37:47.078694 22485033404224 run_lib.py:167] step: 25400, eval_loss: 6.35779e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 02:38:11.033353 22485033404224 run_lib.py:146] step: 25450, training_loss: 7.76221e-04
I0512 02:38:34.572225 22485033404224 run_lib.py:146] step: 25500, training_loss: 6.33931e-04
I0512 02:38:34.733105 22485033404224 run_lib.py:167] step: 25500, eval_loss: 4.57819e-04
I0512 02:38:58.598448 22485033404224 run_lib.py:146] step: 25550, training_loss: 5.38180e-04
I0512 02:39:22.163091 22485033404224 run_lib.py:146] step: 25600, training_loss: 5.81540e-04
I0512 02:39:22.321091 22485033404224 run_lib.py:167] step: 25600, eval_loss: 5.17390e-04
I0512 02:39:46.142047 22485033404224 run_lib.py:146] step: 25650, training_loss: 4.86156e-04
I0512 02:40:09.996146 22485033404224 run_lib.py:146] step: 25700, training_loss: 4.86666e-04
I0512 02:40:10.155458 22485033404224 run_lib.py:167] step: 25700, eval_loss: 4.89839e-04
I0512 02:40:33.656824 22485033404224 run_lib.py:146] step: 25750, training_loss: 6.23549e-04
I0512 02:40:57.488799 22485033404224 run_lib.py:146] step: 25800, training_loss: 5.97515e-04
I0512 02:40:57.647328 22485033404224 run_lib.py:167] step: 25800, eval_loss: 4.58758e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 02:41:21.226610 22485033404224 run_lib.py:146] step: 25850, training_loss: 6.66344e-04
I0512 02:41:45.079643 22485033404224 run_lib.py:146] step: 25900, training_loss: 6.84639e-04
I0512 02:41:45.241707 22485033404224 run_lib.py:167] step: 25900, eval_loss: 6.15134e-04
I0512 02:42:09.139151 22485033404224 run_lib.py:146] step: 25950, training_loss: 6.24629e-04
I0512 02:42:32.698056 22485033404224 run_lib.py:146] step: 26000, training_loss: 5.66233e-04
I0512 02:42:32.857595 22485033404224 run_lib.py:167] step: 26000, eval_loss: 6.01350e-04
I0512 02:42:56.664814 22485033404224 run_lib.py:146] step: 26050, training_loss: 5.79866e-04
I0512 02:43:20.516484 22485033404224 run_lib.py:146] step: 26100, training_loss: 6.25099e-04
I0512 02:43:20.675021 22485033404224 run_lib.py:167] step: 26100, eval_loss: 5.71570e-04
I0512 02:43:44.210874 22485033404224 run_lib.py:146] step: 26150, training_loss: 6.85304e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 02:44:08.096163 22485033404224 run_lib.py:146] step: 26200, training_loss: 4.74896e-04
I0512 02:44:08.256895 22485033404224 run_lib.py:167] step: 26200, eval_loss: 4.44878e-04
I0512 02:44:32.151501 22485033404224 run_lib.py:146] step: 26250, training_loss: 6.33868e-04
I0512 02:44:55.677211 22485033404224 run_lib.py:146] step: 26300, training_loss: 6.85970e-04
I0512 02:44:55.836377 22485033404224 run_lib.py:167] step: 26300, eval_loss: 6.27725e-04
I0512 02:45:19.746783 22485033404224 run_lib.py:146] step: 26350, training_loss: 6.13734e-04
I0512 02:45:43.360562 22485033404224 run_lib.py:146] step: 26400, training_loss: 7.85428e-04
I0512 02:45:43.520864 22485033404224 run_lib.py:167] step: 26400, eval_loss: 6.31988e-04
I0512 02:46:07.423258 22485033404224 run_lib.py:146] step: 26450, training_loss: 5.19035e-04
I0512 02:46:31.318928 22485033404224 run_lib.py:146] step: 26500, training_loss: 5.91581e-04
I0512 02:46:31.480539 22485033404224 run_lib.py:167] step: 26500, eval_loss: 6.22663e-04
I0512 02:46:55.092332 22485033404224 run_lib.py:146] step: 26550, training_loss: 7.70475e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 02:47:19.081301 22485033404224 run_lib.py:146] step: 26600, training_loss: 8.31516e-04
I0512 02:47:19.243995 22485033404224 run_lib.py:167] step: 26600, eval_loss: 4.67166e-04
I0512 02:47:43.305668 22485033404224 run_lib.py:146] step: 26650, training_loss: 7.27443e-04
I0512 02:48:06.888249 22485033404224 run_lib.py:146] step: 26700, training_loss: 6.51980e-04
I0512 02:48:07.048686 22485033404224 run_lib.py:167] step: 26700, eval_loss: 7.13614e-04
I0512 02:48:31.043277 22485033404224 run_lib.py:146] step: 26750, training_loss: 5.84632e-04
I0512 02:48:54.629290 22485033404224 run_lib.py:146] step: 26800, training_loss: 5.30404e-04
I0512 02:48:54.789856 22485033404224 run_lib.py:167] step: 26800, eval_loss: 6.98332e-04
I0512 02:49:18.781610 22485033404224 run_lib.py:146] step: 26850, training_loss: 5.72016e-04
I0512 02:49:42.794174 22485033404224 run_lib.py:146] step: 26900, training_loss: 7.50027e-04
I0512 02:49:42.956146 22485033404224 run_lib.py:167] step: 26900, eval_loss: 5.68610e-04
I0512 02:50:06.506912 22485033404224 run_lib.py:146] step: 26950, training_loss: 6.21194e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 02:50:30.580850 22485033404224 run_lib.py:146] step: 27000, training_loss: 5.90655e-04
I0512 02:50:30.744153 22485033404224 run_lib.py:167] step: 27000, eval_loss: 6.62949e-04
I0512 02:50:54.681153 22485033404224 run_lib.py:146] step: 27050, training_loss: 6.10580e-04
I0512 02:51:18.253503 22485033404224 run_lib.py:146] step: 27100, training_loss: 6.30075e-04
I0512 02:51:18.413354 22485033404224 run_lib.py:167] step: 27100, eval_loss: 6.42353e-04
I0512 02:51:42.453463 22485033404224 run_lib.py:146] step: 27150, training_loss: 7.97358e-04
I0512 02:52:06.350581 22485033404224 run_lib.py:146] step: 27200, training_loss: 6.07989e-04
I0512 02:52:06.510890 22485033404224 run_lib.py:167] step: 27200, eval_loss: 7.81386e-04
I0512 02:52:30.116562 22485033404224 run_lib.py:146] step: 27250, training_loss: 7.69100e-04
I0512 02:52:54.070324 22485033404224 run_lib.py:146] step: 27300, training_loss: 7.93033e-04
I0512 02:52:54.230406 22485033404224 run_lib.py:167] step: 27300, eval_loss: 5.71707e-04
I0512 02:53:17.792993 22485033404224 run_lib.py:146] step: 27350, training_loss: 6.98430e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 02:53:41.691040 22485033404224 run_lib.py:146] step: 27400, training_loss: 5.59992e-04
I0512 02:53:41.853089 22485033404224 run_lib.py:167] step: 27400, eval_loss: 5.21228e-04
I0512 02:54:05.724110 22485033404224 run_lib.py:146] step: 27450, training_loss: 6.87473e-04
I0512 02:54:29.263709 22485033404224 run_lib.py:146] step: 27500, training_loss: 5.63035e-04
I0512 02:54:29.423711 22485033404224 run_lib.py:167] step: 27500, eval_loss: 6.60760e-04
I0512 02:54:53.302180 22485033404224 run_lib.py:146] step: 27550, training_loss: 5.49390e-04
I0512 02:55:16.857783 22485033404224 run_lib.py:146] step: 27600, training_loss: 7.74356e-04
I0512 02:55:17.017436 22485033404224 run_lib.py:167] step: 27600, eval_loss: 6.51958e-04
I0512 02:55:40.836743 22485033404224 run_lib.py:146] step: 27650, training_loss: 5.54723e-04
I0512 02:56:04.657079 22485033404224 run_lib.py:146] step: 27700, training_loss: 6.63738e-04
I0512 02:56:04.816760 22485033404224 run_lib.py:167] step: 27700, eval_loss: 5.63373e-04
I0512 02:56:28.328938 22485033404224 run_lib.py:146] step: 27750, training_loss: 6.67133e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 02:56:52.271133 22485033404224 run_lib.py:146] step: 27800, training_loss: 6.99231e-04
I0512 02:56:52.432399 22485033404224 run_lib.py:167] step: 27800, eval_loss: 5.26794e-04
I0512 02:57:16.303488 22485033404224 run_lib.py:146] step: 27850, training_loss: 6.44312e-04
I0512 02:57:39.802238 22485033404224 run_lib.py:146] step: 27900, training_loss: 7.28617e-04
I0512 02:57:39.962086 22485033404224 run_lib.py:167] step: 27900, eval_loss: 5.48508e-04
I0512 02:58:03.782176 22485033404224 run_lib.py:146] step: 27950, training_loss: 7.00392e-04
I0512 02:58:27.616315 22485033404224 run_lib.py:146] step: 28000, training_loss: 7.59439e-04
I0512 02:58:27.775584 22485033404224 run_lib.py:167] step: 28000, eval_loss: 4.53055e-04
I0512 02:58:51.308914 22485033404224 run_lib.py:146] step: 28050, training_loss: 7.77957e-04
I0512 02:59:15.130637 22485033404224 run_lib.py:146] step: 28100, training_loss: 7.66418e-04
I0512 02:59:15.289526 22485033404224 run_lib.py:167] step: 28100, eval_loss: 7.15596e-04
I0512 02:59:39.090995 22485033404224 run_lib.py:146] step: 28150, training_loss: 9.43916e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 03:00:02.683761 22485033404224 run_lib.py:146] step: 28200, training_loss: 6.00199e-04
I0512 03:00:02.844258 22485033404224 run_lib.py:167] step: 28200, eval_loss: 6.92059e-04
I0512 03:00:26.732193 22485033404224 run_lib.py:146] step: 28250, training_loss: 4.80914e-04
I0512 03:00:50.292273 22485033404224 run_lib.py:146] step: 28300, training_loss: 6.43155e-04
I0512 03:00:50.452766 22485033404224 run_lib.py:167] step: 28300, eval_loss: 5.53330e-04
I0512 03:01:14.311253 22485033404224 run_lib.py:146] step: 28350, training_loss: 6.02062e-04
I0512 03:01:37.866465 22485033404224 run_lib.py:146] step: 28400, training_loss: 7.24270e-04
I0512 03:01:38.026115 22485033404224 run_lib.py:167] step: 28400, eval_loss: 7.26684e-04
I0512 03:02:01.890060 22485033404224 run_lib.py:146] step: 28450, training_loss: 7.04242e-04
I0512 03:02:25.711488 22485033404224 run_lib.py:146] step: 28500, training_loss: 7.41994e-04
I0512 03:02:25.870872 22485033404224 run_lib.py:167] step: 28500, eval_loss: 4.99834e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 03:02:49.477332 22485033404224 run_lib.py:146] step: 28550, training_loss: 5.47980e-04
I0512 03:03:13.363945 22485033404224 run_lib.py:146] step: 28600, training_loss: 6.86250e-04
I0512 03:03:13.525700 22485033404224 run_lib.py:167] step: 28600, eval_loss: 7.35497e-04
I0512 03:03:37.470385 22485033404224 run_lib.py:146] step: 28650, training_loss: 7.85051e-04
I0512 03:04:01.091143 22485033404224 run_lib.py:146] step: 28700, training_loss: 6.71769e-04
I0512 03:04:01.252088 22485033404224 run_lib.py:167] step: 28700, eval_loss: 5.16930e-04
I0512 03:04:25.157323 22485033404224 run_lib.py:146] step: 28750, training_loss: 7.90540e-04
I0512 03:04:49.051582 22485033404224 run_lib.py:146] step: 28800, training_loss: 6.97387e-04
I0512 03:04:49.212023 22485033404224 run_lib.py:167] step: 28800, eval_loss: 7.03396e-04
I0512 03:05:12.796145 22485033404224 run_lib.py:146] step: 28850, training_loss: 4.94220e-04
I0512 03:05:36.724831 22485033404224 run_lib.py:146] step: 28900, training_loss: 5.55265e-04
I0512 03:05:36.884532 22485033404224 run_lib.py:167] step: 28900, eval_loss: 6.79597e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 03:06:01.093513 22485033404224 run_lib.py:146] step: 28950, training_loss: 7.30245e-04
I0512 03:06:24.813952 22485033404224 run_lib.py:146] step: 29000, training_loss: 7.56373e-04
I0512 03:06:24.978475 22485033404224 run_lib.py:167] step: 29000, eval_loss: 7.15151e-04
I0512 03:06:49.185946 22485033404224 run_lib.py:146] step: 29050, training_loss: 7.57155e-04
I0512 03:07:12.881837 22485033404224 run_lib.py:146] step: 29100, training_loss: 5.44732e-04
I0512 03:07:13.043289 22485033404224 run_lib.py:167] step: 29100, eval_loss: 5.41892e-04
I0512 03:07:37.143689 22485033404224 run_lib.py:146] step: 29150, training_loss: 5.90316e-04
I0512 03:08:00.781396 22485033404224 run_lib.py:146] step: 29200, training_loss: 6.15208e-04
I0512 03:08:00.943532 22485033404224 run_lib.py:167] step: 29200, eval_loss: 7.34790e-04
I0512 03:08:24.932401 22485033404224 run_lib.py:146] step: 29250, training_loss: 7.57791e-04
I0512 03:08:48.920860 22485033404224 run_lib.py:146] step: 29300, training_loss: 5.88698e-04
I0512 03:08:49.080839 22485033404224 run_lib.py:167] step: 29300, eval_loss: 5.30387e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 03:09:12.787785 22485033404224 run_lib.py:146] step: 29350, training_loss: 6.23409e-04
I0512 03:09:36.770462 22485033404224 run_lib.py:146] step: 29400, training_loss: 6.18510e-04
I0512 03:09:36.931831 22485033404224 run_lib.py:167] step: 29400, eval_loss: 6.34978e-04
I0512 03:10:00.973173 22485033404224 run_lib.py:146] step: 29450, training_loss: 7.14540e-04
I0512 03:10:24.606882 22485033404224 run_lib.py:146] step: 29500, training_loss: 4.57542e-04
I0512 03:10:24.767673 22485033404224 run_lib.py:167] step: 29500, eval_loss: 5.86206e-04
I0512 03:10:48.654355 22485033404224 run_lib.py:146] step: 29550, training_loss: 6.43496e-04
I0512 03:11:12.572345 22485033404224 run_lib.py:146] step: 29600, training_loss: 7.34197e-04
I0512 03:11:12.732560 22485033404224 run_lib.py:167] step: 29600, eval_loss: 5.99809e-04
I0512 03:11:36.269428 22485033404224 run_lib.py:146] step: 29650, training_loss: 7.18595e-04
I0512 03:12:00.096753 22485033404224 run_lib.py:146] step: 29700, training_loss: 7.46418e-04
I0512 03:12:00.255345 22485033404224 run_lib.py:167] step: 29700, eval_loss: 7.66817e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 03:12:24.207309 22485033404224 run_lib.py:146] step: 29750, training_loss: 5.33756e-04
I0512 03:12:47.730100 22485033404224 run_lib.py:146] step: 29800, training_loss: 5.23762e-04
I0512 03:12:47.892006 22485033404224 run_lib.py:167] step: 29800, eval_loss: 5.88880e-04
I0512 03:13:11.753887 22485033404224 run_lib.py:146] step: 29850, training_loss: 6.54970e-04
I0512 03:13:35.605714 22485033404224 run_lib.py:146] step: 29900, training_loss: 6.65005e-04
I0512 03:13:35.764584 22485033404224 run_lib.py:167] step: 29900, eval_loss: 5.35037e-04
I0512 03:13:59.286699 22485033404224 run_lib.py:146] step: 29950, training_loss: 4.79757e-04
I0512 03:14:23.108823 22485033404224 run_lib.py:146] step: 30000, training_loss: 4.57728e-04
I0512 03:14:25.257464 22485033404224 run_lib.py:167] step: 30000, eval_loss: 6.63279e-04
I0512 03:14:50.559397 22485033404224 run_lib.py:146] step: 30050, training_loss: 8.75663e-04
I0512 03:15:14.412964 22485033404224 run_lib.py:146] step: 30100, training_loss: 6.16768e-04
I0512 03:15:14.571383 22485033404224 run_lib.py:167] step: 30100, eval_loss: 6.58581e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 03:15:38.470821 22485033404224 run_lib.py:146] step: 30150, training_loss: 5.13587e-04
I0512 03:16:02.012372 22485033404224 run_lib.py:146] step: 30200, training_loss: 7.22163e-04
I0512 03:16:02.174620 22485033404224 run_lib.py:167] step: 30200, eval_loss: 5.81363e-04
I0512 03:16:26.039965 22485033404224 run_lib.py:146] step: 30250, training_loss: 7.28471e-04
I0512 03:16:49.915354 22485033404224 run_lib.py:146] step: 30300, training_loss: 6.73185e-04
I0512 03:16:50.074710 22485033404224 run_lib.py:167] step: 30300, eval_loss: 7.44483e-04
I0512 03:17:13.621344 22485033404224 run_lib.py:146] step: 30350, training_loss: 7.22729e-04
I0512 03:17:37.487596 22485033404224 run_lib.py:146] step: 30400, training_loss: 6.32180e-04
I0512 03:17:37.646441 22485033404224 run_lib.py:167] step: 30400, eval_loss: 5.79807e-04
I0512 03:18:01.495858 22485033404224 run_lib.py:146] step: 30450, training_loss: 6.11061e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 03:18:25.121510 22485033404224 run_lib.py:146] step: 30500, training_loss: 6.78081e-04
I0512 03:18:25.284193 22485033404224 run_lib.py:167] step: 30500, eval_loss: 4.91238e-04
I0512 03:18:49.169188 22485033404224 run_lib.py:146] step: 30550, training_loss: 7.62524e-04
I0512 03:19:13.040602 22485033404224 run_lib.py:146] step: 30600, training_loss: 6.96956e-04
I0512 03:19:13.200433 22485033404224 run_lib.py:167] step: 30600, eval_loss: 6.55026e-04
I0512 03:19:36.699791 22485033404224 run_lib.py:146] step: 30650, training_loss: 7.13468e-04
I0512 03:20:00.538111 22485033404224 run_lib.py:146] step: 30700, training_loss: 7.36616e-04
I0512 03:20:00.696983 22485033404224 run_lib.py:167] step: 30700, eval_loss: 5.51336e-04
I0512 03:20:24.541156 22485033404224 run_lib.py:146] step: 30750, training_loss: 5.50446e-04
I0512 03:20:48.079673 22485033404224 run_lib.py:146] step: 30800, training_loss: 6.27251e-04
I0512 03:20:48.239022 22485033404224 run_lib.py:167] step: 30800, eval_loss: 5.31702e-04
I0512 03:21:12.039947 22485033404224 run_lib.py:146] step: 30850, training_loss: 7.02270e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 03:21:35.671001 22485033404224 run_lib.py:146] step: 30900, training_loss: 5.33447e-04
I0512 03:21:35.834234 22485033404224 run_lib.py:167] step: 30900, eval_loss: 5.73998e-04
I0512 03:21:59.800879 22485033404224 run_lib.py:146] step: 30950, training_loss: 4.92713e-04
I0512 03:22:23.429100 22485033404224 run_lib.py:146] step: 31000, training_loss: 5.40394e-04
I0512 03:22:23.590106 22485033404224 run_lib.py:167] step: 31000, eval_loss: 6.42579e-04
I0512 03:22:47.510726 22485033404224 run_lib.py:146] step: 31050, training_loss: 6.67217e-04
I0512 03:23:11.441220 22485033404224 run_lib.py:146] step: 31100, training_loss: 6.17647e-04
I0512 03:23:11.601215 22485033404224 run_lib.py:167] step: 31100, eval_loss: 5.67065e-04
I0512 03:23:35.188360 22485033404224 run_lib.py:146] step: 31150, training_loss: 6.16545e-04
I0512 03:23:59.065032 22485033404224 run_lib.py:146] step: 31200, training_loss: 6.07087e-04
I0512 03:23:59.225431 22485033404224 run_lib.py:167] step: 31200, eval_loss: 6.42800e-04
I0512 03:24:23.101096 22485033404224 run_lib.py:146] step: 31250, training_loss: 6.01096e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 03:24:46.769059 22485033404224 run_lib.py:146] step: 31300, training_loss: 8.08469e-04
I0512 03:24:46.931962 22485033404224 run_lib.py:167] step: 31300, eval_loss: 6.85935e-04
I0512 03:25:10.868600 22485033404224 run_lib.py:146] step: 31350, training_loss: 7.34091e-04
I0512 03:25:34.792991 22485033404224 run_lib.py:146] step: 31400, training_loss: 7.15891e-04
I0512 03:25:34.952824 22485033404224 run_lib.py:167] step: 31400, eval_loss: 3.98135e-04
I0512 03:25:58.528148 22485033404224 run_lib.py:146] step: 31450, training_loss: 8.11456e-04
I0512 03:26:22.414005 22485033404224 run_lib.py:146] step: 31500, training_loss: 6.08055e-04
I0512 03:26:22.500793 22485033404224 run_lib.py:167] step: 31500, eval_loss: 5.66099e-04
I0512 03:26:46.397345 22485033404224 run_lib.py:146] step: 31550, training_loss: 5.67531e-04
I0512 03:27:10.020796 22485033404224 run_lib.py:146] step: 31600, training_loss: 7.02479e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 03:27:10.372382 22485033404224 run_lib.py:167] step: 31600, eval_loss: 8.05838e-04
I0512 03:27:34.407972 22485033404224 run_lib.py:146] step: 31650, training_loss: 7.44467e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 03:27:58.115037 22485033404224 run_lib.py:146] step: 31700, training_loss: 7.03613e-04
I0512 03:27:58.277441 22485033404224 run_lib.py:167] step: 31700, eval_loss: 5.08820e-04
I0512 03:28:22.220453 22485033404224 run_lib.py:146] step: 31750, training_loss: 6.38236e-04
I0512 03:28:45.780547 22485033404224 run_lib.py:146] step: 31800, training_loss: 5.10208e-04
I0512 03:28:45.940399 22485033404224 run_lib.py:167] step: 31800, eval_loss: 6.70002e-04
I0512 03:29:09.789875 22485033404224 run_lib.py:146] step: 31850, training_loss: 6.88069e-04
I0512 03:29:33.613153 22485033404224 run_lib.py:146] step: 31900, training_loss: 6.95257e-04
I0512 03:29:33.774003 22485033404224 run_lib.py:167] step: 31900, eval_loss: 6.65500e-04
I0512 03:29:57.299885 22485033404224 run_lib.py:146] step: 31950, training_loss: 9.31298e-04
I0512 03:30:21.124347 22485033404224 run_lib.py:146] step: 32000, training_loss: 6.54925e-04
I0512 03:30:21.283615 22485033404224 run_lib.py:167] step: 32000, eval_loss: 6.07764e-04
I0512 03:30:45.120896 22485033404224 run_lib.py:146] step: 32050, training_loss: 4.66736e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 03:31:08.736913 22485033404224 run_lib.py:146] step: 32100, training_loss: 5.94890e-04
I0512 03:31:08.899085 22485033404224 run_lib.py:167] step: 32100, eval_loss: 5.15839e-04
I0512 03:31:32.783372 22485033404224 run_lib.py:146] step: 32150, training_loss: 7.20654e-04
I0512 03:31:56.670394 22485033404224 run_lib.py:146] step: 32200, training_loss: 4.58148e-04
I0512 03:31:56.830570 22485033404224 run_lib.py:167] step: 32200, eval_loss: 5.66691e-04
I0512 03:32:20.305404 22485033404224 run_lib.py:146] step: 32250, training_loss: 6.91725e-04
I0512 03:32:44.108866 22485033404224 run_lib.py:146] step: 32300, training_loss: 5.46227e-04
I0512 03:32:44.267494 22485033404224 run_lib.py:167] step: 32300, eval_loss: 5.70639e-04
I0512 03:33:08.104347 22485033404224 run_lib.py:146] step: 32350, training_loss: 5.38651e-04
I0512 03:33:31.627104 22485033404224 run_lib.py:146] step: 32400, training_loss: 5.39756e-04
I0512 03:33:31.786586 22485033404224 run_lib.py:167] step: 32400, eval_loss: 5.38925e-04
I0512 03:33:55.604182 22485033404224 run_lib.py:146] step: 32450, training_loss: 7.33409e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 03:34:19.227713 22485033404224 run_lib.py:146] step: 32500, training_loss: 7.54019e-04
I0512 03:34:19.389497 22485033404224 run_lib.py:167] step: 32500, eval_loss: 5.73494e-04
I0512 03:34:43.179850 22485033404224 run_lib.py:146] step: 32550, training_loss: 6.20388e-04
I0512 03:35:06.686961 22485033404224 run_lib.py:146] step: 32600, training_loss: 5.82918e-04
I0512 03:35:06.846672 22485033404224 run_lib.py:167] step: 32600, eval_loss: 5.83934e-04
I0512 03:35:30.706649 22485033404224 run_lib.py:146] step: 32650, training_loss: 7.42642e-04
I0512 03:35:54.565132 22485033404224 run_lib.py:146] step: 32700, training_loss: 5.83729e-04
I0512 03:35:54.724576 22485033404224 run_lib.py:167] step: 32700, eval_loss: 5.48090e-04
I0512 03:36:18.257634 22485033404224 run_lib.py:146] step: 32750, training_loss: 6.00831e-04
I0512 03:36:42.062412 22485033404224 run_lib.py:146] step: 32800, training_loss: 8.71596e-04
I0512 03:36:42.221110 22485033404224 run_lib.py:167] step: 32800, eval_loss: 6.10843e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 03:37:06.121865 22485033404224 run_lib.py:146] step: 32850, training_loss: 3.85722e-04
I0512 03:37:29.683738 22485033404224 run_lib.py:146] step: 32900, training_loss: 5.95912e-04
I0512 03:37:29.846278 22485033404224 run_lib.py:167] step: 32900, eval_loss: 4.50717e-04
I0512 03:37:53.753388 22485033404224 run_lib.py:146] step: 32950, training_loss: 6.69640e-04
I0512 03:38:17.639658 22485033404224 run_lib.py:146] step: 33000, training_loss: 7.72009e-04
I0512 03:38:17.801316 22485033404224 run_lib.py:167] step: 33000, eval_loss: 6.34817e-04
I0512 03:38:41.312876 22485033404224 run_lib.py:146] step: 33050, training_loss: 6.76111e-04
I0512 03:39:05.182886 22485033404224 run_lib.py:146] step: 33100, training_loss: 5.91175e-04
I0512 03:39:05.342945 22485033404224 run_lib.py:167] step: 33100, eval_loss: 5.21068e-04
I0512 03:39:29.252920 22485033404224 run_lib.py:146] step: 33150, training_loss: 7.47990e-04
I0512 03:39:52.883951 22485033404224 run_lib.py:146] step: 33200, training_loss: 6.65029e-04
I0512 03:39:53.043939 22485033404224 run_lib.py:167] step: 33200, eval_loss: 6.14039e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 03:40:17.077564 22485033404224 run_lib.py:146] step: 33250, training_loss: 5.92711e-04
I0512 03:40:41.057743 22485033404224 run_lib.py:146] step: 33300, training_loss: 5.67321e-04
I0512 03:40:41.219500 22485033404224 run_lib.py:167] step: 33300, eval_loss: 5.28949e-04
I0512 03:41:04.789144 22485033404224 run_lib.py:146] step: 33350, training_loss: 7.37443e-04
I0512 03:41:28.351000 22485033404224 run_lib.py:146] step: 33400, training_loss: 4.13446e-04
I0512 03:41:28.510437 22485033404224 run_lib.py:167] step: 33400, eval_loss: 7.26743e-04
I0512 03:41:52.417590 22485033404224 run_lib.py:146] step: 33450, training_loss: 6.79873e-04
I0512 03:42:16.269737 22485033404224 run_lib.py:146] step: 33500, training_loss: 5.78106e-04
I0512 03:42:16.429182 22485033404224 run_lib.py:167] step: 33500, eval_loss: 7.87839e-04
I0512 03:42:39.989010 22485033404224 run_lib.py:146] step: 33550, training_loss: 5.54773e-04
I0512 03:43:03.898024 22485033404224 run_lib.py:146] step: 33600, training_loss: 6.58481e-04
I0512 03:43:04.058332 22485033404224 run_lib.py:167] step: 33600, eval_loss: 5.33595e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 03:43:28.019554 22485033404224 run_lib.py:146] step: 33650, training_loss: 7.40517e-04
I0512 03:43:51.626969 22485033404224 run_lib.py:146] step: 33700, training_loss: 6.30695e-04
I0512 03:43:51.789685 22485033404224 run_lib.py:167] step: 33700, eval_loss: 5.51629e-04
I0512 03:44:15.748088 22485033404224 run_lib.py:146] step: 33750, training_loss: 5.67731e-04
I0512 03:44:39.700579 22485033404224 run_lib.py:146] step: 33800, training_loss: 8.35118e-04
I0512 03:44:39.860412 22485033404224 run_lib.py:167] step: 33800, eval_loss: 7.59306e-04
I0512 03:45:03.454279 22485033404224 run_lib.py:146] step: 33850, training_loss: 5.53597e-04
I0512 03:45:27.361313 22485033404224 run_lib.py:146] step: 33900, training_loss: 5.28961e-04
I0512 03:45:27.520639 22485033404224 run_lib.py:167] step: 33900, eval_loss: 6.96646e-04
I0512 03:45:51.466187 22485033404224 run_lib.py:146] step: 33950, training_loss: 8.39096e-04
I0512 03:46:15.035240 22485033404224 run_lib.py:146] step: 34000, training_loss: 6.72312e-04
I0512 03:46:15.195441 22485033404224 run_lib.py:167] step: 34000, eval_loss: 7.62579e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 03:46:39.151765 22485033404224 run_lib.py:146] step: 34050, training_loss: 5.42294e-04
I0512 03:47:03.034028 22485033404224 run_lib.py:146] step: 34100, training_loss: 5.85972e-04
I0512 03:47:03.194575 22485033404224 run_lib.py:167] step: 34100, eval_loss: 5.15221e-04
I0512 03:47:26.716253 22485033404224 run_lib.py:146] step: 34150, training_loss: 6.60038e-04
I0512 03:47:50.528959 22485033404224 run_lib.py:146] step: 34200, training_loss: 9.72563e-04
I0512 03:47:50.687438 22485033404224 run_lib.py:167] step: 34200, eval_loss: 8.06421e-04
I0512 03:48:14.571524 22485033404224 run_lib.py:146] step: 34250, training_loss: 6.13932e-04
I0512 03:48:38.094196 22485033404224 run_lib.py:146] step: 34300, training_loss: 7.76648e-04
I0512 03:48:38.253299 22485033404224 run_lib.py:167] step: 34300, eval_loss: 7.88837e-04
I0512 03:49:01.794700 22485033404224 run_lib.py:146] step: 34350, training_loss: 6.59963e-04
I0512 03:49:25.638775 22485033404224 run_lib.py:146] step: 34400, training_loss: 5.03351e-04
I0512 03:49:25.799089 22485033404224 run_lib.py:167] step: 34400, eval_loss: 7.21359e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 03:49:49.672107 22485033404224 run_lib.py:146] step: 34450, training_loss: 6.33083e-04
I0512 03:50:13.217830 22485033404224 run_lib.py:146] step: 34500, training_loss: 7.49749e-04
I0512 03:50:13.378433 22485033404224 run_lib.py:167] step: 34500, eval_loss: 4.53226e-04
I0512 03:50:37.221699 22485033404224 run_lib.py:146] step: 34550, training_loss: 5.57681e-04
I0512 03:51:01.059039 22485033404224 run_lib.py:146] step: 34600, training_loss: 7.47227e-04
I0512 03:51:01.217778 22485033404224 run_lib.py:167] step: 34600, eval_loss: 5.62960e-04
I0512 03:51:24.746321 22485033404224 run_lib.py:146] step: 34650, training_loss: 6.17599e-04
I0512 03:51:48.565125 22485033404224 run_lib.py:146] step: 34700, training_loss: 5.99311e-04
I0512 03:51:48.725406 22485033404224 run_lib.py:167] step: 34700, eval_loss: 6.42520e-04
I0512 03:52:12.586101 22485033404224 run_lib.py:146] step: 34750, training_loss: 7.07756e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 03:52:36.219529 22485033404224 run_lib.py:146] step: 34800, training_loss: 5.16562e-04
I0512 03:52:36.381060 22485033404224 run_lib.py:167] step: 34800, eval_loss: 5.47343e-04
I0512 03:53:00.244147 22485033404224 run_lib.py:146] step: 34850, training_loss: 6.05331e-04
I0512 03:53:24.128828 22485033404224 run_lib.py:146] step: 34900, training_loss: 5.67168e-04
I0512 03:53:24.288435 22485033404224 run_lib.py:167] step: 34900, eval_loss: 7.04819e-04
I0512 03:53:47.848340 22485033404224 run_lib.py:146] step: 34950, training_loss: 9.20779e-04
I0512 03:54:11.718665 22485033404224 run_lib.py:146] step: 35000, training_loss: 5.01439e-04
I0512 03:54:11.879393 22485033404224 run_lib.py:167] step: 35000, eval_loss: 4.70464e-04
I0512 03:54:35.721209 22485033404224 run_lib.py:146] step: 35050, training_loss: 6.71101e-04
I0512 03:54:59.269025 22485033404224 run_lib.py:146] step: 35100, training_loss: 7.10917e-04
I0512 03:54:59.429859 22485033404224 run_lib.py:167] step: 35100, eval_loss: 6.70157e-04
I0512 03:55:22.981333 22485033404224 run_lib.py:146] step: 35150, training_loss: 6.38443e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 03:55:46.896412 22485033404224 run_lib.py:146] step: 35200, training_loss: 5.36532e-04
I0512 03:55:47.058482 22485033404224 run_lib.py:167] step: 35200, eval_loss: 4.42327e-04
I0512 03:56:10.950424 22485033404224 run_lib.py:146] step: 35250, training_loss: 7.67060e-04
I0512 03:56:34.485155 22485033404224 run_lib.py:146] step: 35300, training_loss: 5.41227e-04
I0512 03:56:34.645996 22485033404224 run_lib.py:167] step: 35300, eval_loss: 7.44628e-04
I0512 03:56:58.620697 22485033404224 run_lib.py:146] step: 35350, training_loss: 7.65541e-04
I0512 03:57:22.570284 22485033404224 run_lib.py:146] step: 35400, training_loss: 5.34055e-04
I0512 03:57:22.731027 22485033404224 run_lib.py:167] step: 35400, eval_loss: 5.47038e-04
I0512 03:57:46.363873 22485033404224 run_lib.py:146] step: 35450, training_loss: 6.31049e-04
I0512 03:58:10.291806 22485033404224 run_lib.py:146] step: 35500, training_loss: 6.55488e-04
I0512 03:58:10.452357 22485033404224 run_lib.py:167] step: 35500, eval_loss: 6.21442e-04
I0512 03:58:34.354086 22485033404224 run_lib.py:146] step: 35550, training_loss: 6.40438e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 03:58:58.003252 22485033404224 run_lib.py:146] step: 35600, training_loss: 5.86490e-04
I0512 03:58:58.165380 22485033404224 run_lib.py:167] step: 35600, eval_loss: 4.78579e-04
I0512 03:59:22.222678 22485033404224 run_lib.py:146] step: 35650, training_loss: 6.12277e-04
I0512 03:59:46.300950 22485033404224 run_lib.py:146] step: 35700, training_loss: 5.89777e-04
I0512 03:59:46.461729 22485033404224 run_lib.py:167] step: 35700, eval_loss: 5.75841e-04
I0512 04:00:10.020096 22485033404224 run_lib.py:146] step: 35750, training_loss: 7.40719e-04
I0512 04:00:34.041993 22485033404224 run_lib.py:146] step: 35800, training_loss: 5.36660e-04
I0512 04:00:34.203107 22485033404224 run_lib.py:167] step: 35800, eval_loss: 5.91634e-04
I0512 04:00:58.224754 22485033404224 run_lib.py:146] step: 35850, training_loss: 6.68229e-04
I0512 04:01:21.862530 22485033404224 run_lib.py:146] step: 35900, training_loss: 5.56656e-04
I0512 04:01:22.023057 22485033404224 run_lib.py:167] step: 35900, eval_loss: 6.18567e-04
I0512 04:01:45.950730 22485033404224 run_lib.py:146] step: 35950, training_loss: 6.86315e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 04:02:09.658689 22485033404224 run_lib.py:146] step: 36000, training_loss: 5.95543e-04
I0512 04:02:09.821268 22485033404224 run_lib.py:167] step: 36000, eval_loss: 6.12117e-04
I0512 04:02:33.743319 22485033404224 run_lib.py:146] step: 36050, training_loss: 5.32924e-04
I0512 04:02:57.350973 22485033404224 run_lib.py:146] step: 36100, training_loss: 6.58753e-04
I0512 04:02:57.512751 22485033404224 run_lib.py:167] step: 36100, eval_loss: 8.18736e-04
I0512 04:03:21.468694 22485033404224 run_lib.py:146] step: 36150, training_loss: 8.20661e-04
I0512 04:03:45.341804 22485033404224 run_lib.py:146] step: 36200, training_loss: 5.83086e-04
I0512 04:03:45.500687 22485033404224 run_lib.py:167] step: 36200, eval_loss: 6.79358e-04
I0512 04:04:09.047086 22485033404224 run_lib.py:146] step: 36250, training_loss: 4.91583e-04
I0512 04:04:32.864545 22485033404224 run_lib.py:146] step: 36300, training_loss: 6.68207e-04
I0512 04:04:33.023687 22485033404224 run_lib.py:167] step: 36300, eval_loss: 7.17205e-04
I0512 04:04:56.845108 22485033404224 run_lib.py:146] step: 36350, training_loss: 6.63222e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 04:05:20.478521 22485033404224 run_lib.py:146] step: 36400, training_loss: 5.47841e-04
I0512 04:05:20.639120 22485033404224 run_lib.py:167] step: 36400, eval_loss: 5.28580e-04
I0512 04:05:44.507566 22485033404224 run_lib.py:146] step: 36450, training_loss: 6.36125e-04
I0512 04:06:08.386419 22485033404224 run_lib.py:146] step: 36500, training_loss: 4.65799e-04
I0512 04:06:08.545913 22485033404224 run_lib.py:167] step: 36500, eval_loss: 7.81791e-04
I0512 04:06:32.072550 22485033404224 run_lib.py:146] step: 36550, training_loss: 6.59121e-04
I0512 04:06:55.913846 22485033404224 run_lib.py:146] step: 36600, training_loss: 4.02870e-04
I0512 04:06:56.073239 22485033404224 run_lib.py:167] step: 36600, eval_loss: 5.74101e-04
I0512 04:07:19.879221 22485033404224 run_lib.py:146] step: 36650, training_loss: 6.38693e-04
I0512 04:07:43.402887 22485033404224 run_lib.py:146] step: 36700, training_loss: 5.25548e-04
I0512 04:07:43.562324 22485033404224 run_lib.py:167] step: 36700, eval_loss: 7.66055e-04
I0512 04:08:07.396266 22485033404224 run_lib.py:146] step: 36750, training_loss: 5.56919e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 04:08:30.951887 22485033404224 run_lib.py:146] step: 36800, training_loss: 5.68457e-04
I0512 04:08:31.112504 22485033404224 run_lib.py:167] step: 36800, eval_loss: 4.68657e-04
I0512 04:08:54.964265 22485033404224 run_lib.py:146] step: 36850, training_loss: 6.02717e-04
I0512 04:09:18.491766 22485033404224 run_lib.py:146] step: 36900, training_loss: 6.17351e-04
I0512 04:09:18.650532 22485033404224 run_lib.py:167] step: 36900, eval_loss: 5.30704e-04
I0512 04:09:42.484279 22485033404224 run_lib.py:146] step: 36950, training_loss: 6.38798e-04
I0512 04:10:06.306320 22485033404224 run_lib.py:146] step: 37000, training_loss: 7.36052e-04
I0512 04:10:06.465406 22485033404224 run_lib.py:167] step: 37000, eval_loss: 6.14400e-04
I0512 04:10:29.995193 22485033404224 run_lib.py:146] step: 37050, training_loss: 5.64779e-04
I0512 04:10:53.808111 22485033404224 run_lib.py:146] step: 37100, training_loss: 6.00613e-04
I0512 04:10:53.967597 22485033404224 run_lib.py:167] step: 37100, eval_loss: 6.89094e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 04:11:17.866290 22485033404224 run_lib.py:146] step: 37150, training_loss: 5.81751e-04
I0512 04:11:41.375928 22485033404224 run_lib.py:146] step: 37200, training_loss: 5.44341e-04
I0512 04:11:41.537145 22485033404224 run_lib.py:167] step: 37200, eval_loss: 6.34842e-04
I0512 04:12:05.408896 22485033404224 run_lib.py:146] step: 37250, training_loss: 7.22854e-04
I0512 04:12:29.280497 22485033404224 run_lib.py:146] step: 37300, training_loss: 5.20103e-04
I0512 04:12:29.441100 22485033404224 run_lib.py:167] step: 37300, eval_loss: 5.89979e-04
I0512 04:12:53.014448 22485033404224 run_lib.py:146] step: 37350, training_loss: 5.32763e-04
I0512 04:13:16.865335 22485033404224 run_lib.py:146] step: 37400, training_loss: 6.06001e-04
I0512 04:13:17.025807 22485033404224 run_lib.py:167] step: 37400, eval_loss: 8.94391e-04
I0512 04:13:40.845637 22485033404224 run_lib.py:146] step: 37450, training_loss: 7.33146e-04
I0512 04:14:04.393932 22485033404224 run_lib.py:146] step: 37500, training_loss: 5.93842e-04
I0512 04:14:04.554125 22485033404224 run_lib.py:167] step: 37500, eval_loss: 5.61008e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 04:14:28.544325 22485033404224 run_lib.py:146] step: 37550, training_loss: 8.47011e-04
I0512 04:14:52.523205 22485033404224 run_lib.py:146] step: 37600, training_loss: 4.57944e-04
I0512 04:14:52.684692 22485033404224 run_lib.py:167] step: 37600, eval_loss: 6.16465e-04
I0512 04:15:16.306616 22485033404224 run_lib.py:146] step: 37650, training_loss: 6.16413e-04
I0512 04:15:40.247716 22485033404224 run_lib.py:146] step: 37700, training_loss: 5.19419e-04
I0512 04:15:40.409086 22485033404224 run_lib.py:167] step: 37700, eval_loss: 6.88516e-04
I0512 04:16:04.003852 22485033404224 run_lib.py:146] step: 37750, training_loss: 7.07636e-04
I0512 04:16:27.918108 22485033404224 run_lib.py:146] step: 37800, training_loss: 6.73012e-04
I0512 04:16:28.078034 22485033404224 run_lib.py:167] step: 37800, eval_loss: 5.93736e-04
I0512 04:16:51.662310 22485033404224 run_lib.py:146] step: 37850, training_loss: 5.88965e-04
I0512 04:17:15.543374 22485033404224 run_lib.py:146] step: 37900, training_loss: 5.73181e-04
I0512 04:17:15.704248 22485033404224 run_lib.py:167] step: 37900, eval_loss: 8.12071e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 04:17:39.627303 22485033404224 run_lib.py:146] step: 37950, training_loss: 6.86534e-04
I0512 04:18:03.265531 22485033404224 run_lib.py:146] step: 38000, training_loss: 6.22525e-04
I0512 04:18:03.428272 22485033404224 run_lib.py:167] step: 38000, eval_loss: 6.08387e-04
I0512 04:18:27.415904 22485033404224 run_lib.py:146] step: 38050, training_loss: 9.41192e-04
I0512 04:18:51.347600 22485033404224 run_lib.py:146] step: 38100, training_loss: 7.22002e-04
I0512 04:18:51.507818 22485033404224 run_lib.py:167] step: 38100, eval_loss: 6.85061e-04
I0512 04:19:15.107580 22485033404224 run_lib.py:146] step: 38150, training_loss: 6.92618e-04
I0512 04:19:39.057703 22485033404224 run_lib.py:146] step: 38200, training_loss: 6.76686e-04
I0512 04:19:39.217843 22485033404224 run_lib.py:167] step: 38200, eval_loss: 7.13419e-04
I0512 04:20:03.138662 22485033404224 run_lib.py:146] step: 38250, training_loss: 6.33399e-04
I0512 04:20:26.764620 22485033404224 run_lib.py:146] step: 38300, training_loss: 8.03881e-04
I0512 04:20:26.925356 22485033404224 run_lib.py:167] step: 38300, eval_loss: 7.11475e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 04:20:50.953745 22485033404224 run_lib.py:146] step: 38350, training_loss: 6.65536e-04
I0512 04:21:14.928821 22485033404224 run_lib.py:146] step: 38400, training_loss: 5.59345e-04
I0512 04:21:15.091868 22485033404224 run_lib.py:167] step: 38400, eval_loss: 7.14067e-04
I0512 04:21:38.718521 22485033404224 run_lib.py:146] step: 38450, training_loss: 6.98847e-04
I0512 04:22:02.611347 22485033404224 run_lib.py:146] step: 38500, training_loss: 6.26653e-04
I0512 04:22:02.770757 22485033404224 run_lib.py:167] step: 38500, eval_loss: 5.86431e-04
I0512 04:22:26.318825 22485033404224 run_lib.py:146] step: 38550, training_loss: 5.93950e-04
I0512 04:22:50.152864 22485033404224 run_lib.py:146] step: 38600, training_loss: 8.95510e-04
I0512 04:22:50.311718 22485033404224 run_lib.py:167] step: 38600, eval_loss: 5.71382e-04
I0512 04:23:13.846653 22485033404224 run_lib.py:146] step: 38650, training_loss: 5.30654e-04
I0512 04:23:37.657223 22485033404224 run_lib.py:146] step: 38700, training_loss: 6.02125e-04
I0512 04:23:37.818436 22485033404224 run_lib.py:167] step: 38700, eval_loss: 6.73801e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 04:24:01.778177 22485033404224 run_lib.py:146] step: 38750, training_loss: 6.09037e-04
I0512 04:24:25.308244 22485033404224 run_lib.py:146] step: 38800, training_loss: 7.68495e-04
I0512 04:24:25.469095 22485033404224 run_lib.py:167] step: 38800, eval_loss: 6.57625e-04
I0512 04:24:49.305030 22485033404224 run_lib.py:146] step: 38850, training_loss: 7.18253e-04
I0512 04:25:13.144164 22485033404224 run_lib.py:146] step: 38900, training_loss: 7.12352e-04
I0512 04:25:13.303554 22485033404224 run_lib.py:167] step: 38900, eval_loss: 7.20557e-04
I0512 04:25:36.862383 22485033404224 run_lib.py:146] step: 38950, training_loss: 7.18242e-04
I0512 04:26:00.748803 22485033404224 run_lib.py:146] step: 39000, training_loss: 7.97937e-04
I0512 04:26:00.908538 22485033404224 run_lib.py:167] step: 39000, eval_loss: 6.30274e-04
I0512 04:26:24.743356 22485033404224 run_lib.py:146] step: 39050, training_loss: 6.96479e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 04:26:48.333949 22485033404224 run_lib.py:146] step: 39100, training_loss: 6.76170e-04
I0512 04:26:48.496240 22485033404224 run_lib.py:167] step: 39100, eval_loss: 8.38783e-04
I0512 04:27:12.382009 22485033404224 run_lib.py:146] step: 39150, training_loss: 5.69954e-04
I0512 04:27:36.266919 22485033404224 run_lib.py:146] step: 39200, training_loss: 5.12649e-04
I0512 04:27:36.426237 22485033404224 run_lib.py:167] step: 39200, eval_loss: 5.48720e-04
I0512 04:27:59.930841 22485033404224 run_lib.py:146] step: 39250, training_loss: 7.49013e-04
I0512 04:28:23.756257 22485033404224 run_lib.py:146] step: 39300, training_loss: 6.93358e-04
I0512 04:28:23.914497 22485033404224 run_lib.py:167] step: 39300, eval_loss: 4.94320e-04
I0512 04:28:47.725798 22485033404224 run_lib.py:146] step: 39350, training_loss: 5.53146e-04
I0512 04:29:11.231306 22485033404224 run_lib.py:146] step: 39400, training_loss: 6.37686e-04
I0512 04:29:11.314202 22485033404224 run_lib.py:167] step: 39400, eval_loss: 8.35977e-04
I0512 04:29:35.158640 22485033404224 run_lib.py:146] step: 39450, training_loss: 6.22624e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 04:29:58.785189 22485033404224 run_lib.py:146] step: 39500, training_loss: 5.99414e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 04:29:59.130508 22485033404224 run_lib.py:167] step: 39500, eval_loss: 6.17240e-04
I0512 04:30:23.006584 22485033404224 run_lib.py:146] step: 39550, training_loss: 5.80764e-04
I0512 04:30:46.554366 22485033404224 run_lib.py:146] step: 39600, training_loss: 6.02536e-04
I0512 04:30:46.713381 22485033404224 run_lib.py:167] step: 39600, eval_loss: 6.18664e-04
I0512 04:31:10.580074 22485033404224 run_lib.py:146] step: 39650, training_loss: 7.34094e-04
I0512 04:31:34.434796 22485033404224 run_lib.py:146] step: 39700, training_loss: 6.53758e-04
I0512 04:31:34.594733 22485033404224 run_lib.py:167] step: 39700, eval_loss: 6.88733e-04
I0512 04:31:58.118077 22485033404224 run_lib.py:146] step: 39750, training_loss: 5.54500e-04
I0512 04:32:21.962986 22485033404224 run_lib.py:146] step: 39800, training_loss: 6.29902e-04
I0512 04:32:22.123267 22485033404224 run_lib.py:167] step: 39800, eval_loss: 5.58269e-04
I0512 04:32:46.056815 22485033404224 run_lib.py:146] step: 39850, training_loss: 5.62914e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 04:33:09.735904 22485033404224 run_lib.py:146] step: 39900, training_loss: 6.50370e-04
I0512 04:33:09.897856 22485033404224 run_lib.py:167] step: 39900, eval_loss: 5.41895e-04
I0512 04:33:33.870217 22485033404224 run_lib.py:146] step: 39950, training_loss: 7.21299e-04
I0512 04:33:57.866559 22485033404224 run_lib.py:146] step: 40000, training_loss: 6.22337e-04
I0512 04:33:59.701823 22485033404224 run_lib.py:167] step: 40000, eval_loss: 6.34442e-04
I0512 04:34:24.825947 22485033404224 run_lib.py:146] step: 40050, training_loss: 6.27641e-04
I0512 04:34:48.730189 22485033404224 run_lib.py:146] step: 40100, training_loss: 5.55023e-04
I0512 04:34:48.890420 22485033404224 run_lib.py:167] step: 40100, eval_loss: 7.84176e-04
I0512 04:35:12.776754 22485033404224 run_lib.py:146] step: 40150, training_loss: 6.76318e-04
I0512 04:35:36.340512 22485033404224 run_lib.py:146] step: 40200, training_loss: 7.66011e-04
I0512 04:35:36.499830 22485033404224 run_lib.py:167] step: 40200, eval_loss: 4.58951e-04
I0512 04:36:00.404999 22485033404224 run_lib.py:146] step: 40250, training_loss: 7.51579e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 04:36:24.361240 22485033404224 run_lib.py:146] step: 40300, training_loss: 6.56850e-04
I0512 04:36:24.523289 22485033404224 run_lib.py:167] step: 40300, eval_loss: 6.75251e-04
I0512 04:36:48.176122 22485033404224 run_lib.py:146] step: 40350, training_loss: 7.15094e-04
I0512 04:37:11.814805 22485033404224 run_lib.py:146] step: 40400, training_loss: 6.35538e-04
I0512 04:37:11.974865 22485033404224 run_lib.py:167] step: 40400, eval_loss: 3.51139e-04
I0512 04:37:36.226292 22485033404224 run_lib.py:146] step: 40450, training_loss: 4.77119e-04
I0512 04:37:59.841840 22485033404224 run_lib.py:146] step: 40500, training_loss: 6.72112e-04
I0512 04:38:00.001649 22485033404224 run_lib.py:167] step: 40500, eval_loss: 7.76135e-04
I0512 04:38:23.577311 22485033404224 run_lib.py:146] step: 40550, training_loss: 7.34797e-04
I0512 04:38:47.798078 22485033404224 run_lib.py:146] step: 40600, training_loss: 6.85660e-04
I0512 04:38:47.958333 22485033404224 run_lib.py:167] step: 40600, eval_loss: 6.17861e-04
I0512 04:39:11.595923 22485033404224 run_lib.py:146] step: 40650, training_loss: 5.80190e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 04:39:35.242530 22485033404224 run_lib.py:146] step: 40700, training_loss: 6.73295e-04
I0512 04:39:35.403017 22485033404224 run_lib.py:167] step: 40700, eval_loss: 7.49882e-04
I0512 04:39:59.601181 22485033404224 run_lib.py:146] step: 40750, training_loss: 5.69218e-04
I0512 04:40:23.162826 22485033404224 run_lib.py:146] step: 40800, training_loss: 8.03671e-04
I0512 04:40:23.322870 22485033404224 run_lib.py:167] step: 40800, eval_loss: 7.22711e-04
I0512 04:40:46.849155 22485033404224 run_lib.py:146] step: 40850, training_loss: 7.96807e-04
I0512 04:41:10.956097 22485033404224 run_lib.py:146] step: 40900, training_loss: 7.99746e-04
I0512 04:41:11.114969 22485033404224 run_lib.py:167] step: 40900, eval_loss: 4.72193e-04
I0512 04:41:34.674057 22485033404224 run_lib.py:146] step: 40950, training_loss: 7.03435e-04
I0512 04:41:58.228539 22485033404224 run_lib.py:146] step: 41000, training_loss: 6.96381e-04
I0512 04:41:58.388860 22485033404224 run_lib.py:167] step: 41000, eval_loss: 7.00944e-04
I0512 04:42:22.218369 22485033404224 run_lib.py:146] step: 41050, training_loss: 7.99460e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 04:42:46.176861 22485033404224 run_lib.py:146] step: 41100, training_loss: 6.71617e-04
I0512 04:42:46.336791 22485033404224 run_lib.py:167] step: 41100, eval_loss: 4.58897e-04
I0512 04:43:09.881386 22485033404224 run_lib.py:146] step: 41150, training_loss: 6.77037e-04
I0512 04:43:33.750545 22485033404224 run_lib.py:146] step: 41200, training_loss: 4.58999e-04
I0512 04:43:33.910840 22485033404224 run_lib.py:167] step: 41200, eval_loss: 6.49307e-04
I0512 04:43:57.726542 22485033404224 run_lib.py:146] step: 41250, training_loss: 6.47047e-04
I0512 04:44:21.267307 22485033404224 run_lib.py:146] step: 41300, training_loss: 6.73704e-04
I0512 04:44:21.426608 22485033404224 run_lib.py:167] step: 41300, eval_loss: 6.67199e-04
I0512 04:44:44.957366 22485033404224 run_lib.py:146] step: 41350, training_loss: 6.97246e-04
I0512 04:45:09.080808 22485033404224 run_lib.py:146] step: 41400, training_loss: 6.89310e-04
I0512 04:45:09.241846 22485033404224 run_lib.py:167] step: 41400, eval_loss: 8.63342e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 04:45:32.857219 22485033404224 run_lib.py:146] step: 41450, training_loss: 5.15135e-04
I0512 04:45:56.369291 22485033404224 run_lib.py:146] step: 41500, training_loss: 5.97113e-04
I0512 04:45:56.530908 22485033404224 run_lib.py:167] step: 41500, eval_loss: 5.60153e-04
I0512 04:46:20.709740 22485033404224 run_lib.py:146] step: 41550, training_loss: 6.84521e-04
I0512 04:46:44.237407 22485033404224 run_lib.py:146] step: 41600, training_loss: 7.02186e-04
I0512 04:46:44.395830 22485033404224 run_lib.py:167] step: 41600, eval_loss: 5.74816e-04
I0512 04:47:07.927250 22485033404224 run_lib.py:146] step: 41650, training_loss: 7.41666e-04
I0512 04:47:32.073086 22485033404224 run_lib.py:146] step: 41700, training_loss: 5.47079e-04
I0512 04:47:32.232383 22485033404224 run_lib.py:167] step: 41700, eval_loss: 5.90466e-04
I0512 04:47:55.773520 22485033404224 run_lib.py:146] step: 41750, training_loss: 5.19710e-04
I0512 04:48:19.318396 22485033404224 run_lib.py:146] step: 41800, training_loss: 7.95676e-04
I0512 04:48:19.480580 22485033404224 run_lib.py:167] step: 41800, eval_loss: 6.04969e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 04:48:43.408014 22485033404224 run_lib.py:146] step: 41850, training_loss: 8.11224e-04
I0512 04:49:07.317746 22485033404224 run_lib.py:146] step: 41900, training_loss: 6.61720e-04
I0512 04:49:07.479073 22485033404224 run_lib.py:167] step: 41900, eval_loss: 6.75353e-04
I0512 04:49:31.022069 22485033404224 run_lib.py:146] step: 41950, training_loss: 7.40092e-04
I0512 04:49:54.904683 22485033404224 run_lib.py:146] step: 42000, training_loss: 6.61946e-04
I0512 04:49:55.066279 22485033404224 run_lib.py:167] step: 42000, eval_loss: 5.17176e-04
I0512 04:50:18.965277 22485033404224 run_lib.py:146] step: 42050, training_loss: 6.35873e-04
I0512 04:50:42.573570 22485033404224 run_lib.py:146] step: 42100, training_loss: 5.31317e-04
I0512 04:50:42.733941 22485033404224 run_lib.py:167] step: 42100, eval_loss: 7.42642e-04
I0512 04:51:06.633697 22485033404224 run_lib.py:146] step: 42150, training_loss: 6.81097e-04
I0512 04:51:30.534188 22485033404224 run_lib.py:146] step: 42200, training_loss: 7.18191e-04
I0512 04:51:30.695441 22485033404224 run_lib.py:167] step: 42200, eval_loss: 6.13400e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 04:51:54.351383 22485033404224 run_lib.py:146] step: 42250, training_loss: 6.73237e-04
I0512 04:52:17.926944 22485033404224 run_lib.py:146] step: 42300, training_loss: 5.32475e-04
I0512 04:52:18.089777 22485033404224 run_lib.py:167] step: 42300, eval_loss: 7.50291e-04
I0512 04:52:42.483541 22485033404224 run_lib.py:146] step: 42350, training_loss: 7.05999e-04
I0512 04:53:06.067930 22485033404224 run_lib.py:146] step: 42400, training_loss: 5.09162e-04
I0512 04:53:06.228046 22485033404224 run_lib.py:167] step: 42400, eval_loss: 5.19686e-04
I0512 04:53:29.821809 22485033404224 run_lib.py:146] step: 42450, training_loss: 7.21410e-04
I0512 04:53:54.131158 22485033404224 run_lib.py:146] step: 42500, training_loss: 5.93664e-04
I0512 04:53:54.292071 22485033404224 run_lib.py:167] step: 42500, eval_loss: 8.53925e-04
I0512 04:54:17.927498 22485033404224 run_lib.py:146] step: 42550, training_loss: 7.25361e-04
I0512 04:54:41.517874 22485033404224 run_lib.py:146] step: 42600, training_loss: 4.94042e-04
I0512 04:54:41.677969 22485033404224 run_lib.py:167] step: 42600, eval_loss: 4.72298e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 04:55:06.196271 22485033404224 run_lib.py:146] step: 42650, training_loss: 6.61939e-04
I0512 04:55:29.828697 22485033404224 run_lib.py:146] step: 42700, training_loss: 7.04931e-04
I0512 04:55:29.990334 22485033404224 run_lib.py:167] step: 42700, eval_loss: 5.60547e-04
I0512 04:55:53.587882 22485033404224 run_lib.py:146] step: 42750, training_loss: 8.27798e-04
I0512 04:56:17.540948 22485033404224 run_lib.py:146] step: 42800, training_loss: 6.30768e-04
I0512 04:56:17.701161 22485033404224 run_lib.py:167] step: 42800, eval_loss: 5.88557e-04
I0512 04:56:41.624548 22485033404224 run_lib.py:146] step: 42850, training_loss: 7.90642e-04
I0512 04:57:05.188900 22485033404224 run_lib.py:146] step: 42900, training_loss: 6.38396e-04
I0512 04:57:05.348371 22485033404224 run_lib.py:167] step: 42900, eval_loss: 7.21224e-04
I0512 04:57:29.189305 22485033404224 run_lib.py:146] step: 42950, training_loss: 6.62172e-04
I0512 04:57:53.026938 22485033404224 run_lib.py:146] step: 43000, training_loss: 6.64021e-04
I0512 04:57:53.185379 22485033404224 run_lib.py:167] step: 43000, eval_loss: 4.21823e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 04:58:16.829702 22485033404224 run_lib.py:146] step: 43050, training_loss: 6.79040e-04
I0512 04:58:40.378528 22485033404224 run_lib.py:146] step: 43100, training_loss: 5.81819e-04
I0512 04:58:40.539468 22485033404224 run_lib.py:167] step: 43100, eval_loss: 6.31108e-04
I0512 04:59:04.754668 22485033404224 run_lib.py:146] step: 43150, training_loss: 7.24399e-04
I0512 04:59:28.288801 22485033404224 run_lib.py:146] step: 43200, training_loss: 7.91306e-04
I0512 04:59:28.449182 22485033404224 run_lib.py:167] step: 43200, eval_loss: 5.37851e-04
I0512 04:59:52.010272 22485033404224 run_lib.py:146] step: 43250, training_loss: 7.00271e-04
I0512 05:00:16.120667 22485033404224 run_lib.py:146] step: 43300, training_loss: 6.62210e-04
I0512 05:00:16.281711 22485033404224 run_lib.py:167] step: 43300, eval_loss: 7.81180e-04
I0512 05:00:39.796575 22485033404224 run_lib.py:146] step: 43350, training_loss: 7.31821e-04
I0512 05:01:03.185557 22485033404224 run_lib.py:146] step: 43400, training_loss: 6.87739e-04
I0512 05:01:03.344766 22485033404224 run_lib.py:167] step: 43400, eval_loss: 5.10610e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 05:01:27.722396 22485033404224 run_lib.py:146] step: 43450, training_loss: 6.62724e-04
I0512 05:01:51.248449 22485033404224 run_lib.py:146] step: 43500, training_loss: 6.82579e-04
I0512 05:01:51.407347 22485033404224 run_lib.py:167] step: 43500, eval_loss: 6.15359e-04
I0512 05:02:14.928565 22485033404224 run_lib.py:146] step: 43550, training_loss: 7.42867e-04
I0512 05:02:38.752864 22485033404224 run_lib.py:146] step: 43600, training_loss: 5.50911e-04
I0512 05:02:38.912362 22485033404224 run_lib.py:167] step: 43600, eval_loss: 4.54230e-04
I0512 05:03:02.724149 22485033404224 run_lib.py:146] step: 43650, training_loss: 5.20209e-04
I0512 05:03:26.255525 22485033404224 run_lib.py:146] step: 43700, training_loss: 7.65987e-04
I0512 05:03:26.414815 22485033404224 run_lib.py:167] step: 43700, eval_loss: 6.46898e-04
I0512 05:03:50.252532 22485033404224 run_lib.py:146] step: 43750, training_loss: 5.99680e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 05:04:14.158248 22485033404224 run_lib.py:146] step: 43800, training_loss: 4.65414e-04
I0512 05:04:14.318593 22485033404224 run_lib.py:167] step: 43800, eval_loss: 4.63890e-04
I0512 05:04:37.845133 22485033404224 run_lib.py:146] step: 43850, training_loss: 6.90591e-04
I0512 05:05:01.367331 22485033404224 run_lib.py:146] step: 43900, training_loss: 8.64830e-04
I0512 05:05:01.527210 22485033404224 run_lib.py:167] step: 43900, eval_loss: 6.65314e-04
I0512 05:05:25.745390 22485033404224 run_lib.py:146] step: 43950, training_loss: 8.52617e-04
I0512 05:05:49.247482 22485033404224 run_lib.py:146] step: 44000, training_loss: 7.24353e-04
I0512 05:05:49.406489 22485033404224 run_lib.py:167] step: 44000, eval_loss: 7.31483e-04
I0512 05:06:12.936825 22485033404224 run_lib.py:146] step: 44050, training_loss: 5.47911e-04
I0512 05:06:37.077570 22485033404224 run_lib.py:146] step: 44100, training_loss: 6.77313e-04
I0512 05:06:37.236685 22485033404224 run_lib.py:167] step: 44100, eval_loss: 7.03046e-04
I0512 05:07:00.764531 22485033404224 run_lib.py:146] step: 44150, training_loss: 5.91502e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 05:07:24.370414 22485033404224 run_lib.py:146] step: 44200, training_loss: 8.07079e-04
I0512 05:07:24.532383 22485033404224 run_lib.py:167] step: 44200, eval_loss: 5.32957e-04
I0512 05:07:48.844307 22485033404224 run_lib.py:146] step: 44250, training_loss: 7.46699e-04
I0512 05:08:12.449956 22485033404224 run_lib.py:146] step: 44300, training_loss: 6.40385e-04
I0512 05:08:12.610583 22485033404224 run_lib.py:167] step: 44300, eval_loss: 6.12222e-04
I0512 05:08:36.225976 22485033404224 run_lib.py:146] step: 44350, training_loss: 7.72540e-04
I0512 05:09:00.475116 22485033404224 run_lib.py:146] step: 44400, training_loss: 7.87376e-04
I0512 05:09:00.635072 22485033404224 run_lib.py:167] step: 44400, eval_loss: 4.05038e-04
I0512 05:09:24.225265 22485033404224 run_lib.py:146] step: 44450, training_loss: 9.00580e-04
I0512 05:09:47.842025 22485033404224 run_lib.py:146] step: 44500, training_loss: 5.83980e-04
I0512 05:09:48.002251 22485033404224 run_lib.py:167] step: 44500, eval_loss: 5.45884e-04
I0512 05:10:11.882923 22485033404224 run_lib.py:146] step: 44550, training_loss: 7.02914e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 05:10:35.889806 22485033404224 run_lib.py:146] step: 44600, training_loss: 7.50162e-04
I0512 05:10:36.052385 22485033404224 run_lib.py:167] step: 44600, eval_loss: 3.73039e-04
I0512 05:10:59.706691 22485033404224 run_lib.py:146] step: 44650, training_loss: 5.88997e-04
I0512 05:11:23.720361 22485033404224 run_lib.py:146] step: 44700, training_loss: 5.96627e-04
I0512 05:11:23.882112 22485033404224 run_lib.py:167] step: 44700, eval_loss: 5.96580e-04
I0512 05:11:47.900520 22485033404224 run_lib.py:146] step: 44750, training_loss: 6.76449e-04
I0512 05:12:11.532949 22485033404224 run_lib.py:146] step: 44800, training_loss: 6.37486e-04
I0512 05:12:11.693995 22485033404224 run_lib.py:167] step: 44800, eval_loss: 6.35715e-04
I0512 05:12:35.303673 22485033404224 run_lib.py:146] step: 44850, training_loss: 7.90638e-04
I0512 05:12:59.554789 22485033404224 run_lib.py:146] step: 44900, training_loss: 7.04427e-04
I0512 05:12:59.714777 22485033404224 run_lib.py:167] step: 44900, eval_loss: 4.83363e-04
I0512 05:13:23.348848 22485033404224 run_lib.py:146] step: 44950, training_loss: 6.62333e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 05:13:47.013073 22485033404224 run_lib.py:146] step: 45000, training_loss: 7.15492e-04
I0512 05:13:47.174866 22485033404224 run_lib.py:167] step: 45000, eval_loss: 7.46270e-04
I0512 05:14:11.490906 22485033404224 run_lib.py:146] step: 45050, training_loss: 7.96140e-04
I0512 05:14:35.065861 22485033404224 run_lib.py:146] step: 45100, training_loss: 4.54061e-04
I0512 05:14:35.226035 22485033404224 run_lib.py:167] step: 45100, eval_loss: 5.34937e-04
I0512 05:14:58.731894 22485033404224 run_lib.py:146] step: 45150, training_loss: 5.53621e-04
I0512 05:15:22.902728 22485033404224 run_lib.py:146] step: 45200, training_loss: 7.49125e-04
I0512 05:15:23.064077 22485033404224 run_lib.py:167] step: 45200, eval_loss: 5.75738e-04
I0512 05:15:46.626552 22485033404224 run_lib.py:146] step: 45250, training_loss: 5.83301e-04
I0512 05:16:10.139119 22485033404224 run_lib.py:146] step: 45300, training_loss: 5.53647e-04
I0512 05:16:10.298566 22485033404224 run_lib.py:167] step: 45300, eval_loss: 6.97082e-04
I0512 05:16:34.439615 22485033404224 run_lib.py:146] step: 45350, training_loss: 5.29921e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 05:16:58.037771 22485033404224 run_lib.py:146] step: 45400, training_loss: 5.96222e-04
I0512 05:16:58.199426 22485033404224 run_lib.py:167] step: 45400, eval_loss: 5.53720e-04
I0512 05:17:21.757789 22485033404224 run_lib.py:146] step: 45450, training_loss: 6.79700e-04
I0512 05:17:45.662077 22485033404224 run_lib.py:146] step: 45500, training_loss: 5.63618e-04
I0512 05:17:45.823246 22485033404224 run_lib.py:167] step: 45500, eval_loss: 8.27105e-04
I0512 05:18:09.717704 22485033404224 run_lib.py:146] step: 45550, training_loss: 6.98568e-04
I0512 05:18:33.277687 22485033404224 run_lib.py:146] step: 45600, training_loss: 5.82270e-04
I0512 05:18:33.437229 22485033404224 run_lib.py:167] step: 45600, eval_loss: 6.01187e-04
I0512 05:18:56.946683 22485033404224 run_lib.py:146] step: 45650, training_loss: 6.26769e-04
I0512 05:19:21.101014 22485033404224 run_lib.py:146] step: 45700, training_loss: 6.50360e-04
I0512 05:19:21.260687 22485033404224 run_lib.py:167] step: 45700, eval_loss: 5.85384e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 05:19:44.885969 22485033404224 run_lib.py:146] step: 45750, training_loss: 7.15646e-04
I0512 05:20:08.425745 22485033404224 run_lib.py:146] step: 45800, training_loss: 5.12437e-04
I0512 05:20:08.586589 22485033404224 run_lib.py:167] step: 45800, eval_loss: 5.55656e-04
I0512 05:20:32.775449 22485033404224 run_lib.py:146] step: 45850, training_loss: 5.78847e-04
I0512 05:20:56.295439 22485033404224 run_lib.py:146] step: 45900, training_loss: 4.59303e-04
I0512 05:20:56.454500 22485033404224 run_lib.py:167] step: 45900, eval_loss: 5.61564e-04
I0512 05:21:19.980488 22485033404224 run_lib.py:146] step: 45950, training_loss: 5.92854e-04
I0512 05:21:44.110153 22485033404224 run_lib.py:146] step: 46000, training_loss: 5.44058e-04
I0512 05:21:44.270738 22485033404224 run_lib.py:167] step: 46000, eval_loss: 5.68460e-04
I0512 05:22:07.822650 22485033404224 run_lib.py:146] step: 46050, training_loss: 6.29695e-04
I0512 05:22:31.358486 22485033404224 run_lib.py:146] step: 46100, training_loss: 6.55871e-04
I0512 05:22:31.517855 22485033404224 run_lib.py:167] step: 46100, eval_loss: 5.88793e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 05:22:55.459549 22485033404224 run_lib.py:146] step: 46150, training_loss: 6.98458e-04
I0512 05:23:19.343132 22485033404224 run_lib.py:146] step: 46200, training_loss: 6.55113e-04
I0512 05:23:19.503629 22485033404224 run_lib.py:167] step: 46200, eval_loss: 6.40177e-04
I0512 05:23:43.028807 22485033404224 run_lib.py:146] step: 46250, training_loss: 7.62370e-04
I0512 05:24:06.890082 22485033404224 run_lib.py:146] step: 46300, training_loss: 9.30473e-04
I0512 05:24:07.049385 22485033404224 run_lib.py:167] step: 46300, eval_loss: 5.90198e-04
I0512 05:24:30.854548 22485033404224 run_lib.py:146] step: 46350, training_loss: 7.04599e-04
I0512 05:24:54.357473 22485033404224 run_lib.py:146] step: 46400, training_loss: 6.85870e-04
I0512 05:24:54.516790 22485033404224 run_lib.py:167] step: 46400, eval_loss: 4.15863e-04
I0512 05:25:18.113535 22485033404224 run_lib.py:146] step: 46450, training_loss: 5.32361e-04
I0512 05:25:42.357925 22485033404224 run_lib.py:146] step: 46500, training_loss: 6.19258e-04
I0512 05:25:42.518885 22485033404224 run_lib.py:167] step: 46500, eval_loss: 6.30282e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 05:26:06.185661 22485033404224 run_lib.py:146] step: 46550, training_loss: 6.10213e-04
I0512 05:26:29.799827 22485033404224 run_lib.py:146] step: 46600, training_loss: 6.05563e-04
I0512 05:26:29.963172 22485033404224 run_lib.py:167] step: 46600, eval_loss: 6.14830e-04
I0512 05:26:54.318324 22485033404224 run_lib.py:146] step: 46650, training_loss: 6.93961e-04
I0512 05:27:17.910999 22485033404224 run_lib.py:146] step: 46700, training_loss: 7.34323e-04
I0512 05:27:18.071598 22485033404224 run_lib.py:167] step: 46700, eval_loss: 7.08631e-04
I0512 05:27:41.634338 22485033404224 run_lib.py:146] step: 46750, training_loss: 6.78096e-04
I0512 05:28:05.806679 22485033404224 run_lib.py:146] step: 46800, training_loss: 6.95483e-04
I0512 05:28:05.967565 22485033404224 run_lib.py:167] step: 46800, eval_loss: 4.83639e-04
I0512 05:28:29.527377 22485033404224 run_lib.py:146] step: 46850, training_loss: 5.60388e-04
I0512 05:28:53.105218 22485033404224 run_lib.py:146] step: 46900, training_loss: 5.81212e-04
I0512 05:28:53.265009 22485033404224 run_lib.py:167] step: 46900, eval_loss: 5.17652e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 05:29:17.283120 22485033404224 run_lib.py:146] step: 46950, training_loss: 5.30626e-04
I0512 05:29:41.239559 22485033404224 run_lib.py:146] step: 47000, training_loss: 7.25198e-04
I0512 05:29:41.401442 22485033404224 run_lib.py:167] step: 47000, eval_loss: 6.24881e-04
I0512 05:30:05.000066 22485033404224 run_lib.py:146] step: 47050, training_loss: 7.78949e-04
I0512 05:30:28.915273 22485033404224 run_lib.py:146] step: 47100, training_loss: 6.14997e-04
I0512 05:30:29.076831 22485033404224 run_lib.py:167] step: 47100, eval_loss: 6.49526e-04
I0512 05:30:52.978386 22485033404224 run_lib.py:146] step: 47150, training_loss: 5.71477e-04
I0512 05:31:16.537816 22485033404224 run_lib.py:146] step: 47200, training_loss: 5.09191e-04
I0512 05:31:16.697096 22485033404224 run_lib.py:167] step: 47200, eval_loss: 6.09163e-04
I0512 05:31:40.287327 22485033404224 run_lib.py:146] step: 47250, training_loss: 6.61382e-04
I0512 05:32:04.487426 22485033404224 run_lib.py:146] step: 47300, training_loss: 6.19967e-04
I0512 05:32:04.570628 22485033404224 run_lib.py:167] step: 47300, eval_loss: 6.00298e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 05:32:28.169986 22485033404224 run_lib.py:146] step: 47350, training_loss: 4.66675e-04
I0512 05:32:51.720301 22485033404224 run_lib.py:146] step: 47400, training_loss: 6.45746e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 05:32:52.066647 22485033404224 run_lib.py:167] step: 47400, eval_loss: 5.31798e-04
I0512 05:33:16.254491 22485033404224 run_lib.py:146] step: 47450, training_loss: 5.99542e-04
I0512 05:33:39.809762 22485033404224 run_lib.py:146] step: 47500, training_loss: 7.36527e-04
I0512 05:33:39.968966 22485033404224 run_lib.py:167] step: 47500, eval_loss: 6.89043e-04
I0512 05:34:03.516567 22485033404224 run_lib.py:146] step: 47550, training_loss: 6.34329e-04
I0512 05:34:27.643359 22485033404224 run_lib.py:146] step: 47600, training_loss: 6.17214e-04
I0512 05:34:27.802762 22485033404224 run_lib.py:167] step: 47600, eval_loss: 6.26650e-04
I0512 05:34:51.355243 22485033404224 run_lib.py:146] step: 47650, training_loss: 7.49273e-04
I0512 05:35:14.909235 22485033404224 run_lib.py:146] step: 47700, training_loss: 7.42511e-04
I0512 05:35:15.069424 22485033404224 run_lib.py:167] step: 47700, eval_loss: 6.91765e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 05:35:39.327856 22485033404224 run_lib.py:146] step: 47750, training_loss: 6.17659e-04
I0512 05:36:02.841571 22485033404224 run_lib.py:146] step: 47800, training_loss: 6.45121e-04
I0512 05:36:03.002414 22485033404224 run_lib.py:167] step: 47800, eval_loss: 7.35154e-04
I0512 05:36:26.500565 22485033404224 run_lib.py:146] step: 47850, training_loss: 4.48675e-04
I0512 05:36:50.291351 22485033404224 run_lib.py:146] step: 47900, training_loss: 7.18576e-04
I0512 05:36:50.451273 22485033404224 run_lib.py:167] step: 47900, eval_loss: 6.07527e-04
I0512 05:37:14.232342 22485033404224 run_lib.py:146] step: 47950, training_loss: 5.48487e-04
I0512 05:37:37.725469 22485033404224 run_lib.py:146] step: 48000, training_loss: 6.88198e-04
I0512 05:37:37.884768 22485033404224 run_lib.py:167] step: 48000, eval_loss: 6.21739e-04
I0512 05:38:01.399790 22485033404224 run_lib.py:146] step: 48050, training_loss: 6.14162e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 05:38:25.567472 22485033404224 run_lib.py:146] step: 48100, training_loss: 6.16617e-04
I0512 05:38:25.729333 22485033404224 run_lib.py:167] step: 48100, eval_loss: 6.82605e-04
I0512 05:38:49.268690 22485033404224 run_lib.py:146] step: 48150, training_loss: 6.33207e-04
I0512 05:39:12.805342 22485033404224 run_lib.py:146] step: 48200, training_loss: 4.49024e-04
I0512 05:39:12.965087 22485033404224 run_lib.py:167] step: 48200, eval_loss: 7.15058e-04
I0512 05:39:37.157586 22485033404224 run_lib.py:146] step: 48250, training_loss: 6.05110e-04
I0512 05:40:00.690442 22485033404224 run_lib.py:146] step: 48300, training_loss: 9.46527e-04
I0512 05:40:00.850740 22485033404224 run_lib.py:167] step: 48300, eval_loss: 4.75670e-04
I0512 05:40:24.371412 22485033404224 run_lib.py:146] step: 48350, training_loss: 7.84881e-04
I0512 05:40:48.501229 22485033404224 run_lib.py:146] step: 48400, training_loss: 6.06153e-04
I0512 05:40:48.661068 22485033404224 run_lib.py:167] step: 48400, eval_loss: 7.79774e-04
I0512 05:41:12.183351 22485033404224 run_lib.py:146] step: 48450, training_loss: 7.62432e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 05:41:35.788064 22485033404224 run_lib.py:146] step: 48500, training_loss: 7.34044e-04
I0512 05:41:35.949376 22485033404224 run_lib.py:167] step: 48500, eval_loss: 7.37933e-04
I0512 05:42:00.150745 22485033404224 run_lib.py:146] step: 48550, training_loss: 5.64742e-04
I0512 05:42:23.684407 22485033404224 run_lib.py:146] step: 48600, training_loss: 5.68690e-04
I0512 05:42:23.845062 22485033404224 run_lib.py:167] step: 48600, eval_loss: 6.58649e-04
I0512 05:42:47.376675 22485033404224 run_lib.py:146] step: 48650, training_loss: 8.06113e-04
I0512 05:43:11.290978 22485033404224 run_lib.py:146] step: 48700, training_loss: 6.41657e-04
I0512 05:43:11.451812 22485033404224 run_lib.py:167] step: 48700, eval_loss: 6.37373e-04
I0512 05:43:35.349235 22485033404224 run_lib.py:146] step: 48750, training_loss: 5.54615e-04
I0512 05:43:58.943060 22485033404224 run_lib.py:146] step: 48800, training_loss: 6.73007e-04
I0512 05:43:59.104067 22485033404224 run_lib.py:167] step: 48800, eval_loss: 6.33484e-04
I0512 05:44:23.008907 22485033404224 run_lib.py:146] step: 48850, training_loss: 5.11912e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 05:44:46.948645 22485033404224 run_lib.py:146] step: 48900, training_loss: 6.13040e-04
I0512 05:44:47.111220 22485033404224 run_lib.py:167] step: 48900, eval_loss: 5.17371e-04
I0512 05:45:10.692458 22485033404224 run_lib.py:146] step: 48950, training_loss: 6.44181e-04
I0512 05:45:34.283195 22485033404224 run_lib.py:146] step: 49000, training_loss: 6.13196e-04
I0512 05:45:34.443496 22485033404224 run_lib.py:167] step: 49000, eval_loss: 6.10399e-04
I0512 05:45:58.901188 22485033404224 run_lib.py:146] step: 49050, training_loss: 5.66451e-04
I0512 05:46:22.465656 22485033404224 run_lib.py:146] step: 49100, training_loss: 6.44988e-04
I0512 05:46:22.626081 22485033404224 run_lib.py:167] step: 49100, eval_loss: 5.80037e-04
I0512 05:46:46.205784 22485033404224 run_lib.py:146] step: 49150, training_loss: 6.02038e-04
I0512 05:47:10.623971 22485033404224 run_lib.py:146] step: 49200, training_loss: 5.52311e-04
I0512 05:47:10.784512 22485033404224 run_lib.py:167] step: 49200, eval_loss: 6.42315e-04
I0512 05:47:34.385435 22485033404224 run_lib.py:146] step: 49250, training_loss: 5.00659e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 05:47:58.082394 22485033404224 run_lib.py:146] step: 49300, training_loss: 5.91736e-04
I0512 05:47:58.244403 22485033404224 run_lib.py:167] step: 49300, eval_loss: 6.84058e-04
I0512 05:48:22.679442 22485033404224 run_lib.py:146] step: 49350, training_loss: 6.42934e-04
I0512 05:48:46.262282 22485033404224 run_lib.py:146] step: 49400, training_loss: 6.14342e-04
I0512 05:48:46.422557 22485033404224 run_lib.py:167] step: 49400, eval_loss: 5.52003e-04
I0512 05:49:10.043123 22485033404224 run_lib.py:146] step: 49450, training_loss: 6.15517e-04
I0512 05:49:33.982007 22485033404224 run_lib.py:146] step: 49500, training_loss: 6.77916e-04
I0512 05:49:34.142037 22485033404224 run_lib.py:167] step: 49500, eval_loss: 6.13843e-04
I0512 05:49:58.079560 22485033404224 run_lib.py:146] step: 49550, training_loss: 6.31579e-04
I0512 05:50:21.633622 22485033404224 run_lib.py:146] step: 49600, training_loss: 6.72618e-04
I0512 05:50:21.792775 22485033404224 run_lib.py:167] step: 49600, eval_loss: 7.62300e-04
I0512 05:50:45.612357 22485033404224 run_lib.py:146] step: 49650, training_loss: 5.22001e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 05:51:09.577961 22485033404224 run_lib.py:146] step: 49700, training_loss: 7.34442e-04
I0512 05:51:09.739667 22485033404224 run_lib.py:167] step: 49700, eval_loss: 5.51766e-04
I0512 05:51:33.238920 22485033404224 run_lib.py:146] step: 49750, training_loss: 6.11644e-04
I0512 05:51:56.775383 22485033404224 run_lib.py:146] step: 49800, training_loss: 7.07803e-04
I0512 05:51:56.934307 22485033404224 run_lib.py:167] step: 49800, eval_loss: 5.00739e-04
I0512 05:52:21.087735 22485033404224 run_lib.py:146] step: 49850, training_loss: 6.19010e-04
I0512 05:52:44.626471 22485033404224 run_lib.py:146] step: 49900, training_loss: 5.16175e-04
I0512 05:52:44.784932 22485033404224 run_lib.py:167] step: 49900, eval_loss: 8.34256e-04
I0512 05:53:08.313311 22485033404224 run_lib.py:146] step: 49950, training_loss: 7.22894e-04
I0512 05:53:32.451948 22485033404224 run_lib.py:146] step: 50000, training_loss: 5.06395e-04
I0512 05:53:34.167683 22485033404224 run_lib.py:167] step: 50000, eval_loss: 7.01592e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 05:53:59.256974 22485033404224 run_lib.py:146] step: 50050, training_loss: 5.06445e-04
I0512 05:54:23.106226 22485033404224 run_lib.py:146] step: 50100, training_loss: 5.35721e-04
I0512 05:54:23.266002 22485033404224 run_lib.py:167] step: 50100, eval_loss: 5.42502e-04
I0512 05:54:47.129523 22485033404224 run_lib.py:146] step: 50150, training_loss: 6.55296e-04
I0512 05:55:10.658933 22485033404224 run_lib.py:146] step: 50200, training_loss: 6.31347e-04
I0512 05:55:10.817656 22485033404224 run_lib.py:167] step: 50200, eval_loss: 7.38735e-04
I0512 05:55:34.342043 22485033404224 run_lib.py:146] step: 50250, training_loss: 5.27106e-04
I0512 05:55:58.468226 22485033404224 run_lib.py:146] step: 50300, training_loss: 6.83186e-04
I0512 05:55:58.627171 22485033404224 run_lib.py:167] step: 50300, eval_loss: 4.05255e-04
I0512 05:56:22.168646 22485033404224 run_lib.py:146] step: 50350, training_loss: 6.18709e-04
I0512 05:56:45.717642 22485033404224 run_lib.py:146] step: 50400, training_loss: 7.15154e-04
I0512 05:56:45.878107 22485033404224 run_lib.py:167] step: 50400, eval_loss: 5.46961e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 05:57:10.129430 22485033404224 run_lib.py:146] step: 50450, training_loss: 7.17479e-04
I0512 05:57:33.668530 22485033404224 run_lib.py:146] step: 50500, training_loss: 5.70884e-04
I0512 05:57:33.829439 22485033404224 run_lib.py:167] step: 50500, eval_loss: 5.02220e-04
I0512 05:57:57.364217 22485033404224 run_lib.py:146] step: 50550, training_loss: 6.01316e-04
I0512 05:58:21.224551 22485033404224 run_lib.py:146] step: 50600, training_loss: 6.32343e-04
I0512 05:58:21.384086 22485033404224 run_lib.py:167] step: 50600, eval_loss: 7.49532e-04
I0512 05:58:45.209464 22485033404224 run_lib.py:146] step: 50650, training_loss: 5.74872e-04
I0512 05:59:08.735912 22485033404224 run_lib.py:146] step: 50700, training_loss: 6.45654e-04
I0512 05:59:08.895494 22485033404224 run_lib.py:167] step: 50700, eval_loss: 6.97386e-04
I0512 05:59:32.722927 22485033404224 run_lib.py:146] step: 50750, training_loss: 6.91394e-04
I0512 05:59:56.553839 22485033404224 run_lib.py:146] step: 50800, training_loss: 6.74449e-04
I0512 05:59:56.712906 22485033404224 run_lib.py:167] step: 50800, eval_loss: 5.61629e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 06:00:20.338989 22485033404224 run_lib.py:146] step: 50850, training_loss: 6.28578e-04
I0512 06:00:44.327212 22485033404224 run_lib.py:146] step: 50900, training_loss: 7.50493e-04
I0512 06:00:44.488884 22485033404224 run_lib.py:167] step: 50900, eval_loss: 6.08300e-04
I0512 06:01:08.413712 22485033404224 run_lib.py:146] step: 50950, training_loss: 5.29829e-04
I0512 06:01:32.016914 22485033404224 run_lib.py:146] step: 51000, training_loss: 7.83772e-04
I0512 06:01:32.176826 22485033404224 run_lib.py:167] step: 51000, eval_loss: 6.96093e-04
I0512 06:01:55.817396 22485033404224 run_lib.py:146] step: 51050, training_loss: 5.65304e-04
I0512 06:02:20.020709 22485033404224 run_lib.py:146] step: 51100, training_loss: 5.56848e-04
I0512 06:02:20.180813 22485033404224 run_lib.py:167] step: 51100, eval_loss: 7.06389e-04
I0512 06:02:43.805362 22485033404224 run_lib.py:146] step: 51150, training_loss: 7.22418e-04
I0512 06:03:07.428424 22485033404224 run_lib.py:146] step: 51200, training_loss: 6.06452e-04
I0512 06:03:07.589453 22485033404224 run_lib.py:167] step: 51200, eval_loss: 5.84426e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 06:03:32.224864 22485033404224 run_lib.py:146] step: 51250, training_loss: 6.22958e-04
I0512 06:03:55.867687 22485033404224 run_lib.py:146] step: 51300, training_loss: 6.99597e-04
I0512 06:03:56.029399 22485033404224 run_lib.py:167] step: 51300, eval_loss: 6.36577e-04
I0512 06:04:19.694468 22485033404224 run_lib.py:146] step: 51350, training_loss: 9.29089e-04
I0512 06:04:44.151995 22485033404224 run_lib.py:146] step: 51400, training_loss: 6.76049e-04
I0512 06:04:44.312511 22485033404224 run_lib.py:167] step: 51400, eval_loss: 6.62851e-04
I0512 06:05:07.894655 22485033404224 run_lib.py:146] step: 51450, training_loss: 6.54732e-04
I0512 06:05:31.499341 22485033404224 run_lib.py:146] step: 51500, training_loss: 5.99866e-04
I0512 06:05:31.660755 22485033404224 run_lib.py:167] step: 51500, eval_loss: 4.86479e-04
I0512 06:05:55.578344 22485033404224 run_lib.py:146] step: 51550, training_loss: 4.61230e-04
I0512 06:06:19.482100 22485033404224 run_lib.py:146] step: 51600, training_loss: 3.80061e-04
I0512 06:06:19.642307 22485033404224 run_lib.py:167] step: 51600, eval_loss: 5.79869e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 06:06:43.306246 22485033404224 run_lib.py:146] step: 51650, training_loss: 7.26188e-04
I0512 06:07:07.270941 22485033404224 run_lib.py:146] step: 51700, training_loss: 6.98424e-04
I0512 06:07:07.431915 22485033404224 run_lib.py:167] step: 51700, eval_loss: 5.19481e-04
I0512 06:07:31.315143 22485033404224 run_lib.py:146] step: 51750, training_loss: 5.17963e-04
I0512 06:07:54.837646 22485033404224 run_lib.py:146] step: 51800, training_loss: 7.59738e-04
I0512 06:07:54.996931 22485033404224 run_lib.py:167] step: 51800, eval_loss: 5.38960e-04
I0512 06:08:18.536350 22485033404224 run_lib.py:146] step: 51850, training_loss: 7.56514e-04
I0512 06:08:42.684714 22485033404224 run_lib.py:146] step: 51900, training_loss: 6.09385e-04
I0512 06:08:42.845016 22485033404224 run_lib.py:167] step: 51900, eval_loss: 7.12034e-04
I0512 06:09:06.348088 22485033404224 run_lib.py:146] step: 51950, training_loss: 8.41512e-04
I0512 06:09:29.861031 22485033404224 run_lib.py:146] step: 52000, training_loss: 6.69653e-04
I0512 06:09:30.019535 22485033404224 run_lib.py:167] step: 52000, eval_loss: 7.51734e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 06:09:54.284011 22485033404224 run_lib.py:146] step: 52050, training_loss: 5.47366e-04
I0512 06:10:17.767299 22485033404224 run_lib.py:146] step: 52100, training_loss: 4.50235e-04
I0512 06:10:17.928520 22485033404224 run_lib.py:167] step: 52100, eval_loss: 6.49736e-04
I0512 06:10:41.457658 22485033404224 run_lib.py:146] step: 52150, training_loss: 6.36462e-04
I0512 06:11:05.548980 22485033404224 run_lib.py:146] step: 52200, training_loss: 6.28337e-04
I0512 06:11:05.708407 22485033404224 run_lib.py:167] step: 52200, eval_loss: 5.56834e-04
I0512 06:11:29.226449 22485033404224 run_lib.py:146] step: 52250, training_loss: 7.78340e-04
I0512 06:11:52.735719 22485033404224 run_lib.py:146] step: 52300, training_loss: 5.17640e-04
I0512 06:11:52.895620 22485033404224 run_lib.py:167] step: 52300, eval_loss: 6.06387e-04
I0512 06:12:16.723904 22485033404224 run_lib.py:146] step: 52350, training_loss: 7.06004e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 06:12:40.604224 22485033404224 run_lib.py:146] step: 52400, training_loss: 4.90835e-04
I0512 06:12:40.765823 22485033404224 run_lib.py:167] step: 52400, eval_loss: 5.90322e-04
I0512 06:13:04.299942 22485033404224 run_lib.py:146] step: 52450, training_loss: 6.42705e-04
I0512 06:13:28.217314 22485033404224 run_lib.py:146] step: 52500, training_loss: 8.67575e-04
I0512 06:13:28.376388 22485033404224 run_lib.py:167] step: 52500, eval_loss: 5.01569e-04
I0512 06:13:52.226669 22485033404224 run_lib.py:146] step: 52550, training_loss: 5.05258e-04
I0512 06:14:15.774039 22485033404224 run_lib.py:146] step: 52600, training_loss: 7.42889e-04
I0512 06:14:15.933447 22485033404224 run_lib.py:167] step: 52600, eval_loss: 5.38023e-04
I0512 06:14:39.445859 22485033404224 run_lib.py:146] step: 52650, training_loss: 6.59944e-04
I0512 06:15:03.573840 22485033404224 run_lib.py:146] step: 52700, training_loss: 5.33122e-04
I0512 06:15:03.734607 22485033404224 run_lib.py:167] step: 52700, eval_loss: 5.67745e-04
I0512 06:15:27.287310 22485033404224 run_lib.py:146] step: 52750, training_loss: 5.80557e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 06:15:50.889894 22485033404224 run_lib.py:146] step: 52800, training_loss: 5.45357e-04
I0512 06:15:51.052528 22485033404224 run_lib.py:167] step: 52800, eval_loss: 7.67582e-04
I0512 06:16:15.250702 22485033404224 run_lib.py:146] step: 52850, training_loss: 5.22228e-04
I0512 06:16:38.769064 22485033404224 run_lib.py:146] step: 52900, training_loss: 1.00072e-03
I0512 06:16:38.927535 22485033404224 run_lib.py:167] step: 52900, eval_loss: 5.39990e-04
I0512 06:17:02.414408 22485033404224 run_lib.py:146] step: 52950, training_loss: 6.45093e-04
I0512 06:17:26.548550 22485033404224 run_lib.py:146] step: 53000, training_loss: 5.89612e-04
I0512 06:17:26.709491 22485033404224 run_lib.py:167] step: 53000, eval_loss: 6.65572e-04
I0512 06:17:50.258141 22485033404224 run_lib.py:146] step: 53050, training_loss: 7.18598e-04
I0512 06:18:13.857558 22485033404224 run_lib.py:146] step: 53100, training_loss: 4.60356e-04
I0512 06:18:14.018236 22485033404224 run_lib.py:167] step: 53100, eval_loss: 6.75590e-04
I0512 06:18:37.933595 22485033404224 run_lib.py:146] step: 53150, training_loss: 5.43586e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 06:19:01.914812 22485033404224 run_lib.py:146] step: 53200, training_loss: 6.70521e-04
I0512 06:19:02.077140 22485033404224 run_lib.py:167] step: 53200, eval_loss: 8.04702e-04
I0512 06:19:25.696234 22485033404224 run_lib.py:146] step: 53250, training_loss: 7.80909e-04
I0512 06:19:49.764697 22485033404224 run_lib.py:146] step: 53300, training_loss: 6.12762e-04
I0512 06:19:49.925020 22485033404224 run_lib.py:167] step: 53300, eval_loss: 4.97210e-04
I0512 06:20:13.858263 22485033404224 run_lib.py:146] step: 53350, training_loss: 6.74739e-04
I0512 06:20:37.415410 22485033404224 run_lib.py:146] step: 53400, training_loss: 5.28383e-04
I0512 06:20:37.575443 22485033404224 run_lib.py:167] step: 53400, eval_loss: 6.76422e-04
I0512 06:21:01.543798 22485033404224 run_lib.py:146] step: 53450, training_loss: 6.84628e-04
I0512 06:21:25.423153 22485033404224 run_lib.py:146] step: 53500, training_loss: 6.94360e-04
I0512 06:21:25.583642 22485033404224 run_lib.py:167] step: 53500, eval_loss: 6.21488e-04
I0512 06:21:49.140244 22485033404224 run_lib.py:146] step: 53550, training_loss: 5.53904e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 06:22:12.827588 22485033404224 run_lib.py:146] step: 53600, training_loss: 6.23942e-04
I0512 06:22:12.989704 22485033404224 run_lib.py:167] step: 53600, eval_loss: 7.08982e-04
I0512 06:22:37.272561 22485033404224 run_lib.py:146] step: 53650, training_loss: 5.70628e-04
I0512 06:23:00.829907 22485033404224 run_lib.py:146] step: 53700, training_loss: 4.42123e-04
I0512 06:23:00.989385 22485033404224 run_lib.py:167] step: 53700, eval_loss: 7.54104e-04
I0512 06:23:24.550014 22485033404224 run_lib.py:146] step: 53750, training_loss: 8.23186e-04
I0512 06:23:48.755968 22485033404224 run_lib.py:146] step: 53800, training_loss: 6.24914e-04
I0512 06:23:48.916506 22485033404224 run_lib.py:167] step: 53800, eval_loss: 6.96564e-04
I0512 06:24:12.489470 22485033404224 run_lib.py:146] step: 53850, training_loss: 5.86555e-04
I0512 06:24:36.053304 22485033404224 run_lib.py:146] step: 53900, training_loss: 5.82864e-04
I0512 06:24:36.213743 22485033404224 run_lib.py:167] step: 53900, eval_loss: 6.52862e-04
I0512 06:25:00.099057 22485033404224 run_lib.py:146] step: 53950, training_loss: 6.07600e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 06:25:24.069263 22485033404224 run_lib.py:146] step: 54000, training_loss: 4.95130e-04
I0512 06:25:24.230700 22485033404224 run_lib.py:167] step: 54000, eval_loss: 5.31853e-04
I0512 06:25:47.769500 22485033404224 run_lib.py:146] step: 54050, training_loss: 5.53216e-04
I0512 06:26:11.639540 22485033404224 run_lib.py:146] step: 54100, training_loss: 7.71389e-04
I0512 06:26:11.799980 22485033404224 run_lib.py:167] step: 54100, eval_loss: 6.47479e-04
I0512 06:26:35.627893 22485033404224 run_lib.py:146] step: 54150, training_loss: 7.82762e-04
I0512 06:26:59.120846 22485033404224 run_lib.py:146] step: 54200, training_loss: 6.42117e-04
I0512 06:26:59.279526 22485033404224 run_lib.py:167] step: 54200, eval_loss: 8.09456e-04
I0512 06:27:23.092479 22485033404224 run_lib.py:146] step: 54250, training_loss: 7.57271e-04
I0512 06:27:46.933519 22485033404224 run_lib.py:146] step: 54300, training_loss: 6.19566e-04
I0512 06:27:47.094616 22485033404224 run_lib.py:167] step: 54300, eval_loss: 5.00391e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 06:28:10.685854 22485033404224 run_lib.py:146] step: 54350, training_loss: 6.04129e-04
I0512 06:28:34.238929 22485033404224 run_lib.py:146] step: 54400, training_loss: 5.25156e-04
I0512 06:28:34.399166 22485033404224 run_lib.py:167] step: 54400, eval_loss: 7.62970e-04
I0512 06:28:58.599815 22485033404224 run_lib.py:146] step: 54450, training_loss: 7.29633e-04
I0512 06:29:22.143621 22485033404224 run_lib.py:146] step: 54500, training_loss: 7.15593e-04
I0512 06:29:22.301996 22485033404224 run_lib.py:167] step: 54500, eval_loss: 6.37223e-04
I0512 06:29:45.830079 22485033404224 run_lib.py:146] step: 54550, training_loss: 7.78383e-04
I0512 06:30:09.978031 22485033404224 run_lib.py:146] step: 54600, training_loss: 6.28479e-04
I0512 06:30:10.137534 22485033404224 run_lib.py:167] step: 54600, eval_loss: 5.91038e-04
I0512 06:30:33.660956 22485033404224 run_lib.py:146] step: 54650, training_loss: 6.31469e-04
I0512 06:30:57.204221 22485033404224 run_lib.py:146] step: 54700, training_loss: 5.39345e-04
I0512 06:30:57.363792 22485033404224 run_lib.py:167] step: 54700, eval_loss: 5.55875e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 06:31:21.606474 22485033404224 run_lib.py:146] step: 54750, training_loss: 6.47293e-04
I0512 06:31:45.144437 22485033404224 run_lib.py:146] step: 54800, training_loss: 6.39959e-04
I0512 06:31:45.305400 22485033404224 run_lib.py:167] step: 54800, eval_loss: 5.86933e-04
I0512 06:32:08.848277 22485033404224 run_lib.py:146] step: 54850, training_loss: 5.58283e-04
I0512 06:32:32.702315 22485033404224 run_lib.py:146] step: 54900, training_loss: 5.80614e-04
I0512 06:32:32.861755 22485033404224 run_lib.py:167] step: 54900, eval_loss: 6.91278e-04
I0512 06:32:56.698992 22485033404224 run_lib.py:146] step: 54950, training_loss: 6.85352e-04
I0512 06:33:20.235173 22485033404224 run_lib.py:146] step: 55000, training_loss: 5.26979e-04
I0512 06:33:20.394372 22485033404224 run_lib.py:167] step: 55000, eval_loss: 5.73352e-04
I0512 06:33:44.238677 22485033404224 run_lib.py:146] step: 55050, training_loss: 8.60591e-04
I0512 06:34:08.087792 22485033404224 run_lib.py:146] step: 55100, training_loss: 5.48496e-04
I0512 06:34:08.245503 22485033404224 run_lib.py:167] step: 55100, eval_loss: 5.25122e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 06:34:31.833388 22485033404224 run_lib.py:146] step: 55150, training_loss: 6.54371e-04
I0512 06:34:55.345198 22485033404224 run_lib.py:146] step: 55200, training_loss: 8.97129e-04
I0512 06:34:55.429424 22485033404224 run_lib.py:167] step: 55200, eval_loss: 1.01742e-03
I0512 06:35:19.644026 22485033404224 run_lib.py:146] step: 55250, training_loss: 5.79251e-04
I0512 06:35:43.162897 22485033404224 run_lib.py:146] step: 55300, training_loss: 8.37094e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 06:35:43.511574 22485033404224 run_lib.py:167] step: 55300, eval_loss: 5.94766e-04
I0512 06:36:07.104772 22485033404224 run_lib.py:146] step: 55350, training_loss: 7.11759e-04
I0512 06:36:31.421802 22485033404224 run_lib.py:146] step: 55400, training_loss: 7.75223e-04
I0512 06:36:31.582638 22485033404224 run_lib.py:167] step: 55400, eval_loss: 5.70777e-04
I0512 06:36:55.210570 22485033404224 run_lib.py:146] step: 55450, training_loss: 5.70438e-04
I0512 06:37:18.840463 22485033404224 run_lib.py:146] step: 55500, training_loss: 7.14549e-04
I0512 06:37:19.000999 22485033404224 run_lib.py:167] step: 55500, eval_loss: 7.37654e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 06:37:43.379439 22485033404224 run_lib.py:146] step: 55550, training_loss: 5.77386e-04
I0512 06:38:06.968078 22485033404224 run_lib.py:146] step: 55600, training_loss: 6.28033e-04
I0512 06:38:07.129083 22485033404224 run_lib.py:167] step: 55600, eval_loss: 6.48350e-04
I0512 06:38:30.701611 22485033404224 run_lib.py:146] step: 55650, training_loss: 7.92082e-04
I0512 06:38:54.575500 22485033404224 run_lib.py:146] step: 55700, training_loss: 6.49428e-04
I0512 06:38:54.735745 22485033404224 run_lib.py:167] step: 55700, eval_loss: 8.26448e-04
I0512 06:39:18.596706 22485033404224 run_lib.py:146] step: 55750, training_loss: 6.58056e-04
I0512 06:39:42.183068 22485033404224 run_lib.py:146] step: 55800, training_loss: 5.48973e-04
I0512 06:39:42.343301 22485033404224 run_lib.py:167] step: 55800, eval_loss: 7.41062e-04
I0512 06:40:06.200808 22485033404224 run_lib.py:146] step: 55850, training_loss: 8.59123e-04
I0512 06:40:30.111335 22485033404224 run_lib.py:146] step: 55900, training_loss: 6.00939e-04
I0512 06:40:30.271788 22485033404224 run_lib.py:167] step: 55900, eval_loss: 7.31577e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 06:40:53.929737 22485033404224 run_lib.py:146] step: 55950, training_loss: 6.14346e-04
I0512 06:41:17.859715 22485033404224 run_lib.py:146] step: 56000, training_loss: 6.65331e-04
I0512 06:41:18.020495 22485033404224 run_lib.py:167] step: 56000, eval_loss: 5.45438e-04
I0512 06:41:42.047644 22485033404224 run_lib.py:146] step: 56050, training_loss: 6.16979e-04
I0512 06:42:05.647318 22485033404224 run_lib.py:146] step: 56100, training_loss: 7.85551e-04
I0512 06:42:05.807147 22485033404224 run_lib.py:167] step: 56100, eval_loss: 7.46427e-04
I0512 06:42:29.384359 22485033404224 run_lib.py:146] step: 56150, training_loss: 7.40171e-04
I0512 06:42:53.708065 22485033404224 run_lib.py:146] step: 56200, training_loss: 7.64172e-04
I0512 06:42:53.867462 22485033404224 run_lib.py:167] step: 56200, eval_loss: 6.87972e-04
I0512 06:43:17.462803 22485033404224 run_lib.py:146] step: 56250, training_loss: 4.51213e-04
I0512 06:43:41.014511 22485033404224 run_lib.py:146] step: 56300, training_loss: 5.81724e-04
I0512 06:43:41.174148 22485033404224 run_lib.py:167] step: 56300, eval_loss: 6.59350e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 06:44:05.449249 22485033404224 run_lib.py:146] step: 56350, training_loss: 6.36227e-04
I0512 06:44:28.977110 22485033404224 run_lib.py:146] step: 56400, training_loss: 5.30594e-04
I0512 06:44:29.138099 22485033404224 run_lib.py:167] step: 56400, eval_loss: 5.98674e-04
I0512 06:44:52.681229 22485033404224 run_lib.py:146] step: 56450, training_loss: 5.69056e-04
I0512 06:45:16.805419 22485033404224 run_lib.py:146] step: 56500, training_loss: 6.65481e-04
I0512 06:45:16.964544 22485033404224 run_lib.py:167] step: 56500, eval_loss: 4.96358e-04
I0512 06:45:40.511119 22485033404224 run_lib.py:146] step: 56550, training_loss: 6.89815e-04
I0512 06:46:04.043575 22485033404224 run_lib.py:146] step: 56600, training_loss: 7.08632e-04
I0512 06:46:04.204485 22485033404224 run_lib.py:167] step: 56600, eval_loss: 5.92478e-04
I0512 06:46:28.043861 22485033404224 run_lib.py:146] step: 56650, training_loss: 5.73025e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 06:46:51.949826 22485033404224 run_lib.py:146] step: 56700, training_loss: 7.40227e-04
I0512 06:46:52.110285 22485033404224 run_lib.py:167] step: 56700, eval_loss: 4.82647e-04
I0512 06:47:15.645978 22485033404224 run_lib.py:146] step: 56750, training_loss: 7.00001e-04
I0512 06:47:39.510788 22485033404224 run_lib.py:146] step: 56800, training_loss: 7.06989e-04
I0512 06:47:39.669626 22485033404224 run_lib.py:167] step: 56800, eval_loss: 6.66592e-04
I0512 06:48:03.542742 22485033404224 run_lib.py:146] step: 56850, training_loss: 9.16294e-04
I0512 06:48:27.074878 22485033404224 run_lib.py:146] step: 56900, training_loss: 7.94133e-04
I0512 06:48:27.234941 22485033404224 run_lib.py:167] step: 56900, eval_loss: 3.52189e-04
I0512 06:48:50.779317 22485033404224 run_lib.py:146] step: 56950, training_loss: 5.73948e-04
I0512 06:49:14.925213 22485033404224 run_lib.py:146] step: 57000, training_loss: 6.00173e-04
I0512 06:49:15.084516 22485033404224 run_lib.py:167] step: 57000, eval_loss: 5.58438e-04
I0512 06:49:38.619263 22485033404224 run_lib.py:146] step: 57050, training_loss: 6.40921e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 06:50:02.225866 22485033404224 run_lib.py:146] step: 57100, training_loss: 7.00471e-04
I0512 06:50:02.387299 22485033404224 run_lib.py:167] step: 57100, eval_loss: 6.97445e-04
I0512 06:50:26.602433 22485033404224 run_lib.py:146] step: 57150, training_loss: 6.59418e-04
I0512 06:50:50.095718 22485033404224 run_lib.py:146] step: 57200, training_loss: 4.93947e-04
I0512 06:50:50.255239 22485033404224 run_lib.py:167] step: 57200, eval_loss: 4.92366e-04
I0512 06:51:13.784792 22485033404224 run_lib.py:146] step: 57250, training_loss: 5.92813e-04
I0512 06:51:37.887701 22485033404224 run_lib.py:146] step: 57300, training_loss: 6.75596e-04
I0512 06:51:38.045954 22485033404224 run_lib.py:167] step: 57300, eval_loss: 5.13324e-04
I0512 06:52:01.577010 22485033404224 run_lib.py:146] step: 57350, training_loss: 6.57645e-04
I0512 06:52:25.110435 22485033404224 run_lib.py:146] step: 57400, training_loss: 6.95580e-04
I0512 06:52:25.271198 22485033404224 run_lib.py:167] step: 57400, eval_loss: 6.45171e-04
I0512 06:52:49.098896 22485033404224 run_lib.py:146] step: 57450, training_loss: 7.10486e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 06:53:12.973951 22485033404224 run_lib.py:146] step: 57500, training_loss: 6.94656e-04
I0512 06:53:13.135858 22485033404224 run_lib.py:167] step: 57500, eval_loss: 4.40580e-04
I0512 06:53:36.664535 22485033404224 run_lib.py:146] step: 57550, training_loss: 4.88668e-04
I0512 06:54:00.501862 22485033404224 run_lib.py:146] step: 57600, training_loss: 6.21422e-04
I0512 06:54:00.662059 22485033404224 run_lib.py:167] step: 57600, eval_loss: 7.21579e-04
I0512 06:54:24.566690 22485033404224 run_lib.py:146] step: 57650, training_loss: 5.58706e-04
I0512 06:54:48.189800 22485033404224 run_lib.py:146] step: 57700, training_loss: 5.05218e-04
I0512 06:54:48.350540 22485033404224 run_lib.py:167] step: 57700, eval_loss: 8.61925e-04
I0512 06:55:11.958564 22485033404224 run_lib.py:146] step: 57750, training_loss: 6.34354e-04
I0512 06:55:36.195042 22485033404224 run_lib.py:146] step: 57800, training_loss: 6.38266e-04
I0512 06:55:36.355302 22485033404224 run_lib.py:167] step: 57800, eval_loss: 8.51806e-04
I0512 06:55:59.943962 22485033404224 run_lib.py:146] step: 57850, training_loss: 5.31298e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 06:56:23.619594 22485033404224 run_lib.py:146] step: 57900, training_loss: 5.94460e-04
I0512 06:56:23.781906 22485033404224 run_lib.py:167] step: 57900, eval_loss: 5.43525e-04
I0512 06:56:48.180528 22485033404224 run_lib.py:146] step: 57950, training_loss: 6.63794e-04
I0512 06:57:11.784886 22485033404224 run_lib.py:146] step: 58000, training_loss: 7.70152e-04
I0512 06:57:11.944778 22485033404224 run_lib.py:167] step: 58000, eval_loss: 6.50007e-04
I0512 06:57:35.558005 22485033404224 run_lib.py:146] step: 58050, training_loss: 5.37734e-04
I0512 06:57:59.862266 22485033404224 run_lib.py:146] step: 58100, training_loss: 6.48332e-04
I0512 06:58:00.023394 22485033404224 run_lib.py:167] step: 58100, eval_loss: 5.95002e-04
I0512 06:58:23.651964 22485033404224 run_lib.py:146] step: 58150, training_loss: 6.47384e-04
I0512 06:58:47.253067 22485033404224 run_lib.py:146] step: 58200, training_loss: 6.27008e-04
I0512 06:58:47.414086 22485033404224 run_lib.py:167] step: 58200, eval_loss: 5.39795e-04
I0512 06:59:11.293837 22485033404224 run_lib.py:146] step: 58250, training_loss: 5.08562e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 06:59:35.381690 22485033404224 run_lib.py:146] step: 58300, training_loss: 4.49998e-04
I0512 06:59:35.542598 22485033404224 run_lib.py:167] step: 58300, eval_loss: 4.82134e-04
I0512 06:59:59.152591 22485033404224 run_lib.py:146] step: 58350, training_loss: 9.10396e-04
I0512 07:00:23.179201 22485033404224 run_lib.py:146] step: 58400, training_loss: 6.29039e-04
I0512 07:00:23.339186 22485033404224 run_lib.py:167] step: 58400, eval_loss: 7.56350e-04
I0512 07:00:47.351259 22485033404224 run_lib.py:146] step: 58450, training_loss: 5.72615e-04
I0512 07:01:10.968533 22485033404224 run_lib.py:146] step: 58500, training_loss: 6.94614e-04
I0512 07:01:11.128848 22485033404224 run_lib.py:167] step: 58500, eval_loss: 5.14444e-04
I0512 07:01:35.109235 22485033404224 run_lib.py:146] step: 58550, training_loss: 7.40505e-04
I0512 07:01:59.060113 22485033404224 run_lib.py:146] step: 58600, training_loss: 7.58909e-04
I0512 07:01:59.218627 22485033404224 run_lib.py:167] step: 58600, eval_loss: 6.28748e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 07:02:22.785815 22485033404224 run_lib.py:146] step: 58650, training_loss: 6.89344e-04
I0512 07:02:46.305176 22485033404224 run_lib.py:146] step: 58700, training_loss: 6.61217e-04
I0512 07:02:46.466432 22485033404224 run_lib.py:167] step: 58700, eval_loss: 7.61749e-04
I0512 07:03:10.658118 22485033404224 run_lib.py:146] step: 58750, training_loss: 5.24843e-04
I0512 07:03:34.210232 22485033404224 run_lib.py:146] step: 58800, training_loss: 6.24355e-04
I0512 07:03:34.371370 22485033404224 run_lib.py:167] step: 58800, eval_loss: 5.88482e-04
I0512 07:03:57.902485 22485033404224 run_lib.py:146] step: 58850, training_loss: 5.34605e-04
I0512 07:04:22.033990 22485033404224 run_lib.py:146] step: 58900, training_loss: 6.50800e-04
I0512 07:04:22.192685 22485033404224 run_lib.py:167] step: 58900, eval_loss: 5.29592e-04
I0512 07:04:45.714399 22485033404224 run_lib.py:146] step: 58950, training_loss: 7.88648e-04
I0512 07:05:09.241024 22485033404224 run_lib.py:146] step: 59000, training_loss: 5.12339e-04
I0512 07:05:09.400731 22485033404224 run_lib.py:167] step: 59000, eval_loss: 7.46044e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 07:05:33.662676 22485033404224 run_lib.py:146] step: 59050, training_loss: 6.83931e-04
I0512 07:05:57.170182 22485033404224 run_lib.py:146] step: 59100, training_loss: 5.58357e-04
I0512 07:05:57.330656 22485033404224 run_lib.py:167] step: 59100, eval_loss: 5.30109e-04
I0512 07:06:20.856548 22485033404224 run_lib.py:146] step: 59150, training_loss: 5.97717e-04
I0512 07:06:44.704180 22485033404224 run_lib.py:146] step: 59200, training_loss: 6.06548e-04
I0512 07:06:44.863087 22485033404224 run_lib.py:167] step: 59200, eval_loss: 5.19308e-04
I0512 07:07:08.702182 22485033404224 run_lib.py:146] step: 59250, training_loss: 7.95639e-04
I0512 07:07:32.268519 22485033404224 run_lib.py:146] step: 59300, training_loss: 6.93706e-04
I0512 07:07:32.428697 22485033404224 run_lib.py:167] step: 59300, eval_loss: 6.52445e-04
I0512 07:07:56.284142 22485033404224 run_lib.py:146] step: 59350, training_loss: 6.66701e-04
I0512 07:08:20.140188 22485033404224 run_lib.py:146] step: 59400, training_loss: 4.80390e-04
I0512 07:08:20.299665 22485033404224 run_lib.py:167] step: 59400, eval_loss: 6.17234e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 07:08:43.885060 22485033404224 run_lib.py:146] step: 59450, training_loss: 6.25247e-04
I0512 07:09:07.389644 22485033404224 run_lib.py:146] step: 59500, training_loss: 7.73762e-04
I0512 07:09:07.549903 22485033404224 run_lib.py:167] step: 59500, eval_loss: 3.07190e-04
I0512 07:09:31.758663 22485033404224 run_lib.py:146] step: 59550, training_loss: 5.42286e-04
I0512 07:09:55.309994 22485033404224 run_lib.py:146] step: 59600, training_loss: 6.72252e-04
I0512 07:09:55.470094 22485033404224 run_lib.py:167] step: 59600, eval_loss: 4.09729e-04
I0512 07:10:19.010328 22485033404224 run_lib.py:146] step: 59650, training_loss: 5.63069e-04
I0512 07:10:43.137905 22485033404224 run_lib.py:146] step: 59700, training_loss: 7.29065e-04
I0512 07:10:43.296954 22485033404224 run_lib.py:167] step: 59700, eval_loss: 5.23011e-04
I0512 07:11:06.827685 22485033404224 run_lib.py:146] step: 59750, training_loss: 7.02754e-04
I0512 07:11:30.338818 22485033404224 run_lib.py:146] step: 59800, training_loss: 6.14059e-04
I0512 07:11:30.498392 22485033404224 run_lib.py:167] step: 59800, eval_loss: 5.64943e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 07:11:54.754628 22485033404224 run_lib.py:146] step: 59850, training_loss: 6.79445e-04
I0512 07:12:18.315066 22485033404224 run_lib.py:146] step: 59900, training_loss: 7.12910e-04
I0512 07:12:18.477533 22485033404224 run_lib.py:167] step: 59900, eval_loss: 6.89047e-04
I0512 07:12:42.057486 22485033404224 run_lib.py:146] step: 59950, training_loss: 5.61002e-04
I0512 07:13:05.988103 22485033404224 run_lib.py:146] step: 60000, training_loss: 6.95044e-04
I0512 07:13:07.761909 22485033404224 run_lib.py:167] step: 60000, eval_loss: 5.98638e-04
I0512 07:13:33.280541 22485033404224 run_lib.py:146] step: 60050, training_loss: 5.11348e-04
I0512 07:13:57.164789 22485033404224 run_lib.py:146] step: 60100, training_loss: 6.09075e-04
I0512 07:13:57.324998 22485033404224 run_lib.py:167] step: 60100, eval_loss: 7.04402e-04
I0512 07:14:20.938734 22485033404224 run_lib.py:146] step: 60150, training_loss: 6.35728e-04
I0512 07:14:44.844795 22485033404224 run_lib.py:146] step: 60200, training_loss: 6.44005e-04
I0512 07:14:45.004706 22485033404224 run_lib.py:167] step: 60200, eval_loss: 6.55514e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 07:15:09.240574 22485033404224 run_lib.py:146] step: 60250, training_loss: 7.54199e-04
I0512 07:15:32.918775 22485033404224 run_lib.py:146] step: 60300, training_loss: 7.60289e-04
I0512 07:15:33.080016 22485033404224 run_lib.py:167] step: 60300, eval_loss: 4.53835e-04
I0512 07:15:57.273176 22485033404224 run_lib.py:146] step: 60350, training_loss: 8.28967e-04
I0512 07:16:20.969462 22485033404224 run_lib.py:146] step: 60400, training_loss: 6.00683e-04
I0512 07:16:21.131516 22485033404224 run_lib.py:167] step: 60400, eval_loss: 5.76456e-04
I0512 07:16:45.234785 22485033404224 run_lib.py:146] step: 60450, training_loss: 5.63055e-04
I0512 07:17:09.334904 22485033404224 run_lib.py:146] step: 60500, training_loss: 6.82705e-04
I0512 07:17:09.495633 22485033404224 run_lib.py:167] step: 60500, eval_loss: 6.43525e-04
I0512 07:17:33.178941 22485033404224 run_lib.py:146] step: 60550, training_loss: 8.02293e-04
I0512 07:17:57.159309 22485033404224 run_lib.py:146] step: 60600, training_loss: 6.82987e-04
I0512 07:17:57.320253 22485033404224 run_lib.py:167] step: 60600, eval_loss: 7.15562e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 07:18:21.432643 22485033404224 run_lib.py:146] step: 60650, training_loss: 5.75813e-04
I0512 07:18:44.983104 22485033404224 run_lib.py:146] step: 60700, training_loss: 5.97902e-04
I0512 07:18:45.146149 22485033404224 run_lib.py:167] step: 60700, eval_loss: 5.75071e-04
I0512 07:19:09.050913 22485033404224 run_lib.py:146] step: 60750, training_loss: 7.11753e-04
I0512 07:19:33.049314 22485033404224 run_lib.py:146] step: 60800, training_loss: 7.74377e-04
I0512 07:19:33.210354 22485033404224 run_lib.py:167] step: 60800, eval_loss: 8.40796e-04
I0512 07:19:56.726147 22485033404224 run_lib.py:146] step: 60850, training_loss: 6.49249e-04
I0512 07:20:20.557855 22485033404224 run_lib.py:146] step: 60900, training_loss: 5.72348e-04
I0512 07:20:20.716993 22485033404224 run_lib.py:167] step: 60900, eval_loss: 3.93788e-04
I0512 07:20:44.207540 22485033404224 run_lib.py:146] step: 60950, training_loss: 5.60753e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 07:21:08.086954 22485033404224 run_lib.py:146] step: 61000, training_loss: 4.36387e-04
I0512 07:21:08.248424 22485033404224 run_lib.py:167] step: 61000, eval_loss: 6.20680e-04
I0512 07:21:32.113829 22485033404224 run_lib.py:146] step: 61050, training_loss: 4.96090e-04
I0512 07:21:55.629065 22485033404224 run_lib.py:146] step: 61100, training_loss: 7.87344e-04
I0512 07:21:55.789314 22485033404224 run_lib.py:167] step: 61100, eval_loss: 6.27153e-04
I0512 07:22:19.646933 22485033404224 run_lib.py:146] step: 61150, training_loss: 4.64571e-04
I0512 07:22:43.199681 22485033404224 run_lib.py:146] step: 61200, training_loss: 7.34236e-04
I0512 07:22:43.359926 22485033404224 run_lib.py:167] step: 61200, eval_loss: 3.77392e-04
I0512 07:23:07.176358 22485033404224 run_lib.py:146] step: 61250, training_loss: 5.95994e-04
I0512 07:23:30.987599 22485033404224 run_lib.py:146] step: 61300, training_loss: 5.42192e-04
I0512 07:23:31.146890 22485033404224 run_lib.py:167] step: 61300, eval_loss: 7.08178e-04
I0512 07:23:54.677182 22485033404224 run_lib.py:146] step: 61350, training_loss: 5.76481e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 07:24:18.579689 22485033404224 run_lib.py:146] step: 61400, training_loss: 6.40871e-04
I0512 07:24:18.740931 22485033404224 run_lib.py:167] step: 61400, eval_loss: 7.80903e-04
I0512 07:24:42.568540 22485033404224 run_lib.py:146] step: 61450, training_loss: 5.71050e-04
I0512 07:25:06.095262 22485033404224 run_lib.py:146] step: 61500, training_loss: 6.54381e-04
I0512 07:25:06.253837 22485033404224 run_lib.py:167] step: 61500, eval_loss: 5.93640e-04
I0512 07:25:30.130943 22485033404224 run_lib.py:146] step: 61550, training_loss: 6.68457e-04
I0512 07:25:53.963018 22485033404224 run_lib.py:146] step: 61600, training_loss: 4.73663e-04
I0512 07:25:54.123147 22485033404224 run_lib.py:167] step: 61600, eval_loss: 6.06816e-04
I0512 07:26:17.623241 22485033404224 run_lib.py:146] step: 61650, training_loss: 7.31439e-04
I0512 07:26:41.432095 22485033404224 run_lib.py:146] step: 61700, training_loss: 6.34939e-04
I0512 07:26:41.592191 22485033404224 run_lib.py:167] step: 61700, eval_loss: 4.52849e-04
I0512 07:27:05.411634 22485033404224 run_lib.py:146] step: 61750, training_loss: 6.40836e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 07:27:28.989839 22485033404224 run_lib.py:146] step: 61800, training_loss: 6.29627e-04
I0512 07:27:29.152928 22485033404224 run_lib.py:167] step: 61800, eval_loss: 5.56321e-04
I0512 07:27:53.005128 22485033404224 run_lib.py:146] step: 61850, training_loss: 6.04108e-04
I0512 07:28:16.531748 22485033404224 run_lib.py:146] step: 61900, training_loss: 6.64798e-04
I0512 07:28:16.690523 22485033404224 run_lib.py:167] step: 61900, eval_loss: 6.39582e-04
I0512 07:28:40.532613 22485033404224 run_lib.py:146] step: 61950, training_loss: 5.42894e-04
I0512 07:29:04.047429 22485033404224 run_lib.py:146] step: 62000, training_loss: 6.82440e-04
I0512 07:29:04.206788 22485033404224 run_lib.py:167] step: 62000, eval_loss: 5.60834e-04
I0512 07:29:28.052172 22485033404224 run_lib.py:146] step: 62050, training_loss: 5.35761e-04
I0512 07:29:51.870161 22485033404224 run_lib.py:146] step: 62100, training_loss: 5.04793e-04
I0512 07:29:52.030606 22485033404224 run_lib.py:167] step: 62100, eval_loss: 6.02542e-04
I0512 07:30:15.536055 22485033404224 run_lib.py:146] step: 62150, training_loss: 5.39199e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 07:30:39.515173 22485033404224 run_lib.py:146] step: 62200, training_loss: 7.16277e-04
I0512 07:30:39.677265 22485033404224 run_lib.py:167] step: 62200, eval_loss: 6.35900e-04
I0512 07:31:03.640895 22485033404224 run_lib.py:146] step: 62250, training_loss: 7.06185e-04
I0512 07:31:27.234577 22485033404224 run_lib.py:146] step: 62300, training_loss: 4.89146e-04
I0512 07:31:27.394567 22485033404224 run_lib.py:167] step: 62300, eval_loss: 6.75763e-04
I0512 07:31:51.306757 22485033404224 run_lib.py:146] step: 62350, training_loss: 6.35657e-04
I0512 07:32:15.231879 22485033404224 run_lib.py:146] step: 62400, training_loss: 8.99506e-04
I0512 07:32:15.391398 22485033404224 run_lib.py:167] step: 62400, eval_loss: 5.55230e-04
I0512 07:32:38.985109 22485033404224 run_lib.py:146] step: 62450, training_loss: 7.17978e-04
I0512 07:33:02.872406 22485033404224 run_lib.py:146] step: 62500, training_loss: 5.39206e-04
I0512 07:33:03.032188 22485033404224 run_lib.py:167] step: 62500, eval_loss: 5.64486e-04
I0512 07:33:26.947765 22485033404224 run_lib.py:146] step: 62550, training_loss: 8.39535e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 07:33:50.629210 22485033404224 run_lib.py:146] step: 62600, training_loss: 5.57465e-04
I0512 07:33:50.791046 22485033404224 run_lib.py:167] step: 62600, eval_loss: 6.36386e-04
I0512 07:34:14.870905 22485033404224 run_lib.py:146] step: 62650, training_loss: 5.09600e-04
I0512 07:34:38.535182 22485033404224 run_lib.py:146] step: 62700, training_loss: 7.21106e-04
I0512 07:34:38.695698 22485033404224 run_lib.py:167] step: 62700, eval_loss: 8.00248e-04
I0512 07:35:02.632316 22485033404224 run_lib.py:146] step: 62750, training_loss: 8.68467e-04
I0512 07:35:26.637496 22485033404224 run_lib.py:146] step: 62800, training_loss: 5.01089e-04
I0512 07:35:26.797116 22485033404224 run_lib.py:167] step: 62800, eval_loss: 7.39203e-04
I0512 07:35:50.397223 22485033404224 run_lib.py:146] step: 62850, training_loss: 6.42465e-04
I0512 07:36:14.332583 22485033404224 run_lib.py:146] step: 62900, training_loss: 5.80025e-04
I0512 07:36:14.492592 22485033404224 run_lib.py:167] step: 62900, eval_loss: 6.82767e-04
I0512 07:36:37.970763 22485033404224 run_lib.py:146] step: 62950, training_loss: 4.81041e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 07:37:02.141661 22485033404224 run_lib.py:146] step: 63000, training_loss: 5.67124e-04
I0512 07:37:02.304426 22485033404224 run_lib.py:167] step: 63000, eval_loss: 6.59069e-04
I0512 07:37:26.246885 22485033404224 run_lib.py:146] step: 63050, training_loss: 6.82143e-04
I0512 07:37:49.805793 22485033404224 run_lib.py:146] step: 63100, training_loss: 7.03742e-04
I0512 07:37:49.891761 22485033404224 run_lib.py:167] step: 63100, eval_loss: 3.01414e-04
I0512 07:38:13.750768 22485033404224 run_lib.py:146] step: 63150, training_loss: 6.48928e-04
I0512 07:38:37.570393 22485033404224 run_lib.py:146] step: 63200, training_loss: 8.50020e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 07:38:37.920018 22485033404224 run_lib.py:167] step: 63200, eval_loss: 4.98492e-04
I0512 07:39:01.437466 22485033404224 run_lib.py:146] step: 63250, training_loss: 5.11916e-04
I0512 07:39:25.314909 22485033404224 run_lib.py:146] step: 63300, training_loss: 8.56696e-04
I0512 07:39:25.474035 22485033404224 run_lib.py:167] step: 63300, eval_loss: 6.47103e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 07:39:49.401136 22485033404224 run_lib.py:146] step: 63350, training_loss: 6.88865e-04
I0512 07:40:12.918061 22485033404224 run_lib.py:146] step: 63400, training_loss: 6.77878e-04
I0512 07:40:13.080960 22485033404224 run_lib.py:167] step: 63400, eval_loss: 5.62746e-04
I0512 07:40:36.943188 22485033404224 run_lib.py:146] step: 63450, training_loss: 5.32453e-04
I0512 07:41:00.473328 22485033404224 run_lib.py:146] step: 63500, training_loss: 5.57350e-04
I0512 07:41:00.632903 22485033404224 run_lib.py:167] step: 63500, eval_loss: 6.86219e-04
I0512 07:41:24.458931 22485033404224 run_lib.py:146] step: 63550, training_loss: 6.53717e-04
I0512 07:41:48.283303 22485033404224 run_lib.py:146] step: 63600, training_loss: 7.40103e-04
I0512 07:41:48.444327 22485033404224 run_lib.py:167] step: 63600, eval_loss: 5.04308e-04
I0512 07:42:11.978902 22485033404224 run_lib.py:146] step: 63650, training_loss: 5.23223e-04
I0512 07:42:35.827763 22485033404224 run_lib.py:146] step: 63700, training_loss: 5.56858e-04
I0512 07:42:35.986930 22485033404224 run_lib.py:167] step: 63700, eval_loss: 6.11568e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 07:42:59.597470 22485033404224 run_lib.py:146] step: 63750, training_loss: 5.30396e-04
I0512 07:43:23.490119 22485033404224 run_lib.py:146] step: 63800, training_loss: 6.16347e-04
I0512 07:43:23.652705 22485033404224 run_lib.py:167] step: 63800, eval_loss: 5.72939e-04
I0512 07:43:47.537975 22485033404224 run_lib.py:146] step: 63850, training_loss: 5.57594e-04
I0512 07:44:11.076824 22485033404224 run_lib.py:146] step: 63900, training_loss: 6.71283e-04
I0512 07:44:11.236589 22485033404224 run_lib.py:167] step: 63900, eval_loss: 7.11771e-04
I0512 07:44:35.090785 22485033404224 run_lib.py:146] step: 63950, training_loss: 6.77175e-04
I0512 07:44:58.925925 22485033404224 run_lib.py:146] step: 64000, training_loss: 4.01925e-04
I0512 07:44:59.087409 22485033404224 run_lib.py:167] step: 64000, eval_loss: 8.44748e-04
I0512 07:45:22.645786 22485033404224 run_lib.py:146] step: 64050, training_loss: 7.16112e-04
I0512 07:45:46.495382 22485033404224 run_lib.py:146] step: 64100, training_loss: 7.19545e-04
I0512 07:45:46.654088 22485033404224 run_lib.py:167] step: 64100, eval_loss: 5.22053e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 07:46:10.604096 22485033404224 run_lib.py:146] step: 64150, training_loss: 7.89125e-04
I0512 07:46:34.145658 22485033404224 run_lib.py:146] step: 64200, training_loss: 7.05756e-04
I0512 07:46:34.307035 22485033404224 run_lib.py:167] step: 64200, eval_loss: 7.16590e-04
I0512 07:46:58.129472 22485033404224 run_lib.py:146] step: 64250, training_loss: 5.88037e-04
I0512 07:47:21.958626 22485033404224 run_lib.py:146] step: 64300, training_loss: 4.79905e-04
I0512 07:47:22.117439 22485033404224 run_lib.py:167] step: 64300, eval_loss: 7.25710e-04
I0512 07:47:45.640346 22485033404224 run_lib.py:146] step: 64350, training_loss: 5.84585e-04
I0512 07:48:09.451515 22485033404224 run_lib.py:146] step: 64400, training_loss: 6.02959e-04
I0512 07:48:09.610379 22485033404224 run_lib.py:167] step: 64400, eval_loss: 8.11969e-04
I0512 07:48:33.196371 22485033404224 run_lib.py:146] step: 64450, training_loss: 6.07286e-04
I0512 07:48:57.128219 22485033404224 run_lib.py:146] step: 64500, training_loss: 5.85703e-04
I0512 07:48:57.288650 22485033404224 run_lib.py:167] step: 64500, eval_loss: 6.53584e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 07:49:20.975762 22485033404224 run_lib.py:146] step: 64550, training_loss: 6.82155e-04
I0512 07:49:44.931890 22485033404224 run_lib.py:146] step: 64600, training_loss: 5.46233e-04
I0512 07:49:45.093622 22485033404224 run_lib.py:167] step: 64600, eval_loss: 5.22011e-04
I0512 07:50:09.018905 22485033404224 run_lib.py:146] step: 64650, training_loss: 5.62023e-04
I0512 07:50:32.637241 22485033404224 run_lib.py:146] step: 64700, training_loss: 5.16525e-04
I0512 07:50:32.797704 22485033404224 run_lib.py:167] step: 64700, eval_loss: 7.21483e-04
I0512 07:50:56.668613 22485033404224 run_lib.py:146] step: 64750, training_loss: 5.28387e-04
I0512 07:51:20.566570 22485033404224 run_lib.py:146] step: 64800, training_loss: 7.81158e-04
I0512 07:51:20.726035 22485033404224 run_lib.py:167] step: 64800, eval_loss: 6.07909e-04
I0512 07:51:44.296457 22485033404224 run_lib.py:146] step: 64850, training_loss: 7.97981e-04
I0512 07:52:08.211322 22485033404224 run_lib.py:146] step: 64900, training_loss: 7.33366e-04
I0512 07:52:08.371184 22485033404224 run_lib.py:167] step: 64900, eval_loss: 6.67321e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 07:52:32.587231 22485033404224 run_lib.py:146] step: 64950, training_loss: 6.21535e-04
I0512 07:52:56.296031 22485033404224 run_lib.py:146] step: 65000, training_loss: 4.89854e-04
I0512 07:52:56.457655 22485033404224 run_lib.py:167] step: 65000, eval_loss: 4.74158e-04
I0512 07:53:20.492649 22485033404224 run_lib.py:146] step: 65050, training_loss: 6.73644e-04
I0512 07:53:44.536076 22485033404224 run_lib.py:146] step: 65100, training_loss: 7.24534e-04
I0512 07:53:44.697245 22485033404224 run_lib.py:167] step: 65100, eval_loss: 5.07131e-04
I0512 07:54:08.410130 22485033404224 run_lib.py:146] step: 65150, training_loss: 6.14422e-04
I0512 07:54:32.453431 22485033404224 run_lib.py:146] step: 65200, training_loss: 6.70436e-04
I0512 07:54:32.613833 22485033404224 run_lib.py:167] step: 65200, eval_loss: 4.46621e-04
I0512 07:54:56.287479 22485033404224 run_lib.py:146] step: 65250, training_loss: 6.67382e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 07:55:20.405105 22485033404224 run_lib.py:146] step: 65300, training_loss: 6.05546e-04
I0512 07:55:20.566325 22485033404224 run_lib.py:167] step: 65300, eval_loss: 6.31264e-04
I0512 07:55:44.532313 22485033404224 run_lib.py:146] step: 65350, training_loss: 6.59040e-04
I0512 07:56:08.091184 22485033404224 run_lib.py:146] step: 65400, training_loss: 6.15047e-04
I0512 07:56:08.251178 22485033404224 run_lib.py:167] step: 65400, eval_loss: 8.71279e-04
I0512 07:56:32.093553 22485033404224 run_lib.py:146] step: 65450, training_loss: 4.91830e-04
I0512 07:56:55.606963 22485033404224 run_lib.py:146] step: 65500, training_loss: 7.33081e-04
I0512 07:56:55.767847 22485033404224 run_lib.py:167] step: 65500, eval_loss: 5.53159e-04
I0512 07:57:19.560587 22485033404224 run_lib.py:146] step: 65550, training_loss: 5.96993e-04
I0512 07:57:43.360642 22485033404224 run_lib.py:146] step: 65600, training_loss: 6.80837e-04
I0512 07:57:43.520409 22485033404224 run_lib.py:167] step: 65600, eval_loss: 6.86289e-04
I0512 07:58:07.021585 22485033404224 run_lib.py:146] step: 65650, training_loss: 6.08797e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 07:58:30.931562 22485033404224 run_lib.py:146] step: 65700, training_loss: 7.51165e-04
I0512 07:58:31.092582 22485033404224 run_lib.py:167] step: 65700, eval_loss: 5.93029e-04
I0512 07:58:54.940325 22485033404224 run_lib.py:146] step: 65750, training_loss: 7.68660e-04
I0512 07:59:18.449217 22485033404224 run_lib.py:146] step: 65800, training_loss: 8.08181e-04
I0512 07:59:18.608374 22485033404224 run_lib.py:167] step: 65800, eval_loss: 5.80495e-04
I0512 07:59:42.484227 22485033404224 run_lib.py:146] step: 65850, training_loss: 5.55136e-04
I0512 08:00:06.299969 22485033404224 run_lib.py:146] step: 65900, training_loss: 6.39765e-04
I0512 08:00:06.459188 22485033404224 run_lib.py:167] step: 65900, eval_loss: 6.38563e-04
I0512 08:00:29.987901 22485033404224 run_lib.py:146] step: 65950, training_loss: 4.97947e-04
I0512 08:00:53.807475 22485033404224 run_lib.py:146] step: 66000, training_loss: 4.83287e-04
I0512 08:00:53.966068 22485033404224 run_lib.py:167] step: 66000, eval_loss: 5.15682e-04
I0512 08:01:17.833200 22485033404224 run_lib.py:146] step: 66050, training_loss: 5.16319e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 08:01:41.434036 22485033404224 run_lib.py:146] step: 66100, training_loss: 6.34676e-04
I0512 08:01:41.595666 22485033404224 run_lib.py:167] step: 66100, eval_loss: 5.83536e-04
I0512 08:02:05.462107 22485033404224 run_lib.py:146] step: 66150, training_loss: 5.84490e-04
I0512 08:02:28.996202 22485033404224 run_lib.py:146] step: 66200, training_loss: 6.94013e-04
I0512 08:02:29.155275 22485033404224 run_lib.py:167] step: 66200, eval_loss: 5.80530e-04
I0512 08:02:53.058530 22485033404224 run_lib.py:146] step: 66250, training_loss: 4.92211e-04
I0512 08:03:16.586792 22485033404224 run_lib.py:146] step: 66300, training_loss: 6.93306e-04
I0512 08:03:16.746284 22485033404224 run_lib.py:167] step: 66300, eval_loss: 6.33814e-04
I0512 08:03:40.572396 22485033404224 run_lib.py:146] step: 66350, training_loss: 6.23793e-04
I0512 08:04:04.422076 22485033404224 run_lib.py:146] step: 66400, training_loss: 6.99791e-04
I0512 08:04:04.581275 22485033404224 run_lib.py:167] step: 66400, eval_loss: 6.00197e-04
I0512 08:04:28.111845 22485033404224 run_lib.py:146] step: 66450, training_loss: 8.18409e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 08:04:52.023328 22485033404224 run_lib.py:146] step: 66500, training_loss: 5.22329e-04
I0512 08:04:52.184195 22485033404224 run_lib.py:167] step: 66500, eval_loss: 6.72707e-04
I0512 08:05:16.077620 22485033404224 run_lib.py:146] step: 66550, training_loss: 7.47650e-04
I0512 08:05:39.619398 22485033404224 run_lib.py:146] step: 66600, training_loss: 5.74856e-04
I0512 08:05:39.779203 22485033404224 run_lib.py:167] step: 66600, eval_loss: 7.17511e-04
I0512 08:06:03.629205 22485033404224 run_lib.py:146] step: 66650, training_loss: 6.29682e-04
I0512 08:06:27.445645 22485033404224 run_lib.py:146] step: 66700, training_loss: 5.36189e-04
I0512 08:06:27.605889 22485033404224 run_lib.py:167] step: 66700, eval_loss: 6.11480e-04
I0512 08:06:51.207756 22485033404224 run_lib.py:146] step: 66750, training_loss: 5.49311e-04
I0512 08:07:15.088981 22485033404224 run_lib.py:146] step: 66800, training_loss: 1.01981e-03
I0512 08:07:15.248894 22485033404224 run_lib.py:167] step: 66800, eval_loss: 4.78037e-04
I0512 08:07:39.138650 22485033404224 run_lib.py:146] step: 66850, training_loss: 7.78261e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 08:08:02.810234 22485033404224 run_lib.py:146] step: 66900, training_loss: 8.05023e-04
I0512 08:08:02.972795 22485033404224 run_lib.py:167] step: 66900, eval_loss: 6.59743e-04
I0512 08:08:26.915303 22485033404224 run_lib.py:146] step: 66950, training_loss: 5.19606e-04
I0512 08:08:50.907466 22485033404224 run_lib.py:146] step: 67000, training_loss: 6.91121e-04
I0512 08:08:51.067991 22485033404224 run_lib.py:167] step: 67000, eval_loss: 5.82526e-04
I0512 08:09:14.666711 22485033404224 run_lib.py:146] step: 67050, training_loss: 5.74151e-04
I0512 08:09:38.255451 22485033404224 run_lib.py:146] step: 67100, training_loss: 5.10964e-04
I0512 08:09:38.416330 22485033404224 run_lib.py:167] step: 67100, eval_loss: 6.42565e-04
I0512 08:10:02.277480 22485033404224 run_lib.py:146] step: 67150, training_loss: 5.78684e-04
I0512 08:10:26.172902 22485033404224 run_lib.py:146] step: 67200, training_loss: 7.54108e-04
I0512 08:10:26.334449 22485033404224 run_lib.py:167] step: 67200, eval_loss: 6.85181e-04
I0512 08:10:49.952366 22485033404224 run_lib.py:146] step: 67250, training_loss: 6.50618e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 08:11:13.978085 22485033404224 run_lib.py:146] step: 67300, training_loss: 4.28834e-04
I0512 08:11:14.141065 22485033404224 run_lib.py:167] step: 67300, eval_loss: 5.25548e-04
I0512 08:11:38.127976 22485033404224 run_lib.py:146] step: 67350, training_loss: 7.26178e-04
I0512 08:12:01.729995 22485033404224 run_lib.py:146] step: 67400, training_loss: 6.08697e-04
I0512 08:12:01.891412 22485033404224 run_lib.py:167] step: 67400, eval_loss: 5.90038e-04
I0512 08:12:25.785143 22485033404224 run_lib.py:146] step: 67450, training_loss: 5.54362e-04
I0512 08:12:49.775683 22485033404224 run_lib.py:146] step: 67500, training_loss: 5.34051e-04
I0512 08:12:49.936641 22485033404224 run_lib.py:167] step: 67500, eval_loss: 4.56335e-04
I0512 08:13:13.517185 22485033404224 run_lib.py:146] step: 67550, training_loss: 5.87201e-04
I0512 08:13:37.424125 22485033404224 run_lib.py:146] step: 67600, training_loss: 5.91805e-04
I0512 08:13:37.584169 22485033404224 run_lib.py:167] step: 67600, eval_loss: 5.44319e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 08:14:01.614179 22485033404224 run_lib.py:146] step: 67650, training_loss: 5.39472e-04
I0512 08:14:25.155816 22485033404224 run_lib.py:146] step: 67700, training_loss: 5.95575e-04
I0512 08:14:25.316725 22485033404224 run_lib.py:167] step: 67700, eval_loss: 5.67505e-04
I0512 08:14:49.203044 22485033404224 run_lib.py:146] step: 67750, training_loss: 6.05439e-04
I0512 08:15:13.080180 22485033404224 run_lib.py:146] step: 67800, training_loss: 6.13562e-04
I0512 08:15:13.240767 22485033404224 run_lib.py:167] step: 67800, eval_loss: 8.58764e-04
I0512 08:15:36.748200 22485033404224 run_lib.py:146] step: 67850, training_loss: 7.03586e-04
I0512 08:16:00.272079 22485033404224 run_lib.py:146] step: 67900, training_loss: 5.80674e-04
I0512 08:16:00.432959 22485033404224 run_lib.py:167] step: 67900, eval_loss: 9.44757e-04
I0512 08:16:24.261670 22485033404224 run_lib.py:146] step: 67950, training_loss: 5.41913e-04
I0512 08:16:48.139481 22485033404224 run_lib.py:146] step: 68000, training_loss: 7.87829e-04
I0512 08:16:48.298876 22485033404224 run_lib.py:167] step: 68000, eval_loss: 6.88672e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 08:17:11.878241 22485033404224 run_lib.py:146] step: 68050, training_loss: 6.30829e-04
I0512 08:17:35.745143 22485033404224 run_lib.py:146] step: 68100, training_loss: 6.33521e-04
I0512 08:17:35.904777 22485033404224 run_lib.py:167] step: 68100, eval_loss: 5.85084e-04
I0512 08:17:59.763215 22485033404224 run_lib.py:146] step: 68150, training_loss: 7.10278e-04
I0512 08:18:23.277578 22485033404224 run_lib.py:146] step: 68200, training_loss: 8.07309e-04
I0512 08:18:23.437033 22485033404224 run_lib.py:167] step: 68200, eval_loss: 6.61830e-04
I0512 08:18:47.267855 22485033404224 run_lib.py:146] step: 68250, training_loss: 6.06675e-04
I0512 08:19:11.111660 22485033404224 run_lib.py:146] step: 68300, training_loss: 8.36537e-04
I0512 08:19:11.270776 22485033404224 run_lib.py:167] step: 68300, eval_loss: 7.31394e-04
I0512 08:19:34.794350 22485033404224 run_lib.py:146] step: 68350, training_loss: 6.08022e-04
I0512 08:19:58.611227 22485033404224 run_lib.py:146] step: 68400, training_loss: 6.44982e-04
I0512 08:19:58.770829 22485033404224 run_lib.py:167] step: 68400, eval_loss: 8.15737e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 08:20:22.725112 22485033404224 run_lib.py:146] step: 68450, training_loss: 6.38097e-04
I0512 08:20:46.258274 22485033404224 run_lib.py:146] step: 68500, training_loss: 6.70014e-04
I0512 08:20:46.419595 22485033404224 run_lib.py:167] step: 68500, eval_loss: 4.17105e-04
I0512 08:21:10.284914 22485033404224 run_lib.py:146] step: 68550, training_loss: 6.25693e-04
I0512 08:21:34.137491 22485033404224 run_lib.py:146] step: 68600, training_loss: 8.61497e-04
I0512 08:21:34.297247 22485033404224 run_lib.py:167] step: 68600, eval_loss: 6.32556e-04
I0512 08:21:57.846300 22485033404224 run_lib.py:146] step: 68650, training_loss: 6.30241e-04
I0512 08:22:21.715479 22485033404224 run_lib.py:146] step: 68700, training_loss: 7.48927e-04
I0512 08:22:21.875277 22485033404224 run_lib.py:167] step: 68700, eval_loss: 6.69740e-04
I0512 08:22:45.413449 22485033404224 run_lib.py:146] step: 68750, training_loss: 5.80342e-04
I0512 08:23:09.278461 22485033404224 run_lib.py:146] step: 68800, training_loss: 7.33420e-04
I0512 08:23:09.438698 22485033404224 run_lib.py:167] step: 68800, eval_loss: 6.20648e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 08:23:33.066632 22485033404224 run_lib.py:146] step: 68850, training_loss: 6.32298e-04
I0512 08:23:56.928216 22485033404224 run_lib.py:146] step: 68900, training_loss: 5.64336e-04
I0512 08:23:57.090722 22485033404224 run_lib.py:167] step: 68900, eval_loss: 5.65984e-04
I0512 08:24:20.945117 22485033404224 run_lib.py:146] step: 68950, training_loss: 5.28195e-04
I0512 08:24:44.539694 22485033404224 run_lib.py:146] step: 69000, training_loss: 3.96699e-04
I0512 08:24:44.700963 22485033404224 run_lib.py:167] step: 69000, eval_loss: 5.02301e-04
I0512 08:25:08.601188 22485033404224 run_lib.py:146] step: 69050, training_loss: 6.92788e-04
I0512 08:25:32.518905 22485033404224 run_lib.py:146] step: 69100, training_loss: 4.91855e-04
I0512 08:25:32.679487 22485033404224 run_lib.py:167] step: 69100, eval_loss: 6.03359e-04
I0512 08:25:56.271925 22485033404224 run_lib.py:146] step: 69150, training_loss: 5.08226e-04
I0512 08:26:20.182656 22485033404224 run_lib.py:146] step: 69200, training_loss: 6.60950e-04
I0512 08:26:20.343379 22485033404224 run_lib.py:167] step: 69200, eval_loss: 7.49067e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 08:26:44.357079 22485033404224 run_lib.py:146] step: 69250, training_loss: 4.84910e-04
I0512 08:27:07.888363 22485033404224 run_lib.py:146] step: 69300, training_loss: 6.85382e-04
I0512 08:27:08.050147 22485033404224 run_lib.py:167] step: 69300, eval_loss: 5.29251e-04
I0512 08:27:31.952316 22485033404224 run_lib.py:146] step: 69350, training_loss: 7.04755e-04
I0512 08:27:55.820044 22485033404224 run_lib.py:146] step: 69400, training_loss: 6.53358e-04
I0512 08:27:55.981470 22485033404224 run_lib.py:167] step: 69400, eval_loss: 4.65097e-04
I0512 08:28:19.588272 22485033404224 run_lib.py:146] step: 69450, training_loss: 6.05975e-04
I0512 08:28:43.506543 22485033404224 run_lib.py:146] step: 69500, training_loss: 6.01723e-04
I0512 08:28:43.667917 22485033404224 run_lib.py:167] step: 69500, eval_loss: 4.42800e-04
I0512 08:29:07.569263 22485033404224 run_lib.py:146] step: 69550, training_loss: 6.76359e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 08:29:31.233032 22485033404224 run_lib.py:146] step: 69600, training_loss: 6.45666e-04
I0512 08:29:31.395226 22485033404224 run_lib.py:167] step: 69600, eval_loss: 5.82379e-04
I0512 08:29:55.405610 22485033404224 run_lib.py:146] step: 69650, training_loss: 7.55683e-04
I0512 08:30:19.036060 22485033404224 run_lib.py:146] step: 69700, training_loss: 6.71901e-04
I0512 08:30:19.198248 22485033404224 run_lib.py:167] step: 69700, eval_loss: 6.12867e-04
I0512 08:30:43.155592 22485033404224 run_lib.py:146] step: 69750, training_loss: 6.75698e-04
I0512 08:31:06.761599 22485033404224 run_lib.py:146] step: 69800, training_loss: 4.45857e-04
I0512 08:31:06.922524 22485033404224 run_lib.py:167] step: 69800, eval_loss: 5.70350e-04
I0512 08:31:30.833173 22485033404224 run_lib.py:146] step: 69850, training_loss: 7.59812e-04
I0512 08:31:54.738381 22485033404224 run_lib.py:146] step: 69900, training_loss: 6.92532e-04
I0512 08:31:54.899399 22485033404224 run_lib.py:167] step: 69900, eval_loss: 6.43554e-04
I0512 08:32:18.452551 22485033404224 run_lib.py:146] step: 69950, training_loss: 5.18532e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 08:32:42.356577 22485033404224 run_lib.py:146] step: 70000, training_loss: 7.02733e-04
I0512 08:32:44.142354 22485033404224 run_lib.py:167] step: 70000, eval_loss: 5.10414e-04
I0512 08:33:09.514144 22485033404224 run_lib.py:146] step: 70050, training_loss: 5.14229e-04
I0512 08:33:33.394550 22485033404224 run_lib.py:146] step: 70100, training_loss: 5.54573e-04
I0512 08:33:33.553773 22485033404224 run_lib.py:167] step: 70100, eval_loss: 7.25377e-04
I0512 08:33:57.089419 22485033404224 run_lib.py:146] step: 70150, training_loss: 6.18309e-04
I0512 08:34:20.946344 22485033404224 run_lib.py:146] step: 70200, training_loss: 7.61432e-04
I0512 08:34:21.105122 22485033404224 run_lib.py:167] step: 70200, eval_loss: 5.13733e-04
I0512 08:34:44.944903 22485033404224 run_lib.py:146] step: 70250, training_loss: 6.27316e-04
I0512 08:35:08.492857 22485033404224 run_lib.py:146] step: 70300, training_loss: 7.19713e-04
I0512 08:35:08.652892 22485033404224 run_lib.py:167] step: 70300, eval_loss: 6.47366e-04
I0512 08:35:32.472531 22485033404224 run_lib.py:146] step: 70350, training_loss: 5.78164e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 08:35:56.087939 22485033404224 run_lib.py:146] step: 70400, training_loss: 6.83201e-04
I0512 08:35:56.251195 22485033404224 run_lib.py:167] step: 70400, eval_loss: 6.56633e-04
I0512 08:36:20.141039 22485033404224 run_lib.py:146] step: 70450, training_loss: 7.79960e-04
I0512 08:36:43.696591 22485033404224 run_lib.py:146] step: 70500, training_loss: 6.21764e-04
I0512 08:36:43.856543 22485033404224 run_lib.py:167] step: 70500, eval_loss: 4.94917e-04
I0512 08:37:07.733302 22485033404224 run_lib.py:146] step: 70550, training_loss: 8.04155e-04
I0512 08:37:31.557945 22485033404224 run_lib.py:146] step: 70600, training_loss: 6.13511e-04
I0512 08:37:31.718010 22485033404224 run_lib.py:167] step: 70600, eval_loss: 7.32448e-04
I0512 08:37:55.243190 22485033404224 run_lib.py:146] step: 70650, training_loss: 8.47975e-04
I0512 08:38:19.076642 22485033404224 run_lib.py:146] step: 70700, training_loss: 6.07592e-04
I0512 08:38:19.234948 22485033404224 run_lib.py:167] step: 70700, eval_loss: 5.10580e-04
I0512 08:38:43.054612 22485033404224 run_lib.py:146] step: 70750, training_loss: 8.09045e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 08:39:06.667220 22485033404224 run_lib.py:146] step: 70800, training_loss: 8.22157e-04
I0512 08:39:06.827887 22485033404224 run_lib.py:167] step: 70800, eval_loss: 5.96194e-04
I0512 08:39:30.689335 22485033404224 run_lib.py:146] step: 70850, training_loss: 6.01817e-04
I0512 08:39:54.532556 22485033404224 run_lib.py:146] step: 70900, training_loss: 6.90120e-04
I0512 08:39:54.692197 22485033404224 run_lib.py:167] step: 70900, eval_loss: 4.63201e-04
I0512 08:40:18.192588 22485033404224 run_lib.py:146] step: 70950, training_loss: 6.92674e-04
I0512 08:40:41.983725 22485033404224 run_lib.py:146] step: 71000, training_loss: 7.74916e-04
I0512 08:40:42.070065 22485033404224 run_lib.py:167] step: 71000, eval_loss: 6.90396e-04
I0512 08:41:05.882170 22485033404224 run_lib.py:146] step: 71050, training_loss: 8.14606e-04
I0512 08:41:29.412020 22485033404224 run_lib.py:146] step: 71100, training_loss: 6.00346e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 08:41:29.760316 22485033404224 run_lib.py:167] step: 71100, eval_loss: 6.03359e-04
I0512 08:41:53.669024 22485033404224 run_lib.py:146] step: 71150, training_loss: 4.82371e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 08:42:17.665577 22485033404224 run_lib.py:146] step: 71200, training_loss: 4.19290e-04
I0512 08:42:17.826086 22485033404224 run_lib.py:167] step: 71200, eval_loss: 5.84561e-04
I0512 08:42:41.385001 22485033404224 run_lib.py:146] step: 71250, training_loss: 6.83175e-04
I0512 08:43:04.981888 22485033404224 run_lib.py:146] step: 71300, training_loss: 6.08427e-04
I0512 08:43:05.142384 22485033404224 run_lib.py:167] step: 71300, eval_loss: 6.78604e-04
I0512 08:43:29.089827 22485033404224 run_lib.py:146] step: 71350, training_loss: 6.82318e-04
I0512 08:43:52.995920 22485033404224 run_lib.py:146] step: 71400, training_loss: 6.34296e-04
I0512 08:43:53.156683 22485033404224 run_lib.py:167] step: 71400, eval_loss: 6.39740e-04
I0512 08:44:16.759572 22485033404224 run_lib.py:146] step: 71450, training_loss: 7.27920e-04
I0512 08:44:40.649610 22485033404224 run_lib.py:146] step: 71500, training_loss: 5.56800e-04
I0512 08:44:40.809944 22485033404224 run_lib.py:167] step: 71500, eval_loss: 4.93727e-04
I0512 08:45:04.694698 22485033404224 run_lib.py:146] step: 71550, training_loss: 5.61080e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 08:45:28.630396 22485033404224 run_lib.py:146] step: 71600, training_loss: 5.41465e-04
I0512 08:45:28.794897 22485033404224 run_lib.py:167] step: 71600, eval_loss: 5.85041e-04
I0512 08:45:53.167912 22485033404224 run_lib.py:146] step: 71650, training_loss: 6.43964e-04
I0512 08:46:17.391955 22485033404224 run_lib.py:146] step: 71700, training_loss: 6.55672e-04
I0512 08:46:17.553642 22485033404224 run_lib.py:167] step: 71700, eval_loss: 5.26218e-04
I0512 08:46:41.349675 22485033404224 run_lib.py:146] step: 71750, training_loss: 5.96802e-04
I0512 08:47:05.578298 22485033404224 run_lib.py:146] step: 71800, training_loss: 5.21844e-04
I0512 08:47:05.740653 22485033404224 run_lib.py:167] step: 71800, eval_loss: 6.54466e-04
I0512 08:47:29.619099 22485033404224 run_lib.py:146] step: 71850, training_loss: 5.56680e-04
I0512 08:47:53.218444 22485033404224 run_lib.py:146] step: 71900, training_loss: 7.68327e-04
I0512 08:47:53.378665 22485033404224 run_lib.py:167] step: 71900, eval_loss: 6.66883e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 08:48:17.387461 22485033404224 run_lib.py:146] step: 71950, training_loss: 5.58236e-04
I0512 08:48:41.452733 22485033404224 run_lib.py:146] step: 72000, training_loss: 4.82935e-04
I0512 08:48:41.614718 22485033404224 run_lib.py:167] step: 72000, eval_loss: 7.14156e-04
I0512 08:49:05.247488 22485033404224 run_lib.py:146] step: 72050, training_loss: 5.55766e-04
I0512 08:49:29.221746 22485033404224 run_lib.py:146] step: 72100, training_loss: 6.34936e-04
I0512 08:49:29.384667 22485033404224 run_lib.py:167] step: 72100, eval_loss: 7.11815e-04
I0512 08:49:52.960150 22485033404224 run_lib.py:146] step: 72150, training_loss: 6.01618e-04
I0512 08:50:16.874080 22485033404224 run_lib.py:146] step: 72200, training_loss: 6.27890e-04
I0512 08:50:17.033801 22485033404224 run_lib.py:167] step: 72200, eval_loss: 7.20333e-04
I0512 08:50:40.585709 22485033404224 run_lib.py:146] step: 72250, training_loss: 6.91250e-04
I0512 08:51:04.410505 22485033404224 run_lib.py:146] step: 72300, training_loss: 5.79828e-04
I0512 08:51:04.569576 22485033404224 run_lib.py:167] step: 72300, eval_loss: 5.62658e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 08:51:28.427896 22485033404224 run_lib.py:146] step: 72350, training_loss: 5.54721e-04
I0512 08:51:51.955575 22485033404224 run_lib.py:146] step: 72400, training_loss: 6.71660e-04
I0512 08:51:52.115760 22485033404224 run_lib.py:167] step: 72400, eval_loss: 5.45120e-04
I0512 08:52:15.947718 22485033404224 run_lib.py:146] step: 72450, training_loss: 6.34113e-04
I0512 08:52:39.772362 22485033404224 run_lib.py:146] step: 72500, training_loss: 5.20567e-04
I0512 08:52:39.931333 22485033404224 run_lib.py:167] step: 72500, eval_loss: 7.45716e-04
I0512 08:53:03.441328 22485033404224 run_lib.py:146] step: 72550, training_loss: 5.96903e-04
I0512 08:53:27.264071 22485033404224 run_lib.py:146] step: 72600, training_loss: 6.58293e-04
I0512 08:53:27.425159 22485033404224 run_lib.py:167] step: 72600, eval_loss: 8.00132e-04
I0512 08:53:51.245992 22485033404224 run_lib.py:146] step: 72650, training_loss: 4.90058e-04
I0512 08:54:14.782531 22485033404224 run_lib.py:146] step: 72700, training_loss: 6.12725e-04
I0512 08:54:14.942919 22485033404224 run_lib.py:167] step: 72700, eval_loss: 5.94417e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 08:54:38.884849 22485033404224 run_lib.py:146] step: 72750, training_loss: 6.21531e-04
I0512 08:55:02.762011 22485033404224 run_lib.py:146] step: 72800, training_loss: 5.32414e-04
I0512 08:55:02.922267 22485033404224 run_lib.py:167] step: 72800, eval_loss: 3.97997e-04
I0512 08:55:26.454781 22485033404224 run_lib.py:146] step: 72850, training_loss: 6.55932e-04
I0512 08:55:50.283987 22485033404224 run_lib.py:146] step: 72900, training_loss: 7.82496e-04
I0512 08:55:50.443422 22485033404224 run_lib.py:167] step: 72900, eval_loss: 5.19798e-04
I0512 08:56:14.313224 22485033404224 run_lib.py:146] step: 72950, training_loss: 6.46523e-04
I0512 08:56:37.861625 22485033404224 run_lib.py:146] step: 73000, training_loss: 5.00552e-04
I0512 08:56:38.021581 22485033404224 run_lib.py:167] step: 73000, eval_loss: 6.50182e-04
I0512 08:57:01.553036 22485033404224 run_lib.py:146] step: 73050, training_loss: 7.72942e-04
I0512 08:57:25.413313 22485033404224 run_lib.py:146] step: 73100, training_loss: 4.92137e-04
I0512 08:57:25.572444 22485033404224 run_lib.py:167] step: 73100, eval_loss: 5.17334e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 08:57:49.454813 22485033404224 run_lib.py:146] step: 73150, training_loss: 5.82844e-04
I0512 08:58:12.986238 22485033404224 run_lib.py:146] step: 73200, training_loss: 6.10018e-04
I0512 08:58:13.146921 22485033404224 run_lib.py:167] step: 73200, eval_loss: 5.41801e-04
I0512 08:58:37.019102 22485033404224 run_lib.py:146] step: 73250, training_loss: 4.71345e-04
I0512 08:59:00.846611 22485033404224 run_lib.py:146] step: 73300, training_loss: 5.51417e-04
I0512 08:59:01.005558 22485033404224 run_lib.py:167] step: 73300, eval_loss: 8.70975e-04
I0512 08:59:24.562361 22485033404224 run_lib.py:146] step: 73350, training_loss: 6.62540e-04
I0512 08:59:48.407765 22485033404224 run_lib.py:146] step: 73400, training_loss: 7.06339e-04
I0512 08:59:48.567238 22485033404224 run_lib.py:167] step: 73400, eval_loss: 6.16115e-04
I0512 09:00:12.415763 22485033404224 run_lib.py:146] step: 73450, training_loss: 5.24964e-04
I0512 09:00:36.037087 22485033404224 run_lib.py:146] step: 73500, training_loss: 6.02717e-04
I0512 09:00:36.198541 22485033404224 run_lib.py:167] step: 73500, eval_loss: 5.42755e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 09:01:00.229665 22485033404224 run_lib.py:146] step: 73550, training_loss: 5.59993e-04
I0512 09:01:24.172368 22485033404224 run_lib.py:146] step: 73600, training_loss: 5.66329e-04
I0512 09:01:24.334856 22485033404224 run_lib.py:167] step: 73600, eval_loss: 4.95429e-04
I0512 09:01:47.958925 22485033404224 run_lib.py:146] step: 73650, training_loss: 6.13878e-04
I0512 09:02:11.880620 22485033404224 run_lib.py:146] step: 73700, training_loss: 6.69628e-04
I0512 09:02:12.040891 22485033404224 run_lib.py:167] step: 73700, eval_loss: 7.05419e-04
I0512 09:02:35.965196 22485033404224 run_lib.py:146] step: 73750, training_loss: 5.21047e-04
I0512 09:02:59.573018 22485033404224 run_lib.py:146] step: 73800, training_loss: 6.75937e-04
I0512 09:02:59.734039 22485033404224 run_lib.py:167] step: 73800, eval_loss: 4.52572e-04
I0512 09:03:23.588164 22485033404224 run_lib.py:146] step: 73850, training_loss: 4.99078e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 09:03:47.248398 22485033404224 run_lib.py:146] step: 73900, training_loss: 6.50641e-04
I0512 09:03:47.410151 22485033404224 run_lib.py:167] step: 73900, eval_loss: 4.96439e-04
I0512 09:04:11.312529 22485033404224 run_lib.py:146] step: 73950, training_loss: 5.98530e-04
I0512 09:04:34.927291 22485033404224 run_lib.py:146] step: 74000, training_loss: 6.86823e-04
I0512 09:04:35.087503 22485033404224 run_lib.py:167] step: 74000, eval_loss: 4.96216e-04
I0512 09:04:59.003863 22485033404224 run_lib.py:146] step: 74050, training_loss: 7.23832e-04
I0512 09:05:22.879343 22485033404224 run_lib.py:146] step: 74100, training_loss: 6.47532e-04
I0512 09:05:23.039978 22485033404224 run_lib.py:167] step: 74100, eval_loss: 6.15134e-04
I0512 09:05:46.668980 22485033404224 run_lib.py:146] step: 74150, training_loss: 8.51599e-04
I0512 09:06:10.595041 22485033404224 run_lib.py:146] step: 74200, training_loss: 7.00832e-04
I0512 09:06:10.755297 22485033404224 run_lib.py:167] step: 74200, eval_loss: 7.15012e-04
I0512 09:06:34.664016 22485033404224 run_lib.py:146] step: 74250, training_loss: 7.44924e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 09:06:58.368230 22485033404224 run_lib.py:146] step: 74300, training_loss: 6.07926e-04
I0512 09:06:58.530517 22485033404224 run_lib.py:167] step: 74300, eval_loss: 6.66328e-04
I0512 09:07:22.449489 22485033404224 run_lib.py:146] step: 74350, training_loss: 6.34928e-04
I0512 09:07:46.322933 22485033404224 run_lib.py:146] step: 74400, training_loss: 7.60269e-04
I0512 09:07:46.481990 22485033404224 run_lib.py:167] step: 74400, eval_loss: 4.95878e-04
I0512 09:08:10.040693 22485033404224 run_lib.py:146] step: 74450, training_loss: 8.41995e-04
I0512 09:08:33.887533 22485033404224 run_lib.py:146] step: 74500, training_loss: 6.12095e-04
I0512 09:08:34.048130 22485033404224 run_lib.py:167] step: 74500, eval_loss: 6.52943e-04
I0512 09:08:57.877427 22485033404224 run_lib.py:146] step: 74550, training_loss: 6.87976e-04
I0512 09:09:21.398680 22485033404224 run_lib.py:146] step: 74600, training_loss: 6.24129e-04
I0512 09:09:21.558491 22485033404224 run_lib.py:167] step: 74600, eval_loss: 6.96373e-04
I0512 09:09:45.388422 22485033404224 run_lib.py:146] step: 74650, training_loss: 5.87494e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 09:10:09.353728 22485033404224 run_lib.py:146] step: 74700, training_loss: 4.99130e-04
I0512 09:10:09.513391 22485033404224 run_lib.py:167] step: 74700, eval_loss: 5.82532e-04
I0512 09:10:33.037945 22485033404224 run_lib.py:146] step: 74750, training_loss: 5.33439e-04
I0512 09:10:56.544488 22485033404224 run_lib.py:146] step: 74800, training_loss: 6.78908e-04
I0512 09:10:56.703505 22485033404224 run_lib.py:167] step: 74800, eval_loss: 5.23325e-04
I0512 09:11:20.539951 22485033404224 run_lib.py:146] step: 74850, training_loss: 7.99325e-04
I0512 09:11:44.390053 22485033404224 run_lib.py:146] step: 74900, training_loss: 7.68215e-04
I0512 09:11:44.548628 22485033404224 run_lib.py:167] step: 74900, eval_loss: 6.35009e-04
I0512 09:12:08.072002 22485033404224 run_lib.py:146] step: 74950, training_loss: 6.00247e-04
I0512 09:12:31.904574 22485033404224 run_lib.py:146] step: 75000, training_loss: 6.35546e-04
I0512 09:12:32.064611 22485033404224 run_lib.py:167] step: 75000, eval_loss: 6.63951e-04
I0512 09:12:55.884356 22485033404224 run_lib.py:146] step: 75050, training_loss: 6.35716e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 09:13:19.496253 22485033404224 run_lib.py:146] step: 75100, training_loss: 4.84970e-04
I0512 09:13:19.657920 22485033404224 run_lib.py:167] step: 75100, eval_loss: 3.98056e-04
I0512 09:13:43.527584 22485033404224 run_lib.py:146] step: 75150, training_loss: 6.19780e-04
I0512 09:14:07.373461 22485033404224 run_lib.py:146] step: 75200, training_loss: 8.13588e-04
I0512 09:14:07.533096 22485033404224 run_lib.py:167] step: 75200, eval_loss: 5.51167e-04
I0512 09:14:31.035659 22485033404224 run_lib.py:146] step: 75250, training_loss: 6.37218e-04
I0512 09:14:54.875966 22485033404224 run_lib.py:146] step: 75300, training_loss: 6.04208e-04
I0512 09:14:55.035360 22485033404224 run_lib.py:167] step: 75300, eval_loss: 7.52390e-04
I0512 09:15:18.830681 22485033404224 run_lib.py:146] step: 75350, training_loss: 6.10002e-04
I0512 09:15:42.381118 22485033404224 run_lib.py:146] step: 75400, training_loss: 6.38085e-04
I0512 09:15:42.540427 22485033404224 run_lib.py:167] step: 75400, eval_loss: 4.27345e-04
I0512 09:16:06.364782 22485033404224 run_lib.py:146] step: 75450, training_loss: 7.30574e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 09:16:30.347280 22485033404224 run_lib.py:146] step: 75500, training_loss: 8.07048e-04
I0512 09:16:30.507954 22485033404224 run_lib.py:167] step: 75500, eval_loss: 5.40897e-04
I0512 09:16:54.032241 22485033404224 run_lib.py:146] step: 75550, training_loss: 4.79065e-04
I0512 09:17:17.538741 22485033404224 run_lib.py:146] step: 75600, training_loss: 5.28198e-04
I0512 09:17:17.697303 22485033404224 run_lib.py:167] step: 75600, eval_loss: 7.45755e-04
I0512 09:17:41.552130 22485033404224 run_lib.py:146] step: 75650, training_loss: 5.24353e-04
I0512 09:18:05.427498 22485033404224 run_lib.py:146] step: 75700, training_loss: 3.77256e-04
I0512 09:18:05.588275 22485033404224 run_lib.py:167] step: 75700, eval_loss: 7.70463e-04
I0512 09:18:29.199848 22485033404224 run_lib.py:146] step: 75750, training_loss: 5.99615e-04
I0512 09:18:53.134634 22485033404224 run_lib.py:146] step: 75800, training_loss: 7.04170e-04
I0512 09:18:53.295753 22485033404224 run_lib.py:167] step: 75800, eval_loss: 7.34095e-04
I0512 09:19:17.227648 22485033404224 run_lib.py:146] step: 75850, training_loss: 6.17155e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 09:19:40.905056 22485033404224 run_lib.py:146] step: 75900, training_loss: 7.68238e-04
I0512 09:19:41.066905 22485033404224 run_lib.py:167] step: 75900, eval_loss: 5.51363e-04
I0512 09:20:05.023182 22485033404224 run_lib.py:146] step: 75950, training_loss: 6.18194e-04
I0512 09:20:29.063498 22485033404224 run_lib.py:146] step: 76000, training_loss: 6.55265e-04
I0512 09:20:29.223850 22485033404224 run_lib.py:167] step: 76000, eval_loss: 7.54698e-04
I0512 09:20:52.831264 22485033404224 run_lib.py:146] step: 76050, training_loss: 7.16230e-04
I0512 09:21:16.667808 22485033404224 run_lib.py:146] step: 76100, training_loss: 5.79607e-04
I0512 09:21:16.829007 22485033404224 run_lib.py:167] step: 76100, eval_loss: 6.08082e-04
I0512 09:21:40.818083 22485033404224 run_lib.py:146] step: 76150, training_loss: 4.89629e-04
I0512 09:22:04.412295 22485033404224 run_lib.py:146] step: 76200, training_loss: 6.72660e-04
I0512 09:22:04.574232 22485033404224 run_lib.py:167] step: 76200, eval_loss: 7.35735e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 09:22:28.566413 22485033404224 run_lib.py:146] step: 76250, training_loss: 6.80354e-04
I0512 09:22:52.651773 22485033404224 run_lib.py:146] step: 76300, training_loss: 6.16379e-04
I0512 09:22:52.812723 22485033404224 run_lib.py:167] step: 76300, eval_loss: 4.11308e-04
I0512 09:23:16.405216 22485033404224 run_lib.py:146] step: 76350, training_loss: 6.15454e-04
I0512 09:23:39.997430 22485033404224 run_lib.py:146] step: 76400, training_loss: 7.55220e-04
I0512 09:23:40.157133 22485033404224 run_lib.py:167] step: 76400, eval_loss: 6.41814e-04
I0512 09:24:04.150325 22485033404224 run_lib.py:146] step: 76450, training_loss: 6.48308e-04
I0512 09:24:28.052667 22485033404224 run_lib.py:146] step: 76500, training_loss: 7.74167e-04
I0512 09:24:28.213363 22485033404224 run_lib.py:167] step: 76500, eval_loss: 6.34612e-04
I0512 09:24:51.781576 22485033404224 run_lib.py:146] step: 76550, training_loss: 4.25994e-04
I0512 09:25:15.717525 22485033404224 run_lib.py:146] step: 76600, training_loss: 6.86458e-04
I0512 09:25:15.876008 22485033404224 run_lib.py:167] step: 76600, eval_loss: 4.98170e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 09:25:39.731431 22485033404224 run_lib.py:146] step: 76650, training_loss: 6.27021e-04
I0512 09:26:03.268206 22485033404224 run_lib.py:146] step: 76700, training_loss: 7.03320e-04
I0512 09:26:03.428401 22485033404224 run_lib.py:167] step: 76700, eval_loss: 5.31571e-04
I0512 09:26:27.296981 22485033404224 run_lib.py:146] step: 76750, training_loss: 5.63843e-04
I0512 09:26:51.122244 22485033404224 run_lib.py:146] step: 76800, training_loss: 6.64574e-04
I0512 09:26:51.282582 22485033404224 run_lib.py:167] step: 76800, eval_loss: 5.68360e-04
I0512 09:27:14.794185 22485033404224 run_lib.py:146] step: 76850, training_loss: 7.65515e-04
I0512 09:27:38.650120 22485033404224 run_lib.py:146] step: 76900, training_loss: 5.21658e-04
I0512 09:27:38.810766 22485033404224 run_lib.py:167] step: 76900, eval_loss: 6.11061e-04
I0512 09:28:02.633055 22485033404224 run_lib.py:146] step: 76950, training_loss: 5.05650e-04
I0512 09:28:26.151845 22485033404224 run_lib.py:146] step: 77000, training_loss: 5.07996e-04
I0512 09:28:26.310930 22485033404224 run_lib.py:167] step: 77000, eval_loss: 4.81066e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 09:28:50.267235 22485033404224 run_lib.py:146] step: 77050, training_loss: 4.72554e-04
I0512 09:29:14.096110 22485033404224 run_lib.py:146] step: 77100, training_loss: 8.00292e-04
I0512 09:29:14.256543 22485033404224 run_lib.py:167] step: 77100, eval_loss: 8.76086e-04
I0512 09:29:37.772317 22485033404224 run_lib.py:146] step: 77150, training_loss: 6.53925e-04
I0512 09:30:01.607110 22485033404224 run_lib.py:146] step: 77200, training_loss: 5.55268e-04
I0512 09:30:01.767389 22485033404224 run_lib.py:167] step: 77200, eval_loss: 5.51369e-04
I0512 09:30:25.567363 22485033404224 run_lib.py:146] step: 77250, training_loss: 5.78070e-04
I0512 09:30:49.093578 22485033404224 run_lib.py:146] step: 77300, training_loss: 7.18304e-04
I0512 09:30:49.252883 22485033404224 run_lib.py:167] step: 77300, eval_loss: 6.04655e-04
I0512 09:31:12.771698 22485033404224 run_lib.py:146] step: 77350, training_loss: 7.17392e-04
I0512 09:31:36.609200 22485033404224 run_lib.py:146] step: 77400, training_loss: 6.35943e-04
I0512 09:31:36.769008 22485033404224 run_lib.py:167] step: 77400, eval_loss: 5.45148e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 09:32:00.650442 22485033404224 run_lib.py:146] step: 77450, training_loss: 5.08000e-04
I0512 09:32:24.171786 22485033404224 run_lib.py:146] step: 77500, training_loss: 6.26955e-04
I0512 09:32:24.331794 22485033404224 run_lib.py:167] step: 77500, eval_loss: 7.30326e-04
I0512 09:32:48.175338 22485033404224 run_lib.py:146] step: 77550, training_loss: 5.30815e-04
I0512 09:33:12.013915 22485033404224 run_lib.py:146] step: 77600, training_loss: 6.21589e-04
I0512 09:33:12.173880 22485033404224 run_lib.py:167] step: 77600, eval_loss: 5.88237e-04
I0512 09:33:35.725152 22485033404224 run_lib.py:146] step: 77650, training_loss: 7.39486e-04
I0512 09:33:59.566866 22485033404224 run_lib.py:146] step: 77700, training_loss: 8.90297e-04
I0512 09:33:59.727901 22485033404224 run_lib.py:167] step: 77700, eval_loss: 4.91086e-04
I0512 09:34:23.577310 22485033404224 run_lib.py:146] step: 77750, training_loss: 5.34651e-04
I0512 09:34:47.121933 22485033404224 run_lib.py:146] step: 77800, training_loss: 6.50876e-04
I0512 09:34:47.280450 22485033404224 run_lib.py:167] step: 77800, eval_loss: 5.81780e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 09:35:11.252239 22485033404224 run_lib.py:146] step: 77850, training_loss: 5.06842e-04
I0512 09:35:35.172789 22485033404224 run_lib.py:146] step: 77900, training_loss: 8.28380e-04
I0512 09:35:35.334695 22485033404224 run_lib.py:167] step: 77900, eval_loss: 6.29606e-04
I0512 09:35:58.953649 22485033404224 run_lib.py:146] step: 77950, training_loss: 5.97914e-04
I0512 09:36:22.882513 22485033404224 run_lib.py:146] step: 78000, training_loss: 5.56740e-04
I0512 09:36:23.043112 22485033404224 run_lib.py:167] step: 78000, eval_loss: 6.03102e-04
I0512 09:36:46.945078 22485033404224 run_lib.py:146] step: 78050, training_loss: 5.92711e-04
I0512 09:37:10.569150 22485033404224 run_lib.py:146] step: 78100, training_loss: 6.37651e-04
I0512 09:37:10.730201 22485033404224 run_lib.py:167] step: 78100, eval_loss: 7.31962e-04
I0512 09:37:34.340225 22485033404224 run_lib.py:146] step: 78150, training_loss: 6.83502e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 09:37:58.340557 22485033404224 run_lib.py:146] step: 78200, training_loss: 4.32550e-04
I0512 09:37:58.504779 22485033404224 run_lib.py:167] step: 78200, eval_loss: 8.00731e-04
I0512 09:38:22.771561 22485033404224 run_lib.py:146] step: 78250, training_loss: 6.45737e-04
I0512 09:38:46.558825 22485033404224 run_lib.py:146] step: 78300, training_loss: 5.92478e-04
I0512 09:38:46.720081 22485033404224 run_lib.py:167] step: 78300, eval_loss: 6.47678e-04
I0512 09:39:10.977427 22485033404224 run_lib.py:146] step: 78350, training_loss: 6.17261e-04
I0512 09:39:35.181403 22485033404224 run_lib.py:146] step: 78400, training_loss: 5.91308e-04
I0512 09:39:35.343317 22485033404224 run_lib.py:167] step: 78400, eval_loss: 7.31365e-04
I0512 09:39:59.112565 22485033404224 run_lib.py:146] step: 78450, training_loss: 8.75836e-04
I0512 09:40:23.187794 22485033404224 run_lib.py:146] step: 78500, training_loss: 6.85095e-04
I0512 09:40:23.348045 22485033404224 run_lib.py:167] step: 78500, eval_loss: 6.69291e-04
I0512 09:40:47.248304 22485033404224 run_lib.py:146] step: 78550, training_loss: 4.38477e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 09:41:10.930976 22485033404224 run_lib.py:146] step: 78600, training_loss: 7.18179e-04
I0512 09:41:11.093371 22485033404224 run_lib.py:167] step: 78600, eval_loss: 4.67402e-04
I0512 09:41:35.214280 22485033404224 run_lib.py:146] step: 78650, training_loss: 7.81928e-04
I0512 09:41:59.226128 22485033404224 run_lib.py:146] step: 78700, training_loss: 4.78268e-04
I0512 09:41:59.387740 22485033404224 run_lib.py:167] step: 78700, eval_loss: 4.93989e-04
I0512 09:42:23.012581 22485033404224 run_lib.py:146] step: 78750, training_loss: 6.54570e-04
I0512 09:42:46.981743 22485033404224 run_lib.py:146] step: 78800, training_loss: 6.89211e-04
I0512 09:42:47.140443 22485033404224 run_lib.py:167] step: 78800, eval_loss: 5.68140e-04
I0512 09:43:10.957471 22485033404224 run_lib.py:146] step: 78850, training_loss: 7.64165e-04
I0512 09:43:34.487309 22485033404224 run_lib.py:146] step: 78900, training_loss: 4.44427e-04
I0512 09:43:34.567693 22485033404224 run_lib.py:167] step: 78900, eval_loss: 7.90993e-04
I0512 09:43:58.364366 22485033404224 run_lib.py:146] step: 78950, training_loss: 7.53207e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 09:44:21.966872 22485033404224 run_lib.py:146] step: 79000, training_loss: 7.08362e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 09:44:22.311395 22485033404224 run_lib.py:167] step: 79000, eval_loss: 5.75504e-04
I0512 09:44:46.173937 22485033404224 run_lib.py:146] step: 79050, training_loss: 5.72935e-04
I0512 09:45:09.706048 22485033404224 run_lib.py:146] step: 79100, training_loss: 6.67438e-04
I0512 09:45:09.865334 22485033404224 run_lib.py:167] step: 79100, eval_loss: 5.96075e-04
I0512 09:45:33.708364 22485033404224 run_lib.py:146] step: 79150, training_loss: 5.14851e-04
I0512 09:45:57.526688 22485033404224 run_lib.py:146] step: 79200, training_loss: 5.73654e-04
I0512 09:45:57.686567 22485033404224 run_lib.py:167] step: 79200, eval_loss: 7.28177e-04
I0512 09:46:21.191773 22485033404224 run_lib.py:146] step: 79250, training_loss: 6.27861e-04
I0512 09:46:44.996683 22485033404224 run_lib.py:146] step: 79300, training_loss: 6.45153e-04
I0512 09:46:45.155689 22485033404224 run_lib.py:167] step: 79300, eval_loss: 7.43044e-04
I0512 09:47:08.966329 22485033404224 run_lib.py:146] step: 79350, training_loss: 7.43484e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 09:47:32.572278 22485033404224 run_lib.py:146] step: 79400, training_loss: 6.47217e-04
I0512 09:47:32.733697 22485033404224 run_lib.py:167] step: 79400, eval_loss: 6.53893e-04
I0512 09:47:56.609336 22485033404224 run_lib.py:146] step: 79450, training_loss: 8.45270e-04
I0512 09:48:20.464809 22485033404224 run_lib.py:146] step: 79500, training_loss: 5.79721e-04
I0512 09:48:20.623220 22485033404224 run_lib.py:167] step: 79500, eval_loss: 5.80766e-04
I0512 09:48:44.158479 22485033404224 run_lib.py:146] step: 79550, training_loss: 6.78477e-04
I0512 09:49:08.009027 22485033404224 run_lib.py:146] step: 79600, training_loss: 6.49392e-04
I0512 09:49:08.168963 22485033404224 run_lib.py:167] step: 79600, eval_loss: 7.26606e-04
I0512 09:49:31.926855 22485033404224 run_lib.py:146] step: 79650, training_loss: 5.53321e-04
I0512 09:49:55.433834 22485033404224 run_lib.py:146] step: 79700, training_loss: 4.00583e-04
I0512 09:49:55.592679 22485033404224 run_lib.py:167] step: 79700, eval_loss: 4.88714e-04
I0512 09:50:19.392346 22485033404224 run_lib.py:146] step: 79750, training_loss: 5.80530e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 09:50:43.003189 22485033404224 run_lib.py:146] step: 79800, training_loss: 5.60138e-04
I0512 09:50:43.164397 22485033404224 run_lib.py:167] step: 79800, eval_loss: 4.90823e-04
I0512 09:51:06.997003 22485033404224 run_lib.py:146] step: 79850, training_loss: 5.03363e-04
I0512 09:51:30.505470 22485033404224 run_lib.py:146] step: 79900, training_loss: 5.84663e-04
I0512 09:51:30.664833 22485033404224 run_lib.py:167] step: 79900, eval_loss: 8.16755e-04
I0512 09:51:54.514742 22485033404224 run_lib.py:146] step: 79950, training_loss: 6.45038e-04
I0512 09:52:18.361698 22485033404224 run_lib.py:146] step: 80000, training_loss: 8.54909e-04
I0512 09:52:24.995522 22485033404224 run_lib.py:167] step: 80000, eval_loss: 8.20716e-04
I0512 09:52:54.134686 22485033404224 run_lib.py:146] step: 80050, training_loss: 4.98910e-04
I0512 09:53:18.300202 22485033404224 run_lib.py:146] step: 80100, training_loss: 6.94936e-04
I0512 09:53:18.460846 22485033404224 run_lib.py:167] step: 80100, eval_loss: 5.95795e-04
I0512 09:53:42.055779 22485033404224 run_lib.py:146] step: 80150, training_loss: 7.49284e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 09:54:05.731247 22485033404224 run_lib.py:146] step: 80200, training_loss: 7.01813e-04
I0512 09:54:05.892867 22485033404224 run_lib.py:167] step: 80200, eval_loss: 5.29094e-04
I0512 09:54:30.208558 22485033404224 run_lib.py:146] step: 80250, training_loss: 7.96137e-04
I0512 09:54:53.833934 22485033404224 run_lib.py:146] step: 80300, training_loss: 7.22244e-04
I0512 09:54:53.993600 22485033404224 run_lib.py:167] step: 80300, eval_loss: 5.91626e-04
I0512 09:55:17.562685 22485033404224 run_lib.py:146] step: 80350, training_loss: 6.26804e-04
I0512 09:55:41.726332 22485033404224 run_lib.py:146] step: 80400, training_loss: 5.71976e-04
I0512 09:55:41.885376 22485033404224 run_lib.py:167] step: 80400, eval_loss: 5.31743e-04
I0512 09:56:05.472709 22485033404224 run_lib.py:146] step: 80450, training_loss: 5.29240e-04
I0512 09:56:29.032501 22485033404224 run_lib.py:146] step: 80500, training_loss: 5.13828e-04
I0512 09:56:29.191802 22485033404224 run_lib.py:167] step: 80500, eval_loss: 6.47962e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 09:56:53.322372 22485033404224 run_lib.py:146] step: 80550, training_loss: 6.22012e-04
I0512 09:57:17.469554 22485033404224 run_lib.py:146] step: 80600, training_loss: 6.33193e-04
I0512 09:57:17.634145 22485033404224 run_lib.py:167] step: 80600, eval_loss: 4.76591e-04
I0512 09:57:41.390304 22485033404224 run_lib.py:146] step: 80650, training_loss: 5.44752e-04
I0512 09:58:05.025026 22485033404224 run_lib.py:146] step: 80700, training_loss: 5.77170e-04
I0512 09:58:05.186217 22485033404224 run_lib.py:167] step: 80700, eval_loss: 5.61739e-04
I0512 09:58:29.460085 22485033404224 run_lib.py:146] step: 80750, training_loss: 5.56050e-04
I0512 09:58:53.068698 22485033404224 run_lib.py:146] step: 80800, training_loss: 7.24523e-04
I0512 09:58:53.229265 22485033404224 run_lib.py:167] step: 80800, eval_loss: 6.76208e-04
I0512 09:59:16.813473 22485033404224 run_lib.py:146] step: 80850, training_loss: 6.33097e-04
I0512 09:59:41.063776 22485033404224 run_lib.py:146] step: 80900, training_loss: 7.12030e-04
I0512 09:59:41.224323 22485033404224 run_lib.py:167] step: 80900, eval_loss: 6.12638e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 10:00:04.892211 22485033404224 run_lib.py:146] step: 80950, training_loss: 6.10285e-04
I0512 10:00:28.434275 22485033404224 run_lib.py:146] step: 81000, training_loss: 6.39183e-04
I0512 10:00:28.594516 22485033404224 run_lib.py:167] step: 81000, eval_loss: 5.36575e-04
I0512 10:00:52.825268 22485033404224 run_lib.py:146] step: 81050, training_loss: 6.31269e-04
I0512 10:01:16.341889 22485033404224 run_lib.py:146] step: 81100, training_loss: 6.50589e-04
I0512 10:01:16.501194 22485033404224 run_lib.py:167] step: 81100, eval_loss: 4.97570e-04
I0512 10:01:40.024385 22485033404224 run_lib.py:146] step: 81150, training_loss: 9.38520e-04
I0512 10:02:03.860140 22485033404224 run_lib.py:146] step: 81200, training_loss: 6.32631e-04
I0512 10:02:04.019574 22485033404224 run_lib.py:167] step: 81200, eval_loss: 7.07479e-04
I0512 10:02:27.870783 22485033404224 run_lib.py:146] step: 81250, training_loss: 6.42210e-04
I0512 10:02:51.391458 22485033404224 run_lib.py:146] step: 81300, training_loss: 6.35760e-04
I0512 10:02:51.551321 22485033404224 run_lib.py:167] step: 81300, eval_loss: 6.73153e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 10:03:15.498921 22485033404224 run_lib.py:146] step: 81350, training_loss: 5.03840e-04
I0512 10:03:39.346772 22485033404224 run_lib.py:146] step: 81400, training_loss: 6.49446e-04
I0512 10:03:39.506378 22485033404224 run_lib.py:167] step: 81400, eval_loss: 5.96767e-04
I0512 10:04:03.056245 22485033404224 run_lib.py:146] step: 81450, training_loss: 5.58610e-04
I0512 10:04:26.626596 22485033404224 run_lib.py:146] step: 81500, training_loss: 6.11061e-04
I0512 10:04:26.787077 22485033404224 run_lib.py:167] step: 81500, eval_loss: 5.26908e-04
I0512 10:04:50.914913 22485033404224 run_lib.py:146] step: 81550, training_loss: 6.47822e-04
I0512 10:05:14.469845 22485033404224 run_lib.py:146] step: 81600, training_loss: 6.45605e-04
I0512 10:05:14.630481 22485033404224 run_lib.py:167] step: 81600, eval_loss: 6.09320e-04
I0512 10:05:38.155030 22485033404224 run_lib.py:146] step: 81650, training_loss: 7.02732e-04
I0512 10:06:02.271445 22485033404224 run_lib.py:146] step: 81700, training_loss: 5.14005e-04
I0512 10:06:02.431172 22485033404224 run_lib.py:167] step: 81700, eval_loss: 5.67975e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 10:06:26.022855 22485033404224 run_lib.py:146] step: 81750, training_loss: 5.81093e-04
I0512 10:06:49.552528 22485033404224 run_lib.py:146] step: 81800, training_loss: 6.96227e-04
I0512 10:06:49.715133 22485033404224 run_lib.py:167] step: 81800, eval_loss: 6.28537e-04
I0512 10:07:13.938220 22485033404224 run_lib.py:146] step: 81850, training_loss: 5.56278e-04
I0512 10:07:37.467092 22485033404224 run_lib.py:146] step: 81900, training_loss: 7.28075e-04
I0512 10:07:37.626197 22485033404224 run_lib.py:167] step: 81900, eval_loss: 4.04009e-04
I0512 10:08:01.165419 22485033404224 run_lib.py:146] step: 81950, training_loss: 5.56538e-04
I0512 10:08:25.316973 22485033404224 run_lib.py:146] step: 82000, training_loss: 7.11487e-04
I0512 10:08:25.476295 22485033404224 run_lib.py:167] step: 82000, eval_loss: 5.79120e-04
I0512 10:08:48.998207 22485033404224 run_lib.py:146] step: 82050, training_loss: 5.83274e-04
I0512 10:09:12.555088 22485033404224 run_lib.py:146] step: 82100, training_loss: 5.78642e-04
I0512 10:09:12.715355 22485033404224 run_lib.py:167] step: 82100, eval_loss: 6.85744e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 10:09:36.662833 22485033404224 run_lib.py:146] step: 82150, training_loss: 8.16727e-04
I0512 10:10:00.552979 22485033404224 run_lib.py:146] step: 82200, training_loss: 7.19221e-04
I0512 10:10:00.713392 22485033404224 run_lib.py:167] step: 82200, eval_loss: 7.15155e-04
I0512 10:10:24.272419 22485033404224 run_lib.py:146] step: 82250, training_loss: 4.76732e-04
I0512 10:10:48.144079 22485033404224 run_lib.py:146] step: 82300, training_loss: 6.99771e-04
I0512 10:10:48.304965 22485033404224 run_lib.py:167] step: 82300, eval_loss: 5.64349e-04
I0512 10:11:12.188209 22485033404224 run_lib.py:146] step: 82350, training_loss: 7.11213e-04
I0512 10:11:35.775101 22485033404224 run_lib.py:146] step: 82400, training_loss: 6.55319e-04
I0512 10:11:35.935995 22485033404224 run_lib.py:167] step: 82400, eval_loss: 6.60755e-04
I0512 10:11:59.519795 22485033404224 run_lib.py:146] step: 82450, training_loss: 5.48478e-04
I0512 10:12:23.583914 22485033404224 run_lib.py:146] step: 82500, training_loss: 6.50519e-04
I0512 10:12:23.744667 22485033404224 run_lib.py:167] step: 82500, eval_loss: 5.82409e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 10:12:47.524566 22485033404224 run_lib.py:146] step: 82550, training_loss: 5.02272e-04
I0512 10:13:11.102580 22485033404224 run_lib.py:146] step: 82600, training_loss: 4.04866e-04
I0512 10:13:11.262863 22485033404224 run_lib.py:167] step: 82600, eval_loss: 4.92655e-04
I0512 10:13:35.650869 22485033404224 run_lib.py:146] step: 82650, training_loss: 7.46648e-04
I0512 10:13:59.213386 22485033404224 run_lib.py:146] step: 82700, training_loss: 6.12320e-04
I0512 10:13:59.373546 22485033404224 run_lib.py:167] step: 82700, eval_loss: 6.00301e-04
I0512 10:14:22.950158 22485033404224 run_lib.py:146] step: 82750, training_loss: 6.30135e-04
I0512 10:14:47.262165 22485033404224 run_lib.py:146] step: 82800, training_loss: 6.31675e-04
I0512 10:14:47.422492 22485033404224 run_lib.py:167] step: 82800, eval_loss: 5.57562e-04
I0512 10:15:11.027046 22485033404224 run_lib.py:146] step: 82850, training_loss: 4.61258e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 10:15:34.682147 22485033404224 run_lib.py:146] step: 82900, training_loss: 6.30150e-04
I0512 10:15:34.844295 22485033404224 run_lib.py:167] step: 82900, eval_loss: 5.93683e-04
I0512 10:15:58.893951 22485033404224 run_lib.py:146] step: 82950, training_loss: 8.39847e-04
I0512 10:16:22.839635 22485033404224 run_lib.py:146] step: 83000, training_loss: 7.13298e-04
I0512 10:16:23.000297 22485033404224 run_lib.py:167] step: 83000, eval_loss: 4.71552e-04
I0512 10:16:46.626860 22485033404224 run_lib.py:146] step: 83050, training_loss: 6.86481e-04
I0512 10:17:10.539375 22485033404224 run_lib.py:146] step: 83100, training_loss: 6.74062e-04
I0512 10:17:10.700269 22485033404224 run_lib.py:167] step: 83100, eval_loss: 6.15478e-04
I0512 10:17:34.620381 22485033404224 run_lib.py:146] step: 83150, training_loss: 5.10544e-04
I0512 10:17:58.230910 22485033404224 run_lib.py:146] step: 83200, training_loss: 7.23144e-04
I0512 10:17:58.391499 22485033404224 run_lib.py:167] step: 83200, eval_loss: 6.27778e-04
I0512 10:18:21.958282 22485033404224 run_lib.py:146] step: 83250, training_loss: 7.31895e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 10:18:46.150926 22485033404224 run_lib.py:146] step: 83300, training_loss: 5.61446e-04
I0512 10:18:46.312927 22485033404224 run_lib.py:167] step: 83300, eval_loss: 5.48329e-04
I0512 10:19:09.845084 22485033404224 run_lib.py:146] step: 83350, training_loss: 5.56043e-04
I0512 10:19:33.395645 22485033404224 run_lib.py:146] step: 83400, training_loss: 5.80251e-04
I0512 10:19:33.556602 22485033404224 run_lib.py:167] step: 83400, eval_loss: 5.83487e-04
I0512 10:19:57.770205 22485033404224 run_lib.py:146] step: 83450, training_loss: 7.45000e-04
I0512 10:20:21.338418 22485033404224 run_lib.py:146] step: 83500, training_loss: 8.72802e-04
I0512 10:20:21.498867 22485033404224 run_lib.py:167] step: 83500, eval_loss: 8.04382e-04
I0512 10:20:45.045062 22485033404224 run_lib.py:146] step: 83550, training_loss: 7.05117e-04
I0512 10:21:09.181807 22485033404224 run_lib.py:146] step: 83600, training_loss: 5.27622e-04
I0512 10:21:09.341851 22485033404224 run_lib.py:167] step: 83600, eval_loss: 6.30829e-04
I0512 10:21:32.882713 22485033404224 run_lib.py:146] step: 83650, training_loss: 5.16388e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 10:21:56.484359 22485033404224 run_lib.py:146] step: 83700, training_loss: 8.00271e-04
I0512 10:21:56.645972 22485033404224 run_lib.py:167] step: 83700, eval_loss: 5.30365e-04
I0512 10:22:20.519603 22485033404224 run_lib.py:146] step: 83750, training_loss: 7.71801e-04
I0512 10:22:44.369761 22485033404224 run_lib.py:146] step: 83800, training_loss: 4.85943e-04
I0512 10:22:44.531275 22485033404224 run_lib.py:167] step: 83800, eval_loss: 5.53351e-04
I0512 10:23:08.062892 22485033404224 run_lib.py:146] step: 83850, training_loss: 4.80382e-04
I0512 10:23:31.883237 22485033404224 run_lib.py:146] step: 83900, training_loss: 5.34714e-04
I0512 10:23:32.043610 22485033404224 run_lib.py:167] step: 83900, eval_loss: 6.35354e-04
I0512 10:23:55.864012 22485033404224 run_lib.py:146] step: 83950, training_loss: 6.45015e-04
I0512 10:24:19.397438 22485033404224 run_lib.py:146] step: 84000, training_loss: 6.52128e-04
I0512 10:24:19.556951 22485033404224 run_lib.py:167] step: 84000, eval_loss: 5.83216e-04
I0512 10:24:43.063702 22485033404224 run_lib.py:146] step: 84050, training_loss: 7.04123e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 10:25:07.306354 22485033404224 run_lib.py:146] step: 84100, training_loss: 6.59673e-04
I0512 10:25:07.467478 22485033404224 run_lib.py:167] step: 84100, eval_loss: 5.76124e-04
I0512 10:25:30.993654 22485033404224 run_lib.py:146] step: 84150, training_loss: 4.98332e-04
I0512 10:25:54.538399 22485033404224 run_lib.py:146] step: 84200, training_loss: 6.80306e-04
I0512 10:25:54.697430 22485033404224 run_lib.py:167] step: 84200, eval_loss: 6.74269e-04
I0512 10:26:18.830041 22485033404224 run_lib.py:146] step: 84250, training_loss: 5.71868e-04
I0512 10:26:42.334383 22485033404224 run_lib.py:146] step: 84300, training_loss: 6.17487e-04
I0512 10:26:42.494050 22485033404224 run_lib.py:167] step: 84300, eval_loss: 8.80230e-04
I0512 10:27:06.014018 22485033404224 run_lib.py:146] step: 84350, training_loss: 5.66681e-04
I0512 10:27:30.145180 22485033404224 run_lib.py:146] step: 84400, training_loss: 6.52118e-04
I0512 10:27:30.304726 22485033404224 run_lib.py:167] step: 84400, eval_loss: 4.53188e-04
I0512 10:27:53.820151 22485033404224 run_lib.py:146] step: 84450, training_loss: 5.63806e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 10:28:17.421645 22485033404224 run_lib.py:146] step: 84500, training_loss: 5.90155e-04
I0512 10:28:17.584985 22485033404224 run_lib.py:167] step: 84500, eval_loss: 7.10974e-04
I0512 10:28:41.828199 22485033404224 run_lib.py:146] step: 84550, training_loss: 4.70879e-04
I0512 10:29:05.433702 22485033404224 run_lib.py:146] step: 84600, training_loss: 6.92492e-04
I0512 10:29:05.594229 22485033404224 run_lib.py:167] step: 84600, eval_loss: 5.35244e-04
I0512 10:29:29.208379 22485033404224 run_lib.py:146] step: 84650, training_loss: 7.87101e-04
I0512 10:29:53.125456 22485033404224 run_lib.py:146] step: 84700, training_loss: 5.88797e-04
I0512 10:29:53.287137 22485033404224 run_lib.py:167] step: 84700, eval_loss: 7.82890e-04
I0512 10:30:17.160331 22485033404224 run_lib.py:146] step: 84750, training_loss: 5.55844e-04
I0512 10:30:40.767477 22485033404224 run_lib.py:146] step: 84800, training_loss: 5.93830e-04
I0512 10:30:40.927830 22485033404224 run_lib.py:167] step: 84800, eval_loss: 7.06738e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 10:31:04.620542 22485033404224 run_lib.py:146] step: 84850, training_loss: 7.27271e-04
I0512 10:31:29.056370 22485033404224 run_lib.py:146] step: 84900, training_loss: 6.89937e-04
I0512 10:31:29.217601 22485033404224 run_lib.py:167] step: 84900, eval_loss: 5.37650e-04
I0512 10:31:52.837520 22485033404224 run_lib.py:146] step: 84950, training_loss: 6.96508e-04
I0512 10:32:16.456903 22485033404224 run_lib.py:146] step: 85000, training_loss: 6.82451e-04
I0512 10:32:16.618780 22485033404224 run_lib.py:167] step: 85000, eval_loss: 7.01362e-04
I0512 10:32:40.934669 22485033404224 run_lib.py:146] step: 85050, training_loss: 4.38178e-04
I0512 10:33:04.568032 22485033404224 run_lib.py:146] step: 85100, training_loss: 6.19223e-04
I0512 10:33:04.730533 22485033404224 run_lib.py:167] step: 85100, eval_loss: 6.83869e-04
I0512 10:33:28.368132 22485033404224 run_lib.py:146] step: 85150, training_loss: 6.11580e-04
I0512 10:33:52.598814 22485033404224 run_lib.py:146] step: 85200, training_loss: 5.85382e-04
I0512 10:33:52.759251 22485033404224 run_lib.py:167] step: 85200, eval_loss: 7.74336e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 10:34:16.441447 22485033404224 run_lib.py:146] step: 85250, training_loss: 7.73376e-04
I0512 10:34:40.067273 22485033404224 run_lib.py:146] step: 85300, training_loss: 5.83331e-04
I0512 10:34:40.228317 22485033404224 run_lib.py:167] step: 85300, eval_loss: 9.05857e-04
I0512 10:35:04.733673 22485033404224 run_lib.py:146] step: 85350, training_loss: 6.27294e-04
I0512 10:35:28.312619 22485033404224 run_lib.py:146] step: 85400, training_loss: 6.45890e-04
I0512 10:35:28.474304 22485033404224 run_lib.py:167] step: 85400, eval_loss: 5.77923e-04
I0512 10:35:52.108542 22485033404224 run_lib.py:146] step: 85450, training_loss: 5.75254e-04
I0512 10:36:16.140986 22485033404224 run_lib.py:146] step: 85500, training_loss: 5.42320e-04
I0512 10:36:16.301998 22485033404224 run_lib.py:167] step: 85500, eval_loss: 8.02309e-04
I0512 10:36:40.228951 22485033404224 run_lib.py:146] step: 85550, training_loss: 8.91115e-04
I0512 10:37:03.722412 22485033404224 run_lib.py:146] step: 85600, training_loss: 7.14060e-04
I0512 10:37:03.882475 22485033404224 run_lib.py:167] step: 85600, eval_loss: 5.28719e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 10:37:27.807098 22485033404224 run_lib.py:146] step: 85650, training_loss: 5.81412e-04
I0512 10:37:51.668580 22485033404224 run_lib.py:146] step: 85700, training_loss: 6.83720e-04
I0512 10:37:51.829154 22485033404224 run_lib.py:167] step: 85700, eval_loss: 7.02253e-04
I0512 10:38:15.348208 22485033404224 run_lib.py:146] step: 85750, training_loss: 5.49968e-04
I0512 10:38:38.864245 22485033404224 run_lib.py:146] step: 85800, training_loss: 6.04584e-04
I0512 10:38:39.024248 22485033404224 run_lib.py:167] step: 85800, eval_loss: 7.24960e-04
I0512 10:39:03.144443 22485033404224 run_lib.py:146] step: 85850, training_loss: 4.60394e-04
I0512 10:39:26.669190 22485033404224 run_lib.py:146] step: 85900, training_loss: 6.69927e-04
I0512 10:39:26.828935 22485033404224 run_lib.py:167] step: 85900, eval_loss: 5.89398e-04
I0512 10:39:50.347997 22485033404224 run_lib.py:146] step: 85950, training_loss: 7.36923e-04
I0512 10:40:14.503490 22485033404224 run_lib.py:146] step: 86000, training_loss: 5.31466e-04
I0512 10:40:14.662299 22485033404224 run_lib.py:167] step: 86000, eval_loss: 5.68208e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 10:40:38.221215 22485033404224 run_lib.py:146] step: 86050, training_loss: 6.99061e-04
I0512 10:41:01.727729 22485033404224 run_lib.py:146] step: 86100, training_loss: 8.40456e-04
I0512 10:41:01.888458 22485033404224 run_lib.py:167] step: 86100, eval_loss: 4.60856e-04
I0512 10:41:26.071427 22485033404224 run_lib.py:146] step: 86150, training_loss: 7.29316e-04
I0512 10:41:49.624118 22485033404224 run_lib.py:146] step: 86200, training_loss: 7.03907e-04
I0512 10:41:49.783989 22485033404224 run_lib.py:167] step: 86200, eval_loss: 6.44976e-04
I0512 10:42:13.317319 22485033404224 run_lib.py:146] step: 86250, training_loss: 7.47911e-04
I0512 10:42:37.422884 22485033404224 run_lib.py:146] step: 86300, training_loss: 6.60246e-04
I0512 10:42:37.582286 22485033404224 run_lib.py:167] step: 86300, eval_loss: 5.59981e-04
I0512 10:43:01.113441 22485033404224 run_lib.py:146] step: 86350, training_loss: 6.06455e-04
I0512 10:43:24.632986 22485033404224 run_lib.py:146] step: 86400, training_loss: 6.92976e-04
I0512 10:43:24.793233 22485033404224 run_lib.py:167] step: 86400, eval_loss: 8.70083e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 10:43:48.759228 22485033404224 run_lib.py:146] step: 86450, training_loss: 7.62505e-04
I0512 10:44:12.655103 22485033404224 run_lib.py:146] step: 86500, training_loss: 6.69552e-04
I0512 10:44:12.815912 22485033404224 run_lib.py:167] step: 86500, eval_loss: 5.98066e-04
I0512 10:44:36.337208 22485033404224 run_lib.py:146] step: 86550, training_loss: 8.01713e-04
I0512 10:44:59.851145 22485033404224 run_lib.py:146] step: 86600, training_loss: 6.34321e-04
I0512 10:45:00.011991 22485033404224 run_lib.py:167] step: 86600, eval_loss: 5.52917e-04
I0512 10:45:24.148127 22485033404224 run_lib.py:146] step: 86650, training_loss: 5.89330e-04
I0512 10:45:47.693998 22485033404224 run_lib.py:146] step: 86700, training_loss: 6.72446e-04
I0512 10:45:47.852946 22485033404224 run_lib.py:167] step: 86700, eval_loss: 5.96642e-04
I0512 10:46:11.403949 22485033404224 run_lib.py:146] step: 86750, training_loss: 6.25044e-04
I0512 10:46:35.545566 22485033404224 run_lib.py:146] step: 86800, training_loss: 6.33851e-04
I0512 10:46:35.627951 22485033404224 run_lib.py:167] step: 86800, eval_loss: 5.01072e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 10:46:59.234561 22485033404224 run_lib.py:146] step: 86850, training_loss: 5.60097e-04
I0512 10:47:22.852486 22485033404224 run_lib.py:146] step: 86900, training_loss: 6.81079e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 10:47:23.198848 22485033404224 run_lib.py:167] step: 86900, eval_loss: 6.95698e-04
I0512 10:47:47.540019 22485033404224 run_lib.py:146] step: 86950, training_loss: 6.19500e-04
I0512 10:48:11.130565 22485033404224 run_lib.py:146] step: 87000, training_loss: 5.69100e-04
I0512 10:48:11.291918 22485033404224 run_lib.py:167] step: 87000, eval_loss: 5.92133e-04
I0512 10:48:34.905318 22485033404224 run_lib.py:146] step: 87050, training_loss: 6.49253e-04
I0512 10:48:59.114086 22485033404224 run_lib.py:146] step: 87100, training_loss: 6.48685e-04
I0512 10:48:59.274236 22485033404224 run_lib.py:167] step: 87100, eval_loss: 5.16992e-04
I0512 10:49:22.876118 22485033404224 run_lib.py:146] step: 87150, training_loss: 5.97558e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 10:49:46.540241 22485033404224 run_lib.py:146] step: 87200, training_loss: 5.85226e-04
I0512 10:49:46.702021 22485033404224 run_lib.py:167] step: 87200, eval_loss: 5.91294e-04
I0512 10:50:10.749644 22485033404224 run_lib.py:146] step: 87250, training_loss: 6.92553e-04
I0512 10:50:34.778368 22485033404224 run_lib.py:146] step: 87300, training_loss: 6.01380e-04
I0512 10:50:34.937546 22485033404224 run_lib.py:167] step: 87300, eval_loss: 5.41867e-04
I0512 10:50:58.528398 22485033404224 run_lib.py:146] step: 87350, training_loss: 7.03543e-04
I0512 10:51:22.148462 22485033404224 run_lib.py:146] step: 87400, training_loss: 6.38252e-04
I0512 10:51:22.310087 22485033404224 run_lib.py:167] step: 87400, eval_loss: 6.63011e-04
I0512 10:51:46.681868 22485033404224 run_lib.py:146] step: 87450, training_loss: 6.98396e-04
I0512 10:52:10.285723 22485033404224 run_lib.py:146] step: 87500, training_loss: 6.17018e-04
I0512 10:52:10.447238 22485033404224 run_lib.py:167] step: 87500, eval_loss: 8.92015e-04
I0512 10:52:34.057153 22485033404224 run_lib.py:146] step: 87550, training_loss: 5.92927e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 10:52:58.328357 22485033404224 run_lib.py:146] step: 87600, training_loss: 5.86123e-04
I0512 10:52:58.490934 22485033404224 run_lib.py:167] step: 87600, eval_loss: 5.16592e-04
I0512 10:53:22.072958 22485033404224 run_lib.py:146] step: 87650, training_loss: 5.65186e-04
I0512 10:53:45.637149 22485033404224 run_lib.py:146] step: 87700, training_loss: 7.99964e-04
I0512 10:53:45.797651 22485033404224 run_lib.py:167] step: 87700, eval_loss: 5.47428e-04
I0512 10:54:10.062330 22485033404224 run_lib.py:146] step: 87750, training_loss: 6.77079e-04
I0512 10:54:33.646645 22485033404224 run_lib.py:146] step: 87800, training_loss: 7.88366e-04
I0512 10:54:33.806473 22485033404224 run_lib.py:167] step: 87800, eval_loss: 6.63093e-04
I0512 10:54:57.300975 22485033404224 run_lib.py:146] step: 87850, training_loss: 6.51663e-04
I0512 10:55:21.417019 22485033404224 run_lib.py:146] step: 87900, training_loss: 5.54867e-04
I0512 10:55:21.575103 22485033404224 run_lib.py:167] step: 87900, eval_loss: 5.30884e-04
I0512 10:55:45.084686 22485033404224 run_lib.py:146] step: 87950, training_loss: 5.09509e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 10:56:08.695998 22485033404224 run_lib.py:146] step: 88000, training_loss: 5.76232e-04
I0512 10:56:08.857922 22485033404224 run_lib.py:167] step: 88000, eval_loss: 7.33491e-04
I0512 10:56:32.705366 22485033404224 run_lib.py:146] step: 88050, training_loss: 6.14634e-04
I0512 10:56:56.563499 22485033404224 run_lib.py:146] step: 88100, training_loss: 8.58267e-04
I0512 10:56:56.722786 22485033404224 run_lib.py:167] step: 88100, eval_loss: 6.61914e-04
I0512 10:57:20.263800 22485033404224 run_lib.py:146] step: 88150, training_loss: 5.29230e-04
I0512 10:57:44.093893 22485033404224 run_lib.py:146] step: 88200, training_loss: 4.94256e-04
I0512 10:57:44.252832 22485033404224 run_lib.py:167] step: 88200, eval_loss: 6.24053e-04
I0512 10:58:08.105117 22485033404224 run_lib.py:146] step: 88250, training_loss: 6.22712e-04
I0512 10:58:31.666060 22485033404224 run_lib.py:146] step: 88300, training_loss: 6.51083e-04
I0512 10:58:31.826458 22485033404224 run_lib.py:167] step: 88300, eval_loss: 6.02679e-04
I0512 10:58:55.372714 22485033404224 run_lib.py:146] step: 88350, training_loss: 5.43383e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 10:59:19.616199 22485033404224 run_lib.py:146] step: 88400, training_loss: 5.08293e-04
I0512 10:59:19.777191 22485033404224 run_lib.py:167] step: 88400, eval_loss: 6.59327e-04
I0512 10:59:43.318637 22485033404224 run_lib.py:146] step: 88450, training_loss: 7.65560e-04
I0512 11:00:06.893185 22485033404224 run_lib.py:146] step: 88500, training_loss: 5.97936e-04
I0512 11:00:07.053420 22485033404224 run_lib.py:167] step: 88500, eval_loss: 6.67742e-04
I0512 11:00:31.157546 22485033404224 run_lib.py:146] step: 88550, training_loss: 5.14055e-04
I0512 11:00:54.697139 22485033404224 run_lib.py:146] step: 88600, training_loss: 5.25885e-04
I0512 11:00:54.856544 22485033404224 run_lib.py:167] step: 88600, eval_loss: 6.62147e-04
I0512 11:01:18.406572 22485033404224 run_lib.py:146] step: 88650, training_loss: 6.76977e-04
I0512 11:01:42.549237 22485033404224 run_lib.py:146] step: 88700, training_loss: 5.84512e-04
I0512 11:01:42.709246 22485033404224 run_lib.py:167] step: 88700, eval_loss: 5.38781e-04
I0512 11:02:06.232262 22485033404224 run_lib.py:146] step: 88750, training_loss: 5.76198e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 11:02:29.835599 22485033404224 run_lib.py:146] step: 88800, training_loss: 5.51795e-04
I0512 11:02:29.997896 22485033404224 run_lib.py:167] step: 88800, eval_loss: 7.48008e-04
I0512 11:02:53.870301 22485033404224 run_lib.py:146] step: 88850, training_loss: 5.59548e-04
I0512 11:03:17.752151 22485033404224 run_lib.py:146] step: 88900, training_loss: 7.79449e-04
I0512 11:03:17.911252 22485033404224 run_lib.py:167] step: 88900, eval_loss: 4.91207e-04
I0512 11:03:41.438138 22485033404224 run_lib.py:146] step: 88950, training_loss: 5.75374e-04
I0512 11:04:05.226449 22485033404224 run_lib.py:146] step: 89000, training_loss: 6.48904e-04
I0512 11:04:05.386181 22485033404224 run_lib.py:167] step: 89000, eval_loss: 6.77603e-04
I0512 11:04:29.200330 22485033404224 run_lib.py:146] step: 89050, training_loss: 7.30404e-04
I0512 11:04:52.727154 22485033404224 run_lib.py:146] step: 89100, training_loss: 7.33933e-04
I0512 11:04:52.886525 22485033404224 run_lib.py:167] step: 89100, eval_loss: 5.37206e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 11:05:16.527750 22485033404224 run_lib.py:146] step: 89150, training_loss: 5.96183e-04
I0512 11:05:40.845923 22485033404224 run_lib.py:146] step: 89200, training_loss: 6.65563e-04
I0512 11:05:41.007890 22485033404224 run_lib.py:167] step: 89200, eval_loss: 4.98558e-04
I0512 11:06:04.613053 22485033404224 run_lib.py:146] step: 89250, training_loss: 5.54967e-04
I0512 11:06:28.214242 22485033404224 run_lib.py:146] step: 89300, training_loss: 7.59869e-04
I0512 11:06:28.375763 22485033404224 run_lib.py:167] step: 89300, eval_loss: 8.30314e-04
I0512 11:06:52.559200 22485033404224 run_lib.py:146] step: 89350, training_loss: 6.87699e-04
I0512 11:07:16.171305 22485033404224 run_lib.py:146] step: 89400, training_loss: 8.18624e-04
I0512 11:07:16.331447 22485033404224 run_lib.py:167] step: 89400, eval_loss: 6.13755e-04
I0512 11:07:39.927084 22485033404224 run_lib.py:146] step: 89450, training_loss: 6.40251e-04
I0512 11:08:04.105009 22485033404224 run_lib.py:146] step: 89500, training_loss: 5.29984e-04
I0512 11:08:04.265070 22485033404224 run_lib.py:167] step: 89500, eval_loss: 7.78872e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 11:08:27.930351 22485033404224 run_lib.py:146] step: 89550, training_loss: 6.02716e-04
I0512 11:08:51.588985 22485033404224 run_lib.py:146] step: 89600, training_loss: 8.02712e-04
I0512 11:08:51.751542 22485033404224 run_lib.py:167] step: 89600, eval_loss: 5.88430e-04
I0512 11:09:16.175109 22485033404224 run_lib.py:146] step: 89650, training_loss: 5.99651e-04
I0512 11:09:39.809247 22485033404224 run_lib.py:146] step: 89700, training_loss: 5.35859e-04
I0512 11:09:39.969944 22485033404224 run_lib.py:167] step: 89700, eval_loss: 6.22250e-04
I0512 11:10:03.603514 22485033404224 run_lib.py:146] step: 89750, training_loss: 6.33405e-04
I0512 11:10:27.614102 22485033404224 run_lib.py:146] step: 89800, training_loss: 6.10701e-04
I0512 11:10:27.775709 22485033404224 run_lib.py:167] step: 89800, eval_loss: 5.91137e-04
I0512 11:10:51.702782 22485033404224 run_lib.py:146] step: 89850, training_loss: 6.59765e-04
I0512 11:11:15.356006 22485033404224 run_lib.py:146] step: 89900, training_loss: 4.56935e-04
I0512 11:11:15.516151 22485033404224 run_lib.py:167] step: 89900, eval_loss: 7.19131e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 11:11:39.215805 22485033404224 run_lib.py:146] step: 89950, training_loss: 6.15161e-04
I0512 11:12:03.739439 22485033404224 run_lib.py:146] step: 90000, training_loss: 7.30249e-04
I0512 11:12:12.488810 22485033404224 run_lib.py:167] step: 90000, eval_loss: 8.47494e-04
I0512 11:12:43.040495 22485033404224 run_lib.py:146] step: 90050, training_loss: 5.80586e-04
I0512 11:13:06.899805 22485033404224 run_lib.py:146] step: 90100, training_loss: 8.72072e-04
I0512 11:13:07.059427 22485033404224 run_lib.py:167] step: 90100, eval_loss: 4.22706e-04
I0512 11:13:31.019713 22485033404224 run_lib.py:146] step: 90150, training_loss: 7.18754e-04
I0512 11:13:54.559822 22485033404224 run_lib.py:146] step: 90200, training_loss: 7.32748e-04
I0512 11:13:54.719300 22485033404224 run_lib.py:167] step: 90200, eval_loss: 6.22230e-04
I0512 11:14:18.525306 22485033404224 run_lib.py:146] step: 90250, training_loss: 7.73903e-04
I0512 11:14:42.349961 22485033404224 run_lib.py:146] step: 90300, training_loss: 7.80088e-04
I0512 11:14:42.509775 22485033404224 run_lib.py:167] step: 90300, eval_loss: 7.06895e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 11:15:06.086289 22485033404224 run_lib.py:146] step: 90350, training_loss: 5.99480e-04
I0512 11:15:29.623502 22485033404224 run_lib.py:146] step: 90400, training_loss: 5.81735e-04
I0512 11:15:29.785170 22485033404224 run_lib.py:167] step: 90400, eval_loss: 5.28315e-04
I0512 11:15:53.994837 22485033404224 run_lib.py:146] step: 90450, training_loss: 6.70595e-04
I0512 11:16:17.507159 22485033404224 run_lib.py:146] step: 90500, training_loss: 5.43881e-04
I0512 11:16:17.666676 22485033404224 run_lib.py:167] step: 90500, eval_loss: 6.01651e-04
I0512 11:16:41.200765 22485033404224 run_lib.py:146] step: 90550, training_loss: 8.63312e-04
I0512 11:17:05.304636 22485033404224 run_lib.py:146] step: 90600, training_loss: 6.69144e-04
I0512 11:17:05.464885 22485033404224 run_lib.py:167] step: 90600, eval_loss: 8.65306e-04
I0512 11:17:29.016764 22485033404224 run_lib.py:146] step: 90650, training_loss: 6.18118e-04
I0512 11:17:52.564048 22485033404224 run_lib.py:146] step: 90700, training_loss: 6.86110e-04
I0512 11:17:52.724775 22485033404224 run_lib.py:167] step: 90700, eval_loss: 4.83168e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 11:18:16.683406 22485033404224 run_lib.py:146] step: 90750, training_loss: 5.56315e-04
I0512 11:18:40.589024 22485033404224 run_lib.py:146] step: 90800, training_loss: 6.50297e-04
I0512 11:18:40.750303 22485033404224 run_lib.py:167] step: 90800, eval_loss: 5.58578e-04
I0512 11:19:04.278714 22485033404224 run_lib.py:146] step: 90850, training_loss: 5.77108e-04
I0512 11:19:28.115887 22485033404224 run_lib.py:146] step: 90900, training_loss: 7.37069e-04
I0512 11:19:28.275933 22485033404224 run_lib.py:167] step: 90900, eval_loss: 5.63054e-04
I0512 11:19:52.102653 22485033404224 run_lib.py:146] step: 90950, training_loss: 6.94589e-04
I0512 11:20:15.645400 22485033404224 run_lib.py:146] step: 91000, training_loss: 5.31813e-04
I0512 11:20:15.804328 22485033404224 run_lib.py:167] step: 91000, eval_loss: 4.79244e-04
I0512 11:20:39.656329 22485033404224 run_lib.py:146] step: 91050, training_loss: 5.60383e-04
I0512 11:21:03.501053 22485033404224 run_lib.py:146] step: 91100, training_loss: 6.23794e-04
I0512 11:21:03.660089 22485033404224 run_lib.py:167] step: 91100, eval_loss: 6.51846e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 11:21:27.273869 22485033404224 run_lib.py:146] step: 91150, training_loss: 5.84303e-04
I0512 11:21:50.829688 22485033404224 run_lib.py:146] step: 91200, training_loss: 5.78275e-04
I0512 11:21:50.992112 22485033404224 run_lib.py:167] step: 91200, eval_loss: 4.69534e-04
I0512 11:22:15.166627 22485033404224 run_lib.py:146] step: 91250, training_loss: 6.48250e-04
I0512 11:22:38.678458 22485033404224 run_lib.py:146] step: 91300, training_loss: 6.62522e-04
I0512 11:22:38.838095 22485033404224 run_lib.py:167] step: 91300, eval_loss: 5.61978e-04
I0512 11:23:02.358575 22485033404224 run_lib.py:146] step: 91350, training_loss: 7.76676e-04
I0512 11:23:26.544269 22485033404224 run_lib.py:146] step: 91400, training_loss: 6.17392e-04
I0512 11:23:26.704320 22485033404224 run_lib.py:167] step: 91400, eval_loss: 6.37953e-04
I0512 11:23:50.305152 22485033404224 run_lib.py:146] step: 91450, training_loss: 6.74613e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 11:24:13.984558 22485033404224 run_lib.py:146] step: 91500, training_loss: 5.20412e-04
I0512 11:24:14.146718 22485033404224 run_lib.py:167] step: 91500, eval_loss: 7.95142e-04
I0512 11:24:38.097745 22485033404224 run_lib.py:146] step: 91550, training_loss: 5.07349e-04
I0512 11:25:02.020703 22485033404224 run_lib.py:146] step: 91600, training_loss: 5.58791e-04
I0512 11:25:02.181296 22485033404224 run_lib.py:167] step: 91600, eval_loss: 6.83390e-04
I0512 11:25:25.777825 22485033404224 run_lib.py:146] step: 91650, training_loss: 7.00051e-04
I0512 11:25:49.679003 22485033404224 run_lib.py:146] step: 91700, training_loss: 6.50410e-04
I0512 11:25:49.839019 22485033404224 run_lib.py:167] step: 91700, eval_loss: 6.19565e-04
I0512 11:26:13.698419 22485033404224 run_lib.py:146] step: 91750, training_loss: 7.48220e-04
I0512 11:26:37.300334 22485033404224 run_lib.py:146] step: 91800, training_loss: 5.05963e-04
I0512 11:26:37.460117 22485033404224 run_lib.py:167] step: 91800, eval_loss: 5.34001e-04
I0512 11:27:01.337036 22485033404224 run_lib.py:146] step: 91850, training_loss: 5.87298e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 11:27:25.353274 22485033404224 run_lib.py:146] step: 91900, training_loss: 7.18205e-04
I0512 11:27:25.516407 22485033404224 run_lib.py:167] step: 91900, eval_loss: 5.80744e-04
I0512 11:27:49.177542 22485033404224 run_lib.py:146] step: 91950, training_loss: 7.34384e-04
I0512 11:28:13.146914 22485033404224 run_lib.py:146] step: 92000, training_loss: 7.01861e-04
I0512 11:28:13.307153 22485033404224 run_lib.py:167] step: 92000, eval_loss: 6.47609e-04
I0512 11:28:37.385867 22485033404224 run_lib.py:146] step: 92050, training_loss: 5.52983e-04
I0512 11:29:01.038247 22485033404224 run_lib.py:146] step: 92100, training_loss: 6.20185e-04
I0512 11:29:01.198235 22485033404224 run_lib.py:167] step: 92100, eval_loss: 6.21504e-04
I0512 11:29:24.838333 22485033404224 run_lib.py:146] step: 92150, training_loss: 7.67646e-04
I0512 11:29:49.179197 22485033404224 run_lib.py:146] step: 92200, training_loss: 5.77957e-04
I0512 11:29:49.338282 22485033404224 run_lib.py:167] step: 92200, eval_loss: 5.38649e-04
I0512 11:30:13.007853 22485033404224 run_lib.py:146] step: 92250, training_loss: 5.91142e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 11:30:36.715042 22485033404224 run_lib.py:146] step: 92300, training_loss: 8.00001e-04
I0512 11:30:36.876793 22485033404224 run_lib.py:167] step: 92300, eval_loss: 5.77296e-04
I0512 11:31:01.270503 22485033404224 run_lib.py:146] step: 92350, training_loss: 6.45232e-04
I0512 11:31:24.854647 22485033404224 run_lib.py:146] step: 92400, training_loss: 6.15670e-04
I0512 11:31:25.014447 22485033404224 run_lib.py:167] step: 92400, eval_loss: 6.04086e-04
I0512 11:31:48.544481 22485033404224 run_lib.py:146] step: 92450, training_loss: 6.38343e-04
I0512 11:32:12.362677 22485033404224 run_lib.py:146] step: 92500, training_loss: 5.71351e-04
I0512 11:32:12.522001 22485033404224 run_lib.py:167] step: 92500, eval_loss: 4.72711e-04
I0512 11:32:36.311702 22485033404224 run_lib.py:146] step: 92550, training_loss: 6.55366e-04
I0512 11:32:59.841876 22485033404224 run_lib.py:146] step: 92600, training_loss: 7.55273e-04
I0512 11:33:00.001661 22485033404224 run_lib.py:167] step: 92600, eval_loss: 7.19090e-04
I0512 11:33:23.839575 22485033404224 run_lib.py:146] step: 92650, training_loss: 4.67655e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 11:33:47.817039 22485033404224 run_lib.py:146] step: 92700, training_loss: 7.40090e-04
I0512 11:33:47.979515 22485033404224 run_lib.py:167] step: 92700, eval_loss: 8.53251e-04
I0512 11:34:11.499341 22485033404224 run_lib.py:146] step: 92750, training_loss: 6.98224e-04
I0512 11:34:35.387002 22485033404224 run_lib.py:146] step: 92800, training_loss: 7.88567e-04
I0512 11:34:35.547389 22485033404224 run_lib.py:167] step: 92800, eval_loss: 5.96798e-04
I0512 11:34:59.368249 22485033404224 run_lib.py:146] step: 92850, training_loss: 6.12999e-04
I0512 11:35:22.910176 22485033404224 run_lib.py:146] step: 92900, training_loss: 5.11180e-04
I0512 11:35:23.069764 22485033404224 run_lib.py:167] step: 92900, eval_loss: 5.54522e-04
I0512 11:35:46.617749 22485033404224 run_lib.py:146] step: 92950, training_loss: 5.25913e-04
I0512 11:36:10.769258 22485033404224 run_lib.py:146] step: 93000, training_loss: 6.50991e-04
I0512 11:36:10.927917 22485033404224 run_lib.py:167] step: 93000, eval_loss: 6.75746e-04
I0512 11:36:34.478419 22485033404224 run_lib.py:146] step: 93050, training_loss: 6.18036e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 11:36:58.115510 22485033404224 run_lib.py:146] step: 93100, training_loss: 7.70008e-04
I0512 11:36:58.278913 22485033404224 run_lib.py:167] step: 93100, eval_loss: 5.35214e-04
I0512 11:37:22.504697 22485033404224 run_lib.py:146] step: 93150, training_loss: 8.43170e-04
I0512 11:37:46.030130 22485033404224 run_lib.py:146] step: 93200, training_loss: 5.72265e-04
I0512 11:37:46.189555 22485033404224 run_lib.py:167] step: 93200, eval_loss: 4.62979e-04
I0512 11:38:09.699695 22485033404224 run_lib.py:146] step: 93250, training_loss: 5.98876e-04
I0512 11:38:33.517030 22485033404224 run_lib.py:146] step: 93300, training_loss: 5.99591e-04
I0512 11:38:33.677234 22485033404224 run_lib.py:167] step: 93300, eval_loss: 6.70764e-04
I0512 11:38:57.570688 22485033404224 run_lib.py:146] step: 93350, training_loss: 7.28292e-04
I0512 11:39:21.119129 22485033404224 run_lib.py:146] step: 93400, training_loss: 4.82499e-04
I0512 11:39:21.280502 22485033404224 run_lib.py:167] step: 93400, eval_loss: 6.97662e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 11:39:45.200743 22485033404224 run_lib.py:146] step: 93450, training_loss: 6.85275e-04
I0512 11:40:09.094073 22485033404224 run_lib.py:146] step: 93500, training_loss: 4.21936e-04
I0512 11:40:09.255988 22485033404224 run_lib.py:167] step: 93500, eval_loss: 6.47204e-04
I0512 11:40:32.800132 22485033404224 run_lib.py:146] step: 93550, training_loss: 5.57002e-04
I0512 11:40:56.690795 22485033404224 run_lib.py:146] step: 93600, training_loss: 7.02344e-04
I0512 11:40:56.849532 22485033404224 run_lib.py:167] step: 93600, eval_loss: 5.43940e-04
I0512 11:41:20.684758 22485033404224 run_lib.py:146] step: 93650, training_loss: 6.56667e-04
I0512 11:41:44.278809 22485033404224 run_lib.py:146] step: 93700, training_loss: 7.33725e-04
I0512 11:41:44.440282 22485033404224 run_lib.py:167] step: 93700, eval_loss: 6.99921e-04
I0512 11:42:08.052528 22485033404224 run_lib.py:146] step: 93750, training_loss: 5.99367e-04
I0512 11:42:32.297083 22485033404224 run_lib.py:146] step: 93800, training_loss: 6.97134e-04
I0512 11:42:32.457304 22485033404224 run_lib.py:167] step: 93800, eval_loss: 4.79182e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 11:42:56.113142 22485033404224 run_lib.py:146] step: 93850, training_loss: 7.12845e-04
I0512 11:43:19.700522 22485033404224 run_lib.py:146] step: 93900, training_loss: 5.76805e-04
I0512 11:43:19.862204 22485033404224 run_lib.py:167] step: 93900, eval_loss: 5.18980e-04
I0512 11:43:44.261785 22485033404224 run_lib.py:146] step: 93950, training_loss: 5.20501e-04
I0512 11:44:07.873115 22485033404224 run_lib.py:146] step: 94000, training_loss: 7.04660e-04
I0512 11:44:08.032846 22485033404224 run_lib.py:167] step: 94000, eval_loss: 5.54319e-04
I0512 11:44:31.632210 22485033404224 run_lib.py:146] step: 94050, training_loss: 7.17374e-04
I0512 11:44:55.651520 22485033404224 run_lib.py:146] step: 94100, training_loss: 6.48430e-04
I0512 11:44:55.813547 22485033404224 run_lib.py:167] step: 94100, eval_loss: 5.42090e-04
I0512 11:45:19.750599 22485033404224 run_lib.py:146] step: 94150, training_loss: 6.16921e-04
I0512 11:45:43.369580 22485033404224 run_lib.py:146] step: 94200, training_loss: 7.01378e-04
I0512 11:45:43.530416 22485033404224 run_lib.py:167] step: 94200, eval_loss: 6.21436e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 11:46:07.707015 22485033404224 run_lib.py:146] step: 94250, training_loss: 5.05079e-04
I0512 11:46:31.640910 22485033404224 run_lib.py:146] step: 94300, training_loss: 5.20094e-04
I0512 11:46:31.802128 22485033404224 run_lib.py:167] step: 94300, eval_loss: 5.29340e-04
I0512 11:46:55.420444 22485033404224 run_lib.py:146] step: 94350, training_loss: 5.31136e-04
I0512 11:47:19.371330 22485033404224 run_lib.py:146] step: 94400, training_loss: 6.84578e-04
I0512 11:47:19.532573 22485033404224 run_lib.py:167] step: 94400, eval_loss: 5.67171e-04
I0512 11:47:43.457593 22485033404224 run_lib.py:146] step: 94450, training_loss: 5.12180e-04
I0512 11:48:07.073271 22485033404224 run_lib.py:146] step: 94500, training_loss: 6.13157e-04
I0512 11:48:07.233809 22485033404224 run_lib.py:167] step: 94500, eval_loss: 7.02701e-04
I0512 11:48:31.160182 22485033404224 run_lib.py:146] step: 94550, training_loss: 6.78398e-04
I0512 11:48:55.096555 22485033404224 run_lib.py:146] step: 94600, training_loss: 5.83234e-04
I0512 11:48:55.255488 22485033404224 run_lib.py:167] step: 94600, eval_loss: 4.84440e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 11:49:18.861637 22485033404224 run_lib.py:146] step: 94650, training_loss: 5.47400e-04
I0512 11:49:42.385684 22485033404224 run_lib.py:146] step: 94700, training_loss: 7.47454e-04
I0512 11:49:42.472765 22485033404224 run_lib.py:167] step: 94700, eval_loss: 4.24420e-04
I0512 11:50:06.678885 22485033404224 run_lib.py:146] step: 94750, training_loss: 5.09065e-04
I0512 11:50:30.186629 22485033404224 run_lib.py:146] step: 94800, training_loss: 5.08464e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 11:50:30.536792 22485033404224 run_lib.py:167] step: 94800, eval_loss: 6.34084e-04
I0512 11:50:54.070829 22485033404224 run_lib.py:146] step: 94850, training_loss: 6.32979e-04
I0512 11:51:18.316234 22485033404224 run_lib.py:146] step: 94900, training_loss: 6.07518e-04
I0512 11:51:18.475808 22485033404224 run_lib.py:167] step: 94900, eval_loss: 7.51956e-04
I0512 11:51:42.008229 22485033404224 run_lib.py:146] step: 94950, training_loss: 5.57569e-04
I0512 11:52:05.547369 22485033404224 run_lib.py:146] step: 95000, training_loss: 6.29529e-04
I0512 11:52:05.706554 22485033404224 run_lib.py:167] step: 95000, eval_loss: 6.40517e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 11:52:29.636863 22485033404224 run_lib.py:146] step: 95050, training_loss: 7.07631e-04
I0512 11:52:53.527536 22485033404224 run_lib.py:146] step: 95100, training_loss: 6.35388e-04
I0512 11:52:53.689033 22485033404224 run_lib.py:167] step: 95100, eval_loss: 5.28590e-04
I0512 11:53:17.230046 22485033404224 run_lib.py:146] step: 95150, training_loss: 7.89241e-04
I0512 11:53:41.061214 22485033404224 run_lib.py:146] step: 95200, training_loss: 5.63531e-04
I0512 11:53:41.222687 22485033404224 run_lib.py:167] step: 95200, eval_loss: 6.62503e-04
I0512 11:54:05.033947 22485033404224 run_lib.py:146] step: 95250, training_loss: 7.14850e-04
I0512 11:54:28.566984 22485033404224 run_lib.py:146] step: 95300, training_loss: 6.00703e-04
I0512 11:54:28.728246 22485033404224 run_lib.py:167] step: 95300, eval_loss: 3.94583e-04
I0512 11:54:52.528476 22485033404224 run_lib.py:146] step: 95350, training_loss: 6.07930e-04
I0512 11:55:16.385617 22485033404224 run_lib.py:146] step: 95400, training_loss: 5.74856e-04
I0512 11:55:16.544862 22485033404224 run_lib.py:167] step: 95400, eval_loss: 6.52709e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 11:55:40.133499 22485033404224 run_lib.py:146] step: 95450, training_loss: 6.53833e-04
I0512 11:56:03.678326 22485033404224 run_lib.py:146] step: 95500, training_loss: 5.05695e-04
I0512 11:56:03.840345 22485033404224 run_lib.py:167] step: 95500, eval_loss: 5.74557e-04
I0512 11:56:28.039798 22485033404224 run_lib.py:146] step: 95550, training_loss: 8.23288e-04
I0512 11:56:51.552009 22485033404224 run_lib.py:146] step: 95600, training_loss: 8.05624e-04
I0512 11:56:51.710712 22485033404224 run_lib.py:167] step: 95600, eval_loss: 8.75042e-04
I0512 11:57:15.226141 22485033404224 run_lib.py:146] step: 95650, training_loss: 7.44731e-04
I0512 11:57:39.341091 22485033404224 run_lib.py:146] step: 95700, training_loss: 6.11657e-04
I0512 11:57:39.500612 22485033404224 run_lib.py:167] step: 95700, eval_loss: 6.30186e-04
I0512 11:58:03.010032 22485033404224 run_lib.py:146] step: 95750, training_loss: 5.09428e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 11:58:26.610051 22485033404224 run_lib.py:146] step: 95800, training_loss: 6.00620e-04
I0512 11:58:26.771660 22485033404224 run_lib.py:167] step: 95800, eval_loss: 8.06221e-04
I0512 11:58:50.632366 22485033404224 run_lib.py:146] step: 95850, training_loss: 5.85811e-04
I0512 11:59:14.476116 22485033404224 run_lib.py:146] step: 95900, training_loss: 4.30314e-04
I0512 11:59:14.635445 22485033404224 run_lib.py:167] step: 95900, eval_loss: 7.93079e-04
I0512 11:59:38.171196 22485033404224 run_lib.py:146] step: 95950, training_loss: 7.29791e-04
I0512 12:00:02.097949 22485033404224 run_lib.py:146] step: 96000, training_loss: 5.95159e-04
I0512 12:00:02.258518 22485033404224 run_lib.py:167] step: 96000, eval_loss: 5.82429e-04
I0512 12:00:26.187385 22485033404224 run_lib.py:146] step: 96050, training_loss: 8.44025e-04
I0512 12:00:49.813591 22485033404224 run_lib.py:146] step: 96100, training_loss: 6.60474e-04
I0512 12:00:49.973618 22485033404224 run_lib.py:167] step: 96100, eval_loss: 5.90937e-04
I0512 12:01:13.914469 22485033404224 run_lib.py:146] step: 96150, training_loss: 4.75121e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 12:01:37.912562 22485033404224 run_lib.py:146] step: 96200, training_loss: 5.80680e-04
I0512 12:01:38.074934 22485033404224 run_lib.py:167] step: 96200, eval_loss: 7.33390e-04
I0512 12:02:01.671905 22485033404224 run_lib.py:146] step: 96250, training_loss: 6.10310e-04
I0512 12:02:25.274449 22485033404224 run_lib.py:146] step: 96300, training_loss: 6.37789e-04
I0512 12:02:25.435787 22485033404224 run_lib.py:167] step: 96300, eval_loss: 7.14909e-04
I0512 12:02:49.788543 22485033404224 run_lib.py:146] step: 96350, training_loss: 8.59093e-04
I0512 12:03:13.400253 22485033404224 run_lib.py:146] step: 96400, training_loss: 6.09301e-04
I0512 12:03:13.560276 22485033404224 run_lib.py:167] step: 96400, eval_loss: 5.57066e-04
I0512 12:03:37.155661 22485033404224 run_lib.py:146] step: 96450, training_loss: 5.39651e-04
I0512 12:04:01.496249 22485033404224 run_lib.py:146] step: 96500, training_loss: 7.80070e-04
I0512 12:04:01.656116 22485033404224 run_lib.py:167] step: 96500, eval_loss: 6.05485e-04
I0512 12:04:25.307490 22485033404224 run_lib.py:146] step: 96550, training_loss: 5.44565e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 12:04:49.032715 22485033404224 run_lib.py:146] step: 96600, training_loss: 6.36255e-04
I0512 12:04:49.196375 22485033404224 run_lib.py:167] step: 96600, eval_loss: 5.69164e-04
I0512 12:05:13.213460 22485033404224 run_lib.py:146] step: 96650, training_loss: 5.45235e-04
I0512 12:05:37.274111 22485033404224 run_lib.py:146] step: 96700, training_loss: 5.41316e-04
I0512 12:05:37.435272 22485033404224 run_lib.py:167] step: 96700, eval_loss: 6.07947e-04
I0512 12:06:01.082973 22485033404224 run_lib.py:146] step: 96750, training_loss: 5.44688e-04
I0512 12:06:25.016301 22485033404224 run_lib.py:146] step: 96800, training_loss: 5.16576e-04
I0512 12:06:25.176897 22485033404224 run_lib.py:167] step: 96800, eval_loss: 6.01429e-04
I0512 12:06:49.177482 22485033404224 run_lib.py:146] step: 96850, training_loss: 6.33896e-04
I0512 12:07:12.807526 22485033404224 run_lib.py:146] step: 96900, training_loss: 6.97538e-04
I0512 12:07:12.966505 22485033404224 run_lib.py:167] step: 96900, eval_loss: 8.95412e-04
I0512 12:07:36.859602 22485033404224 run_lib.py:146] step: 96950, training_loss: 6.52614e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 12:08:00.864473 22485033404224 run_lib.py:146] step: 97000, training_loss: 5.48506e-04
I0512 12:08:01.025194 22485033404224 run_lib.py:167] step: 97000, eval_loss: 5.78069e-04
I0512 12:08:24.542758 22485033404224 run_lib.py:146] step: 97050, training_loss: 6.59855e-04
I0512 12:08:48.052442 22485033404224 run_lib.py:146] step: 97100, training_loss: 6.76959e-04
I0512 12:08:48.213053 22485033404224 run_lib.py:167] step: 97100, eval_loss: 5.22995e-04
I0512 12:09:12.343802 22485033404224 run_lib.py:146] step: 97150, training_loss: 6.85305e-04
I0512 12:09:35.878636 22485033404224 run_lib.py:146] step: 97200, training_loss: 6.72228e-04
I0512 12:09:36.037061 22485033404224 run_lib.py:167] step: 97200, eval_loss: 6.29555e-04
I0512 12:09:59.558746 22485033404224 run_lib.py:146] step: 97250, training_loss: 7.40338e-04
I0512 12:10:23.686682 22485033404224 run_lib.py:146] step: 97300, training_loss: 4.88463e-04
I0512 12:10:23.846313 22485033404224 run_lib.py:167] step: 97300, eval_loss: 4.73420e-04
I0512 12:10:47.363389 22485033404224 run_lib.py:146] step: 97350, training_loss: 6.83292e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 12:11:10.968273 22485033404224 run_lib.py:146] step: 97400, training_loss: 6.00302e-04
I0512 12:11:11.129680 22485033404224 run_lib.py:167] step: 97400, eval_loss: 7.64092e-04
I0512 12:11:35.313658 22485033404224 run_lib.py:146] step: 97450, training_loss: 7.28775e-04
I0512 12:11:58.836465 22485033404224 run_lib.py:146] step: 97500, training_loss: 5.08159e-04
I0512 12:11:58.995480 22485033404224 run_lib.py:167] step: 97500, eval_loss: 4.90177e-04
I0512 12:12:22.528348 22485033404224 run_lib.py:146] step: 97550, training_loss: 5.76693e-04
I0512 12:12:46.345819 22485033404224 run_lib.py:146] step: 97600, training_loss: 5.49356e-04
I0512 12:12:46.504200 22485033404224 run_lib.py:167] step: 97600, eval_loss: 4.86464e-04
I0512 12:13:10.323485 22485033404224 run_lib.py:146] step: 97650, training_loss: 5.89484e-04
I0512 12:13:33.848888 22485033404224 run_lib.py:146] step: 97700, training_loss: 5.87036e-04
I0512 12:13:34.009171 22485033404224 run_lib.py:167] step: 97700, eval_loss: 5.57903e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 12:13:57.919417 22485033404224 run_lib.py:146] step: 97750, training_loss: 5.40294e-04
I0512 12:14:21.821791 22485033404224 run_lib.py:146] step: 97800, training_loss: 7.72373e-04
I0512 12:14:21.984270 22485033404224 run_lib.py:167] step: 97800, eval_loss: 5.89394e-04
I0512 12:14:45.513276 22485033404224 run_lib.py:146] step: 97850, training_loss: 7.28547e-04
I0512 12:15:09.045994 22485033404224 run_lib.py:146] step: 97900, training_loss: 7.07872e-04
I0512 12:15:09.205717 22485033404224 run_lib.py:167] step: 97900, eval_loss: 7.27759e-04
I0512 12:15:33.354176 22485033404224 run_lib.py:146] step: 97950, training_loss: 6.55469e-04
I0512 12:15:56.883417 22485033404224 run_lib.py:146] step: 98000, training_loss: 5.22135e-04
I0512 12:15:57.042168 22485033404224 run_lib.py:167] step: 98000, eval_loss: 4.83320e-04
I0512 12:16:20.552535 22485033404224 run_lib.py:146] step: 98050, training_loss: 5.82142e-04
I0512 12:16:44.702717 22485033404224 run_lib.py:146] step: 98100, training_loss: 6.18829e-04
I0512 12:16:44.862588 22485033404224 run_lib.py:167] step: 98100, eval_loss: 5.97441e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 12:17:08.450772 22485033404224 run_lib.py:146] step: 98150, training_loss: 5.80462e-04
I0512 12:17:31.975658 22485033404224 run_lib.py:146] step: 98200, training_loss: 5.84051e-04
I0512 12:17:32.135991 22485033404224 run_lib.py:167] step: 98200, eval_loss: 6.73260e-04
I0512 12:17:56.361956 22485033404224 run_lib.py:146] step: 98250, training_loss: 7.06782e-04
I0512 12:18:19.936713 22485033404224 run_lib.py:146] step: 98300, training_loss: 6.73353e-04
I0512 12:18:20.096734 22485033404224 run_lib.py:167] step: 98300, eval_loss: 6.27450e-04
I0512 12:18:43.680943 22485033404224 run_lib.py:146] step: 98350, training_loss: 5.22312e-04
I0512 12:19:07.550894 22485033404224 run_lib.py:146] step: 98400, training_loss: 6.89603e-04
I0512 12:19:07.711643 22485033404224 run_lib.py:167] step: 98400, eval_loss: 5.29283e-04
I0512 12:19:31.613069 22485033404224 run_lib.py:146] step: 98450, training_loss: 7.01924e-04
I0512 12:19:55.230525 22485033404224 run_lib.py:146] step: 98500, training_loss: 5.47530e-04
I0512 12:19:55.391092 22485033404224 run_lib.py:167] step: 98500, eval_loss: 4.46936e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 12:20:19.540967 22485033404224 run_lib.py:146] step: 98550, training_loss: 5.78972e-04
I0512 12:20:43.606902 22485033404224 run_lib.py:146] step: 98600, training_loss: 6.01761e-04
I0512 12:20:43.768782 22485033404224 run_lib.py:167] step: 98600, eval_loss: 4.92076e-04
I0512 12:21:07.391788 22485033404224 run_lib.py:146] step: 98650, training_loss: 5.33169e-04
I0512 12:21:31.038480 22485033404224 run_lib.py:146] step: 98700, training_loss: 5.70315e-04
I0512 12:21:31.198308 22485033404224 run_lib.py:167] step: 98700, eval_loss: 6.05983e-04
I0512 12:21:55.635549 22485033404224 run_lib.py:146] step: 98750, training_loss: 6.44487e-04
I0512 12:22:19.297781 22485033404224 run_lib.py:146] step: 98800, training_loss: 5.28587e-04
I0512 12:22:19.458818 22485033404224 run_lib.py:167] step: 98800, eval_loss: 7.20581e-04
I0512 12:22:43.060014 22485033404224 run_lib.py:146] step: 98850, training_loss: 6.06636e-04
I0512 12:23:07.498545 22485033404224 run_lib.py:146] step: 98900, training_loss: 7.11236e-04
I0512 12:23:07.659186 22485033404224 run_lib.py:167] step: 98900, eval_loss: 6.03391e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 12:23:31.367702 22485033404224 run_lib.py:146] step: 98950, training_loss: 6.35579e-04
I0512 12:23:54.988870 22485033404224 run_lib.py:146] step: 99000, training_loss: 6.10818e-04
I0512 12:23:55.151210 22485033404224 run_lib.py:167] step: 99000, eval_loss: 4.57996e-04
I0512 12:24:19.630201 22485033404224 run_lib.py:146] step: 99050, training_loss: 6.11677e-04
I0512 12:24:43.248889 22485033404224 run_lib.py:146] step: 99100, training_loss: 5.24828e-04
I0512 12:24:43.410189 22485033404224 run_lib.py:167] step: 99100, eval_loss: 5.56670e-04
I0512 12:25:07.014950 22485033404224 run_lib.py:146] step: 99150, training_loss: 6.00809e-04
I0512 12:25:30.943331 22485033404224 run_lib.py:146] step: 99200, training_loss: 5.88413e-04
I0512 12:25:31.102728 22485033404224 run_lib.py:167] step: 99200, eval_loss: 5.64281e-04
I0512 12:25:55.046389 22485033404224 run_lib.py:146] step: 99250, training_loss: 7.12163e-04
I0512 12:26:18.551713 22485033404224 run_lib.py:146] step: 99300, training_loss: 5.37174e-04
I0512 12:26:18.712085 22485033404224 run_lib.py:167] step: 99300, eval_loss: 6.92519e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 12:26:42.699477 22485033404224 run_lib.py:146] step: 99350, training_loss: 5.04638e-04
I0512 12:27:06.567642 22485033404224 run_lib.py:146] step: 99400, training_loss: 5.49513e-04
I0512 12:27:06.728315 22485033404224 run_lib.py:167] step: 99400, eval_loss: 5.93406e-04
I0512 12:27:30.225327 22485033404224 run_lib.py:146] step: 99450, training_loss: 5.97387e-04
I0512 12:27:53.762637 22485033404224 run_lib.py:146] step: 99500, training_loss: 4.97453e-04
I0512 12:27:53.922279 22485033404224 run_lib.py:167] step: 99500, eval_loss: 5.50693e-04
I0512 12:28:18.079388 22485033404224 run_lib.py:146] step: 99550, training_loss: 7.08483e-04
I0512 12:28:41.604736 22485033404224 run_lib.py:146] step: 99600, training_loss: 6.37637e-04
I0512 12:28:41.763463 22485033404224 run_lib.py:167] step: 99600, eval_loss: 6.18158e-04
I0512 12:29:05.278549 22485033404224 run_lib.py:146] step: 99650, training_loss: 6.13369e-04
I0512 12:29:29.410803 22485033404224 run_lib.py:146] step: 99700, training_loss: 5.33823e-04
I0512 12:29:29.571745 22485033404224 run_lib.py:167] step: 99700, eval_loss: 5.71567e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 12:29:53.166250 22485033404224 run_lib.py:146] step: 99750, training_loss: 8.43480e-04
I0512 12:30:16.713016 22485033404224 run_lib.py:146] step: 99800, training_loss: 5.52420e-04
I0512 12:30:16.873217 22485033404224 run_lib.py:167] step: 99800, eval_loss: 6.77027e-04
I0512 12:30:41.071265 22485033404224 run_lib.py:146] step: 99850, training_loss: 7.43235e-04
I0512 12:31:04.615626 22485033404224 run_lib.py:146] step: 99900, training_loss: 7.77033e-04
I0512 12:31:04.774632 22485033404224 run_lib.py:167] step: 99900, eval_loss: 4.62451e-04
I0512 12:31:28.305347 22485033404224 run_lib.py:146] step: 99950, training_loss: 6.20031e-04
I0512 12:31:52.163235 22485033404224 run_lib.py:146] step: 100000, training_loss: 7.17749e-04
I0512 12:31:58.601511 22485033404224 run_lib.py:167] step: 100000, eval_loss: 7.97734e-04
I0512 12:32:29.293527 22485033404224 run_lib.py:146] step: 100050, training_loss: 6.59261e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 12:32:53.147711 22485033404224 run_lib.py:146] step: 100100, training_loss: 5.29255e-04
I0512 12:32:53.308345 22485033404224 run_lib.py:167] step: 100100, eval_loss: 6.66810e-04
I0512 12:33:16.833967 22485033404224 run_lib.py:146] step: 100150, training_loss: 6.92324e-04
I0512 12:33:40.697080 22485033404224 run_lib.py:146] step: 100200, training_loss: 5.95549e-04
I0512 12:33:40.857095 22485033404224 run_lib.py:167] step: 100200, eval_loss: 7.44549e-04
I0512 12:34:04.725394 22485033404224 run_lib.py:146] step: 100250, training_loss: 5.02433e-04
I0512 12:34:28.260458 22485033404224 run_lib.py:146] step: 100300, training_loss: 5.83105e-04
I0512 12:34:28.419919 22485033404224 run_lib.py:167] step: 100300, eval_loss: 6.25736e-04
I0512 12:34:52.227057 22485033404224 run_lib.py:146] step: 100350, training_loss: 5.91524e-04
I0512 12:35:15.756964 22485033404224 run_lib.py:146] step: 100400, training_loss: 5.99806e-04
I0512 12:35:15.916778 22485033404224 run_lib.py:167] step: 100400, eval_loss: 7.70882e-04
I0512 12:35:39.766505 22485033404224 run_lib.py:146] step: 100450, training_loss: 6.31178e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 12:36:03.738945 22485033404224 run_lib.py:146] step: 100500, training_loss: 5.45144e-04
I0512 12:36:03.902005 22485033404224 run_lib.py:167] step: 100500, eval_loss: 5.64819e-04
I0512 12:36:27.546510 22485033404224 run_lib.py:146] step: 100550, training_loss: 5.49349e-04
I0512 12:36:51.530473 22485033404224 run_lib.py:146] step: 100600, training_loss: 6.67776e-04
I0512 12:36:51.690946 22485033404224 run_lib.py:167] step: 100600, eval_loss: 5.60873e-04
I0512 12:37:15.669603 22485033404224 run_lib.py:146] step: 100650, training_loss: 6.53673e-04
I0512 12:37:39.294565 22485033404224 run_lib.py:146] step: 100700, training_loss: 5.24638e-04
I0512 12:37:39.454040 22485033404224 run_lib.py:167] step: 100700, eval_loss: 7.16750e-04
I0512 12:38:03.349555 22485033404224 run_lib.py:146] step: 100750, training_loss: 4.62582e-04
I0512 12:38:27.276824 22485033404224 run_lib.py:146] step: 100800, training_loss: 4.45007e-04
I0512 12:38:27.436421 22485033404224 run_lib.py:167] step: 100800, eval_loss: 5.42561e-04
I0512 12:38:51.040287 22485033404224 run_lib.py:146] step: 100850, training_loss: 6.87717e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 12:39:15.166840 22485033404224 run_lib.py:146] step: 100900, training_loss: 7.08641e-04
I0512 12:39:15.328734 22485033404224 run_lib.py:167] step: 100900, eval_loss: 6.68797e-04
I0512 12:39:39.017697 22485033404224 run_lib.py:146] step: 100950, training_loss: 7.48326e-04
I0512 12:40:03.131696 22485033404224 run_lib.py:146] step: 101000, training_loss: 5.15189e-04
I0512 12:40:03.293581 22485033404224 run_lib.py:167] step: 101000, eval_loss: 7.30907e-04
I0512 12:40:27.340163 22485033404224 run_lib.py:146] step: 101050, training_loss: 6.80293e-04
I0512 12:40:50.938852 22485033404224 run_lib.py:146] step: 101100, training_loss: 7.74685e-04
I0512 12:40:51.098678 22485033404224 run_lib.py:167] step: 101100, eval_loss: 7.99117e-04
I0512 12:41:15.085525 22485033404224 run_lib.py:146] step: 101150, training_loss: 5.05687e-04
I0512 12:41:38.683341 22485033404224 run_lib.py:146] step: 101200, training_loss: 8.34659e-04
I0512 12:41:38.844127 22485033404224 run_lib.py:167] step: 101200, eval_loss: 7.12910e-04
I0512 12:42:02.757987 22485033404224 run_lib.py:146] step: 101250, training_loss: 5.16814e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 12:42:26.810368 22485033404224 run_lib.py:146] step: 101300, training_loss: 5.06150e-04
I0512 12:42:26.972917 22485033404224 run_lib.py:167] step: 101300, eval_loss: 6.01801e-04
I0512 12:42:50.591375 22485033404224 run_lib.py:146] step: 101350, training_loss: 6.24632e-04
I0512 12:43:14.532874 22485033404224 run_lib.py:146] step: 101400, training_loss: 6.68035e-04
I0512 12:43:14.692707 22485033404224 run_lib.py:167] step: 101400, eval_loss: 7.95765e-04
I0512 12:43:38.574476 22485033404224 run_lib.py:146] step: 101450, training_loss: 6.49901e-04
I0512 12:44:02.126307 22485033404224 run_lib.py:146] step: 101500, training_loss: 7.87550e-04
I0512 12:44:02.285398 22485033404224 run_lib.py:167] step: 101500, eval_loss: 7.91064e-04
I0512 12:44:26.123148 22485033404224 run_lib.py:146] step: 101550, training_loss: 6.77257e-04
I0512 12:44:49.922494 22485033404224 run_lib.py:146] step: 101600, training_loss: 7.11789e-04
I0512 12:44:50.081696 22485033404224 run_lib.py:167] step: 101600, eval_loss: 5.25634e-04
I0512 12:45:13.611452 22485033404224 run_lib.py:146] step: 101650, training_loss: 5.72682e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 12:45:37.547271 22485033404224 run_lib.py:146] step: 101700, training_loss: 6.02867e-04
I0512 12:45:37.707586 22485033404224 run_lib.py:167] step: 101700, eval_loss: 5.90800e-04
I0512 12:46:01.568573 22485033404224 run_lib.py:146] step: 101750, training_loss: 7.29605e-04
I0512 12:46:25.081661 22485033404224 run_lib.py:146] step: 101800, training_loss: 6.24128e-04
I0512 12:46:25.241290 22485033404224 run_lib.py:167] step: 101800, eval_loss: 5.01868e-04
I0512 12:46:49.090331 22485033404224 run_lib.py:146] step: 101850, training_loss: 8.15298e-04
I0512 12:47:12.625670 22485033404224 run_lib.py:146] step: 101900, training_loss: 5.38032e-04
I0512 12:47:12.784062 22485033404224 run_lib.py:167] step: 101900, eval_loss: 7.15292e-04
I0512 12:47:36.619522 22485033404224 run_lib.py:146] step: 101950, training_loss: 5.28410e-04
I0512 12:48:00.177620 22485033404224 run_lib.py:146] step: 102000, training_loss: 8.03651e-04
I0512 12:48:00.339024 22485033404224 run_lib.py:167] step: 102000, eval_loss: 6.11320e-04
I0512 12:48:24.046967 22485033404224 run_lib.py:146] step: 102050, training_loss: 7.32030e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 12:48:48.166538 22485033404224 run_lib.py:146] step: 102100, training_loss: 6.58364e-04
I0512 12:48:48.327206 22485033404224 run_lib.py:167] step: 102100, eval_loss: 5.49239e-04
I0512 12:49:11.859066 22485033404224 run_lib.py:146] step: 102150, training_loss: 4.72675e-04
I0512 12:49:35.726432 22485033404224 run_lib.py:146] step: 102200, training_loss: 6.57010e-04
I0512 12:49:35.886266 22485033404224 run_lib.py:167] step: 102200, eval_loss: 6.57815e-04
I0512 12:49:59.718776 22485033404224 run_lib.py:146] step: 102250, training_loss: 7.38658e-04
I0512 12:50:23.252889 22485033404224 run_lib.py:146] step: 102300, training_loss: 7.36920e-04
I0512 12:50:23.412438 22485033404224 run_lib.py:167] step: 102300, eval_loss: 5.48692e-04
I0512 12:50:47.247448 22485033404224 run_lib.py:146] step: 102350, training_loss: 7.20407e-04
I0512 12:51:11.068512 22485033404224 run_lib.py:146] step: 102400, training_loss: 7.58806e-04
I0512 12:51:11.227015 22485033404224 run_lib.py:167] step: 102400, eval_loss: 6.61504e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 12:51:34.825276 22485033404224 run_lib.py:146] step: 102450, training_loss: 4.61777e-04
I0512 12:51:58.690126 22485033404224 run_lib.py:146] step: 102500, training_loss: 5.94744e-04
I0512 12:51:58.848821 22485033404224 run_lib.py:167] step: 102500, eval_loss: 6.48445e-04
I0512 12:52:22.707702 22485033404224 run_lib.py:146] step: 102550, training_loss: 5.69293e-04
I0512 12:52:46.223674 22485033404224 run_lib.py:146] step: 102600, training_loss: 6.15568e-04
I0512 12:52:46.307832 22485033404224 run_lib.py:167] step: 102600, eval_loss: 1.29472e-03
I0512 12:53:10.163056 22485033404224 run_lib.py:146] step: 102650, training_loss: 7.63575e-04
I0512 12:53:33.695683 22485033404224 run_lib.py:146] step: 102700, training_loss: 5.58819e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 12:53:34.041428 22485033404224 run_lib.py:167] step: 102700, eval_loss: 5.43669e-04
I0512 12:53:57.943188 22485033404224 run_lib.py:146] step: 102750, training_loss: 5.12243e-04
I0512 12:54:21.547216 22485033404224 run_lib.py:146] step: 102800, training_loss: 5.24969e-04
I0512 12:54:21.707495 22485033404224 run_lib.py:167] step: 102800, eval_loss: 6.88323e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 12:54:45.738137 22485033404224 run_lib.py:146] step: 102850, training_loss: 5.57683e-04
I0512 12:55:09.717429 22485033404224 run_lib.py:146] step: 102900, training_loss: 8.88735e-04
I0512 12:55:09.880391 22485033404224 run_lib.py:167] step: 102900, eval_loss: 6.46039e-04
I0512 12:55:33.524355 22485033404224 run_lib.py:146] step: 102950, training_loss: 6.60364e-04
I0512 12:55:57.576339 22485033404224 run_lib.py:146] step: 103000, training_loss: 6.56154e-04
I0512 12:55:57.736834 22485033404224 run_lib.py:167] step: 103000, eval_loss: 6.28868e-04
I0512 12:56:21.672568 22485033404224 run_lib.py:146] step: 103050, training_loss: 7.64471e-04
I0512 12:56:45.289025 22485033404224 run_lib.py:146] step: 103100, training_loss: 4.83834e-04
I0512 12:56:45.449732 22485033404224 run_lib.py:167] step: 103100, eval_loss: 8.67531e-04
I0512 12:57:09.463598 22485033404224 run_lib.py:146] step: 103150, training_loss: 4.94047e-04
I0512 12:57:33.372109 22485033404224 run_lib.py:146] step: 103200, training_loss: 7.33347e-04
I0512 12:57:33.532578 22485033404224 run_lib.py:167] step: 103200, eval_loss: 4.54849e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 12:57:57.309149 22485033404224 run_lib.py:146] step: 103250, training_loss: 6.91366e-04
I0512 12:58:21.609515 22485033404224 run_lib.py:146] step: 103300, training_loss: 5.95878e-04
I0512 12:58:21.771224 22485033404224 run_lib.py:167] step: 103300, eval_loss: 6.77789e-04
I0512 12:58:45.834249 22485033404224 run_lib.py:146] step: 103350, training_loss: 6.10236e-04
I0512 12:59:09.481314 22485033404224 run_lib.py:146] step: 103400, training_loss: 7.76842e-04
I0512 12:59:09.641481 22485033404224 run_lib.py:167] step: 103400, eval_loss: 5.58962e-04
I0512 12:59:33.595801 22485033404224 run_lib.py:146] step: 103450, training_loss: 6.18953e-04
I0512 12:59:57.538767 22485033404224 run_lib.py:146] step: 103500, training_loss: 6.63068e-04
I0512 12:59:57.698243 22485033404224 run_lib.py:167] step: 103500, eval_loss: 5.36475e-04
I0512 13:00:21.328085 22485033404224 run_lib.py:146] step: 103550, training_loss: 6.26009e-04
I0512 13:00:45.268958 22485033404224 run_lib.py:146] step: 103600, training_loss: 5.96643e-04
I0512 13:00:45.428748 22485033404224 run_lib.py:167] step: 103600, eval_loss: 8.72221e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 13:01:09.075030 22485033404224 run_lib.py:146] step: 103650, training_loss: 5.60894e-04
I0512 13:01:32.962771 22485033404224 run_lib.py:146] step: 103700, training_loss: 6.30210e-04
I0512 13:01:33.123750 22485033404224 run_lib.py:167] step: 103700, eval_loss: 6.82740e-04
I0512 13:01:56.637563 22485033404224 run_lib.py:146] step: 103750, training_loss: 7.30539e-04
I0512 13:02:20.523955 22485033404224 run_lib.py:146] step: 103800, training_loss: 4.27375e-04
I0512 13:02:20.684168 22485033404224 run_lib.py:167] step: 103800, eval_loss: 8.34005e-04
I0512 13:02:44.485956 22485033404224 run_lib.py:146] step: 103850, training_loss: 6.21388e-04
I0512 13:03:08.003978 22485033404224 run_lib.py:146] step: 103900, training_loss: 6.42137e-04
I0512 13:03:08.163003 22485033404224 run_lib.py:167] step: 103900, eval_loss: 5.26948e-04
I0512 13:03:31.976640 22485033404224 run_lib.py:146] step: 103950, training_loss: 6.92516e-04
I0512 13:03:55.820526 22485033404224 run_lib.py:146] step: 104000, training_loss: 6.87818e-04
I0512 13:03:55.980674 22485033404224 run_lib.py:167] step: 104000, eval_loss: 5.85001e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 13:04:19.598899 22485033404224 run_lib.py:146] step: 104050, training_loss: 5.88682e-04
I0512 13:04:43.523218 22485033404224 run_lib.py:146] step: 104100, training_loss: 5.90985e-04
I0512 13:04:43.685509 22485033404224 run_lib.py:167] step: 104100, eval_loss: 5.67722e-04
I0512 13:05:07.526668 22485033404224 run_lib.py:146] step: 104150, training_loss: 4.36834e-04
I0512 13:05:31.075248 22485033404224 run_lib.py:146] step: 104200, training_loss: 7.31386e-04
I0512 13:05:31.233984 22485033404224 run_lib.py:167] step: 104200, eval_loss: 7.02132e-04
I0512 13:05:55.071518 22485033404224 run_lib.py:146] step: 104250, training_loss: 4.93204e-04
I0512 13:06:18.905579 22485033404224 run_lib.py:146] step: 104300, training_loss: 8.56158e-04
I0512 13:06:19.065998 22485033404224 run_lib.py:167] step: 104300, eval_loss: 5.39968e-04
I0512 13:06:42.586419 22485033404224 run_lib.py:146] step: 104350, training_loss: 7.04550e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 13:07:06.480816 22485033404224 run_lib.py:146] step: 104400, training_loss: 7.97444e-04
I0512 13:07:06.641396 22485033404224 run_lib.py:167] step: 104400, eval_loss: 6.83292e-04
I0512 13:07:30.501379 22485033404224 run_lib.py:146] step: 104450, training_loss: 7.35725e-04
I0512 13:07:54.048303 22485033404224 run_lib.py:146] step: 104500, training_loss: 4.93362e-04
I0512 13:07:54.208440 22485033404224 run_lib.py:167] step: 104500, eval_loss: 6.10722e-04
I0512 13:08:17.752945 22485033404224 run_lib.py:146] step: 104550, training_loss: 6.58149e-04
I0512 13:08:41.648584 22485033404224 run_lib.py:146] step: 104600, training_loss: 5.72842e-04
I0512 13:08:41.808448 22485033404224 run_lib.py:167] step: 104600, eval_loss: 6.75525e-04
I0512 13:09:05.628044 22485033404224 run_lib.py:146] step: 104650, training_loss: 4.80046e-04
I0512 13:09:29.190403 22485033404224 run_lib.py:146] step: 104700, training_loss: 6.17631e-04
I0512 13:09:29.351295 22485033404224 run_lib.py:167] step: 104700, eval_loss: 5.94493e-04
I0512 13:09:53.176374 22485033404224 run_lib.py:146] step: 104750, training_loss: 6.61730e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 13:10:17.095930 22485033404224 run_lib.py:146] step: 104800, training_loss: 9.07425e-04
I0512 13:10:17.257122 22485033404224 run_lib.py:167] step: 104800, eval_loss: 5.96178e-04
I0512 13:10:40.779883 22485033404224 run_lib.py:146] step: 104850, training_loss: 7.08982e-04
I0512 13:11:04.629066 22485033404224 run_lib.py:146] step: 104900, training_loss: 5.31978e-04
I0512 13:11:04.789195 22485033404224 run_lib.py:167] step: 104900, eval_loss: 7.71245e-04
I0512 13:11:28.665449 22485033404224 run_lib.py:146] step: 104950, training_loss: 5.01227e-04
I0512 13:11:52.253015 22485033404224 run_lib.py:146] step: 105000, training_loss: 7.50898e-04
I0512 13:11:52.413426 22485033404224 run_lib.py:167] step: 105000, eval_loss: 7.15680e-04
I0512 13:12:16.297251 22485033404224 run_lib.py:146] step: 105050, training_loss: 7.91632e-04
I0512 13:12:40.260283 22485033404224 run_lib.py:146] step: 105100, training_loss: 5.41738e-04
I0512 13:12:40.420988 22485033404224 run_lib.py:167] step: 105100, eval_loss: 7.53195e-04
I0512 13:13:04.047108 22485033404224 run_lib.py:146] step: 105150, training_loss: 6.26088e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 13:13:28.245144 22485033404224 run_lib.py:146] step: 105200, training_loss: 6.37360e-04
I0512 13:13:28.407563 22485033404224 run_lib.py:167] step: 105200, eval_loss: 5.68972e-04
I0512 13:13:52.441890 22485033404224 run_lib.py:146] step: 105250, training_loss: 6.44487e-04
I0512 13:14:16.037976 22485033404224 run_lib.py:146] step: 105300, training_loss: 5.50687e-04
I0512 13:14:16.199569 22485033404224 run_lib.py:167] step: 105300, eval_loss: 5.86858e-04
I0512 13:14:40.192622 22485033404224 run_lib.py:146] step: 105350, training_loss: 6.02354e-04
I0512 13:15:03.763817 22485033404224 run_lib.py:146] step: 105400, training_loss: 7.51375e-04
I0512 13:15:03.924342 22485033404224 run_lib.py:167] step: 105400, eval_loss: 5.46976e-04
I0512 13:15:27.810220 22485033404224 run_lib.py:146] step: 105450, training_loss: 8.03045e-04
I0512 13:15:51.423392 22485033404224 run_lib.py:146] step: 105500, training_loss: 7.42821e-04
I0512 13:15:51.584708 22485033404224 run_lib.py:167] step: 105500, eval_loss: 6.63199e-04
I0512 13:16:15.571269 22485033404224 run_lib.py:146] step: 105550, training_loss: 8.15965e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 13:16:39.566282 22485033404224 run_lib.py:146] step: 105600, training_loss: 4.98846e-04
I0512 13:16:39.728067 22485033404224 run_lib.py:167] step: 105600, eval_loss: 5.91555e-04
I0512 13:17:03.353322 22485033404224 run_lib.py:146] step: 105650, training_loss: 6.32402e-04
I0512 13:17:27.325254 22485033404224 run_lib.py:146] step: 105700, training_loss: 6.04420e-04
I0512 13:17:27.485239 22485033404224 run_lib.py:167] step: 105700, eval_loss: 5.38136e-04
I0512 13:17:51.516350 22485033404224 run_lib.py:146] step: 105750, training_loss: 7.13007e-04
I0512 13:18:15.150077 22485033404224 run_lib.py:146] step: 105800, training_loss: 1.03945e-03
I0512 13:18:15.310432 22485033404224 run_lib.py:167] step: 105800, eval_loss: 6.41527e-04
I0512 13:18:39.211810 22485033404224 run_lib.py:146] step: 105850, training_loss: 6.37005e-04
I0512 13:19:03.174771 22485033404224 run_lib.py:146] step: 105900, training_loss: 7.84107e-04
I0512 13:19:03.335495 22485033404224 run_lib.py:167] step: 105900, eval_loss: 6.29739e-04
I0512 13:19:26.878124 22485033404224 run_lib.py:146] step: 105950, training_loss: 5.22989e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 13:19:50.833321 22485033404224 run_lib.py:146] step: 106000, training_loss: 7.46015e-04
I0512 13:19:50.996115 22485033404224 run_lib.py:167] step: 106000, eval_loss: 5.52608e-04
I0512 13:20:14.863423 22485033404224 run_lib.py:146] step: 106050, training_loss: 6.51687e-04
I0512 13:20:38.403978 22485033404224 run_lib.py:146] step: 106100, training_loss: 6.90733e-04
I0512 13:20:38.564398 22485033404224 run_lib.py:167] step: 106100, eval_loss: 6.18836e-04
I0512 13:21:02.399926 22485033404224 run_lib.py:146] step: 106150, training_loss: 5.32148e-04
I0512 13:21:25.927825 22485033404224 run_lib.py:146] step: 106200, training_loss: 4.98182e-04
I0512 13:21:26.087584 22485033404224 run_lib.py:167] step: 106200, eval_loss: 6.17929e-04
I0512 13:21:49.873350 22485033404224 run_lib.py:146] step: 106250, training_loss: 6.39794e-04
I0512 13:22:13.367376 22485033404224 run_lib.py:146] step: 106300, training_loss: 9.27805e-04
I0512 13:22:13.526712 22485033404224 run_lib.py:167] step: 106300, eval_loss: 7.02505e-04
I0512 13:22:37.365724 22485033404224 run_lib.py:146] step: 106350, training_loss: 6.90078e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 13:23:01.340871 22485033404224 run_lib.py:146] step: 106400, training_loss: 4.44477e-04
I0512 13:23:01.502805 22485033404224 run_lib.py:167] step: 106400, eval_loss: 8.30324e-04
I0512 13:23:25.073755 22485033404224 run_lib.py:146] step: 106450, training_loss: 7.42462e-04
I0512 13:23:48.986442 22485033404224 run_lib.py:146] step: 106500, training_loss: 9.49617e-04
I0512 13:23:49.146676 22485033404224 run_lib.py:167] step: 106500, eval_loss: 7.92889e-04
I0512 13:24:12.991091 22485033404224 run_lib.py:146] step: 106550, training_loss: 7.01967e-04
I0512 13:24:36.539961 22485033404224 run_lib.py:146] step: 106600, training_loss: 6.61604e-04
I0512 13:24:36.699975 22485033404224 run_lib.py:167] step: 106600, eval_loss: 6.84375e-04
I0512 13:25:00.528775 22485033404224 run_lib.py:146] step: 106650, training_loss: 6.60682e-04
I0512 13:25:24.352657 22485033404224 run_lib.py:146] step: 106700, training_loss: 6.41169e-04
I0512 13:25:24.512768 22485033404224 run_lib.py:167] step: 106700, eval_loss: 5.64262e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 13:25:48.125278 22485033404224 run_lib.py:146] step: 106750, training_loss: 4.90681e-04
I0512 13:26:12.015996 22485033404224 run_lib.py:146] step: 106800, training_loss: 5.58823e-04
I0512 13:26:12.176390 22485033404224 run_lib.py:167] step: 106800, eval_loss: 4.84924e-04
I0512 13:26:36.074930 22485033404224 run_lib.py:146] step: 106850, training_loss: 6.46873e-04
I0512 13:26:59.629361 22485033404224 run_lib.py:146] step: 106900, training_loss: 6.37863e-04
I0512 13:26:59.790845 22485033404224 run_lib.py:167] step: 106900, eval_loss: 6.08339e-04
I0512 13:27:23.616309 22485033404224 run_lib.py:146] step: 106950, training_loss: 5.98304e-04
I0512 13:27:47.429717 22485033404224 run_lib.py:146] step: 107000, training_loss: 8.78767e-04
I0512 13:27:47.589428 22485033404224 run_lib.py:167] step: 107000, eval_loss: 4.47901e-04
I0512 13:28:11.124165 22485033404224 run_lib.py:146] step: 107050, training_loss: 7.40353e-04
I0512 13:28:34.968821 22485033404224 run_lib.py:146] step: 107100, training_loss: 4.85458e-04
I0512 13:28:35.128233 22485033404224 run_lib.py:167] step: 107100, eval_loss: 7.56386e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 13:28:58.731294 22485033404224 run_lib.py:146] step: 107150, training_loss: 6.36935e-04
I0512 13:29:22.661505 22485033404224 run_lib.py:146] step: 107200, training_loss: 5.69068e-04
I0512 13:29:22.823198 22485033404224 run_lib.py:167] step: 107200, eval_loss: 7.84417e-04
I0512 13:29:46.463469 22485033404224 run_lib.py:146] step: 107250, training_loss: 6.30793e-04
I0512 13:30:10.456157 22485033404224 run_lib.py:146] step: 107300, training_loss: 6.79190e-04
I0512 13:30:10.616597 22485033404224 run_lib.py:167] step: 107300, eval_loss: 6.31438e-04
I0512 13:30:34.547024 22485033404224 run_lib.py:146] step: 107350, training_loss: 6.27806e-04
I0512 13:30:58.161562 22485033404224 run_lib.py:146] step: 107400, training_loss: 5.06572e-04
I0512 13:30:58.321746 22485033404224 run_lib.py:167] step: 107400, eval_loss: 6.18043e-04
I0512 13:31:22.242262 22485033404224 run_lib.py:146] step: 107450, training_loss: 5.62351e-04
I0512 13:31:46.181650 22485033404224 run_lib.py:146] step: 107500, training_loss: 5.87849e-04
I0512 13:31:46.341969 22485033404224 run_lib.py:167] step: 107500, eval_loss: 4.78881e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 13:32:10.022624 22485033404224 run_lib.py:146] step: 107550, training_loss: 5.62059e-04
I0512 13:32:34.062339 22485033404224 run_lib.py:146] step: 107600, training_loss: 8.77696e-04
I0512 13:32:34.223630 22485033404224 run_lib.py:167] step: 107600, eval_loss: 7.61932e-04
I0512 13:32:58.208441 22485033404224 run_lib.py:146] step: 107650, training_loss: 6.66714e-04
I0512 13:33:21.839650 22485033404224 run_lib.py:146] step: 107700, training_loss: 5.78687e-04
I0512 13:33:22.001709 22485033404224 run_lib.py:167] step: 107700, eval_loss: 6.45142e-04
I0512 13:33:46.028728 22485033404224 run_lib.py:146] step: 107750, training_loss: 6.53126e-04
I0512 13:34:09.965188 22485033404224 run_lib.py:146] step: 107800, training_loss: 5.70749e-04
I0512 13:34:10.125378 22485033404224 run_lib.py:167] step: 107800, eval_loss: 5.54015e-04
I0512 13:34:33.779480 22485033404224 run_lib.py:146] step: 107850, training_loss: 4.75603e-04
I0512 13:34:57.701300 22485033404224 run_lib.py:146] step: 107900, training_loss: 6.92602e-04
I0512 13:34:57.861487 22485033404224 run_lib.py:167] step: 107900, eval_loss: 8.36178e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 13:35:21.548236 22485033404224 run_lib.py:146] step: 107950, training_loss: 6.81403e-04
I0512 13:35:45.613798 22485033404224 run_lib.py:146] step: 108000, training_loss: 5.74158e-04
I0512 13:35:45.776133 22485033404224 run_lib.py:167] step: 108000, eval_loss: 4.36078e-04
I0512 13:36:09.425338 22485033404224 run_lib.py:146] step: 108050, training_loss: 6.36368e-04
I0512 13:36:33.381993 22485033404224 run_lib.py:146] step: 108100, training_loss: 7.05701e-04
I0512 13:36:33.542258 22485033404224 run_lib.py:167] step: 108100, eval_loss: 4.28840e-04
I0512 13:36:57.530582 22485033404224 run_lib.py:146] step: 108150, training_loss: 5.89505e-04
I0512 13:37:21.126330 22485033404224 run_lib.py:146] step: 108200, training_loss: 5.97819e-04
I0512 13:37:21.287152 22485033404224 run_lib.py:167] step: 108200, eval_loss: 5.88709e-04
I0512 13:37:45.151330 22485033404224 run_lib.py:146] step: 108250, training_loss: 5.46344e-04
I0512 13:38:08.989696 22485033404224 run_lib.py:146] step: 108300, training_loss: 5.61242e-04
I0512 13:38:09.149596 22485033404224 run_lib.py:167] step: 108300, eval_loss: 6.29102e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 13:38:32.748704 22485033404224 run_lib.py:146] step: 108350, training_loss: 7.10450e-04
I0512 13:38:56.627750 22485033404224 run_lib.py:146] step: 108400, training_loss: 6.88351e-04
I0512 13:38:56.788838 22485033404224 run_lib.py:167] step: 108400, eval_loss: 9.32904e-04
I0512 13:39:20.645411 22485033404224 run_lib.py:146] step: 108450, training_loss: 6.39011e-04
I0512 13:39:44.186053 22485033404224 run_lib.py:146] step: 108500, training_loss: 6.46121e-04
I0512 13:39:44.344602 22485033404224 run_lib.py:167] step: 108500, eval_loss: 4.01193e-04
I0512 13:40:08.187684 22485033404224 run_lib.py:146] step: 108550, training_loss: 5.64374e-04
I0512 13:40:32.027313 22485033404224 run_lib.py:146] step: 108600, training_loss: 5.79274e-04
I0512 13:40:32.187755 22485033404224 run_lib.py:167] step: 108600, eval_loss: 5.06941e-04
I0512 13:40:55.687846 22485033404224 run_lib.py:146] step: 108650, training_loss: 6.30462e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 13:41:19.636857 22485033404224 run_lib.py:146] step: 108700, training_loss: 5.76831e-04
I0512 13:41:19.798146 22485033404224 run_lib.py:167] step: 108700, eval_loss: 7.38573e-04
I0512 13:41:43.339465 22485033404224 run_lib.py:146] step: 108750, training_loss: 5.03354e-04
I0512 13:42:07.230509 22485033404224 run_lib.py:146] step: 108800, training_loss: 5.65338e-04
I0512 13:42:07.390316 22485033404224 run_lib.py:167] step: 108800, eval_loss: 8.54701e-04
I0512 13:42:30.915338 22485033404224 run_lib.py:146] step: 108850, training_loss: 5.39127e-04
I0512 13:42:54.731685 22485033404224 run_lib.py:146] step: 108900, training_loss: 6.49303e-04
I0512 13:42:54.890015 22485033404224 run_lib.py:167] step: 108900, eval_loss: 7.55025e-04
I0512 13:43:18.721976 22485033404224 run_lib.py:146] step: 108950, training_loss: 3.99658e-04
I0512 13:43:42.249444 22485033404224 run_lib.py:146] step: 109000, training_loss: 7.13051e-04
I0512 13:43:42.409821 22485033404224 run_lib.py:167] step: 109000, eval_loss: 5.95117e-04
I0512 13:44:06.213841 22485033404224 run_lib.py:146] step: 109050, training_loss: 8.39657e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 13:44:30.102039 22485033404224 run_lib.py:146] step: 109100, training_loss: 7.04184e-04
I0512 13:44:30.263181 22485033404224 run_lib.py:167] step: 109100, eval_loss: 4.86874e-04
I0512 13:44:53.825208 22485033404224 run_lib.py:146] step: 109150, training_loss: 6.32749e-04
I0512 13:45:17.692967 22485033404224 run_lib.py:146] step: 109200, training_loss: 5.48813e-04
I0512 13:45:17.852201 22485033404224 run_lib.py:167] step: 109200, eval_loss: 7.18942e-04
I0512 13:45:41.723304 22485033404224 run_lib.py:146] step: 109250, training_loss: 4.75243e-04
I0512 13:46:05.291024 22485033404224 run_lib.py:146] step: 109300, training_loss: 5.55868e-04
I0512 13:46:05.450529 22485033404224 run_lib.py:167] step: 109300, eval_loss: 5.79984e-04
I0512 13:46:29.288810 22485033404224 run_lib.py:146] step: 109350, training_loss: 6.11708e-04
I0512 13:46:53.118725 22485033404224 run_lib.py:146] step: 109400, training_loss: 6.21599e-04
I0512 13:46:53.278640 22485033404224 run_lib.py:167] step: 109400, eval_loss: 5.67364e-04
I0512 13:47:16.848231 22485033404224 run_lib.py:146] step: 109450, training_loss: 5.56095e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 13:47:40.905733 22485033404224 run_lib.py:146] step: 109500, training_loss: 4.89130e-04
I0512 13:47:41.067895 22485033404224 run_lib.py:167] step: 109500, eval_loss: 5.08058e-04
I0512 13:48:04.669600 22485033404224 run_lib.py:146] step: 109550, training_loss: 6.41446e-04
I0512 13:48:28.596245 22485033404224 run_lib.py:146] step: 109600, training_loss: 4.92148e-04
I0512 13:48:28.757007 22485033404224 run_lib.py:167] step: 109600, eval_loss: 5.23162e-04
I0512 13:48:52.666706 22485033404224 run_lib.py:146] step: 109650, training_loss: 8.10187e-04
I0512 13:49:16.303897 22485033404224 run_lib.py:146] step: 109700, training_loss: 5.98891e-04
I0512 13:49:16.463903 22485033404224 run_lib.py:167] step: 109700, eval_loss: 5.32261e-04
I0512 13:49:40.408889 22485033404224 run_lib.py:146] step: 109750, training_loss: 6.47550e-04
I0512 13:50:04.008814 22485033404224 run_lib.py:146] step: 109800, training_loss: 7.88820e-04
I0512 13:50:04.169638 22485033404224 run_lib.py:167] step: 109800, eval_loss: 6.08095e-04
I0512 13:50:28.071177 22485033404224 run_lib.py:146] step: 109850, training_loss: 5.54130e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 13:50:52.251816 22485033404224 run_lib.py:146] step: 109900, training_loss: 7.94765e-04
I0512 13:50:52.415478 22485033404224 run_lib.py:167] step: 109900, eval_loss: 6.83769e-04
I0512 13:51:16.078027 22485033404224 run_lib.py:146] step: 109950, training_loss: 6.63553e-04
I0512 13:51:40.111896 22485033404224 run_lib.py:146] step: 110000, training_loss: 8.27473e-04
I0512 13:51:42.525082 22485033404224 run_lib.py:167] step: 110000, eval_loss: 6.32818e-04
I0512 13:52:08.925800 22485033404224 run_lib.py:146] step: 110050, training_loss: 6.97437e-04
I0512 13:52:32.846265 22485033404224 run_lib.py:146] step: 110100, training_loss: 5.47622e-04
I0512 13:52:33.007286 22485033404224 run_lib.py:167] step: 110100, eval_loss: 7.32299e-04
I0512 13:52:56.629618 22485033404224 run_lib.py:146] step: 110150, training_loss: 7.41686e-04
I0512 13:53:20.575294 22485033404224 run_lib.py:146] step: 110200, training_loss: 5.85720e-04
I0512 13:53:20.735949 22485033404224 run_lib.py:167] step: 110200, eval_loss: 7.23799e-04
I0512 13:53:44.625714 22485033404224 run_lib.py:146] step: 110250, training_loss: 6.30514e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 13:54:08.339449 22485033404224 run_lib.py:146] step: 110300, training_loss: 7.25670e-04
I0512 13:54:08.501710 22485033404224 run_lib.py:167] step: 110300, eval_loss: 6.31724e-04
I0512 13:54:32.158198 22485033404224 run_lib.py:146] step: 110350, training_loss: 5.78740e-04
I0512 13:54:56.121762 22485033404224 run_lib.py:146] step: 110400, training_loss: 5.32702e-04
I0512 13:54:56.282129 22485033404224 run_lib.py:167] step: 110400, eval_loss: 5.57661e-04
I0512 13:55:20.162770 22485033404224 run_lib.py:146] step: 110450, training_loss: 7.36647e-04
I0512 13:55:43.716473 22485033404224 run_lib.py:146] step: 110500, training_loss: 8.51132e-04
I0512 13:55:43.800853 22485033404224 run_lib.py:167] step: 110500, eval_loss: 6.04387e-04
I0512 13:56:07.624360 22485033404224 run_lib.py:146] step: 110550, training_loss: 6.27179e-04
I0512 13:56:31.469103 22485033404224 run_lib.py:146] step: 110600, training_loss: 6.98687e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 13:56:31.819958 22485033404224 run_lib.py:167] step: 110600, eval_loss: 7.21250e-04
I0512 13:56:55.369446 22485033404224 run_lib.py:146] step: 110650, training_loss: 5.00213e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 13:57:19.367747 22485033404224 run_lib.py:146] step: 110700, training_loss: 5.51990e-04
I0512 13:57:19.530867 22485033404224 run_lib.py:167] step: 110700, eval_loss: 6.98213e-04
I0512 13:57:43.396574 22485033404224 run_lib.py:146] step: 110750, training_loss: 6.54758e-04
I0512 13:58:06.960111 22485033404224 run_lib.py:146] step: 110800, training_loss: 7.21346e-04
I0512 13:58:07.119542 22485033404224 run_lib.py:167] step: 110800, eval_loss: 5.68886e-04
I0512 13:58:30.974210 22485033404224 run_lib.py:146] step: 110850, training_loss: 6.25219e-04
I0512 13:58:54.803401 22485033404224 run_lib.py:146] step: 110900, training_loss: 5.40918e-04
I0512 13:58:54.963390 22485033404224 run_lib.py:167] step: 110900, eval_loss: 6.62565e-04
I0512 13:59:18.493980 22485033404224 run_lib.py:146] step: 110950, training_loss: 5.25837e-04
I0512 13:59:42.322706 22485033404224 run_lib.py:146] step: 111000, training_loss: 7.31433e-04
I0512 13:59:42.482162 22485033404224 run_lib.py:167] step: 111000, eval_loss: 6.76459e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 14:00:06.381096 22485033404224 run_lib.py:146] step: 111050, training_loss: 7.07932e-04
I0512 14:00:29.903352 22485033404224 run_lib.py:146] step: 111100, training_loss: 4.99911e-04
I0512 14:00:30.064178 22485033404224 run_lib.py:167] step: 111100, eval_loss: 4.89747e-04
I0512 14:00:53.581448 22485033404224 run_lib.py:146] step: 111150, training_loss: 6.83360e-04
I0512 14:01:17.773977 22485033404224 run_lib.py:146] step: 111200, training_loss: 5.86234e-04
I0512 14:01:17.932857 22485033404224 run_lib.py:167] step: 111200, eval_loss: 4.87433e-04
I0512 14:01:41.458389 22485033404224 run_lib.py:146] step: 111250, training_loss: 5.24530e-04
I0512 14:02:04.985121 22485033404224 run_lib.py:146] step: 111300, training_loss: 7.62616e-04
I0512 14:02:05.143973 22485033404224 run_lib.py:167] step: 111300, eval_loss: 6.04270e-04
I0512 14:02:28.993341 22485033404224 run_lib.py:146] step: 111350, training_loss: 6.98537e-04
I0512 14:02:52.838415 22485033404224 run_lib.py:146] step: 111400, training_loss: 6.06896e-04
I0512 14:02:52.997657 22485033404224 run_lib.py:167] step: 111400, eval_loss: 6.03695e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 14:03:16.578676 22485033404224 run_lib.py:146] step: 111450, training_loss: 6.16244e-04
I0512 14:03:40.462999 22485033404224 run_lib.py:146] step: 111500, training_loss: 7.29338e-04
I0512 14:03:40.623507 22485033404224 run_lib.py:167] step: 111500, eval_loss: 7.19384e-04
I0512 14:04:04.502627 22485033404224 run_lib.py:146] step: 111550, training_loss: 6.49123e-04
I0512 14:04:28.022304 22485033404224 run_lib.py:146] step: 111600, training_loss: 5.58669e-04
I0512 14:04:28.182282 22485033404224 run_lib.py:167] step: 111600, eval_loss: 7.84016e-04
I0512 14:04:52.022015 22485033404224 run_lib.py:146] step: 111650, training_loss: 4.52554e-04
I0512 14:05:15.829872 22485033404224 run_lib.py:146] step: 111700, training_loss: 6.41212e-04
I0512 14:05:15.988708 22485033404224 run_lib.py:167] step: 111700, eval_loss: 5.23926e-04
I0512 14:05:39.563962 22485033404224 run_lib.py:146] step: 111750, training_loss: 4.38353e-04
I0512 14:06:03.492184 22485033404224 run_lib.py:146] step: 111800, training_loss: 4.59992e-04
I0512 14:06:03.652612 22485033404224 run_lib.py:167] step: 111800, eval_loss: 6.83737e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 14:06:27.704677 22485033404224 run_lib.py:146] step: 111850, training_loss: 5.45354e-04
I0512 14:06:51.322976 22485033404224 run_lib.py:146] step: 111900, training_loss: 6.60449e-04
I0512 14:06:51.485686 22485033404224 run_lib.py:167] step: 111900, eval_loss: 6.92506e-04
I0512 14:07:15.110707 22485033404224 run_lib.py:146] step: 111950, training_loss: 6.65317e-04
I0512 14:07:39.480792 22485033404224 run_lib.py:146] step: 112000, training_loss: 5.25783e-04
I0512 14:07:39.640625 22485033404224 run_lib.py:167] step: 112000, eval_loss: 6.80830e-04
I0512 14:08:03.218251 22485033404224 run_lib.py:146] step: 112050, training_loss: 6.13948e-04
I0512 14:08:26.800709 22485033404224 run_lib.py:146] step: 112100, training_loss: 6.05587e-04
I0512 14:08:26.960629 22485033404224 run_lib.py:167] step: 112100, eval_loss: 5.95111e-04
I0512 14:08:50.951034 22485033404224 run_lib.py:146] step: 112150, training_loss: 7.36883e-04
I0512 14:09:14.886665 22485033404224 run_lib.py:146] step: 112200, training_loss: 5.78883e-04
I0512 14:09:15.046622 22485033404224 run_lib.py:167] step: 112200, eval_loss: 7.74230e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 14:09:38.772559 22485033404224 run_lib.py:146] step: 112250, training_loss: 7.75789e-04
I0512 14:10:02.860711 22485033404224 run_lib.py:146] step: 112300, training_loss: 7.61848e-04
I0512 14:10:03.022516 22485033404224 run_lib.py:167] step: 112300, eval_loss: 5.28070e-04
I0512 14:10:26.920897 22485033404224 run_lib.py:146] step: 112350, training_loss: 7.21520e-04
I0512 14:10:50.554767 22485033404224 run_lib.py:146] step: 112400, training_loss: 7.86629e-04
I0512 14:10:50.715154 22485033404224 run_lib.py:167] step: 112400, eval_loss: 6.05450e-04
I0512 14:11:14.638481 22485033404224 run_lib.py:146] step: 112450, training_loss: 4.59144e-04
I0512 14:11:38.579854 22485033404224 run_lib.py:146] step: 112500, training_loss: 5.43941e-04
I0512 14:11:38.740038 22485033404224 run_lib.py:167] step: 112500, eval_loss: 6.80047e-04
I0512 14:12:02.341869 22485033404224 run_lib.py:146] step: 112550, training_loss: 6.05475e-04
I0512 14:12:26.311926 22485033404224 run_lib.py:146] step: 112600, training_loss: 6.09671e-04
I0512 14:12:26.472311 22485033404224 run_lib.py:167] step: 112600, eval_loss: 6.34982e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 14:12:50.533963 22485033404224 run_lib.py:146] step: 112650, training_loss: 7.50265e-04
I0512 14:13:14.111778 22485033404224 run_lib.py:146] step: 112700, training_loss: 4.82394e-04
I0512 14:13:14.272964 22485033404224 run_lib.py:167] step: 112700, eval_loss: 5.71045e-04
I0512 14:13:37.818429 22485033404224 run_lib.py:146] step: 112750, training_loss: 6.43577e-04
I0512 14:14:01.989578 22485033404224 run_lib.py:146] step: 112800, training_loss: 4.83684e-04
I0512 14:14:02.148087 22485033404224 run_lib.py:167] step: 112800, eval_loss: 7.66908e-04
I0512 14:14:25.665993 22485033404224 run_lib.py:146] step: 112850, training_loss: 7.10399e-04
I0512 14:14:49.197534 22485033404224 run_lib.py:146] step: 112900, training_loss: 6.35567e-04
I0512 14:14:49.357401 22485033404224 run_lib.py:167] step: 112900, eval_loss: 6.27474e-04
I0512 14:15:13.177392 22485033404224 run_lib.py:146] step: 112950, training_loss: 5.76666e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 14:15:37.066259 22485033404224 run_lib.py:146] step: 113000, training_loss: 6.18366e-04
I0512 14:15:37.228414 22485033404224 run_lib.py:167] step: 113000, eval_loss: 5.84687e-04
I0512 14:16:00.765708 22485033404224 run_lib.py:146] step: 113050, training_loss: 6.77448e-04
I0512 14:16:24.646792 22485033404224 run_lib.py:146] step: 113100, training_loss: 6.43822e-04
I0512 14:16:24.805572 22485033404224 run_lib.py:167] step: 113100, eval_loss: 5.41617e-04
I0512 14:16:48.680463 22485033404224 run_lib.py:146] step: 113150, training_loss: 6.74521e-04
I0512 14:17:12.202205 22485033404224 run_lib.py:146] step: 113200, training_loss: 4.80214e-04
I0512 14:17:12.362927 22485033404224 run_lib.py:167] step: 113200, eval_loss: 8.45915e-04
I0512 14:17:36.206840 22485033404224 run_lib.py:146] step: 113250, training_loss: 7.71027e-04
I0512 14:18:00.046810 22485033404224 run_lib.py:146] step: 113300, training_loss: 7.39665e-04
I0512 14:18:00.205711 22485033404224 run_lib.py:167] step: 113300, eval_loss: 6.81877e-04
I0512 14:18:23.770900 22485033404224 run_lib.py:146] step: 113350, training_loss: 6.95509e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 14:18:47.696785 22485033404224 run_lib.py:146] step: 113400, training_loss: 8.36251e-04
I0512 14:18:47.858218 22485033404224 run_lib.py:167] step: 113400, eval_loss: 5.87255e-04
I0512 14:19:11.749881 22485033404224 run_lib.py:146] step: 113450, training_loss: 4.71085e-04
I0512 14:19:35.323034 22485033404224 run_lib.py:146] step: 113500, training_loss: 6.67026e-04
I0512 14:19:35.482261 22485033404224 run_lib.py:167] step: 113500, eval_loss: 6.72506e-04
I0512 14:19:59.051898 22485033404224 run_lib.py:146] step: 113550, training_loss: 6.81351e-04
I0512 14:20:23.238898 22485033404224 run_lib.py:146] step: 113600, training_loss: 6.31351e-04
I0512 14:20:23.398431 22485033404224 run_lib.py:167] step: 113600, eval_loss: 6.70916e-04
I0512 14:20:46.963209 22485033404224 run_lib.py:146] step: 113650, training_loss: 5.14111e-04
I0512 14:21:10.493011 22485033404224 run_lib.py:146] step: 113700, training_loss: 7.31353e-04
I0512 14:21:10.651950 22485033404224 run_lib.py:167] step: 113700, eval_loss: 6.19606e-04
I0512 14:21:34.496869 22485033404224 run_lib.py:146] step: 113750, training_loss: 5.64658e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 14:21:58.412622 22485033404224 run_lib.py:146] step: 113800, training_loss: 6.48830e-04
I0512 14:21:58.573837 22485033404224 run_lib.py:167] step: 113800, eval_loss: 5.98972e-04
I0512 14:22:22.142340 22485033404224 run_lib.py:146] step: 113850, training_loss: 5.42687e-04
I0512 14:22:46.024367 22485033404224 run_lib.py:146] step: 113900, training_loss: 7.32649e-04
I0512 14:22:46.184680 22485033404224 run_lib.py:167] step: 113900, eval_loss: 6.97360e-04
I0512 14:23:10.024016 22485033404224 run_lib.py:146] step: 113950, training_loss: 4.70394e-04
I0512 14:23:33.573585 22485033404224 run_lib.py:146] step: 114000, training_loss: 6.87827e-04
I0512 14:23:33.733926 22485033404224 run_lib.py:167] step: 114000, eval_loss: 8.20052e-04
I0512 14:23:57.669631 22485033404224 run_lib.py:146] step: 114050, training_loss: 6.91612e-04
I0512 14:24:21.600208 22485033404224 run_lib.py:146] step: 114100, training_loss: 4.46582e-04
I0512 14:24:21.761044 22485033404224 run_lib.py:167] step: 114100, eval_loss: 6.32747e-04
I0512 14:24:45.375762 22485033404224 run_lib.py:146] step: 114150, training_loss: 6.31467e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 14:25:09.424737 22485033404224 run_lib.py:146] step: 114200, training_loss: 6.24597e-04
I0512 14:25:09.586935 22485033404224 run_lib.py:167] step: 114200, eval_loss: 5.91416e-04
I0512 14:25:33.657345 22485033404224 run_lib.py:146] step: 114250, training_loss: 6.44326e-04
I0512 14:25:57.303031 22485033404224 run_lib.py:146] step: 114300, training_loss: 9.13485e-04
I0512 14:25:57.463806 22485033404224 run_lib.py:167] step: 114300, eval_loss: 4.73445e-04
I0512 14:26:21.388442 22485033404224 run_lib.py:146] step: 114350, training_loss: 7.57410e-04
I0512 14:26:45.414333 22485033404224 run_lib.py:146] step: 114400, training_loss: 6.53903e-04
I0512 14:26:45.574798 22485033404224 run_lib.py:167] step: 114400, eval_loss: 4.35078e-04
I0512 14:27:09.179173 22485033404224 run_lib.py:146] step: 114450, training_loss: 6.88077e-04
I0512 14:27:32.807602 22485033404224 run_lib.py:146] step: 114500, training_loss: 5.34755e-04
I0512 14:27:32.969609 22485033404224 run_lib.py:167] step: 114500, eval_loss: 5.70265e-04
I0512 14:27:57.298617 22485033404224 run_lib.py:146] step: 114550, training_loss: 6.13322e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 14:28:20.974779 22485033404224 run_lib.py:146] step: 114600, training_loss: 6.60842e-04
I0512 14:28:21.136435 22485033404224 run_lib.py:167] step: 114600, eval_loss: 6.58700e-04
I0512 14:28:44.749215 22485033404224 run_lib.py:146] step: 114650, training_loss: 5.77899e-04
I0512 14:29:08.755559 22485033404224 run_lib.py:146] step: 114700, training_loss: 5.99982e-04
I0512 14:29:08.917451 22485033404224 run_lib.py:167] step: 114700, eval_loss: 5.13271e-04
I0512 14:29:32.872799 22485033404224 run_lib.py:146] step: 114750, training_loss: 7.05266e-04
I0512 14:29:56.475974 22485033404224 run_lib.py:146] step: 114800, training_loss: 6.58349e-04
I0512 14:29:56.636892 22485033404224 run_lib.py:167] step: 114800, eval_loss: 3.75656e-04
I0512 14:30:20.571672 22485033404224 run_lib.py:146] step: 114850, training_loss: 6.58917e-04
I0512 14:30:44.507505 22485033404224 run_lib.py:146] step: 114900, training_loss: 6.21545e-04
I0512 14:30:44.668062 22485033404224 run_lib.py:167] step: 114900, eval_loss: 3.93146e-04
I0512 14:31:08.266597 22485033404224 run_lib.py:146] step: 114950, training_loss: 3.87790e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 14:31:32.242353 22485033404224 run_lib.py:146] step: 115000, training_loss: 6.37558e-04
I0512 14:31:32.405163 22485033404224 run_lib.py:167] step: 115000, eval_loss: 7.06526e-04
I0512 14:31:56.245867 22485033404224 run_lib.py:146] step: 115050, training_loss: 9.19175e-04
I0512 14:32:19.794067 22485033404224 run_lib.py:146] step: 115100, training_loss: 6.22660e-04
I0512 14:32:19.953594 22485033404224 run_lib.py:167] step: 115100, eval_loss: 7.93087e-04
I0512 14:32:43.803815 22485033404224 run_lib.py:146] step: 115150, training_loss: 7.12234e-04
I0512 14:33:07.632103 22485033404224 run_lib.py:146] step: 115200, training_loss: 9.02812e-04
I0512 14:33:07.791196 22485033404224 run_lib.py:167] step: 115200, eval_loss: 8.44187e-04
I0512 14:33:31.317069 22485033404224 run_lib.py:146] step: 115250, training_loss: 5.26758e-04
I0512 14:33:55.132063 22485033404224 run_lib.py:146] step: 115300, training_loss: 6.56195e-04
I0512 14:33:55.292632 22485033404224 run_lib.py:167] step: 115300, eval_loss: 6.18766e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 14:34:19.270133 22485033404224 run_lib.py:146] step: 115350, training_loss: 5.81472e-04
I0512 14:34:42.803895 22485033404224 run_lib.py:146] step: 115400, training_loss: 6.35265e-04
I0512 14:34:42.964376 22485033404224 run_lib.py:167] step: 115400, eval_loss: 6.53801e-04
I0512 14:35:06.505926 22485033404224 run_lib.py:146] step: 115450, training_loss: 8.07886e-04
I0512 14:35:30.407447 22485033404224 run_lib.py:146] step: 115500, training_loss: 7.12436e-04
I0512 14:35:30.565667 22485033404224 run_lib.py:167] step: 115500, eval_loss: 5.90986e-04
I0512 14:35:54.370832 22485033404224 run_lib.py:146] step: 115550, training_loss: 6.78264e-04
I0512 14:36:17.874137 22485033404224 run_lib.py:146] step: 115600, training_loss: 4.31567e-04
I0512 14:36:18.034587 22485033404224 run_lib.py:167] step: 115600, eval_loss: 5.98908e-04
I0512 14:36:41.848825 22485033404224 run_lib.py:146] step: 115650, training_loss: 5.13341e-04
I0512 14:37:05.654662 22485033404224 run_lib.py:146] step: 115700, training_loss: 7.26595e-04
I0512 14:37:05.813122 22485033404224 run_lib.py:167] step: 115700, eval_loss: 7.73544e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 14:37:29.416571 22485033404224 run_lib.py:146] step: 115750, training_loss: 6.01308e-04
I0512 14:37:53.261384 22485033404224 run_lib.py:146] step: 115800, training_loss: 7.00478e-04
I0512 14:37:53.422862 22485033404224 run_lib.py:167] step: 115800, eval_loss: 7.30249e-04
I0512 14:38:17.280230 22485033404224 run_lib.py:146] step: 115850, training_loss: 6.53728e-04
I0512 14:38:40.833047 22485033404224 run_lib.py:146] step: 115900, training_loss: 6.03030e-04
I0512 14:38:40.992386 22485033404224 run_lib.py:167] step: 115900, eval_loss: 4.66566e-04
I0512 14:39:04.843941 22485033404224 run_lib.py:146] step: 115950, training_loss: 6.20437e-04
I0512 14:39:28.706527 22485033404224 run_lib.py:146] step: 116000, training_loss: 6.48471e-04
I0512 14:39:28.866698 22485033404224 run_lib.py:167] step: 116000, eval_loss: 8.22710e-04
I0512 14:39:52.422456 22485033404224 run_lib.py:146] step: 116050, training_loss: 5.05672e-04
I0512 14:40:16.276715 22485033404224 run_lib.py:146] step: 116100, training_loss: 6.75539e-04
I0512 14:40:16.437691 22485033404224 run_lib.py:167] step: 116100, eval_loss: 4.87266e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 14:40:40.393303 22485033404224 run_lib.py:146] step: 116150, training_loss: 6.80780e-04
I0512 14:41:03.915497 22485033404224 run_lib.py:146] step: 116200, training_loss: 6.57991e-04
I0512 14:41:04.077033 22485033404224 run_lib.py:167] step: 116200, eval_loss: 6.60539e-04
I0512 14:41:27.609082 22485033404224 run_lib.py:146] step: 116250, training_loss: 5.74993e-04
I0512 14:41:51.525261 22485033404224 run_lib.py:146] step: 116300, training_loss: 5.29880e-04
I0512 14:41:51.687125 22485033404224 run_lib.py:167] step: 116300, eval_loss: 6.78290e-04
I0512 14:42:15.581540 22485033404224 run_lib.py:146] step: 116350, training_loss: 5.21128e-04
I0512 14:42:39.195277 22485033404224 run_lib.py:146] step: 116400, training_loss: 5.16992e-04
I0512 14:42:39.355351 22485033404224 run_lib.py:167] step: 116400, eval_loss: 6.91068e-04
I0512 14:43:03.279620 22485033404224 run_lib.py:146] step: 116450, training_loss: 7.72410e-04
I0512 14:43:27.187071 22485033404224 run_lib.py:146] step: 116500, training_loss: 5.34476e-04
I0512 14:43:27.347733 22485033404224 run_lib.py:167] step: 116500, eval_loss: 7.28265e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 14:43:51.027285 22485033404224 run_lib.py:146] step: 116550, training_loss: 6.23007e-04
I0512 14:44:14.947626 22485033404224 run_lib.py:146] step: 116600, training_loss: 5.30966e-04
I0512 14:44:15.109456 22485033404224 run_lib.py:167] step: 116600, eval_loss: 5.75406e-04
I0512 14:44:39.040535 22485033404224 run_lib.py:146] step: 116650, training_loss: 7.57416e-04
I0512 14:45:02.613229 22485033404224 run_lib.py:146] step: 116700, training_loss: 5.24507e-04
I0512 14:45:02.773206 22485033404224 run_lib.py:167] step: 116700, eval_loss: 5.02794e-04
I0512 14:45:26.677997 22485033404224 run_lib.py:146] step: 116750, training_loss: 6.18691e-04
I0512 14:45:50.581637 22485033404224 run_lib.py:146] step: 116800, training_loss: 5.53716e-04
I0512 14:45:50.743336 22485033404224 run_lib.py:167] step: 116800, eval_loss: 4.70968e-04
I0512 14:46:14.346456 22485033404224 run_lib.py:146] step: 116850, training_loss: 8.34962e-04
I0512 14:46:38.224133 22485033404224 run_lib.py:146] step: 116900, training_loss: 6.70570e-04
I0512 14:46:38.385205 22485033404224 run_lib.py:167] step: 116900, eval_loss: 5.86256e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 14:47:02.408354 22485033404224 run_lib.py:146] step: 116950, training_loss: 5.49749e-04
I0512 14:47:26.002724 22485033404224 run_lib.py:146] step: 117000, training_loss: 4.86332e-04
I0512 14:47:26.165082 22485033404224 run_lib.py:167] step: 117000, eval_loss: 5.46051e-04
I0512 14:47:49.756665 22485033404224 run_lib.py:146] step: 117050, training_loss: 5.93011e-04
I0512 14:48:14.057151 22485033404224 run_lib.py:146] step: 117100, training_loss: 6.96415e-04
I0512 14:48:14.216216 22485033404224 run_lib.py:167] step: 117100, eval_loss: 5.05632e-04
I0512 14:48:37.827574 22485033404224 run_lib.py:146] step: 117150, training_loss: 6.57064e-04
I0512 14:49:01.430577 22485033404224 run_lib.py:146] step: 117200, training_loss: 5.59121e-04
I0512 14:49:01.589730 22485033404224 run_lib.py:167] step: 117200, eval_loss: 4.97465e-04
I0512 14:49:25.508020 22485033404224 run_lib.py:146] step: 117250, training_loss: 5.59721e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 14:49:49.436496 22485033404224 run_lib.py:146] step: 117300, training_loss: 6.53054e-04
I0512 14:49:49.598986 22485033404224 run_lib.py:167] step: 117300, eval_loss: 7.44685e-04
I0512 14:50:13.133139 22485033404224 run_lib.py:146] step: 117350, training_loss: 6.14037e-04
I0512 14:50:37.015977 22485033404224 run_lib.py:146] step: 117400, training_loss: 6.04331e-04
I0512 14:50:37.177114 22485033404224 run_lib.py:167] step: 117400, eval_loss: 4.16767e-04
I0512 14:51:01.057023 22485033404224 run_lib.py:146] step: 117450, training_loss: 7.90433e-04
I0512 14:51:24.611181 22485033404224 run_lib.py:146] step: 117500, training_loss: 5.98668e-04
I0512 14:51:24.771582 22485033404224 run_lib.py:167] step: 117500, eval_loss: 6.05192e-04
I0512 14:51:48.631585 22485033404224 run_lib.py:146] step: 117550, training_loss: 5.78217e-04
I0512 14:52:12.471540 22485033404224 run_lib.py:146] step: 117600, training_loss: 5.98941e-04
I0512 14:52:12.631075 22485033404224 run_lib.py:167] step: 117600, eval_loss: 6.12850e-04
I0512 14:52:36.199087 22485033404224 run_lib.py:146] step: 117650, training_loss: 5.66655e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 14:53:00.110190 22485033404224 run_lib.py:146] step: 117700, training_loss: 8.29439e-04
I0512 14:53:00.272099 22485033404224 run_lib.py:167] step: 117700, eval_loss: 4.38476e-04
I0512 14:53:24.145492 22485033404224 run_lib.py:146] step: 117750, training_loss: 4.92640e-04
I0512 14:53:47.681836 22485033404224 run_lib.py:146] step: 117800, training_loss: 6.70482e-04
I0512 14:53:47.842824 22485033404224 run_lib.py:167] step: 117800, eval_loss: 7.42110e-04
I0512 14:54:11.694640 22485033404224 run_lib.py:146] step: 117850, training_loss: 7.15832e-04
I0512 14:54:35.509281 22485033404224 run_lib.py:146] step: 117900, training_loss: 5.19352e-04
I0512 14:54:35.669734 22485033404224 run_lib.py:167] step: 117900, eval_loss: 6.02067e-04
I0512 14:54:59.211482 22485033404224 run_lib.py:146] step: 117950, training_loss: 6.68015e-04
I0512 14:55:22.760497 22485033404224 run_lib.py:146] step: 118000, training_loss: 4.88830e-04
I0512 14:55:22.920140 22485033404224 run_lib.py:167] step: 118000, eval_loss: 5.08886e-04
I0512 14:55:46.746644 22485033404224 run_lib.py:146] step: 118050, training_loss: 5.48068e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 14:56:10.692964 22485033404224 run_lib.py:146] step: 118100, training_loss: 6.90383e-04
I0512 14:56:10.855269 22485033404224 run_lib.py:167] step: 118100, eval_loss: 6.15973e-04
I0512 14:56:34.366157 22485033404224 run_lib.py:146] step: 118150, training_loss: 4.15486e-04
I0512 14:56:58.240596 22485033404224 run_lib.py:146] step: 118200, training_loss: 6.30753e-04
I0512 14:56:58.400246 22485033404224 run_lib.py:167] step: 118200, eval_loss: 7.15584e-04
I0512 14:57:22.263991 22485033404224 run_lib.py:146] step: 118250, training_loss: 5.89789e-04
I0512 14:57:45.778454 22485033404224 run_lib.py:146] step: 118300, training_loss: 6.03851e-04
I0512 14:57:45.936190 22485033404224 run_lib.py:167] step: 118300, eval_loss: 5.98650e-04
I0512 14:58:09.796490 22485033404224 run_lib.py:146] step: 118350, training_loss: 6.94146e-04
I0512 14:58:33.654664 22485033404224 run_lib.py:146] step: 118400, training_loss: 7.87047e-04
I0512 14:58:33.737724 22485033404224 run_lib.py:167] step: 118400, eval_loss: 1.48405e-03
I0512 14:58:57.286799 22485033404224 run_lib.py:146] step: 118450, training_loss: 5.34890e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 14:59:21.264531 22485033404224 run_lib.py:146] step: 118500, training_loss: 4.46401e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 14:59:21.611092 22485033404224 run_lib.py:167] step: 118500, eval_loss: 7.43918e-04
I0512 14:59:45.516028 22485033404224 run_lib.py:146] step: 118550, training_loss: 6.39747e-04
I0512 15:00:09.116006 22485033404224 run_lib.py:146] step: 118600, training_loss: 6.03406e-04
I0512 15:00:09.276570 22485033404224 run_lib.py:167] step: 118600, eval_loss: 6.87761e-04
I0512 15:00:33.241168 22485033404224 run_lib.py:146] step: 118650, training_loss: 5.58974e-04
I0512 15:00:57.163906 22485033404224 run_lib.py:146] step: 118700, training_loss: 5.09610e-04
I0512 15:00:57.324624 22485033404224 run_lib.py:167] step: 118700, eval_loss: 7.41797e-04
I0512 15:01:20.947048 22485033404224 run_lib.py:146] step: 118750, training_loss: 5.66129e-04
I0512 15:01:44.554909 22485033404224 run_lib.py:146] step: 118800, training_loss: 5.70721e-04
I0512 15:01:44.715669 22485033404224 run_lib.py:167] step: 118800, eval_loss: 5.82179e-04
I0512 15:02:08.957093 22485033404224 run_lib.py:146] step: 118850, training_loss: 6.88984e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 15:02:32.834035 22485033404224 run_lib.py:146] step: 118900, training_loss: 7.03934e-04
I0512 15:02:32.996912 22485033404224 run_lib.py:167] step: 118900, eval_loss: 6.27489e-04
I0512 15:02:56.886771 22485033404224 run_lib.py:146] step: 118950, training_loss: 6.01103e-04
I0512 15:03:21.280975 22485033404224 run_lib.py:146] step: 119000, training_loss: 6.89392e-04
I0512 15:03:21.442795 22485033404224 run_lib.py:167] step: 119000, eval_loss: 6.93672e-04
I0512 15:03:45.748929 22485033404224 run_lib.py:146] step: 119050, training_loss: 5.65201e-04
I0512 15:04:09.636729 22485033404224 run_lib.py:146] step: 119100, training_loss: 6.20338e-04
I0512 15:04:09.797389 22485033404224 run_lib.py:167] step: 119100, eval_loss: 6.24710e-04
I0512 15:04:34.085550 22485033404224 run_lib.py:146] step: 119150, training_loss: 7.01722e-04
I0512 15:04:58.175087 22485033404224 run_lib.py:146] step: 119200, training_loss: 6.56816e-04
I0512 15:04:58.335396 22485033404224 run_lib.py:167] step: 119200, eval_loss: 6.96467e-04
I0512 15:05:22.017513 22485033404224 run_lib.py:146] step: 119250, training_loss: 6.27682e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 15:05:46.095286 22485033404224 run_lib.py:146] step: 119300, training_loss: 6.62366e-04
I0512 15:05:46.257716 22485033404224 run_lib.py:167] step: 119300, eval_loss: 5.69216e-04
I0512 15:06:10.337183 22485033404224 run_lib.py:146] step: 119350, training_loss: 6.01091e-04
I0512 15:06:33.974567 22485033404224 run_lib.py:146] step: 119400, training_loss: 6.97509e-04
I0512 15:06:34.135560 22485033404224 run_lib.py:167] step: 119400, eval_loss: 6.50261e-04
I0512 15:06:58.087560 22485033404224 run_lib.py:146] step: 119450, training_loss: 7.22537e-04
I0512 15:07:22.100720 22485033404224 run_lib.py:146] step: 119500, training_loss: 6.03306e-04
I0512 15:07:22.259808 22485033404224 run_lib.py:167] step: 119500, eval_loss: 7.50620e-04
I0512 15:07:45.810950 22485033404224 run_lib.py:146] step: 119550, training_loss: 6.42004e-04
I0512 15:08:09.689562 22485033404224 run_lib.py:146] step: 119600, training_loss: 5.76474e-04
I0512 15:08:09.849894 22485033404224 run_lib.py:167] step: 119600, eval_loss: 5.61016e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 15:08:33.837100 22485033404224 run_lib.py:146] step: 119650, training_loss: 6.58241e-04
I0512 15:08:57.377918 22485033404224 run_lib.py:146] step: 119700, training_loss: 6.05930e-04
I0512 15:08:57.538824 22485033404224 run_lib.py:167] step: 119700, eval_loss: 4.89227e-04
I0512 15:09:21.057454 22485033404224 run_lib.py:146] step: 119750, training_loss: 6.28182e-04
I0512 15:09:44.914437 22485033404224 run_lib.py:146] step: 119800, training_loss: 6.92168e-04
I0512 15:09:45.074491 22485033404224 run_lib.py:167] step: 119800, eval_loss: 7.94244e-04
I0512 15:10:08.871540 22485033404224 run_lib.py:146] step: 119850, training_loss: 7.44667e-04
I0512 15:10:32.412262 22485033404224 run_lib.py:146] step: 119900, training_loss: 6.44104e-04
I0512 15:10:32.573587 22485033404224 run_lib.py:167] step: 119900, eval_loss: 7.08075e-04
I0512 15:10:56.388181 22485033404224 run_lib.py:146] step: 119950, training_loss: 7.15175e-04
I0512 15:11:20.219968 22485033404224 run_lib.py:146] step: 120000, training_loss: 6.45490e-04
I0512 15:11:22.312006 22485033404224 run_lib.py:167] step: 120000, eval_loss: 5.97066e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 15:11:47.534799 22485033404224 run_lib.py:146] step: 120050, training_loss: 6.68476e-04
I0512 15:12:11.427535 22485033404224 run_lib.py:146] step: 120100, training_loss: 6.90730e-04
I0512 15:12:11.588018 22485033404224 run_lib.py:167] step: 120100, eval_loss: 5.12168e-04
I0512 15:12:35.118980 22485033404224 run_lib.py:146] step: 120150, training_loss: 4.86798e-04
I0512 15:12:58.658305 22485033404224 run_lib.py:146] step: 120200, training_loss: 7.01541e-04
I0512 15:12:58.818140 22485033404224 run_lib.py:167] step: 120200, eval_loss: 5.86012e-04
I0512 15:13:22.971588 22485033404224 run_lib.py:146] step: 120250, training_loss: 7.01798e-04
I0512 15:13:46.509759 22485033404224 run_lib.py:146] step: 120300, training_loss: 6.92776e-04
I0512 15:13:46.671010 22485033404224 run_lib.py:167] step: 120300, eval_loss: 6.38542e-04
I0512 15:14:10.192764 22485033404224 run_lib.py:146] step: 120350, training_loss: 5.12500e-04
I0512 15:14:34.325560 22485033404224 run_lib.py:146] step: 120400, training_loss: 8.81486e-04
I0512 15:14:34.484558 22485033404224 run_lib.py:167] step: 120400, eval_loss: 5.04219e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 15:14:58.106871 22485033404224 run_lib.py:146] step: 120450, training_loss: 5.41561e-04
I0512 15:15:21.643767 22485033404224 run_lib.py:146] step: 120500, training_loss: 7.11633e-04
I0512 15:15:21.803507 22485033404224 run_lib.py:167] step: 120500, eval_loss: 4.58988e-04
I0512 15:15:45.677763 22485033404224 run_lib.py:146] step: 120550, training_loss: 5.55083e-04
I0512 15:16:09.206572 22485033404224 run_lib.py:146] step: 120600, training_loss: 4.35081e-04
I0512 15:16:09.365860 22485033404224 run_lib.py:167] step: 120600, eval_loss: 6.20581e-04
I0512 15:16:32.883795 22485033404224 run_lib.py:146] step: 120650, training_loss: 7.22426e-04
I0512 15:16:56.442636 22485033404224 run_lib.py:146] step: 120700, training_loss: 4.63911e-04
I0512 15:16:56.603997 22485033404224 run_lib.py:167] step: 120700, eval_loss: 6.45321e-04
I0512 15:17:20.761444 22485033404224 run_lib.py:146] step: 120750, training_loss: 5.56468e-04
I0512 15:17:44.323843 22485033404224 run_lib.py:146] step: 120800, training_loss: 5.71942e-04
I0512 15:17:44.485663 22485033404224 run_lib.py:167] step: 120800, eval_loss: 5.16387e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 15:18:08.142570 22485033404224 run_lib.py:146] step: 120850, training_loss: 5.96499e-04
I0512 15:18:32.451646 22485033404224 run_lib.py:146] step: 120900, training_loss: 6.98297e-04
I0512 15:18:32.613058 22485033404224 run_lib.py:167] step: 120900, eval_loss: 7.79463e-04
I0512 15:18:56.203858 22485033404224 run_lib.py:146] step: 120950, training_loss: 7.12499e-04
I0512 15:19:19.806058 22485033404224 run_lib.py:146] step: 121000, training_loss: 6.37905e-04
I0512 15:19:19.965670 22485033404224 run_lib.py:167] step: 121000, eval_loss: 4.31381e-04
I0512 15:19:44.185853 22485033404224 run_lib.py:146] step: 121050, training_loss: 6.14144e-04
I0512 15:20:07.807068 22485033404224 run_lib.py:146] step: 121100, training_loss: 5.69579e-04
I0512 15:20:07.967736 22485033404224 run_lib.py:167] step: 121100, eval_loss: 8.94866e-04
I0512 15:20:31.555652 22485033404224 run_lib.py:146] step: 121150, training_loss: 5.58489e-04
I0512 15:20:55.761373 22485033404224 run_lib.py:146] step: 121200, training_loss: 5.96127e-04
I0512 15:20:55.921022 22485033404224 run_lib.py:167] step: 121200, eval_loss: 6.63621e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 15:21:19.616458 22485033404224 run_lib.py:146] step: 121250, training_loss: 5.86050e-04
I0512 15:21:43.262437 22485033404224 run_lib.py:146] step: 121300, training_loss: 6.06116e-04
I0512 15:21:43.425190 22485033404224 run_lib.py:167] step: 121300, eval_loss: 6.09208e-04
I0512 15:22:07.780382 22485033404224 run_lib.py:146] step: 121350, training_loss: 7.31464e-04
I0512 15:22:31.389092 22485033404224 run_lib.py:146] step: 121400, training_loss: 6.49401e-04
I0512 15:22:31.550694 22485033404224 run_lib.py:167] step: 121400, eval_loss: 6.23422e-04
I0512 15:22:55.156023 22485033404224 run_lib.py:146] step: 121450, training_loss: 4.91241e-04
I0512 15:23:18.799023 22485033404224 run_lib.py:146] step: 121500, training_loss: 4.60776e-04
I0512 15:23:18.959175 22485033404224 run_lib.py:167] step: 121500, eval_loss: 6.27415e-04
I0512 15:23:43.174989 22485033404224 run_lib.py:146] step: 121550, training_loss: 6.50029e-04
I0512 15:24:06.647594 22485033404224 run_lib.py:146] step: 121600, training_loss: 8.28234e-04
I0512 15:24:06.807860 22485033404224 run_lib.py:167] step: 121600, eval_loss: 4.53045e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 15:24:30.564138 22485033404224 run_lib.py:146] step: 121650, training_loss: 5.88423e-04
I0512 15:24:54.853180 22485033404224 run_lib.py:146] step: 121700, training_loss: 6.04110e-04
I0512 15:24:55.013616 22485033404224 run_lib.py:167] step: 121700, eval_loss: 5.68083e-04
I0512 15:25:18.618237 22485033404224 run_lib.py:146] step: 121750, training_loss: 5.87323e-04
I0512 15:25:42.164365 22485033404224 run_lib.py:146] step: 121800, training_loss: 7.66081e-04
I0512 15:25:42.322506 22485033404224 run_lib.py:167] step: 121800, eval_loss: 4.38561e-04
I0512 15:26:06.449281 22485033404224 run_lib.py:146] step: 121850, training_loss: 5.88125e-04
I0512 15:26:29.992580 22485033404224 run_lib.py:146] step: 121900, training_loss: 6.72222e-04
I0512 15:26:30.151598 22485033404224 run_lib.py:167] step: 121900, eval_loss: 7.33881e-04
I0512 15:26:53.676854 22485033404224 run_lib.py:146] step: 121950, training_loss: 5.77485e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 15:27:17.854283 22485033404224 run_lib.py:146] step: 122000, training_loss: 5.56786e-04
I0512 15:27:18.014660 22485033404224 run_lib.py:167] step: 122000, eval_loss: 6.36351e-04
I0512 15:27:41.533725 22485033404224 run_lib.py:146] step: 122050, training_loss: 4.92716e-04
I0512 15:28:05.058110 22485033404224 run_lib.py:146] step: 122100, training_loss: 6.36039e-04
I0512 15:28:05.217787 22485033404224 run_lib.py:167] step: 122100, eval_loss: 5.52348e-04
I0512 15:28:29.393074 22485033404224 run_lib.py:146] step: 122150, training_loss: 5.88213e-04
I0512 15:28:52.927350 22485033404224 run_lib.py:146] step: 122200, training_loss: 5.43001e-04
I0512 15:28:53.087300 22485033404224 run_lib.py:167] step: 122200, eval_loss: 5.82193e-04
I0512 15:29:16.599067 22485033404224 run_lib.py:146] step: 122250, training_loss: 4.32893e-04
I0512 15:29:40.110065 22485033404224 run_lib.py:146] step: 122300, training_loss: 6.48929e-04
I0512 15:29:40.269005 22485033404224 run_lib.py:167] step: 122300, eval_loss: 6.88553e-04
I0512 15:30:04.117791 22485033404224 run_lib.py:146] step: 122350, training_loss: 7.84396e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 15:30:27.708103 22485033404224 run_lib.py:146] step: 122400, training_loss: 8.16569e-04
I0512 15:30:27.869156 22485033404224 run_lib.py:167] step: 122400, eval_loss: 6.49915e-04
I0512 15:30:51.377137 22485033404224 run_lib.py:146] step: 122450, training_loss: 7.05207e-04
I0512 15:31:15.590487 22485033404224 run_lib.py:146] step: 122500, training_loss: 6.44318e-04
I0512 15:31:15.749884 22485033404224 run_lib.py:167] step: 122500, eval_loss: 6.54587e-04
I0512 15:31:39.252230 22485033404224 run_lib.py:146] step: 122550, training_loss: 7.84793e-04
I0512 15:32:02.751524 22485033404224 run_lib.py:146] step: 122600, training_loss: 8.09252e-04
I0512 15:32:02.910799 22485033404224 run_lib.py:167] step: 122600, eval_loss: 4.97294e-04
I0512 15:32:27.033914 22485033404224 run_lib.py:146] step: 122650, training_loss: 6.67575e-04
I0512 15:32:50.569091 22485033404224 run_lib.py:146] step: 122700, training_loss: 3.86435e-04
I0512 15:32:50.728046 22485033404224 run_lib.py:167] step: 122700, eval_loss: 5.46968e-04
I0512 15:33:14.210273 22485033404224 run_lib.py:146] step: 122750, training_loss: 5.22187e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 15:33:38.479948 22485033404224 run_lib.py:146] step: 122800, training_loss: 9.55311e-04
I0512 15:33:38.639943 22485033404224 run_lib.py:167] step: 122800, eval_loss: 5.05517e-04
I0512 15:34:02.151967 22485033404224 run_lib.py:146] step: 122850, training_loss: 4.93771e-04
I0512 15:34:25.674272 22485033404224 run_lib.py:146] step: 122900, training_loss: 6.70856e-04
I0512 15:34:25.832787 22485033404224 run_lib.py:167] step: 122900, eval_loss: 5.21064e-04
I0512 15:34:49.670364 22485033404224 run_lib.py:146] step: 122950, training_loss: 4.42716e-04
I0512 15:35:13.217588 22485033404224 run_lib.py:146] step: 123000, training_loss: 1.03849e-03
I0512 15:35:13.378306 22485033404224 run_lib.py:167] step: 123000, eval_loss: 6.55975e-04
I0512 15:35:36.890975 22485033404224 run_lib.py:146] step: 123050, training_loss: 6.75841e-04
I0512 15:36:01.068670 22485033404224 run_lib.py:146] step: 123100, training_loss: 7.31817e-04
I0512 15:36:01.228430 22485033404224 run_lib.py:167] step: 123100, eval_loss: 5.24903e-04
I0512 15:36:24.817365 22485033404224 run_lib.py:146] step: 123150, training_loss: 6.24120e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 15:36:48.473856 22485033404224 run_lib.py:146] step: 123200, training_loss: 7.01006e-04
I0512 15:36:48.637322 22485033404224 run_lib.py:167] step: 123200, eval_loss: 5.47202e-04
I0512 15:37:12.216964 22485033404224 run_lib.py:146] step: 123250, training_loss: 5.95554e-04
I0512 15:37:36.145243 22485033404224 run_lib.py:146] step: 123300, training_loss: 6.50739e-04
I0512 15:37:36.305071 22485033404224 run_lib.py:167] step: 123300, eval_loss: 6.62284e-04
I0512 15:37:59.877665 22485033404224 run_lib.py:146] step: 123350, training_loss: 6.72880e-04
I0512 15:38:23.455836 22485033404224 run_lib.py:146] step: 123400, training_loss: 6.14316e-04
I0512 15:38:23.615124 22485033404224 run_lib.py:167] step: 123400, eval_loss: 5.62109e-04
I0512 15:38:47.764892 22485033404224 run_lib.py:146] step: 123450, training_loss: 5.84361e-04
I0512 15:39:11.339485 22485033404224 run_lib.py:146] step: 123500, training_loss: 6.88326e-04
I0512 15:39:11.499182 22485033404224 run_lib.py:167] step: 123500, eval_loss: 6.07635e-04
I0512 15:39:35.085760 22485033404224 run_lib.py:146] step: 123550, training_loss: 7.12038e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 15:39:59.798396 22485033404224 run_lib.py:146] step: 123600, training_loss: 7.76693e-04
I0512 15:39:59.962183 22485033404224 run_lib.py:167] step: 123600, eval_loss: 5.84159e-04
I0512 15:40:23.665287 22485033404224 run_lib.py:146] step: 123650, training_loss: 4.12144e-04
I0512 15:40:47.306754 22485033404224 run_lib.py:146] step: 123700, training_loss: 6.18763e-04
I0512 15:40:47.467405 22485033404224 run_lib.py:167] step: 123700, eval_loss: 6.41370e-04
I0512 15:41:11.857751 22485033404224 run_lib.py:146] step: 123750, training_loss: 7.26416e-04
I0512 15:41:35.521646 22485033404224 run_lib.py:146] step: 123800, training_loss: 8.67198e-04
I0512 15:41:35.682710 22485033404224 run_lib.py:167] step: 123800, eval_loss: 5.00592e-04
I0512 15:41:59.355832 22485033404224 run_lib.py:146] step: 123850, training_loss: 6.44669e-04
I0512 15:42:23.273623 22485033404224 run_lib.py:146] step: 123900, training_loss: 6.16651e-04
I0512 15:42:23.434041 22485033404224 run_lib.py:167] step: 123900, eval_loss: 5.20762e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 15:42:47.171012 22485033404224 run_lib.py:146] step: 123950, training_loss: 7.52054e-04
I0512 15:43:10.793225 22485033404224 run_lib.py:146] step: 124000, training_loss: 8.56331e-04
I0512 15:43:10.955190 22485033404224 run_lib.py:167] step: 124000, eval_loss: 5.67329e-04
I0512 15:43:34.509087 22485033404224 run_lib.py:146] step: 124050, training_loss: 6.80122e-04
I0512 15:43:58.718370 22485033404224 run_lib.py:146] step: 124100, training_loss: 5.61549e-04
I0512 15:43:58.878948 22485033404224 run_lib.py:167] step: 124100, eval_loss: 6.52499e-04
I0512 15:44:22.417010 22485033404224 run_lib.py:146] step: 124150, training_loss: 7.39515e-04
I0512 15:44:45.942993 22485033404224 run_lib.py:146] step: 124200, training_loss: 5.24263e-04
I0512 15:44:46.101716 22485033404224 run_lib.py:167] step: 124200, eval_loss: 6.19837e-04
I0512 15:45:10.194536 22485033404224 run_lib.py:146] step: 124250, training_loss: 5.40849e-04
I0512 15:45:33.684270 22485033404224 run_lib.py:146] step: 124300, training_loss: 7.27544e-04
I0512 15:45:33.845560 22485033404224 run_lib.py:167] step: 124300, eval_loss: 6.40763e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 15:45:57.408254 22485033404224 run_lib.py:146] step: 124350, training_loss: 7.16648e-04
I0512 15:46:21.619175 22485033404224 run_lib.py:146] step: 124400, training_loss: 3.80805e-04
I0512 15:46:21.779319 22485033404224 run_lib.py:167] step: 124400, eval_loss: 5.75441e-04
I0512 15:46:45.310025 22485033404224 run_lib.py:146] step: 124450, training_loss: 6.76229e-04
I0512 15:47:08.801970 22485033404224 run_lib.py:146] step: 124500, training_loss: 6.85133e-04
I0512 15:47:08.960555 22485033404224 run_lib.py:167] step: 124500, eval_loss: 6.87066e-04
I0512 15:47:33.056534 22485033404224 run_lib.py:146] step: 124550, training_loss: 5.55439e-04
I0512 15:47:56.593019 22485033404224 run_lib.py:146] step: 124600, training_loss: 7.14426e-04
I0512 15:47:56.752332 22485033404224 run_lib.py:167] step: 124600, eval_loss: 7.42508e-04
I0512 15:48:20.269261 22485033404224 run_lib.py:146] step: 124650, training_loss: 8.08002e-04
I0512 15:48:44.388910 22485033404224 run_lib.py:146] step: 124700, training_loss: 5.68519e-04
I0512 15:48:44.547879 22485033404224 run_lib.py:167] step: 124700, eval_loss: 6.75306e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 15:49:08.122828 22485033404224 run_lib.py:146] step: 124750, training_loss: 6.81443e-04
I0512 15:49:31.622653 22485033404224 run_lib.py:146] step: 124800, training_loss: 5.84676e-04
I0512 15:49:31.783702 22485033404224 run_lib.py:167] step: 124800, eval_loss: 8.12523e-04
I0512 15:49:55.299073 22485033404224 run_lib.py:146] step: 124850, training_loss: 6.12607e-04
I0512 15:50:19.457839 22485033404224 run_lib.py:146] step: 124900, training_loss: 4.71646e-04
I0512 15:50:19.616851 22485033404224 run_lib.py:167] step: 124900, eval_loss: 6.60601e-04
I0512 15:50:43.118026 22485033404224 run_lib.py:146] step: 124950, training_loss: 5.36660e-04
I0512 15:51:06.630685 22485033404224 run_lib.py:146] step: 125000, training_loss: 6.70935e-04
I0512 15:51:06.789286 22485033404224 run_lib.py:167] step: 125000, eval_loss: 5.70172e-04
I0512 15:51:30.857198 22485033404224 run_lib.py:146] step: 125050, training_loss: 5.50565e-04
I0512 15:51:54.368357 22485033404224 run_lib.py:146] step: 125100, training_loss: 7.11235e-04
I0512 15:51:54.528592 22485033404224 run_lib.py:167] step: 125100, eval_loss: 5.40181e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 15:52:18.130049 22485033404224 run_lib.py:146] step: 125150, training_loss: 6.59140e-04
I0512 15:52:42.303768 22485033404224 run_lib.py:146] step: 125200, training_loss: 6.55467e-04
I0512 15:52:42.466153 22485033404224 run_lib.py:167] step: 125200, eval_loss: 7.08677e-04
I0512 15:53:05.979750 22485033404224 run_lib.py:146] step: 125250, training_loss: 7.61788e-04
I0512 15:53:29.487744 22485033404224 run_lib.py:146] step: 125300, training_loss: 5.86260e-04
I0512 15:53:29.648353 22485033404224 run_lib.py:167] step: 125300, eval_loss: 4.84562e-04
I0512 15:53:53.758495 22485033404224 run_lib.py:146] step: 125350, training_loss: 6.17617e-04
I0512 15:54:17.350973 22485033404224 run_lib.py:146] step: 125400, training_loss: 8.44209e-04
I0512 15:54:17.510894 22485033404224 run_lib.py:167] step: 125400, eval_loss: 5.61421e-04
I0512 15:54:41.095155 22485033404224 run_lib.py:146] step: 125450, training_loss: 7.13319e-04
I0512 15:55:05.302545 22485033404224 run_lib.py:146] step: 125500, training_loss: 6.78950e-04
I0512 15:55:05.463804 22485033404224 run_lib.py:167] step: 125500, eval_loss: 5.67488e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 15:55:29.135966 22485033404224 run_lib.py:146] step: 125550, training_loss: 6.91263e-04
I0512 15:55:52.709414 22485033404224 run_lib.py:146] step: 125600, training_loss: 6.64780e-04
I0512 15:55:52.871297 22485033404224 run_lib.py:167] step: 125600, eval_loss: 7.09946e-04
I0512 15:56:16.766430 22485033404224 run_lib.py:146] step: 125650, training_loss: 5.45040e-04
I0512 15:56:40.771867 22485033404224 run_lib.py:146] step: 125700, training_loss: 6.14357e-04
I0512 15:56:40.934049 22485033404224 run_lib.py:167] step: 125700, eval_loss: 6.71816e-04
I0512 15:57:04.481408 22485033404224 run_lib.py:146] step: 125750, training_loss: 5.49410e-04
I0512 15:57:28.035599 22485033404224 run_lib.py:146] step: 125800, training_loss: 6.04005e-04
I0512 15:57:28.197030 22485033404224 run_lib.py:167] step: 125800, eval_loss: 4.87994e-04
I0512 15:57:52.446065 22485033404224 run_lib.py:146] step: 125850, training_loss: 5.77470e-04
I0512 15:58:16.037487 22485033404224 run_lib.py:146] step: 125900, training_loss: 6.56735e-04
I0512 15:58:16.197698 22485033404224 run_lib.py:167] step: 125900, eval_loss: 5.24596e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 15:58:39.818270 22485033404224 run_lib.py:146] step: 125950, training_loss: 5.16370e-04
I0512 15:59:04.266848 22485033404224 run_lib.py:146] step: 126000, training_loss: 6.00655e-04
I0512 15:59:04.428077 22485033404224 run_lib.py:167] step: 126000, eval_loss: 6.87969e-04
I0512 15:59:28.032635 22485033404224 run_lib.py:146] step: 126050, training_loss: 6.20039e-04
I0512 15:59:51.633873 22485033404224 run_lib.py:146] step: 126100, training_loss: 8.61427e-04
I0512 15:59:51.795561 22485033404224 run_lib.py:167] step: 126100, eval_loss: 5.11983e-04
I0512 16:00:16.133682 22485033404224 run_lib.py:146] step: 126150, training_loss: 4.99737e-04
I0512 16:00:39.688441 22485033404224 run_lib.py:146] step: 126200, training_loss: 6.20746e-04
I0512 16:00:39.847222 22485033404224 run_lib.py:167] step: 126200, eval_loss: 5.16031e-04
I0512 16:01:03.418981 22485033404224 run_lib.py:146] step: 126250, training_loss: 8.93918e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 16:01:27.904339 22485033404224 run_lib.py:146] step: 126300, training_loss: 6.33359e-04
I0512 16:01:27.989063 22485033404224 run_lib.py:167] step: 126300, eval_loss: 1.32940e-03
I0512 16:01:51.500894 22485033404224 run_lib.py:146] step: 126350, training_loss: 5.86766e-04
I0512 16:02:15.015088 22485033404224 run_lib.py:146] step: 126400, training_loss: 6.44009e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 16:02:15.363071 22485033404224 run_lib.py:167] step: 126400, eval_loss: 7.63946e-04
I0512 16:02:39.262995 22485033404224 run_lib.py:146] step: 126450, training_loss: 7.38044e-04
I0512 16:03:03.146829 22485033404224 run_lib.py:146] step: 126500, training_loss: 6.16960e-04
I0512 16:03:03.306569 22485033404224 run_lib.py:167] step: 126500, eval_loss: 5.86232e-04
I0512 16:03:26.830718 22485033404224 run_lib.py:146] step: 126550, training_loss: 7.54067e-04
I0512 16:03:50.370958 22485033404224 run_lib.py:146] step: 126600, training_loss: 6.61768e-04
I0512 16:03:50.531157 22485033404224 run_lib.py:167] step: 126600, eval_loss: 6.97532e-04
I0512 16:04:14.654998 22485033404224 run_lib.py:146] step: 126650, training_loss: 6.17581e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 16:04:38.273654 22485033404224 run_lib.py:146] step: 126700, training_loss: 4.64096e-04
I0512 16:04:38.434236 22485033404224 run_lib.py:167] step: 126700, eval_loss: 6.88976e-04
I0512 16:05:01.974573 22485033404224 run_lib.py:146] step: 126750, training_loss: 5.47288e-04
I0512 16:05:26.172852 22485033404224 run_lib.py:146] step: 126800, training_loss: 6.03424e-04
I0512 16:05:26.332424 22485033404224 run_lib.py:167] step: 126800, eval_loss: 6.53249e-04
I0512 16:05:49.879239 22485033404224 run_lib.py:146] step: 126850, training_loss: 5.63967e-04
I0512 16:06:13.457601 22485033404224 run_lib.py:146] step: 126900, training_loss: 5.81474e-04
I0512 16:06:13.616696 22485033404224 run_lib.py:167] step: 126900, eval_loss: 5.36810e-04
I0512 16:06:37.761695 22485033404224 run_lib.py:146] step: 126950, training_loss: 6.81264e-04
I0512 16:07:01.321389 22485033404224 run_lib.py:146] step: 127000, training_loss: 6.43917e-04
I0512 16:07:01.480101 22485033404224 run_lib.py:167] step: 127000, eval_loss: 5.43029e-04
I0512 16:07:25.022257 22485033404224 run_lib.py:146] step: 127050, training_loss: 6.15972e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 16:07:49.342314 22485033404224 run_lib.py:146] step: 127100, training_loss: 4.62698e-04
I0512 16:07:49.502860 22485033404224 run_lib.py:167] step: 127100, eval_loss: 5.79290e-04
I0512 16:08:13.027308 22485033404224 run_lib.py:146] step: 127150, training_loss: 8.16145e-04
I0512 16:08:36.578783 22485033404224 run_lib.py:146] step: 127200, training_loss: 6.73980e-04
I0512 16:08:36.738629 22485033404224 run_lib.py:167] step: 127200, eval_loss: 7.09598e-04
I0512 16:09:00.866796 22485033404224 run_lib.py:146] step: 127250, training_loss: 6.78855e-04
I0512 16:09:24.390143 22485033404224 run_lib.py:146] step: 127300, training_loss: 4.85908e-04
I0512 16:09:24.549486 22485033404224 run_lib.py:167] step: 127300, eval_loss: 7.45761e-04
I0512 16:09:48.064654 22485033404224 run_lib.py:146] step: 127350, training_loss: 6.87445e-04
I0512 16:10:11.888145 22485033404224 run_lib.py:146] step: 127400, training_loss: 5.48023e-04
I0512 16:10:12.047271 22485033404224 run_lib.py:167] step: 127400, eval_loss: 5.38586e-04
I0512 16:10:35.888747 22485033404224 run_lib.py:146] step: 127450, training_loss: 6.77975e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 16:10:59.499572 22485033404224 run_lib.py:146] step: 127500, training_loss: 7.16766e-04
I0512 16:10:59.660448 22485033404224 run_lib.py:167] step: 127500, eval_loss: 5.86147e-04
I0512 16:11:23.200742 22485033404224 run_lib.py:146] step: 127550, training_loss: 7.36894e-04
I0512 16:11:47.402864 22485033404224 run_lib.py:146] step: 127600, training_loss: 5.67156e-04
I0512 16:11:47.561901 22485033404224 run_lib.py:167] step: 127600, eval_loss: 6.77217e-04
I0512 16:12:11.147782 22485033404224 run_lib.py:146] step: 127650, training_loss: 6.22651e-04
I0512 16:12:34.761599 22485033404224 run_lib.py:146] step: 127700, training_loss: 6.27188e-04
I0512 16:12:34.922910 22485033404224 run_lib.py:167] step: 127700, eval_loss: 4.34848e-04
I0512 16:12:59.121095 22485033404224 run_lib.py:146] step: 127750, training_loss: 4.83383e-04
I0512 16:13:22.735347 22485033404224 run_lib.py:146] step: 127800, training_loss: 4.70778e-04
I0512 16:13:22.895764 22485033404224 run_lib.py:167] step: 127800, eval_loss: 4.76169e-04
I0512 16:13:46.478649 22485033404224 run_lib.py:146] step: 127850, training_loss: 5.37916e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 16:14:10.883698 22485033404224 run_lib.py:146] step: 127900, training_loss: 5.80509e-04
I0512 16:14:11.045341 22485033404224 run_lib.py:167] step: 127900, eval_loss: 7.40810e-04
I0512 16:14:34.587024 22485033404224 run_lib.py:146] step: 127950, training_loss: 5.27409e-04
I0512 16:14:58.171421 22485033404224 run_lib.py:146] step: 128000, training_loss: 4.24751e-04
I0512 16:14:58.331959 22485033404224 run_lib.py:167] step: 128000, eval_loss: 5.55978e-04
I0512 16:15:22.508462 22485033404224 run_lib.py:146] step: 128050, training_loss: 7.31000e-04
I0512 16:15:46.087719 22485033404224 run_lib.py:146] step: 128100, training_loss: 6.30873e-04
I0512 16:15:46.248883 22485033404224 run_lib.py:167] step: 128100, eval_loss: 4.83591e-04
I0512 16:16:09.859902 22485033404224 run_lib.py:146] step: 128150, training_loss: 6.81190e-04
I0512 16:16:33.759902 22485033404224 run_lib.py:146] step: 128200, training_loss: 6.53158e-04
I0512 16:16:33.920392 22485033404224 run_lib.py:167] step: 128200, eval_loss: 5.92521e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 16:16:57.893419 22485033404224 run_lib.py:146] step: 128250, training_loss: 5.78267e-04
I0512 16:17:21.510148 22485033404224 run_lib.py:146] step: 128300, training_loss: 5.19079e-04
I0512 16:17:21.671495 22485033404224 run_lib.py:167] step: 128300, eval_loss: 5.83961e-04
I0512 16:17:45.292599 22485033404224 run_lib.py:146] step: 128350, training_loss: 5.36691e-04
I0512 16:18:09.615491 22485033404224 run_lib.py:146] step: 128400, training_loss: 7.08338e-04
I0512 16:18:09.776440 22485033404224 run_lib.py:167] step: 128400, eval_loss: 6.09039e-04
I0512 16:18:33.382148 22485033404224 run_lib.py:146] step: 128450, training_loss: 5.86559e-04
I0512 16:18:57.007791 22485033404224 run_lib.py:146] step: 128500, training_loss: 6.71438e-04
I0512 16:18:57.169309 22485033404224 run_lib.py:167] step: 128500, eval_loss: 5.69147e-04
I0512 16:19:21.386054 22485033404224 run_lib.py:146] step: 128550, training_loss: 6.83537e-04
I0512 16:19:44.942122 22485033404224 run_lib.py:146] step: 128600, training_loss: 5.19771e-04
I0512 16:19:45.100783 22485033404224 run_lib.py:167] step: 128600, eval_loss: 8.13540e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 16:20:08.723388 22485033404224 run_lib.py:146] step: 128650, training_loss: 5.37417e-04
I0512 16:20:32.945625 22485033404224 run_lib.py:146] step: 128700, training_loss: 5.85606e-04
I0512 16:20:33.104944 22485033404224 run_lib.py:167] step: 128700, eval_loss: 5.53623e-04
I0512 16:20:56.633512 22485033404224 run_lib.py:146] step: 128750, training_loss: 7.17273e-04
I0512 16:21:20.169560 22485033404224 run_lib.py:146] step: 128800, training_loss: 5.79719e-04
I0512 16:21:20.329859 22485033404224 run_lib.py:167] step: 128800, eval_loss: 6.85332e-04
I0512 16:21:44.444368 22485033404224 run_lib.py:146] step: 128850, training_loss: 5.92796e-04
I0512 16:22:07.973210 22485033404224 run_lib.py:146] step: 128900, training_loss: 4.68265e-04
I0512 16:22:08.134091 22485033404224 run_lib.py:167] step: 128900, eval_loss: 7.39562e-04
I0512 16:22:31.674008 22485033404224 run_lib.py:146] step: 128950, training_loss: 6.70911e-04
I0512 16:22:55.814540 22485033404224 run_lib.py:146] step: 129000, training_loss: 6.04440e-04
I0512 16:22:55.974825 22485033404224 run_lib.py:167] step: 129000, eval_loss: 5.64201e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 16:23:19.602168 22485033404224 run_lib.py:146] step: 129050, training_loss: 5.97793e-04
I0512 16:23:43.115493 22485033404224 run_lib.py:146] step: 129100, training_loss: 5.66775e-04
I0512 16:23:43.275748 22485033404224 run_lib.py:167] step: 129100, eval_loss: 5.66195e-04
I0512 16:24:07.147442 22485033404224 run_lib.py:146] step: 129150, training_loss: 6.80055e-04
I0512 16:24:31.031121 22485033404224 run_lib.py:146] step: 129200, training_loss: 5.54015e-04
I0512 16:24:31.190643 22485033404224 run_lib.py:167] step: 129200, eval_loss: 9.25231e-04
I0512 16:24:54.720531 22485033404224 run_lib.py:146] step: 129250, training_loss: 5.26192e-04
I0512 16:25:18.236528 22485033404224 run_lib.py:146] step: 129300, training_loss: 6.33176e-04
I0512 16:25:18.395934 22485033404224 run_lib.py:167] step: 129300, eval_loss: 6.13257e-04
I0512 16:25:42.523962 22485033404224 run_lib.py:146] step: 129350, training_loss: 5.24232e-04
I0512 16:26:06.045760 22485033404224 run_lib.py:146] step: 129400, training_loss: 6.95642e-04
I0512 16:26:06.206211 22485033404224 run_lib.py:167] step: 129400, eval_loss: 4.30533e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 16:26:29.816253 22485033404224 run_lib.py:146] step: 129450, training_loss: 7.47141e-04
I0512 16:26:54.033067 22485033404224 run_lib.py:146] step: 129500, training_loss: 5.84850e-04
I0512 16:26:54.193677 22485033404224 run_lib.py:167] step: 129500, eval_loss: 5.45142e-04
I0512 16:27:17.721771 22485033404224 run_lib.py:146] step: 129550, training_loss: 8.52758e-04
I0512 16:27:41.245510 22485033404224 run_lib.py:146] step: 129600, training_loss: 5.71513e-04
I0512 16:27:41.406700 22485033404224 run_lib.py:167] step: 129600, eval_loss: 5.62137e-04
I0512 16:28:05.523765 22485033404224 run_lib.py:146] step: 129650, training_loss: 7.03450e-04
I0512 16:28:29.087909 22485033404224 run_lib.py:146] step: 129700, training_loss: 6.45755e-04
I0512 16:28:29.246831 22485033404224 run_lib.py:167] step: 129700, eval_loss: 5.35281e-04
I0512 16:28:52.799664 22485033404224 run_lib.py:146] step: 129750, training_loss: 7.27574e-04
I0512 16:29:16.940109 22485033404224 run_lib.py:146] step: 129800, training_loss: 7.37126e-04
I0512 16:29:17.100185 22485033404224 run_lib.py:167] step: 129800, eval_loss: 7.56982e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 16:29:40.712467 22485033404224 run_lib.py:146] step: 129850, training_loss: 5.08054e-04
I0512 16:30:04.266769 22485033404224 run_lib.py:146] step: 129900, training_loss: 6.37074e-04
I0512 16:30:04.428514 22485033404224 run_lib.py:167] step: 129900, eval_loss: 9.58427e-04
I0512 16:30:28.406972 22485033404224 run_lib.py:146] step: 129950, training_loss: 4.91913e-04
I0512 16:30:52.354576 22485033404224 run_lib.py:146] step: 130000, training_loss: 6.77782e-04
I0512 16:30:54.080081 22485033404224 run_lib.py:167] step: 130000, eval_loss: 5.65372e-04
I0512 16:31:19.212728 22485033404224 run_lib.py:146] step: 130050, training_loss: 4.69848e-04
I0512 16:31:43.110159 22485033404224 run_lib.py:146] step: 130100, training_loss: 4.50983e-04
I0512 16:31:43.270559 22485033404224 run_lib.py:167] step: 130100, eval_loss: 4.95635e-04
I0512 16:32:07.190517 22485033404224 run_lib.py:146] step: 130150, training_loss: 6.49254e-04
I0512 16:32:30.785727 22485033404224 run_lib.py:146] step: 130200, training_loss: 5.43542e-04
I0512 16:32:30.945450 22485033404224 run_lib.py:167] step: 130200, eval_loss: 6.80655e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 16:32:55.240083 22485033404224 run_lib.py:146] step: 130250, training_loss: 6.18079e-04
I0512 16:33:19.419917 22485033404224 run_lib.py:146] step: 130300, training_loss: 7.09167e-04
I0512 16:33:19.584022 22485033404224 run_lib.py:167] step: 130300, eval_loss: 6.81607e-04
I0512 16:33:43.317836 22485033404224 run_lib.py:146] step: 130350, training_loss: 6.84164e-04
I0512 16:34:07.473571 22485033404224 run_lib.py:146] step: 130400, training_loss: 6.05386e-04
I0512 16:34:07.636059 22485033404224 run_lib.py:167] step: 130400, eval_loss: 5.35906e-04
I0512 16:34:31.742124 22485033404224 run_lib.py:146] step: 130450, training_loss: 6.58295e-04
I0512 16:34:55.396544 22485033404224 run_lib.py:146] step: 130500, training_loss: 4.66148e-04
I0512 16:34:55.556106 22485033404224 run_lib.py:167] step: 130500, eval_loss: 5.11491e-04
I0512 16:35:19.510393 22485033404224 run_lib.py:146] step: 130550, training_loss: 7.62430e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 16:35:43.597915 22485033404224 run_lib.py:146] step: 130600, training_loss: 4.94179e-04
I0512 16:35:43.760220 22485033404224 run_lib.py:167] step: 130600, eval_loss: 3.86982e-04
I0512 16:36:07.415845 22485033404224 run_lib.py:146] step: 130650, training_loss: 7.03051e-04
I0512 16:36:31.020401 22485033404224 run_lib.py:146] step: 130700, training_loss: 7.94532e-04
I0512 16:36:31.181048 22485033404224 run_lib.py:167] step: 130700, eval_loss: 7.50349e-04
I0512 16:36:55.544439 22485033404224 run_lib.py:146] step: 130750, training_loss: 5.76034e-04
I0512 16:37:19.176079 22485033404224 run_lib.py:146] step: 130800, training_loss: 6.46418e-04
I0512 16:37:19.336747 22485033404224 run_lib.py:167] step: 130800, eval_loss: 6.25257e-04
I0512 16:37:42.912999 22485033404224 run_lib.py:146] step: 130850, training_loss: 5.58479e-04
I0512 16:38:06.899058 22485033404224 run_lib.py:146] step: 130900, training_loss: 7.63952e-04
I0512 16:38:07.058269 22485033404224 run_lib.py:167] step: 130900, eval_loss: 6.28952e-04
I0512 16:38:30.860624 22485033404224 run_lib.py:146] step: 130950, training_loss: 5.99497e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 16:38:54.476283 22485033404224 run_lib.py:146] step: 131000, training_loss: 7.58101e-04
I0512 16:38:54.639303 22485033404224 run_lib.py:167] step: 131000, eval_loss: 8.03570e-04
I0512 16:39:18.487953 22485033404224 run_lib.py:146] step: 131050, training_loss: 6.80954e-04
I0512 16:39:42.359758 22485033404224 run_lib.py:146] step: 131100, training_loss: 6.30358e-04
I0512 16:39:42.519828 22485033404224 run_lib.py:167] step: 131100, eval_loss: 6.32933e-04
I0512 16:40:06.053068 22485033404224 run_lib.py:146] step: 131150, training_loss: 4.93962e-04
I0512 16:40:29.885068 22485033404224 run_lib.py:146] step: 131200, training_loss: 6.47223e-04
I0512 16:40:30.045168 22485033404224 run_lib.py:167] step: 131200, eval_loss: 6.32950e-04
I0512 16:40:53.875120 22485033404224 run_lib.py:146] step: 131250, training_loss: 6.27147e-04
I0512 16:41:17.409782 22485033404224 run_lib.py:146] step: 131300, training_loss: 8.00254e-04
I0512 16:41:17.568905 22485033404224 run_lib.py:167] step: 131300, eval_loss: 6.94927e-04
I0512 16:41:41.405647 22485033404224 run_lib.py:146] step: 131350, training_loss: 5.89164e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 16:42:05.364192 22485033404224 run_lib.py:146] step: 131400, training_loss: 7.21881e-04
I0512 16:42:05.527611 22485033404224 run_lib.py:167] step: 131400, eval_loss: 5.94219e-04
I0512 16:42:29.058689 22485033404224 run_lib.py:146] step: 131450, training_loss: 5.91710e-04
I0512 16:42:52.608222 22485033404224 run_lib.py:146] step: 131500, training_loss: 7.84396e-04
I0512 16:42:52.767599 22485033404224 run_lib.py:167] step: 131500, eval_loss: 7.66484e-04
I0512 16:43:16.939453 22485033404224 run_lib.py:146] step: 131550, training_loss: 8.18224e-04
I0512 16:43:40.464355 22485033404224 run_lib.py:146] step: 131600, training_loss: 6.75773e-04
I0512 16:43:40.623373 22485033404224 run_lib.py:167] step: 131600, eval_loss: 8.88742e-04
I0512 16:44:04.158452 22485033404224 run_lib.py:146] step: 131650, training_loss: 6.06733e-04
I0512 16:44:28.292027 22485033404224 run_lib.py:146] step: 131700, training_loss: 5.63496e-04
I0512 16:44:28.451015 22485033404224 run_lib.py:167] step: 131700, eval_loss: 5.80603e-04
I0512 16:44:51.956774 22485033404224 run_lib.py:146] step: 131750, training_loss: 6.13792e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 16:45:15.533207 22485033404224 run_lib.py:146] step: 131800, training_loss: 6.39647e-04
I0512 16:45:15.694548 22485033404224 run_lib.py:167] step: 131800, eval_loss: 5.73098e-04
I0512 16:45:39.580952 22485033404224 run_lib.py:146] step: 131850, training_loss: 5.03192e-04
I0512 16:46:03.471771 22485033404224 run_lib.py:146] step: 131900, training_loss: 4.69310e-04
I0512 16:46:03.631386 22485033404224 run_lib.py:167] step: 131900, eval_loss: 4.63004e-04
I0512 16:46:27.158121 22485033404224 run_lib.py:146] step: 131950, training_loss: 7.13009e-04
I0512 16:46:50.978183 22485033404224 run_lib.py:146] step: 132000, training_loss: 5.88587e-04
I0512 16:46:51.138987 22485033404224 run_lib.py:167] step: 132000, eval_loss: 5.04003e-04
I0512 16:47:14.957481 22485033404224 run_lib.py:146] step: 132050, training_loss: 5.35923e-04
I0512 16:47:38.503974 22485033404224 run_lib.py:146] step: 132100, training_loss: 5.34072e-04
I0512 16:47:38.663354 22485033404224 run_lib.py:167] step: 132100, eval_loss: 7.33191e-04
I0512 16:48:02.484375 22485033404224 run_lib.py:146] step: 132150, training_loss: 7.91663e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 16:48:26.540047 22485033404224 run_lib.py:146] step: 132200, training_loss: 7.31512e-04
I0512 16:48:26.702041 22485033404224 run_lib.py:167] step: 132200, eval_loss: 5.42308e-04
I0512 16:48:50.312172 22485033404224 run_lib.py:146] step: 132250, training_loss: 6.08183e-04
I0512 16:49:13.936828 22485033404224 run_lib.py:146] step: 132300, training_loss: 5.83569e-04
I0512 16:49:14.097106 22485033404224 run_lib.py:167] step: 132300, eval_loss: 5.01539e-04
I0512 16:49:38.327037 22485033404224 run_lib.py:146] step: 132350, training_loss: 6.46035e-04
I0512 16:50:01.937026 22485033404224 run_lib.py:146] step: 132400, training_loss: 5.70019e-04
I0512 16:50:02.097953 22485033404224 run_lib.py:167] step: 132400, eval_loss: 9.40716e-04
I0512 16:50:25.722321 22485033404224 run_lib.py:146] step: 132450, training_loss: 8.47086e-04
I0512 16:50:49.904261 22485033404224 run_lib.py:146] step: 132500, training_loss: 6.80305e-04
I0512 16:50:50.065127 22485033404224 run_lib.py:167] step: 132500, eval_loss: 6.91587e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 16:51:13.734512 22485033404224 run_lib.py:146] step: 132550, training_loss: 6.65984e-04
I0512 16:51:37.379214 22485033404224 run_lib.py:146] step: 132600, training_loss: 6.02292e-04
I0512 16:51:37.541342 22485033404224 run_lib.py:167] step: 132600, eval_loss: 3.80819e-04
I0512 16:52:01.646804 22485033404224 run_lib.py:146] step: 132650, training_loss: 5.45782e-04
I0512 16:52:25.612435 22485033404224 run_lib.py:146] step: 132700, training_loss: 6.45628e-04
I0512 16:52:25.774243 22485033404224 run_lib.py:167] step: 132700, eval_loss: 5.61173e-04
I0512 16:52:49.395226 22485033404224 run_lib.py:146] step: 132750, training_loss: 5.32259e-04
I0512 16:53:13.395149 22485033404224 run_lib.py:146] step: 132800, training_loss: 5.55505e-04
I0512 16:53:13.556141 22485033404224 run_lib.py:167] step: 132800, eval_loss: 7.37447e-04
I0512 16:53:37.444943 22485033404224 run_lib.py:146] step: 132850, training_loss: 6.85271e-04
I0512 16:54:01.070739 22485033404224 run_lib.py:146] step: 132900, training_loss: 7.20180e-04
I0512 16:54:01.232944 22485033404224 run_lib.py:167] step: 132900, eval_loss: 7.19405e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 16:54:25.319685 22485033404224 run_lib.py:146] step: 132950, training_loss: 6.95015e-04
I0512 16:54:49.412540 22485033404224 run_lib.py:146] step: 133000, training_loss: 7.31674e-04
I0512 16:54:49.575194 22485033404224 run_lib.py:167] step: 133000, eval_loss: 6.28097e-04
I0512 16:55:13.219284 22485033404224 run_lib.py:146] step: 133050, training_loss: 7.98338e-04
I0512 16:55:37.169310 22485033404224 run_lib.py:146] step: 133100, training_loss: 7.42003e-04
I0512 16:55:37.328233 22485033404224 run_lib.py:167] step: 133100, eval_loss: 6.78466e-04
I0512 16:56:01.270935 22485033404224 run_lib.py:146] step: 133150, training_loss: 5.37712e-04
I0512 16:56:24.847280 22485033404224 run_lib.py:146] step: 133200, training_loss: 6.94041e-04
I0512 16:56:25.007807 22485033404224 run_lib.py:167] step: 133200, eval_loss: 2.77899e-04
I0512 16:56:48.531053 22485033404224 run_lib.py:146] step: 133250, training_loss: 6.26216e-04
I0512 16:57:12.639612 22485033404224 run_lib.py:146] step: 133300, training_loss: 5.92797e-04
I0512 16:57:12.798861 22485033404224 run_lib.py:167] step: 133300, eval_loss: 5.25662e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 16:57:36.376058 22485033404224 run_lib.py:146] step: 133350, training_loss: 5.23722e-04
I0512 16:57:59.888544 22485033404224 run_lib.py:146] step: 133400, training_loss: 5.01643e-04
I0512 16:58:00.050208 22485033404224 run_lib.py:167] step: 133400, eval_loss: 6.37142e-04
I0512 16:58:23.947246 22485033404224 run_lib.py:146] step: 133450, training_loss: 5.34778e-04
I0512 16:58:47.825463 22485033404224 run_lib.py:146] step: 133500, training_loss: 5.42552e-04
I0512 16:58:47.984458 22485033404224 run_lib.py:167] step: 133500, eval_loss: 6.76868e-04
I0512 16:59:11.536532 22485033404224 run_lib.py:146] step: 133550, training_loss: 6.37109e-04
I0512 16:59:35.371224 22485033404224 run_lib.py:146] step: 133600, training_loss: 5.95097e-04
I0512 16:59:35.530774 22485033404224 run_lib.py:167] step: 133600, eval_loss: 5.42255e-04
I0512 16:59:59.381927 22485033404224 run_lib.py:146] step: 133650, training_loss: 8.51193e-04
I0512 17:00:22.900732 22485033404224 run_lib.py:146] step: 133700, training_loss: 6.62341e-04
I0512 17:00:23.059283 22485033404224 run_lib.py:167] step: 133700, eval_loss: 5.89390e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 17:00:47.003634 22485033404224 run_lib.py:146] step: 133750, training_loss: 6.29046e-04
I0512 17:01:10.873895 22485033404224 run_lib.py:146] step: 133800, training_loss: 6.90203e-04
I0512 17:01:11.035452 22485033404224 run_lib.py:167] step: 133800, eval_loss: 7.03279e-04
I0512 17:01:34.580656 22485033404224 run_lib.py:146] step: 133850, training_loss: 6.70862e-04
I0512 17:01:58.410694 22485033404224 run_lib.py:146] step: 133900, training_loss: 5.60285e-04
I0512 17:01:58.570116 22485033404224 run_lib.py:167] step: 133900, eval_loss: 7.03220e-04
I0512 17:02:22.421458 22485033404224 run_lib.py:146] step: 133950, training_loss: 5.36476e-04
I0512 17:02:45.963652 22485033404224 run_lib.py:146] step: 134000, training_loss: 4.86342e-04
I0512 17:02:46.123150 22485033404224 run_lib.py:167] step: 134000, eval_loss: 5.59870e-04
I0512 17:03:09.651291 22485033404224 run_lib.py:146] step: 134050, training_loss: 6.02848e-04
I0512 17:03:33.786251 22485033404224 run_lib.py:146] step: 134100, training_loss: 5.49913e-04
I0512 17:03:33.944694 22485033404224 run_lib.py:167] step: 134100, eval_loss: 6.57976e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 17:03:57.544620 22485033404224 run_lib.py:146] step: 134150, training_loss: 5.98764e-04
I0512 17:04:21.084625 22485033404224 run_lib.py:146] step: 134200, training_loss: 5.71199e-04
I0512 17:04:21.172381 22485033404224 run_lib.py:167] step: 134200, eval_loss: 9.69648e-04
I0512 17:04:45.394620 22485033404224 run_lib.py:146] step: 134250, training_loss: 7.47863e-04
I0512 17:05:08.924610 22485033404224 run_lib.py:146] step: 134300, training_loss: 8.14567e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 17:05:09.271301 22485033404224 run_lib.py:167] step: 134300, eval_loss: 6.04266e-04
I0512 17:05:32.811498 22485033404224 run_lib.py:146] step: 134350, training_loss: 3.74998e-04
I0512 17:05:56.675259 22485033404224 run_lib.py:146] step: 134400, training_loss: 5.70114e-04
I0512 17:05:56.834859 22485033404224 run_lib.py:167] step: 134400, eval_loss: 6.16810e-04
I0512 17:06:20.772364 22485033404224 run_lib.py:146] step: 134450, training_loss: 6.01517e-04
I0512 17:06:44.397733 22485033404224 run_lib.py:146] step: 134500, training_loss: 5.00495e-04
I0512 17:06:44.558692 22485033404224 run_lib.py:167] step: 134500, eval_loss: 4.86341e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 17:07:08.574898 22485033404224 run_lib.py:146] step: 134550, training_loss: 6.06896e-04
I0512 17:07:32.540868 22485033404224 run_lib.py:146] step: 134600, training_loss: 6.61560e-04
I0512 17:07:32.702284 22485033404224 run_lib.py:167] step: 134600, eval_loss: 6.51635e-04
I0512 17:07:56.306203 22485033404224 run_lib.py:146] step: 134650, training_loss: 6.66149e-04
I0512 17:08:20.208009 22485033404224 run_lib.py:146] step: 134700, training_loss: 6.60250e-04
I0512 17:08:20.368743 22485033404224 run_lib.py:167] step: 134700, eval_loss: 5.83464e-04
I0512 17:08:44.286229 22485033404224 run_lib.py:146] step: 134750, training_loss: 5.58690e-04
I0512 17:09:07.874852 22485033404224 run_lib.py:146] step: 134800, training_loss: 5.33183e-04
I0512 17:09:08.034636 22485033404224 run_lib.py:167] step: 134800, eval_loss: 5.67634e-04
I0512 17:09:31.924309 22485033404224 run_lib.py:146] step: 134850, training_loss: 7.53541e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 17:09:55.917490 22485033404224 run_lib.py:146] step: 134900, training_loss: 7.33828e-04
I0512 17:09:56.078961 22485033404224 run_lib.py:167] step: 134900, eval_loss: 6.95951e-04
I0512 17:10:19.677949 22485033404224 run_lib.py:146] step: 134950, training_loss: 4.96104e-04
I0512 17:10:43.304507 22485033404224 run_lib.py:146] step: 135000, training_loss: 5.95901e-04
I0512 17:10:43.466889 22485033404224 run_lib.py:167] step: 135000, eval_loss: 5.88653e-04
I0512 17:11:07.814354 22485033404224 run_lib.py:146] step: 135050, training_loss: 6.26902e-04
I0512 17:11:31.416578 22485033404224 run_lib.py:146] step: 135100, training_loss: 6.58058e-04
I0512 17:11:31.577934 22485033404224 run_lib.py:167] step: 135100, eval_loss: 6.17831e-04
I0512 17:11:55.185229 22485033404224 run_lib.py:146] step: 135150, training_loss: 6.63242e-04
I0512 17:12:19.078657 22485033404224 run_lib.py:146] step: 135200, training_loss: 7.97899e-04
I0512 17:12:19.239991 22485033404224 run_lib.py:167] step: 135200, eval_loss: 5.34769e-04
I0512 17:12:43.239017 22485033404224 run_lib.py:146] step: 135250, training_loss: 6.93415e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 17:13:06.927934 22485033404224 run_lib.py:146] step: 135300, training_loss: 6.55105e-04
I0512 17:13:07.089900 22485033404224 run_lib.py:167] step: 135300, eval_loss: 6.83840e-04
I0512 17:13:31.081161 22485033404224 run_lib.py:146] step: 135350, training_loss: 5.39976e-04
I0512 17:13:55.115862 22485033404224 run_lib.py:146] step: 135400, training_loss: 6.88991e-04
I0512 17:13:55.276480 22485033404224 run_lib.py:167] step: 135400, eval_loss: 5.14758e-04
I0512 17:14:18.820804 22485033404224 run_lib.py:146] step: 135450, training_loss: 5.71349e-04
I0512 17:14:42.632890 22485033404224 run_lib.py:146] step: 135500, training_loss: 6.66112e-04
I0512 17:14:42.791819 22485033404224 run_lib.py:167] step: 135500, eval_loss: 5.65697e-04
I0512 17:15:06.647121 22485033404224 run_lib.py:146] step: 135550, training_loss: 5.62405e-04
I0512 17:15:30.190661 22485033404224 run_lib.py:146] step: 135600, training_loss: 7.28719e-04
I0512 17:15:30.349108 22485033404224 run_lib.py:167] step: 135600, eval_loss: 5.73743e-04
I0512 17:15:54.186992 22485033404224 run_lib.py:146] step: 135650, training_loss: 6.07660e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 17:16:18.136927 22485033404224 run_lib.py:146] step: 135700, training_loss: 6.50496e-04
I0512 17:16:18.297965 22485033404224 run_lib.py:167] step: 135700, eval_loss: 5.75008e-04
I0512 17:16:41.794345 22485033404224 run_lib.py:146] step: 135750, training_loss: 7.88526e-04
I0512 17:17:05.332450 22485033404224 run_lib.py:146] step: 135800, training_loss: 6.78581e-04
I0512 17:17:05.492701 22485033404224 run_lib.py:167] step: 135800, eval_loss: 6.53779e-04
I0512 17:17:29.663807 22485033404224 run_lib.py:146] step: 135850, training_loss: 5.75152e-04
I0512 17:17:53.199919 22485033404224 run_lib.py:146] step: 135900, training_loss: 6.67141e-04
I0512 17:17:53.359999 22485033404224 run_lib.py:167] step: 135900, eval_loss: 4.08107e-04
I0512 17:18:16.882614 22485033404224 run_lib.py:146] step: 135950, training_loss: 5.31440e-04
I0512 17:18:40.731651 22485033404224 run_lib.py:146] step: 136000, training_loss: 5.78817e-04
I0512 17:18:40.891540 22485033404224 run_lib.py:167] step: 136000, eval_loss: 8.74439e-04
I0512 17:19:04.761505 22485033404224 run_lib.py:146] step: 136050, training_loss: 6.56433e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 17:19:28.386202 22485033404224 run_lib.py:146] step: 136100, training_loss: 6.20248e-04
I0512 17:19:28.548044 22485033404224 run_lib.py:167] step: 136100, eval_loss: 3.89530e-04
I0512 17:19:52.402706 22485033404224 run_lib.py:146] step: 136150, training_loss: 5.79619e-04
I0512 17:20:16.261561 22485033404224 run_lib.py:146] step: 136200, training_loss: 7.22353e-04
I0512 17:20:16.420812 22485033404224 run_lib.py:167] step: 136200, eval_loss: 5.38424e-04
I0512 17:20:39.975024 22485033404224 run_lib.py:146] step: 136250, training_loss: 6.12376e-04
I0512 17:21:03.839871 22485033404224 run_lib.py:146] step: 136300, training_loss: 7.17856e-04
I0512 17:21:03.998692 22485033404224 run_lib.py:167] step: 136300, eval_loss: 4.25421e-04
I0512 17:21:27.849043 22485033404224 run_lib.py:146] step: 136350, training_loss: 6.62964e-04
I0512 17:21:51.400212 22485033404224 run_lib.py:146] step: 136400, training_loss: 4.85582e-04
I0512 17:21:51.559592 22485033404224 run_lib.py:167] step: 136400, eval_loss: 6.14576e-04
I0512 17:22:15.386176 22485033404224 run_lib.py:146] step: 136450, training_loss: 5.81495e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 17:22:39.322442 22485033404224 run_lib.py:146] step: 136500, training_loss: 6.49032e-04
I0512 17:22:39.482759 22485033404224 run_lib.py:167] step: 136500, eval_loss: 6.52856e-04
I0512 17:23:03.013369 22485033404224 run_lib.py:146] step: 136550, training_loss: 6.52712e-04
I0512 17:23:26.521967 22485033404224 run_lib.py:146] step: 136600, training_loss: 4.81888e-04
I0512 17:23:26.682060 22485033404224 run_lib.py:167] step: 136600, eval_loss: 6.49769e-04
I0512 17:23:50.862464 22485033404224 run_lib.py:146] step: 136650, training_loss: 7.97201e-04
I0512 17:24:14.428549 22485033404224 run_lib.py:146] step: 136700, training_loss: 6.23915e-04
I0512 17:24:14.589944 22485033404224 run_lib.py:167] step: 136700, eval_loss: 5.44455e-04
I0512 17:24:38.167438 22485033404224 run_lib.py:146] step: 136750, training_loss: 5.83177e-04
I0512 17:25:02.378349 22485033404224 run_lib.py:146] step: 136800, training_loss: 4.05255e-04
I0512 17:25:02.538978 22485033404224 run_lib.py:167] step: 136800, eval_loss: 5.82989e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 17:25:26.225018 22485033404224 run_lib.py:146] step: 136850, training_loss: 6.61946e-04
I0512 17:25:49.819890 22485033404224 run_lib.py:146] step: 136900, training_loss: 5.83799e-04
I0512 17:25:49.981652 22485033404224 run_lib.py:167] step: 136900, eval_loss: 5.20182e-04
I0512 17:26:13.910787 22485033404224 run_lib.py:146] step: 136950, training_loss: 6.84840e-04
I0512 17:26:37.856732 22485033404224 run_lib.py:146] step: 137000, training_loss: 7.03364e-04
I0512 17:26:38.018209 22485033404224 run_lib.py:167] step: 137000, eval_loss: 5.78819e-04
I0512 17:27:01.597609 22485033404224 run_lib.py:146] step: 137050, training_loss: 5.66891e-04
I0512 17:27:25.478553 22485033404224 run_lib.py:146] step: 137100, training_loss: 4.78913e-04
I0512 17:27:25.638092 22485033404224 run_lib.py:167] step: 137100, eval_loss: 6.96630e-04
I0512 17:27:49.486034 22485033404224 run_lib.py:146] step: 137150, training_loss: 5.39424e-04
I0512 17:28:13.068099 22485033404224 run_lib.py:146] step: 137200, training_loss: 5.90653e-04
I0512 17:28:13.228368 22485033404224 run_lib.py:167] step: 137200, eval_loss: 6.40919e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 17:28:37.250200 22485033404224 run_lib.py:146] step: 137250, training_loss: 7.65310e-04
I0512 17:29:01.207989 22485033404224 run_lib.py:146] step: 137300, training_loss: 6.78006e-04
I0512 17:29:01.370159 22485033404224 run_lib.py:167] step: 137300, eval_loss: 6.71947e-04
I0512 17:29:24.971612 22485033404224 run_lib.py:146] step: 137350, training_loss: 5.81517e-04
I0512 17:29:48.600259 22485033404224 run_lib.py:146] step: 137400, training_loss: 7.05963e-04
I0512 17:29:48.760959 22485033404224 run_lib.py:167] step: 137400, eval_loss: 6.43188e-04
I0512 17:30:12.982009 22485033404224 run_lib.py:146] step: 137450, training_loss: 4.69189e-04
I0512 17:30:36.584228 22485033404224 run_lib.py:146] step: 137500, training_loss: 4.45280e-04
I0512 17:30:36.744788 22485033404224 run_lib.py:167] step: 137500, eval_loss: 6.22091e-04
I0512 17:31:00.303555 22485033404224 run_lib.py:146] step: 137550, training_loss: 5.75730e-04
I0512 17:31:24.523198 22485033404224 run_lib.py:146] step: 137600, training_loss: 6.76769e-04
I0512 17:31:24.682717 22485033404224 run_lib.py:167] step: 137600, eval_loss: 7.65814e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 17:31:48.381241 22485033404224 run_lib.py:146] step: 137650, training_loss: 5.82549e-04
I0512 17:32:11.958883 22485033404224 run_lib.py:146] step: 137700, training_loss: 4.12948e-04
I0512 17:32:12.120379 22485033404224 run_lib.py:167] step: 137700, eval_loss: 7.14739e-04
I0512 17:32:36.026227 22485033404224 run_lib.py:146] step: 137750, training_loss: 6.99817e-04
I0512 17:32:59.914624 22485033404224 run_lib.py:146] step: 137800, training_loss: 8.28571e-04
I0512 17:33:00.073431 22485033404224 run_lib.py:167] step: 137800, eval_loss: 6.31972e-04
I0512 17:33:23.618357 22485033404224 run_lib.py:146] step: 137850, training_loss: 6.73730e-04
I0512 17:33:47.441469 22485033404224 run_lib.py:146] step: 137900, training_loss: 8.42556e-04
I0512 17:33:47.600702 22485033404224 run_lib.py:167] step: 137900, eval_loss: 4.57935e-04
I0512 17:34:11.459764 22485033404224 run_lib.py:146] step: 137950, training_loss: 6.59454e-04
I0512 17:34:35.024648 22485033404224 run_lib.py:146] step: 138000, training_loss: 7.38592e-04
I0512 17:34:35.183842 22485033404224 run_lib.py:167] step: 138000, eval_loss: 7.09458e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 17:34:59.143156 22485033404224 run_lib.py:146] step: 138050, training_loss: 5.25957e-04
I0512 17:35:23.068248 22485033404224 run_lib.py:146] step: 138100, training_loss: 6.73141e-04
I0512 17:35:23.229058 22485033404224 run_lib.py:167] step: 138100, eval_loss: 6.73882e-04
I0512 17:35:46.800327 22485033404224 run_lib.py:146] step: 138150, training_loss: 5.66831e-04
I0512 17:36:10.363741 22485033404224 run_lib.py:146] step: 138200, training_loss: 5.70581e-04
I0512 17:36:10.523453 22485033404224 run_lib.py:167] step: 138200, eval_loss: 4.06885e-04
I0512 17:36:34.631874 22485033404224 run_lib.py:146] step: 138250, training_loss: 6.47835e-04
I0512 17:36:58.195858 22485033404224 run_lib.py:146] step: 138300, training_loss: 5.83428e-04
I0512 17:36:58.355479 22485033404224 run_lib.py:167] step: 138300, eval_loss: 5.61619e-04
I0512 17:37:21.897890 22485033404224 run_lib.py:146] step: 138350, training_loss: 4.46851e-04
I0512 17:37:46.043412 22485033404224 run_lib.py:146] step: 138400, training_loss: 5.72443e-04
I0512 17:37:46.203818 22485033404224 run_lib.py:167] step: 138400, eval_loss: 4.89579e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 17:38:09.785432 22485033404224 run_lib.py:146] step: 138450, training_loss: 5.43373e-04
I0512 17:38:33.292022 22485033404224 run_lib.py:146] step: 138500, training_loss: 5.70094e-04
I0512 17:38:33.451886 22485033404224 run_lib.py:167] step: 138500, eval_loss: 6.16383e-04
I0512 17:38:57.619468 22485033404224 run_lib.py:146] step: 138550, training_loss: 7.91033e-04
I0512 17:39:21.157712 22485033404224 run_lib.py:146] step: 138600, training_loss: 5.02183e-04
I0512 17:39:21.316594 22485033404224 run_lib.py:167] step: 138600, eval_loss: 7.95303e-04
I0512 17:39:44.854692 22485033404224 run_lib.py:146] step: 138650, training_loss: 6.30221e-04
I0512 17:40:08.655124 22485033404224 run_lib.py:146] step: 138700, training_loss: 6.91769e-04
I0512 17:40:08.813608 22485033404224 run_lib.py:167] step: 138700, eval_loss: 5.70943e-04
I0512 17:40:32.623760 22485033404224 run_lib.py:146] step: 138750, training_loss: 7.69058e-04
I0512 17:40:56.159569 22485033404224 run_lib.py:146] step: 138800, training_loss: 6.10485e-04
I0512 17:40:56.321037 22485033404224 run_lib.py:167] step: 138800, eval_loss: 6.85376e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 17:41:20.247496 22485033404224 run_lib.py:146] step: 138850, training_loss: 5.12109e-04
I0512 17:41:44.123533 22485033404224 run_lib.py:146] step: 138900, training_loss: 7.02806e-04
I0512 17:41:44.283649 22485033404224 run_lib.py:167] step: 138900, eval_loss: 6.46003e-04
I0512 17:42:07.813714 22485033404224 run_lib.py:146] step: 138950, training_loss: 6.84042e-04
I0512 17:42:31.378138 22485033404224 run_lib.py:146] step: 139000, training_loss: 7.65470e-04
I0512 17:42:31.538552 22485033404224 run_lib.py:167] step: 139000, eval_loss: 6.52811e-04
I0512 17:42:55.759440 22485033404224 run_lib.py:146] step: 139050, training_loss: 5.56399e-04
I0512 17:43:19.385983 22485033404224 run_lib.py:146] step: 139100, training_loss: 7.92749e-04
I0512 17:43:19.546563 22485033404224 run_lib.py:167] step: 139100, eval_loss: 6.37828e-04
I0512 17:43:43.169284 22485033404224 run_lib.py:146] step: 139150, training_loss: 6.42007e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 17:44:07.486512 22485033404224 run_lib.py:146] step: 139200, training_loss: 7.18343e-04
I0512 17:44:07.648857 22485033404224 run_lib.py:167] step: 139200, eval_loss: 6.28195e-04
I0512 17:44:31.307686 22485033404224 run_lib.py:146] step: 139250, training_loss: 6.02737e-04
I0512 17:44:54.949082 22485033404224 run_lib.py:146] step: 139300, training_loss: 6.77675e-04
I0512 17:44:55.109261 22485033404224 run_lib.py:167] step: 139300, eval_loss: 6.43011e-04
I0512 17:45:19.582288 22485033404224 run_lib.py:146] step: 139350, training_loss: 4.61072e-04
I0512 17:45:43.195209 22485033404224 run_lib.py:146] step: 139400, training_loss: 4.87215e-04
I0512 17:45:43.354947 22485033404224 run_lib.py:167] step: 139400, eval_loss: 5.50177e-04
I0512 17:46:06.953206 22485033404224 run_lib.py:146] step: 139450, training_loss: 6.72579e-04
I0512 17:46:30.849866 22485033404224 run_lib.py:146] step: 139500, training_loss: 4.80056e-04
I0512 17:46:31.010772 22485033404224 run_lib.py:167] step: 139500, eval_loss: 6.65411e-04
I0512 17:46:55.031753 22485033404224 run_lib.py:146] step: 139550, training_loss: 6.18443e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 17:47:18.722062 22485033404224 run_lib.py:146] step: 139600, training_loss: 7.19504e-04
I0512 17:47:18.884930 22485033404224 run_lib.py:167] step: 139600, eval_loss: 7.29622e-04
I0512 17:47:42.852013 22485033404224 run_lib.py:146] step: 139650, training_loss: 7.41263e-04
I0512 17:48:06.854904 22485033404224 run_lib.py:146] step: 139700, training_loss: 5.44227e-04
I0512 17:48:07.016633 22485033404224 run_lib.py:167] step: 139700, eval_loss: 6.75382e-04
I0512 17:48:30.588943 22485033404224 run_lib.py:146] step: 139750, training_loss: 4.90103e-04
I0512 17:48:54.502324 22485033404224 run_lib.py:146] step: 139800, training_loss: 8.31299e-04
I0512 17:48:54.662633 22485033404224 run_lib.py:167] step: 139800, eval_loss: 5.22014e-04
I0512 17:49:18.566971 22485033404224 run_lib.py:146] step: 139850, training_loss: 6.36279e-04
I0512 17:49:42.123077 22485033404224 run_lib.py:146] step: 139900, training_loss: 8.75055e-04
I0512 17:49:42.281789 22485033404224 run_lib.py:167] step: 139900, eval_loss: 5.63054e-04
I0512 17:50:05.819869 22485033404224 run_lib.py:146] step: 139950, training_loss: 6.73324e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 17:50:30.098427 22485033404224 run_lib.py:146] step: 140000, training_loss: 4.92144e-04
I0512 17:50:31.795773 22485033404224 run_lib.py:167] step: 140000, eval_loss: 6.93155e-04
I0512 17:50:56.819166 22485033404224 run_lib.py:146] step: 140050, training_loss: 5.53605e-04
I0512 17:51:20.676241 22485033404224 run_lib.py:146] step: 140100, training_loss: 4.51060e-04
I0512 17:51:20.836679 22485033404224 run_lib.py:167] step: 140100, eval_loss: 6.03767e-04
I0512 17:51:44.680409 22485033404224 run_lib.py:146] step: 140150, training_loss: 5.79644e-04
I0512 17:52:08.238812 22485033404224 run_lib.py:146] step: 140200, training_loss: 7.68806e-04
I0512 17:52:08.398137 22485033404224 run_lib.py:167] step: 140200, eval_loss: 6.69383e-04
I0512 17:52:32.225250 22485033404224 run_lib.py:146] step: 140250, training_loss: 5.04573e-04
I0512 17:52:55.734560 22485033404224 run_lib.py:146] step: 140300, training_loss: 5.93840e-04
I0512 17:52:55.894928 22485033404224 run_lib.py:167] step: 140300, eval_loss: 5.61417e-04
I0512 17:53:19.721773 22485033404224 run_lib.py:146] step: 140350, training_loss: 6.77363e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 17:53:43.685277 22485033404224 run_lib.py:146] step: 140400, training_loss: 6.30188e-04
I0512 17:53:43.846674 22485033404224 run_lib.py:167] step: 140400, eval_loss: 5.51164e-04
I0512 17:54:07.380801 22485033404224 run_lib.py:146] step: 140450, training_loss: 5.72184e-04
I0512 17:54:31.281861 22485033404224 run_lib.py:146] step: 140500, training_loss: 6.47746e-04
I0512 17:54:31.441494 22485033404224 run_lib.py:167] step: 140500, eval_loss: 6.55945e-04
I0512 17:54:55.263339 22485033404224 run_lib.py:146] step: 140550, training_loss: 6.90477e-04
I0512 17:55:18.777446 22485033404224 run_lib.py:146] step: 140600, training_loss: 6.80669e-04
I0512 17:55:18.936119 22485033404224 run_lib.py:167] step: 140600, eval_loss: 6.72936e-04
I0512 17:55:42.785594 22485033404224 run_lib.py:146] step: 140650, training_loss: 7.42472e-04
I0512 17:56:06.277379 22485033404224 run_lib.py:146] step: 140700, training_loss: 5.29891e-04
I0512 17:56:06.438567 22485033404224 run_lib.py:167] step: 140700, eval_loss: 4.74048e-04
I0512 17:56:30.254843 22485033404224 run_lib.py:146] step: 140750, training_loss: 6.86033e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 17:56:54.225176 22485033404224 run_lib.py:146] step: 140800, training_loss: 7.69805e-04
I0512 17:56:54.386368 22485033404224 run_lib.py:167] step: 140800, eval_loss: 7.40267e-04
I0512 17:57:17.910610 22485033404224 run_lib.py:146] step: 140850, training_loss: 6.08373e-04
I0512 17:57:41.794906 22485033404224 run_lib.py:146] step: 140900, training_loss: 5.92009e-04
I0512 17:57:41.954983 22485033404224 run_lib.py:167] step: 140900, eval_loss: 5.39654e-04
I0512 17:58:05.793820 22485033404224 run_lib.py:146] step: 140950, training_loss: 6.00200e-04
I0512 17:58:29.333519 22485033404224 run_lib.py:146] step: 141000, training_loss: 5.08329e-04
I0512 17:58:29.494247 22485033404224 run_lib.py:167] step: 141000, eval_loss: 4.52954e-04
I0512 17:58:53.332208 22485033404224 run_lib.py:146] step: 141050, training_loss: 6.80738e-04
I0512 17:59:17.193305 22485033404224 run_lib.py:146] step: 141100, training_loss: 5.77274e-04
I0512 17:59:17.353336 22485033404224 run_lib.py:167] step: 141100, eval_loss: 7.11106e-04
I0512 17:59:40.767372 22485033404224 run_lib.py:146] step: 141150, training_loss: 6.13610e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 18:00:04.896046 22485033404224 run_lib.py:146] step: 141200, training_loss: 7.44723e-04
I0512 18:00:05.057902 22485033404224 run_lib.py:167] step: 141200, eval_loss: 5.52143e-04
I0512 18:00:28.681195 22485033404224 run_lib.py:146] step: 141250, training_loss: 5.63551e-04
I0512 18:00:52.651696 22485033404224 run_lib.py:146] step: 141300, training_loss: 7.20566e-04
I0512 18:00:52.811779 22485033404224 run_lib.py:167] step: 141300, eval_loss: 6.12188e-04
I0512 18:01:16.718900 22485033404224 run_lib.py:146] step: 141350, training_loss: 8.58526e-04
I0512 18:01:40.378440 22485033404224 run_lib.py:146] step: 141400, training_loss: 7.86933e-04
I0512 18:01:40.538763 22485033404224 run_lib.py:167] step: 141400, eval_loss: 7.16781e-04
I0512 18:02:04.408613 22485033404224 run_lib.py:146] step: 141450, training_loss: 7.39522e-04
I0512 18:02:28.002471 22485033404224 run_lib.py:146] step: 141500, training_loss: 6.06711e-04
I0512 18:02:28.163125 22485033404224 run_lib.py:167] step: 141500, eval_loss: 5.77652e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 18:02:52.143935 22485033404224 run_lib.py:146] step: 141550, training_loss: 8.69802e-04
I0512 18:03:16.201257 22485033404224 run_lib.py:146] step: 141600, training_loss: 6.68097e-04
I0512 18:03:16.362942 22485033404224 run_lib.py:167] step: 141600, eval_loss: 5.86437e-04
I0512 18:03:39.943874 22485033404224 run_lib.py:146] step: 141650, training_loss: 4.26606e-04
I0512 18:04:04.011348 22485033404224 run_lib.py:146] step: 141700, training_loss: 6.02690e-04
I0512 18:04:04.172078 22485033404224 run_lib.py:167] step: 141700, eval_loss: 7.06955e-04
I0512 18:04:28.201663 22485033404224 run_lib.py:146] step: 141750, training_loss: 4.14340e-04
I0512 18:04:51.796531 22485033404224 run_lib.py:146] step: 141800, training_loss: 6.00600e-04
I0512 18:04:51.958318 22485033404224 run_lib.py:167] step: 141800, eval_loss: 6.75414e-04
I0512 18:05:15.982747 22485033404224 run_lib.py:146] step: 141850, training_loss: 6.45693e-04
I0512 18:05:39.889600 22485033404224 run_lib.py:146] step: 141900, training_loss: 5.62877e-04
I0512 18:05:40.050871 22485033404224 run_lib.py:167] step: 141900, eval_loss: 5.58307e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 18:06:03.692104 22485033404224 run_lib.py:146] step: 141950, training_loss: 5.34147e-04
I0512 18:06:27.628140 22485033404224 run_lib.py:146] step: 142000, training_loss: 6.85853e-04
I0512 18:06:27.788871 22485033404224 run_lib.py:167] step: 142000, eval_loss: 5.42873e-04
I0512 18:06:51.385074 22485033404224 run_lib.py:146] step: 142050, training_loss: 9.04076e-04
I0512 18:07:15.277214 22485033404224 run_lib.py:146] step: 142100, training_loss: 5.38184e-04
I0512 18:07:15.358972 22485033404224 run_lib.py:167] step: 142100, eval_loss: 1.91770e-04
I0512 18:07:39.212722 22485033404224 run_lib.py:146] step: 142150, training_loss: 6.83756e-04
I0512 18:08:02.780645 22485033404224 run_lib.py:146] step: 142200, training_loss: 5.26708e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 18:08:03.128005 22485033404224 run_lib.py:167] step: 142200, eval_loss: 5.86480e-04
I0512 18:08:27.037137 22485033404224 run_lib.py:146] step: 142250, training_loss: 5.46752e-04
I0512 18:08:50.925461 22485033404224 run_lib.py:146] step: 142300, training_loss: 8.08052e-04
I0512 18:08:51.085566 22485033404224 run_lib.py:167] step: 142300, eval_loss: 7.63887e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 18:09:14.691384 22485033404224 run_lib.py:146] step: 142350, training_loss: 9.17764e-04
I0512 18:09:38.575838 22485033404224 run_lib.py:146] step: 142400, training_loss: 5.42620e-04
I0512 18:09:38.736492 22485033404224 run_lib.py:167] step: 142400, eval_loss: 7.24201e-04
I0512 18:10:02.272022 22485033404224 run_lib.py:146] step: 142450, training_loss: 4.93803e-04
I0512 18:10:26.162971 22485033404224 run_lib.py:146] step: 142500, training_loss: 7.21650e-04
I0512 18:10:26.322893 22485033404224 run_lib.py:167] step: 142500, eval_loss: 5.50604e-04
I0512 18:10:50.146484 22485033404224 run_lib.py:146] step: 142550, training_loss: 6.70810e-04
I0512 18:11:13.681025 22485033404224 run_lib.py:146] step: 142600, training_loss: 4.56477e-04
I0512 18:11:13.841412 22485033404224 run_lib.py:167] step: 142600, eval_loss: 7.01519e-04
I0512 18:11:37.660728 22485033404224 run_lib.py:146] step: 142650, training_loss: 7.20228e-04
I0512 18:12:01.518070 22485033404224 run_lib.py:146] step: 142700, training_loss: 6.48850e-04
I0512 18:12:01.677939 22485033404224 run_lib.py:167] step: 142700, eval_loss: 6.54643e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 18:12:25.275631 22485033404224 run_lib.py:146] step: 142750, training_loss: 5.83672e-04
I0512 18:12:49.181046 22485033404224 run_lib.py:146] step: 142800, training_loss: 6.41161e-04
I0512 18:12:49.343519 22485033404224 run_lib.py:167] step: 142800, eval_loss: 5.77405e-04
I0512 18:13:13.200410 22485033404224 run_lib.py:146] step: 142850, training_loss: 5.55429e-04
I0512 18:13:36.736333 22485033404224 run_lib.py:146] step: 142900, training_loss: 5.63655e-04
I0512 18:13:36.895805 22485033404224 run_lib.py:167] step: 142900, eval_loss: 6.13749e-04
I0512 18:14:00.764844 22485033404224 run_lib.py:146] step: 142950, training_loss: 4.89202e-04
I0512 18:14:24.285078 22485033404224 run_lib.py:146] step: 143000, training_loss: 6.44410e-04
I0512 18:14:24.443772 22485033404224 run_lib.py:167] step: 143000, eval_loss: 5.48405e-04
I0512 18:14:48.277823 22485033404224 run_lib.py:146] step: 143050, training_loss: 8.62476e-04
I0512 18:15:12.111742 22485033404224 run_lib.py:146] step: 143100, training_loss: 5.21367e-04
I0512 18:15:12.270845 22485033404224 run_lib.py:167] step: 143100, eval_loss: 5.61505e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 18:15:35.874547 22485033404224 run_lib.py:146] step: 143150, training_loss: 6.03899e-04
I0512 18:15:59.767169 22485033404224 run_lib.py:146] step: 143200, training_loss: 5.33031e-04
I0512 18:15:59.928244 22485033404224 run_lib.py:167] step: 143200, eval_loss: 7.55772e-04
I0512 18:16:23.471436 22485033404224 run_lib.py:146] step: 143250, training_loss: 6.49962e-04
I0512 18:16:47.328601 22485033404224 run_lib.py:146] step: 143300, training_loss: 7.25896e-04
I0512 18:16:47.487275 22485033404224 run_lib.py:167] step: 143300, eval_loss: 5.58468e-04
I0512 18:17:11.292955 22485033404224 run_lib.py:146] step: 143350, training_loss: 8.70230e-04
I0512 18:17:34.818106 22485033404224 run_lib.py:146] step: 143400, training_loss: 8.51705e-04
I0512 18:17:34.978323 22485033404224 run_lib.py:167] step: 143400, eval_loss: 6.41178e-04
I0512 18:17:58.880414 22485033404224 run_lib.py:146] step: 143450, training_loss: 4.64073e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 18:18:22.893333 22485033404224 run_lib.py:146] step: 143500, training_loss: 5.99929e-04
I0512 18:18:23.056734 22485033404224 run_lib.py:167] step: 143500, eval_loss: 6.07670e-04
I0512 18:18:46.621115 22485033404224 run_lib.py:146] step: 143550, training_loss: 5.93818e-04
I0512 18:19:10.568533 22485033404224 run_lib.py:146] step: 143600, training_loss: 6.94762e-04
I0512 18:19:10.728544 22485033404224 run_lib.py:167] step: 143600, eval_loss: 6.11460e-04
I0512 18:19:34.770737 22485033404224 run_lib.py:146] step: 143650, training_loss: 4.30664e-04
I0512 18:19:58.358108 22485033404224 run_lib.py:146] step: 143700, training_loss: 6.28641e-04
I0512 18:19:58.517996 22485033404224 run_lib.py:167] step: 143700, eval_loss: 5.39639e-04
I0512 18:20:22.369888 22485033404224 run_lib.py:146] step: 143750, training_loss: 5.36873e-04
I0512 18:20:45.970201 22485033404224 run_lib.py:146] step: 143800, training_loss: 7.99161e-04
I0512 18:20:46.131013 22485033404224 run_lib.py:167] step: 143800, eval_loss: 5.08583e-04
I0512 18:21:10.142836 22485033404224 run_lib.py:146] step: 143850, training_loss: 6.57342e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 18:21:34.331419 22485033404224 run_lib.py:146] step: 143900, training_loss: 6.06866e-04
I0512 18:21:34.496118 22485033404224 run_lib.py:167] step: 143900, eval_loss: 7.60872e-04
I0512 18:21:58.262226 22485033404224 run_lib.py:146] step: 143950, training_loss: 6.70849e-04
I0512 18:22:22.355946 22485033404224 run_lib.py:146] step: 144000, training_loss: 7.26794e-04
I0512 18:22:22.518970 22485033404224 run_lib.py:167] step: 144000, eval_loss: 5.68118e-04
I0512 18:22:46.218980 22485033404224 run_lib.py:146] step: 144050, training_loss: 6.07347e-04
I0512 18:23:10.333809 22485033404224 run_lib.py:146] step: 144100, training_loss: 5.25695e-04
I0512 18:23:10.493200 22485033404224 run_lib.py:167] step: 144100, eval_loss: 6.09472e-04
I0512 18:23:34.542134 22485033404224 run_lib.py:146] step: 144150, training_loss: 7.34233e-04
I0512 18:23:58.302215 22485033404224 run_lib.py:146] step: 144200, training_loss: 5.52219e-04
I0512 18:23:58.461776 22485033404224 run_lib.py:167] step: 144200, eval_loss: 5.15776e-04
I0512 18:24:22.552171 22485033404224 run_lib.py:146] step: 144250, training_loss: 5.35127e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 18:24:46.666700 22485033404224 run_lib.py:146] step: 144300, training_loss: 5.14115e-04
I0512 18:24:46.828668 22485033404224 run_lib.py:167] step: 144300, eval_loss: 7.22711e-04
I0512 18:25:10.446287 22485033404224 run_lib.py:146] step: 144350, training_loss: 5.00949e-04
I0512 18:25:34.472656 22485033404224 run_lib.py:146] step: 144400, training_loss: 5.74658e-04
I0512 18:25:34.633901 22485033404224 run_lib.py:167] step: 144400, eval_loss: 7.00143e-04
I0512 18:25:58.486690 22485033404224 run_lib.py:146] step: 144450, training_loss: 6.71138e-04
I0512 18:26:22.031134 22485033404224 run_lib.py:146] step: 144500, training_loss: 5.55028e-04
I0512 18:26:22.190572 22485033404224 run_lib.py:167] step: 144500, eval_loss: 5.81288e-04
I0512 18:26:46.042313 22485033404224 run_lib.py:146] step: 144550, training_loss: 5.97446e-04
I0512 18:27:09.608931 22485033404224 run_lib.py:146] step: 144600, training_loss: 6.86785e-04
I0512 18:27:09.769214 22485033404224 run_lib.py:167] step: 144600, eval_loss: 6.21566e-04
I0512 18:27:33.620960 22485033404224 run_lib.py:146] step: 144650, training_loss: 7.78588e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 18:27:57.582901 22485033404224 run_lib.py:146] step: 144700, training_loss: 7.40704e-04
I0512 18:27:57.743260 22485033404224 run_lib.py:167] step: 144700, eval_loss: 5.26394e-04
I0512 18:28:21.288989 22485033404224 run_lib.py:146] step: 144750, training_loss: 8.10233e-04
I0512 18:28:45.192571 22485033404224 run_lib.py:146] step: 144800, training_loss: 5.28957e-04
I0512 18:28:45.351514 22485033404224 run_lib.py:167] step: 144800, eval_loss: 5.67131e-04
I0512 18:29:08.880851 22485033404224 run_lib.py:146] step: 144850, training_loss: 7.94958e-04
I0512 18:29:32.697651 22485033404224 run_lib.py:146] step: 144900, training_loss: 7.07362e-04
I0512 18:29:32.857886 22485033404224 run_lib.py:167] step: 144900, eval_loss: 8.24477e-04
I0512 18:29:56.695509 22485033404224 run_lib.py:146] step: 144950, training_loss: 7.12353e-04
I0512 18:30:20.243877 22485033404224 run_lib.py:146] step: 145000, training_loss: 7.23810e-04
I0512 18:30:20.403421 22485033404224 run_lib.py:167] step: 145000, eval_loss: 6.77123e-04
I0512 18:30:44.219574 22485033404224 run_lib.py:146] step: 145050, training_loss: 6.58111e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 18:31:08.186512 22485033404224 run_lib.py:146] step: 145100, training_loss: 7.10773e-04
I0512 18:31:08.348578 22485033404224 run_lib.py:167] step: 145100, eval_loss: 6.78003e-04
I0512 18:31:31.910072 22485033404224 run_lib.py:146] step: 145150, training_loss: 5.66927e-04
I0512 18:31:55.774004 22485033404224 run_lib.py:146] step: 145200, training_loss: 4.21702e-04
I0512 18:31:55.933791 22485033404224 run_lib.py:167] step: 145200, eval_loss: 6.66367e-04
I0512 18:32:19.791808 22485033404224 run_lib.py:146] step: 145250, training_loss: 6.15066e-04
I0512 18:32:43.331534 22485033404224 run_lib.py:146] step: 145300, training_loss: 6.74575e-04
I0512 18:32:43.493008 22485033404224 run_lib.py:167] step: 145300, eval_loss: 6.28611e-04
I0512 18:33:07.300417 22485033404224 run_lib.py:146] step: 145350, training_loss: 8.08640e-04
I0512 18:33:30.846211 22485033404224 run_lib.py:146] step: 145400, training_loss: 6.21622e-04
I0512 18:33:31.005524 22485033404224 run_lib.py:167] step: 145400, eval_loss: 6.23523e-04
I0512 18:33:54.833081 22485033404224 run_lib.py:146] step: 145450, training_loss: 7.51641e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 18:34:18.791709 22485033404224 run_lib.py:146] step: 145500, training_loss: 5.32036e-04
I0512 18:34:18.951757 22485033404224 run_lib.py:167] step: 145500, eval_loss: 5.89740e-04
I0512 18:34:42.489823 22485033404224 run_lib.py:146] step: 145550, training_loss: 6.58868e-04
I0512 18:35:06.371263 22485033404224 run_lib.py:146] step: 145600, training_loss: 6.15469e-04
I0512 18:35:06.530415 22485033404224 run_lib.py:167] step: 145600, eval_loss: 6.41923e-04
I0512 18:35:30.404309 22485033404224 run_lib.py:146] step: 145650, training_loss: 6.80317e-04
I0512 18:35:54.002434 22485033404224 run_lib.py:146] step: 145700, training_loss: 5.50265e-04
I0512 18:35:54.163039 22485033404224 run_lib.py:167] step: 145700, eval_loss: 5.78752e-04
I0512 18:36:18.093917 22485033404224 run_lib.py:146] step: 145750, training_loss: 7.00431e-04
I0512 18:36:41.717692 22485033404224 run_lib.py:146] step: 145800, training_loss: 6.10394e-04
I0512 18:36:41.878371 22485033404224 run_lib.py:167] step: 145800, eval_loss: 5.20775e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 18:37:05.863987 22485033404224 run_lib.py:146] step: 145850, training_loss: 4.88392e-04
I0512 18:37:29.788296 22485033404224 run_lib.py:146] step: 145900, training_loss: 5.85489e-04
I0512 18:37:29.950584 22485033404224 run_lib.py:167] step: 145900, eval_loss: 6.77785e-04
I0512 18:37:53.539500 22485033404224 run_lib.py:146] step: 145950, training_loss: 5.25078e-04
I0512 18:38:17.484660 22485033404224 run_lib.py:146] step: 146000, training_loss: 6.24887e-04
I0512 18:38:17.644390 22485033404224 run_lib.py:167] step: 146000, eval_loss: 7.41381e-04
I0512 18:38:41.538253 22485033404224 run_lib.py:146] step: 146050, training_loss: 6.33412e-04
I0512 18:39:05.110876 22485033404224 run_lib.py:146] step: 146100, training_loss: 5.12047e-04
I0512 18:39:05.270898 22485033404224 run_lib.py:167] step: 146100, eval_loss: 6.11369e-04
I0512 18:39:29.129634 22485033404224 run_lib.py:146] step: 146150, training_loss: 7.23175e-04
I0512 18:39:53.026417 22485033404224 run_lib.py:146] step: 146200, training_loss: 7.00224e-04
I0512 18:39:53.186637 22485033404224 run_lib.py:167] step: 146200, eval_loss: 4.97082e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 18:40:16.859249 22485033404224 run_lib.py:146] step: 146250, training_loss: 6.39666e-04
I0512 18:40:40.791846 22485033404224 run_lib.py:146] step: 146300, training_loss: 4.48785e-04
I0512 18:40:40.953281 22485033404224 run_lib.py:167] step: 146300, eval_loss: 4.40423e-04
I0512 18:41:04.570814 22485033404224 run_lib.py:146] step: 146350, training_loss: 5.71219e-04
I0512 18:41:28.522634 22485033404224 run_lib.py:146] step: 146400, training_loss: 7.66008e-04
I0512 18:41:28.684350 22485033404224 run_lib.py:167] step: 146400, eval_loss: 6.39717e-04
I0512 18:41:52.593678 22485033404224 run_lib.py:146] step: 146450, training_loss: 6.59865e-04
I0512 18:42:16.171050 22485033404224 run_lib.py:146] step: 146500, training_loss: 4.12199e-04
I0512 18:42:16.331619 22485033404224 run_lib.py:167] step: 146500, eval_loss: 5.66643e-04
I0512 18:42:40.241078 22485033404224 run_lib.py:146] step: 146550, training_loss: 6.52804e-04
I0512 18:43:03.856354 22485033404224 run_lib.py:146] step: 146600, training_loss: 5.33843e-04
I0512 18:43:04.017204 22485033404224 run_lib.py:167] step: 146600, eval_loss: 6.96469e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 18:43:27.969967 22485033404224 run_lib.py:146] step: 146650, training_loss: 5.60349e-04
I0512 18:43:51.854294 22485033404224 run_lib.py:146] step: 146700, training_loss: 7.02802e-04
I0512 18:43:52.016278 22485033404224 run_lib.py:167] step: 146700, eval_loss: 7.50070e-04
I0512 18:44:15.557121 22485033404224 run_lib.py:146] step: 146750, training_loss: 5.41559e-04
I0512 18:44:39.442423 22485033404224 run_lib.py:146] step: 146800, training_loss: 6.55234e-04
I0512 18:44:39.601709 22485033404224 run_lib.py:167] step: 146800, eval_loss: 7.10008e-04
I0512 18:45:03.457047 22485033404224 run_lib.py:146] step: 146850, training_loss: 4.63655e-04
I0512 18:45:27.001613 22485033404224 run_lib.py:146] step: 146900, training_loss: 4.99164e-04
I0512 18:45:27.162429 22485033404224 run_lib.py:167] step: 146900, eval_loss: 6.68482e-04
I0512 18:45:51.010511 22485033404224 run_lib.py:146] step: 146950, training_loss: 6.09616e-04
I0512 18:46:14.836139 22485033404224 run_lib.py:146] step: 147000, training_loss: 5.51576e-04
I0512 18:46:14.995654 22485033404224 run_lib.py:167] step: 147000, eval_loss: 6.66327e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 18:46:38.621531 22485033404224 run_lib.py:146] step: 147050, training_loss: 5.85543e-04
I0512 18:47:02.512112 22485033404224 run_lib.py:146] step: 147100, training_loss: 7.53673e-04
I0512 18:47:02.671823 22485033404224 run_lib.py:167] step: 147100, eval_loss: 4.39283e-04
I0512 18:47:26.201892 22485033404224 run_lib.py:146] step: 147150, training_loss: 4.79313e-04
I0512 18:47:50.108093 22485033404224 run_lib.py:146] step: 147200, training_loss: 5.76012e-04
I0512 18:47:50.267238 22485033404224 run_lib.py:167] step: 147200, eval_loss: 7.20389e-04
I0512 18:48:14.111119 22485033404224 run_lib.py:146] step: 147250, training_loss: 5.86835e-04
I0512 18:48:37.659696 22485033404224 run_lib.py:146] step: 147300, training_loss: 5.79378e-04
I0512 18:48:37.819381 22485033404224 run_lib.py:167] step: 147300, eval_loss: 6.17245e-04
I0512 18:49:01.637840 22485033404224 run_lib.py:146] step: 147350, training_loss: 6.05369e-04
I0512 18:49:25.461447 22485033404224 run_lib.py:146] step: 147400, training_loss: 8.92666e-04
I0512 18:49:25.621342 22485033404224 run_lib.py:167] step: 147400, eval_loss: 7.05215e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 18:49:49.216819 22485033404224 run_lib.py:146] step: 147450, training_loss: 6.59625e-04
I0512 18:50:13.102590 22485033404224 run_lib.py:146] step: 147500, training_loss: 5.53784e-04
I0512 18:50:13.264650 22485033404224 run_lib.py:167] step: 147500, eval_loss: 7.11486e-04
I0512 18:50:36.772726 22485033404224 run_lib.py:146] step: 147550, training_loss: 5.87221e-04
I0512 18:51:00.641719 22485033404224 run_lib.py:146] step: 147600, training_loss: 7.39977e-04
I0512 18:51:00.800080 22485033404224 run_lib.py:167] step: 147600, eval_loss: 5.53721e-04
I0512 18:51:24.598574 22485033404224 run_lib.py:146] step: 147650, training_loss: 5.26887e-04
I0512 18:51:48.125796 22485033404224 run_lib.py:146] step: 147700, training_loss: 5.46776e-04
I0512 18:51:48.286440 22485033404224 run_lib.py:167] step: 147700, eval_loss: 6.93138e-04
I0512 18:52:12.077031 22485033404224 run_lib.py:146] step: 147750, training_loss: 6.07162e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 18:52:35.989983 22485033404224 run_lib.py:146] step: 147800, training_loss: 6.18191e-04
I0512 18:52:36.151054 22485033404224 run_lib.py:167] step: 147800, eval_loss: 6.31841e-04
I0512 18:52:59.679656 22485033404224 run_lib.py:146] step: 147850, training_loss: 6.23216e-04
I0512 18:53:23.565694 22485033404224 run_lib.py:146] step: 147900, training_loss: 5.83620e-04
I0512 18:53:23.725202 22485033404224 run_lib.py:167] step: 147900, eval_loss: 5.20256e-04
I0512 18:53:47.595516 22485033404224 run_lib.py:146] step: 147950, training_loss: 5.82891e-04
I0512 18:54:11.191188 22485033404224 run_lib.py:146] step: 148000, training_loss: 7.06504e-04
I0512 18:54:11.352783 22485033404224 run_lib.py:167] step: 148000, eval_loss: 7.09780e-04
I0512 18:54:35.268015 22485033404224 run_lib.py:146] step: 148050, training_loss: 6.47963e-04
I0512 18:54:58.868592 22485033404224 run_lib.py:146] step: 148100, training_loss: 6.25533e-04
I0512 18:54:59.029362 22485033404224 run_lib.py:167] step: 148100, eval_loss: 7.25553e-04
I0512 18:55:22.950104 22485033404224 run_lib.py:146] step: 148150, training_loss: 7.31510e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 18:55:47.008556 22485033404224 run_lib.py:146] step: 148200, training_loss: 6.13657e-04
I0512 18:55:47.169814 22485033404224 run_lib.py:167] step: 148200, eval_loss: 5.70799e-04
I0512 18:56:10.784338 22485033404224 run_lib.py:146] step: 148250, training_loss: 5.18993e-04
I0512 18:56:34.816974 22485033404224 run_lib.py:146] step: 148300, training_loss: 6.09551e-04
I0512 18:56:34.977333 22485033404224 run_lib.py:167] step: 148300, eval_loss: 6.74131e-04
I0512 18:56:58.567694 22485033404224 run_lib.py:146] step: 148350, training_loss: 4.80434e-04
I0512 18:57:22.434750 22485033404224 run_lib.py:146] step: 148400, training_loss: 6.59663e-04
I0512 18:57:22.594656 22485033404224 run_lib.py:167] step: 148400, eval_loss: 5.61225e-04
I0512 18:57:46.576252 22485033404224 run_lib.py:146] step: 148450, training_loss: 4.36827e-04
I0512 18:58:10.192779 22485033404224 run_lib.py:146] step: 148500, training_loss: 6.64861e-04
I0512 18:58:10.353741 22485033404224 run_lib.py:167] step: 148500, eval_loss: 5.07917e-04
I0512 18:58:34.271468 22485033404224 run_lib.py:146] step: 148550, training_loss: 7.19177e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 18:58:58.427223 22485033404224 run_lib.py:146] step: 148600, training_loss: 7.46436e-04
I0512 18:58:58.589448 22485033404224 run_lib.py:167] step: 148600, eval_loss: 5.05567e-04
I0512 18:59:22.174959 22485033404224 run_lib.py:146] step: 148650, training_loss: 6.67750e-04
I0512 18:59:46.226850 22485033404224 run_lib.py:146] step: 148700, training_loss: 6.03452e-04
I0512 18:59:46.387076 22485033404224 run_lib.py:167] step: 148700, eval_loss: 8.51258e-04
I0512 19:00:10.265144 22485033404224 run_lib.py:146] step: 148750, training_loss: 6.25903e-04
I0512 19:00:33.899846 22485033404224 run_lib.py:146] step: 148800, training_loss: 5.64117e-04
I0512 19:00:34.061434 22485033404224 run_lib.py:167] step: 148800, eval_loss: 6.11416e-04
I0512 19:00:58.056792 22485033404224 run_lib.py:146] step: 148850, training_loss: 8.55264e-04
I0512 19:01:21.603925 22485033404224 run_lib.py:146] step: 148900, training_loss: 4.88307e-04
I0512 19:01:21.764967 22485033404224 run_lib.py:167] step: 148900, eval_loss: 6.60213e-04
I0512 19:01:45.615535 22485033404224 run_lib.py:146] step: 148950, training_loss: 4.98456e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 19:02:09.570424 22485033404224 run_lib.py:146] step: 149000, training_loss: 6.91927e-04
I0512 19:02:09.732165 22485033404224 run_lib.py:167] step: 149000, eval_loss: 4.59302e-04
I0512 19:02:33.261664 22485033404224 run_lib.py:146] step: 149050, training_loss: 5.05029e-04
I0512 19:02:57.103828 22485033404224 run_lib.py:146] step: 149100, training_loss: 7.54200e-04
I0512 19:02:57.263538 22485033404224 run_lib.py:167] step: 149100, eval_loss: 6.44758e-04
I0512 19:03:21.108538 22485033404224 run_lib.py:146] step: 149150, training_loss: 4.80902e-04
I0512 19:03:44.673320 22485033404224 run_lib.py:146] step: 149200, training_loss: 4.96365e-04
I0512 19:03:44.832938 22485033404224 run_lib.py:167] step: 149200, eval_loss: 9.10533e-04
I0512 19:04:08.673370 22485033404224 run_lib.py:146] step: 149250, training_loss: 5.04207e-04
I0512 19:04:32.204459 22485033404224 run_lib.py:146] step: 149300, training_loss: 5.14476e-04
I0512 19:04:32.364813 22485033404224 run_lib.py:167] step: 149300, eval_loss: 6.43052e-04
I0512 19:04:56.208399 22485033404224 run_lib.py:146] step: 149350, training_loss: 4.86231e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 19:05:20.210511 22485033404224 run_lib.py:146] step: 149400, training_loss: 3.53673e-04
I0512 19:05:20.371190 22485033404224 run_lib.py:167] step: 149400, eval_loss: 6.91698e-04
I0512 19:05:43.884329 22485033404224 run_lib.py:146] step: 149450, training_loss: 6.88199e-04
I0512 19:06:07.736364 22485033404224 run_lib.py:146] step: 149500, training_loss: 6.34378e-04
I0512 19:06:07.895910 22485033404224 run_lib.py:167] step: 149500, eval_loss: 4.81734e-04
I0512 19:06:31.745848 22485033404224 run_lib.py:146] step: 149550, training_loss: 6.99416e-04
I0512 19:06:55.288629 22485033404224 run_lib.py:146] step: 149600, training_loss: 6.05024e-04
I0512 19:06:55.450077 22485033404224 run_lib.py:167] step: 149600, eval_loss: 7.42325e-04
I0512 19:07:19.286430 22485033404224 run_lib.py:146] step: 149650, training_loss: 5.89958e-04
I0512 19:07:42.829338 22485033404224 run_lib.py:146] step: 149700, training_loss: 9.19133e-04
I0512 19:07:42.988563 22485033404224 run_lib.py:167] step: 149700, eval_loss: 6.42347e-04
I0512 19:08:06.817710 22485033404224 run_lib.py:146] step: 149750, training_loss: 7.48626e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 19:08:30.780687 22485033404224 run_lib.py:146] step: 149800, training_loss: 6.68426e-04
I0512 19:08:30.942003 22485033404224 run_lib.py:167] step: 149800, eval_loss: 5.60572e-04
I0512 19:08:54.455415 22485033404224 run_lib.py:146] step: 149850, training_loss: 8.47102e-04
I0512 19:09:18.347114 22485033404224 run_lib.py:146] step: 149900, training_loss: 5.39212e-04
I0512 19:09:18.506065 22485033404224 run_lib.py:167] step: 149900, eval_loss: 5.23103e-04
I0512 19:09:42.371054 22485033404224 run_lib.py:146] step: 149950, training_loss: 7.68636e-04
I0512 19:10:05.910480 22485033404224 run_lib.py:146] step: 150000, training_loss: 6.72377e-04
I0512 19:10:07.634222 22485033404224 run_lib.py:167] step: 150000, eval_loss: 3.24682e-04
I0512 19:10:32.976573 22485033404224 run_lib.py:146] step: 150050, training_loss: 4.08873e-04
I0512 19:10:56.847924 22485033404224 run_lib.py:146] step: 150100, training_loss: 5.70731e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 19:10:57.197844 22485033404224 run_lib.py:167] step: 150100, eval_loss: 5.92892e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 19:11:20.798800 22485033404224 run_lib.py:146] step: 150150, training_loss: 5.54119e-04
I0512 19:11:44.715218 22485033404224 run_lib.py:146] step: 150200, training_loss: 5.15857e-04
I0512 19:11:44.877306 22485033404224 run_lib.py:167] step: 150200, eval_loss: 6.52056e-04
I0512 19:12:08.873184 22485033404224 run_lib.py:146] step: 150250, training_loss: 6.26176e-04
I0512 19:12:32.483718 22485033404224 run_lib.py:146] step: 150300, training_loss: 5.71105e-04
I0512 19:12:32.644454 22485033404224 run_lib.py:167] step: 150300, eval_loss: 6.28566e-04
I0512 19:12:56.550183 22485033404224 run_lib.py:146] step: 150350, training_loss: 5.74901e-04
I0512 19:13:20.460444 22485033404224 run_lib.py:146] step: 150400, training_loss: 6.76672e-04
I0512 19:13:20.621452 22485033404224 run_lib.py:167] step: 150400, eval_loss: 7.71042e-04
I0512 19:13:44.218904 22485033404224 run_lib.py:146] step: 150450, training_loss: 6.73446e-04
I0512 19:14:07.800433 22485033404224 run_lib.py:146] step: 150500, training_loss: 5.77765e-04
I0512 19:14:07.960273 22485033404224 run_lib.py:167] step: 150500, eval_loss: 6.72470e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 19:14:32.534867 22485033404224 run_lib.py:146] step: 150550, training_loss: 6.49164e-04
I0512 19:14:56.366043 22485033404224 run_lib.py:146] step: 150600, training_loss: 5.39281e-04
I0512 19:14:56.530952 22485033404224 run_lib.py:167] step: 150600, eval_loss: 6.54108e-04
I0512 19:15:20.392852 22485033404224 run_lib.py:146] step: 150650, training_loss: 6.10618e-04
I0512 19:15:45.054796 22485033404224 run_lib.py:146] step: 150700, training_loss: 5.07426e-04
I0512 19:15:45.216870 22485033404224 run_lib.py:167] step: 150700, eval_loss: 7.40295e-04
I0512 19:16:08.971796 22485033404224 run_lib.py:146] step: 150750, training_loss: 5.37521e-04
I0512 19:16:32.582193 22485033404224 run_lib.py:146] step: 150800, training_loss: 5.89572e-04
I0512 19:16:32.744803 22485033404224 run_lib.py:167] step: 150800, eval_loss: 6.44011e-04
I0512 19:16:56.661091 22485033404224 run_lib.py:146] step: 150850, training_loss: 5.21712e-04
I0512 19:17:20.577796 22485033404224 run_lib.py:146] step: 150900, training_loss: 6.50216e-04
I0512 19:17:20.737919 22485033404224 run_lib.py:167] step: 150900, eval_loss: 5.65792e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 19:17:44.422754 22485033404224 run_lib.py:146] step: 150950, training_loss: 5.61002e-04
I0512 19:18:08.413451 22485033404224 run_lib.py:146] step: 151000, training_loss: 5.68491e-04
I0512 19:18:08.574811 22485033404224 run_lib.py:167] step: 151000, eval_loss: 7.56583e-04
I0512 19:18:32.571069 22485033404224 run_lib.py:146] step: 151050, training_loss: 7.44935e-04
I0512 19:18:56.128659 22485033404224 run_lib.py:146] step: 151100, training_loss: 5.73278e-04
I0512 19:18:56.287811 22485033404224 run_lib.py:167] step: 151100, eval_loss: 6.98122e-04
I0512 19:19:20.126316 22485033404224 run_lib.py:146] step: 151150, training_loss: 6.75532e-04
I0512 19:19:43.985272 22485033404224 run_lib.py:146] step: 151200, training_loss: 5.41588e-04
I0512 19:19:44.144996 22485033404224 run_lib.py:167] step: 151200, eval_loss: 7.27645e-04
I0512 19:20:07.687060 22485033404224 run_lib.py:146] step: 151250, training_loss: 6.80080e-04
I0512 19:20:31.259554 22485033404224 run_lib.py:146] step: 151300, training_loss: 7.01349e-04
I0512 19:20:31.420823 22485033404224 run_lib.py:167] step: 151300, eval_loss: 5.99938e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 19:20:55.712378 22485033404224 run_lib.py:146] step: 151350, training_loss: 6.70927e-04
I0512 19:21:19.230063 22485033404224 run_lib.py:146] step: 151400, training_loss: 5.20743e-04
I0512 19:21:19.389997 22485033404224 run_lib.py:167] step: 151400, eval_loss: 6.08637e-04
I0512 19:21:42.924962 22485033404224 run_lib.py:146] step: 151450, training_loss: 7.41285e-04
I0512 19:22:07.063032 22485033404224 run_lib.py:146] step: 151500, training_loss: 7.25960e-04
I0512 19:22:07.222442 22485033404224 run_lib.py:167] step: 151500, eval_loss: 5.50329e-04
I0512 19:22:30.736664 22485033404224 run_lib.py:146] step: 151550, training_loss: 5.73484e-04
I0512 19:22:54.244300 22485033404224 run_lib.py:146] step: 151600, training_loss: 5.38816e-04
I0512 19:22:54.403589 22485033404224 run_lib.py:167] step: 151600, eval_loss: 6.53787e-04
I0512 19:23:18.239484 22485033404224 run_lib.py:146] step: 151650, training_loss: 6.69844e-04
I0512 19:23:42.075572 22485033404224 run_lib.py:146] step: 151700, training_loss: 4.64048e-04
I0512 19:23:42.235023 22485033404224 run_lib.py:167] step: 151700, eval_loss: 5.73512e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 19:24:05.839591 22485033404224 run_lib.py:146] step: 151750, training_loss: 6.57968e-04
I0512 19:24:29.705311 22485033404224 run_lib.py:146] step: 151800, training_loss: 5.76490e-04
I0512 19:24:29.865671 22485033404224 run_lib.py:167] step: 151800, eval_loss: 6.10095e-04
I0512 19:24:53.747815 22485033404224 run_lib.py:146] step: 151850, training_loss: 6.19045e-04
I0512 19:25:17.280617 22485033404224 run_lib.py:146] step: 151900, training_loss: 6.57047e-04
I0512 19:25:17.438984 22485033404224 run_lib.py:167] step: 151900, eval_loss: 6.32511e-04
I0512 19:25:41.270147 22485033404224 run_lib.py:146] step: 151950, training_loss: 5.76737e-04
I0512 19:26:05.086939 22485033404224 run_lib.py:146] step: 152000, training_loss: 8.74669e-04
I0512 19:26:05.246803 22485033404224 run_lib.py:167] step: 152000, eval_loss: 6.42517e-04
I0512 19:26:28.759627 22485033404224 run_lib.py:146] step: 152050, training_loss: 6.19534e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 19:26:52.662489 22485033404224 run_lib.py:146] step: 152100, training_loss: 7.32432e-04
I0512 19:26:52.823351 22485033404224 run_lib.py:167] step: 152100, eval_loss: 4.89422e-04
I0512 19:27:16.658181 22485033404224 run_lib.py:146] step: 152150, training_loss: 7.70340e-04
I0512 19:27:40.188246 22485033404224 run_lib.py:146] step: 152200, training_loss: 5.75776e-04
I0512 19:27:40.346901 22485033404224 run_lib.py:167] step: 152200, eval_loss: 4.98948e-04
I0512 19:28:03.885472 22485033404224 run_lib.py:146] step: 152250, training_loss: 6.29773e-04
I0512 19:28:28.062005 22485033404224 run_lib.py:146] step: 152300, training_loss: 5.88584e-04
I0512 19:28:28.222175 22485033404224 run_lib.py:167] step: 152300, eval_loss: 4.82867e-04
I0512 19:28:51.746035 22485033404224 run_lib.py:146] step: 152350, training_loss: 7.32378e-04
I0512 19:29:15.293531 22485033404224 run_lib.py:146] step: 152400, training_loss: 5.68409e-04
I0512 19:29:15.454036 22485033404224 run_lib.py:167] step: 152400, eval_loss: 8.69231e-04
I0512 19:29:39.671345 22485033404224 run_lib.py:146] step: 152450, training_loss: 6.07975e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 19:30:03.359592 22485033404224 run_lib.py:146] step: 152500, training_loss: 4.72288e-04
I0512 19:30:03.521645 22485033404224 run_lib.py:167] step: 152500, eval_loss: 6.73057e-04
I0512 19:30:27.124171 22485033404224 run_lib.py:146] step: 152550, training_loss: 6.39584e-04
I0512 19:30:51.125841 22485033404224 run_lib.py:146] step: 152600, training_loss: 6.48768e-04
I0512 19:30:51.285558 22485033404224 run_lib.py:167] step: 152600, eval_loss: 6.69920e-04
I0512 19:31:15.317354 22485033404224 run_lib.py:146] step: 152650, training_loss: 8.45793e-04
I0512 19:31:38.915240 22485033404224 run_lib.py:146] step: 152700, training_loss: 5.97541e-04
I0512 19:31:39.075107 22485033404224 run_lib.py:167] step: 152700, eval_loss: 6.19544e-04
I0512 19:32:02.983541 22485033404224 run_lib.py:146] step: 152750, training_loss: 7.59768e-04
I0512 19:32:27.006215 22485033404224 run_lib.py:146] step: 152800, training_loss: 6.97391e-04
I0512 19:32:27.166137 22485033404224 run_lib.py:167] step: 152800, eval_loss: 6.17316e-04
I0512 19:32:50.763687 22485033404224 run_lib.py:146] step: 152850, training_loss: 5.83738e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 19:33:14.790517 22485033404224 run_lib.py:146] step: 152900, training_loss: 4.74750e-04
I0512 19:33:14.952744 22485033404224 run_lib.py:167] step: 152900, eval_loss: 6.19808e-04
I0512 19:33:38.936475 22485033404224 run_lib.py:146] step: 152950, training_loss: 6.63319e-04
I0512 19:34:02.501371 22485033404224 run_lib.py:146] step: 153000, training_loss: 5.42551e-04
I0512 19:34:02.661580 22485033404224 run_lib.py:167] step: 153000, eval_loss: 5.08846e-04
I0512 19:34:26.254033 22485033404224 run_lib.py:146] step: 153050, training_loss: 5.79856e-04
I0512 19:34:50.446238 22485033404224 run_lib.py:146] step: 153100, training_loss: 5.77382e-04
I0512 19:34:50.606751 22485033404224 run_lib.py:167] step: 153100, eval_loss: 6.49739e-04
I0512 19:35:14.198698 22485033404224 run_lib.py:146] step: 153150, training_loss: 7.16039e-04
I0512 19:35:37.790485 22485033404224 run_lib.py:146] step: 153200, training_loss: 5.23806e-04
I0512 19:35:37.952642 22485033404224 run_lib.py:167] step: 153200, eval_loss: 7.48341e-04
I0512 19:36:02.150647 22485033404224 run_lib.py:146] step: 153250, training_loss: 4.73340e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 19:36:25.808699 22485033404224 run_lib.py:146] step: 153300, training_loss: 4.78653e-04
I0512 19:36:25.971121 22485033404224 run_lib.py:167] step: 153300, eval_loss: 5.28016e-04
I0512 19:36:49.528865 22485033404224 run_lib.py:146] step: 153350, training_loss: 6.41379e-04
I0512 19:37:13.434703 22485033404224 run_lib.py:146] step: 153400, training_loss: 7.08367e-04
I0512 19:37:13.594280 22485033404224 run_lib.py:167] step: 153400, eval_loss: 4.76252e-04
I0512 19:37:37.443286 22485033404224 run_lib.py:146] step: 153450, training_loss: 5.50388e-04
I0512 19:38:00.982271 22485033404224 run_lib.py:146] step: 153500, training_loss: 6.79676e-04
I0512 19:38:01.141695 22485033404224 run_lib.py:167] step: 153500, eval_loss: 4.51186e-04
I0512 19:38:24.994955 22485033404224 run_lib.py:146] step: 153550, training_loss: 6.56942e-04
I0512 19:38:48.817000 22485033404224 run_lib.py:146] step: 153600, training_loss: 5.66400e-04
I0512 19:38:48.977162 22485033404224 run_lib.py:167] step: 153600, eval_loss: 7.01319e-04
I0512 19:39:12.501838 22485033404224 run_lib.py:146] step: 153650, training_loss: 7.01893e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 19:39:36.470019 22485033404224 run_lib.py:146] step: 153700, training_loss: 4.18173e-04
I0512 19:39:36.630905 22485033404224 run_lib.py:167] step: 153700, eval_loss: 4.58262e-04
I0512 19:40:00.505666 22485033404224 run_lib.py:146] step: 153750, training_loss: 4.63150e-04
I0512 19:40:24.070011 22485033404224 run_lib.py:146] step: 153800, training_loss: 6.26214e-04
I0512 19:40:24.229277 22485033404224 run_lib.py:167] step: 153800, eval_loss: 5.23428e-04
I0512 19:40:48.081070 22485033404224 run_lib.py:146] step: 153850, training_loss: 4.81467e-04
I0512 19:41:11.911324 22485033404224 run_lib.py:146] step: 153900, training_loss: 5.57477e-04
I0512 19:41:12.071505 22485033404224 run_lib.py:167] step: 153900, eval_loss: 4.96234e-04
I0512 19:41:35.640377 22485033404224 run_lib.py:146] step: 153950, training_loss: 6.62010e-04
I0512 19:41:59.195532 22485033404224 run_lib.py:146] step: 154000, training_loss: 7.08671e-04
I0512 19:41:59.354774 22485033404224 run_lib.py:167] step: 154000, eval_loss: 6.20817e-04
I0512 19:42:23.488187 22485033404224 run_lib.py:146] step: 154050, training_loss: 5.93979e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 19:42:47.078022 22485033404224 run_lib.py:146] step: 154100, training_loss: 7.19414e-04
I0512 19:42:47.239110 22485033404224 run_lib.py:167] step: 154100, eval_loss: 6.69546e-04
I0512 19:43:10.756422 22485033404224 run_lib.py:146] step: 154150, training_loss: 6.46443e-04
I0512 19:43:34.646459 22485033404224 run_lib.py:146] step: 154200, training_loss: 6.87144e-04
I0512 19:43:34.807488 22485033404224 run_lib.py:167] step: 154200, eval_loss: 6.39417e-04
I0512 19:43:58.683997 22485033404224 run_lib.py:146] step: 154250, training_loss: 6.22611e-04
I0512 19:44:22.231694 22485033404224 run_lib.py:146] step: 154300, training_loss: 5.99838e-04
I0512 19:44:22.390793 22485033404224 run_lib.py:167] step: 154300, eval_loss: 6.18376e-04
I0512 19:44:46.231294 22485033404224 run_lib.py:146] step: 154350, training_loss: 5.60638e-04
I0512 19:45:10.089526 22485033404224 run_lib.py:146] step: 154400, training_loss: 5.94010e-04
I0512 19:45:10.249311 22485033404224 run_lib.py:167] step: 154400, eval_loss: 4.69333e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 19:45:33.859824 22485033404224 run_lib.py:146] step: 154450, training_loss: 5.48109e-04
I0512 19:45:57.760013 22485033404224 run_lib.py:146] step: 154500, training_loss: 5.04091e-04
I0512 19:45:57.921199 22485033404224 run_lib.py:167] step: 154500, eval_loss: 5.01106e-04
I0512 19:46:21.801368 22485033404224 run_lib.py:146] step: 154550, training_loss: 7.25195e-04
I0512 19:46:45.334935 22485033404224 run_lib.py:146] step: 154600, training_loss: 4.98321e-04
I0512 19:46:45.494345 22485033404224 run_lib.py:167] step: 154600, eval_loss: 7.69779e-04
I0512 19:47:09.427587 22485033404224 run_lib.py:146] step: 154650, training_loss: 5.56981e-04
I0512 19:47:33.383545 22485033404224 run_lib.py:146] step: 154700, training_loss: 4.69797e-04
I0512 19:47:33.543901 22485033404224 run_lib.py:167] step: 154700, eval_loss: 4.77838e-04
I0512 19:47:57.152779 22485033404224 run_lib.py:146] step: 154750, training_loss: 5.72950e-04
I0512 19:48:20.763923 22485033404224 run_lib.py:146] step: 154800, training_loss: 4.40217e-04
I0512 19:48:20.925011 22485033404224 run_lib.py:167] step: 154800, eval_loss: 6.33379e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 19:48:45.268149 22485033404224 run_lib.py:146] step: 154850, training_loss: 7.27222e-04
I0512 19:49:08.858013 22485033404224 run_lib.py:146] step: 154900, training_loss: 6.73842e-04
I0512 19:49:09.019114 22485033404224 run_lib.py:167] step: 154900, eval_loss: 6.84345e-04
I0512 19:49:32.584531 22485033404224 run_lib.py:146] step: 154950, training_loss: 6.54711e-04
I0512 19:49:56.515927 22485033404224 run_lib.py:146] step: 155000, training_loss: 5.85924e-04
I0512 19:49:56.675876 22485033404224 run_lib.py:167] step: 155000, eval_loss: 6.16081e-04
I0512 19:50:20.539759 22485033404224 run_lib.py:146] step: 155050, training_loss: 6.55787e-04
I0512 19:50:44.135631 22485033404224 run_lib.py:146] step: 155100, training_loss: 7.44400e-04
I0512 19:50:44.295980 22485033404224 run_lib.py:167] step: 155100, eval_loss: 7.91722e-04
I0512 19:51:08.226290 22485033404224 run_lib.py:146] step: 155150, training_loss: 6.75813e-04
I0512 19:51:32.168679 22485033404224 run_lib.py:146] step: 155200, training_loss: 6.16096e-04
I0512 19:51:32.329481 22485033404224 run_lib.py:167] step: 155200, eval_loss: 7.60757e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 19:51:56.023404 22485033404224 run_lib.py:146] step: 155250, training_loss: 6.75077e-04
I0512 19:52:20.011489 22485033404224 run_lib.py:146] step: 155300, training_loss: 6.78556e-04
I0512 19:52:20.173169 22485033404224 run_lib.py:167] step: 155300, eval_loss: 7.47724e-04
I0512 19:52:44.246898 22485033404224 run_lib.py:146] step: 155350, training_loss: 7.62784e-04
I0512 19:53:07.870318 22485033404224 run_lib.py:146] step: 155400, training_loss: 6.80632e-04
I0512 19:53:08.031155 22485033404224 run_lib.py:167] step: 155400, eval_loss: 9.62366e-04
I0512 19:53:31.970782 22485033404224 run_lib.py:146] step: 155450, training_loss: 4.82389e-04
I0512 19:53:55.974255 22485033404224 run_lib.py:146] step: 155500, training_loss: 6.78241e-04
I0512 19:53:56.133553 22485033404224 run_lib.py:167] step: 155500, eval_loss: 4.07281e-04
I0512 19:54:19.676829 22485033404224 run_lib.py:146] step: 155550, training_loss: 6.84992e-04
I0512 19:54:43.520899 22485033404224 run_lib.py:146] step: 155600, training_loss: 5.13179e-04
I0512 19:54:43.680298 22485033404224 run_lib.py:167] step: 155600, eval_loss: 6.47195e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 19:55:07.610335 22485033404224 run_lib.py:146] step: 155650, training_loss: 5.93766e-04
I0512 19:55:31.129049 22485033404224 run_lib.py:146] step: 155700, training_loss: 6.63611e-04
I0512 19:55:31.290369 22485033404224 run_lib.py:167] step: 155700, eval_loss: 6.08892e-04
I0512 19:55:54.804023 22485033404224 run_lib.py:146] step: 155750, training_loss: 4.63871e-04
I0512 19:56:18.980940 22485033404224 run_lib.py:146] step: 155800, training_loss: 6.18736e-04
I0512 19:56:19.141541 22485033404224 run_lib.py:167] step: 155800, eval_loss: 4.22302e-04
I0512 19:56:42.666204 22485033404224 run_lib.py:146] step: 155850, training_loss: 4.53484e-04
I0512 19:57:06.226514 22485033404224 run_lib.py:146] step: 155900, training_loss: 6.64446e-04
I0512 19:57:06.385064 22485033404224 run_lib.py:167] step: 155900, eval_loss: 6.93736e-04
I0512 19:57:30.219983 22485033404224 run_lib.py:146] step: 155950, training_loss: 6.25215e-04
I0512 19:57:54.059956 22485033404224 run_lib.py:146] step: 156000, training_loss: 4.63132e-04
I0512 19:57:54.219921 22485033404224 run_lib.py:167] step: 156000, eval_loss: 5.84082e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 19:58:17.831079 22485033404224 run_lib.py:146] step: 156050, training_loss: 5.17182e-04
I0512 19:58:41.699241 22485033404224 run_lib.py:146] step: 156100, training_loss: 6.32868e-04
I0512 19:58:41.859430 22485033404224 run_lib.py:167] step: 156100, eval_loss: 4.92290e-04
I0512 19:59:05.703951 22485033404224 run_lib.py:146] step: 156150, training_loss: 5.32897e-04
I0512 19:59:29.217271 22485033404224 run_lib.py:146] step: 156200, training_loss: 7.20239e-04
I0512 19:59:29.377011 22485033404224 run_lib.py:167] step: 156200, eval_loss: 7.19669e-04
I0512 19:59:53.221868 22485033404224 run_lib.py:146] step: 156250, training_loss: 5.96386e-04
I0512 20:00:17.062081 22485033404224 run_lib.py:146] step: 156300, training_loss: 7.05397e-04
I0512 20:00:17.220358 22485033404224 run_lib.py:167] step: 156300, eval_loss: 6.18730e-04
I0512 20:00:40.777853 22485033404224 run_lib.py:146] step: 156350, training_loss: 5.50724e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 20:01:04.705651 22485033404224 run_lib.py:146] step: 156400, training_loss: 5.84877e-04
I0512 20:01:04.867363 22485033404224 run_lib.py:167] step: 156400, eval_loss: 8.23300e-04
I0512 20:01:28.743365 22485033404224 run_lib.py:146] step: 156450, training_loss: 7.03780e-04
I0512 20:01:52.278558 22485033404224 run_lib.py:146] step: 156500, training_loss: 4.86368e-04
I0512 20:01:52.440253 22485033404224 run_lib.py:167] step: 156500, eval_loss: 6.34507e-04
I0512 20:02:15.971047 22485033404224 run_lib.py:146] step: 156550, training_loss: 4.44924e-04
I0512 20:02:40.135378 22485033404224 run_lib.py:146] step: 156600, training_loss: 5.16343e-04
I0512 20:02:40.294215 22485033404224 run_lib.py:167] step: 156600, eval_loss: 7.13570e-04
I0512 20:03:03.824390 22485033404224 run_lib.py:146] step: 156650, training_loss: 6.17935e-04
I0512 20:03:27.356487 22485033404224 run_lib.py:146] step: 156700, training_loss: 5.45308e-04
I0512 20:03:27.516028 22485033404224 run_lib.py:167] step: 156700, eval_loss: 6.11000e-04
I0512 20:03:51.330791 22485033404224 run_lib.py:146] step: 156750, training_loss: 6.64745e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 20:04:15.216740 22485033404224 run_lib.py:146] step: 156800, training_loss: 6.40829e-04
I0512 20:04:15.377630 22485033404224 run_lib.py:167] step: 156800, eval_loss: 6.60789e-04
I0512 20:04:38.923189 22485033404224 run_lib.py:146] step: 156850, training_loss: 7.79268e-04
I0512 20:05:02.877000 22485033404224 run_lib.py:146] step: 156900, training_loss: 5.10887e-04
I0512 20:05:03.037523 22485033404224 run_lib.py:167] step: 156900, eval_loss: 5.02555e-04
I0512 20:05:27.009546 22485033404224 run_lib.py:146] step: 156950, training_loss: 7.03957e-04
I0512 20:05:50.606040 22485033404224 run_lib.py:146] step: 157000, training_loss: 6.64972e-04
I0512 20:05:50.766806 22485033404224 run_lib.py:167] step: 157000, eval_loss: 5.67582e-04
I0512 20:06:14.699109 22485033404224 run_lib.py:146] step: 157050, training_loss: 5.96203e-04
I0512 20:06:38.618551 22485033404224 run_lib.py:146] step: 157100, training_loss: 5.53036e-04
I0512 20:06:38.779028 22485033404224 run_lib.py:167] step: 157100, eval_loss: 6.76009e-04
I0512 20:07:02.396914 22485033404224 run_lib.py:146] step: 157150, training_loss: 6.60851e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 20:07:26.621373 22485033404224 run_lib.py:146] step: 157200, training_loss: 5.79021e-04
I0512 20:07:26.784176 22485033404224 run_lib.py:167] step: 157200, eval_loss: 5.15643e-04
I0512 20:07:50.935646 22485033404224 run_lib.py:146] step: 157250, training_loss: 5.81957e-04
I0512 20:08:14.613636 22485033404224 run_lib.py:146] step: 157300, training_loss: 5.38066e-04
I0512 20:08:14.775999 22485033404224 run_lib.py:167] step: 157300, eval_loss: 7.31480e-04
I0512 20:08:38.897558 22485033404224 run_lib.py:146] step: 157350, training_loss: 6.98110e-04
I0512 20:09:03.026146 22485033404224 run_lib.py:146] step: 157400, training_loss: 4.74993e-04
I0512 20:09:03.186357 22485033404224 run_lib.py:167] step: 157400, eval_loss: 6.56548e-04
I0512 20:09:26.838854 22485033404224 run_lib.py:146] step: 157450, training_loss: 7.45379e-04
I0512 20:09:50.499829 22485033404224 run_lib.py:146] step: 157500, training_loss: 5.05820e-04
I0512 20:09:50.660797 22485033404224 run_lib.py:167] step: 157500, eval_loss: 7.44304e-04
I0512 20:10:14.613757 22485033404224 run_lib.py:146] step: 157550, training_loss: 6.79304e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 20:10:38.602396 22485033404224 run_lib.py:146] step: 157600, training_loss: 5.16706e-04
I0512 20:10:38.763903 22485033404224 run_lib.py:167] step: 157600, eval_loss: 6.92830e-04
I0512 20:11:02.365931 22485033404224 run_lib.py:146] step: 157650, training_loss: 4.88938e-04
I0512 20:11:26.344508 22485033404224 run_lib.py:146] step: 157700, training_loss: 5.54653e-04
I0512 20:11:26.504817 22485033404224 run_lib.py:167] step: 157700, eval_loss: 4.83450e-04
I0512 20:11:50.405685 22485033404224 run_lib.py:146] step: 157750, training_loss: 8.08658e-04
I0512 20:12:13.960380 22485033404224 run_lib.py:146] step: 157800, training_loss: 6.02152e-04
I0512 20:12:14.119146 22485033404224 run_lib.py:167] step: 157800, eval_loss: 5.67147e-04
I0512 20:12:37.949573 22485033404224 run_lib.py:146] step: 157850, training_loss: 6.33905e-04
I0512 20:13:01.776844 22485033404224 run_lib.py:146] step: 157900, training_loss: 8.32830e-04
I0512 20:13:01.859287 22485033404224 run_lib.py:167] step: 157900, eval_loss: 8.31302e-04
I0512 20:13:25.371010 22485033404224 run_lib.py:146] step: 157950, training_loss: 6.43733e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 20:13:49.313185 22485033404224 run_lib.py:146] step: 158000, training_loss: 6.68653e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 20:13:49.659952 22485033404224 run_lib.py:167] step: 158000, eval_loss: 5.40250e-04
I0512 20:14:13.500141 22485033404224 run_lib.py:146] step: 158050, training_loss: 6.87187e-04
I0512 20:14:37.046951 22485033404224 run_lib.py:146] step: 158100, training_loss: 6.20135e-04
I0512 20:14:37.205673 22485033404224 run_lib.py:167] step: 158100, eval_loss: 5.33471e-04
I0512 20:15:01.092417 22485033404224 run_lib.py:146] step: 158150, training_loss: 5.57487e-04
I0512 20:15:24.930075 22485033404224 run_lib.py:146] step: 158200, training_loss: 5.98384e-04
I0512 20:15:25.088864 22485033404224 run_lib.py:167] step: 158200, eval_loss: 5.81710e-04
I0512 20:15:48.614369 22485033404224 run_lib.py:146] step: 158250, training_loss: 7.10751e-04
I0512 20:16:12.151228 22485033404224 run_lib.py:146] step: 158300, training_loss: 5.11350e-04
I0512 20:16:12.311262 22485033404224 run_lib.py:167] step: 158300, eval_loss: 5.01776e-04
I0512 20:16:36.162236 22485033404224 run_lib.py:146] step: 158350, training_loss: 7.37233e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 20:17:00.081394 22485033404224 run_lib.py:146] step: 158400, training_loss: 5.90545e-04
I0512 20:17:00.242725 22485033404224 run_lib.py:167] step: 158400, eval_loss: 6.04135e-04
I0512 20:17:23.786141 22485033404224 run_lib.py:146] step: 158450, training_loss: 6.98454e-04
I0512 20:17:47.665155 22485033404224 run_lib.py:146] step: 158500, training_loss: 4.74852e-04
I0512 20:17:47.824847 22485033404224 run_lib.py:167] step: 158500, eval_loss: 4.95956e-04
I0512 20:18:11.700854 22485033404224 run_lib.py:146] step: 158550, training_loss: 5.79355e-04
I0512 20:18:35.245472 22485033404224 run_lib.py:146] step: 158600, training_loss: 7.20824e-04
I0512 20:18:35.405160 22485033404224 run_lib.py:167] step: 158600, eval_loss: 7.05963e-04
I0512 20:18:59.239116 22485033404224 run_lib.py:146] step: 158650, training_loss: 5.74717e-04
I0512 20:19:23.073754 22485033404224 run_lib.py:146] step: 158700, training_loss: 6.39425e-04
I0512 20:19:23.232980 22485033404224 run_lib.py:167] step: 158700, eval_loss: 6.43338e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 20:19:46.847238 22485033404224 run_lib.py:146] step: 158750, training_loss: 7.40925e-04
I0512 20:20:10.742201 22485033404224 run_lib.py:146] step: 158800, training_loss: 7.06085e-04
I0512 20:20:10.903063 22485033404224 run_lib.py:167] step: 158800, eval_loss: 7.07004e-04
I0512 20:20:34.806479 22485033404224 run_lib.py:146] step: 158850, training_loss: 6.57413e-04
I0512 20:20:58.339507 22485033404224 run_lib.py:146] step: 158900, training_loss: 4.95182e-04
I0512 20:20:58.499334 22485033404224 run_lib.py:167] step: 158900, eval_loss: 5.46435e-04
I0512 20:21:22.349479 22485033404224 run_lib.py:146] step: 158950, training_loss: 8.01920e-04
I0512 20:21:46.192556 22485033404224 run_lib.py:146] step: 159000, training_loss: 6.99859e-04
I0512 20:21:46.351284 22485033404224 run_lib.py:167] step: 159000, eval_loss: 6.28951e-04
I0512 20:22:09.911687 22485033404224 run_lib.py:146] step: 159050, training_loss: 6.33088e-04
I0512 20:22:33.519526 22485033404224 run_lib.py:146] step: 159100, training_loss: 5.56954e-04
I0512 20:22:33.680150 22485033404224 run_lib.py:167] step: 159100, eval_loss: 7.06965e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 20:22:58.014784 22485033404224 run_lib.py:146] step: 159150, training_loss: 5.99904e-04
I0512 20:23:21.622888 22485033404224 run_lib.py:146] step: 159200, training_loss: 5.52887e-04
I0512 20:23:21.784307 22485033404224 run_lib.py:167] step: 159200, eval_loss: 7.66512e-04
I0512 20:23:45.419561 22485033404224 run_lib.py:146] step: 159250, training_loss: 6.10996e-04
I0512 20:24:09.494979 22485033404224 run_lib.py:146] step: 159300, training_loss: 6.72782e-04
I0512 20:24:09.655614 22485033404224 run_lib.py:167] step: 159300, eval_loss: 5.72818e-04
I0512 20:24:33.598526 22485033404224 run_lib.py:146] step: 159350, training_loss: 8.19134e-04
I0512 20:24:57.244536 22485033404224 run_lib.py:146] step: 159400, training_loss: 5.21585e-04
I0512 20:24:57.405412 22485033404224 run_lib.py:167] step: 159400, eval_loss: 6.16321e-04
I0512 20:25:21.440730 22485033404224 run_lib.py:146] step: 159450, training_loss: 7.69579e-04
I0512 20:25:45.361397 22485033404224 run_lib.py:146] step: 159500, training_loss: 6.54085e-04
I0512 20:25:45.521554 22485033404224 run_lib.py:167] step: 159500, eval_loss: 5.28663e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 20:26:09.270158 22485033404224 run_lib.py:146] step: 159550, training_loss: 6.93999e-04
I0512 20:26:33.506556 22485033404224 run_lib.py:146] step: 159600, training_loss: 4.27331e-04
I0512 20:26:33.670383 22485033404224 run_lib.py:167] step: 159600, eval_loss: 5.22508e-04
I0512 20:26:57.638062 22485033404224 run_lib.py:146] step: 159650, training_loss: 6.49775e-04
I0512 20:27:21.289638 22485033404224 run_lib.py:146] step: 159700, training_loss: 6.69787e-04
I0512 20:27:21.450356 22485033404224 run_lib.py:167] step: 159700, eval_loss: 5.56078e-04
I0512 20:27:45.075683 22485033404224 run_lib.py:146] step: 159750, training_loss: 6.99199e-04
I0512 20:28:09.274845 22485033404224 run_lib.py:146] step: 159800, training_loss: 4.28596e-04
I0512 20:28:09.434381 22485033404224 run_lib.py:167] step: 159800, eval_loss: 7.10287e-04
I0512 20:28:33.029559 22485033404224 run_lib.py:146] step: 159850, training_loss: 6.60008e-04
I0512 20:28:56.660561 22485033404224 run_lib.py:146] step: 159900, training_loss: 5.90090e-04
I0512 20:28:56.821019 22485033404224 run_lib.py:167] step: 159900, eval_loss: 5.97524e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 20:29:21.124209 22485033404224 run_lib.py:146] step: 159950, training_loss: 6.62041e-04
I0512 20:29:44.685141 22485033404224 run_lib.py:146] step: 160000, training_loss: 5.90922e-04
I0512 20:29:46.404400 22485033404224 run_lib.py:167] step: 160000, eval_loss: 6.43631e-04
I0512 20:30:11.598512 22485033404224 run_lib.py:146] step: 160050, training_loss: 4.52119e-04
I0512 20:30:35.758839 22485033404224 run_lib.py:146] step: 160100, training_loss: 5.57223e-04
I0512 20:30:35.918570 22485033404224 run_lib.py:167] step: 160100, eval_loss: 5.25007e-04
I0512 20:30:59.437922 22485033404224 run_lib.py:146] step: 160150, training_loss: 4.33145e-04
I0512 20:31:22.983059 22485033404224 run_lib.py:146] step: 160200, training_loss: 5.81080e-04
I0512 20:31:23.144238 22485033404224 run_lib.py:167] step: 160200, eval_loss: 6.58100e-04
I0512 20:31:47.309136 22485033404224 run_lib.py:146] step: 160250, training_loss: 5.84691e-04
I0512 20:32:10.838634 22485033404224 run_lib.py:146] step: 160300, training_loss: 7.52735e-04
I0512 20:32:10.998467 22485033404224 run_lib.py:167] step: 160300, eval_loss: 5.08418e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 20:32:34.627133 22485033404224 run_lib.py:146] step: 160350, training_loss: 7.98701e-04
I0512 20:32:58.854919 22485033404224 run_lib.py:146] step: 160400, training_loss: 7.44086e-04
I0512 20:32:59.015380 22485033404224 run_lib.py:167] step: 160400, eval_loss: 4.62631e-04
I0512 20:33:22.544311 22485033404224 run_lib.py:146] step: 160450, training_loss: 6.72132e-04
I0512 20:33:46.059803 22485033404224 run_lib.py:146] step: 160500, training_loss: 5.73911e-04
I0512 20:33:46.218398 22485033404224 run_lib.py:167] step: 160500, eval_loss: 5.21025e-04
I0512 20:34:10.383327 22485033404224 run_lib.py:146] step: 160550, training_loss: 6.02769e-04
I0512 20:34:33.912921 22485033404224 run_lib.py:146] step: 160600, training_loss: 5.93238e-04
I0512 20:34:34.071723 22485033404224 run_lib.py:167] step: 160600, eval_loss: 5.11884e-04
I0512 20:34:57.604751 22485033404224 run_lib.py:146] step: 160650, training_loss: 5.59792e-04
I0512 20:35:21.328929 22485033404224 run_lib.py:146] step: 160700, training_loss: 6.18242e-04
I0512 20:35:21.487930 22485033404224 run_lib.py:167] step: 160700, eval_loss: 8.77700e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 20:35:45.596956 22485033404224 run_lib.py:146] step: 160750, training_loss: 6.96594e-04
I0512 20:36:09.134397 22485033404224 run_lib.py:146] step: 160800, training_loss: 6.59976e-04
I0512 20:36:09.293827 22485033404224 run_lib.py:167] step: 160800, eval_loss: 4.75782e-04
I0512 20:36:32.825939 22485033404224 run_lib.py:146] step: 160850, training_loss: 5.67651e-04
I0512 20:36:56.990402 22485033404224 run_lib.py:146] step: 160900, training_loss: 7.52532e-04
I0512 20:36:57.150186 22485033404224 run_lib.py:167] step: 160900, eval_loss: 3.61954e-04
I0512 20:37:20.711299 22485033404224 run_lib.py:146] step: 160950, training_loss: 6.02484e-04
I0512 20:37:44.305220 22485033404224 run_lib.py:146] step: 161000, training_loss: 5.69679e-04
I0512 20:37:44.464854 22485033404224 run_lib.py:167] step: 161000, eval_loss: 7.36355e-04
I0512 20:38:08.604616 22485033404224 run_lib.py:146] step: 161050, training_loss: 7.55480e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 20:38:32.222992 22485033404224 run_lib.py:146] step: 161100, training_loss: 5.88866e-04
I0512 20:38:32.384296 22485033404224 run_lib.py:167] step: 161100, eval_loss: 6.92769e-04
I0512 20:38:55.966619 22485033404224 run_lib.py:146] step: 161150, training_loss: 6.53102e-04
I0512 20:39:20.226215 22485033404224 run_lib.py:146] step: 161200, training_loss: 4.12381e-04
I0512 20:39:20.385947 22485033404224 run_lib.py:167] step: 161200, eval_loss: 7.76726e-04
I0512 20:39:43.934375 22485033404224 run_lib.py:146] step: 161250, training_loss: 7.29910e-04
I0512 20:40:07.545587 22485033404224 run_lib.py:146] step: 161300, training_loss: 6.60897e-04
I0512 20:40:07.707318 22485033404224 run_lib.py:167] step: 161300, eval_loss: 6.52018e-04
I0512 20:40:31.907462 22485033404224 run_lib.py:146] step: 161350, training_loss: 7.19957e-04
I0512 20:40:55.498884 22485033404224 run_lib.py:146] step: 161400, training_loss: 4.85665e-04
I0512 20:40:55.659205 22485033404224 run_lib.py:167] step: 161400, eval_loss: 6.53426e-04
I0512 20:41:19.300059 22485033404224 run_lib.py:146] step: 161450, training_loss: 7.38378e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 20:41:43.333111 22485033404224 run_lib.py:146] step: 161500, training_loss: 7.77324e-04
I0512 20:41:43.494913 22485033404224 run_lib.py:167] step: 161500, eval_loss: 5.27544e-04
I0512 20:42:07.477129 22485033404224 run_lib.py:146] step: 161550, training_loss: 6.30137e-04
I0512 20:42:31.094571 22485033404224 run_lib.py:146] step: 161600, training_loss: 7.31504e-04
I0512 20:42:31.255012 22485033404224 run_lib.py:167] step: 161600, eval_loss: 4.59884e-04
I0512 20:42:55.185164 22485033404224 run_lib.py:146] step: 161650, training_loss: 6.14055e-04
I0512 20:43:19.115003 22485033404224 run_lib.py:146] step: 161700, training_loss: 6.47943e-04
I0512 20:43:19.276433 22485033404224 run_lib.py:167] step: 161700, eval_loss: 5.55559e-04
I0512 20:43:42.896156 22485033404224 run_lib.py:146] step: 161750, training_loss: 7.15782e-04
I0512 20:44:06.541716 22485033404224 run_lib.py:146] step: 161800, training_loss: 5.91763e-04
I0512 20:44:06.703352 22485033404224 run_lib.py:167] step: 161800, eval_loss: 6.70071e-04
I0512 20:44:30.966135 22485033404224 run_lib.py:146] step: 161850, training_loss: 6.17418e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 20:44:54.696317 22485033404224 run_lib.py:146] step: 161900, training_loss: 6.01208e-04
I0512 20:44:54.859063 22485033404224 run_lib.py:167] step: 161900, eval_loss: 7.49391e-04
I0512 20:45:18.509671 22485033404224 run_lib.py:146] step: 161950, training_loss: 6.09818e-04
I0512 20:45:43.054303 22485033404224 run_lib.py:146] step: 162000, training_loss: 5.97312e-04
I0512 20:45:43.213759 22485033404224 run_lib.py:167] step: 162000, eval_loss: 6.03271e-04
I0512 20:46:06.807785 22485033404224 run_lib.py:146] step: 162050, training_loss: 6.29405e-04
I0512 20:46:30.462350 22485033404224 run_lib.py:146] step: 162100, training_loss: 6.15562e-04
I0512 20:46:30.624227 22485033404224 run_lib.py:167] step: 162100, eval_loss: 5.35551e-04
I0512 20:46:55.050395 22485033404224 run_lib.py:146] step: 162150, training_loss: 7.64085e-04
I0512 20:47:18.582529 22485033404224 run_lib.py:146] step: 162200, training_loss: 5.25357e-04
I0512 20:47:18.744032 22485033404224 run_lib.py:167] step: 162200, eval_loss: 5.77794e-04
I0512 20:47:42.316246 22485033404224 run_lib.py:146] step: 162250, training_loss: 6.35406e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 20:48:06.331885 22485033404224 run_lib.py:146] step: 162300, training_loss: 5.91519e-04
I0512 20:48:06.492274 22485033404224 run_lib.py:167] step: 162300, eval_loss: 4.36898e-04
I0512 20:48:30.340775 22485033404224 run_lib.py:146] step: 162350, training_loss: 5.08350e-04
I0512 20:48:53.867220 22485033404224 run_lib.py:146] step: 162400, training_loss: 9.07916e-04
I0512 20:48:54.027179 22485033404224 run_lib.py:167] step: 162400, eval_loss: 4.61037e-04
I0512 20:49:17.859988 22485033404224 run_lib.py:146] step: 162450, training_loss: 5.64756e-04
I0512 20:49:41.700278 22485033404224 run_lib.py:146] step: 162500, training_loss: 5.94812e-04
I0512 20:49:41.860373 22485033404224 run_lib.py:167] step: 162500, eval_loss: 6.91471e-04
I0512 20:50:05.400820 22485033404224 run_lib.py:146] step: 162550, training_loss: 4.61369e-04
I0512 20:50:28.939321 22485033404224 run_lib.py:146] step: 162600, training_loss: 6.89263e-04
I0512 20:50:29.099044 22485033404224 run_lib.py:167] step: 162600, eval_loss: 7.42569e-04
I0512 20:50:53.243448 22485033404224 run_lib.py:146] step: 162650, training_loss: 6.32693e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 20:51:16.874356 22485033404224 run_lib.py:146] step: 162700, training_loss: 5.70436e-04
I0512 20:51:17.036158 22485033404224 run_lib.py:167] step: 162700, eval_loss: 5.01069e-04
I0512 20:51:40.557210 22485033404224 run_lib.py:146] step: 162750, training_loss: 4.99880e-04
I0512 20:52:04.768593 22485033404224 run_lib.py:146] step: 162800, training_loss: 6.28120e-04
I0512 20:52:04.928586 22485033404224 run_lib.py:167] step: 162800, eval_loss: 7.44296e-04
I0512 20:52:28.506302 22485033404224 run_lib.py:146] step: 162850, training_loss: 6.49480e-04
I0512 20:52:52.060873 22485033404224 run_lib.py:146] step: 162900, training_loss: 5.47464e-04
I0512 20:52:52.220588 22485033404224 run_lib.py:167] step: 162900, eval_loss: 7.12761e-04
I0512 20:53:16.356800 22485033404224 run_lib.py:146] step: 162950, training_loss: 7.32304e-04
I0512 20:53:39.899843 22485033404224 run_lib.py:146] step: 163000, training_loss: 8.22012e-04
I0512 20:53:40.059184 22485033404224 run_lib.py:167] step: 163000, eval_loss: 6.22654e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 20:54:03.690239 22485033404224 run_lib.py:146] step: 163050, training_loss: 6.97375e-04
I0512 20:54:27.954427 22485033404224 run_lib.py:146] step: 163100, training_loss: 6.77214e-04
I0512 20:54:28.115144 22485033404224 run_lib.py:167] step: 163100, eval_loss: 8.08531e-04
I0512 20:54:51.681416 22485033404224 run_lib.py:146] step: 163150, training_loss: 6.82317e-04
I0512 20:55:15.249413 22485033404224 run_lib.py:146] step: 163200, training_loss: 5.00184e-04
I0512 20:55:15.408249 22485033404224 run_lib.py:167] step: 163200, eval_loss: 6.57712e-04
I0512 20:55:39.273220 22485033404224 run_lib.py:146] step: 163250, training_loss: 6.28723e-04
I0512 20:56:03.112278 22485033404224 run_lib.py:146] step: 163300, training_loss: 5.25823e-04
I0512 20:56:03.271339 22485033404224 run_lib.py:167] step: 163300, eval_loss: 7.54520e-04
I0512 20:56:26.795269 22485033404224 run_lib.py:146] step: 163350, training_loss: 7.31248e-04
I0512 20:56:50.326695 22485033404224 run_lib.py:146] step: 163400, training_loss: 5.41729e-04
I0512 20:56:50.486451 22485033404224 run_lib.py:167] step: 163400, eval_loss: 3.94428e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 20:57:14.687755 22485033404224 run_lib.py:146] step: 163450, training_loss: 4.91514e-04
I0512 20:57:38.303724 22485033404224 run_lib.py:146] step: 163500, training_loss: 4.49466e-04
I0512 20:57:38.466899 22485033404224 run_lib.py:167] step: 163500, eval_loss: 7.53641e-04
I0512 20:58:02.066074 22485033404224 run_lib.py:146] step: 163550, training_loss: 6.51674e-04
I0512 20:58:26.352291 22485033404224 run_lib.py:146] step: 163600, training_loss: 7.20378e-04
I0512 20:58:26.513274 22485033404224 run_lib.py:167] step: 163600, eval_loss: 5.92143e-04
I0512 20:58:50.136593 22485033404224 run_lib.py:146] step: 163650, training_loss: 5.28764e-04
I0512 20:59:13.759726 22485033404224 run_lib.py:146] step: 163700, training_loss: 5.44875e-04
I0512 20:59:13.919970 22485033404224 run_lib.py:167] step: 163700, eval_loss: 6.78219e-04
I0512 20:59:38.142828 22485033404224 run_lib.py:146] step: 163750, training_loss: 5.69629e-04
I0512 21:00:01.724324 22485033404224 run_lib.py:146] step: 163800, training_loss: 6.60704e-04
I0512 21:00:01.885222 22485033404224 run_lib.py:167] step: 163800, eval_loss: 8.45355e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 21:00:25.587129 22485033404224 run_lib.py:146] step: 163850, training_loss: 5.85411e-04
I0512 21:00:50.142097 22485033404224 run_lib.py:146] step: 163900, training_loss: 8.28442e-04
I0512 21:00:50.303471 22485033404224 run_lib.py:167] step: 163900, eval_loss: 6.61151e-04
I0512 21:01:13.965851 22485033404224 run_lib.py:146] step: 163950, training_loss: 5.84912e-04
I0512 21:01:37.654144 22485033404224 run_lib.py:146] step: 164000, training_loss: 5.75380e-04
I0512 21:01:37.818169 22485033404224 run_lib.py:167] step: 164000, eval_loss: 5.47615e-04
I0512 21:02:01.887298 22485033404224 run_lib.py:146] step: 164050, training_loss: 6.18243e-04
I0512 21:02:25.878874 22485033404224 run_lib.py:146] step: 164100, training_loss: 5.22893e-04
I0512 21:02:26.040063 22485033404224 run_lib.py:167] step: 164100, eval_loss: 7.73313e-04
I0512 21:02:49.667961 22485033404224 run_lib.py:146] step: 164150, training_loss: 6.44906e-04
I0512 21:03:13.285935 22485033404224 run_lib.py:146] step: 164200, training_loss: 6.62112e-04
I0512 21:03:13.446766 22485033404224 run_lib.py:167] step: 164200, eval_loss: 6.59115e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 21:03:37.722946 22485033404224 run_lib.py:146] step: 164250, training_loss: 5.99770e-04
I0512 21:04:01.358789 22485033404224 run_lib.py:146] step: 164300, training_loss: 6.59828e-04
I0512 21:04:01.520084 22485033404224 run_lib.py:167] step: 164300, eval_loss: 7.89273e-04
I0512 21:04:25.121218 22485033404224 run_lib.py:146] step: 164350, training_loss: 7.51049e-04
I0512 21:04:49.324938 22485033404224 run_lib.py:146] step: 164400, training_loss: 7.17329e-04
I0512 21:04:49.484050 22485033404224 run_lib.py:167] step: 164400, eval_loss: 5.83878e-04
I0512 21:05:13.039106 22485033404224 run_lib.py:146] step: 164450, training_loss: 5.96779e-04
I0512 21:05:36.576444 22485033404224 run_lib.py:146] step: 164500, training_loss: 4.68069e-04
I0512 21:05:36.737499 22485033404224 run_lib.py:167] step: 164500, eval_loss: 6.53677e-04
I0512 21:06:00.842480 22485033404224 run_lib.py:146] step: 164550, training_loss: 7.15539e-04
I0512 21:06:24.387217 22485033404224 run_lib.py:146] step: 164600, training_loss: 7.02816e-04
I0512 21:06:24.547213 22485033404224 run_lib.py:167] step: 164600, eval_loss: 4.20798e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 21:06:48.144767 22485033404224 run_lib.py:146] step: 164650, training_loss: 6.44558e-04
I0512 21:07:12.350680 22485033404224 run_lib.py:146] step: 164700, training_loss: 7.59853e-04
I0512 21:07:12.511249 22485033404224 run_lib.py:167] step: 164700, eval_loss: 6.23818e-04
I0512 21:07:36.043148 22485033404224 run_lib.py:146] step: 164750, training_loss: 7.17371e-04
I0512 21:07:59.579557 22485033404224 run_lib.py:146] step: 164800, training_loss: 6.49774e-04
I0512 21:07:59.739763 22485033404224 run_lib.py:167] step: 164800, eval_loss: 6.34209e-04
I0512 21:08:23.843981 22485033404224 run_lib.py:146] step: 164850, training_loss: 7.79194e-04
I0512 21:08:47.388925 22485033404224 run_lib.py:146] step: 164900, training_loss: 6.76487e-04
I0512 21:08:47.547941 22485033404224 run_lib.py:167] step: 164900, eval_loss: 7.77185e-04
I0512 21:09:11.075624 22485033404224 run_lib.py:146] step: 164950, training_loss: 6.84209e-04
I0512 21:09:34.594385 22485033404224 run_lib.py:146] step: 165000, training_loss: 6.33816e-04
I0512 21:09:34.753910 22485033404224 run_lib.py:167] step: 165000, eval_loss: 5.57929e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 21:09:59.029982 22485033404224 run_lib.py:146] step: 165050, training_loss: 5.31292e-04
I0512 21:10:22.575222 22485033404224 run_lib.py:146] step: 165100, training_loss: 6.24307e-04
I0512 21:10:22.735421 22485033404224 run_lib.py:167] step: 165100, eval_loss: 7.77086e-04
I0512 21:10:46.283131 22485033404224 run_lib.py:146] step: 165150, training_loss: 6.12781e-04
I0512 21:11:10.456707 22485033404224 run_lib.py:146] step: 165200, training_loss: 5.38217e-04
I0512 21:11:10.615574 22485033404224 run_lib.py:167] step: 165200, eval_loss: 6.34126e-04
I0512 21:11:34.141591 22485033404224 run_lib.py:146] step: 165250, training_loss: 5.71339e-04
I0512 21:11:57.695774 22485033404224 run_lib.py:146] step: 165300, training_loss: 6.28267e-04
I0512 21:11:57.855870 22485033404224 run_lib.py:167] step: 165300, eval_loss: 5.73959e-04
I0512 21:12:21.972480 22485033404224 run_lib.py:146] step: 165350, training_loss: 5.36181e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 21:12:45.596961 22485033404224 run_lib.py:146] step: 165400, training_loss: 6.17003e-04
I0512 21:12:45.759993 22485033404224 run_lib.py:167] step: 165400, eval_loss: 7.96407e-04
I0512 21:13:09.253973 22485033404224 run_lib.py:146] step: 165450, training_loss: 5.99715e-04
I0512 21:13:33.478186 22485033404224 run_lib.py:146] step: 165500, training_loss: 5.46227e-04
I0512 21:13:33.638007 22485033404224 run_lib.py:167] step: 165500, eval_loss: 5.62862e-04
I0512 21:13:57.172003 22485033404224 run_lib.py:146] step: 165550, training_loss: 7.88155e-04
I0512 21:14:20.740179 22485033404224 run_lib.py:146] step: 165600, training_loss: 7.17239e-04
I0512 21:14:20.900361 22485033404224 run_lib.py:167] step: 165600, eval_loss: 7.09051e-04
I0512 21:14:45.027209 22485033404224 run_lib.py:146] step: 165650, training_loss: 6.36521e-04
I0512 21:15:08.588229 22485033404224 run_lib.py:146] step: 165700, training_loss: 6.38673e-04
I0512 21:15:08.747889 22485033404224 run_lib.py:167] step: 165700, eval_loss: 6.05991e-04
I0512 21:15:32.338002 22485033404224 run_lib.py:146] step: 165750, training_loss: 7.75914e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 21:15:56.405499 22485033404224 run_lib.py:146] step: 165800, training_loss: 6.95765e-04
I0512 21:15:56.492667 22485033404224 run_lib.py:167] step: 165800, eval_loss: 2.05342e-04
I0512 21:16:20.436632 22485033404224 run_lib.py:146] step: 165850, training_loss: 5.86288e-04
I0512 21:16:44.047533 22485033404224 run_lib.py:146] step: 165900, training_loss: 3.99388e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 21:16:44.395289 22485033404224 run_lib.py:167] step: 165900, eval_loss: 6.69306e-04
I0512 21:17:08.012058 22485033404224 run_lib.py:146] step: 165950, training_loss: 6.63021e-04
I0512 21:17:32.284426 22485033404224 run_lib.py:146] step: 166000, training_loss: 5.57484e-04
I0512 21:17:32.444476 22485033404224 run_lib.py:167] step: 166000, eval_loss: 5.75353e-04
I0512 21:17:56.035304 22485033404224 run_lib.py:146] step: 166050, training_loss: 6.30431e-04
I0512 21:18:19.639777 22485033404224 run_lib.py:146] step: 166100, training_loss: 4.47046e-04
I0512 21:18:19.799710 22485033404224 run_lib.py:167] step: 166100, eval_loss: 8.26630e-04
I0512 21:18:43.983480 22485033404224 run_lib.py:146] step: 166150, training_loss: 6.08098e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 21:19:07.766419 22485033404224 run_lib.py:146] step: 166200, training_loss: 6.35874e-04
I0512 21:19:07.931450 22485033404224 run_lib.py:167] step: 166200, eval_loss: 5.95461e-04
I0512 21:19:31.698025 22485033404224 run_lib.py:146] step: 166250, training_loss: 8.13932e-04
I0512 21:19:56.154854 22485033404224 run_lib.py:146] step: 166300, training_loss: 6.16355e-04
I0512 21:19:56.315365 22485033404224 run_lib.py:167] step: 166300, eval_loss: 5.25955e-04
I0512 21:20:20.024015 22485033404224 run_lib.py:146] step: 166350, training_loss: 8.20978e-04
I0512 21:20:43.712412 22485033404224 run_lib.py:146] step: 166400, training_loss: 4.36026e-04
I0512 21:20:43.872733 22485033404224 run_lib.py:167] step: 166400, eval_loss: 7.66016e-04
I0512 21:21:08.171153 22485033404224 run_lib.py:146] step: 166450, training_loss: 5.68155e-04
I0512 21:21:31.793303 22485033404224 run_lib.py:146] step: 166500, training_loss: 5.41503e-04
I0512 21:21:31.953331 22485033404224 run_lib.py:167] step: 166500, eval_loss: 6.05259e-04
I0512 21:21:55.555287 22485033404224 run_lib.py:146] step: 166550, training_loss: 6.46865e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 21:22:19.606462 22485033404224 run_lib.py:146] step: 166600, training_loss: 5.47614e-04
I0512 21:22:19.769629 22485033404224 run_lib.py:167] step: 166600, eval_loss: 5.97036e-04
I0512 21:22:43.723663 22485033404224 run_lib.py:146] step: 166650, training_loss: 6.23924e-04
I0512 21:23:07.272136 22485033404224 run_lib.py:146] step: 166700, training_loss: 5.03521e-04
I0512 21:23:07.432708 22485033404224 run_lib.py:167] step: 166700, eval_loss: 7.35040e-04
I0512 21:23:30.962640 22485033404224 run_lib.py:146] step: 166750, training_loss: 6.40495e-04
I0512 21:23:55.077972 22485033404224 run_lib.py:146] step: 166800, training_loss: 5.60655e-04
I0512 21:23:55.238532 22485033404224 run_lib.py:167] step: 166800, eval_loss: 7.13928e-04
I0512 21:24:18.781593 22485033404224 run_lib.py:146] step: 166850, training_loss: 5.75665e-04
I0512 21:24:42.348914 22485033404224 run_lib.py:146] step: 166900, training_loss: 7.14418e-04
I0512 21:24:42.510027 22485033404224 run_lib.py:167] step: 166900, eval_loss: 6.34109e-04
I0512 21:25:06.662190 22485033404224 run_lib.py:146] step: 166950, training_loss: 4.62154e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 21:25:30.266128 22485033404224 run_lib.py:146] step: 167000, training_loss: 8.69985e-04
I0512 21:25:30.429044 22485033404224 run_lib.py:167] step: 167000, eval_loss: 7.48133e-04
I0512 21:25:53.927708 22485033404224 run_lib.py:146] step: 167050, training_loss: 6.50853e-04
I0512 21:26:18.117193 22485033404224 run_lib.py:146] step: 167100, training_loss: 6.57706e-04
I0512 21:26:18.277002 22485033404224 run_lib.py:167] step: 167100, eval_loss: 5.41302e-04
I0512 21:26:41.783510 22485033404224 run_lib.py:146] step: 167150, training_loss: 6.14460e-04
I0512 21:27:05.301642 22485033404224 run_lib.py:146] step: 167200, training_loss: 8.36053e-04
I0512 21:27:05.460472 22485033404224 run_lib.py:167] step: 167200, eval_loss: 7.64975e-04
I0512 21:27:29.591590 22485033404224 run_lib.py:146] step: 167250, training_loss: 7.09318e-04
I0512 21:27:53.120247 22485033404224 run_lib.py:146] step: 167300, training_loss: 6.01070e-04
I0512 21:27:53.279965 22485033404224 run_lib.py:167] step: 167300, eval_loss: 6.69343e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 21:28:16.904362 22485033404224 run_lib.py:146] step: 167350, training_loss: 6.36343e-04
I0512 21:28:41.110277 22485033404224 run_lib.py:146] step: 167400, training_loss: 6.08986e-04
I0512 21:28:41.270863 22485033404224 run_lib.py:167] step: 167400, eval_loss: 6.72708e-04
I0512 21:29:04.779368 22485033404224 run_lib.py:146] step: 167450, training_loss: 5.50687e-04
I0512 21:29:28.294386 22485033404224 run_lib.py:146] step: 167500, training_loss: 6.24505e-04
I0512 21:29:28.454356 22485033404224 run_lib.py:167] step: 167500, eval_loss: 4.47397e-04
I0512 21:29:51.948340 22485033404224 run_lib.py:146] step: 167550, training_loss: 6.60478e-04
I0512 21:30:16.126644 22485033404224 run_lib.py:146] step: 167600, training_loss: 4.71651e-04
I0512 21:30:16.286303 22485033404224 run_lib.py:167] step: 167600, eval_loss: 4.36351e-04
I0512 21:30:39.795795 22485033404224 run_lib.py:146] step: 167650, training_loss: 5.25476e-04
I0512 21:31:03.330082 22485033404224 run_lib.py:146] step: 167700, training_loss: 6.45192e-04
I0512 21:31:03.490436 22485033404224 run_lib.py:167] step: 167700, eval_loss: 4.66035e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 21:31:27.725150 22485033404224 run_lib.py:146] step: 167750, training_loss: 6.81050e-04
I0512 21:31:51.230900 22485033404224 run_lib.py:146] step: 167800, training_loss: 6.51806e-04
I0512 21:31:51.391602 22485033404224 run_lib.py:167] step: 167800, eval_loss: 5.93112e-04
I0512 21:32:14.908058 22485033404224 run_lib.py:146] step: 167850, training_loss: 6.14818e-04
I0512 21:32:39.118895 22485033404224 run_lib.py:146] step: 167900, training_loss: 4.99425e-04
I0512 21:32:39.278654 22485033404224 run_lib.py:167] step: 167900, eval_loss: 6.86706e-04
I0512 21:33:02.854625 22485033404224 run_lib.py:146] step: 167950, training_loss: 6.37016e-04
I0512 21:33:26.458848 22485033404224 run_lib.py:146] step: 168000, training_loss: 4.00105e-04
I0512 21:33:26.619384 22485033404224 run_lib.py:167] step: 168000, eval_loss: 6.17365e-04
I0512 21:33:50.845920 22485033404224 run_lib.py:146] step: 168050, training_loss: 5.45913e-04
I0512 21:34:14.477975 22485033404224 run_lib.py:146] step: 168100, training_loss: 6.14255e-04
I0512 21:34:14.639598 22485033404224 run_lib.py:167] step: 168100, eval_loss: 7.11187e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 21:34:38.348074 22485033404224 run_lib.py:146] step: 168150, training_loss: 5.26197e-04
I0512 21:35:02.798730 22485033404224 run_lib.py:146] step: 168200, training_loss: 7.89077e-04
I0512 21:35:02.959851 22485033404224 run_lib.py:167] step: 168200, eval_loss: 6.00067e-04
I0512 21:35:26.631618 22485033404224 run_lib.py:146] step: 168250, training_loss: 4.78321e-04
I0512 21:35:50.249335 22485033404224 run_lib.py:146] step: 168300, training_loss: 6.52632e-04
I0512 21:35:50.409495 22485033404224 run_lib.py:167] step: 168300, eval_loss: 6.85759e-04
I0512 21:36:14.014137 22485033404224 run_lib.py:146] step: 168350, training_loss: 5.80478e-04
I0512 21:36:38.307333 22485033404224 run_lib.py:146] step: 168400, training_loss: 8.06250e-04
I0512 21:36:38.467384 22485033404224 run_lib.py:167] step: 168400, eval_loss: 5.57003e-04
I0512 21:37:02.065211 22485033404224 run_lib.py:146] step: 168450, training_loss: 7.19836e-04
I0512 21:37:25.680118 22485033404224 run_lib.py:146] step: 168500, training_loss: 8.07109e-04
I0512 21:37:25.840818 22485033404224 run_lib.py:167] step: 168500, eval_loss: 7.57643e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 21:37:50.271036 22485033404224 run_lib.py:146] step: 168550, training_loss: 6.74566e-04
I0512 21:38:13.913022 22485033404224 run_lib.py:146] step: 168600, training_loss: 6.57361e-04
I0512 21:38:14.074660 22485033404224 run_lib.py:167] step: 168600, eval_loss: 6.33609e-04
I0512 21:38:37.715812 22485033404224 run_lib.py:146] step: 168650, training_loss: 8.34439e-04
I0512 21:39:01.991011 22485033404224 run_lib.py:146] step: 168700, training_loss: 5.97839e-04
I0512 21:39:02.152477 22485033404224 run_lib.py:167] step: 168700, eval_loss: 6.27379e-04
I0512 21:39:25.782252 22485033404224 run_lib.py:146] step: 168750, training_loss: 4.71528e-04
I0512 21:39:49.378299 22485033404224 run_lib.py:146] step: 168800, training_loss: 7.20039e-04
I0512 21:39:49.538113 22485033404224 run_lib.py:167] step: 168800, eval_loss: 4.90705e-04
I0512 21:40:13.757877 22485033404224 run_lib.py:146] step: 168850, training_loss: 5.53773e-04
I0512 21:40:37.387698 22485033404224 run_lib.py:146] step: 168900, training_loss: 5.95275e-04
I0512 21:40:37.547551 22485033404224 run_lib.py:167] step: 168900, eval_loss: 5.49771e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 21:41:01.216625 22485033404224 run_lib.py:146] step: 168950, training_loss: 6.51192e-04
I0512 21:41:25.478315 22485033404224 run_lib.py:146] step: 169000, training_loss: 4.29558e-04
I0512 21:41:25.639473 22485033404224 run_lib.py:167] step: 169000, eval_loss: 6.35803e-04
I0512 21:41:49.177457 22485033404224 run_lib.py:146] step: 169050, training_loss: 5.03690e-04
I0512 21:42:12.720381 22485033404224 run_lib.py:146] step: 169100, training_loss: 5.93320e-04
I0512 21:42:12.880377 22485033404224 run_lib.py:167] step: 169100, eval_loss: 6.04971e-04
I0512 21:42:36.419174 22485033404224 run_lib.py:146] step: 169150, training_loss: 5.61502e-04
I0512 21:43:00.551786 22485033404224 run_lib.py:146] step: 169200, training_loss: 5.60603e-04
I0512 21:43:00.711725 22485033404224 run_lib.py:167] step: 169200, eval_loss: 6.25080e-04
I0512 21:43:24.277369 22485033404224 run_lib.py:146] step: 169250, training_loss: 4.45111e-04
I0512 21:43:47.835429 22485033404224 run_lib.py:146] step: 169300, training_loss: 6.93784e-04
I0512 21:43:47.995783 22485033404224 run_lib.py:167] step: 169300, eval_loss: 4.87934e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 21:44:11.938552 22485033404224 run_lib.py:146] step: 169350, training_loss: 5.31668e-04
I0512 21:44:35.492969 22485033404224 run_lib.py:146] step: 169400, training_loss: 7.39396e-04
I0512 21:44:35.655458 22485033404224 run_lib.py:167] step: 169400, eval_loss: 5.98586e-04
I0512 21:44:59.203818 22485033404224 run_lib.py:146] step: 169450, training_loss: 6.51943e-04
I0512 21:45:23.355392 22485033404224 run_lib.py:146] step: 169500, training_loss: 5.57859e-04
I0512 21:45:23.516363 22485033404224 run_lib.py:167] step: 169500, eval_loss: 6.36620e-04
I0512 21:45:47.072613 22485033404224 run_lib.py:146] step: 169550, training_loss: 6.04445e-04
I0512 21:46:10.604340 22485033404224 run_lib.py:146] step: 169600, training_loss: 5.64284e-04
I0512 21:46:10.763244 22485033404224 run_lib.py:167] step: 169600, eval_loss: 5.72701e-04
I0512 21:46:34.893081 22485033404224 run_lib.py:146] step: 169650, training_loss: 6.06770e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 21:46:58.515567 22485033404224 run_lib.py:146] step: 169700, training_loss: 5.56828e-04
I0512 21:46:58.676810 22485033404224 run_lib.py:167] step: 169700, eval_loss: 4.91579e-04
I0512 21:47:22.272087 22485033404224 run_lib.py:146] step: 169750, training_loss: 4.02856e-04
I0512 21:47:46.503248 22485033404224 run_lib.py:146] step: 169800, training_loss: 4.39665e-04
I0512 21:47:46.663287 22485033404224 run_lib.py:167] step: 169800, eval_loss: 7.18673e-04
I0512 21:48:10.200273 22485033404224 run_lib.py:146] step: 169850, training_loss: 6.54871e-04
I0512 21:48:33.759825 22485033404224 run_lib.py:146] step: 169900, training_loss: 6.63551e-04
I0512 21:48:33.918999 22485033404224 run_lib.py:167] step: 169900, eval_loss: 4.46745e-04
I0512 21:48:58.041839 22485033404224 run_lib.py:146] step: 169950, training_loss: 7.59124e-04
I0512 21:49:21.581785 22485033404224 run_lib.py:146] step: 170000, training_loss: 7.28101e-04
I0512 21:49:23.295813 22485033404224 run_lib.py:167] step: 170000, eval_loss: 6.74276e-04
I0512 21:49:48.375213 22485033404224 run_lib.py:146] step: 170050, training_loss: 6.40594e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 21:50:12.273582 22485033404224 run_lib.py:146] step: 170100, training_loss: 6.81974e-04
I0512 21:50:12.435813 22485033404224 run_lib.py:167] step: 170100, eval_loss: 6.93990e-04
I0512 21:50:36.323989 22485033404224 run_lib.py:146] step: 170150, training_loss: 7.89796e-04
I0512 21:50:59.854943 22485033404224 run_lib.py:146] step: 170200, training_loss: 7.35159e-04
I0512 21:51:00.014779 22485033404224 run_lib.py:167] step: 170200, eval_loss: 4.58329e-04
I0512 21:51:23.894133 22485033404224 run_lib.py:146] step: 170250, training_loss: 7.79176e-04
I0512 21:51:47.794094 22485033404224 run_lib.py:146] step: 170300, training_loss: 5.44683e-04
I0512 21:51:47.954821 22485033404224 run_lib.py:167] step: 170300, eval_loss: 6.71136e-04
I0512 21:52:11.586417 22485033404224 run_lib.py:146] step: 170350, training_loss: 8.06177e-04
I0512 21:52:35.546579 22485033404224 run_lib.py:146] step: 170400, training_loss: 7.49955e-04
I0512 21:52:35.707106 22485033404224 run_lib.py:167] step: 170400, eval_loss: 6.55921e-04
I0512 21:52:59.647951 22485033404224 run_lib.py:146] step: 170450, training_loss: 5.08665e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 21:53:23.331687 22485033404224 run_lib.py:146] step: 170500, training_loss: 6.09942e-04
I0512 21:53:23.494025 22485033404224 run_lib.py:167] step: 170500, eval_loss: 6.85416e-04
I0512 21:53:47.458552 22485033404224 run_lib.py:146] step: 170550, training_loss: 4.25694e-04
I0512 21:54:11.436101 22485033404224 run_lib.py:146] step: 170600, training_loss: 5.59576e-04
I0512 21:54:11.596018 22485033404224 run_lib.py:167] step: 170600, eval_loss: 5.93605e-04
I0512 21:54:35.212987 22485033404224 run_lib.py:146] step: 170650, training_loss: 5.42467e-04
I0512 21:54:59.108037 22485033404224 run_lib.py:146] step: 170700, training_loss: 6.37165e-04
I0512 21:54:59.269128 22485033404224 run_lib.py:167] step: 170700, eval_loss: 4.78112e-04
I0512 21:55:23.172936 22485033404224 run_lib.py:146] step: 170750, training_loss: 6.47646e-04
I0512 21:55:46.824544 22485033404224 run_lib.py:146] step: 170800, training_loss: 5.39414e-04
I0512 21:55:46.985687 22485033404224 run_lib.py:167] step: 170800, eval_loss: 6.11470e-04
I0512 21:56:10.578989 22485033404224 run_lib.py:146] step: 170850, training_loss: 5.59490e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 21:56:34.596213 22485033404224 run_lib.py:146] step: 170900, training_loss: 5.86961e-04
I0512 21:56:34.758244 22485033404224 run_lib.py:167] step: 170900, eval_loss: 6.27971e-04
I0512 21:56:58.762081 22485033404224 run_lib.py:146] step: 170950, training_loss: 6.24265e-04
I0512 21:57:22.414924 22485033404224 run_lib.py:146] step: 171000, training_loss: 4.94889e-04
I0512 21:57:22.575631 22485033404224 run_lib.py:167] step: 171000, eval_loss: 7.94822e-04
I0512 21:57:46.507679 22485033404224 run_lib.py:146] step: 171050, training_loss: 6.49287e-04
I0512 21:58:10.464368 22485033404224 run_lib.py:146] step: 171100, training_loss: 5.91389e-04
I0512 21:58:10.624207 22485033404224 run_lib.py:167] step: 171100, eval_loss: 7.68955e-04
I0512 21:58:34.213158 22485033404224 run_lib.py:146] step: 171150, training_loss: 6.10998e-04
I0512 21:58:58.080932 22485033404224 run_lib.py:146] step: 171200, training_loss: 6.01950e-04
I0512 21:58:58.240461 22485033404224 run_lib.py:167] step: 171200, eval_loss: 5.20088e-04
I0512 21:59:22.105601 22485033404224 run_lib.py:146] step: 171250, training_loss: 5.60353e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 21:59:45.732310 22485033404224 run_lib.py:146] step: 171300, training_loss: 7.09058e-04
I0512 21:59:45.893888 22485033404224 run_lib.py:167] step: 171300, eval_loss: 6.68670e-04
I0512 22:00:09.715262 22485033404224 run_lib.py:146] step: 171350, training_loss: 5.89472e-04
I0512 22:00:33.598504 22485033404224 run_lib.py:146] step: 171400, training_loss: 6.96618e-04
I0512 22:00:33.758072 22485033404224 run_lib.py:167] step: 171400, eval_loss: 6.04378e-04
I0512 22:00:57.285467 22485033404224 run_lib.py:146] step: 171450, training_loss: 5.02345e-04
I0512 22:01:21.131570 22485033404224 run_lib.py:146] step: 171500, training_loss: 6.44246e-04
I0512 22:01:21.290928 22485033404224 run_lib.py:167] step: 171500, eval_loss: 6.35377e-04
I0512 22:01:45.137881 22485033404224 run_lib.py:146] step: 171550, training_loss: 5.92281e-04
I0512 22:02:08.668366 22485033404224 run_lib.py:146] step: 171600, training_loss: 7.57174e-04
I0512 22:02:08.828143 22485033404224 run_lib.py:167] step: 171600, eval_loss: 6.34946e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 22:02:32.437984 22485033404224 run_lib.py:146] step: 171650, training_loss: 5.90870e-04
I0512 22:02:56.653284 22485033404224 run_lib.py:146] step: 171700, training_loss: 7.59462e-04
I0512 22:02:56.814912 22485033404224 run_lib.py:167] step: 171700, eval_loss: 7.67101e-04
I0512 22:03:20.324281 22485033404224 run_lib.py:146] step: 171750, training_loss: 5.73101e-04
I0512 22:03:43.854788 22485033404224 run_lib.py:146] step: 171800, training_loss: 6.42280e-04
I0512 22:03:44.014878 22485033404224 run_lib.py:167] step: 171800, eval_loss: 6.62972e-04
I0512 22:04:07.857797 22485033404224 run_lib.py:146] step: 171850, training_loss: 6.34770e-04
I0512 22:04:31.688593 22485033404224 run_lib.py:146] step: 171900, training_loss: 1.05747e-03
I0512 22:04:31.849509 22485033404224 run_lib.py:167] step: 171900, eval_loss: 6.22849e-04
I0512 22:04:55.378860 22485033404224 run_lib.py:146] step: 171950, training_loss: 6.28265e-04
I0512 22:05:19.232730 22485033404224 run_lib.py:146] step: 172000, training_loss: 7.05975e-04
I0512 22:05:19.391194 22485033404224 run_lib.py:167] step: 172000, eval_loss: 5.18588e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 22:05:43.313449 22485033404224 run_lib.py:146] step: 172050, training_loss: 3.61396e-04
I0512 22:06:06.853368 22485033404224 run_lib.py:146] step: 172100, training_loss: 5.78233e-04
I0512 22:06:07.015975 22485033404224 run_lib.py:167] step: 172100, eval_loss: 6.25181e-04
I0512 22:06:30.894850 22485033404224 run_lib.py:146] step: 172150, training_loss: 6.53905e-04
I0512 22:06:54.796718 22485033404224 run_lib.py:146] step: 172200, training_loss: 7.42041e-04
I0512 22:06:54.957269 22485033404224 run_lib.py:167] step: 172200, eval_loss: 8.31079e-04
I0512 22:07:18.495357 22485033404224 run_lib.py:146] step: 172250, training_loss: 6.81227e-04
I0512 22:07:42.328799 22485033404224 run_lib.py:146] step: 172300, training_loss: 6.58121e-04
I0512 22:07:42.488171 22485033404224 run_lib.py:167] step: 172300, eval_loss: 3.99692e-04
I0512 22:08:06.334162 22485033404224 run_lib.py:146] step: 172350, training_loss: 4.90321e-04
I0512 22:08:29.908010 22485033404224 run_lib.py:146] step: 172400, training_loss: 6.71819e-04
I0512 22:08:30.069012 22485033404224 run_lib.py:167] step: 172400, eval_loss: 6.73722e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 22:08:53.668861 22485033404224 run_lib.py:146] step: 172450, training_loss: 6.30375e-04
I0512 22:09:17.953434 22485033404224 run_lib.py:146] step: 172500, training_loss: 5.32702e-04
I0512 22:09:18.114082 22485033404224 run_lib.py:167] step: 172500, eval_loss: 5.79100e-04
I0512 22:09:41.744076 22485033404224 run_lib.py:146] step: 172550, training_loss: 6.14855e-04
I0512 22:10:05.365059 22485033404224 run_lib.py:146] step: 172600, training_loss: 5.75692e-04
I0512 22:10:05.525506 22485033404224 run_lib.py:167] step: 172600, eval_loss: 5.75124e-04
I0512 22:10:29.460672 22485033404224 run_lib.py:146] step: 172650, training_loss: 7.28777e-04
I0512 22:10:53.386392 22485033404224 run_lib.py:146] step: 172700, training_loss: 7.60824e-04
I0512 22:10:53.546550 22485033404224 run_lib.py:167] step: 172700, eval_loss: 6.90673e-04
I0512 22:11:17.161344 22485033404224 run_lib.py:146] step: 172750, training_loss: 8.44475e-04
I0512 22:11:41.055630 22485033404224 run_lib.py:146] step: 172800, training_loss: 5.22230e-04
I0512 22:11:41.215709 22485033404224 run_lib.py:167] step: 172800, eval_loss: 5.77248e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 22:12:05.244608 22485033404224 run_lib.py:146] step: 172850, training_loss: 5.66232e-04
I0512 22:12:28.894357 22485033404224 run_lib.py:146] step: 172900, training_loss: 5.44926e-04
I0512 22:12:29.056288 22485033404224 run_lib.py:167] step: 172900, eval_loss: 3.07194e-04
I0512 22:12:53.135293 22485033404224 run_lib.py:146] step: 172950, training_loss: 5.58931e-04
I0512 22:13:17.162368 22485033404224 run_lib.py:146] step: 173000, training_loss: 3.38962e-04
I0512 22:13:17.323265 22485033404224 run_lib.py:167] step: 173000, eval_loss: 5.39282e-04
I0512 22:13:41.005953 22485033404224 run_lib.py:146] step: 173050, training_loss: 4.87685e-04
I0512 22:14:05.035783 22485033404224 run_lib.py:146] step: 173100, training_loss: 8.23223e-04
I0512 22:14:05.195528 22485033404224 run_lib.py:167] step: 173100, eval_loss: 4.90196e-04
I0512 22:14:29.114474 22485033404224 run_lib.py:146] step: 173150, training_loss: 7.22476e-04
I0512 22:14:52.753001 22485033404224 run_lib.py:146] step: 173200, training_loss: 5.26234e-04
I0512 22:14:52.913843 22485033404224 run_lib.py:167] step: 173200, eval_loss: 6.26489e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 22:15:16.585438 22485033404224 run_lib.py:146] step: 173250, training_loss: 6.18053e-04
I0512 22:15:40.897723 22485033404224 run_lib.py:146] step: 173300, training_loss: 7.03319e-04
I0512 22:15:41.059327 22485033404224 run_lib.py:167] step: 173300, eval_loss: 5.70956e-04
I0512 22:16:04.669348 22485033404224 run_lib.py:146] step: 173350, training_loss: 7.84274e-04
I0512 22:16:28.242774 22485033404224 run_lib.py:146] step: 173400, training_loss: 6.42710e-04
I0512 22:16:28.403035 22485033404224 run_lib.py:167] step: 173400, eval_loss: 6.66659e-04
I0512 22:16:52.252529 22485033404224 run_lib.py:146] step: 173450, training_loss: 6.51747e-04
I0512 22:17:16.123465 22485033404224 run_lib.py:146] step: 173500, training_loss: 6.01819e-04
I0512 22:17:16.284151 22485033404224 run_lib.py:167] step: 173500, eval_loss: 5.85669e-04
I0512 22:17:39.818583 22485033404224 run_lib.py:146] step: 173550, training_loss: 5.80228e-04
I0512 22:18:03.662060 22485033404224 run_lib.py:146] step: 173600, training_loss: 5.57096e-04
I0512 22:18:03.819482 22485033404224 run_lib.py:167] step: 173600, eval_loss: 6.23336e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 22:18:27.769514 22485033404224 run_lib.py:146] step: 173650, training_loss: 5.61219e-04
I0512 22:18:51.306546 22485033404224 run_lib.py:146] step: 173700, training_loss: 5.54326e-04
I0512 22:18:51.392541 22485033404224 run_lib.py:167] step: 173700, eval_loss: 6.54609e-04
I0512 22:19:15.273481 22485033404224 run_lib.py:146] step: 173750, training_loss: 7.57397e-04
I0512 22:19:39.102443 22485033404224 run_lib.py:146] step: 173800, training_loss: 5.97837e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 22:19:39.447963 22485033404224 run_lib.py:167] step: 173800, eval_loss: 7.68368e-04
I0512 22:20:02.993117 22485033404224 run_lib.py:146] step: 173850, training_loss: 7.75229e-04
I0512 22:20:26.878040 22485033404224 run_lib.py:146] step: 173900, training_loss: 5.18645e-04
I0512 22:20:27.037461 22485033404224 run_lib.py:167] step: 173900, eval_loss: 6.32797e-04
I0512 22:20:50.911293 22485033404224 run_lib.py:146] step: 173950, training_loss: 6.36923e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 22:21:14.513449 22485033404224 run_lib.py:146] step: 174000, training_loss: 8.20198e-04
I0512 22:21:14.676252 22485033404224 run_lib.py:167] step: 174000, eval_loss: 5.09888e-04
I0512 22:21:38.540928 22485033404224 run_lib.py:146] step: 174050, training_loss: 4.40070e-04
I0512 22:22:02.382699 22485033404224 run_lib.py:146] step: 174100, training_loss: 5.57856e-04
I0512 22:22:02.542442 22485033404224 run_lib.py:167] step: 174100, eval_loss: 4.94941e-04
I0512 22:22:26.096488 22485033404224 run_lib.py:146] step: 174150, training_loss: 7.11087e-04
I0512 22:22:49.657292 22485033404224 run_lib.py:146] step: 174200, training_loss: 5.77357e-04
I0512 22:22:49.828122 22485033404224 run_lib.py:167] step: 174200, eval_loss: 3.91571e-04
I0512 22:23:13.978837 22485033404224 run_lib.py:146] step: 174250, training_loss: 7.10573e-04
I0512 22:23:37.544905 22485033404224 run_lib.py:146] step: 174300, training_loss: 5.74429e-04
I0512 22:23:37.703560 22485033404224 run_lib.py:167] step: 174300, eval_loss: 5.71886e-04
I0512 22:24:01.219466 22485033404224 run_lib.py:146] step: 174350, training_loss: 6.52901e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 22:24:25.117959 22485033404224 run_lib.py:146] step: 174400, training_loss: 6.49998e-04
I0512 22:24:25.280831 22485033404224 run_lib.py:167] step: 174400, eval_loss: 6.06110e-04
I0512 22:24:49.164088 22485033404224 run_lib.py:146] step: 174450, training_loss: 6.69998e-04
I0512 22:25:12.728486 22485033404224 run_lib.py:146] step: 174500, training_loss: 6.30794e-04
I0512 22:25:12.889586 22485033404224 run_lib.py:167] step: 174500, eval_loss: 6.35122e-04
I0512 22:25:36.731880 22485033404224 run_lib.py:146] step: 174550, training_loss: 6.04928e-04
I0512 22:26:00.596145 22485033404224 run_lib.py:146] step: 174600, training_loss: 4.97561e-04
I0512 22:26:00.756054 22485033404224 run_lib.py:167] step: 174600, eval_loss: 7.22828e-04
I0512 22:26:24.296374 22485033404224 run_lib.py:146] step: 174650, training_loss: 5.23656e-04
I0512 22:26:48.206937 22485033404224 run_lib.py:146] step: 174700, training_loss: 7.61637e-04
I0512 22:26:48.366918 22485033404224 run_lib.py:167] step: 174700, eval_loss: 4.51713e-04
I0512 22:27:12.318400 22485033404224 run_lib.py:146] step: 174750, training_loss: 5.35708e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 22:27:36.029889 22485033404224 run_lib.py:146] step: 174800, training_loss: 6.84805e-04
I0512 22:27:36.192019 22485033404224 run_lib.py:167] step: 174800, eval_loss: 5.55178e-04
I0512 22:28:00.174979 22485033404224 run_lib.py:146] step: 174850, training_loss: 6.19825e-04
I0512 22:28:24.165744 22485033404224 run_lib.py:146] step: 174900, training_loss: 7.61276e-04
I0512 22:28:24.326368 22485033404224 run_lib.py:167] step: 174900, eval_loss: 5.89119e-04
I0512 22:28:47.958459 22485033404224 run_lib.py:146] step: 174950, training_loss: 6.43351e-04
I0512 22:29:11.554667 22485033404224 run_lib.py:146] step: 175000, training_loss: 6.10075e-04
I0512 22:29:11.715250 22485033404224 run_lib.py:167] step: 175000, eval_loss: 6.40533e-04
I0512 22:29:35.931246 22485033404224 run_lib.py:146] step: 175050, training_loss: 5.30961e-04
I0512 22:29:59.503770 22485033404224 run_lib.py:146] step: 175100, training_loss: 5.15800e-04
I0512 22:29:59.662902 22485033404224 run_lib.py:167] step: 175100, eval_loss: 4.39622e-04
I0512 22:30:23.249346 22485033404224 run_lib.py:146] step: 175150, training_loss: 7.62539e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 22:30:47.337452 22485033404224 run_lib.py:146] step: 175200, training_loss: 7.47055e-04
I0512 22:30:47.502929 22485033404224 run_lib.py:167] step: 175200, eval_loss: 8.27796e-04
I0512 22:31:11.614986 22485033404224 run_lib.py:146] step: 175250, training_loss: 6.53298e-04
I0512 22:31:35.331043 22485033404224 run_lib.py:146] step: 175300, training_loss: 5.58169e-04
I0512 22:31:35.492375 22485033404224 run_lib.py:167] step: 175300, eval_loss: 6.48382e-04
I0512 22:31:59.456303 22485033404224 run_lib.py:146] step: 175350, training_loss: 4.61637e-04
I0512 22:32:23.402549 22485033404224 run_lib.py:146] step: 175400, training_loss: 5.31714e-04
I0512 22:32:23.563451 22485033404224 run_lib.py:167] step: 175400, eval_loss: 6.36183e-04
I0512 22:32:47.173969 22485033404224 run_lib.py:146] step: 175450, training_loss: 6.25920e-04
I0512 22:33:11.093351 22485033404224 run_lib.py:146] step: 175500, training_loss: 5.18415e-04
I0512 22:33:11.253628 22485033404224 run_lib.py:167] step: 175500, eval_loss: 5.07211e-04
I0512 22:33:35.180150 22485033404224 run_lib.py:146] step: 175550, training_loss: 6.32059e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 22:33:58.834254 22485033404224 run_lib.py:146] step: 175600, training_loss: 5.58392e-04
I0512 22:33:58.997349 22485033404224 run_lib.py:167] step: 175600, eval_loss: 6.48404e-04
I0512 22:34:22.892198 22485033404224 run_lib.py:146] step: 175650, training_loss: 5.80534e-04
I0512 22:34:46.752201 22485033404224 run_lib.py:146] step: 175700, training_loss: 5.69701e-04
I0512 22:34:46.910887 22485033404224 run_lib.py:167] step: 175700, eval_loss: 5.84189e-04
I0512 22:35:10.477196 22485033404224 run_lib.py:146] step: 175750, training_loss: 5.31785e-04
I0512 22:35:34.337805 22485033404224 run_lib.py:146] step: 175800, training_loss: 6.28513e-04
I0512 22:35:34.498444 22485033404224 run_lib.py:167] step: 175800, eval_loss: 4.14756e-04
I0512 22:35:58.342370 22485033404224 run_lib.py:146] step: 175850, training_loss: 6.69104e-04
I0512 22:36:21.886256 22485033404224 run_lib.py:146] step: 175900, training_loss: 5.64660e-04
I0512 22:36:22.046884 22485033404224 run_lib.py:167] step: 175900, eval_loss: 6.45219e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 22:36:45.644695 22485033404224 run_lib.py:146] step: 175950, training_loss: 6.36060e-04
I0512 22:37:09.538138 22485033404224 run_lib.py:146] step: 176000, training_loss: 4.97615e-04
I0512 22:37:09.699181 22485033404224 run_lib.py:167] step: 176000, eval_loss: 6.95527e-04
I0512 22:37:33.597865 22485033404224 run_lib.py:146] step: 176050, training_loss: 6.23152e-04
I0512 22:37:57.145705 22485033404224 run_lib.py:146] step: 176100, training_loss: 6.83644e-04
I0512 22:37:57.304491 22485033404224 run_lib.py:167] step: 176100, eval_loss: 5.33910e-04
I0512 22:38:21.177803 22485033404224 run_lib.py:146] step: 176150, training_loss: 7.61156e-04
I0512 22:38:44.994167 22485033404224 run_lib.py:146] step: 176200, training_loss: 6.30615e-04
I0512 22:38:45.154575 22485033404224 run_lib.py:167] step: 176200, eval_loss: 7.41892e-04
I0512 22:39:08.683614 22485033404224 run_lib.py:146] step: 176250, training_loss: 6.78329e-04
I0512 22:39:32.529844 22485033404224 run_lib.py:146] step: 176300, training_loss: 8.07956e-04
I0512 22:39:32.691272 22485033404224 run_lib.py:167] step: 176300, eval_loss: 6.24545e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 22:39:56.594343 22485033404224 run_lib.py:146] step: 176350, training_loss: 4.54004e-04
I0512 22:40:20.121235 22485033404224 run_lib.py:146] step: 176400, training_loss: 5.87601e-04
I0512 22:40:20.282390 22485033404224 run_lib.py:167] step: 176400, eval_loss: 8.20729e-04
I0512 22:40:44.165156 22485033404224 run_lib.py:146] step: 176450, training_loss: 5.76877e-04
I0512 22:41:08.032934 22485033404224 run_lib.py:146] step: 176500, training_loss: 4.64629e-04
I0512 22:41:08.192100 22485033404224 run_lib.py:167] step: 176500, eval_loss: 5.44382e-04
I0512 22:41:31.721972 22485033404224 run_lib.py:146] step: 176550, training_loss: 6.24777e-04
I0512 22:41:55.570571 22485033404224 run_lib.py:146] step: 176600, training_loss: 4.08727e-04
I0512 22:41:55.731992 22485033404224 run_lib.py:167] step: 176600, eval_loss: 6.41724e-04
I0512 22:42:19.593143 22485033404224 run_lib.py:146] step: 176650, training_loss: 6.53697e-04
I0512 22:42:43.118032 22485033404224 run_lib.py:146] step: 176700, training_loss: 5.63905e-04
I0512 22:42:43.278435 22485033404224 run_lib.py:167] step: 176700, eval_loss: 6.69113e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 22:43:07.251177 22485033404224 run_lib.py:146] step: 176750, training_loss: 5.58807e-04
I0512 22:43:31.133515 22485033404224 run_lib.py:146] step: 176800, training_loss: 6.65920e-04
I0512 22:43:31.293602 22485033404224 run_lib.py:167] step: 176800, eval_loss: 5.78538e-04
I0512 22:43:54.838296 22485033404224 run_lib.py:146] step: 176850, training_loss: 9.39719e-04
I0512 22:44:18.362973 22485033404224 run_lib.py:146] step: 176900, training_loss: 6.12150e-04
I0512 22:44:18.523976 22485033404224 run_lib.py:167] step: 176900, eval_loss: 5.03876e-04
I0512 22:44:42.457660 22485033404224 run_lib.py:146] step: 176950, training_loss: 6.78445e-04
I0512 22:45:06.397181 22485033404224 run_lib.py:146] step: 177000, training_loss: 4.38627e-04
I0512 22:45:06.558611 22485033404224 run_lib.py:167] step: 177000, eval_loss: 7.73364e-04
I0512 22:45:30.159472 22485033404224 run_lib.py:146] step: 177050, training_loss: 5.30867e-04
I0512 22:45:54.104046 22485033404224 run_lib.py:146] step: 177100, training_loss: 6.98000e-04
I0512 22:45:54.264564 22485033404224 run_lib.py:167] step: 177100, eval_loss: 7.43213e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 22:46:18.253159 22485033404224 run_lib.py:146] step: 177150, training_loss: 5.23826e-04
I0512 22:46:41.853925 22485033404224 run_lib.py:146] step: 177200, training_loss: 6.38288e-04
I0512 22:46:42.016405 22485033404224 run_lib.py:167] step: 177200, eval_loss: 5.83959e-04
I0512 22:47:06.064561 22485033404224 run_lib.py:146] step: 177250, training_loss: 7.19846e-04
I0512 22:47:30.103313 22485033404224 run_lib.py:146] step: 177300, training_loss: 7.09315e-04
I0512 22:47:30.263714 22485033404224 run_lib.py:167] step: 177300, eval_loss: 5.94218e-04
I0512 22:47:53.849535 22485033404224 run_lib.py:146] step: 177350, training_loss: 6.43469e-04
I0512 22:48:17.836075 22485033404224 run_lib.py:146] step: 177400, training_loss: 6.90622e-04
I0512 22:48:17.996923 22485033404224 run_lib.py:167] step: 177400, eval_loss: 5.18849e-04
I0512 22:48:42.059908 22485033404224 run_lib.py:146] step: 177450, training_loss: 7.84412e-04
I0512 22:49:05.688759 22485033404224 run_lib.py:146] step: 177500, training_loss: 5.33629e-04
I0512 22:49:05.850772 22485033404224 run_lib.py:167] step: 177500, eval_loss: 6.03763e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 22:49:29.988423 22485033404224 run_lib.py:146] step: 177550, training_loss: 6.24522e-04
I0512 22:49:53.972292 22485033404224 run_lib.py:146] step: 177600, training_loss: 5.75632e-04
I0512 22:49:54.133698 22485033404224 run_lib.py:167] step: 177600, eval_loss: 5.19801e-04
I0512 22:50:17.739712 22485033404224 run_lib.py:146] step: 177650, training_loss: 5.87266e-04
I0512 22:50:41.326725 22485033404224 run_lib.py:146] step: 177700, training_loss: 6.50015e-04
I0512 22:50:41.486735 22485033404224 run_lib.py:167] step: 177700, eval_loss: 5.83836e-04
I0512 22:51:05.402666 22485033404224 run_lib.py:146] step: 177750, training_loss: 7.63436e-04
I0512 22:51:29.287199 22485033404224 run_lib.py:146] step: 177800, training_loss: 5.07757e-04
I0512 22:51:29.446185 22485033404224 run_lib.py:167] step: 177800, eval_loss: 4.60548e-04
I0512 22:51:53.000809 22485033404224 run_lib.py:146] step: 177850, training_loss: 6.62195e-04
I0512 22:52:16.874863 22485033404224 run_lib.py:146] step: 177900, training_loss: 7.81361e-04
I0512 22:52:17.034813 22485033404224 run_lib.py:167] step: 177900, eval_loss: 4.69401e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 22:52:41.016432 22485033404224 run_lib.py:146] step: 177950, training_loss: 5.73319e-04
I0512 22:53:04.555444 22485033404224 run_lib.py:146] step: 178000, training_loss: 6.07465e-04
I0512 22:53:04.715814 22485033404224 run_lib.py:167] step: 178000, eval_loss: 7.14942e-04
I0512 22:53:28.600004 22485033404224 run_lib.py:146] step: 178050, training_loss: 5.59627e-04
I0512 22:53:52.449591 22485033404224 run_lib.py:146] step: 178100, training_loss: 6.36758e-04
I0512 22:53:52.610682 22485033404224 run_lib.py:167] step: 178100, eval_loss: 4.55054e-04
I0512 22:54:16.140273 22485033404224 run_lib.py:146] step: 178150, training_loss: 6.23152e-04
I0512 22:54:39.977313 22485033404224 run_lib.py:146] step: 178200, training_loss: 5.34408e-04
I0512 22:54:40.135848 22485033404224 run_lib.py:167] step: 178200, eval_loss: 5.95858e-04
I0512 22:55:03.979993 22485033404224 run_lib.py:146] step: 178250, training_loss: 4.76603e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 22:55:27.594645 22485033404224 run_lib.py:146] step: 178300, training_loss: 6.88298e-04
I0512 22:55:27.755843 22485033404224 run_lib.py:167] step: 178300, eval_loss: 5.51532e-04
I0512 22:55:51.653144 22485033404224 run_lib.py:146] step: 178350, training_loss: 6.91467e-04
I0512 22:56:15.540545 22485033404224 run_lib.py:146] step: 178400, training_loss: 6.37717e-04
I0512 22:56:15.699141 22485033404224 run_lib.py:167] step: 178400, eval_loss: 5.46209e-04
I0512 22:56:39.241879 22485033404224 run_lib.py:146] step: 178450, training_loss: 7.40202e-04
I0512 22:57:02.769452 22485033404224 run_lib.py:146] step: 178500, training_loss: 5.12760e-04
I0512 22:57:02.929692 22485033404224 run_lib.py:167] step: 178500, eval_loss: 7.76390e-04
I0512 22:57:26.729774 22485033404224 run_lib.py:146] step: 178550, training_loss: 6.63706e-04
I0512 22:57:50.575942 22485033404224 run_lib.py:146] step: 178600, training_loss: 5.51970e-04
I0512 22:57:50.735694 22485033404224 run_lib.py:167] step: 178600, eval_loss: 6.30552e-04
I0512 22:58:14.284876 22485033404224 run_lib.py:146] step: 178650, training_loss: 7.15836e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 22:58:38.181836 22485033404224 run_lib.py:146] step: 178700, training_loss: 4.17031e-04
I0512 22:58:38.342068 22485033404224 run_lib.py:167] step: 178700, eval_loss: 5.71904e-04
I0512 22:59:02.219225 22485033404224 run_lib.py:146] step: 178750, training_loss: 6.46050e-04
I0512 22:59:25.778480 22485033404224 run_lib.py:146] step: 178800, training_loss: 8.91322e-04
I0512 22:59:25.938449 22485033404224 run_lib.py:167] step: 178800, eval_loss: 7.36475e-04
I0512 22:59:49.815647 22485033404224 run_lib.py:146] step: 178850, training_loss: 6.17551e-04
I0512 23:00:13.642073 22485033404224 run_lib.py:146] step: 178900, training_loss: 6.92601e-04
I0512 23:00:13.801435 22485033404224 run_lib.py:167] step: 178900, eval_loss: 7.04477e-04
I0512 23:00:37.334048 22485033404224 run_lib.py:146] step: 178950, training_loss: 7.75258e-04
I0512 23:01:01.167049 22485033404224 run_lib.py:146] step: 179000, training_loss: 6.45986e-04
I0512 23:01:01.325775 22485033404224 run_lib.py:167] step: 179000, eval_loss: 7.58601e-04
I0512 23:01:25.154363 22485033404224 run_lib.py:146] step: 179050, training_loss: 7.24950e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 23:01:48.766526 22485033404224 run_lib.py:146] step: 179100, training_loss: 6.36808e-04
I0512 23:01:48.927887 22485033404224 run_lib.py:167] step: 179100, eval_loss: 5.08730e-04
I0512 23:02:12.866115 22485033404224 run_lib.py:146] step: 179150, training_loss: 5.92281e-04
I0512 23:02:36.851764 22485033404224 run_lib.py:146] step: 179200, training_loss: 7.16266e-04
I0512 23:02:37.011866 22485033404224 run_lib.py:167] step: 179200, eval_loss: 5.73149e-04
I0512 23:03:00.643934 22485033404224 run_lib.py:146] step: 179250, training_loss: 6.78783e-04
I0512 23:03:24.591100 22485033404224 run_lib.py:146] step: 179300, training_loss: 6.00245e-04
I0512 23:03:24.751005 22485033404224 run_lib.py:167] step: 179300, eval_loss: 5.87961e-04
I0512 23:03:48.670065 22485033404224 run_lib.py:146] step: 179350, training_loss: 4.50433e-04
I0512 23:04:12.303066 22485033404224 run_lib.py:146] step: 179400, training_loss: 8.11019e-04
I0512 23:04:12.463529 22485033404224 run_lib.py:167] step: 179400, eval_loss: 5.38205e-04
I0512 23:04:36.069481 22485033404224 run_lib.py:146] step: 179450, training_loss: 5.70991e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 23:05:00.043786 22485033404224 run_lib.py:146] step: 179500, training_loss: 5.29860e-04
I0512 23:05:00.206740 22485033404224 run_lib.py:167] step: 179500, eval_loss: 5.12298e-04
I0512 23:05:24.229093 22485033404224 run_lib.py:146] step: 179550, training_loss: 5.87733e-04
I0512 23:05:47.830280 22485033404224 run_lib.py:146] step: 179600, training_loss: 6.83026e-04
I0512 23:05:47.990509 22485033404224 run_lib.py:167] step: 179600, eval_loss: 6.77880e-04
I0512 23:06:12.026287 22485033404224 run_lib.py:146] step: 179650, training_loss: 6.59702e-04
I0512 23:06:36.033635 22485033404224 run_lib.py:146] step: 179700, training_loss: 8.39147e-04
I0512 23:06:36.194008 22485033404224 run_lib.py:167] step: 179700, eval_loss: 7.47345e-04
I0512 23:06:59.771719 22485033404224 run_lib.py:146] step: 179750, training_loss: 6.98551e-04
I0512 23:07:23.792516 22485033404224 run_lib.py:146] step: 179800, training_loss: 5.72060e-04
I0512 23:07:23.952653 22485033404224 run_lib.py:167] step: 179800, eval_loss: 7.40755e-04
I0512 23:07:47.863939 22485033404224 run_lib.py:146] step: 179850, training_loss: 6.83260e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 23:08:11.524856 22485033404224 run_lib.py:146] step: 179900, training_loss: 7.03380e-04
I0512 23:08:11.687129 22485033404224 run_lib.py:167] step: 179900, eval_loss: 7.01104e-04
I0512 23:08:35.744986 22485033404224 run_lib.py:146] step: 179950, training_loss: 5.94524e-04
I0512 23:08:59.723571 22485033404224 run_lib.py:146] step: 180000, training_loss: 6.96889e-04
I0512 23:09:01.608176 22485033404224 run_lib.py:167] step: 180000, eval_loss: 6.10272e-04
I0512 23:09:27.192850 22485033404224 run_lib.py:146] step: 180050, training_loss: 5.74458e-04
I0512 23:09:50.716948 22485033404224 run_lib.py:146] step: 180100, training_loss: 5.91929e-04
I0512 23:09:50.876810 22485033404224 run_lib.py:167] step: 180100, eval_loss: 5.33095e-04
I0512 23:10:14.706296 22485033404224 run_lib.py:146] step: 180150, training_loss: 5.61215e-04
I0512 23:10:38.279593 22485033404224 run_lib.py:146] step: 180200, training_loss: 6.64180e-04
I0512 23:10:38.440415 22485033404224 run_lib.py:167] step: 180200, eval_loss: 5.82890e-04
I0512 23:11:02.169615 22485033404224 run_lib.py:146] step: 180250, training_loss: 6.03513e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 23:11:25.918911 22485033404224 run_lib.py:146] step: 180300, training_loss: 4.68431e-04
I0512 23:11:26.080882 22485033404224 run_lib.py:167] step: 180300, eval_loss: 7.32732e-04
I0512 23:11:49.986454 22485033404224 run_lib.py:146] step: 180350, training_loss: 6.72254e-04
I0512 23:12:13.865349 22485033404224 run_lib.py:146] step: 180400, training_loss: 5.89550e-04
I0512 23:12:14.025572 22485033404224 run_lib.py:167] step: 180400, eval_loss: 5.89173e-04
I0512 23:12:37.565473 22485033404224 run_lib.py:146] step: 180450, training_loss: 3.95868e-04
I0512 23:13:01.427436 22485033404224 run_lib.py:146] step: 180500, training_loss: 6.14386e-04
I0512 23:13:01.586791 22485033404224 run_lib.py:167] step: 180500, eval_loss: 7.14551e-04
I0512 23:13:25.442973 22485033404224 run_lib.py:146] step: 180550, training_loss: 6.32303e-04
I0512 23:13:48.972154 22485033404224 run_lib.py:146] step: 180600, training_loss: 7.12816e-04
I0512 23:13:49.131751 22485033404224 run_lib.py:167] step: 180600, eval_loss: 4.54180e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 23:14:13.061648 22485033404224 run_lib.py:146] step: 180650, training_loss: 6.20242e-04
I0512 23:14:36.930696 22485033404224 run_lib.py:146] step: 180700, training_loss: 9.58201e-04
I0512 23:14:37.091080 22485033404224 run_lib.py:167] step: 180700, eval_loss: 6.80210e-04
I0512 23:15:00.612687 22485033404224 run_lib.py:146] step: 180750, training_loss: 6.29850e-04
I0512 23:15:24.479068 22485033404224 run_lib.py:146] step: 180800, training_loss: 5.37575e-04
I0512 23:15:24.638067 22485033404224 run_lib.py:167] step: 180800, eval_loss: 4.70341e-04
I0512 23:15:48.476910 22485033404224 run_lib.py:146] step: 180850, training_loss: 5.89783e-04
I0512 23:16:12.041860 22485033404224 run_lib.py:146] step: 180900, training_loss: 7.03043e-04
I0512 23:16:12.201759 22485033404224 run_lib.py:167] step: 180900, eval_loss: 5.22299e-04
I0512 23:16:36.055067 22485033404224 run_lib.py:146] step: 180950, training_loss: 5.55720e-04
I0512 23:16:59.586972 22485033404224 run_lib.py:146] step: 181000, training_loss: 6.11430e-04
I0512 23:16:59.746783 22485033404224 run_lib.py:167] step: 181000, eval_loss: 3.77054e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 23:17:23.650412 22485033404224 run_lib.py:146] step: 181050, training_loss: 7.65816e-04
I0512 23:17:47.211683 22485033404224 run_lib.py:146] step: 181100, training_loss: 5.52700e-04
I0512 23:17:47.373936 22485033404224 run_lib.py:167] step: 181100, eval_loss: 4.57175e-04
I0512 23:18:11.256798 22485033404224 run_lib.py:146] step: 181150, training_loss: 5.46827e-04
I0512 23:18:35.155741 22485033404224 run_lib.py:146] step: 181200, training_loss: 6.55689e-04
I0512 23:18:35.315428 22485033404224 run_lib.py:167] step: 181200, eval_loss: 6.71741e-04
I0512 23:18:58.852814 22485033404224 run_lib.py:146] step: 181250, training_loss: 7.90323e-04
I0512 23:19:22.722651 22485033404224 run_lib.py:146] step: 181300, training_loss: 6.07748e-04
I0512 23:19:22.882697 22485033404224 run_lib.py:167] step: 181300, eval_loss: 6.32194e-04
I0512 23:19:46.721086 22485033404224 run_lib.py:146] step: 181350, training_loss: 6.51916e-04
I0512 23:20:10.267683 22485033404224 run_lib.py:146] step: 181400, training_loss: 5.14860e-04
I0512 23:20:10.428281 22485033404224 run_lib.py:167] step: 181400, eval_loss: 7.11047e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 23:20:34.469890 22485033404224 run_lib.py:146] step: 181450, training_loss: 8.06517e-04
I0512 23:20:58.447868 22485033404224 run_lib.py:146] step: 181500, training_loss: 6.34250e-04
I0512 23:20:58.608295 22485033404224 run_lib.py:167] step: 181500, eval_loss: 4.24979e-04
I0512 23:21:22.189980 22485033404224 run_lib.py:146] step: 181550, training_loss: 6.23261e-04
I0512 23:21:46.123219 22485033404224 run_lib.py:146] step: 181600, training_loss: 7.89530e-04
I0512 23:21:46.211979 22485033404224 run_lib.py:167] step: 181600, eval_loss: 6.06842e-04
I0512 23:22:10.119985 22485033404224 run_lib.py:146] step: 181650, training_loss: 5.85910e-04
I0512 23:22:33.717640 22485033404224 run_lib.py:146] step: 181700, training_loss: 6.81152e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 23:22:34.073740 22485033404224 run_lib.py:167] step: 181700, eval_loss: 4.77304e-04
I0512 23:22:58.247518 22485033404224 run_lib.py:146] step: 181750, training_loss: 5.88199e-04
I0512 23:23:22.011595 22485033404224 run_lib.py:146] step: 181800, training_loss: 6.93600e-04
I0512 23:23:22.172412 22485033404224 run_lib.py:167] step: 181800, eval_loss: 7.19865e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 23:23:46.366403 22485033404224 run_lib.py:146] step: 181850, training_loss: 6.72753e-04
I0512 23:24:10.019775 22485033404224 run_lib.py:146] step: 181900, training_loss: 6.15450e-04
I0512 23:24:10.183502 22485033404224 run_lib.py:167] step: 181900, eval_loss: 5.33719e-04
I0512 23:24:34.187196 22485033404224 run_lib.py:146] step: 181950, training_loss: 5.75887e-04
I0512 23:24:58.230586 22485033404224 run_lib.py:146] step: 182000, training_loss: 4.16543e-04
I0512 23:24:58.390407 22485033404224 run_lib.py:167] step: 182000, eval_loss: 5.45010e-04
I0512 23:25:22.011644 22485033404224 run_lib.py:146] step: 182050, training_loss: 4.99728e-04
I0512 23:25:45.960667 22485033404224 run_lib.py:146] step: 182100, training_loss: 6.14134e-04
I0512 23:25:46.121558 22485033404224 run_lib.py:167] step: 182100, eval_loss: 6.44428e-04
I0512 23:26:10.028774 22485033404224 run_lib.py:146] step: 182150, training_loss: 7.59576e-04
I0512 23:26:33.652152 22485033404224 run_lib.py:146] step: 182200, training_loss: 5.07504e-04
I0512 23:26:33.813560 22485033404224 run_lib.py:167] step: 182200, eval_loss: 6.99244e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 23:26:57.867087 22485033404224 run_lib.py:146] step: 182250, training_loss: 5.97690e-04
I0512 23:27:21.816467 22485033404224 run_lib.py:146] step: 182300, training_loss: 6.43454e-04
I0512 23:27:21.976688 22485033404224 run_lib.py:167] step: 182300, eval_loss: 5.18946e-04
I0512 23:27:45.518721 22485033404224 run_lib.py:146] step: 182350, training_loss: 5.78420e-04
I0512 23:28:09.390928 22485033404224 run_lib.py:146] step: 182400, training_loss: 5.32217e-04
I0512 23:28:09.550300 22485033404224 run_lib.py:167] step: 182400, eval_loss: 6.74754e-04
I0512 23:28:33.404060 22485033404224 run_lib.py:146] step: 182450, training_loss: 5.39712e-04
I0512 23:28:56.951009 22485033404224 run_lib.py:146] step: 182500, training_loss: 6.19207e-04
I0512 23:28:57.110235 22485033404224 run_lib.py:167] step: 182500, eval_loss: 6.52477e-04
I0512 23:29:20.958509 22485033404224 run_lib.py:146] step: 182550, training_loss: 5.68419e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 23:29:44.881060 22485033404224 run_lib.py:146] step: 182600, training_loss: 6.13669e-04
I0512 23:29:45.041348 22485033404224 run_lib.py:167] step: 182600, eval_loss: 6.12631e-04
I0512 23:30:08.558318 22485033404224 run_lib.py:146] step: 182650, training_loss: 5.97325e-04
I0512 23:30:32.416890 22485033404224 run_lib.py:146] step: 182700, training_loss: 5.51566e-04
I0512 23:30:32.576992 22485033404224 run_lib.py:167] step: 182700, eval_loss: 7.26907e-04
I0512 23:30:56.066439 22485033404224 run_lib.py:146] step: 182750, training_loss: 5.00198e-04
I0512 23:31:19.921949 22485033404224 run_lib.py:146] step: 182800, training_loss: 5.74370e-04
I0512 23:31:20.081432 22485033404224 run_lib.py:167] step: 182800, eval_loss: 6.02237e-04
I0512 23:31:43.606010 22485033404224 run_lib.py:146] step: 182850, training_loss: 6.26271e-04
I0512 23:32:07.405337 22485033404224 run_lib.py:146] step: 182900, training_loss: 6.94758e-04
I0512 23:32:07.563935 22485033404224 run_lib.py:167] step: 182900, eval_loss: 5.52443e-04
I0512 23:32:31.383181 22485033404224 run_lib.py:146] step: 182950, training_loss: 6.58622e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 23:32:54.970477 22485033404224 run_lib.py:146] step: 183000, training_loss: 6.96082e-04
I0512 23:32:55.131305 22485033404224 run_lib.py:167] step: 183000, eval_loss: 4.97148e-04
I0512 23:33:19.019945 22485033404224 run_lib.py:146] step: 183050, training_loss: 6.24357e-04
I0512 23:33:42.916298 22485033404224 run_lib.py:146] step: 183100, training_loss: 7.20129e-04
I0512 23:33:43.075439 22485033404224 run_lib.py:167] step: 183100, eval_loss: 7.71623e-04
I0512 23:34:06.628131 22485033404224 run_lib.py:146] step: 183150, training_loss: 6.02935e-04
I0512 23:34:30.479136 22485033404224 run_lib.py:146] step: 183200, training_loss: 6.50546e-04
I0512 23:34:30.639320 22485033404224 run_lib.py:167] step: 183200, eval_loss: 5.98147e-04
I0512 23:34:54.494752 22485033404224 run_lib.py:146] step: 183250, training_loss: 6.98413e-04
I0512 23:35:18.041822 22485033404224 run_lib.py:146] step: 183300, training_loss: 6.33368e-04
I0512 23:35:18.201576 22485033404224 run_lib.py:167] step: 183300, eval_loss: 5.43504e-04
I0512 23:35:42.051496 22485033404224 run_lib.py:146] step: 183350, training_loss: 4.31414e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 23:36:06.014369 22485033404224 run_lib.py:146] step: 183400, training_loss: 5.63665e-04
I0512 23:36:06.174174 22485033404224 run_lib.py:167] step: 183400, eval_loss: 4.35270e-04
I0512 23:36:29.698202 22485033404224 run_lib.py:146] step: 183450, training_loss: 7.13365e-04
I0512 23:36:53.596169 22485033404224 run_lib.py:146] step: 183500, training_loss: 6.60063e-04
I0512 23:36:53.756383 22485033404224 run_lib.py:167] step: 183500, eval_loss: 6.22287e-04
I0512 23:37:17.614143 22485033404224 run_lib.py:146] step: 183550, training_loss: 6.22563e-04
I0512 23:37:41.147823 22485033404224 run_lib.py:146] step: 183600, training_loss: 5.81455e-04
I0512 23:37:41.308409 22485033404224 run_lib.py:167] step: 183600, eval_loss: 6.06955e-04
I0512 23:38:05.214455 22485033404224 run_lib.py:146] step: 183650, training_loss: 4.83566e-04
I0512 23:38:28.833378 22485033404224 run_lib.py:146] step: 183700, training_loss: 7.68005e-04
I0512 23:38:28.993705 22485033404224 run_lib.py:167] step: 183700, eval_loss: 4.83943e-04
I0512 23:38:52.909706 22485033404224 run_lib.py:146] step: 183750, training_loss: 6.48700e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 23:39:16.634139 22485033404224 run_lib.py:146] step: 183800, training_loss: 4.55933e-04
I0512 23:39:16.795966 22485033404224 run_lib.py:167] step: 183800, eval_loss: 5.76593e-04
I0512 23:39:40.766175 22485033404224 run_lib.py:146] step: 183850, training_loss: 6.28889e-04
I0512 23:40:04.726141 22485033404224 run_lib.py:146] step: 183900, training_loss: 8.87572e-04
I0512 23:40:04.886391 22485033404224 run_lib.py:167] step: 183900, eval_loss: 5.26864e-04
I0512 23:40:28.504408 22485033404224 run_lib.py:146] step: 183950, training_loss: 6.13563e-04
I0512 23:40:52.424590 22485033404224 run_lib.py:146] step: 184000, training_loss: 8.68767e-04
I0512 23:40:52.584772 22485033404224 run_lib.py:167] step: 184000, eval_loss: 6.75113e-04
I0512 23:41:16.459284 22485033404224 run_lib.py:146] step: 184050, training_loss: 5.84411e-04
I0512 23:41:40.062561 22485033404224 run_lib.py:146] step: 184100, training_loss: 7.28495e-04
I0512 23:41:40.222402 22485033404224 run_lib.py:167] step: 184100, eval_loss: 7.93295e-04
I0512 23:42:04.173275 22485033404224 run_lib.py:146] step: 184150, training_loss: 5.99886e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 23:42:28.206518 22485033404224 run_lib.py:146] step: 184200, training_loss: 7.72476e-04
I0512 23:42:28.367574 22485033404224 run_lib.py:167] step: 184200, eval_loss: 5.16424e-04
I0512 23:42:51.970768 22485033404224 run_lib.py:146] step: 184250, training_loss: 5.76779e-04
I0512 23:43:15.904737 22485033404224 run_lib.py:146] step: 184300, training_loss: 5.71750e-04
I0512 23:43:16.066044 22485033404224 run_lib.py:167] step: 184300, eval_loss: 6.97900e-04
I0512 23:43:39.977622 22485033404224 run_lib.py:146] step: 184350, training_loss: 5.83883e-04
I0512 23:44:03.555497 22485033404224 run_lib.py:146] step: 184400, training_loss: 8.12221e-04
I0512 23:44:03.715932 22485033404224 run_lib.py:167] step: 184400, eval_loss: 5.73784e-04
I0512 23:44:27.611641 22485033404224 run_lib.py:146] step: 184450, training_loss: 6.22186e-04
I0512 23:44:51.216750 22485033404224 run_lib.py:146] step: 184500, training_loss: 5.90570e-04
I0512 23:44:51.375631 22485033404224 run_lib.py:167] step: 184500, eval_loss: 6.46238e-04
I0512 23:45:15.197335 22485033404224 run_lib.py:146] step: 184550, training_loss: 7.09118e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 23:45:38.780080 22485033404224 run_lib.py:146] step: 184600, training_loss: 4.65927e-04
I0512 23:45:38.940401 22485033404224 run_lib.py:167] step: 184600, eval_loss: 5.05217e-04
I0512 23:46:02.799399 22485033404224 run_lib.py:146] step: 184650, training_loss: 6.62979e-04
I0512 23:46:26.660510 22485033404224 run_lib.py:146] step: 184700, training_loss: 7.06270e-04
I0512 23:46:26.819531 22485033404224 run_lib.py:167] step: 184700, eval_loss: 6.42048e-04
I0512 23:46:50.352492 22485033404224 run_lib.py:146] step: 184750, training_loss: 5.98480e-04
I0512 23:47:14.215338 22485033404224 run_lib.py:146] step: 184800, training_loss: 6.97621e-04
I0512 23:47:14.375179 22485033404224 run_lib.py:167] step: 184800, eval_loss: 6.18892e-04
I0512 23:47:38.232357 22485033404224 run_lib.py:146] step: 184850, training_loss: 5.87523e-04
I0512 23:48:01.760202 22485033404224 run_lib.py:146] step: 184900, training_loss: 7.98880e-04
I0512 23:48:01.920919 22485033404224 run_lib.py:167] step: 184900, eval_loss: 5.00834e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 23:48:25.824573 22485033404224 run_lib.py:146] step: 184950, training_loss: 5.04728e-04
I0512 23:48:49.713099 22485033404224 run_lib.py:146] step: 185000, training_loss: 6.84070e-04
I0512 23:48:49.874300 22485033404224 run_lib.py:167] step: 185000, eval_loss: 5.29603e-04
I0512 23:49:13.432574 22485033404224 run_lib.py:146] step: 185050, training_loss: 4.97825e-04
I0512 23:49:37.338892 22485033404224 run_lib.py:146] step: 185100, training_loss: 1.04687e-03
I0512 23:49:37.498338 22485033404224 run_lib.py:167] step: 185100, eval_loss: 7.42971e-04
I0512 23:50:01.322895 22485033404224 run_lib.py:146] step: 185150, training_loss: 4.01980e-04
I0512 23:50:24.871529 22485033404224 run_lib.py:146] step: 185200, training_loss: 9.72182e-04
I0512 23:50:25.031156 22485033404224 run_lib.py:167] step: 185200, eval_loss: 6.54357e-04
I0512 23:50:48.880521 22485033404224 run_lib.py:146] step: 185250, training_loss: 6.61927e-04
I0512 23:51:12.445784 22485033404224 run_lib.py:146] step: 185300, training_loss: 6.13069e-04
I0512 23:51:12.605416 22485033404224 run_lib.py:167] step: 185300, eval_loss: 5.41786e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 23:51:36.511169 22485033404224 run_lib.py:146] step: 185350, training_loss: 6.96344e-04
I0512 23:52:00.071584 22485033404224 run_lib.py:146] step: 185400, training_loss: 6.13149e-04
I0512 23:52:00.232675 22485033404224 run_lib.py:167] step: 185400, eval_loss: 4.81300e-04
I0512 23:52:24.106784 22485033404224 run_lib.py:146] step: 185450, training_loss: 6.78402e-04
I0512 23:52:47.965542 22485033404224 run_lib.py:146] step: 185500, training_loss: 6.93336e-04
I0512 23:52:48.125625 22485033404224 run_lib.py:167] step: 185500, eval_loss: 7.57285e-04
I0512 23:53:11.694870 22485033404224 run_lib.py:146] step: 185550, training_loss: 6.66690e-04
I0512 23:53:35.529841 22485033404224 run_lib.py:146] step: 185600, training_loss: 5.70984e-04
I0512 23:53:35.689320 22485033404224 run_lib.py:167] step: 185600, eval_loss: 5.93636e-04
I0512 23:53:59.521759 22485033404224 run_lib.py:146] step: 185650, training_loss: 6.01167e-04
I0512 23:54:23.044225 22485033404224 run_lib.py:146] step: 185700, training_loss: 6.81088e-04
I0512 23:54:23.203985 22485033404224 run_lib.py:167] step: 185700, eval_loss: 5.97743e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 23:54:47.116814 22485033404224 run_lib.py:146] step: 185750, training_loss: 7.47447e-04
I0512 23:55:11.010548 22485033404224 run_lib.py:146] step: 185800, training_loss: 7.39891e-04
I0512 23:55:11.170236 22485033404224 run_lib.py:167] step: 185800, eval_loss: 6.13756e-04
I0512 23:55:34.696356 22485033404224 run_lib.py:146] step: 185850, training_loss: 7.89777e-04
I0512 23:55:58.639995 22485033404224 run_lib.py:146] step: 185900, training_loss: 7.34225e-04
I0512 23:55:58.800741 22485033404224 run_lib.py:167] step: 185900, eval_loss: 3.75673e-04
I0512 23:56:22.734155 22485033404224 run_lib.py:146] step: 185950, training_loss: 5.68465e-04
I0512 23:56:46.318038 22485033404224 run_lib.py:146] step: 186000, training_loss: 5.83634e-04
I0512 23:56:46.478418 22485033404224 run_lib.py:167] step: 186000, eval_loss: 8.18666e-04
I0512 23:57:10.380228 22485033404224 run_lib.py:146] step: 186050, training_loss: 6.11013e-04
I0512 23:57:33.989151 22485033404224 run_lib.py:146] step: 186100, training_loss: 6.52184e-04
I0512 23:57:34.149988 22485033404224 run_lib.py:167] step: 186100, eval_loss: 6.21602e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0512 23:57:58.238728 22485033404224 run_lib.py:146] step: 186150, training_loss: 6.67911e-04
I0512 23:58:21.972600 22485033404224 run_lib.py:146] step: 186200, training_loss: 7.55129e-04
I0512 23:58:22.136532 22485033404224 run_lib.py:167] step: 186200, eval_loss: 8.02093e-04
I0512 23:58:46.396718 22485033404224 run_lib.py:146] step: 186250, training_loss: 5.58780e-04
I0512 23:59:10.622004 22485033404224 run_lib.py:146] step: 186300, training_loss: 6.00708e-04
I0512 23:59:10.784521 22485033404224 run_lib.py:167] step: 186300, eval_loss: 5.70548e-04
I0512 23:59:34.526101 22485033404224 run_lib.py:146] step: 186350, training_loss: 4.96983e-04
I0512 23:59:58.742036 22485033404224 run_lib.py:146] step: 186400, training_loss: 6.42121e-04
I0512 23:59:58.905071 22485033404224 run_lib.py:167] step: 186400, eval_loss: 6.36113e-04
I0513 00:00:22.906553 22485033404224 run_lib.py:146] step: 186450, training_loss: 6.84476e-04
I0513 00:00:46.485575 22485033404224 run_lib.py:146] step: 186500, training_loss: 6.20388e-04
I0513 00:00:46.646038 22485033404224 run_lib.py:167] step: 186500, eval_loss: 5.34209e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 00:01:10.676750 22485033404224 run_lib.py:146] step: 186550, training_loss: 5.02021e-04
I0513 00:01:34.708332 22485033404224 run_lib.py:146] step: 186600, training_loss: 7.45229e-04
I0513 00:01:34.870660 22485033404224 run_lib.py:167] step: 186600, eval_loss: 5.24646e-04
I0513 00:01:58.510165 22485033404224 run_lib.py:146] step: 186650, training_loss: 6.96405e-04
I0513 00:02:22.436039 22485033404224 run_lib.py:146] step: 186700, training_loss: 4.96059e-04
I0513 00:02:22.597961 22485033404224 run_lib.py:167] step: 186700, eval_loss: 6.42913e-04
I0513 00:02:46.555271 22485033404224 run_lib.py:146] step: 186750, training_loss: 7.68207e-04
I0513 00:03:10.104734 22485033404224 run_lib.py:146] step: 186800, training_loss: 6.74991e-04
I0513 00:03:10.265707 22485033404224 run_lib.py:167] step: 186800, eval_loss: 6.25364e-04
I0513 00:03:34.151196 22485033404224 run_lib.py:146] step: 186850, training_loss: 6.93906e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 00:03:57.803075 22485033404224 run_lib.py:146] step: 186900, training_loss: 5.38389e-04
I0513 00:03:57.966062 22485033404224 run_lib.py:167] step: 186900, eval_loss: 7.35771e-04
I0513 00:04:21.869471 22485033404224 run_lib.py:146] step: 186950, training_loss: 6.16604e-04
I0513 00:04:45.410234 22485033404224 run_lib.py:146] step: 187000, training_loss: 5.43703e-04
I0513 00:04:45.568991 22485033404224 run_lib.py:167] step: 187000, eval_loss: 5.14686e-04
I0513 00:05:09.452129 22485033404224 run_lib.py:146] step: 187050, training_loss: 6.70128e-04
I0513 00:05:33.293313 22485033404224 run_lib.py:146] step: 187100, training_loss: 5.81033e-04
I0513 00:05:33.453392 22485033404224 run_lib.py:167] step: 187100, eval_loss: 4.75844e-04
I0513 00:05:57.018650 22485033404224 run_lib.py:146] step: 187150, training_loss: 7.42837e-04
I0513 00:06:20.838045 22485033404224 run_lib.py:146] step: 187200, training_loss: 6.30374e-04
I0513 00:06:20.998348 22485033404224 run_lib.py:167] step: 187200, eval_loss: 7.06999e-04
I0513 00:06:44.833847 22485033404224 run_lib.py:146] step: 187250, training_loss: 6.01570e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 00:07:08.444316 22485033404224 run_lib.py:146] step: 187300, training_loss: 7.65529e-04
I0513 00:07:08.605504 22485033404224 run_lib.py:167] step: 187300, eval_loss: 5.40172e-04
I0513 00:07:32.495719 22485033404224 run_lib.py:146] step: 187350, training_loss: 6.53976e-04
I0513 00:07:56.357557 22485033404224 run_lib.py:146] step: 187400, training_loss: 7.93102e-04
I0513 00:07:56.516077 22485033404224 run_lib.py:167] step: 187400, eval_loss: 5.01872e-04
I0513 00:08:20.041497 22485033404224 run_lib.py:146] step: 187450, training_loss: 5.18793e-04
I0513 00:08:43.877060 22485033404224 run_lib.py:146] step: 187500, training_loss: 5.94561e-04
I0513 00:08:44.037398 22485033404224 run_lib.py:167] step: 187500, eval_loss: 6.07186e-04
I0513 00:09:07.834865 22485033404224 run_lib.py:146] step: 187550, training_loss: 4.59353e-04
I0513 00:09:31.392151 22485033404224 run_lib.py:146] step: 187600, training_loss: 6.06628e-04
I0513 00:09:31.553219 22485033404224 run_lib.py:167] step: 187600, eval_loss: 6.96024e-04
I0513 00:09:55.362099 22485033404224 run_lib.py:146] step: 187650, training_loss: 3.50526e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 00:10:18.968680 22485033404224 run_lib.py:146] step: 187700, training_loss: 6.01302e-04
I0513 00:10:19.131009 22485033404224 run_lib.py:167] step: 187700, eval_loss: 7.65601e-04
I0513 00:10:43.015581 22485033404224 run_lib.py:146] step: 187750, training_loss: 6.85176e-04
I0513 00:11:06.860429 22485033404224 run_lib.py:146] step: 187800, training_loss: 5.43010e-04
I0513 00:11:07.021094 22485033404224 run_lib.py:167] step: 187800, eval_loss: 9.03850e-04
I0513 00:11:30.547264 22485033404224 run_lib.py:146] step: 187850, training_loss: 7.19156e-04
I0513 00:11:54.358994 22485033404224 run_lib.py:146] step: 187900, training_loss: 6.49106e-04
I0513 00:11:54.517556 22485033404224 run_lib.py:167] step: 187900, eval_loss: 6.88327e-04
I0513 00:12:18.057482 22485033404224 run_lib.py:146] step: 187950, training_loss: 5.42429e-04
I0513 00:12:41.923332 22485033404224 run_lib.py:146] step: 188000, training_loss: 5.88157e-04
I0513 00:12:42.082297 22485033404224 run_lib.py:167] step: 188000, eval_loss: 6.64462e-04
I0513 00:13:05.911103 22485033404224 run_lib.py:146] step: 188050, training_loss: 5.70265e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 00:13:29.596441 22485033404224 run_lib.py:146] step: 188100, training_loss: 8.33888e-04
I0513 00:13:29.758748 22485033404224 run_lib.py:167] step: 188100, eval_loss: 6.00537e-04
I0513 00:13:53.718316 22485033404224 run_lib.py:146] step: 188150, training_loss: 6.34428e-04
I0513 00:14:17.674158 22485033404224 run_lib.py:146] step: 188200, training_loss: 6.24546e-04
I0513 00:14:17.835001 22485033404224 run_lib.py:167] step: 188200, eval_loss: 6.60654e-04
I0513 00:14:41.451938 22485033404224 run_lib.py:146] step: 188250, training_loss: 5.07612e-04
I0513 00:15:05.361668 22485033404224 run_lib.py:146] step: 188300, training_loss: 5.75261e-04
I0513 00:15:05.522102 22485033404224 run_lib.py:167] step: 188300, eval_loss: 5.37443e-04
I0513 00:15:29.406586 22485033404224 run_lib.py:146] step: 188350, training_loss: 7.40173e-04
I0513 00:15:53.008125 22485033404224 run_lib.py:146] step: 188400, training_loss: 4.22462e-04
I0513 00:15:53.168832 22485033404224 run_lib.py:167] step: 188400, eval_loss: 5.42139e-04
I0513 00:16:17.078194 22485033404224 run_lib.py:146] step: 188450, training_loss: 7.07103e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 00:16:41.084651 22485033404224 run_lib.py:146] step: 188500, training_loss: 4.26813e-04
I0513 00:16:41.246948 22485033404224 run_lib.py:167] step: 188500, eval_loss: 6.61952e-04
I0513 00:17:04.842020 22485033404224 run_lib.py:146] step: 188550, training_loss: 6.68518e-04
I0513 00:17:28.839874 22485033404224 run_lib.py:146] step: 188600, training_loss: 5.32082e-04
I0513 00:17:29.000093 22485033404224 run_lib.py:167] step: 188600, eval_loss: 4.60679e-04
I0513 00:17:52.622841 22485033404224 run_lib.py:146] step: 188650, training_loss: 7.14418e-04
I0513 00:18:16.552244 22485033404224 run_lib.py:146] step: 188700, training_loss: 7.25830e-04
I0513 00:18:16.713747 22485033404224 run_lib.py:167] step: 188700, eval_loss: 5.85763e-04
I0513 00:18:40.363880 22485033404224 run_lib.py:146] step: 188750, training_loss: 6.31416e-04
I0513 00:19:04.268635 22485033404224 run_lib.py:146] step: 188800, training_loss: 6.83221e-04
I0513 00:19:04.429824 22485033404224 run_lib.py:167] step: 188800, eval_loss: 5.28585e-04
I0513 00:19:28.302172 22485033404224 run_lib.py:146] step: 188850, training_loss: 6.15717e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 00:19:52.018460 22485033404224 run_lib.py:146] step: 188900, training_loss: 4.19682e-04
I0513 00:19:52.182011 22485033404224 run_lib.py:167] step: 188900, eval_loss: 5.03277e-04
I0513 00:20:16.104797 22485033404224 run_lib.py:146] step: 188950, training_loss: 8.66787e-04
I0513 00:20:39.962040 22485033404224 run_lib.py:146] step: 189000, training_loss: 5.53827e-04
I0513 00:20:40.120561 22485033404224 run_lib.py:167] step: 189000, eval_loss: 4.60806e-04
I0513 00:21:03.682342 22485033404224 run_lib.py:146] step: 189050, training_loss: 5.39274e-04
I0513 00:21:27.529041 22485033404224 run_lib.py:146] step: 189100, training_loss: 7.58823e-04
I0513 00:21:27.688060 22485033404224 run_lib.py:167] step: 189100, eval_loss: 7.20051e-04
I0513 00:21:51.527836 22485033404224 run_lib.py:146] step: 189150, training_loss: 8.14198e-04
I0513 00:22:15.061613 22485033404224 run_lib.py:146] step: 189200, training_loss: 6.44145e-04
I0513 00:22:15.221680 22485033404224 run_lib.py:167] step: 189200, eval_loss: 5.95857e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 00:22:39.081285 22485033404224 run_lib.py:146] step: 189250, training_loss: 5.31152e-04
I0513 00:23:02.974630 22485033404224 run_lib.py:146] step: 189300, training_loss: 6.25814e-04
I0513 00:23:03.134241 22485033404224 run_lib.py:167] step: 189300, eval_loss: 6.03468e-04
I0513 00:23:26.649291 22485033404224 run_lib.py:146] step: 189350, training_loss: 5.79421e-04
I0513 00:23:50.511478 22485033404224 run_lib.py:146] step: 189400, training_loss: 5.81739e-04
I0513 00:23:50.671345 22485033404224 run_lib.py:167] step: 189400, eval_loss: 4.59651e-04
I0513 00:24:14.233411 22485033404224 run_lib.py:146] step: 189450, training_loss: 5.60413e-04
I0513 00:24:38.069818 22485033404224 run_lib.py:146] step: 189500, training_loss: 6.01546e-04
I0513 00:24:38.154220 22485033404224 run_lib.py:167] step: 189500, eval_loss: 7.44841e-04
I0513 00:25:01.999800 22485033404224 run_lib.py:146] step: 189550, training_loss: 5.62481e-04
I0513 00:25:25.532037 22485033404224 run_lib.py:146] step: 189600, training_loss: 5.39924e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 00:25:25.877739 22485033404224 run_lib.py:167] step: 189600, eval_loss: 5.48661e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 00:25:49.839704 22485033404224 run_lib.py:146] step: 189650, training_loss: 5.08331e-04
I0513 00:26:13.362303 22485033404224 run_lib.py:146] step: 189700, training_loss: 4.51323e-04
I0513 00:26:13.522296 22485033404224 run_lib.py:167] step: 189700, eval_loss: 6.92778e-04
I0513 00:26:37.380998 22485033404224 run_lib.py:146] step: 189750, training_loss: 7.17443e-04
I0513 00:27:01.223907 22485033404224 run_lib.py:146] step: 189800, training_loss: 7.20877e-04
I0513 00:27:01.384711 22485033404224 run_lib.py:167] step: 189800, eval_loss: 7.68432e-04
I0513 00:27:24.947213 22485033404224 run_lib.py:146] step: 189850, training_loss: 5.95588e-04
I0513 00:27:48.791068 22485033404224 run_lib.py:146] step: 189900, training_loss: 7.40709e-04
I0513 00:27:48.951148 22485033404224 run_lib.py:167] step: 189900, eval_loss: 4.80877e-04
I0513 00:28:12.803350 22485033404224 run_lib.py:146] step: 189950, training_loss: 6.57573e-04
I0513 00:28:36.351299 22485033404224 run_lib.py:146] step: 190000, training_loss: 7.74957e-04
I0513 00:28:38.078729 22485033404224 run_lib.py:167] step: 190000, eval_loss: 5.33116e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 00:29:03.619513 22485033404224 run_lib.py:146] step: 190050, training_loss: 5.07201e-04
I0513 00:29:27.528856 22485033404224 run_lib.py:146] step: 190100, training_loss: 4.57076e-04
I0513 00:29:27.689956 22485033404224 run_lib.py:167] step: 190100, eval_loss: 9.02430e-04
I0513 00:29:51.208467 22485033404224 run_lib.py:146] step: 190150, training_loss: 5.88059e-04
I0513 00:30:15.078793 22485033404224 run_lib.py:146] step: 190200, training_loss: 6.53441e-04
I0513 00:30:15.238451 22485033404224 run_lib.py:167] step: 190200, eval_loss: 6.81217e-04
I0513 00:30:39.117838 22485033404224 run_lib.py:146] step: 190250, training_loss: 5.56566e-04
I0513 00:31:02.718791 22485033404224 run_lib.py:146] step: 190300, training_loss: 7.42982e-04
I0513 00:31:02.879701 22485033404224 run_lib.py:167] step: 190300, eval_loss: 4.97790e-04
I0513 00:31:26.834395 22485033404224 run_lib.py:146] step: 190350, training_loss: 7.09198e-04
I0513 00:31:50.772649 22485033404224 run_lib.py:146] step: 190400, training_loss: 5.10235e-04
I0513 00:31:50.934166 22485033404224 run_lib.py:167] step: 190400, eval_loss: 6.11576e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 00:32:14.620933 22485033404224 run_lib.py:146] step: 190450, training_loss: 5.49244e-04
I0513 00:32:38.252928 22485033404224 run_lib.py:146] step: 190500, training_loss: 6.79401e-04
I0513 00:32:38.414829 22485033404224 run_lib.py:167] step: 190500, eval_loss: 4.18060e-04
I0513 00:33:02.809651 22485033404224 run_lib.py:146] step: 190550, training_loss: 8.47747e-04
I0513 00:33:26.416780 22485033404224 run_lib.py:146] step: 190600, training_loss: 5.86125e-04
I0513 00:33:26.577315 22485033404224 run_lib.py:167] step: 190600, eval_loss: 7.25038e-04
I0513 00:33:50.183065 22485033404224 run_lib.py:146] step: 190650, training_loss: 4.14956e-04
I0513 00:34:14.512705 22485033404224 run_lib.py:146] step: 190700, training_loss: 7.18747e-04
I0513 00:34:14.672717 22485033404224 run_lib.py:167] step: 190700, eval_loss: 5.70948e-04
I0513 00:34:38.268525 22485033404224 run_lib.py:146] step: 190750, training_loss: 5.86403e-04
I0513 00:35:01.898281 22485033404224 run_lib.py:146] step: 190800, training_loss: 6.53722e-04
I0513 00:35:02.059204 22485033404224 run_lib.py:167] step: 190800, eval_loss: 6.17406e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 00:35:26.284110 22485033404224 run_lib.py:146] step: 190850, training_loss: 7.10435e-04
I0513 00:35:50.257641 22485033404224 run_lib.py:146] step: 190900, training_loss: 3.33378e-04
I0513 00:35:50.419628 22485033404224 run_lib.py:167] step: 190900, eval_loss: 7.47712e-04
I0513 00:36:14.035574 22485033404224 run_lib.py:146] step: 190950, training_loss: 6.51745e-04
I0513 00:36:37.929911 22485033404224 run_lib.py:146] step: 191000, training_loss: 6.22732e-04
I0513 00:36:38.091201 22485033404224 run_lib.py:167] step: 191000, eval_loss: 6.07516e-04
I0513 00:37:01.994889 22485033404224 run_lib.py:146] step: 191050, training_loss: 4.98434e-04
I0513 00:37:25.632019 22485033404224 run_lib.py:146] step: 191100, training_loss: 6.59572e-04
I0513 00:37:25.791390 22485033404224 run_lib.py:167] step: 191100, eval_loss: 5.29503e-04
I0513 00:37:49.727820 22485033404224 run_lib.py:146] step: 191150, training_loss: 6.13043e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 00:38:13.676843 22485033404224 run_lib.py:146] step: 191200, training_loss: 6.48364e-04
I0513 00:38:13.837870 22485033404224 run_lib.py:167] step: 191200, eval_loss: 6.93001e-04
I0513 00:38:37.368905 22485033404224 run_lib.py:146] step: 191250, training_loss: 7.21248e-04
I0513 00:39:00.883828 22485033404224 run_lib.py:146] step: 191300, training_loss: 7.53317e-04
I0513 00:39:01.044958 22485033404224 run_lib.py:167] step: 191300, eval_loss: 5.00287e-04
I0513 00:39:25.253549 22485033404224 run_lib.py:146] step: 191350, training_loss: 4.94112e-04
I0513 00:39:48.796030 22485033404224 run_lib.py:146] step: 191400, training_loss: 6.06135e-04
I0513 00:39:48.955456 22485033404224 run_lib.py:167] step: 191400, eval_loss: 6.03277e-04
I0513 00:40:12.514421 22485033404224 run_lib.py:146] step: 191450, training_loss: 5.44977e-04
I0513 00:40:36.675537 22485033404224 run_lib.py:146] step: 191500, training_loss: 7.04597e-04
I0513 00:40:36.836284 22485033404224 run_lib.py:167] step: 191500, eval_loss: 5.05977e-04
I0513 00:41:00.405823 22485033404224 run_lib.py:146] step: 191550, training_loss: 6.04097e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 00:41:24.027412 22485033404224 run_lib.py:146] step: 191600, training_loss: 7.04093e-04
I0513 00:41:24.190496 22485033404224 run_lib.py:167] step: 191600, eval_loss: 5.01922e-04
I0513 00:41:48.058581 22485033404224 run_lib.py:146] step: 191650, training_loss: 6.39228e-04
I0513 00:42:11.937499 22485033404224 run_lib.py:146] step: 191700, training_loss: 5.55988e-04
I0513 00:42:12.097401 22485033404224 run_lib.py:167] step: 191700, eval_loss: 4.74747e-04
I0513 00:42:35.621973 22485033404224 run_lib.py:146] step: 191750, training_loss: 5.20086e-04
I0513 00:42:59.468999 22485033404224 run_lib.py:146] step: 191800, training_loss: 5.46009e-04
I0513 00:42:59.629455 22485033404224 run_lib.py:167] step: 191800, eval_loss: 6.54683e-04
I0513 00:43:23.510580 22485033404224 run_lib.py:146] step: 191850, training_loss: 7.66769e-04
I0513 00:43:47.087696 22485033404224 run_lib.py:146] step: 191900, training_loss: 6.73997e-04
I0513 00:43:47.247376 22485033404224 run_lib.py:167] step: 191900, eval_loss: 4.89860e-04
I0513 00:44:11.120077 22485033404224 run_lib.py:146] step: 191950, training_loss: 7.39889e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 00:44:35.027678 22485033404224 run_lib.py:146] step: 192000, training_loss: 6.49458e-04
I0513 00:44:35.189485 22485033404224 run_lib.py:167] step: 192000, eval_loss: 8.65594e-04
I0513 00:44:58.721406 22485033404224 run_lib.py:146] step: 192050, training_loss: 7.38225e-04
I0513 00:45:22.295094 22485033404224 run_lib.py:146] step: 192100, training_loss: 4.78948e-04
I0513 00:45:22.455346 22485033404224 run_lib.py:167] step: 192100, eval_loss: 4.74963e-04
I0513 00:45:46.679235 22485033404224 run_lib.py:146] step: 192150, training_loss: 6.61372e-04
I0513 00:46:10.215865 22485033404224 run_lib.py:146] step: 192200, training_loss: 6.98631e-04
I0513 00:46:10.375919 22485033404224 run_lib.py:167] step: 192200, eval_loss: 5.48449e-04
I0513 00:46:33.909019 22485033404224 run_lib.py:146] step: 192250, training_loss: 6.21556e-04
I0513 00:46:58.034354 22485033404224 run_lib.py:146] step: 192300, training_loss: 5.77780e-04
I0513 00:46:58.195007 22485033404224 run_lib.py:167] step: 192300, eval_loss: 5.05376e-04
I0513 00:47:21.722030 22485033404224 run_lib.py:146] step: 192350, training_loss: 5.16979e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 00:47:45.355541 22485033404224 run_lib.py:146] step: 192400, training_loss: 7.36027e-04
I0513 00:47:45.516018 22485033404224 run_lib.py:167] step: 192400, eval_loss: 7.14978e-04
I0513 00:48:09.407797 22485033404224 run_lib.py:146] step: 192450, training_loss: 6.09138e-04
I0513 00:48:33.295174 22485033404224 run_lib.py:146] step: 192500, training_loss: 6.41488e-04
I0513 00:48:33.455479 22485033404224 run_lib.py:167] step: 192500, eval_loss: 6.99202e-04
I0513 00:48:57.085190 22485033404224 run_lib.py:146] step: 192550, training_loss: 6.00986e-04
I0513 00:49:21.016982 22485033404224 run_lib.py:146] step: 192600, training_loss: 6.13124e-04
I0513 00:49:21.177974 22485033404224 run_lib.py:167] step: 192600, eval_loss: 8.19824e-04
I0513 00:49:45.133786 22485033404224 run_lib.py:146] step: 192650, training_loss: 7.80251e-04
I0513 00:50:08.777983 22485033404224 run_lib.py:146] step: 192700, training_loss: 5.40986e-04
I0513 00:50:08.937730 22485033404224 run_lib.py:167] step: 192700, eval_loss: 6.47513e-04
I0513 00:50:32.862711 22485033404224 run_lib.py:146] step: 192750, training_loss: 6.55823e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 00:50:57.016903 22485033404224 run_lib.py:146] step: 192800, training_loss: 4.59442e-04
I0513 00:50:57.180579 22485033404224 run_lib.py:167] step: 192800, eval_loss: 5.83078e-04
I0513 00:51:20.904168 22485033404224 run_lib.py:146] step: 192850, training_loss: 4.14835e-04
I0513 00:51:44.607499 22485033404224 run_lib.py:146] step: 192900, training_loss: 5.81763e-04
I0513 00:51:44.770087 22485033404224 run_lib.py:167] step: 192900, eval_loss: 6.99180e-04
I0513 00:52:09.251525 22485033404224 run_lib.py:146] step: 192950, training_loss: 5.67045e-04
I0513 00:52:32.983884 22485033404224 run_lib.py:146] step: 193000, training_loss: 6.65814e-04
I0513 00:52:33.145063 22485033404224 run_lib.py:167] step: 193000, eval_loss: 7.72562e-04
I0513 00:52:56.867002 22485033404224 run_lib.py:146] step: 193050, training_loss: 6.49675e-04
I0513 00:53:21.198271 22485033404224 run_lib.py:146] step: 193100, training_loss: 6.54499e-04
I0513 00:53:21.358929 22485033404224 run_lib.py:167] step: 193100, eval_loss: 6.14862e-04
I0513 00:53:44.944830 22485033404224 run_lib.py:146] step: 193150, training_loss: 6.22371e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 00:54:08.622461 22485033404224 run_lib.py:146] step: 193200, training_loss: 5.48933e-04
I0513 00:54:08.784288 22485033404224 run_lib.py:167] step: 193200, eval_loss: 5.64055e-04
I0513 00:54:33.253346 22485033404224 run_lib.py:146] step: 193250, training_loss: 8.06230e-04
I0513 00:54:56.905306 22485033404224 run_lib.py:146] step: 193300, training_loss: 5.87977e-04
I0513 00:54:57.066088 22485033404224 run_lib.py:167] step: 193300, eval_loss: 4.53261e-04
I0513 00:55:20.698819 22485033404224 run_lib.py:146] step: 193350, training_loss: 7.21930e-04
I0513 00:55:44.678771 22485033404224 run_lib.py:146] step: 193400, training_loss: 4.93819e-04
I0513 00:55:44.839192 22485033404224 run_lib.py:167] step: 193400, eval_loss: 4.31592e-04
I0513 00:56:08.745200 22485033404224 run_lib.py:146] step: 193450, training_loss: 5.62439e-04
I0513 00:56:32.257002 22485033404224 run_lib.py:146] step: 193500, training_loss: 5.47397e-04
I0513 00:56:32.417780 22485033404224 run_lib.py:167] step: 193500, eval_loss: 5.44720e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 00:56:56.331810 22485033404224 run_lib.py:146] step: 193550, training_loss: 5.98414e-04
I0513 00:57:20.214571 22485033404224 run_lib.py:146] step: 193600, training_loss: 4.30834e-04
I0513 00:57:20.374656 22485033404224 run_lib.py:167] step: 193600, eval_loss: 6.71821e-04
I0513 00:57:43.889429 22485033404224 run_lib.py:146] step: 193650, training_loss: 4.28729e-04
I0513 00:58:07.429796 22485033404224 run_lib.py:146] step: 193700, training_loss: 8.28683e-04
I0513 00:58:07.588482 22485033404224 run_lib.py:167] step: 193700, eval_loss: 6.21119e-04
I0513 00:58:31.721287 22485033404224 run_lib.py:146] step: 193750, training_loss: 5.68928e-04
I0513 00:58:55.236270 22485033404224 run_lib.py:146] step: 193800, training_loss: 5.33205e-04
I0513 00:58:55.395353 22485033404224 run_lib.py:167] step: 193800, eval_loss: 7.26325e-04
I0513 00:59:18.950638 22485033404224 run_lib.py:146] step: 193850, training_loss: 4.97527e-04
I0513 00:59:43.134242 22485033404224 run_lib.py:146] step: 193900, training_loss: 5.99048e-04
I0513 00:59:43.293624 22485033404224 run_lib.py:167] step: 193900, eval_loss: 5.07702e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 01:00:06.911320 22485033404224 run_lib.py:146] step: 193950, training_loss: 6.00238e-04
I0513 01:00:30.483194 22485033404224 run_lib.py:146] step: 194000, training_loss: 5.49746e-04
I0513 01:00:30.643864 22485033404224 run_lib.py:167] step: 194000, eval_loss: 6.21716e-04
I0513 01:00:54.865364 22485033404224 run_lib.py:146] step: 194050, training_loss: 6.29234e-04
I0513 01:01:18.412423 22485033404224 run_lib.py:146] step: 194100, training_loss: 6.40240e-04
I0513 01:01:18.571664 22485033404224 run_lib.py:167] step: 194100, eval_loss: 4.32271e-04
I0513 01:01:42.103277 22485033404224 run_lib.py:146] step: 194150, training_loss: 6.71864e-04
I0513 01:02:05.955358 22485033404224 run_lib.py:146] step: 194200, training_loss: 5.62958e-04
I0513 01:02:06.114481 22485033404224 run_lib.py:167] step: 194200, eval_loss: 5.72872e-04
I0513 01:02:29.953591 22485033404224 run_lib.py:146] step: 194250, training_loss: 5.92536e-04
I0513 01:02:53.501405 22485033404224 run_lib.py:146] step: 194300, training_loss: 6.21264e-04
I0513 01:02:53.660929 22485033404224 run_lib.py:167] step: 194300, eval_loss: 7.06120e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 01:03:17.614600 22485033404224 run_lib.py:146] step: 194350, training_loss: 7.76688e-04
I0513 01:03:41.508534 22485033404224 run_lib.py:146] step: 194400, training_loss: 5.08119e-04
I0513 01:03:41.669204 22485033404224 run_lib.py:167] step: 194400, eval_loss: 6.06420e-04
I0513 01:04:05.207333 22485033404224 run_lib.py:146] step: 194450, training_loss: 7.88275e-04
I0513 01:04:29.049418 22485033404224 run_lib.py:146] step: 194500, training_loss: 5.99115e-04
I0513 01:04:29.208537 22485033404224 run_lib.py:167] step: 194500, eval_loss: 5.21282e-04
I0513 01:04:53.053041 22485033404224 run_lib.py:146] step: 194550, training_loss: 5.72953e-04
I0513 01:05:16.579357 22485033404224 run_lib.py:146] step: 194600, training_loss: 7.25071e-04
I0513 01:05:16.740246 22485033404224 run_lib.py:167] step: 194600, eval_loss: 5.55238e-04
I0513 01:05:40.272070 22485033404224 run_lib.py:146] step: 194650, training_loss: 3.54950e-04
I0513 01:06:04.441663 22485033404224 run_lib.py:146] step: 194700, training_loss: 3.76720e-04
I0513 01:06:04.602777 22485033404224 run_lib.py:167] step: 194700, eval_loss: 5.03694e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 01:06:28.295250 22485033404224 run_lib.py:146] step: 194750, training_loss: 6.64136e-04
I0513 01:06:51.902315 22485033404224 run_lib.py:146] step: 194800, training_loss: 5.45295e-04
I0513 01:06:52.065329 22485033404224 run_lib.py:167] step: 194800, eval_loss: 8.37514e-04
I0513 01:07:16.374578 22485033404224 run_lib.py:146] step: 194850, training_loss: 6.81238e-04
I0513 01:07:39.971096 22485033404224 run_lib.py:146] step: 194900, training_loss: 5.59410e-04
I0513 01:07:40.131762 22485033404224 run_lib.py:167] step: 194900, eval_loss: 6.18715e-04
I0513 01:08:03.721315 22485033404224 run_lib.py:146] step: 194950, training_loss: 7.79759e-04
I0513 01:08:27.606974 22485033404224 run_lib.py:146] step: 195000, training_loss: 6.22113e-04
I0513 01:08:27.767765 22485033404224 run_lib.py:167] step: 195000, eval_loss: 5.56293e-04
I0513 01:08:51.641041 22485033404224 run_lib.py:146] step: 195050, training_loss: 6.69618e-04
I0513 01:09:15.279516 22485033404224 run_lib.py:146] step: 195100, training_loss: 8.64100e-04
I0513 01:09:15.440671 22485033404224 run_lib.py:167] step: 195100, eval_loss: 4.69879e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 01:09:39.466006 22485033404224 run_lib.py:146] step: 195150, training_loss: 6.45969e-04
I0513 01:10:03.530190 22485033404224 run_lib.py:146] step: 195200, training_loss: 7.43242e-04
I0513 01:10:03.692446 22485033404224 run_lib.py:167] step: 195200, eval_loss: 4.94868e-04
I0513 01:10:27.349182 22485033404224 run_lib.py:146] step: 195250, training_loss: 7.46912e-04
I0513 01:10:51.284742 22485033404224 run_lib.py:146] step: 195300, training_loss: 4.17178e-04
I0513 01:10:51.444486 22485033404224 run_lib.py:167] step: 195300, eval_loss: 6.30580e-04
I0513 01:11:15.468611 22485033404224 run_lib.py:146] step: 195350, training_loss: 6.13912e-04
I0513 01:11:39.119821 22485033404224 run_lib.py:146] step: 195400, training_loss: 5.56526e-04
I0513 01:11:39.280646 22485033404224 run_lib.py:167] step: 195400, eval_loss: 6.26023e-04
I0513 01:12:02.885380 22485033404224 run_lib.py:146] step: 195450, training_loss: 6.45993e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 01:12:27.219126 22485033404224 run_lib.py:146] step: 195500, training_loss: 5.48646e-04
I0513 01:12:27.381318 22485033404224 run_lib.py:167] step: 195500, eval_loss: 6.71043e-04
I0513 01:12:51.025540 22485033404224 run_lib.py:146] step: 195550, training_loss: 6.14203e-04
I0513 01:13:14.613708 22485033404224 run_lib.py:146] step: 195600, training_loss: 6.16106e-04
I0513 01:13:14.773370 22485033404224 run_lib.py:167] step: 195600, eval_loss: 5.51008e-04
I0513 01:13:39.031362 22485033404224 run_lib.py:146] step: 195650, training_loss: 7.78088e-04
I0513 01:14:02.602689 22485033404224 run_lib.py:146] step: 195700, training_loss: 6.00995e-04
I0513 01:14:02.762353 22485033404224 run_lib.py:167] step: 195700, eval_loss: 6.19116e-04
I0513 01:14:26.299094 22485033404224 run_lib.py:146] step: 195750, training_loss: 6.14117e-04
I0513 01:14:50.482625 22485033404224 run_lib.py:146] step: 195800, training_loss: 5.01487e-04
I0513 01:14:50.641637 22485033404224 run_lib.py:167] step: 195800, eval_loss: 7.62475e-04
I0513 01:15:14.172925 22485033404224 run_lib.py:146] step: 195850, training_loss: 4.80778e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 01:15:37.802659 22485033404224 run_lib.py:146] step: 195900, training_loss: 7.91766e-04
I0513 01:15:37.963817 22485033404224 run_lib.py:167] step: 195900, eval_loss: 5.44338e-04
I0513 01:16:01.862097 22485033404224 run_lib.py:146] step: 195950, training_loss: 8.42896e-04
I0513 01:16:25.768721 22485033404224 run_lib.py:146] step: 196000, training_loss: 6.87529e-04
I0513 01:16:25.928114 22485033404224 run_lib.py:167] step: 196000, eval_loss: 6.85518e-04
I0513 01:16:49.450088 22485033404224 run_lib.py:146] step: 196050, training_loss: 6.83481e-04
I0513 01:17:13.292655 22485033404224 run_lib.py:146] step: 196100, training_loss: 8.07918e-04
I0513 01:17:13.452866 22485033404224 run_lib.py:167] step: 196100, eval_loss: 7.71150e-04
I0513 01:17:37.281572 22485033404224 run_lib.py:146] step: 196150, training_loss: 5.68191e-04
I0513 01:18:00.807302 22485033404224 run_lib.py:146] step: 196200, training_loss: 7.39911e-04
I0513 01:18:00.968112 22485033404224 run_lib.py:167] step: 196200, eval_loss: 5.35219e-04
I0513 01:18:24.818763 22485033404224 run_lib.py:146] step: 196250, training_loss: 7.58045e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 01:18:48.737027 22485033404224 run_lib.py:146] step: 196300, training_loss: 5.07073e-04
I0513 01:18:48.898380 22485033404224 run_lib.py:167] step: 196300, eval_loss: 7.41667e-04
I0513 01:19:12.441914 22485033404224 run_lib.py:146] step: 196350, training_loss: 5.77116e-04
I0513 01:19:35.984354 22485033404224 run_lib.py:146] step: 196400, training_loss: 7.97134e-04
I0513 01:19:36.144363 22485033404224 run_lib.py:167] step: 196400, eval_loss: 4.58575e-04
I0513 01:20:00.338444 22485033404224 run_lib.py:146] step: 196450, training_loss: 5.62448e-04
I0513 01:20:23.872498 22485033404224 run_lib.py:146] step: 196500, training_loss: 6.62971e-04
I0513 01:20:24.031270 22485033404224 run_lib.py:167] step: 196500, eval_loss: 6.10399e-04
I0513 01:20:47.561503 22485033404224 run_lib.py:146] step: 196550, training_loss: 9.38016e-04
I0513 01:21:11.694515 22485033404224 run_lib.py:146] step: 196600, training_loss: 4.88925e-04
I0513 01:21:11.854483 22485033404224 run_lib.py:167] step: 196600, eval_loss: 6.33776e-04
I0513 01:21:35.387676 22485033404224 run_lib.py:146] step: 196650, training_loss: 7.86864e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 01:21:59.002798 22485033404224 run_lib.py:146] step: 196700, training_loss: 7.54997e-04
I0513 01:21:59.164201 22485033404224 run_lib.py:167] step: 196700, eval_loss: 6.82353e-04
I0513 01:22:23.039922 22485033404224 run_lib.py:146] step: 196750, training_loss: 6.38256e-04
I0513 01:22:46.921392 22485033404224 run_lib.py:146] step: 196800, training_loss: 6.09530e-04
I0513 01:22:47.081801 22485033404224 run_lib.py:167] step: 196800, eval_loss: 6.15898e-04
I0513 01:23:10.634378 22485033404224 run_lib.py:146] step: 196850, training_loss: 8.61771e-04
I0513 01:23:34.491181 22485033404224 run_lib.py:146] step: 196900, training_loss: 5.24723e-04
I0513 01:23:34.651477 22485033404224 run_lib.py:167] step: 196900, eval_loss: 8.53087e-04
I0513 01:23:58.549178 22485033404224 run_lib.py:146] step: 196950, training_loss: 6.30288e-04
I0513 01:24:22.158966 22485033404224 run_lib.py:146] step: 197000, training_loss: 6.79328e-04
I0513 01:24:22.320515 22485033404224 run_lib.py:167] step: 197000, eval_loss: 6.69347e-04
I0513 01:24:46.222673 22485033404224 run_lib.py:146] step: 197050, training_loss: 7.63638e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 01:25:10.306822 22485033404224 run_lib.py:146] step: 197100, training_loss: 5.68593e-04
I0513 01:25:10.468639 22485033404224 run_lib.py:167] step: 197100, eval_loss: 6.67140e-04
I0513 01:25:34.055584 22485033404224 run_lib.py:146] step: 197150, training_loss: 7.40642e-04
I0513 01:25:57.654345 22485033404224 run_lib.py:146] step: 197200, training_loss: 7.35157e-04
I0513 01:25:57.815542 22485033404224 run_lib.py:167] step: 197200, eval_loss: 7.11920e-04
I0513 01:26:21.995306 22485033404224 run_lib.py:146] step: 197250, training_loss: 5.80804e-04
I0513 01:26:45.545195 22485033404224 run_lib.py:146] step: 197300, training_loss: 7.76963e-04
I0513 01:26:45.703539 22485033404224 run_lib.py:167] step: 197300, eval_loss: 5.25020e-04
I0513 01:27:09.250038 22485033404224 run_lib.py:146] step: 197350, training_loss: 6.15981e-04
I0513 01:27:33.407062 22485033404224 run_lib.py:146] step: 197400, training_loss: 6.59306e-04
I0513 01:27:33.491921 22485033404224 run_lib.py:167] step: 197400, eval_loss: 4.70975e-04
I0513 01:27:57.070020 22485033404224 run_lib.py:146] step: 197450, training_loss: 5.42915e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 01:28:20.741166 22485033404224 run_lib.py:146] step: 197500, training_loss: 4.94426e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 01:28:21.087983 22485033404224 run_lib.py:167] step: 197500, eval_loss: 6.04752e-04
I0513 01:28:44.996220 22485033404224 run_lib.py:146] step: 197550, training_loss: 5.60533e-04
I0513 01:29:09.029146 22485033404224 run_lib.py:146] step: 197600, training_loss: 7.08274e-04
I0513 01:29:09.189259 22485033404224 run_lib.py:167] step: 197600, eval_loss: 6.58995e-04
I0513 01:29:32.769035 22485033404224 run_lib.py:146] step: 197650, training_loss: 6.92830e-04
I0513 01:29:56.663936 22485033404224 run_lib.py:146] step: 197700, training_loss: 5.32978e-04
I0513 01:29:56.824266 22485033404224 run_lib.py:167] step: 197700, eval_loss: 5.50009e-04
I0513 01:30:20.798892 22485033404224 run_lib.py:146] step: 197750, training_loss: 7.31131e-04
I0513 01:30:44.425235 22485033404224 run_lib.py:146] step: 197800, training_loss: 4.97057e-04
I0513 01:30:44.585783 22485033404224 run_lib.py:167] step: 197800, eval_loss: 6.70330e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 01:31:08.589049 22485033404224 run_lib.py:146] step: 197850, training_loss: 4.86087e-04
I0513 01:31:32.602433 22485033404224 run_lib.py:146] step: 197900, training_loss: 5.17390e-04
I0513 01:31:32.763306 22485033404224 run_lib.py:167] step: 197900, eval_loss: 5.56826e-04
I0513 01:31:56.289602 22485033404224 run_lib.py:146] step: 197950, training_loss: 5.83003e-04
I0513 01:32:19.879383 22485033404224 run_lib.py:146] step: 198000, training_loss: 6.53338e-04
I0513 01:32:20.039016 22485033404224 run_lib.py:167] step: 198000, eval_loss: 6.30165e-04
I0513 01:32:44.187768 22485033404224 run_lib.py:146] step: 198050, training_loss: 6.65016e-04
I0513 01:33:07.763090 22485033404224 run_lib.py:146] step: 198100, training_loss: 6.24197e-04
I0513 01:33:07.924126 22485033404224 run_lib.py:167] step: 198100, eval_loss: 7.66208e-04
I0513 01:33:31.462685 22485033404224 run_lib.py:146] step: 198150, training_loss: 5.21729e-04
I0513 01:33:55.602699 22485033404224 run_lib.py:146] step: 198200, training_loss: 5.47368e-04
I0513 01:33:55.761260 22485033404224 run_lib.py:167] step: 198200, eval_loss: 6.30678e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 01:34:19.374839 22485033404224 run_lib.py:146] step: 198250, training_loss: 6.65329e-04
I0513 01:34:42.923821 22485033404224 run_lib.py:146] step: 198300, training_loss: 6.07489e-04
I0513 01:34:43.085157 22485033404224 run_lib.py:167] step: 198300, eval_loss: 4.40570e-04
I0513 01:35:07.282925 22485033404224 run_lib.py:146] step: 198350, training_loss: 5.45477e-04
I0513 01:35:30.832852 22485033404224 run_lib.py:146] step: 198400, training_loss: 7.00207e-04
I0513 01:35:30.991894 22485033404224 run_lib.py:167] step: 198400, eval_loss: 4.06705e-04
I0513 01:35:54.528439 22485033404224 run_lib.py:146] step: 198450, training_loss: 6.23344e-04
I0513 01:36:18.353450 22485033404224 run_lib.py:146] step: 198500, training_loss: 7.24798e-04
I0513 01:36:18.512809 22485033404224 run_lib.py:167] step: 198500, eval_loss: 6.91358e-04
I0513 01:36:42.321968 22485033404224 run_lib.py:146] step: 198550, training_loss: 6.84786e-04
I0513 01:37:05.866206 22485033404224 run_lib.py:146] step: 198600, training_loss: 6.34512e-04
I0513 01:37:06.025072 22485033404224 run_lib.py:167] step: 198600, eval_loss: 6.19622e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 01:37:29.975824 22485033404224 run_lib.py:146] step: 198650, training_loss: 5.99092e-04
I0513 01:37:53.857114 22485033404224 run_lib.py:146] step: 198700, training_loss: 4.91807e-04
I0513 01:37:54.018022 22485033404224 run_lib.py:167] step: 198700, eval_loss: 6.41811e-04
I0513 01:38:17.584408 22485033404224 run_lib.py:146] step: 198750, training_loss: 8.94183e-04
I0513 01:38:41.449092 22485033404224 run_lib.py:146] step: 198800, training_loss: 4.25043e-04
I0513 01:38:41.608910 22485033404224 run_lib.py:167] step: 198800, eval_loss: 5.07454e-04
I0513 01:39:05.458999 22485033404224 run_lib.py:146] step: 198850, training_loss: 6.83971e-04
I0513 01:39:29.000618 22485033404224 run_lib.py:146] step: 198900, training_loss: 6.54110e-04
I0513 01:39:29.160286 22485033404224 run_lib.py:167] step: 198900, eval_loss: 4.76085e-04
I0513 01:39:52.676750 22485033404224 run_lib.py:146] step: 198950, training_loss: 6.97231e-04
I0513 01:40:16.870996 22485033404224 run_lib.py:146] step: 199000, training_loss: 5.83585e-04
I0513 01:40:17.031862 22485033404224 run_lib.py:167] step: 199000, eval_loss: 6.23600e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 01:40:40.644464 22485033404224 run_lib.py:146] step: 199050, training_loss: 7.68713e-04
I0513 01:41:04.196105 22485033404224 run_lib.py:146] step: 199100, training_loss: 7.54722e-04
I0513 01:41:04.358693 22485033404224 run_lib.py:167] step: 199100, eval_loss: 4.24557e-04
I0513 01:41:28.571531 22485033404224 run_lib.py:146] step: 199150, training_loss: 7.25682e-04
I0513 01:41:52.115291 22485033404224 run_lib.py:146] step: 199200, training_loss: 6.62912e-04
I0513 01:41:52.276496 22485033404224 run_lib.py:167] step: 199200, eval_loss: 3.86539e-04
I0513 01:42:15.848470 22485033404224 run_lib.py:146] step: 199250, training_loss: 6.47966e-04
I0513 01:42:39.775244 22485033404224 run_lib.py:146] step: 199300, training_loss: 5.24509e-04
I0513 01:42:39.935708 22485033404224 run_lib.py:167] step: 199300, eval_loss: 5.20487e-04
I0513 01:43:03.849071 22485033404224 run_lib.py:146] step: 199350, training_loss: 5.84792e-04
I0513 01:43:27.466859 22485033404224 run_lib.py:146] step: 199400, training_loss: 7.93935e-04
I0513 01:43:27.627057 22485033404224 run_lib.py:167] step: 199400, eval_loss: 5.59962e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 01:43:51.681912 22485033404224 run_lib.py:146] step: 199450, training_loss: 4.35818e-04
I0513 01:44:15.749897 22485033404224 run_lib.py:146] step: 199500, training_loss: 5.59603e-04
I0513 01:44:15.913225 22485033404224 run_lib.py:167] step: 199500, eval_loss: 6.84093e-04
I0513 01:44:39.498236 22485033404224 run_lib.py:146] step: 199550, training_loss: 6.74156e-04
I0513 01:45:03.413205 22485033404224 run_lib.py:146] step: 199600, training_loss: 6.45410e-04
I0513 01:45:03.573004 22485033404224 run_lib.py:167] step: 199600, eval_loss: 5.86778e-04
I0513 01:45:27.580711 22485033404224 run_lib.py:146] step: 199650, training_loss: 4.35021e-04
I0513 01:45:51.210810 22485033404224 run_lib.py:146] step: 199700, training_loss: 6.00972e-04
I0513 01:45:51.370818 22485033404224 run_lib.py:167] step: 199700, eval_loss: 5.56103e-04
I0513 01:46:15.316231 22485033404224 run_lib.py:146] step: 199750, training_loss: 6.73573e-04
I0513 01:46:39.218061 22485033404224 run_lib.py:146] step: 199800, training_loss: 7.76466e-04
I0513 01:46:39.379144 22485033404224 run_lib.py:167] step: 199800, eval_loss: 4.60328e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 01:47:03.140315 22485033404224 run_lib.py:146] step: 199850, training_loss: 8.01918e-04
I0513 01:47:26.768679 22485033404224 run_lib.py:146] step: 199900, training_loss: 7.28922e-04
I0513 01:47:26.931223 22485033404224 run_lib.py:167] step: 199900, eval_loss: 5.79292e-04
I0513 01:47:51.310719 22485033404224 run_lib.py:146] step: 199950, training_loss: 6.65261e-04
I0513 01:48:14.917377 22485033404224 run_lib.py:146] step: 200000, training_loss: 5.58164e-04
I0513 01:48:16.714202 22485033404224 run_lib.py:167] step: 200000, eval_loss: 6.38672e-04
I0513 01:48:41.848741 22485033404224 run_lib.py:146] step: 200050, training_loss: 5.72574e-04
I0513 01:49:06.182290 22485033404224 run_lib.py:146] step: 200100, training_loss: 6.06090e-04
I0513 01:49:06.342102 22485033404224 run_lib.py:167] step: 200100, eval_loss: 5.13893e-04
I0513 01:49:29.962080 22485033404224 run_lib.py:146] step: 200150, training_loss: 4.98392e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 01:49:53.621229 22485033404224 run_lib.py:146] step: 200200, training_loss: 6.28635e-04
I0513 01:49:53.783601 22485033404224 run_lib.py:167] step: 200200, eval_loss: 6.02568e-04
I0513 01:50:17.997658 22485033404224 run_lib.py:146] step: 200250, training_loss: 7.54112e-04
I0513 01:50:41.562005 22485033404224 run_lib.py:146] step: 200300, training_loss: 6.39707e-04
I0513 01:50:41.721740 22485033404224 run_lib.py:167] step: 200300, eval_loss: 6.16287e-04
I0513 01:51:05.254169 22485033404224 run_lib.py:146] step: 200350, training_loss: 6.86157e-04
I0513 01:51:29.385386 22485033404224 run_lib.py:146] step: 200400, training_loss: 5.64669e-04
I0513 01:51:29.545132 22485033404224 run_lib.py:167] step: 200400, eval_loss: 5.26488e-04
I0513 01:51:53.107896 22485033404224 run_lib.py:146] step: 200450, training_loss: 5.50570e-04
I0513 01:52:16.649447 22485033404224 run_lib.py:146] step: 200500, training_loss: 5.37710e-04
I0513 01:52:16.809160 22485033404224 run_lib.py:167] step: 200500, eval_loss: 6.21298e-04
I0513 01:52:40.933185 22485033404224 run_lib.py:146] step: 200550, training_loss: 4.78960e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 01:53:04.535088 22485033404224 run_lib.py:146] step: 200600, training_loss: 5.55258e-04
I0513 01:53:04.696653 22485033404224 run_lib.py:167] step: 200600, eval_loss: 3.69399e-04
I0513 01:53:28.268796 22485033404224 run_lib.py:146] step: 200650, training_loss: 6.52211e-04
I0513 01:53:52.152471 22485033404224 run_lib.py:146] step: 200700, training_loss: 8.18259e-04
I0513 01:53:52.312580 22485033404224 run_lib.py:167] step: 200700, eval_loss: 5.44662e-04
I0513 01:54:16.182572 22485033404224 run_lib.py:146] step: 200750, training_loss: 7.19578e-04
I0513 01:54:39.692589 22485033404224 run_lib.py:146] step: 200800, training_loss: 5.06328e-04
I0513 01:54:39.851286 22485033404224 run_lib.py:167] step: 200800, eval_loss: 8.14736e-04
I0513 01:55:03.397376 22485033404224 run_lib.py:146] step: 200850, training_loss: 6.10423e-04
I0513 01:55:27.491061 22485033404224 run_lib.py:146] step: 200900, training_loss: 5.63145e-04
I0513 01:55:27.651260 22485033404224 run_lib.py:167] step: 200900, eval_loss: 6.87215e-04
I0513 01:55:51.198406 22485033404224 run_lib.py:146] step: 200950, training_loss: 6.39839e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 01:56:14.823432 22485033404224 run_lib.py:146] step: 201000, training_loss: 6.71935e-04
I0513 01:56:14.986176 22485033404224 run_lib.py:167] step: 201000, eval_loss: 5.23316e-04
I0513 01:56:39.250772 22485033404224 run_lib.py:146] step: 201050, training_loss: 6.08428e-04
I0513 01:57:02.789047 22485033404224 run_lib.py:146] step: 201100, training_loss: 7.11779e-04
I0513 01:57:02.947923 22485033404224 run_lib.py:167] step: 201100, eval_loss: 5.29106e-04
I0513 01:57:26.480244 22485033404224 run_lib.py:146] step: 201150, training_loss: 6.97984e-04
I0513 01:57:50.618010 22485033404224 run_lib.py:146] step: 201200, training_loss: 5.00771e-04
I0513 01:57:50.778635 22485033404224 run_lib.py:167] step: 201200, eval_loss: 5.63731e-04
I0513 01:58:14.318746 22485033404224 run_lib.py:146] step: 201250, training_loss: 6.44443e-04
I0513 01:58:37.832763 22485033404224 run_lib.py:146] step: 201300, training_loss: 6.85430e-04
I0513 01:58:37.991627 22485033404224 run_lib.py:167] step: 201300, eval_loss: 7.18127e-04
I0513 01:59:02.087118 22485033404224 run_lib.py:146] step: 201350, training_loss: 4.92964e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 01:59:25.698371 22485033404224 run_lib.py:146] step: 201400, training_loss: 6.27015e-04
I0513 01:59:25.859955 22485033404224 run_lib.py:167] step: 201400, eval_loss: 6.08144e-04
I0513 01:59:49.411084 22485033404224 run_lib.py:146] step: 201450, training_loss: 6.17480e-04
I0513 02:00:13.328614 22485033404224 run_lib.py:146] step: 201500, training_loss: 4.77407e-04
I0513 02:00:13.489317 22485033404224 run_lib.py:167] step: 201500, eval_loss: 6.59118e-04
I0513 02:00:37.401679 22485033404224 run_lib.py:146] step: 201550, training_loss: 5.68216e-04
I0513 02:01:01.021332 22485033404224 run_lib.py:146] step: 201600, training_loss: 5.68028e-04
I0513 02:01:01.181580 22485033404224 run_lib.py:167] step: 201600, eval_loss: 5.69045e-04
I0513 02:01:24.789644 22485033404224 run_lib.py:146] step: 201650, training_loss: 6.94857e-04
I0513 02:01:58.672145 22485033404224 run_lib.py:146] step: 201700, training_loss: 7.29941e-04
I0513 02:01:58.832680 22485033404224 run_lib.py:167] step: 201700, eval_loss: 6.27426e-04
I0513 02:02:22.433125 22485033404224 run_lib.py:146] step: 201750, training_loss: 5.97633e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 02:02:46.104291 22485033404224 run_lib.py:146] step: 201800, training_loss: 5.28935e-04
I0513 02:02:46.266939 22485033404224 run_lib.py:167] step: 201800, eval_loss: 5.30091e-04
I0513 02:03:10.615242 22485033404224 run_lib.py:146] step: 201850, training_loss: 6.07384e-04
I0513 02:03:34.170003 22485033404224 run_lib.py:146] step: 201900, training_loss: 5.99495e-04
I0513 02:03:34.330195 22485033404224 run_lib.py:167] step: 201900, eval_loss: 7.42983e-04
I0513 02:03:57.919742 22485033404224 run_lib.py:146] step: 201950, training_loss: 6.21214e-04
I0513 02:04:22.214384 22485033404224 run_lib.py:146] step: 202000, training_loss: 6.34160e-04
I0513 02:04:22.374805 22485033404224 run_lib.py:167] step: 202000, eval_loss: 7.45830e-04
I0513 02:04:45.977518 22485033404224 run_lib.py:146] step: 202050, training_loss: 7.61705e-04
I0513 02:05:09.582625 22485033404224 run_lib.py:146] step: 202100, training_loss: 5.43131e-04
I0513 02:05:09.742259 22485033404224 run_lib.py:167] step: 202100, eval_loss: 5.26719e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 02:05:34.088781 22485033404224 run_lib.py:146] step: 202150, training_loss: 6.26659e-04
I0513 02:05:57.711431 22485033404224 run_lib.py:146] step: 202200, training_loss: 5.92541e-04
I0513 02:05:57.873239 22485033404224 run_lib.py:167] step: 202200, eval_loss: 7.51925e-04
I0513 02:06:21.515821 22485033404224 run_lib.py:146] step: 202250, training_loss: 4.66826e-04
I0513 02:06:46.040168 22485033404224 run_lib.py:146] step: 202300, training_loss: 6.56867e-04
I0513 02:06:46.199568 22485033404224 run_lib.py:167] step: 202300, eval_loss: 5.39865e-04
I0513 02:07:09.814000 22485033404224 run_lib.py:146] step: 202350, training_loss: 6.49344e-04
I0513 02:07:33.471876 22485033404224 run_lib.py:146] step: 202400, training_loss: 4.43240e-04
I0513 02:07:33.632372 22485033404224 run_lib.py:167] step: 202400, eval_loss: 5.64223e-04
I0513 02:07:57.621887 22485033404224 run_lib.py:146] step: 202450, training_loss: 5.77780e-04
I0513 02:08:21.576483 22485033404224 run_lib.py:146] step: 202500, training_loss: 4.33635e-04
I0513 02:08:21.735425 22485033404224 run_lib.py:167] step: 202500, eval_loss: 5.38595e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 02:08:45.364549 22485033404224 run_lib.py:146] step: 202550, training_loss: 7.56762e-04
I0513 02:09:08.925162 22485033404224 run_lib.py:146] step: 202600, training_loss: 8.71694e-04
I0513 02:09:09.085360 22485033404224 run_lib.py:167] step: 202600, eval_loss: 5.61798e-04
I0513 02:09:33.416904 22485033404224 run_lib.py:146] step: 202650, training_loss: 6.29855e-04
I0513 02:09:56.957222 22485033404224 run_lib.py:146] step: 202700, training_loss: 7.05092e-04
I0513 02:09:57.117943 22485033404224 run_lib.py:167] step: 202700, eval_loss: 6.97486e-04
I0513 02:10:20.660215 22485033404224 run_lib.py:146] step: 202750, training_loss: 4.52278e-04
I0513 02:10:44.813834 22485033404224 run_lib.py:146] step: 202800, training_loss: 6.46085e-04
I0513 02:10:44.972727 22485033404224 run_lib.py:167] step: 202800, eval_loss: 5.24400e-04
I0513 02:11:08.521207 22485033404224 run_lib.py:146] step: 202850, training_loss: 6.83659e-04
I0513 02:11:32.047441 22485033404224 run_lib.py:146] step: 202900, training_loss: 8.85679e-04
I0513 02:11:32.206079 22485033404224 run_lib.py:167] step: 202900, eval_loss: 4.87869e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 02:11:56.478090 22485033404224 run_lib.py:146] step: 202950, training_loss: 6.39352e-04
I0513 02:12:19.998973 22485033404224 run_lib.py:146] step: 203000, training_loss: 6.47000e-04
I0513 02:12:20.159870 22485033404224 run_lib.py:167] step: 203000, eval_loss: 8.00181e-04
I0513 02:12:43.673777 22485033404224 run_lib.py:146] step: 203050, training_loss: 5.49338e-04
I0513 02:13:07.851346 22485033404224 run_lib.py:146] step: 203100, training_loss: 5.71169e-04
I0513 02:13:08.011935 22485033404224 run_lib.py:167] step: 203100, eval_loss: 4.80932e-04
I0513 02:13:31.550923 22485033404224 run_lib.py:146] step: 203150, training_loss: 6.34263e-04
I0513 02:13:55.072687 22485033404224 run_lib.py:146] step: 203200, training_loss: 6.59023e-04
I0513 02:13:55.232834 22485033404224 run_lib.py:167] step: 203200, eval_loss: 7.42452e-04
I0513 02:14:19.092307 22485033404224 run_lib.py:146] step: 203250, training_loss: 7.00003e-04
I0513 02:14:42.943669 22485033404224 run_lib.py:146] step: 203300, training_loss: 5.17711e-04
I0513 02:14:43.103488 22485033404224 run_lib.py:167] step: 203300, eval_loss: 6.84828e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 02:15:06.733797 22485033404224 run_lib.py:146] step: 203350, training_loss: 5.97955e-04
I0513 02:15:30.252294 22485033404224 run_lib.py:146] step: 203400, training_loss: 7.24846e-04
I0513 02:15:30.412740 22485033404224 run_lib.py:167] step: 203400, eval_loss: 4.95260e-04
I0513 02:15:54.616729 22485033404224 run_lib.py:146] step: 203450, training_loss: 6.49878e-04
I0513 02:16:18.127757 22485033404224 run_lib.py:146] step: 203500, training_loss: 6.60356e-04
I0513 02:16:18.286824 22485033404224 run_lib.py:167] step: 203500, eval_loss: 7.14972e-04
I0513 02:16:41.838560 22485033404224 run_lib.py:146] step: 203550, training_loss: 6.49563e-04
I0513 02:17:05.970417 22485033404224 run_lib.py:146] step: 203600, training_loss: 5.12207e-04
I0513 02:17:06.131265 22485033404224 run_lib.py:167] step: 203600, eval_loss: 7.67641e-04
I0513 02:17:29.684194 22485033404224 run_lib.py:146] step: 203650, training_loss: 6.38497e-04
I0513 02:17:53.230531 22485033404224 run_lib.py:146] step: 203700, training_loss: 6.14328e-04
I0513 02:17:53.389492 22485033404224 run_lib.py:167] step: 203700, eval_loss: 5.16475e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 02:18:17.729772 22485033404224 run_lib.py:146] step: 203750, training_loss: 5.49731e-04
I0513 02:18:41.328631 22485033404224 run_lib.py:146] step: 203800, training_loss: 6.53784e-04
I0513 02:18:41.490082 22485033404224 run_lib.py:167] step: 203800, eval_loss: 5.70420e-04
I0513 02:19:05.120115 22485033404224 run_lib.py:146] step: 203850, training_loss: 5.44810e-04
I0513 02:19:29.355719 22485033404224 run_lib.py:146] step: 203900, training_loss: 5.90882e-04
I0513 02:19:29.516064 22485033404224 run_lib.py:167] step: 203900, eval_loss: 5.96992e-04
I0513 02:19:53.110358 22485033404224 run_lib.py:146] step: 203950, training_loss: 6.89118e-04
I0513 02:20:16.739045 22485033404224 run_lib.py:146] step: 204000, training_loss: 5.28807e-04
I0513 02:20:16.900301 22485033404224 run_lib.py:167] step: 204000, eval_loss: 7.06160e-04
I0513 02:20:40.836879 22485033404224 run_lib.py:146] step: 204050, training_loss: 7.26896e-04
I0513 02:21:04.735390 22485033404224 run_lib.py:146] step: 204100, training_loss: 6.24432e-04
I0513 02:21:04.895404 22485033404224 run_lib.py:167] step: 204100, eval_loss: 5.03730e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 02:21:28.683027 22485033404224 run_lib.py:146] step: 204150, training_loss: 7.37770e-04
I0513 02:21:52.371781 22485033404224 run_lib.py:146] step: 204200, training_loss: 6.60831e-04
I0513 02:21:52.534359 22485033404224 run_lib.py:167] step: 204200, eval_loss: 5.52829e-04
I0513 02:22:17.160496 22485033404224 run_lib.py:146] step: 204250, training_loss: 6.59272e-04
I0513 02:22:40.883359 22485033404224 run_lib.py:146] step: 204300, training_loss: 6.51250e-04
I0513 02:22:41.046828 22485033404224 run_lib.py:167] step: 204300, eval_loss: 5.05742e-04
I0513 02:23:04.766949 22485033404224 run_lib.py:146] step: 204350, training_loss: 5.78008e-04
I0513 02:23:29.241760 22485033404224 run_lib.py:146] step: 204400, training_loss: 6.25598e-04
I0513 02:23:29.402574 22485033404224 run_lib.py:167] step: 204400, eval_loss: 7.70383e-04
I0513 02:23:53.022284 22485033404224 run_lib.py:146] step: 204450, training_loss: 5.87885e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 02:24:16.745952 22485033404224 run_lib.py:146] step: 204500, training_loss: 6.64538e-04
I0513 02:24:16.911077 22485033404224 run_lib.py:167] step: 204500, eval_loss: 6.84078e-04
I0513 02:24:41.595885 22485033404224 run_lib.py:146] step: 204550, training_loss: 6.19504e-04
I0513 02:25:05.275343 22485033404224 run_lib.py:146] step: 204600, training_loss: 6.58978e-04
I0513 02:25:05.437569 22485033404224 run_lib.py:167] step: 204600, eval_loss: 5.28198e-04
I0513 02:25:29.148902 22485033404224 run_lib.py:146] step: 204650, training_loss: 5.89278e-04
I0513 02:25:53.617109 22485033404224 run_lib.py:146] step: 204700, training_loss: 6.29534e-04
I0513 02:25:53.777197 22485033404224 run_lib.py:167] step: 204700, eval_loss: 6.15236e-04
I0513 02:26:17.341925 22485033404224 run_lib.py:146] step: 204750, training_loss: 5.57901e-04
I0513 02:26:40.884484 22485033404224 run_lib.py:146] step: 204800, training_loss: 6.37984e-04
I0513 02:26:41.044217 22485033404224 run_lib.py:167] step: 204800, eval_loss: 5.43756e-04
I0513 02:27:04.862692 22485033404224 run_lib.py:146] step: 204850, training_loss: 4.96856e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 02:27:28.462989 22485033404224 run_lib.py:146] step: 204900, training_loss: 6.02742e-04
I0513 02:27:28.626384 22485033404224 run_lib.py:167] step: 204900, eval_loss: 7.02834e-04
I0513 02:27:52.144762 22485033404224 run_lib.py:146] step: 204950, training_loss: 5.58785e-04
I0513 02:28:15.684622 22485033404224 run_lib.py:146] step: 205000, training_loss: 5.91767e-04
I0513 02:28:15.845763 22485033404224 run_lib.py:167] step: 205000, eval_loss: 5.96798e-04
I0513 02:28:40.023962 22485033404224 run_lib.py:146] step: 205050, training_loss: 7.79214e-04
I0513 02:29:03.547472 22485033404224 run_lib.py:146] step: 205100, training_loss: 5.94667e-04
I0513 02:29:03.706499 22485033404224 run_lib.py:167] step: 205100, eval_loss: 5.61078e-04
I0513 02:29:27.238071 22485033404224 run_lib.py:146] step: 205150, training_loss: 6.66502e-04
I0513 02:29:51.382130 22485033404224 run_lib.py:146] step: 205200, training_loss: 7.68416e-04
I0513 02:29:51.540747 22485033404224 run_lib.py:167] step: 205200, eval_loss: 6.82028e-04
I0513 02:30:15.074859 22485033404224 run_lib.py:146] step: 205250, training_loss: 5.40403e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 02:30:38.658928 22485033404224 run_lib.py:146] step: 205300, training_loss: 5.90854e-04
I0513 02:30:38.744337 22485033404224 run_lib.py:167] step: 205300, eval_loss: 6.87998e-04
I0513 02:31:02.638947 22485033404224 run_lib.py:146] step: 205350, training_loss: 5.66489e-04
I0513 02:31:26.177737 22485033404224 run_lib.py:146] step: 205400, training_loss: 7.54268e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 02:31:26.527744 22485033404224 run_lib.py:167] step: 205400, eval_loss: 6.57660e-04
I0513 02:31:50.053731 22485033404224 run_lib.py:146] step: 205450, training_loss: 8.76344e-04
I0513 02:32:14.292995 22485033404224 run_lib.py:146] step: 205500, training_loss: 7.36019e-04
I0513 02:32:14.452072 22485033404224 run_lib.py:167] step: 205500, eval_loss: 4.47690e-04
I0513 02:32:37.976700 22485033404224 run_lib.py:146] step: 205550, training_loss: 6.79885e-04
I0513 02:33:01.525173 22485033404224 run_lib.py:146] step: 205600, training_loss: 5.81570e-04
I0513 02:33:01.684738 22485033404224 run_lib.py:167] step: 205600, eval_loss: 3.71695e-04
I0513 02:33:25.817181 22485033404224 run_lib.py:146] step: 205650, training_loss: 6.02030e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 02:33:49.423568 22485033404224 run_lib.py:146] step: 205700, training_loss: 5.51647e-04
I0513 02:33:49.586106 22485033404224 run_lib.py:167] step: 205700, eval_loss: 5.62706e-04
I0513 02:34:13.100311 22485033404224 run_lib.py:146] step: 205750, training_loss: 7.66473e-04
I0513 02:34:36.987574 22485033404224 run_lib.py:146] step: 205800, training_loss: 5.32020e-04
I0513 02:34:37.147597 22485033404224 run_lib.py:167] step: 205800, eval_loss: 5.06882e-04
I0513 02:35:00.990555 22485033404224 run_lib.py:146] step: 205850, training_loss: 7.29607e-04
I0513 02:35:24.521643 22485033404224 run_lib.py:146] step: 205900, training_loss: 6.43301e-04
I0513 02:35:24.681967 22485033404224 run_lib.py:167] step: 205900, eval_loss: 6.23844e-04
I0513 02:35:48.230077 22485033404224 run_lib.py:146] step: 205950, training_loss: 6.54761e-04
I0513 02:36:12.360196 22485033404224 run_lib.py:146] step: 206000, training_loss: 3.59994e-04
I0513 02:36:12.519513 22485033404224 run_lib.py:167] step: 206000, eval_loss: 8.80206e-04
I0513 02:36:36.081127 22485033404224 run_lib.py:146] step: 206050, training_loss: 4.49337e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 02:36:59.745317 22485033404224 run_lib.py:146] step: 206100, training_loss: 6.54104e-04
I0513 02:36:59.907413 22485033404224 run_lib.py:167] step: 206100, eval_loss: 8.22130e-04
I0513 02:37:24.209449 22485033404224 run_lib.py:146] step: 206150, training_loss: 6.46755e-04
I0513 02:37:47.829136 22485033404224 run_lib.py:146] step: 206200, training_loss: 6.36498e-04
I0513 02:37:47.989367 22485033404224 run_lib.py:167] step: 206200, eval_loss: 5.70996e-04
I0513 02:38:11.579489 22485033404224 run_lib.py:146] step: 206250, training_loss: 6.95399e-04
I0513 02:38:35.800462 22485033404224 run_lib.py:146] step: 206300, training_loss: 4.52963e-04
I0513 02:38:35.960933 22485033404224 run_lib.py:167] step: 206300, eval_loss: 8.23040e-04
I0513 02:38:59.592188 22485033404224 run_lib.py:146] step: 206350, training_loss: 5.98448e-04
I0513 02:39:23.201891 22485033404224 run_lib.py:146] step: 206400, training_loss: 5.00598e-04
I0513 02:39:23.362278 22485033404224 run_lib.py:167] step: 206400, eval_loss: 6.28766e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 02:39:47.644324 22485033404224 run_lib.py:146] step: 206450, training_loss: 6.39026e-04
I0513 02:40:11.304722 22485033404224 run_lib.py:146] step: 206500, training_loss: 7.38851e-04
I0513 02:40:11.466656 22485033404224 run_lib.py:167] step: 206500, eval_loss: 6.19233e-04
I0513 02:40:35.125709 22485033404224 run_lib.py:146] step: 206550, training_loss: 4.68602e-04
I0513 02:40:59.150516 22485033404224 run_lib.py:146] step: 206600, training_loss: 6.76102e-04
I0513 02:40:59.311682 22485033404224 run_lib.py:167] step: 206600, eval_loss: 5.96353e-04
I0513 02:41:23.259306 22485033404224 run_lib.py:146] step: 206650, training_loss: 6.76235e-04
I0513 02:41:46.858079 22485033404224 run_lib.py:146] step: 206700, training_loss: 4.75964e-04
I0513 02:41:47.019037 22485033404224 run_lib.py:167] step: 206700, eval_loss: 6.27598e-04
I0513 02:42:10.634303 22485033404224 run_lib.py:146] step: 206750, training_loss: 8.34604e-04
I0513 02:42:34.879660 22485033404224 run_lib.py:146] step: 206800, training_loss: 5.41626e-04
I0513 02:42:35.039849 22485033404224 run_lib.py:167] step: 206800, eval_loss: 7.19691e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 02:42:58.727303 22485033404224 run_lib.py:146] step: 206850, training_loss: 5.44329e-04
I0513 02:43:22.385453 22485033404224 run_lib.py:146] step: 206900, training_loss: 6.50734e-04
I0513 02:43:22.547390 22485033404224 run_lib.py:167] step: 206900, eval_loss: 1.03681e-03
I0513 02:43:46.937936 22485033404224 run_lib.py:146] step: 206950, training_loss: 5.10214e-04
I0513 02:44:10.568357 22485033404224 run_lib.py:146] step: 207000, training_loss: 4.71787e-04
I0513 02:44:10.729901 22485033404224 run_lib.py:167] step: 207000, eval_loss: 6.26469e-04
I0513 02:44:34.317878 22485033404224 run_lib.py:146] step: 207050, training_loss: 7.78690e-04
I0513 02:44:58.476344 22485033404224 run_lib.py:146] step: 207100, training_loss: 5.91767e-04
I0513 02:44:58.636623 22485033404224 run_lib.py:167] step: 207100, eval_loss: 5.45980e-04
I0513 02:45:22.163697 22485033404224 run_lib.py:146] step: 207150, training_loss: 5.59004e-04
I0513 02:45:45.688073 22485033404224 run_lib.py:146] step: 207200, training_loss: 6.23654e-04
I0513 02:45:45.847337 22485033404224 run_lib.py:167] step: 207200, eval_loss: 7.30530e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 02:46:10.060254 22485033404224 run_lib.py:146] step: 207250, training_loss: 5.02719e-04
I0513 02:46:33.578591 22485033404224 run_lib.py:146] step: 207300, training_loss: 6.46814e-04
I0513 02:46:33.739434 22485033404224 run_lib.py:167] step: 207300, eval_loss: 6.87614e-04
I0513 02:46:57.286386 22485033404224 run_lib.py:146] step: 207350, training_loss: 8.58800e-04
I0513 02:47:21.149082 22485033404224 run_lib.py:146] step: 207400, training_loss: 7.18747e-04
I0513 02:47:21.308356 22485033404224 run_lib.py:167] step: 207400, eval_loss: 4.31312e-04
I0513 02:47:45.115967 22485033404224 run_lib.py:146] step: 207450, training_loss: 5.45847e-04
I0513 02:48:08.624246 22485033404224 run_lib.py:146] step: 207500, training_loss: 5.66482e-04
I0513 02:48:08.784199 22485033404224 run_lib.py:167] step: 207500, eval_loss: 4.64412e-04
I0513 02:48:32.614886 22485033404224 run_lib.py:146] step: 207550, training_loss: 8.72561e-04
I0513 02:48:56.456942 22485033404224 run_lib.py:146] step: 207600, training_loss: 7.25316e-04
I0513 02:48:56.615877 22485033404224 run_lib.py:167] step: 207600, eval_loss: 6.53189e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 02:49:20.218289 22485033404224 run_lib.py:146] step: 207650, training_loss: 6.65221e-04
I0513 02:49:43.743654 22485033404224 run_lib.py:146] step: 207700, training_loss: 5.74491e-04
I0513 02:49:43.905346 22485033404224 run_lib.py:167] step: 207700, eval_loss: 7.02397e-04
I0513 02:50:08.093498 22485033404224 run_lib.py:146] step: 207750, training_loss: 6.46601e-04
I0513 02:50:31.636795 22485033404224 run_lib.py:146] step: 207800, training_loss: 6.64619e-04
I0513 02:50:31.797780 22485033404224 run_lib.py:167] step: 207800, eval_loss: 6.34050e-04
I0513 02:50:55.323060 22485033404224 run_lib.py:146] step: 207850, training_loss: 5.98223e-04
I0513 02:51:19.473320 22485033404224 run_lib.py:146] step: 207900, training_loss: 6.55184e-04
I0513 02:51:19.632035 22485033404224 run_lib.py:167] step: 207900, eval_loss: 5.35965e-04
I0513 02:51:43.141445 22485033404224 run_lib.py:146] step: 207950, training_loss: 6.00762e-04
I0513 02:52:06.677210 22485033404224 run_lib.py:146] step: 208000, training_loss: 5.48627e-04
I0513 02:52:06.837665 22485033404224 run_lib.py:167] step: 208000, eval_loss: 7.02223e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 02:52:31.150815 22485033404224 run_lib.py:146] step: 208050, training_loss: 6.34946e-04
I0513 02:52:54.711397 22485033404224 run_lib.py:146] step: 208100, training_loss: 6.65092e-04
I0513 02:52:54.871972 22485033404224 run_lib.py:167] step: 208100, eval_loss: 4.76199e-04
I0513 02:53:18.402150 22485033404224 run_lib.py:146] step: 208150, training_loss: 5.55251e-04
I0513 02:53:42.551245 22485033404224 run_lib.py:146] step: 208200, training_loss: 9.35340e-04
I0513 02:53:42.710998 22485033404224 run_lib.py:167] step: 208200, eval_loss: 6.76739e-04
I0513 02:54:06.248399 22485033404224 run_lib.py:146] step: 208250, training_loss: 5.93945e-04
I0513 02:54:29.771825 22485033404224 run_lib.py:146] step: 208300, training_loss: 5.23611e-04
I0513 02:54:29.932037 22485033404224 run_lib.py:167] step: 208300, eval_loss: 3.95900e-04
I0513 02:54:53.800390 22485033404224 run_lib.py:146] step: 208350, training_loss: 6.29437e-04
I0513 02:55:17.721626 22485033404224 run_lib.py:146] step: 208400, training_loss: 6.86027e-04
I0513 02:55:17.882103 22485033404224 run_lib.py:167] step: 208400, eval_loss: 5.84307e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 02:55:41.548925 22485033404224 run_lib.py:146] step: 208450, training_loss: 5.12424e-04
I0513 02:56:05.510932 22485033404224 run_lib.py:146] step: 208500, training_loss: 6.98616e-04
I0513 02:56:05.672827 22485033404224 run_lib.py:167] step: 208500, eval_loss: 7.06799e-04
I0513 02:56:29.611694 22485033404224 run_lib.py:146] step: 208550, training_loss: 6.35164e-04
I0513 02:56:53.192104 22485033404224 run_lib.py:146] step: 208600, training_loss: 6.07315e-04
I0513 02:56:53.352675 22485033404224 run_lib.py:167] step: 208600, eval_loss: 6.24225e-04
I0513 02:57:16.907921 22485033404224 run_lib.py:146] step: 208650, training_loss: 4.96328e-04
I0513 02:57:41.085444 22485033404224 run_lib.py:146] step: 208700, training_loss: 7.21579e-04
I0513 02:57:41.246756 22485033404224 run_lib.py:167] step: 208700, eval_loss: 5.33453e-04
I0513 02:58:04.854791 22485033404224 run_lib.py:146] step: 208750, training_loss: 5.18618e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 02:58:28.546356 22485033404224 run_lib.py:146] step: 208800, training_loss: 5.57540e-04
I0513 02:58:28.709018 22485033404224 run_lib.py:167] step: 208800, eval_loss: 6.69336e-04
I0513 02:58:53.203925 22485033404224 run_lib.py:146] step: 208850, training_loss: 4.01374e-04
I0513 02:59:16.857663 22485033404224 run_lib.py:146] step: 208900, training_loss: 8.14948e-04
I0513 02:59:17.017399 22485033404224 run_lib.py:167] step: 208900, eval_loss: 6.00153e-04
I0513 02:59:40.624078 22485033404224 run_lib.py:146] step: 208950, training_loss: 4.70679e-04
I0513 03:00:04.934581 22485033404224 run_lib.py:146] step: 209000, training_loss: 6.45905e-04
I0513 03:00:05.094726 22485033404224 run_lib.py:167] step: 209000, eval_loss: 5.22852e-04
I0513 03:00:28.665289 22485033404224 run_lib.py:146] step: 209050, training_loss: 6.70539e-04
I0513 03:00:52.244328 22485033404224 run_lib.py:146] step: 209100, training_loss: 5.40885e-04
I0513 03:00:52.404828 22485033404224 run_lib.py:167] step: 209100, eval_loss: 5.84041e-04
I0513 03:01:16.273766 22485033404224 run_lib.py:146] step: 209150, training_loss: 5.42434e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 03:01:40.248281 22485033404224 run_lib.py:146] step: 209200, training_loss: 5.89765e-04
I0513 03:01:40.409222 22485033404224 run_lib.py:167] step: 209200, eval_loss: 5.82409e-04
I0513 03:02:04.046550 22485033404224 run_lib.py:146] step: 209250, training_loss: 5.53287e-04
I0513 03:02:27.985642 22485033404224 run_lib.py:146] step: 209300, training_loss: 5.97981e-04
I0513 03:02:28.143947 22485033404224 run_lib.py:167] step: 209300, eval_loss: 7.75205e-04
I0513 03:02:51.988800 22485033404224 run_lib.py:146] step: 209350, training_loss: 5.14928e-04
I0513 03:03:15.514523 22485033404224 run_lib.py:146] step: 209400, training_loss: 5.90313e-04
I0513 03:03:15.674651 22485033404224 run_lib.py:167] step: 209400, eval_loss: 6.24437e-04
I0513 03:03:39.226396 22485033404224 run_lib.py:146] step: 209450, training_loss: 6.38563e-04
I0513 03:04:03.415022 22485033404224 run_lib.py:146] step: 209500, training_loss: 7.81843e-04
I0513 03:04:03.574199 22485033404224 run_lib.py:167] step: 209500, eval_loss: 5.28109e-04
I0513 03:04:27.098664 22485033404224 run_lib.py:146] step: 209550, training_loss: 5.59907e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 03:04:50.718452 22485033404224 run_lib.py:146] step: 209600, training_loss: 6.19884e-04
I0513 03:04:50.879310 22485033404224 run_lib.py:167] step: 209600, eval_loss: 7.80411e-04
I0513 03:05:15.073858 22485033404224 run_lib.py:146] step: 209650, training_loss: 4.23375e-04
I0513 03:05:38.595738 22485033404224 run_lib.py:146] step: 209700, training_loss: 4.88352e-04
I0513 03:05:38.755809 22485033404224 run_lib.py:167] step: 209700, eval_loss: 4.98400e-04
I0513 03:06:02.304497 22485033404224 run_lib.py:146] step: 209750, training_loss: 5.83526e-04
I0513 03:06:26.444816 22485033404224 run_lib.py:146] step: 209800, training_loss: 5.11265e-04
I0513 03:06:26.604686 22485033404224 run_lib.py:167] step: 209800, eval_loss: 6.69377e-04
I0513 03:06:50.142474 22485033404224 run_lib.py:146] step: 209850, training_loss: 5.39404e-04
I0513 03:07:13.666531 22485033404224 run_lib.py:146] step: 209900, training_loss: 7.42201e-04
I0513 03:07:13.825226 22485033404224 run_lib.py:167] step: 209900, eval_loss: 7.33169e-04
I0513 03:07:37.938694 22485033404224 run_lib.py:146] step: 209950, training_loss: 8.29204e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 03:08:01.556196 22485033404224 run_lib.py:146] step: 210000, training_loss: 5.66725e-04
I0513 03:08:03.292896 22485033404224 run_lib.py:167] step: 210000, eval_loss: 6.39523e-04
I0513 03:08:28.388213 22485033404224 run_lib.py:146] step: 210050, training_loss: 6.50447e-04
I0513 03:08:52.593961 22485033404224 run_lib.py:146] step: 210100, training_loss: 4.53335e-04
I0513 03:08:52.754099 22485033404224 run_lib.py:167] step: 210100, eval_loss: 5.65533e-04
I0513 03:09:16.313326 22485033404224 run_lib.py:146] step: 210150, training_loss: 5.55734e-04
I0513 03:09:39.832871 22485033404224 run_lib.py:146] step: 210200, training_loss: 6.32998e-04
I0513 03:09:39.991687 22485033404224 run_lib.py:167] step: 210200, eval_loss: 5.84797e-04
I0513 03:10:03.821000 22485033404224 run_lib.py:146] step: 210250, training_loss: 6.00993e-04
I0513 03:10:27.638926 22485033404224 run_lib.py:146] step: 210300, training_loss: 5.27666e-04
I0513 03:10:27.797419 22485033404224 run_lib.py:167] step: 210300, eval_loss: 7.40208e-04
I0513 03:10:51.290184 22485033404224 run_lib.py:146] step: 210350, training_loss: 5.83774e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 03:11:15.227760 22485033404224 run_lib.py:146] step: 210400, training_loss: 5.62151e-04
I0513 03:11:15.388303 22485033404224 run_lib.py:167] step: 210400, eval_loss: 5.15363e-04
I0513 03:11:39.277292 22485033404224 run_lib.py:146] step: 210450, training_loss: 3.85479e-04
I0513 03:12:02.805750 22485033404224 run_lib.py:146] step: 210500, training_loss: 5.10198e-04
I0513 03:12:02.965517 22485033404224 run_lib.py:167] step: 210500, eval_loss: 5.73440e-04
I0513 03:12:26.814192 22485033404224 run_lib.py:146] step: 210550, training_loss: 5.93300e-04
I0513 03:12:50.660438 22485033404224 run_lib.py:146] step: 210600, training_loss: 5.75684e-04
I0513 03:12:50.820456 22485033404224 run_lib.py:167] step: 210600, eval_loss: 6.45676e-04
I0513 03:13:14.444002 22485033404224 run_lib.py:146] step: 210650, training_loss: 6.87502e-04
I0513 03:13:38.385146 22485033404224 run_lib.py:146] step: 210700, training_loss: 5.58137e-04
I0513 03:13:38.545196 22485033404224 run_lib.py:167] step: 210700, eval_loss: 6.21589e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 03:14:02.538225 22485033404224 run_lib.py:146] step: 210750, training_loss: 5.98271e-04
I0513 03:14:26.135210 22485033404224 run_lib.py:146] step: 210800, training_loss: 5.75467e-04
I0513 03:14:26.296555 22485033404224 run_lib.py:167] step: 210800, eval_loss: 5.22441e-04
I0513 03:14:49.915433 22485033404224 run_lib.py:146] step: 210850, training_loss: 7.69836e-04
I0513 03:15:14.317354 22485033404224 run_lib.py:146] step: 210900, training_loss: 6.90984e-04
I0513 03:15:14.477689 22485033404224 run_lib.py:167] step: 210900, eval_loss: 5.63282e-04
I0513 03:15:38.065088 22485033404224 run_lib.py:146] step: 210950, training_loss: 5.99960e-04
I0513 03:16:01.653891 22485033404224 run_lib.py:146] step: 211000, training_loss: 5.95767e-04
I0513 03:16:01.814818 22485033404224 run_lib.py:167] step: 211000, eval_loss: 7.36873e-04
I0513 03:16:26.117559 22485033404224 run_lib.py:146] step: 211050, training_loss: 7.89578e-04
I0513 03:16:49.717040 22485033404224 run_lib.py:146] step: 211100, training_loss: 5.63675e-04
I0513 03:16:49.878225 22485033404224 run_lib.py:167] step: 211100, eval_loss: 6.25403e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 03:17:13.589129 22485033404224 run_lib.py:146] step: 211150, training_loss: 6.21351e-04
I0513 03:17:37.552556 22485033404224 run_lib.py:146] step: 211200, training_loss: 5.07845e-04
I0513 03:17:37.714122 22485033404224 run_lib.py:167] step: 211200, eval_loss: 6.29992e-04
I0513 03:18:01.669852 22485033404224 run_lib.py:146] step: 211250, training_loss: 6.97661e-04
I0513 03:18:25.277663 22485033404224 run_lib.py:146] step: 211300, training_loss: 5.18526e-04
I0513 03:18:25.437557 22485033404224 run_lib.py:167] step: 211300, eval_loss: 5.17757e-04
I0513 03:18:49.334196 22485033404224 run_lib.py:146] step: 211350, training_loss: 7.34837e-04
I0513 03:19:13.239348 22485033404224 run_lib.py:146] step: 211400, training_loss: 6.98610e-04
I0513 03:19:13.398873 22485033404224 run_lib.py:167] step: 211400, eval_loss: 6.72873e-04
I0513 03:19:36.998928 22485033404224 run_lib.py:146] step: 211450, training_loss: 7.38672e-04
I0513 03:20:00.910471 22485033404224 run_lib.py:146] step: 211500, training_loss: 5.31301e-04
I0513 03:20:01.069678 22485033404224 run_lib.py:167] step: 211500, eval_loss: 5.46561e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 03:20:25.105252 22485033404224 run_lib.py:146] step: 211550, training_loss: 5.55382e-04
I0513 03:20:48.680939 22485033404224 run_lib.py:146] step: 211600, training_loss: 6.16500e-04
I0513 03:20:48.841327 22485033404224 run_lib.py:167] step: 211600, eval_loss: 7.38653e-04
I0513 03:21:12.738458 22485033404224 run_lib.py:146] step: 211650, training_loss: 8.07381e-04
I0513 03:21:36.614403 22485033404224 run_lib.py:146] step: 211700, training_loss: 5.07660e-04
I0513 03:21:36.772808 22485033404224 run_lib.py:167] step: 211700, eval_loss: 5.91427e-04
I0513 03:22:00.305935 22485033404224 run_lib.py:146] step: 211750, training_loss: 4.83892e-04
I0513 03:22:23.825764 22485033404224 run_lib.py:146] step: 211800, training_loss: 5.40426e-04
I0513 03:22:23.985774 22485033404224 run_lib.py:167] step: 211800, eval_loss: 5.42552e-04
I0513 03:22:48.123467 22485033404224 run_lib.py:146] step: 211850, training_loss: 6.35132e-04
I0513 03:23:11.703988 22485033404224 run_lib.py:146] step: 211900, training_loss: 6.17084e-04
I0513 03:23:11.864777 22485033404224 run_lib.py:167] step: 211900, eval_loss: 5.30034e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 03:23:35.473875 22485033404224 run_lib.py:146] step: 211950, training_loss: 4.93825e-04
I0513 03:23:59.328539 22485033404224 run_lib.py:146] step: 212000, training_loss: 6.09094e-04
I0513 03:23:59.489061 22485033404224 run_lib.py:167] step: 212000, eval_loss: 5.83336e-04
I0513 03:24:23.354100 22485033404224 run_lib.py:146] step: 212050, training_loss: 6.82836e-04
I0513 03:24:46.901830 22485033404224 run_lib.py:146] step: 212100, training_loss: 4.99810e-04
I0513 03:24:47.062483 22485033404224 run_lib.py:167] step: 212100, eval_loss: 6.43876e-04
I0513 03:25:10.905105 22485033404224 run_lib.py:146] step: 212150, training_loss: 6.15228e-04
I0513 03:25:34.764268 22485033404224 run_lib.py:146] step: 212200, training_loss: 6.26218e-04
I0513 03:25:34.923524 22485033404224 run_lib.py:167] step: 212200, eval_loss: 5.28474e-04
I0513 03:25:58.452999 22485033404224 run_lib.py:146] step: 212250, training_loss: 3.92875e-04
I0513 03:26:22.308907 22485033404224 run_lib.py:146] step: 212300, training_loss: 7.00898e-04
I0513 03:26:22.469148 22485033404224 run_lib.py:167] step: 212300, eval_loss: 5.59074e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 03:26:46.439442 22485033404224 run_lib.py:146] step: 212350, training_loss: 5.81180e-04
I0513 03:27:09.981924 22485033404224 run_lib.py:146] step: 212400, training_loss: 7.02801e-04
I0513 03:27:10.142881 22485033404224 run_lib.py:167] step: 212400, eval_loss: 6.99234e-04
I0513 03:27:34.009997 22485033404224 run_lib.py:146] step: 212450, training_loss: 7.24177e-04
I0513 03:27:57.891453 22485033404224 run_lib.py:146] step: 212500, training_loss: 8.22680e-04
I0513 03:27:58.052985 22485033404224 run_lib.py:167] step: 212500, eval_loss: 5.74710e-04
I0513 03:28:21.584767 22485033404224 run_lib.py:146] step: 212550, training_loss: 6.72355e-04
I0513 03:28:45.106111 22485033404224 run_lib.py:146] step: 212600, training_loss: 7.31839e-04
I0513 03:28:45.265247 22485033404224 run_lib.py:167] step: 212600, eval_loss: 5.18119e-04
I0513 03:29:09.407750 22485033404224 run_lib.py:146] step: 212650, training_loss: 5.92250e-04
I0513 03:29:32.963603 22485033404224 run_lib.py:146] step: 212700, training_loss: 5.21529e-04
I0513 03:29:33.122313 22485033404224 run_lib.py:167] step: 212700, eval_loss: 7.07128e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 03:29:56.696768 22485033404224 run_lib.py:146] step: 212750, training_loss: 5.18071e-04
I0513 03:30:20.526126 22485033404224 run_lib.py:146] step: 212800, training_loss: 6.52057e-04
I0513 03:30:20.686591 22485033404224 run_lib.py:167] step: 212800, eval_loss: 7.41166e-04
I0513 03:30:44.541623 22485033404224 run_lib.py:146] step: 212850, training_loss: 5.24065e-04
I0513 03:31:08.112485 22485033404224 run_lib.py:146] step: 212900, training_loss: 5.35655e-04
I0513 03:31:08.272656 22485033404224 run_lib.py:167] step: 212900, eval_loss: 6.31211e-04
I0513 03:31:32.153245 22485033404224 run_lib.py:146] step: 212950, training_loss: 6.78713e-04
I0513 03:31:56.054037 22485033404224 run_lib.py:146] step: 213000, training_loss: 4.88552e-04
I0513 03:31:56.215802 22485033404224 run_lib.py:167] step: 213000, eval_loss: 6.91828e-04
I0513 03:32:19.834166 22485033404224 run_lib.py:146] step: 213050, training_loss: 5.68067e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 03:32:43.814270 22485033404224 run_lib.py:146] step: 213100, training_loss: 4.18557e-04
I0513 03:32:43.975144 22485033404224 run_lib.py:167] step: 213100, eval_loss: 5.94232e-04
I0513 03:33:08.057304 22485033404224 run_lib.py:146] step: 213150, training_loss: 6.07391e-04
I0513 03:33:31.670296 22485033404224 run_lib.py:146] step: 213200, training_loss: 5.04176e-04
I0513 03:33:31.755496 22485033404224 run_lib.py:167] step: 213200, eval_loss: 9.92533e-04
I0513 03:33:55.693519 22485033404224 run_lib.py:146] step: 213250, training_loss: 7.27013e-04
I0513 03:34:19.691033 22485033404224 run_lib.py:146] step: 213300, training_loss: 7.93481e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 03:34:20.038877 22485033404224 run_lib.py:167] step: 213300, eval_loss: 6.47414e-04
I0513 03:34:43.687639 22485033404224 run_lib.py:146] step: 213350, training_loss: 6.48350e-04
I0513 03:35:07.341135 22485033404224 run_lib.py:146] step: 213400, training_loss: 7.60689e-04
I0513 03:35:07.502889 22485033404224 run_lib.py:167] step: 213400, eval_loss: 4.94151e-04
I0513 03:35:31.882827 22485033404224 run_lib.py:146] step: 213450, training_loss: 6.01677e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 03:35:55.594361 22485033404224 run_lib.py:146] step: 213500, training_loss: 6.66243e-04
I0513 03:35:55.756952 22485033404224 run_lib.py:167] step: 213500, eval_loss: 5.10790e-04
I0513 03:36:19.391271 22485033404224 run_lib.py:146] step: 213550, training_loss: 5.39078e-04
I0513 03:36:43.725037 22485033404224 run_lib.py:146] step: 213600, training_loss: 5.31242e-04
I0513 03:36:43.885996 22485033404224 run_lib.py:167] step: 213600, eval_loss: 5.85527e-04
I0513 03:37:07.525711 22485033404224 run_lib.py:146] step: 213650, training_loss: 5.55248e-04
I0513 03:37:31.149301 22485033404224 run_lib.py:146] step: 213700, training_loss: 8.06423e-04
I0513 03:37:31.310395 22485033404224 run_lib.py:167] step: 213700, eval_loss: 6.14239e-04
I0513 03:37:55.238426 22485033404224 run_lib.py:146] step: 213750, training_loss: 5.12426e-04
I0513 03:38:19.197228 22485033404224 run_lib.py:146] step: 213800, training_loss: 7.73542e-04
I0513 03:38:19.358818 22485033404224 run_lib.py:167] step: 213800, eval_loss: 7.01497e-04
I0513 03:38:42.939141 22485033404224 run_lib.py:146] step: 213850, training_loss: 5.71331e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 03:39:06.877798 22485033404224 run_lib.py:146] step: 213900, training_loss: 6.83944e-04
I0513 03:39:07.039077 22485033404224 run_lib.py:167] step: 213900, eval_loss: 7.79364e-04
I0513 03:39:30.897926 22485033404224 run_lib.py:146] step: 213950, training_loss: 6.33057e-04
I0513 03:39:54.431657 22485033404224 run_lib.py:146] step: 214000, training_loss: 6.20897e-04
I0513 03:39:54.591363 22485033404224 run_lib.py:167] step: 214000, eval_loss: 6.98644e-04
I0513 03:40:18.418854 22485033404224 run_lib.py:146] step: 214050, training_loss: 5.75769e-04
I0513 03:40:42.251328 22485033404224 run_lib.py:146] step: 214100, training_loss: 4.52321e-04
I0513 03:40:42.411921 22485033404224 run_lib.py:167] step: 214100, eval_loss: 5.70701e-04
I0513 03:41:05.949716 22485033404224 run_lib.py:146] step: 214150, training_loss: 8.86561e-04
I0513 03:41:29.504979 22485033404224 run_lib.py:146] step: 214200, training_loss: 7.92090e-04
I0513 03:41:29.664833 22485033404224 run_lib.py:167] step: 214200, eval_loss: 8.29067e-04
I0513 03:41:53.758524 22485033404224 run_lib.py:146] step: 214250, training_loss: 6.27861e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 03:42:17.369256 22485033404224 run_lib.py:146] step: 214300, training_loss: 6.59871e-04
I0513 03:42:17.530041 22485033404224 run_lib.py:167] step: 214300, eval_loss: 6.79284e-04
I0513 03:42:41.068423 22485033404224 run_lib.py:146] step: 214350, training_loss: 6.17438e-04
I0513 03:43:05.297056 22485033404224 run_lib.py:146] step: 214400, training_loss: 6.70205e-04
I0513 03:43:05.455478 22485033404224 run_lib.py:167] step: 214400, eval_loss: 6.53527e-04
I0513 03:43:28.993536 22485033404224 run_lib.py:146] step: 214450, training_loss: 7.81039e-04
I0513 03:43:52.527972 22485033404224 run_lib.py:146] step: 214500, training_loss: 6.82793e-04
I0513 03:43:52.688236 22485033404224 run_lib.py:167] step: 214500, eval_loss: 5.46348e-04
I0513 03:44:16.522982 22485033404224 run_lib.py:146] step: 214550, training_loss: 4.87140e-04
I0513 03:44:40.369875 22485033404224 run_lib.py:146] step: 214600, training_loss: 5.50931e-04
I0513 03:44:40.528595 22485033404224 run_lib.py:167] step: 214600, eval_loss: 6.89988e-04
I0513 03:45:04.077864 22485033404224 run_lib.py:146] step: 214650, training_loss: 6.19589e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 03:45:28.041757 22485033404224 run_lib.py:146] step: 214700, training_loss: 5.58944e-04
I0513 03:45:28.204255 22485033404224 run_lib.py:167] step: 214700, eval_loss: 6.48092e-04
I0513 03:45:52.099905 22485033404224 run_lib.py:146] step: 214750, training_loss: 6.19108e-04
I0513 03:46:15.646457 22485033404224 run_lib.py:146] step: 214800, training_loss: 5.94640e-04
I0513 03:46:15.805652 22485033404224 run_lib.py:167] step: 214800, eval_loss: 6.24222e-04
I0513 03:46:39.651209 22485033404224 run_lib.py:146] step: 214850, training_loss: 5.77085e-04
I0513 03:47:03.466638 22485033404224 run_lib.py:146] step: 214900, training_loss: 6.61281e-04
I0513 03:47:03.626203 22485033404224 run_lib.py:167] step: 214900, eval_loss: 5.95709e-04
I0513 03:47:27.153413 22485033404224 run_lib.py:146] step: 214950, training_loss: 6.10044e-04
I0513 03:47:51.004770 22485033404224 run_lib.py:146] step: 215000, training_loss: 5.03947e-04
I0513 03:47:51.165529 22485033404224 run_lib.py:167] step: 215000, eval_loss: 4.81560e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 03:48:15.068970 22485033404224 run_lib.py:146] step: 215050, training_loss: 5.83323e-04
I0513 03:48:38.604563 22485033404224 run_lib.py:146] step: 215100, training_loss: 8.35687e-04
I0513 03:48:38.766057 22485033404224 run_lib.py:167] step: 215100, eval_loss: 6.27946e-04
I0513 03:49:02.311448 22485033404224 run_lib.py:146] step: 215150, training_loss: 5.64237e-04
I0513 03:49:26.614189 22485033404224 run_lib.py:146] step: 215200, training_loss: 6.89336e-04
I0513 03:49:26.774840 22485033404224 run_lib.py:167] step: 215200, eval_loss: 6.64452e-04
I0513 03:49:50.376662 22485033404224 run_lib.py:146] step: 215250, training_loss: 6.29435e-04
I0513 03:50:13.980398 22485033404224 run_lib.py:146] step: 215300, training_loss: 6.43807e-04
I0513 03:50:14.141456 22485033404224 run_lib.py:167] step: 215300, eval_loss: 5.74959e-04
I0513 03:50:38.016742 22485033404224 run_lib.py:146] step: 215350, training_loss: 5.65246e-04
I0513 03:51:01.955231 22485033404224 run_lib.py:146] step: 215400, training_loss: 7.43324e-04
I0513 03:51:02.114966 22485033404224 run_lib.py:167] step: 215400, eval_loss: 7.24397e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 03:51:25.791438 22485033404224 run_lib.py:146] step: 215450, training_loss: 5.86382e-04
I0513 03:51:49.869479 22485033404224 run_lib.py:146] step: 215500, training_loss: 5.08995e-04
I0513 03:51:50.031009 22485033404224 run_lib.py:167] step: 215500, eval_loss: 6.09239e-04
I0513 03:52:13.998954 22485033404224 run_lib.py:146] step: 215550, training_loss: 5.43504e-04
I0513 03:52:37.590721 22485033404224 run_lib.py:146] step: 215600, training_loss: 4.86269e-04
I0513 03:52:37.752806 22485033404224 run_lib.py:167] step: 215600, eval_loss: 6.91122e-04
I0513 03:53:01.768956 22485033404224 run_lib.py:146] step: 215650, training_loss: 7.22804e-04
I0513 03:53:25.708322 22485033404224 run_lib.py:146] step: 215700, training_loss: 5.40136e-04
I0513 03:53:25.870714 22485033404224 run_lib.py:167] step: 215700, eval_loss: 5.60779e-04
I0513 03:53:49.524918 22485033404224 run_lib.py:146] step: 215750, training_loss: 5.64035e-04
I0513 03:54:13.534555 22485033404224 run_lib.py:146] step: 215800, training_loss: 6.26475e-04
I0513 03:54:13.694892 22485033404224 run_lib.py:167] step: 215800, eval_loss: 6.52008e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 03:54:37.752799 22485033404224 run_lib.py:146] step: 215850, training_loss: 4.62179e-04
I0513 03:55:01.358351 22485033404224 run_lib.py:146] step: 215900, training_loss: 5.73418e-04
I0513 03:55:01.520341 22485033404224 run_lib.py:167] step: 215900, eval_loss: 8.79860e-04
I0513 03:55:25.136057 22485033404224 run_lib.py:146] step: 215950, training_loss: 7.01090e-04
I0513 03:55:49.404949 22485033404224 run_lib.py:146] step: 216000, training_loss: 5.28810e-04
I0513 03:55:49.565191 22485033404224 run_lib.py:167] step: 216000, eval_loss: 5.65759e-04
I0513 03:56:13.177996 22485033404224 run_lib.py:146] step: 216050, training_loss: 6.48678e-04
I0513 03:56:36.760878 22485033404224 run_lib.py:146] step: 216100, training_loss: 8.63861e-04
I0513 03:56:36.920712 22485033404224 run_lib.py:167] step: 216100, eval_loss: 5.01061e-04
I0513 03:57:00.751410 22485033404224 run_lib.py:146] step: 216150, training_loss: 5.26918e-04
I0513 03:57:24.585871 22485033404224 run_lib.py:146] step: 216200, training_loss: 5.38233e-04
I0513 03:57:24.746026 22485033404224 run_lib.py:167] step: 216200, eval_loss: 6.48459e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 03:57:48.343759 22485033404224 run_lib.py:146] step: 216250, training_loss: 8.23959e-04
I0513 03:58:12.210415 22485033404224 run_lib.py:146] step: 216300, training_loss: 4.29739e-04
I0513 03:58:12.370566 22485033404224 run_lib.py:167] step: 216300, eval_loss: 5.48850e-04
I0513 03:58:36.282935 22485033404224 run_lib.py:146] step: 216350, training_loss: 7.70546e-04
I0513 03:58:59.817202 22485033404224 run_lib.py:146] step: 216400, training_loss: 7.83019e-04
I0513 03:58:59.976477 22485033404224 run_lib.py:167] step: 216400, eval_loss: 7.41853e-04
I0513 03:59:23.798101 22485033404224 run_lib.py:146] step: 216450, training_loss: 5.24509e-04
I0513 03:59:47.673433 22485033404224 run_lib.py:146] step: 216500, training_loss: 5.75676e-04
I0513 03:59:47.832680 22485033404224 run_lib.py:167] step: 216500, eval_loss: 8.14986e-04
I0513 04:00:11.375534 22485033404224 run_lib.py:146] step: 216550, training_loss: 5.95392e-04
I0513 04:00:35.225325 22485033404224 run_lib.py:146] step: 216600, training_loss: 6.63810e-04
I0513 04:00:35.384079 22485033404224 run_lib.py:167] step: 216600, eval_loss: 6.35105e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 04:00:59.333477 22485033404224 run_lib.py:146] step: 216650, training_loss: 7.29447e-04
I0513 04:01:22.866827 22485033404224 run_lib.py:146] step: 216700, training_loss: 5.05231e-04
I0513 04:01:23.026544 22485033404224 run_lib.py:167] step: 216700, eval_loss: 7.16257e-04
I0513 04:01:46.902909 22485033404224 run_lib.py:146] step: 216750, training_loss: 5.85593e-04
I0513 04:02:10.727764 22485033404224 run_lib.py:146] step: 216800, training_loss: 7.18838e-04
I0513 04:02:10.886521 22485033404224 run_lib.py:167] step: 216800, eval_loss: 6.65857e-04
I0513 04:02:34.423481 22485033404224 run_lib.py:146] step: 216850, training_loss: 6.64529e-04
I0513 04:02:57.959712 22485033404224 run_lib.py:146] step: 216900, training_loss: 6.53525e-04
I0513 04:02:58.118902 22485033404224 run_lib.py:167] step: 216900, eval_loss: 4.18404e-04
I0513 04:03:21.954198 22485033404224 run_lib.py:146] step: 216950, training_loss: 6.50824e-04
I0513 04:03:45.792054 22485033404224 run_lib.py:146] step: 217000, training_loss: 5.16127e-04
I0513 04:03:45.951977 22485033404224 run_lib.py:167] step: 217000, eval_loss: 6.30850e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 04:04:09.542870 22485033404224 run_lib.py:146] step: 217050, training_loss: 7.65386e-04
I0513 04:04:33.402721 22485033404224 run_lib.py:146] step: 217100, training_loss: 5.89479e-04
I0513 04:04:33.563168 22485033404224 run_lib.py:167] step: 217100, eval_loss: 4.49419e-04
I0513 04:04:57.430247 22485033404224 run_lib.py:146] step: 217150, training_loss: 5.41558e-04
I0513 04:05:21.016492 22485033404224 run_lib.py:146] step: 217200, training_loss: 7.30251e-04
I0513 04:05:21.177795 22485033404224 run_lib.py:167] step: 217200, eval_loss: 6.78442e-04
I0513 04:05:45.022531 22485033404224 run_lib.py:146] step: 217250, training_loss: 6.23551e-04
I0513 04:06:08.867233 22485033404224 run_lib.py:146] step: 217300, training_loss: 5.79087e-04
I0513 04:06:09.027130 22485033404224 run_lib.py:167] step: 217300, eval_loss: 6.50698e-04
I0513 04:06:32.579915 22485033404224 run_lib.py:146] step: 217350, training_loss: 5.94245e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 04:06:56.551732 22485033404224 run_lib.py:146] step: 217400, training_loss: 6.82640e-04
I0513 04:06:56.714018 22485033404224 run_lib.py:167] step: 217400, eval_loss: 4.09560e-04
I0513 04:07:20.690880 22485033404224 run_lib.py:146] step: 217450, training_loss: 4.05868e-04
I0513 04:07:44.321152 22485033404224 run_lib.py:146] step: 217500, training_loss: 6.82365e-04
I0513 04:07:44.481859 22485033404224 run_lib.py:167] step: 217500, eval_loss: 5.69941e-04
I0513 04:08:08.436080 22485033404224 run_lib.py:146] step: 217550, training_loss: 5.35436e-04
I0513 04:08:32.349958 22485033404224 run_lib.py:146] step: 217600, training_loss: 6.90515e-04
I0513 04:08:32.511700 22485033404224 run_lib.py:167] step: 217600, eval_loss: 4.93459e-04
I0513 04:08:56.093729 22485033404224 run_lib.py:146] step: 217650, training_loss: 4.90809e-04
I0513 04:09:19.698430 22485033404224 run_lib.py:146] step: 217700, training_loss: 7.41888e-04
I0513 04:09:19.859116 22485033404224 run_lib.py:167] step: 217700, eval_loss: 6.17037e-04
I0513 04:09:44.037624 22485033404224 run_lib.py:146] step: 217750, training_loss: 7.34548e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 04:10:07.683573 22485033404224 run_lib.py:146] step: 217800, training_loss: 5.72361e-04
I0513 04:10:07.845703 22485033404224 run_lib.py:167] step: 217800, eval_loss: 6.85575e-04
I0513 04:10:31.466922 22485033404224 run_lib.py:146] step: 217850, training_loss: 7.04685e-04
I0513 04:10:55.572069 22485033404224 run_lib.py:146] step: 217900, training_loss: 4.45986e-04
I0513 04:10:55.733599 22485033404224 run_lib.py:167] step: 217900, eval_loss: 7.47211e-04
I0513 04:11:19.703327 22485033404224 run_lib.py:146] step: 217950, training_loss: 7.88993e-04
I0513 04:11:43.284101 22485033404224 run_lib.py:146] step: 218000, training_loss: 8.06537e-04
I0513 04:11:43.444563 22485033404224 run_lib.py:167] step: 218000, eval_loss: 5.06166e-04
I0513 04:12:07.409357 22485033404224 run_lib.py:146] step: 218050, training_loss: 4.90388e-04
I0513 04:12:31.317569 22485033404224 run_lib.py:146] step: 218100, training_loss: 5.07869e-04
I0513 04:12:31.478566 22485033404224 run_lib.py:167] step: 218100, eval_loss: 5.96143e-04
I0513 04:12:55.066018 22485033404224 run_lib.py:146] step: 218150, training_loss: 5.08736e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 04:13:19.235487 22485033404224 run_lib.py:146] step: 218200, training_loss: 6.85826e-04
I0513 04:13:19.397353 22485033404224 run_lib.py:167] step: 218200, eval_loss: 6.36485e-04
I0513 04:13:43.363515 22485033404224 run_lib.py:146] step: 218250, training_loss: 5.54748e-04
I0513 04:14:07.013031 22485033404224 run_lib.py:146] step: 218300, training_loss: 5.98325e-04
I0513 04:14:07.174464 22485033404224 run_lib.py:167] step: 218300, eval_loss: 5.46170e-04
I0513 04:14:31.162244 22485033404224 run_lib.py:146] step: 218350, training_loss: 6.34631e-04
I0513 04:14:55.035746 22485033404224 run_lib.py:146] step: 218400, training_loss: 8.11664e-04
I0513 04:14:55.194903 22485033404224 run_lib.py:167] step: 218400, eval_loss: 5.76146e-04
I0513 04:15:18.724005 22485033404224 run_lib.py:146] step: 218450, training_loss: 5.00050e-04
I0513 04:15:42.256703 22485033404224 run_lib.py:146] step: 218500, training_loss: 5.95560e-04
I0513 04:15:42.417249 22485033404224 run_lib.py:167] step: 218500, eval_loss: 6.80838e-04
I0513 04:16:06.513046 22485033404224 run_lib.py:146] step: 218550, training_loss: 6.75173e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 04:16:30.140447 22485033404224 run_lib.py:146] step: 218600, training_loss: 5.31623e-04
I0513 04:16:30.301996 22485033404224 run_lib.py:167] step: 218600, eval_loss: 6.42875e-04
I0513 04:16:53.808334 22485033404224 run_lib.py:146] step: 218650, training_loss: 5.34368e-04
I0513 04:17:17.655099 22485033404224 run_lib.py:146] step: 218700, training_loss: 8.28895e-04
I0513 04:17:17.814458 22485033404224 run_lib.py:167] step: 218700, eval_loss: 4.74068e-04
I0513 04:17:41.635246 22485033404224 run_lib.py:146] step: 218750, training_loss: 6.16563e-04
I0513 04:18:05.163664 22485033404224 run_lib.py:146] step: 218800, training_loss: 5.93956e-04
I0513 04:18:05.322971 22485033404224 run_lib.py:167] step: 218800, eval_loss: 5.92303e-04
I0513 04:18:29.148079 22485033404224 run_lib.py:146] step: 218850, training_loss: 7.23063e-04
I0513 04:18:52.999760 22485033404224 run_lib.py:146] step: 218900, training_loss: 4.56903e-04
I0513 04:18:53.160005 22485033404224 run_lib.py:167] step: 218900, eval_loss: 4.15553e-04
I0513 04:19:16.665678 22485033404224 run_lib.py:146] step: 218950, training_loss: 5.90535e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 04:19:40.625931 22485033404224 run_lib.py:146] step: 219000, training_loss: 7.88499e-04
I0513 04:19:40.786952 22485033404224 run_lib.py:167] step: 219000, eval_loss: 6.30723e-04
I0513 04:20:04.632812 22485033404224 run_lib.py:146] step: 219050, training_loss: 6.70598e-04
I0513 04:20:28.180363 22485033404224 run_lib.py:146] step: 219100, training_loss: 6.29253e-04
I0513 04:20:28.339540 22485033404224 run_lib.py:167] step: 219100, eval_loss: 6.99362e-04
I0513 04:20:52.135178 22485033404224 run_lib.py:146] step: 219150, training_loss: 5.68585e-04
I0513 04:21:15.981351 22485033404224 run_lib.py:146] step: 219200, training_loss: 4.23730e-04
I0513 04:21:16.142614 22485033404224 run_lib.py:167] step: 219200, eval_loss: 7.64091e-04
I0513 04:21:39.683336 22485033404224 run_lib.py:146] step: 219250, training_loss: 6.10361e-04
I0513 04:22:03.257333 22485033404224 run_lib.py:146] step: 219300, training_loss: 5.40380e-04
I0513 04:22:03.418163 22485033404224 run_lib.py:167] step: 219300, eval_loss: 6.73982e-04
I0513 04:22:27.450071 22485033404224 run_lib.py:146] step: 219350, training_loss: 6.64633e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 04:22:51.170836 22485033404224 run_lib.py:146] step: 219400, training_loss: 5.04964e-04
I0513 04:22:51.332386 22485033404224 run_lib.py:167] step: 219400, eval_loss: 6.10268e-04
I0513 04:23:14.875777 22485033404224 run_lib.py:146] step: 219450, training_loss: 6.91718e-04
I0513 04:23:39.118710 22485033404224 run_lib.py:146] step: 219500, training_loss: 7.27707e-04
I0513 04:23:39.278802 22485033404224 run_lib.py:167] step: 219500, eval_loss: 4.99796e-04
I0513 04:24:02.846248 22485033404224 run_lib.py:146] step: 219550, training_loss: 5.48296e-04
I0513 04:24:26.414294 22485033404224 run_lib.py:146] step: 219600, training_loss: 5.16784e-04
I0513 04:24:26.573538 22485033404224 run_lib.py:167] step: 219600, eval_loss: 7.72650e-04
I0513 04:24:50.429052 22485033404224 run_lib.py:146] step: 219650, training_loss: 6.40240e-04
I0513 04:25:14.321183 22485033404224 run_lib.py:146] step: 219700, training_loss: 6.94413e-04
I0513 04:25:14.482062 22485033404224 run_lib.py:167] step: 219700, eval_loss: 4.58174e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 04:25:38.175221 22485033404224 run_lib.py:146] step: 219750, training_loss: 7.99132e-04
I0513 04:26:02.163944 22485033404224 run_lib.py:146] step: 219800, training_loss: 5.01763e-04
I0513 04:26:02.325637 22485033404224 run_lib.py:167] step: 219800, eval_loss: 6.36429e-04
I0513 04:26:26.264589 22485033404224 run_lib.py:146] step: 219850, training_loss: 5.75232e-04
I0513 04:26:49.886155 22485033404224 run_lib.py:146] step: 219900, training_loss: 5.92804e-04
I0513 04:26:50.046162 22485033404224 run_lib.py:167] step: 219900, eval_loss: 7.07480e-04
I0513 04:27:13.922427 22485033404224 run_lib.py:146] step: 219950, training_loss: 4.85856e-04
I0513 04:27:37.811997 22485033404224 run_lib.py:146] step: 220000, training_loss: 6.49891e-04
I0513 04:27:39.579615 22485033404224 run_lib.py:167] step: 220000, eval_loss: 5.39293e-04
I0513 04:28:05.005517 22485033404224 run_lib.py:146] step: 220050, training_loss: 6.48647e-04
I0513 04:28:28.604998 22485033404224 run_lib.py:146] step: 220100, training_loss: 5.16340e-04
I0513 04:28:28.767224 22485033404224 run_lib.py:167] step: 220100, eval_loss: 6.53739e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 04:28:52.789353 22485033404224 run_lib.py:146] step: 220150, training_loss: 6.59765e-04
I0513 04:29:16.385339 22485033404224 run_lib.py:146] step: 220200, training_loss: 7.39852e-04
I0513 04:29:16.546645 22485033404224 run_lib.py:167] step: 220200, eval_loss: 6.87378e-04
I0513 04:29:40.501968 22485033404224 run_lib.py:146] step: 220250, training_loss: 5.38878e-04
I0513 04:30:04.365652 22485033404224 run_lib.py:146] step: 220300, training_loss: 7.00998e-04
I0513 04:30:04.525489 22485033404224 run_lib.py:167] step: 220300, eval_loss: 5.35313e-04
I0513 04:30:28.122909 22485033404224 run_lib.py:146] step: 220350, training_loss: 6.77879e-04
I0513 04:30:52.043734 22485033404224 run_lib.py:146] step: 220400, training_loss: 7.31247e-04
I0513 04:30:52.203856 22485033404224 run_lib.py:167] step: 220400, eval_loss: 4.69480e-04
I0513 04:31:15.802058 22485033404224 run_lib.py:146] step: 220450, training_loss: 5.81072e-04
I0513 04:31:39.669187 22485033404224 run_lib.py:146] step: 220500, training_loss: 7.40450e-04
I0513 04:31:39.830673 22485033404224 run_lib.py:167] step: 220500, eval_loss: 4.34018e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 04:32:03.872822 22485033404224 run_lib.py:146] step: 220550, training_loss: 7.00398e-04
I0513 04:32:27.535516 22485033404224 run_lib.py:146] step: 220600, training_loss: 5.19549e-04
I0513 04:32:27.697632 22485033404224 run_lib.py:167] step: 220600, eval_loss: 5.70613e-04
I0513 04:32:51.626801 22485033404224 run_lib.py:146] step: 220650, training_loss: 6.51710e-04
I0513 04:33:15.470586 22485033404224 run_lib.py:146] step: 220700, training_loss: 6.36094e-04
I0513 04:33:15.630747 22485033404224 run_lib.py:167] step: 220700, eval_loss: 6.42870e-04
I0513 04:33:39.192395 22485033404224 run_lib.py:146] step: 220750, training_loss: 7.74013e-04
I0513 04:34:03.052560 22485033404224 run_lib.py:146] step: 220800, training_loss: 5.03139e-04
I0513 04:34:03.212686 22485033404224 run_lib.py:167] step: 220800, eval_loss: 7.29354e-04
I0513 04:34:27.036966 22485033404224 run_lib.py:146] step: 220850, training_loss: 4.74848e-04
I0513 04:34:50.588757 22485033404224 run_lib.py:146] step: 220900, training_loss: 9.49239e-04
I0513 04:34:50.747556 22485033404224 run_lib.py:167] step: 220900, eval_loss: 5.01884e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 04:35:14.723682 22485033404224 run_lib.py:146] step: 220950, training_loss: 6.29443e-04
I0513 04:35:38.267674 22485033404224 run_lib.py:146] step: 221000, training_loss: 5.60933e-04
I0513 04:35:38.426493 22485033404224 run_lib.py:167] step: 221000, eval_loss: 5.98744e-04
I0513 04:36:02.286749 22485033404224 run_lib.py:146] step: 221050, training_loss: 5.88708e-04
I0513 04:36:26.106487 22485033404224 run_lib.py:146] step: 221100, training_loss: 5.62991e-04
I0513 04:36:26.193428 22485033404224 run_lib.py:167] step: 221100, eval_loss: 6.65090e-04
I0513 04:36:49.738858 22485033404224 run_lib.py:146] step: 221150, training_loss: 7.27294e-04
I0513 04:37:13.602143 22485033404224 run_lib.py:146] step: 221200, training_loss: 5.98694e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 04:37:13.950758 22485033404224 run_lib.py:167] step: 221200, eval_loss: 7.31502e-04
I0513 04:37:37.523117 22485033404224 run_lib.py:146] step: 221250, training_loss: 5.55520e-04
I0513 04:38:01.436598 22485033404224 run_lib.py:146] step: 221300, training_loss: 5.34880e-04
I0513 04:38:01.597048 22485033404224 run_lib.py:167] step: 221300, eval_loss: 6.53702e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 04:38:25.570216 22485033404224 run_lib.py:146] step: 221350, training_loss: 6.35559e-04
I0513 04:38:49.106562 22485033404224 run_lib.py:146] step: 221400, training_loss: 5.85687e-04
I0513 04:38:49.267724 22485033404224 run_lib.py:167] step: 221400, eval_loss: 5.81057e-04
I0513 04:39:13.153937 22485033404224 run_lib.py:146] step: 221450, training_loss: 5.10067e-04
I0513 04:39:36.989966 22485033404224 run_lib.py:146] step: 221500, training_loss: 5.05847e-04
I0513 04:39:37.150599 22485033404224 run_lib.py:167] step: 221500, eval_loss: 5.83768e-04
I0513 04:40:00.688838 22485033404224 run_lib.py:146] step: 221550, training_loss: 4.01789e-04
I0513 04:40:24.554524 22485033404224 run_lib.py:146] step: 221600, training_loss: 5.48058e-04
I0513 04:40:24.713471 22485033404224 run_lib.py:167] step: 221600, eval_loss: 7.80911e-04
I0513 04:40:48.585483 22485033404224 run_lib.py:146] step: 221650, training_loss: 6.96923e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 04:41:12.178674 22485033404224 run_lib.py:146] step: 221700, training_loss: 6.46064e-04
I0513 04:41:12.341738 22485033404224 run_lib.py:167] step: 221700, eval_loss: 3.51795e-04
I0513 04:41:36.245649 22485033404224 run_lib.py:146] step: 221750, training_loss: 6.56578e-04
I0513 04:41:59.797673 22485033404224 run_lib.py:146] step: 221800, training_loss: 8.05249e-04
I0513 04:41:59.957005 22485033404224 run_lib.py:167] step: 221800, eval_loss: 6.16913e-04
I0513 04:42:23.846940 22485033404224 run_lib.py:146] step: 221850, training_loss: 5.86504e-04
I0513 04:42:47.696488 22485033404224 run_lib.py:146] step: 221900, training_loss: 6.26112e-04
I0513 04:42:47.856072 22485033404224 run_lib.py:167] step: 221900, eval_loss: 7.37204e-04
I0513 04:43:11.434101 22485033404224 run_lib.py:146] step: 221950, training_loss: 6.82291e-04
I0513 04:43:35.357724 22485033404224 run_lib.py:146] step: 222000, training_loss: 7.17328e-04
I0513 04:43:35.518340 22485033404224 run_lib.py:167] step: 222000, eval_loss: 5.50980e-04
I0513 04:43:59.443109 22485033404224 run_lib.py:146] step: 222050, training_loss: 7.67022e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 04:44:23.117461 22485033404224 run_lib.py:146] step: 222100, training_loss: 7.96082e-04
I0513 04:44:23.279648 22485033404224 run_lib.py:167] step: 222100, eval_loss: 5.39785e-04
I0513 04:44:47.226532 22485033404224 run_lib.py:146] step: 222150, training_loss: 7.55071e-04
I0513 04:45:10.841062 22485033404224 run_lib.py:146] step: 222200, training_loss: 6.87086e-04
I0513 04:45:11.000976 22485033404224 run_lib.py:167] step: 222200, eval_loss: 6.38207e-04
I0513 04:45:34.970980 22485033404224 run_lib.py:146] step: 222250, training_loss: 5.49638e-04
I0513 04:45:58.860447 22485033404224 run_lib.py:146] step: 222300, training_loss: 5.49159e-04
I0513 04:45:59.020936 22485033404224 run_lib.py:167] step: 222300, eval_loss: 6.88196e-04
I0513 04:46:22.618266 22485033404224 run_lib.py:146] step: 222350, training_loss: 6.21383e-04
I0513 04:46:46.513818 22485033404224 run_lib.py:146] step: 222400, training_loss: 5.33242e-04
I0513 04:46:46.675077 22485033404224 run_lib.py:167] step: 222400, eval_loss: 4.64586e-04
I0513 04:47:10.599273 22485033404224 run_lib.py:146] step: 222450, training_loss: 5.79339e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 04:47:34.287039 22485033404224 run_lib.py:146] step: 222500, training_loss: 7.72957e-04
I0513 04:47:34.449106 22485033404224 run_lib.py:167] step: 222500, eval_loss: 4.57329e-04
I0513 04:47:58.384427 22485033404224 run_lib.py:146] step: 222550, training_loss: 6.60432e-04
I0513 04:48:21.991723 22485033404224 run_lib.py:146] step: 222600, training_loss: 7.56050e-04
I0513 04:48:22.152399 22485033404224 run_lib.py:167] step: 222600, eval_loss: 4.21774e-04
I0513 04:48:46.178209 22485033404224 run_lib.py:146] step: 222650, training_loss: 4.87822e-04
I0513 04:49:10.095083 22485033404224 run_lib.py:146] step: 222700, training_loss: 3.93243e-04
I0513 04:49:10.255510 22485033404224 run_lib.py:167] step: 222700, eval_loss: 7.02291e-04
I0513 04:49:33.854486 22485033404224 run_lib.py:146] step: 222750, training_loss: 7.81777e-04
I0513 04:49:57.840626 22485033404224 run_lib.py:146] step: 222800, training_loss: 4.55528e-04
I0513 04:49:58.000893 22485033404224 run_lib.py:167] step: 222800, eval_loss: 5.19966e-04
I0513 04:50:21.936019 22485033404224 run_lib.py:146] step: 222850, training_loss: 6.70766e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 04:50:45.600348 22485033404224 run_lib.py:146] step: 222900, training_loss: 6.59166e-04
I0513 04:50:45.761312 22485033404224 run_lib.py:167] step: 222900, eval_loss: 5.36353e-04
I0513 04:51:09.755077 22485033404224 run_lib.py:146] step: 222950, training_loss: 7.63515e-04
I0513 04:51:33.289899 22485033404224 run_lib.py:146] step: 223000, training_loss: 5.28273e-04
I0513 04:51:33.448499 22485033404224 run_lib.py:167] step: 223000, eval_loss: 4.55832e-04
I0513 04:51:57.285685 22485033404224 run_lib.py:146] step: 223050, training_loss: 6.54251e-04
I0513 04:52:21.095911 22485033404224 run_lib.py:146] step: 223100, training_loss: 8.15542e-04
I0513 04:52:21.254823 22485033404224 run_lib.py:167] step: 223100, eval_loss: 7.30468e-04
I0513 04:52:44.770025 22485033404224 run_lib.py:146] step: 223150, training_loss: 7.09388e-04
I0513 04:53:08.603873 22485033404224 run_lib.py:146] step: 223200, training_loss: 7.33296e-04
I0513 04:53:08.762248 22485033404224 run_lib.py:167] step: 223200, eval_loss: 5.39969e-04
I0513 04:53:32.546153 22485033404224 run_lib.py:146] step: 223250, training_loss: 4.56125e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 04:53:56.144020 22485033404224 run_lib.py:146] step: 223300, training_loss: 5.28398e-04
I0513 04:53:56.305244 22485033404224 run_lib.py:167] step: 223300, eval_loss: 6.36410e-04
I0513 04:54:20.158294 22485033404224 run_lib.py:146] step: 223350, training_loss: 6.83770e-04
I0513 04:54:44.029555 22485033404224 run_lib.py:146] step: 223400, training_loss: 4.82218e-04
I0513 04:54:44.188379 22485033404224 run_lib.py:167] step: 223400, eval_loss: 6.75440e-04
I0513 04:55:07.703557 22485033404224 run_lib.py:146] step: 223450, training_loss: 6.30413e-04
I0513 04:55:31.546620 22485033404224 run_lib.py:146] step: 223500, training_loss: 5.46768e-04
I0513 04:55:31.706295 22485033404224 run_lib.py:167] step: 223500, eval_loss: 5.50161e-04
I0513 04:55:55.247230 22485033404224 run_lib.py:146] step: 223550, training_loss: 5.37110e-04
I0513 04:56:19.081929 22485033404224 run_lib.py:146] step: 223600, training_loss: 7.32830e-04
I0513 04:56:19.240585 22485033404224 run_lib.py:167] step: 223600, eval_loss: 6.64778e-04
I0513 04:56:43.073856 22485033404224 run_lib.py:146] step: 223650, training_loss: 7.00927e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 04:57:06.679062 22485033404224 run_lib.py:146] step: 223700, training_loss: 6.68919e-04
I0513 04:57:06.840262 22485033404224 run_lib.py:167] step: 223700, eval_loss: 6.19478e-04
I0513 04:57:30.702390 22485033404224 run_lib.py:146] step: 223750, training_loss: 6.05527e-04
I0513 04:57:54.231328 22485033404224 run_lib.py:146] step: 223800, training_loss: 7.57040e-04
I0513 04:57:54.390413 22485033404224 run_lib.py:167] step: 223800, eval_loss: 3.67761e-04
I0513 04:58:18.257573 22485033404224 run_lib.py:146] step: 223850, training_loss: 4.58396e-04
I0513 04:58:42.101167 22485033404224 run_lib.py:146] step: 223900, training_loss: 6.44248e-04
I0513 04:58:42.261043 22485033404224 run_lib.py:167] step: 223900, eval_loss: 7.14223e-04
I0513 04:59:05.798999 22485033404224 run_lib.py:146] step: 223950, training_loss: 6.65246e-04
I0513 04:59:29.619389 22485033404224 run_lib.py:146] step: 224000, training_loss: 4.51895e-04
I0513 04:59:29.779031 22485033404224 run_lib.py:167] step: 224000, eval_loss: 4.36101e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 04:59:53.669492 22485033404224 run_lib.py:146] step: 224050, training_loss: 6.82530e-04
I0513 05:00:17.210861 22485033404224 run_lib.py:146] step: 224100, training_loss: 5.65932e-04
I0513 05:00:17.371163 22485033404224 run_lib.py:167] step: 224100, eval_loss: 4.71670e-04
I0513 05:00:41.199923 22485033404224 run_lib.py:146] step: 224150, training_loss: 5.98577e-04
I0513 05:01:05.053514 22485033404224 run_lib.py:146] step: 224200, training_loss: 4.71511e-04
I0513 05:01:05.212455 22485033404224 run_lib.py:167] step: 224200, eval_loss: 5.92637e-04
I0513 05:01:28.759219 22485033404224 run_lib.py:146] step: 224250, training_loss: 6.35703e-04
I0513 05:01:52.630560 22485033404224 run_lib.py:146] step: 224300, training_loss: 7.76816e-04
I0513 05:01:52.791670 22485033404224 run_lib.py:167] step: 224300, eval_loss: 4.30045e-04
I0513 05:02:16.389745 22485033404224 run_lib.py:146] step: 224350, training_loss: 5.83112e-04
I0513 05:02:40.277021 22485033404224 run_lib.py:146] step: 224400, training_loss: 5.64478e-04
I0513 05:02:40.436732 22485033404224 run_lib.py:167] step: 224400, eval_loss: 4.58416e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 05:03:04.445225 22485033404224 run_lib.py:146] step: 224450, training_loss: 6.29538e-04
I0513 05:03:28.019964 22485033404224 run_lib.py:146] step: 224500, training_loss: 6.06366e-04
I0513 05:03:28.182181 22485033404224 run_lib.py:167] step: 224500, eval_loss: 6.44767e-04
I0513 05:03:52.192176 22485033404224 run_lib.py:146] step: 224550, training_loss: 7.08808e-04
I0513 05:04:16.080043 22485033404224 run_lib.py:146] step: 224600, training_loss: 6.68675e-04
I0513 05:04:16.240415 22485033404224 run_lib.py:167] step: 224600, eval_loss: 7.26964e-04
I0513 05:04:39.788028 22485033404224 run_lib.py:146] step: 224650, training_loss: 7.58911e-04
I0513 05:05:03.743627 22485033404224 run_lib.py:146] step: 224700, training_loss: 4.83696e-04
I0513 05:05:03.904181 22485033404224 run_lib.py:167] step: 224700, eval_loss: 6.31604e-04
I0513 05:05:27.479071 22485033404224 run_lib.py:146] step: 224750, training_loss: 7.08063e-04
I0513 05:05:51.365260 22485033404224 run_lib.py:146] step: 224800, training_loss: 6.22747e-04
I0513 05:05:51.525313 22485033404224 run_lib.py:167] step: 224800, eval_loss: 5.98781e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 05:06:15.637275 22485033404224 run_lib.py:146] step: 224850, training_loss: 6.17062e-04
I0513 05:06:39.251277 22485033404224 run_lib.py:146] step: 224900, training_loss: 5.60458e-04
I0513 05:06:39.414456 22485033404224 run_lib.py:167] step: 224900, eval_loss: 5.85660e-04
I0513 05:07:03.507368 22485033404224 run_lib.py:146] step: 224950, training_loss: 7.54362e-04
I0513 05:07:27.431186 22485033404224 run_lib.py:146] step: 225000, training_loss: 6.56354e-04
I0513 05:07:27.591127 22485033404224 run_lib.py:167] step: 225000, eval_loss: 4.66982e-04
I0513 05:07:51.190533 22485033404224 run_lib.py:146] step: 225050, training_loss: 4.81670e-04
I0513 05:08:15.192917 22485033404224 run_lib.py:146] step: 225100, training_loss: 5.82021e-04
I0513 05:08:15.353302 22485033404224 run_lib.py:167] step: 225100, eval_loss: 7.11403e-04
I0513 05:08:38.953024 22485033404224 run_lib.py:146] step: 225150, training_loss: 5.84817e-04
I0513 05:09:02.832988 22485033404224 run_lib.py:146] step: 225200, training_loss: 5.96947e-04
I0513 05:09:02.991808 22485033404224 run_lib.py:167] step: 225200, eval_loss: 4.75769e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 05:09:26.926844 22485033404224 run_lib.py:146] step: 225250, training_loss: 6.49783e-04
I0513 05:09:50.417171 22485033404224 run_lib.py:146] step: 225300, training_loss: 6.39957e-04
I0513 05:09:50.579063 22485033404224 run_lib.py:167] step: 225300, eval_loss: 4.57171e-04
I0513 05:10:14.444675 22485033404224 run_lib.py:146] step: 225350, training_loss: 6.70920e-04
I0513 05:10:38.277631 22485033404224 run_lib.py:146] step: 225400, training_loss: 6.18316e-04
I0513 05:10:38.437126 22485033404224 run_lib.py:167] step: 225400, eval_loss: 6.09444e-04
I0513 05:11:01.974191 22485033404224 run_lib.py:146] step: 225450, training_loss: 6.14943e-04
I0513 05:11:25.838276 22485033404224 run_lib.py:146] step: 225500, training_loss: 5.33288e-04
I0513 05:11:25.996847 22485033404224 run_lib.py:167] step: 225500, eval_loss: 5.36220e-04
I0513 05:11:49.552485 22485033404224 run_lib.py:146] step: 225550, training_loss: 5.40093e-04
I0513 05:12:13.383162 22485033404224 run_lib.py:146] step: 225600, training_loss: 7.17458e-04
I0513 05:12:13.542201 22485033404224 run_lib.py:167] step: 225600, eval_loss: 6.28861e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 05:12:37.476791 22485033404224 run_lib.py:146] step: 225650, training_loss: 5.50232e-04
I0513 05:13:01.001010 22485033404224 run_lib.py:146] step: 225700, training_loss: 7.36432e-04
I0513 05:13:01.162317 22485033404224 run_lib.py:167] step: 225700, eval_loss: 6.85248e-04
I0513 05:13:25.003891 22485033404224 run_lib.py:146] step: 225750, training_loss: 6.56108e-04
I0513 05:13:48.838125 22485033404224 run_lib.py:146] step: 225800, training_loss: 6.81161e-04
I0513 05:13:48.998768 22485033404224 run_lib.py:167] step: 225800, eval_loss: 6.29149e-04
I0513 05:14:12.513581 22485033404224 run_lib.py:146] step: 225850, training_loss: 5.61408e-04
I0513 05:14:36.350458 22485033404224 run_lib.py:146] step: 225900, training_loss: 4.57088e-04
I0513 05:14:36.510299 22485033404224 run_lib.py:167] step: 225900, eval_loss: 7.10959e-04
I0513 05:15:00.025629 22485033404224 run_lib.py:146] step: 225950, training_loss: 5.32935e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 05:15:23.913929 22485033404224 run_lib.py:146] step: 226000, training_loss: 7.84764e-04
I0513 05:15:24.074787 22485033404224 run_lib.py:167] step: 226000, eval_loss: 4.88291e-04
I0513 05:15:47.946912 22485033404224 run_lib.py:146] step: 226050, training_loss: 7.22545e-04
I0513 05:16:11.483107 22485033404224 run_lib.py:146] step: 226100, training_loss: 5.16852e-04
I0513 05:16:11.644159 22485033404224 run_lib.py:167] step: 226100, eval_loss: 5.76397e-04
I0513 05:16:35.506186 22485033404224 run_lib.py:146] step: 226150, training_loss: 6.17467e-04
I0513 05:16:59.317878 22485033404224 run_lib.py:146] step: 226200, training_loss: 7.27893e-04
I0513 05:16:59.479688 22485033404224 run_lib.py:167] step: 226200, eval_loss: 5.88440e-04
I0513 05:17:23.005870 22485033404224 run_lib.py:146] step: 226250, training_loss: 5.85264e-04
I0513 05:17:46.806299 22485033404224 run_lib.py:146] step: 226300, training_loss: 7.70981e-04
I0513 05:17:46.966044 22485033404224 run_lib.py:167] step: 226300, eval_loss: 6.14782e-04
I0513 05:18:10.493335 22485033404224 run_lib.py:146] step: 226350, training_loss: 6.79867e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 05:18:34.352543 22485033404224 run_lib.py:146] step: 226400, training_loss: 7.12427e-04
I0513 05:18:34.514280 22485033404224 run_lib.py:167] step: 226400, eval_loss: 5.36764e-04
I0513 05:18:58.383284 22485033404224 run_lib.py:146] step: 226450, training_loss: 7.91103e-04
I0513 05:19:21.931094 22485033404224 run_lib.py:146] step: 226500, training_loss: 5.74520e-04
I0513 05:19:22.091603 22485033404224 run_lib.py:167] step: 226500, eval_loss: 6.12925e-04
I0513 05:19:46.037794 22485033404224 run_lib.py:146] step: 226550, training_loss: 7.44450e-04
I0513 05:20:09.980755 22485033404224 run_lib.py:146] step: 226600, training_loss: 6.82277e-04
I0513 05:20:10.140851 22485033404224 run_lib.py:167] step: 226600, eval_loss: 3.94028e-04
I0513 05:20:33.728187 22485033404224 run_lib.py:146] step: 226650, training_loss: 5.58602e-04
I0513 05:20:57.625592 22485033404224 run_lib.py:146] step: 226700, training_loss: 4.82823e-04
I0513 05:20:57.785853 22485033404224 run_lib.py:167] step: 226700, eval_loss: 6.56066e-04
I0513 05:21:21.381206 22485033404224 run_lib.py:146] step: 226750, training_loss: 5.11097e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 05:21:45.358720 22485033404224 run_lib.py:146] step: 226800, training_loss: 5.23889e-04
I0513 05:21:45.521994 22485033404224 run_lib.py:167] step: 226800, eval_loss: 6.42604e-04
I0513 05:22:09.554333 22485033404224 run_lib.py:146] step: 226850, training_loss: 5.53276e-04
I0513 05:22:33.136752 22485033404224 run_lib.py:146] step: 226900, training_loss: 6.41201e-04
I0513 05:22:33.297573 22485033404224 run_lib.py:167] step: 226900, eval_loss: 6.05639e-04
I0513 05:22:57.351180 22485033404224 run_lib.py:146] step: 226950, training_loss: 3.97590e-04
I0513 05:23:21.364859 22485033404224 run_lib.py:146] step: 227000, training_loss: 6.93417e-04
I0513 05:23:21.525624 22485033404224 run_lib.py:167] step: 227000, eval_loss: 8.12222e-04
I0513 05:23:45.120525 22485033404224 run_lib.py:146] step: 227050, training_loss: 6.35948e-04
I0513 05:24:09.101581 22485033404224 run_lib.py:146] step: 227100, training_loss: 4.04549e-04
I0513 05:24:09.261376 22485033404224 run_lib.py:167] step: 227100, eval_loss: 7.45349e-04
I0513 05:24:33.219918 22485033404224 run_lib.py:146] step: 227150, training_loss: 7.17767e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 05:24:56.872727 22485033404224 run_lib.py:146] step: 227200, training_loss: 7.03795e-04
I0513 05:24:57.034842 22485033404224 run_lib.py:167] step: 227200, eval_loss: 5.98386e-04
I0513 05:25:20.969410 22485033404224 run_lib.py:146] step: 227250, training_loss: 5.92826e-04
I0513 05:25:44.520438 22485033404224 run_lib.py:146] step: 227300, training_loss: 5.48425e-04
I0513 05:25:44.681817 22485033404224 run_lib.py:167] step: 227300, eval_loss: 6.58964e-04
I0513 05:26:08.689893 22485033404224 run_lib.py:146] step: 227350, training_loss: 3.74707e-04
I0513 05:26:32.606090 22485033404224 run_lib.py:146] step: 227400, training_loss: 6.34810e-04
I0513 05:26:32.765654 22485033404224 run_lib.py:167] step: 227400, eval_loss: 5.02946e-04
I0513 05:26:56.353215 22485033404224 run_lib.py:146] step: 227450, training_loss: 6.90346e-04
I0513 05:27:20.261898 22485033404224 run_lib.py:146] step: 227500, training_loss: 6.87451e-04
I0513 05:27:20.420883 22485033404224 run_lib.py:167] step: 227500, eval_loss: 8.49411e-04
I0513 05:27:44.192505 22485033404224 run_lib.py:146] step: 227550, training_loss: 7.12069e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 05:28:07.780732 22485033404224 run_lib.py:146] step: 227600, training_loss: 5.86108e-04
I0513 05:28:07.940845 22485033404224 run_lib.py:167] step: 227600, eval_loss: 5.59994e-04
I0513 05:28:31.843043 22485033404224 run_lib.py:146] step: 227650, training_loss: 6.29892e-04
I0513 05:28:55.371983 22485033404224 run_lib.py:146] step: 227700, training_loss: 6.28689e-04
I0513 05:28:55.532132 22485033404224 run_lib.py:167] step: 227700, eval_loss: 5.63176e-04
I0513 05:29:19.397326 22485033404224 run_lib.py:146] step: 227750, training_loss: 3.85181e-04
I0513 05:29:43.218409 22485033404224 run_lib.py:146] step: 227800, training_loss: 6.20428e-04
I0513 05:29:43.376856 22485033404224 run_lib.py:167] step: 227800, eval_loss: 5.52328e-04
I0513 05:30:06.888555 22485033404224 run_lib.py:146] step: 227850, training_loss: 5.52261e-04
I0513 05:30:30.703548 22485033404224 run_lib.py:146] step: 227900, training_loss: 7.23880e-04
I0513 05:30:30.863327 22485033404224 run_lib.py:167] step: 227900, eval_loss: 6.97730e-04
I0513 05:30:54.657613 22485033404224 run_lib.py:146] step: 227950, training_loss: 6.60587e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 05:31:18.253192 22485033404224 run_lib.py:146] step: 228000, training_loss: 4.54341e-04
I0513 05:31:18.414520 22485033404224 run_lib.py:167] step: 228000, eval_loss: 5.41639e-04
I0513 05:31:42.248197 22485033404224 run_lib.py:146] step: 228050, training_loss: 5.79088e-04
I0513 05:32:05.786681 22485033404224 run_lib.py:146] step: 228100, training_loss: 5.13453e-04
I0513 05:32:05.948389 22485033404224 run_lib.py:167] step: 228100, eval_loss: 6.19463e-04
I0513 05:32:29.764558 22485033404224 run_lib.py:146] step: 228150, training_loss: 7.33432e-04
I0513 05:32:53.581442 22485033404224 run_lib.py:146] step: 228200, training_loss: 6.66534e-04
I0513 05:32:53.739894 22485033404224 run_lib.py:167] step: 228200, eval_loss: 6.60953e-04
I0513 05:33:17.253748 22485033404224 run_lib.py:146] step: 228250, training_loss: 6.37190e-04
I0513 05:33:41.060202 22485033404224 run_lib.py:146] step: 228300, training_loss: 5.16072e-04
I0513 05:33:41.218696 22485033404224 run_lib.py:167] step: 228300, eval_loss: 6.00397e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 05:34:05.152692 22485033404224 run_lib.py:146] step: 228350, training_loss: 4.98392e-04
I0513 05:34:28.666601 22485033404224 run_lib.py:146] step: 228400, training_loss: 5.66754e-04
I0513 05:34:28.827722 22485033404224 run_lib.py:167] step: 228400, eval_loss: 5.77127e-04
I0513 05:34:52.726977 22485033404224 run_lib.py:146] step: 228450, training_loss: 5.56089e-04
I0513 05:35:16.262350 22485033404224 run_lib.py:146] step: 228500, training_loss: 5.26152e-04
I0513 05:35:16.421185 22485033404224 run_lib.py:167] step: 228500, eval_loss: 5.75676e-04
I0513 05:35:40.212295 22485033404224 run_lib.py:146] step: 228550, training_loss: 6.04431e-04
I0513 05:36:04.043245 22485033404224 run_lib.py:146] step: 228600, training_loss: 5.17151e-04
I0513 05:36:04.203170 22485033404224 run_lib.py:167] step: 228600, eval_loss: 8.29966e-04
I0513 05:36:27.741818 22485033404224 run_lib.py:146] step: 228650, training_loss: 5.29853e-04
I0513 05:36:51.553779 22485033404224 run_lib.py:146] step: 228700, training_loss: 4.19711e-04
I0513 05:36:51.712234 22485033404224 run_lib.py:167] step: 228700, eval_loss: 6.99553e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 05:37:15.660166 22485033404224 run_lib.py:146] step: 228750, training_loss: 6.44003e-04
I0513 05:37:39.231830 22485033404224 run_lib.py:146] step: 228800, training_loss: 9.98923e-04
I0513 05:37:39.394286 22485033404224 run_lib.py:167] step: 228800, eval_loss: 7.82539e-04
I0513 05:38:03.328237 22485033404224 run_lib.py:146] step: 228850, training_loss: 7.18059e-04
I0513 05:38:27.230876 22485033404224 run_lib.py:146] step: 228900, training_loss: 6.42806e-04
I0513 05:38:27.389995 22485033404224 run_lib.py:167] step: 228900, eval_loss: 6.18427e-04
I0513 05:38:50.950194 22485033404224 run_lib.py:146] step: 228950, training_loss: 6.58607e-04
I0513 05:39:14.830191 22485033404224 run_lib.py:146] step: 229000, training_loss: 6.08158e-04
I0513 05:39:14.914017 22485033404224 run_lib.py:167] step: 229000, eval_loss: 9.83398e-04
I0513 05:39:38.524076 22485033404224 run_lib.py:146] step: 229050, training_loss: 5.96436e-04
I0513 05:40:02.434118 22485033404224 run_lib.py:146] step: 229100, training_loss: 7.37099e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 05:40:02.789792 22485033404224 run_lib.py:167] step: 229100, eval_loss: 7.47983e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 05:40:27.035647 22485033404224 run_lib.py:146] step: 229150, training_loss: 6.41851e-04
I0513 05:40:50.797341 22485033404224 run_lib.py:146] step: 229200, training_loss: 5.63700e-04
I0513 05:40:50.960871 22485033404224 run_lib.py:167] step: 229200, eval_loss: 5.30333e-04
I0513 05:41:15.145594 22485033404224 run_lib.py:146] step: 229250, training_loss: 7.31471e-04
I0513 05:41:39.238999 22485033404224 run_lib.py:146] step: 229300, training_loss: 5.79460e-04
I0513 05:41:39.401345 22485033404224 run_lib.py:167] step: 229300, eval_loss: 5.76237e-04
I0513 05:42:03.062309 22485033404224 run_lib.py:146] step: 229350, training_loss: 6.11776e-04
I0513 05:42:27.082232 22485033404224 run_lib.py:146] step: 229400, training_loss: 5.83865e-04
I0513 05:42:27.242148 22485033404224 run_lib.py:167] step: 229400, eval_loss: 6.23988e-04
I0513 05:42:50.916825 22485033404224 run_lib.py:146] step: 229450, training_loss: 7.23441e-04
I0513 05:43:14.880321 22485033404224 run_lib.py:146] step: 229500, training_loss: 6.74001e-04
I0513 05:43:15.041283 22485033404224 run_lib.py:167] step: 229500, eval_loss: 5.46707e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 05:43:39.087629 22485033404224 run_lib.py:146] step: 229550, training_loss: 5.98070e-04
I0513 05:44:02.666543 22485033404224 run_lib.py:146] step: 229600, training_loss: 5.76509e-04
I0513 05:44:02.829642 22485033404224 run_lib.py:167] step: 229600, eval_loss: 6.96045e-04
I0513 05:44:26.851157 22485033404224 run_lib.py:146] step: 229650, training_loss: 5.74675e-04
I0513 05:44:50.798823 22485033404224 run_lib.py:146] step: 229700, training_loss: 6.38581e-04
I0513 05:44:50.959201 22485033404224 run_lib.py:167] step: 229700, eval_loss: 5.27426e-04
I0513 05:45:14.538483 22485033404224 run_lib.py:146] step: 229750, training_loss: 7.04490e-04
I0513 05:45:38.444770 22485033404224 run_lib.py:146] step: 229800, training_loss: 4.74451e-04
I0513 05:45:38.603493 22485033404224 run_lib.py:167] step: 229800, eval_loss: 4.50540e-04
I0513 05:46:02.389691 22485033404224 run_lib.py:146] step: 229850, training_loss: 5.95725e-04
I0513 05:46:25.873147 22485033404224 run_lib.py:146] step: 229900, training_loss: 5.14002e-04
I0513 05:46:26.032377 22485033404224 run_lib.py:167] step: 229900, eval_loss: 6.23394e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 05:46:49.972413 22485033404224 run_lib.py:146] step: 229950, training_loss: 7.02788e-04
I0513 05:47:13.468950 22485033404224 run_lib.py:146] step: 230000, training_loss: 6.42799e-04
I0513 05:47:15.219548 22485033404224 run_lib.py:167] step: 230000, eval_loss: 6.09120e-04
I0513 05:47:40.834357 22485033404224 run_lib.py:146] step: 230050, training_loss: 4.90270e-04
I0513 05:48:04.339464 22485033404224 run_lib.py:146] step: 230100, training_loss: 6.82475e-04
I0513 05:48:04.498998 22485033404224 run_lib.py:167] step: 230100, eval_loss: 6.37447e-04
I0513 05:48:28.015238 22485033404224 run_lib.py:146] step: 230150, training_loss: 6.20465e-04
I0513 05:48:51.822226 22485033404224 run_lib.py:146] step: 230200, training_loss: 4.59967e-04
I0513 05:48:51.981569 22485033404224 run_lib.py:167] step: 230200, eval_loss: 6.42230e-04
I0513 05:49:15.775390 22485033404224 run_lib.py:146] step: 230250, training_loss: 5.98672e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 05:49:39.377781 22485033404224 run_lib.py:146] step: 230300, training_loss: 6.72276e-04
I0513 05:49:39.537998 22485033404224 run_lib.py:167] step: 230300, eval_loss: 7.40390e-04
I0513 05:50:03.397341 22485033404224 run_lib.py:146] step: 230350, training_loss: 6.10227e-04
I0513 05:50:27.268480 22485033404224 run_lib.py:146] step: 230400, training_loss: 6.05276e-04
I0513 05:50:27.428629 22485033404224 run_lib.py:167] step: 230400, eval_loss: 4.52255e-04
I0513 05:50:50.961731 22485033404224 run_lib.py:146] step: 230450, training_loss: 5.93213e-04
I0513 05:51:14.801281 22485033404224 run_lib.py:146] step: 230500, training_loss: 7.00621e-04
I0513 05:51:14.962025 22485033404224 run_lib.py:167] step: 230500, eval_loss: 7.42952e-04
I0513 05:51:38.776707 22485033404224 run_lib.py:146] step: 230550, training_loss: 7.18816e-04
I0513 05:52:02.310416 22485033404224 run_lib.py:146] step: 230600, training_loss: 6.06330e-04
I0513 05:52:02.470259 22485033404224 run_lib.py:167] step: 230600, eval_loss: 5.85051e-04
I0513 05:52:26.277732 22485033404224 run_lib.py:146] step: 230650, training_loss: 5.20777e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 05:52:50.197065 22485033404224 run_lib.py:146] step: 230700, training_loss: 6.17414e-04
I0513 05:52:50.357720 22485033404224 run_lib.py:167] step: 230700, eval_loss: 8.02400e-04
I0513 05:53:13.874204 22485033404224 run_lib.py:146] step: 230750, training_loss: 6.15668e-04
I0513 05:53:37.387210 22485033404224 run_lib.py:146] step: 230800, training_loss: 7.15348e-04
I0513 05:53:37.546738 22485033404224 run_lib.py:167] step: 230800, eval_loss: 5.44647e-04
I0513 05:54:01.757492 22485033404224 run_lib.py:146] step: 230850, training_loss: 6.82529e-04
I0513 05:54:25.246381 22485033404224 run_lib.py:146] step: 230900, training_loss: 5.45716e-04
I0513 05:54:25.406820 22485033404224 run_lib.py:167] step: 230900, eval_loss: 6.04539e-04
I0513 05:54:48.917403 22485033404224 run_lib.py:146] step: 230950, training_loss: 5.87162e-04
I0513 05:55:13.052735 22485033404224 run_lib.py:146] step: 231000, training_loss: 6.43885e-04
I0513 05:55:13.211393 22485033404224 run_lib.py:167] step: 231000, eval_loss: 6.08020e-04
I0513 05:55:36.723411 22485033404224 run_lib.py:146] step: 231050, training_loss: 4.96868e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 05:56:00.384962 22485033404224 run_lib.py:146] step: 231100, training_loss: 4.31554e-04
I0513 05:56:00.546009 22485033404224 run_lib.py:167] step: 231100, eval_loss: 4.71510e-04
I0513 05:56:24.491384 22485033404224 run_lib.py:146] step: 231150, training_loss: 6.05492e-04
I0513 05:56:48.439643 22485033404224 run_lib.py:146] step: 231200, training_loss: 5.80898e-04
I0513 05:56:48.599498 22485033404224 run_lib.py:167] step: 231200, eval_loss: 6.46537e-04
I0513 05:57:12.172763 22485033404224 run_lib.py:146] step: 231250, training_loss: 6.03195e-04
I0513 05:57:36.035664 22485033404224 run_lib.py:146] step: 231300, training_loss: 6.48864e-04
I0513 05:57:36.197022 22485033404224 run_lib.py:167] step: 231300, eval_loss: 6.92762e-04
I0513 05:58:00.068159 22485033404224 run_lib.py:146] step: 231350, training_loss: 5.42198e-04
I0513 05:58:23.627618 22485033404224 run_lib.py:146] step: 231400, training_loss: 8.36331e-04
I0513 05:58:23.787455 22485033404224 run_lib.py:167] step: 231400, eval_loss: 5.34207e-04
I0513 05:58:47.613524 22485033404224 run_lib.py:146] step: 231450, training_loss: 6.99938e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 05:59:11.745298 22485033404224 run_lib.py:146] step: 231500, training_loss: 5.03541e-04
I0513 05:59:11.906663 22485033404224 run_lib.py:167] step: 231500, eval_loss: 6.60209e-04
I0513 05:59:35.492977 22485033404224 run_lib.py:146] step: 231550, training_loss: 4.72329e-04
I0513 05:59:59.125519 22485033404224 run_lib.py:146] step: 231600, training_loss: 6.79327e-04
I0513 05:59:59.287228 22485033404224 run_lib.py:167] step: 231600, eval_loss: 7.12681e-04
I0513 06:00:23.663722 22485033404224 run_lib.py:146] step: 231650, training_loss: 4.36543e-04
I0513 06:00:47.216779 22485033404224 run_lib.py:146] step: 231700, training_loss: 6.20124e-04
I0513 06:00:47.377071 22485033404224 run_lib.py:167] step: 231700, eval_loss: 6.03896e-04
I0513 06:01:10.971092 22485033404224 run_lib.py:146] step: 231750, training_loss: 7.41036e-04
I0513 06:01:35.167510 22485033404224 run_lib.py:146] step: 231800, training_loss: 8.78564e-04
I0513 06:01:35.327540 22485033404224 run_lib.py:167] step: 231800, eval_loss: 4.81438e-04
I0513 06:01:58.918852 22485033404224 run_lib.py:146] step: 231850, training_loss: 5.80162e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 06:02:22.567075 22485033404224 run_lib.py:146] step: 231900, training_loss: 4.48802e-04
I0513 06:02:22.728290 22485033404224 run_lib.py:167] step: 231900, eval_loss: 4.93854e-04
I0513 06:02:46.678808 22485033404224 run_lib.py:146] step: 231950, training_loss: 5.50345e-04
I0513 06:03:10.616617 22485033404224 run_lib.py:146] step: 232000, training_loss: 5.07598e-04
I0513 06:03:10.775995 22485033404224 run_lib.py:167] step: 232000, eval_loss: 5.03478e-04
I0513 06:03:34.352484 22485033404224 run_lib.py:146] step: 232050, training_loss: 7.16298e-04
I0513 06:03:58.188890 22485033404224 run_lib.py:146] step: 232100, training_loss: 6.05621e-04
I0513 06:03:58.347788 22485033404224 run_lib.py:167] step: 232100, eval_loss: 6.33828e-04
I0513 06:04:22.161916 22485033404224 run_lib.py:146] step: 232150, training_loss: 6.61279e-04
I0513 06:04:45.707874 22485033404224 run_lib.py:146] step: 232200, training_loss: 7.87673e-04
I0513 06:04:45.868129 22485033404224 run_lib.py:167] step: 232200, eval_loss: 7.66520e-04
I0513 06:05:09.677254 22485033404224 run_lib.py:146] step: 232250, training_loss: 5.59308e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 06:05:33.578590 22485033404224 run_lib.py:146] step: 232300, training_loss: 8.13159e-04
I0513 06:05:33.739275 22485033404224 run_lib.py:167] step: 232300, eval_loss: 7.20766e-04
I0513 06:05:57.196377 22485033404224 run_lib.py:146] step: 232350, training_loss: 6.82779e-04
I0513 06:06:20.696923 22485033404224 run_lib.py:146] step: 232400, training_loss: 5.33879e-04
I0513 06:06:20.858019 22485033404224 run_lib.py:167] step: 232400, eval_loss: 5.32999e-04
I0513 06:06:44.964165 22485033404224 run_lib.py:146] step: 232450, training_loss: 6.94761e-04
I0513 06:07:08.491922 22485033404224 run_lib.py:146] step: 232500, training_loss: 8.69910e-04
I0513 06:07:08.651932 22485033404224 run_lib.py:167] step: 232500, eval_loss: 6.41238e-04
I0513 06:07:32.162898 22485033404224 run_lib.py:146] step: 232550, training_loss: 5.49551e-04
I0513 06:07:56.271949 22485033404224 run_lib.py:146] step: 232600, training_loss: 4.46217e-04
I0513 06:07:56.430965 22485033404224 run_lib.py:167] step: 232600, eval_loss: 5.14696e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 06:08:20.005482 22485033404224 run_lib.py:146] step: 232650, training_loss: 5.33226e-04
I0513 06:08:43.549965 22485033404224 run_lib.py:146] step: 232700, training_loss: 4.60905e-04
I0513 06:08:43.711210 22485033404224 run_lib.py:167] step: 232700, eval_loss: 7.51602e-04
I0513 06:09:07.532035 22485033404224 run_lib.py:146] step: 232750, training_loss: 4.58343e-04
I0513 06:09:31.387753 22485033404224 run_lib.py:146] step: 232800, training_loss: 6.78370e-04
I0513 06:09:31.546324 22485033404224 run_lib.py:167] step: 232800, eval_loss: 7.12542e-04
I0513 06:09:55.065030 22485033404224 run_lib.py:146] step: 232850, training_loss: 7.54359e-04
I0513 06:10:18.888510 22485033404224 run_lib.py:146] step: 232900, training_loss: 6.96643e-04
I0513 06:10:19.048445 22485033404224 run_lib.py:167] step: 232900, eval_loss: 6.59135e-04
I0513 06:10:42.875314 22485033404224 run_lib.py:146] step: 232950, training_loss: 5.04734e-04
I0513 06:11:06.395016 22485033404224 run_lib.py:146] step: 233000, training_loss: 4.58640e-04
I0513 06:11:06.554021 22485033404224 run_lib.py:167] step: 233000, eval_loss: 6.33606e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 06:11:30.493762 22485033404224 run_lib.py:146] step: 233050, training_loss: 7.44148e-04
I0513 06:11:54.403198 22485033404224 run_lib.py:146] step: 233100, training_loss: 5.44771e-04
I0513 06:11:54.563595 22485033404224 run_lib.py:167] step: 233100, eval_loss: 5.56006e-04
I0513 06:12:18.080657 22485033404224 run_lib.py:146] step: 233150, training_loss: 5.15347e-04
I0513 06:12:41.574936 22485033404224 run_lib.py:146] step: 233200, training_loss: 6.04890e-04
I0513 06:12:41.734419 22485033404224 run_lib.py:167] step: 233200, eval_loss: 3.57123e-04
I0513 06:13:05.862020 22485033404224 run_lib.py:146] step: 233250, training_loss: 5.63628e-04
I0513 06:13:29.378981 22485033404224 run_lib.py:146] step: 233300, training_loss: 6.35168e-04
I0513 06:13:29.537405 22485033404224 run_lib.py:167] step: 233300, eval_loss: 6.06913e-04
I0513 06:13:53.104384 22485033404224 run_lib.py:146] step: 233350, training_loss: 6.97259e-04
I0513 06:14:17.339476 22485033404224 run_lib.py:146] step: 233400, training_loss: 6.11601e-04
I0513 06:14:17.500128 22485033404224 run_lib.py:167] step: 233400, eval_loss: 4.71100e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 06:14:41.167586 22485033404224 run_lib.py:146] step: 233450, training_loss: 6.76160e-04
I0513 06:15:04.746599 22485033404224 run_lib.py:146] step: 233500, training_loss: 7.52590e-04
I0513 06:15:04.909617 22485033404224 run_lib.py:167] step: 233500, eval_loss: 6.82482e-04
I0513 06:15:28.874703 22485033404224 run_lib.py:146] step: 233550, training_loss: 5.28124e-04
I0513 06:15:52.883019 22485033404224 run_lib.py:146] step: 233600, training_loss: 5.30463e-04
I0513 06:15:53.043266 22485033404224 run_lib.py:167] step: 233600, eval_loss: 4.74973e-04
I0513 06:16:16.606030 22485033404224 run_lib.py:146] step: 233650, training_loss: 6.81748e-04
I0513 06:16:40.532172 22485033404224 run_lib.py:146] step: 233700, training_loss: 7.61257e-04
I0513 06:16:40.693137 22485033404224 run_lib.py:167] step: 233700, eval_loss: 5.74429e-04
I0513 06:17:04.672917 22485033404224 run_lib.py:146] step: 233750, training_loss: 6.66632e-04
I0513 06:17:28.265160 22485033404224 run_lib.py:146] step: 233800, training_loss: 7.11589e-04
I0513 06:17:28.426964 22485033404224 run_lib.py:167] step: 233800, eval_loss: 7.95405e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 06:17:52.555487 22485033404224 run_lib.py:146] step: 233850, training_loss: 4.91409e-04
I0513 06:18:16.713529 22485033404224 run_lib.py:146] step: 233900, training_loss: 5.63633e-04
I0513 06:18:16.876290 22485033404224 run_lib.py:167] step: 233900, eval_loss: 6.80112e-04
I0513 06:18:40.486082 22485033404224 run_lib.py:146] step: 233950, training_loss: 5.67887e-04
I0513 06:19:04.431216 22485033404224 run_lib.py:146] step: 234000, training_loss: 6.48692e-04
I0513 06:19:04.592876 22485033404224 run_lib.py:167] step: 234000, eval_loss: 5.70118e-04
I0513 06:19:28.530162 22485033404224 run_lib.py:146] step: 234050, training_loss: 7.68496e-04
I0513 06:19:52.110145 22485033404224 run_lib.py:146] step: 234100, training_loss: 4.86373e-04
I0513 06:19:52.269690 22485033404224 run_lib.py:167] step: 234100, eval_loss: 5.81078e-04
I0513 06:20:15.893491 22485033404224 run_lib.py:146] step: 234150, training_loss: 5.10553e-04
I0513 06:20:40.112622 22485033404224 run_lib.py:146] step: 234200, training_loss: 6.74399e-04
I0513 06:20:40.273964 22485033404224 run_lib.py:167] step: 234200, eval_loss: 8.18378e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 06:21:03.926974 22485033404224 run_lib.py:146] step: 234250, training_loss: 5.87562e-04
I0513 06:21:27.498449 22485033404224 run_lib.py:146] step: 234300, training_loss: 6.06117e-04
I0513 06:21:27.657914 22485033404224 run_lib.py:167] step: 234300, eval_loss: 5.00810e-04
I0513 06:21:51.530696 22485033404224 run_lib.py:146] step: 234350, training_loss: 5.00964e-04
I0513 06:22:15.407160 22485033404224 run_lib.py:146] step: 234400, training_loss: 6.22812e-04
I0513 06:22:15.568511 22485033404224 run_lib.py:167] step: 234400, eval_loss: 5.77720e-04
I0513 06:22:39.097796 22485033404224 run_lib.py:146] step: 234450, training_loss: 9.22199e-04
I0513 06:23:02.926728 22485033404224 run_lib.py:146] step: 234500, training_loss: 6.70147e-04
I0513 06:23:03.087246 22485033404224 run_lib.py:167] step: 234500, eval_loss: 6.77694e-04
I0513 06:23:26.902299 22485033404224 run_lib.py:146] step: 234550, training_loss: 7.41322e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 06:23:50.523339 22485033404224 run_lib.py:146] step: 234600, training_loss: 6.44568e-04
I0513 06:23:50.684849 22485033404224 run_lib.py:167] step: 234600, eval_loss: 5.63338e-04
I0513 06:24:14.558910 22485033404224 run_lib.py:146] step: 234650, training_loss: 7.40570e-04
I0513 06:24:38.386103 22485033404224 run_lib.py:146] step: 234700, training_loss: 7.27320e-04
I0513 06:24:38.544484 22485033404224 run_lib.py:167] step: 234700, eval_loss: 5.81605e-04
I0513 06:25:02.019582 22485033404224 run_lib.py:146] step: 234750, training_loss: 6.37052e-04
I0513 06:25:25.812503 22485033404224 run_lib.py:146] step: 234800, training_loss: 6.18810e-04
I0513 06:25:25.972382 22485033404224 run_lib.py:167] step: 234800, eval_loss: 6.58434e-04
I0513 06:25:49.758772 22485033404224 run_lib.py:146] step: 234850, training_loss: 8.59613e-04
I0513 06:26:13.255869 22485033404224 run_lib.py:146] step: 234900, training_loss: 4.65753e-04
I0513 06:26:13.414850 22485033404224 run_lib.py:167] step: 234900, eval_loss: 5.99640e-04
I0513 06:26:36.913177 22485033404224 run_lib.py:146] step: 234950, training_loss: 5.67684e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 06:27:01.132980 22485033404224 run_lib.py:146] step: 235000, training_loss: 4.24381e-04
I0513 06:27:01.295216 22485033404224 run_lib.py:167] step: 235000, eval_loss: 6.57244e-04
I0513 06:27:24.812295 22485033404224 run_lib.py:146] step: 235050, training_loss: 6.18371e-04
I0513 06:27:48.334545 22485033404224 run_lib.py:146] step: 235100, training_loss: 6.63224e-04
I0513 06:27:48.496015 22485033404224 run_lib.py:167] step: 235100, eval_loss: 6.83451e-04
I0513 06:28:12.635956 22485033404224 run_lib.py:146] step: 235150, training_loss: 5.92191e-04
I0513 06:28:36.143493 22485033404224 run_lib.py:146] step: 235200, training_loss: 6.24068e-04
I0513 06:28:36.304614 22485033404224 run_lib.py:167] step: 235200, eval_loss: 7.24098e-04
I0513 06:28:59.816048 22485033404224 run_lib.py:146] step: 235250, training_loss: 5.51862e-04
I0513 06:29:23.629527 22485033404224 run_lib.py:146] step: 235300, training_loss: 6.91631e-04
I0513 06:29:23.790823 22485033404224 run_lib.py:167] step: 235300, eval_loss: 4.12285e-04
I0513 06:29:47.602319 22485033404224 run_lib.py:146] step: 235350, training_loss: 5.53709e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 06:30:11.186097 22485033404224 run_lib.py:146] step: 235400, training_loss: 7.49667e-04
I0513 06:30:11.348073 22485033404224 run_lib.py:167] step: 235400, eval_loss: 6.31653e-04
I0513 06:30:35.211640 22485033404224 run_lib.py:146] step: 235450, training_loss: 6.73802e-04
I0513 06:30:59.074999 22485033404224 run_lib.py:146] step: 235500, training_loss: 6.62277e-04
I0513 06:30:59.236013 22485033404224 run_lib.py:167] step: 235500, eval_loss: 5.46067e-04
I0513 06:31:22.787506 22485033404224 run_lib.py:146] step: 235550, training_loss: 5.41510e-04
I0513 06:31:46.686562 22485033404224 run_lib.py:146] step: 235600, training_loss: 6.48759e-04
I0513 06:31:46.846957 22485033404224 run_lib.py:167] step: 235600, eval_loss: 6.41223e-04
I0513 06:32:10.773342 22485033404224 run_lib.py:146] step: 235650, training_loss: 6.99505e-04
I0513 06:32:34.349992 22485033404224 run_lib.py:146] step: 235700, training_loss: 4.30066e-04
I0513 06:32:34.510416 22485033404224 run_lib.py:167] step: 235700, eval_loss: 4.84243e-04
I0513 06:32:58.399692 22485033404224 run_lib.py:146] step: 235750, training_loss: 5.28178e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 06:33:22.420241 22485033404224 run_lib.py:146] step: 235800, training_loss: 7.83667e-04
I0513 06:33:22.581788 22485033404224 run_lib.py:167] step: 235800, eval_loss: 6.79110e-04
I0513 06:33:46.147842 22485033404224 run_lib.py:146] step: 235850, training_loss: 5.48618e-04
I0513 06:34:09.744227 22485033404224 run_lib.py:146] step: 235900, training_loss: 6.49600e-04
I0513 06:34:09.904028 22485033404224 run_lib.py:167] step: 235900, eval_loss: 7.93266e-04
I0513 06:34:34.235421 22485033404224 run_lib.py:146] step: 235950, training_loss: 7.64599e-04
I0513 06:34:57.779985 22485033404224 run_lib.py:146] step: 236000, training_loss: 7.07498e-04
I0513 06:34:57.940220 22485033404224 run_lib.py:167] step: 236000, eval_loss: 5.54819e-04
I0513 06:35:21.521756 22485033404224 run_lib.py:146] step: 236050, training_loss: 6.16730e-04
I0513 06:35:45.521419 22485033404224 run_lib.py:146] step: 236100, training_loss: 7.46996e-04
I0513 06:35:45.681713 22485033404224 run_lib.py:167] step: 236100, eval_loss: 8.00656e-04
I0513 06:36:09.540956 22485033404224 run_lib.py:146] step: 236150, training_loss: 6.37179e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 06:36:33.207677 22485033404224 run_lib.py:146] step: 236200, training_loss: 6.25605e-04
I0513 06:36:33.369869 22485033404224 run_lib.py:167] step: 236200, eval_loss: 5.63968e-04
I0513 06:36:57.315209 22485033404224 run_lib.py:146] step: 236250, training_loss: 6.28229e-04
I0513 06:37:21.338569 22485033404224 run_lib.py:146] step: 236300, training_loss: 7.34722e-04
I0513 06:37:21.498061 22485033404224 run_lib.py:167] step: 236300, eval_loss: 7.67043e-04
I0513 06:37:45.090261 22485033404224 run_lib.py:146] step: 236350, training_loss: 6.52087e-04
I0513 06:38:09.006337 22485033404224 run_lib.py:146] step: 236400, training_loss: 6.53194e-04
I0513 06:38:09.167155 22485033404224 run_lib.py:167] step: 236400, eval_loss: 6.29607e-04
I0513 06:38:33.087522 22485033404224 run_lib.py:146] step: 236450, training_loss: 5.67299e-04
I0513 06:38:56.618237 22485033404224 run_lib.py:146] step: 236500, training_loss: 6.11624e-04
I0513 06:38:56.777861 22485033404224 run_lib.py:167] step: 236500, eval_loss: 5.78810e-04
I0513 06:39:20.544442 22485033404224 run_lib.py:146] step: 236550, training_loss: 6.31620e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 06:39:44.461942 22485033404224 run_lib.py:146] step: 236600, training_loss: 7.02088e-04
I0513 06:39:44.621369 22485033404224 run_lib.py:167] step: 236600, eval_loss: 6.99659e-04
I0513 06:40:08.096793 22485033404224 run_lib.py:146] step: 236650, training_loss: 6.39693e-04
I0513 06:40:31.918196 22485033404224 run_lib.py:146] step: 236700, training_loss: 6.73774e-04
I0513 06:40:32.078119 22485033404224 run_lib.py:167] step: 236700, eval_loss: 6.37580e-04
I0513 06:40:55.848647 22485033404224 run_lib.py:146] step: 236750, training_loss: 6.35215e-04
I0513 06:41:19.339492 22485033404224 run_lib.py:146] step: 236800, training_loss: 6.91696e-04
I0513 06:41:19.497591 22485033404224 run_lib.py:167] step: 236800, eval_loss: 5.23898e-04
I0513 06:41:42.950078 22485033404224 run_lib.py:146] step: 236850, training_loss: 6.50637e-04
I0513 06:42:06.769944 22485033404224 run_lib.py:146] step: 236900, training_loss: 5.40352e-04
I0513 06:42:06.852323 22485033404224 run_lib.py:167] step: 236900, eval_loss: 1.05353e-03
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 06:42:30.706581 22485033404224 run_lib.py:146] step: 236950, training_loss: 4.00757e-04
I0513 06:42:54.243319 22485033404224 run_lib.py:146] step: 237000, training_loss: 5.56594e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 06:42:54.591603 22485033404224 run_lib.py:167] step: 237000, eval_loss: 5.92273e-04
I0513 06:43:18.457026 22485033404224 run_lib.py:146] step: 237050, training_loss: 5.81165e-04
I0513 06:43:42.340114 22485033404224 run_lib.py:146] step: 237100, training_loss: 5.00900e-04
I0513 06:43:42.498958 22485033404224 run_lib.py:167] step: 237100, eval_loss: 6.99870e-04
I0513 06:44:06.011537 22485033404224 run_lib.py:146] step: 237150, training_loss: 6.76298e-04
I0513 06:44:29.830520 22485033404224 run_lib.py:146] step: 237200, training_loss: 4.42667e-04
I0513 06:44:29.990396 22485033404224 run_lib.py:167] step: 237200, eval_loss: 7.99364e-04
I0513 06:44:53.794243 22485033404224 run_lib.py:146] step: 237250, training_loss: 4.60213e-04
I0513 06:45:17.338895 22485033404224 run_lib.py:146] step: 237300, training_loss: 6.66228e-04
I0513 06:45:17.499127 22485033404224 run_lib.py:167] step: 237300, eval_loss: 4.93747e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 06:45:41.404150 22485033404224 run_lib.py:146] step: 237350, training_loss: 6.38062e-04
I0513 06:46:05.309593 22485033404224 run_lib.py:146] step: 237400, training_loss: 6.15614e-04
I0513 06:46:05.471741 22485033404224 run_lib.py:167] step: 237400, eval_loss: 5.32084e-04
I0513 06:46:28.981467 22485033404224 run_lib.py:146] step: 237450, training_loss: 5.99872e-04
I0513 06:46:52.842669 22485033404224 run_lib.py:146] step: 237500, training_loss: 5.24522e-04
I0513 06:46:53.001922 22485033404224 run_lib.py:167] step: 237500, eval_loss: 5.58527e-04
I0513 06:47:16.828197 22485033404224 run_lib.py:146] step: 237550, training_loss: 7.15003e-04
I0513 06:47:40.335629 22485033404224 run_lib.py:146] step: 237600, training_loss: 5.64038e-04
I0513 06:47:40.495592 22485033404224 run_lib.py:167] step: 237600, eval_loss: 8.85756e-04
I0513 06:48:04.006497 22485033404224 run_lib.py:146] step: 237650, training_loss: 7.71188e-04
I0513 06:48:28.129108 22485033404224 run_lib.py:146] step: 237700, training_loss: 6.33355e-04
I0513 06:48:28.288518 22485033404224 run_lib.py:167] step: 237700, eval_loss: 8.36658e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 06:48:51.887990 22485033404224 run_lib.py:146] step: 237750, training_loss: 6.07924e-04
I0513 06:49:15.486433 22485033404224 run_lib.py:146] step: 237800, training_loss: 6.64678e-04
I0513 06:49:15.646966 22485033404224 run_lib.py:167] step: 237800, eval_loss: 4.42677e-04
I0513 06:49:39.575852 22485033404224 run_lib.py:146] step: 237850, training_loss: 4.11060e-04
I0513 06:50:03.517084 22485033404224 run_lib.py:146] step: 237900, training_loss: 5.73517e-04
I0513 06:50:03.676696 22485033404224 run_lib.py:167] step: 237900, eval_loss: 5.89319e-04
I0513 06:50:27.313167 22485033404224 run_lib.py:146] step: 237950, training_loss: 5.61533e-04
I0513 06:50:51.227220 22485033404224 run_lib.py:146] step: 238000, training_loss: 5.95155e-04
I0513 06:50:51.387854 22485033404224 run_lib.py:167] step: 238000, eval_loss: 7.98806e-04
I0513 06:51:15.315945 22485033404224 run_lib.py:146] step: 238050, training_loss: 7.08009e-04
I0513 06:51:38.918734 22485033404224 run_lib.py:146] step: 238100, training_loss: 4.78462e-04
I0513 06:51:39.079313 22485033404224 run_lib.py:167] step: 238100, eval_loss: 6.35641e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 06:52:03.243581 22485033404224 run_lib.py:146] step: 238150, training_loss: 6.48137e-04
I0513 06:52:27.332133 22485033404224 run_lib.py:146] step: 238200, training_loss: 7.91772e-04
I0513 06:52:27.494089 22485033404224 run_lib.py:167] step: 238200, eval_loss: 6.36128e-04
I0513 06:52:51.134955 22485033404224 run_lib.py:146] step: 238250, training_loss: 5.57989e-04
I0513 06:53:15.169984 22485033404224 run_lib.py:146] step: 238300, training_loss: 5.88225e-04
I0513 06:53:15.330265 22485033404224 run_lib.py:167] step: 238300, eval_loss: 6.64357e-04
I0513 06:53:39.293766 22485033404224 run_lib.py:146] step: 238350, training_loss: 6.37833e-04
I0513 06:54:02.877040 22485033404224 run_lib.py:146] step: 238400, training_loss: 4.46808e-04
I0513 06:54:03.036286 22485033404224 run_lib.py:167] step: 238400, eval_loss: 5.25721e-04
I0513 06:54:26.922845 22485033404224 run_lib.py:146] step: 238450, training_loss: 6.14588e-04
I0513 06:54:50.788013 22485033404224 run_lib.py:146] step: 238500, training_loss: 4.88384e-04
I0513 06:54:50.948882 22485033404224 run_lib.py:167] step: 238500, eval_loss: 6.46660e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 06:55:14.598227 22485033404224 run_lib.py:146] step: 238550, training_loss: 5.13745e-04
I0513 06:55:38.220951 22485033404224 run_lib.py:146] step: 238600, training_loss: 7.52518e-04
I0513 06:55:38.381671 22485033404224 run_lib.py:167] step: 238600, eval_loss: 4.49917e-04
I0513 06:56:02.635493 22485033404224 run_lib.py:146] step: 238650, training_loss: 7.01576e-04
I0513 06:56:26.138026 22485033404224 run_lib.py:146] step: 238700, training_loss: 5.60896e-04
I0513 06:56:26.296638 22485033404224 run_lib.py:167] step: 238700, eval_loss: 6.46786e-04
I0513 06:56:49.813552 22485033404224 run_lib.py:146] step: 238750, training_loss: 6.56178e-04
I0513 06:57:13.641829 22485033404224 run_lib.py:146] step: 238800, training_loss: 5.75582e-04
I0513 06:57:13.800054 22485033404224 run_lib.py:167] step: 238800, eval_loss: 4.76147e-04
I0513 06:57:37.565147 22485033404224 run_lib.py:146] step: 238850, training_loss: 7.22741e-04
I0513 06:58:00.926795 22485033404224 run_lib.py:146] step: 238900, training_loss: 6.09320e-04
I0513 06:58:01.085868 22485033404224 run_lib.py:167] step: 238900, eval_loss: 6.20211e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 06:58:25.107501 22485033404224 run_lib.py:146] step: 238950, training_loss: 6.79074e-04
I0513 06:58:48.955555 22485033404224 run_lib.py:146] step: 239000, training_loss: 5.12672e-04
I0513 06:58:49.114090 22485033404224 run_lib.py:167] step: 239000, eval_loss: 6.99299e-04
I0513 06:59:12.620057 22485033404224 run_lib.py:146] step: 239050, training_loss: 6.44423e-04
I0513 06:59:36.438290 22485033404224 run_lib.py:146] step: 239100, training_loss: 5.23775e-04
I0513 06:59:36.597379 22485033404224 run_lib.py:167] step: 239100, eval_loss: 5.53970e-04
I0513 07:00:00.404735 22485033404224 run_lib.py:146] step: 239150, training_loss: 5.52256e-04
I0513 07:00:23.928173 22485033404224 run_lib.py:146] step: 239200, training_loss: 4.43602e-04
I0513 07:00:24.088332 22485033404224 run_lib.py:167] step: 239200, eval_loss: 4.62258e-04
I0513 07:00:47.876855 22485033404224 run_lib.py:146] step: 239250, training_loss: 5.67365e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 07:01:11.773108 22485033404224 run_lib.py:146] step: 239300, training_loss: 5.98272e-04
I0513 07:01:11.933282 22485033404224 run_lib.py:167] step: 239300, eval_loss: 5.65049e-04
I0513 07:01:35.427500 22485033404224 run_lib.py:146] step: 239350, training_loss: 7.23500e-04
I0513 07:01:58.908666 22485033404224 run_lib.py:146] step: 239400, training_loss: 5.13400e-04
I0513 07:01:59.069087 22485033404224 run_lib.py:167] step: 239400, eval_loss: 6.67431e-04
I0513 07:02:23.207273 22485033404224 run_lib.py:146] step: 239450, training_loss: 5.41480e-04
I0513 07:02:46.722442 22485033404224 run_lib.py:146] step: 239500, training_loss: 5.41655e-04
I0513 07:02:46.881434 22485033404224 run_lib.py:167] step: 239500, eval_loss: 5.08448e-04
I0513 07:03:10.397483 22485033404224 run_lib.py:146] step: 239550, training_loss: 6.42491e-04
I0513 07:03:34.161189 22485033404224 run_lib.py:146] step: 239600, training_loss: 8.93619e-04
I0513 07:03:34.320866 22485033404224 run_lib.py:167] step: 239600, eval_loss: 5.97418e-04
I0513 07:03:58.123785 22485033404224 run_lib.py:146] step: 239650, training_loss: 6.71148e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 07:04:21.723581 22485033404224 run_lib.py:146] step: 239700, training_loss: 6.28180e-04
I0513 07:04:21.886539 22485033404224 run_lib.py:167] step: 239700, eval_loss: 5.76453e-04
I0513 07:04:45.758035 22485033404224 run_lib.py:146] step: 239750, training_loss: 4.59840e-04
I0513 07:05:09.621889 22485033404224 run_lib.py:146] step: 239800, training_loss: 4.58615e-04
I0513 07:05:09.782467 22485033404224 run_lib.py:167] step: 239800, eval_loss: 6.13590e-04
I0513 07:05:33.277677 22485033404224 run_lib.py:146] step: 239850, training_loss: 4.83020e-04
I0513 07:05:57.098197 22485033404224 run_lib.py:146] step: 239900, training_loss: 7.77444e-04
I0513 07:05:57.256907 22485033404224 run_lib.py:167] step: 239900, eval_loss: 5.70442e-04
I0513 07:06:21.064060 22485033404224 run_lib.py:146] step: 239950, training_loss: 6.46841e-04
I0513 07:06:44.603058 22485033404224 run_lib.py:146] step: 240000, training_loss: 6.52312e-04
I0513 07:06:46.343537 22485033404224 run_lib.py:167] step: 240000, eval_loss: 5.14476e-04
I0513 07:07:12.074665 22485033404224 run_lib.py:146] step: 240050, training_loss: 4.92584e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 07:07:35.735335 22485033404224 run_lib.py:146] step: 240100, training_loss: 6.95134e-04
I0513 07:07:35.898839 22485033404224 run_lib.py:167] step: 240100, eval_loss: 6.61137e-04
I0513 07:07:59.515206 22485033404224 run_lib.py:146] step: 240150, training_loss: 8.35843e-04
I0513 07:08:23.576250 22485033404224 run_lib.py:146] step: 240200, training_loss: 4.82503e-04
I0513 07:08:23.736216 22485033404224 run_lib.py:167] step: 240200, eval_loss: 5.19315e-04
I0513 07:08:47.781029 22485033404224 run_lib.py:146] step: 240250, training_loss: 6.65208e-04
I0513 07:09:11.355237 22485033404224 run_lib.py:146] step: 240300, training_loss: 7.10725e-04
I0513 07:09:11.515188 22485033404224 run_lib.py:167] step: 240300, eval_loss: 7.73632e-04
I0513 07:09:35.110714 22485033404224 run_lib.py:146] step: 240350, training_loss: 6.89625e-04
I0513 07:09:59.491410 22485033404224 run_lib.py:146] step: 240400, training_loss: 7.54515e-04
I0513 07:09:59.651463 22485033404224 run_lib.py:167] step: 240400, eval_loss: 5.71854e-04
I0513 07:10:23.236766 22485033404224 run_lib.py:146] step: 240450, training_loss: 8.14648e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 07:10:46.902104 22485033404224 run_lib.py:146] step: 240500, training_loss: 8.66954e-04
I0513 07:10:47.064718 22485033404224 run_lib.py:167] step: 240500, eval_loss: 6.13611e-04
I0513 07:11:11.541798 22485033404224 run_lib.py:146] step: 240550, training_loss: 6.28657e-04
I0513 07:11:35.117505 22485033404224 run_lib.py:146] step: 240600, training_loss: 4.54412e-04
I0513 07:11:35.277931 22485033404224 run_lib.py:167] step: 240600, eval_loss: 5.15462e-04
I0513 07:11:58.874508 22485033404224 run_lib.py:146] step: 240650, training_loss: 5.37369e-04
I0513 07:12:23.084824 22485033404224 run_lib.py:146] step: 240700, training_loss: 7.37733e-04
I0513 07:12:23.244447 22485033404224 run_lib.py:167] step: 240700, eval_loss: 5.40699e-04
I0513 07:12:46.811598 22485033404224 run_lib.py:146] step: 240750, training_loss: 5.53823e-04
I0513 07:13:10.436882 22485033404224 run_lib.py:146] step: 240800, training_loss: 5.11956e-04
I0513 07:13:10.596901 22485033404224 run_lib.py:167] step: 240800, eval_loss: 5.65194e-04
I0513 07:13:34.776830 22485033404224 run_lib.py:146] step: 240850, training_loss: 6.96070e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 07:13:58.412878 22485033404224 run_lib.py:146] step: 240900, training_loss: 6.26836e-04
I0513 07:13:58.575355 22485033404224 run_lib.py:167] step: 240900, eval_loss: 5.25191e-04
I0513 07:14:22.129846 22485033404224 run_lib.py:146] step: 240950, training_loss: 5.23329e-04
I0513 07:14:46.334434 22485033404224 run_lib.py:146] step: 241000, training_loss: 5.33035e-04
I0513 07:14:46.493422 22485033404224 run_lib.py:167] step: 241000, eval_loss: 4.52861e-04
I0513 07:15:10.017127 22485033404224 run_lib.py:146] step: 241050, training_loss: 8.19433e-04
I0513 07:15:33.558969 22485033404224 run_lib.py:146] step: 241100, training_loss: 6.51333e-04
I0513 07:15:33.717928 22485033404224 run_lib.py:167] step: 241100, eval_loss: 4.36332e-04
I0513 07:15:57.510696 22485033404224 run_lib.py:146] step: 241150, training_loss: 5.62022e-04
I0513 07:16:21.310734 22485033404224 run_lib.py:146] step: 241200, training_loss: 7.22219e-04
I0513 07:16:21.470617 22485033404224 run_lib.py:167] step: 241200, eval_loss: 5.60486e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 07:16:45.059736 22485033404224 run_lib.py:146] step: 241250, training_loss: 7.06438e-04
I0513 07:17:08.564988 22485033404224 run_lib.py:146] step: 241300, training_loss: 7.72101e-04
I0513 07:17:08.725278 22485033404224 run_lib.py:167] step: 241300, eval_loss: 4.07289e-04
I0513 07:17:32.922632 22485033404224 run_lib.py:146] step: 241350, training_loss: 7.23542e-04
I0513 07:17:56.457824 22485033404224 run_lib.py:146] step: 241400, training_loss: 5.56165e-04
I0513 07:17:56.616702 22485033404224 run_lib.py:167] step: 241400, eval_loss: 4.88362e-04
I0513 07:18:20.167382 22485033404224 run_lib.py:146] step: 241450, training_loss: 4.80867e-04
I0513 07:18:44.282575 22485033404224 run_lib.py:146] step: 241500, training_loss: 7.18103e-04
I0513 07:18:44.444206 22485033404224 run_lib.py:167] step: 241500, eval_loss: 7.45637e-04
I0513 07:19:07.969023 22485033404224 run_lib.py:146] step: 241550, training_loss: 6.69634e-04
I0513 07:19:31.514804 22485033404224 run_lib.py:146] step: 241600, training_loss: 5.61911e-04
I0513 07:19:31.675006 22485033404224 run_lib.py:167] step: 241600, eval_loss: 6.92053e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 07:19:55.861294 22485033404224 run_lib.py:146] step: 241650, training_loss: 6.18933e-04
I0513 07:20:19.370670 22485033404224 run_lib.py:146] step: 241700, training_loss: 5.58259e-04
I0513 07:20:19.531417 22485033404224 run_lib.py:167] step: 241700, eval_loss: 6.03110e-04
I0513 07:20:43.054338 22485033404224 run_lib.py:146] step: 241750, training_loss: 6.49044e-04
I0513 07:21:07.255498 22485033404224 run_lib.py:146] step: 241800, training_loss: 7.05258e-04
I0513 07:21:07.416751 22485033404224 run_lib.py:167] step: 241800, eval_loss: 5.12153e-04
I0513 07:21:30.934112 22485033404224 run_lib.py:146] step: 241850, training_loss: 6.34879e-04
I0513 07:21:54.449871 22485033404224 run_lib.py:146] step: 241900, training_loss: 7.29562e-04
I0513 07:21:54.608817 22485033404224 run_lib.py:167] step: 241900, eval_loss: 8.18261e-04
I0513 07:22:18.479074 22485033404224 run_lib.py:146] step: 241950, training_loss: 6.24976e-04
I0513 07:22:42.326895 22485033404224 run_lib.py:146] step: 242000, training_loss: 6.53026e-04
I0513 07:22:42.486200 22485033404224 run_lib.py:167] step: 242000, eval_loss: 7.83118e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 07:23:06.101624 22485033404224 run_lib.py:146] step: 242050, training_loss: 4.58745e-04
I0513 07:23:29.615001 22485033404224 run_lib.py:146] step: 242100, training_loss: 6.52081e-04
I0513 07:23:29.775867 22485033404224 run_lib.py:167] step: 242100, eval_loss: 7.95234e-04
I0513 07:23:53.969229 22485033404224 run_lib.py:146] step: 242150, training_loss: 6.49221e-04
I0513 07:24:17.523699 22485033404224 run_lib.py:146] step: 242200, training_loss: 6.54303e-04
I0513 07:24:17.683757 22485033404224 run_lib.py:167] step: 242200, eval_loss: 7.02272e-04
I0513 07:24:41.280512 22485033404224 run_lib.py:146] step: 242250, training_loss: 4.31664e-04
I0513 07:25:05.495185 22485033404224 run_lib.py:146] step: 242300, training_loss: 7.51141e-04
I0513 07:25:05.655814 22485033404224 run_lib.py:167] step: 242300, eval_loss: 6.46243e-04
I0513 07:25:29.258671 22485033404224 run_lib.py:146] step: 242350, training_loss: 5.89640e-04
I0513 07:25:52.890116 22485033404224 run_lib.py:146] step: 242400, training_loss: 6.60435e-04
I0513 07:25:53.050457 22485033404224 run_lib.py:167] step: 242400, eval_loss: 5.55390e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 07:26:17.430024 22485033404224 run_lib.py:146] step: 242450, training_loss: 5.79273e-04
I0513 07:26:41.025791 22485033404224 run_lib.py:146] step: 242500, training_loss: 5.67011e-04
I0513 07:26:41.188222 22485033404224 run_lib.py:167] step: 242500, eval_loss: 9.50733e-04
I0513 07:27:04.822449 22485033404224 run_lib.py:146] step: 242550, training_loss: 6.11715e-04
I0513 07:27:29.010994 22485033404224 run_lib.py:146] step: 242600, training_loss: 4.57930e-04
I0513 07:27:29.170870 22485033404224 run_lib.py:167] step: 242600, eval_loss: 5.91305e-04
I0513 07:27:52.774972 22485033404224 run_lib.py:146] step: 242650, training_loss: 6.05277e-04
I0513 07:28:16.409214 22485033404224 run_lib.py:146] step: 242700, training_loss: 6.34060e-04
I0513 07:28:16.569511 22485033404224 run_lib.py:167] step: 242700, eval_loss: 7.67734e-04
I0513 07:28:40.504169 22485033404224 run_lib.py:146] step: 242750, training_loss: 4.85960e-04
I0513 07:29:04.389639 22485033404224 run_lib.py:146] step: 242800, training_loss: 6.54036e-04
I0513 07:29:04.549957 22485033404224 run_lib.py:167] step: 242800, eval_loss: 5.93015e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 07:29:28.241385 22485033404224 run_lib.py:146] step: 242850, training_loss: 8.06884e-04
I0513 07:29:51.891774 22485033404224 run_lib.py:146] step: 242900, training_loss: 6.81490e-04
I0513 07:29:52.053076 22485033404224 run_lib.py:167] step: 242900, eval_loss: 6.73940e-04
I0513 07:30:16.560540 22485033404224 run_lib.py:146] step: 242950, training_loss: 5.34269e-04
I0513 07:30:40.191653 22485033404224 run_lib.py:146] step: 243000, training_loss: 6.96901e-04
I0513 07:30:40.352368 22485033404224 run_lib.py:167] step: 243000, eval_loss: 5.80922e-04
I0513 07:31:03.959404 22485033404224 run_lib.py:146] step: 243050, training_loss: 6.25652e-04
I0513 07:31:28.305571 22485033404224 run_lib.py:146] step: 243100, training_loss: 7.22694e-04
I0513 07:31:28.466000 22485033404224 run_lib.py:167] step: 243100, eval_loss: 5.03939e-04
I0513 07:31:52.001447 22485033404224 run_lib.py:146] step: 243150, training_loss: 5.18362e-04
I0513 07:32:15.545615 22485033404224 run_lib.py:146] step: 243200, training_loss: 5.44323e-04
I0513 07:32:15.704801 22485033404224 run_lib.py:167] step: 243200, eval_loss: 5.86941e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 07:32:40.039986 22485033404224 run_lib.py:146] step: 243250, training_loss: 4.82920e-04
I0513 07:33:03.559809 22485033404224 run_lib.py:146] step: 243300, training_loss: 5.91791e-04
I0513 07:33:03.719743 22485033404224 run_lib.py:167] step: 243300, eval_loss: 7.53275e-04
I0513 07:33:27.202576 22485033404224 run_lib.py:146] step: 243350, training_loss: 5.88124e-04
I0513 07:33:51.301360 22485033404224 run_lib.py:146] step: 243400, training_loss: 5.72190e-04
I0513 07:33:51.461421 22485033404224 run_lib.py:167] step: 243400, eval_loss: 6.68893e-04
I0513 07:34:14.963870 22485033404224 run_lib.py:146] step: 243450, training_loss: 6.17111e-04
I0513 07:34:38.476136 22485033404224 run_lib.py:146] step: 243500, training_loss: 4.95711e-04
I0513 07:34:38.635522 22485033404224 run_lib.py:167] step: 243500, eval_loss: 5.63983e-04
I0513 07:35:02.746848 22485033404224 run_lib.py:146] step: 243550, training_loss: 5.87262e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 07:35:26.354887 22485033404224 run_lib.py:146] step: 243600, training_loss: 5.07847e-04
I0513 07:35:26.516179 22485033404224 run_lib.py:167] step: 243600, eval_loss: 5.95841e-04
I0513 07:35:50.031626 22485033404224 run_lib.py:146] step: 243650, training_loss: 5.01120e-04
I0513 07:36:13.880537 22485033404224 run_lib.py:146] step: 243700, training_loss: 5.96379e-04
I0513 07:36:14.040467 22485033404224 run_lib.py:167] step: 243700, eval_loss: 7.92342e-04
I0513 07:36:37.899871 22485033404224 run_lib.py:146] step: 243750, training_loss: 5.90410e-04
I0513 07:37:01.420009 22485033404224 run_lib.py:146] step: 243800, training_loss: 6.75055e-04
I0513 07:37:01.578849 22485033404224 run_lib.py:167] step: 243800, eval_loss: 5.87179e-04
I0513 07:37:25.112406 22485033404224 run_lib.py:146] step: 243850, training_loss: 6.14626e-04
I0513 07:37:49.256518 22485033404224 run_lib.py:146] step: 243900, training_loss: 7.60178e-04
I0513 07:37:49.415519 22485033404224 run_lib.py:167] step: 243900, eval_loss: 6.18610e-04
I0513 07:38:12.942722 22485033404224 run_lib.py:146] step: 243950, training_loss: 5.12882e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 07:38:36.523346 22485033404224 run_lib.py:146] step: 244000, training_loss: 4.17867e-04
I0513 07:38:36.683382 22485033404224 run_lib.py:167] step: 244000, eval_loss: 6.82662e-04
I0513 07:39:00.834938 22485033404224 run_lib.py:146] step: 244050, training_loss: 6.79591e-04
I0513 07:39:24.339064 22485033404224 run_lib.py:146] step: 244100, training_loss: 6.28390e-04
I0513 07:39:24.497281 22485033404224 run_lib.py:167] step: 244100, eval_loss: 6.04350e-04
I0513 07:39:48.009083 22485033404224 run_lib.py:146] step: 244150, training_loss: 6.80325e-04
I0513 07:40:12.160524 22485033404224 run_lib.py:146] step: 244200, training_loss: 8.74132e-04
I0513 07:40:12.321208 22485033404224 run_lib.py:167] step: 244200, eval_loss: 6.55000e-04
I0513 07:40:35.851336 22485033404224 run_lib.py:146] step: 244250, training_loss: 5.23728e-04
I0513 07:40:59.355610 22485033404224 run_lib.py:146] step: 244300, training_loss: 7.13408e-04
I0513 07:40:59.515406 22485033404224 run_lib.py:167] step: 244300, eval_loss: 5.79388e-04
I0513 07:41:23.603682 22485033404224 run_lib.py:146] step: 244350, training_loss: 5.31805e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 07:41:47.225432 22485033404224 run_lib.py:146] step: 244400, training_loss: 7.33534e-04
I0513 07:41:47.387769 22485033404224 run_lib.py:167] step: 244400, eval_loss: 7.67485e-04
I0513 07:42:11.000213 22485033404224 run_lib.py:146] step: 244450, training_loss: 7.83905e-04
I0513 07:42:34.952128 22485033404224 run_lib.py:146] step: 244500, training_loss: 6.32497e-04
I0513 07:42:35.112188 22485033404224 run_lib.py:167] step: 244500, eval_loss: 6.41397e-04
I0513 07:42:59.034950 22485033404224 run_lib.py:146] step: 244550, training_loss: 5.52450e-04
I0513 07:43:22.653781 22485033404224 run_lib.py:146] step: 244600, training_loss: 5.08329e-04
I0513 07:43:22.814202 22485033404224 run_lib.py:167] step: 244600, eval_loss: 6.58953e-04
I0513 07:43:46.415880 22485033404224 run_lib.py:146] step: 244650, training_loss: 5.75073e-04
I0513 07:44:10.634404 22485033404224 run_lib.py:146] step: 244700, training_loss: 6.14837e-04
I0513 07:44:10.794110 22485033404224 run_lib.py:167] step: 244700, eval_loss: 4.88266e-04
I0513 07:44:34.375196 22485033404224 run_lib.py:146] step: 244750, training_loss: 5.65173e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 07:44:58.070858 22485033404224 run_lib.py:146] step: 244800, training_loss: 6.30655e-04
I0513 07:44:58.159796 22485033404224 run_lib.py:167] step: 244800, eval_loss: 7.80376e-04
I0513 07:45:22.597271 22485033404224 run_lib.py:146] step: 244850, training_loss: 8.34957e-04
I0513 07:45:46.263660 22485033404224 run_lib.py:146] step: 244900, training_loss: 6.72102e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 07:45:46.619183 22485033404224 run_lib.py:167] step: 244900, eval_loss: 6.59328e-04
I0513 07:46:10.252651 22485033404224 run_lib.py:146] step: 244950, training_loss: 7.21877e-04
I0513 07:46:34.540179 22485033404224 run_lib.py:146] step: 245000, training_loss: 5.51667e-04
I0513 07:46:34.699958 22485033404224 run_lib.py:167] step: 245000, eval_loss: 5.94316e-04
I0513 07:46:58.311794 22485033404224 run_lib.py:146] step: 245050, training_loss: 5.53143e-04
I0513 07:47:21.932195 22485033404224 run_lib.py:146] step: 245100, training_loss: 6.38336e-04
I0513 07:47:22.092391 22485033404224 run_lib.py:167] step: 245100, eval_loss: 5.20875e-04
I0513 07:47:46.252974 22485033404224 run_lib.py:146] step: 245150, training_loss: 5.71964e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 07:48:09.924576 22485033404224 run_lib.py:146] step: 245200, training_loss: 7.44741e-04
I0513 07:48:10.086426 22485033404224 run_lib.py:167] step: 245200, eval_loss: 4.74620e-04
I0513 07:48:33.704729 22485033404224 run_lib.py:146] step: 245250, training_loss: 7.48291e-04
I0513 07:48:57.590907 22485033404224 run_lib.py:146] step: 245300, training_loss: 7.13481e-04
I0513 07:48:57.749612 22485033404224 run_lib.py:167] step: 245300, eval_loss: 6.60738e-04
I0513 07:49:21.619907 22485033404224 run_lib.py:146] step: 245350, training_loss: 5.60096e-04
I0513 07:49:45.186471 22485033404224 run_lib.py:146] step: 245400, training_loss: 8.17822e-04
I0513 07:49:45.345069 22485033404224 run_lib.py:167] step: 245400, eval_loss: 6.54996e-04
I0513 07:50:08.872152 22485033404224 run_lib.py:146] step: 245450, training_loss: 5.83507e-04
I0513 07:50:32.970168 22485033404224 run_lib.py:146] step: 245500, training_loss: 5.69365e-04
I0513 07:50:33.131084 22485033404224 run_lib.py:167] step: 245500, eval_loss: 6.82676e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 07:50:56.690339 22485033404224 run_lib.py:146] step: 245550, training_loss: 6.09079e-04
I0513 07:51:20.212616 22485033404224 run_lib.py:146] step: 245600, training_loss: 5.28668e-04
I0513 07:51:20.372979 22485033404224 run_lib.py:167] step: 245600, eval_loss: 4.50977e-04
I0513 07:51:44.571351 22485033404224 run_lib.py:146] step: 245650, training_loss: 5.47597e-04
I0513 07:52:08.048099 22485033404224 run_lib.py:146] step: 245700, training_loss: 6.58582e-04
I0513 07:52:08.207737 22485033404224 run_lib.py:167] step: 245700, eval_loss: 6.73130e-04
I0513 07:52:31.729994 22485033404224 run_lib.py:146] step: 245750, training_loss: 5.45797e-04
I0513 07:52:55.839701 22485033404224 run_lib.py:146] step: 245800, training_loss: 6.92906e-04
I0513 07:52:55.998346 22485033404224 run_lib.py:167] step: 245800, eval_loss: 6.82547e-04
I0513 07:53:19.507714 22485033404224 run_lib.py:146] step: 245850, training_loss: 7.94878e-04
I0513 07:53:43.020996 22485033404224 run_lib.py:146] step: 245900, training_loss: 5.24321e-04
I0513 07:53:43.180494 22485033404224 run_lib.py:167] step: 245900, eval_loss: 6.81689e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 07:54:07.395689 22485033404224 run_lib.py:146] step: 245950, training_loss: 5.59954e-04
I0513 07:54:30.924296 22485033404224 run_lib.py:146] step: 246000, training_loss: 8.26330e-04
I0513 07:54:31.084526 22485033404224 run_lib.py:167] step: 246000, eval_loss: 8.19178e-04
I0513 07:54:54.600918 22485033404224 run_lib.py:146] step: 246050, training_loss: 5.46949e-04
I0513 07:55:18.426619 22485033404224 run_lib.py:146] step: 246100, training_loss: 4.71632e-04
I0513 07:55:18.584654 22485033404224 run_lib.py:167] step: 246100, eval_loss: 4.96019e-04
I0513 07:55:42.415539 22485033404224 run_lib.py:146] step: 246150, training_loss: 6.20445e-04
I0513 07:56:05.920345 22485033404224 run_lib.py:146] step: 246200, training_loss: 6.06770e-04
I0513 07:56:06.081651 22485033404224 run_lib.py:167] step: 246200, eval_loss: 6.08926e-04
I0513 07:56:29.924119 22485033404224 run_lib.py:146] step: 246250, training_loss: 7.83490e-04
I0513 07:56:53.754375 22485033404224 run_lib.py:146] step: 246300, training_loss: 4.71834e-04
I0513 07:56:53.914112 22485033404224 run_lib.py:167] step: 246300, eval_loss: 5.83171e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 07:57:17.506236 22485033404224 run_lib.py:146] step: 246350, training_loss: 7.78473e-04
I0513 07:57:41.033943 22485033404224 run_lib.py:146] step: 246400, training_loss: 7.90899e-04
I0513 07:57:41.194700 22485033404224 run_lib.py:167] step: 246400, eval_loss: 7.64642e-04
I0513 07:58:05.396356 22485033404224 run_lib.py:146] step: 246450, training_loss: 8.67212e-04
I0513 07:58:28.896960 22485033404224 run_lib.py:146] step: 246500, training_loss: 6.74782e-04
I0513 07:58:29.055975 22485033404224 run_lib.py:167] step: 246500, eval_loss: 7.28898e-04
I0513 07:58:52.550477 22485033404224 run_lib.py:146] step: 246550, training_loss: 4.72871e-04
I0513 07:59:16.643861 22485033404224 run_lib.py:146] step: 246600, training_loss: 7.45923e-04
I0513 07:59:16.804232 22485033404224 run_lib.py:167] step: 246600, eval_loss: 4.17694e-04
I0513 07:59:40.375720 22485033404224 run_lib.py:146] step: 246650, training_loss: 5.80731e-04
I0513 08:00:03.961297 22485033404224 run_lib.py:146] step: 246700, training_loss: 5.70387e-04
I0513 08:00:04.121518 22485033404224 run_lib.py:167] step: 246700, eval_loss: 5.90833e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 08:00:28.500865 22485033404224 run_lib.py:146] step: 246750, training_loss: 6.69140e-04
I0513 08:00:52.098735 22485033404224 run_lib.py:146] step: 246800, training_loss: 4.46323e-04
I0513 08:00:52.259861 22485033404224 run_lib.py:167] step: 246800, eval_loss: 7.32131e-04
I0513 08:01:15.823840 22485033404224 run_lib.py:146] step: 246850, training_loss: 7.74712e-04
I0513 08:01:39.726665 22485033404224 run_lib.py:146] step: 246900, training_loss: 5.62482e-04
I0513 08:01:39.886907 22485033404224 run_lib.py:167] step: 246900, eval_loss: 6.69750e-04
I0513 08:02:03.776672 22485033404224 run_lib.py:146] step: 246950, training_loss: 8.36446e-04
I0513 08:02:27.355714 22485033404224 run_lib.py:146] step: 247000, training_loss: 7.35595e-04
I0513 08:02:27.515366 22485033404224 run_lib.py:167] step: 247000, eval_loss: 5.58465e-04
I0513 08:02:51.385332 22485033404224 run_lib.py:146] step: 247050, training_loss: 5.77029e-04
I0513 08:03:15.298374 22485033404224 run_lib.py:146] step: 247100, training_loss: 3.80369e-04
I0513 08:03:15.459120 22485033404224 run_lib.py:167] step: 247100, eval_loss: 5.69108e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 08:03:39.135904 22485033404224 run_lib.py:146] step: 247150, training_loss: 6.99213e-04
I0513 08:04:02.725138 22485033404224 run_lib.py:146] step: 247200, training_loss: 5.52094e-04
I0513 08:04:02.885569 22485033404224 run_lib.py:167] step: 247200, eval_loss: 6.39737e-04
I0513 08:04:27.157715 22485033404224 run_lib.py:146] step: 247250, training_loss: 5.32218e-04
I0513 08:04:50.763024 22485033404224 run_lib.py:146] step: 247300, training_loss: 8.70091e-04
I0513 08:04:50.923551 22485033404224 run_lib.py:167] step: 247300, eval_loss: 6.40457e-04
I0513 08:05:14.507410 22485033404224 run_lib.py:146] step: 247350, training_loss: 5.45656e-04
I0513 08:05:38.698826 22485033404224 run_lib.py:146] step: 247400, training_loss: 6.19902e-04
I0513 08:05:38.860249 22485033404224 run_lib.py:167] step: 247400, eval_loss: 5.71319e-04
I0513 08:06:02.448531 22485033404224 run_lib.py:146] step: 247450, training_loss: 6.97295e-04
I0513 08:06:26.023450 22485033404224 run_lib.py:146] step: 247500, training_loss: 6.28440e-04
I0513 08:06:26.183356 22485033404224 run_lib.py:167] step: 247500, eval_loss: 7.83804e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 08:06:50.469864 22485033404224 run_lib.py:146] step: 247550, training_loss: 4.76385e-04
I0513 08:07:14.012939 22485033404224 run_lib.py:146] step: 247600, training_loss: 5.62026e-04
I0513 08:07:14.172833 22485033404224 run_lib.py:167] step: 247600, eval_loss: 4.49483e-04
I0513 08:07:37.690250 22485033404224 run_lib.py:146] step: 247650, training_loss: 5.45226e-04
I0513 08:08:01.525926 22485033404224 run_lib.py:146] step: 247700, training_loss: 8.02770e-04
I0513 08:08:01.684484 22485033404224 run_lib.py:167] step: 247700, eval_loss: 5.89762e-04
I0513 08:08:25.491285 22485033404224 run_lib.py:146] step: 247750, training_loss: 6.18981e-04
I0513 08:08:49.006241 22485033404224 run_lib.py:146] step: 247800, training_loss: 4.55159e-04
I0513 08:08:49.166453 22485033404224 run_lib.py:167] step: 247800, eval_loss: 6.30412e-04
I0513 08:09:12.983914 22485033404224 run_lib.py:146] step: 247850, training_loss: 6.25630e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 08:09:36.851782 22485033404224 run_lib.py:146] step: 247900, training_loss: 5.91253e-04
I0513 08:09:37.012994 22485033404224 run_lib.py:167] step: 247900, eval_loss: 5.13214e-04
I0513 08:10:00.515103 22485033404224 run_lib.py:146] step: 247950, training_loss: 6.84680e-04
I0513 08:10:24.040434 22485033404224 run_lib.py:146] step: 248000, training_loss: 6.70287e-04
I0513 08:10:24.198899 22485033404224 run_lib.py:167] step: 248000, eval_loss: 7.09057e-04
I0513 08:10:48.315289 22485033404224 run_lib.py:146] step: 248050, training_loss: 3.93183e-04
I0513 08:11:11.836130 22485033404224 run_lib.py:146] step: 248100, training_loss: 6.63676e-04
I0513 08:11:11.995167 22485033404224 run_lib.py:167] step: 248100, eval_loss: 5.11644e-04
I0513 08:11:35.504266 22485033404224 run_lib.py:146] step: 248150, training_loss: 5.38100e-04
I0513 08:11:59.622729 22485033404224 run_lib.py:146] step: 248200, training_loss: 6.43391e-04
I0513 08:11:59.783148 22485033404224 run_lib.py:167] step: 248200, eval_loss: 6.46455e-04
I0513 08:12:23.281594 22485033404224 run_lib.py:146] step: 248250, training_loss: 6.39624e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 08:12:46.850343 22485033404224 run_lib.py:146] step: 248300, training_loss: 5.01931e-04
I0513 08:12:47.012164 22485033404224 run_lib.py:167] step: 248300, eval_loss: 7.56289e-04
I0513 08:13:11.150679 22485033404224 run_lib.py:146] step: 248350, training_loss: 6.51308e-04
I0513 08:13:34.651575 22485033404224 run_lib.py:146] step: 248400, training_loss: 9.29249e-04
I0513 08:13:34.809966 22485033404224 run_lib.py:167] step: 248400, eval_loss: 6.04388e-04
I0513 08:13:58.333903 22485033404224 run_lib.py:146] step: 248450, training_loss: 4.59536e-04
I0513 08:14:22.446979 22485033404224 run_lib.py:146] step: 248500, training_loss: 7.63039e-04
I0513 08:14:22.605227 22485033404224 run_lib.py:167] step: 248500, eval_loss: 6.20069e-04
I0513 08:14:46.098664 22485033404224 run_lib.py:146] step: 248550, training_loss: 5.88559e-04
I0513 08:15:09.609393 22485033404224 run_lib.py:146] step: 248600, training_loss: 5.64973e-04
I0513 08:15:09.768429 22485033404224 run_lib.py:167] step: 248600, eval_loss: 5.09641e-04
I0513 08:15:33.568886 22485033404224 run_lib.py:146] step: 248650, training_loss: 6.47909e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 08:15:57.445689 22485033404224 run_lib.py:146] step: 248700, training_loss: 4.55124e-04
I0513 08:15:57.607598 22485033404224 run_lib.py:167] step: 248700, eval_loss: 6.44473e-04
I0513 08:16:21.120287 22485033404224 run_lib.py:146] step: 248750, training_loss: 6.23252e-04
I0513 08:16:44.636378 22485033404224 run_lib.py:146] step: 248800, training_loss: 7.44896e-04
I0513 08:16:44.795106 22485033404224 run_lib.py:167] step: 248800, eval_loss: 6.31493e-04
I0513 08:17:09.014426 22485033404224 run_lib.py:146] step: 248850, training_loss: 5.45828e-04
I0513 08:17:32.596638 22485033404224 run_lib.py:146] step: 248900, training_loss: 6.41903e-04
I0513 08:17:32.756699 22485033404224 run_lib.py:167] step: 248900, eval_loss: 7.94449e-04
I0513 08:17:56.365562 22485033404224 run_lib.py:146] step: 248950, training_loss: 5.85320e-04
I0513 08:18:20.597012 22485033404224 run_lib.py:146] step: 249000, training_loss: 6.27273e-04
I0513 08:18:20.757570 22485033404224 run_lib.py:167] step: 249000, eval_loss: 5.41711e-04
I0513 08:18:44.382993 22485033404224 run_lib.py:146] step: 249050, training_loss: 6.59540e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 08:19:08.066586 22485033404224 run_lib.py:146] step: 249100, training_loss: 7.02118e-04
I0513 08:19:08.227921 22485033404224 run_lib.py:167] step: 249100, eval_loss: 5.09323e-04
I0513 08:19:32.683808 22485033404224 run_lib.py:146] step: 249150, training_loss: 7.21857e-04
I0513 08:19:56.270720 22485033404224 run_lib.py:146] step: 249200, training_loss: 5.47089e-04
I0513 08:19:56.430154 22485033404224 run_lib.py:167] step: 249200, eval_loss: 5.28508e-04
I0513 08:20:19.960803 22485033404224 run_lib.py:146] step: 249250, training_loss: 4.98199e-04
I0513 08:20:44.345133 22485033404224 run_lib.py:146] step: 249300, training_loss: 5.61850e-04
I0513 08:20:44.505153 22485033404224 run_lib.py:167] step: 249300, eval_loss: 7.38939e-04
I0513 08:21:08.118642 22485033404224 run_lib.py:146] step: 249350, training_loss: 5.28272e-04
I0513 08:21:31.734980 22485033404224 run_lib.py:146] step: 249400, training_loss: 4.86966e-04
I0513 08:21:31.896415 22485033404224 run_lib.py:167] step: 249400, eval_loss: 5.82343e-04
I0513 08:21:55.879429 22485033404224 run_lib.py:146] step: 249450, training_loss: 5.65447e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 08:22:20.003573 22485033404224 run_lib.py:146] step: 249500, training_loss: 5.65938e-04
I0513 08:22:20.165157 22485033404224 run_lib.py:167] step: 249500, eval_loss: 6.90371e-04
I0513 08:22:43.764191 22485033404224 run_lib.py:146] step: 249550, training_loss: 4.78127e-04
I0513 08:23:07.346979 22485033404224 run_lib.py:146] step: 249600, training_loss: 6.76397e-04
I0513 08:23:07.507447 22485033404224 run_lib.py:167] step: 249600, eval_loss: 6.41678e-04
I0513 08:23:31.795589 22485033404224 run_lib.py:146] step: 249650, training_loss: 5.83265e-04
I0513 08:23:55.382644 22485033404224 run_lib.py:146] step: 249700, training_loss: 6.73766e-04
I0513 08:23:55.543918 22485033404224 run_lib.py:167] step: 249700, eval_loss: 7.34942e-04
I0513 08:24:19.085944 22485033404224 run_lib.py:146] step: 249750, training_loss: 5.61212e-04
I0513 08:24:43.185693 22485033404224 run_lib.py:146] step: 249800, training_loss: 7.10272e-04
I0513 08:24:43.343688 22485033404224 run_lib.py:167] step: 249800, eval_loss: 6.09012e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 08:25:06.967440 22485033404224 run_lib.py:146] step: 249850, training_loss: 6.33013e-04
I0513 08:25:30.505885 22485033404224 run_lib.py:146] step: 249900, training_loss: 6.88370e-04
I0513 08:25:30.666517 22485033404224 run_lib.py:167] step: 249900, eval_loss: 5.79371e-04
I0513 08:25:54.857837 22485033404224 run_lib.py:146] step: 249950, training_loss: 6.78960e-04
I0513 08:26:18.393274 22485033404224 run_lib.py:146] step: 250000, training_loss: 5.22027e-04
I0513 08:26:21.052064 22485033404224 run_lib.py:167] step: 250000, eval_loss: 8.05595e-04
I0513 08:26:47.642740 22485033404224 run_lib.py:146] step: 250050, training_loss: 6.02115e-04
I0513 08:27:11.454785 22485033404224 run_lib.py:146] step: 250100, training_loss: 5.83474e-04
I0513 08:27:11.614002 22485033404224 run_lib.py:167] step: 250100, eval_loss: 7.37627e-04
I0513 08:27:35.120202 22485033404224 run_lib.py:146] step: 250150, training_loss: 6.81489e-04
I0513 08:27:58.938146 22485033404224 run_lib.py:146] step: 250200, training_loss: 5.22474e-04
I0513 08:27:59.096166 22485033404224 run_lib.py:167] step: 250200, eval_loss: 5.72216e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 08:28:23.027758 22485033404224 run_lib.py:146] step: 250250, training_loss: 5.19417e-04
I0513 08:28:46.524372 22485033404224 run_lib.py:146] step: 250300, training_loss: 5.62819e-04
I0513 08:28:46.685519 22485033404224 run_lib.py:167] step: 250300, eval_loss: 6.27173e-04
I0513 08:29:10.189187 22485033404224 run_lib.py:146] step: 250350, training_loss: 6.49270e-04
I0513 08:29:34.022283 22485033404224 run_lib.py:146] step: 250400, training_loss: 5.66931e-04
I0513 08:29:34.181109 22485033404224 run_lib.py:167] step: 250400, eval_loss: 5.91088e-04
I0513 08:29:57.940341 22485033404224 run_lib.py:146] step: 250450, training_loss: 6.75873e-04
I0513 08:30:21.442157 22485033404224 run_lib.py:146] step: 250500, training_loss: 6.04116e-04
I0513 08:30:21.601767 22485033404224 run_lib.py:167] step: 250500, eval_loss: 6.01016e-04
I0513 08:30:45.375562 22485033404224 run_lib.py:146] step: 250550, training_loss: 7.43795e-04
I0513 08:31:09.145769 22485033404224 run_lib.py:146] step: 250600, training_loss: 7.09009e-04
I0513 08:31:09.305574 22485033404224 run_lib.py:167] step: 250600, eval_loss: 8.23167e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 08:31:32.877946 22485033404224 run_lib.py:146] step: 250650, training_loss: 6.53798e-04
I0513 08:31:56.729161 22485033404224 run_lib.py:146] step: 250700, training_loss: 5.12874e-04
I0513 08:31:56.891006 22485033404224 run_lib.py:167] step: 250700, eval_loss: 5.74462e-04
I0513 08:32:20.708204 22485033404224 run_lib.py:146] step: 250750, training_loss: 6.05589e-04
I0513 08:32:44.196041 22485033404224 run_lib.py:146] step: 250800, training_loss: 5.71746e-04
I0513 08:32:44.356967 22485033404224 run_lib.py:167] step: 250800, eval_loss: 5.51332e-04
I0513 08:33:08.185950 22485033404224 run_lib.py:146] step: 250850, training_loss: 5.18319e-04
I0513 08:33:31.966547 22485033404224 run_lib.py:146] step: 250900, training_loss: 4.97681e-04
I0513 08:33:32.125555 22485033404224 run_lib.py:167] step: 250900, eval_loss: 6.40209e-04
I0513 08:33:55.608485 22485033404224 run_lib.py:146] step: 250950, training_loss: 6.13677e-04
I0513 08:34:19.400841 22485033404224 run_lib.py:146] step: 251000, training_loss: 7.14254e-04
I0513 08:34:19.559967 22485033404224 run_lib.py:167] step: 251000, eval_loss: 6.13588e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 08:34:43.578151 22485033404224 run_lib.py:146] step: 251050, training_loss: 5.43369e-04
I0513 08:35:07.178509 22485033404224 run_lib.py:146] step: 251100, training_loss: 7.04998e-04
I0513 08:35:07.340620 22485033404224 run_lib.py:167] step: 251100, eval_loss: 4.93138e-04
I0513 08:35:30.931081 22485033404224 run_lib.py:146] step: 251150, training_loss: 6.92763e-04
I0513 08:35:54.889839 22485033404224 run_lib.py:146] step: 251200, training_loss: 5.11155e-04
I0513 08:35:55.050111 22485033404224 run_lib.py:167] step: 251200, eval_loss: 7.15337e-04
I0513 08:36:18.974178 22485033404224 run_lib.py:146] step: 251250, training_loss: 5.92309e-04
I0513 08:36:42.592677 22485033404224 run_lib.py:146] step: 251300, training_loss: 6.30467e-04
I0513 08:36:42.754145 22485033404224 run_lib.py:167] step: 251300, eval_loss: 6.89394e-04
I0513 08:37:06.628642 22485033404224 run_lib.py:146] step: 251350, training_loss: 4.30563e-04
I0513 08:37:30.545151 22485033404224 run_lib.py:146] step: 251400, training_loss: 5.53318e-04
I0513 08:37:30.705401 22485033404224 run_lib.py:167] step: 251400, eval_loss: 7.57688e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 08:37:54.371046 22485033404224 run_lib.py:146] step: 251450, training_loss: 6.59554e-04
I0513 08:38:18.457984 22485033404224 run_lib.py:146] step: 251500, training_loss: 6.25234e-04
I0513 08:38:18.619500 22485033404224 run_lib.py:167] step: 251500, eval_loss: 5.28655e-04
I0513 08:38:42.625785 22485033404224 run_lib.py:146] step: 251550, training_loss: 5.51092e-04
I0513 08:39:06.271659 22485033404224 run_lib.py:146] step: 251600, training_loss: 5.69141e-04
I0513 08:39:06.433376 22485033404224 run_lib.py:167] step: 251600, eval_loss: 4.53139e-04
I0513 08:39:30.465144 22485033404224 run_lib.py:146] step: 251650, training_loss: 6.37623e-04
I0513 08:39:54.380646 22485033404224 run_lib.py:146] step: 251700, training_loss: 5.88769e-04
I0513 08:39:54.542105 22485033404224 run_lib.py:167] step: 251700, eval_loss: 5.44431e-04
I0513 08:40:18.144469 22485033404224 run_lib.py:146] step: 251750, training_loss: 6.80785e-04
I0513 08:40:42.020741 22485033404224 run_lib.py:146] step: 251800, training_loss: 6.53627e-04
I0513 08:40:42.181501 22485033404224 run_lib.py:167] step: 251800, eval_loss: 5.25751e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 08:41:06.236030 22485033404224 run_lib.py:146] step: 251850, training_loss: 6.53462e-04
I0513 08:41:29.829668 22485033404224 run_lib.py:146] step: 251900, training_loss: 6.02617e-04
I0513 08:41:29.990103 22485033404224 run_lib.py:167] step: 251900, eval_loss: 7.50184e-04
I0513 08:41:53.860220 22485033404224 run_lib.py:146] step: 251950, training_loss: 6.07319e-04
I0513 08:42:17.677565 22485033404224 run_lib.py:146] step: 252000, training_loss: 6.35028e-04
I0513 08:42:17.835961 22485033404224 run_lib.py:167] step: 252000, eval_loss: 8.05489e-04
I0513 08:42:41.355972 22485033404224 run_lib.py:146] step: 252050, training_loss: 7.37207e-04
I0513 08:43:04.871097 22485033404224 run_lib.py:146] step: 252100, training_loss: 6.05331e-04
I0513 08:43:05.030306 22485033404224 run_lib.py:167] step: 252100, eval_loss: 6.52478e-04
I0513 08:43:28.850270 22485033404224 run_lib.py:146] step: 252150, training_loss: 4.26057e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 08:43:52.724251 22485033404224 run_lib.py:146] step: 252200, training_loss: 6.18506e-04
I0513 08:43:52.885472 22485033404224 run_lib.py:167] step: 252200, eval_loss: 5.43360e-04
I0513 08:44:16.386013 22485033404224 run_lib.py:146] step: 252250, training_loss: 5.10552e-04
I0513 08:44:40.226194 22485033404224 run_lib.py:146] step: 252300, training_loss: 6.98189e-04
I0513 08:44:40.385303 22485033404224 run_lib.py:167] step: 252300, eval_loss: 6.00930e-04
I0513 08:45:04.257321 22485033404224 run_lib.py:146] step: 252350, training_loss: 5.78450e-04
I0513 08:45:27.791896 22485033404224 run_lib.py:146] step: 252400, training_loss: 5.89236e-04
I0513 08:45:27.951449 22485033404224 run_lib.py:167] step: 252400, eval_loss: 5.16467e-04
I0513 08:45:51.785509 22485033404224 run_lib.py:146] step: 252450, training_loss: 6.47662e-04
I0513 08:46:15.625463 22485033404224 run_lib.py:146] step: 252500, training_loss: 6.66697e-04
I0513 08:46:15.785564 22485033404224 run_lib.py:167] step: 252500, eval_loss: 4.70914e-04
I0513 08:46:39.298763 22485033404224 run_lib.py:146] step: 252550, training_loss: 6.64321e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 08:47:03.211315 22485033404224 run_lib.py:146] step: 252600, training_loss: 4.86359e-04
I0513 08:47:03.370339 22485033404224 run_lib.py:167] step: 252600, eval_loss: 5.31850e-04
I0513 08:47:27.215242 22485033404224 run_lib.py:146] step: 252650, training_loss: 5.81474e-04
I0513 08:47:50.719960 22485033404224 run_lib.py:146] step: 252700, training_loss: 6.42304e-04
I0513 08:47:50.802991 22485033404224 run_lib.py:167] step: 252700, eval_loss: 6.63387e-04
I0513 08:48:14.639984 22485033404224 run_lib.py:146] step: 252750, training_loss: 4.86013e-04
I0513 08:48:38.467405 22485033404224 run_lib.py:146] step: 252800, training_loss: 6.97399e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 08:48:38.817400 22485033404224 run_lib.py:167] step: 252800, eval_loss: 6.64046e-04
I0513 08:49:02.360192 22485033404224 run_lib.py:146] step: 252850, training_loss: 6.51538e-04
I0513 08:49:25.887115 22485033404224 run_lib.py:146] step: 252900, training_loss: 5.17400e-04
I0513 08:49:26.046422 22485033404224 run_lib.py:167] step: 252900, eval_loss: 5.47946e-04
I0513 08:49:49.896504 22485033404224 run_lib.py:146] step: 252950, training_loss: 6.06425e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 08:50:13.811372 22485033404224 run_lib.py:146] step: 253000, training_loss: 7.56368e-04
I0513 08:50:13.972674 22485033404224 run_lib.py:167] step: 253000, eval_loss: 5.52298e-04
I0513 08:50:37.487157 22485033404224 run_lib.py:146] step: 253050, training_loss: 7.34819e-04
I0513 08:51:01.328987 22485033404224 run_lib.py:146] step: 253100, training_loss: 6.95340e-04
I0513 08:51:01.488002 22485033404224 run_lib.py:167] step: 253100, eval_loss: 7.80643e-04
I0513 08:51:25.316087 22485033404224 run_lib.py:146] step: 253150, training_loss: 6.97446e-04
I0513 08:51:48.854697 22485033404224 run_lib.py:146] step: 253200, training_loss: 6.16406e-04
I0513 08:51:49.014964 22485033404224 run_lib.py:167] step: 253200, eval_loss: 6.10522e-04
I0513 08:52:12.879852 22485033404224 run_lib.py:146] step: 253250, training_loss: 5.71503e-04
I0513 08:52:36.794092 22485033404224 run_lib.py:146] step: 253300, training_loss: 5.15569e-04
I0513 08:52:36.954691 22485033404224 run_lib.py:167] step: 253300, eval_loss: 5.18519e-04
I0513 08:53:00.570668 22485033404224 run_lib.py:146] step: 253350, training_loss: 5.99239e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 08:53:24.599583 22485033404224 run_lib.py:146] step: 253400, training_loss: 3.39628e-04
I0513 08:53:24.762068 22485033404224 run_lib.py:167] step: 253400, eval_loss: 5.00800e-04
I0513 08:53:48.709506 22485033404224 run_lib.py:146] step: 253450, training_loss: 4.67408e-04
I0513 08:54:12.294007 22485033404224 run_lib.py:146] step: 253500, training_loss: 6.82589e-04
I0513 08:54:12.454765 22485033404224 run_lib.py:167] step: 253500, eval_loss: 7.47892e-04
I0513 08:54:36.328011 22485033404224 run_lib.py:146] step: 253550, training_loss: 8.72476e-04
I0513 08:55:00.264553 22485033404224 run_lib.py:146] step: 253600, training_loss: 5.70211e-04
I0513 08:55:00.424707 22485033404224 run_lib.py:167] step: 253600, eval_loss: 7.87515e-04
I0513 08:55:24.001500 22485033404224 run_lib.py:146] step: 253650, training_loss: 4.93875e-04
I0513 08:55:47.888399 22485033404224 run_lib.py:146] step: 253700, training_loss: 8.02067e-04
I0513 08:55:48.048211 22485033404224 run_lib.py:167] step: 253700, eval_loss: 6.44297e-04
I0513 08:56:11.622526 22485033404224 run_lib.py:146] step: 253750, training_loss: 6.87133e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 08:56:35.644269 22485033404224 run_lib.py:146] step: 253800, training_loss: 7.32598e-04
I0513 08:56:35.806616 22485033404224 run_lib.py:167] step: 253800, eval_loss: 6.08963e-04
I0513 08:56:59.407347 22485033404224 run_lib.py:146] step: 253850, training_loss: 5.90568e-04
I0513 08:57:23.346277 22485033404224 run_lib.py:146] step: 253900, training_loss: 5.98712e-04
I0513 08:57:23.507513 22485033404224 run_lib.py:167] step: 253900, eval_loss: 6.69485e-04
I0513 08:57:47.427479 22485033404224 run_lib.py:146] step: 253950, training_loss: 8.50303e-04
I0513 08:58:10.996281 22485033404224 run_lib.py:146] step: 254000, training_loss: 5.99392e-04
I0513 08:58:11.157285 22485033404224 run_lib.py:167] step: 254000, eval_loss: 6.77331e-04
I0513 08:58:35.046435 22485033404224 run_lib.py:146] step: 254050, training_loss: 5.74068e-04
I0513 08:58:58.963997 22485033404224 run_lib.py:146] step: 254100, training_loss: 6.47995e-04
I0513 08:58:59.124190 22485033404224 run_lib.py:167] step: 254100, eval_loss: 3.37430e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 08:59:22.712495 22485033404224 run_lib.py:146] step: 254150, training_loss: 5.78744e-04
I0513 08:59:46.608268 22485033404224 run_lib.py:146] step: 254200, training_loss: 4.71129e-04
I0513 08:59:46.767740 22485033404224 run_lib.py:167] step: 254200, eval_loss: 5.25210e-04
I0513 09:00:10.633000 22485033404224 run_lib.py:146] step: 254250, training_loss: 4.49156e-04
I0513 09:00:34.161458 22485033404224 run_lib.py:146] step: 254300, training_loss: 6.29704e-04
I0513 09:00:34.320784 22485033404224 run_lib.py:167] step: 254300, eval_loss: 6.14134e-04
I0513 09:00:58.160034 22485033404224 run_lib.py:146] step: 254350, training_loss: 5.98910e-04
I0513 09:01:22.009982 22485033404224 run_lib.py:146] step: 254400, training_loss: 7.46018e-04
I0513 09:01:22.170736 22485033404224 run_lib.py:167] step: 254400, eval_loss: 6.98979e-04
I0513 09:01:45.653588 22485033404224 run_lib.py:146] step: 254450, training_loss: 6.49407e-04
I0513 09:02:09.438871 22485033404224 run_lib.py:146] step: 254500, training_loss: 6.21769e-04
I0513 09:02:09.599051 22485033404224 run_lib.py:167] step: 254500, eval_loss: 6.26548e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 09:02:33.540590 22485033404224 run_lib.py:146] step: 254550, training_loss: 5.94684e-04
I0513 09:02:57.041421 22485033404224 run_lib.py:146] step: 254600, training_loss: 5.92282e-04
I0513 09:02:57.200963 22485033404224 run_lib.py:167] step: 254600, eval_loss: 6.10889e-04
I0513 09:03:20.689141 22485033404224 run_lib.py:146] step: 254650, training_loss: 3.81769e-04
I0513 09:03:44.546797 22485033404224 run_lib.py:146] step: 254700, training_loss: 5.45872e-04
I0513 09:03:44.706495 22485033404224 run_lib.py:167] step: 254700, eval_loss: 6.17681e-04
I0513 09:04:08.533137 22485033404224 run_lib.py:146] step: 254750, training_loss: 7.95806e-04
I0513 09:04:32.064810 22485033404224 run_lib.py:146] step: 254800, training_loss: 7.22649e-04
I0513 09:04:32.224505 22485033404224 run_lib.py:167] step: 254800, eval_loss: 6.55664e-04
I0513 09:04:56.037381 22485033404224 run_lib.py:146] step: 254850, training_loss: 8.33208e-04
I0513 09:05:19.865986 22485033404224 run_lib.py:146] step: 254900, training_loss: 8.00968e-04
I0513 09:05:20.026464 22485033404224 run_lib.py:167] step: 254900, eval_loss: 6.93168e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 09:05:43.621491 22485033404224 run_lib.py:146] step: 254950, training_loss: 5.27631e-04
I0513 09:06:07.511104 22485033404224 run_lib.py:146] step: 255000, training_loss: 4.41382e-04
I0513 09:06:07.673540 22485033404224 run_lib.py:167] step: 255000, eval_loss: 5.78910e-04
I0513 09:06:31.498865 22485033404224 run_lib.py:146] step: 255050, training_loss: 6.57748e-04
I0513 09:06:55.043639 22485033404224 run_lib.py:146] step: 255100, training_loss: 5.03332e-04
I0513 09:06:55.204928 22485033404224 run_lib.py:167] step: 255100, eval_loss: 5.42094e-04
I0513 09:07:19.035183 22485033404224 run_lib.py:146] step: 255150, training_loss: 5.33600e-04
I0513 09:07:42.831869 22485033404224 run_lib.py:146] step: 255200, training_loss: 8.44598e-04
I0513 09:07:42.990740 22485033404224 run_lib.py:167] step: 255200, eval_loss: 5.91839e-04
I0513 09:08:06.507579 22485033404224 run_lib.py:146] step: 255250, training_loss: 5.13818e-04
I0513 09:08:30.329914 22485033404224 run_lib.py:146] step: 255300, training_loss: 9.04980e-04
I0513 09:08:30.489392 22485033404224 run_lib.py:167] step: 255300, eval_loss: 6.41287e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 09:08:54.442462 22485033404224 run_lib.py:146] step: 255350, training_loss: 6.74671e-04
I0513 09:09:17.961159 22485033404224 run_lib.py:146] step: 255400, training_loss: 7.43954e-04
I0513 09:09:18.120762 22485033404224 run_lib.py:167] step: 255400, eval_loss: 8.13200e-04
I0513 09:09:41.991582 22485033404224 run_lib.py:146] step: 255450, training_loss: 5.07112e-04
I0513 09:10:05.554345 22485033404224 run_lib.py:146] step: 255500, training_loss: 6.92433e-04
I0513 09:10:05.714367 22485033404224 run_lib.py:167] step: 255500, eval_loss: 7.71017e-04
I0513 09:10:29.607188 22485033404224 run_lib.py:146] step: 255550, training_loss: 4.96688e-04
I0513 09:10:53.192744 22485033404224 run_lib.py:146] step: 255600, training_loss: 6.69514e-04
I0513 09:10:53.352847 22485033404224 run_lib.py:167] step: 255600, eval_loss: 4.36888e-04
I0513 09:11:17.248833 22485033404224 run_lib.py:146] step: 255650, training_loss: 6.86387e-04
I0513 09:11:41.163633 22485033404224 run_lib.py:146] step: 255700, training_loss: 4.34428e-04
I0513 09:11:41.323927 22485033404224 run_lib.py:167] step: 255700, eval_loss: 3.54704e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 09:12:04.990418 22485033404224 run_lib.py:146] step: 255750, training_loss: 6.43305e-04
I0513 09:12:29.010615 22485033404224 run_lib.py:146] step: 255800, training_loss: 5.17355e-04
I0513 09:12:29.171981 22485033404224 run_lib.py:167] step: 255800, eval_loss: 5.53041e-04
I0513 09:12:53.168106 22485033404224 run_lib.py:146] step: 255850, training_loss: 6.43922e-04
I0513 09:13:16.730895 22485033404224 run_lib.py:146] step: 255900, training_loss: 5.79928e-04
I0513 09:13:16.891346 22485033404224 run_lib.py:167] step: 255900, eval_loss: 5.24669e-04
I0513 09:13:40.877458 22485033404224 run_lib.py:146] step: 255950, training_loss: 7.18378e-04
I0513 09:14:04.894219 22485033404224 run_lib.py:146] step: 256000, training_loss: 6.96953e-04
I0513 09:14:05.054447 22485033404224 run_lib.py:167] step: 256000, eval_loss: 4.64569e-04
I0513 09:14:28.643994 22485033404224 run_lib.py:146] step: 256050, training_loss: 6.62875e-04
I0513 09:14:52.628767 22485033404224 run_lib.py:146] step: 256100, training_loss: 8.54644e-04
I0513 09:14:52.789271 22485033404224 run_lib.py:167] step: 256100, eval_loss: 5.92192e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 09:15:16.794957 22485033404224 run_lib.py:146] step: 256150, training_loss: 5.97424e-04
I0513 09:15:40.359833 22485033404224 run_lib.py:146] step: 256200, training_loss: 6.61799e-04
I0513 09:15:40.520483 22485033404224 run_lib.py:167] step: 256200, eval_loss: 7.29941e-04
I0513 09:16:04.478225 22485033404224 run_lib.py:146] step: 256250, training_loss: 5.80779e-04
I0513 09:16:28.116785 22485033404224 run_lib.py:146] step: 256300, training_loss: 5.93580e-04
I0513 09:16:28.277589 22485033404224 run_lib.py:167] step: 256300, eval_loss: 5.91867e-04
I0513 09:16:52.157064 22485033404224 run_lib.py:146] step: 256350, training_loss: 5.38715e-04
I0513 09:17:15.700474 22485033404224 run_lib.py:146] step: 256400, training_loss: 7.08442e-04
I0513 09:17:15.860949 22485033404224 run_lib.py:167] step: 256400, eval_loss: 6.56079e-04
I0513 09:17:39.670212 22485033404224 run_lib.py:146] step: 256450, training_loss: 8.81727e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 09:18:03.565276 22485033404224 run_lib.py:146] step: 256500, training_loss: 6.41940e-04
I0513 09:18:03.727503 22485033404224 run_lib.py:167] step: 256500, eval_loss: 5.13248e-04
I0513 09:18:27.269676 22485033404224 run_lib.py:146] step: 256550, training_loss: 4.83752e-04
I0513 09:18:51.115854 22485033404224 run_lib.py:146] step: 256600, training_loss: 6.53135e-04
I0513 09:18:51.274824 22485033404224 run_lib.py:167] step: 256600, eval_loss: 4.52654e-04
I0513 09:19:15.157432 22485033404224 run_lib.py:146] step: 256650, training_loss: 5.81401e-04
I0513 09:19:38.686964 22485033404224 run_lib.py:146] step: 256700, training_loss: 6.91177e-04
I0513 09:19:38.845814 22485033404224 run_lib.py:167] step: 256700, eval_loss: 5.81777e-04
I0513 09:20:02.675599 22485033404224 run_lib.py:146] step: 256750, training_loss: 7.30827e-04
I0513 09:20:26.512123 22485033404224 run_lib.py:146] step: 256800, training_loss: 6.25613e-04
I0513 09:20:26.672224 22485033404224 run_lib.py:167] step: 256800, eval_loss: 8.06456e-04
I0513 09:20:50.202965 22485033404224 run_lib.py:146] step: 256850, training_loss: 7.82283e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 09:21:14.090427 22485033404224 run_lib.py:146] step: 256900, training_loss: 5.18089e-04
I0513 09:21:14.251030 22485033404224 run_lib.py:167] step: 256900, eval_loss: 5.91181e-04
I0513 09:21:38.130462 22485033404224 run_lib.py:146] step: 256950, training_loss: 7.08970e-04
I0513 09:22:01.641183 22485033404224 run_lib.py:146] step: 257000, training_loss: 4.58761e-04
I0513 09:22:01.799651 22485033404224 run_lib.py:167] step: 257000, eval_loss: 7.71656e-04
I0513 09:22:25.618542 22485033404224 run_lib.py:146] step: 257050, training_loss: 5.46369e-04
I0513 09:22:49.430111 22485033404224 run_lib.py:146] step: 257100, training_loss: 5.54348e-04
I0513 09:22:49.589681 22485033404224 run_lib.py:167] step: 257100, eval_loss: 5.05760e-04
I0513 09:23:13.091013 22485033404224 run_lib.py:146] step: 257150, training_loss: 8.47957e-04
I0513 09:23:36.925806 22485033404224 run_lib.py:146] step: 257200, training_loss: 4.72812e-04
I0513 09:23:37.086537 22485033404224 run_lib.py:167] step: 257200, eval_loss: 7.13106e-04
I0513 09:24:00.580843 22485033404224 run_lib.py:146] step: 257250, training_loss: 5.35238e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 09:24:24.459627 22485033404224 run_lib.py:146] step: 257300, training_loss: 5.76565e-04
I0513 09:24:24.620599 22485033404224 run_lib.py:167] step: 257300, eval_loss: 6.55899e-04
I0513 09:24:48.111801 22485033404224 run_lib.py:146] step: 257350, training_loss: 6.11575e-04
I0513 09:25:11.955537 22485033404224 run_lib.py:146] step: 257400, training_loss: 6.19424e-04
I0513 09:25:12.114862 22485033404224 run_lib.py:167] step: 257400, eval_loss: 6.03628e-04
I0513 09:25:35.930631 22485033404224 run_lib.py:146] step: 257450, training_loss: 5.99297e-04
I0513 09:25:59.410135 22485033404224 run_lib.py:146] step: 257500, training_loss: 6.98552e-04
I0513 09:25:59.568923 22485033404224 run_lib.py:167] step: 257500, eval_loss: 7.33547e-04
I0513 09:26:23.377057 22485033404224 run_lib.py:146] step: 257550, training_loss: 6.51079e-04
I0513 09:26:47.157995 22485033404224 run_lib.py:146] step: 257600, training_loss: 6.63546e-04
I0513 09:26:47.316393 22485033404224 run_lib.py:167] step: 257600, eval_loss: 6.26738e-04
I0513 09:27:10.816317 22485033404224 run_lib.py:146] step: 257650, training_loss: 7.16193e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 09:27:34.800736 22485033404224 run_lib.py:146] step: 257700, training_loss: 5.29050e-04
I0513 09:27:34.961699 22485033404224 run_lib.py:167] step: 257700, eval_loss: 7.36541e-04
I0513 09:27:58.853878 22485033404224 run_lib.py:146] step: 257750, training_loss: 6.70395e-04
I0513 09:28:22.403483 22485033404224 run_lib.py:146] step: 257800, training_loss: 4.74298e-04
I0513 09:28:22.563449 22485033404224 run_lib.py:167] step: 257800, eval_loss: 5.71389e-04
I0513 09:28:46.468895 22485033404224 run_lib.py:146] step: 257850, training_loss: 5.26370e-04
I0513 09:29:10.373141 22485033404224 run_lib.py:146] step: 257900, training_loss: 6.92989e-04
I0513 09:29:10.532136 22485033404224 run_lib.py:167] step: 257900, eval_loss: 5.35667e-04
I0513 09:29:34.130748 22485033404224 run_lib.py:146] step: 257950, training_loss: 6.50808e-04
I0513 09:29:57.994293 22485033404224 run_lib.py:146] step: 258000, training_loss: 6.63590e-04
I0513 09:29:58.154300 22485033404224 run_lib.py:167] step: 258000, eval_loss: 6.50936e-04
I0513 09:30:22.034836 22485033404224 run_lib.py:146] step: 258050, training_loss: 5.78787e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 09:30:45.667314 22485033404224 run_lib.py:146] step: 258100, training_loss: 6.76379e-04
I0513 09:30:45.829027 22485033404224 run_lib.py:167] step: 258100, eval_loss: 5.83506e-04
I0513 09:31:09.768548 22485033404224 run_lib.py:146] step: 258150, training_loss: 5.57762e-04
I0513 09:31:33.369150 22485033404224 run_lib.py:146] step: 258200, training_loss: 7.22842e-04
I0513 09:31:33.529336 22485033404224 run_lib.py:167] step: 258200, eval_loss: 6.46412e-04
I0513 09:31:57.459171 22485033404224 run_lib.py:146] step: 258250, training_loss: 6.87432e-04
I0513 09:32:21.061562 22485033404224 run_lib.py:146] step: 258300, training_loss: 4.51316e-04
I0513 09:32:21.221397 22485033404224 run_lib.py:167] step: 258300, eval_loss: 6.53383e-04
I0513 09:32:45.118001 22485033404224 run_lib.py:146] step: 258350, training_loss: 5.88779e-04
I0513 09:33:09.030457 22485033404224 run_lib.py:146] step: 258400, training_loss: 6.39666e-04
I0513 09:33:09.190030 22485033404224 run_lib.py:167] step: 258400, eval_loss: 5.64261e-04
I0513 09:33:32.636000 22485033404224 run_lib.py:146] step: 258450, training_loss: 7.37768e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 09:33:56.766859 22485033404224 run_lib.py:146] step: 258500, training_loss: 7.51696e-04
I0513 09:33:56.929560 22485033404224 run_lib.py:167] step: 258500, eval_loss: 5.90241e-04
I0513 09:34:20.845841 22485033404224 run_lib.py:146] step: 258550, training_loss: 6.74310e-04
I0513 09:34:44.348423 22485033404224 run_lib.py:146] step: 258600, training_loss: 4.48635e-04
I0513 09:34:44.509215 22485033404224 run_lib.py:167] step: 258600, eval_loss: 5.96024e-04
I0513 09:35:08.304479 22485033404224 run_lib.py:146] step: 258650, training_loss: 9.49652e-04
I0513 09:35:32.126064 22485033404224 run_lib.py:146] step: 258700, training_loss: 6.12622e-04
I0513 09:35:32.285819 22485033404224 run_lib.py:167] step: 258700, eval_loss: 5.03343e-04
I0513 09:35:55.803251 22485033404224 run_lib.py:146] step: 258750, training_loss: 5.01422e-04
I0513 09:36:19.603668 22485033404224 run_lib.py:146] step: 258800, training_loss: 5.43812e-04
I0513 09:36:19.762370 22485033404224 run_lib.py:167] step: 258800, eval_loss: 6.17855e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 09:36:43.673478 22485033404224 run_lib.py:146] step: 258850, training_loss: 5.76563e-04
I0513 09:37:07.200855 22485033404224 run_lib.py:146] step: 258900, training_loss: 6.95041e-04
I0513 09:37:07.363440 22485033404224 run_lib.py:167] step: 258900, eval_loss: 6.12882e-04
I0513 09:37:31.206430 22485033404224 run_lib.py:146] step: 258950, training_loss: 5.65895e-04
I0513 09:37:54.736351 22485033404224 run_lib.py:146] step: 259000, training_loss: 5.92420e-04
I0513 09:37:54.895198 22485033404224 run_lib.py:167] step: 259000, eval_loss: 7.34134e-04
I0513 09:38:18.715337 22485033404224 run_lib.py:146] step: 259050, training_loss: 6.26618e-04
I0513 09:38:42.233460 22485033404224 run_lib.py:146] step: 259100, training_loss: 5.00455e-04
I0513 09:38:42.392898 22485033404224 run_lib.py:167] step: 259100, eval_loss: 5.06957e-04
I0513 09:39:06.189335 22485033404224 run_lib.py:146] step: 259150, training_loss: 6.22036e-04
I0513 09:39:30.000080 22485033404224 run_lib.py:146] step: 259200, training_loss: 8.85524e-04
I0513 09:39:30.159605 22485033404224 run_lib.py:167] step: 259200, eval_loss: 4.61284e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 09:39:53.740556 22485033404224 run_lib.py:146] step: 259250, training_loss: 6.62878e-04
I0513 09:40:17.626591 22485033404224 run_lib.py:146] step: 259300, training_loss: 8.75464e-04
I0513 09:40:17.788524 22485033404224 run_lib.py:167] step: 259300, eval_loss: 5.83049e-04
I0513 09:40:41.606232 22485033404224 run_lib.py:146] step: 259350, training_loss: 5.41595e-04
I0513 09:41:05.106838 22485033404224 run_lib.py:146] step: 259400, training_loss: 6.34649e-04
I0513 09:41:05.266170 22485033404224 run_lib.py:167] step: 259400, eval_loss: 4.52502e-04
I0513 09:41:29.075479 22485033404224 run_lib.py:146] step: 259450, training_loss: 7.35497e-04
I0513 09:41:52.905992 22485033404224 run_lib.py:146] step: 259500, training_loss: 4.77511e-04
I0513 09:41:53.065240 22485033404224 run_lib.py:167] step: 259500, eval_loss: 5.43089e-04
I0513 09:42:16.618424 22485033404224 run_lib.py:146] step: 259550, training_loss: 5.28148e-04
I0513 09:42:40.443176 22485033404224 run_lib.py:146] step: 259600, training_loss: 7.04679e-04
I0513 09:42:40.601517 22485033404224 run_lib.py:167] step: 259600, eval_loss: 4.62419e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 09:43:04.535083 22485033404224 run_lib.py:146] step: 259650, training_loss: 6.24073e-04
I0513 09:43:28.061248 22485033404224 run_lib.py:146] step: 259700, training_loss: 6.02702e-04
I0513 09:43:28.222362 22485033404224 run_lib.py:167] step: 259700, eval_loss: 6.67717e-04
I0513 09:43:52.079259 22485033404224 run_lib.py:146] step: 259750, training_loss: 6.42827e-04
I0513 09:44:15.882002 22485033404224 run_lib.py:146] step: 259800, training_loss: 7.21830e-04
I0513 09:44:16.041166 22485033404224 run_lib.py:167] step: 259800, eval_loss: 7.34731e-04
I0513 09:44:39.550534 22485033404224 run_lib.py:146] step: 259850, training_loss: 7.11294e-04
I0513 09:45:03.105787 22485033404224 run_lib.py:146] step: 259900, training_loss: 5.67657e-04
I0513 09:45:03.266392 22485033404224 run_lib.py:167] step: 259900, eval_loss: 5.62572e-04
I0513 09:45:27.157642 22485033404224 run_lib.py:146] step: 259950, training_loss: 5.10860e-04
I0513 09:45:51.055141 22485033404224 run_lib.py:146] step: 260000, training_loss: 6.46450e-04
I0513 09:45:52.793563 22485033404224 run_lib.py:167] step: 260000, eval_loss: 6.24595e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 09:46:18.434051 22485033404224 run_lib.py:146] step: 260050, training_loss: 7.66365e-04
I0513 09:46:42.033661 22485033404224 run_lib.py:146] step: 260100, training_loss: 4.54050e-04
I0513 09:46:42.194339 22485033404224 run_lib.py:167] step: 260100, eval_loss: 4.32035e-04
I0513 09:47:06.146029 22485033404224 run_lib.py:146] step: 260150, training_loss: 5.82432e-04
I0513 09:47:30.050250 22485033404224 run_lib.py:146] step: 260200, training_loss: 5.60768e-04
I0513 09:47:30.209771 22485033404224 run_lib.py:167] step: 260200, eval_loss: 6.89189e-04
I0513 09:47:53.818713 22485033404224 run_lib.py:146] step: 260250, training_loss: 4.89484e-04
I0513 09:48:17.724179 22485033404224 run_lib.py:146] step: 260300, training_loss: 5.31622e-04
I0513 09:48:17.883542 22485033404224 run_lib.py:167] step: 260300, eval_loss: 5.39263e-04
I0513 09:48:41.747699 22485033404224 run_lib.py:146] step: 260350, training_loss: 7.19456e-04
I0513 09:49:05.363961 22485033404224 run_lib.py:146] step: 260400, training_loss: 6.84560e-04
I0513 09:49:05.526126 22485033404224 run_lib.py:167] step: 260400, eval_loss: 6.88896e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 09:49:29.547750 22485033404224 run_lib.py:146] step: 260450, training_loss: 6.68350e-04
I0513 09:49:53.494469 22485033404224 run_lib.py:146] step: 260500, training_loss: 5.90527e-04
I0513 09:49:53.654987 22485033404224 run_lib.py:167] step: 260500, eval_loss: 4.94337e-04
I0513 09:50:17.250394 22485033404224 run_lib.py:146] step: 260550, training_loss: 5.69839e-04
I0513 09:50:41.125869 22485033404224 run_lib.py:146] step: 260600, training_loss: 6.00759e-04
I0513 09:50:41.210928 22485033404224 run_lib.py:167] step: 260600, eval_loss: 8.13963e-04
I0513 09:51:04.783534 22485033404224 run_lib.py:146] step: 260650, training_loss: 6.41027e-04
I0513 09:51:28.693306 22485033404224 run_lib.py:146] step: 260700, training_loss: 7.27701e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 09:51:29.043951 22485033404224 run_lib.py:167] step: 260700, eval_loss: 6.80250e-04
I0513 09:51:52.962167 22485033404224 run_lib.py:146] step: 260750, training_loss: 6.45678e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 09:52:16.577403 22485033404224 run_lib.py:146] step: 260800, training_loss: 6.15172e-04
I0513 09:52:16.739387 22485033404224 run_lib.py:167] step: 260800, eval_loss: 6.70454e-04
I0513 09:52:40.585538 22485033404224 run_lib.py:146] step: 260850, training_loss: 8.03784e-04
I0513 09:53:04.091449 22485033404224 run_lib.py:146] step: 260900, training_loss: 5.12913e-04
I0513 09:53:04.250751 22485033404224 run_lib.py:167] step: 260900, eval_loss: 5.83979e-04
I0513 09:53:28.100106 22485033404224 run_lib.py:146] step: 260950, training_loss: 5.58140e-04
I0513 09:53:51.923326 22485033404224 run_lib.py:146] step: 261000, training_loss: 5.53529e-04
I0513 09:53:52.081818 22485033404224 run_lib.py:167] step: 261000, eval_loss: 6.93927e-04
I0513 09:54:15.606320 22485033404224 run_lib.py:146] step: 261050, training_loss: 7.43402e-04
I0513 09:54:39.424787 22485033404224 run_lib.py:146] step: 261100, training_loss: 6.78462e-04
I0513 09:54:39.584987 22485033404224 run_lib.py:167] step: 261100, eval_loss: 5.53207e-04
I0513 09:55:03.405423 22485033404224 run_lib.py:146] step: 261150, training_loss: 5.71421e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 09:55:26.980148 22485033404224 run_lib.py:146] step: 261200, training_loss: 6.86398e-04
I0513 09:55:27.142395 22485033404224 run_lib.py:167] step: 261200, eval_loss: 6.10480e-04
I0513 09:55:50.976567 22485033404224 run_lib.py:146] step: 261250, training_loss: 7.61374e-04
I0513 09:56:14.843575 22485033404224 run_lib.py:146] step: 261300, training_loss: 5.94773e-04
I0513 09:56:15.004511 22485033404224 run_lib.py:167] step: 261300, eval_loss: 5.22756e-04
I0513 09:56:38.516714 22485033404224 run_lib.py:146] step: 261350, training_loss: 5.73173e-04
I0513 09:57:02.339179 22485033404224 run_lib.py:146] step: 261400, training_loss: 5.74907e-04
I0513 09:57:02.497580 22485033404224 run_lib.py:167] step: 261400, eval_loss: 7.45617e-04
I0513 09:57:26.047776 22485033404224 run_lib.py:146] step: 261450, training_loss: 5.39194e-04
I0513 09:57:49.858441 22485033404224 run_lib.py:146] step: 261500, training_loss: 7.69604e-04
I0513 09:57:50.017716 22485033404224 run_lib.py:167] step: 261500, eval_loss: 6.02340e-04
I0513 09:58:13.830372 22485033404224 run_lib.py:146] step: 261550, training_loss: 5.89365e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 09:58:37.413426 22485033404224 run_lib.py:146] step: 261600, training_loss: 4.99344e-04
I0513 09:58:37.574023 22485033404224 run_lib.py:167] step: 261600, eval_loss: 5.99472e-04
I0513 09:59:01.393616 22485033404224 run_lib.py:146] step: 261650, training_loss: 5.53830e-04
I0513 09:59:24.888847 22485033404224 run_lib.py:146] step: 261700, training_loss: 6.65382e-04
I0513 09:59:25.048993 22485033404224 run_lib.py:167] step: 261700, eval_loss: 5.04431e-04
I0513 09:59:48.828962 22485033404224 run_lib.py:146] step: 261750, training_loss: 5.07234e-04
I0513 10:00:12.628764 22485033404224 run_lib.py:146] step: 261800, training_loss: 6.08253e-04
I0513 10:00:12.787418 22485033404224 run_lib.py:167] step: 261800, eval_loss: 6.16968e-04
I0513 10:00:36.315333 22485033404224 run_lib.py:146] step: 261850, training_loss: 5.69513e-04
I0513 10:01:00.114266 22485033404224 run_lib.py:146] step: 261900, training_loss: 5.68833e-04
I0513 10:01:00.274078 22485033404224 run_lib.py:167] step: 261900, eval_loss: 6.83068e-04
I0513 10:01:24.073962 22485033404224 run_lib.py:146] step: 261950, training_loss: 7.99364e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 10:01:47.657732 22485033404224 run_lib.py:146] step: 262000, training_loss: 7.58355e-04
I0513 10:01:47.818697 22485033404224 run_lib.py:167] step: 262000, eval_loss: 5.57841e-04
I0513 10:02:11.655568 22485033404224 run_lib.py:146] step: 262050, training_loss: 7.36251e-04
I0513 10:02:35.541995 22485033404224 run_lib.py:146] step: 262100, training_loss: 4.99092e-04
I0513 10:02:35.703430 22485033404224 run_lib.py:167] step: 262100, eval_loss: 8.43924e-04
I0513 10:02:59.281640 22485033404224 run_lib.py:146] step: 262150, training_loss: 5.36763e-04
I0513 10:03:23.169952 22485033404224 run_lib.py:146] step: 262200, training_loss: 6.66926e-04
I0513 10:03:23.329968 22485033404224 run_lib.py:167] step: 262200, eval_loss: 5.36582e-04
I0513 10:03:47.222722 22485033404224 run_lib.py:146] step: 262250, training_loss: 7.53111e-04
I0513 10:04:10.808748 22485033404224 run_lib.py:146] step: 262300, training_loss: 6.27974e-04
I0513 10:04:10.968447 22485033404224 run_lib.py:167] step: 262300, eval_loss: 4.63644e-04
I0513 10:04:34.850042 22485033404224 run_lib.py:146] step: 262350, training_loss: 7.44960e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 10:04:58.475761 22485033404224 run_lib.py:146] step: 262400, training_loss: 4.99582e-04
I0513 10:04:58.638375 22485033404224 run_lib.py:167] step: 262400, eval_loss: 7.04231e-04
I0513 10:05:22.690858 22485033404224 run_lib.py:146] step: 262450, training_loss: 7.16261e-04
I0513 10:05:46.239881 22485033404224 run_lib.py:146] step: 262500, training_loss: 4.60590e-04
I0513 10:05:46.399825 22485033404224 run_lib.py:167] step: 262500, eval_loss: 7.10058e-04
I0513 10:06:10.410995 22485033404224 run_lib.py:146] step: 262550, training_loss: 8.21532e-04
I0513 10:06:34.385586 22485033404224 run_lib.py:146] step: 262600, training_loss: 6.84666e-04
I0513 10:06:34.546607 22485033404224 run_lib.py:167] step: 262600, eval_loss: 5.20495e-04
I0513 10:06:58.147834 22485033404224 run_lib.py:146] step: 262650, training_loss: 7.73766e-04
I0513 10:07:22.124790 22485033404224 run_lib.py:146] step: 262700, training_loss: 6.28904e-04
I0513 10:07:22.285084 22485033404224 run_lib.py:167] step: 262700, eval_loss: 4.29049e-04
I0513 10:07:46.280732 22485033404224 run_lib.py:146] step: 262750, training_loss: 7.03645e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 10:08:09.943452 22485033404224 run_lib.py:146] step: 262800, training_loss: 6.78407e-04
I0513 10:08:10.106811 22485033404224 run_lib.py:167] step: 262800, eval_loss: 6.76913e-04
I0513 10:08:34.119174 22485033404224 run_lib.py:146] step: 262850, training_loss: 6.98292e-04
I0513 10:08:58.075149 22485033404224 run_lib.py:146] step: 262900, training_loss: 6.45318e-04
I0513 10:08:58.236333 22485033404224 run_lib.py:167] step: 262900, eval_loss: 6.12206e-04
I0513 10:09:21.828440 22485033404224 run_lib.py:146] step: 262950, training_loss: 6.46117e-04
I0513 10:09:45.778630 22485033404224 run_lib.py:146] step: 263000, training_loss: 5.98346e-04
I0513 10:09:45.937970 22485033404224 run_lib.py:167] step: 263000, eval_loss: 5.83986e-04
I0513 10:10:09.756551 22485033404224 run_lib.py:146] step: 263050, training_loss: 4.24454e-04
I0513 10:10:33.232869 22485033404224 run_lib.py:146] step: 263100, training_loss: 6.05689e-04
I0513 10:10:33.391435 22485033404224 run_lib.py:167] step: 263100, eval_loss: 4.17595e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 10:10:57.326090 22485033404224 run_lib.py:146] step: 263150, training_loss: 4.65259e-04
I0513 10:11:20.842014 22485033404224 run_lib.py:146] step: 263200, training_loss: 5.45972e-04
I0513 10:11:21.003222 22485033404224 run_lib.py:167] step: 263200, eval_loss: 5.20023e-04
I0513 10:11:44.826642 22485033404224 run_lib.py:146] step: 263250, training_loss: 6.71582e-04
I0513 10:12:08.344291 22485033404224 run_lib.py:146] step: 263300, training_loss: 6.93047e-04
I0513 10:12:08.504054 22485033404224 run_lib.py:167] step: 263300, eval_loss: 4.75883e-04
I0513 10:12:32.370486 22485033404224 run_lib.py:146] step: 263350, training_loss: 7.34028e-04
I0513 10:12:56.177054 22485033404224 run_lib.py:146] step: 263400, training_loss: 7.80596e-04
I0513 10:12:56.335070 22485033404224 run_lib.py:167] step: 263400, eval_loss: 6.89354e-04
I0513 10:13:19.854361 22485033404224 run_lib.py:146] step: 263450, training_loss: 6.92021e-04
I0513 10:13:43.680660 22485033404224 run_lib.py:146] step: 263500, training_loss: 4.02575e-04
I0513 10:13:43.839660 22485033404224 run_lib.py:167] step: 263500, eval_loss: 5.18410e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 10:14:07.729907 22485033404224 run_lib.py:146] step: 263550, training_loss: 6.99197e-04
I0513 10:14:31.251487 22485033404224 run_lib.py:146] step: 263600, training_loss: 6.71981e-04
I0513 10:14:31.412467 22485033404224 run_lib.py:167] step: 263600, eval_loss: 3.27926e-04
I0513 10:14:55.264193 22485033404224 run_lib.py:146] step: 263650, training_loss: 6.27801e-04
I0513 10:15:19.127464 22485033404224 run_lib.py:146] step: 263700, training_loss: 7.70061e-04
I0513 10:15:19.285977 22485033404224 run_lib.py:167] step: 263700, eval_loss: 7.02747e-04
I0513 10:15:42.800217 22485033404224 run_lib.py:146] step: 263750, training_loss: 5.22564e-04
I0513 10:16:06.632773 22485033404224 run_lib.py:146] step: 263800, training_loss: 5.05578e-04
I0513 10:16:06.793112 22485033404224 run_lib.py:167] step: 263800, eval_loss: 5.43927e-04
I0513 10:16:30.618044 22485033404224 run_lib.py:146] step: 263850, training_loss: 7.31820e-04
I0513 10:16:54.159598 22485033404224 run_lib.py:146] step: 263900, training_loss: 5.36491e-04
I0513 10:16:54.318610 22485033404224 run_lib.py:167] step: 263900, eval_loss: 5.41883e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 10:17:18.268776 22485033404224 run_lib.py:146] step: 263950, training_loss: 9.34865e-04
I0513 10:17:42.158271 22485033404224 run_lib.py:146] step: 264000, training_loss: 8.93842e-04
I0513 10:17:42.319133 22485033404224 run_lib.py:167] step: 264000, eval_loss: 6.72874e-04
I0513 10:18:05.830980 22485033404224 run_lib.py:146] step: 264050, training_loss: 7.05584e-04
I0513 10:18:29.324152 22485033404224 run_lib.py:146] step: 264100, training_loss: 6.60455e-04
I0513 10:18:29.483172 22485033404224 run_lib.py:167] step: 264100, eval_loss: 8.92622e-04
I0513 10:18:53.318364 22485033404224 run_lib.py:146] step: 264150, training_loss: 4.49102e-04
I0513 10:19:17.147908 22485033404224 run_lib.py:146] step: 264200, training_loss: 6.71873e-04
I0513 10:19:17.307358 22485033404224 run_lib.py:167] step: 264200, eval_loss: 4.76838e-04
I0513 10:19:40.825444 22485033404224 run_lib.py:146] step: 264250, training_loss: 6.44943e-04
I0513 10:20:04.627643 22485033404224 run_lib.py:146] step: 264300, training_loss: 6.34499e-04
I0513 10:20:04.788656 22485033404224 run_lib.py:167] step: 264300, eval_loss: 5.76196e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 10:20:28.775987 22485033404224 run_lib.py:146] step: 264350, training_loss: 5.49185e-04
I0513 10:20:52.363646 22485033404224 run_lib.py:146] step: 264400, training_loss: 5.08653e-04
I0513 10:20:52.524837 22485033404224 run_lib.py:167] step: 264400, eval_loss: 5.51925e-04
I0513 10:21:16.461535 22485033404224 run_lib.py:146] step: 264450, training_loss: 7.79094e-04
I0513 10:21:40.400753 22485033404224 run_lib.py:146] step: 264500, training_loss: 8.02483e-04
I0513 10:21:40.560523 22485033404224 run_lib.py:167] step: 264500, eval_loss: 6.69359e-04
I0513 10:22:04.102355 22485033404224 run_lib.py:146] step: 264550, training_loss: 5.23286e-04
I0513 10:22:28.008675 22485033404224 run_lib.py:146] step: 264600, training_loss: 3.20008e-04
I0513 10:22:28.170200 22485033404224 run_lib.py:167] step: 264600, eval_loss: 5.64482e-04
I0513 10:22:52.041956 22485033404224 run_lib.py:146] step: 264650, training_loss: 6.58277e-04
I0513 10:23:15.576304 22485033404224 run_lib.py:146] step: 264700, training_loss: 6.07561e-04
I0513 10:23:15.735760 22485033404224 run_lib.py:167] step: 264700, eval_loss: 4.36657e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 10:23:39.699802 22485033404224 run_lib.py:146] step: 264750, training_loss: 5.19790e-04
I0513 10:24:03.601278 22485033404224 run_lib.py:146] step: 264800, training_loss: 6.57368e-04
I0513 10:24:03.762262 22485033404224 run_lib.py:167] step: 264800, eval_loss: 6.05391e-04
I0513 10:24:27.369901 22485033404224 run_lib.py:146] step: 264850, training_loss: 6.86016e-04
I0513 10:24:50.973513 22485033404224 run_lib.py:146] step: 264900, training_loss: 5.27819e-04
I0513 10:24:51.134544 22485033404224 run_lib.py:167] step: 264900, eval_loss: 6.05313e-04
I0513 10:25:15.322373 22485033404224 run_lib.py:146] step: 264950, training_loss: 5.11978e-04
I0513 10:25:38.931215 22485033404224 run_lib.py:146] step: 265000, training_loss: 6.96059e-04
I0513 10:25:39.091382 22485033404224 run_lib.py:167] step: 265000, eval_loss: 3.42838e-04
I0513 10:26:02.665581 22485033404224 run_lib.py:146] step: 265050, training_loss: 6.92585e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 10:26:26.610709 22485033404224 run_lib.py:146] step: 265100, training_loss: 6.13717e-04
I0513 10:26:26.772622 22485033404224 run_lib.py:167] step: 265100, eval_loss: 4.80796e-04
I0513 10:26:50.715101 22485033404224 run_lib.py:146] step: 265150, training_loss: 4.69048e-04
I0513 10:27:14.298218 22485033404224 run_lib.py:146] step: 265200, training_loss: 5.94205e-04
I0513 10:27:14.459449 22485033404224 run_lib.py:167] step: 265200, eval_loss: 6.17877e-04
I0513 10:27:38.314431 22485033404224 run_lib.py:146] step: 265250, training_loss: 4.97969e-04
I0513 10:28:02.148072 22485033404224 run_lib.py:146] step: 265300, training_loss: 5.30388e-04
I0513 10:28:02.307681 22485033404224 run_lib.py:167] step: 265300, eval_loss: 6.48841e-04
I0513 10:28:25.845229 22485033404224 run_lib.py:146] step: 265350, training_loss: 6.11039e-04
I0513 10:28:49.640216 22485033404224 run_lib.py:146] step: 265400, training_loss: 4.45716e-04
I0513 10:28:49.799357 22485033404224 run_lib.py:167] step: 265400, eval_loss: 4.99061e-04
I0513 10:29:13.612308 22485033404224 run_lib.py:146] step: 265450, training_loss: 7.65441e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 10:29:37.203745 22485033404224 run_lib.py:146] step: 265500, training_loss: 7.09394e-04
I0513 10:29:37.364835 22485033404224 run_lib.py:167] step: 265500, eval_loss: 5.20830e-04
I0513 10:30:01.224959 22485033404224 run_lib.py:146] step: 265550, training_loss: 6.42977e-04
I0513 10:30:25.082519 22485033404224 run_lib.py:146] step: 265600, training_loss: 7.25248e-04
I0513 10:30:25.243120 22485033404224 run_lib.py:167] step: 265600, eval_loss: 6.69709e-04
I0513 10:30:48.753902 22485033404224 run_lib.py:146] step: 265650, training_loss: 5.30382e-04
I0513 10:31:12.267803 22485033404224 run_lib.py:146] step: 265700, training_loss: 6.92138e-04
I0513 10:31:12.427350 22485033404224 run_lib.py:167] step: 265700, eval_loss: 6.36021e-04
I0513 10:31:36.551136 22485033404224 run_lib.py:146] step: 265750, training_loss: 5.27641e-04
I0513 10:32:00.081068 22485033404224 run_lib.py:146] step: 265800, training_loss: 4.98795e-04
I0513 10:32:00.241215 22485033404224 run_lib.py:167] step: 265800, eval_loss: 8.34639e-04
I0513 10:32:23.767762 22485033404224 run_lib.py:146] step: 265850, training_loss: 5.43499e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 10:32:47.661915 22485033404224 run_lib.py:146] step: 265900, training_loss: 6.49028e-04
I0513 10:32:47.823184 22485033404224 run_lib.py:167] step: 265900, eval_loss: 5.32573e-04
I0513 10:33:11.695042 22485033404224 run_lib.py:146] step: 265950, training_loss: 6.81993e-04
I0513 10:33:35.209120 22485033404224 run_lib.py:146] step: 266000, training_loss: 8.22529e-04
I0513 10:33:35.369884 22485033404224 run_lib.py:167] step: 266000, eval_loss: 4.67673e-04
I0513 10:33:59.213727 22485033404224 run_lib.py:146] step: 266050, training_loss: 6.27868e-04
I0513 10:34:23.029042 22485033404224 run_lib.py:146] step: 266100, training_loss: 5.94991e-04
I0513 10:34:23.189905 22485033404224 run_lib.py:167] step: 266100, eval_loss: 5.64992e-04
I0513 10:34:46.734115 22485033404224 run_lib.py:146] step: 266150, training_loss: 5.97885e-04
I0513 10:35:10.580003 22485033404224 run_lib.py:146] step: 266200, training_loss: 5.12963e-04
I0513 10:35:10.738330 22485033404224 run_lib.py:167] step: 266200, eval_loss: 5.40475e-04
I0513 10:35:34.532940 22485033404224 run_lib.py:146] step: 266250, training_loss: 4.71735e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 10:35:58.122928 22485033404224 run_lib.py:146] step: 266300, training_loss: 8.07864e-04
I0513 10:35:58.283786 22485033404224 run_lib.py:167] step: 266300, eval_loss: 5.98096e-04
I0513 10:36:22.134785 22485033404224 run_lib.py:146] step: 266350, training_loss: 5.89772e-04
I0513 10:36:46.000696 22485033404224 run_lib.py:146] step: 266400, training_loss: 5.68724e-04
I0513 10:36:46.160365 22485033404224 run_lib.py:167] step: 266400, eval_loss: 5.85774e-04
I0513 10:37:09.698251 22485033404224 run_lib.py:146] step: 266450, training_loss: 6.20939e-04
I0513 10:37:33.232856 22485033404224 run_lib.py:146] step: 266500, training_loss: 6.37874e-04
I0513 10:37:33.392986 22485033404224 run_lib.py:167] step: 266500, eval_loss: 6.66480e-04
I0513 10:37:57.616534 22485033404224 run_lib.py:146] step: 266550, training_loss: 5.28302e-04
I0513 10:38:21.221853 22485033404224 run_lib.py:146] step: 266600, training_loss: 4.65577e-04
I0513 10:38:21.383206 22485033404224 run_lib.py:167] step: 266600, eval_loss: 7.19342e-04
I0513 10:38:44.971068 22485033404224 run_lib.py:146] step: 266650, training_loss: 6.04534e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 10:39:08.998712 22485033404224 run_lib.py:146] step: 266700, training_loss: 5.23620e-04
I0513 10:39:09.160315 22485033404224 run_lib.py:167] step: 266700, eval_loss: 7.51762e-04
I0513 10:39:33.082401 22485033404224 run_lib.py:146] step: 266750, training_loss: 3.86339e-04
I0513 10:39:56.642301 22485033404224 run_lib.py:146] step: 266800, training_loss: 6.25243e-04
I0513 10:39:56.802526 22485033404224 run_lib.py:167] step: 266800, eval_loss: 5.95642e-04
I0513 10:40:20.661927 22485033404224 run_lib.py:146] step: 266850, training_loss: 5.86281e-04
I0513 10:40:44.538889 22485033404224 run_lib.py:146] step: 266900, training_loss: 4.33667e-04
I0513 10:40:44.699983 22485033404224 run_lib.py:167] step: 266900, eval_loss: 6.92844e-04
I0513 10:41:08.218550 22485033404224 run_lib.py:146] step: 266950, training_loss: 4.89023e-04
I0513 10:41:32.076817 22485033404224 run_lib.py:146] step: 267000, training_loss: 6.00346e-04
I0513 10:41:32.237153 22485033404224 run_lib.py:167] step: 267000, eval_loss: 7.41225e-04
I0513 10:41:56.136810 22485033404224 run_lib.py:146] step: 267050, training_loss: 8.52890e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 10:42:19.802469 22485033404224 run_lib.py:146] step: 267100, training_loss: 5.72605e-04
I0513 10:42:19.964349 22485033404224 run_lib.py:167] step: 267100, eval_loss: 6.86318e-04
I0513 10:42:43.890023 22485033404224 run_lib.py:146] step: 267150, training_loss: 8.36664e-04
I0513 10:43:07.808231 22485033404224 run_lib.py:146] step: 267200, training_loss: 6.95542e-04
I0513 10:43:07.969411 22485033404224 run_lib.py:167] step: 267200, eval_loss: 6.80722e-04
I0513 10:43:31.543274 22485033404224 run_lib.py:146] step: 267250, training_loss: 7.55359e-04
I0513 10:43:55.097485 22485033404224 run_lib.py:146] step: 267300, training_loss: 5.16433e-04
I0513 10:43:55.257815 22485033404224 run_lib.py:167] step: 267300, eval_loss: 6.17330e-04
I0513 10:44:19.440221 22485033404224 run_lib.py:146] step: 267350, training_loss: 5.57305e-04
I0513 10:44:43.015460 22485033404224 run_lib.py:146] step: 267400, training_loss: 9.10061e-04
I0513 10:44:43.175355 22485033404224 run_lib.py:167] step: 267400, eval_loss: 6.65920e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 10:45:06.789598 22485033404224 run_lib.py:146] step: 267450, training_loss: 7.72777e-04
I0513 10:45:30.649688 22485033404224 run_lib.py:146] step: 267500, training_loss: 7.99443e-04
I0513 10:45:31.132882 22485033404224 run_lib.py:167] step: 267500, eval_loss: 4.11176e-04
I0513 10:45:54.643140 22485033404224 run_lib.py:146] step: 267550, training_loss: 5.84244e-04
I0513 10:46:18.170696 22485033404224 run_lib.py:146] step: 267600, training_loss: 6.36844e-04
I0513 10:46:18.329716 22485033404224 run_lib.py:167] step: 267600, eval_loss: 6.49922e-04
I0513 10:46:42.142993 22485033404224 run_lib.py:146] step: 267650, training_loss: 6.02623e-04
I0513 10:47:05.958213 22485033404224 run_lib.py:146] step: 267700, training_loss: 7.62046e-04
I0513 10:47:06.116945 22485033404224 run_lib.py:167] step: 267700, eval_loss: 6.33137e-04
I0513 10:47:29.659111 22485033404224 run_lib.py:146] step: 267750, training_loss: 4.73426e-04
I0513 10:47:53.487050 22485033404224 run_lib.py:146] step: 267800, training_loss: 6.07222e-04
I0513 10:47:53.648391 22485033404224 run_lib.py:167] step: 267800, eval_loss: 7.55958e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 10:48:17.532327 22485033404224 run_lib.py:146] step: 267850, training_loss: 5.62873e-04
I0513 10:48:41.040832 22485033404224 run_lib.py:146] step: 267900, training_loss: 6.16804e-04
I0513 10:48:41.203296 22485033404224 run_lib.py:167] step: 267900, eval_loss: 4.38790e-04
I0513 10:49:05.027496 22485033404224 run_lib.py:146] step: 267950, training_loss: 7.02918e-04
I0513 10:49:28.888518 22485033404224 run_lib.py:146] step: 268000, training_loss: 8.40539e-04
I0513 10:49:29.047949 22485033404224 run_lib.py:167] step: 268000, eval_loss: 6.31810e-04
I0513 10:49:52.570919 22485033404224 run_lib.py:146] step: 268050, training_loss: 5.17879e-04
I0513 10:50:16.375688 22485033404224 run_lib.py:146] step: 268100, training_loss: 6.51391e-04
I0513 10:50:16.535165 22485033404224 run_lib.py:167] step: 268100, eval_loss: 6.99097e-04
I0513 10:50:40.368310 22485033404224 run_lib.py:146] step: 268150, training_loss: 3.37505e-04
I0513 10:51:03.902238 22485033404224 run_lib.py:146] step: 268200, training_loss: 5.23874e-04
I0513 10:51:04.061063 22485033404224 run_lib.py:167] step: 268200, eval_loss: 6.98762e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 10:51:27.635666 22485033404224 run_lib.py:146] step: 268250, training_loss: 6.96729e-04
I0513 10:51:51.857846 22485033404224 run_lib.py:146] step: 268300, training_loss: 7.11420e-04
I0513 10:51:52.018535 22485033404224 run_lib.py:167] step: 268300, eval_loss: 6.18804e-04
I0513 10:52:15.516507 22485033404224 run_lib.py:146] step: 268350, training_loss: 7.17313e-04
I0513 10:52:39.017877 22485033404224 run_lib.py:146] step: 268400, training_loss: 5.37288e-04
I0513 10:52:39.176931 22485033404224 run_lib.py:167] step: 268400, eval_loss: 7.06167e-04
I0513 10:53:02.973387 22485033404224 run_lib.py:146] step: 268450, training_loss: 6.10774e-04
I0513 10:53:26.755322 22485033404224 run_lib.py:146] step: 268500, training_loss: 7.40639e-04
I0513 10:53:26.839470 22485033404224 run_lib.py:167] step: 268500, eval_loss: 6.99459e-04
I0513 10:53:50.315182 22485033404224 run_lib.py:146] step: 268550, training_loss: 6.03021e-04
I0513 10:54:14.125159 22485033404224 run_lib.py:146] step: 268600, training_loss: 4.90681e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 10:54:14.474184 22485033404224 run_lib.py:167] step: 268600, eval_loss: 5.66176e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 10:54:38.409269 22485033404224 run_lib.py:146] step: 268650, training_loss: 6.31338e-04
I0513 10:55:01.943559 22485033404224 run_lib.py:146] step: 268700, training_loss: 7.68044e-04
I0513 10:55:02.104589 22485033404224 run_lib.py:167] step: 268700, eval_loss: 6.63305e-04
I0513 10:55:25.987396 22485033404224 run_lib.py:146] step: 268750, training_loss: 6.77783e-04
I0513 10:55:49.921648 22485033404224 run_lib.py:146] step: 268800, training_loss: 6.82151e-04
I0513 10:55:50.083535 22485033404224 run_lib.py:167] step: 268800, eval_loss: 6.37543e-04
I0513 10:56:13.664043 22485033404224 run_lib.py:146] step: 268850, training_loss: 6.93447e-04
I0513 10:56:37.564512 22485033404224 run_lib.py:146] step: 268900, training_loss: 6.53271e-04
I0513 10:56:37.724418 22485033404224 run_lib.py:167] step: 268900, eval_loss: 6.71206e-04
I0513 10:57:01.640990 22485033404224 run_lib.py:146] step: 268950, training_loss: 4.59999e-04
I0513 10:57:25.211036 22485033404224 run_lib.py:146] step: 269000, training_loss: 6.23626e-04
I0513 10:57:25.371064 22485033404224 run_lib.py:167] step: 269000, eval_loss: 5.50448e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 10:57:49.701937 22485033404224 run_lib.py:146] step: 269050, training_loss: 5.45854e-04
I0513 10:58:14.011871 22485033404224 run_lib.py:146] step: 269100, training_loss: 5.43565e-04
I0513 10:58:14.174524 22485033404224 run_lib.py:167] step: 269100, eval_loss: 7.34181e-04
I0513 10:58:37.969943 22485033404224 run_lib.py:146] step: 269150, training_loss: 6.44227e-04
I0513 10:59:01.799025 22485033404224 run_lib.py:146] step: 269200, training_loss: 5.49691e-04
I0513 10:59:01.960553 22485033404224 run_lib.py:167] step: 269200, eval_loss: 5.43658e-04
I0513 10:59:26.196536 22485033404224 run_lib.py:146] step: 269250, training_loss: 5.93129e-04
I0513 10:59:50.277917 22485033404224 run_lib.py:146] step: 269300, training_loss: 7.89592e-04
I0513 10:59:50.437184 22485033404224 run_lib.py:167] step: 269300, eval_loss: 6.32129e-04
I0513 11:00:14.025952 22485033404224 run_lib.py:146] step: 269350, training_loss: 5.41764e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 11:00:38.015741 22485033404224 run_lib.py:146] step: 269400, training_loss: 4.27120e-04
I0513 11:00:38.178748 22485033404224 run_lib.py:167] step: 269400, eval_loss: 5.35374e-04
I0513 11:01:02.134378 22485033404224 run_lib.py:146] step: 269450, training_loss: 6.60276e-04
I0513 11:01:25.703700 22485033404224 run_lib.py:146] step: 269500, training_loss: 5.86883e-04
I0513 11:01:25.864251 22485033404224 run_lib.py:167] step: 269500, eval_loss: 9.09553e-04
I0513 11:01:49.792738 22485033404224 run_lib.py:146] step: 269550, training_loss: 5.54011e-04
I0513 11:02:13.692338 22485033404224 run_lib.py:146] step: 269600, training_loss: 7.58020e-04
I0513 11:02:13.851129 22485033404224 run_lib.py:167] step: 269600, eval_loss: 7.61102e-04
I0513 11:02:37.387734 22485033404224 run_lib.py:146] step: 269650, training_loss: 8.65811e-04
I0513 11:03:01.211380 22485033404224 run_lib.py:146] step: 269700, training_loss: 6.13654e-04
I0513 11:03:01.370212 22485033404224 run_lib.py:167] step: 269700, eval_loss: 4.68316e-04
I0513 11:03:25.207922 22485033404224 run_lib.py:146] step: 269750, training_loss: 6.08715e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 11:03:48.799020 22485033404224 run_lib.py:146] step: 269800, training_loss: 8.79338e-04
I0513 11:03:48.960201 22485033404224 run_lib.py:167] step: 269800, eval_loss: 6.08737e-04
I0513 11:04:12.811532 22485033404224 run_lib.py:146] step: 269850, training_loss: 5.80776e-04
I0513 11:04:36.613929 22485033404224 run_lib.py:146] step: 269900, training_loss: 5.68168e-04
I0513 11:04:36.773963 22485033404224 run_lib.py:167] step: 269900, eval_loss: 5.96396e-04
I0513 11:05:00.281308 22485033404224 run_lib.py:146] step: 269950, training_loss: 4.49686e-04
I0513 11:05:23.792409 22485033404224 run_lib.py:146] step: 270000, training_loss: 6.10094e-04
I0513 11:05:25.499919 22485033404224 run_lib.py:167] step: 270000, eval_loss: 5.35785e-04
I0513 11:05:51.050968 22485033404224 run_lib.py:146] step: 270050, training_loss: 4.81881e-04
I0513 11:06:14.530564 22485033404224 run_lib.py:146] step: 270100, training_loss: 6.82564e-04
I0513 11:06:14.688876 22485033404224 run_lib.py:167] step: 270100, eval_loss: 7.22939e-04
I0513 11:06:38.186388 22485033404224 run_lib.py:146] step: 270150, training_loss: 6.98747e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 11:07:02.086635 22485033404224 run_lib.py:146] step: 270200, training_loss: 4.94075e-04
I0513 11:07:02.246628 22485033404224 run_lib.py:167] step: 270200, eval_loss: 5.23663e-04
I0513 11:07:25.710789 22485033404224 run_lib.py:146] step: 270250, training_loss: 6.47063e-04
I0513 11:07:49.181724 22485033404224 run_lib.py:146] step: 270300, training_loss: 5.19002e-04
I0513 11:07:49.340423 22485033404224 run_lib.py:167] step: 270300, eval_loss: 6.49972e-04
I0513 11:08:13.509418 22485033404224 run_lib.py:146] step: 270350, training_loss: 8.07384e-04
I0513 11:08:37.022762 22485033404224 run_lib.py:146] step: 270400, training_loss: 5.62741e-04
I0513 11:08:37.183910 22485033404224 run_lib.py:167] step: 270400, eval_loss: 5.29930e-04
I0513 11:09:00.673891 22485033404224 run_lib.py:146] step: 270450, training_loss: 5.99340e-04
I0513 11:09:24.782199 22485033404224 run_lib.py:146] step: 270500, training_loss: 5.16031e-04
I0513 11:09:24.941163 22485033404224 run_lib.py:167] step: 270500, eval_loss: 7.37191e-04
I0513 11:09:48.430843 22485033404224 run_lib.py:146] step: 270550, training_loss: 5.59293e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 11:10:12.016730 22485033404224 run_lib.py:146] step: 270600, training_loss: 5.65375e-04
I0513 11:10:12.178390 22485033404224 run_lib.py:167] step: 270600, eval_loss: 6.59470e-04
I0513 11:10:36.032292 22485033404224 run_lib.py:146] step: 270650, training_loss: 5.90581e-04
I0513 11:10:59.549513 22485033404224 run_lib.py:146] step: 270700, training_loss: 5.12273e-04
I0513 11:10:59.709383 22485033404224 run_lib.py:167] step: 270700, eval_loss: 4.63247e-04
I0513 11:11:23.212644 22485033404224 run_lib.py:146] step: 270750, training_loss: 6.48716e-04
I0513 11:11:47.027313 22485033404224 run_lib.py:146] step: 270800, training_loss: 6.71890e-04
I0513 11:11:47.186955 22485033404224 run_lib.py:167] step: 270800, eval_loss: 7.17914e-04
I0513 11:12:10.992223 22485033404224 run_lib.py:146] step: 270850, training_loss: 6.36978e-04
I0513 11:12:34.518926 22485033404224 run_lib.py:146] step: 270900, training_loss: 5.91534e-04
I0513 11:12:34.679965 22485033404224 run_lib.py:167] step: 270900, eval_loss: 5.73413e-04
I0513 11:12:58.251269 22485033404224 run_lib.py:146] step: 270950, training_loss: 5.12946e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 11:13:22.242294 22485033404224 run_lib.py:146] step: 271000, training_loss: 7.07709e-04
I0513 11:13:22.404345 22485033404224 run_lib.py:167] step: 271000, eval_loss: 5.54846e-04
I0513 11:13:45.988165 22485033404224 run_lib.py:146] step: 271050, training_loss: 5.69185e-04
I0513 11:14:09.562699 22485033404224 run_lib.py:146] step: 271100, training_loss: 5.95822e-04
I0513 11:14:09.722679 22485033404224 run_lib.py:167] step: 271100, eval_loss: 4.72369e-04
I0513 11:14:33.713484 22485033404224 run_lib.py:146] step: 271150, training_loss: 5.58878e-04
I0513 11:14:57.304793 22485033404224 run_lib.py:146] step: 271200, training_loss: 6.66869e-04
I0513 11:14:57.465022 22485033404224 run_lib.py:167] step: 271200, eval_loss: 5.52990e-04
I0513 11:15:21.051461 22485033404224 run_lib.py:146] step: 271250, training_loss: 6.85830e-04
I0513 11:15:44.965950 22485033404224 run_lib.py:146] step: 271300, training_loss: 5.71275e-04
I0513 11:15:45.126839 22485033404224 run_lib.py:167] step: 271300, eval_loss: 5.80022e-04
I0513 11:16:08.707527 22485033404224 run_lib.py:146] step: 271350, training_loss: 5.62286e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 11:16:32.361621 22485033404224 run_lib.py:146] step: 271400, training_loss: 7.64351e-04
I0513 11:16:32.524727 22485033404224 run_lib.py:167] step: 271400, eval_loss: 5.94387e-04
I0513 11:16:56.811241 22485033404224 run_lib.py:146] step: 271450, training_loss: 7.27713e-04
I0513 11:17:20.416189 22485033404224 run_lib.py:146] step: 271500, training_loss: 5.66584e-04
I0513 11:17:20.577144 22485033404224 run_lib.py:167] step: 271500, eval_loss: 3.54005e-04
I0513 11:17:44.138758 22485033404224 run_lib.py:146] step: 271550, training_loss: 4.75595e-04
I0513 11:18:08.345462 22485033404224 run_lib.py:146] step: 271600, training_loss: 7.94764e-04
I0513 11:18:08.504967 22485033404224 run_lib.py:167] step: 271600, eval_loss: 5.94122e-04
I0513 11:18:32.099781 22485033404224 run_lib.py:146] step: 271650, training_loss: 5.02135e-04
I0513 11:18:55.685766 22485033404224 run_lib.py:146] step: 271700, training_loss: 7.33981e-04
I0513 11:18:55.845393 22485033404224 run_lib.py:167] step: 271700, eval_loss: 4.84699e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 11:19:19.525272 22485033404224 run_lib.py:146] step: 271750, training_loss: 7.50960e-04
I0513 11:19:43.835506 22485033404224 run_lib.py:146] step: 271800, training_loss: 5.14127e-04
I0513 11:19:43.996656 22485033404224 run_lib.py:167] step: 271800, eval_loss: 7.80630e-04
I0513 11:20:07.539891 22485033404224 run_lib.py:146] step: 271850, training_loss: 6.47600e-04
I0513 11:20:31.096513 22485033404224 run_lib.py:146] step: 271900, training_loss: 9.51967e-04
I0513 11:20:31.256296 22485033404224 run_lib.py:167] step: 271900, eval_loss: 4.87165e-04
I0513 11:20:55.349592 22485033404224 run_lib.py:146] step: 271950, training_loss: 5.47641e-04
I0513 11:21:18.849901 22485033404224 run_lib.py:146] step: 272000, training_loss: 4.77207e-04
I0513 11:21:19.009219 22485033404224 run_lib.py:167] step: 272000, eval_loss: 6.68762e-04
I0513 11:21:42.507214 22485033404224 run_lib.py:146] step: 272050, training_loss: 4.97930e-04
I0513 11:22:06.615672 22485033404224 run_lib.py:146] step: 272100, training_loss: 4.51793e-04
I0513 11:22:06.775249 22485033404224 run_lib.py:167] step: 272100, eval_loss: 5.46035e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 11:22:30.358372 22485033404224 run_lib.py:146] step: 272150, training_loss: 5.44260e-04
I0513 11:22:53.868719 22485033404224 run_lib.py:146] step: 272200, training_loss: 5.30705e-04
I0513 11:22:54.031359 22485033404224 run_lib.py:167] step: 272200, eval_loss: 4.72346e-04
I0513 11:23:18.199959 22485033404224 run_lib.py:146] step: 272250, training_loss: 7.90257e-04
I0513 11:23:41.710658 22485033404224 run_lib.py:146] step: 272300, training_loss: 5.51605e-04
I0513 11:23:41.870345 22485033404224 run_lib.py:167] step: 272300, eval_loss: 6.66018e-04
I0513 11:24:05.379679 22485033404224 run_lib.py:146] step: 272350, training_loss: 5.70608e-04
I0513 11:24:29.473256 22485033404224 run_lib.py:146] step: 272400, training_loss: 6.11474e-04
I0513 11:24:29.631583 22485033404224 run_lib.py:167] step: 272400, eval_loss: 5.16331e-04
I0513 11:24:53.122012 22485033404224 run_lib.py:146] step: 272450, training_loss: 6.71326e-04
I0513 11:25:16.620549 22485033404224 run_lib.py:146] step: 272500, training_loss: 5.38020e-04
I0513 11:25:16.779703 22485033404224 run_lib.py:167] step: 272500, eval_loss: 9.07934e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 11:25:40.729056 22485033404224 run_lib.py:146] step: 272550, training_loss: 5.32653e-04
I0513 11:26:04.568210 22485033404224 run_lib.py:146] step: 272600, training_loss: 5.37387e-04
I0513 11:26:04.728879 22485033404224 run_lib.py:167] step: 272600, eval_loss: 6.37764e-04
I0513 11:26:28.243792 22485033404224 run_lib.py:146] step: 272650, training_loss: 6.00739e-04
I0513 11:26:51.759169 22485033404224 run_lib.py:146] step: 272700, training_loss: 5.76374e-04
I0513 11:26:51.917958 22485033404224 run_lib.py:167] step: 272700, eval_loss: 5.10535e-04
I0513 11:27:16.005139 22485033404224 run_lib.py:146] step: 272750, training_loss: 5.53674e-04
I0513 11:27:39.505047 22485033404224 run_lib.py:146] step: 272800, training_loss: 6.80935e-04
I0513 11:27:39.663732 22485033404224 run_lib.py:167] step: 272800, eval_loss: 6.37276e-04
I0513 11:28:03.184550 22485033404224 run_lib.py:146] step: 272850, training_loss: 6.49996e-04
I0513 11:28:27.362835 22485033404224 run_lib.py:146] step: 272900, training_loss: 7.17296e-04
I0513 11:28:27.523818 22485033404224 run_lib.py:167] step: 272900, eval_loss: 5.64058e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 11:28:51.146840 22485033404224 run_lib.py:146] step: 272950, training_loss: 5.80175e-04
I0513 11:29:14.677289 22485033404224 run_lib.py:146] step: 273000, training_loss: 6.89979e-04
I0513 11:29:14.838049 22485033404224 run_lib.py:167] step: 273000, eval_loss: 5.45519e-04
I0513 11:29:39.003131 22485033404224 run_lib.py:146] step: 273050, training_loss: 5.94499e-04
I0513 11:30:02.583353 22485033404224 run_lib.py:146] step: 273100, training_loss: 5.94883e-04
I0513 11:30:02.744546 22485033404224 run_lib.py:167] step: 273100, eval_loss: 6.27954e-04
I0513 11:30:26.290153 22485033404224 run_lib.py:146] step: 273150, training_loss: 6.53540e-04
I0513 11:30:50.529706 22485033404224 run_lib.py:146] step: 273200, training_loss: 4.77875e-04
I0513 11:30:50.690134 22485033404224 run_lib.py:167] step: 273200, eval_loss: 4.80828e-04
I0513 11:31:14.300715 22485033404224 run_lib.py:146] step: 273250, training_loss: 5.56035e-04
I0513 11:31:37.914702 22485033404224 run_lib.py:146] step: 273300, training_loss: 5.29199e-04
I0513 11:31:38.076277 22485033404224 run_lib.py:167] step: 273300, eval_loss: 7.07481e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 11:32:02.143988 22485033404224 run_lib.py:146] step: 273350, training_loss: 6.26311e-04
I0513 11:32:26.114275 22485033404224 run_lib.py:146] step: 273400, training_loss: 6.37658e-04
I0513 11:32:26.276295 22485033404224 run_lib.py:167] step: 273400, eval_loss: 5.99188e-04
I0513 11:32:49.876695 22485033404224 run_lib.py:146] step: 273450, training_loss: 7.51152e-04
I0513 11:33:13.463316 22485033404224 run_lib.py:146] step: 273500, training_loss: 6.10762e-04
I0513 11:33:13.624183 22485033404224 run_lib.py:167] step: 273500, eval_loss: 6.71233e-04
I0513 11:33:37.830415 22485033404224 run_lib.py:146] step: 273550, training_loss: 6.24845e-04
I0513 11:34:01.434862 22485033404224 run_lib.py:146] step: 273600, training_loss: 5.35086e-04
I0513 11:34:01.595523 22485033404224 run_lib.py:167] step: 273600, eval_loss: 5.93613e-04
I0513 11:34:25.193252 22485033404224 run_lib.py:146] step: 273650, training_loss: 7.02734e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 11:34:49.516158 22485033404224 run_lib.py:146] step: 273700, training_loss: 5.52029e-04
I0513 11:34:49.677920 22485033404224 run_lib.py:167] step: 273700, eval_loss: 7.02648e-04
I0513 11:35:13.297060 22485033404224 run_lib.py:146] step: 273750, training_loss: 7.30117e-04
I0513 11:35:36.909866 22485033404224 run_lib.py:146] step: 273800, training_loss: 6.36449e-04
I0513 11:35:37.069955 22485033404224 run_lib.py:167] step: 273800, eval_loss: 6.02192e-04
I0513 11:36:01.361182 22485033404224 run_lib.py:146] step: 273850, training_loss: 6.44734e-04
I0513 11:36:24.947695 22485033404224 run_lib.py:146] step: 273900, training_loss: 7.15134e-04
I0513 11:36:25.107618 22485033404224 run_lib.py:167] step: 273900, eval_loss: 4.32374e-04
I0513 11:36:48.694115 22485033404224 run_lib.py:146] step: 273950, training_loss: 6.46074e-04
I0513 11:37:12.961406 22485033404224 run_lib.py:146] step: 274000, training_loss: 6.80289e-04
I0513 11:37:13.121800 22485033404224 run_lib.py:167] step: 274000, eval_loss: 7.29604e-04
I0513 11:37:36.738675 22485033404224 run_lib.py:146] step: 274050, training_loss: 7.77911e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 11:38:00.389994 22485033404224 run_lib.py:146] step: 274100, training_loss: 4.73484e-04
I0513 11:38:00.550747 22485033404224 run_lib.py:167] step: 274100, eval_loss: 5.40945e-04
I0513 11:38:24.764936 22485033404224 run_lib.py:146] step: 274150, training_loss: 6.56366e-04
I0513 11:38:48.322145 22485033404224 run_lib.py:146] step: 274200, training_loss: 6.70111e-04
I0513 11:38:48.482221 22485033404224 run_lib.py:167] step: 274200, eval_loss: 6.49585e-04
I0513 11:39:12.030829 22485033404224 run_lib.py:146] step: 274250, training_loss: 4.34653e-04
I0513 11:39:35.883103 22485033404224 run_lib.py:146] step: 274300, training_loss: 4.02504e-04
I0513 11:39:36.041743 22485033404224 run_lib.py:167] step: 274300, eval_loss: 4.98083e-04
I0513 11:39:59.863856 22485033404224 run_lib.py:146] step: 274350, training_loss: 5.73279e-04
I0513 11:40:23.426526 22485033404224 run_lib.py:146] step: 274400, training_loss: 7.61080e-04
I0513 11:40:23.586198 22485033404224 run_lib.py:167] step: 274400, eval_loss: 6.19227e-04
I0513 11:40:47.129695 22485033404224 run_lib.py:146] step: 274450, training_loss: 5.78299e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 11:41:11.353902 22485033404224 run_lib.py:146] step: 274500, training_loss: 5.17186e-04
I0513 11:41:11.516428 22485033404224 run_lib.py:167] step: 274500, eval_loss: 7.56698e-04
I0513 11:41:35.057362 22485033404224 run_lib.py:146] step: 274550, training_loss: 6.75127e-04
I0513 11:41:58.587418 22485033404224 run_lib.py:146] step: 274600, training_loss: 4.81013e-04
I0513 11:41:58.746747 22485033404224 run_lib.py:167] step: 274600, eval_loss: 6.93739e-04
I0513 11:42:22.938843 22485033404224 run_lib.py:146] step: 274650, training_loss: 4.91649e-04
I0513 11:42:46.477220 22485033404224 run_lib.py:146] step: 274700, training_loss: 6.08469e-04
I0513 11:42:46.637046 22485033404224 run_lib.py:167] step: 274700, eval_loss: 5.82699e-04
I0513 11:43:10.160891 22485033404224 run_lib.py:146] step: 274750, training_loss: 5.84217e-04
I0513 11:43:34.303206 22485033404224 run_lib.py:146] step: 274800, training_loss: 5.54098e-04
I0513 11:43:34.462872 22485033404224 run_lib.py:167] step: 274800, eval_loss: 5.09295e-04
I0513 11:43:57.995666 22485033404224 run_lib.py:146] step: 274850, training_loss: 6.90996e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 11:44:21.615332 22485033404224 run_lib.py:146] step: 274900, training_loss: 5.83828e-04
I0513 11:44:21.778315 22485033404224 run_lib.py:167] step: 274900, eval_loss: 6.52579e-04
I0513 11:44:45.964361 22485033404224 run_lib.py:146] step: 274950, training_loss: 6.52706e-04
I0513 11:45:09.512250 22485033404224 run_lib.py:146] step: 275000, training_loss: 5.54125e-04
I0513 11:45:09.670956 22485033404224 run_lib.py:167] step: 275000, eval_loss: 6.29693e-04
I0513 11:45:33.222747 22485033404224 run_lib.py:146] step: 275050, training_loss: 7.00428e-04
I0513 11:45:57.074246 22485033404224 run_lib.py:146] step: 275100, training_loss: 4.74942e-04
I0513 11:45:57.233106 22485033404224 run_lib.py:167] step: 275100, eval_loss: 4.90064e-04
I0513 11:46:21.070821 22485033404224 run_lib.py:146] step: 275150, training_loss: 6.51118e-04
I0513 11:46:44.608152 22485033404224 run_lib.py:146] step: 275200, training_loss: 5.16515e-04
I0513 11:46:44.767971 22485033404224 run_lib.py:167] step: 275200, eval_loss: 7.00779e-04
I0513 11:47:08.310249 22485033404224 run_lib.py:146] step: 275250, training_loss: 6.19906e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 11:47:32.503219 22485033404224 run_lib.py:146] step: 275300, training_loss: 7.53636e-04
I0513 11:47:32.664332 22485033404224 run_lib.py:167] step: 275300, eval_loss: 6.64263e-04
I0513 11:47:56.196953 22485033404224 run_lib.py:146] step: 275350, training_loss: 5.74920e-04
I0513 11:48:19.772666 22485033404224 run_lib.py:146] step: 275400, training_loss: 5.85678e-04
I0513 11:48:19.933352 22485033404224 run_lib.py:167] step: 275400, eval_loss: 6.18432e-04
I0513 11:48:44.232692 22485033404224 run_lib.py:146] step: 275450, training_loss: 6.84766e-04
I0513 11:49:07.842469 22485033404224 run_lib.py:146] step: 275500, training_loss: 5.30482e-04
I0513 11:49:08.004859 22485033404224 run_lib.py:167] step: 275500, eval_loss: 6.23493e-04
I0513 11:49:31.611537 22485033404224 run_lib.py:146] step: 275550, training_loss: 6.58514e-04
I0513 11:49:55.828621 22485033404224 run_lib.py:146] step: 275600, training_loss: 7.73324e-04
I0513 11:49:55.989975 22485033404224 run_lib.py:167] step: 275600, eval_loss: 5.69700e-04
I0513 11:50:19.591232 22485033404224 run_lib.py:146] step: 275650, training_loss: 5.97666e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 11:50:43.417436 22485033404224 run_lib.py:146] step: 275700, training_loss: 6.65351e-04
I0513 11:50:43.582031 22485033404224 run_lib.py:167] step: 275700, eval_loss: 6.00203e-04
I0513 11:51:08.289792 22485033404224 run_lib.py:146] step: 275750, training_loss: 5.55000e-04
I0513 11:51:32.059858 22485033404224 run_lib.py:146] step: 275800, training_loss: 4.03429e-04
I0513 11:51:32.222434 22485033404224 run_lib.py:167] step: 275800, eval_loss: 6.68729e-04
I0513 11:51:56.013998 22485033404224 run_lib.py:146] step: 275850, training_loss: 5.54001e-04
I0513 11:52:20.647689 22485033404224 run_lib.py:146] step: 275900, training_loss: 7.11999e-04
I0513 11:52:20.809607 22485033404224 run_lib.py:167] step: 275900, eval_loss: 6.42170e-04
I0513 11:52:44.548341 22485033404224 run_lib.py:146] step: 275950, training_loss: 7.30527e-04
I0513 11:53:08.227915 22485033404224 run_lib.py:146] step: 276000, training_loss: 6.35807e-04
I0513 11:53:08.389299 22485033404224 run_lib.py:167] step: 276000, eval_loss: 4.67265e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 11:53:32.445024 22485033404224 run_lib.py:146] step: 276050, training_loss: 4.95473e-04
I0513 11:53:56.454274 22485033404224 run_lib.py:146] step: 276100, training_loss: 6.47160e-04
I0513 11:53:56.616067 22485033404224 run_lib.py:167] step: 276100, eval_loss: 5.94781e-04
I0513 11:54:20.236965 22485033404224 run_lib.py:146] step: 276150, training_loss: 6.52571e-04
I0513 11:54:43.861986 22485033404224 run_lib.py:146] step: 276200, training_loss: 5.08239e-04
I0513 11:54:44.023201 22485033404224 run_lib.py:167] step: 276200, eval_loss: 6.13247e-04
I0513 11:55:08.231061 22485033404224 run_lib.py:146] step: 276250, training_loss: 5.52723e-04
I0513 11:55:31.781726 22485033404224 run_lib.py:146] step: 276300, training_loss: 6.53111e-04
I0513 11:55:31.941711 22485033404224 run_lib.py:167] step: 276300, eval_loss: 5.26834e-04
I0513 11:55:55.515268 22485033404224 run_lib.py:146] step: 276350, training_loss: 5.57018e-04
I0513 11:56:19.637789 22485033404224 run_lib.py:146] step: 276400, training_loss: 5.82685e-04
I0513 11:56:19.722963 22485033404224 run_lib.py:167] step: 276400, eval_loss: 8.26794e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 11:56:43.322290 22485033404224 run_lib.py:146] step: 276450, training_loss: 4.58663e-04
I0513 11:57:06.870583 22485033404224 run_lib.py:146] step: 276500, training_loss: 6.58451e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 11:57:07.215669 22485033404224 run_lib.py:167] step: 276500, eval_loss: 5.59233e-04
I0513 11:57:31.445493 22485033404224 run_lib.py:146] step: 276550, training_loss: 5.53007e-04
I0513 11:57:54.992747 22485033404224 run_lib.py:146] step: 276600, training_loss: 4.72175e-04
I0513 11:57:55.152727 22485033404224 run_lib.py:167] step: 276600, eval_loss: 6.53710e-04
I0513 11:58:18.691146 22485033404224 run_lib.py:146] step: 276650, training_loss: 5.75576e-04
I0513 11:58:42.796908 22485033404224 run_lib.py:146] step: 276700, training_loss: 8.17298e-04
I0513 11:58:42.955811 22485033404224 run_lib.py:167] step: 276700, eval_loss: 5.45126e-04
I0513 11:59:06.482975 22485033404224 run_lib.py:146] step: 276750, training_loss: 7.80222e-04
I0513 11:59:30.013464 22485033404224 run_lib.py:146] step: 276800, training_loss: 6.47300e-04
I0513 11:59:30.172903 22485033404224 run_lib.py:167] step: 276800, eval_loss: 4.38212e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 11:59:54.134171 22485033404224 run_lib.py:146] step: 276850, training_loss: 5.75528e-04
I0513 12:00:18.032062 22485033404224 run_lib.py:146] step: 276900, training_loss: 5.17079e-04
I0513 12:00:18.194382 22485033404224 run_lib.py:167] step: 276900, eval_loss: 7.53478e-04
I0513 12:00:41.726767 22485033404224 run_lib.py:146] step: 276950, training_loss: 7.24377e-04
I0513 12:01:05.270928 22485033404224 run_lib.py:146] step: 277000, training_loss: 5.81630e-04
I0513 12:01:05.430640 22485033404224 run_lib.py:167] step: 277000, eval_loss: 7.10813e-04
I0513 12:01:29.568916 22485033404224 run_lib.py:146] step: 277050, training_loss: 6.06962e-04
I0513 12:01:53.110970 22485033404224 run_lib.py:146] step: 277100, training_loss: 6.53127e-04
I0513 12:01:53.269967 22485033404224 run_lib.py:167] step: 277100, eval_loss: 6.66420e-04
I0513 12:02:16.796985 22485033404224 run_lib.py:146] step: 277150, training_loss: 7.70516e-04
I0513 12:02:40.955703 22485033404224 run_lib.py:146] step: 277200, training_loss: 5.67819e-04
I0513 12:02:41.115714 22485033404224 run_lib.py:167] step: 277200, eval_loss: 6.77381e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 12:03:04.740250 22485033404224 run_lib.py:146] step: 277250, training_loss: 6.71911e-04
I0513 12:03:28.269208 22485033404224 run_lib.py:146] step: 277300, training_loss: 6.05457e-04
I0513 12:03:28.431668 22485033404224 run_lib.py:167] step: 277300, eval_loss: 4.35895e-04
I0513 12:03:52.601706 22485033404224 run_lib.py:146] step: 277350, training_loss: 6.71944e-04
I0513 12:04:16.128643 22485033404224 run_lib.py:146] step: 277400, training_loss: 7.08291e-04
I0513 12:04:16.287369 22485033404224 run_lib.py:167] step: 277400, eval_loss: 5.32404e-04
I0513 12:04:39.835455 22485033404224 run_lib.py:146] step: 277450, training_loss: 6.03751e-04
I0513 12:05:03.970806 22485033404224 run_lib.py:146] step: 277500, training_loss: 6.83685e-04
I0513 12:05:04.132526 22485033404224 run_lib.py:167] step: 277500, eval_loss: 7.23087e-04
I0513 12:05:27.656043 22485033404224 run_lib.py:146] step: 277550, training_loss: 6.39330e-04
I0513 12:05:51.238766 22485033404224 run_lib.py:146] step: 277600, training_loss: 7.37057e-04
I0513 12:05:51.399178 22485033404224 run_lib.py:167] step: 277600, eval_loss: 4.84066e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 12:06:15.799320 22485033404224 run_lib.py:146] step: 277650, training_loss: 7.70051e-04
I0513 12:06:39.408782 22485033404224 run_lib.py:146] step: 277700, training_loss: 7.45022e-04
I0513 12:06:39.571354 22485033404224 run_lib.py:167] step: 277700, eval_loss: 5.91246e-04
I0513 12:07:03.169094 22485033404224 run_lib.py:146] step: 277750, training_loss: 7.51164e-04
I0513 12:07:26.765513 22485033404224 run_lib.py:146] step: 277800, training_loss: 6.65569e-04
I0513 12:07:26.926538 22485033404224 run_lib.py:167] step: 277800, eval_loss: 8.24468e-04
I0513 12:07:51.127269 22485033404224 run_lib.py:146] step: 277850, training_loss: 5.41713e-04
I0513 12:08:14.746375 22485033404224 run_lib.py:146] step: 277900, training_loss: 6.29201e-04
I0513 12:08:14.906471 22485033404224 run_lib.py:167] step: 277900, eval_loss: 7.46373e-04
I0513 12:08:38.498953 22485033404224 run_lib.py:146] step: 277950, training_loss: 6.35147e-04
I0513 12:09:02.557811 22485033404224 run_lib.py:146] step: 278000, training_loss: 4.85603e-04
I0513 12:09:02.718744 22485033404224 run_lib.py:167] step: 278000, eval_loss: 5.95647e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 12:09:26.549620 22485033404224 run_lib.py:146] step: 278050, training_loss: 6.11610e-04
I0513 12:09:50.186917 22485033404224 run_lib.py:146] step: 278100, training_loss: 7.05873e-04
I0513 12:09:50.348627 22485033404224 run_lib.py:167] step: 278100, eval_loss: 5.87720e-04
I0513 12:10:14.741429 22485033404224 run_lib.py:146] step: 278150, training_loss: 4.62283e-04
I0513 12:10:38.362006 22485033404224 run_lib.py:146] step: 278200, training_loss: 5.22652e-04
I0513 12:10:38.523523 22485033404224 run_lib.py:167] step: 278200, eval_loss: 4.90041e-04
I0513 12:11:02.124571 22485033404224 run_lib.py:146] step: 278250, training_loss: 7.24737e-04
I0513 12:11:26.345345 22485033404224 run_lib.py:146] step: 278300, training_loss: 7.07477e-04
I0513 12:11:26.506224 22485033404224 run_lib.py:167] step: 278300, eval_loss: 6.09397e-04
I0513 12:11:50.107288 22485033404224 run_lib.py:146] step: 278350, training_loss: 6.17199e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 12:12:13.760484 22485033404224 run_lib.py:146] step: 278400, training_loss: 6.15535e-04
I0513 12:12:13.923836 22485033404224 run_lib.py:167] step: 278400, eval_loss: 6.18478e-04
I0513 12:12:38.209652 22485033404224 run_lib.py:146] step: 278450, training_loss: 5.48215e-04
I0513 12:13:01.838505 22485033404224 run_lib.py:146] step: 278500, training_loss: 6.28569e-04
I0513 12:13:01.999286 22485033404224 run_lib.py:167] step: 278500, eval_loss: 4.48590e-04
I0513 12:13:25.593666 22485033404224 run_lib.py:146] step: 278550, training_loss: 6.87608e-04
I0513 12:13:49.141960 22485033404224 run_lib.py:146] step: 278600, training_loss: 7.51068e-04
I0513 12:13:49.301985 22485033404224 run_lib.py:167] step: 278600, eval_loss: 5.23990e-04
I0513 12:14:13.410743 22485033404224 run_lib.py:146] step: 278650, training_loss: 7.58287e-04
I0513 12:14:36.966900 22485033404224 run_lib.py:146] step: 278700, training_loss: 5.92052e-04
I0513 12:14:37.125914 22485033404224 run_lib.py:167] step: 278700, eval_loss: 5.29778e-04
I0513 12:15:00.669044 22485033404224 run_lib.py:146] step: 278750, training_loss: 5.07984e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 12:15:24.868737 22485033404224 run_lib.py:146] step: 278800, training_loss: 7.01097e-04
I0513 12:15:25.029105 22485033404224 run_lib.py:167] step: 278800, eval_loss: 5.68855e-04
I0513 12:15:48.560045 22485033404224 run_lib.py:146] step: 278850, training_loss: 7.00561e-04
I0513 12:16:12.087018 22485033404224 run_lib.py:146] step: 278900, training_loss: 6.69163e-04
I0513 12:16:12.247288 22485033404224 run_lib.py:167] step: 278900, eval_loss: 8.24368e-04
I0513 12:16:36.463944 22485033404224 run_lib.py:146] step: 278950, training_loss: 7.36576e-04
I0513 12:17:00.002294 22485033404224 run_lib.py:146] step: 279000, training_loss: 7.56948e-04
I0513 12:17:00.163635 22485033404224 run_lib.py:167] step: 279000, eval_loss: 4.02557e-04
I0513 12:17:23.676265 22485033404224 run_lib.py:146] step: 279050, training_loss: 6.74700e-04
I0513 12:17:47.834847 22485033404224 run_lib.py:146] step: 279100, training_loss: 4.95292e-04
I0513 12:17:47.994519 22485033404224 run_lib.py:167] step: 279100, eval_loss: 6.67444e-04
I0513 12:18:11.507817 22485033404224 run_lib.py:146] step: 279150, training_loss: 7.98594e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 12:18:35.121602 22485033404224 run_lib.py:146] step: 279200, training_loss: 7.63668e-04
I0513 12:18:35.282959 22485033404224 run_lib.py:167] step: 279200, eval_loss: 8.11180e-04
I0513 12:18:59.537513 22485033404224 run_lib.py:146] step: 279250, training_loss: 5.02425e-04
I0513 12:19:23.082978 22485033404224 run_lib.py:146] step: 279300, training_loss: 6.36765e-04
I0513 12:19:23.241664 22485033404224 run_lib.py:167] step: 279300, eval_loss: 6.50332e-04
I0513 12:19:46.762811 22485033404224 run_lib.py:146] step: 279350, training_loss: 4.31070e-04
I0513 12:20:10.576513 22485033404224 run_lib.py:146] step: 279400, training_loss: 5.61933e-04
I0513 12:20:10.735739 22485033404224 run_lib.py:167] step: 279400, eval_loss: 5.85494e-04
I0513 12:20:34.565798 22485033404224 run_lib.py:146] step: 279450, training_loss: 6.00794e-04
I0513 12:20:58.110549 22485033404224 run_lib.py:146] step: 279500, training_loss: 5.90190e-04
I0513 12:20:58.269157 22485033404224 run_lib.py:167] step: 279500, eval_loss: 9.59223e-04
I0513 12:21:21.823457 22485033404224 run_lib.py:146] step: 279550, training_loss: 5.20405e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 12:21:46.029784 22485033404224 run_lib.py:146] step: 279600, training_loss: 6.79402e-04
I0513 12:21:46.191649 22485033404224 run_lib.py:167] step: 279600, eval_loss: 5.50871e-04
I0513 12:22:09.739016 22485033404224 run_lib.py:146] step: 279650, training_loss: 5.03312e-04
I0513 12:22:33.280584 22485033404224 run_lib.py:146] step: 279700, training_loss: 4.88321e-04
I0513 12:22:33.441809 22485033404224 run_lib.py:167] step: 279700, eval_loss: 5.92311e-04
I0513 12:22:57.658641 22485033404224 run_lib.py:146] step: 279750, training_loss: 4.21857e-04
I0513 12:23:21.199876 22485033404224 run_lib.py:146] step: 279800, training_loss: 5.40697e-04
I0513 12:23:21.360677 22485033404224 run_lib.py:167] step: 279800, eval_loss: 6.42744e-04
I0513 12:23:44.918889 22485033404224 run_lib.py:146] step: 279850, training_loss: 4.70975e-04
I0513 12:24:09.124509 22485033404224 run_lib.py:146] step: 279900, training_loss: 6.61180e-04
I0513 12:24:09.285127 22485033404224 run_lib.py:167] step: 279900, eval_loss: 5.95230e-04
I0513 12:24:32.929040 22485033404224 run_lib.py:146] step: 279950, training_loss: 6.54071e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 12:24:56.659574 22485033404224 run_lib.py:146] step: 280000, training_loss: 6.82757e-04
I0513 12:24:58.408163 22485033404224 run_lib.py:167] step: 280000, eval_loss: 6.13964e-04
I0513 12:25:24.341081 22485033404224 run_lib.py:146] step: 280050, training_loss: 6.09008e-04
I0513 12:25:47.957255 22485033404224 run_lib.py:146] step: 280100, training_loss: 5.67690e-04
I0513 12:25:48.117711 22485033404224 run_lib.py:167] step: 280100, eval_loss: 6.97256e-04
I0513 12:26:11.738492 22485033404224 run_lib.py:146] step: 280150, training_loss: 4.63830e-04
I0513 12:26:35.917609 22485033404224 run_lib.py:146] step: 280200, training_loss: 4.73904e-04
I0513 12:26:36.077968 22485033404224 run_lib.py:167] step: 280200, eval_loss: 6.81833e-04
I0513 12:26:59.667492 22485033404224 run_lib.py:146] step: 280250, training_loss: 5.85118e-04
I0513 12:27:23.234632 22485033404224 run_lib.py:146] step: 280300, training_loss: 5.96668e-04
I0513 12:27:23.395590 22485033404224 run_lib.py:167] step: 280300, eval_loss: 4.94117e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 12:27:47.367432 22485033404224 run_lib.py:146] step: 280350, training_loss: 6.49052e-04
I0513 12:28:11.575829 22485033404224 run_lib.py:146] step: 280400, training_loss: 7.21366e-04
I0513 12:28:11.738216 22485033404224 run_lib.py:167] step: 280400, eval_loss: 6.36383e-04
I0513 12:28:35.358880 22485033404224 run_lib.py:146] step: 280450, training_loss: 5.09918e-04
I0513 12:28:59.408448 22485033404224 run_lib.py:146] step: 280500, training_loss: 4.35383e-04
I0513 12:28:59.569337 22485033404224 run_lib.py:167] step: 280500, eval_loss: 6.84580e-04
I0513 12:29:23.583886 22485033404224 run_lib.py:146] step: 280550, training_loss: 6.31970e-04
I0513 12:29:47.176028 22485033404224 run_lib.py:146] step: 280600, training_loss: 5.39770e-04
I0513 12:29:47.336677 22485033404224 run_lib.py:167] step: 280600, eval_loss: 6.07247e-04
I0513 12:30:11.343598 22485033404224 run_lib.py:146] step: 280650, training_loss: 5.46759e-04
I0513 12:30:35.283069 22485033404224 run_lib.py:146] step: 280700, training_loss: 6.37786e-04
I0513 12:30:35.444008 22485033404224 run_lib.py:167] step: 280700, eval_loss: 6.06784e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 12:30:59.147597 22485033404224 run_lib.py:146] step: 280750, training_loss: 7.83014e-04
I0513 12:31:23.206350 22485033404224 run_lib.py:146] step: 280800, training_loss: 5.68585e-04
I0513 12:31:23.367048 22485033404224 run_lib.py:167] step: 280800, eval_loss: 6.25669e-04
I0513 12:31:47.233311 22485033404224 run_lib.py:146] step: 280850, training_loss: 3.86267e-04
I0513 12:32:10.804112 22485033404224 run_lib.py:146] step: 280900, training_loss: 4.78479e-04
I0513 12:32:10.963250 22485033404224 run_lib.py:167] step: 280900, eval_loss: 5.70149e-04
I0513 12:32:34.512640 22485033404224 run_lib.py:146] step: 280950, training_loss: 4.50628e-04
I0513 12:32:58.657212 22485033404224 run_lib.py:146] step: 281000, training_loss: 5.85615e-04
I0513 12:32:58.816679 22485033404224 run_lib.py:167] step: 281000, eval_loss: 6.65626e-04
I0513 12:33:22.343020 22485033404224 run_lib.py:146] step: 281050, training_loss: 7.07694e-04
I0513 12:33:45.880936 22485033404224 run_lib.py:146] step: 281100, training_loss: 7.61366e-04
I0513 12:33:46.040565 22485033404224 run_lib.py:167] step: 281100, eval_loss: 5.74625e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 12:34:10.282890 22485033404224 run_lib.py:146] step: 281150, training_loss: 5.99464e-04
I0513 12:34:33.784536 22485033404224 run_lib.py:146] step: 281200, training_loss: 5.28519e-04
I0513 12:34:33.945392 22485033404224 run_lib.py:167] step: 281200, eval_loss: 5.52422e-04
I0513 12:34:57.465578 22485033404224 run_lib.py:146] step: 281250, training_loss: 6.49526e-04
I0513 12:35:21.347075 22485033404224 run_lib.py:146] step: 281300, training_loss: 7.78737e-04
I0513 12:35:21.507629 22485033404224 run_lib.py:167] step: 281300, eval_loss: 4.78446e-04
I0513 12:35:45.340578 22485033404224 run_lib.py:146] step: 281350, training_loss: 6.05942e-04
I0513 12:36:08.887790 22485033404224 run_lib.py:146] step: 281400, training_loss: 6.48042e-04
I0513 12:36:09.047209 22485033404224 run_lib.py:167] step: 281400, eval_loss: 7.09460e-04
I0513 12:36:32.898829 22485033404224 run_lib.py:146] step: 281450, training_loss: 7.08536e-04
I0513 12:36:56.731816 22485033404224 run_lib.py:146] step: 281500, training_loss: 8.72901e-04
I0513 12:36:56.891170 22485033404224 run_lib.py:167] step: 281500, eval_loss: 6.18979e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 12:37:20.500151 22485033404224 run_lib.py:146] step: 281550, training_loss: 6.09667e-04
I0513 12:37:44.350594 22485033404224 run_lib.py:146] step: 281600, training_loss: 5.85988e-04
I0513 12:37:44.510918 22485033404224 run_lib.py:167] step: 281600, eval_loss: 7.87519e-04
I0513 12:38:08.408806 22485033404224 run_lib.py:146] step: 281650, training_loss: 5.37567e-04
I0513 12:38:31.929189 22485033404224 run_lib.py:146] step: 281700, training_loss: 6.35815e-04
I0513 12:38:32.088684 22485033404224 run_lib.py:167] step: 281700, eval_loss: 6.23201e-04
I0513 12:38:55.897155 22485033404224 run_lib.py:146] step: 281750, training_loss: 6.13275e-04
I0513 12:39:19.743666 22485033404224 run_lib.py:146] step: 281800, training_loss: 7.13256e-04
I0513 12:39:19.902794 22485033404224 run_lib.py:167] step: 281800, eval_loss: 5.79655e-04
I0513 12:39:43.437090 22485033404224 run_lib.py:146] step: 281850, training_loss: 6.43080e-04
I0513 12:40:06.962943 22485033404224 run_lib.py:146] step: 281900, training_loss: 7.59531e-04
I0513 12:40:07.122117 22485033404224 run_lib.py:167] step: 281900, eval_loss: 5.24618e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 12:40:31.324947 22485033404224 run_lib.py:146] step: 281950, training_loss: 6.45415e-04
I0513 12:40:54.851438 22485033404224 run_lib.py:146] step: 282000, training_loss: 6.47145e-04
I0513 12:40:55.011698 22485033404224 run_lib.py:167] step: 282000, eval_loss: 5.91476e-04
I0513 12:41:18.559753 22485033404224 run_lib.py:146] step: 282050, training_loss: 5.79028e-04
I0513 12:41:42.421961 22485033404224 run_lib.py:146] step: 282100, training_loss: 5.58227e-04
I0513 12:41:42.582405 22485033404224 run_lib.py:167] step: 282100, eval_loss: 5.79576e-04
I0513 12:42:06.415922 22485033404224 run_lib.py:146] step: 282150, training_loss: 6.73305e-04
I0513 12:42:30.014170 22485033404224 run_lib.py:146] step: 282200, training_loss: 6.60433e-04
I0513 12:42:30.174745 22485033404224 run_lib.py:167] step: 282200, eval_loss: 5.21328e-04
I0513 12:42:54.101941 22485033404224 run_lib.py:146] step: 282250, training_loss: 6.72757e-04
I0513 12:43:18.024682 22485033404224 run_lib.py:146] step: 282300, training_loss: 7.35067e-04
I0513 12:43:18.186851 22485033404224 run_lib.py:167] step: 282300, eval_loss: 5.94989e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 12:43:41.895544 22485033404224 run_lib.py:146] step: 282350, training_loss: 5.14148e-04
I0513 12:44:05.864614 22485033404224 run_lib.py:146] step: 282400, training_loss: 5.66759e-04
I0513 12:44:06.026582 22485033404224 run_lib.py:167] step: 282400, eval_loss: 7.60834e-04
I0513 12:44:29.987939 22485033404224 run_lib.py:146] step: 282450, training_loss: 6.32193e-04
I0513 12:44:53.587214 22485033404224 run_lib.py:146] step: 282500, training_loss: 6.18199e-04
I0513 12:44:53.747904 22485033404224 run_lib.py:167] step: 282500, eval_loss: 8.16717e-04
I0513 12:45:17.613874 22485033404224 run_lib.py:146] step: 282550, training_loss: 5.64844e-04
I0513 12:45:41.521626 22485033404224 run_lib.py:146] step: 282600, training_loss: 4.58621e-04
I0513 12:45:41.682522 22485033404224 run_lib.py:167] step: 282600, eval_loss: 5.16153e-04
I0513 12:46:05.272432 22485033404224 run_lib.py:146] step: 282650, training_loss: 5.71109e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 12:46:28.958326 22485033404224 run_lib.py:146] step: 282700, training_loss: 5.05764e-04
I0513 12:46:29.121663 22485033404224 run_lib.py:167] step: 282700, eval_loss: 7.89759e-04
I0513 12:46:53.452960 22485033404224 run_lib.py:146] step: 282750, training_loss: 5.65992e-04
I0513 12:47:17.072637 22485033404224 run_lib.py:146] step: 282800, training_loss: 6.08571e-04
I0513 12:47:17.233147 22485033404224 run_lib.py:167] step: 282800, eval_loss: 7.03471e-04
I0513 12:47:40.833011 22485033404224 run_lib.py:146] step: 282850, training_loss: 5.83803e-04
I0513 12:48:04.730080 22485033404224 run_lib.py:146] step: 282900, training_loss: 6.19915e-04
I0513 12:48:04.890645 22485033404224 run_lib.py:167] step: 282900, eval_loss: 5.57161e-04
I0513 12:48:28.771754 22485033404224 run_lib.py:146] step: 282950, training_loss: 5.96272e-04
I0513 12:48:52.404859 22485033404224 run_lib.py:146] step: 283000, training_loss: 7.66463e-04
I0513 12:48:52.565486 22485033404224 run_lib.py:167] step: 283000, eval_loss: 8.49224e-04
I0513 12:49:16.435387 22485033404224 run_lib.py:146] step: 283050, training_loss: 7.20419e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 12:49:40.350918 22485033404224 run_lib.py:146] step: 283100, training_loss: 5.97833e-04
I0513 12:49:40.513535 22485033404224 run_lib.py:167] step: 283100, eval_loss: 4.88754e-04
I0513 12:50:04.078106 22485033404224 run_lib.py:146] step: 283150, training_loss: 5.84102e-04
I0513 12:50:27.949522 22485033404224 run_lib.py:146] step: 283200, training_loss: 4.97007e-04
I0513 12:50:28.109349 22485033404224 run_lib.py:167] step: 283200, eval_loss: 5.47371e-04
I0513 12:50:52.007447 22485033404224 run_lib.py:146] step: 283250, training_loss: 6.61454e-04
I0513 12:51:15.553594 22485033404224 run_lib.py:146] step: 283300, training_loss: 6.52914e-04
I0513 12:51:15.714027 22485033404224 run_lib.py:167] step: 283300, eval_loss: 5.97503e-04
I0513 12:51:39.507295 22485033404224 run_lib.py:146] step: 283350, training_loss: 5.41036e-04
I0513 12:52:03.330919 22485033404224 run_lib.py:146] step: 283400, training_loss: 6.01321e-04
I0513 12:52:03.491284 22485033404224 run_lib.py:167] step: 283400, eval_loss: 5.03123e-04
I0513 12:52:27.008960 22485033404224 run_lib.py:146] step: 283450, training_loss: 4.83152e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 12:52:50.637979 22485033404224 run_lib.py:146] step: 283500, training_loss: 5.12795e-04
I0513 12:52:50.798724 22485033404224 run_lib.py:167] step: 283500, eval_loss: 6.63158e-04
I0513 12:53:15.028678 22485033404224 run_lib.py:146] step: 283550, training_loss: 6.88351e-04
I0513 12:53:38.569514 22485033404224 run_lib.py:146] step: 283600, training_loss: 5.72581e-04
I0513 12:53:38.730084 22485033404224 run_lib.py:167] step: 283600, eval_loss: 4.41885e-04
I0513 12:54:02.252376 22485033404224 run_lib.py:146] step: 283650, training_loss: 8.25185e-04
I0513 12:54:26.381094 22485033404224 run_lib.py:146] step: 283700, training_loss: 6.24111e-04
I0513 12:54:26.540388 22485033404224 run_lib.py:167] step: 283700, eval_loss: 5.88869e-04
I0513 12:54:50.082467 22485033404224 run_lib.py:146] step: 283750, training_loss: 7.94780e-04
I0513 12:55:13.633490 22485033404224 run_lib.py:146] step: 283800, training_loss: 6.65186e-04
I0513 12:55:13.792791 22485033404224 run_lib.py:167] step: 283800, eval_loss: 5.08897e-04
I0513 12:55:37.649219 22485033404224 run_lib.py:146] step: 283850, training_loss: 6.34544e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 12:56:01.561375 22485033404224 run_lib.py:146] step: 283900, training_loss: 7.08577e-04
I0513 12:56:01.722184 22485033404224 run_lib.py:167] step: 283900, eval_loss: 6.96886e-04
I0513 12:56:25.269702 22485033404224 run_lib.py:146] step: 283950, training_loss: 6.44139e-04
I0513 12:56:49.121048 22485033404224 run_lib.py:146] step: 284000, training_loss: 5.15004e-04
I0513 12:56:49.280592 22485033404224 run_lib.py:167] step: 284000, eval_loss: 6.04203e-04
I0513 12:57:13.128646 22485033404224 run_lib.py:146] step: 284050, training_loss: 6.44361e-04
I0513 12:57:36.638106 22485033404224 run_lib.py:146] step: 284100, training_loss: 6.46428e-04
I0513 12:57:36.799627 22485033404224 run_lib.py:167] step: 284100, eval_loss: 6.07537e-04
I0513 12:58:00.566228 22485033404224 run_lib.py:146] step: 284150, training_loss: 7.29844e-04
I0513 12:58:24.352491 22485033404224 run_lib.py:146] step: 284200, training_loss: 5.39387e-04
I0513 12:58:24.510424 22485033404224 run_lib.py:167] step: 284200, eval_loss: 7.70038e-04
I0513 12:58:48.010880 22485033404224 run_lib.py:146] step: 284250, training_loss: 5.55444e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 12:59:11.602802 22485033404224 run_lib.py:146] step: 284300, training_loss: 6.83229e-04
I0513 12:59:11.690461 22485033404224 run_lib.py:167] step: 284300, eval_loss: 6.26807e-04
I0513 12:59:35.905593 22485033404224 run_lib.py:146] step: 284350, training_loss: 5.96788e-04
I0513 12:59:59.484270 22485033404224 run_lib.py:146] step: 284400, training_loss: 7.27257e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 12:59:59.832082 22485033404224 run_lib.py:167] step: 284400, eval_loss: 6.15484e-04
I0513 13:00:23.437727 22485033404224 run_lib.py:146] step: 284450, training_loss: 6.27293e-04
I0513 13:00:47.705443 22485033404224 run_lib.py:146] step: 284500, training_loss: 6.30861e-04
I0513 13:00:47.866346 22485033404224 run_lib.py:167] step: 284500, eval_loss: 5.54653e-04
I0513 13:01:11.446998 22485033404224 run_lib.py:146] step: 284550, training_loss: 4.79964e-04
I0513 13:01:35.044077 22485033404224 run_lib.py:146] step: 284600, training_loss: 7.55563e-04
I0513 13:01:35.203562 22485033404224 run_lib.py:167] step: 284600, eval_loss: 6.59613e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 13:01:59.156670 22485033404224 run_lib.py:146] step: 284650, training_loss: 6.25157e-04
I0513 13:02:23.199724 22485033404224 run_lib.py:146] step: 284700, training_loss: 5.02057e-04
I0513 13:02:23.361376 22485033404224 run_lib.py:167] step: 284700, eval_loss: 7.33559e-04
I0513 13:02:46.951463 22485033404224 run_lib.py:146] step: 284750, training_loss: 5.04756e-04
I0513 13:03:10.929513 22485033404224 run_lib.py:146] step: 284800, training_loss: 6.76455e-04
I0513 13:03:11.089107 22485033404224 run_lib.py:167] step: 284800, eval_loss: 7.06370e-04
I0513 13:03:35.081780 22485033404224 run_lib.py:146] step: 284850, training_loss: 7.19786e-04
I0513 13:03:58.698893 22485033404224 run_lib.py:146] step: 284900, training_loss: 8.67101e-04
I0513 13:03:58.859186 22485033404224 run_lib.py:167] step: 284900, eval_loss: 5.86175e-04
I0513 13:04:22.819245 22485033404224 run_lib.py:146] step: 284950, training_loss: 4.71793e-04
I0513 13:04:46.830987 22485033404224 run_lib.py:146] step: 285000, training_loss: 4.96433e-04
I0513 13:04:46.991292 22485033404224 run_lib.py:167] step: 285000, eval_loss: 6.39542e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 13:05:10.663280 22485033404224 run_lib.py:146] step: 285050, training_loss: 7.19528e-04
I0513 13:05:34.670459 22485033404224 run_lib.py:146] step: 285100, training_loss: 5.62452e-04
I0513 13:05:34.831137 22485033404224 run_lib.py:167] step: 285100, eval_loss: 6.77428e-04
I0513 13:05:58.697593 22485033404224 run_lib.py:146] step: 285150, training_loss: 7.64459e-04
I0513 13:06:22.273511 22485033404224 run_lib.py:146] step: 285200, training_loss: 5.45050e-04
I0513 13:06:22.432570 22485033404224 run_lib.py:167] step: 285200, eval_loss: 7.06934e-04
I0513 13:06:45.971462 22485033404224 run_lib.py:146] step: 285250, training_loss: 6.24766e-04
I0513 13:07:10.170097 22485033404224 run_lib.py:146] step: 285300, training_loss: 5.65871e-04
I0513 13:07:10.329965 22485033404224 run_lib.py:167] step: 285300, eval_loss: 4.58827e-04
I0513 13:07:33.850543 22485033404224 run_lib.py:146] step: 285350, training_loss: 7.42100e-04
I0513 13:07:57.369382 22485033404224 run_lib.py:146] step: 285400, training_loss: 4.44002e-04
I0513 13:07:57.529202 22485033404224 run_lib.py:167] step: 285400, eval_loss: 7.27387e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 13:08:21.389397 22485033404224 run_lib.py:146] step: 285450, training_loss: 6.65571e-04
I0513 13:08:45.291172 22485033404224 run_lib.py:146] step: 285500, training_loss: 8.76311e-04
I0513 13:08:45.451599 22485033404224 run_lib.py:167] step: 285500, eval_loss: 7.75744e-04
I0513 13:09:08.974993 22485033404224 run_lib.py:146] step: 285550, training_loss: 5.75561e-04
I0513 13:09:32.841774 22485033404224 run_lib.py:146] step: 285600, training_loss: 6.32433e-04
I0513 13:09:33.000931 22485033404224 run_lib.py:167] step: 285600, eval_loss: 5.85860e-04
I0513 13:09:56.796789 22485033404224 run_lib.py:146] step: 285650, training_loss: 6.30983e-04
I0513 13:10:20.323624 22485033404224 run_lib.py:146] step: 285700, training_loss: 5.64537e-04
I0513 13:10:20.483067 22485033404224 run_lib.py:167] step: 285700, eval_loss: 7.17748e-04
I0513 13:10:44.357921 22485033404224 run_lib.py:146] step: 285750, training_loss: 5.99798e-04
I0513 13:11:08.186197 22485033404224 run_lib.py:146] step: 285800, training_loss: 5.50178e-04
I0513 13:11:08.344625 22485033404224 run_lib.py:167] step: 285800, eval_loss: 6.88538e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 13:11:31.949578 22485033404224 run_lib.py:146] step: 285850, training_loss: 8.69605e-04
I0513 13:11:55.799784 22485033404224 run_lib.py:146] step: 285900, training_loss: 4.87905e-04
I0513 13:11:55.961618 22485033404224 run_lib.py:167] step: 285900, eval_loss: 7.45059e-04
I0513 13:12:19.819611 22485033404224 run_lib.py:146] step: 285950, training_loss: 5.95841e-04
I0513 13:12:43.336977 22485033404224 run_lib.py:146] step: 286000, training_loss: 5.84718e-04
I0513 13:12:43.496411 22485033404224 run_lib.py:167] step: 286000, eval_loss: 5.96949e-04
I0513 13:13:07.330014 22485033404224 run_lib.py:146] step: 286050, training_loss: 5.36837e-04
I0513 13:13:31.163249 22485033404224 run_lib.py:146] step: 286100, training_loss: 5.15823e-04
I0513 13:13:31.322080 22485033404224 run_lib.py:167] step: 286100, eval_loss: 6.16944e-04
I0513 13:13:54.826181 22485033404224 run_lib.py:146] step: 286150, training_loss: 7.43239e-04
I0513 13:14:18.346364 22485033404224 run_lib.py:146] step: 286200, training_loss: 7.76743e-04
I0513 13:14:18.505977 22485033404224 run_lib.py:167] step: 286200, eval_loss: 4.52009e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 13:14:42.739863 22485033404224 run_lib.py:146] step: 286250, training_loss: 5.15381e-04
I0513 13:15:06.278736 22485033404224 run_lib.py:146] step: 286300, training_loss: 6.05865e-04
I0513 13:15:06.441157 22485033404224 run_lib.py:167] step: 286300, eval_loss: 6.56134e-04
I0513 13:15:29.973483 22485033404224 run_lib.py:146] step: 286350, training_loss: 5.19750e-04
I0513 13:15:53.859727 22485033404224 run_lib.py:146] step: 286400, training_loss: 7.56903e-04
I0513 13:15:54.020523 22485033404224 run_lib.py:167] step: 286400, eval_loss: 4.85481e-04
I0513 13:16:17.832282 22485033404224 run_lib.py:146] step: 286450, training_loss: 6.94899e-04
I0513 13:16:41.339849 22485033404224 run_lib.py:146] step: 286500, training_loss: 5.13131e-04
I0513 13:16:41.499070 22485033404224 run_lib.py:167] step: 286500, eval_loss: 5.58618e-04
I0513 13:17:05.333549 22485033404224 run_lib.py:146] step: 286550, training_loss: 6.54271e-04
I0513 13:17:29.237953 22485033404224 run_lib.py:146] step: 286600, training_loss: 8.01530e-04
I0513 13:17:29.397809 22485033404224 run_lib.py:167] step: 286600, eval_loss: 5.24468e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 13:17:53.071851 22485033404224 run_lib.py:146] step: 286650, training_loss: 5.58480e-04
I0513 13:18:17.045014 22485033404224 run_lib.py:146] step: 286700, training_loss: 5.96608e-04
I0513 13:18:17.207113 22485033404224 run_lib.py:167] step: 286700, eval_loss: 6.48732e-04
I0513 13:18:41.120559 22485033404224 run_lib.py:146] step: 286750, training_loss: 8.64693e-04
I0513 13:19:04.715536 22485033404224 run_lib.py:146] step: 286800, training_loss: 5.01960e-04
I0513 13:19:04.875547 22485033404224 run_lib.py:167] step: 286800, eval_loss: 7.00626e-04
I0513 13:19:28.760823 22485033404224 run_lib.py:146] step: 286850, training_loss: 6.97364e-04
I0513 13:19:52.651161 22485033404224 run_lib.py:146] step: 286900, training_loss: 6.82687e-04
I0513 13:19:52.811294 22485033404224 run_lib.py:167] step: 286900, eval_loss: 7.30467e-04
I0513 13:20:16.379622 22485033404224 run_lib.py:146] step: 286950, training_loss: 6.49988e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 13:20:39.988906 22485033404224 run_lib.py:146] step: 287000, training_loss: 6.21713e-04
I0513 13:20:40.150081 22485033404224 run_lib.py:167] step: 287000, eval_loss: 7.98276e-04
I0513 13:21:04.548921 22485033404224 run_lib.py:146] step: 287050, training_loss: 6.50590e-04
I0513 13:21:28.167648 22485033404224 run_lib.py:146] step: 287100, training_loss: 4.44793e-04
I0513 13:21:28.327830 22485033404224 run_lib.py:167] step: 287100, eval_loss: 8.01631e-04
I0513 13:21:51.914809 22485033404224 run_lib.py:146] step: 287150, training_loss: 6.40852e-04
I0513 13:22:15.862524 22485033404224 run_lib.py:146] step: 287200, training_loss: 7.99460e-04
I0513 13:22:16.023899 22485033404224 run_lib.py:167] step: 287200, eval_loss: 5.43608e-04
I0513 13:22:40.009316 22485033404224 run_lib.py:146] step: 287250, training_loss: 5.61406e-04
I0513 13:23:03.593113 22485033404224 run_lib.py:146] step: 287300, training_loss: 5.35645e-04
I0513 13:23:03.753487 22485033404224 run_lib.py:167] step: 287300, eval_loss: 5.76375e-04
I0513 13:23:27.604978 22485033404224 run_lib.py:146] step: 287350, training_loss: 6.36361e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 13:23:51.583651 22485033404224 run_lib.py:146] step: 287400, training_loss: 6.12527e-04
I0513 13:23:51.746686 22485033404224 run_lib.py:167] step: 287400, eval_loss: 6.64497e-04
I0513 13:24:15.339136 22485033404224 run_lib.py:146] step: 287450, training_loss: 5.80759e-04
I0513 13:24:39.226426 22485033404224 run_lib.py:146] step: 287500, training_loss: 8.47179e-04
I0513 13:24:39.385100 22485033404224 run_lib.py:167] step: 287500, eval_loss: 6.31110e-04
I0513 13:25:03.275555 22485033404224 run_lib.py:146] step: 287550, training_loss: 4.88665e-04
I0513 13:25:26.785201 22485033404224 run_lib.py:146] step: 287600, training_loss: 8.81140e-04
I0513 13:25:26.944275 22485033404224 run_lib.py:167] step: 287600, eval_loss: 6.09745e-04
I0513 13:25:50.792598 22485033404224 run_lib.py:146] step: 287650, training_loss: 5.37113e-04
I0513 13:26:14.595243 22485033404224 run_lib.py:146] step: 287700, training_loss: 4.58521e-04
I0513 13:26:14.755969 22485033404224 run_lib.py:167] step: 287700, eval_loss: 6.30026e-04
I0513 13:26:38.269821 22485033404224 run_lib.py:146] step: 287750, training_loss: 3.80651e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 13:27:02.238017 22485033404224 run_lib.py:146] step: 287800, training_loss: 6.36823e-04
I0513 13:27:02.398694 22485033404224 run_lib.py:167] step: 287800, eval_loss: 6.03082e-04
I0513 13:27:26.246996 22485033404224 run_lib.py:146] step: 287850, training_loss: 5.20663e-04
I0513 13:27:49.774116 22485033404224 run_lib.py:146] step: 287900, training_loss: 4.94896e-04
I0513 13:27:49.932652 22485033404224 run_lib.py:167] step: 287900, eval_loss: 6.56811e-04
I0513 13:28:13.472125 22485033404224 run_lib.py:146] step: 287950, training_loss: 4.69273e-04
I0513 13:28:37.292016 22485033404224 run_lib.py:146] step: 288000, training_loss: 5.94541e-04
I0513 13:28:37.450974 22485033404224 run_lib.py:167] step: 288000, eval_loss: 6.04561e-04
I0513 13:29:01.266355 22485033404224 run_lib.py:146] step: 288050, training_loss: 5.38994e-04
I0513 13:29:24.795195 22485033404224 run_lib.py:146] step: 288100, training_loss: 5.49172e-04
I0513 13:29:24.955741 22485033404224 run_lib.py:167] step: 288100, eval_loss: 7.52323e-04
I0513 13:29:48.776804 22485033404224 run_lib.py:146] step: 288150, training_loss: 6.46253e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 13:30:12.708032 22485033404224 run_lib.py:146] step: 288200, training_loss: 6.21057e-04
I0513 13:30:12.869355 22485033404224 run_lib.py:167] step: 288200, eval_loss: 7.50774e-04
I0513 13:30:36.418840 22485033404224 run_lib.py:146] step: 288250, training_loss: 6.76167e-04
I0513 13:31:00.287714 22485033404224 run_lib.py:146] step: 288300, training_loss: 8.18427e-04
I0513 13:31:00.446822 22485033404224 run_lib.py:167] step: 288300, eval_loss: 5.63797e-04
I0513 13:31:24.313506 22485033404224 run_lib.py:146] step: 288350, training_loss: 5.26062e-04
I0513 13:31:47.807143 22485033404224 run_lib.py:146] step: 288400, training_loss: 6.17760e-04
I0513 13:31:47.966638 22485033404224 run_lib.py:167] step: 288400, eval_loss: 6.18142e-04
I0513 13:32:11.805141 22485033404224 run_lib.py:146] step: 288450, training_loss: 6.39307e-04
I0513 13:32:35.645446 22485033404224 run_lib.py:146] step: 288500, training_loss: 6.03779e-04
I0513 13:32:35.805419 22485033404224 run_lib.py:167] step: 288500, eval_loss: 4.74488e-04
I0513 13:32:59.367403 22485033404224 run_lib.py:146] step: 288550, training_loss: 4.98098e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 13:33:23.335794 22485033404224 run_lib.py:146] step: 288600, training_loss: 7.53190e-04
I0513 13:33:23.497730 22485033404224 run_lib.py:167] step: 288600, eval_loss: 6.16590e-04
I0513 13:33:47.348708 22485033404224 run_lib.py:146] step: 288650, training_loss: 5.97369e-04
I0513 13:34:10.897061 22485033404224 run_lib.py:146] step: 288700, training_loss: 7.52843e-04
I0513 13:34:11.056575 22485033404224 run_lib.py:167] step: 288700, eval_loss: 5.60863e-04
I0513 13:34:34.591677 22485033404224 run_lib.py:146] step: 288750, training_loss: 5.57286e-04
I0513 13:34:58.413050 22485033404224 run_lib.py:146] step: 288800, training_loss: 5.99725e-04
I0513 13:34:58.573798 22485033404224 run_lib.py:167] step: 288800, eval_loss: 5.05624e-04
I0513 13:35:22.469599 22485033404224 run_lib.py:146] step: 288850, training_loss: 6.27949e-04
I0513 13:35:46.063749 22485033404224 run_lib.py:146] step: 288900, training_loss: 5.08283e-04
I0513 13:35:46.224319 22485033404224 run_lib.py:167] step: 288900, eval_loss: 6.16817e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 13:36:10.230050 22485033404224 run_lib.py:146] step: 288950, training_loss: 5.66386e-04
I0513 13:36:34.189183 22485033404224 run_lib.py:146] step: 289000, training_loss: 4.91805e-04
I0513 13:36:34.351354 22485033404224 run_lib.py:167] step: 289000, eval_loss: 6.62603e-04
I0513 13:36:57.921855 22485033404224 run_lib.py:146] step: 289050, training_loss: 6.19924e-04
I0513 13:37:21.857512 22485033404224 run_lib.py:146] step: 289100, training_loss: 6.82415e-04
I0513 13:37:22.017873 22485033404224 run_lib.py:167] step: 289100, eval_loss: 7.34336e-04
I0513 13:37:45.881745 22485033404224 run_lib.py:146] step: 289150, training_loss: 6.31967e-04
I0513 13:38:09.455484 22485033404224 run_lib.py:146] step: 289200, training_loss: 7.11785e-04
I0513 13:38:09.616481 22485033404224 run_lib.py:167] step: 289200, eval_loss: 6.11750e-04
I0513 13:38:33.478728 22485033404224 run_lib.py:146] step: 289250, training_loss: 5.99860e-04
I0513 13:38:57.379390 22485033404224 run_lib.py:146] step: 289300, training_loss: 6.30105e-04
I0513 13:38:57.540051 22485033404224 run_lib.py:167] step: 289300, eval_loss: 6.91666e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 13:39:21.224426 22485033404224 run_lib.py:146] step: 289350, training_loss: 6.76798e-04
I0513 13:39:45.173788 22485033404224 run_lib.py:146] step: 289400, training_loss: 4.62876e-04
I0513 13:39:45.334540 22485033404224 run_lib.py:167] step: 289400, eval_loss: 5.71146e-04
I0513 13:40:09.367443 22485033404224 run_lib.py:146] step: 289450, training_loss: 7.09391e-04
I0513 13:40:32.992798 22485033404224 run_lib.py:146] step: 289500, training_loss: 6.24625e-04
I0513 13:40:33.154359 22485033404224 run_lib.py:167] step: 289500, eval_loss: 6.32974e-04
I0513 13:40:56.759617 22485033404224 run_lib.py:146] step: 289550, training_loss: 5.17052e-04
I0513 13:41:21.074135 22485033404224 run_lib.py:146] step: 289600, training_loss: 5.93969e-04
I0513 13:41:21.233622 22485033404224 run_lib.py:167] step: 289600, eval_loss: 6.71909e-04
I0513 13:41:44.821747 22485033404224 run_lib.py:146] step: 289650, training_loss: 6.72874e-04
I0513 13:42:08.432582 22485033404224 run_lib.py:146] step: 289700, training_loss: 5.87096e-04
I0513 13:42:08.592889 22485033404224 run_lib.py:167] step: 289700, eval_loss: 5.32341e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 13:42:32.533577 22485033404224 run_lib.py:146] step: 289750, training_loss: 5.89627e-04
I0513 13:42:56.522579 22485033404224 run_lib.py:146] step: 289800, training_loss: 6.57284e-04
I0513 13:42:56.682286 22485033404224 run_lib.py:167] step: 289800, eval_loss: 4.98218e-04
I0513 13:43:20.209797 22485033404224 run_lib.py:146] step: 289850, training_loss: 7.08870e-04
I0513 13:43:44.043619 22485033404224 run_lib.py:146] step: 289900, training_loss: 8.13102e-04
I0513 13:43:44.202275 22485033404224 run_lib.py:167] step: 289900, eval_loss: 7.24974e-04
I0513 13:44:08.045837 22485033404224 run_lib.py:146] step: 289950, training_loss: 6.77933e-04
I0513 13:44:31.572245 22485033404224 run_lib.py:146] step: 290000, training_loss: 7.28055e-04
I0513 13:44:33.283350 22485033404224 run_lib.py:167] step: 290000, eval_loss: 5.92181e-04
I0513 13:44:58.642699 22485033404224 run_lib.py:146] step: 290050, training_loss: 5.22486e-04
I0513 13:45:22.497973 22485033404224 run_lib.py:146] step: 290100, training_loss: 5.47723e-04
I0513 13:45:22.657482 22485033404224 run_lib.py:167] step: 290100, eval_loss: 4.70448e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 13:45:46.573000 22485033404224 run_lib.py:146] step: 290150, training_loss: 7.04121e-04
I0513 13:46:10.115182 22485033404224 run_lib.py:146] step: 290200, training_loss: 5.89791e-04
I0513 13:46:10.274630 22485033404224 run_lib.py:167] step: 290200, eval_loss: 6.46808e-04
I0513 13:46:34.112336 22485033404224 run_lib.py:146] step: 290250, training_loss: 9.17162e-04
I0513 13:46:57.659153 22485033404224 run_lib.py:146] step: 290300, training_loss: 4.44763e-04
I0513 13:46:57.819128 22485033404224 run_lib.py:167] step: 290300, eval_loss: 6.23782e-04
I0513 13:47:21.645156 22485033404224 run_lib.py:146] step: 290350, training_loss: 6.05326e-04
I0513 13:47:45.496248 22485033404224 run_lib.py:146] step: 290400, training_loss: 4.71508e-04
I0513 13:47:45.657554 22485033404224 run_lib.py:167] step: 290400, eval_loss: 6.25259e-04
I0513 13:48:09.181486 22485033404224 run_lib.py:146] step: 290450, training_loss: 5.95129e-04
I0513 13:48:33.020544 22485033404224 run_lib.py:146] step: 290500, training_loss: 7.50155e-04
I0513 13:48:33.179691 22485033404224 run_lib.py:167] step: 290500, eval_loss: 7.06429e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 13:48:57.131561 22485033404224 run_lib.py:146] step: 290550, training_loss: 6.51337e-04
I0513 13:49:20.631180 22485033404224 run_lib.py:146] step: 290600, training_loss: 5.87819e-04
I0513 13:49:20.792990 22485033404224 run_lib.py:167] step: 290600, eval_loss: 5.46932e-04
I0513 13:49:44.670306 22485033404224 run_lib.py:146] step: 290650, training_loss: 4.94656e-04
I0513 13:50:08.178964 22485033404224 run_lib.py:146] step: 290700, training_loss: 6.16976e-04
I0513 13:50:08.340201 22485033404224 run_lib.py:167] step: 290700, eval_loss: 7.11433e-04
I0513 13:50:32.168886 22485033404224 run_lib.py:146] step: 290750, training_loss: 6.33495e-04
I0513 13:50:55.995286 22485033404224 run_lib.py:146] step: 290800, training_loss: 7.00790e-04
I0513 13:50:56.155175 22485033404224 run_lib.py:167] step: 290800, eval_loss: 6.09372e-04
I0513 13:51:19.671513 22485033404224 run_lib.py:146] step: 290850, training_loss: 5.27528e-04
I0513 13:51:43.477803 22485033404224 run_lib.py:146] step: 290900, training_loss: 7.86126e-04
I0513 13:51:43.638946 22485033404224 run_lib.py:167] step: 290900, eval_loss: 6.18110e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 13:52:07.613832 22485033404224 run_lib.py:146] step: 290950, training_loss: 8.07402e-04
I0513 13:52:31.173184 22485033404224 run_lib.py:146] step: 291000, training_loss: 5.83334e-04
I0513 13:52:31.334394 22485033404224 run_lib.py:167] step: 291000, eval_loss: 6.34585e-04
I0513 13:52:55.220027 22485033404224 run_lib.py:146] step: 291050, training_loss: 7.19660e-04
I0513 13:53:19.170174 22485033404224 run_lib.py:146] step: 291100, training_loss: 6.79614e-04
I0513 13:53:19.330880 22485033404224 run_lib.py:167] step: 291100, eval_loss: 7.53425e-04
I0513 13:53:42.926599 22485033404224 run_lib.py:146] step: 291150, training_loss: 6.42328e-04
I0513 13:54:06.809133 22485033404224 run_lib.py:146] step: 291200, training_loss: 5.54443e-04
I0513 13:54:06.969799 22485033404224 run_lib.py:167] step: 291200, eval_loss: 5.81831e-04
I0513 13:54:30.563005 22485033404224 run_lib.py:146] step: 291250, training_loss: 5.78471e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 13:54:54.536936 22485033404224 run_lib.py:146] step: 291300, training_loss: 6.52226e-04
I0513 13:54:54.700285 22485033404224 run_lib.py:167] step: 291300, eval_loss: 7.14358e-04
I0513 13:55:18.707182 22485033404224 run_lib.py:146] step: 291350, training_loss: 6.02167e-04
I0513 13:55:42.335852 22485033404224 run_lib.py:146] step: 291400, training_loss: 6.08422e-04
I0513 13:55:42.496493 22485033404224 run_lib.py:167] step: 291400, eval_loss: 4.68438e-04
I0513 13:56:06.488762 22485033404224 run_lib.py:146] step: 291450, training_loss: 6.67214e-04
I0513 13:56:30.107310 22485033404224 run_lib.py:146] step: 291500, training_loss: 6.61968e-04
I0513 13:56:30.267384 22485033404224 run_lib.py:167] step: 291500, eval_loss: 4.75606e-04
I0513 13:56:54.201857 22485033404224 run_lib.py:146] step: 291550, training_loss: 6.87260e-04
I0513 13:57:18.178218 22485033404224 run_lib.py:146] step: 291600, training_loss: 4.04908e-04
I0513 13:57:18.338429 22485033404224 run_lib.py:167] step: 291600, eval_loss: 5.04102e-04
I0513 13:57:41.944669 22485033404224 run_lib.py:146] step: 291650, training_loss: 6.43826e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 13:58:05.950393 22485033404224 run_lib.py:146] step: 291700, training_loss: 7.07216e-04
I0513 13:58:06.112565 22485033404224 run_lib.py:167] step: 291700, eval_loss: 4.94454e-04
I0513 13:58:30.139685 22485033404224 run_lib.py:146] step: 291750, training_loss: 5.08004e-04
I0513 13:58:53.765563 22485033404224 run_lib.py:146] step: 291800, training_loss: 4.64977e-04
I0513 13:58:53.927647 22485033404224 run_lib.py:167] step: 291800, eval_loss: 6.83831e-04
I0513 13:59:17.966089 22485033404224 run_lib.py:146] step: 291850, training_loss: 6.58504e-04
I0513 13:59:41.863296 22485033404224 run_lib.py:146] step: 291900, training_loss: 5.31460e-04
I0513 13:59:42.023606 22485033404224 run_lib.py:167] step: 291900, eval_loss: 7.58221e-04
I0513 14:00:05.639472 22485033404224 run_lib.py:146] step: 291950, training_loss: 6.70102e-04
I0513 14:00:29.602892 22485033404224 run_lib.py:146] step: 292000, training_loss: 7.08735e-04
I0513 14:00:29.764045 22485033404224 run_lib.py:167] step: 292000, eval_loss: 5.88921e-04
I0513 14:00:53.267167 22485033404224 run_lib.py:146] step: 292050, training_loss: 5.25850e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 14:01:17.155162 22485033404224 run_lib.py:146] step: 292100, training_loss: 6.84606e-04
I0513 14:01:17.315454 22485033404224 run_lib.py:167] step: 292100, eval_loss: 7.05111e-04
I0513 14:01:41.182835 22485033404224 run_lib.py:146] step: 292150, training_loss: 5.96406e-04
I0513 14:02:04.697996 22485033404224 run_lib.py:146] step: 292200, training_loss: 5.34490e-04
I0513 14:02:04.784330 22485033404224 run_lib.py:167] step: 292200, eval_loss: 1.19202e-03
I0513 14:02:28.638794 22485033404224 run_lib.py:146] step: 292250, training_loss: 5.75690e-04
I0513 14:02:52.160451 22485033404224 run_lib.py:146] step: 292300, training_loss: 6.46500e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 14:02:52.509194 22485033404224 run_lib.py:167] step: 292300, eval_loss: 4.81243e-04
I0513 14:03:16.428194 22485033404224 run_lib.py:146] step: 292350, training_loss: 6.25681e-04
I0513 14:03:40.302867 22485033404224 run_lib.py:146] step: 292400, training_loss: 6.20481e-04
I0513 14:03:40.461764 22485033404224 run_lib.py:167] step: 292400, eval_loss: 6.69294e-04
I0513 14:04:03.994836 22485033404224 run_lib.py:146] step: 292450, training_loss: 5.57373e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 14:04:27.878524 22485033404224 run_lib.py:146] step: 292500, training_loss: 5.21473e-04
I0513 14:04:28.040066 22485033404224 run_lib.py:167] step: 292500, eval_loss: 7.01779e-04
I0513 14:04:51.887326 22485033404224 run_lib.py:146] step: 292550, training_loss: 6.13716e-04
I0513 14:05:15.433161 22485033404224 run_lib.py:146] step: 292600, training_loss: 7.11427e-04
I0513 14:05:15.592011 22485033404224 run_lib.py:167] step: 292600, eval_loss: 7.63784e-04
I0513 14:05:39.439517 22485033404224 run_lib.py:146] step: 292650, training_loss: 5.14921e-04
I0513 14:06:03.277420 22485033404224 run_lib.py:146] step: 292700, training_loss: 7.04209e-04
I0513 14:06:03.437600 22485033404224 run_lib.py:167] step: 292700, eval_loss: 5.85071e-04
I0513 14:06:26.951657 22485033404224 run_lib.py:146] step: 292750, training_loss: 6.25952e-04
I0513 14:06:50.772518 22485033404224 run_lib.py:146] step: 292800, training_loss: 5.19585e-04
I0513 14:06:50.932291 22485033404224 run_lib.py:167] step: 292800, eval_loss: 6.12128e-04
I0513 14:07:14.460304 22485033404224 run_lib.py:146] step: 292850, training_loss: 7.66375e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 14:07:38.358769 22485033404224 run_lib.py:146] step: 292900, training_loss: 5.63327e-04
I0513 14:07:38.519689 22485033404224 run_lib.py:167] step: 292900, eval_loss: 7.17627e-04
I0513 14:08:02.345907 22485033404224 run_lib.py:146] step: 292950, training_loss: 6.71294e-04
I0513 14:08:25.858683 22485033404224 run_lib.py:146] step: 293000, training_loss: 5.96215e-04
I0513 14:08:26.018432 22485033404224 run_lib.py:167] step: 293000, eval_loss: 5.57208e-04
I0513 14:08:49.846738 22485033404224 run_lib.py:146] step: 293050, training_loss: 6.60565e-04
I0513 14:09:13.369085 22485033404224 run_lib.py:146] step: 293100, training_loss: 6.79582e-04
I0513 14:09:13.529188 22485033404224 run_lib.py:167] step: 293100, eval_loss: 7.68769e-04
I0513 14:09:37.358296 22485033404224 run_lib.py:146] step: 293150, training_loss: 4.27057e-04
I0513 14:10:01.192952 22485033404224 run_lib.py:146] step: 293200, training_loss: 6.30644e-04
I0513 14:10:01.351544 22485033404224 run_lib.py:167] step: 293200, eval_loss: 5.86894e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 14:10:24.922585 22485033404224 run_lib.py:146] step: 293250, training_loss: 6.04207e-04
I0513 14:10:48.815840 22485033404224 run_lib.py:146] step: 293300, training_loss: 7.34547e-04
I0513 14:10:48.976801 22485033404224 run_lib.py:167] step: 293300, eval_loss: 5.19949e-04
I0513 14:11:12.856149 22485033404224 run_lib.py:146] step: 293350, training_loss: 6.93918e-04
I0513 14:11:36.469085 22485033404224 run_lib.py:146] step: 293400, training_loss: 5.23158e-04
I0513 14:11:36.629374 22485033404224 run_lib.py:167] step: 293400, eval_loss: 5.19802e-04
I0513 14:12:00.562969 22485033404224 run_lib.py:146] step: 293450, training_loss: 8.02070e-04
I0513 14:12:24.471739 22485033404224 run_lib.py:146] step: 293500, training_loss: 8.06538e-04
I0513 14:12:24.632109 22485033404224 run_lib.py:167] step: 293500, eval_loss: 6.63883e-04
I0513 14:12:48.234091 22485033404224 run_lib.py:146] step: 293550, training_loss: 7.98265e-04
I0513 14:13:12.121239 22485033404224 run_lib.py:146] step: 293600, training_loss: 7.19695e-04
I0513 14:13:12.281857 22485033404224 run_lib.py:167] step: 293600, eval_loss: 6.01417e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 14:13:36.419574 22485033404224 run_lib.py:146] step: 293650, training_loss: 6.82074e-04
I0513 14:14:00.061183 22485033404224 run_lib.py:146] step: 293700, training_loss: 7.50687e-04
I0513 14:14:00.222865 22485033404224 run_lib.py:167] step: 293700, eval_loss: 6.49661e-04
I0513 14:14:24.332811 22485033404224 run_lib.py:146] step: 293750, training_loss: 6.51622e-04
I0513 14:14:47.990224 22485033404224 run_lib.py:146] step: 293800, training_loss: 7.07885e-04
I0513 14:14:48.151024 22485033404224 run_lib.py:167] step: 293800, eval_loss: 7.72358e-04
I0513 14:15:12.202629 22485033404224 run_lib.py:146] step: 293850, training_loss: 4.71384e-04
I0513 14:15:36.315242 22485033404224 run_lib.py:146] step: 293900, training_loss: 5.46640e-04
I0513 14:15:36.475924 22485033404224 run_lib.py:167] step: 293900, eval_loss: 4.79987e-04
I0513 14:16:00.104107 22485033404224 run_lib.py:146] step: 293950, training_loss: 6.17557e-04
I0513 14:16:24.098393 22485033404224 run_lib.py:146] step: 294000, training_loss: 7.56505e-04
I0513 14:16:24.258825 22485033404224 run_lib.py:167] step: 294000, eval_loss: 5.39496e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 14:16:47.925719 22485033404224 run_lib.py:146] step: 294050, training_loss: 5.08475e-04
I0513 14:17:11.984654 22485033404224 run_lib.py:146] step: 294100, training_loss: 7.27997e-04
I0513 14:17:12.146306 22485033404224 run_lib.py:167] step: 294100, eval_loss: 5.26645e-04
I0513 14:17:36.071933 22485033404224 run_lib.py:146] step: 294150, training_loss: 6.86967e-04
I0513 14:17:59.679249 22485033404224 run_lib.py:146] step: 294200, training_loss: 6.82195e-04
I0513 14:17:59.839717 22485033404224 run_lib.py:167] step: 294200, eval_loss: 7.51638e-04
I0513 14:18:23.797060 22485033404224 run_lib.py:146] step: 294250, training_loss: 6.24136e-04
I0513 14:18:47.605841 22485033404224 run_lib.py:146] step: 294300, training_loss: 7.57958e-04
I0513 14:18:47.765381 22485033404224 run_lib.py:167] step: 294300, eval_loss: 5.18863e-04
I0513 14:19:11.279995 22485033404224 run_lib.py:146] step: 294350, training_loss: 8.50453e-04
I0513 14:19:35.107749 22485033404224 run_lib.py:146] step: 294400, training_loss: 6.68579e-04
I0513 14:19:35.267818 22485033404224 run_lib.py:167] step: 294400, eval_loss: 5.32844e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 14:19:59.223619 22485033404224 run_lib.py:146] step: 294450, training_loss: 5.09595e-04
I0513 14:20:22.748039 22485033404224 run_lib.py:146] step: 294500, training_loss: 5.88758e-04
I0513 14:20:22.908271 22485033404224 run_lib.py:167] step: 294500, eval_loss: 7.31088e-04
I0513 14:20:46.784945 22485033404224 run_lib.py:146] step: 294550, training_loss: 5.49749e-04
I0513 14:21:10.335330 22485033404224 run_lib.py:146] step: 294600, training_loss: 6.63790e-04
I0513 14:21:10.495774 22485033404224 run_lib.py:167] step: 294600, eval_loss: 5.04676e-04
I0513 14:21:34.309013 22485033404224 run_lib.py:146] step: 294650, training_loss: 5.30988e-04
I0513 14:21:58.148757 22485033404224 run_lib.py:146] step: 294700, training_loss: 5.03775e-04
I0513 14:21:58.308859 22485033404224 run_lib.py:167] step: 294700, eval_loss: 5.05430e-04
I0513 14:22:21.825177 22485033404224 run_lib.py:146] step: 294750, training_loss: 7.45228e-04
I0513 14:22:45.661368 22485033404224 run_lib.py:146] step: 294800, training_loss: 5.99326e-04
I0513 14:22:45.820917 22485033404224 run_lib.py:167] step: 294800, eval_loss: 7.30211e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 14:23:09.442336 22485033404224 run_lib.py:146] step: 294850, training_loss: 7.86738e-04
I0513 14:23:33.313853 22485033404224 run_lib.py:146] step: 294900, training_loss: 7.47955e-04
I0513 14:23:33.474165 22485033404224 run_lib.py:167] step: 294900, eval_loss: 6.24432e-04
I0513 14:23:57.289453 22485033404224 run_lib.py:146] step: 294950, training_loss: 6.31170e-04
I0513 14:24:20.795945 22485033404224 run_lib.py:146] step: 295000, training_loss: 6.76678e-04
I0513 14:24:20.957357 22485033404224 run_lib.py:167] step: 295000, eval_loss: 6.61314e-04
I0513 14:24:44.775999 22485033404224 run_lib.py:146] step: 295050, training_loss: 5.18601e-04
I0513 14:25:08.576380 22485033404224 run_lib.py:146] step: 295100, training_loss: 5.00343e-04
I0513 14:25:08.735557 22485033404224 run_lib.py:167] step: 295100, eval_loss: 8.41812e-04
I0513 14:25:32.261042 22485033404224 run_lib.py:146] step: 295150, training_loss: 5.33711e-04
I0513 14:25:56.072209 22485033404224 run_lib.py:146] step: 295200, training_loss: 7.21742e-04
I0513 14:25:56.230677 22485033404224 run_lib.py:167] step: 295200, eval_loss: 5.94535e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 14:26:20.189882 22485033404224 run_lib.py:146] step: 295250, training_loss: 7.48112e-04
I0513 14:26:43.705224 22485033404224 run_lib.py:146] step: 295300, training_loss: 6.81618e-04
I0513 14:26:43.867513 22485033404224 run_lib.py:167] step: 295300, eval_loss: 5.96861e-04
I0513 14:27:07.722786 22485033404224 run_lib.py:146] step: 295350, training_loss: 6.24496e-04
I0513 14:27:31.234100 22485033404224 run_lib.py:146] step: 295400, training_loss: 7.08460e-04
I0513 14:27:31.393091 22485033404224 run_lib.py:167] step: 295400, eval_loss: 6.30751e-04
I0513 14:27:55.212718 22485033404224 run_lib.py:146] step: 295450, training_loss: 5.60898e-04
I0513 14:28:19.008480 22485033404224 run_lib.py:146] step: 295500, training_loss: 5.54538e-04
I0513 14:28:19.167825 22485033404224 run_lib.py:167] step: 295500, eval_loss: 4.88728e-04
I0513 14:28:42.697460 22485033404224 run_lib.py:146] step: 295550, training_loss: 7.88350e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 14:29:06.678579 22485033404224 run_lib.py:146] step: 295600, training_loss: 4.36639e-04
I0513 14:29:06.841019 22485033404224 run_lib.py:167] step: 295600, eval_loss: 6.42524e-04
I0513 14:29:30.821779 22485033404224 run_lib.py:146] step: 295650, training_loss: 6.49510e-04
I0513 14:29:54.423383 22485033404224 run_lib.py:146] step: 295700, training_loss: 4.91015e-04
I0513 14:29:54.585241 22485033404224 run_lib.py:167] step: 295700, eval_loss: 6.21086e-04
I0513 14:30:18.543106 22485033404224 run_lib.py:146] step: 295750, training_loss: 6.76072e-04
I0513 14:30:42.144344 22485033404224 run_lib.py:146] step: 295800, training_loss: 5.24371e-04
I0513 14:30:42.304365 22485033404224 run_lib.py:167] step: 295800, eval_loss: 7.17277e-04
I0513 14:31:06.183198 22485033404224 run_lib.py:146] step: 295850, training_loss: 6.32699e-04
I0513 14:31:30.066436 22485033404224 run_lib.py:146] step: 295900, training_loss: 7.41393e-04
I0513 14:31:30.226956 22485033404224 run_lib.py:167] step: 295900, eval_loss: 5.56097e-04
I0513 14:31:53.804376 22485033404224 run_lib.py:146] step: 295950, training_loss: 6.06886e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 14:32:17.742285 22485033404224 run_lib.py:146] step: 296000, training_loss: 6.93209e-04
I0513 14:32:17.904503 22485033404224 run_lib.py:167] step: 296000, eval_loss: 6.47062e-04
I0513 14:32:41.922458 22485033404224 run_lib.py:146] step: 296050, training_loss: 6.89660e-04
I0513 14:33:05.510140 22485033404224 run_lib.py:146] step: 296100, training_loss: 5.39601e-04
I0513 14:33:05.670611 22485033404224 run_lib.py:167] step: 296100, eval_loss: 4.27741e-04
I0513 14:33:29.602634 22485033404224 run_lib.py:146] step: 296150, training_loss: 6.19712e-04
I0513 14:33:53.569648 22485033404224 run_lib.py:146] step: 296200, training_loss: 6.11438e-04
I0513 14:33:53.728579 22485033404224 run_lib.py:167] step: 296200, eval_loss: 8.17118e-04
I0513 14:34:17.325396 22485033404224 run_lib.py:146] step: 296250, training_loss: 7.95132e-04
I0513 14:34:41.216027 22485033404224 run_lib.py:146] step: 296300, training_loss: 7.88500e-04
I0513 14:34:41.376278 22485033404224 run_lib.py:167] step: 296300, eval_loss: 6.71270e-04
I0513 14:35:04.949715 22485033404224 run_lib.py:146] step: 296350, training_loss: 5.99770e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 14:35:28.910272 22485033404224 run_lib.py:146] step: 296400, training_loss: 7.46314e-04
I0513 14:35:29.072353 22485033404224 run_lib.py:167] step: 296400, eval_loss: 6.73950e-04
I0513 14:35:52.995867 22485033404224 run_lib.py:146] step: 296450, training_loss: 5.86187e-04
I0513 14:36:16.516393 22485033404224 run_lib.py:146] step: 296500, training_loss: 4.96470e-04
I0513 14:36:16.676005 22485033404224 run_lib.py:167] step: 296500, eval_loss: 5.52524e-04
I0513 14:36:40.508164 22485033404224 run_lib.py:146] step: 296550, training_loss: 6.56719e-04
I0513 14:37:04.340323 22485033404224 run_lib.py:146] step: 296600, training_loss: 7.66015e-04
I0513 14:37:04.501679 22485033404224 run_lib.py:167] step: 296600, eval_loss: 6.12871e-04
I0513 14:37:28.022074 22485033404224 run_lib.py:146] step: 296650, training_loss: 5.12533e-04
I0513 14:37:51.834238 22485033404224 run_lib.py:146] step: 296700, training_loss: 6.30119e-04
I0513 14:37:51.993260 22485033404224 run_lib.py:167] step: 296700, eval_loss: 7.20232e-04
I0513 14:38:15.526475 22485033404224 run_lib.py:146] step: 296750, training_loss: 6.45845e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 14:38:39.431854 22485033404224 run_lib.py:146] step: 296800, training_loss: 7.38530e-04
I0513 14:38:39.592311 22485033404224 run_lib.py:167] step: 296800, eval_loss: 7.61211e-04
I0513 14:39:03.464712 22485033404224 run_lib.py:146] step: 296850, training_loss: 6.29940e-04
I0513 14:39:26.988196 22485033404224 run_lib.py:146] step: 296900, training_loss: 5.16250e-04
I0513 14:39:27.147656 22485033404224 run_lib.py:167] step: 296900, eval_loss: 5.98142e-04
I0513 14:39:51.022073 22485033404224 run_lib.py:146] step: 296950, training_loss: 7.13621e-04
I0513 14:40:14.864873 22485033404224 run_lib.py:146] step: 297000, training_loss: 6.42853e-04
I0513 14:40:15.024675 22485033404224 run_lib.py:167] step: 297000, eval_loss: 6.09228e-04
I0513 14:40:38.557841 22485033404224 run_lib.py:146] step: 297050, training_loss: 6.18236e-04
I0513 14:41:02.400681 22485033404224 run_lib.py:146] step: 297100, training_loss: 6.30682e-04
I0513 14:41:02.559720 22485033404224 run_lib.py:167] step: 297100, eval_loss: 4.34338e-04
I0513 14:41:26.089695 22485033404224 run_lib.py:146] step: 297150, training_loss: 6.33073e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 14:41:49.980906 22485033404224 run_lib.py:146] step: 297200, training_loss: 5.08848e-04
I0513 14:41:50.142424 22485033404224 run_lib.py:167] step: 297200, eval_loss: 5.14147e-04
I0513 14:42:14.003714 22485033404224 run_lib.py:146] step: 297250, training_loss: 6.55560e-04
I0513 14:42:37.544417 22485033404224 run_lib.py:146] step: 297300, training_loss: 4.58608e-04
I0513 14:42:37.702939 22485033404224 run_lib.py:167] step: 297300, eval_loss: 6.08732e-04
I0513 14:43:01.513052 22485033404224 run_lib.py:146] step: 297350, training_loss: 5.89092e-04
I0513 14:43:25.301911 22485033404224 run_lib.py:146] step: 297400, training_loss: 4.34300e-04
I0513 14:43:25.462419 22485033404224 run_lib.py:167] step: 297400, eval_loss: 5.13264e-04
I0513 14:43:48.994723 22485033404224 run_lib.py:146] step: 297450, training_loss: 5.40204e-04
I0513 14:44:12.822546 22485033404224 run_lib.py:146] step: 297500, training_loss: 5.78467e-04
I0513 14:44:12.983248 22485033404224 run_lib.py:167] step: 297500, eval_loss: 6.03811e-04
I0513 14:44:36.378252 22485033404224 run_lib.py:146] step: 297550, training_loss: 7.25133e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 14:45:00.760522 22485033404224 run_lib.py:146] step: 297600, training_loss: 8.08317e-04
I0513 14:45:00.920959 22485033404224 run_lib.py:167] step: 297600, eval_loss: 4.97525e-04
I0513 14:45:24.762765 22485033404224 run_lib.py:146] step: 297650, training_loss: 6.24619e-04
I0513 14:45:48.298142 22485033404224 run_lib.py:146] step: 297700, training_loss: 6.54874e-04
I0513 14:45:48.457435 22485033404224 run_lib.py:167] step: 297700, eval_loss: 5.50941e-04
I0513 14:46:12.276262 22485033404224 run_lib.py:146] step: 297750, training_loss: 5.92242e-04
I0513 14:46:36.152260 22485033404224 run_lib.py:146] step: 297800, training_loss: 6.36988e-04
I0513 14:46:36.312299 22485033404224 run_lib.py:167] step: 297800, eval_loss: 5.79788e-04
I0513 14:46:59.898160 22485033404224 run_lib.py:146] step: 297850, training_loss: 7.83155e-04
I0513 14:47:23.814794 22485033404224 run_lib.py:146] step: 297900, training_loss: 5.16364e-04
I0513 14:47:23.975056 22485033404224 run_lib.py:167] step: 297900, eval_loss: 7.08024e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 14:47:47.981747 22485033404224 run_lib.py:146] step: 297950, training_loss: 5.71708e-04
I0513 14:48:11.544821 22485033404224 run_lib.py:146] step: 298000, training_loss: 5.62427e-04
I0513 14:48:11.705772 22485033404224 run_lib.py:167] step: 298000, eval_loss: 5.67688e-04
I0513 14:48:35.729447 22485033404224 run_lib.py:146] step: 298050, training_loss: 6.21441e-04
I0513 14:48:59.298667 22485033404224 run_lib.py:146] step: 298100, training_loss: 5.96580e-04
I0513 14:48:59.459081 22485033404224 run_lib.py:167] step: 298100, eval_loss: 6.52251e-04
I0513 14:49:23.306711 22485033404224 run_lib.py:146] step: 298150, training_loss: 5.23302e-04
I0513 14:49:47.267536 22485033404224 run_lib.py:146] step: 298200, training_loss: 4.62100e-04
I0513 14:49:47.427349 22485033404224 run_lib.py:167] step: 298200, eval_loss: 5.92912e-04
I0513 14:50:10.981500 22485033404224 run_lib.py:146] step: 298250, training_loss: 6.51352e-04
I0513 14:50:34.855358 22485033404224 run_lib.py:146] step: 298300, training_loss: 7.19146e-04
I0513 14:50:35.015648 22485033404224 run_lib.py:167] step: 298300, eval_loss: 6.63454e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 14:50:59.026386 22485033404224 run_lib.py:146] step: 298350, training_loss: 6.10567e-04
I0513 14:51:22.594759 22485033404224 run_lib.py:146] step: 298400, training_loss: 5.13409e-04
I0513 14:51:22.756804 22485033404224 run_lib.py:167] step: 298400, eval_loss: 6.58624e-04
I0513 14:51:46.790181 22485033404224 run_lib.py:146] step: 298450, training_loss: 3.14931e-04
I0513 14:52:10.394601 22485033404224 run_lib.py:146] step: 298500, training_loss: 5.70545e-04
I0513 14:52:10.555058 22485033404224 run_lib.py:167] step: 298500, eval_loss: 7.16517e-04
I0513 14:52:34.462369 22485033404224 run_lib.py:146] step: 298550, training_loss: 6.40292e-04
I0513 14:52:58.445967 22485033404224 run_lib.py:146] step: 298600, training_loss: 6.77898e-04
I0513 14:52:58.606187 22485033404224 run_lib.py:167] step: 298600, eval_loss: 5.72573e-04
I0513 14:53:22.193198 22485033404224 run_lib.py:146] step: 298650, training_loss: 6.94484e-04
I0513 14:53:46.113705 22485033404224 run_lib.py:146] step: 298700, training_loss: 5.62885e-04
I0513 14:53:46.273966 22485033404224 run_lib.py:167] step: 298700, eval_loss: 4.66559e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 14:54:10.317975 22485033404224 run_lib.py:146] step: 298750, training_loss: 6.90538e-04
I0513 14:54:33.835621 22485033404224 run_lib.py:146] step: 298800, training_loss: 5.62636e-04
I0513 14:54:33.996462 22485033404224 run_lib.py:167] step: 298800, eval_loss: 6.57457e-04
I0513 14:54:57.842092 22485033404224 run_lib.py:146] step: 298850, training_loss: 4.44485e-04
I0513 14:55:21.643952 22485033404224 run_lib.py:146] step: 298900, training_loss: 4.76218e-04
I0513 14:55:21.802031 22485033404224 run_lib.py:167] step: 298900, eval_loss: 6.18075e-04
I0513 14:55:45.306107 22485033404224 run_lib.py:146] step: 298950, training_loss: 8.19715e-04
I0513 14:56:09.109178 22485033404224 run_lib.py:146] step: 299000, training_loss: 5.36073e-04
I0513 14:56:09.268689 22485033404224 run_lib.py:167] step: 299000, eval_loss: 8.69591e-04
I0513 14:56:32.794674 22485033404224 run_lib.py:146] step: 299050, training_loss: 8.40464e-04
I0513 14:56:56.622042 22485033404224 run_lib.py:146] step: 299100, training_loss: 5.33039e-04
I0513 14:56:56.780349 22485033404224 run_lib.py:167] step: 299100, eval_loss: 5.39278e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 14:57:20.726083 22485033404224 run_lib.py:146] step: 299150, training_loss: 6.52964e-04
I0513 14:57:44.261699 22485033404224 run_lib.py:146] step: 299200, training_loss: 6.40665e-04
I0513 14:57:44.423292 22485033404224 run_lib.py:167] step: 299200, eval_loss: 5.07417e-04
I0513 14:58:08.280280 22485033404224 run_lib.py:146] step: 299250, training_loss: 3.83987e-04
I0513 14:58:31.811250 22485033404224 run_lib.py:146] step: 299300, training_loss: 6.14233e-04
I0513 14:58:31.970233 22485033404224 run_lib.py:167] step: 299300, eval_loss: 5.87525e-04
I0513 14:58:55.795289 22485033404224 run_lib.py:146] step: 299350, training_loss: 5.57236e-04
I0513 14:59:19.637499 22485033404224 run_lib.py:146] step: 299400, training_loss: 7.46461e-04
I0513 14:59:19.796805 22485033404224 run_lib.py:167] step: 299400, eval_loss: 6.42532e-04
I0513 14:59:43.320671 22485033404224 run_lib.py:146] step: 299450, training_loss: 5.57349e-04
I0513 15:00:07.131418 22485033404224 run_lib.py:146] step: 299500, training_loss: 5.59965e-04
I0513 15:00:07.290919 22485033404224 run_lib.py:167] step: 299500, eval_loss: 4.78590e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 15:00:31.228339 22485033404224 run_lib.py:146] step: 299550, training_loss: 7.98587e-04
I0513 15:00:54.746206 22485033404224 run_lib.py:146] step: 299600, training_loss: 7.41821e-04
I0513 15:00:54.907104 22485033404224 run_lib.py:167] step: 299600, eval_loss: 6.44343e-04
I0513 15:01:18.743639 22485033404224 run_lib.py:146] step: 299650, training_loss: 5.67101e-04
I0513 15:01:42.548976 22485033404224 run_lib.py:146] step: 299700, training_loss: 5.45964e-04
I0513 15:01:42.708148 22485033404224 run_lib.py:167] step: 299700, eval_loss: 7.53601e-04
I0513 15:02:06.227877 22485033404224 run_lib.py:146] step: 299750, training_loss: 6.24804e-04
I0513 15:02:30.044631 22485033404224 run_lib.py:146] step: 299800, training_loss: 6.33548e-04
I0513 15:02:30.204437 22485033404224 run_lib.py:167] step: 299800, eval_loss: 6.48626e-04
I0513 15:02:53.704548 22485033404224 run_lib.py:146] step: 299850, training_loss: 5.88315e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 15:03:17.585544 22485033404224 run_lib.py:146] step: 299900, training_loss: 5.83315e-04
I0513 15:03:17.746658 22485033404224 run_lib.py:167] step: 299900, eval_loss: 7.27215e-04
I0513 15:03:41.615805 22485033404224 run_lib.py:146] step: 299950, training_loss: 4.99147e-04
I0513 15:04:05.135926 22485033404224 run_lib.py:146] step: 300000, training_loss: 6.98530e-04
I0513 15:04:07.243706 22485033404224 run_lib.py:167] step: 300000, eval_loss: 3.59424e-04
I0513 15:04:32.316947 22485033404224 run_lib.py:146] step: 300050, training_loss: 4.19802e-04
I0513 15:04:55.917796 22485033404224 run_lib.py:146] step: 300100, training_loss: 5.22479e-04
I0513 15:04:56.004263 22485033404224 run_lib.py:167] step: 300100, eval_loss: 1.03466e-03
I0513 15:05:20.204340 22485033404224 run_lib.py:146] step: 300150, training_loss: 5.69612e-04
I0513 15:05:43.801749 22485033404224 run_lib.py:146] step: 300200, training_loss: 6.89189e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 15:05:44.152823 22485033404224 run_lib.py:167] step: 300200, eval_loss: 6.45813e-04
I0513 15:06:07.747268 22485033404224 run_lib.py:146] step: 300250, training_loss: 5.92720e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 15:06:32.213577 22485033404224 run_lib.py:146] step: 300300, training_loss: 7.29532e-04
I0513 15:06:32.376218 22485033404224 run_lib.py:167] step: 300300, eval_loss: 5.62392e-04
I0513 15:06:55.965942 22485033404224 run_lib.py:146] step: 300350, training_loss: 7.27319e-04
I0513 15:07:19.527098 22485033404224 run_lib.py:146] step: 300400, training_loss: 6.63466e-04
I0513 15:07:19.688196 22485033404224 run_lib.py:167] step: 300400, eval_loss: 7.45875e-04
I0513 15:07:44.110143 22485033404224 run_lib.py:146] step: 300450, training_loss: 7.75104e-04
I0513 15:08:07.667366 22485033404224 run_lib.py:146] step: 300500, training_loss: 4.27915e-04
I0513 15:08:07.827352 22485033404224 run_lib.py:167] step: 300500, eval_loss: 6.30790e-04
I0513 15:08:31.388562 22485033404224 run_lib.py:146] step: 300550, training_loss: 6.43306e-04
I0513 15:08:55.380239 22485033404224 run_lib.py:146] step: 300600, training_loss: 5.96247e-04
I0513 15:08:55.540913 22485033404224 run_lib.py:167] step: 300600, eval_loss: 6.23207e-04
I0513 15:09:19.493058 22485033404224 run_lib.py:146] step: 300650, training_loss: 5.46091e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 15:09:43.176745 22485033404224 run_lib.py:146] step: 300700, training_loss: 7.18429e-04
I0513 15:09:43.339195 22485033404224 run_lib.py:167] step: 300700, eval_loss: 4.58111e-04
I0513 15:10:07.447801 22485033404224 run_lib.py:146] step: 300750, training_loss: 6.48115e-04
I0513 15:10:31.458681 22485033404224 run_lib.py:146] step: 300800, training_loss: 6.05862e-04
I0513 15:10:31.619589 22485033404224 run_lib.py:167] step: 300800, eval_loss: 5.48920e-04
I0513 15:10:55.225986 22485033404224 run_lib.py:146] step: 300850, training_loss: 6.76649e-04
I0513 15:11:19.225966 22485033404224 run_lib.py:146] step: 300900, training_loss: 4.98968e-04
I0513 15:11:19.386305 22485033404224 run_lib.py:167] step: 300900, eval_loss: 5.21231e-04
I0513 15:11:43.315389 22485033404224 run_lib.py:146] step: 300950, training_loss: 5.66380e-04
I0513 15:12:06.936450 22485033404224 run_lib.py:146] step: 301000, training_loss: 8.77296e-04
I0513 15:12:07.096946 22485033404224 run_lib.py:167] step: 301000, eval_loss: 6.07088e-04
I0513 15:12:30.670318 22485033404224 run_lib.py:146] step: 301050, training_loss: 6.42679e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 15:12:54.906146 22485033404224 run_lib.py:146] step: 301100, training_loss: 6.04386e-04
I0513 15:12:55.066661 22485033404224 run_lib.py:167] step: 301100, eval_loss: 5.31673e-04
I0513 15:13:18.577680 22485033404224 run_lib.py:146] step: 301150, training_loss: 5.69488e-04
I0513 15:13:42.107163 22485033404224 run_lib.py:146] step: 301200, training_loss: 5.42299e-04
I0513 15:13:42.265729 22485033404224 run_lib.py:167] step: 301200, eval_loss: 6.99597e-04
I0513 15:14:06.410393 22485033404224 run_lib.py:146] step: 301250, training_loss: 5.77930e-04
I0513 15:14:29.919498 22485033404224 run_lib.py:146] step: 301300, training_loss: 5.24355e-04
I0513 15:14:30.078206 22485033404224 run_lib.py:167] step: 301300, eval_loss: 7.08860e-04
I0513 15:14:53.583792 22485033404224 run_lib.py:146] step: 301350, training_loss: 7.78369e-04
I0513 15:15:17.403336 22485033404224 run_lib.py:146] step: 301400, training_loss: 4.97194e-04
I0513 15:15:17.563254 22485033404224 run_lib.py:167] step: 301400, eval_loss: 7.48814e-04
I0513 15:15:41.363517 22485033404224 run_lib.py:146] step: 301450, training_loss: 7.04865e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 15:16:04.974563 22485033404224 run_lib.py:146] step: 301500, training_loss: 5.49435e-04
I0513 15:16:05.135737 22485033404224 run_lib.py:167] step: 301500, eval_loss: 8.21473e-04
I0513 15:16:29.003462 22485033404224 run_lib.py:146] step: 301550, training_loss: 8.03012e-04
I0513 15:16:52.837503 22485033404224 run_lib.py:146] step: 301600, training_loss: 5.37454e-04
I0513 15:16:52.996465 22485033404224 run_lib.py:167] step: 301600, eval_loss: 6.98624e-04
I0513 15:17:16.510210 22485033404224 run_lib.py:146] step: 301650, training_loss: 7.32118e-04
I0513 15:17:40.332864 22485033404224 run_lib.py:146] step: 301700, training_loss: 7.80568e-04
I0513 15:17:40.492443 22485033404224 run_lib.py:167] step: 301700, eval_loss: 8.36584e-04
I0513 15:18:04.322302 22485033404224 run_lib.py:146] step: 301750, training_loss: 6.94024e-04
I0513 15:18:27.846764 22485033404224 run_lib.py:146] step: 301800, training_loss: 7.43214e-04
I0513 15:18:28.006819 22485033404224 run_lib.py:167] step: 301800, eval_loss: 5.78670e-04
I0513 15:18:51.816673 22485033404224 run_lib.py:146] step: 301850, training_loss: 7.19305e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 15:19:15.761424 22485033404224 run_lib.py:146] step: 301900, training_loss: 6.25435e-04
I0513 15:19:15.922117 22485033404224 run_lib.py:167] step: 301900, eval_loss: 5.15941e-04
I0513 15:19:39.432975 22485033404224 run_lib.py:146] step: 301950, training_loss: 5.92417e-04
I0513 15:20:02.944435 22485033404224 run_lib.py:146] step: 302000, training_loss: 5.74761e-04
I0513 15:20:03.105251 22485033404224 run_lib.py:167] step: 302000, eval_loss: 4.47971e-04
I0513 15:20:27.255922 22485033404224 run_lib.py:146] step: 302050, training_loss: 5.63177e-04
I0513 15:20:50.779730 22485033404224 run_lib.py:146] step: 302100, training_loss: 6.72938e-04
I0513 15:20:50.940614 22485033404224 run_lib.py:167] step: 302100, eval_loss: 5.62188e-04
I0513 15:21:14.468524 22485033404224 run_lib.py:146] step: 302150, training_loss: 6.59027e-04
I0513 15:21:38.302923 22485033404224 run_lib.py:146] step: 302200, training_loss: 6.20396e-04
I0513 15:21:38.464179 22485033404224 run_lib.py:167] step: 302200, eval_loss: 4.26178e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 15:22:02.359108 22485033404224 run_lib.py:146] step: 302250, training_loss: 7.45780e-04
I0513 15:22:25.885579 22485033404224 run_lib.py:146] step: 302300, training_loss: 5.79641e-04
I0513 15:22:26.046203 22485033404224 run_lib.py:167] step: 302300, eval_loss: 6.26582e-04
I0513 15:22:49.934918 22485033404224 run_lib.py:146] step: 302350, training_loss: 5.93822e-04
I0513 15:23:13.875357 22485033404224 run_lib.py:146] step: 302400, training_loss: 5.57405e-04
I0513 15:23:14.035337 22485033404224 run_lib.py:167] step: 302400, eval_loss: 7.94163e-04
I0513 15:23:37.625879 22485033404224 run_lib.py:146] step: 302450, training_loss: 8.20868e-04
I0513 15:24:01.508088 22485033404224 run_lib.py:146] step: 302500, training_loss: 5.25704e-04
I0513 15:24:01.668883 22485033404224 run_lib.py:167] step: 302500, eval_loss: 4.25249e-04
I0513 15:24:25.552590 22485033404224 run_lib.py:146] step: 302550, training_loss: 6.63155e-04
I0513 15:24:49.117192 22485033404224 run_lib.py:146] step: 302600, training_loss: 7.40286e-04
I0513 15:24:49.278252 22485033404224 run_lib.py:167] step: 302600, eval_loss: 5.82198e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 15:25:13.458878 22485033404224 run_lib.py:146] step: 302650, training_loss: 5.32444e-04
I0513 15:25:37.686106 22485033404224 run_lib.py:146] step: 302700, training_loss: 5.69935e-04
I0513 15:25:37.850020 22485033404224 run_lib.py:167] step: 302700, eval_loss: 5.81438e-04
I0513 15:26:01.577174 22485033404224 run_lib.py:146] step: 302750, training_loss: 7.50995e-04
I0513 15:26:25.314082 22485033404224 run_lib.py:146] step: 302800, training_loss: 6.68543e-04
I0513 15:26:25.476203 22485033404224 run_lib.py:167] step: 302800, eval_loss: 7.57604e-04
I0513 15:26:50.067222 22485033404224 run_lib.py:146] step: 302850, training_loss: 4.96255e-04
I0513 15:27:13.753073 22485033404224 run_lib.py:146] step: 302900, training_loss: 4.63230e-04
I0513 15:27:13.915271 22485033404224 run_lib.py:167] step: 302900, eval_loss: 4.54094e-04
I0513 15:27:37.469447 22485033404224 run_lib.py:146] step: 302950, training_loss: 5.37170e-04
I0513 15:28:01.767386 22485033404224 run_lib.py:146] step: 303000, training_loss: 4.77703e-04
I0513 15:28:01.927888 22485033404224 run_lib.py:167] step: 303000, eval_loss: 6.48014e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 15:28:25.575851 22485033404224 run_lib.py:146] step: 303050, training_loss: 4.76649e-04
I0513 15:28:49.140957 22485033404224 run_lib.py:146] step: 303100, training_loss: 6.59238e-04
I0513 15:28:49.302445 22485033404224 run_lib.py:167] step: 303100, eval_loss: 6.25547e-04
I0513 15:29:13.236171 22485033404224 run_lib.py:146] step: 303150, training_loss: 4.51279e-04
I0513 15:29:37.159548 22485033404224 run_lib.py:146] step: 303200, training_loss: 5.52347e-04
I0513 15:29:37.319787 22485033404224 run_lib.py:167] step: 303200, eval_loss: 7.51360e-04
I0513 15:30:00.833853 22485033404224 run_lib.py:146] step: 303250, training_loss: 8.03344e-04
I0513 15:30:24.634581 22485033404224 run_lib.py:146] step: 303300, training_loss: 7.98346e-04
I0513 15:30:24.794100 22485033404224 run_lib.py:167] step: 303300, eval_loss: 5.31241e-04
I0513 15:30:48.600251 22485033404224 run_lib.py:146] step: 303350, training_loss: 5.11630e-04
I0513 15:31:12.125934 22485033404224 run_lib.py:146] step: 303400, training_loss: 6.36032e-04
I0513 15:31:12.286695 22485033404224 run_lib.py:167] step: 303400, eval_loss: 6.40322e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 15:31:36.220542 22485033404224 run_lib.py:146] step: 303450, training_loss: 7.55234e-04
I0513 15:32:00.063668 22485033404224 run_lib.py:146] step: 303500, training_loss: 7.84766e-04
I0513 15:32:00.223799 22485033404224 run_lib.py:167] step: 303500, eval_loss: 5.61886e-04
I0513 15:32:23.746136 22485033404224 run_lib.py:146] step: 303550, training_loss: 6.94134e-04
I0513 15:32:47.259538 22485033404224 run_lib.py:146] step: 303600, training_loss: 5.46885e-04
I0513 15:32:47.418748 22485033404224 run_lib.py:167] step: 303600, eval_loss: 6.06950e-04
I0513 15:33:11.557843 22485033404224 run_lib.py:146] step: 303650, training_loss: 5.73339e-04
I0513 15:33:35.086330 22485033404224 run_lib.py:146] step: 303700, training_loss: 6.42765e-04
I0513 15:33:35.245367 22485033404224 run_lib.py:167] step: 303700, eval_loss: 4.65323e-04
I0513 15:33:58.758020 22485033404224 run_lib.py:146] step: 303750, training_loss: 4.07280e-04
I0513 15:34:22.875750 22485033404224 run_lib.py:146] step: 303800, training_loss: 5.01676e-04
I0513 15:34:23.035790 22485033404224 run_lib.py:167] step: 303800, eval_loss: 6.18286e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 15:34:46.601564 22485033404224 run_lib.py:146] step: 303850, training_loss: 5.26676e-04
I0513 15:35:10.085474 22485033404224 run_lib.py:146] step: 303900, training_loss: 5.49367e-04
I0513 15:35:10.246185 22485033404224 run_lib.py:167] step: 303900, eval_loss: 5.27185e-04
I0513 15:35:34.094953 22485033404224 run_lib.py:146] step: 303950, training_loss: 5.78550e-04
I0513 15:35:57.945271 22485033404224 run_lib.py:146] step: 304000, training_loss: 5.03210e-04
I0513 15:35:58.104498 22485033404224 run_lib.py:167] step: 304000, eval_loss: 5.57281e-04
I0513 15:36:21.605902 22485033404224 run_lib.py:146] step: 304050, training_loss: 7.16050e-04
I0513 15:36:45.420005 22485033404224 run_lib.py:146] step: 304100, training_loss: 5.91389e-04
I0513 15:36:45.578688 22485033404224 run_lib.py:167] step: 304100, eval_loss: 5.58416e-04
I0513 15:37:09.396090 22485033404224 run_lib.py:146] step: 304150, training_loss: 6.27163e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 15:37:32.971239 22485033404224 run_lib.py:146] step: 304200, training_loss: 6.34817e-04
I0513 15:37:33.132056 22485033404224 run_lib.py:167] step: 304200, eval_loss: 4.39079e-04
I0513 15:37:56.982800 22485033404224 run_lib.py:146] step: 304250, training_loss: 5.13863e-04
I0513 15:38:20.835872 22485033404224 run_lib.py:146] step: 304300, training_loss: 5.75643e-04
I0513 15:38:20.995639 22485033404224 run_lib.py:167] step: 304300, eval_loss: 5.50566e-04
I0513 15:38:44.509322 22485033404224 run_lib.py:146] step: 304350, training_loss: 5.01839e-04
I0513 15:39:08.319855 22485033404224 run_lib.py:146] step: 304400, training_loss: 4.96822e-04
I0513 15:39:08.478678 22485033404224 run_lib.py:167] step: 304400, eval_loss: 4.10622e-04
I0513 15:39:32.302107 22485033404224 run_lib.py:146] step: 304450, training_loss: 5.92619e-04
I0513 15:39:55.817988 22485033404224 run_lib.py:146] step: 304500, training_loss: 8.06204e-04
I0513 15:39:55.976934 22485033404224 run_lib.py:167] step: 304500, eval_loss: 4.30536e-04
I0513 15:40:19.489751 22485033404224 run_lib.py:146] step: 304550, training_loss: 6.20486e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 15:40:43.759938 22485033404224 run_lib.py:146] step: 304600, training_loss: 4.97599e-04
I0513 15:40:43.921652 22485033404224 run_lib.py:167] step: 304600, eval_loss: 5.27680e-04
I0513 15:41:07.519525 22485033404224 run_lib.py:146] step: 304650, training_loss: 6.31109e-04
I0513 15:41:31.110104 22485033404224 run_lib.py:146] step: 304700, training_loss: 5.82789e-04
I0513 15:41:31.270775 22485033404224 run_lib.py:167] step: 304700, eval_loss: 4.65589e-04
I0513 15:41:55.189509 22485033404224 run_lib.py:146] step: 304750, training_loss: 6.61295e-04
I0513 15:42:19.044541 22485033404224 run_lib.py:146] step: 304800, training_loss: 5.33897e-04
I0513 15:42:19.204934 22485033404224 run_lib.py:167] step: 304800, eval_loss: 6.37124e-04
I0513 15:42:42.793807 22485033404224 run_lib.py:146] step: 304850, training_loss: 8.01276e-04
I0513 15:43:06.691675 22485033404224 run_lib.py:146] step: 304900, training_loss: 6.64348e-04
I0513 15:43:06.852043 22485033404224 run_lib.py:167] step: 304900, eval_loss: 5.69663e-04
I0513 15:43:30.692596 22485033404224 run_lib.py:146] step: 304950, training_loss: 4.11874e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 15:43:54.328542 22485033404224 run_lib.py:146] step: 305000, training_loss: 6.42318e-04
I0513 15:43:54.491185 22485033404224 run_lib.py:167] step: 305000, eval_loss: 6.50530e-04
I0513 15:44:18.445595 22485033404224 run_lib.py:146] step: 305050, training_loss: 5.66056e-04
I0513 15:44:42.436032 22485033404224 run_lib.py:146] step: 305100, training_loss: 5.29626e-04
I0513 15:44:42.597024 22485033404224 run_lib.py:167] step: 305100, eval_loss: 7.52517e-04
I0513 15:45:06.193628 22485033404224 run_lib.py:146] step: 305150, training_loss: 6.49007e-04
I0513 15:45:30.106568 22485033404224 run_lib.py:146] step: 305200, training_loss: 5.94680e-04
I0513 15:45:30.267083 22485033404224 run_lib.py:167] step: 305200, eval_loss: 4.78334e-04
I0513 15:45:54.167680 22485033404224 run_lib.py:146] step: 305250, training_loss: 5.93959e-04
I0513 15:46:17.755372 22485033404224 run_lib.py:146] step: 305300, training_loss: 3.94405e-04
I0513 15:46:17.914993 22485033404224 run_lib.py:167] step: 305300, eval_loss: 7.46094e-04
I0513 15:46:41.498014 22485033404224 run_lib.py:146] step: 305350, training_loss: 6.55996e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 15:47:05.866274 22485033404224 run_lib.py:146] step: 305400, training_loss: 7.10821e-04
I0513 15:47:06.028784 22485033404224 run_lib.py:167] step: 305400, eval_loss: 4.44134e-04
I0513 15:47:29.593743 22485033404224 run_lib.py:146] step: 305450, training_loss: 6.14784e-04
I0513 15:47:53.129992 22485033404224 run_lib.py:146] step: 305500, training_loss: 9.07098e-04
I0513 15:47:53.288827 22485033404224 run_lib.py:167] step: 305500, eval_loss: 7.65968e-04
I0513 15:48:17.157918 22485033404224 run_lib.py:146] step: 305550, training_loss: 7.18333e-04
I0513 15:48:41.003760 22485033404224 run_lib.py:146] step: 305600, training_loss: 5.66159e-04
I0513 15:48:41.162833 22485033404224 run_lib.py:167] step: 305600, eval_loss: 4.41484e-04
I0513 15:49:04.696943 22485033404224 run_lib.py:146] step: 305650, training_loss: 5.57265e-04
I0513 15:49:28.526967 22485033404224 run_lib.py:146] step: 305700, training_loss: 6.44682e-04
I0513 15:49:28.686495 22485033404224 run_lib.py:167] step: 305700, eval_loss: 6.33954e-04
I0513 15:49:52.486098 22485033404224 run_lib.py:146] step: 305750, training_loss: 6.60428e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 15:50:16.079197 22485033404224 run_lib.py:146] step: 305800, training_loss: 5.45393e-04
I0513 15:50:16.241523 22485033404224 run_lib.py:167] step: 305800, eval_loss: 5.79604e-04
I0513 15:50:40.096609 22485033404224 run_lib.py:146] step: 305850, training_loss: 6.43668e-04
I0513 15:51:03.951186 22485033404224 run_lib.py:146] step: 305900, training_loss: 5.39058e-04
I0513 15:51:04.112208 22485033404224 run_lib.py:167] step: 305900, eval_loss: 5.56993e-04
I0513 15:51:27.642843 22485033404224 run_lib.py:146] step: 305950, training_loss: 6.08117e-04
I0513 15:51:51.478436 22485033404224 run_lib.py:146] step: 306000, training_loss: 5.94149e-04
I0513 15:51:51.638332 22485033404224 run_lib.py:167] step: 306000, eval_loss: 6.49693e-04
I0513 15:52:15.475449 22485033404224 run_lib.py:146] step: 306050, training_loss: 6.15810e-04
I0513 15:52:39.008470 22485033404224 run_lib.py:146] step: 306100, training_loss: 8.60330e-04
I0513 15:52:39.169765 22485033404224 run_lib.py:167] step: 306100, eval_loss: 7.87251e-04
I0513 15:53:03.019379 22485033404224 run_lib.py:146] step: 306150, training_loss: 5.47300e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 15:53:26.996655 22485033404224 run_lib.py:146] step: 306200, training_loss: 5.33899e-04
I0513 15:53:27.159152 22485033404224 run_lib.py:167] step: 306200, eval_loss: 5.59989e-04
I0513 15:53:50.676368 22485033404224 run_lib.py:146] step: 306250, training_loss: 8.33548e-04
I0513 15:54:14.206255 22485033404224 run_lib.py:146] step: 306300, training_loss: 6.25115e-04
I0513 15:54:14.365603 22485033404224 run_lib.py:167] step: 306300, eval_loss: 6.55977e-04
I0513 15:54:38.501173 22485033404224 run_lib.py:146] step: 306350, training_loss: 6.13007e-04
I0513 15:55:02.023713 22485033404224 run_lib.py:146] step: 306400, training_loss: 6.21692e-04
I0513 15:55:02.182998 22485033404224 run_lib.py:167] step: 306400, eval_loss: 5.36194e-04
I0513 15:55:25.695057 22485033404224 run_lib.py:146] step: 306450, training_loss: 8.21612e-04
I0513 15:55:49.517410 22485033404224 run_lib.py:146] step: 306500, training_loss: 7.37416e-04
I0513 15:55:49.676143 22485033404224 run_lib.py:167] step: 306500, eval_loss: 7.20570e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 15:56:13.541915 22485033404224 run_lib.py:146] step: 306550, training_loss: 5.36806e-04
I0513 15:56:37.051822 22485033404224 run_lib.py:146] step: 306600, training_loss: 6.47699e-04
I0513 15:56:37.211925 22485033404224 run_lib.py:167] step: 306600, eval_loss: 4.93519e-04
I0513 15:57:01.063333 22485033404224 run_lib.py:146] step: 306650, training_loss: 5.87825e-04
I0513 15:57:24.943590 22485033404224 run_lib.py:146] step: 306700, training_loss: 4.21855e-04
I0513 15:57:25.102015 22485033404224 run_lib.py:167] step: 306700, eval_loss: 6.92275e-04
I0513 15:57:48.656227 22485033404224 run_lib.py:146] step: 306750, training_loss: 5.50564e-04
I0513 15:58:12.555383 22485033404224 run_lib.py:146] step: 306800, training_loss: 5.98135e-04
I0513 15:58:12.715830 22485033404224 run_lib.py:167] step: 306800, eval_loss: 6.03121e-04
I0513 15:58:36.628885 22485033404224 run_lib.py:146] step: 306850, training_loss: 5.12551e-04
I0513 15:59:00.233871 22485033404224 run_lib.py:146] step: 306900, training_loss: 4.97953e-04
I0513 15:59:00.394369 22485033404224 run_lib.py:167] step: 306900, eval_loss: 6.55213e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 15:59:24.420411 22485033404224 run_lib.py:146] step: 306950, training_loss: 7.19267e-04
I0513 15:59:48.491795 22485033404224 run_lib.py:146] step: 307000, training_loss: 5.84635e-04
I0513 15:59:48.653456 22485033404224 run_lib.py:167] step: 307000, eval_loss: 5.54955e-04
I0513 16:00:12.247487 22485033404224 run_lib.py:146] step: 307050, training_loss: 6.14051e-04
I0513 16:00:36.131432 22485033404224 run_lib.py:146] step: 307100, training_loss: 4.01319e-04
I0513 16:00:36.291006 22485033404224 run_lib.py:167] step: 307100, eval_loss: 4.56963e-04
I0513 16:01:00.305453 22485033404224 run_lib.py:146] step: 307150, training_loss: 5.59182e-04
I0513 16:01:23.883757 22485033404224 run_lib.py:146] step: 307200, training_loss: 5.52200e-04
I0513 16:01:24.043830 22485033404224 run_lib.py:167] step: 307200, eval_loss: 7.58370e-04
I0513 16:01:47.646619 22485033404224 run_lib.py:146] step: 307250, training_loss: 6.94754e-04
I0513 16:02:11.585834 22485033404224 run_lib.py:146] step: 307300, training_loss: 5.71426e-04
I0513 16:02:11.747395 22485033404224 run_lib.py:167] step: 307300, eval_loss: 6.18576e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 16:02:35.826282 22485033404224 run_lib.py:146] step: 307350, training_loss: 7.12876e-04
I0513 16:02:59.433696 22485033404224 run_lib.py:146] step: 307400, training_loss: 5.52786e-04
I0513 16:02:59.594972 22485033404224 run_lib.py:167] step: 307400, eval_loss: 5.11683e-04
I0513 16:03:23.547412 22485033404224 run_lib.py:146] step: 307450, training_loss: 6.52242e-04
I0513 16:03:47.502204 22485033404224 run_lib.py:146] step: 307500, training_loss: 5.83104e-04
I0513 16:03:47.662113 22485033404224 run_lib.py:167] step: 307500, eval_loss: 7.39033e-04
I0513 16:04:11.245337 22485033404224 run_lib.py:146] step: 307550, training_loss: 4.51431e-04
I0513 16:04:35.159164 22485033404224 run_lib.py:146] step: 307600, training_loss: 5.43304e-04
I0513 16:04:35.319726 22485033404224 run_lib.py:167] step: 307600, eval_loss: 7.19200e-04
I0513 16:04:59.218017 22485033404224 run_lib.py:146] step: 307650, training_loss: 6.28081e-04
I0513 16:05:22.772818 22485033404224 run_lib.py:146] step: 307700, training_loss: 5.79517e-04
I0513 16:05:22.932566 22485033404224 run_lib.py:167] step: 307700, eval_loss: 7.02782e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 16:05:46.877042 22485033404224 run_lib.py:146] step: 307750, training_loss: 4.66494e-04
I0513 16:06:10.734682 22485033404224 run_lib.py:146] step: 307800, training_loss: 5.73243e-04
I0513 16:06:10.894753 22485033404224 run_lib.py:167] step: 307800, eval_loss: 5.16323e-04
I0513 16:06:34.406931 22485033404224 run_lib.py:146] step: 307850, training_loss: 5.87233e-04
I0513 16:06:58.221315 22485033404224 run_lib.py:146] step: 307900, training_loss: 7.99715e-04
I0513 16:06:58.379372 22485033404224 run_lib.py:167] step: 307900, eval_loss: 5.59876e-04
I0513 16:07:22.168439 22485033404224 run_lib.py:146] step: 307950, training_loss: 4.88538e-04
I0513 16:07:45.687897 22485033404224 run_lib.py:146] step: 308000, training_loss: 6.45242e-04
I0513 16:07:45.771895 22485033404224 run_lib.py:167] step: 308000, eval_loss: 5.18484e-04
I0513 16:08:09.573181 22485033404224 run_lib.py:146] step: 308050, training_loss: 6.01661e-04
I0513 16:08:33.083727 22485033404224 run_lib.py:146] step: 308100, training_loss: 6.46070e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 16:08:33.431386 22485033404224 run_lib.py:167] step: 308100, eval_loss: 5.74018e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 16:08:57.390801 22485033404224 run_lib.py:146] step: 308150, training_loss: 6.88180e-04
I0513 16:09:20.914477 22485033404224 run_lib.py:146] step: 308200, training_loss: 5.52024e-04
I0513 16:09:21.076453 22485033404224 run_lib.py:167] step: 308200, eval_loss: 5.78036e-04
I0513 16:09:44.961824 22485033404224 run_lib.py:146] step: 308250, training_loss: 6.39905e-04
I0513 16:10:08.853143 22485033404224 run_lib.py:146] step: 308300, training_loss: 4.16360e-04
I0513 16:10:09.013540 22485033404224 run_lib.py:167] step: 308300, eval_loss: 5.15635e-04
I0513 16:10:32.562881 22485033404224 run_lib.py:146] step: 308350, training_loss: 6.51795e-04
I0513 16:10:56.387253 22485033404224 run_lib.py:146] step: 308400, training_loss: 7.75243e-04
I0513 16:10:56.547193 22485033404224 run_lib.py:167] step: 308400, eval_loss: 6.20660e-04
I0513 16:11:20.380499 22485033404224 run_lib.py:146] step: 308450, training_loss: 6.51707e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 16:11:44.007338 22485033404224 run_lib.py:146] step: 308500, training_loss: 6.56977e-04
I0513 16:11:44.169609 22485033404224 run_lib.py:167] step: 308500, eval_loss: 4.86698e-04
I0513 16:12:08.065498 22485033404224 run_lib.py:146] step: 308550, training_loss: 7.51321e-04
I0513 16:12:31.954100 22485033404224 run_lib.py:146] step: 308600, training_loss: 6.02840e-04
I0513 16:12:32.113578 22485033404224 run_lib.py:167] step: 308600, eval_loss: 6.17158e-04
I0513 16:12:55.657329 22485033404224 run_lib.py:146] step: 308650, training_loss: 5.73379e-04
I0513 16:13:19.500793 22485033404224 run_lib.py:146] step: 308700, training_loss: 5.13575e-04
I0513 16:13:19.661041 22485033404224 run_lib.py:167] step: 308700, eval_loss: 5.24778e-04
I0513 16:13:43.517610 22485033404224 run_lib.py:146] step: 308750, training_loss: 6.98906e-04
I0513 16:14:07.078662 22485033404224 run_lib.py:146] step: 308800, training_loss: 6.95515e-04
I0513 16:14:07.237724 22485033404224 run_lib.py:167] step: 308800, eval_loss: 5.21131e-04
I0513 16:14:31.065950 22485033404224 run_lib.py:146] step: 308850, training_loss: 6.65427e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 16:14:54.687681 22485033404224 run_lib.py:146] step: 308900, training_loss: 5.89709e-04
I0513 16:14:54.849292 22485033404224 run_lib.py:167] step: 308900, eval_loss: 7.16981e-04
I0513 16:15:18.720527 22485033404224 run_lib.py:146] step: 308950, training_loss: 7.50414e-04
I0513 16:15:42.310307 22485033404224 run_lib.py:146] step: 309000, training_loss: 6.43005e-04
I0513 16:15:42.471106 22485033404224 run_lib.py:167] step: 309000, eval_loss: 6.30900e-04
I0513 16:16:06.396935 22485033404224 run_lib.py:146] step: 309050, training_loss: 6.79609e-04
I0513 16:16:30.319848 22485033404224 run_lib.py:146] step: 309100, training_loss: 5.36763e-04
I0513 16:16:30.480438 22485033404224 run_lib.py:167] step: 309100, eval_loss: 5.93512e-04
I0513 16:16:54.076503 22485033404224 run_lib.py:146] step: 309150, training_loss: 6.35286e-04
I0513 16:17:18.004650 22485033404224 run_lib.py:146] step: 309200, training_loss: 7.23062e-04
I0513 16:17:18.164498 22485033404224 run_lib.py:167] step: 309200, eval_loss: 7.61988e-04
I0513 16:17:42.081610 22485033404224 run_lib.py:146] step: 309250, training_loss: 6.07427e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 16:18:05.741316 22485033404224 run_lib.py:146] step: 309300, training_loss: 5.97715e-04
I0513 16:18:05.904004 22485033404224 run_lib.py:167] step: 309300, eval_loss: 5.34834e-04
I0513 16:18:29.865440 22485033404224 run_lib.py:146] step: 309350, training_loss: 7.82463e-04
I0513 16:18:53.901775 22485033404224 run_lib.py:146] step: 309400, training_loss: 6.27523e-04
I0513 16:18:54.061668 22485033404224 run_lib.py:167] step: 309400, eval_loss: 5.59913e-04
I0513 16:19:17.649046 22485033404224 run_lib.py:146] step: 309450, training_loss: 6.14149e-04
I0513 16:19:41.578301 22485033404224 run_lib.py:146] step: 309500, training_loss: 7.54845e-04
I0513 16:19:41.739554 22485033404224 run_lib.py:167] step: 309500, eval_loss: 7.66640e-04
I0513 16:20:05.750067 22485033404224 run_lib.py:146] step: 309550, training_loss: 6.59900e-04
I0513 16:20:29.322093 22485033404224 run_lib.py:146] step: 309600, training_loss: 7.32475e-04
I0513 16:20:29.482528 22485033404224 run_lib.py:167] step: 309600, eval_loss: 6.50123e-04
I0513 16:20:53.400726 22485033404224 run_lib.py:146] step: 309650, training_loss: 6.15356e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 16:21:17.555142 22485033404224 run_lib.py:146] step: 309700, training_loss: 5.27429e-04
I0513 16:21:17.717150 22485033404224 run_lib.py:167] step: 309700, eval_loss: 5.08054e-04
I0513 16:21:41.277875 22485033404224 run_lib.py:146] step: 309750, training_loss: 5.57445e-04
I0513 16:22:05.221525 22485033404224 run_lib.py:146] step: 309800, training_loss: 5.70555e-04
I0513 16:22:05.385047 22485033404224 run_lib.py:167] step: 309800, eval_loss: 5.48787e-04
I0513 16:22:28.969103 22485033404224 run_lib.py:146] step: 309850, training_loss: 5.12712e-04
I0513 16:22:52.894355 22485033404224 run_lib.py:146] step: 309900, training_loss: 4.60932e-04
I0513 16:22:53.054179 22485033404224 run_lib.py:167] step: 309900, eval_loss: 7.63157e-04
I0513 16:23:16.566125 22485033404224 run_lib.py:146] step: 309950, training_loss: 7.28449e-04
I0513 16:23:40.370700 22485033404224 run_lib.py:146] step: 310000, training_loss: 7.01533e-04
I0513 16:23:42.387852 22485033404224 run_lib.py:167] step: 310000, eval_loss: 4.94483e-04
I0513 16:24:07.418571 22485033404224 run_lib.py:146] step: 310050, training_loss: 7.07113e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 16:24:31.013266 22485033404224 run_lib.py:146] step: 310100, training_loss: 7.45214e-04
I0513 16:24:31.174508 22485033404224 run_lib.py:167] step: 310100, eval_loss: 5.20155e-04
I0513 16:24:55.375305 22485033404224 run_lib.py:146] step: 310150, training_loss: 5.47492e-04
I0513 16:25:18.913223 22485033404224 run_lib.py:146] step: 310200, training_loss: 6.30697e-04
I0513 16:25:19.073655 22485033404224 run_lib.py:167] step: 310200, eval_loss: 6.46729e-04
I0513 16:25:42.589446 22485033404224 run_lib.py:146] step: 310250, training_loss: 6.97125e-04
I0513 16:26:06.710076 22485033404224 run_lib.py:146] step: 310300, training_loss: 5.39793e-04
I0513 16:26:06.869538 22485033404224 run_lib.py:167] step: 310300, eval_loss: 5.47856e-04
I0513 16:26:30.362292 22485033404224 run_lib.py:146] step: 310350, training_loss: 7.05112e-04
I0513 16:26:53.860353 22485033404224 run_lib.py:146] step: 310400, training_loss: 7.50252e-04
I0513 16:26:54.020191 22485033404224 run_lib.py:167] step: 310400, eval_loss: 5.69018e-04
I0513 16:27:18.136251 22485033404224 run_lib.py:146] step: 310450, training_loss: 4.79867e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 16:27:41.718066 22485033404224 run_lib.py:146] step: 310500, training_loss: 4.65563e-04
I0513 16:27:41.878237 22485033404224 run_lib.py:167] step: 310500, eval_loss: 6.25892e-04
I0513 16:28:05.382951 22485033404224 run_lib.py:146] step: 310550, training_loss: 3.88703e-04
I0513 16:28:29.239993 22485033404224 run_lib.py:146] step: 310600, training_loss: 7.76113e-04
I0513 16:28:29.399381 22485033404224 run_lib.py:167] step: 310600, eval_loss: 5.72512e-04
I0513 16:28:53.251056 22485033404224 run_lib.py:146] step: 310650, training_loss: 6.32458e-04
I0513 16:29:16.766554 22485033404224 run_lib.py:146] step: 310700, training_loss: 6.69452e-04
I0513 16:29:16.925271 22485033404224 run_lib.py:167] step: 310700, eval_loss: 6.36465e-04
I0513 16:29:40.739617 22485033404224 run_lib.py:146] step: 310750, training_loss: 6.93217e-04
I0513 16:30:04.570735 22485033404224 run_lib.py:146] step: 310800, training_loss: 4.44266e-04
I0513 16:30:04.729707 22485033404224 run_lib.py:167] step: 310800, eval_loss: 3.94549e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 16:30:28.327757 22485033404224 run_lib.py:146] step: 310850, training_loss: 4.59561e-04
I0513 16:30:51.845361 22485033404224 run_lib.py:146] step: 310900, training_loss: 5.89043e-04
I0513 16:30:52.005591 22485033404224 run_lib.py:167] step: 310900, eval_loss: 6.82886e-04
I0513 16:31:16.184366 22485033404224 run_lib.py:146] step: 310950, training_loss: 4.86529e-04
I0513 16:31:39.702091 22485033404224 run_lib.py:146] step: 311000, training_loss: 7.43056e-04
I0513 16:31:39.860642 22485033404224 run_lib.py:167] step: 311000, eval_loss: 4.28334e-04
I0513 16:32:03.361011 22485033404224 run_lib.py:146] step: 311050, training_loss: 6.32244e-04
I0513 16:32:27.499988 22485033404224 run_lib.py:146] step: 311100, training_loss: 5.96265e-04
I0513 16:32:27.660758 22485033404224 run_lib.py:167] step: 311100, eval_loss: 8.13093e-04
I0513 16:32:51.167793 22485033404224 run_lib.py:146] step: 311150, training_loss: 6.52904e-04
I0513 16:33:14.707281 22485033404224 run_lib.py:146] step: 311200, training_loss: 8.43089e-04
I0513 16:33:14.867402 22485033404224 run_lib.py:167] step: 311200, eval_loss: 6.97226e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 16:33:39.186955 22485033404224 run_lib.py:146] step: 311250, training_loss: 5.69718e-04
I0513 16:34:02.780094 22485033404224 run_lib.py:146] step: 311300, training_loss: 4.80604e-04
I0513 16:34:02.942748 22485033404224 run_lib.py:167] step: 311300, eval_loss: 4.23738e-04
I0513 16:34:26.542901 22485033404224 run_lib.py:146] step: 311350, training_loss: 4.65457e-04
I0513 16:34:50.525454 22485033404224 run_lib.py:146] step: 311400, training_loss: 4.80854e-04
I0513 16:34:50.687228 22485033404224 run_lib.py:167] step: 311400, eval_loss: 5.69239e-04
I0513 16:35:14.563723 22485033404224 run_lib.py:146] step: 311450, training_loss: 6.90056e-04
I0513 16:35:38.158543 22485033404224 run_lib.py:146] step: 311500, training_loss: 5.68413e-04
I0513 16:35:38.318104 22485033404224 run_lib.py:167] step: 311500, eval_loss: 6.49697e-04
I0513 16:36:02.200757 22485033404224 run_lib.py:146] step: 311550, training_loss: 5.23743e-04
I0513 16:36:26.074424 22485033404224 run_lib.py:146] step: 311600, training_loss: 6.75081e-04
I0513 16:36:26.234591 22485033404224 run_lib.py:167] step: 311600, eval_loss: 6.82197e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 16:36:49.869289 22485033404224 run_lib.py:146] step: 311650, training_loss: 5.72637e-04
I0513 16:37:13.461093 22485033404224 run_lib.py:146] step: 311700, training_loss: 6.13051e-04
I0513 16:37:13.624027 22485033404224 run_lib.py:167] step: 311700, eval_loss: 6.82132e-04
I0513 16:37:37.925199 22485033404224 run_lib.py:146] step: 311750, training_loss: 5.68313e-04
I0513 16:38:01.531476 22485033404224 run_lib.py:146] step: 311800, training_loss: 6.62137e-04
I0513 16:38:01.690942 22485033404224 run_lib.py:167] step: 311800, eval_loss: 5.19790e-04
I0513 16:38:25.306779 22485033404224 run_lib.py:146] step: 311850, training_loss: 5.28257e-04
I0513 16:38:49.523697 22485033404224 run_lib.py:146] step: 311900, training_loss: 4.86442e-04
I0513 16:38:49.683534 22485033404224 run_lib.py:167] step: 311900, eval_loss: 5.19309e-04
I0513 16:39:13.270854 22485033404224 run_lib.py:146] step: 311950, training_loss: 4.83020e-04
I0513 16:39:36.869181 22485033404224 run_lib.py:146] step: 312000, training_loss: 7.57583e-04
I0513 16:39:37.029928 22485033404224 run_lib.py:167] step: 312000, eval_loss: 5.61151e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 16:40:01.415170 22485033404224 run_lib.py:146] step: 312050, training_loss: 5.73540e-04
I0513 16:40:24.992461 22485033404224 run_lib.py:146] step: 312100, training_loss: 6.63998e-04
I0513 16:40:25.153765 22485033404224 run_lib.py:167] step: 312100, eval_loss: 7.50439e-04
I0513 16:40:48.713390 22485033404224 run_lib.py:146] step: 312150, training_loss: 6.15004e-04
I0513 16:41:12.868344 22485033404224 run_lib.py:146] step: 312200, training_loss: 5.08264e-04
I0513 16:41:13.027101 22485033404224 run_lib.py:167] step: 312200, eval_loss: 5.63693e-04
I0513 16:41:36.551692 22485033404224 run_lib.py:146] step: 312250, training_loss: 6.29922e-04
I0513 16:42:00.085939 22485033404224 run_lib.py:146] step: 312300, training_loss: 7.15646e-04
I0513 16:42:00.246196 22485033404224 run_lib.py:167] step: 312300, eval_loss: 5.16246e-04
I0513 16:42:24.063566 22485033404224 run_lib.py:146] step: 312350, training_loss: 5.92945e-04
I0513 16:42:47.901072 22485033404224 run_lib.py:146] step: 312400, training_loss: 5.39126e-04
I0513 16:42:48.061044 22485033404224 run_lib.py:167] step: 312400, eval_loss: 6.04359e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 16:43:11.659338 22485033404224 run_lib.py:146] step: 312450, training_loss: 5.33717e-04
I0513 16:43:35.185266 22485033404224 run_lib.py:146] step: 312500, training_loss: 6.43864e-04
I0513 16:43:35.345956 22485033404224 run_lib.py:167] step: 312500, eval_loss: 6.50952e-04
I0513 16:43:59.528853 22485033404224 run_lib.py:146] step: 312550, training_loss: 7.16768e-04
I0513 16:44:23.050819 22485033404224 run_lib.py:146] step: 312600, training_loss: 4.50704e-04
I0513 16:44:23.210383 22485033404224 run_lib.py:167] step: 312600, eval_loss: 8.19243e-04
I0513 16:44:46.751960 22485033404224 run_lib.py:146] step: 312650, training_loss: 5.94773e-04
I0513 16:45:10.866662 22485033404224 run_lib.py:146] step: 312700, training_loss: 8.06395e-04
I0513 16:45:11.025537 22485033404224 run_lib.py:167] step: 312700, eval_loss: 7.16656e-04
I0513 16:45:34.553824 22485033404224 run_lib.py:146] step: 312750, training_loss: 7.13301e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 16:45:58.149583 22485033404224 run_lib.py:146] step: 312800, training_loss: 5.30619e-04
I0513 16:45:58.310070 22485033404224 run_lib.py:167] step: 312800, eval_loss: 5.98920e-04
I0513 16:46:22.505494 22485033404224 run_lib.py:146] step: 312850, training_loss: 6.95069e-04
I0513 16:46:46.009835 22485033404224 run_lib.py:146] step: 312900, training_loss: 8.02499e-04
I0513 16:46:46.170284 22485033404224 run_lib.py:167] step: 312900, eval_loss: 6.19060e-04
I0513 16:47:09.674487 22485033404224 run_lib.py:146] step: 312950, training_loss: 7.06750e-04
I0513 16:47:33.803307 22485033404224 run_lib.py:146] step: 313000, training_loss: 6.12855e-04
I0513 16:47:33.961906 22485033404224 run_lib.py:167] step: 313000, eval_loss: 6.88532e-04
I0513 16:47:57.469963 22485033404224 run_lib.py:146] step: 313050, training_loss: 6.66761e-04
I0513 16:48:20.974639 22485033404224 run_lib.py:146] step: 313100, training_loss: 6.67828e-04
I0513 16:48:21.135543 22485033404224 run_lib.py:167] step: 313100, eval_loss: 5.08938e-04
I0513 16:48:44.951935 22485033404224 run_lib.py:146] step: 313150, training_loss: 6.56083e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 16:49:08.816119 22485033404224 run_lib.py:146] step: 313200, training_loss: 5.57032e-04
I0513 16:49:08.977014 22485033404224 run_lib.py:167] step: 313200, eval_loss: 7.05798e-04
I0513 16:49:32.521453 22485033404224 run_lib.py:146] step: 313250, training_loss: 7.15880e-04
I0513 16:49:56.057948 22485033404224 run_lib.py:146] step: 313300, training_loss: 5.97352e-04
I0513 16:49:56.217266 22485033404224 run_lib.py:167] step: 313300, eval_loss: 7.52504e-04
I0513 16:50:20.430621 22485033404224 run_lib.py:146] step: 313350, training_loss: 5.38054e-04
I0513 16:50:43.969875 22485033404224 run_lib.py:146] step: 313400, training_loss: 6.62525e-04
I0513 16:50:44.129215 22485033404224 run_lib.py:167] step: 313400, eval_loss: 8.22756e-04
I0513 16:51:07.725984 22485033404224 run_lib.py:146] step: 313450, training_loss: 3.72294e-04
I0513 16:51:31.946824 22485033404224 run_lib.py:146] step: 313500, training_loss: 8.94505e-04
I0513 16:51:32.107583 22485033404224 run_lib.py:167] step: 313500, eval_loss: 4.62712e-04
I0513 16:51:55.708284 22485033404224 run_lib.py:146] step: 313550, training_loss: 5.64347e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 16:52:19.411699 22485033404224 run_lib.py:146] step: 313600, training_loss: 3.92752e-04
I0513 16:52:19.573787 22485033404224 run_lib.py:167] step: 313600, eval_loss: 6.19562e-04
I0513 16:52:44.065002 22485033404224 run_lib.py:146] step: 313650, training_loss: 6.52120e-04
I0513 16:53:07.664544 22485033404224 run_lib.py:146] step: 313700, training_loss: 5.01750e-04
I0513 16:53:07.823890 22485033404224 run_lib.py:167] step: 313700, eval_loss: 5.00295e-04
I0513 16:53:31.405656 22485033404224 run_lib.py:146] step: 313750, training_loss: 6.28241e-04
I0513 16:53:55.817519 22485033404224 run_lib.py:146] step: 313800, training_loss: 5.86851e-04
I0513 16:53:55.977677 22485033404224 run_lib.py:167] step: 313800, eval_loss: 4.20641e-04
I0513 16:54:19.514338 22485033404224 run_lib.py:146] step: 313850, training_loss: 7.99348e-04
I0513 16:54:43.072659 22485033404224 run_lib.py:146] step: 313900, training_loss: 6.64451e-04
I0513 16:54:43.232720 22485033404224 run_lib.py:167] step: 313900, eval_loss: 6.30350e-04
I0513 16:55:07.229007 22485033404224 run_lib.py:146] step: 313950, training_loss: 8.30485e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 16:55:31.302202 22485033404224 run_lib.py:146] step: 314000, training_loss: 4.82904e-04
I0513 16:55:31.463307 22485033404224 run_lib.py:167] step: 314000, eval_loss: 6.16611e-04
I0513 16:55:55.075529 22485033404224 run_lib.py:146] step: 314050, training_loss: 7.09416e-04
I0513 16:56:18.679379 22485033404224 run_lib.py:146] step: 314100, training_loss: 6.98647e-04
I0513 16:56:18.840439 22485033404224 run_lib.py:167] step: 314100, eval_loss: 5.11361e-04
I0513 16:56:43.109379 22485033404224 run_lib.py:146] step: 314150, training_loss: 7.79101e-04
I0513 16:57:06.687096 22485033404224 run_lib.py:146] step: 314200, training_loss: 4.67438e-04
I0513 16:57:06.847709 22485033404224 run_lib.py:167] step: 314200, eval_loss: 4.42020e-04
I0513 16:57:30.426586 22485033404224 run_lib.py:146] step: 314250, training_loss: 6.73208e-04
I0513 16:57:54.617133 22485033404224 run_lib.py:146] step: 314300, training_loss: 5.48934e-04
I0513 16:57:54.777217 22485033404224 run_lib.py:167] step: 314300, eval_loss: 6.36293e-04
I0513 16:58:18.309168 22485033404224 run_lib.py:146] step: 314350, training_loss: 4.91240e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 16:58:41.904780 22485033404224 run_lib.py:146] step: 314400, training_loss: 6.08009e-04
I0513 16:58:42.065688 22485033404224 run_lib.py:167] step: 314400, eval_loss: 5.51759e-04
I0513 16:59:06.283852 22485033404224 run_lib.py:146] step: 314450, training_loss: 6.80523e-04
I0513 16:59:29.826048 22485033404224 run_lib.py:146] step: 314500, training_loss: 6.06560e-04
I0513 16:59:29.985200 22485033404224 run_lib.py:167] step: 314500, eval_loss: 5.43768e-04
I0513 16:59:53.523165 22485033404224 run_lib.py:146] step: 314550, training_loss: 7.20424e-04
I0513 17:00:17.664367 22485033404224 run_lib.py:146] step: 314600, training_loss: 8.17744e-04
I0513 17:00:17.825048 22485033404224 run_lib.py:167] step: 314600, eval_loss: 6.64541e-04
I0513 17:00:41.357956 22485033404224 run_lib.py:146] step: 314650, training_loss: 5.90691e-04
I0513 17:01:04.901437 22485033404224 run_lib.py:146] step: 314700, training_loss: 4.60954e-04
I0513 17:01:05.060518 22485033404224 run_lib.py:167] step: 314700, eval_loss: 6.18441e-04
I0513 17:01:29.220479 22485033404224 run_lib.py:146] step: 314750, training_loss: 8.47199e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 17:01:52.846317 22485033404224 run_lib.py:146] step: 314800, training_loss: 7.84059e-04
I0513 17:01:53.006899 22485033404224 run_lib.py:167] step: 314800, eval_loss: 5.29148e-04
I0513 17:02:16.559832 22485033404224 run_lib.py:146] step: 314850, training_loss: 7.12560e-04
I0513 17:02:40.441035 22485033404224 run_lib.py:146] step: 314900, training_loss: 8.50378e-04
I0513 17:02:40.600689 22485033404224 run_lib.py:167] step: 314900, eval_loss: 7.11027e-04
I0513 17:03:04.464704 22485033404224 run_lib.py:146] step: 314950, training_loss: 6.71755e-04
I0513 17:03:28.029660 22485033404224 run_lib.py:146] step: 315000, training_loss: 6.22891e-04
I0513 17:03:28.189007 22485033404224 run_lib.py:167] step: 315000, eval_loss: 7.72001e-04
I0513 17:03:51.725836 22485033404224 run_lib.py:146] step: 315050, training_loss: 5.59381e-04
I0513 17:04:15.840687 22485033404224 run_lib.py:146] step: 315100, training_loss: 6.53124e-04
I0513 17:04:16.000394 22485033404224 run_lib.py:167] step: 315100, eval_loss: 7.27599e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 17:04:39.602309 22485033404224 run_lib.py:146] step: 315150, training_loss: 5.99279e-04
I0513 17:05:03.120939 22485033404224 run_lib.py:146] step: 315200, training_loss: 5.42233e-04
I0513 17:05:03.280679 22485033404224 run_lib.py:167] step: 315200, eval_loss: 6.25599e-04
I0513 17:05:27.466074 22485033404224 run_lib.py:146] step: 315250, training_loss: 6.47186e-04
I0513 17:05:50.986191 22485033404224 run_lib.py:146] step: 315300, training_loss: 5.04424e-04
I0513 17:05:51.144707 22485033404224 run_lib.py:167] step: 315300, eval_loss: 6.86774e-04
I0513 17:06:14.670130 22485033404224 run_lib.py:146] step: 315350, training_loss: 5.61212e-04
I0513 17:06:38.780961 22485033404224 run_lib.py:146] step: 315400, training_loss: 4.69602e-04
I0513 17:06:38.939790 22485033404224 run_lib.py:167] step: 315400, eval_loss: 6.29897e-04
I0513 17:07:02.463308 22485033404224 run_lib.py:146] step: 315450, training_loss: 6.70885e-04
I0513 17:07:26.008693 22485033404224 run_lib.py:146] step: 315500, training_loss: 5.77579e-04
I0513 17:07:26.168933 22485033404224 run_lib.py:167] step: 315500, eval_loss: 5.56207e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 17:07:50.428833 22485033404224 run_lib.py:146] step: 315550, training_loss: 5.22579e-04
I0513 17:08:13.964617 22485033404224 run_lib.py:146] step: 315600, training_loss: 6.06539e-04
I0513 17:08:14.125472 22485033404224 run_lib.py:167] step: 315600, eval_loss: 5.29997e-04
I0513 17:08:37.696143 22485033404224 run_lib.py:146] step: 315650, training_loss: 6.72258e-04
I0513 17:09:01.655821 22485033404224 run_lib.py:146] step: 315700, training_loss: 8.24809e-04
I0513 17:09:01.816911 22485033404224 run_lib.py:167] step: 315700, eval_loss: 6.49509e-04
I0513 17:09:25.739037 22485033404224 run_lib.py:146] step: 315750, training_loss: 6.13539e-04
I0513 17:09:49.336187 22485033404224 run_lib.py:146] step: 315800, training_loss: 5.92794e-04
I0513 17:09:49.496414 22485033404224 run_lib.py:167] step: 315800, eval_loss: 4.50101e-04
I0513 17:10:13.130052 22485033404224 run_lib.py:146] step: 315850, training_loss: 5.12369e-04
I0513 17:10:37.335067 22485033404224 run_lib.py:146] step: 315900, training_loss: 5.19016e-04
I0513 17:10:37.421726 22485033404224 run_lib.py:167] step: 315900, eval_loss: 8.40952e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 17:11:01.083563 22485033404224 run_lib.py:146] step: 315950, training_loss: 7.81713e-04
I0513 17:11:24.653704 22485033404224 run_lib.py:146] step: 316000, training_loss: 5.40016e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 17:11:25.004374 22485033404224 run_lib.py:167] step: 316000, eval_loss: 5.77549e-04
I0513 17:11:49.597899 22485033404224 run_lib.py:146] step: 316050, training_loss: 5.49713e-04
I0513 17:12:13.243678 22485033404224 run_lib.py:146] step: 316100, training_loss: 6.27473e-04
I0513 17:12:13.404107 22485033404224 run_lib.py:167] step: 316100, eval_loss: 6.39248e-04
I0513 17:12:37.057729 22485033404224 run_lib.py:146] step: 316150, training_loss: 8.75359e-04
I0513 17:13:01.524860 22485033404224 run_lib.py:146] step: 316200, training_loss: 4.32471e-04
I0513 17:13:01.686163 22485033404224 run_lib.py:167] step: 316200, eval_loss: 5.40689e-04
I0513 17:13:25.283372 22485033404224 run_lib.py:146] step: 316250, training_loss: 8.20863e-04
I0513 17:13:48.892690 22485033404224 run_lib.py:146] step: 316300, training_loss: 4.69627e-04
I0513 17:13:49.053152 22485033404224 run_lib.py:167] step: 316300, eval_loss: 4.35310e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 17:14:13.535452 22485033404224 run_lib.py:146] step: 316350, training_loss: 5.75296e-04
I0513 17:14:37.115068 22485033404224 run_lib.py:146] step: 316400, training_loss: 6.63437e-04
I0513 17:14:37.277383 22485033404224 run_lib.py:167] step: 316400, eval_loss: 6.13048e-04
I0513 17:15:00.893690 22485033404224 run_lib.py:146] step: 316450, training_loss: 4.58170e-04
I0513 17:15:24.822622 22485033404224 run_lib.py:146] step: 316500, training_loss: 7.77925e-04
I0513 17:15:24.983644 22485033404224 run_lib.py:167] step: 316500, eval_loss: 6.33075e-04
I0513 17:15:48.946191 22485033404224 run_lib.py:146] step: 316550, training_loss: 5.14628e-04
I0513 17:16:12.463647 22485033404224 run_lib.py:146] step: 316600, training_loss: 6.11025e-04
I0513 17:16:12.623764 22485033404224 run_lib.py:167] step: 316600, eval_loss: 4.74113e-04
I0513 17:16:36.445461 22485033404224 run_lib.py:146] step: 316650, training_loss: 4.67463e-04
I0513 17:17:00.276627 22485033404224 run_lib.py:146] step: 316700, training_loss: 5.49635e-04
I0513 17:17:00.436434 22485033404224 run_lib.py:167] step: 316700, eval_loss: 4.38640e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 17:17:24.033335 22485033404224 run_lib.py:146] step: 316750, training_loss: 4.34714e-04
I0513 17:17:47.582531 22485033404224 run_lib.py:146] step: 316800, training_loss: 6.96590e-04
I0513 17:17:47.743829 22485033404224 run_lib.py:167] step: 316800, eval_loss: 7.96207e-04
I0513 17:18:11.965699 22485033404224 run_lib.py:146] step: 316850, training_loss: 6.57945e-04
I0513 17:18:35.476735 22485033404224 run_lib.py:146] step: 316900, training_loss: 6.19054e-04
I0513 17:18:35.635784 22485033404224 run_lib.py:167] step: 316900, eval_loss: 7.15541e-04
I0513 17:18:59.144340 22485033404224 run_lib.py:146] step: 316950, training_loss: 6.46777e-04
I0513 17:19:23.272209 22485033404224 run_lib.py:146] step: 317000, training_loss: 6.49270e-04
I0513 17:19:23.431839 22485033404224 run_lib.py:167] step: 317000, eval_loss: 6.99270e-04
I0513 17:19:46.957915 22485033404224 run_lib.py:146] step: 317050, training_loss: 7.03453e-04
I0513 17:20:10.371048 22485033404224 run_lib.py:146] step: 317100, training_loss: 4.73821e-04
I0513 17:20:10.530793 22485033404224 run_lib.py:167] step: 317100, eval_loss: 6.99724e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 17:20:34.935849 22485033404224 run_lib.py:146] step: 317150, training_loss: 7.10906e-04
I0513 17:20:58.452767 22485033404224 run_lib.py:146] step: 317200, training_loss: 7.11812e-04
I0513 17:20:58.613773 22485033404224 run_lib.py:167] step: 317200, eval_loss: 6.94182e-04
I0513 17:21:22.127425 22485033404224 run_lib.py:146] step: 317250, training_loss: 5.42053e-04
I0513 17:21:45.937467 22485033404224 run_lib.py:146] step: 317300, training_loss: 8.08491e-04
I0513 17:21:46.098034 22485033404224 run_lib.py:167] step: 317300, eval_loss: 6.44429e-04
I0513 17:22:09.897386 22485033404224 run_lib.py:146] step: 317350, training_loss: 6.14582e-04
I0513 17:22:33.418984 22485033404224 run_lib.py:146] step: 317400, training_loss: 5.80385e-04
I0513 17:22:33.578960 22485033404224 run_lib.py:167] step: 317400, eval_loss: 6.34194e-04
I0513 17:22:57.375442 22485033404224 run_lib.py:146] step: 317450, training_loss: 3.90297e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 17:23:21.284289 22485033404224 run_lib.py:146] step: 317500, training_loss: 6.91976e-04
I0513 17:23:21.445061 22485033404224 run_lib.py:167] step: 317500, eval_loss: 6.84478e-04
I0513 17:23:44.969260 22485033404224 run_lib.py:146] step: 317550, training_loss: 4.68910e-04
I0513 17:24:08.828025 22485033404224 run_lib.py:146] step: 317600, training_loss: 5.53459e-04
I0513 17:24:08.987786 22485033404224 run_lib.py:167] step: 317600, eval_loss: 5.58271e-04
I0513 17:24:32.870394 22485033404224 run_lib.py:146] step: 317650, training_loss: 6.15714e-04
I0513 17:24:56.404888 22485033404224 run_lib.py:146] step: 317700, training_loss: 6.77957e-04
I0513 17:24:56.564803 22485033404224 run_lib.py:167] step: 317700, eval_loss: 6.05718e-04
I0513 17:25:20.093965 22485033404224 run_lib.py:146] step: 317750, training_loss: 6.21352e-04
I0513 17:25:44.230698 22485033404224 run_lib.py:146] step: 317800, training_loss: 5.95211e-04
I0513 17:25:44.390795 22485033404224 run_lib.py:167] step: 317800, eval_loss: 5.63819e-04
I0513 17:26:07.938283 22485033404224 run_lib.py:146] step: 317850, training_loss: 7.42543e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 17:26:31.641894 22485033404224 run_lib.py:146] step: 317900, training_loss: 8.39514e-04
I0513 17:26:31.804387 22485033404224 run_lib.py:167] step: 317900, eval_loss: 6.60254e-04
I0513 17:26:56.116694 22485033404224 run_lib.py:146] step: 317950, training_loss: 7.09406e-04
I0513 17:27:19.724936 22485033404224 run_lib.py:146] step: 318000, training_loss: 8.43021e-04
I0513 17:27:19.885761 22485033404224 run_lib.py:167] step: 318000, eval_loss: 6.16966e-04
I0513 17:27:43.507145 22485033404224 run_lib.py:146] step: 318050, training_loss: 6.82437e-04
I0513 17:28:07.424465 22485033404224 run_lib.py:146] step: 318100, training_loss: 5.63149e-04
I0513 17:28:07.585880 22485033404224 run_lib.py:167] step: 318100, eval_loss: 6.23423e-04
I0513 17:28:31.480076 22485033404224 run_lib.py:146] step: 318150, training_loss: 6.18477e-04
I0513 17:28:55.045698 22485033404224 run_lib.py:146] step: 318200, training_loss: 5.59605e-04
I0513 17:28:55.205937 22485033404224 run_lib.py:167] step: 318200, eval_loss: 6.79236e-04
I0513 17:29:19.095293 22485033404224 run_lib.py:146] step: 318250, training_loss: 6.39903e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 17:29:43.032995 22485033404224 run_lib.py:146] step: 318300, training_loss: 6.69928e-04
I0513 17:29:43.196108 22485033404224 run_lib.py:167] step: 318300, eval_loss: 5.54973e-04
I0513 17:30:06.794631 22485033404224 run_lib.py:146] step: 318350, training_loss: 5.87740e-04
I0513 17:30:30.789182 22485033404224 run_lib.py:146] step: 318400, training_loss: 7.92822e-04
I0513 17:30:30.949096 22485033404224 run_lib.py:167] step: 318400, eval_loss: 8.23263e-04
I0513 17:30:54.868847 22485033404224 run_lib.py:146] step: 318450, training_loss: 6.26681e-04
I0513 17:31:18.460825 22485033404224 run_lib.py:146] step: 318500, training_loss: 6.88145e-04
I0513 17:31:18.620651 22485033404224 run_lib.py:167] step: 318500, eval_loss: 7.48866e-04
I0513 17:31:42.226391 22485033404224 run_lib.py:146] step: 318550, training_loss: 8.21643e-04
I0513 17:32:06.432492 22485033404224 run_lib.py:146] step: 318600, training_loss: 6.90153e-04
I0513 17:32:06.592894 22485033404224 run_lib.py:167] step: 318600, eval_loss: 7.51265e-04
I0513 17:32:30.181164 22485033404224 run_lib.py:146] step: 318650, training_loss: 5.28836e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 17:32:53.875421 22485033404224 run_lib.py:146] step: 318700, training_loss: 6.67984e-04
I0513 17:32:54.036564 22485033404224 run_lib.py:167] step: 318700, eval_loss: 7.24597e-04
I0513 17:33:18.247298 22485033404224 run_lib.py:146] step: 318750, training_loss: 4.39863e-04
I0513 17:33:41.762206 22485033404224 run_lib.py:146] step: 318800, training_loss: 5.15265e-04
I0513 17:33:41.921735 22485033404224 run_lib.py:167] step: 318800, eval_loss: 5.38737e-04
I0513 17:34:05.430336 22485033404224 run_lib.py:146] step: 318850, training_loss: 3.59428e-04
I0513 17:34:29.238836 22485033404224 run_lib.py:146] step: 318900, training_loss: 4.29721e-04
I0513 17:34:29.399168 22485033404224 run_lib.py:167] step: 318900, eval_loss: 6.53236e-04
I0513 17:34:53.193047 22485033404224 run_lib.py:146] step: 318950, training_loss: 6.05528e-04
I0513 17:35:16.695689 22485033404224 run_lib.py:146] step: 319000, training_loss: 6.46581e-04
I0513 17:35:16.855240 22485033404224 run_lib.py:167] step: 319000, eval_loss: 6.09477e-04
I0513 17:35:40.656894 22485033404224 run_lib.py:146] step: 319050, training_loss: 5.18623e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 17:36:04.598298 22485033404224 run_lib.py:146] step: 319100, training_loss: 8.16815e-04
I0513 17:36:04.759054 22485033404224 run_lib.py:167] step: 319100, eval_loss: 4.89948e-04
I0513 17:36:28.274167 22485033404224 run_lib.py:146] step: 319150, training_loss: 6.34723e-04
I0513 17:36:52.107543 22485033404224 run_lib.py:146] step: 319200, training_loss: 5.36820e-04
I0513 17:36:52.266293 22485033404224 run_lib.py:167] step: 319200, eval_loss: 6.03309e-04
I0513 17:37:16.052269 22485033404224 run_lib.py:146] step: 319250, training_loss: 6.06541e-04
I0513 17:37:39.561641 22485033404224 run_lib.py:146] step: 319300, training_loss: 7.50135e-04
I0513 17:37:39.721239 22485033404224 run_lib.py:167] step: 319300, eval_loss: 4.62458e-04
I0513 17:38:03.238267 22485033404224 run_lib.py:146] step: 319350, training_loss: 6.64101e-04
I0513 17:38:27.358857 22485033404224 run_lib.py:146] step: 319400, training_loss: 6.49743e-04
I0513 17:38:27.518062 22485033404224 run_lib.py:167] step: 319400, eval_loss: 6.90193e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 17:38:51.115597 22485033404224 run_lib.py:146] step: 319450, training_loss: 5.43718e-04
I0513 17:39:14.630902 22485033404224 run_lib.py:146] step: 319500, training_loss: 4.84020e-04
I0513 17:39:14.791011 22485033404224 run_lib.py:167] step: 319500, eval_loss: 6.19761e-04
I0513 17:39:38.989387 22485033404224 run_lib.py:146] step: 319550, training_loss: 4.70952e-04
I0513 17:40:02.501409 22485033404224 run_lib.py:146] step: 319600, training_loss: 4.59114e-04
I0513 17:40:02.662213 22485033404224 run_lib.py:167] step: 319600, eval_loss: 5.80453e-04
I0513 17:40:26.184041 22485033404224 run_lib.py:146] step: 319650, training_loss: 7.76823e-04
I0513 17:40:50.001682 22485033404224 run_lib.py:146] step: 319700, training_loss: 7.49622e-04
I0513 17:40:50.163220 22485033404224 run_lib.py:167] step: 319700, eval_loss: 4.77966e-04
I0513 17:41:13.989277 22485033404224 run_lib.py:146] step: 319750, training_loss: 6.57825e-04
I0513 17:41:37.512328 22485033404224 run_lib.py:146] step: 319800, training_loss: 5.88778e-04
I0513 17:41:37.671669 22485033404224 run_lib.py:167] step: 319800, eval_loss: 5.03788e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 17:42:01.952020 22485033404224 run_lib.py:146] step: 319850, training_loss: 4.91611e-04
I0513 17:42:25.827091 22485033404224 run_lib.py:146] step: 319900, training_loss: 7.51228e-04
I0513 17:42:25.988359 22485033404224 run_lib.py:167] step: 319900, eval_loss: 6.49285e-04
I0513 17:42:49.517076 22485033404224 run_lib.py:146] step: 319950, training_loss: 6.15707e-04
I0513 17:43:13.350294 22485033404224 run_lib.py:146] step: 320000, training_loss: 5.61888e-04
I0513 17:43:15.055481 22485033404224 run_lib.py:167] step: 320000, eval_loss: 4.51490e-04
I0513 17:43:40.449750 22485033404224 run_lib.py:146] step: 320050, training_loss: 5.04556e-04
I0513 17:44:04.049373 22485033404224 run_lib.py:146] step: 320100, training_loss: 4.72580e-04
I0513 17:44:04.208934 22485033404224 run_lib.py:167] step: 320100, eval_loss: 5.95143e-04
I0513 17:44:28.145373 22485033404224 run_lib.py:146] step: 320150, training_loss: 8.20597e-04
I0513 17:44:52.046435 22485033404224 run_lib.py:146] step: 320200, training_loss: 5.18935e-04
I0513 17:44:52.207482 22485033404224 run_lib.py:167] step: 320200, eval_loss: 4.06759e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 17:45:15.877336 22485033404224 run_lib.py:146] step: 320250, training_loss: 5.03812e-04
I0513 17:45:39.461837 22485033404224 run_lib.py:146] step: 320300, training_loss: 8.61020e-04
I0513 17:45:39.623232 22485033404224 run_lib.py:167] step: 320300, eval_loss: 5.22632e-04
I0513 17:46:04.022186 22485033404224 run_lib.py:146] step: 320350, training_loss: 6.26747e-04
I0513 17:46:27.587248 22485033404224 run_lib.py:146] step: 320400, training_loss: 7.01167e-04
I0513 17:46:27.747856 22485033404224 run_lib.py:167] step: 320400, eval_loss: 7.01094e-04
I0513 17:46:51.331835 22485033404224 run_lib.py:146] step: 320450, training_loss: 3.76670e-04
I0513 17:47:15.608449 22485033404224 run_lib.py:146] step: 320500, training_loss: 6.16972e-04
I0513 17:47:15.768110 22485033404224 run_lib.py:167] step: 320500, eval_loss: 7.36346e-04
I0513 17:47:39.352411 22485033404224 run_lib.py:146] step: 320550, training_loss: 6.75941e-04
I0513 17:48:02.962938 22485033404224 run_lib.py:146] step: 320600, training_loss: 5.27395e-04
I0513 17:48:03.123075 22485033404224 run_lib.py:167] step: 320600, eval_loss: 5.55070e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 17:48:27.611993 22485033404224 run_lib.py:146] step: 320650, training_loss: 5.03544e-04
I0513 17:48:51.207853 22485033404224 run_lib.py:146] step: 320700, training_loss: 6.86737e-04
I0513 17:48:51.369546 22485033404224 run_lib.py:167] step: 320700, eval_loss: 5.56788e-04
I0513 17:49:14.964820 22485033404224 run_lib.py:146] step: 320750, training_loss: 5.71587e-04
I0513 17:49:39.151025 22485033404224 run_lib.py:146] step: 320800, training_loss: 5.64039e-04
I0513 17:49:39.311138 22485033404224 run_lib.py:167] step: 320800, eval_loss: 4.21294e-04
I0513 17:50:02.873326 22485033404224 run_lib.py:146] step: 320850, training_loss: 6.00882e-04
I0513 17:50:26.463602 22485033404224 run_lib.py:146] step: 320900, training_loss: 6.92063e-04
I0513 17:50:26.623173 22485033404224 run_lib.py:167] step: 320900, eval_loss: 4.82185e-04
I0513 17:50:50.780242 22485033404224 run_lib.py:146] step: 320950, training_loss: 5.55849e-04
I0513 17:51:14.293852 22485033404224 run_lib.py:146] step: 321000, training_loss: 7.50269e-04
I0513 17:51:14.452383 22485033404224 run_lib.py:167] step: 321000, eval_loss: 6.62713e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 17:51:38.044006 22485033404224 run_lib.py:146] step: 321050, training_loss: 6.27110e-04
I0513 17:52:01.900603 22485033404224 run_lib.py:146] step: 321100, training_loss: 7.30745e-04
I0513 17:52:02.060696 22485033404224 run_lib.py:167] step: 321100, eval_loss: 5.87428e-04
I0513 17:52:25.913727 22485033404224 run_lib.py:146] step: 321150, training_loss: 5.32429e-04
I0513 17:52:49.431619 22485033404224 run_lib.py:146] step: 321200, training_loss: 7.55885e-04
I0513 17:52:49.590734 22485033404224 run_lib.py:167] step: 321200, eval_loss: 5.95592e-04
I0513 17:53:13.103139 22485033404224 run_lib.py:146] step: 321250, training_loss: 6.35255e-04
I0513 17:53:37.203790 22485033404224 run_lib.py:146] step: 321300, training_loss: 6.61363e-04
I0513 17:53:37.362195 22485033404224 run_lib.py:167] step: 321300, eval_loss: 7.19683e-04
I0513 17:54:00.859204 22485033404224 run_lib.py:146] step: 321350, training_loss: 5.59358e-04
I0513 17:54:24.379323 22485033404224 run_lib.py:146] step: 321400, training_loss: 7.11345e-04
I0513 17:54:24.539054 22485033404224 run_lib.py:167] step: 321400, eval_loss: 5.30311e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 17:54:48.809436 22485033404224 run_lib.py:146] step: 321450, training_loss: 6.76994e-04
I0513 17:55:12.348253 22485033404224 run_lib.py:146] step: 321500, training_loss: 5.43842e-04
I0513 17:55:12.509070 22485033404224 run_lib.py:167] step: 321500, eval_loss: 5.97793e-04
I0513 17:55:36.032778 22485033404224 run_lib.py:146] step: 321550, training_loss: 6.86016e-04
I0513 17:56:00.155551 22485033404224 run_lib.py:146] step: 321600, training_loss: 5.63457e-04
I0513 17:56:00.315327 22485033404224 run_lib.py:167] step: 321600, eval_loss: 5.59030e-04
I0513 17:56:23.840586 22485033404224 run_lib.py:146] step: 321650, training_loss: 6.66709e-04
I0513 17:56:47.376682 22485033404224 run_lib.py:146] step: 321700, training_loss: 7.51755e-04
I0513 17:56:47.536418 22485033404224 run_lib.py:167] step: 321700, eval_loss: 7.18665e-04
I0513 17:57:11.652020 22485033404224 run_lib.py:146] step: 321750, training_loss: 6.24240e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 17:57:35.238979 22485033404224 run_lib.py:146] step: 321800, training_loss: 4.22522e-04
I0513 17:57:35.400163 22485033404224 run_lib.py:167] step: 321800, eval_loss: 7.65773e-04
I0513 17:57:58.931791 22485033404224 run_lib.py:146] step: 321850, training_loss: 5.40179e-04
I0513 17:58:22.813044 22485033404224 run_lib.py:146] step: 321900, training_loss: 5.67291e-04
I0513 17:58:22.972485 22485033404224 run_lib.py:167] step: 321900, eval_loss: 4.97327e-04
I0513 17:58:46.810034 22485033404224 run_lib.py:146] step: 321950, training_loss: 5.15332e-04
I0513 17:59:10.320768 22485033404224 run_lib.py:146] step: 322000, training_loss: 4.40092e-04
I0513 17:59:10.480482 22485033404224 run_lib.py:167] step: 322000, eval_loss: 5.69584e-04
I0513 17:59:34.328886 22485033404224 run_lib.py:146] step: 322050, training_loss: 5.83950e-04
I0513 17:59:58.187573 22485033404224 run_lib.py:146] step: 322100, training_loss: 5.27470e-04
I0513 17:59:58.346867 22485033404224 run_lib.py:167] step: 322100, eval_loss: 4.77938e-04
I0513 18:00:21.881874 22485033404224 run_lib.py:146] step: 322150, training_loss: 6.17886e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 18:00:45.481367 22485033404224 run_lib.py:146] step: 322200, training_loss: 6.33729e-04
I0513 18:00:45.643033 22485033404224 run_lib.py:167] step: 322200, eval_loss: 5.69504e-04
I0513 18:01:09.890611 22485033404224 run_lib.py:146] step: 322250, training_loss: 7.60737e-04
I0513 18:01:33.464144 22485033404224 run_lib.py:146] step: 322300, training_loss: 6.86403e-04
I0513 18:01:33.625842 22485033404224 run_lib.py:167] step: 322300, eval_loss: 5.61414e-04
I0513 18:01:57.234842 22485033404224 run_lib.py:146] step: 322350, training_loss: 4.65294e-04
I0513 18:02:21.477273 22485033404224 run_lib.py:146] step: 322400, training_loss: 4.96566e-04
I0513 18:02:21.637491 22485033404224 run_lib.py:167] step: 322400, eval_loss: 4.57085e-04
I0513 18:02:45.259641 22485033404224 run_lib.py:146] step: 322450, training_loss: 5.56333e-04
I0513 18:03:08.872307 22485033404224 run_lib.py:146] step: 322500, training_loss: 6.99797e-04
I0513 18:03:09.032680 22485033404224 run_lib.py:167] step: 322500, eval_loss: 6.23359e-04
I0513 18:03:33.202974 22485033404224 run_lib.py:146] step: 322550, training_loss: 6.42881e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 18:03:56.858366 22485033404224 run_lib.py:146] step: 322600, training_loss: 4.69367e-04
I0513 18:03:57.020949 22485033404224 run_lib.py:167] step: 322600, eval_loss: 7.02874e-04
I0513 18:04:20.614505 22485033404224 run_lib.py:146] step: 322650, training_loss: 8.52821e-04
I0513 18:04:44.652493 22485033404224 run_lib.py:146] step: 322700, training_loss: 5.50476e-04
I0513 18:04:44.812708 22485033404224 run_lib.py:167] step: 322700, eval_loss: 6.58254e-04
I0513 18:05:08.838818 22485033404224 run_lib.py:146] step: 322750, training_loss: 4.00133e-04
I0513 18:05:32.455934 22485033404224 run_lib.py:146] step: 322800, training_loss: 6.43187e-04
I0513 18:05:32.617574 22485033404224 run_lib.py:167] step: 322800, eval_loss: 5.07549e-04
I0513 18:05:56.644440 22485033404224 run_lib.py:146] step: 322850, training_loss: 7.85053e-04
I0513 18:06:20.641790 22485033404224 run_lib.py:146] step: 322900, training_loss: 4.88299e-04
I0513 18:06:20.803348 22485033404224 run_lib.py:167] step: 322900, eval_loss: 4.56951e-04
I0513 18:06:44.412374 22485033404224 run_lib.py:146] step: 322950, training_loss: 5.90997e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 18:07:08.123352 22485033404224 run_lib.py:146] step: 323000, training_loss: 6.65069e-04
I0513 18:07:08.285638 22485033404224 run_lib.py:167] step: 323000, eval_loss: 4.69578e-04
I0513 18:07:32.776401 22485033404224 run_lib.py:146] step: 323050, training_loss: 5.96039e-04
I0513 18:07:56.401142 22485033404224 run_lib.py:146] step: 323100, training_loss: 5.12759e-04
I0513 18:07:56.562170 22485033404224 run_lib.py:167] step: 323100, eval_loss: 6.69001e-04
I0513 18:08:20.172912 22485033404224 run_lib.py:146] step: 323150, training_loss: 4.97236e-04
I0513 18:08:44.509527 22485033404224 run_lib.py:146] step: 323200, training_loss: 5.53429e-04
I0513 18:08:44.670099 22485033404224 run_lib.py:167] step: 323200, eval_loss: 6.11541e-04
I0513 18:09:08.192622 22485033404224 run_lib.py:146] step: 323250, training_loss: 5.76503e-04
I0513 18:09:31.720155 22485033404224 run_lib.py:146] step: 323300, training_loss: 7.23181e-04
I0513 18:09:31.879344 22485033404224 run_lib.py:167] step: 323300, eval_loss: 4.84141e-04
I0513 18:09:55.992983 22485033404224 run_lib.py:146] step: 323350, training_loss: 6.30975e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 18:10:19.584618 22485033404224 run_lib.py:146] step: 323400, training_loss: 4.78611e-04
I0513 18:10:19.745833 22485033404224 run_lib.py:167] step: 323400, eval_loss: 6.03434e-04
I0513 18:10:43.269362 22485033404224 run_lib.py:146] step: 323450, training_loss: 5.97913e-04
I0513 18:11:07.108797 22485033404224 run_lib.py:146] step: 323500, training_loss: 7.89404e-04
I0513 18:11:07.268153 22485033404224 run_lib.py:167] step: 323500, eval_loss: 5.14883e-04
I0513 18:11:31.127966 22485033404224 run_lib.py:146] step: 323550, training_loss: 7.15335e-04
I0513 18:11:54.649563 22485033404224 run_lib.py:146] step: 323600, training_loss: 6.01124e-04
I0513 18:11:54.810649 22485033404224 run_lib.py:167] step: 323600, eval_loss: 5.11338e-04
I0513 18:12:18.615412 22485033404224 run_lib.py:146] step: 323650, training_loss: 6.60769e-04
I0513 18:12:42.446398 22485033404224 run_lib.py:146] step: 323700, training_loss: 5.57421e-04
I0513 18:12:42.606480 22485033404224 run_lib.py:167] step: 323700, eval_loss: 5.60283e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 18:13:06.209602 22485033404224 run_lib.py:146] step: 323750, training_loss: 7.02033e-04
I0513 18:13:29.729828 22485033404224 run_lib.py:146] step: 323800, training_loss: 6.86757e-04
I0513 18:13:29.818347 22485033404224 run_lib.py:167] step: 323800, eval_loss: 7.97256e-04
I0513 18:13:54.018017 22485033404224 run_lib.py:146] step: 323850, training_loss: 5.14953e-04
I0513 18:14:17.528782 22485033404224 run_lib.py:146] step: 323900, training_loss: 6.62540e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 18:14:17.874819 22485033404224 run_lib.py:167] step: 323900, eval_loss: 7.87937e-04
I0513 18:14:41.393711 22485033404224 run_lib.py:146] step: 323950, training_loss: 4.79692e-04
I0513 18:15:05.597206 22485033404224 run_lib.py:146] step: 324000, training_loss: 7.81900e-04
I0513 18:15:05.756076 22485033404224 run_lib.py:167] step: 324000, eval_loss: 4.22401e-04
I0513 18:15:29.280140 22485033404224 run_lib.py:146] step: 324050, training_loss: 6.61156e-04
I0513 18:15:52.812124 22485033404224 run_lib.py:146] step: 324100, training_loss: 7.07987e-04
I0513 18:15:52.973536 22485033404224 run_lib.py:167] step: 324100, eval_loss: 6.52765e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 18:16:17.193037 22485033404224 run_lib.py:146] step: 324150, training_loss: 8.46099e-04
I0513 18:16:40.738458 22485033404224 run_lib.py:146] step: 324200, training_loss: 5.10497e-04
I0513 18:16:40.900540 22485033404224 run_lib.py:167] step: 324200, eval_loss: 7.23717e-04
I0513 18:17:04.438004 22485033404224 run_lib.py:146] step: 324250, training_loss: 7.56671e-04
I0513 18:17:28.648282 22485033404224 run_lib.py:146] step: 324300, training_loss: 7.33003e-04
I0513 18:17:28.808043 22485033404224 run_lib.py:167] step: 324300, eval_loss: 6.09896e-04
I0513 18:17:52.334159 22485033404224 run_lib.py:146] step: 324350, training_loss: 6.81790e-04
I0513 18:18:15.873477 22485033404224 run_lib.py:146] step: 324400, training_loss: 4.99638e-04
I0513 18:18:16.032684 22485033404224 run_lib.py:167] step: 324400, eval_loss: 8.61204e-04
I0513 18:18:39.863144 22485033404224 run_lib.py:146] step: 324450, training_loss: 6.92491e-04
I0513 18:19:03.720596 22485033404224 run_lib.py:146] step: 324500, training_loss: 4.77906e-04
I0513 18:19:03.881097 22485033404224 run_lib.py:167] step: 324500, eval_loss: 7.22065e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 18:19:27.540330 22485033404224 run_lib.py:146] step: 324550, training_loss: 5.64980e-04
I0513 18:19:51.126904 22485033404224 run_lib.py:146] step: 324600, training_loss: 7.58202e-04
I0513 18:19:51.288539 22485033404224 run_lib.py:167] step: 324600, eval_loss: 7.81884e-04
I0513 18:20:15.547992 22485033404224 run_lib.py:146] step: 324650, training_loss: 8.58381e-04
I0513 18:20:39.137963 22485033404224 run_lib.py:146] step: 324700, training_loss: 5.09493e-04
I0513 18:20:39.298369 22485033404224 run_lib.py:167] step: 324700, eval_loss: 5.06774e-04
I0513 18:21:02.858144 22485033404224 run_lib.py:146] step: 324750, training_loss: 6.88253e-04
I0513 18:21:27.045751 22485033404224 run_lib.py:146] step: 324800, training_loss: 6.09848e-04
I0513 18:21:27.206820 22485033404224 run_lib.py:167] step: 324800, eval_loss: 6.08877e-04
I0513 18:21:50.782810 22485033404224 run_lib.py:146] step: 324850, training_loss: 6.58515e-04
I0513 18:22:14.361247 22485033404224 run_lib.py:146] step: 324900, training_loss: 7.67633e-04
I0513 18:22:14.520872 22485033404224 run_lib.py:167] step: 324900, eval_loss: 7.84876e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 18:22:39.059396 22485033404224 run_lib.py:146] step: 324950, training_loss: 7.17580e-04
I0513 18:23:02.636471 22485033404224 run_lib.py:146] step: 325000, training_loss: 4.43272e-04
I0513 18:23:02.798805 22485033404224 run_lib.py:167] step: 325000, eval_loss: 7.39410e-04
I0513 18:23:26.383865 22485033404224 run_lib.py:146] step: 325050, training_loss: 6.01471e-04
I0513 18:23:50.727025 22485033404224 run_lib.py:146] step: 325100, training_loss: 5.95578e-04
I0513 18:23:50.886364 22485033404224 run_lib.py:167] step: 325100, eval_loss: 8.34409e-04
I0513 18:24:14.483565 22485033404224 run_lib.py:146] step: 325150, training_loss: 5.03353e-04
I0513 18:24:38.089212 22485033404224 run_lib.py:146] step: 325200, training_loss: 6.88760e-04
I0513 18:24:38.249675 22485033404224 run_lib.py:167] step: 325200, eval_loss: 5.30699e-04
I0513 18:25:02.129279 22485033404224 run_lib.py:146] step: 325250, training_loss: 5.55953e-04
I0513 18:25:26.004293 22485033404224 run_lib.py:146] step: 325300, training_loss: 4.77290e-04
I0513 18:25:26.165238 22485033404224 run_lib.py:167] step: 325300, eval_loss: 5.61907e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 18:25:49.854302 22485033404224 run_lib.py:146] step: 325350, training_loss: 5.36484e-04
I0513 18:26:13.453600 22485033404224 run_lib.py:146] step: 325400, training_loss: 5.67495e-04
I0513 18:26:13.614443 22485033404224 run_lib.py:167] step: 325400, eval_loss: 7.09851e-04
I0513 18:26:37.791530 22485033404224 run_lib.py:146] step: 325450, training_loss: 6.33905e-04
I0513 18:27:01.314106 22485033404224 run_lib.py:146] step: 325500, training_loss: 7.42901e-04
I0513 18:27:01.473779 22485033404224 run_lib.py:167] step: 325500, eval_loss: 7.63372e-04
I0513 18:27:24.994468 22485033404224 run_lib.py:146] step: 325550, training_loss: 5.20271e-04
I0513 18:27:49.121049 22485033404224 run_lib.py:146] step: 325600, training_loss: 5.30892e-04
I0513 18:27:49.280442 22485033404224 run_lib.py:167] step: 325600, eval_loss: 6.46301e-04
I0513 18:28:12.804298 22485033404224 run_lib.py:146] step: 325650, training_loss: 4.67259e-04
I0513 18:28:36.332741 22485033404224 run_lib.py:146] step: 325700, training_loss: 4.86709e-04
I0513 18:28:36.492146 22485033404224 run_lib.py:167] step: 325700, eval_loss: 4.95157e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 18:29:00.776953 22485033404224 run_lib.py:146] step: 325750, training_loss: 5.91756e-04
I0513 18:29:24.302936 22485033404224 run_lib.py:146] step: 325800, training_loss: 7.41686e-04
I0513 18:29:24.463587 22485033404224 run_lib.py:167] step: 325800, eval_loss: 6.23103e-04
I0513 18:29:47.995198 22485033404224 run_lib.py:146] step: 325850, training_loss: 4.69193e-04
I0513 18:30:12.143198 22485033404224 run_lib.py:146] step: 325900, training_loss: 5.57260e-04
I0513 18:30:12.302839 22485033404224 run_lib.py:167] step: 325900, eval_loss: 6.22698e-04
I0513 18:30:35.853239 22485033404224 run_lib.py:146] step: 325950, training_loss: 4.68322e-04
I0513 18:30:59.411078 22485033404224 run_lib.py:146] step: 326000, training_loss: 4.06411e-04
I0513 18:30:59.571033 22485033404224 run_lib.py:167] step: 326000, eval_loss: 5.63453e-04
I0513 18:31:23.714771 22485033404224 run_lib.py:146] step: 326050, training_loss: 5.12041e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 18:31:47.306976 22485033404224 run_lib.py:146] step: 326100, training_loss: 6.21384e-04
I0513 18:31:47.470033 22485033404224 run_lib.py:167] step: 326100, eval_loss: 6.23173e-04
I0513 18:32:10.983812 22485033404224 run_lib.py:146] step: 326150, training_loss: 6.55589e-04
I0513 18:32:34.850333 22485033404224 run_lib.py:146] step: 326200, training_loss: 6.31613e-04
I0513 18:32:35.010145 22485033404224 run_lib.py:167] step: 326200, eval_loss: 4.71731e-04
I0513 18:32:58.811529 22485033404224 run_lib.py:146] step: 326250, training_loss: 4.69527e-04
I0513 18:33:22.335701 22485033404224 run_lib.py:146] step: 326300, training_loss: 7.49888e-04
I0513 18:33:22.495000 22485033404224 run_lib.py:167] step: 326300, eval_loss: 6.08203e-04
I0513 18:33:46.027659 22485033404224 run_lib.py:146] step: 326350, training_loss: 6.38460e-04
I0513 18:34:10.182090 22485033404224 run_lib.py:146] step: 326400, training_loss: 4.88631e-04
I0513 18:34:10.342053 22485033404224 run_lib.py:167] step: 326400, eval_loss: 6.64187e-04
I0513 18:34:33.880662 22485033404224 run_lib.py:146] step: 326450, training_loss: 7.13118e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 18:34:57.485575 22485033404224 run_lib.py:146] step: 326500, training_loss: 4.58576e-04
I0513 18:34:57.647062 22485033404224 run_lib.py:167] step: 326500, eval_loss: 5.23396e-04
I0513 18:35:21.835039 22485033404224 run_lib.py:146] step: 326550, training_loss: 6.43884e-04
I0513 18:35:45.361138 22485033404224 run_lib.py:146] step: 326600, training_loss: 6.40012e-04
I0513 18:35:45.521434 22485033404224 run_lib.py:167] step: 326600, eval_loss: 5.83716e-04
I0513 18:36:09.023113 22485033404224 run_lib.py:146] step: 326650, training_loss: 7.80514e-04
I0513 18:36:33.131337 22485033404224 run_lib.py:146] step: 326700, training_loss: 5.16523e-04
I0513 18:36:33.291993 22485033404224 run_lib.py:167] step: 326700, eval_loss: 6.15177e-04
I0513 18:36:56.868213 22485033404224 run_lib.py:146] step: 326750, training_loss: 6.06663e-04
I0513 18:37:20.463797 22485033404224 run_lib.py:146] step: 326800, training_loss: 6.31354e-04
I0513 18:37:20.625281 22485033404224 run_lib.py:167] step: 326800, eval_loss: 8.45044e-04
I0513 18:37:44.778681 22485033404224 run_lib.py:146] step: 326850, training_loss: 7.14204e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 18:38:08.443294 22485033404224 run_lib.py:146] step: 326900, training_loss: 6.62985e-04
I0513 18:38:08.605319 22485033404224 run_lib.py:167] step: 326900, eval_loss: 5.36524e-04
I0513 18:38:32.184151 22485033404224 run_lib.py:146] step: 326950, training_loss: 5.27373e-04
I0513 18:38:56.445653 22485033404224 run_lib.py:146] step: 327000, training_loss: 5.77335e-04
I0513 18:38:56.606207 22485033404224 run_lib.py:167] step: 327000, eval_loss: 5.75843e-04
I0513 18:39:20.163769 22485033404224 run_lib.py:146] step: 327050, training_loss: 7.16097e-04
I0513 18:39:43.747529 22485033404224 run_lib.py:146] step: 327100, training_loss: 6.79333e-04
I0513 18:39:43.907462 22485033404224 run_lib.py:167] step: 327100, eval_loss: 5.96432e-04
I0513 18:40:07.764291 22485033404224 run_lib.py:146] step: 327150, training_loss: 6.06509e-04
I0513 18:40:31.650237 22485033404224 run_lib.py:146] step: 327200, training_loss: 7.09623e-04
I0513 18:40:31.811201 22485033404224 run_lib.py:167] step: 327200, eval_loss: 7.69590e-04
I0513 18:40:55.399352 22485033404224 run_lib.py:146] step: 327250, training_loss: 6.72382e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 18:41:19.084028 22485033404224 run_lib.py:146] step: 327300, training_loss: 7.61794e-04
I0513 18:41:19.246179 22485033404224 run_lib.py:167] step: 327300, eval_loss: 5.17300e-04
I0513 18:41:43.494999 22485033404224 run_lib.py:146] step: 327350, training_loss: 7.01871e-04
I0513 18:42:07.089444 22485033404224 run_lib.py:146] step: 327400, training_loss: 7.51957e-04
I0513 18:42:07.249939 22485033404224 run_lib.py:167] step: 327400, eval_loss: 6.84733e-04
I0513 18:42:30.842737 22485033404224 run_lib.py:146] step: 327450, training_loss: 6.59981e-04
I0513 18:42:55.005208 22485033404224 run_lib.py:146] step: 327500, training_loss: 6.09123e-04
I0513 18:42:55.166391 22485033404224 run_lib.py:167] step: 327500, eval_loss: 6.53152e-04
I0513 18:43:18.752587 22485033404224 run_lib.py:146] step: 327550, training_loss: 5.11505e-04
I0513 18:43:42.348916 22485033404224 run_lib.py:146] step: 327600, training_loss: 5.88194e-04
I0513 18:43:42.509553 22485033404224 run_lib.py:167] step: 327600, eval_loss: 5.23194e-04
I0513 18:44:06.638080 22485033404224 run_lib.py:146] step: 327650, training_loss: 5.24821e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 18:44:30.250528 22485033404224 run_lib.py:146] step: 327700, training_loss: 6.12987e-04
I0513 18:44:30.412812 22485033404224 run_lib.py:167] step: 327700, eval_loss: 6.68389e-04
I0513 18:44:53.948513 22485033404224 run_lib.py:146] step: 327750, training_loss: 7.00061e-04
I0513 18:45:18.123626 22485033404224 run_lib.py:146] step: 327800, training_loss: 7.09899e-04
I0513 18:45:18.283465 22485033404224 run_lib.py:167] step: 327800, eval_loss: 5.66130e-04
I0513 18:45:41.803274 22485033404224 run_lib.py:146] step: 327850, training_loss: 3.80214e-04
I0513 18:46:05.323874 22485033404224 run_lib.py:146] step: 327900, training_loss: 6.18954e-04
I0513 18:46:05.483712 22485033404224 run_lib.py:167] step: 327900, eval_loss: 6.79890e-04
I0513 18:46:29.304661 22485033404224 run_lib.py:146] step: 327950, training_loss: 5.72389e-04
I0513 18:46:53.115479 22485033404224 run_lib.py:146] step: 328000, training_loss: 5.26115e-04
I0513 18:46:53.276591 22485033404224 run_lib.py:167] step: 328000, eval_loss: 6.01404e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 18:47:16.864396 22485033404224 run_lib.py:146] step: 328050, training_loss: 6.45082e-04
I0513 18:47:40.402278 22485033404224 run_lib.py:146] step: 328100, training_loss: 5.60756e-04
I0513 18:47:40.563055 22485033404224 run_lib.py:167] step: 328100, eval_loss: 6.78570e-04
I0513 18:48:04.780711 22485033404224 run_lib.py:146] step: 328150, training_loss: 5.46781e-04
I0513 18:48:28.289687 22485033404224 run_lib.py:146] step: 328200, training_loss: 5.60953e-04
I0513 18:48:28.448933 22485033404224 run_lib.py:167] step: 328200, eval_loss: 6.58301e-04
I0513 18:48:51.966898 22485033404224 run_lib.py:146] step: 328250, training_loss: 4.69860e-04
I0513 18:49:16.061675 22485033404224 run_lib.py:146] step: 328300, training_loss: 7.09379e-04
I0513 18:49:16.220437 22485033404224 run_lib.py:167] step: 328300, eval_loss: 5.85352e-04
I0513 18:49:39.745134 22485033404224 run_lib.py:146] step: 328350, training_loss: 6.44527e-04
I0513 18:50:03.256484 22485033404224 run_lib.py:146] step: 328400, training_loss: 5.07840e-04
I0513 18:50:03.416004 22485033404224 run_lib.py:167] step: 328400, eval_loss: 6.50222e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 18:50:27.600786 22485033404224 run_lib.py:146] step: 328450, training_loss: 5.24901e-04
I0513 18:50:51.125116 22485033404224 run_lib.py:146] step: 328500, training_loss: 4.47583e-04
I0513 18:50:51.285854 22485033404224 run_lib.py:167] step: 328500, eval_loss: 6.34830e-04
I0513 18:51:14.816852 22485033404224 run_lib.py:146] step: 328550, training_loss: 4.68814e-04
I0513 18:51:39.014445 22485033404224 run_lib.py:146] step: 328600, training_loss: 6.04356e-04
I0513 18:51:39.173224 22485033404224 run_lib.py:167] step: 328600, eval_loss: 4.30700e-04
I0513 18:52:02.699199 22485033404224 run_lib.py:146] step: 328650, training_loss: 6.44208e-04
I0513 18:52:26.245872 22485033404224 run_lib.py:146] step: 328700, training_loss: 4.12830e-04
I0513 18:52:26.405342 22485033404224 run_lib.py:167] step: 328700, eval_loss: 6.89617e-04
I0513 18:52:50.521697 22485033404224 run_lib.py:146] step: 328750, training_loss: 6.51057e-04
I0513 18:53:14.081005 22485033404224 run_lib.py:146] step: 328800, training_loss: 6.80007e-04
I0513 18:53:14.239865 22485033404224 run_lib.py:167] step: 328800, eval_loss: 6.11285e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 18:53:37.850592 22485033404224 run_lib.py:146] step: 328850, training_loss: 5.57025e-04
I0513 18:54:01.408311 22485033404224 run_lib.py:146] step: 328900, training_loss: 6.49475e-04
I0513 18:54:01.568766 22485033404224 run_lib.py:167] step: 328900, eval_loss: 5.86076e-04
I0513 18:54:25.788108 22485033404224 run_lib.py:146] step: 328950, training_loss: 5.41810e-04
I0513 18:54:49.403901 22485033404224 run_lib.py:146] step: 329000, training_loss: 7.00816e-04
I0513 18:54:49.564585 22485033404224 run_lib.py:167] step: 329000, eval_loss: 7.09423e-04
I0513 18:55:13.168221 22485033404224 run_lib.py:146] step: 329050, training_loss: 6.10199e-04
I0513 18:55:37.370835 22485033404224 run_lib.py:146] step: 329100, training_loss: 4.61260e-04
I0513 18:55:37.530805 22485033404224 run_lib.py:167] step: 329100, eval_loss: 6.64922e-04
I0513 18:56:01.159172 22485033404224 run_lib.py:146] step: 329150, training_loss: 5.86269e-04
I0513 18:56:24.751846 22485033404224 run_lib.py:146] step: 329200, training_loss: 6.99692e-04
I0513 18:56:24.912928 22485033404224 run_lib.py:167] step: 329200, eval_loss: 5.63716e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 18:56:49.384361 22485033404224 run_lib.py:146] step: 329250, training_loss: 6.83351e-04
I0513 18:57:12.977513 22485033404224 run_lib.py:146] step: 329300, training_loss: 5.14603e-04
I0513 18:57:13.140466 22485033404224 run_lib.py:167] step: 329300, eval_loss: 6.15014e-04
I0513 18:57:36.746540 22485033404224 run_lib.py:146] step: 329350, training_loss: 6.70910e-04
I0513 18:58:01.059471 22485033404224 run_lib.py:146] step: 329400, training_loss: 6.46884e-04
I0513 18:58:01.219631 22485033404224 run_lib.py:167] step: 329400, eval_loss: 5.53746e-04
I0513 18:58:24.828346 22485033404224 run_lib.py:146] step: 329450, training_loss: 5.25709e-04
I0513 18:58:48.464333 22485033404224 run_lib.py:146] step: 329500, training_loss: 7.68657e-04
I0513 18:58:48.625066 22485033404224 run_lib.py:167] step: 329500, eval_loss: 7.28713e-04
I0513 18:59:12.827436 22485033404224 run_lib.py:146] step: 329550, training_loss: 5.75474e-04
I0513 18:59:36.448769 22485033404224 run_lib.py:146] step: 329600, training_loss: 6.66130e-04
I0513 18:59:36.609207 22485033404224 run_lib.py:167] step: 329600, eval_loss: 5.75847e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:00:00.276767 22485033404224 run_lib.py:146] step: 329650, training_loss: 6.91906e-04
I0513 19:00:24.310923 22485033404224 run_lib.py:146] step: 329700, training_loss: 7.38798e-04
I0513 19:00:24.472855 22485033404224 run_lib.py:167] step: 329700, eval_loss: 5.65414e-04
I0513 19:00:48.545441 22485033404224 run_lib.py:146] step: 329750, training_loss: 6.60323e-04
I0513 19:01:12.177332 22485033404224 run_lib.py:146] step: 329800, training_loss: 5.24095e-04
I0513 19:01:12.338436 22485033404224 run_lib.py:167] step: 329800, eval_loss: 6.21042e-04
I0513 19:01:35.900825 22485033404224 run_lib.py:146] step: 329850, training_loss: 5.58937e-04
I0513 19:02:00.219073 22485033404224 run_lib.py:146] step: 329900, training_loss: 5.82924e-04
I0513 19:02:00.380052 22485033404224 run_lib.py:167] step: 329900, eval_loss: 7.35073e-04
I0513 19:02:23.904955 22485033404224 run_lib.py:146] step: 329950, training_loss: 7.47922e-04
I0513 19:02:47.426573 22485033404224 run_lib.py:146] step: 330000, training_loss: 5.17203e-04
I0513 19:02:49.539741 22485033404224 run_lib.py:167] step: 330000, eval_loss: 4.07027e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:03:14.958826 22485033404224 run_lib.py:146] step: 330050, training_loss: 5.96418e-04
I0513 19:03:38.463811 22485033404224 run_lib.py:146] step: 330100, training_loss: 5.86111e-04
I0513 19:03:38.623194 22485033404224 run_lib.py:167] step: 330100, eval_loss: 5.03661e-04
I0513 19:04:02.448271 22485033404224 run_lib.py:146] step: 330150, training_loss: 6.16646e-04
I0513 19:04:26.251775 22485033404224 run_lib.py:146] step: 330200, training_loss: 6.92541e-04
I0513 19:04:26.411686 22485033404224 run_lib.py:167] step: 330200, eval_loss: 5.57612e-04
I0513 19:04:49.920140 22485033404224 run_lib.py:146] step: 330250, training_loss: 5.73901e-04
I0513 19:05:13.730343 22485033404224 run_lib.py:146] step: 330300, training_loss: 6.00696e-04
I0513 19:05:13.889302 22485033404224 run_lib.py:167] step: 330300, eval_loss: 5.89460e-04
I0513 19:05:37.694149 22485033404224 run_lib.py:146] step: 330350, training_loss: 4.05553e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:06:01.279738 22485033404224 run_lib.py:146] step: 330400, training_loss: 5.17373e-04
I0513 19:06:01.441074 22485033404224 run_lib.py:167] step: 330400, eval_loss: 6.19205e-04
I0513 19:06:24.976597 22485033404224 run_lib.py:146] step: 330450, training_loss: 5.83617e-04
I0513 19:06:49.201132 22485033404224 run_lib.py:146] step: 330500, training_loss: 5.26553e-04
I0513 19:06:49.360352 22485033404224 run_lib.py:167] step: 330500, eval_loss: 5.45510e-04
I0513 19:07:12.870409 22485033404224 run_lib.py:146] step: 330550, training_loss: 6.23233e-04
I0513 19:07:36.388072 22485033404224 run_lib.py:146] step: 330600, training_loss: 5.52437e-04
I0513 19:07:36.546893 22485033404224 run_lib.py:167] step: 330600, eval_loss: 5.52557e-04
I0513 19:08:00.366468 22485033404224 run_lib.py:146] step: 330650, training_loss: 7.30913e-04
I0513 19:08:24.212967 22485033404224 run_lib.py:146] step: 330700, training_loss: 7.12453e-04
I0513 19:08:24.372778 22485033404224 run_lib.py:167] step: 330700, eval_loss: 6.97083e-04
I0513 19:08:47.896804 22485033404224 run_lib.py:146] step: 330750, training_loss: 7.19581e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:09:11.810462 22485033404224 run_lib.py:146] step: 330800, training_loss: 5.46250e-04
I0513 19:09:11.972008 22485033404224 run_lib.py:167] step: 330800, eval_loss: 6.32989e-04
I0513 19:09:35.798144 22485033404224 run_lib.py:146] step: 330850, training_loss: 5.87976e-04
I0513 19:09:59.311585 22485033404224 run_lib.py:146] step: 330900, training_loss: 8.33548e-04
I0513 19:09:59.470971 22485033404224 run_lib.py:167] step: 330900, eval_loss: 5.57563e-04
I0513 19:10:23.328523 22485033404224 run_lib.py:146] step: 330950, training_loss: 4.67348e-04
I0513 19:10:47.160742 22485033404224 run_lib.py:146] step: 331000, training_loss: 6.74451e-04
I0513 19:10:47.321345 22485033404224 run_lib.py:167] step: 331000, eval_loss: 5.84207e-04
I0513 19:11:10.873691 22485033404224 run_lib.py:146] step: 331050, training_loss: 4.92100e-04
I0513 19:11:34.711827 22485033404224 run_lib.py:146] step: 331100, training_loss: 6.63440e-04
I0513 19:11:34.870795 22485033404224 run_lib.py:167] step: 331100, eval_loss: 6.49674e-04
I0513 19:11:58.710462 22485033404224 run_lib.py:146] step: 331150, training_loss: 7.05085e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:12:22.390430 22485033404224 run_lib.py:146] step: 331200, training_loss: 6.73049e-04
I0513 19:12:22.552718 22485033404224 run_lib.py:167] step: 331200, eval_loss: 5.85966e-04
I0513 19:12:46.175274 22485033404224 run_lib.py:146] step: 331250, training_loss: 7.13537e-04
I0513 19:13:10.479935 22485033404224 run_lib.py:146] step: 331300, training_loss: 5.32359e-04
I0513 19:13:10.640551 22485033404224 run_lib.py:167] step: 331300, eval_loss: 6.85414e-04
I0513 19:13:34.225974 22485033404224 run_lib.py:146] step: 331350, training_loss: 7.32114e-04
I0513 19:13:57.811029 22485033404224 run_lib.py:146] step: 331400, training_loss: 6.23348e-04
I0513 19:13:57.977506 22485033404224 run_lib.py:167] step: 331400, eval_loss: 7.89461e-04
I0513 19:14:22.170231 22485033404224 run_lib.py:146] step: 331450, training_loss: 5.22394e-04
I0513 19:14:45.751495 22485033404224 run_lib.py:146] step: 331500, training_loss: 6.99967e-04
I0513 19:14:45.911086 22485033404224 run_lib.py:167] step: 331500, eval_loss: 5.65944e-04
I0513 19:15:09.480141 22485033404224 run_lib.py:146] step: 331550, training_loss: 5.31035e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:15:33.600440 22485033404224 run_lib.py:146] step: 331600, training_loss: 4.69140e-04
I0513 19:15:33.762123 22485033404224 run_lib.py:167] step: 331600, eval_loss: 2.96124e-04
I0513 19:15:57.746565 22485033404224 run_lib.py:146] step: 331650, training_loss: 7.02483e-04
I0513 19:16:21.410654 22485033404224 run_lib.py:146] step: 331700, training_loss: 3.85635e-04
I0513 19:16:21.495821 22485033404224 run_lib.py:167] step: 331700, eval_loss: 6.19228e-04
I0513 19:16:45.473060 22485033404224 run_lib.py:146] step: 331750, training_loss: 4.71471e-04
I0513 19:17:09.358717 22485033404224 run_lib.py:146] step: 331800, training_loss: 6.29963e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:17:09.707643 22485033404224 run_lib.py:167] step: 331800, eval_loss: 5.62662e-04
I0513 19:17:33.305021 22485033404224 run_lib.py:146] step: 331850, training_loss: 5.73849e-04
I0513 19:17:57.230509 22485033404224 run_lib.py:146] step: 331900, training_loss: 7.12869e-04
I0513 19:17:57.391413 22485033404224 run_lib.py:167] step: 331900, eval_loss: 4.33311e-04
I0513 19:18:21.416758 22485033404224 run_lib.py:146] step: 331950, training_loss: 4.98516e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:18:45.046362 22485033404224 run_lib.py:146] step: 332000, training_loss: 5.27936e-04
I0513 19:18:45.209029 22485033404224 run_lib.py:167] step: 332000, eval_loss: 5.86724e-04
I0513 19:19:08.783683 22485033404224 run_lib.py:146] step: 332050, training_loss: 5.95321e-04
I0513 19:19:33.018004 22485033404224 run_lib.py:146] step: 332100, training_loss: 6.51400e-04
I0513 19:19:33.177632 22485033404224 run_lib.py:167] step: 332100, eval_loss: 4.49202e-04
I0513 19:19:56.688832 22485033404224 run_lib.py:146] step: 332150, training_loss: 6.26013e-04
I0513 19:20:20.207773 22485033404224 run_lib.py:146] step: 332200, training_loss: 4.76594e-04
I0513 19:20:20.367797 22485033404224 run_lib.py:167] step: 332200, eval_loss: 5.65896e-04
I0513 19:20:44.482985 22485033404224 run_lib.py:146] step: 332250, training_loss: 4.93526e-04
I0513 19:21:08.019869 22485033404224 run_lib.py:146] step: 332300, training_loss: 7.13063e-04
I0513 19:21:08.181164 22485033404224 run_lib.py:167] step: 332300, eval_loss: 7.25250e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:21:31.776330 22485033404224 run_lib.py:146] step: 332350, training_loss: 6.33228e-04
I0513 19:21:55.644280 22485033404224 run_lib.py:146] step: 332400, training_loss: 5.76172e-04
I0513 19:21:55.805333 22485033404224 run_lib.py:167] step: 332400, eval_loss: 5.62891e-04
I0513 19:22:19.670824 22485033404224 run_lib.py:146] step: 332450, training_loss: 6.02319e-04
I0513 19:22:43.201627 22485033404224 run_lib.py:146] step: 332500, training_loss: 5.65510e-04
I0513 19:22:43.361766 22485033404224 run_lib.py:167] step: 332500, eval_loss: 6.61558e-04
I0513 19:23:07.183333 22485033404224 run_lib.py:146] step: 332550, training_loss: 6.74010e-04
I0513 19:23:31.032789 22485033404224 run_lib.py:146] step: 332600, training_loss: 6.78862e-04
I0513 19:23:31.193425 22485033404224 run_lib.py:167] step: 332600, eval_loss: 6.73640e-04
I0513 19:23:54.738366 22485033404224 run_lib.py:146] step: 332650, training_loss: 7.77749e-04
I0513 19:24:18.588134 22485033404224 run_lib.py:146] step: 332700, training_loss: 5.65516e-04
I0513 19:24:18.748560 22485033404224 run_lib.py:167] step: 332700, eval_loss: 6.18957e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:24:42.663406 22485033404224 run_lib.py:146] step: 332750, training_loss: 6.89329e-04
I0513 19:25:06.177932 22485033404224 run_lib.py:146] step: 332800, training_loss: 5.32274e-04
I0513 19:25:06.339300 22485033404224 run_lib.py:167] step: 332800, eval_loss: 6.99681e-04
I0513 19:25:30.181399 22485033404224 run_lib.py:146] step: 332850, training_loss: 6.35964e-04
I0513 19:25:54.041185 22485033404224 run_lib.py:146] step: 332900, training_loss: 6.58784e-04
I0513 19:25:54.201303 22485033404224 run_lib.py:167] step: 332900, eval_loss: 8.23491e-04
I0513 19:26:17.720145 22485033404224 run_lib.py:146] step: 332950, training_loss: 8.78798e-04
I0513 19:26:41.245532 22485033404224 run_lib.py:146] step: 333000, training_loss: 4.96805e-04
I0513 19:26:41.405779 22485033404224 run_lib.py:167] step: 333000, eval_loss: 6.48810e-04
I0513 19:27:05.528771 22485033404224 run_lib.py:146] step: 333050, training_loss: 6.37289e-04
I0513 19:27:29.065118 22485033404224 run_lib.py:146] step: 333100, training_loss: 6.14078e-04
I0513 19:27:29.224166 22485033404224 run_lib.py:167] step: 333100, eval_loss: 5.87735e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:27:52.830425 22485033404224 run_lib.py:146] step: 333150, training_loss: 5.38250e-04
I0513 19:28:16.690487 22485033404224 run_lib.py:146] step: 333200, training_loss: 8.31714e-04
I0513 19:28:17.321822 22485033404224 run_lib.py:167] step: 333200, eval_loss: 5.90095e-04
I0513 19:28:40.956912 22485033404224 run_lib.py:146] step: 333250, training_loss: 7.22005e-04
I0513 19:29:04.498219 22485033404224 run_lib.py:146] step: 333300, training_loss: 5.72550e-04
I0513 19:29:04.658004 22485033404224 run_lib.py:167] step: 333300, eval_loss: 7.25199e-04
I0513 19:29:28.494223 22485033404224 run_lib.py:146] step: 333350, training_loss: 7.60836e-04
I0513 19:29:52.340584 22485033404224 run_lib.py:146] step: 333400, training_loss: 5.98747e-04
I0513 19:29:52.499382 22485033404224 run_lib.py:167] step: 333400, eval_loss: 8.59906e-04
I0513 19:30:16.055754 22485033404224 run_lib.py:146] step: 333450, training_loss: 5.00595e-04
I0513 19:30:39.967202 22485033404224 run_lib.py:146] step: 333500, training_loss: 5.74042e-04
I0513 19:30:40.128707 22485033404224 run_lib.py:167] step: 333500, eval_loss: 5.13495e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:31:04.140926 22485033404224 run_lib.py:146] step: 333550, training_loss: 5.45310e-04
I0513 19:31:27.744247 22485033404224 run_lib.py:146] step: 333600, training_loss: 5.26668e-04
I0513 19:31:27.906039 22485033404224 run_lib.py:167] step: 333600, eval_loss: 5.95614e-04
I0513 19:31:51.837794 22485033404224 run_lib.py:146] step: 333650, training_loss: 5.14311e-04
I0513 19:32:15.849169 22485033404224 run_lib.py:146] step: 333700, training_loss: 6.46959e-04
I0513 19:32:16.009521 22485033404224 run_lib.py:167] step: 333700, eval_loss: 7.22009e-04
I0513 19:32:39.591867 22485033404224 run_lib.py:146] step: 333750, training_loss: 5.70209e-04
I0513 19:33:03.155817 22485033404224 run_lib.py:146] step: 333800, training_loss: 6.70780e-04
I0513 19:33:03.315759 22485033404224 run_lib.py:167] step: 333800, eval_loss: 5.43266e-04
I0513 19:33:27.579140 22485033404224 run_lib.py:146] step: 333850, training_loss: 7.40006e-04
I0513 19:33:51.141157 22485033404224 run_lib.py:146] step: 333900, training_loss: 6.94138e-04
I0513 19:33:51.301943 22485033404224 run_lib.py:167] step: 333900, eval_loss: 5.47410e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:34:15.077863 22485033404224 run_lib.py:146] step: 333950, training_loss: 6.92995e-04
I0513 19:34:39.550442 22485033404224 run_lib.py:146] step: 334000, training_loss: 5.95576e-04
I0513 19:34:39.713324 22485033404224 run_lib.py:167] step: 334000, eval_loss: 7.61339e-04
I0513 19:35:03.302900 22485033404224 run_lib.py:146] step: 334050, training_loss: 6.38626e-04
I0513 19:35:26.902667 22485033404224 run_lib.py:146] step: 334100, training_loss: 6.49209e-04
I0513 19:35:27.064107 22485033404224 run_lib.py:167] step: 334100, eval_loss: 6.67257e-04
I0513 19:35:50.953750 22485033404224 run_lib.py:146] step: 334150, training_loss: 7.65196e-04
I0513 19:36:14.878266 22485033404224 run_lib.py:146] step: 334200, training_loss: 9.29243e-04
I0513 19:36:15.038502 22485033404224 run_lib.py:167] step: 334200, eval_loss: 6.68659e-04
I0513 19:36:38.626610 22485033404224 run_lib.py:146] step: 334250, training_loss: 6.59714e-04
I0513 19:37:02.551781 22485033404224 run_lib.py:146] step: 334300, training_loss: 8.98433e-04
I0513 19:37:02.713545 22485033404224 run_lib.py:167] step: 334300, eval_loss: 5.82542e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:37:26.755151 22485033404224 run_lib.py:146] step: 334350, training_loss: 6.19139e-04
I0513 19:37:50.322502 22485033404224 run_lib.py:146] step: 334400, training_loss: 5.70340e-04
I0513 19:37:50.483191 22485033404224 run_lib.py:167] step: 334400, eval_loss: 6.02400e-04
I0513 19:38:14.349337 22485033404224 run_lib.py:146] step: 334450, training_loss: 6.27305e-04
I0513 19:38:38.141056 22485033404224 run_lib.py:146] step: 334500, training_loss: 4.57534e-04
I0513 19:38:38.300287 22485033404224 run_lib.py:167] step: 334500, eval_loss: 5.48724e-04
I0513 19:39:01.825565 22485033404224 run_lib.py:146] step: 334550, training_loss: 6.46504e-04
I0513 19:39:25.352302 22485033404224 run_lib.py:146] step: 334600, training_loss: 6.82795e-04
I0513 19:39:25.512598 22485033404224 run_lib.py:167] step: 334600, eval_loss: 6.89672e-04
I0513 19:39:49.637842 22485033404224 run_lib.py:146] step: 334650, training_loss: 5.71689e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:40:13.240983 22485033404224 run_lib.py:146] step: 334700, training_loss: 5.32196e-04
I0513 19:40:13.403419 22485033404224 run_lib.py:167] step: 334700, eval_loss: 4.21957e-04
I0513 19:40:36.939297 22485033404224 run_lib.py:146] step: 334750, training_loss: 8.86273e-04
I0513 19:41:01.176392 22485033404224 run_lib.py:146] step: 334800, training_loss: 6.42905e-04
I0513 19:41:01.337581 22485033404224 run_lib.py:167] step: 334800, eval_loss: 4.82091e-04
I0513 19:41:24.838286 22485033404224 run_lib.py:146] step: 334850, training_loss: 7.35804e-04
I0513 19:41:48.354030 22485033404224 run_lib.py:146] step: 334900, training_loss: 6.60956e-04
I0513 19:41:48.513894 22485033404224 run_lib.py:167] step: 334900, eval_loss: 6.61294e-04
I0513 19:42:12.339099 22485033404224 run_lib.py:146] step: 334950, training_loss: 5.93119e-04
I0513 19:42:36.131593 22485033404224 run_lib.py:146] step: 335000, training_loss: 5.67805e-04
I0513 19:42:36.290252 22485033404224 run_lib.py:167] step: 335000, eval_loss: 5.59411e-04
I0513 19:42:59.819690 22485033404224 run_lib.py:146] step: 335050, training_loss: 7.19857e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:43:23.695254 22485033404224 run_lib.py:146] step: 335100, training_loss: 5.14224e-04
I0513 19:43:23.856429 22485033404224 run_lib.py:167] step: 335100, eval_loss: 6.36386e-04
I0513 19:43:47.715274 22485033404224 run_lib.py:146] step: 335150, training_loss: 5.26053e-04
I0513 19:44:11.217201 22485033404224 run_lib.py:146] step: 335200, training_loss: 5.98481e-04
I0513 19:44:11.376626 22485033404224 run_lib.py:167] step: 335200, eval_loss: 6.25652e-04
I0513 19:44:35.205080 22485033404224 run_lib.py:146] step: 335250, training_loss: 6.15440e-04
I0513 19:44:59.018660 22485033404224 run_lib.py:146] step: 335300, training_loss: 6.97573e-04
I0513 19:44:59.177465 22485033404224 run_lib.py:167] step: 335300, eval_loss: 5.28132e-04
I0513 19:45:22.686987 22485033404224 run_lib.py:146] step: 335350, training_loss: 6.35138e-04
I0513 19:45:46.505988 22485033404224 run_lib.py:146] step: 335400, training_loss: 7.94171e-04
I0513 19:45:46.664721 22485033404224 run_lib.py:167] step: 335400, eval_loss: 5.78320e-04
I0513 19:46:10.453374 22485033404224 run_lib.py:146] step: 335450, training_loss: 8.31876e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:46:34.035187 22485033404224 run_lib.py:146] step: 335500, training_loss: 5.94241e-04
I0513 19:46:34.196913 22485033404224 run_lib.py:167] step: 335500, eval_loss: 6.94516e-04
I0513 19:46:57.715112 22485033404224 run_lib.py:146] step: 335550, training_loss: 5.87516e-04
I0513 19:47:21.940371 22485033404224 run_lib.py:146] step: 335600, training_loss: 6.06709e-04
I0513 19:47:22.099987 22485033404224 run_lib.py:167] step: 335600, eval_loss: 6.52841e-04
I0513 19:47:45.615833 22485033404224 run_lib.py:146] step: 335650, training_loss: 6.40820e-04
I0513 19:48:09.138729 22485033404224 run_lib.py:146] step: 335700, training_loss: 8.58409e-04
I0513 19:48:09.298331 22485033404224 run_lib.py:167] step: 335700, eval_loss: 6.79377e-04
I0513 19:48:33.169391 22485033404224 run_lib.py:146] step: 335750, training_loss: 4.65723e-04
I0513 19:48:57.042549 22485033404224 run_lib.py:146] step: 335800, training_loss: 6.17213e-04
I0513 19:48:57.202750 22485033404224 run_lib.py:167] step: 335800, eval_loss: 6.30254e-04
I0513 19:49:20.792276 22485033404224 run_lib.py:146] step: 335850, training_loss: 5.57085e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:49:44.812955 22485033404224 run_lib.py:146] step: 335900, training_loss: 7.05729e-04
I0513 19:49:44.974933 22485033404224 run_lib.py:167] step: 335900, eval_loss: 6.23543e-04
I0513 19:50:08.925207 22485033404224 run_lib.py:146] step: 335950, training_loss: 4.90872e-04
I0513 19:50:32.521771 22485033404224 run_lib.py:146] step: 336000, training_loss: 6.46784e-04
I0513 19:50:32.682116 22485033404224 run_lib.py:167] step: 336000, eval_loss: 6.07168e-04
I0513 19:50:56.545009 22485033404224 run_lib.py:146] step: 336050, training_loss: 5.20825e-04
I0513 19:51:20.428142 22485033404224 run_lib.py:146] step: 336100, training_loss: 5.13273e-04
I0513 19:51:20.588786 22485033404224 run_lib.py:167] step: 336100, eval_loss: 3.53419e-04
I0513 19:51:44.131319 22485033404224 run_lib.py:146] step: 336150, training_loss: 6.74067e-04
I0513 19:52:07.988832 22485033404224 run_lib.py:146] step: 336200, training_loss: 4.92683e-04
I0513 19:52:08.148628 22485033404224 run_lib.py:167] step: 336200, eval_loss: 4.89724e-04
I0513 19:52:32.037880 22485033404224 run_lib.py:146] step: 336250, training_loss: 6.78480e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:52:55.681108 22485033404224 run_lib.py:146] step: 336300, training_loss: 6.69502e-04
I0513 19:52:55.842665 22485033404224 run_lib.py:167] step: 336300, eval_loss: 7.18337e-04
I0513 19:53:19.401733 22485033404224 run_lib.py:146] step: 336350, training_loss: 6.30479e-04
I0513 19:53:43.753463 22485033404224 run_lib.py:146] step: 336400, training_loss: 6.17255e-04
I0513 19:53:43.913890 22485033404224 run_lib.py:167] step: 336400, eval_loss: 7.04143e-04
I0513 19:54:07.487340 22485033404224 run_lib.py:146] step: 336450, training_loss: 7.29467e-04
I0513 19:54:31.085890 22485033404224 run_lib.py:146] step: 336500, training_loss: 5.62448e-04
I0513 19:54:31.246376 22485033404224 run_lib.py:167] step: 336500, eval_loss: 6.08909e-04
I0513 19:54:55.214658 22485033404224 run_lib.py:146] step: 336550, training_loss: 6.33952e-04
I0513 19:55:19.162102 22485033404224 run_lib.py:146] step: 336600, training_loss: 6.97621e-04
I0513 19:55:19.322204 22485033404224 run_lib.py:167] step: 336600, eval_loss: 6.72827e-04
I0513 19:55:42.820759 22485033404224 run_lib.py:146] step: 336650, training_loss: 4.07974e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:56:07.012874 22485033404224 run_lib.py:146] step: 336700, training_loss: 6.41661e-04
I0513 19:56:07.172966 22485033404224 run_lib.py:167] step: 336700, eval_loss: 7.56658e-04
I0513 19:56:31.044683 22485033404224 run_lib.py:146] step: 336750, training_loss: 4.83273e-04
I0513 19:56:54.577325 22485033404224 run_lib.py:146] step: 336800, training_loss: 5.77063e-04
I0513 19:56:54.737782 22485033404224 run_lib.py:167] step: 336800, eval_loss: 5.88594e-04
I0513 19:57:18.558292 22485033404224 run_lib.py:146] step: 336850, training_loss: 6.83329e-04
I0513 19:57:42.373750 22485033404224 run_lib.py:146] step: 336900, training_loss: 5.38100e-04
I0513 19:57:42.534459 22485033404224 run_lib.py:167] step: 336900, eval_loss: 6.22970e-04
I0513 19:58:06.071223 22485033404224 run_lib.py:146] step: 336950, training_loss: 7.14285e-04
I0513 19:58:29.892412 22485033404224 run_lib.py:146] step: 337000, training_loss: 8.22107e-04
I0513 19:58:30.051182 22485033404224 run_lib.py:167] step: 337000, eval_loss: 6.60704e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:58:53.952833 22485033404224 run_lib.py:146] step: 337050, training_loss: 5.25028e-04
I0513 19:59:17.496209 22485033404224 run_lib.py:146] step: 337100, training_loss: 5.54870e-04
I0513 19:59:17.657697 22485033404224 run_lib.py:167] step: 337100, eval_loss: 7.36477e-04
I0513 19:59:41.557155 22485033404224 run_lib.py:146] step: 337150, training_loss: 6.02083e-04
I0513 20:00:05.436275 22485033404224 run_lib.py:146] step: 337200, training_loss: 5.29715e-04
I0513 20:00:05.596093 22485033404224 run_lib.py:167] step: 337200, eval_loss: 5.93130e-04
I0513 20:00:29.119181 22485033404224 run_lib.py:146] step: 337250, training_loss: 6.93301e-04
I0513 20:00:52.644595 22485033404224 run_lib.py:146] step: 337300, training_loss: 4.98928e-04
I0513 20:00:52.804644 22485033404224 run_lib.py:167] step: 337300, eval_loss: 6.27196e-04
I0513 20:01:16.951935 22485033404224 run_lib.py:146] step: 337350, training_loss: 4.73537e-04
I0513 20:01:40.486526 22485033404224 run_lib.py:146] step: 337400, training_loss: 6.41289e-04
I0513 20:01:40.646014 22485033404224 run_lib.py:167] step: 337400, eval_loss: 7.73864e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:02:04.239217 22485033404224 run_lib.py:146] step: 337450, training_loss: 5.87158e-04
I0513 20:02:28.087441 22485033404224 run_lib.py:146] step: 337500, training_loss: 7.14428e-04
I0513 20:02:28.247272 22485033404224 run_lib.py:167] step: 337500, eval_loss: 7.60958e-04
I0513 20:02:52.068909 22485033404224 run_lib.py:146] step: 337550, training_loss: 7.05862e-04
I0513 20:03:15.575470 22485033404224 run_lib.py:146] step: 337600, training_loss: 6.38859e-04
I0513 20:03:15.735175 22485033404224 run_lib.py:167] step: 337600, eval_loss: 6.38949e-04
I0513 20:03:39.560198 22485033404224 run_lib.py:146] step: 337650, training_loss: 7.03752e-04
I0513 20:04:03.381124 22485033404224 run_lib.py:146] step: 337700, training_loss: 7.39407e-04
I0513 20:04:03.539573 22485033404224 run_lib.py:167] step: 337700, eval_loss: 5.54736e-04
I0513 20:04:27.062799 22485033404224 run_lib.py:146] step: 337750, training_loss: 5.54589e-04
I0513 20:04:50.904676 22485033404224 run_lib.py:146] step: 337800, training_loss: 7.08272e-04
I0513 20:04:51.063657 22485033404224 run_lib.py:167] step: 337800, eval_loss: 5.04950e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:05:14.946228 22485033404224 run_lib.py:146] step: 337850, training_loss: 6.58202e-04
I0513 20:05:38.467310 22485033404224 run_lib.py:146] step: 337900, training_loss: 6.14308e-04
I0513 20:05:38.628854 22485033404224 run_lib.py:167] step: 337900, eval_loss: 5.47274e-04
I0513 20:06:02.508004 22485033404224 run_lib.py:146] step: 337950, training_loss: 4.32331e-04
I0513 20:06:26.377317 22485033404224 run_lib.py:146] step: 338000, training_loss: 4.82142e-04
I0513 20:06:26.538424 22485033404224 run_lib.py:167] step: 338000, eval_loss: 5.43535e-04
I0513 20:06:50.141476 22485033404224 run_lib.py:146] step: 338050, training_loss: 3.90965e-04
I0513 20:07:13.743502 22485033404224 run_lib.py:146] step: 338100, training_loss: 7.47217e-04
I0513 20:07:13.903958 22485033404224 run_lib.py:167] step: 338100, eval_loss: 5.72495e-04
I0513 20:07:38.096672 22485033404224 run_lib.py:146] step: 338150, training_loss: 5.80058e-04
I0513 20:08:01.676929 22485033404224 run_lib.py:146] step: 338200, training_loss: 6.89792e-04
I0513 20:08:01.837102 22485033404224 run_lib.py:167] step: 338200, eval_loss: 5.21710e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:08:25.534436 22485033404224 run_lib.py:146] step: 338250, training_loss: 7.66196e-04
I0513 20:08:49.504332 22485033404224 run_lib.py:146] step: 338300, training_loss: 8.05475e-04
I0513 20:08:49.665964 22485033404224 run_lib.py:167] step: 338300, eval_loss: 7.38793e-04
I0513 20:09:13.743926 22485033404224 run_lib.py:146] step: 338350, training_loss: 5.74178e-04
I0513 20:09:37.341072 22485033404224 run_lib.py:146] step: 338400, training_loss: 3.78766e-04
I0513 20:09:37.501549 22485033404224 run_lib.py:167] step: 338400, eval_loss: 5.69274e-04
I0513 20:10:01.429231 22485033404224 run_lib.py:146] step: 338450, training_loss: 4.76987e-04
I0513 20:10:25.467746 22485033404224 run_lib.py:146] step: 338500, training_loss: 5.38983e-04
I0513 20:10:25.629328 22485033404224 run_lib.py:167] step: 338500, eval_loss: 7.12910e-04
I0513 20:10:49.253627 22485033404224 run_lib.py:146] step: 338550, training_loss: 7.42182e-04
I0513 20:11:13.141878 22485033404224 run_lib.py:146] step: 338600, training_loss: 7.52447e-04
I0513 20:11:13.302040 22485033404224 run_lib.py:167] step: 338600, eval_loss: 8.86489e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:11:37.506209 22485033404224 run_lib.py:146] step: 338650, training_loss: 5.09606e-04
I0513 20:12:01.153908 22485033404224 run_lib.py:146] step: 338700, training_loss: 5.75285e-04
I0513 20:12:01.316321 22485033404224 run_lib.py:167] step: 338700, eval_loss: 5.52336e-04
I0513 20:12:25.430592 22485033404224 run_lib.py:146] step: 338750, training_loss: 4.28910e-04
I0513 20:12:49.455466 22485033404224 run_lib.py:146] step: 338800, training_loss: 5.83196e-04
I0513 20:12:49.614576 22485033404224 run_lib.py:167] step: 338800, eval_loss: 7.23502e-04
I0513 20:13:13.254867 22485033404224 run_lib.py:146] step: 338850, training_loss: 5.54654e-04
I0513 20:13:36.891071 22485033404224 run_lib.py:146] step: 338900, training_loss: 5.25424e-04
I0513 20:13:37.051731 22485033404224 run_lib.py:167] step: 338900, eval_loss: 5.94102e-04
I0513 20:14:01.431285 22485033404224 run_lib.py:146] step: 338950, training_loss: 5.60199e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:14:25.037133 22485033404224 run_lib.py:146] step: 339000, training_loss: 6.00260e-04
I0513 20:14:25.198781 22485033404224 run_lib.py:167] step: 339000, eval_loss: 6.91951e-04
I0513 20:14:48.732583 22485033404224 run_lib.py:146] step: 339050, training_loss: 4.20581e-04
I0513 20:15:12.594490 22485033404224 run_lib.py:146] step: 339100, training_loss: 5.64303e-04
I0513 20:15:12.755810 22485033404224 run_lib.py:167] step: 339100, eval_loss: 7.34255e-04
I0513 20:15:36.598584 22485033404224 run_lib.py:146] step: 339150, training_loss: 5.37793e-04
I0513 20:16:00.111250 22485033404224 run_lib.py:146] step: 339200, training_loss: 5.35758e-04
I0513 20:16:00.270680 22485033404224 run_lib.py:167] step: 339200, eval_loss: 5.75541e-04
I0513 20:16:24.090204 22485033404224 run_lib.py:146] step: 339250, training_loss: 5.04089e-04
I0513 20:16:47.919890 22485033404224 run_lib.py:146] step: 339300, training_loss: 5.91695e-04
I0513 20:16:48.078318 22485033404224 run_lib.py:167] step: 339300, eval_loss: 5.84202e-04
I0513 20:17:11.601595 22485033404224 run_lib.py:146] step: 339350, training_loss: 4.98503e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:17:35.493203 22485033404224 run_lib.py:146] step: 339400, training_loss: 7.42458e-04
I0513 20:17:35.655483 22485033404224 run_lib.py:167] step: 339400, eval_loss: 7.25083e-04
I0513 20:17:59.547718 22485033404224 run_lib.py:146] step: 339450, training_loss: 5.97776e-04
I0513 20:18:23.080350 22485033404224 run_lib.py:146] step: 339500, training_loss: 4.10685e-04
I0513 20:18:23.238564 22485033404224 run_lib.py:167] step: 339500, eval_loss: 5.86909e-04
I0513 20:18:47.106337 22485033404224 run_lib.py:146] step: 339550, training_loss: 6.81467e-04
I0513 20:19:10.926167 22485033404224 run_lib.py:146] step: 339600, training_loss: 5.50553e-04
I0513 20:19:11.012473 22485033404224 run_lib.py:167] step: 339600, eval_loss: 6.79677e-04
I0513 20:19:34.520815 22485033404224 run_lib.py:146] step: 339650, training_loss: 6.66085e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:19:58.348997 22485033404224 run_lib.py:146] step: 339700, training_loss: 6.68557e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:19:58.690217 22485033404224 run_lib.py:167] step: 339700, eval_loss: 4.51167e-04
I0513 20:20:22.579925 22485033404224 run_lib.py:146] step: 339750, training_loss: 6.98120e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:20:46.188169 22485033404224 run_lib.py:146] step: 339800, training_loss: 5.87210e-04
I0513 20:20:46.349198 22485033404224 run_lib.py:167] step: 339800, eval_loss: 6.83570e-04
I0513 20:21:09.878256 22485033404224 run_lib.py:146] step: 339850, training_loss: 7.12628e-04
I0513 20:21:33.738673 22485033404224 run_lib.py:146] step: 339900, training_loss: 4.60399e-04
I0513 20:21:33.898734 22485033404224 run_lib.py:167] step: 339900, eval_loss: 6.45797e-04
I0513 20:21:57.738733 22485033404224 run_lib.py:146] step: 339950, training_loss: 8.51225e-04
I0513 20:22:21.280836 22485033404224 run_lib.py:146] step: 340000, training_loss: 6.11374e-04
I0513 20:22:33.151538 22485033404224 run_lib.py:167] step: 340000, eval_loss: 6.73017e-04
I0513 20:23:11.187507 22485033404224 run_lib.py:146] step: 340050, training_loss: 8.23753e-04
I0513 20:23:34.996900 22485033404224 run_lib.py:146] step: 340100, training_loss: 6.45736e-04
I0513 20:23:35.155981 22485033404224 run_lib.py:167] step: 340100, eval_loss: 5.57112e-04
I0513 20:23:59.002816 22485033404224 run_lib.py:146] step: 340150, training_loss: 5.42498e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:24:22.604412 22485033404224 run_lib.py:146] step: 340200, training_loss: 5.59454e-04
I0513 20:24:22.766219 22485033404224 run_lib.py:167] step: 340200, eval_loss: 5.04694e-04
I0513 20:24:46.722266 22485033404224 run_lib.py:146] step: 340250, training_loss: 5.80366e-04
I0513 20:25:10.694262 22485033404224 run_lib.py:146] step: 340300, training_loss: 5.56318e-04
I0513 20:25:10.854419 22485033404224 run_lib.py:167] step: 340300, eval_loss: 6.93381e-04
I0513 20:25:34.485223 22485033404224 run_lib.py:146] step: 340350, training_loss: 4.68898e-04
I0513 20:25:58.400287 22485033404224 run_lib.py:146] step: 340400, training_loss: 3.05905e-04
I0513 20:25:58.560883 22485033404224 run_lib.py:167] step: 340400, eval_loss: 5.58914e-04
I0513 20:26:22.479631 22485033404224 run_lib.py:146] step: 340450, training_loss: 6.64992e-04
I0513 20:26:46.082619 22485033404224 run_lib.py:146] step: 340500, training_loss: 5.35172e-04
I0513 20:26:46.268127 22485033404224 run_lib.py:167] step: 340500, eval_loss: 5.00335e-04
I0513 20:27:10.157381 22485033404224 run_lib.py:146] step: 340550, training_loss: 6.48160e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:27:34.030631 22485033404224 run_lib.py:146] step: 340600, training_loss: 5.12035e-04
I0513 20:27:34.192957 22485033404224 run_lib.py:167] step: 340600, eval_loss: 5.58826e-04
I0513 20:27:58.253388 22485033404224 run_lib.py:146] step: 340650, training_loss: 6.86470e-04
I0513 20:28:22.333265 22485033404224 run_lib.py:146] step: 340700, training_loss: 5.32523e-04
I0513 20:28:22.493997 22485033404224 run_lib.py:167] step: 340700, eval_loss: 7.42715e-04
I0513 20:28:46.123541 22485033404224 run_lib.py:146] step: 340750, training_loss: 7.60212e-04
I0513 20:29:10.104005 22485033404224 run_lib.py:146] step: 340800, training_loss: 5.17316e-04
I0513 20:29:10.264631 22485033404224 run_lib.py:167] step: 340800, eval_loss: 6.11608e-04
I0513 20:29:33.866703 22485033404224 run_lib.py:146] step: 340850, training_loss: 6.66363e-04
I0513 20:29:57.878209 22485033404224 run_lib.py:146] step: 340900, training_loss: 6.69429e-04
I0513 20:29:58.037906 22485033404224 run_lib.py:167] step: 340900, eval_loss: 5.42291e-04
I0513 20:30:21.950729 22485033404224 run_lib.py:146] step: 340950, training_loss: 6.00017e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:30:45.643074 22485033404224 run_lib.py:146] step: 341000, training_loss: 5.98776e-04
I0513 20:30:45.805223 22485033404224 run_lib.py:167] step: 341000, eval_loss: 7.06393e-04
I0513 20:31:09.865547 22485033404224 run_lib.py:146] step: 341050, training_loss: 5.48861e-04
I0513 20:31:33.855199 22485033404224 run_lib.py:146] step: 341100, training_loss: 6.52962e-04
I0513 20:31:34.016590 22485033404224 run_lib.py:167] step: 341100, eval_loss: 5.95390e-04
I0513 20:31:57.638713 22485033404224 run_lib.py:146] step: 341150, training_loss: 6.11410e-04
I0513 20:32:21.589953 22485033404224 run_lib.py:146] step: 341200, training_loss: 4.68300e-04
I0513 20:32:21.749420 22485033404224 run_lib.py:167] step: 341200, eval_loss: 5.41582e-04
I0513 20:32:45.565384 22485033404224 run_lib.py:146] step: 341250, training_loss: 6.44796e-04
I0513 20:33:09.087731 22485033404224 run_lib.py:146] step: 341300, training_loss: 5.95068e-04
I0513 20:33:09.248329 22485033404224 run_lib.py:167] step: 341300, eval_loss: 5.84686e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:33:33.118900 22485033404224 run_lib.py:146] step: 341350, training_loss: 5.88891e-04
I0513 20:33:56.631228 22485033404224 run_lib.py:146] step: 341400, training_loss: 4.52380e-04
I0513 20:33:56.791582 22485033404224 run_lib.py:167] step: 341400, eval_loss: 6.09957e-04
I0513 20:34:20.642975 22485033404224 run_lib.py:146] step: 341450, training_loss: 7.75162e-04
I0513 20:34:44.486959 22485033404224 run_lib.py:146] step: 341500, training_loss: 6.48922e-04
I0513 20:34:44.647845 22485033404224 run_lib.py:167] step: 341500, eval_loss: 5.60664e-04
I0513 20:35:08.171405 22485033404224 run_lib.py:146] step: 341550, training_loss: 6.17143e-04
I0513 20:35:31.981909 22485033404224 run_lib.py:146] step: 341600, training_loss: 5.92394e-04
I0513 20:35:32.141163 22485033404224 run_lib.py:167] step: 341600, eval_loss: 5.64588e-04
I0513 20:35:55.960363 22485033404224 run_lib.py:146] step: 341650, training_loss: 6.98574e-04
I0513 20:36:19.508898 22485033404224 run_lib.py:146] step: 341700, training_loss: 6.74397e-04
I0513 20:36:19.669166 22485033404224 run_lib.py:167] step: 341700, eval_loss: 5.54967e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:36:43.595627 22485033404224 run_lib.py:146] step: 341750, training_loss: 6.14589e-04
I0513 20:37:07.121778 22485033404224 run_lib.py:146] step: 341800, training_loss: 6.13627e-04
I0513 20:37:07.282370 22485033404224 run_lib.py:167] step: 341800, eval_loss: 4.93769e-04
I0513 20:37:31.142997 22485033404224 run_lib.py:146] step: 341850, training_loss: 5.85349e-04
I0513 20:37:55.024666 22485033404224 run_lib.py:146] step: 341900, training_loss: 6.54850e-04
I0513 20:37:55.183683 22485033404224 run_lib.py:167] step: 341900, eval_loss: 4.91103e-04
I0513 20:38:18.704971 22485033404224 run_lib.py:146] step: 341950, training_loss: 6.81065e-04
I0513 20:38:42.545002 22485033404224 run_lib.py:146] step: 342000, training_loss: 6.41922e-04
I0513 20:38:42.704111 22485033404224 run_lib.py:167] step: 342000, eval_loss: 4.30658e-04
I0513 20:39:06.550681 22485033404224 run_lib.py:146] step: 342050, training_loss: 7.17637e-04
I0513 20:39:30.125042 22485033404224 run_lib.py:146] step: 342100, training_loss: 5.40206e-04
I0513 20:39:30.283546 22485033404224 run_lib.py:167] step: 342100, eval_loss: 5.50618e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:39:54.163562 22485033404224 run_lib.py:146] step: 342150, training_loss: 6.10697e-04
I0513 20:40:17.686348 22485033404224 run_lib.py:146] step: 342200, training_loss: 5.47087e-04
I0513 20:40:17.846424 22485033404224 run_lib.py:167] step: 342200, eval_loss: 5.39447e-04
I0513 20:40:41.722982 22485033404224 run_lib.py:146] step: 342250, training_loss: 5.51292e-04
I0513 20:41:05.591485 22485033404224 run_lib.py:146] step: 342300, training_loss: 6.97420e-04
I0513 20:41:05.751591 22485033404224 run_lib.py:167] step: 342300, eval_loss: 6.06205e-04
I0513 20:41:29.279543 22485033404224 run_lib.py:146] step: 342350, training_loss: 6.97382e-04
I0513 20:41:53.091409 22485033404224 run_lib.py:146] step: 342400, training_loss: 6.27067e-04
I0513 20:41:53.251304 22485033404224 run_lib.py:167] step: 342400, eval_loss: 8.30825e-04
I0513 20:42:17.067146 22485033404224 run_lib.py:146] step: 342450, training_loss: 5.62254e-04
I0513 20:42:40.609696 22485033404224 run_lib.py:146] step: 342500, training_loss: 6.84838e-04
I0513 20:42:40.770354 22485033404224 run_lib.py:167] step: 342500, eval_loss: 6.89490e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:43:04.776263 22485033404224 run_lib.py:146] step: 342550, training_loss: 5.75555e-04
I0513 20:43:28.365973 22485033404224 run_lib.py:146] step: 342600, training_loss: 6.07141e-04
I0513 20:43:28.527223 22485033404224 run_lib.py:167] step: 342600, eval_loss: 6.90791e-04
I0513 20:43:52.476994 22485033404224 run_lib.py:146] step: 342650, training_loss: 6.55282e-04
I0513 20:44:16.379290 22485033404224 run_lib.py:146] step: 342700, training_loss: 5.38600e-04
I0513 20:44:16.539169 22485033404224 run_lib.py:167] step: 342700, eval_loss: 5.76296e-04
I0513 20:44:40.148818 22485033404224 run_lib.py:146] step: 342750, training_loss: 7.33613e-04
I0513 20:45:04.069294 22485033404224 run_lib.py:146] step: 342800, training_loss: 4.91964e-04
I0513 20:45:04.229245 22485033404224 run_lib.py:167] step: 342800, eval_loss: 4.60990e-04
I0513 20:45:28.118136 22485033404224 run_lib.py:146] step: 342850, training_loss: 5.97058e-04
I0513 20:45:51.702719 22485033404224 run_lib.py:146] step: 342900, training_loss: 6.39085e-04
I0513 20:45:51.863382 22485033404224 run_lib.py:167] step: 342900, eval_loss: 7.04595e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:46:16.011585 22485033404224 run_lib.py:146] step: 342950, training_loss: 7.39013e-04
I0513 20:46:39.642602 22485033404224 run_lib.py:146] step: 343000, training_loss: 6.08572e-04
I0513 20:46:39.804384 22485033404224 run_lib.py:167] step: 343000, eval_loss: 6.93191e-04
I0513 20:47:03.803655 22485033404224 run_lib.py:146] step: 343050, training_loss: 6.27818e-04
I0513 20:47:27.826916 22485033404224 run_lib.py:146] step: 343100, training_loss: 6.18405e-04
I0513 20:47:27.987381 22485033404224 run_lib.py:167] step: 343100, eval_loss: 8.30141e-04
I0513 20:47:51.592782 22485033404224 run_lib.py:146] step: 343150, training_loss: 7.23925e-04
I0513 20:48:15.486324 22485033404224 run_lib.py:146] step: 343200, training_loss: 5.96830e-04
I0513 20:48:15.647388 22485033404224 run_lib.py:167] step: 343200, eval_loss: 6.08560e-04
I0513 20:48:39.527563 22485033404224 run_lib.py:146] step: 343250, training_loss: 5.94354e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:49:03.164139 22485033404224 run_lib.py:146] step: 343300, training_loss: 7.29912e-04
I0513 20:49:03.327170 22485033404224 run_lib.py:167] step: 343300, eval_loss: 7.43987e-04
I0513 20:49:27.280758 22485033404224 run_lib.py:146] step: 343350, training_loss: 5.82464e-04
I0513 20:49:51.243839 22485033404224 run_lib.py:146] step: 343400, training_loss: 4.12532e-04
I0513 20:49:51.403677 22485033404224 run_lib.py:167] step: 343400, eval_loss: 6.64626e-04
I0513 20:50:14.961474 22485033404224 run_lib.py:146] step: 343450, training_loss: 6.98417e-04
I0513 20:50:38.795581 22485033404224 run_lib.py:146] step: 343500, training_loss: 7.45878e-04
I0513 20:50:38.954278 22485033404224 run_lib.py:167] step: 343500, eval_loss: 5.65454e-04
I0513 20:51:02.481171 22485033404224 run_lib.py:146] step: 343550, training_loss: 4.93452e-04
I0513 20:51:26.310552 22485033404224 run_lib.py:146] step: 343600, training_loss: 5.97926e-04
I0513 20:51:26.470387 22485033404224 run_lib.py:167] step: 343600, eval_loss: 6.17824e-04
I0513 20:51:50.304677 22485033404224 run_lib.py:146] step: 343650, training_loss: 5.63168e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:52:14.007662 22485033404224 run_lib.py:146] step: 343700, training_loss: 4.71609e-04
I0513 20:52:14.168871 22485033404224 run_lib.py:167] step: 343700, eval_loss: 5.09568e-04
I0513 20:52:38.037146 22485033404224 run_lib.py:146] step: 343750, training_loss: 5.84969e-04
I0513 20:53:01.925673 22485033404224 run_lib.py:146] step: 343800, training_loss: 5.81611e-04
I0513 20:53:02.085005 22485033404224 run_lib.py:167] step: 343800, eval_loss: 5.19942e-04
I0513 20:53:25.635431 22485033404224 run_lib.py:146] step: 343850, training_loss: 5.70622e-04
I0513 20:53:49.472248 22485033404224 run_lib.py:146] step: 343900, training_loss: 5.74176e-04
I0513 20:53:49.632276 22485033404224 run_lib.py:167] step: 343900, eval_loss: 6.76262e-04
I0513 20:54:13.176448 22485033404224 run_lib.py:146] step: 343950, training_loss: 6.35163e-04
I0513 20:54:37.007205 22485033404224 run_lib.py:146] step: 344000, training_loss: 7.08773e-04
I0513 20:54:37.167190 22485033404224 run_lib.py:167] step: 344000, eval_loss: 6.02213e-04
I0513 20:55:01.009147 22485033404224 run_lib.py:146] step: 344050, training_loss: 7.13107e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:55:24.618167 22485033404224 run_lib.py:146] step: 344100, training_loss: 5.82427e-04
I0513 20:55:24.779841 22485033404224 run_lib.py:167] step: 344100, eval_loss: 6.40432e-04
I0513 20:55:48.611925 22485033404224 run_lib.py:146] step: 344150, training_loss: 6.32485e-04
I0513 20:56:12.468706 22485033404224 run_lib.py:146] step: 344200, training_loss: 5.65217e-04
I0513 20:56:12.628008 22485033404224 run_lib.py:167] step: 344200, eval_loss: 7.00107e-04
I0513 20:56:36.140938 22485033404224 run_lib.py:146] step: 344250, training_loss: 6.22927e-04
I0513 20:56:59.964389 22485033404224 run_lib.py:146] step: 344300, training_loss: 5.42916e-04
I0513 20:57:00.124105 22485033404224 run_lib.py:167] step: 344300, eval_loss: 5.82920e-04
I0513 20:57:23.637616 22485033404224 run_lib.py:146] step: 344350, training_loss: 6.45624e-04
I0513 20:57:47.449117 22485033404224 run_lib.py:146] step: 344400, training_loss: 7.46647e-04
I0513 20:57:47.607930 22485033404224 run_lib.py:167] step: 344400, eval_loss: 6.64851e-04
I0513 20:58:11.500524 22485033404224 run_lib.py:146] step: 344450, training_loss: 6.53773e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:58:35.085827 22485033404224 run_lib.py:146] step: 344500, training_loss: 5.62269e-04
I0513 20:58:35.246444 22485033404224 run_lib.py:167] step: 344500, eval_loss: 5.49752e-04
I0513 20:58:59.121425 22485033404224 run_lib.py:146] step: 344550, training_loss: 4.16119e-04
I0513 20:59:22.992101 22485033404224 run_lib.py:146] step: 344600, training_loss: 5.39750e-04
I0513 20:59:23.151164 22485033404224 run_lib.py:167] step: 344600, eval_loss: 5.80688e-04
I0513 20:59:46.650650 22485033404224 run_lib.py:146] step: 344650, training_loss: 4.74725e-04
I0513 21:00:10.477955 22485033404224 run_lib.py:146] step: 344700, training_loss: 4.31573e-04
I0513 21:00:10.637058 22485033404224 run_lib.py:167] step: 344700, eval_loss: 4.67116e-04
I0513 21:00:34.480111 22485033404224 run_lib.py:146] step: 344750, training_loss: 6.50795e-04
I0513 21:00:58.067934 22485033404224 run_lib.py:146] step: 344800, training_loss: 4.87303e-04
I0513 21:00:58.228739 22485033404224 run_lib.py:167] step: 344800, eval_loss: 6.38820e-04
I0513 21:01:22.125277 22485033404224 run_lib.py:146] step: 344850, training_loss: 5.08038e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:01:45.850221 22485033404224 run_lib.py:146] step: 344900, training_loss: 4.93773e-04
I0513 21:01:46.013210 22485033404224 run_lib.py:167] step: 344900, eval_loss: 6.64602e-04
I0513 21:02:09.943601 22485033404224 run_lib.py:146] step: 344950, training_loss: 4.68935e-04
I0513 21:02:34.011669 22485033404224 run_lib.py:146] step: 345000, training_loss: 5.87804e-04
I0513 21:02:34.171449 22485033404224 run_lib.py:167] step: 345000, eval_loss: 7.50341e-04
I0513 21:02:57.763780 22485033404224 run_lib.py:146] step: 345050, training_loss: 6.40986e-04
I0513 21:03:21.635582 22485033404224 run_lib.py:146] step: 345100, training_loss: 5.61682e-04
I0513 21:03:21.795473 22485033404224 run_lib.py:167] step: 345100, eval_loss: 7.28412e-04
I0513 21:03:45.812247 22485033404224 run_lib.py:146] step: 345150, training_loss: 6.89766e-04
I0513 21:04:09.407916 22485033404224 run_lib.py:146] step: 345200, training_loss: 6.30005e-04
I0513 21:04:09.567246 22485033404224 run_lib.py:167] step: 345200, eval_loss: 5.65463e-04
I0513 21:04:33.440651 22485033404224 run_lib.py:146] step: 345250, training_loss: 6.46157e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:04:57.305484 22485033404224 run_lib.py:146] step: 345300, training_loss: 3.90568e-04
I0513 21:04:57.468408 22485033404224 run_lib.py:167] step: 345300, eval_loss: 3.63580e-04
I0513 21:05:21.510518 22485033404224 run_lib.py:146] step: 345350, training_loss: 7.00815e-04
I0513 21:05:45.594115 22485033404224 run_lib.py:146] step: 345400, training_loss: 7.22842e-04
I0513 21:05:45.753161 22485033404224 run_lib.py:167] step: 345400, eval_loss: 5.55110e-04
I0513 21:06:09.411798 22485033404224 run_lib.py:146] step: 345450, training_loss: 5.94558e-04
I0513 21:06:33.384863 22485033404224 run_lib.py:146] step: 345500, training_loss: 5.81204e-04
I0513 21:06:33.545599 22485033404224 run_lib.py:167] step: 345500, eval_loss: 5.93062e-04
I0513 21:06:57.587693 22485033404224 run_lib.py:146] step: 345550, training_loss: 5.85345e-04
I0513 21:07:21.214611 22485033404224 run_lib.py:146] step: 345600, training_loss: 6.65170e-04
I0513 21:07:21.375646 22485033404224 run_lib.py:167] step: 345600, eval_loss: 5.65539e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:07:45.446621 22485033404224 run_lib.py:146] step: 345650, training_loss: 6.06097e-04
I0513 21:08:09.056419 22485033404224 run_lib.py:146] step: 345700, training_loss: 5.47002e-04
I0513 21:08:09.217280 22485033404224 run_lib.py:167] step: 345700, eval_loss: 8.10578e-04
I0513 21:08:33.216158 22485033404224 run_lib.py:146] step: 345750, training_loss: 5.11693e-04
I0513 21:08:57.046916 22485033404224 run_lib.py:146] step: 345800, training_loss: 7.05490e-04
I0513 21:08:57.206201 22485033404224 run_lib.py:167] step: 345800, eval_loss: 7.03678e-04
I0513 21:09:20.737691 22485033404224 run_lib.py:146] step: 345850, training_loss: 6.10482e-04
I0513 21:09:44.548054 22485033404224 run_lib.py:146] step: 345900, training_loss: 6.45425e-04
I0513 21:09:44.706501 22485033404224 run_lib.py:167] step: 345900, eval_loss: 4.95240e-04
I0513 21:10:08.518318 22485033404224 run_lib.py:146] step: 345950, training_loss: 5.51798e-04
I0513 21:10:32.049323 22485033404224 run_lib.py:146] step: 346000, training_loss: 4.78543e-04
I0513 21:10:32.208741 22485033404224 run_lib.py:167] step: 346000, eval_loss: 7.10069e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:10:56.108660 22485033404224 run_lib.py:146] step: 346050, training_loss: 7.00573e-04
I0513 21:11:19.621112 22485033404224 run_lib.py:146] step: 346100, training_loss: 6.10846e-04
I0513 21:11:19.781239 22485033404224 run_lib.py:167] step: 346100, eval_loss: 5.88066e-04
I0513 21:11:43.645969 22485033404224 run_lib.py:146] step: 346150, training_loss: 7.40260e-04
I0513 21:12:07.511298 22485033404224 run_lib.py:146] step: 346200, training_loss: 7.05237e-04
I0513 21:12:07.763439 22485033404224 run_lib.py:167] step: 346200, eval_loss: 4.78951e-04
I0513 21:12:31.297833 22485033404224 run_lib.py:146] step: 346250, training_loss: 6.11599e-04
I0513 21:12:55.133425 22485033404224 run_lib.py:146] step: 346300, training_loss: 5.39410e-04
I0513 21:12:55.294211 22485033404224 run_lib.py:167] step: 346300, eval_loss: 5.83588e-04
I0513 21:13:19.139898 22485033404224 run_lib.py:146] step: 346350, training_loss: 5.92359e-04
I0513 21:13:42.673429 22485033404224 run_lib.py:146] step: 346400, training_loss: 8.17360e-04
I0513 21:13:42.831907 22485033404224 run_lib.py:167] step: 346400, eval_loss: 7.65561e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:14:06.727817 22485033404224 run_lib.py:146] step: 346450, training_loss: 6.51373e-04
I0513 21:14:30.251696 22485033404224 run_lib.py:146] step: 346500, training_loss: 6.03813e-04
I0513 21:14:30.412321 22485033404224 run_lib.py:167] step: 346500, eval_loss: 5.96602e-04
I0513 21:14:54.264509 22485033404224 run_lib.py:146] step: 346550, training_loss: 6.71823e-04
I0513 21:15:18.154053 22485033404224 run_lib.py:146] step: 346600, training_loss: 8.10446e-04
I0513 21:15:18.313621 22485033404224 run_lib.py:167] step: 346600, eval_loss: 7.83657e-04
I0513 21:15:41.853471 22485033404224 run_lib.py:146] step: 346650, training_loss: 7.22836e-04
I0513 21:16:05.686030 22485033404224 run_lib.py:146] step: 346700, training_loss: 6.58206e-04
I0513 21:16:05.845281 22485033404224 run_lib.py:167] step: 346700, eval_loss: 4.73202e-04
I0513 21:16:29.672030 22485033404224 run_lib.py:146] step: 346750, training_loss: 5.78473e-04
I0513 21:16:53.182661 22485033404224 run_lib.py:146] step: 346800, training_loss: 5.37804e-04
I0513 21:16:53.342208 22485033404224 run_lib.py:167] step: 346800, eval_loss: 8.30938e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:17:17.368757 22485033404224 run_lib.py:146] step: 346850, training_loss: 4.30825e-04
I0513 21:17:40.901433 22485033404224 run_lib.py:146] step: 346900, training_loss: 4.26536e-04
I0513 21:17:41.062221 22485033404224 run_lib.py:167] step: 346900, eval_loss: 7.49875e-04
I0513 21:18:04.895109 22485033404224 run_lib.py:146] step: 346950, training_loss: 6.10286e-04
I0513 21:18:28.731034 22485033404224 run_lib.py:146] step: 347000, training_loss: 8.32109e-04
I0513 21:18:28.889410 22485033404224 run_lib.py:167] step: 347000, eval_loss: 6.66681e-04
I0513 21:18:52.462820 22485033404224 run_lib.py:146] step: 347050, training_loss: 4.86918e-04
I0513 21:19:16.381238 22485033404224 run_lib.py:146] step: 347100, training_loss: 6.80816e-04
I0513 21:19:16.541646 22485033404224 run_lib.py:167] step: 347100, eval_loss: 5.73245e-04
I0513 21:19:40.466564 22485033404224 run_lib.py:146] step: 347150, training_loss: 6.01943e-04
I0513 21:20:04.077335 22485033404224 run_lib.py:146] step: 347200, training_loss: 5.92407e-04
I0513 21:20:04.238159 22485033404224 run_lib.py:167] step: 347200, eval_loss: 4.73363e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:20:28.278124 22485033404224 run_lib.py:146] step: 347250, training_loss: 5.99594e-04
I0513 21:20:52.230711 22485033404224 run_lib.py:146] step: 347300, training_loss: 7.32408e-04
I0513 21:20:52.392731 22485033404224 run_lib.py:167] step: 347300, eval_loss: 6.50746e-04
I0513 21:21:15.974083 22485033404224 run_lib.py:146] step: 347350, training_loss: 8.78308e-04
I0513 21:21:39.876336 22485033404224 run_lib.py:146] step: 347400, training_loss: 6.37804e-04
I0513 21:21:40.035618 22485033404224 run_lib.py:167] step: 347400, eval_loss: 4.69039e-04
I0513 21:22:03.621559 22485033404224 run_lib.py:146] step: 347450, training_loss: 5.60714e-04
I0513 21:22:27.494632 22485033404224 run_lib.py:146] step: 347500, training_loss: 4.14852e-04
I0513 21:22:27.578530 22485033404224 run_lib.py:167] step: 347500, eval_loss: 1.00008e-03
I0513 21:22:51.493629 22485033404224 run_lib.py:146] step: 347550, training_loss: 3.41746e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:23:15.218885 22485033404224 run_lib.py:146] step: 347600, training_loss: 6.81692e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:23:15.567334 22485033404224 run_lib.py:167] step: 347600, eval_loss: 6.53689e-04
I0513 21:23:39.527574 22485033404224 run_lib.py:146] step: 347650, training_loss: 5.81413e-04
I0513 21:24:03.173866 22485033404224 run_lib.py:146] step: 347700, training_loss: 3.96288e-04
I0513 21:24:03.334801 22485033404224 run_lib.py:167] step: 347700, eval_loss: 6.38921e-04
I0513 21:24:27.296714 22485033404224 run_lib.py:146] step: 347750, training_loss: 6.66022e-04
I0513 21:24:51.224220 22485033404224 run_lib.py:146] step: 347800, training_loss: 5.55066e-04
I0513 21:24:51.385271 22485033404224 run_lib.py:167] step: 347800, eval_loss: 5.44354e-04
I0513 21:25:15.013481 22485033404224 run_lib.py:146] step: 347850, training_loss: 5.95732e-04
I0513 21:25:38.955579 22485033404224 run_lib.py:146] step: 347900, training_loss: 6.29309e-04
I0513 21:25:39.116744 22485033404224 run_lib.py:167] step: 347900, eval_loss: 6.22825e-04
I0513 21:26:02.979753 22485033404224 run_lib.py:146] step: 347950, training_loss: 6.55818e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:26:26.596407 22485033404224 run_lib.py:146] step: 348000, training_loss: 6.49377e-04
I0513 21:26:26.758821 22485033404224 run_lib.py:167] step: 348000, eval_loss: 7.28967e-04
I0513 21:26:50.608777 22485033404224 run_lib.py:146] step: 348050, training_loss: 6.43197e-04
I0513 21:27:14.446402 22485033404224 run_lib.py:146] step: 348100, training_loss: 7.68218e-04
I0513 21:27:14.606240 22485033404224 run_lib.py:167] step: 348100, eval_loss: 4.54776e-04
I0513 21:27:38.148592 22485033404224 run_lib.py:146] step: 348150, training_loss: 7.83184e-04
I0513 21:28:01.979072 22485033404224 run_lib.py:146] step: 348200, training_loss: 5.56655e-04
I0513 21:28:02.139147 22485033404224 run_lib.py:167] step: 348200, eval_loss: 8.01267e-04
I0513 21:28:25.967274 22485033404224 run_lib.py:146] step: 348250, training_loss: 7.23980e-04
I0513 21:28:49.494997 22485033404224 run_lib.py:146] step: 348300, training_loss: 7.84541e-04
I0513 21:28:49.654431 22485033404224 run_lib.py:167] step: 348300, eval_loss: 5.80029e-04
I0513 21:29:13.470927 22485033404224 run_lib.py:146] step: 348350, training_loss: 5.31777e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:29:37.077045 22485033404224 run_lib.py:146] step: 348400, training_loss: 5.57205e-04
I0513 21:29:37.382757 22485033404224 run_lib.py:167] step: 348400, eval_loss: 5.36041e-04
I0513 21:30:01.244266 22485033404224 run_lib.py:146] step: 348450, training_loss: 5.73058e-04
I0513 21:30:25.119053 22485033404224 run_lib.py:146] step: 348500, training_loss: 7.34016e-04
I0513 21:30:25.277886 22485033404224 run_lib.py:167] step: 348500, eval_loss: 7.21233e-04
I0513 21:30:48.803077 22485033404224 run_lib.py:146] step: 348550, training_loss: 6.68993e-04
I0513 21:31:12.633267 22485033404224 run_lib.py:146] step: 348600, training_loss: 6.77493e-04
I0513 21:31:12.793988 22485033404224 run_lib.py:167] step: 348600, eval_loss: 7.28344e-04
I0513 21:31:36.325600 22485033404224 run_lib.py:146] step: 348650, training_loss: 5.72478e-04
I0513 21:32:00.173831 22485033404224 run_lib.py:146] step: 348700, training_loss: 6.67834e-04
I0513 21:32:00.332569 22485033404224 run_lib.py:167] step: 348700, eval_loss: 4.79021e-04
I0513 21:32:24.164674 22485033404224 run_lib.py:146] step: 348750, training_loss: 9.00710e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:32:47.773292 22485033404224 run_lib.py:146] step: 348800, training_loss: 7.01994e-04
I0513 21:32:47.933802 22485033404224 run_lib.py:167] step: 348800, eval_loss: 6.83435e-04
I0513 21:33:11.808043 22485033404224 run_lib.py:146] step: 348850, training_loss: 5.92247e-04
I0513 21:33:35.683294 22485033404224 run_lib.py:146] step: 348900, training_loss: 6.09340e-04
I0513 21:33:35.842809 22485033404224 run_lib.py:167] step: 348900, eval_loss: 5.43522e-04
I0513 21:33:59.373462 22485033404224 run_lib.py:146] step: 348950, training_loss: 4.83457e-04
I0513 21:34:23.187472 22485033404224 run_lib.py:146] step: 349000, training_loss: 4.42684e-04
I0513 21:34:23.346805 22485033404224 run_lib.py:167] step: 349000, eval_loss: 6.93776e-04
I0513 21:34:47.152435 22485033404224 run_lib.py:146] step: 349050, training_loss: 5.36366e-04
I0513 21:35:10.667464 22485033404224 run_lib.py:146] step: 349100, training_loss: 5.79444e-04
I0513 21:35:10.825659 22485033404224 run_lib.py:167] step: 349100, eval_loss: 5.78766e-04
I0513 21:35:34.661976 22485033404224 run_lib.py:146] step: 349150, training_loss: 5.68267e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:35:58.441423 22485033404224 run_lib.py:146] step: 349200, training_loss: 6.44472e-04
I0513 21:35:58.603843 22485033404224 run_lib.py:167] step: 349200, eval_loss: 5.94690e-04
I0513 21:36:22.478514 22485033404224 run_lib.py:146] step: 349250, training_loss: 5.23054e-04
I0513 21:36:46.449776 22485033404224 run_lib.py:146] step: 349300, training_loss: 5.96641e-04
I0513 21:36:46.610140 22485033404224 run_lib.py:167] step: 349300, eval_loss: 4.97530e-04
I0513 21:37:10.202855 22485033404224 run_lib.py:146] step: 349350, training_loss: 5.04944e-04
I0513 21:37:34.087347 22485033404224 run_lib.py:146] step: 349400, training_loss: 5.81585e-04
I0513 21:37:34.247601 22485033404224 run_lib.py:167] step: 349400, eval_loss: 5.55941e-04
I0513 21:37:57.866929 22485033404224 run_lib.py:146] step: 349450, training_loss: 5.58169e-04
I0513 21:38:21.764364 22485033404224 run_lib.py:146] step: 349500, training_loss: 5.32652e-04
I0513 21:38:21.924902 22485033404224 run_lib.py:167] step: 349500, eval_loss: 6.98138e-04
I0513 21:38:45.858567 22485033404224 run_lib.py:146] step: 349550, training_loss: 5.48630e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:39:09.681143 22485033404224 run_lib.py:146] step: 349600, training_loss: 4.86099e-04
I0513 21:39:09.845312 22485033404224 run_lib.py:167] step: 349600, eval_loss: 4.94509e-04
I0513 21:39:34.042881 22485033404224 run_lib.py:146] step: 349650, training_loss: 6.96187e-04
I0513 21:39:58.254066 22485033404224 run_lib.py:146] step: 349700, training_loss: 6.49891e-04
I0513 21:39:58.416173 22485033404224 run_lib.py:167] step: 349700, eval_loss: 6.09928e-04
I0513 21:40:22.127799 22485033404224 run_lib.py:146] step: 349750, training_loss: 7.94517e-04
I0513 21:40:46.387700 22485033404224 run_lib.py:146] step: 349800, training_loss: 7.81904e-04
I0513 21:40:46.549717 22485033404224 run_lib.py:167] step: 349800, eval_loss: 3.73236e-04
I0513 21:41:10.604217 22485033404224 run_lib.py:146] step: 349850, training_loss: 5.74473e-04
I0513 21:41:34.226461 22485033404224 run_lib.py:146] step: 349900, training_loss: 4.66826e-04
I0513 21:41:34.386300 22485033404224 run_lib.py:167] step: 349900, eval_loss: 5.35060e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:41:58.359216 22485033404224 run_lib.py:146] step: 349950, training_loss: 5.14458e-04
I0513 21:42:21.958780 22485033404224 run_lib.py:146] step: 350000, training_loss: 5.31495e-04
I0513 21:42:36.582238 22485033404224 run_lib.py:167] step: 350000, eval_loss: 8.26589e-04
I0513 21:43:13.904561 22485033404224 run_lib.py:146] step: 350050, training_loss: 6.31570e-04
I0513 21:43:37.823697 22485033404224 run_lib.py:146] step: 350100, training_loss: 6.69788e-04
I0513 21:43:37.983649 22485033404224 run_lib.py:167] step: 350100, eval_loss: 4.70913e-04
I0513 21:44:01.901082 22485033404224 run_lib.py:146] step: 350150, training_loss: 6.50000e-04
I0513 21:44:25.445677 22485033404224 run_lib.py:146] step: 350200, training_loss: 7.73300e-04
I0513 21:44:25.605776 22485033404224 run_lib.py:167] step: 350200, eval_loss: 7.91120e-04
I0513 21:44:49.478132 22485033404224 run_lib.py:146] step: 350250, training_loss: 5.73189e-04
I0513 21:45:13.303393 22485033404224 run_lib.py:146] step: 350300, training_loss: 6.24089e-04
I0513 21:45:13.462025 22485033404224 run_lib.py:167] step: 350300, eval_loss: 7.63199e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:45:37.131926 22485033404224 run_lib.py:146] step: 350350, training_loss: 3.44394e-04
I0513 21:46:00.655880 22485033404224 run_lib.py:146] step: 350400, training_loss: 6.12578e-04
I0513 21:46:00.817186 22485033404224 run_lib.py:167] step: 350400, eval_loss: 5.50497e-04
I0513 21:46:25.001159 22485033404224 run_lib.py:146] step: 350450, training_loss: 5.25012e-04
I0513 21:46:48.517937 22485033404224 run_lib.py:146] step: 350500, training_loss: 6.58045e-04
I0513 21:46:48.677333 22485033404224 run_lib.py:167] step: 350500, eval_loss: 5.17346e-04
I0513 21:47:12.191512 22485033404224 run_lib.py:146] step: 350550, training_loss: 7.55324e-04
I0513 21:47:35.999719 22485033404224 run_lib.py:146] step: 350600, training_loss: 6.36959e-04
I0513 21:47:36.160217 22485033404224 run_lib.py:167] step: 350600, eval_loss: 5.37539e-04
I0513 21:47:59.968322 22485033404224 run_lib.py:146] step: 350650, training_loss: 7.58360e-04
I0513 21:48:23.485987 22485033404224 run_lib.py:146] step: 350700, training_loss: 5.34759e-04
I0513 21:48:23.645965 22485033404224 run_lib.py:167] step: 350700, eval_loss: 6.48857e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:48:47.593676 22485033404224 run_lib.py:146] step: 350750, training_loss: 6.39715e-04
I0513 21:49:11.435432 22485033404224 run_lib.py:146] step: 350800, training_loss: 6.68432e-04
I0513 21:49:11.595881 22485033404224 run_lib.py:167] step: 350800, eval_loss: 5.76686e-04
I0513 21:49:35.111343 22485033404224 run_lib.py:146] step: 350850, training_loss: 6.44616e-04
I0513 21:49:58.922567 22485033404224 run_lib.py:146] step: 350900, training_loss: 7.00607e-04
I0513 21:49:59.082665 22485033404224 run_lib.py:167] step: 350900, eval_loss: 4.58158e-04
I0513 21:50:22.902738 22485033404224 run_lib.py:146] step: 350950, training_loss: 4.19591e-04
I0513 21:50:46.415678 22485033404224 run_lib.py:146] step: 351000, training_loss: 8.38936e-04
I0513 21:50:46.575748 22485033404224 run_lib.py:167] step: 351000, eval_loss: 5.86087e-04
I0513 21:51:10.369577 22485033404224 run_lib.py:146] step: 351050, training_loss: 5.97884e-04
I0513 21:51:34.180994 22485033404224 run_lib.py:146] step: 351100, training_loss: 6.24962e-04
I0513 21:51:34.340177 22485033404224 run_lib.py:167] step: 351100, eval_loss: 6.06299e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:51:57.979181 22485033404224 run_lib.py:146] step: 351150, training_loss: 6.21989e-04
I0513 21:52:21.506363 22485033404224 run_lib.py:146] step: 351200, training_loss: 6.04088e-04
I0513 21:52:21.667435 22485033404224 run_lib.py:167] step: 351200, eval_loss: 5.32299e-04
I0513 21:52:45.842159 22485033404224 run_lib.py:146] step: 351250, training_loss: 5.25003e-04
I0513 21:53:09.366558 22485033404224 run_lib.py:146] step: 351300, training_loss: 6.99574e-04
I0513 21:53:09.525804 22485033404224 run_lib.py:167] step: 351300, eval_loss: 6.18233e-04
I0513 21:53:33.045127 22485033404224 run_lib.py:146] step: 351350, training_loss: 8.28754e-04
I0513 21:53:56.875030 22485033404224 run_lib.py:146] step: 351400, training_loss: 6.89742e-04
I0513 21:53:57.034198 22485033404224 run_lib.py:167] step: 351400, eval_loss: 5.59253e-04
I0513 21:54:20.937547 22485033404224 run_lib.py:146] step: 351450, training_loss: 8.55903e-04
I0513 21:54:44.562200 22485033404224 run_lib.py:146] step: 351500, training_loss: 5.03008e-04
I0513 21:54:44.722609 22485033404224 run_lib.py:167] step: 351500, eval_loss: 5.39173e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:55:08.745851 22485033404224 run_lib.py:146] step: 351550, training_loss: 5.18486e-04
I0513 21:55:32.748556 22485033404224 run_lib.py:146] step: 351600, training_loss: 6.69355e-04
I0513 21:55:32.911124 22485033404224 run_lib.py:167] step: 351600, eval_loss: 6.21058e-04
I0513 21:55:56.538819 22485033404224 run_lib.py:146] step: 351650, training_loss: 5.53985e-04
I0513 21:56:20.422062 22485033404224 run_lib.py:146] step: 351700, training_loss: 6.85168e-04
I0513 21:56:20.583356 22485033404224 run_lib.py:167] step: 351700, eval_loss: 4.45173e-04
I0513 21:56:44.438220 22485033404224 run_lib.py:146] step: 351750, training_loss: 6.36410e-04
I0513 21:57:08.028026 22485033404224 run_lib.py:146] step: 351800, training_loss: 4.61319e-04
I0513 21:57:08.187700 22485033404224 run_lib.py:167] step: 351800, eval_loss: 5.38113e-04
I0513 21:57:32.037981 22485033404224 run_lib.py:146] step: 351850, training_loss: 5.09692e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:57:55.999872 22485033404224 run_lib.py:146] step: 351900, training_loss: 4.72254e-04
I0513 21:57:56.161629 22485033404224 run_lib.py:167] step: 351900, eval_loss: 4.19586e-04
I0513 21:58:19.794167 22485033404224 run_lib.py:146] step: 351950, training_loss: 5.99482e-04
I0513 21:58:43.421808 22485033404224 run_lib.py:146] step: 352000, training_loss: 6.61127e-04
I0513 21:58:43.581802 22485033404224 run_lib.py:167] step: 352000, eval_loss: 5.83183e-04
I0513 21:59:07.902080 22485033404224 run_lib.py:146] step: 352050, training_loss: 6.03709e-04
I0513 21:59:31.536032 22485033404224 run_lib.py:146] step: 352100, training_loss: 5.07053e-04
I0513 21:59:31.697549 22485033404224 run_lib.py:167] step: 352100, eval_loss: 5.69452e-04
I0513 21:59:55.317763 22485033404224 run_lib.py:146] step: 352150, training_loss: 7.04241e-04
I0513 22:00:19.213551 22485033404224 run_lib.py:146] step: 352200, training_loss: 5.09020e-04
I0513 22:00:19.373789 22485033404224 run_lib.py:167] step: 352200, eval_loss: 5.66933e-04
I0513 22:00:43.296270 22485033404224 run_lib.py:146] step: 352250, training_loss: 6.55251e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:01:06.984165 22485033404224 run_lib.py:146] step: 352300, training_loss: 5.36880e-04
I0513 22:01:07.145925 22485033404224 run_lib.py:167] step: 352300, eval_loss: 6.16824e-04
I0513 22:01:31.019342 22485033404224 run_lib.py:146] step: 352350, training_loss: 5.76745e-04
I0513 22:01:54.878877 22485033404224 run_lib.py:146] step: 352400, training_loss: 6.22463e-04
I0513 22:01:55.038142 22485033404224 run_lib.py:167] step: 352400, eval_loss: 4.95900e-04
I0513 22:02:18.573800 22485033404224 run_lib.py:146] step: 352450, training_loss: 7.09683e-04
I0513 22:02:42.409670 22485033404224 run_lib.py:146] step: 352500, training_loss: 5.40224e-04
I0513 22:02:42.569175 22485033404224 run_lib.py:167] step: 352500, eval_loss: 5.75615e-04
I0513 22:03:06.382088 22485033404224 run_lib.py:146] step: 352550, training_loss: 4.55260e-04
I0513 22:03:29.897744 22485033404224 run_lib.py:146] step: 352600, training_loss: 5.51458e-04
I0513 22:03:30.056628 22485033404224 run_lib.py:167] step: 352600, eval_loss: 5.72719e-04
I0513 22:03:53.859015 22485033404224 run_lib.py:146] step: 352650, training_loss: 5.99110e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:04:17.800616 22485033404224 run_lib.py:146] step: 352700, training_loss: 7.28185e-04
I0513 22:04:17.960675 22485033404224 run_lib.py:167] step: 352700, eval_loss: 4.94857e-04
I0513 22:04:41.476410 22485033404224 run_lib.py:146] step: 352750, training_loss: 5.68541e-04
I0513 22:05:05.323397 22485033404224 run_lib.py:146] step: 352800, training_loss: 5.41474e-04
I0513 22:05:05.484058 22485033404224 run_lib.py:167] step: 352800, eval_loss: 5.58705e-04
I0513 22:05:29.283262 22485033404224 run_lib.py:146] step: 352850, training_loss: 6.71530e-04
I0513 22:05:52.782537 22485033404224 run_lib.py:146] step: 352900, training_loss: 7.36117e-04
I0513 22:05:52.960709 22485033404224 run_lib.py:167] step: 352900, eval_loss: 6.34494e-04
I0513 22:06:16.473859 22485033404224 run_lib.py:146] step: 352950, training_loss: 6.31008e-04
I0513 22:06:40.306441 22485033404224 run_lib.py:146] step: 353000, training_loss: 6.21334e-04
I0513 22:06:40.465700 22485033404224 run_lib.py:167] step: 353000, eval_loss: 5.43446e-04
I0513 22:07:04.286484 22485033404224 run_lib.py:146] step: 353050, training_loss: 6.35311e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:07:27.908946 22485033404224 run_lib.py:146] step: 353100, training_loss: 7.11414e-04
I0513 22:07:28.069674 22485033404224 run_lib.py:167] step: 353100, eval_loss: 6.10284e-04
I0513 22:07:51.917982 22485033404224 run_lib.py:146] step: 353150, training_loss: 5.39048e-04
I0513 22:08:15.769040 22485033404224 run_lib.py:146] step: 353200, training_loss: 6.58362e-04
I0513 22:08:15.929513 22485033404224 run_lib.py:167] step: 353200, eval_loss: 6.20914e-04
I0513 22:08:39.503182 22485033404224 run_lib.py:146] step: 353250, training_loss: 3.98395e-04
I0513 22:09:03.327838 22485033404224 run_lib.py:146] step: 353300, training_loss: 4.55757e-04
I0513 22:09:03.487934 22485033404224 run_lib.py:167] step: 353300, eval_loss: 4.17863e-04
I0513 22:09:27.316711 22485033404224 run_lib.py:146] step: 353350, training_loss: 4.57338e-04
I0513 22:09:50.841049 22485033404224 run_lib.py:146] step: 353400, training_loss: 8.45467e-04
I0513 22:09:51.000714 22485033404224 run_lib.py:167] step: 353400, eval_loss: 7.91663e-04
I0513 22:10:14.803002 22485033404224 run_lib.py:146] step: 353450, training_loss: 6.53810e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:10:38.717327 22485033404224 run_lib.py:146] step: 353500, training_loss: 5.18216e-04
I0513 22:10:38.879210 22485033404224 run_lib.py:167] step: 353500, eval_loss: 5.56590e-04
I0513 22:11:02.373454 22485033404224 run_lib.py:146] step: 353550, training_loss: 4.71450e-04
I0513 22:11:26.215685 22485033404224 run_lib.py:146] step: 353600, training_loss: 6.17593e-04
I0513 22:11:26.374093 22485033404224 run_lib.py:167] step: 353600, eval_loss: 7.04621e-04
I0513 22:11:50.222062 22485033404224 run_lib.py:146] step: 353650, training_loss: 9.50703e-04
I0513 22:12:13.824562 22485033404224 run_lib.py:146] step: 353700, training_loss: 6.46486e-04
I0513 22:12:13.985231 22485033404224 run_lib.py:167] step: 353700, eval_loss: 5.90246e-04
I0513 22:12:37.586876 22485033404224 run_lib.py:146] step: 353750, training_loss: 6.90273e-04
I0513 22:13:01.462273 22485033404224 run_lib.py:146] step: 353800, training_loss: 7.25658e-04
I0513 22:13:01.622351 22485033404224 run_lib.py:167] step: 353800, eval_loss: 6.12389e-04
I0513 22:13:25.547821 22485033404224 run_lib.py:146] step: 353850, training_loss: 6.16842e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:13:49.200990 22485033404224 run_lib.py:146] step: 353900, training_loss: 5.54531e-04
I0513 22:13:49.363765 22485033404224 run_lib.py:167] step: 353900, eval_loss: 4.44942e-04
I0513 22:14:13.403909 22485033404224 run_lib.py:146] step: 353950, training_loss: 6.50058e-04
I0513 22:14:37.430631 22485033404224 run_lib.py:146] step: 354000, training_loss: 6.23878e-04
I0513 22:14:37.590593 22485033404224 run_lib.py:167] step: 354000, eval_loss: 5.54951e-04
I0513 22:15:01.156487 22485033404224 run_lib.py:146] step: 354050, training_loss: 5.21505e-04
I0513 22:15:25.118183 22485033404224 run_lib.py:146] step: 354100, training_loss: 6.66770e-04
I0513 22:15:25.278310 22485033404224 run_lib.py:167] step: 354100, eval_loss: 7.79475e-04
I0513 22:15:49.252092 22485033404224 run_lib.py:146] step: 354150, training_loss: 6.07338e-04
I0513 22:16:12.862481 22485033404224 run_lib.py:146] step: 354200, training_loss: 6.77439e-04
I0513 22:16:13.023447 22485033404224 run_lib.py:167] step: 354200, eval_loss: 5.74025e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:16:37.010161 22485033404224 run_lib.py:146] step: 354250, training_loss: 6.48189e-04
I0513 22:17:00.972513 22485033404224 run_lib.py:146] step: 354300, training_loss: 5.49549e-04
I0513 22:17:01.135076 22485033404224 run_lib.py:167] step: 354300, eval_loss: 5.65051e-04
I0513 22:17:24.751295 22485033404224 run_lib.py:146] step: 354350, training_loss: 7.16448e-04
I0513 22:17:48.797645 22485033404224 run_lib.py:146] step: 354400, training_loss: 5.81845e-04
I0513 22:17:48.957427 22485033404224 run_lib.py:167] step: 354400, eval_loss: 6.79331e-04
I0513 22:18:12.881172 22485033404224 run_lib.py:146] step: 354450, training_loss: 5.01216e-04
I0513 22:18:36.495017 22485033404224 run_lib.py:146] step: 354500, training_loss: 6.01586e-04
I0513 22:18:36.654848 22485033404224 run_lib.py:167] step: 354500, eval_loss: 6.01584e-04
I0513 22:19:00.229953 22485033404224 run_lib.py:146] step: 354550, training_loss: 8.32026e-04
I0513 22:19:24.157310 22485033404224 run_lib.py:146] step: 354600, training_loss: 5.70172e-04
I0513 22:19:24.316310 22485033404224 run_lib.py:167] step: 354600, eval_loss: 7.58595e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:19:48.225097 22485033404224 run_lib.py:146] step: 354650, training_loss: 7.05232e-04
I0513 22:20:11.753083 22485033404224 run_lib.py:146] step: 354700, training_loss: 6.58133e-04
I0513 22:20:11.991773 22485033404224 run_lib.py:167] step: 354700, eval_loss: 6.20088e-04
I0513 22:20:35.890551 22485033404224 run_lib.py:146] step: 354750, training_loss: 6.65056e-04
I0513 22:20:59.752904 22485033404224 run_lib.py:146] step: 354800, training_loss: 6.33746e-04
I0513 22:20:59.911875 22485033404224 run_lib.py:167] step: 354800, eval_loss: 7.22798e-04
I0513 22:21:23.442221 22485033404224 run_lib.py:146] step: 354850, training_loss: 6.26917e-04
I0513 22:21:47.254734 22485033404224 run_lib.py:146] step: 354900, training_loss: 6.21156e-04
I0513 22:21:47.413794 22485033404224 run_lib.py:167] step: 354900, eval_loss: 4.79230e-04
I0513 22:22:11.217845 22485033404224 run_lib.py:146] step: 354950, training_loss: 6.24642e-04
I0513 22:22:34.739228 22485033404224 run_lib.py:146] step: 355000, training_loss: 6.40097e-04
I0513 22:22:34.899290 22485033404224 run_lib.py:167] step: 355000, eval_loss: 9.12811e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:22:58.867141 22485033404224 run_lib.py:146] step: 355050, training_loss: 6.69208e-04
I0513 22:23:22.747196 22485033404224 run_lib.py:146] step: 355100, training_loss: 6.63136e-04
I0513 22:23:22.909177 22485033404224 run_lib.py:167] step: 355100, eval_loss: 5.60347e-04
I0513 22:23:46.435215 22485033404224 run_lib.py:146] step: 355150, training_loss: 5.78984e-04
I0513 22:24:10.274513 22485033404224 run_lib.py:146] step: 355200, training_loss: 7.16486e-04
I0513 22:24:10.434765 22485033404224 run_lib.py:167] step: 355200, eval_loss: 6.49998e-04
I0513 22:24:34.294426 22485033404224 run_lib.py:146] step: 355250, training_loss: 7.19087e-04
I0513 22:24:57.823399 22485033404224 run_lib.py:146] step: 355300, training_loss: 5.89221e-04
I0513 22:24:57.981816 22485033404224 run_lib.py:167] step: 355300, eval_loss: 6.70400e-04
I0513 22:25:21.500249 22485033404224 run_lib.py:146] step: 355350, training_loss: 6.64718e-04
I0513 22:25:45.339837 22485033404224 run_lib.py:146] step: 355400, training_loss: 6.20730e-04
I0513 22:25:45.424819 22485033404224 run_lib.py:167] step: 355400, eval_loss: 4.58770e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:26:09.347507 22485033404224 run_lib.py:146] step: 355450, training_loss: 7.01818e-04
I0513 22:26:32.874871 22485033404224 run_lib.py:146] step: 355500, training_loss: 6.97053e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:26:33.220699 22485033404224 run_lib.py:167] step: 355500, eval_loss: 8.40123e-04
I0513 22:26:57.092283 22485033404224 run_lib.py:146] step: 355550, training_loss: 6.11796e-04
I0513 22:27:20.976236 22485033404224 run_lib.py:146] step: 355600, training_loss: 5.89175e-04
I0513 22:27:21.136435 22485033404224 run_lib.py:167] step: 355600, eval_loss: 7.70276e-04
I0513 22:27:44.678632 22485033404224 run_lib.py:146] step: 355650, training_loss: 6.15469e-04
I0513 22:28:08.518510 22485033404224 run_lib.py:146] step: 355700, training_loss: 4.99359e-04
I0513 22:28:08.679832 22485033404224 run_lib.py:167] step: 355700, eval_loss: 5.24074e-04
I0513 22:28:32.537333 22485033404224 run_lib.py:146] step: 355750, training_loss: 6.52444e-04
I0513 22:28:56.098827 22485033404224 run_lib.py:146] step: 355800, training_loss: 5.03566e-04
I0513 22:28:56.258323 22485033404224 run_lib.py:167] step: 355800, eval_loss: 4.89024e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:29:20.212499 22485033404224 run_lib.py:146] step: 355850, training_loss: 5.48982e-04
I0513 22:29:44.187765 22485033404224 run_lib.py:146] step: 355900, training_loss: 6.03587e-04
I0513 22:29:44.349556 22485033404224 run_lib.py:167] step: 355900, eval_loss: 3.58307e-04
I0513 22:30:07.953129 22485033404224 run_lib.py:146] step: 355950, training_loss: 6.46675e-04
I0513 22:30:31.874584 22485033404224 run_lib.py:146] step: 356000, training_loss: 6.66728e-04
I0513 22:30:32.035808 22485033404224 run_lib.py:167] step: 356000, eval_loss: 6.26399e-04
I0513 22:30:55.974915 22485033404224 run_lib.py:146] step: 356050, training_loss: 5.53601e-04
I0513 22:31:19.571403 22485033404224 run_lib.py:146] step: 356100, training_loss: 6.29969e-04
I0513 22:31:19.731683 22485033404224 run_lib.py:167] step: 356100, eval_loss: 7.92577e-04
I0513 22:31:43.643036 22485033404224 run_lib.py:146] step: 356150, training_loss: 6.17648e-04
I0513 22:32:07.118188 22485033404224 run_lib.py:146] step: 356200, training_loss: 5.16072e-04
I0513 22:32:07.278877 22485033404224 run_lib.py:167] step: 356200, eval_loss: 5.36432e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:32:31.418674 22485033404224 run_lib.py:146] step: 356250, training_loss: 6.49436e-04
I0513 22:32:55.013918 22485033404224 run_lib.py:146] step: 356300, training_loss: 6.16393e-04
I0513 22:32:55.175810 22485033404224 run_lib.py:167] step: 356300, eval_loss: 6.65159e-04
I0513 22:33:19.096327 22485033404224 run_lib.py:146] step: 356350, training_loss: 5.48290e-04
I0513 22:33:43.005996 22485033404224 run_lib.py:146] step: 356400, training_loss: 6.18656e-04
I0513 22:33:43.165627 22485033404224 run_lib.py:167] step: 356400, eval_loss: 6.08187e-04
I0513 22:34:06.816590 22485033404224 run_lib.py:146] step: 356450, training_loss: 6.53561e-04
I0513 22:34:30.715569 22485033404224 run_lib.py:146] step: 356500, training_loss: 5.47399e-04
I0513 22:34:30.896508 22485033404224 run_lib.py:167] step: 356500, eval_loss: 7.67849e-04
I0513 22:34:54.806509 22485033404224 run_lib.py:146] step: 356550, training_loss: 6.16079e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:35:18.494795 22485033404224 run_lib.py:146] step: 356600, training_loss: 5.24516e-04
I0513 22:35:18.656659 22485033404224 run_lib.py:167] step: 356600, eval_loss: 7.08306e-04
I0513 22:35:42.809499 22485033404224 run_lib.py:146] step: 356650, training_loss: 5.07695e-04
I0513 22:36:06.858977 22485033404224 run_lib.py:146] step: 356700, training_loss: 6.28097e-04
I0513 22:36:07.020910 22485033404224 run_lib.py:167] step: 356700, eval_loss: 7.94386e-04
I0513 22:36:30.617425 22485033404224 run_lib.py:146] step: 356750, training_loss: 6.65667e-04
I0513 22:36:54.553014 22485033404224 run_lib.py:146] step: 356800, training_loss: 6.32800e-04
I0513 22:36:54.712320 22485033404224 run_lib.py:167] step: 356800, eval_loss: 6.17361e-04
I0513 22:37:18.540373 22485033404224 run_lib.py:146] step: 356850, training_loss: 4.53038e-04
I0513 22:37:42.073240 22485033404224 run_lib.py:146] step: 356900, training_loss: 6.17145e-04
I0513 22:37:42.231740 22485033404224 run_lib.py:167] step: 356900, eval_loss: 7.74099e-04
I0513 22:38:06.057123 22485033404224 run_lib.py:146] step: 356950, training_loss: 7.05597e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:38:30.054366 22485033404224 run_lib.py:146] step: 357000, training_loss: 6.44464e-04
I0513 22:38:30.213946 22485033404224 run_lib.py:167] step: 357000, eval_loss: 4.49689e-04
I0513 22:38:53.716093 22485033404224 run_lib.py:146] step: 357050, training_loss: 6.25439e-04
I0513 22:39:17.224298 22485033404224 run_lib.py:146] step: 357100, training_loss: 5.41473e-04
I0513 22:39:17.383259 22485033404224 run_lib.py:167] step: 357100, eval_loss: 5.04945e-04
I0513 22:39:41.250008 22485033404224 run_lib.py:146] step: 357150, training_loss: 8.03722e-04
I0513 22:40:05.045563 22485033404224 run_lib.py:146] step: 357200, training_loss: 6.99966e-04
I0513 22:40:05.204715 22485033404224 run_lib.py:167] step: 357200, eval_loss: 6.71395e-04
I0513 22:40:28.709724 22485033404224 run_lib.py:146] step: 357250, training_loss: 8.77902e-04
I0513 22:40:52.533636 22485033404224 run_lib.py:146] step: 357300, training_loss: 6.91327e-04
I0513 22:40:52.694369 22485033404224 run_lib.py:167] step: 357300, eval_loss: 6.32836e-04
I0513 22:41:16.494624 22485033404224 run_lib.py:146] step: 357350, training_loss: 7.76692e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:41:40.101025 22485033404224 run_lib.py:146] step: 357400, training_loss: 8.33889e-04
I0513 22:41:40.262171 22485033404224 run_lib.py:167] step: 357400, eval_loss: 5.45021e-04
I0513 22:42:04.125190 22485033404224 run_lib.py:146] step: 357450, training_loss: 5.67887e-04
I0513 22:42:28.004730 22485033404224 run_lib.py:146] step: 357500, training_loss: 5.83276e-04
I0513 22:42:28.165001 22485033404224 run_lib.py:167] step: 357500, eval_loss: 4.76183e-04
I0513 22:42:51.692797 22485033404224 run_lib.py:146] step: 357550, training_loss: 6.70113e-04
I0513 22:43:15.506176 22485033404224 run_lib.py:146] step: 357600, training_loss: 6.16467e-04
I0513 22:43:15.665909 22485033404224 run_lib.py:167] step: 357600, eval_loss: 4.46899e-04
I0513 22:43:39.483286 22485033404224 run_lib.py:146] step: 357650, training_loss: 6.64491e-04
I0513 22:44:03.003857 22485033404224 run_lib.py:146] step: 357700, training_loss: 5.57900e-04
I0513 22:44:03.163822 22485033404224 run_lib.py:167] step: 357700, eval_loss: 5.48148e-04
I0513 22:44:26.976715 22485033404224 run_lib.py:146] step: 357750, training_loss: 7.07805e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:44:50.949215 22485033404224 run_lib.py:146] step: 357800, training_loss: 5.99464e-04
I0513 22:44:51.110114 22485033404224 run_lib.py:167] step: 357800, eval_loss: 5.09161e-04
I0513 22:45:14.634390 22485033404224 run_lib.py:146] step: 357850, training_loss: 6.23581e-04
I0513 22:45:38.501435 22485033404224 run_lib.py:146] step: 357900, training_loss: 6.54937e-04
I0513 22:45:38.661381 22485033404224 run_lib.py:167] step: 357900, eval_loss: 5.57282e-04
I0513 22:46:02.192750 22485033404224 run_lib.py:146] step: 357950, training_loss: 4.34661e-04
I0513 22:46:26.026869 22485033404224 run_lib.py:146] step: 358000, training_loss: 5.35642e-04
I0513 22:46:26.187314 22485033404224 run_lib.py:167] step: 358000, eval_loss: 6.56713e-04
I0513 22:46:49.709414 22485033404224 run_lib.py:146] step: 358050, training_loss: 5.66259e-04
I0513 22:47:13.583821 22485033404224 run_lib.py:146] step: 358100, training_loss: 6.32350e-04
I0513 22:47:13.744769 22485033404224 run_lib.py:167] step: 358100, eval_loss: 5.76972e-04
I0513 22:47:37.652266 22485033404224 run_lib.py:146] step: 358150, training_loss: 4.71303e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:48:01.347088 22485033404224 run_lib.py:146] step: 358200, training_loss: 5.88461e-04
I0513 22:48:01.508744 22485033404224 run_lib.py:167] step: 358200, eval_loss: 6.38076e-04
I0513 22:48:25.464664 22485033404224 run_lib.py:146] step: 358250, training_loss: 5.20425e-04
I0513 22:48:49.428193 22485033404224 run_lib.py:146] step: 358300, training_loss: 5.88953e-04
I0513 22:48:49.588075 22485033404224 run_lib.py:167] step: 358300, eval_loss: 5.84619e-04
I0513 22:49:13.204457 22485033404224 run_lib.py:146] step: 358350, training_loss: 6.38923e-04
I0513 22:49:37.108929 22485033404224 run_lib.py:146] step: 358400, training_loss: 5.72511e-04
I0513 22:49:37.269044 22485033404224 run_lib.py:167] step: 358400, eval_loss: 5.30840e-04
I0513 22:50:01.137694 22485033404224 run_lib.py:146] step: 358450, training_loss: 5.35945e-04
I0513 22:50:24.712947 22485033404224 run_lib.py:146] step: 358500, training_loss: 6.61701e-04
I0513 22:50:24.873305 22485033404224 run_lib.py:167] step: 358500, eval_loss: 6.57840e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:50:48.856022 22485033404224 run_lib.py:146] step: 358550, training_loss: 6.76306e-04
I0513 22:51:12.984060 22485033404224 run_lib.py:146] step: 358600, training_loss: 6.71363e-04
I0513 22:51:13.146587 22485033404224 run_lib.py:167] step: 358600, eval_loss: 5.20777e-04
I0513 22:51:36.836768 22485033404224 run_lib.py:146] step: 358650, training_loss: 6.17373e-04
I0513 22:52:00.780555 22485033404224 run_lib.py:146] step: 358700, training_loss: 4.68407e-04
I0513 22:52:00.941935 22485033404224 run_lib.py:167] step: 358700, eval_loss: 4.93414e-04
I0513 22:52:24.814450 22485033404224 run_lib.py:146] step: 358750, training_loss: 6.34229e-04
I0513 22:52:48.409618 22485033404224 run_lib.py:146] step: 358800, training_loss: 6.03299e-04
I0513 22:52:48.569545 22485033404224 run_lib.py:167] step: 358800, eval_loss: 7.67966e-04
I0513 22:53:12.133447 22485033404224 run_lib.py:146] step: 358850, training_loss: 5.61823e-04
I0513 22:53:36.031621 22485033404224 run_lib.py:146] step: 358900, training_loss: 6.12113e-04
I0513 22:53:36.192911 22485033404224 run_lib.py:167] step: 358900, eval_loss: 6.07562e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:54:00.132930 22485033404224 run_lib.py:146] step: 358950, training_loss: 4.86077e-04
I0513 22:54:23.658198 22485033404224 run_lib.py:146] step: 359000, training_loss: 3.63702e-04
I0513 22:54:23.818639 22485033404224 run_lib.py:167] step: 359000, eval_loss: 5.61774e-04
I0513 22:54:47.688797 22485033404224 run_lib.py:146] step: 359050, training_loss: 6.65554e-04
I0513 22:55:11.522937 22485033404224 run_lib.py:146] step: 359100, training_loss: 4.59043e-04
I0513 22:55:11.683100 22485033404224 run_lib.py:167] step: 359100, eval_loss: 5.35498e-04
I0513 22:55:35.196181 22485033404224 run_lib.py:146] step: 359150, training_loss: 4.60627e-04
I0513 22:55:59.011698 22485033404224 run_lib.py:146] step: 359200, training_loss: 6.83544e-04
I0513 22:55:59.170442 22485033404224 run_lib.py:167] step: 359200, eval_loss: 6.08244e-04
I0513 22:56:22.976427 22485033404224 run_lib.py:146] step: 359250, training_loss: 5.85207e-04
I0513 22:56:46.482242 22485033404224 run_lib.py:146] step: 359300, training_loss: 6.48330e-04
I0513 22:56:46.642045 22485033404224 run_lib.py:167] step: 359300, eval_loss: 6.00670e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:57:10.567717 22485033404224 run_lib.py:146] step: 359350, training_loss: 5.74613e-04
I0513 22:57:34.429845 22485033404224 run_lib.py:146] step: 359400, training_loss: 6.58909e-04
I0513 22:57:34.590340 22485033404224 run_lib.py:167] step: 359400, eval_loss: 7.87195e-04
I0513 22:57:58.087389 22485033404224 run_lib.py:146] step: 359450, training_loss: 5.89159e-04
I0513 22:58:21.893333 22485033404224 run_lib.py:146] step: 359500, training_loss: 5.68103e-04
I0513 22:58:22.052126 22485033404224 run_lib.py:167] step: 359500, eval_loss: 6.11160e-04
I0513 22:58:45.865298 22485033404224 run_lib.py:146] step: 359550, training_loss: 6.30082e-04
I0513 22:59:09.371696 22485033404224 run_lib.py:146] step: 359600, training_loss: 7.57263e-04
I0513 22:59:09.611830 22485033404224 run_lib.py:167] step: 359600, eval_loss: 7.12036e-04
I0513 22:59:33.151795 22485033404224 run_lib.py:146] step: 359650, training_loss: 4.50977e-04
I0513 22:59:56.977127 22485033404224 run_lib.py:146] step: 359700, training_loss: 5.69324e-04
I0513 22:59:57.137990 22485033404224 run_lib.py:167] step: 359700, eval_loss: 6.06284e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:00:21.023118 22485033404224 run_lib.py:146] step: 359750, training_loss: 5.33514e-04
I0513 23:00:44.556590 22485033404224 run_lib.py:146] step: 359800, training_loss: 5.74927e-04
I0513 23:00:44.718444 22485033404224 run_lib.py:167] step: 359800, eval_loss: 6.74238e-04
I0513 23:01:08.562642 22485033404224 run_lib.py:146] step: 359850, training_loss: 6.81735e-04
I0513 23:01:32.404113 22485033404224 run_lib.py:146] step: 359900, training_loss: 6.50101e-04
I0513 23:01:32.564767 22485033404224 run_lib.py:167] step: 359900, eval_loss: 5.29028e-04
I0513 23:01:56.092438 22485033404224 run_lib.py:146] step: 359950, training_loss: 5.37632e-04
I0513 23:02:19.917741 22485033404224 run_lib.py:146] step: 360000, training_loss: 5.63511e-04
I0513 23:02:21.947320 22485033404224 run_lib.py:167] step: 360000, eval_loss: 6.84635e-04
I0513 23:02:47.181386 22485033404224 run_lib.py:146] step: 360050, training_loss: 6.04830e-04
I0513 23:03:10.714332 22485033404224 run_lib.py:146] step: 360100, training_loss: 5.29367e-04
I0513 23:03:10.873411 22485033404224 run_lib.py:167] step: 360100, eval_loss: 7.06268e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:03:35.186519 22485033404224 run_lib.py:146] step: 360150, training_loss: 6.49561e-04
I0513 23:03:58.709856 22485033404224 run_lib.py:146] step: 360200, training_loss: 8.07153e-04
I0513 23:03:58.871458 22485033404224 run_lib.py:167] step: 360200, eval_loss: 7.36643e-04
I0513 23:04:22.396172 22485033404224 run_lib.py:146] step: 360250, training_loss: 5.98831e-04
I0513 23:04:46.260915 22485033404224 run_lib.py:146] step: 360300, training_loss: 6.55278e-04
I0513 23:04:46.422027 22485033404224 run_lib.py:167] step: 360300, eval_loss: 7.75089e-04
I0513 23:05:10.342223 22485033404224 run_lib.py:146] step: 360350, training_loss: 7.14870e-04
I0513 23:05:33.945688 22485033404224 run_lib.py:146] step: 360400, training_loss: 4.98314e-04
I0513 23:05:34.105932 22485033404224 run_lib.py:167] step: 360400, eval_loss: 5.21306e-04
I0513 23:05:58.021957 22485033404224 run_lib.py:146] step: 360450, training_loss: 7.67002e-04
I0513 23:06:21.925091 22485033404224 run_lib.py:146] step: 360500, training_loss: 7.22209e-04
I0513 23:06:22.085300 22485033404224 run_lib.py:167] step: 360500, eval_loss: 5.76173e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:06:45.724427 22485033404224 run_lib.py:146] step: 360550, training_loss: 5.74042e-04
I0513 23:07:09.309719 22485033404224 run_lib.py:146] step: 360600, training_loss: 4.22063e-04
I0513 23:07:09.471998 22485033404224 run_lib.py:167] step: 360600, eval_loss: 7.77188e-04
I0513 23:07:33.906489 22485033404224 run_lib.py:146] step: 360650, training_loss: 5.51409e-04
I0513 23:07:57.475536 22485033404224 run_lib.py:146] step: 360700, training_loss: 7.47905e-04
I0513 23:07:57.635930 22485033404224 run_lib.py:167] step: 360700, eval_loss: 5.94562e-04
I0513 23:08:21.213499 22485033404224 run_lib.py:146] step: 360750, training_loss: 6.77829e-04
I0513 23:08:45.621795 22485033404224 run_lib.py:146] step: 360800, training_loss: 5.99559e-04
I0513 23:08:45.783183 22485033404224 run_lib.py:167] step: 360800, eval_loss: 4.94309e-04
I0513 23:09:09.367892 22485033404224 run_lib.py:146] step: 360850, training_loss: 6.34398e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:09:33.038828 22485033404224 run_lib.py:146] step: 360900, training_loss: 5.23148e-04
I0513 23:09:33.200258 22485033404224 run_lib.py:167] step: 360900, eval_loss: 5.50573e-04
I0513 23:09:57.711405 22485033404224 run_lib.py:146] step: 360950, training_loss: 5.01098e-04
I0513 23:10:21.307077 22485033404224 run_lib.py:146] step: 361000, training_loss: 6.61153e-04
I0513 23:10:21.468077 22485033404224 run_lib.py:167] step: 361000, eval_loss: 6.34336e-04
I0513 23:10:45.074127 22485033404224 run_lib.py:146] step: 361050, training_loss: 5.42732e-04
I0513 23:11:09.079165 22485033404224 run_lib.py:146] step: 361100, training_loss: 7.59303e-04
I0513 23:11:09.238423 22485033404224 run_lib.py:167] step: 361100, eval_loss: 6.84885e-04
I0513 23:11:33.126079 22485033404224 run_lib.py:146] step: 361150, training_loss: 6.22973e-04
I0513 23:11:56.735744 22485033404224 run_lib.py:146] step: 361200, training_loss: 6.58571e-04
I0513 23:11:56.930813 22485033404224 run_lib.py:167] step: 361200, eval_loss: 5.90774e-04
I0513 23:12:20.901449 22485033404224 run_lib.py:146] step: 361250, training_loss: 5.43534e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:12:44.827995 22485033404224 run_lib.py:146] step: 361300, training_loss: 6.29862e-04
I0513 23:12:44.988785 22485033404224 run_lib.py:167] step: 361300, eval_loss: 7.08948e-04
I0513 23:13:08.515577 22485033404224 run_lib.py:146] step: 361350, training_loss: 5.03310e-04
I0513 23:13:32.041154 22485033404224 run_lib.py:146] step: 361400, training_loss: 7.02155e-04
I0513 23:13:32.213526 22485033404224 run_lib.py:167] step: 361400, eval_loss: 5.91849e-04
I0513 23:13:56.375379 22485033404224 run_lib.py:146] step: 361450, training_loss: 5.89085e-04
I0513 23:14:19.888515 22485033404224 run_lib.py:146] step: 361500, training_loss: 6.94100e-04
I0513 23:14:20.047540 22485033404224 run_lib.py:167] step: 361500, eval_loss: 5.70244e-04
I0513 23:14:43.563557 22485033404224 run_lib.py:146] step: 361550, training_loss: 6.73171e-04
I0513 23:15:07.680331 22485033404224 run_lib.py:146] step: 361600, training_loss: 7.71843e-04
I0513 23:15:07.840658 22485033404224 run_lib.py:167] step: 361600, eval_loss: 5.55458e-04
I0513 23:15:31.363520 22485033404224 run_lib.py:146] step: 361650, training_loss: 6.96101e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:15:54.970272 22485033404224 run_lib.py:146] step: 361700, training_loss: 6.93666e-04
I0513 23:15:55.131066 22485033404224 run_lib.py:167] step: 361700, eval_loss: 4.81431e-04
I0513 23:16:19.334879 22485033404224 run_lib.py:146] step: 361750, training_loss: 5.38829e-04
I0513 23:16:42.864717 22485033404224 run_lib.py:146] step: 361800, training_loss: 6.65803e-04
I0513 23:16:43.025285 22485033404224 run_lib.py:167] step: 361800, eval_loss: 7.01816e-04
I0513 23:17:06.563334 22485033404224 run_lib.py:146] step: 361850, training_loss: 7.27450e-04
I0513 23:17:30.394484 22485033404224 run_lib.py:146] step: 361900, training_loss: 5.52652e-04
I0513 23:17:30.554642 22485033404224 run_lib.py:167] step: 361900, eval_loss: 6.76362e-04
I0513 23:17:54.382847 22485033404224 run_lib.py:146] step: 361950, training_loss: 7.37064e-04
I0513 23:18:17.916731 22485033404224 run_lib.py:146] step: 362000, training_loss: 7.27131e-04
I0513 23:18:18.077356 22485033404224 run_lib.py:167] step: 362000, eval_loss: 7.20939e-04
I0513 23:18:41.913809 22485033404224 run_lib.py:146] step: 362050, training_loss: 6.15609e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:19:05.847869 22485033404224 run_lib.py:146] step: 362100, training_loss: 8.02494e-04
I0513 23:19:06.010332 22485033404224 run_lib.py:167] step: 362100, eval_loss: 4.97179e-04
I0513 23:19:29.533929 22485033404224 run_lib.py:146] step: 362150, training_loss: 6.08224e-04
I0513 23:19:53.063294 22485033404224 run_lib.py:146] step: 362200, training_loss: 7.26979e-04
I0513 23:19:53.222009 22485033404224 run_lib.py:167] step: 362200, eval_loss: 4.98686e-04
I0513 23:20:17.431369 22485033404224 run_lib.py:146] step: 362250, training_loss: 6.33738e-04
I0513 23:20:40.966779 22485033404224 run_lib.py:146] step: 362300, training_loss: 6.23844e-04
I0513 23:20:41.127350 22485033404224 run_lib.py:167] step: 362300, eval_loss: 4.45244e-04
I0513 23:21:04.657171 22485033404224 run_lib.py:146] step: 362350, training_loss: 6.81759e-04
I0513 23:21:28.803084 22485033404224 run_lib.py:146] step: 362400, training_loss: 6.59649e-04
I0513 23:21:28.963051 22485033404224 run_lib.py:167] step: 362400, eval_loss: 4.84643e-04
I0513 23:21:52.507558 22485033404224 run_lib.py:146] step: 362450, training_loss: 6.07621e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:22:16.109988 22485033404224 run_lib.py:146] step: 362500, training_loss: 6.20249e-04
I0513 23:22:16.271888 22485033404224 run_lib.py:167] step: 362500, eval_loss: 6.65718e-04
I0513 23:22:40.482624 22485033404224 run_lib.py:146] step: 362550, training_loss: 4.50026e-04
I0513 23:23:04.075828 22485033404224 run_lib.py:146] step: 362600, training_loss: 6.30981e-04
I0513 23:23:04.236002 22485033404224 run_lib.py:167] step: 362600, eval_loss: 7.38299e-04
I0513 23:23:27.842761 22485033404224 run_lib.py:146] step: 362650, training_loss: 6.87899e-04
I0513 23:23:52.056308 22485033404224 run_lib.py:146] step: 362700, training_loss: 6.83624e-04
I0513 23:23:52.216708 22485033404224 run_lib.py:167] step: 362700, eval_loss: 4.49175e-04
I0513 23:24:15.805416 22485033404224 run_lib.py:146] step: 362750, training_loss: 6.94355e-04
I0513 23:24:39.400122 22485033404224 run_lib.py:146] step: 362800, training_loss: 6.24063e-04
I0513 23:24:39.574476 22485033404224 run_lib.py:167] step: 362800, eval_loss: 6.00721e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:25:03.538975 22485033404224 run_lib.py:146] step: 362850, training_loss: 6.27099e-04
I0513 23:25:27.560672 22485033404224 run_lib.py:146] step: 362900, training_loss: 6.53076e-04
I0513 23:25:27.723708 22485033404224 run_lib.py:167] step: 362900, eval_loss: 5.57927e-04
I0513 23:25:51.296421 22485033404224 run_lib.py:146] step: 362950, training_loss: 3.68782e-04
I0513 23:26:14.853189 22485033404224 run_lib.py:146] step: 363000, training_loss: 6.27512e-04
I0513 23:26:15.013629 22485033404224 run_lib.py:167] step: 363000, eval_loss: 7.09664e-04
I0513 23:26:39.436721 22485033404224 run_lib.py:146] step: 363050, training_loss: 6.67747e-04
I0513 23:27:03.033503 22485033404224 run_lib.py:146] step: 363100, training_loss: 6.44305e-04
I0513 23:27:03.195760 22485033404224 run_lib.py:167] step: 363100, eval_loss: 7.17867e-04
I0513 23:27:26.762902 22485033404224 run_lib.py:146] step: 363150, training_loss: 6.59265e-04
I0513 23:27:51.137084 22485033404224 run_lib.py:146] step: 363200, training_loss: 4.44118e-04
I0513 23:27:51.297025 22485033404224 run_lib.py:167] step: 363200, eval_loss: 6.78333e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:28:14.965646 22485033404224 run_lib.py:146] step: 363250, training_loss: 5.98559e-04
I0513 23:28:38.557926 22485033404224 run_lib.py:146] step: 363300, training_loss: 5.98390e-04
I0513 23:28:38.645684 22485033404224 run_lib.py:167] step: 363300, eval_loss: 6.41195e-04
I0513 23:29:03.110912 22485033404224 run_lib.py:146] step: 363350, training_loss: 5.68566e-04
I0513 23:29:26.662806 22485033404224 run_lib.py:146] step: 363400, training_loss: 5.86670e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:29:27.021301 22485033404224 run_lib.py:167] step: 363400, eval_loss: 5.71606e-04
I0513 23:29:50.673439 22485033404224 run_lib.py:146] step: 363450, training_loss: 5.20486e-04
I0513 23:30:15.102067 22485033404224 run_lib.py:146] step: 363500, training_loss: 5.88722e-04
I0513 23:30:15.260719 22485033404224 run_lib.py:167] step: 363500, eval_loss: 6.94527e-04
I0513 23:30:38.804548 22485033404224 run_lib.py:146] step: 363550, training_loss: 7.65009e-04
I0513 23:31:02.351049 22485033404224 run_lib.py:146] step: 363600, training_loss: 5.60273e-04
I0513 23:31:02.512348 22485033404224 run_lib.py:167] step: 363600, eval_loss: 5.71762e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:31:26.892834 22485033404224 run_lib.py:146] step: 363650, training_loss: 6.91144e-04
I0513 23:31:50.415569 22485033404224 run_lib.py:146] step: 363700, training_loss: 7.63594e-04
I0513 23:31:50.576928 22485033404224 run_lib.py:167] step: 363700, eval_loss: 7.36969e-04
I0513 23:32:14.097689 22485033404224 run_lib.py:146] step: 363750, training_loss: 4.99759e-04
I0513 23:32:37.921244 22485033404224 run_lib.py:146] step: 363800, training_loss: 6.90277e-04
I0513 23:32:38.080331 22485033404224 run_lib.py:167] step: 363800, eval_loss: 6.17529e-04
I0513 23:33:01.883416 22485033404224 run_lib.py:146] step: 363850, training_loss: 6.23505e-04
I0513 23:33:25.405080 22485033404224 run_lib.py:146] step: 363900, training_loss: 6.09967e-04
I0513 23:33:25.563816 22485033404224 run_lib.py:167] step: 363900, eval_loss: 6.65641e-04
I0513 23:33:49.079732 22485033404224 run_lib.py:146] step: 363950, training_loss: 6.55436e-04
I0513 23:34:13.212765 22485033404224 run_lib.py:146] step: 364000, training_loss: 5.37391e-04
I0513 23:34:13.373488 22485033404224 run_lib.py:167] step: 364000, eval_loss: 5.14456e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:34:36.966307 22485033404224 run_lib.py:146] step: 364050, training_loss: 8.62417e-04
I0513 23:35:00.486024 22485033404224 run_lib.py:146] step: 364100, training_loss: 4.21987e-04
I0513 23:35:00.646465 22485033404224 run_lib.py:167] step: 364100, eval_loss: 6.24710e-04
I0513 23:35:24.844767 22485033404224 run_lib.py:146] step: 364150, training_loss: 6.86307e-04
I0513 23:35:48.361269 22485033404224 run_lib.py:146] step: 364200, training_loss: 5.92163e-04
I0513 23:35:48.519787 22485033404224 run_lib.py:167] step: 364200, eval_loss: 6.79603e-04
I0513 23:36:12.046504 22485033404224 run_lib.py:146] step: 364250, training_loss: 4.98833e-04
I0513 23:36:36.180355 22485033404224 run_lib.py:146] step: 364300, training_loss: 5.97619e-04
I0513 23:36:36.339387 22485033404224 run_lib.py:167] step: 364300, eval_loss: 5.15543e-04
I0513 23:36:59.864799 22485033404224 run_lib.py:146] step: 364350, training_loss: 6.10347e-04
I0513 23:37:23.404356 22485033404224 run_lib.py:146] step: 364400, training_loss: 5.79422e-04
I0513 23:37:23.591689 22485033404224 run_lib.py:167] step: 364400, eval_loss: 5.51969e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:37:47.908733 22485033404224 run_lib.py:146] step: 364450, training_loss: 5.20831e-04
I0513 23:38:11.437096 22485033404224 run_lib.py:146] step: 364500, training_loss: 5.88565e-04
I0513 23:38:11.598824 22485033404224 run_lib.py:167] step: 364500, eval_loss: 5.77631e-04
I0513 23:38:35.123044 22485033404224 run_lib.py:146] step: 364550, training_loss: 5.58979e-04
I0513 23:38:58.969965 22485033404224 run_lib.py:146] step: 364600, training_loss: 6.42064e-04
I0513 23:38:59.129038 22485033404224 run_lib.py:167] step: 364600, eval_loss: 7.34625e-04
I0513 23:39:22.984558 22485033404224 run_lib.py:146] step: 364650, training_loss: 5.34375e-04
I0513 23:39:46.527272 22485033404224 run_lib.py:146] step: 364700, training_loss: 4.97733e-04
I0513 23:39:46.687024 22485033404224 run_lib.py:167] step: 364700, eval_loss: 6.48325e-04
I0513 23:40:10.219672 22485033404224 run_lib.py:146] step: 364750, training_loss: 7.23276e-04
I0513 23:40:34.374874 22485033404224 run_lib.py:146] step: 364800, training_loss: 5.66774e-04
I0513 23:40:34.534969 22485033404224 run_lib.py:167] step: 364800, eval_loss: 7.30994e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:40:58.125373 22485033404224 run_lib.py:146] step: 364850, training_loss: 4.65594e-04
I0513 23:41:21.705905 22485033404224 run_lib.py:146] step: 364900, training_loss: 7.63139e-04
I0513 23:41:21.867552 22485033404224 run_lib.py:167] step: 364900, eval_loss: 5.75122e-04
I0513 23:41:46.159434 22485033404224 run_lib.py:146] step: 364950, training_loss: 6.85229e-04
I0513 23:42:09.781156 22485033404224 run_lib.py:146] step: 365000, training_loss: 5.98930e-04
I0513 23:42:09.941745 22485033404224 run_lib.py:167] step: 365000, eval_loss: 5.88695e-04
I0513 23:42:33.524278 22485033404224 run_lib.py:146] step: 365050, training_loss: 4.57012e-04
I0513 23:42:57.690241 22485033404224 run_lib.py:146] step: 365100, training_loss: 4.56208e-04
I0513 23:42:57.850674 22485033404224 run_lib.py:167] step: 365100, eval_loss: 5.92221e-04
I0513 23:43:21.429616 22485033404224 run_lib.py:146] step: 365150, training_loss: 5.75238e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:43:45.060116 22485033404224 run_lib.py:146] step: 365200, training_loss: 5.33752e-04
I0513 23:43:45.222635 22485033404224 run_lib.py:167] step: 365200, eval_loss: 6.88584e-04
I0513 23:44:09.727042 22485033404224 run_lib.py:146] step: 365250, training_loss: 5.40262e-04
I0513 23:44:33.290399 22485033404224 run_lib.py:146] step: 365300, training_loss: 5.87609e-04
I0513 23:44:33.451035 22485033404224 run_lib.py:167] step: 365300, eval_loss: 5.28950e-04
I0513 23:44:57.012824 22485033404224 run_lib.py:146] step: 365350, training_loss: 4.87477e-04
I0513 23:45:20.977146 22485033404224 run_lib.py:146] step: 365400, training_loss: 6.37538e-04
I0513 23:45:21.138492 22485033404224 run_lib.py:167] step: 365400, eval_loss: 3.50963e-04
I0513 23:45:45.092465 22485033404224 run_lib.py:146] step: 365450, training_loss: 5.52632e-04
I0513 23:46:08.651425 22485033404224 run_lib.py:146] step: 365500, training_loss: 7.03853e-04
I0513 23:46:08.813247 22485033404224 run_lib.py:167] step: 365500, eval_loss: 4.87701e-04
I0513 23:46:32.393843 22485033404224 run_lib.py:146] step: 365550, training_loss: 5.33031e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:46:56.657295 22485033404224 run_lib.py:146] step: 365600, training_loss: 7.41580e-04
I0513 23:46:56.819457 22485033404224 run_lib.py:167] step: 365600, eval_loss: 7.59949e-04
I0513 23:47:20.408812 22485033404224 run_lib.py:146] step: 365650, training_loss: 8.46638e-04
I0513 23:47:43.996136 22485033404224 run_lib.py:146] step: 365700, training_loss: 6.21121e-04
I0513 23:47:44.158041 22485033404224 run_lib.py:167] step: 365700, eval_loss: 4.98588e-04
I0513 23:48:08.432785 22485033404224 run_lib.py:146] step: 365750, training_loss: 7.38006e-04
I0513 23:48:31.985372 22485033404224 run_lib.py:146] step: 365800, training_loss: 5.03101e-04
I0513 23:48:32.145540 22485033404224 run_lib.py:167] step: 365800, eval_loss: 6.05951e-04
I0513 23:48:55.673208 22485033404224 run_lib.py:146] step: 365850, training_loss: 4.81227e-04
I0513 23:49:19.781102 22485033404224 run_lib.py:146] step: 365900, training_loss: 7.41065e-04
I0513 23:49:19.941141 22485033404224 run_lib.py:167] step: 365900, eval_loss: 5.06782e-04
I0513 23:49:43.466095 22485033404224 run_lib.py:146] step: 365950, training_loss: 8.27624e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:50:07.053002 22485033404224 run_lib.py:146] step: 366000, training_loss: 7.02125e-04
I0513 23:50:07.229448 22485033404224 run_lib.py:167] step: 366000, eval_loss: 6.86867e-04
I0513 23:50:31.396321 22485033404224 run_lib.py:146] step: 366050, training_loss: 5.80390e-04
I0513 23:50:54.903777 22485033404224 run_lib.py:146] step: 366100, training_loss: 6.83250e-04
I0513 23:50:55.062918 22485033404224 run_lib.py:167] step: 366100, eval_loss: 6.05973e-04
I0513 23:51:18.555480 22485033404224 run_lib.py:146] step: 366150, training_loss: 8.13373e-04
I0513 23:51:42.354161 22485033404224 run_lib.py:146] step: 366200, training_loss: 6.19310e-04
I0513 23:51:42.512883 22485033404224 run_lib.py:167] step: 366200, eval_loss: 5.04160e-04
I0513 23:52:06.305060 22485033404224 run_lib.py:146] step: 366250, training_loss: 6.55948e-04
I0513 23:52:29.813661 22485033404224 run_lib.py:146] step: 366300, training_loss: 4.33581e-04
I0513 23:52:29.972779 22485033404224 run_lib.py:167] step: 366300, eval_loss: 6.53758e-04
I0513 23:52:53.481253 22485033404224 run_lib.py:146] step: 366350, training_loss: 5.23345e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:53:17.706088 22485033404224 run_lib.py:146] step: 366400, training_loss: 5.43287e-04
I0513 23:53:17.867053 22485033404224 run_lib.py:167] step: 366400, eval_loss: 6.03604e-04
I0513 23:53:41.390587 22485033404224 run_lib.py:146] step: 366450, training_loss: 6.53209e-04
I0513 23:54:04.915013 22485033404224 run_lib.py:146] step: 366500, training_loss: 6.62086e-04
I0513 23:54:05.075009 22485033404224 run_lib.py:167] step: 366500, eval_loss: 5.75831e-04
I0513 23:54:29.207437 22485033404224 run_lib.py:146] step: 366550, training_loss: 6.15570e-04
I0513 23:54:52.722915 22485033404224 run_lib.py:146] step: 366600, training_loss: 6.22658e-04
I0513 23:54:52.883576 22485033404224 run_lib.py:167] step: 366600, eval_loss: 6.20500e-04
I0513 23:55:16.417622 22485033404224 run_lib.py:146] step: 366650, training_loss: 5.52245e-04
I0513 23:55:40.556427 22485033404224 run_lib.py:146] step: 366700, training_loss: 5.94957e-04
I0513 23:55:40.715353 22485033404224 run_lib.py:167] step: 366700, eval_loss: 6.48534e-04
I0513 23:56:04.220883 22485033404224 run_lib.py:146] step: 366750, training_loss: 5.64308e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:56:27.812276 22485033404224 run_lib.py:146] step: 366800, training_loss: 7.80389e-04
I0513 23:56:27.972433 22485033404224 run_lib.py:167] step: 366800, eval_loss: 8.38361e-04
I0513 23:56:52.140043 22485033404224 run_lib.py:146] step: 366850, training_loss: 5.71249e-04
I0513 23:57:15.631309 22485033404224 run_lib.py:146] step: 366900, training_loss: 6.83566e-04
I0513 23:57:15.790024 22485033404224 run_lib.py:167] step: 366900, eval_loss: 5.19040e-04
I0513 23:57:39.290736 22485033404224 run_lib.py:146] step: 366950, training_loss: 4.43035e-04
I0513 23:58:03.092838 22485033404224 run_lib.py:146] step: 367000, training_loss: 6.07634e-04
I0513 23:58:03.253228 22485033404224 run_lib.py:167] step: 367000, eval_loss: 5.72082e-04
I0513 23:58:27.044984 22485033404224 run_lib.py:146] step: 367050, training_loss: 4.61622e-04
I0513 23:58:50.551138 22485033404224 run_lib.py:146] step: 367100, training_loss: 6.16354e-04
I0513 23:58:50.710460 22485033404224 run_lib.py:167] step: 367100, eval_loss: 6.88704e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:59:14.706526 22485033404224 run_lib.py:146] step: 367150, training_loss: 7.30059e-04
I0513 23:59:38.649146 22485033404224 run_lib.py:146] step: 367200, training_loss: 7.30128e-04
I0513 23:59:38.811333 22485033404224 run_lib.py:167] step: 367200, eval_loss: 5.60051e-04
I0514 00:00:02.399650 22485033404224 run_lib.py:146] step: 367250, training_loss: 5.83062e-04
I0514 00:00:25.991942 22485033404224 run_lib.py:146] step: 367300, training_loss: 7.78140e-04
I0514 00:00:26.152989 22485033404224 run_lib.py:167] step: 367300, eval_loss: 4.79599e-04
I0514 00:00:50.318738 22485033404224 run_lib.py:146] step: 367350, training_loss: 5.56352e-04
I0514 00:01:13.934272 22485033404224 run_lib.py:146] step: 367400, training_loss: 8.15176e-04
I0514 00:01:14.095572 22485033404224 run_lib.py:167] step: 367400, eval_loss: 5.39081e-04
I0514 00:01:37.712299 22485033404224 run_lib.py:146] step: 367450, training_loss: 7.39459e-04
I0514 00:02:01.928566 22485033404224 run_lib.py:146] step: 367500, training_loss: 5.87044e-04
I0514 00:02:02.089080 22485033404224 run_lib.py:167] step: 367500, eval_loss: 4.33842e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:02:25.766504 22485033404224 run_lib.py:146] step: 367550, training_loss: 6.35024e-04
I0514 00:02:49.396421 22485033404224 run_lib.py:146] step: 367600, training_loss: 5.44050e-04
I0514 00:02:49.558387 22485033404224 run_lib.py:167] step: 367600, eval_loss: 6.86373e-04
I0514 00:03:13.935586 22485033404224 run_lib.py:146] step: 367650, training_loss: 6.01341e-04
I0514 00:03:37.521969 22485033404224 run_lib.py:146] step: 367700, training_loss: 6.23086e-04
I0514 00:03:37.683731 22485033404224 run_lib.py:167] step: 367700, eval_loss: 5.37909e-04
I0514 00:04:01.253109 22485033404224 run_lib.py:146] step: 367750, training_loss: 5.81947e-04
I0514 00:04:25.169064 22485033404224 run_lib.py:146] step: 367800, training_loss: 5.54995e-04
I0514 00:04:25.329784 22485033404224 run_lib.py:167] step: 367800, eval_loss: 6.49777e-04
I0514 00:04:49.199769 22485033404224 run_lib.py:146] step: 367850, training_loss: 4.57396e-04
I0514 00:05:12.785086 22485033404224 run_lib.py:146] step: 367900, training_loss: 5.65981e-04
I0514 00:05:12.946212 22485033404224 run_lib.py:167] step: 367900, eval_loss: 6.24949e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:05:37.027240 22485033404224 run_lib.py:146] step: 367950, training_loss: 7.67625e-04
I0514 00:06:00.995813 22485033404224 run_lib.py:146] step: 368000, training_loss: 6.85441e-04
I0514 00:06:01.157789 22485033404224 run_lib.py:167] step: 368000, eval_loss: 7.00011e-04
I0514 00:06:24.757492 22485033404224 run_lib.py:146] step: 368050, training_loss: 6.70809e-04
I0514 00:06:48.308212 22485033404224 run_lib.py:146] step: 368100, training_loss: 7.01095e-04
I0514 00:06:48.468992 22485033404224 run_lib.py:167] step: 368100, eval_loss: 9.93871e-04
I0514 00:07:12.670302 22485033404224 run_lib.py:146] step: 368150, training_loss: 6.43113e-04
I0514 00:07:36.198163 22485033404224 run_lib.py:146] step: 368200, training_loss: 6.16513e-04
I0514 00:07:36.358784 22485033404224 run_lib.py:167] step: 368200, eval_loss: 6.89225e-04
I0514 00:07:59.872503 22485033404224 run_lib.py:146] step: 368250, training_loss: 6.09198e-04
I0514 00:08:24.005621 22485033404224 run_lib.py:146] step: 368300, training_loss: 6.05981e-04
I0514 00:08:24.165036 22485033404224 run_lib.py:167] step: 368300, eval_loss: 6.58887e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:08:47.767904 22485033404224 run_lib.py:146] step: 368350, training_loss: 7.64826e-04
I0514 00:09:11.313249 22485033404224 run_lib.py:146] step: 368400, training_loss: 5.79846e-04
I0514 00:09:11.474571 22485033404224 run_lib.py:167] step: 368400, eval_loss: 7.26979e-04
I0514 00:09:35.642629 22485033404224 run_lib.py:146] step: 368450, training_loss: 6.04101e-04
I0514 00:09:59.162320 22485033404224 run_lib.py:146] step: 368500, training_loss: 4.61109e-04
I0514 00:09:59.321857 22485033404224 run_lib.py:167] step: 368500, eval_loss: 6.98754e-04
I0514 00:10:22.849888 22485033404224 run_lib.py:146] step: 368550, training_loss: 6.60694e-04
I0514 00:10:46.682812 22485033404224 run_lib.py:146] step: 368600, training_loss: 8.15151e-04
I0514 00:10:46.841873 22485033404224 run_lib.py:167] step: 368600, eval_loss: 6.36885e-04
I0514 00:11:10.675273 22485033404224 run_lib.py:146] step: 368650, training_loss: 5.18986e-04
I0514 00:11:34.229401 22485033404224 run_lib.py:146] step: 368700, training_loss: 5.65446e-04
I0514 00:11:34.390412 22485033404224 run_lib.py:167] step: 368700, eval_loss: 6.43845e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:11:58.339413 22485033404224 run_lib.py:146] step: 368750, training_loss: 7.92217e-04
I0514 00:12:22.214529 22485033404224 run_lib.py:146] step: 368800, training_loss: 6.55639e-04
I0514 00:12:22.374439 22485033404224 run_lib.py:167] step: 368800, eval_loss: 4.05114e-04
I0514 00:12:45.887546 22485033404224 run_lib.py:146] step: 368850, training_loss: 6.70057e-04
I0514 00:13:09.729821 22485033404224 run_lib.py:146] step: 368900, training_loss: 6.27714e-04
I0514 00:13:09.888386 22485033404224 run_lib.py:167] step: 368900, eval_loss: 5.61645e-04
I0514 00:13:33.727790 22485033404224 run_lib.py:146] step: 368950, training_loss: 6.20564e-04
I0514 00:13:57.262272 22485033404224 run_lib.py:146] step: 369000, training_loss: 5.60190e-04
I0514 00:13:57.421566 22485033404224 run_lib.py:167] step: 369000, eval_loss: 4.94077e-04
I0514 00:14:20.934792 22485033404224 run_lib.py:146] step: 369050, training_loss: 6.02402e-04
I0514 00:14:45.080108 22485033404224 run_lib.py:146] step: 369100, training_loss: 4.48545e-04
I0514 00:14:45.239114 22485033404224 run_lib.py:167] step: 369100, eval_loss: 5.77526e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:15:08.857912 22485033404224 run_lib.py:146] step: 369150, training_loss: 6.42758e-04
I0514 00:15:32.403014 22485033404224 run_lib.py:146] step: 369200, training_loss: 8.06668e-04
I0514 00:15:32.564196 22485033404224 run_lib.py:167] step: 369200, eval_loss: 6.19591e-04
I0514 00:15:56.779138 22485033404224 run_lib.py:146] step: 369250, training_loss: 8.25537e-04
I0514 00:16:20.324168 22485033404224 run_lib.py:146] step: 369300, training_loss: 5.54100e-04
I0514 00:16:20.483434 22485033404224 run_lib.py:167] step: 369300, eval_loss: 5.39323e-04
I0514 00:16:44.022739 22485033404224 run_lib.py:146] step: 369350, training_loss: 7.32903e-04
I0514 00:17:08.190008 22485033404224 run_lib.py:146] step: 369400, training_loss: 3.91262e-04
I0514 00:17:08.350978 22485033404224 run_lib.py:167] step: 369400, eval_loss: 6.00663e-04
I0514 00:17:31.953801 22485033404224 run_lib.py:146] step: 369450, training_loss: 5.33190e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:17:55.662998 22485033404224 run_lib.py:146] step: 369500, training_loss: 6.37633e-04
I0514 00:17:55.825023 22485033404224 run_lib.py:167] step: 369500, eval_loss: 7.03540e-04
I0514 00:18:19.752463 22485033404224 run_lib.py:146] step: 369550, training_loss: 6.37688e-04
I0514 00:18:43.660186 22485033404224 run_lib.py:146] step: 369600, training_loss: 5.19685e-04
I0514 00:18:43.820026 22485033404224 run_lib.py:167] step: 369600, eval_loss: 6.92739e-04
I0514 00:19:07.369462 22485033404224 run_lib.py:146] step: 369650, training_loss: 7.85406e-04
I0514 00:19:31.222575 22485033404224 run_lib.py:146] step: 369700, training_loss: 5.19419e-04
I0514 00:19:31.382932 22485033404224 run_lib.py:167] step: 369700, eval_loss: 6.47181e-04
I0514 00:19:55.209000 22485033404224 run_lib.py:146] step: 369750, training_loss: 6.71897e-04
I0514 00:20:18.752212 22485033404224 run_lib.py:146] step: 369800, training_loss: 6.12597e-04
I0514 00:20:18.913105 22485033404224 run_lib.py:167] step: 369800, eval_loss: 4.48916e-04
I0514 00:20:42.437008 22485033404224 run_lib.py:146] step: 369850, training_loss: 4.49093e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:21:06.738399 22485033404224 run_lib.py:146] step: 369900, training_loss: 6.42032e-04
I0514 00:21:06.918616 22485033404224 run_lib.py:167] step: 369900, eval_loss: 6.81511e-04
I0514 00:21:30.683509 22485033404224 run_lib.py:146] step: 369950, training_loss: 6.19275e-04
I0514 00:21:54.437088 22485033404224 run_lib.py:146] step: 370000, training_loss: 8.15369e-04
I0514 00:21:56.217700 22485033404224 run_lib.py:167] step: 370000, eval_loss: 6.93052e-04
I0514 00:22:22.857525 22485033404224 run_lib.py:146] step: 370050, training_loss: 7.01985e-04
I0514 00:22:46.595683 22485033404224 run_lib.py:146] step: 370100, training_loss: 8.78786e-04
I0514 00:22:46.758668 22485033404224 run_lib.py:167] step: 370100, eval_loss: 5.46750e-04
I0514 00:23:10.505559 22485033404224 run_lib.py:146] step: 370150, training_loss: 4.41846e-04
I0514 00:23:34.818114 22485033404224 run_lib.py:146] step: 370200, training_loss: 7.46441e-04
I0514 00:23:34.979447 22485033404224 run_lib.py:167] step: 370200, eval_loss: 5.97658e-04
I0514 00:23:58.582201 22485033404224 run_lib.py:146] step: 370250, training_loss: 6.47417e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:24:22.271261 22485033404224 run_lib.py:146] step: 370300, training_loss: 7.11410e-04
I0514 00:24:22.433611 22485033404224 run_lib.py:167] step: 370300, eval_loss: 6.00793e-04
I0514 00:24:46.657573 22485033404224 run_lib.py:146] step: 370350, training_loss: 5.99381e-04
I0514 00:25:10.174547 22485033404224 run_lib.py:146] step: 370400, training_loss: 8.86373e-04
I0514 00:25:10.333668 22485033404224 run_lib.py:167] step: 370400, eval_loss: 5.44307e-04
I0514 00:25:33.856374 22485033404224 run_lib.py:146] step: 370450, training_loss: 5.22193e-04
I0514 00:25:57.947149 22485033404224 run_lib.py:146] step: 370500, training_loss: 6.83811e-04
I0514 00:25:58.105369 22485033404224 run_lib.py:167] step: 370500, eval_loss: 6.26540e-04
I0514 00:26:21.633867 22485033404224 run_lib.py:146] step: 370550, training_loss: 6.54193e-04
I0514 00:26:45.162560 22485033404224 run_lib.py:146] step: 370600, training_loss: 8.91746e-04
I0514 00:26:45.321919 22485033404224 run_lib.py:167] step: 370600, eval_loss: 7.45291e-04
I0514 00:27:09.097110 22485033404224 run_lib.py:146] step: 370650, training_loss: 6.75301e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:27:32.979837 22485033404224 run_lib.py:146] step: 370700, training_loss: 5.93287e-04
I0514 00:27:33.140688 22485033404224 run_lib.py:167] step: 370700, eval_loss: 5.30750e-04
I0514 00:27:56.653741 22485033404224 run_lib.py:146] step: 370750, training_loss: 7.90973e-04
I0514 00:28:20.540690 22485033404224 run_lib.py:146] step: 370800, training_loss: 5.52381e-04
I0514 00:28:20.701313 22485033404224 run_lib.py:167] step: 370800, eval_loss: 5.66362e-04
I0514 00:28:44.567315 22485033404224 run_lib.py:146] step: 370850, training_loss: 7.16616e-04
I0514 00:29:08.097942 22485033404224 run_lib.py:146] step: 370900, training_loss: 8.30292e-04
I0514 00:29:08.257373 22485033404224 run_lib.py:167] step: 370900, eval_loss: 4.90326e-04
I0514 00:29:32.093297 22485033404224 run_lib.py:146] step: 370950, training_loss: 9.22646e-04
I0514 00:29:55.920213 22485033404224 run_lib.py:146] step: 371000, training_loss: 7.28908e-04
I0514 00:29:56.079343 22485033404224 run_lib.py:167] step: 371000, eval_loss: 8.90406e-04
I0514 00:30:19.602519 22485033404224 run_lib.py:146] step: 371050, training_loss: 6.47662e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:30:43.186534 22485033404224 run_lib.py:146] step: 371100, training_loss: 6.06174e-04
I0514 00:30:43.346473 22485033404224 run_lib.py:167] step: 371100, eval_loss: 6.64576e-04
I0514 00:31:07.517378 22485033404224 run_lib.py:146] step: 371150, training_loss: 6.51893e-04
I0514 00:31:31.040714 22485033404224 run_lib.py:146] step: 371200, training_loss: 5.23062e-04
I0514 00:31:31.126771 22485033404224 run_lib.py:167] step: 371200, eval_loss: 3.93129e-04
I0514 00:31:54.638395 22485033404224 run_lib.py:146] step: 371250, training_loss: 4.79257e-04
I0514 00:32:18.792166 22485033404224 run_lib.py:146] step: 371300, training_loss: 5.83315e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:32:19.145973 22485033404224 run_lib.py:167] step: 371300, eval_loss: 6.35639e-04
I0514 00:32:42.698370 22485033404224 run_lib.py:146] step: 371350, training_loss: 5.06377e-04
I0514 00:33:06.253599 22485033404224 run_lib.py:146] step: 371400, training_loss: 6.26129e-04
I0514 00:33:06.412374 22485033404224 run_lib.py:167] step: 371400, eval_loss: 5.19922e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:33:30.349088 22485033404224 run_lib.py:146] step: 371450, training_loss: 6.25149e-04
I0514 00:33:54.210814 22485033404224 run_lib.py:146] step: 371500, training_loss: 6.63997e-04
I0514 00:33:54.372255 22485033404224 run_lib.py:167] step: 371500, eval_loss: 5.46839e-04
I0514 00:34:17.913610 22485033404224 run_lib.py:146] step: 371550, training_loss: 7.82788e-04
I0514 00:34:41.785924 22485033404224 run_lib.py:146] step: 371600, training_loss: 7.37376e-04
I0514 00:34:41.944829 22485033404224 run_lib.py:167] step: 371600, eval_loss: 6.40043e-04
I0514 00:35:05.790569 22485033404224 run_lib.py:146] step: 371650, training_loss: 5.03199e-04
I0514 00:35:29.399541 22485033404224 run_lib.py:146] step: 371700, training_loss: 5.58458e-04
I0514 00:35:29.576546 22485033404224 run_lib.py:167] step: 371700, eval_loss: 6.15670e-04
I0514 00:35:53.516965 22485033404224 run_lib.py:146] step: 371750, training_loss: 5.30174e-04
I0514 00:36:17.437590 22485033404224 run_lib.py:146] step: 371800, training_loss: 7.43290e-04
I0514 00:36:17.599262 22485033404224 run_lib.py:167] step: 371800, eval_loss: 6.91049e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:36:41.238440 22485033404224 run_lib.py:146] step: 371850, training_loss: 5.72750e-04
I0514 00:37:04.807543 22485033404224 run_lib.py:146] step: 371900, training_loss: 4.27025e-04
I0514 00:37:04.970556 22485033404224 run_lib.py:167] step: 371900, eval_loss: 7.16844e-04
I0514 00:37:29.394978 22485033404224 run_lib.py:146] step: 371950, training_loss: 6.50417e-04
I0514 00:37:52.952123 22485033404224 run_lib.py:146] step: 372000, training_loss: 6.10405e-04
I0514 00:37:53.113363 22485033404224 run_lib.py:167] step: 372000, eval_loss: 6.36968e-04
I0514 00:38:16.667706 22485033404224 run_lib.py:146] step: 372050, training_loss: 3.95551e-04
I0514 00:38:40.919155 22485033404224 run_lib.py:146] step: 372100, training_loss: 6.36415e-04
I0514 00:38:41.078713 22485033404224 run_lib.py:167] step: 372100, eval_loss: 6.08337e-04
I0514 00:39:04.640965 22485033404224 run_lib.py:146] step: 372150, training_loss: 5.23728e-04
I0514 00:39:28.227653 22485033404224 run_lib.py:146] step: 372200, training_loss: 6.20485e-04
I0514 00:39:28.389048 22485033404224 run_lib.py:167] step: 372200, eval_loss: 8.28812e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:39:52.782324 22485033404224 run_lib.py:146] step: 372250, training_loss: 4.99299e-04
I0514 00:40:16.344081 22485033404224 run_lib.py:146] step: 372300, training_loss: 7.15607e-04
I0514 00:40:16.505771 22485033404224 run_lib.py:167] step: 372300, eval_loss: 7.16632e-04
I0514 00:40:40.090285 22485033404224 run_lib.py:146] step: 372350, training_loss: 7.04649e-04
I0514 00:41:04.064181 22485033404224 run_lib.py:146] step: 372400, training_loss: 6.67269e-04
I0514 00:41:04.223358 22485033404224 run_lib.py:167] step: 372400, eval_loss: 5.91412e-04
I0514 00:41:28.118999 22485033404224 run_lib.py:146] step: 372450, training_loss: 5.91532e-04
I0514 00:41:51.698635 22485033404224 run_lib.py:146] step: 372500, training_loss: 8.43563e-04
I0514 00:41:51.859511 22485033404224 run_lib.py:167] step: 372500, eval_loss: 6.76145e-04
I0514 00:42:15.756902 22485033404224 run_lib.py:146] step: 372550, training_loss: 7.54325e-04
I0514 00:42:39.657390 22485033404224 run_lib.py:146] step: 372600, training_loss: 4.82932e-04
I0514 00:42:39.818447 22485033404224 run_lib.py:167] step: 372600, eval_loss: 6.00194e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:43:03.423086 22485033404224 run_lib.py:146] step: 372650, training_loss: 5.10875e-04
I0514 00:43:27.279610 22485033404224 run_lib.py:146] step: 372700, training_loss: 5.05057e-04
I0514 00:43:27.441689 22485033404224 run_lib.py:167] step: 372700, eval_loss: 7.75066e-04
I0514 00:43:51.297927 22485033404224 run_lib.py:146] step: 372750, training_loss: 5.91234e-04
I0514 00:44:14.824019 22485033404224 run_lib.py:146] step: 372800, training_loss: 6.55861e-04
I0514 00:44:14.982820 22485033404224 run_lib.py:167] step: 372800, eval_loss: 6.57718e-04
I0514 00:44:38.509342 22485033404224 run_lib.py:146] step: 372850, training_loss: 6.23075e-04
I0514 00:45:02.620918 22485033404224 run_lib.py:146] step: 372900, training_loss: 6.63836e-04
I0514 00:45:02.780521 22485033404224 run_lib.py:167] step: 372900, eval_loss: 5.71531e-04
I0514 00:45:26.293652 22485033404224 run_lib.py:146] step: 372950, training_loss: 6.53328e-04
I0514 00:45:49.801345 22485033404224 run_lib.py:146] step: 373000, training_loss: 5.30322e-04
I0514 00:45:49.959806 22485033404224 run_lib.py:167] step: 373000, eval_loss: 4.88497e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:46:14.255588 22485033404224 run_lib.py:146] step: 373050, training_loss: 4.38459e-04
I0514 00:46:37.772567 22485033404224 run_lib.py:146] step: 373100, training_loss: 5.28300e-04
I0514 00:46:37.933230 22485033404224 run_lib.py:167] step: 373100, eval_loss: 6.29360e-04
I0514 00:47:01.449715 22485033404224 run_lib.py:146] step: 373150, training_loss: 6.13870e-04
I0514 00:47:25.584352 22485033404224 run_lib.py:146] step: 373200, training_loss: 6.42802e-04
I0514 00:47:25.743889 22485033404224 run_lib.py:167] step: 373200, eval_loss: 6.43252e-04
I0514 00:47:49.279558 22485033404224 run_lib.py:146] step: 373250, training_loss: 8.04767e-04
I0514 00:48:12.819733 22485033404224 run_lib.py:146] step: 373300, training_loss: 5.81326e-04
I0514 00:48:12.979192 22485033404224 run_lib.py:167] step: 373300, eval_loss: 4.10785e-04
I0514 00:48:36.816552 22485033404224 run_lib.py:146] step: 373350, training_loss: 5.35380e-04
I0514 00:49:00.633767 22485033404224 run_lib.py:146] step: 373400, training_loss: 5.04120e-04
I0514 00:49:00.792343 22485033404224 run_lib.py:167] step: 373400, eval_loss: 5.75967e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:49:24.403514 22485033404224 run_lib.py:146] step: 373450, training_loss: 7.21158e-04
I0514 00:49:48.304780 22485033404224 run_lib.py:146] step: 373500, training_loss: 6.64808e-04
I0514 00:49:48.465146 22485033404224 run_lib.py:167] step: 373500, eval_loss: 5.86127e-04
I0514 00:50:12.317842 22485033404224 run_lib.py:146] step: 373550, training_loss: 7.17981e-04
I0514 00:50:35.883440 22485033404224 run_lib.py:146] step: 373600, training_loss: 7.70081e-04
I0514 00:50:36.043160 22485033404224 run_lib.py:167] step: 373600, eval_loss: 5.98327e-04
I0514 00:50:59.581884 22485033404224 run_lib.py:146] step: 373650, training_loss: 6.51472e-04
I0514 00:51:23.697856 22485033404224 run_lib.py:146] step: 373700, training_loss: 6.87824e-04
I0514 00:51:23.857509 22485033404224 run_lib.py:167] step: 373700, eval_loss: 6.83337e-04
I0514 00:51:47.374620 22485033404224 run_lib.py:146] step: 373750, training_loss: 7.93145e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:52:10.977347 22485033404224 run_lib.py:146] step: 373800, training_loss: 4.46661e-04
I0514 00:52:11.138761 22485033404224 run_lib.py:167] step: 373800, eval_loss: 6.81800e-04
I0514 00:52:35.346843 22485033404224 run_lib.py:146] step: 373850, training_loss: 5.64793e-04
I0514 00:52:58.879071 22485033404224 run_lib.py:146] step: 373900, training_loss: 6.23607e-04
I0514 00:52:59.038404 22485033404224 run_lib.py:167] step: 373900, eval_loss: 7.62233e-04
I0514 00:53:22.578371 22485033404224 run_lib.py:146] step: 373950, training_loss: 7.28332e-04
I0514 00:53:46.805177 22485033404224 run_lib.py:146] step: 374000, training_loss: 8.12955e-04
I0514 00:53:46.966573 22485033404224 run_lib.py:167] step: 374000, eval_loss: 6.56664e-04
I0514 00:54:10.554687 22485033404224 run_lib.py:146] step: 374050, training_loss: 5.52866e-04
I0514 00:54:34.148238 22485033404224 run_lib.py:146] step: 374100, training_loss: 4.44853e-04
I0514 00:54:34.308194 22485033404224 run_lib.py:167] step: 374100, eval_loss: 5.91040e-04
I0514 00:54:58.218110 22485033404224 run_lib.py:146] step: 374150, training_loss: 7.48822e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:55:22.207162 22485033404224 run_lib.py:146] step: 374200, training_loss: 5.79613e-04
I0514 00:55:22.369443 22485033404224 run_lib.py:167] step: 374200, eval_loss: 5.19411e-04
I0514 00:55:45.973928 22485033404224 run_lib.py:146] step: 374250, training_loss: 8.50015e-04
I0514 00:56:09.884267 22485033404224 run_lib.py:146] step: 374300, training_loss: 5.32446e-04
I0514 00:56:10.044593 22485033404224 run_lib.py:167] step: 374300, eval_loss: 4.07638e-04
I0514 00:56:34.065570 22485033404224 run_lib.py:146] step: 374350, training_loss: 8.06715e-04
I0514 00:56:57.654969 22485033404224 run_lib.py:146] step: 374400, training_loss: 7.64881e-04
I0514 00:56:57.815593 22485033404224 run_lib.py:167] step: 374400, eval_loss: 7.13649e-04
I0514 00:57:21.701036 22485033404224 run_lib.py:146] step: 374450, training_loss: 5.42064e-04
I0514 00:57:45.721769 22485033404224 run_lib.py:146] step: 374500, training_loss: 7.43518e-04
I0514 00:57:45.881527 22485033404224 run_lib.py:167] step: 374500, eval_loss: 5.69077e-04
I0514 00:58:09.456903 22485033404224 run_lib.py:146] step: 374550, training_loss: 7.35694e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:58:33.132809 22485033404224 run_lib.py:146] step: 374600, training_loss: 6.45738e-04
I0514 00:58:33.294603 22485033404224 run_lib.py:167] step: 374600, eval_loss: 5.53731e-04
I0514 00:58:57.588765 22485033404224 run_lib.py:146] step: 374650, training_loss: 5.70921e-04
I0514 00:59:21.199073 22485033404224 run_lib.py:146] step: 374700, training_loss: 4.50445e-04
I0514 00:59:21.359493 22485033404224 run_lib.py:167] step: 374700, eval_loss: 8.05171e-04
I0514 00:59:44.941498 22485033404224 run_lib.py:146] step: 374750, training_loss: 6.68811e-04
I0514 01:00:09.134163 22485033404224 run_lib.py:146] step: 374800, training_loss: 6.62799e-04
I0514 01:00:09.293992 22485033404224 run_lib.py:167] step: 374800, eval_loss: 4.34078e-04
I0514 01:00:32.951309 22485033404224 run_lib.py:146] step: 374850, training_loss: 6.45822e-04
I0514 01:00:56.562013 22485033404224 run_lib.py:146] step: 374900, training_loss: 7.12225e-04
I0514 01:00:56.722077 22485033404224 run_lib.py:167] step: 374900, eval_loss: 6.95205e-04
I0514 01:01:20.562138 22485033404224 run_lib.py:146] step: 374950, training_loss: 5.55046e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:01:44.444319 22485033404224 run_lib.py:146] step: 375000, training_loss: 6.22217e-04
I0514 01:01:44.604635 22485033404224 run_lib.py:167] step: 375000, eval_loss: 5.23207e-04
I0514 01:02:08.099628 22485033404224 run_lib.py:146] step: 375050, training_loss: 5.80660e-04
I0514 01:02:31.952487 22485033404224 run_lib.py:146] step: 375100, training_loss: 5.28058e-04
I0514 01:02:32.112142 22485033404224 run_lib.py:167] step: 375100, eval_loss: 6.43006e-04
I0514 01:02:55.936542 22485033404224 run_lib.py:146] step: 375150, training_loss: 5.79289e-04
I0514 01:03:19.448827 22485033404224 run_lib.py:146] step: 375200, training_loss: 7.80263e-04
I0514 01:03:19.608261 22485033404224 run_lib.py:167] step: 375200, eval_loss: 7.44865e-04
I0514 01:03:43.413991 22485033404224 run_lib.py:146] step: 375250, training_loss: 5.20057e-04
I0514 01:04:07.217965 22485033404224 run_lib.py:146] step: 375300, training_loss: 5.46262e-04
I0514 01:04:07.378242 22485033404224 run_lib.py:167] step: 375300, eval_loss: 5.88050e-04
I0514 01:04:30.891985 22485033404224 run_lib.py:146] step: 375350, training_loss: 4.85542e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:04:54.534000 22485033404224 run_lib.py:146] step: 375400, training_loss: 6.91062e-04
I0514 01:04:54.695440 22485033404224 run_lib.py:167] step: 375400, eval_loss: 5.33050e-04
I0514 01:05:18.884299 22485033404224 run_lib.py:146] step: 375450, training_loss: 8.19483e-04
I0514 01:05:42.422074 22485033404224 run_lib.py:146] step: 375500, training_loss: 6.00028e-04
I0514 01:05:42.581509 22485033404224 run_lib.py:167] step: 375500, eval_loss: 6.36391e-04
I0514 01:06:06.106971 22485033404224 run_lib.py:146] step: 375550, training_loss: 6.07327e-04
I0514 01:06:30.273141 22485033404224 run_lib.py:146] step: 375600, training_loss: 5.39542e-04
I0514 01:06:30.432387 22485033404224 run_lib.py:167] step: 375600, eval_loss: 5.27065e-04
I0514 01:06:53.972297 22485033404224 run_lib.py:146] step: 375650, training_loss: 6.08702e-04
I0514 01:07:17.534719 22485033404224 run_lib.py:146] step: 375700, training_loss: 7.16206e-04
I0514 01:07:17.695059 22485033404224 run_lib.py:167] step: 375700, eval_loss: 5.85080e-04
I0514 01:07:41.689040 22485033404224 run_lib.py:146] step: 375750, training_loss: 7.46468e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:08:05.409853 22485033404224 run_lib.py:146] step: 375800, training_loss: 6.18531e-04
I0514 01:08:05.571268 22485033404224 run_lib.py:167] step: 375800, eval_loss: 6.04472e-04
I0514 01:08:29.107202 22485033404224 run_lib.py:146] step: 375850, training_loss: 6.19176e-04
I0514 01:08:52.961546 22485033404224 run_lib.py:146] step: 375900, training_loss: 6.27889e-04
I0514 01:08:53.121071 22485033404224 run_lib.py:167] step: 375900, eval_loss: 6.94551e-04
I0514 01:09:16.955665 22485033404224 run_lib.py:146] step: 375950, training_loss: 6.77884e-04
I0514 01:09:40.477282 22485033404224 run_lib.py:146] step: 376000, training_loss: 5.34515e-04
I0514 01:09:40.637896 22485033404224 run_lib.py:167] step: 376000, eval_loss: 8.61478e-04
I0514 01:10:04.460878 22485033404224 run_lib.py:146] step: 376050, training_loss: 6.16781e-04
I0514 01:10:28.273356 22485033404224 run_lib.py:146] step: 376100, training_loss: 4.37429e-04
I0514 01:10:28.432204 22485033404224 run_lib.py:167] step: 376100, eval_loss: 5.69911e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:10:52.038363 22485033404224 run_lib.py:146] step: 376150, training_loss: 5.39474e-04
I0514 01:11:15.573721 22485033404224 run_lib.py:146] step: 376200, training_loss: 7.62775e-04
I0514 01:11:15.733741 22485033404224 run_lib.py:167] step: 376200, eval_loss: 5.20326e-04
I0514 01:11:40.007653 22485033404224 run_lib.py:146] step: 376250, training_loss: 6.55601e-04
I0514 01:12:03.624295 22485033404224 run_lib.py:146] step: 376300, training_loss: 7.39409e-04
I0514 01:12:03.784612 22485033404224 run_lib.py:167] step: 376300, eval_loss: 4.87673e-04
I0514 01:12:27.402591 22485033404224 run_lib.py:146] step: 376350, training_loss: 7.08761e-04
I0514 01:12:51.613811 22485033404224 run_lib.py:146] step: 376400, training_loss: 5.93453e-04
I0514 01:12:51.774994 22485033404224 run_lib.py:167] step: 376400, eval_loss: 6.36357e-04
I0514 01:13:15.346140 22485033404224 run_lib.py:146] step: 376450, training_loss: 5.21353e-04
I0514 01:13:38.931727 22485033404224 run_lib.py:146] step: 376500, training_loss: 5.70323e-04
I0514 01:13:39.093067 22485033404224 run_lib.py:167] step: 376500, eval_loss: 7.61906e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:14:03.593594 22485033404224 run_lib.py:146] step: 376550, training_loss: 6.06737e-04
I0514 01:14:27.332171 22485033404224 run_lib.py:146] step: 376600, training_loss: 5.09971e-04
I0514 01:14:27.496835 22485033404224 run_lib.py:167] step: 376600, eval_loss: 5.29176e-04
I0514 01:14:51.250435 22485033404224 run_lib.py:146] step: 376650, training_loss: 5.51682e-04
I0514 01:15:15.365792 22485033404224 run_lib.py:146] step: 376700, training_loss: 8.29611e-04
I0514 01:15:15.529587 22485033404224 run_lib.py:167] step: 376700, eval_loss: 5.24593e-04
I0514 01:15:39.692427 22485033404224 run_lib.py:146] step: 376750, training_loss: 8.17981e-04
I0514 01:16:03.391649 22485033404224 run_lib.py:146] step: 376800, training_loss: 5.60947e-04
I0514 01:16:03.554672 22485033404224 run_lib.py:167] step: 376800, eval_loss: 6.41761e-04
I0514 01:16:27.513829 22485033404224 run_lib.py:146] step: 376850, training_loss: 5.89973e-04
I0514 01:16:51.596175 22485033404224 run_lib.py:146] step: 376900, training_loss: 5.39750e-04
I0514 01:16:51.755717 22485033404224 run_lib.py:167] step: 376900, eval_loss: 4.86467e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:17:15.484729 22485033404224 run_lib.py:146] step: 376950, training_loss: 9.46299e-04
I0514 01:17:39.564485 22485033404224 run_lib.py:146] step: 377000, training_loss: 6.74846e-04
I0514 01:17:39.726117 22485033404224 run_lib.py:167] step: 377000, eval_loss: 7.13555e-04
I0514 01:18:03.783985 22485033404224 run_lib.py:146] step: 377050, training_loss: 6.03724e-04
I0514 01:18:27.442096 22485033404224 run_lib.py:146] step: 377100, training_loss: 7.01424e-04
I0514 01:18:27.602613 22485033404224 run_lib.py:167] step: 377100, eval_loss: 7.09565e-04
I0514 01:18:51.249821 22485033404224 run_lib.py:146] step: 377150, training_loss: 7.11987e-04
I0514 01:19:15.583236 22485033404224 run_lib.py:146] step: 377200, training_loss: 5.60707e-04
I0514 01:19:15.742825 22485033404224 run_lib.py:167] step: 377200, eval_loss: 7.29551e-04
I0514 01:19:39.273939 22485033404224 run_lib.py:146] step: 377250, training_loss: 6.84381e-04
I0514 01:20:02.816291 22485033404224 run_lib.py:146] step: 377300, training_loss: 5.52795e-04
I0514 01:20:02.976051 22485033404224 run_lib.py:167] step: 377300, eval_loss: 6.00725e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:20:27.245106 22485033404224 run_lib.py:146] step: 377350, training_loss: 6.49970e-04
I0514 01:20:50.764100 22485033404224 run_lib.py:146] step: 377400, training_loss: 5.15625e-04
I0514 01:20:50.924797 22485033404224 run_lib.py:167] step: 377400, eval_loss: 8.13786e-04
I0514 01:21:14.432460 22485033404224 run_lib.py:146] step: 377450, training_loss: 5.62407e-04
I0514 01:21:38.543725 22485033404224 run_lib.py:146] step: 377500, training_loss: 6.56983e-04
I0514 01:21:38.702963 22485033404224 run_lib.py:167] step: 377500, eval_loss: 5.56187e-04
I0514 01:22:02.203124 22485033404224 run_lib.py:146] step: 377550, training_loss: 5.32133e-04
I0514 01:22:25.722578 22485033404224 run_lib.py:146] step: 377600, training_loss: 5.44337e-04
I0514 01:22:25.882272 22485033404224 run_lib.py:167] step: 377600, eval_loss: 7.62010e-04
I0514 01:22:49.699520 22485033404224 run_lib.py:146] step: 377650, training_loss: 7.97109e-04
I0514 01:23:13.514036 22485033404224 run_lib.py:146] step: 377700, training_loss: 5.70382e-04
I0514 01:23:13.672960 22485033404224 run_lib.py:167] step: 377700, eval_loss: 5.67614e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:23:37.244018 22485033404224 run_lib.py:146] step: 377750, training_loss: 4.56867e-04
I0514 01:24:01.072613 22485033404224 run_lib.py:146] step: 377800, training_loss: 6.12654e-04
I0514 01:24:01.232478 22485033404224 run_lib.py:167] step: 377800, eval_loss: 6.25301e-04
I0514 01:24:25.083087 22485033404224 run_lib.py:146] step: 377850, training_loss: 7.09575e-04
I0514 01:24:48.608358 22485033404224 run_lib.py:146] step: 377900, training_loss: 6.76247e-04
I0514 01:24:48.768539 22485033404224 run_lib.py:167] step: 377900, eval_loss: 4.95254e-04
I0514 01:25:12.305977 22485033404224 run_lib.py:146] step: 377950, training_loss: 6.73060e-04
I0514 01:25:36.435692 22485033404224 run_lib.py:146] step: 378000, training_loss: 6.29767e-04
I0514 01:25:36.652029 22485033404224 run_lib.py:167] step: 378000, eval_loss: 4.88630e-04
I0514 01:26:00.171043 22485033404224 run_lib.py:146] step: 378050, training_loss: 4.75042e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:26:23.780823 22485033404224 run_lib.py:146] step: 378100, training_loss: 6.67472e-04
I0514 01:26:23.941707 22485033404224 run_lib.py:167] step: 378100, eval_loss: 6.20392e-04
I0514 01:26:48.150330 22485033404224 run_lib.py:146] step: 378150, training_loss: 6.62333e-04
I0514 01:27:11.682413 22485033404224 run_lib.py:146] step: 378200, training_loss: 5.29999e-04
I0514 01:27:11.841259 22485033404224 run_lib.py:167] step: 378200, eval_loss: 5.55043e-04
I0514 01:27:35.343084 22485033404224 run_lib.py:146] step: 378250, training_loss: 6.93560e-04
I0514 01:27:59.448220 22485033404224 run_lib.py:146] step: 378300, training_loss: 5.81240e-04
I0514 01:27:59.608046 22485033404224 run_lib.py:167] step: 378300, eval_loss: 7.43988e-04
I0514 01:28:23.120348 22485033404224 run_lib.py:146] step: 378350, training_loss: 5.10260e-04
I0514 01:28:46.646176 22485033404224 run_lib.py:146] step: 378400, training_loss: 6.73723e-04
I0514 01:28:46.806880 22485033404224 run_lib.py:167] step: 378400, eval_loss: 5.44508e-04
I0514 01:29:10.892010 22485033404224 run_lib.py:146] step: 378450, training_loss: 5.52236e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:29:34.520095 22485033404224 run_lib.py:146] step: 378500, training_loss: 6.72292e-04
I0514 01:29:34.682220 22485033404224 run_lib.py:167] step: 378500, eval_loss: 5.20210e-04
I0514 01:29:58.254427 22485033404224 run_lib.py:146] step: 378550, training_loss: 7.11108e-04
I0514 01:30:22.199852 22485033404224 run_lib.py:146] step: 378600, training_loss: 6.32578e-04
I0514 01:30:22.360673 22485033404224 run_lib.py:167] step: 378600, eval_loss: 6.49918e-04
I0514 01:30:46.275654 22485033404224 run_lib.py:146] step: 378650, training_loss: 7.85731e-04
I0514 01:31:09.862118 22485033404224 run_lib.py:146] step: 378700, training_loss: 6.03121e-04
I0514 01:31:10.022022 22485033404224 run_lib.py:167] step: 378700, eval_loss: 7.33027e-04
I0514 01:31:34.002241 22485033404224 run_lib.py:146] step: 378750, training_loss: 6.54895e-04
I0514 01:31:57.918210 22485033404224 run_lib.py:146] step: 378800, training_loss: 6.21888e-04
I0514 01:31:58.078981 22485033404224 run_lib.py:167] step: 378800, eval_loss: 6.81143e-04
I0514 01:32:21.671468 22485033404224 run_lib.py:146] step: 378850, training_loss: 7.12825e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:32:45.335887 22485033404224 run_lib.py:146] step: 378900, training_loss: 6.08692e-04
I0514 01:32:45.499210 22485033404224 run_lib.py:167] step: 378900, eval_loss: 7.30037e-04
I0514 01:33:10.042027 22485033404224 run_lib.py:146] step: 378950, training_loss: 6.76049e-04
I0514 01:33:33.671317 22485033404224 run_lib.py:146] step: 379000, training_loss: 5.37820e-04
I0514 01:33:33.832629 22485033404224 run_lib.py:167] step: 379000, eval_loss: 5.08256e-04
I0514 01:33:57.455717 22485033404224 run_lib.py:146] step: 379050, training_loss: 6.07880e-04
I0514 01:34:21.837162 22485033404224 run_lib.py:146] step: 379100, training_loss: 4.80784e-04
I0514 01:34:21.921842 22485033404224 run_lib.py:167] step: 379100, eval_loss: 6.93504e-04
I0514 01:34:45.485198 22485033404224 run_lib.py:146] step: 379150, training_loss: 6.21080e-04
I0514 01:35:09.068283 22485033404224 run_lib.py:146] step: 379200, training_loss: 6.70440e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:35:09.429976 22485033404224 run_lib.py:167] step: 379200, eval_loss: 5.24252e-04
I0514 01:35:33.947152 22485033404224 run_lib.py:146] step: 379250, training_loss: 6.35480e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:35:57.651506 22485033404224 run_lib.py:146] step: 379300, training_loss: 5.86951e-04
I0514 01:35:57.813287 22485033404224 run_lib.py:167] step: 379300, eval_loss: 7.90674e-04
I0514 01:36:21.485165 22485033404224 run_lib.py:146] step: 379350, training_loss: 6.98098e-04
I0514 01:36:45.636490 22485033404224 run_lib.py:146] step: 379400, training_loss: 7.90146e-04
I0514 01:36:45.797267 22485033404224 run_lib.py:167] step: 379400, eval_loss: 5.27277e-04
I0514 01:37:09.810923 22485033404224 run_lib.py:146] step: 379450, training_loss: 6.63219e-04
I0514 01:37:33.336292 22485033404224 run_lib.py:146] step: 379500, training_loss: 5.24911e-04
I0514 01:37:33.495522 22485033404224 run_lib.py:167] step: 379500, eval_loss: 7.08944e-04
I0514 01:37:57.313306 22485033404224 run_lib.py:146] step: 379550, training_loss: 5.91268e-04
I0514 01:38:21.132236 22485033404224 run_lib.py:146] step: 379600, training_loss: 5.90652e-04
I0514 01:38:21.291548 22485033404224 run_lib.py:167] step: 379600, eval_loss: 4.17657e-04
I0514 01:38:44.822173 22485033404224 run_lib.py:146] step: 379650, training_loss: 9.07691e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:39:08.421817 22485033404224 run_lib.py:146] step: 379700, training_loss: 7.08604e-04
I0514 01:39:08.582311 22485033404224 run_lib.py:167] step: 379700, eval_loss: 6.15630e-04
I0514 01:39:32.748363 22485033404224 run_lib.py:146] step: 379750, training_loss: 6.99851e-04
I0514 01:39:56.277725 22485033404224 run_lib.py:146] step: 379800, training_loss: 6.11609e-04
I0514 01:39:56.436323 22485033404224 run_lib.py:167] step: 379800, eval_loss: 5.59242e-04
I0514 01:40:19.953042 22485033404224 run_lib.py:146] step: 379850, training_loss: 6.59361e-04
I0514 01:40:44.067737 22485033404224 run_lib.py:146] step: 379900, training_loss: 5.43137e-04
I0514 01:40:44.226469 22485033404224 run_lib.py:167] step: 379900, eval_loss: 6.10544e-04
I0514 01:41:07.748956 22485033404224 run_lib.py:146] step: 379950, training_loss: 6.34471e-04
I0514 01:41:31.259437 22485033404224 run_lib.py:146] step: 380000, training_loss: 5.97467e-04
I0514 01:41:33.015565 22485033404224 run_lib.py:167] step: 380000, eval_loss: 6.15592e-04
I0514 01:41:58.652060 22485033404224 run_lib.py:146] step: 380050, training_loss: 6.16832e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:42:22.275664 22485033404224 run_lib.py:146] step: 380100, training_loss: 4.00338e-04
I0514 01:42:22.436478 22485033404224 run_lib.py:167] step: 380100, eval_loss: 7.48896e-04
I0514 01:42:45.973875 22485033404224 run_lib.py:146] step: 380150, training_loss: 6.79348e-04
I0514 01:43:09.829796 22485033404224 run_lib.py:146] step: 380200, training_loss: 5.87439e-04
I0514 01:43:10.006078 22485033404224 run_lib.py:167] step: 380200, eval_loss: 7.71367e-04
I0514 01:43:33.824238 22485033404224 run_lib.py:146] step: 380250, training_loss: 6.14846e-04
I0514 01:43:57.340881 22485033404224 run_lib.py:146] step: 380300, training_loss: 4.86743e-04
I0514 01:43:57.501346 22485033404224 run_lib.py:167] step: 380300, eval_loss: 5.77426e-04
I0514 01:44:21.343365 22485033404224 run_lib.py:146] step: 380350, training_loss: 7.65998e-04
I0514 01:44:45.159819 22485033404224 run_lib.py:146] step: 380400, training_loss: 6.02700e-04
I0514 01:44:45.319102 22485033404224 run_lib.py:167] step: 380400, eval_loss: 5.67240e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:45:08.893530 22485033404224 run_lib.py:146] step: 380450, training_loss: 5.80523e-04
I0514 01:45:32.770943 22485033404224 run_lib.py:146] step: 380500, training_loss: 4.67419e-04
I0514 01:45:32.931239 22485033404224 run_lib.py:167] step: 380500, eval_loss: 5.05432e-04
I0514 01:45:56.788439 22485033404224 run_lib.py:146] step: 380550, training_loss: 4.44491e-04
I0514 01:46:20.309419 22485033404224 run_lib.py:146] step: 380600, training_loss: 6.06283e-04
I0514 01:46:20.469591 22485033404224 run_lib.py:167] step: 380600, eval_loss: 5.91206e-04
I0514 01:46:44.211923 22485033404224 run_lib.py:146] step: 380650, training_loss: 5.52788e-04
I0514 01:47:08.027657 22485033404224 run_lib.py:146] step: 380700, training_loss: 8.21558e-04
I0514 01:47:08.186820 22485033404224 run_lib.py:167] step: 380700, eval_loss: 8.15126e-04
I0514 01:47:31.698814 22485033404224 run_lib.py:146] step: 380750, training_loss: 4.62070e-04
I0514 01:47:55.549326 22485033404224 run_lib.py:146] step: 380800, training_loss: 6.11364e-04
I0514 01:47:55.709759 22485033404224 run_lib.py:167] step: 380800, eval_loss: 6.20925e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:48:19.740370 22485033404224 run_lib.py:146] step: 380850, training_loss: 5.98138e-04
I0514 01:48:43.327438 22485033404224 run_lib.py:146] step: 380900, training_loss: 6.19853e-04
I0514 01:48:43.488673 22485033404224 run_lib.py:167] step: 380900, eval_loss: 6.09449e-04
I0514 01:49:07.071959 22485033404224 run_lib.py:146] step: 380950, training_loss: 5.50800e-04
I0514 01:49:31.301259 22485033404224 run_lib.py:146] step: 381000, training_loss: 7.38142e-04
I0514 01:49:31.461529 22485033404224 run_lib.py:167] step: 381000, eval_loss: 5.85291e-04
I0514 01:49:55.052930 22485033404224 run_lib.py:146] step: 381050, training_loss: 8.48240e-04
I0514 01:50:18.646911 22485033404224 run_lib.py:146] step: 381100, training_loss: 6.58831e-04
I0514 01:50:18.807776 22485033404224 run_lib.py:167] step: 381100, eval_loss: 5.68807e-04
I0514 01:50:42.680394 22485033404224 run_lib.py:146] step: 381150, training_loss: 6.01323e-04
I0514 01:51:06.540005 22485033404224 run_lib.py:146] step: 381200, training_loss: 5.94037e-04
I0514 01:51:06.699342 22485033404224 run_lib.py:167] step: 381200, eval_loss: 4.37910e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:51:30.366433 22485033404224 run_lib.py:146] step: 381250, training_loss: 5.08361e-04
I0514 01:51:54.423482 22485033404224 run_lib.py:146] step: 381300, training_loss: 6.90853e-04
I0514 01:51:54.585639 22485033404224 run_lib.py:167] step: 381300, eval_loss: 6.85646e-04
I0514 01:52:18.520520 22485033404224 run_lib.py:146] step: 381350, training_loss: 6.08270e-04
I0514 01:52:42.093456 22485033404224 run_lib.py:146] step: 381400, training_loss: 6.09601e-04
I0514 01:52:42.254025 22485033404224 run_lib.py:167] step: 381400, eval_loss: 7.81168e-04
I0514 01:53:06.225402 22485033404224 run_lib.py:146] step: 381450, training_loss: 6.65054e-04
I0514 01:53:30.107038 22485033404224 run_lib.py:146] step: 381500, training_loss: 6.29057e-04
I0514 01:53:30.266793 22485033404224 run_lib.py:167] step: 381500, eval_loss: 7.51896e-04
I0514 01:53:53.873445 22485033404224 run_lib.py:146] step: 381550, training_loss: 6.85983e-04
I0514 01:54:17.888788 22485033404224 run_lib.py:146] step: 381600, training_loss: 6.41679e-04
I0514 01:54:18.049688 22485033404224 run_lib.py:167] step: 381600, eval_loss: 6.36840e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:54:42.070565 22485033404224 run_lib.py:146] step: 381650, training_loss: 7.17311e-04
I0514 01:55:05.700386 22485033404224 run_lib.py:146] step: 381700, training_loss: 6.02807e-04
I0514 01:55:05.861505 22485033404224 run_lib.py:167] step: 381700, eval_loss: 5.31905e-04
I0514 01:55:29.444651 22485033404224 run_lib.py:146] step: 381750, training_loss: 5.62563e-04
I0514 01:55:53.629778 22485033404224 run_lib.py:146] step: 381800, training_loss: 4.91609e-04
I0514 01:55:53.789070 22485033404224 run_lib.py:167] step: 381800, eval_loss: 5.54966e-04
I0514 01:56:17.337543 22485033404224 run_lib.py:146] step: 381850, training_loss: 5.40965e-04
I0514 01:56:40.877042 22485033404224 run_lib.py:146] step: 381900, training_loss: 7.94538e-04
I0514 01:56:41.036727 22485033404224 run_lib.py:167] step: 381900, eval_loss: 8.35042e-04
I0514 01:57:04.908494 22485033404224 run_lib.py:146] step: 381950, training_loss: 7.31379e-04
I0514 01:57:28.735635 22485033404224 run_lib.py:146] step: 382000, training_loss: 6.44078e-04
I0514 01:57:28.895769 22485033404224 run_lib.py:167] step: 382000, eval_loss: 8.41512e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:57:52.489447 22485033404224 run_lib.py:146] step: 382050, training_loss: 6.96345e-04
I0514 01:58:16.344014 22485033404224 run_lib.py:146] step: 382100, training_loss: 6.04144e-04
I0514 01:58:16.503993 22485033404224 run_lib.py:167] step: 382100, eval_loss: 6.56883e-04
I0514 01:58:40.340132 22485033404224 run_lib.py:146] step: 382150, training_loss: 5.58679e-04
I0514 01:59:03.866253 22485033404224 run_lib.py:146] step: 382200, training_loss: 6.29301e-04
I0514 01:59:04.025516 22485033404224 run_lib.py:167] step: 382200, eval_loss: 5.58975e-04
I0514 01:59:27.852012 22485033404224 run_lib.py:146] step: 382250, training_loss: 5.81539e-04
I0514 01:59:51.681935 22485033404224 run_lib.py:146] step: 382300, training_loss: 5.32114e-04
I0514 01:59:51.841458 22485033404224 run_lib.py:167] step: 382300, eval_loss: 7.83541e-04
I0514 02:00:15.384161 22485033404224 run_lib.py:146] step: 382350, training_loss: 5.78301e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:00:46.509511 22485033404224 run_lib.py:146] step: 382400, training_loss: 6.51414e-04
I0514 02:00:46.670342 22485033404224 run_lib.py:167] step: 382400, eval_loss: 5.63856e-04
I0514 02:01:10.533534 22485033404224 run_lib.py:146] step: 382450, training_loss: 5.10644e-04
I0514 02:01:34.091017 22485033404224 run_lib.py:146] step: 382500, training_loss: 4.99651e-04
I0514 02:01:34.249655 22485033404224 run_lib.py:167] step: 382500, eval_loss: 5.97770e-04
I0514 02:01:57.792617 22485033404224 run_lib.py:146] step: 382550, training_loss: 8.20420e-04
I0514 02:02:21.932708 22485033404224 run_lib.py:146] step: 382600, training_loss: 6.90803e-04
I0514 02:02:22.091589 22485033404224 run_lib.py:167] step: 382600, eval_loss: 5.75976e-04
I0514 02:02:45.609967 22485033404224 run_lib.py:146] step: 382650, training_loss: 7.43250e-04
I0514 02:03:09.132486 22485033404224 run_lib.py:146] step: 382700, training_loss: 6.76042e-04
I0514 02:03:09.293230 22485033404224 run_lib.py:167] step: 382700, eval_loss: 5.53799e-04
I0514 02:03:33.116635 22485033404224 run_lib.py:146] step: 382750, training_loss: 4.89652e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:03:57.060369 22485033404224 run_lib.py:146] step: 382800, training_loss: 7.57050e-04
I0514 02:03:57.220688 22485033404224 run_lib.py:167] step: 382800, eval_loss: 7.71181e-04
I0514 02:04:20.739935 22485033404224 run_lib.py:146] step: 382850, training_loss: 6.26073e-04
I0514 02:04:44.612200 22485033404224 run_lib.py:146] step: 382900, training_loss: 6.87088e-04
I0514 02:04:44.771162 22485033404224 run_lib.py:167] step: 382900, eval_loss: 6.51841e-04
I0514 02:05:08.634593 22485033404224 run_lib.py:146] step: 382950, training_loss: 5.59907e-04
I0514 02:05:32.177143 22485033404224 run_lib.py:146] step: 383000, training_loss: 8.52678e-04
I0514 02:05:32.338312 22485033404224 run_lib.py:167] step: 383000, eval_loss: 4.80179e-04
I0514 02:05:56.168065 22485033404224 run_lib.py:146] step: 383050, training_loss: 5.82784e-04
I0514 02:06:20.027069 22485033404224 run_lib.py:146] step: 383100, training_loss: 6.24462e-04
I0514 02:06:20.187597 22485033404224 run_lib.py:167] step: 383100, eval_loss: 5.46647e-04
I0514 02:06:43.786179 22485033404224 run_lib.py:146] step: 383150, training_loss: 4.88517e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:07:07.846928 22485033404224 run_lib.py:146] step: 383200, training_loss: 6.46347e-04
I0514 02:07:08.008732 22485033404224 run_lib.py:167] step: 383200, eval_loss: 4.76584e-04
I0514 02:07:31.973552 22485033404224 run_lib.py:146] step: 383250, training_loss: 5.89602e-04
I0514 02:07:55.587302 22485033404224 run_lib.py:146] step: 383300, training_loss: 8.29522e-04
I0514 02:07:55.747321 22485033404224 run_lib.py:167] step: 383300, eval_loss: 6.74985e-04
I0514 02:08:19.661480 22485033404224 run_lib.py:146] step: 383350, training_loss: 5.87438e-04
I0514 02:08:43.564485 22485033404224 run_lib.py:146] step: 383400, training_loss: 6.50998e-04
I0514 02:08:43.725011 22485033404224 run_lib.py:167] step: 383400, eval_loss: 6.59476e-04
I0514 02:09:07.310907 22485033404224 run_lib.py:146] step: 383450, training_loss: 5.94396e-04
I0514 02:09:30.897792 22485033404224 run_lib.py:146] step: 383500, training_loss: 6.12163e-04
I0514 02:09:31.058033 22485033404224 run_lib.py:167] step: 383500, eval_loss: 5.05927e-04
I0514 02:09:55.274919 22485033404224 run_lib.py:146] step: 383550, training_loss: 4.82845e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:10:19.043714 22485033404224 run_lib.py:146] step: 383600, training_loss: 9.44787e-04
I0514 02:10:19.207868 22485033404224 run_lib.py:167] step: 383600, eval_loss: 7.52570e-04
I0514 02:10:42.973233 22485033404224 run_lib.py:146] step: 383650, training_loss: 5.36675e-04
I0514 02:11:06.919321 22485033404224 run_lib.py:146] step: 383700, training_loss: 7.12688e-04
I0514 02:11:07.079363 22485033404224 run_lib.py:167] step: 383700, eval_loss: 6.12927e-04
I0514 02:11:31.083891 22485033404224 run_lib.py:146] step: 383750, training_loss: 5.66099e-04
I0514 02:11:54.697451 22485033404224 run_lib.py:146] step: 383800, training_loss: 5.86411e-04
I0514 02:11:54.857969 22485033404224 run_lib.py:167] step: 383800, eval_loss: 8.34650e-04
I0514 02:12:18.777767 22485033404224 run_lib.py:146] step: 383850, training_loss: 6.47711e-04
I0514 02:12:42.760165 22485033404224 run_lib.py:146] step: 383900, training_loss: 6.40251e-04
I0514 02:12:42.919510 22485033404224 run_lib.py:167] step: 383900, eval_loss: 5.28406e-04
I0514 02:13:06.526068 22485033404224 run_lib.py:146] step: 383950, training_loss: 5.04948e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:13:30.616319 22485033404224 run_lib.py:146] step: 384000, training_loss: 6.53448e-04
I0514 02:13:30.778847 22485033404224 run_lib.py:167] step: 384000, eval_loss: 7.39160e-04
I0514 02:13:54.784756 22485033404224 run_lib.py:146] step: 384050, training_loss: 7.09895e-04
I0514 02:14:18.335672 22485033404224 run_lib.py:146] step: 384100, training_loss: 5.92571e-04
I0514 02:14:18.494731 22485033404224 run_lib.py:167] step: 384100, eval_loss: 7.74660e-04
I0514 02:14:42.313337 22485033404224 run_lib.py:146] step: 384150, training_loss: 7.61484e-04
I0514 02:15:06.138671 22485033404224 run_lib.py:146] step: 384200, training_loss: 6.63814e-04
I0514 02:15:06.298108 22485033404224 run_lib.py:167] step: 384200, eval_loss: 5.66544e-04
I0514 02:15:29.809081 22485033404224 run_lib.py:146] step: 384250, training_loss: 7.26880e-04
I0514 02:15:53.309070 22485033404224 run_lib.py:146] step: 384300, training_loss: 5.45714e-04
I0514 02:15:53.468405 22485033404224 run_lib.py:167] step: 384300, eval_loss: 7.92848e-04
I0514 02:16:17.557171 22485033404224 run_lib.py:146] step: 384350, training_loss: 5.03809e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:16:41.127621 22485033404224 run_lib.py:146] step: 384400, training_loss: 5.36613e-04
I0514 02:16:41.290488 22485033404224 run_lib.py:167] step: 384400, eval_loss: 6.43692e-04
I0514 02:17:04.796537 22485033404224 run_lib.py:146] step: 384450, training_loss: 7.29859e-04
I0514 02:17:28.665110 22485033404224 run_lib.py:146] step: 384500, training_loss: 6.40816e-04
I0514 02:17:28.824944 22485033404224 run_lib.py:167] step: 384500, eval_loss: 6.24769e-04
I0514 02:17:52.640480 22485033404224 run_lib.py:146] step: 384550, training_loss: 7.01401e-04
I0514 02:18:16.152122 22485033404224 run_lib.py:146] step: 384600, training_loss: 7.24797e-04
I0514 02:18:16.310242 22485033404224 run_lib.py:167] step: 384600, eval_loss: 5.61485e-04
I0514 02:18:40.142484 22485033404224 run_lib.py:146] step: 384650, training_loss: 5.04006e-04
I0514 02:19:03.957774 22485033404224 run_lib.py:146] step: 384700, training_loss: 7.41041e-04
I0514 02:19:04.154310 22485033404224 run_lib.py:167] step: 384700, eval_loss: 7.07771e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:19:27.743166 22485033404224 run_lib.py:146] step: 384750, training_loss: 7.37561e-04
I0514 02:19:51.599890 22485033404224 run_lib.py:146] step: 384800, training_loss: 4.85846e-04
I0514 02:19:51.759707 22485033404224 run_lib.py:167] step: 384800, eval_loss: 4.44671e-04
I0514 02:20:15.610087 22485033404224 run_lib.py:146] step: 384850, training_loss: 6.76627e-04
I0514 02:20:39.156227 22485033404224 run_lib.py:146] step: 384900, training_loss: 6.13139e-04
I0514 02:20:39.315498 22485033404224 run_lib.py:167] step: 384900, eval_loss: 4.23059e-04
I0514 02:21:03.155995 22485033404224 run_lib.py:146] step: 384950, training_loss: 4.98943e-04
I0514 02:21:26.996808 22485033404224 run_lib.py:146] step: 385000, training_loss: 6.82497e-04
I0514 02:21:27.156524 22485033404224 run_lib.py:167] step: 385000, eval_loss: 7.78590e-04
I0514 02:21:50.689300 22485033404224 run_lib.py:146] step: 385050, training_loss: 6.95651e-04
I0514 02:22:14.539915 22485033404224 run_lib.py:146] step: 385100, training_loss: 5.44332e-04
I0514 02:22:14.732802 22485033404224 run_lib.py:167] step: 385100, eval_loss: 5.82722e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:22:38.687922 22485033404224 run_lib.py:146] step: 385150, training_loss: 5.78750e-04
I0514 02:23:02.222400 22485033404224 run_lib.py:146] step: 385200, training_loss: 7.70401e-04
I0514 02:23:02.383696 22485033404224 run_lib.py:167] step: 385200, eval_loss: 6.22491e-04
I0514 02:23:25.921643 22485033404224 run_lib.py:146] step: 385250, training_loss: 7.39943e-04
I0514 02:23:50.084710 22485033404224 run_lib.py:146] step: 385300, training_loss: 7.87890e-04
I0514 02:23:50.244943 22485033404224 run_lib.py:167] step: 385300, eval_loss: 4.78567e-04
I0514 02:24:13.779851 22485033404224 run_lib.py:146] step: 385350, training_loss: 5.92401e-04
I0514 02:24:37.373883 22485033404224 run_lib.py:146] step: 385400, training_loss: 6.25894e-04
I0514 02:24:37.534485 22485033404224 run_lib.py:167] step: 385400, eval_loss: 6.49060e-04
I0514 02:25:01.446865 22485033404224 run_lib.py:146] step: 385450, training_loss: 6.42354e-04
I0514 02:25:25.369752 22485033404224 run_lib.py:146] step: 385500, training_loss: 5.69386e-04
I0514 02:25:25.530040 22485033404224 run_lib.py:167] step: 385500, eval_loss: 4.14527e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:25:49.216679 22485033404224 run_lib.py:146] step: 385550, training_loss: 7.00887e-04
I0514 02:26:13.161287 22485033404224 run_lib.py:146] step: 385600, training_loss: 5.44788e-04
I0514 02:26:13.323644 22485033404224 run_lib.py:167] step: 385600, eval_loss: 4.63520e-04
I0514 02:26:37.418028 22485033404224 run_lib.py:146] step: 385650, training_loss: 6.40806e-04
I0514 02:27:01.037915 22485033404224 run_lib.py:146] step: 385700, training_loss: 4.53025e-04
I0514 02:27:01.199613 22485033404224 run_lib.py:167] step: 385700, eval_loss: 5.74375e-04
I0514 02:27:25.117684 22485033404224 run_lib.py:146] step: 385750, training_loss: 6.82658e-04
I0514 02:27:49.143587 22485033404224 run_lib.py:146] step: 385800, training_loss: 7.53793e-04
I0514 02:27:49.303324 22485033404224 run_lib.py:167] step: 385800, eval_loss: 5.26854e-04
I0514 02:28:12.927826 22485033404224 run_lib.py:146] step: 385850, training_loss: 4.67777e-04
I0514 02:28:36.835573 22485033404224 run_lib.py:146] step: 385900, training_loss: 4.59354e-04
I0514 02:28:36.995999 22485033404224 run_lib.py:167] step: 385900, eval_loss: 7.44712e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:29:01.166921 22485033404224 run_lib.py:146] step: 385950, training_loss: 6.92457e-04
I0514 02:29:24.766175 22485033404224 run_lib.py:146] step: 386000, training_loss: 6.23159e-04
I0514 02:29:24.929328 22485033404224 run_lib.py:167] step: 386000, eval_loss: 5.34711e-04
I0514 02:29:48.893279 22485033404224 run_lib.py:146] step: 386050, training_loss: 6.45152e-04
I0514 02:30:12.832924 22485033404224 run_lib.py:146] step: 386100, training_loss: 1.01172e-03
I0514 02:30:12.993362 22485033404224 run_lib.py:167] step: 386100, eval_loss: 6.11937e-04
I0514 02:30:36.610086 22485033404224 run_lib.py:146] step: 386150, training_loss: 5.97810e-04
I0514 02:31:00.200828 22485033404224 run_lib.py:146] step: 386200, training_loss: 7.47786e-04
I0514 02:31:00.360711 22485033404224 run_lib.py:167] step: 386200, eval_loss: 7.57100e-04
I0514 02:31:24.278903 22485033404224 run_lib.py:146] step: 386250, training_loss: 6.29421e-04
I0514 02:31:48.186153 22485033404224 run_lib.py:146] step: 386300, training_loss: 4.13806e-04
I0514 02:31:48.347850 22485033404224 run_lib.py:167] step: 386300, eval_loss: 7.88838e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:32:11.982058 22485033404224 run_lib.py:146] step: 386350, training_loss: 6.93489e-04
I0514 02:32:35.851180 22485033404224 run_lib.py:146] step: 386400, training_loss: 6.63550e-04
I0514 02:32:36.011519 22485033404224 run_lib.py:167] step: 386400, eval_loss: 5.98121e-04
I0514 02:32:59.915419 22485033404224 run_lib.py:146] step: 386450, training_loss: 7.55666e-04
I0514 02:33:23.470364 22485033404224 run_lib.py:146] step: 386500, training_loss: 5.52460e-04
I0514 02:33:23.643239 22485033404224 run_lib.py:167] step: 386500, eval_loss: 5.21941e-04
I0514 02:33:47.466699 22485033404224 run_lib.py:146] step: 386550, training_loss: 5.62788e-04
I0514 02:34:11.283555 22485033404224 run_lib.py:146] step: 386600, training_loss: 5.11487e-04
I0514 02:34:11.443908 22485033404224 run_lib.py:167] step: 386600, eval_loss: 7.78773e-04
I0514 02:34:34.966315 22485033404224 run_lib.py:146] step: 386650, training_loss: 7.53206e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:34:58.866811 22485033404224 run_lib.py:146] step: 386700, training_loss: 6.21889e-04
I0514 02:34:59.051712 22485033404224 run_lib.py:167] step: 386700, eval_loss: 5.40845e-04
I0514 02:35:22.923645 22485033404224 run_lib.py:146] step: 386750, training_loss: 6.13669e-04
I0514 02:35:46.478065 22485033404224 run_lib.py:146] step: 386800, training_loss: 8.29990e-04
I0514 02:35:46.639512 22485033404224 run_lib.py:167] step: 386800, eval_loss: 6.32255e-04
I0514 02:36:10.528666 22485033404224 run_lib.py:146] step: 386850, training_loss: 6.89852e-04
I0514 02:36:34.360240 22485033404224 run_lib.py:146] step: 386900, training_loss: 6.79612e-04
I0514 02:36:34.518458 22485033404224 run_lib.py:167] step: 386900, eval_loss: 4.74041e-04
I0514 02:36:58.072368 22485033404224 run_lib.py:146] step: 386950, training_loss: 4.79509e-04
I0514 02:37:21.616503 22485033404224 run_lib.py:146] step: 387000, training_loss: 5.43545e-04
I0514 02:37:21.702159 22485033404224 run_lib.py:167] step: 387000, eval_loss: 2.67395e-04
I0514 02:37:45.846417 22485033404224 run_lib.py:146] step: 387050, training_loss: 5.24899e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:38:09.486767 22485033404224 run_lib.py:146] step: 387100, training_loss: 6.64439e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:38:09.835933 22485033404224 run_lib.py:167] step: 387100, eval_loss: 5.23401e-04
I0514 02:38:33.386925 22485033404224 run_lib.py:146] step: 387150, training_loss: 5.47608e-04
I0514 02:38:57.269927 22485033404224 run_lib.py:146] step: 387200, training_loss: 6.10170e-04
I0514 02:38:57.428890 22485033404224 run_lib.py:167] step: 387200, eval_loss: 4.93413e-04
I0514 02:39:21.282455 22485033404224 run_lib.py:146] step: 387250, training_loss: 6.48299e-04
I0514 02:39:44.800373 22485033404224 run_lib.py:146] step: 387300, training_loss: 5.38753e-04
I0514 02:39:44.960319 22485033404224 run_lib.py:167] step: 387300, eval_loss: 4.35809e-04
I0514 02:40:08.746663 22485033404224 run_lib.py:146] step: 387350, training_loss: 7.24253e-04
I0514 02:40:32.562389 22485033404224 run_lib.py:146] step: 387400, training_loss: 6.68988e-04
I0514 02:40:32.721873 22485033404224 run_lib.py:167] step: 387400, eval_loss: 5.49068e-04
I0514 02:40:56.235776 22485033404224 run_lib.py:146] step: 387450, training_loss: 5.19160e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:41:20.164813 22485033404224 run_lib.py:146] step: 387500, training_loss: 5.89468e-04
I0514 02:41:20.325690 22485033404224 run_lib.py:167] step: 387500, eval_loss: 6.04706e-04
I0514 02:41:44.189430 22485033404224 run_lib.py:146] step: 387550, training_loss: 5.80293e-04
I0514 02:42:07.726422 22485033404224 run_lib.py:146] step: 387600, training_loss: 5.69231e-04
I0514 02:42:07.885932 22485033404224 run_lib.py:167] step: 387600, eval_loss: 6.00561e-04
I0514 02:42:31.715841 22485033404224 run_lib.py:146] step: 387650, training_loss: 6.22864e-04
I0514 02:42:55.615712 22485033404224 run_lib.py:146] step: 387700, training_loss: 5.51401e-04
I0514 02:42:55.777016 22485033404224 run_lib.py:167] step: 387700, eval_loss: 6.99517e-04
I0514 02:43:19.373936 22485033404224 run_lib.py:146] step: 387750, training_loss: 5.51244e-04
I0514 02:43:42.969753 22485033404224 run_lib.py:146] step: 387800, training_loss: 5.58968e-04
I0514 02:43:43.130717 22485033404224 run_lib.py:167] step: 387800, eval_loss: 4.13759e-04
I0514 02:44:07.379671 22485033404224 run_lib.py:146] step: 387850, training_loss: 5.91145e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:44:31.042446 22485033404224 run_lib.py:146] step: 387900, training_loss: 6.75347e-04
I0514 02:44:31.204699 22485033404224 run_lib.py:167] step: 387900, eval_loss: 6.84480e-04
I0514 02:44:54.830985 22485033404224 run_lib.py:146] step: 387950, training_loss: 6.49540e-04
I0514 02:45:18.844748 22485033404224 run_lib.py:146] step: 388000, training_loss: 7.94280e-04
I0514 02:45:19.004710 22485033404224 run_lib.py:167] step: 388000, eval_loss: 6.66134e-04
I0514 02:45:43.037442 22485033404224 run_lib.py:146] step: 388050, training_loss: 6.95733e-04
I0514 02:46:06.624934 22485033404224 run_lib.py:146] step: 388100, training_loss: 5.89448e-04
I0514 02:46:06.786209 22485033404224 run_lib.py:167] step: 388100, eval_loss: 8.38410e-04
I0514 02:46:30.757395 22485033404224 run_lib.py:146] step: 388150, training_loss: 7.74582e-04
I0514 02:46:54.797732 22485033404224 run_lib.py:146] step: 388200, training_loss: 5.81173e-04
I0514 02:46:54.958283 22485033404224 run_lib.py:167] step: 388200, eval_loss: 6.74794e-04
I0514 02:47:18.556020 22485033404224 run_lib.py:146] step: 388250, training_loss: 7.49364e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:47:42.714392 22485033404224 run_lib.py:146] step: 388300, training_loss: 5.66709e-04
I0514 02:47:42.888107 22485033404224 run_lib.py:167] step: 388300, eval_loss: 7.32688e-04
I0514 02:48:06.835651 22485033404224 run_lib.py:146] step: 388350, training_loss: 6.81415e-04
I0514 02:48:30.422132 22485033404224 run_lib.py:146] step: 388400, training_loss: 8.34738e-04
I0514 02:48:30.581371 22485033404224 run_lib.py:167] step: 388400, eval_loss: 6.89944e-04
I0514 02:48:54.440132 22485033404224 run_lib.py:146] step: 388450, training_loss: 8.17622e-04
I0514 02:49:18.360806 22485033404224 run_lib.py:146] step: 388500, training_loss: 5.13402e-04
I0514 02:49:18.521723 22485033404224 run_lib.py:167] step: 388500, eval_loss: 6.92517e-04
I0514 02:49:42.099556 22485033404224 run_lib.py:146] step: 388550, training_loss: 6.60867e-04
I0514 02:50:05.942667 22485033404224 run_lib.py:146] step: 388600, training_loss: 5.69821e-04
I0514 02:50:06.103429 22485033404224 run_lib.py:167] step: 388600, eval_loss: 6.48897e-04
I0514 02:50:29.911901 22485033404224 run_lib.py:146] step: 388650, training_loss: 6.08565e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:50:53.502464 22485033404224 run_lib.py:146] step: 388700, training_loss: 5.10062e-04
I0514 02:50:53.673113 22485033404224 run_lib.py:167] step: 388700, eval_loss: 4.84565e-04
I0514 02:51:17.191615 22485033404224 run_lib.py:146] step: 388750, training_loss: 6.99823e-04
I0514 02:51:41.044340 22485033404224 run_lib.py:146] step: 388800, training_loss: 7.47091e-04
I0514 02:51:41.204720 22485033404224 run_lib.py:167] step: 388800, eval_loss: 4.98156e-04
I0514 02:52:05.027244 22485033404224 run_lib.py:146] step: 388850, training_loss: 5.65044e-04
I0514 02:52:28.534530 22485033404224 run_lib.py:146] step: 388900, training_loss: 7.72339e-04
I0514 02:52:28.693887 22485033404224 run_lib.py:167] step: 388900, eval_loss: 5.55079e-04
I0514 02:52:52.494300 22485033404224 run_lib.py:146] step: 388950, training_loss: 6.54825e-04
I0514 02:53:16.307035 22485033404224 run_lib.py:146] step: 389000, training_loss: 6.81421e-04
I0514 02:53:16.467342 22485033404224 run_lib.py:167] step: 389000, eval_loss: 6.21465e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:53:40.046808 22485033404224 run_lib.py:146] step: 389050, training_loss: 6.83183e-04
I0514 02:54:03.904417 22485033404224 run_lib.py:146] step: 389100, training_loss: 6.41054e-04
I0514 02:54:04.066278 22485033404224 run_lib.py:167] step: 389100, eval_loss: 4.68702e-04
I0514 02:54:27.889035 22485033404224 run_lib.py:146] step: 389150, training_loss: 6.27284e-04
I0514 02:54:51.412012 22485033404224 run_lib.py:146] step: 389200, training_loss: 6.04180e-04
I0514 02:54:51.570339 22485033404224 run_lib.py:167] step: 389200, eval_loss: 5.07661e-04
I0514 02:55:15.409811 22485033404224 run_lib.py:146] step: 389250, training_loss: 6.87097e-04
I0514 02:55:39.239974 22485033404224 run_lib.py:146] step: 389300, training_loss: 6.49378e-04
I0514 02:55:39.398653 22485033404224 run_lib.py:167] step: 389300, eval_loss: 6.45563e-04
I0514 02:56:02.902236 22485033404224 run_lib.py:146] step: 389350, training_loss: 6.47524e-04
I0514 02:56:26.709069 22485033404224 run_lib.py:146] step: 389400, training_loss: 7.11525e-04
I0514 02:56:26.868180 22485033404224 run_lib.py:167] step: 389400, eval_loss: 5.32472e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:56:50.819076 22485033404224 run_lib.py:146] step: 389450, training_loss: 5.70454e-04
I0514 02:57:14.334197 22485033404224 run_lib.py:146] step: 389500, training_loss: 6.53321e-04
I0514 02:57:14.494774 22485033404224 run_lib.py:167] step: 389500, eval_loss: 4.65200e-04
I0514 02:57:38.022071 22485033404224 run_lib.py:146] step: 389550, training_loss: 6.27786e-04
I0514 02:58:02.178622 22485033404224 run_lib.py:146] step: 389600, training_loss: 4.85961e-04
I0514 02:58:02.338906 22485033404224 run_lib.py:167] step: 389600, eval_loss: 5.40181e-04
I0514 02:58:25.862369 22485033404224 run_lib.py:146] step: 389650, training_loss: 6.66064e-04
I0514 02:58:49.388624 22485033404224 run_lib.py:146] step: 389700, training_loss: 6.01770e-04
I0514 02:58:49.548195 22485033404224 run_lib.py:167] step: 389700, eval_loss: 8.20649e-04
I0514 02:59:13.361091 22485033404224 run_lib.py:146] step: 389750, training_loss: 6.25447e-04
I0514 02:59:37.193167 22485033404224 run_lib.py:146] step: 389800, training_loss: 7.32217e-04
I0514 02:59:37.353693 22485033404224 run_lib.py:167] step: 389800, eval_loss: 5.72136e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:00:00.960886 22485033404224 run_lib.py:146] step: 389850, training_loss: 6.16116e-04
I0514 03:00:24.896310 22485033404224 run_lib.py:146] step: 389900, training_loss: 5.75538e-04
I0514 03:00:25.091006 22485033404224 run_lib.py:167] step: 389900, eval_loss: 5.82576e-04
I0514 03:00:49.024402 22485033404224 run_lib.py:146] step: 389950, training_loss: 6.49345e-04
I0514 03:01:12.625620 22485033404224 run_lib.py:146] step: 390000, training_loss: 7.17185e-04
I0514 03:01:14.593465 22485033404224 run_lib.py:167] step: 390000, eval_loss: 5.25966e-04
I0514 03:01:40.038195 22485033404224 run_lib.py:146] step: 390050, training_loss: 7.41906e-04
I0514 03:02:03.934094 22485033404224 run_lib.py:146] step: 390100, training_loss: 6.91537e-04
I0514 03:02:04.093117 22485033404224 run_lib.py:167] step: 390100, eval_loss: 7.32903e-04
I0514 03:02:27.681115 22485033404224 run_lib.py:146] step: 390150, training_loss: 6.44492e-04
I0514 03:02:51.573997 22485033404224 run_lib.py:146] step: 390200, training_loss: 7.27785e-04
I0514 03:02:51.734006 22485033404224 run_lib.py:167] step: 390200, eval_loss: 5.46900e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:03:15.848228 22485033404224 run_lib.py:146] step: 390250, training_loss: 7.42754e-04
I0514 03:03:39.404483 22485033404224 run_lib.py:146] step: 390300, training_loss: 5.21593e-04
I0514 03:03:39.567174 22485033404224 run_lib.py:167] step: 390300, eval_loss: 5.62222e-04
I0514 03:04:03.507018 22485033404224 run_lib.py:146] step: 390350, training_loss: 8.30786e-04
I0514 03:04:27.534263 22485033404224 run_lib.py:146] step: 390400, training_loss: 5.19961e-04
I0514 03:04:27.694853 22485033404224 run_lib.py:167] step: 390400, eval_loss: 5.78011e-04
I0514 03:04:51.297640 22485033404224 run_lib.py:146] step: 390450, training_loss: 4.84067e-04
I0514 03:05:15.184385 22485033404224 run_lib.py:146] step: 390500, training_loss: 8.33332e-04
I0514 03:05:15.344775 22485033404224 run_lib.py:167] step: 390500, eval_loss: 6.47639e-04
I0514 03:05:38.937580 22485033404224 run_lib.py:146] step: 390550, training_loss: 6.57820e-04
I0514 03:06:02.864305 22485033404224 run_lib.py:146] step: 390600, training_loss: 5.30193e-04
I0514 03:06:03.024642 22485033404224 run_lib.py:167] step: 390600, eval_loss: 6.46306e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:06:27.209813 22485033404224 run_lib.py:146] step: 390650, training_loss: 7.00317e-04
I0514 03:06:50.862775 22485033404224 run_lib.py:146] step: 390700, training_loss: 5.01819e-04
I0514 03:06:51.025108 22485033404224 run_lib.py:167] step: 390700, eval_loss: 4.85721e-04
I0514 03:07:14.994987 22485033404224 run_lib.py:146] step: 390750, training_loss: 6.84935e-04
I0514 03:07:38.933904 22485033404224 run_lib.py:146] step: 390800, training_loss: 6.58373e-04
I0514 03:07:39.093160 22485033404224 run_lib.py:167] step: 390800, eval_loss: 6.64166e-04
I0514 03:08:02.609862 22485033404224 run_lib.py:146] step: 390850, training_loss: 7.28904e-04
I0514 03:08:26.421521 22485033404224 run_lib.py:146] step: 390900, training_loss: 5.37142e-04
I0514 03:08:26.581259 22485033404224 run_lib.py:167] step: 390900, eval_loss: 5.14051e-04
I0514 03:08:50.091345 22485033404224 run_lib.py:146] step: 390950, training_loss: 5.39111e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:09:13.966746 22485033404224 run_lib.py:146] step: 391000, training_loss: 4.78147e-04
I0514 03:09:14.128041 22485033404224 run_lib.py:167] step: 391000, eval_loss: 5.78117e-04
I0514 03:09:37.968481 22485033404224 run_lib.py:146] step: 391050, training_loss: 6.31378e-04
I0514 03:10:01.477507 22485033404224 run_lib.py:146] step: 391100, training_loss: 6.70210e-04
I0514 03:10:01.636872 22485033404224 run_lib.py:167] step: 391100, eval_loss: 3.56996e-04
I0514 03:10:25.494709 22485033404224 run_lib.py:146] step: 391150, training_loss: 7.83871e-04
I0514 03:10:49.292487 22485033404224 run_lib.py:146] step: 391200, training_loss: 6.29085e-04
I0514 03:10:49.452629 22485033404224 run_lib.py:167] step: 391200, eval_loss: 5.01828e-04
I0514 03:11:12.965998 22485033404224 run_lib.py:146] step: 391250, training_loss: 5.84733e-04
I0514 03:11:36.789164 22485033404224 run_lib.py:146] step: 391300, training_loss: 6.70054e-04
I0514 03:11:36.948303 22485033404224 run_lib.py:167] step: 391300, eval_loss: 6.98257e-04
I0514 03:12:00.776850 22485033404224 run_lib.py:146] step: 391350, training_loss: 4.59892e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:12:24.399523 22485033404224 run_lib.py:146] step: 391400, training_loss: 6.05866e-04
I0514 03:12:24.561412 22485033404224 run_lib.py:167] step: 391400, eval_loss: 4.23879e-04
I0514 03:12:48.454662 22485033404224 run_lib.py:146] step: 391450, training_loss: 7.06696e-04
I0514 03:13:12.006466 22485033404224 run_lib.py:146] step: 391500, training_loss: 5.76716e-04
I0514 03:13:12.198103 22485033404224 run_lib.py:167] step: 391500, eval_loss: 7.48324e-04
I0514 03:13:36.062143 22485033404224 run_lib.py:146] step: 391550, training_loss: 5.06619e-04
I0514 03:13:59.888872 22485033404224 run_lib.py:146] step: 391600, training_loss: 6.94758e-04
I0514 03:14:00.047535 22485033404224 run_lib.py:167] step: 391600, eval_loss: 7.48341e-04
I0514 03:14:23.584665 22485033404224 run_lib.py:146] step: 391650, training_loss: 7.71204e-04
I0514 03:14:47.422090 22485033404224 run_lib.py:146] step: 391700, training_loss: 4.91908e-04
I0514 03:14:47.581995 22485033404224 run_lib.py:167] step: 391700, eval_loss: 6.28762e-04
I0514 03:15:11.416201 22485033404224 run_lib.py:146] step: 391750, training_loss: 5.31738e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:15:35.026350 22485033404224 run_lib.py:146] step: 391800, training_loss: 6.83755e-04
I0514 03:15:35.186917 22485033404224 run_lib.py:167] step: 391800, eval_loss: 6.71126e-04
I0514 03:15:59.098277 22485033404224 run_lib.py:146] step: 391850, training_loss: 9.46414e-04
I0514 03:16:22.642323 22485033404224 run_lib.py:146] step: 391900, training_loss: 5.44179e-04
I0514 03:16:22.802768 22485033404224 run_lib.py:167] step: 391900, eval_loss: 4.37468e-04
I0514 03:16:46.658680 22485033404224 run_lib.py:146] step: 391950, training_loss: 6.54797e-04
I0514 03:17:10.500124 22485033404224 run_lib.py:146] step: 392000, training_loss: 4.04915e-04
I0514 03:17:10.659631 22485033404224 run_lib.py:167] step: 392000, eval_loss: 6.52327e-04
I0514 03:17:34.222253 22485033404224 run_lib.py:146] step: 392050, training_loss: 6.62375e-04
I0514 03:17:58.116914 22485033404224 run_lib.py:146] step: 392100, training_loss: 4.98564e-04
I0514 03:17:58.277244 22485033404224 run_lib.py:167] step: 392100, eval_loss: 6.26385e-04
I0514 03:18:22.191223 22485033404224 run_lib.py:146] step: 392150, training_loss: 5.59838e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:18:45.863731 22485033404224 run_lib.py:146] step: 392200, training_loss: 6.07605e-04
I0514 03:18:46.026787 22485033404224 run_lib.py:167] step: 392200, eval_loss: 7.26713e-04
I0514 03:19:09.936462 22485033404224 run_lib.py:146] step: 392250, training_loss: 6.22032e-04
I0514 03:19:33.547214 22485033404224 run_lib.py:146] step: 392300, training_loss: 7.42637e-04
I0514 03:19:33.707543 22485033404224 run_lib.py:167] step: 392300, eval_loss: 6.25666e-04
I0514 03:19:57.748941 22485033404224 run_lib.py:146] step: 392350, training_loss: 7.25570e-04
I0514 03:20:21.636050 22485033404224 run_lib.py:146] step: 392400, training_loss: 5.16899e-04
I0514 03:20:21.795579 22485033404224 run_lib.py:167] step: 392400, eval_loss: 5.83935e-04
I0514 03:20:45.396062 22485033404224 run_lib.py:146] step: 392450, training_loss: 5.10904e-04
I0514 03:21:09.402448 22485033404224 run_lib.py:146] step: 392500, training_loss: 4.82607e-04
I0514 03:21:09.562553 22485033404224 run_lib.py:167] step: 392500, eval_loss: 6.13532e-04
I0514 03:21:33.442470 22485033404224 run_lib.py:146] step: 392550, training_loss: 7.71804e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:21:57.268556 22485033404224 run_lib.py:146] step: 392600, training_loss: 5.12322e-04
I0514 03:21:57.431985 22485033404224 run_lib.py:167] step: 392600, eval_loss: 5.69567e-04
I0514 03:22:21.695099 22485033404224 run_lib.py:146] step: 392650, training_loss: 5.72536e-04
I0514 03:22:45.315571 22485033404224 run_lib.py:146] step: 392700, training_loss: 6.02139e-04
I0514 03:22:45.476756 22485033404224 run_lib.py:167] step: 392700, eval_loss: 5.62635e-04
I0514 03:23:09.393732 22485033404224 run_lib.py:146] step: 392750, training_loss: 6.15180e-04
I0514 03:23:33.311150 22485033404224 run_lib.py:146] step: 392800, training_loss: 7.57156e-04
I0514 03:23:33.471796 22485033404224 run_lib.py:167] step: 392800, eval_loss: 4.80653e-04
I0514 03:23:57.073325 22485033404224 run_lib.py:146] step: 392850, training_loss: 5.43932e-04
I0514 03:24:20.963449 22485033404224 run_lib.py:146] step: 392900, training_loss: 6.26699e-04
I0514 03:24:21.122804 22485033404224 run_lib.py:167] step: 392900, eval_loss: 5.45095e-04
I0514 03:24:45.018663 22485033404224 run_lib.py:146] step: 392950, training_loss: 6.30292e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:25:08.664854 22485033404224 run_lib.py:146] step: 393000, training_loss: 7.41109e-04
I0514 03:25:08.825862 22485033404224 run_lib.py:167] step: 393000, eval_loss: 7.90993e-04
I0514 03:25:32.703639 22485033404224 run_lib.py:146] step: 393050, training_loss: 4.98156e-04
I0514 03:25:56.527223 22485033404224 run_lib.py:146] step: 393100, training_loss: 5.56194e-04
I0514 03:25:56.685747 22485033404224 run_lib.py:167] step: 393100, eval_loss: 5.36771e-04
I0514 03:26:20.553473 22485033404224 run_lib.py:146] step: 393150, training_loss: 7.38379e-04
I0514 03:26:44.377357 22485033404224 run_lib.py:146] step: 393200, training_loss: 6.29496e-04
I0514 03:26:44.546476 22485033404224 run_lib.py:167] step: 393200, eval_loss: 5.59865e-04
I0514 03:27:08.061526 22485033404224 run_lib.py:146] step: 393250, training_loss: 5.72900e-04
I0514 03:27:31.882128 22485033404224 run_lib.py:146] step: 393300, training_loss: 5.99690e-04
I0514 03:27:32.040395 22485033404224 run_lib.py:167] step: 393300, eval_loss: 6.99719e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:27:55.903596 22485033404224 run_lib.py:146] step: 393350, training_loss: 5.05696e-04
I0514 03:28:19.436563 22485033404224 run_lib.py:146] step: 393400, training_loss: 6.64706e-04
I0514 03:28:19.596848 22485033404224 run_lib.py:167] step: 393400, eval_loss: 5.64345e-04
I0514 03:28:43.445561 22485033404224 run_lib.py:146] step: 393450, training_loss: 6.44238e-04
I0514 03:29:07.303987 22485033404224 run_lib.py:146] step: 393500, training_loss: 5.80011e-04
I0514 03:29:07.463249 22485033404224 run_lib.py:167] step: 393500, eval_loss: 5.07237e-04
I0514 03:29:30.972286 22485033404224 run_lib.py:146] step: 393550, training_loss: 6.89818e-04
I0514 03:29:54.792876 22485033404224 run_lib.py:146] step: 393600, training_loss: 6.78126e-04
I0514 03:29:54.952535 22485033404224 run_lib.py:167] step: 393600, eval_loss: 5.02661e-04
I0514 03:30:18.474239 22485033404224 run_lib.py:146] step: 393650, training_loss: 5.82631e-04
I0514 03:30:42.313737 22485033404224 run_lib.py:146] step: 393700, training_loss: 6.22568e-04
I0514 03:30:42.473115 22485033404224 run_lib.py:167] step: 393700, eval_loss: 4.56109e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:31:06.415286 22485033404224 run_lib.py:146] step: 393750, training_loss: 4.99498e-04
I0514 03:31:29.945369 22485033404224 run_lib.py:146] step: 393800, training_loss: 6.14261e-04
I0514 03:31:30.106732 22485033404224 run_lib.py:167] step: 393800, eval_loss: 7.58133e-04
I0514 03:31:53.927894 22485033404224 run_lib.py:146] step: 393850, training_loss: 6.35751e-04
I0514 03:32:17.470098 22485033404224 run_lib.py:146] step: 393900, training_loss: 6.25481e-04
I0514 03:32:17.630055 22485033404224 run_lib.py:167] step: 393900, eval_loss: 4.94173e-04
I0514 03:32:41.450319 22485033404224 run_lib.py:146] step: 393950, training_loss: 6.91182e-04
I0514 03:33:05.299892 22485033404224 run_lib.py:146] step: 394000, training_loss: 5.85065e-04
I0514 03:33:05.458677 22485033404224 run_lib.py:167] step: 394000, eval_loss: 6.36297e-04
I0514 03:33:28.996919 22485033404224 run_lib.py:146] step: 394050, training_loss: 5.67558e-04
I0514 03:33:52.834199 22485033404224 run_lib.py:146] step: 394100, training_loss: 6.99127e-04
I0514 03:33:52.994501 22485033404224 run_lib.py:167] step: 394100, eval_loss: 7.49709e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:34:16.932495 22485033404224 run_lib.py:146] step: 394150, training_loss: 6.31849e-04
I0514 03:34:40.448775 22485033404224 run_lib.py:146] step: 394200, training_loss: 6.78116e-04
I0514 03:34:40.610093 22485033404224 run_lib.py:167] step: 394200, eval_loss: 8.07325e-04
I0514 03:35:04.472310 22485033404224 run_lib.py:146] step: 394250, training_loss: 6.18911e-04
I0514 03:35:28.287704 22485033404224 run_lib.py:146] step: 394300, training_loss: 4.44695e-04
I0514 03:35:28.447220 22485033404224 run_lib.py:167] step: 394300, eval_loss: 7.71508e-04
I0514 03:35:52.041600 22485033404224 run_lib.py:146] step: 394350, training_loss: 4.89391e-04
I0514 03:36:15.958432 22485033404224 run_lib.py:146] step: 394400, training_loss: 6.18436e-04
I0514 03:36:16.118834 22485033404224 run_lib.py:167] step: 394400, eval_loss: 4.17916e-04
I0514 03:36:39.717597 22485033404224 run_lib.py:146] step: 394450, training_loss: 5.89044e-04
I0514 03:37:03.548561 22485033404224 run_lib.py:146] step: 394500, training_loss: 5.74426e-04
I0514 03:37:03.709335 22485033404224 run_lib.py:167] step: 394500, eval_loss: 6.91912e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:37:27.846372 22485033404224 run_lib.py:146] step: 394550, training_loss: 6.56945e-04
I0514 03:37:51.462454 22485033404224 run_lib.py:146] step: 394600, training_loss: 6.21852e-04
I0514 03:37:51.624515 22485033404224 run_lib.py:167] step: 394600, eval_loss: 6.67640e-04
I0514 03:38:15.560013 22485033404224 run_lib.py:146] step: 394650, training_loss: 6.46712e-04
I0514 03:38:39.597930 22485033404224 run_lib.py:146] step: 394700, training_loss: 5.37370e-04
I0514 03:38:39.758129 22485033404224 run_lib.py:167] step: 394700, eval_loss: 6.19332e-04
I0514 03:39:03.362275 22485033404224 run_lib.py:146] step: 394750, training_loss: 6.39402e-04
I0514 03:39:27.285620 22485033404224 run_lib.py:146] step: 394800, training_loss: 7.54649e-04
I0514 03:39:27.445464 22485033404224 run_lib.py:167] step: 394800, eval_loss: 5.61533e-04
I0514 03:39:51.063357 22485033404224 run_lib.py:146] step: 394850, training_loss: 4.65833e-04
I0514 03:40:15.086135 22485033404224 run_lib.py:146] step: 394900, training_loss: 7.15006e-04
I0514 03:40:15.171686 22485033404224 run_lib.py:167] step: 394900, eval_loss: 4.56890e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:40:39.258770 22485033404224 run_lib.py:146] step: 394950, training_loss: 6.15372e-04
I0514 03:41:02.842281 22485033404224 run_lib.py:146] step: 395000, training_loss: 7.09686e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:41:03.220488 22485033404224 run_lib.py:167] step: 395000, eval_loss: 6.31152e-04
I0514 03:41:27.180754 22485033404224 run_lib.py:146] step: 395050, training_loss: 7.89584e-04
I0514 03:41:51.266818 22485033404224 run_lib.py:146] step: 395100, training_loss: 6.56586e-04
I0514 03:41:51.427021 22485033404224 run_lib.py:167] step: 395100, eval_loss: 5.95573e-04
I0514 03:42:14.999202 22485033404224 run_lib.py:146] step: 395150, training_loss: 7.62062e-04
I0514 03:42:38.951426 22485033404224 run_lib.py:146] step: 395200, training_loss: 6.61401e-04
I0514 03:42:39.110784 22485033404224 run_lib.py:167] step: 395200, eval_loss: 6.80762e-04
I0514 03:43:03.126216 22485033404224 run_lib.py:146] step: 395250, training_loss: 4.91007e-04
I0514 03:43:26.558388 22485033404224 run_lib.py:146] step: 395300, training_loss: 6.95361e-04
I0514 03:43:26.718273 22485033404224 run_lib.py:167] step: 395300, eval_loss: 6.77307e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:43:50.787205 22485033404224 run_lib.py:146] step: 395350, training_loss: 6.03889e-04
I0514 03:44:14.314013 22485033404224 run_lib.py:146] step: 395400, training_loss: 5.51868e-04
I0514 03:44:14.501833 22485033404224 run_lib.py:167] step: 395400, eval_loss: 4.93196e-04
I0514 03:44:38.339588 22485033404224 run_lib.py:146] step: 395450, training_loss: 5.57115e-04
I0514 03:45:02.168403 22485033404224 run_lib.py:146] step: 395500, training_loss: 6.89805e-04
I0514 03:45:02.327859 22485033404224 run_lib.py:167] step: 395500, eval_loss: 5.70942e-04
I0514 03:45:25.853676 22485033404224 run_lib.py:146] step: 395550, training_loss: 7.16636e-04
I0514 03:45:49.682964 22485033404224 run_lib.py:146] step: 395600, training_loss: 5.07957e-04
I0514 03:45:49.843070 22485033404224 run_lib.py:167] step: 395600, eval_loss: 6.54214e-04
I0514 03:46:13.374454 22485033404224 run_lib.py:146] step: 395650, training_loss: 6.68332e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:46:37.274189 22485033404224 run_lib.py:146] step: 395700, training_loss: 7.11000e-04
I0514 03:46:37.435947 22485033404224 run_lib.py:167] step: 395700, eval_loss: 7.07466e-04
I0514 03:47:01.280619 22485033404224 run_lib.py:146] step: 395750, training_loss: 4.89253e-04
I0514 03:47:24.789415 22485033404224 run_lib.py:146] step: 395800, training_loss: 6.38920e-04
I0514 03:47:24.949569 22485033404224 run_lib.py:167] step: 395800, eval_loss: 4.90828e-04
I0514 03:47:48.781002 22485033404224 run_lib.py:146] step: 395850, training_loss: 7.03948e-04
I0514 03:48:12.581435 22485033404224 run_lib.py:146] step: 395900, training_loss: 4.31602e-04
I0514 03:48:12.741930 22485033404224 run_lib.py:167] step: 395900, eval_loss: 8.22738e-04
I0514 03:48:36.246989 22485033404224 run_lib.py:146] step: 395950, training_loss: 6.25951e-04
I0514 03:49:00.053930 22485033404224 run_lib.py:146] step: 396000, training_loss: 7.12332e-04
I0514 03:49:00.213252 22485033404224 run_lib.py:167] step: 396000, eval_loss: 6.53724e-04
I0514 03:49:24.015173 22485033404224 run_lib.py:146] step: 396050, training_loss: 6.94977e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:49:47.667637 22485033404224 run_lib.py:146] step: 396100, training_loss: 5.80826e-04
I0514 03:49:47.829319 22485033404224 run_lib.py:167] step: 396100, eval_loss: 5.67124e-04
I0514 03:50:11.696979 22485033404224 run_lib.py:146] step: 396150, training_loss: 6.11004e-04
I0514 03:50:35.205212 22485033404224 run_lib.py:146] step: 396200, training_loss: 8.28413e-04
I0514 03:50:35.365958 22485033404224 run_lib.py:167] step: 396200, eval_loss: 5.09622e-04
I0514 03:50:59.194819 22485033404224 run_lib.py:146] step: 396250, training_loss: 6.82807e-04
I0514 03:51:23.203345 22485033404224 run_lib.py:146] step: 396300, training_loss: 6.15175e-04
I0514 03:51:23.363715 22485033404224 run_lib.py:167] step: 396300, eval_loss: 4.47946e-04
I0514 03:51:46.859485 22485033404224 run_lib.py:146] step: 396350, training_loss: 7.96702e-04
I0514 03:52:10.674005 22485033404224 run_lib.py:146] step: 396400, training_loss: 6.36504e-04
I0514 03:52:10.832923 22485033404224 run_lib.py:167] step: 396400, eval_loss: 7.23388e-04
I0514 03:52:34.655829 22485033404224 run_lib.py:146] step: 396450, training_loss: 5.82760e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:52:58.267033 22485033404224 run_lib.py:146] step: 396500, training_loss: 7.39198e-04
I0514 03:52:58.428342 22485033404224 run_lib.py:167] step: 396500, eval_loss: 8.55290e-04
I0514 03:53:22.296306 22485033404224 run_lib.py:146] step: 396550, training_loss: 6.10751e-04
I0514 03:53:45.845499 22485033404224 run_lib.py:146] step: 396600, training_loss: 6.60005e-04
I0514 03:53:46.006437 22485033404224 run_lib.py:167] step: 396600, eval_loss: 4.22596e-04
I0514 03:54:09.958788 22485033404224 run_lib.py:146] step: 396650, training_loss: 5.38268e-04
I0514 03:54:33.873324 22485033404224 run_lib.py:146] step: 396700, training_loss: 5.43094e-04
I0514 03:54:34.034242 22485033404224 run_lib.py:167] step: 396700, eval_loss: 5.74472e-04
I0514 03:54:57.640841 22485033404224 run_lib.py:146] step: 396750, training_loss: 7.30539e-04
I0514 03:55:21.667094 22485033404224 run_lib.py:146] step: 396800, training_loss: 5.11893e-04
I0514 03:55:21.827675 22485033404224 run_lib.py:167] step: 396800, eval_loss: 6.54695e-04
I0514 03:55:45.730009 22485033404224 run_lib.py:146] step: 396850, training_loss: 5.82303e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:56:09.519034 22485033404224 run_lib.py:146] step: 396900, training_loss: 6.06637e-04
I0514 03:56:09.682435 22485033404224 run_lib.py:167] step: 396900, eval_loss: 5.41865e-04
I0514 03:56:33.863795 22485033404224 run_lib.py:146] step: 396950, training_loss: 6.01417e-04
I0514 03:56:58.055029 22485033404224 run_lib.py:146] step: 397000, training_loss: 6.03772e-04
I0514 03:56:58.215152 22485033404224 run_lib.py:167] step: 397000, eval_loss: 6.15662e-04
I0514 03:57:21.953260 22485033404224 run_lib.py:146] step: 397050, training_loss: 7.04232e-04
I0514 03:57:46.052959 22485033404224 run_lib.py:146] step: 397100, training_loss: 5.85804e-04
I0514 03:57:46.214107 22485033404224 run_lib.py:167] step: 397100, eval_loss: 7.00512e-04
I0514 03:58:09.904666 22485033404224 run_lib.py:146] step: 397150, training_loss: 5.36704e-04
I0514 03:58:33.896790 22485033404224 run_lib.py:146] step: 397200, training_loss: 5.78997e-04
I0514 03:58:34.057204 22485033404224 run_lib.py:167] step: 397200, eval_loss: 5.36597e-04
I0514 03:58:57.995078 22485033404224 run_lib.py:146] step: 397250, training_loss: 6.23871e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:59:21.772331 22485033404224 run_lib.py:146] step: 397300, training_loss: 5.66923e-04
I0514 03:59:21.934512 22485033404224 run_lib.py:167] step: 397300, eval_loss: 7.35056e-04
I0514 03:59:45.968897 22485033404224 run_lib.py:146] step: 397350, training_loss: 4.76842e-04
I0514 04:00:09.597460 22485033404224 run_lib.py:146] step: 397400, training_loss: 7.04840e-04
I0514 04:00:09.758181 22485033404224 run_lib.py:167] step: 397400, eval_loss: 6.24198e-04
I0514 04:00:33.720503 22485033404224 run_lib.py:146] step: 397450, training_loss: 5.54309e-04
I0514 04:00:57.666507 22485033404224 run_lib.py:146] step: 397500, training_loss: 5.91251e-04
I0514 04:00:57.826320 22485033404224 run_lib.py:167] step: 397500, eval_loss: 6.12150e-04
I0514 04:01:21.376348 22485033404224 run_lib.py:146] step: 397550, training_loss: 6.97385e-04
I0514 04:01:45.223748 22485033404224 run_lib.py:146] step: 397600, training_loss: 6.31344e-04
I0514 04:01:45.382480 22485033404224 run_lib.py:167] step: 397600, eval_loss: 5.21129e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:02:09.277342 22485033404224 run_lib.py:146] step: 397650, training_loss: 4.19071e-04
I0514 04:02:32.800829 22485033404224 run_lib.py:146] step: 397700, training_loss: 6.55091e-04
I0514 04:02:32.962852 22485033404224 run_lib.py:167] step: 397700, eval_loss: 4.17573e-04
I0514 04:02:56.807757 22485033404224 run_lib.py:146] step: 397750, training_loss: 5.35113e-04
I0514 04:03:20.640574 22485033404224 run_lib.py:146] step: 397800, training_loss: 4.98344e-04
I0514 04:03:20.801319 22485033404224 run_lib.py:167] step: 397800, eval_loss: 5.96579e-04
I0514 04:03:44.306414 22485033404224 run_lib.py:146] step: 397850, training_loss: 5.42461e-04
I0514 04:04:08.117261 22485033404224 run_lib.py:146] step: 397900, training_loss: 5.69411e-04
I0514 04:04:08.276944 22485033404224 run_lib.py:167] step: 397900, eval_loss: 6.77908e-04
I0514 04:04:31.796776 22485033404224 run_lib.py:146] step: 397950, training_loss: 7.01150e-04
I0514 04:04:55.598436 22485033404224 run_lib.py:146] step: 398000, training_loss: 5.01484e-04
I0514 04:04:55.759047 22485033404224 run_lib.py:167] step: 398000, eval_loss: 7.74819e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:05:19.702629 22485033404224 run_lib.py:146] step: 398050, training_loss: 8.42800e-04
I0514 04:05:43.220565 22485033404224 run_lib.py:146] step: 398100, training_loss: 6.49516e-04
I0514 04:05:43.382224 22485033404224 run_lib.py:167] step: 398100, eval_loss: 4.75284e-04
I0514 04:06:07.257555 22485033404224 run_lib.py:146] step: 398150, training_loss: 6.14630e-04
I0514 04:06:30.789482 22485033404224 run_lib.py:146] step: 398200, training_loss: 6.25249e-04
I0514 04:06:30.950502 22485033404224 run_lib.py:167] step: 398200, eval_loss: 6.38778e-04
I0514 04:06:54.781934 22485033404224 run_lib.py:146] step: 398250, training_loss: 6.83604e-04
I0514 04:07:18.615972 22485033404224 run_lib.py:146] step: 398300, training_loss: 5.48128e-04
I0514 04:07:18.775006 22485033404224 run_lib.py:167] step: 398300, eval_loss: 4.83064e-04
I0514 04:07:42.300004 22485033404224 run_lib.py:146] step: 398350, training_loss: 6.89089e-04
I0514 04:08:06.135255 22485033404224 run_lib.py:146] step: 398400, training_loss: 6.65290e-04
I0514 04:08:06.295552 22485033404224 run_lib.py:167] step: 398400, eval_loss: 6.44789e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:08:30.257130 22485033404224 run_lib.py:146] step: 398450, training_loss: 6.77218e-04
I0514 04:08:53.791679 22485033404224 run_lib.py:146] step: 398500, training_loss: 6.80067e-04
I0514 04:08:53.952462 22485033404224 run_lib.py:167] step: 398500, eval_loss: 5.16102e-04
I0514 04:09:17.815264 22485033404224 run_lib.py:146] step: 398550, training_loss: 6.45408e-04
I0514 04:09:41.660819 22485033404224 run_lib.py:146] step: 398600, training_loss: 7.82883e-04
I0514 04:09:41.820630 22485033404224 run_lib.py:167] step: 398600, eval_loss: 6.19385e-04
I0514 04:10:05.346885 22485033404224 run_lib.py:146] step: 398650, training_loss: 6.17624e-04
I0514 04:10:29.192060 22485033404224 run_lib.py:146] step: 398700, training_loss: 7.24155e-04
I0514 04:10:29.352838 22485033404224 run_lib.py:167] step: 398700, eval_loss: 6.90932e-04
I0514 04:10:52.889443 22485033404224 run_lib.py:146] step: 398750, training_loss: 7.39669e-04
I0514 04:11:16.711549 22485033404224 run_lib.py:146] step: 398800, training_loss: 8.18070e-04
I0514 04:11:16.872040 22485033404224 run_lib.py:167] step: 398800, eval_loss: 7.02323e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:11:40.878829 22485033404224 run_lib.py:146] step: 398850, training_loss: 6.18610e-04
I0514 04:12:04.480017 22485033404224 run_lib.py:146] step: 398900, training_loss: 7.12205e-04
I0514 04:12:04.641672 22485033404224 run_lib.py:167] step: 398900, eval_loss: 6.55151e-04
I0514 04:12:28.579010 22485033404224 run_lib.py:146] step: 398950, training_loss: 8.38406e-04
I0514 04:12:52.458932 22485033404224 run_lib.py:146] step: 399000, training_loss: 6.04210e-04
I0514 04:12:52.619037 22485033404224 run_lib.py:167] step: 399000, eval_loss: 6.80508e-04
I0514 04:13:16.203381 22485033404224 run_lib.py:146] step: 399050, training_loss: 5.35500e-04
I0514 04:13:40.086185 22485033404224 run_lib.py:146] step: 399100, training_loss: 6.13185e-04
I0514 04:13:40.246288 22485033404224 run_lib.py:167] step: 399100, eval_loss: 6.82268e-04
I0514 04:14:03.805098 22485033404224 run_lib.py:146] step: 399150, training_loss: 5.20609e-04
I0514 04:14:27.688301 22485033404224 run_lib.py:146] step: 399200, training_loss: 7.05309e-04
I0514 04:14:27.849306 22485033404224 run_lib.py:167] step: 399200, eval_loss: 6.33054e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:14:52.032116 22485033404224 run_lib.py:146] step: 399250, training_loss: 4.89171e-04
I0514 04:15:15.682466 22485033404224 run_lib.py:146] step: 399300, training_loss: 6.18517e-04
I0514 04:15:15.844069 22485033404224 run_lib.py:167] step: 399300, eval_loss: 4.95111e-04
I0514 04:15:39.864896 22485033404224 run_lib.py:146] step: 399350, training_loss: 7.22717e-04
I0514 04:16:03.867204 22485033404224 run_lib.py:146] step: 399400, training_loss: 5.97799e-04
I0514 04:16:04.026772 22485033404224 run_lib.py:167] step: 399400, eval_loss: 5.87979e-04
I0514 04:16:27.624968 22485033404224 run_lib.py:146] step: 399450, training_loss: 6.68076e-04
I0514 04:16:51.598049 22485033404224 run_lib.py:146] step: 399500, training_loss: 6.70400e-04
I0514 04:16:51.759087 22485033404224 run_lib.py:167] step: 399500, eval_loss: 8.02479e-04
I0514 04:17:15.689281 22485033404224 run_lib.py:146] step: 399550, training_loss: 9.40763e-04
I0514 04:17:39.307622 22485033404224 run_lib.py:146] step: 399600, training_loss: 5.18569e-04
I0514 04:17:39.467763 22485033404224 run_lib.py:167] step: 399600, eval_loss: 6.04910e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:18:03.421962 22485033404224 run_lib.py:146] step: 399650, training_loss: 5.89428e-04
I0514 04:18:27.027476 22485033404224 run_lib.py:146] step: 399700, training_loss: 6.39925e-04
I0514 04:18:27.188683 22485033404224 run_lib.py:167] step: 399700, eval_loss: 5.39977e-04
I0514 04:18:51.134258 22485033404224 run_lib.py:146] step: 399750, training_loss: 5.62697e-04
I0514 04:19:14.963636 22485033404224 run_lib.py:146] step: 399800, training_loss: 6.81264e-04
I0514 04:19:15.122548 22485033404224 run_lib.py:167] step: 399800, eval_loss: 5.74804e-04
I0514 04:19:38.645487 22485033404224 run_lib.py:146] step: 399850, training_loss: 7.66506e-04
I0514 04:20:02.459315 22485033404224 run_lib.py:146] step: 399900, training_loss: 5.81139e-04
I0514 04:20:02.620527 22485033404224 run_lib.py:167] step: 399900, eval_loss: 4.57730e-04
I0514 04:20:26.450672 22485033404224 run_lib.py:146] step: 399950, training_loss: 5.90727e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:20:50.061368 22485033404224 run_lib.py:146] step: 400000, training_loss: 4.02620e-04
I0514 04:20:53.189774 22485033404224 run_lib.py:167] step: 400000, eval_loss: 6.27408e-04
I0514 04:21:19.352828 22485033404224 run_lib.py:146] step: 400050, training_loss: 6.29329e-04
I0514 04:21:42.862912 22485033404224 run_lib.py:146] step: 400100, training_loss: 5.51679e-04
I0514 04:21:43.021619 22485033404224 run_lib.py:167] step: 400100, eval_loss: 5.06622e-04
I0514 04:22:07.168342 22485033404224 run_lib.py:146] step: 400150, training_loss: 5.42889e-04
I0514 04:22:30.702120 22485033404224 run_lib.py:146] step: 400200, training_loss: 7.33573e-04
I0514 04:22:30.861218 22485033404224 run_lib.py:167] step: 400200, eval_loss: 5.47890e-04
I0514 04:22:54.391203 22485033404224 run_lib.py:146] step: 400250, training_loss: 5.70883e-04
I0514 04:23:18.218855 22485033404224 run_lib.py:146] step: 400300, training_loss: 9.13762e-04
I0514 04:23:18.377924 22485033404224 run_lib.py:167] step: 400300, eval_loss: 5.55931e-04
I0514 04:23:42.190671 22485033404224 run_lib.py:146] step: 400350, training_loss: 5.33564e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:24:05.808123 22485033404224 run_lib.py:146] step: 400400, training_loss: 5.86054e-04
I0514 04:24:05.970467 22485033404224 run_lib.py:167] step: 400400, eval_loss: 5.89746e-04
I0514 04:24:29.843498 22485033404224 run_lib.py:146] step: 400450, training_loss: 6.45450e-04
I0514 04:24:53.701214 22485033404224 run_lib.py:146] step: 400500, training_loss: 7.33933e-04
I0514 04:24:53.860203 22485033404224 run_lib.py:167] step: 400500, eval_loss: 7.66410e-04
I0514 04:25:17.392273 22485033404224 run_lib.py:146] step: 400550, training_loss: 6.08794e-04
I0514 04:25:41.204375 22485033404224 run_lib.py:146] step: 400600, training_loss: 5.54881e-04
I0514 04:25:41.363937 22485033404224 run_lib.py:167] step: 400600, eval_loss: 5.09248e-04
I0514 04:26:05.198580 22485033404224 run_lib.py:146] step: 400650, training_loss: 6.93143e-04
I0514 04:26:28.738677 22485033404224 run_lib.py:146] step: 400700, training_loss: 6.89298e-04
I0514 04:26:28.897997 22485033404224 run_lib.py:167] step: 400700, eval_loss: 3.67279e-04
I0514 04:26:52.714164 22485033404224 run_lib.py:146] step: 400750, training_loss: 5.34912e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:27:16.657733 22485033404224 run_lib.py:146] step: 400800, training_loss: 6.26253e-04
I0514 04:27:16.818252 22485033404224 run_lib.py:167] step: 400800, eval_loss: 7.80881e-04
I0514 04:27:40.340727 22485033404224 run_lib.py:146] step: 400850, training_loss: 7.01019e-04
I0514 04:28:03.851889 22485033404224 run_lib.py:146] step: 400900, training_loss: 6.24020e-04
I0514 04:28:04.011009 22485033404224 run_lib.py:167] step: 400900, eval_loss: 6.31218e-04
I0514 04:28:28.160467 22485033404224 run_lib.py:146] step: 400950, training_loss: 6.34741e-04
I0514 04:28:51.687811 22485033404224 run_lib.py:146] step: 401000, training_loss: 6.54086e-04
I0514 04:28:51.846737 22485033404224 run_lib.py:167] step: 401000, eval_loss: 6.71906e-04
I0514 04:29:15.373677 22485033404224 run_lib.py:146] step: 401050, training_loss: 6.63956e-04
I0514 04:29:39.314287 22485033404224 run_lib.py:146] step: 401100, training_loss: 6.34341e-04
I0514 04:29:39.475606 22485033404224 run_lib.py:167] step: 401100, eval_loss: 6.26390e-04
I0514 04:30:03.376535 22485033404224 run_lib.py:146] step: 401150, training_loss: 5.95146e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:30:27.041204 22485033404224 run_lib.py:146] step: 401200, training_loss: 6.11699e-04
I0514 04:30:27.203631 22485033404224 run_lib.py:167] step: 401200, eval_loss: 5.45101e-04
I0514 04:30:51.158634 22485033404224 run_lib.py:146] step: 401250, training_loss: 5.43143e-04
I0514 04:31:15.092244 22485033404224 run_lib.py:146] step: 401300, training_loss: 5.67886e-04
I0514 04:31:15.252545 22485033404224 run_lib.py:167] step: 401300, eval_loss: 6.63041e-04
I0514 04:31:38.833385 22485033404224 run_lib.py:146] step: 401350, training_loss: 5.97000e-04
I0514 04:32:02.716372 22485033404224 run_lib.py:146] step: 401400, training_loss: 5.62714e-04
I0514 04:32:02.876170 22485033404224 run_lib.py:167] step: 401400, eval_loss: 6.23452e-04
I0514 04:32:26.753676 22485033404224 run_lib.py:146] step: 401450, training_loss: 7.50186e-04
I0514 04:32:50.310838 22485033404224 run_lib.py:146] step: 401500, training_loss: 6.02566e-04
I0514 04:32:50.470518 22485033404224 run_lib.py:167] step: 401500, eval_loss: 7.37304e-04
I0514 04:33:14.348504 22485033404224 run_lib.py:146] step: 401550, training_loss: 4.51289e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:33:38.388835 22485033404224 run_lib.py:146] step: 401600, training_loss: 5.15144e-04
I0514 04:33:38.550043 22485033404224 run_lib.py:167] step: 401600, eval_loss: 7.74277e-04
I0514 04:34:02.143277 22485033404224 run_lib.py:146] step: 401650, training_loss: 4.31263e-04
I0514 04:34:25.728190 22485033404224 run_lib.py:146] step: 401700, training_loss: 7.13124e-04
I0514 04:34:25.903374 22485033404224 run_lib.py:167] step: 401700, eval_loss: 8.19116e-04
I0514 04:34:50.162037 22485033404224 run_lib.py:146] step: 401750, training_loss: 5.32028e-04
I0514 04:35:13.765239 22485033404224 run_lib.py:146] step: 401800, training_loss: 6.87702e-04
I0514 04:35:13.925386 22485033404224 run_lib.py:167] step: 401800, eval_loss: 4.61471e-04
I0514 04:35:37.494702 22485033404224 run_lib.py:146] step: 401850, training_loss: 6.85992e-04
I0514 04:36:01.403051 22485033404224 run_lib.py:146] step: 401900, training_loss: 6.25791e-04
I0514 04:36:01.563481 22485033404224 run_lib.py:167] step: 401900, eval_loss: 7.11827e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:36:25.528948 22485033404224 run_lib.py:146] step: 401950, training_loss: 6.94340e-04
I0514 04:36:49.056318 22485033404224 run_lib.py:146] step: 402000, training_loss: 6.91683e-04
I0514 04:36:49.217278 22485033404224 run_lib.py:167] step: 402000, eval_loss: 6.03319e-04
I0514 04:37:13.049147 22485033404224 run_lib.py:146] step: 402050, training_loss: 5.97042e-04
I0514 04:37:36.887825 22485033404224 run_lib.py:146] step: 402100, training_loss: 6.09359e-04
I0514 04:37:37.048668 22485033404224 run_lib.py:167] step: 402100, eval_loss: 4.95593e-04
I0514 04:38:00.546108 22485033404224 run_lib.py:146] step: 402150, training_loss: 6.17749e-04
I0514 04:38:24.339829 22485033404224 run_lib.py:146] step: 402200, training_loss: 5.64004e-04
I0514 04:38:24.498445 22485033404224 run_lib.py:167] step: 402200, eval_loss: 6.56762e-04
I0514 04:38:48.305216 22485033404224 run_lib.py:146] step: 402250, training_loss: 7.07445e-04
I0514 04:39:11.814601 22485033404224 run_lib.py:146] step: 402300, training_loss: 7.04624e-04
I0514 04:39:11.974251 22485033404224 run_lib.py:167] step: 402300, eval_loss: 6.46227e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:39:35.947446 22485033404224 run_lib.py:146] step: 402350, training_loss: 6.64203e-04
I0514 04:39:59.822273 22485033404224 run_lib.py:146] step: 402400, training_loss: 5.79355e-04
I0514 04:39:59.982270 22485033404224 run_lib.py:167] step: 402400, eval_loss: 6.78702e-04
I0514 04:40:23.500933 22485033404224 run_lib.py:146] step: 402450, training_loss: 5.36329e-04
I0514 04:40:47.010558 22485033404224 run_lib.py:146] step: 402500, training_loss: 7.88830e-04
I0514 04:40:47.169383 22485033404224 run_lib.py:167] step: 402500, eval_loss: 7.72931e-04
I0514 04:41:11.278178 22485033404224 run_lib.py:146] step: 402550, training_loss: 6.45801e-04
I0514 04:41:34.786580 22485033404224 run_lib.py:146] step: 402600, training_loss: 6.33009e-04
I0514 04:41:34.945781 22485033404224 run_lib.py:167] step: 402600, eval_loss: 6.99721e-04
I0514 04:41:58.531226 22485033404224 run_lib.py:146] step: 402650, training_loss: 6.97667e-04
I0514 04:42:22.348467 22485033404224 run_lib.py:146] step: 402700, training_loss: 4.95261e-04
I0514 04:42:22.506681 22485033404224 run_lib.py:167] step: 402700, eval_loss: 6.17723e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:42:46.384642 22485033404224 run_lib.py:146] step: 402750, training_loss: 5.80142e-04
I0514 04:43:09.911878 22485033404224 run_lib.py:146] step: 402800, training_loss: 6.55146e-04
I0514 04:43:09.996960 22485033404224 run_lib.py:167] step: 402800, eval_loss: 8.03596e-04
I0514 04:43:33.884091 22485033404224 run_lib.py:146] step: 402850, training_loss: 5.36384e-04
I0514 04:43:57.775942 22485033404224 run_lib.py:146] step: 402900, training_loss: 6.77877e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:43:58.143107 22485033404224 run_lib.py:167] step: 402900, eval_loss: 4.97986e-04
I0514 04:44:21.649420 22485033404224 run_lib.py:146] step: 402950, training_loss: 3.96326e-04
I0514 04:44:45.534801 22485033404224 run_lib.py:146] step: 403000, training_loss: 5.72516e-04
I0514 04:44:45.694759 22485033404224 run_lib.py:167] step: 403000, eval_loss: 7.18615e-04
I0514 04:45:09.521804 22485033404224 run_lib.py:146] step: 403050, training_loss: 6.02420e-04
I0514 04:45:33.040045 22485033404224 run_lib.py:146] step: 403100, training_loss: 6.58474e-04
I0514 04:45:33.200248 22485033404224 run_lib.py:167] step: 403100, eval_loss: 7.58026e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:45:57.128743 22485033404224 run_lib.py:146] step: 403150, training_loss: 6.86506e-04
I0514 04:46:20.987641 22485033404224 run_lib.py:146] step: 403200, training_loss: 5.74157e-04
I0514 04:46:21.147229 22485033404224 run_lib.py:167] step: 403200, eval_loss: 4.12234e-04
I0514 04:46:44.680896 22485033404224 run_lib.py:146] step: 403250, training_loss: 5.99352e-04
I0514 04:47:08.229882 22485033404224 run_lib.py:146] step: 403300, training_loss: 5.36553e-04
I0514 04:47:08.390078 22485033404224 run_lib.py:167] step: 403300, eval_loss: 6.02105e-04
I0514 04:47:32.597587 22485033404224 run_lib.py:146] step: 403350, training_loss: 7.11931e-04
I0514 04:47:56.205319 22485033404224 run_lib.py:146] step: 403400, training_loss: 8.49653e-04
I0514 04:47:56.367264 22485033404224 run_lib.py:167] step: 403400, eval_loss: 5.33765e-04
I0514 04:48:19.980194 22485033404224 run_lib.py:146] step: 403450, training_loss: 6.67384e-04
I0514 04:48:44.207752 22485033404224 run_lib.py:146] step: 403500, training_loss: 5.00246e-04
I0514 04:48:44.375587 22485033404224 run_lib.py:167] step: 403500, eval_loss: 5.05103e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:49:08.010168 22485033404224 run_lib.py:146] step: 403550, training_loss: 7.04963e-04
I0514 04:49:31.607525 22485033404224 run_lib.py:146] step: 403600, training_loss: 7.45567e-04
I0514 04:49:31.769957 22485033404224 run_lib.py:167] step: 403600, eval_loss: 4.99540e-04
I0514 04:49:55.799795 22485033404224 run_lib.py:146] step: 403650, training_loss: 6.16253e-04
I0514 04:50:19.836998 22485033404224 run_lib.py:146] step: 403700, training_loss: 6.43786e-04
I0514 04:50:19.998310 22485033404224 run_lib.py:167] step: 403700, eval_loss: 7.08107e-04
I0514 04:50:43.588011 22485033404224 run_lib.py:146] step: 403750, training_loss: 7.91272e-04
I0514 04:51:07.600017 22485033404224 run_lib.py:146] step: 403800, training_loss: 5.22236e-04
I0514 04:51:07.761661 22485033404224 run_lib.py:167] step: 403800, eval_loss: 6.04617e-04
I0514 04:51:31.766798 22485033404224 run_lib.py:146] step: 403850, training_loss: 6.46876e-04
I0514 04:51:55.339870 22485033404224 run_lib.py:146] step: 403900, training_loss: 5.70631e-04
I0514 04:51:55.500722 22485033404224 run_lib.py:167] step: 403900, eval_loss: 5.90762e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:52:19.515326 22485033404224 run_lib.py:146] step: 403950, training_loss: 5.39562e-04
I0514 04:52:43.457927 22485033404224 run_lib.py:146] step: 404000, training_loss: 5.35561e-04
I0514 04:52:43.619613 22485033404224 run_lib.py:167] step: 404000, eval_loss: 6.25318e-04
I0514 04:53:07.192446 22485033404224 run_lib.py:146] step: 404050, training_loss: 5.63495e-04
I0514 04:53:30.789135 22485033404224 run_lib.py:146] step: 404100, training_loss: 8.02283e-04
I0514 04:53:30.949967 22485033404224 run_lib.py:167] step: 404100, eval_loss: 6.02345e-04
I0514 04:53:55.153108 22485033404224 run_lib.py:146] step: 404150, training_loss: 5.26000e-04
I0514 04:54:18.705384 22485033404224 run_lib.py:146] step: 404200, training_loss: 6.70386e-04
I0514 04:54:18.864756 22485033404224 run_lib.py:167] step: 404200, eval_loss: 5.48682e-04
I0514 04:54:42.489439 22485033404224 run_lib.py:146] step: 404250, training_loss: 6.36790e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:55:06.741581 22485033404224 run_lib.py:146] step: 404300, training_loss: 6.87274e-04
I0514 04:55:06.902437 22485033404224 run_lib.py:167] step: 404300, eval_loss: 6.11805e-04
I0514 04:55:30.426041 22485033404224 run_lib.py:146] step: 404350, training_loss: 4.10240e-04
I0514 04:55:53.951426 22485033404224 run_lib.py:146] step: 404400, training_loss: 5.65239e-04
I0514 04:55:54.110323 22485033404224 run_lib.py:167] step: 404400, eval_loss: 7.46827e-04
I0514 04:56:17.983665 22485033404224 run_lib.py:146] step: 404450, training_loss: 5.63532e-04
I0514 04:56:41.846514 22485033404224 run_lib.py:146] step: 404500, training_loss: 7.13215e-04
I0514 04:56:42.005412 22485033404224 run_lib.py:167] step: 404500, eval_loss: 6.48740e-04
I0514 04:57:05.552104 22485033404224 run_lib.py:146] step: 404550, training_loss: 6.47740e-04
I0514 04:57:29.410625 22485033404224 run_lib.py:146] step: 404600, training_loss: 6.25632e-04
I0514 04:57:29.571101 22485033404224 run_lib.py:167] step: 404600, eval_loss: 5.77791e-04
I0514 04:57:53.398262 22485033404224 run_lib.py:146] step: 404650, training_loss: 5.77328e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:58:16.993836 22485033404224 run_lib.py:146] step: 404700, training_loss: 7.43923e-04
I0514 04:58:17.154297 22485033404224 run_lib.py:167] step: 404700, eval_loss: 5.49355e-04
I0514 04:58:40.980664 22485033404224 run_lib.py:146] step: 404750, training_loss: 6.12851e-04
I0514 04:59:04.813066 22485033404224 run_lib.py:146] step: 404800, training_loss: 6.11734e-04
I0514 04:59:04.972260 22485033404224 run_lib.py:167] step: 404800, eval_loss: 5.79995e-04
I0514 04:59:28.485940 22485033404224 run_lib.py:146] step: 404850, training_loss: 5.65346e-04
I0514 04:59:52.298617 22485033404224 run_lib.py:146] step: 404900, training_loss: 6.69461e-04
I0514 04:59:52.457963 22485033404224 run_lib.py:167] step: 404900, eval_loss: 5.79805e-04
I0514 05:00:16.265701 22485033404224 run_lib.py:146] step: 404950, training_loss: 6.55822e-04
I0514 05:00:39.780752 22485033404224 run_lib.py:146] step: 405000, training_loss: 6.50958e-04
I0514 05:00:39.939340 22485033404224 run_lib.py:167] step: 405000, eval_loss: 5.33590e-04
I0514 05:01:03.444156 22485033404224 run_lib.py:146] step: 405050, training_loss: 6.04050e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:01:27.689676 22485033404224 run_lib.py:146] step: 405100, training_loss: 7.24319e-04
I0514 05:01:27.850298 22485033404224 run_lib.py:167] step: 405100, eval_loss: 6.72394e-04
I0514 05:01:51.372403 22485033404224 run_lib.py:146] step: 405150, training_loss: 6.08206e-04
I0514 05:02:14.911885 22485033404224 run_lib.py:146] step: 405200, training_loss: 5.07917e-04
I0514 05:02:15.071524 22485033404224 run_lib.py:167] step: 405200, eval_loss: 6.37914e-04
I0514 05:02:39.169059 22485033404224 run_lib.py:146] step: 405250, training_loss: 8.64003e-04
I0514 05:03:02.667844 22485033404224 run_lib.py:146] step: 405300, training_loss: 6.26241e-04
I0514 05:03:02.826966 22485033404224 run_lib.py:167] step: 405300, eval_loss: 8.15708e-04
I0514 05:03:26.336621 22485033404224 run_lib.py:146] step: 405350, training_loss: 7.12829e-04
I0514 05:03:50.151571 22485033404224 run_lib.py:146] step: 405400, training_loss: 6.73442e-04
I0514 05:03:50.311990 22485033404224 run_lib.py:167] step: 405400, eval_loss: 5.36293e-04
I0514 05:04:14.118586 22485033404224 run_lib.py:146] step: 405450, training_loss: 7.23522e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:04:37.705286 22485033404224 run_lib.py:146] step: 405500, training_loss: 6.95682e-04
I0514 05:04:37.866376 22485033404224 run_lib.py:167] step: 405500, eval_loss: 5.50500e-04
I0514 05:05:01.778007 22485033404224 run_lib.py:146] step: 405550, training_loss: 5.43896e-04
I0514 05:05:25.727104 22485033404224 run_lib.py:146] step: 405600, training_loss: 4.68426e-04
I0514 05:05:25.886607 22485033404224 run_lib.py:167] step: 405600, eval_loss: 6.06814e-04
I0514 05:05:49.473291 22485033404224 run_lib.py:146] step: 405650, training_loss: 6.99353e-04
I0514 05:06:13.361785 22485033404224 run_lib.py:146] step: 405700, training_loss: 7.09784e-04
I0514 05:06:13.522136 22485033404224 run_lib.py:167] step: 405700, eval_loss: 5.99959e-04
I0514 05:06:37.393208 22485033404224 run_lib.py:146] step: 405750, training_loss: 4.90541e-04
I0514 05:07:01.002722 22485033404224 run_lib.py:146] step: 405800, training_loss: 6.02322e-04
I0514 05:07:01.162808 22485033404224 run_lib.py:167] step: 405800, eval_loss: 5.12240e-04
I0514 05:07:24.773511 22485033404224 run_lib.py:146] step: 405850, training_loss: 6.16687e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:07:49.321412 22485033404224 run_lib.py:146] step: 405900, training_loss: 5.94538e-04
I0514 05:07:49.484317 22485033404224 run_lib.py:167] step: 405900, eval_loss: 7.80880e-04
I0514 05:08:13.211023 22485033404224 run_lib.py:146] step: 405950, training_loss: 6.51168e-04
I0514 05:08:36.925871 22485033404224 run_lib.py:146] step: 406000, training_loss: 6.48101e-04
I0514 05:08:37.087180 22485033404224 run_lib.py:167] step: 406000, eval_loss: 6.36830e-04
I0514 05:09:01.548696 22485033404224 run_lib.py:146] step: 406050, training_loss: 5.94635e-04
I0514 05:09:25.169263 22485033404224 run_lib.py:146] step: 406100, training_loss: 5.06995e-04
I0514 05:09:25.330956 22485033404224 run_lib.py:167] step: 406100, eval_loss: 5.30444e-04
I0514 05:09:48.910216 22485033404224 run_lib.py:146] step: 406150, training_loss: 6.33815e-04
I0514 05:10:12.906919 22485033404224 run_lib.py:146] step: 406200, training_loss: 7.49798e-04
I0514 05:10:13.067378 22485033404224 run_lib.py:167] step: 406200, eval_loss: 6.55879e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:10:37.030820 22485033404224 run_lib.py:146] step: 406250, training_loss: 6.31477e-04
I0514 05:11:00.599043 22485033404224 run_lib.py:146] step: 406300, training_loss: 7.23509e-04
I0514 05:11:00.761167 22485033404224 run_lib.py:167] step: 406300, eval_loss: 4.54099e-04
I0514 05:11:24.791156 22485033404224 run_lib.py:146] step: 406350, training_loss: 6.07681e-04
I0514 05:11:48.743090 22485033404224 run_lib.py:146] step: 406400, training_loss: 6.99378e-04
I0514 05:11:48.904397 22485033404224 run_lib.py:167] step: 406400, eval_loss: 6.64711e-04
I0514 05:12:12.507697 22485033404224 run_lib.py:146] step: 406450, training_loss: 5.88252e-04
I0514 05:12:36.449295 22485033404224 run_lib.py:146] step: 406500, training_loss: 7.07611e-04
I0514 05:12:36.609046 22485033404224 run_lib.py:167] step: 406500, eval_loss: 5.39791e-04
I0514 05:13:00.436803 22485033404224 run_lib.py:146] step: 406550, training_loss: 6.20827e-04
I0514 05:13:23.968518 22485033404224 run_lib.py:146] step: 406600, training_loss: 5.00337e-04
I0514 05:13:24.127424 22485033404224 run_lib.py:167] step: 406600, eval_loss: 6.09152e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:13:48.088873 22485033404224 run_lib.py:146] step: 406650, training_loss: 6.30612e-04
I0514 05:14:11.929091 22485033404224 run_lib.py:146] step: 406700, training_loss: 4.79641e-04
I0514 05:14:12.088796 22485033404224 run_lib.py:167] step: 406700, eval_loss: 6.42228e-04
I0514 05:14:35.604127 22485033404224 run_lib.py:146] step: 406750, training_loss: 7.45882e-04
I0514 05:14:59.130214 22485033404224 run_lib.py:146] step: 406800, training_loss: 7.68000e-04
I0514 05:14:59.288662 22485033404224 run_lib.py:167] step: 406800, eval_loss: 5.19503e-04
I0514 05:15:23.404155 22485033404224 run_lib.py:146] step: 406850, training_loss: 5.23057e-04
I0514 05:15:46.899346 22485033404224 run_lib.py:146] step: 406900, training_loss: 5.49563e-04
I0514 05:15:47.059114 22485033404224 run_lib.py:167] step: 406900, eval_loss: 6.45537e-04
I0514 05:16:10.562196 22485033404224 run_lib.py:146] step: 406950, training_loss: 6.55842e-04
I0514 05:16:34.394364 22485033404224 run_lib.py:146] step: 407000, training_loss: 5.05307e-04
I0514 05:16:34.554312 22485033404224 run_lib.py:167] step: 407000, eval_loss: 4.23868e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:16:58.417110 22485033404224 run_lib.py:146] step: 407050, training_loss: 5.14405e-04
I0514 05:17:21.979774 22485033404224 run_lib.py:146] step: 407100, training_loss: 4.88286e-04
I0514 05:17:22.140551 22485033404224 run_lib.py:167] step: 407100, eval_loss: 5.96347e-04
I0514 05:17:46.005935 22485033404224 run_lib.py:146] step: 407150, training_loss: 5.07810e-04
I0514 05:18:09.855911 22485033404224 run_lib.py:146] step: 407200, training_loss: 4.76911e-04
I0514 05:18:10.014597 22485033404224 run_lib.py:167] step: 407200, eval_loss: 5.57508e-04
I0514 05:18:33.547431 22485033404224 run_lib.py:146] step: 407250, training_loss: 6.83074e-04
I0514 05:18:57.394872 22485033404224 run_lib.py:146] step: 407300, training_loss: 5.74085e-04
I0514 05:18:57.553187 22485033404224 run_lib.py:167] step: 407300, eval_loss: 7.29712e-04
I0514 05:19:21.334888 22485033404224 run_lib.py:146] step: 407350, training_loss: 5.53517e-04
I0514 05:19:44.843414 22485033404224 run_lib.py:146] step: 407400, training_loss: 5.65785e-04
I0514 05:19:45.001993 22485033404224 run_lib.py:167] step: 407400, eval_loss: 4.87968e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:20:08.951072 22485033404224 run_lib.py:146] step: 407450, training_loss: 6.21808e-04
I0514 05:20:32.814857 22485033404224 run_lib.py:146] step: 407500, training_loss: 4.69190e-04
I0514 05:20:32.976230 22485033404224 run_lib.py:167] step: 407500, eval_loss: 7.14297e-04
I0514 05:20:56.476451 22485033404224 run_lib.py:146] step: 407550, training_loss: 6.74462e-04
I0514 05:21:19.981999 22485033404224 run_lib.py:146] step: 407600, training_loss: 5.79038e-04
I0514 05:21:20.141396 22485033404224 run_lib.py:167] step: 407600, eval_loss: 6.61467e-04
I0514 05:21:44.284923 22485033404224 run_lib.py:146] step: 407650, training_loss: 5.44169e-04
I0514 05:22:07.810101 22485033404224 run_lib.py:146] step: 407700, training_loss: 5.62052e-04
I0514 05:22:07.969251 22485033404224 run_lib.py:167] step: 407700, eval_loss: 5.65625e-04
I0514 05:22:31.495069 22485033404224 run_lib.py:146] step: 407750, training_loss: 6.16094e-04
I0514 05:22:55.349475 22485033404224 run_lib.py:146] step: 407800, training_loss: 6.73228e-04
I0514 05:22:55.510081 22485033404224 run_lib.py:167] step: 407800, eval_loss: 5.68998e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:23:19.595566 22485033404224 run_lib.py:146] step: 407850, training_loss: 6.64891e-04
I0514 05:23:43.196542 22485033404224 run_lib.py:146] step: 407900, training_loss: 6.14473e-04
I0514 05:23:43.358005 22485033404224 run_lib.py:167] step: 407900, eval_loss: 7.19847e-04
I0514 05:24:07.282927 22485033404224 run_lib.py:146] step: 407950, training_loss: 6.33230e-04
I0514 05:24:31.206973 22485033404224 run_lib.py:146] step: 408000, training_loss: 6.92267e-04
I0514 05:24:31.366718 22485033404224 run_lib.py:167] step: 408000, eval_loss: 6.34448e-04
I0514 05:24:54.966939 22485033404224 run_lib.py:146] step: 408050, training_loss: 6.07730e-04
I0514 05:25:18.883777 22485033404224 run_lib.py:146] step: 408100, training_loss: 3.98137e-04
I0514 05:25:19.044773 22485033404224 run_lib.py:167] step: 408100, eval_loss: 6.45630e-04
I0514 05:25:42.914633 22485033404224 run_lib.py:146] step: 408150, training_loss: 6.01156e-04
I0514 05:26:06.512940 22485033404224 run_lib.py:146] step: 408200, training_loss: 5.39724e-04
I0514 05:26:06.673173 22485033404224 run_lib.py:167] step: 408200, eval_loss: 5.97297e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:26:30.844686 22485033404224 run_lib.py:146] step: 408250, training_loss: 4.41349e-04
I0514 05:26:54.933339 22485033404224 run_lib.py:146] step: 408300, training_loss: 5.89295e-04
I0514 05:26:55.096125 22485033404224 run_lib.py:167] step: 408300, eval_loss: 7.31559e-04
I0514 05:27:18.720496 22485033404224 run_lib.py:146] step: 408350, training_loss: 5.90263e-04
I0514 05:27:42.722932 22485033404224 run_lib.py:146] step: 408400, training_loss: 7.46350e-04
I0514 05:27:42.883216 22485033404224 run_lib.py:167] step: 408400, eval_loss: 7.25600e-04
I0514 05:28:06.917683 22485033404224 run_lib.py:146] step: 408450, training_loss: 5.68164e-04
I0514 05:28:30.527809 22485033404224 run_lib.py:146] step: 408500, training_loss: 5.11102e-04
I0514 05:28:30.689068 22485033404224 run_lib.py:167] step: 408500, eval_loss: 7.50430e-04
I0514 05:28:54.304543 22485033404224 run_lib.py:146] step: 408550, training_loss: 5.28416e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:29:18.730969 22485033404224 run_lib.py:146] step: 408600, training_loss: 7.31370e-04
I0514 05:29:18.891356 22485033404224 run_lib.py:167] step: 408600, eval_loss: 6.76594e-04
I0514 05:29:42.479008 22485033404224 run_lib.py:146] step: 408650, training_loss: 5.60387e-04
I0514 05:30:06.087596 22485033404224 run_lib.py:146] step: 408700, training_loss: 6.28493e-04
I0514 05:30:06.249374 22485033404224 run_lib.py:167] step: 408700, eval_loss: 5.34768e-04
I0514 05:30:30.134945 22485033404224 run_lib.py:146] step: 408750, training_loss: 6.90556e-04
I0514 05:30:54.014432 22485033404224 run_lib.py:146] step: 408800, training_loss: 6.89421e-04
I0514 05:30:54.173274 22485033404224 run_lib.py:167] step: 408800, eval_loss: 5.60638e-04
I0514 05:31:17.670650 22485033404224 run_lib.py:146] step: 408850, training_loss: 7.26652e-04
I0514 05:31:41.492961 22485033404224 run_lib.py:146] step: 408900, training_loss: 6.15953e-04
I0514 05:31:41.651432 22485033404224 run_lib.py:167] step: 408900, eval_loss: 9.38427e-04
I0514 05:32:05.478256 22485033404224 run_lib.py:146] step: 408950, training_loss: 5.17373e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:32:29.071472 22485033404224 run_lib.py:146] step: 409000, training_loss: 6.41072e-04
I0514 05:32:29.232722 22485033404224 run_lib.py:167] step: 409000, eval_loss: 5.61559e-04
I0514 05:32:53.122742 22485033404224 run_lib.py:146] step: 409050, training_loss: 5.33028e-04
I0514 05:33:16.984648 22485033404224 run_lib.py:146] step: 409100, training_loss: 6.80098e-04
I0514 05:33:17.143918 22485033404224 run_lib.py:167] step: 409100, eval_loss: 4.63230e-04
I0514 05:33:40.636320 22485033404224 run_lib.py:146] step: 409150, training_loss: 5.75682e-04
I0514 05:34:04.434195 22485033404224 run_lib.py:146] step: 409200, training_loss: 6.25539e-04
I0514 05:34:04.592787 22485033404224 run_lib.py:167] step: 409200, eval_loss: 7.05642e-04
I0514 05:34:28.412395 22485033404224 run_lib.py:146] step: 409250, training_loss: 5.96086e-04
I0514 05:34:51.928072 22485033404224 run_lib.py:146] step: 409300, training_loss: 6.91582e-04
I0514 05:34:52.088299 22485033404224 run_lib.py:167] step: 409300, eval_loss: 7.53057e-04
I0514 05:35:15.905492 22485033404224 run_lib.py:146] step: 409350, training_loss: 4.66321e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:35:39.827284 22485033404224 run_lib.py:146] step: 409400, training_loss: 4.60703e-04
I0514 05:35:39.987745 22485033404224 run_lib.py:167] step: 409400, eval_loss: 6.01734e-04
I0514 05:36:03.503210 22485033404224 run_lib.py:146] step: 409450, training_loss: 6.77846e-04
I0514 05:36:27.004035 22485033404224 run_lib.py:146] step: 409500, training_loss: 5.54164e-04
I0514 05:36:27.163457 22485033404224 run_lib.py:167] step: 409500, eval_loss: 7.08930e-04
I0514 05:36:50.988847 22485033404224 run_lib.py:146] step: 409550, training_loss: 4.71788e-04
I0514 05:37:14.791751 22485033404224 run_lib.py:146] step: 409600, training_loss: 4.27187e-04
I0514 05:37:14.951418 22485033404224 run_lib.py:167] step: 409600, eval_loss: 6.05197e-04
I0514 05:37:38.475438 22485033404224 run_lib.py:146] step: 409650, training_loss: 8.56948e-04
I0514 05:38:02.298213 22485033404224 run_lib.py:146] step: 409700, training_loss: 6.50446e-04
I0514 05:38:02.457573 22485033404224 run_lib.py:167] step: 409700, eval_loss: 7.28466e-04
I0514 05:38:26.286237 22485033404224 run_lib.py:146] step: 409750, training_loss: 5.93390e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:38:50.027599 22485033404224 run_lib.py:146] step: 409800, training_loss: 5.42435e-04
I0514 05:38:50.188267 22485033404224 run_lib.py:167] step: 409800, eval_loss: 5.84166e-04
I0514 05:39:14.050145 22485033404224 run_lib.py:146] step: 409850, training_loss: 5.53118e-04
I0514 05:39:37.916957 22485033404224 run_lib.py:146] step: 409900, training_loss: 5.03058e-04
I0514 05:39:38.076202 22485033404224 run_lib.py:167] step: 409900, eval_loss: 5.32093e-04
I0514 05:40:01.587656 22485033404224 run_lib.py:146] step: 409950, training_loss: 6.17885e-04
I0514 05:40:25.403559 22485033404224 run_lib.py:146] step: 410000, training_loss: 4.79971e-04
I0514 05:40:35.584019 22485033404224 run_lib.py:167] step: 410000, eval_loss: 6.81940e-04
I0514 05:41:08.310324 22485033404224 run_lib.py:146] step: 410050, training_loss: 6.40781e-04
I0514 05:41:31.893674 22485033404224 run_lib.py:146] step: 410100, training_loss: 5.72819e-04
I0514 05:41:32.054040 22485033404224 run_lib.py:167] step: 410100, eval_loss: 6.07983e-04
I0514 05:41:56.262717 22485033404224 run_lib.py:146] step: 410150, training_loss: 4.43202e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:42:19.917761 22485033404224 run_lib.py:146] step: 410200, training_loss: 4.88079e-04
I0514 05:42:20.100987 22485033404224 run_lib.py:167] step: 410200, eval_loss: 5.79645e-04
I0514 05:42:43.676406 22485033404224 run_lib.py:146] step: 410250, training_loss: 7.25654e-04
I0514 05:43:07.258593 22485033404224 run_lib.py:146] step: 410300, training_loss: 6.50468e-04
I0514 05:43:07.419453 22485033404224 run_lib.py:167] step: 410300, eval_loss: 6.71784e-04
I0514 05:43:31.669876 22485033404224 run_lib.py:146] step: 410350, training_loss: 6.19644e-04
I0514 05:43:55.233505 22485033404224 run_lib.py:146] step: 410400, training_loss: 4.88509e-04
I0514 05:43:55.394611 22485033404224 run_lib.py:167] step: 410400, eval_loss: 7.74936e-04
I0514 05:44:18.942040 22485033404224 run_lib.py:146] step: 410450, training_loss: 6.05163e-04
I0514 05:44:43.116459 22485033404224 run_lib.py:146] step: 410500, training_loss: 5.40902e-04
I0514 05:44:43.276682 22485033404224 run_lib.py:167] step: 410500, eval_loss: 7.41145e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:45:06.918619 22485033404224 run_lib.py:146] step: 410550, training_loss: 7.15810e-04
I0514 05:45:30.489971 22485033404224 run_lib.py:146] step: 410600, training_loss: 5.54948e-04
I0514 05:45:30.670284 22485033404224 run_lib.py:167] step: 410600, eval_loss: 5.86854e-04
I0514 05:45:54.916943 22485033404224 run_lib.py:146] step: 410650, training_loss: 5.58342e-04
I0514 05:46:18.506809 22485033404224 run_lib.py:146] step: 410700, training_loss: 5.28569e-04
I0514 05:46:18.592467 22485033404224 run_lib.py:167] step: 410700, eval_loss: 1.04954e-03
I0514 05:46:42.179037 22485033404224 run_lib.py:146] step: 410750, training_loss: 6.53365e-04
I0514 05:47:06.369451 22485033404224 run_lib.py:146] step: 410800, training_loss: 5.06308e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:47:06.721920 22485033404224 run_lib.py:167] step: 410800, eval_loss: 6.85696e-04
I0514 05:47:30.376109 22485033404224 run_lib.py:146] step: 410850, training_loss: 6.77749e-04
I0514 05:47:54.049585 22485033404224 run_lib.py:146] step: 410900, training_loss: 5.05511e-04
I0514 05:47:54.211246 22485033404224 run_lib.py:167] step: 410900, eval_loss: 6.29662e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:48:18.600072 22485033404224 run_lib.py:146] step: 410950, training_loss: 6.25053e-04
I0514 05:48:42.145867 22485033404224 run_lib.py:146] step: 411000, training_loss: 4.62051e-04
I0514 05:48:42.306330 22485033404224 run_lib.py:167] step: 411000, eval_loss: 5.24775e-04
I0514 05:49:05.815824 22485033404224 run_lib.py:146] step: 411050, training_loss: 6.99667e-04
I0514 05:49:29.660792 22485033404224 run_lib.py:146] step: 411100, training_loss: 6.27762e-04
I0514 05:49:29.821209 22485033404224 run_lib.py:167] step: 411100, eval_loss: 7.66326e-04
I0514 05:49:53.641022 22485033404224 run_lib.py:146] step: 411150, training_loss: 4.74585e-04
I0514 05:50:17.171668 22485033404224 run_lib.py:146] step: 411200, training_loss: 4.67224e-04
I0514 05:50:17.331268 22485033404224 run_lib.py:167] step: 411200, eval_loss: 4.39709e-04
I0514 05:50:40.841443 22485033404224 run_lib.py:146] step: 411250, training_loss: 4.63556e-04
I0514 05:51:04.949997 22485033404224 run_lib.py:146] step: 411300, training_loss: 7.67042e-04
I0514 05:51:05.109644 22485033404224 run_lib.py:167] step: 411300, eval_loss: 5.31630e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:51:28.704586 22485033404224 run_lib.py:146] step: 411350, training_loss: 6.61647e-04
I0514 05:51:52.223807 22485033404224 run_lib.py:146] step: 411400, training_loss: 6.17345e-04
I0514 05:51:52.384594 22485033404224 run_lib.py:167] step: 411400, eval_loss: 5.76353e-04
I0514 05:52:16.566649 22485033404224 run_lib.py:146] step: 411450, training_loss: 6.11714e-04
I0514 05:52:40.078042 22485033404224 run_lib.py:146] step: 411500, training_loss: 4.55521e-04
I0514 05:52:40.236989 22485033404224 run_lib.py:167] step: 411500, eval_loss: 6.96920e-04
I0514 05:53:03.768806 22485033404224 run_lib.py:146] step: 411550, training_loss: 5.99487e-04
I0514 05:53:27.916230 22485033404224 run_lib.py:146] step: 411600, training_loss: 8.42426e-04
I0514 05:53:28.076956 22485033404224 run_lib.py:167] step: 411600, eval_loss: 6.34563e-04
I0514 05:53:51.626588 22485033404224 run_lib.py:146] step: 411650, training_loss: 7.17698e-04
I0514 05:54:15.169659 22485033404224 run_lib.py:146] step: 411700, training_loss: 4.97109e-04
I0514 05:54:15.329316 22485033404224 run_lib.py:167] step: 411700, eval_loss: 5.29486e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:54:39.634964 22485033404224 run_lib.py:146] step: 411750, training_loss: 5.56381e-04
I0514 05:55:03.156116 22485033404224 run_lib.py:146] step: 411800, training_loss: 4.96238e-04
I0514 05:55:03.317150 22485033404224 run_lib.py:167] step: 411800, eval_loss: 5.75064e-04
I0514 05:55:26.855171 22485033404224 run_lib.py:146] step: 411850, training_loss: 5.92048e-04
I0514 05:55:50.684335 22485033404224 run_lib.py:146] step: 411900, training_loss: 6.30055e-04
I0514 05:55:50.844826 22485033404224 run_lib.py:167] step: 411900, eval_loss: 6.87036e-04
I0514 05:56:14.716433 22485033404224 run_lib.py:146] step: 411950, training_loss: 5.29686e-04
I0514 05:56:38.272299 22485033404224 run_lib.py:146] step: 412000, training_loss: 6.84917e-04
I0514 05:56:38.478927 22485033404224 run_lib.py:167] step: 412000, eval_loss: 5.99698e-04
I0514 05:57:02.291990 22485033404224 run_lib.py:146] step: 412050, training_loss: 5.75745e-04
I0514 05:57:26.133473 22485033404224 run_lib.py:146] step: 412100, training_loss: 7.53389e-04
I0514 05:57:26.294211 22485033404224 run_lib.py:167] step: 412100, eval_loss: 4.60217e-04
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
slurmstepd: error: *** JOB 53144907 ON gl1517 CANCELLED AT 2023-05-14T05:57:39 ***
