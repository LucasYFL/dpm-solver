2
WARNING:tensorflow:From /home/yifulu/.conda/envs/dpm/lib/python3.9/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.

I0215 21:34:16.937106 22839682574144 main.py:54] Conditional: True
W0215 21:34:19.182552 22839682574144 utils.py:10] No checkpoint found at experiments/dpm_one_first/checkpoints-meta/checkpoint.pth. Returned the same state as input
I0215 21:34:19.186506 22839682574144 xla_bridge.py:355] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0215 21:34:19.186771 22839682574144 xla_bridge.py:355] Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0215 21:34:19.186857 22839682574144 xla_bridge.py:355] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0215 21:34:19.187906 22839682574144 xla_bridge.py:355] Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.
I0215 21:34:19.188080 22839682574144 xla_bridge.py:355] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
W0215 21:34:19.188170 22839682574144 xla_bridge.py:362] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0215 21:34:19.191575 22839682574144 dataset_info.py:358] Load dataset info from /home/yifulu/tensorflow_datasets/cifar10/3.0.2
W0215 21:34:19.196229 22839682574144 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
W0215 21:34:19.196457 22839682574144 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
I0215 21:34:19.196622 22839682574144 dataset_builder.py:351] Reusing dataset cifar10 (/home/yifulu/tensorflow_datasets/cifar10/3.0.2)
I0215 21:34:19.196736 22839682574144 logging_logger.py:35] Constructing tf.data.Dataset cifar10 for split train, from /home/yifulu/tensorflow_datasets/cifar10/3.0.2
W0215 21:34:19.376762 22839682574144 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
W0215 21:34:19.377047 22839682574144 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
I0215 21:34:19.377193 22839682574144 dataset_builder.py:351] Reusing dataset cifar10 (/home/yifulu/tensorflow_datasets/cifar10/3.0.2)
I0215 21:34:19.377286 22839682574144 logging_logger.py:35] Constructing tf.data.Dataset cifar10 for split test, from /home/yifulu/tensorflow_datasets/cifar10/3.0.2
I0215 21:34:20.036727 22839682574144 losses.py:57] Sde loss
I0215 21:34:20.037009 22839682574144 losses.py:59] Fewer: 2
I0215 21:34:20.037137 22839682574144 losses.py:71] one step set
I0215 21:34:20.037213 22839682574144 losses.py:57] Sde loss
I0215 21:34:20.037274 22839682574144 losses.py:59] Fewer: 2
I0215 21:34:20.037347 22839682574144 losses.py:71] one step set
I0215 21:34:20.037417 22839682574144 sampling.py:98] dpm_solver
I0215 21:34:20.037526 22839682574144 run_lib.py:123] Starting training loop at step 0.
I0215 21:34:41.789258 22839682574144 run_lib.py:133] step: 0, training_loss: 1.00399e+00
I0215 21:34:44.063066 22839682574144 run_lib.py:146] step: 0, eval_loss: 9.98632e-01
I0215 21:35:04.040625 22839682574144 run_lib.py:133] step: 50, training_loss: 9.92108e-01
I0215 21:35:23.798857 22839682574144 run_lib.py:133] step: 100, training_loss: 9.59359e-01
I0215 21:35:23.954089 22839682574144 run_lib.py:146] step: 100, eval_loss: 9.66784e-01
I0215 21:35:43.675623 22839682574144 run_lib.py:133] step: 150, training_loss: 9.00118e-01
I0215 21:36:01.213955 22839682574144 run_lib.py:133] step: 200, training_loss: 8.20905e-01
I0215 21:36:01.370858 22839682574144 run_lib.py:146] step: 200, eval_loss: 8.48769e-01
I0215 21:36:19.038445 22839682574144 run_lib.py:133] step: 250, training_loss: 7.32919e-01
I0215 21:36:36.552789 22839682574144 run_lib.py:133] step: 300, training_loss: 6.29834e-01
I0215 21:36:36.713144 22839682574144 run_lib.py:146] step: 300, eval_loss: 6.82993e-01
I0215 21:36:54.227479 22839682574144 run_lib.py:133] step: 350, training_loss: 5.30793e-01
I0215 21:37:11.952026 22839682574144 run_lib.py:133] step: 400, training_loss: 4.26225e-01
I0215 21:37:12.110664 22839682574144 run_lib.py:146] step: 400, eval_loss: 4.93546e-01
I0215 21:37:29.594810 22839682574144 run_lib.py:133] step: 450, training_loss: 3.33415e-01
I0215 21:37:47.294275 22839682574144 run_lib.py:133] step: 500, training_loss: 2.55209e-01
I0215 21:37:47.455119 22839682574144 run_lib.py:146] step: 500, eval_loss: 3.20033e-01
I0215 21:38:04.923106 22839682574144 run_lib.py:133] step: 550, training_loss: 2.00938e-01
I0215 21:38:22.377726 22839682574144 run_lib.py:133] step: 600, training_loss: 1.73759e-01
I0215 21:38:22.535969 22839682574144 run_lib.py:146] step: 600, eval_loss: 2.00837e-01
I0215 21:38:40.237254 22839682574144 run_lib.py:133] step: 650, training_loss: 1.58662e-01
I0215 21:38:57.691072 22839682574144 run_lib.py:133] step: 700, training_loss: 1.55504e-01
I0215 21:38:57.854410 22839682574144 run_lib.py:146] step: 700, eval_loss: 1.60047e-01
I0215 21:39:15.379356 22839682574144 run_lib.py:133] step: 750, training_loss: 1.52153e-01
I0215 21:39:33.063138 22839682574144 run_lib.py:133] step: 800, training_loss: 1.46239e-01
I0215 21:39:33.229175 22839682574144 run_lib.py:146] step: 800, eval_loss: 1.45808e-01
I0215 21:39:50.760984 22839682574144 run_lib.py:133] step: 850, training_loss: 1.55297e-01
I0215 21:40:08.240461 22839682574144 run_lib.py:133] step: 900, training_loss: 1.53881e-01
I0215 21:40:08.401852 22839682574144 run_lib.py:146] step: 900, eval_loss: 1.44651e-01
I0215 21:40:26.003555 22839682574144 run_lib.py:133] step: 950, training_loss: 1.55851e-01
I0215 21:40:43.529197 22839682574144 run_lib.py:133] step: 1000, training_loss: 1.47860e-01
I0215 21:40:43.686779 22839682574144 run_lib.py:146] step: 1000, eval_loss: 1.44899e-01
I0215 21:41:01.177354 22839682574144 run_lib.py:133] step: 1050, training_loss: 1.49331e-01
I0215 21:41:18.710154 22839682574144 run_lib.py:133] step: 1100, training_loss: 1.49125e-01
I0215 21:41:18.869317 22839682574144 run_lib.py:146] step: 1100, eval_loss: 1.45108e-01
I0215 21:41:36.642173 22839682574144 run_lib.py:133] step: 1150, training_loss: 1.43398e-01
I0215 21:41:54.225668 22839682574144 run_lib.py:133] step: 1200, training_loss: 1.46861e-01
I0215 21:41:54.380253 22839682574144 run_lib.py:146] step: 1200, eval_loss: 1.43292e-01
I0215 21:42:11.877960 22839682574144 run_lib.py:133] step: 1250, training_loss: 1.48460e-01
I0215 21:42:29.391464 22839682574144 run_lib.py:133] step: 1300, training_loss: 1.46514e-01
I0215 21:42:29.565067 22839682574144 run_lib.py:146] step: 1300, eval_loss: 1.40897e-01
I0215 21:42:47.285216 22839682574144 run_lib.py:133] step: 1350, training_loss: 1.42104e-01
I0215 21:43:04.820408 22839682574144 run_lib.py:133] step: 1400, training_loss: 1.40381e-01
I0215 21:43:04.977125 22839682574144 run_lib.py:146] step: 1400, eval_loss: 1.42075e-01
I0215 21:43:22.477508 22839682574144 run_lib.py:133] step: 1450, training_loss: 1.45131e-01
I0215 21:43:40.183374 22839682574144 run_lib.py:133] step: 1500, training_loss: 1.41963e-01
I0215 21:43:40.342827 22839682574144 run_lib.py:146] step: 1500, eval_loss: 1.38357e-01
I0215 21:43:57.856861 22839682574144 run_lib.py:133] step: 1550, training_loss: 1.41914e-01
I0215 21:44:15.552305 22839682574144 run_lib.py:133] step: 1600, training_loss: 1.45484e-01
I0215 21:44:15.714741 22839682574144 run_lib.py:146] step: 1600, eval_loss: 1.35665e-01
I0215 21:44:33.249531 22839682574144 run_lib.py:133] step: 1650, training_loss: 1.37149e-01
I0215 21:44:50.774575 22839682574144 run_lib.py:133] step: 1700, training_loss: 1.38893e-01
I0215 21:44:50.930981 22839682574144 run_lib.py:146] step: 1700, eval_loss: 1.37617e-01
I0215 21:45:08.663517 22839682574144 run_lib.py:133] step: 1750, training_loss: 1.43998e-01
I0215 21:45:26.172597 22839682574144 run_lib.py:133] step: 1800, training_loss: 1.39829e-01
I0215 21:45:26.331854 22839682574144 run_lib.py:146] step: 1800, eval_loss: 1.35099e-01
I0215 21:45:43.790571 22839682574144 run_lib.py:133] step: 1850, training_loss: 1.40472e-01
I0215 21:46:01.429506 22839682574144 run_lib.py:133] step: 1900, training_loss: 1.40585e-01
I0215 21:46:01.595076 22839682574144 run_lib.py:146] step: 1900, eval_loss: 1.38492e-01
I0215 21:46:19.080110 22839682574144 run_lib.py:133] step: 1950, training_loss: 1.38798e-01
I0215 21:46:36.577430 22839682574144 run_lib.py:133] step: 2000, training_loss: 1.36502e-01
I0215 21:46:36.736201 22839682574144 run_lib.py:146] step: 2000, eval_loss: 1.38902e-01
I0215 21:46:54.358780 22839682574144 run_lib.py:133] step: 2050, training_loss: 1.39600e-01
I0215 21:47:11.876340 22839682574144 run_lib.py:133] step: 2100, training_loss: 1.38353e-01
I0215 21:47:12.031805 22839682574144 run_lib.py:146] step: 2100, eval_loss: 1.34806e-01
I0215 21:47:29.556285 22839682574144 run_lib.py:133] step: 2150, training_loss: 1.37077e-01
I0215 21:47:47.058978 22839682574144 run_lib.py:133] step: 2200, training_loss: 1.39243e-01
I0215 21:47:47.221211 22839682574144 run_lib.py:146] step: 2200, eval_loss: 1.35130e-01
I0215 21:48:04.944232 22839682574144 run_lib.py:133] step: 2250, training_loss: 1.35427e-01
I0215 21:48:22.549490 22839682574144 run_lib.py:133] step: 2300, training_loss: 1.40520e-01
I0215 21:48:22.709957 22839682574144 run_lib.py:146] step: 2300, eval_loss: 1.32518e-01
I0215 21:48:40.235623 22839682574144 run_lib.py:133] step: 2350, training_loss: 1.36202e-01
I0215 21:48:57.719112 22839682574144 run_lib.py:133] step: 2400, training_loss: 1.39617e-01
I0215 21:48:57.878134 22839682574144 run_lib.py:146] step: 2400, eval_loss: 1.35528e-01
I0215 21:49:15.508774 22839682574144 run_lib.py:133] step: 2450, training_loss: 1.41421e-01
I0215 21:49:33.046069 22839682574144 run_lib.py:133] step: 2500, training_loss: 1.31998e-01
I0215 21:49:33.199796 22839682574144 run_lib.py:146] step: 2500, eval_loss: 1.32999e-01
I0215 21:49:50.689926 22839682574144 run_lib.py:133] step: 2550, training_loss: 1.38296e-01
I0215 21:50:08.393458 22839682574144 run_lib.py:133] step: 2600, training_loss: 1.37653e-01
I0215 21:50:08.556709 22839682574144 run_lib.py:146] step: 2600, eval_loss: 1.32833e-01
I0215 21:50:26.073127 22839682574144 run_lib.py:133] step: 2650, training_loss: 1.40712e-01
I0215 21:50:43.748939 22839682574144 run_lib.py:133] step: 2700, training_loss: 1.40060e-01
I0215 21:50:43.904977 22839682574144 run_lib.py:146] step: 2700, eval_loss: 1.31311e-01
I0215 21:51:01.403867 22839682574144 run_lib.py:133] step: 2750, training_loss: 1.38074e-01
I0215 21:51:18.914175 22839682574144 run_lib.py:133] step: 2800, training_loss: 1.35708e-01
I0215 21:51:19.088019 22839682574144 run_lib.py:146] step: 2800, eval_loss: 1.30844e-01
I0215 21:51:36.829539 22839682574144 run_lib.py:133] step: 2850, training_loss: 1.36800e-01
I0215 21:51:54.326080 22839682574144 run_lib.py:133] step: 2900, training_loss: 1.40477e-01
I0215 21:51:54.483905 22839682574144 run_lib.py:146] step: 2900, eval_loss: 1.32593e-01
I0215 21:52:11.976907 22839682574144 run_lib.py:133] step: 2950, training_loss: 1.36770e-01
I0215 21:52:29.656495 22839682574144 run_lib.py:133] step: 3000, training_loss: 1.39104e-01
I0215 21:52:29.821904 22839682574144 run_lib.py:146] step: 3000, eval_loss: 1.34521e-01
I0215 21:52:47.315524 22839682574144 run_lib.py:133] step: 3050, training_loss: 1.37644e-01
I0215 21:53:04.867723 22839682574144 run_lib.py:133] step: 3100, training_loss: 1.35171e-01
I0215 21:53:05.024427 22839682574144 run_lib.py:146] step: 3100, eval_loss: 1.32401e-01
I0215 21:53:22.674672 22839682574144 run_lib.py:133] step: 3150, training_loss: 1.37878e-01
I0215 21:53:40.161642 22839682574144 run_lib.py:133] step: 3200, training_loss: 1.34928e-01
I0215 21:53:40.318939 22839682574144 run_lib.py:146] step: 3200, eval_loss: 1.32508e-01
I0215 21:53:57.785567 22839682574144 run_lib.py:133] step: 3250, training_loss: 1.36352e-01
I0215 21:54:15.333462 22839682574144 run_lib.py:133] step: 3300, training_loss: 1.37286e-01
I0215 21:54:15.508084 22839682574144 run_lib.py:146] step: 3300, eval_loss: 1.36822e-01
I0215 21:54:33.196384 22839682574144 run_lib.py:133] step: 3350, training_loss: 1.40353e-01
I0215 21:54:50.838303 22839682574144 run_lib.py:133] step: 3400, training_loss: 1.36095e-01
I0215 21:54:50.994704 22839682574144 run_lib.py:146] step: 3400, eval_loss: 1.31754e-01
I0215 21:55:08.509676 22839682574144 run_lib.py:133] step: 3450, training_loss: 1.34162e-01
I0215 21:55:26.025339 22839682574144 run_lib.py:133] step: 3500, training_loss: 1.33738e-01
I0215 21:55:26.182092 22839682574144 run_lib.py:146] step: 3500, eval_loss: 1.33729e-01
I0215 21:55:43.840699 22839682574144 run_lib.py:133] step: 3550, training_loss: 1.30017e-01
I0215 21:56:01.382654 22839682574144 run_lib.py:133] step: 3600, training_loss: 1.37745e-01
I0215 21:56:01.545174 22839682574144 run_lib.py:146] step: 3600, eval_loss: 1.31191e-01
I0215 21:56:19.079663 22839682574144 run_lib.py:133] step: 3650, training_loss: 1.34117e-01
I0215 21:56:36.789018 22839682574144 run_lib.py:133] step: 3700, training_loss: 1.35059e-01
I0215 21:56:36.948195 22839682574144 run_lib.py:146] step: 3700, eval_loss: 1.32042e-01
I0215 21:56:54.446058 22839682574144 run_lib.py:133] step: 3750, training_loss: 1.33765e-01
I0215 21:57:12.065688 22839682574144 run_lib.py:133] step: 3800, training_loss: 1.32679e-01
I0215 21:57:12.224386 22839682574144 run_lib.py:146] step: 3800, eval_loss: 1.35930e-01
I0215 21:57:29.708444 22839682574144 run_lib.py:133] step: 3850, training_loss: 1.35949e-01
I0215 21:57:47.191859 22839682574144 run_lib.py:133] step: 3900, training_loss: 1.37647e-01
I0215 21:57:47.361533 22839682574144 run_lib.py:146] step: 3900, eval_loss: 1.34973e-01
I0215 21:58:05.085464 22839682574144 run_lib.py:133] step: 3950, training_loss: 1.35324e-01
I0215 21:58:22.614564 22839682574144 run_lib.py:133] step: 4000, training_loss: 1.35547e-01
I0215 21:58:22.769747 22839682574144 run_lib.py:146] step: 4000, eval_loss: 1.32755e-01
I0215 21:58:40.298422 22839682574144 run_lib.py:133] step: 4050, training_loss: 1.38447e-01
I0215 21:58:57.999266 22839682574144 run_lib.py:133] step: 4100, training_loss: 1.32993e-01
I0215 21:58:58.154030 22839682574144 run_lib.py:146] step: 4100, eval_loss: 1.28489e-01
I0215 21:59:15.637448 22839682574144 run_lib.py:133] step: 4150, training_loss: 1.32780e-01
I0215 21:59:33.140566 22839682574144 run_lib.py:133] step: 4200, training_loss: 1.29536e-01
I0215 21:59:33.314167 22839682574144 run_lib.py:146] step: 4200, eval_loss: 1.29969e-01
I0215 21:59:50.914092 22839682574144 run_lib.py:133] step: 4250, training_loss: 1.35704e-01
I0215 22:00:08.445697 22839682574144 run_lib.py:133] step: 4300, training_loss: 1.37502e-01
I0215 22:00:08.603355 22839682574144 run_lib.py:146] step: 4300, eval_loss: 1.32024e-01
I0215 22:00:26.061640 22839682574144 run_lib.py:133] step: 4350, training_loss: 1.33419e-01
I0215 22:00:43.518153 22839682574144 run_lib.py:133] step: 4400, training_loss: 1.32006e-01
I0215 22:00:43.676106 22839682574144 run_lib.py:146] step: 4400, eval_loss: 1.29375e-01
I0215 22:01:01.440838 22839682574144 run_lib.py:133] step: 4450, training_loss: 1.29493e-01
I0215 22:01:19.072720 22839682574144 run_lib.py:133] step: 4500, training_loss: 1.35519e-01
I0215 22:01:19.226816 22839682574144 run_lib.py:146] step: 4500, eval_loss: 1.28030e-01
I0215 22:01:36.721006 22839682574144 run_lib.py:133] step: 4550, training_loss: 1.38009e-01
I0215 22:01:54.184592 22839682574144 run_lib.py:133] step: 4600, training_loss: 1.34918e-01
I0215 22:01:54.341923 22839682574144 run_lib.py:146] step: 4600, eval_loss: 1.30593e-01
I0215 22:02:11.961759 22839682574144 run_lib.py:133] step: 4650, training_loss: 1.32326e-01
I0215 22:02:29.443499 22839682574144 run_lib.py:133] step: 4700, training_loss: 1.32136e-01
I0215 22:02:29.603229 22839682574144 run_lib.py:146] step: 4700, eval_loss: 1.31818e-01
I0215 22:02:47.091049 22839682574144 run_lib.py:133] step: 4750, training_loss: 1.35972e-01
I0215 22:03:04.770647 22839682574144 run_lib.py:133] step: 4800, training_loss: 1.34473e-01
I0215 22:03:04.928157 22839682574144 run_lib.py:146] step: 4800, eval_loss: 1.34177e-01
I0215 22:03:22.421432 22839682574144 run_lib.py:133] step: 4850, training_loss: 1.35268e-01
I0215 22:03:40.142425 22839682574144 run_lib.py:133] step: 4900, training_loss: 1.31114e-01
I0215 22:03:40.299776 22839682574144 run_lib.py:146] step: 4900, eval_loss: 1.32603e-01
I0215 22:03:57.836453 22839682574144 run_lib.py:133] step: 4950, training_loss: 1.34575e-01
I0215 22:04:15.313383 22839682574144 run_lib.py:133] step: 5000, training_loss: 1.35720e-01
I0215 22:04:15.466979 22839682574144 run_lib.py:146] step: 5000, eval_loss: 1.31747e-01
I0215 22:04:33.128957 22839682574144 run_lib.py:133] step: 5050, training_loss: 1.41539e-01
I0215 22:04:50.660390 22839682574144 run_lib.py:133] step: 5100, training_loss: 1.35370e-01
I0215 22:04:50.828285 22839682574144 run_lib.py:146] step: 5100, eval_loss: 1.30111e-01
I0215 22:05:08.376644 22839682574144 run_lib.py:133] step: 5150, training_loss: 1.28666e-01
I0215 22:05:26.102063 22839682574144 run_lib.py:133] step: 5200, training_loss: 1.33538e-01
I0215 22:05:26.261203 22839682574144 run_lib.py:146] step: 5200, eval_loss: 1.30787e-01
I0215 22:05:43.778304 22839682574144 run_lib.py:133] step: 5250, training_loss: 1.32501e-01
I0215 22:06:01.247107 22839682574144 run_lib.py:133] step: 5300, training_loss: 1.27907e-01
I0215 22:06:01.404153 22839682574144 run_lib.py:146] step: 5300, eval_loss: 1.33357e-01
I0215 22:06:19.043462 22839682574144 run_lib.py:133] step: 5350, training_loss: 1.30765e-01
I0215 22:06:36.562996 22839682574144 run_lib.py:133] step: 5400, training_loss: 1.30177e-01
I0215 22:06:36.729515 22839682574144 run_lib.py:146] step: 5400, eval_loss: 1.27890e-01
I0215 22:06:54.247199 22839682574144 run_lib.py:133] step: 5450, training_loss: 1.34274e-01
I0215 22:07:11.730651 22839682574144 run_lib.py:133] step: 5500, training_loss: 1.27537e-01
I0215 22:07:11.885609 22839682574144 run_lib.py:146] step: 5500, eval_loss: 1.30581e-01
I0215 22:07:29.604770 22839682574144 run_lib.py:133] step: 5550, training_loss: 1.30466e-01
I0215 22:07:47.242507 22839682574144 run_lib.py:133] step: 5600, training_loss: 1.34360e-01
I0215 22:07:47.418304 22839682574144 run_lib.py:146] step: 5600, eval_loss: 1.22525e-01
I0215 22:08:04.977308 22839682574144 run_lib.py:133] step: 5650, training_loss: 1.29118e-01
I0215 22:08:22.516753 22839682574144 run_lib.py:133] step: 5700, training_loss: 1.31914e-01
I0215 22:08:22.675002 22839682574144 run_lib.py:146] step: 5700, eval_loss: 1.28456e-01
I0215 22:08:40.419339 22839682574144 run_lib.py:133] step: 5750, training_loss: 1.35460e-01
I0215 22:08:57.928957 22839682574144 run_lib.py:133] step: 5800, training_loss: 1.33275e-01
I0215 22:08:58.087009 22839682574144 run_lib.py:146] step: 5800, eval_loss: 1.27062e-01
I0215 22:09:15.595325 22839682574144 run_lib.py:133] step: 5850, training_loss: 1.34535e-01
I0215 22:09:33.282213 22839682574144 run_lib.py:133] step: 5900, training_loss: 1.37813e-01
I0215 22:09:33.439303 22839682574144 run_lib.py:146] step: 5900, eval_loss: 1.28527e-01
I0215 22:09:51.002953 22839682574144 run_lib.py:133] step: 5950, training_loss: 1.34403e-01
I0215 22:10:08.729284 22839682574144 run_lib.py:133] step: 6000, training_loss: 1.26992e-01
I0215 22:10:08.886919 22839682574144 run_lib.py:146] step: 6000, eval_loss: 1.28865e-01
I0215 22:10:26.351509 22839682574144 run_lib.py:133] step: 6050, training_loss: 1.34636e-01
I0215 22:10:43.848659 22839682574144 run_lib.py:133] step: 6100, training_loss: 1.30935e-01
I0215 22:10:44.009656 22839682574144 run_lib.py:146] step: 6100, eval_loss: 1.29180e-01
I0215 22:11:01.687764 22839682574144 run_lib.py:133] step: 6150, training_loss: 1.31449e-01
I0215 22:11:19.208331 22839682574144 run_lib.py:133] step: 6200, training_loss: 1.28190e-01
I0215 22:11:19.380039 22839682574144 run_lib.py:146] step: 6200, eval_loss: 1.30718e-01
I0215 22:11:36.911305 22839682574144 run_lib.py:133] step: 6250, training_loss: 1.28153e-01
I0215 22:11:54.644700 22839682574144 run_lib.py:133] step: 6300, training_loss: 1.32290e-01
I0215 22:11:54.801763 22839682574144 run_lib.py:146] step: 6300, eval_loss: 1.31736e-01
I0215 22:12:12.313024 22839682574144 run_lib.py:133] step: 6350, training_loss: 1.31976e-01
I0215 22:12:29.842780 22839682574144 run_lib.py:133] step: 6400, training_loss: 1.30795e-01
I0215 22:12:29.997000 22839682574144 run_lib.py:146] step: 6400, eval_loss: 1.33771e-01
I0215 22:12:47.619815 22839682574144 run_lib.py:133] step: 6450, training_loss: 1.33075e-01
I0215 22:13:05.134209 22839682574144 run_lib.py:133] step: 6500, training_loss: 1.30543e-01
I0215 22:13:05.302265 22839682574144 run_lib.py:146] step: 6500, eval_loss: 1.29708e-01
I0215 22:13:22.846281 22839682574144 run_lib.py:133] step: 6550, training_loss: 1.28628e-01
I0215 22:13:40.359484 22839682574144 run_lib.py:133] step: 6600, training_loss: 1.30144e-01
I0215 22:13:40.518997 22839682574144 run_lib.py:146] step: 6600, eval_loss: 1.27648e-01
I0215 22:13:58.235573 22839682574144 run_lib.py:133] step: 6650, training_loss: 1.31051e-01
I0215 22:14:15.827243 22839682574144 run_lib.py:133] step: 6700, training_loss: 1.31680e-01
I0215 22:14:15.984083 22839682574144 run_lib.py:146] step: 6700, eval_loss: 1.25267e-01
I0215 22:14:33.518370 22839682574144 run_lib.py:133] step: 6750, training_loss: 1.33675e-01
I0215 22:14:51.058930 22839682574144 run_lib.py:133] step: 6800, training_loss: 1.27507e-01
I0215 22:14:51.215707 22839682574144 run_lib.py:146] step: 6800, eval_loss: 1.31413e-01
I0215 22:15:08.945210 22839682574144 run_lib.py:133] step: 6850, training_loss: 1.29841e-01
I0215 22:15:26.426076 22839682574144 run_lib.py:133] step: 6900, training_loss: 1.26350e-01
I0215 22:15:26.580038 22839682574144 run_lib.py:146] step: 6900, eval_loss: 1.30390e-01
I0215 22:15:44.075374 22839682574144 run_lib.py:133] step: 6950, training_loss: 1.27461e-01
I0215 22:16:01.749004 22839682574144 run_lib.py:133] step: 7000, training_loss: 1.30650e-01
I0215 22:16:01.907970 22839682574144 run_lib.py:146] step: 7000, eval_loss: 1.34210e-01
I0215 22:16:19.419682 22839682574144 run_lib.py:133] step: 7050, training_loss: 1.28349e-01
I0215 22:16:37.121594 22839682574144 run_lib.py:133] step: 7100, training_loss: 1.30960e-01
I0215 22:16:37.299636 22839682574144 run_lib.py:146] step: 7100, eval_loss: 1.27820e-01
I0215 22:16:54.789201 22839682574144 run_lib.py:133] step: 7150, training_loss: 1.32121e-01
I0215 22:17:12.282558 22839682574144 run_lib.py:133] step: 7200, training_loss: 1.33197e-01
I0215 22:17:12.440238 22839682574144 run_lib.py:146] step: 7200, eval_loss: 1.26370e-01
I0215 22:17:30.170979 22839682574144 run_lib.py:133] step: 7250, training_loss: 1.32331e-01
I0215 22:17:47.647858 22839682574144 run_lib.py:133] step: 7300, training_loss: 1.29873e-01
I0215 22:17:47.805062 22839682574144 run_lib.py:146] step: 7300, eval_loss: 1.24153e-01
I0215 22:18:05.327372 22839682574144 run_lib.py:133] step: 7350, training_loss: 1.34528e-01
I0215 22:18:23.122169 22839682574144 run_lib.py:133] step: 7400, training_loss: 1.26689e-01
I0215 22:18:23.280297 22839682574144 run_lib.py:146] step: 7400, eval_loss: 1.23366e-01
I0215 22:18:40.825902 22839682574144 run_lib.py:133] step: 7450, training_loss: 1.32152e-01
I0215 22:18:58.354871 22839682574144 run_lib.py:133] step: 7500, training_loss: 1.30231e-01
I0215 22:18:58.519269 22839682574144 run_lib.py:146] step: 7500, eval_loss: 1.28606e-01
I0215 22:19:16.058732 22839682574144 run_lib.py:133] step: 7550, training_loss: 1.27351e-01
I0215 22:19:33.575593 22839682574144 run_lib.py:133] step: 7600, training_loss: 1.31770e-01
I0215 22:19:33.743030 22839682574144 run_lib.py:146] step: 7600, eval_loss: 1.25363e-01
I0215 22:19:51.250158 22839682574144 run_lib.py:133] step: 7650, training_loss: 1.31590e-01
I0215 22:20:08.792414 22839682574144 run_lib.py:133] step: 7700, training_loss: 1.28316e-01
I0215 22:20:08.948863 22839682574144 run_lib.py:146] step: 7700, eval_loss: 1.28240e-01
I0215 22:20:26.657573 22839682574144 run_lib.py:133] step: 7750, training_loss: 1.28668e-01
I0215 22:20:44.260658 22839682574144 run_lib.py:133] step: 7800, training_loss: 1.29961e-01
I0215 22:20:44.415959 22839682574144 run_lib.py:146] step: 7800, eval_loss: 1.27493e-01
I0215 22:21:01.865841 22839682574144 run_lib.py:133] step: 7850, training_loss: 1.28108e-01
I0215 22:21:19.366444 22839682574144 run_lib.py:133] step: 7900, training_loss: 1.33307e-01
I0215 22:21:19.522131 22839682574144 run_lib.py:146] step: 7900, eval_loss: 1.32975e-01
I0215 22:21:37.229799 22839682574144 run_lib.py:133] step: 7950, training_loss: 1.30668e-01
I0215 22:21:54.777375 22839682574144 run_lib.py:133] step: 8000, training_loss: 1.35452e-01
I0215 22:21:54.934144 22839682574144 run_lib.py:146] step: 8000, eval_loss: 1.30093e-01
I0215 22:22:12.418629 22839682574144 run_lib.py:133] step: 8050, training_loss: 1.33364e-01
I0215 22:22:30.128975 22839682574144 run_lib.py:133] step: 8100, training_loss: 1.33095e-01
I0215 22:22:30.286097 22839682574144 run_lib.py:146] step: 8100, eval_loss: 1.26443e-01
I0215 22:22:47.776445 22839682574144 run_lib.py:133] step: 8150, training_loss: 1.28100e-01
I0215 22:23:05.445590 22839682574144 run_lib.py:133] step: 8200, training_loss: 1.30162e-01
I0215 22:23:05.601637 22839682574144 run_lib.py:146] step: 8200, eval_loss: 1.28111e-01
I0215 22:23:23.138501 22839682574144 run_lib.py:133] step: 8250, training_loss: 1.29670e-01
I0215 22:23:40.654151 22839682574144 run_lib.py:133] step: 8300, training_loss: 1.30401e-01
I0215 22:23:40.810285 22839682574144 run_lib.py:146] step: 8300, eval_loss: 1.30985e-01
I0215 22:23:58.527542 22839682574144 run_lib.py:133] step: 8350, training_loss: 1.33852e-01
I0215 22:24:16.088007 22839682574144 run_lib.py:133] step: 8400, training_loss: 1.29742e-01
I0215 22:24:16.245023 22839682574144 run_lib.py:146] step: 8400, eval_loss: 1.30601e-01
I0215 22:24:33.762483 22839682574144 run_lib.py:133] step: 8450, training_loss: 1.31764e-01
I0215 22:24:51.427339 22839682574144 run_lib.py:133] step: 8500, training_loss: 1.30028e-01
I0215 22:24:51.585986 22839682574144 run_lib.py:146] step: 8500, eval_loss: 1.27143e-01
I0215 22:25:09.115885 22839682574144 run_lib.py:133] step: 8550, training_loss: 1.30051e-01
I0215 22:25:26.668335 22839682574144 run_lib.py:133] step: 8600, training_loss: 1.32208e-01
I0215 22:25:26.826615 22839682574144 run_lib.py:146] step: 8600, eval_loss: 1.30824e-01
I0215 22:25:44.490377 22839682574144 run_lib.py:133] step: 8650, training_loss: 1.35332e-01
I0215 22:26:02.003644 22839682574144 run_lib.py:133] step: 8700, training_loss: 1.29196e-01
I0215 22:26:02.167015 22839682574144 run_lib.py:146] step: 8700, eval_loss: 1.27277e-01
I0215 22:26:19.688231 22839682574144 run_lib.py:133] step: 8750, training_loss: 1.35192e-01
I0215 22:26:37.194620 22839682574144 run_lib.py:133] step: 8800, training_loss: 1.33034e-01
I0215 22:26:37.351229 22839682574144 run_lib.py:146] step: 8800, eval_loss: 1.29701e-01
I0215 22:26:55.063691 22839682574144 run_lib.py:133] step: 8850, training_loss: 1.30270e-01
I0215 22:27:12.735824 22839682574144 run_lib.py:133] step: 8900, training_loss: 1.29996e-01
I0215 22:27:12.893997 22839682574144 run_lib.py:146] step: 8900, eval_loss: 1.26561e-01
I0215 22:27:30.375064 22839682574144 run_lib.py:133] step: 8950, training_loss: 1.31094e-01
I0215 22:27:47.880043 22839682574144 run_lib.py:133] step: 9000, training_loss: 1.26594e-01
I0215 22:27:48.047507 22839682574144 run_lib.py:146] step: 9000, eval_loss: 1.24737e-01
I0215 22:28:05.748895 22839682574144 run_lib.py:133] step: 9050, training_loss: 1.26085e-01
I0215 22:28:23.309964 22839682574144 run_lib.py:133] step: 9100, training_loss: 1.28570e-01
I0215 22:28:23.479253 22839682574144 run_lib.py:146] step: 9100, eval_loss: 1.32798e-01
I0215 22:28:41.042109 22839682574144 run_lib.py:133] step: 9150, training_loss: 1.28623e-01
I0215 22:28:58.761699 22839682574144 run_lib.py:133] step: 9200, training_loss: 1.27856e-01
I0215 22:28:58.916706 22839682574144 run_lib.py:146] step: 9200, eval_loss: 1.28556e-01
I0215 22:29:16.436660 22839682574144 run_lib.py:133] step: 9250, training_loss: 1.28179e-01
I0215 22:29:34.078683 22839682574144 run_lib.py:133] step: 9300, training_loss: 1.25194e-01
I0215 22:29:34.234043 22839682574144 run_lib.py:146] step: 9300, eval_loss: 1.29660e-01
I0215 22:29:51.723825 22839682574144 run_lib.py:133] step: 9350, training_loss: 1.27272e-01
I0215 22:30:09.249174 22839682574144 run_lib.py:133] step: 9400, training_loss: 1.30933e-01
I0215 22:30:09.431044 22839682574144 run_lib.py:146] step: 9400, eval_loss: 1.28346e-01
I0215 22:30:27.160432 22839682574144 run_lib.py:133] step: 9450, training_loss: 1.26720e-01
I0215 22:30:44.694359 22839682574144 run_lib.py:133] step: 9500, training_loss: 1.33212e-01
I0215 22:30:44.850240 22839682574144 run_lib.py:146] step: 9500, eval_loss: 1.24043e-01
I0215 22:31:02.391641 22839682574144 run_lib.py:133] step: 9550, training_loss: 1.27980e-01
I0215 22:31:20.030594 22839682574144 run_lib.py:133] step: 9600, training_loss: 1.31108e-01
I0215 22:31:20.187999 22839682574144 run_lib.py:146] step: 9600, eval_loss: 1.26352e-01
I0215 22:31:37.682955 22839682574144 run_lib.py:133] step: 9650, training_loss: 1.29115e-01
I0215 22:31:55.214324 22839682574144 run_lib.py:133] step: 9700, training_loss: 1.26641e-01
I0215 22:31:55.377546 22839682574144 run_lib.py:146] step: 9700, eval_loss: 1.23888e-01
I0215 22:32:13.036512 22839682574144 run_lib.py:133] step: 9750, training_loss: 1.27255e-01
I0215 22:32:30.507342 22839682574144 run_lib.py:133] step: 9800, training_loss: 1.32815e-01
I0215 22:32:30.665027 22839682574144 run_lib.py:146] step: 9800, eval_loss: 1.28419e-01
I0215 22:32:48.187783 22839682574144 run_lib.py:133] step: 9850, training_loss: 1.32346e-01
I0215 22:33:05.686367 22839682574144 run_lib.py:133] step: 9900, training_loss: 1.27432e-01
I0215 22:33:05.843269 22839682574144 run_lib.py:146] step: 9900, eval_loss: 1.28955e-01
I0215 22:33:23.495991 22839682574144 run_lib.py:133] step: 9950, training_loss: 1.30467e-01
I0215 22:33:41.136249 22839682574144 run_lib.py:133] step: 10000, training_loss: 1.24828e-01
I0215 22:33:41.892206 22839682574144 run_lib.py:146] step: 10000, eval_loss: 1.28064e-01
I0215 22:34:02.256916 22839682574144 run_lib.py:133] step: 10050, training_loss: 1.26282e-01
I0215 22:34:19.858859 22839682574144 run_lib.py:133] step: 10100, training_loss: 1.29688e-01
I0215 22:34:20.016157 22839682574144 run_lib.py:146] step: 10100, eval_loss: 1.23020e-01
I0215 22:34:37.521369 22839682574144 run_lib.py:133] step: 10150, training_loss: 1.29190e-01
I0215 22:34:55.018583 22839682574144 run_lib.py:133] step: 10200, training_loss: 1.27977e-01
I0215 22:34:55.175949 22839682574144 run_lib.py:146] step: 10200, eval_loss: 1.24706e-01
I0215 22:35:12.863991 22839682574144 run_lib.py:133] step: 10250, training_loss: 1.36581e-01
I0215 22:35:30.403810 22839682574144 run_lib.py:133] step: 10300, training_loss: 1.30356e-01
I0215 22:35:30.561288 22839682574144 run_lib.py:146] step: 10300, eval_loss: 1.26738e-01
I0215 22:35:48.342853 22839682574144 run_lib.py:133] step: 10350, training_loss: 1.32454e-01
I0215 22:36:05.814767 22839682574144 run_lib.py:133] step: 10400, training_loss: 1.29924e-01
I0215 22:36:05.972079 22839682574144 run_lib.py:146] step: 10400, eval_loss: 1.32050e-01
I0215 22:36:23.616593 22839682574144 run_lib.py:133] step: 10450, training_loss: 1.30303e-01
I0215 22:36:41.109126 22839682574144 run_lib.py:133] step: 10500, training_loss: 1.31179e-01
I0215 22:36:41.268301 22839682574144 run_lib.py:146] step: 10500, eval_loss: 1.25919e-01
I0215 22:36:58.789762 22839682574144 run_lib.py:133] step: 10550, training_loss: 1.23068e-01
I0215 22:37:16.342525 22839682574144 run_lib.py:133] step: 10600, training_loss: 1.29535e-01
I0215 22:37:16.501267 22839682574144 run_lib.py:146] step: 10600, eval_loss: 1.25829e-01
I0215 22:37:34.218572 22839682574144 run_lib.py:133] step: 10650, training_loss: 1.28923e-01
I0215 22:37:51.929814 22839682574144 run_lib.py:133] step: 10700, training_loss: 1.25780e-01
I0215 22:37:52.085962 22839682574144 run_lib.py:146] step: 10700, eval_loss: 1.27030e-01
I0215 22:38:09.574905 22839682574144 run_lib.py:133] step: 10750, training_loss: 1.26192e-01
I0215 22:38:27.072911 22839682574144 run_lib.py:133] step: 10800, training_loss: 1.26531e-01
I0215 22:38:27.227185 22839682574144 run_lib.py:146] step: 10800, eval_loss: 1.32774e-01
I0215 22:38:44.765704 22839682574144 run_lib.py:133] step: 10850, training_loss: 1.31407e-01
I0215 22:39:02.488179 22839682574144 run_lib.py:133] step: 10900, training_loss: 1.29900e-01
I0215 22:39:02.648014 22839682574144 run_lib.py:146] step: 10900, eval_loss: 1.25666e-01
I0215 22:39:20.146510 22839682574144 run_lib.py:133] step: 10950, training_loss: 1.29500e-01
I0215 22:39:37.700177 22839682574144 run_lib.py:133] step: 11000, training_loss: 1.33098e-01
I0215 22:39:37.857016 22839682574144 run_lib.py:146] step: 11000, eval_loss: 1.22863e-01
I0215 22:39:55.364312 22839682574144 run_lib.py:133] step: 11050, training_loss: 1.27261e-01
I0215 22:40:13.095536 22839682574144 run_lib.py:133] step: 11100, training_loss: 1.28920e-01
I0215 22:40:13.254375 22839682574144 run_lib.py:146] step: 11100, eval_loss: 1.24695e-01
I0215 22:40:30.762127 22839682574144 run_lib.py:133] step: 11150, training_loss: 1.30919e-01
I0215 22:40:48.379622 22839682574144 run_lib.py:133] step: 11200, training_loss: 1.32622e-01
I0215 22:40:48.534734 22839682574144 run_lib.py:146] step: 11200, eval_loss: 1.24910e-01
I0215 22:41:06.025327 22839682574144 run_lib.py:133] step: 11250, training_loss: 1.30115e-01
I0215 22:41:23.519922 22839682574144 run_lib.py:133] step: 11300, training_loss: 1.30132e-01
I0215 22:41:23.676037 22839682574144 run_lib.py:146] step: 11300, eval_loss: 1.24045e-01
I0215 22:41:41.365823 22839682574144 run_lib.py:133] step: 11350, training_loss: 1.28071e-01
I0215 22:41:58.904089 22839682574144 run_lib.py:133] step: 11400, training_loss: 1.25068e-01
I0215 22:41:59.080890 22839682574144 run_lib.py:146] step: 11400, eval_loss: 1.27946e-01
I0215 22:42:16.778035 22839682574144 run_lib.py:133] step: 11450, training_loss: 1.30399e-01
I0215 22:42:34.311679 22839682574144 run_lib.py:133] step: 11500, training_loss: 1.30016e-01
I0215 22:42:34.469139 22839682574144 run_lib.py:146] step: 11500, eval_loss: 1.29280e-01
I0215 22:42:52.180927 22839682574144 run_lib.py:133] step: 11550, training_loss: 1.25523e-01
I0215 22:43:09.680744 22839682574144 run_lib.py:133] step: 11600, training_loss: 1.26353e-01
I0215 22:43:09.843170 22839682574144 run_lib.py:146] step: 11600, eval_loss: 1.26904e-01
I0215 22:43:27.322659 22839682574144 run_lib.py:133] step: 11650, training_loss: 1.29950e-01
I0215 22:43:44.864629 22839682574144 run_lib.py:133] step: 11700, training_loss: 1.26185e-01
I0215 22:43:45.022295 22839682574144 run_lib.py:146] step: 11700, eval_loss: 1.27116e-01
I0215 22:44:02.765348 22839682574144 run_lib.py:133] step: 11750, training_loss: 1.27752e-01
I0215 22:44:20.462876 22839682574144 run_lib.py:133] step: 11800, training_loss: 1.26064e-01
I0215 22:44:20.621094 22839682574144 run_lib.py:146] step: 11800, eval_loss: 1.27235e-01
I0215 22:44:38.152642 22839682574144 run_lib.py:133] step: 11850, training_loss: 1.24995e-01
I0215 22:44:55.731336 22839682574144 run_lib.py:133] step: 11900, training_loss: 1.24288e-01
I0215 22:44:55.900491 22839682574144 run_lib.py:146] step: 11900, eval_loss: 1.24992e-01
I0215 22:45:13.441308 22839682574144 run_lib.py:133] step: 11950, training_loss: 1.26632e-01
I0215 22:45:31.176121 22839682574144 run_lib.py:133] step: 12000, training_loss: 1.26157e-01
I0215 22:45:31.335098 22839682574144 run_lib.py:146] step: 12000, eval_loss: 1.28922e-01
I0215 22:45:48.846976 22839682574144 run_lib.py:133] step: 12050, training_loss: 1.32317e-01
I0215 22:46:06.368469 22839682574144 run_lib.py:133] step: 12100, training_loss: 1.27470e-01
I0215 22:46:06.532801 22839682574144 run_lib.py:146] step: 12100, eval_loss: 1.27912e-01
I0215 22:46:24.064824 22839682574144 run_lib.py:133] step: 12150, training_loss: 1.27506e-01
I0215 22:46:41.762226 22839682574144 run_lib.py:133] step: 12200, training_loss: 1.24454e-01
I0215 22:46:41.916346 22839682574144 run_lib.py:146] step: 12200, eval_loss: 1.29761e-01
I0215 22:46:59.445348 22839682574144 run_lib.py:133] step: 12250, training_loss: 1.30054e-01
I0215 22:47:17.117433 22839682574144 run_lib.py:133] step: 12300, training_loss: 1.28445e-01
I0215 22:47:17.304924 22839682574144 run_lib.py:146] step: 12300, eval_loss: 1.28966e-01
I0215 22:47:34.650679 22839682574144 run_lib.py:133] step: 12350, training_loss: 1.27387e-01
I0215 22:47:51.906400 22839682574144 run_lib.py:133] step: 12400, training_loss: 1.28290e-01
I0215 22:47:52.067888 22839682574144 run_lib.py:146] step: 12400, eval_loss: 1.26701e-01
I0215 22:48:09.529198 22839682574144 run_lib.py:133] step: 12450, training_loss: 1.30094e-01
I0215 22:48:26.842996 22839682574144 run_lib.py:133] step: 12500, training_loss: 1.23440e-01
I0215 22:48:26.995985 22839682574144 run_lib.py:146] step: 12500, eval_loss: 1.27188e-01
I0215 22:48:44.457534 22839682574144 run_lib.py:133] step: 12550, training_loss: 1.29164e-01
I0215 22:49:01.982776 22839682574144 run_lib.py:133] step: 12600, training_loss: 1.28125e-01
I0215 22:49:02.170327 22839682574144 run_lib.py:146] step: 12600, eval_loss: 1.26740e-01
I0215 22:49:19.914996 22839682574144 run_lib.py:133] step: 12650, training_loss: 1.29751e-01
I0215 22:49:37.451615 22839682574144 run_lib.py:133] step: 12700, training_loss: 1.26367e-01
I0215 22:49:37.606980 22839682574144 run_lib.py:146] step: 12700, eval_loss: 1.24403e-01
I0215 22:49:55.126670 22839682574144 run_lib.py:133] step: 12750, training_loss: 1.29085e-01
I0215 22:50:12.650012 22839682574144 run_lib.py:133] step: 12800, training_loss: 1.23529e-01
I0215 22:50:12.825434 22839682574144 run_lib.py:146] step: 12800, eval_loss: 1.29846e-01
I0215 22:50:30.542532 22839682574144 run_lib.py:133] step: 12850, training_loss: 1.31355e-01
I0215 22:50:48.269591 22839682574144 run_lib.py:133] step: 12900, training_loss: 1.28998e-01
I0215 22:50:48.427506 22839682574144 run_lib.py:146] step: 12900, eval_loss: 1.29424e-01
I0215 22:51:05.922764 22839682574144 run_lib.py:133] step: 12950, training_loss: 1.28319e-01
I0215 22:51:23.466956 22839682574144 run_lib.py:133] step: 13000, training_loss: 1.29627e-01
I0215 22:51:23.624967 22839682574144 run_lib.py:146] step: 13000, eval_loss: 1.22427e-01
I0215 22:51:41.133972 22839682574144 run_lib.py:133] step: 13050, training_loss: 1.28147e-01
I0215 22:51:58.814779 22839682574144 run_lib.py:133] step: 13100, training_loss: 1.26978e-01
I0215 22:51:58.979305 22839682574144 run_lib.py:146] step: 13100, eval_loss: 1.31383e-01
I0215 22:52:16.536276 22839682574144 run_lib.py:133] step: 13150, training_loss: 1.24695e-01
I0215 22:52:34.067437 22839682574144 run_lib.py:133] step: 13200, training_loss: 1.24716e-01
I0215 22:52:34.225110 22839682574144 run_lib.py:146] step: 13200, eval_loss: 1.27090e-01
I0215 22:52:51.722277 22839682574144 run_lib.py:133] step: 13250, training_loss: 1.19969e-01
I0215 22:53:09.449175 22839682574144 run_lib.py:133] step: 13300, training_loss: 1.27174e-01
I0215 22:53:09.612139 22839682574144 run_lib.py:146] step: 13300, eval_loss: 1.34112e-01
I0215 22:53:27.082516 22839682574144 run_lib.py:133] step: 13350, training_loss: 1.26760e-01
I0215 22:53:44.724728 22839682574144 run_lib.py:133] step: 13400, training_loss: 1.30139e-01
I0215 22:53:44.893262 22839682574144 run_lib.py:146] step: 13400, eval_loss: 1.25308e-01
I0215 22:54:02.448159 22839682574144 run_lib.py:133] step: 13450, training_loss: 1.28802e-01
I0215 22:54:19.994489 22839682574144 run_lib.py:133] step: 13500, training_loss: 1.23779e-01
I0215 22:54:20.171650 22839682574144 run_lib.py:146] step: 13500, eval_loss: 1.24974e-01
I0215 22:54:37.901089 22839682574144 run_lib.py:133] step: 13550, training_loss: 1.23780e-01
I0215 22:54:55.419029 22839682574144 run_lib.py:133] step: 13600, training_loss: 1.28953e-01
I0215 22:54:55.572978 22839682574144 run_lib.py:146] step: 13600, eval_loss: 1.24386e-01
I0215 22:55:13.233611 22839682574144 run_lib.py:133] step: 13650, training_loss: 1.26298e-01
I0215 22:55:30.765689 22839682574144 run_lib.py:133] step: 13700, training_loss: 1.29025e-01
I0215 22:55:30.934260 22839682574144 run_lib.py:146] step: 13700, eval_loss: 1.25506e-01
I0215 22:55:48.656860 22839682574144 run_lib.py:133] step: 13750, training_loss: 1.23420e-01
I0215 22:56:06.183229 22839682574144 run_lib.py:133] step: 13800, training_loss: 1.25087e-01
I0215 22:56:06.367216 22839682574144 run_lib.py:146] step: 13800, eval_loss: 1.30860e-01
I0215 22:56:23.899226 22839682574144 run_lib.py:133] step: 13850, training_loss: 1.25985e-01
I0215 22:56:41.430363 22839682574144 run_lib.py:133] step: 13900, training_loss: 1.25475e-01
I0215 22:56:41.587891 22839682574144 run_lib.py:146] step: 13900, eval_loss: 1.27086e-01
I0215 22:56:59.285400 22839682574144 run_lib.py:133] step: 13950, training_loss: 1.27202e-01
I0215 22:57:17.037038 22839682574144 run_lib.py:133] step: 14000, training_loss: 1.25151e-01
I0215 22:57:17.202497 22839682574144 run_lib.py:146] step: 14000, eval_loss: 1.25746e-01
I0215 22:57:34.734373 22839682574144 run_lib.py:133] step: 14050, training_loss: 1.26019e-01
I0215 22:57:52.219292 22839682574144 run_lib.py:133] step: 14100, training_loss: 1.27474e-01
I0215 22:57:52.374044 22839682574144 run_lib.py:146] step: 14100, eval_loss: 1.22916e-01
I0215 22:58:09.861248 22839682574144 run_lib.py:133] step: 14150, training_loss: 1.31697e-01
I0215 22:58:27.546697 22839682574144 run_lib.py:133] step: 14200, training_loss: 1.22914e-01
I0215 22:58:27.712926 22839682574144 run_lib.py:146] step: 14200, eval_loss: 1.28802e-01
I0215 22:58:45.253267 22839682574144 run_lib.py:133] step: 14250, training_loss: 1.29744e-01
I0215 22:59:02.756773 22839682574144 run_lib.py:133] step: 14300, training_loss: 1.27441e-01
I0215 22:59:02.915182 22839682574144 run_lib.py:146] step: 14300, eval_loss: 1.28840e-01
I0215 22:59:20.446214 22839682574144 run_lib.py:133] step: 14350, training_loss: 1.28706e-01
I0215 22:59:38.202293 22839682574144 run_lib.py:133] step: 14400, training_loss: 1.24511e-01
I0215 22:59:38.360045 22839682574144 run_lib.py:146] step: 14400, eval_loss: 1.21034e-01
I0215 22:59:55.884463 22839682574144 run_lib.py:133] step: 14450, training_loss: 1.29365e-01
I0215 23:00:13.463974 22839682574144 run_lib.py:133] step: 14500, training_loss: 1.27348e-01
I0215 23:00:13.619672 22839682574144 run_lib.py:146] step: 14500, eval_loss: 1.28703e-01
I0215 23:00:31.134232 22839682574144 run_lib.py:133] step: 14550, training_loss: 1.28518e-01
I0215 23:00:48.655220 22839682574144 run_lib.py:133] step: 14600, training_loss: 1.28415e-01
I0215 23:00:48.821235 22839682574144 run_lib.py:146] step: 14600, eval_loss: 1.26899e-01
I0215 23:01:06.557358 22839682574144 run_lib.py:133] step: 14650, training_loss: 1.23215e-01
I0215 23:01:24.075639 22839682574144 run_lib.py:133] step: 14700, training_loss: 1.24962e-01
I0215 23:01:24.234819 22839682574144 run_lib.py:146] step: 14700, eval_loss: 1.25139e-01
I0215 23:01:41.876729 22839682574144 run_lib.py:133] step: 14750, training_loss: 1.29076e-01
I0215 23:01:59.381783 22839682574144 run_lib.py:133] step: 14800, training_loss: 1.29233e-01
I0215 23:01:59.556057 22839682574144 run_lib.py:146] step: 14800, eval_loss: 1.25804e-01
I0215 23:02:17.309702 22839682574144 run_lib.py:133] step: 14850, training_loss: 1.27548e-01
I0215 23:02:34.829131 22839682574144 run_lib.py:133] step: 14900, training_loss: 1.29255e-01
I0215 23:02:34.987291 22839682574144 run_lib.py:146] step: 14900, eval_loss: 1.32397e-01
I0215 23:02:52.510525 22839682574144 run_lib.py:133] step: 14950, training_loss: 1.26974e-01
I0215 23:03:10.025679 22839682574144 run_lib.py:133] step: 15000, training_loss: 1.28497e-01
I0215 23:03:10.179746 22839682574144 run_lib.py:146] step: 15000, eval_loss: 1.26636e-01
I0215 23:03:27.886073 22839682574144 run_lib.py:133] step: 15050, training_loss: 1.30647e-01
I0215 23:03:45.625608 22839682574144 run_lib.py:133] step: 15100, training_loss: 1.25097e-01
I0215 23:03:45.810268 22839682574144 run_lib.py:146] step: 15100, eval_loss: 1.30844e-01
I0215 23:04:03.372338 22839682574144 run_lib.py:133] step: 15150, training_loss: 1.25478e-01
I0215 23:04:20.921835 22839682574144 run_lib.py:133] step: 15200, training_loss: 1.28729e-01
I0215 23:04:21.106177 22839682574144 run_lib.py:146] step: 15200, eval_loss: 1.23941e-01
I0215 23:04:38.628099 22839682574144 run_lib.py:133] step: 15250, training_loss: 1.25208e-01
I0215 23:04:56.336985 22839682574144 run_lib.py:133] step: 15300, training_loss: 1.26804e-01
I0215 23:04:56.524980 22839682574144 run_lib.py:146] step: 15300, eval_loss: 1.27434e-01
I0215 23:05:14.054532 22839682574144 run_lib.py:133] step: 15350, training_loss: 1.27708e-01
I0215 23:05:31.601730 22839682574144 run_lib.py:133] step: 15400, training_loss: 1.22003e-01
I0215 23:05:31.758776 22839682574144 run_lib.py:146] step: 15400, eval_loss: 1.28653e-01
I0215 23:05:49.274685 22839682574144 run_lib.py:133] step: 15450, training_loss: 1.25711e-01
I0215 23:06:06.963315 22839682574144 run_lib.py:133] step: 15500, training_loss: 1.26504e-01
I0215 23:06:07.118014 22839682574144 run_lib.py:146] step: 15500, eval_loss: 1.27773e-01
I0215 23:06:24.618486 22839682574144 run_lib.py:133] step: 15550, training_loss: 1.28447e-01
I0215 23:06:42.201033 22839682574144 run_lib.py:133] step: 15600, training_loss: 1.23332e-01
I0215 23:06:42.359011 22839682574144 run_lib.py:146] step: 15600, eval_loss: 1.28302e-01
I0215 23:06:59.881867 22839682574144 run_lib.py:133] step: 15650, training_loss: 1.28343e-01
I0215 23:07:17.401824 22839682574144 run_lib.py:133] step: 15700, training_loss: 1.26589e-01
I0215 23:07:17.562055 22839682574144 run_lib.py:146] step: 15700, eval_loss: 1.22872e-01
I0215 23:07:35.275235 22839682574144 run_lib.py:133] step: 15750, training_loss: 1.28783e-01
I0215 23:07:52.767864 22839682574144 run_lib.py:133] step: 15800, training_loss: 1.23707e-01
I0215 23:07:52.925793 22839682574144 run_lib.py:146] step: 15800, eval_loss: 1.25737e-01
I0215 23:08:10.595956 22839682574144 run_lib.py:133] step: 15850, training_loss: 1.22681e-01
I0215 23:08:28.113217 22839682574144 run_lib.py:133] step: 15900, training_loss: 1.25959e-01
I0215 23:08:28.273106 22839682574144 run_lib.py:146] step: 15900, eval_loss: 1.23780e-01
I0215 23:08:45.980228 22839682574144 run_lib.py:133] step: 15950, training_loss: 1.26867e-01
I0215 23:09:03.523437 22839682574144 run_lib.py:133] step: 16000, training_loss: 1.25595e-01
I0215 23:09:03.682346 22839682574144 run_lib.py:146] step: 16000, eval_loss: 1.24042e-01
I0215 23:09:21.207186 22839682574144 run_lib.py:133] step: 16050, training_loss: 1.27802e-01
I0215 23:09:38.720772 22839682574144 run_lib.py:133] step: 16100, training_loss: 1.24492e-01
I0215 23:09:38.878345 22839682574144 run_lib.py:146] step: 16100, eval_loss: 1.28896e-01
I0215 23:09:56.595014 22839682574144 run_lib.py:133] step: 16150, training_loss: 1.27450e-01
I0215 23:10:14.328180 22839682574144 run_lib.py:133] step: 16200, training_loss: 1.28285e-01
I0215 23:10:14.498126 22839682574144 run_lib.py:146] step: 16200, eval_loss: 1.26710e-01
I0215 23:10:32.007949 22839682574144 run_lib.py:133] step: 16250, training_loss: 1.26277e-01
I0215 23:10:49.526582 22839682574144 run_lib.py:133] step: 16300, training_loss: 1.28421e-01
I0215 23:10:49.683803 22839682574144 run_lib.py:146] step: 16300, eval_loss: 1.25094e-01
I0215 23:11:07.216711 22839682574144 run_lib.py:133] step: 16350, training_loss: 1.23778e-01
I0215 23:11:24.922593 22839682574144 run_lib.py:133] step: 16400, training_loss: 1.27033e-01
I0215 23:11:25.077021 22839682574144 run_lib.py:146] step: 16400, eval_loss: 1.25382e-01
I0215 23:11:42.605025 22839682574144 run_lib.py:133] step: 16450, training_loss: 1.25202e-01
I0215 23:12:00.114220 22839682574144 run_lib.py:133] step: 16500, training_loss: 1.26138e-01
I0215 23:12:00.274313 22839682574144 run_lib.py:146] step: 16500, eval_loss: 1.25016e-01
I0215 23:12:17.801241 22839682574144 run_lib.py:133] step: 16550, training_loss: 1.24943e-01
I0215 23:12:35.550635 22839682574144 run_lib.py:133] step: 16600, training_loss: 1.29390e-01
I0215 23:12:35.709088 22839682574144 run_lib.py:146] step: 16600, eval_loss: 1.24958e-01
I0215 23:12:53.229742 22839682574144 run_lib.py:133] step: 16650, training_loss: 1.26684e-01
I0215 23:13:10.844889 22839682574144 run_lib.py:133] step: 16700, training_loss: 1.29809e-01
I0215 23:13:11.040057 22839682574144 run_lib.py:146] step: 16700, eval_loss: 1.28652e-01
I0215 23:13:28.559689 22839682574144 run_lib.py:133] step: 16750, training_loss: 1.24906e-01
I0215 23:13:46.141986 22839682574144 run_lib.py:133] step: 16800, training_loss: 1.27131e-01
I0215 23:13:46.299463 22839682574144 run_lib.py:146] step: 16800, eval_loss: 1.22677e-01
I0215 23:14:03.997486 22839682574144 run_lib.py:133] step: 16850, training_loss: 1.24603e-01
I0215 23:14:21.531694 22839682574144 run_lib.py:133] step: 16900, training_loss: 1.24819e-01
I0215 23:14:21.685875 22839682574144 run_lib.py:146] step: 16900, eval_loss: 1.28113e-01
I0215 23:14:39.404626 22839682574144 run_lib.py:133] step: 16950, training_loss: 1.23480e-01
I0215 23:14:56.937538 22839682574144 run_lib.py:133] step: 17000, training_loss: 1.26472e-01
I0215 23:14:57.104267 22839682574144 run_lib.py:146] step: 17000, eval_loss: 1.23902e-01
I0215 23:15:14.854921 22839682574144 run_lib.py:133] step: 17050, training_loss: 1.27688e-01
I0215 23:15:32.409471 22839682574144 run_lib.py:133] step: 17100, training_loss: 1.26215e-01
I0215 23:15:32.568124 22839682574144 run_lib.py:146] step: 17100, eval_loss: 1.25872e-01
I0215 23:15:50.095833 22839682574144 run_lib.py:133] step: 17150, training_loss: 1.27968e-01
I0215 23:16:07.625628 22839682574144 run_lib.py:133] step: 17200, training_loss: 1.32188e-01
I0215 23:16:07.780302 22839682574144 run_lib.py:146] step: 17200, eval_loss: 1.27538e-01
I0215 23:16:25.473381 22839682574144 run_lib.py:133] step: 17250, training_loss: 1.29120e-01
I0215 23:16:43.211516 22839682574144 run_lib.py:133] step: 17300, training_loss: 1.26307e-01
I0215 23:16:43.372176 22839682574144 run_lib.py:146] step: 17300, eval_loss: 1.23651e-01
I0215 23:17:00.932079 22839682574144 run_lib.py:133] step: 17350, training_loss: 1.27600e-01
I0215 23:17:18.432115 22839682574144 run_lib.py:133] step: 17400, training_loss: 1.26686e-01
I0215 23:17:18.587125 22839682574144 run_lib.py:146] step: 17400, eval_loss: 1.27420e-01
I0215 23:17:36.111198 22839682574144 run_lib.py:133] step: 17450, training_loss: 1.25601e-01
I0215 23:17:53.789412 22839682574144 run_lib.py:133] step: 17500, training_loss: 1.25543e-01
I0215 23:17:53.947076 22839682574144 run_lib.py:146] step: 17500, eval_loss: 1.26985e-01
I0215 23:18:11.551278 22839682574144 run_lib.py:133] step: 17550, training_loss: 1.23835e-01
I0215 23:18:29.077851 22839682574144 run_lib.py:133] step: 17600, training_loss: 1.26882e-01
I0215 23:18:29.236963 22839682574144 run_lib.py:146] step: 17600, eval_loss: 1.28974e-01
I0215 23:18:46.740266 22839682574144 run_lib.py:133] step: 17650, training_loss: 1.24914e-01
I0215 23:19:04.491795 22839682574144 run_lib.py:133] step: 17700, training_loss: 1.25462e-01
I0215 23:19:04.648722 22839682574144 run_lib.py:146] step: 17700, eval_loss: 1.29415e-01
I0215 23:19:22.160873 22839682574144 run_lib.py:133] step: 17750, training_loss: 1.22847e-01
I0215 23:19:39.746520 22839682574144 run_lib.py:133] step: 17800, training_loss: 1.23855e-01
I0215 23:19:39.904128 22839682574144 run_lib.py:146] step: 17800, eval_loss: 1.27226e-01
I0215 23:19:57.440820 22839682574144 run_lib.py:133] step: 17850, training_loss: 1.26214e-01
I0215 23:20:14.961169 22839682574144 run_lib.py:133] step: 17900, training_loss: 1.26732e-01
I0215 23:20:15.119209 22839682574144 run_lib.py:146] step: 17900, eval_loss: 1.24658e-01
I0215 23:20:32.892463 22839682574144 run_lib.py:133] step: 17950, training_loss: 1.25155e-01
I0215 23:20:50.426228 22839682574144 run_lib.py:133] step: 18000, training_loss: 1.24110e-01
I0215 23:20:50.587221 22839682574144 run_lib.py:146] step: 18000, eval_loss: 1.25019e-01
I0215 23:21:08.267771 22839682574144 run_lib.py:133] step: 18050, training_loss: 1.27234e-01
I0215 23:21:25.760755 22839682574144 run_lib.py:133] step: 18100, training_loss: 1.26978e-01
I0215 23:21:25.934108 22839682574144 run_lib.py:146] step: 18100, eval_loss: 1.26476e-01
I0215 23:21:43.649800 22839682574144 run_lib.py:133] step: 18150, training_loss: 1.25853e-01
I0215 23:22:01.165915 22839682574144 run_lib.py:133] step: 18200, training_loss: 1.24556e-01
I0215 23:22:01.332585 22839682574144 run_lib.py:146] step: 18200, eval_loss: 1.24399e-01
I0215 23:22:18.843951 22839682574144 run_lib.py:133] step: 18250, training_loss: 1.30067e-01
I0215 23:22:36.422245 22839682574144 run_lib.py:133] step: 18300, training_loss: 1.24858e-01
I0215 23:22:36.578015 22839682574144 run_lib.py:146] step: 18300, eval_loss: 1.20082e-01
I0215 23:22:54.336056 22839682574144 run_lib.py:133] step: 18350, training_loss: 1.25923e-01
I0215 23:23:12.042521 22839682574144 run_lib.py:133] step: 18400, training_loss: 1.28993e-01
I0215 23:23:12.207479 22839682574144 run_lib.py:146] step: 18400, eval_loss: 1.23496e-01
I0215 23:23:29.727286 22839682574144 run_lib.py:133] step: 18450, training_loss: 1.22320e-01
I0215 23:23:47.239227 22839682574144 run_lib.py:133] step: 18500, training_loss: 1.27547e-01
I0215 23:23:47.398015 22839682574144 run_lib.py:146] step: 18500, eval_loss: 1.25129e-01
I0215 23:24:04.922048 22839682574144 run_lib.py:133] step: 18550, training_loss: 1.25198e-01
I0215 23:24:22.669261 22839682574144 run_lib.py:133] step: 18600, training_loss: 1.28139e-01
I0215 23:24:22.826043 22839682574144 run_lib.py:146] step: 18600, eval_loss: 1.22254e-01
I0215 23:24:40.355852 22839682574144 run_lib.py:133] step: 18650, training_loss: 1.24561e-01
I0215 23:24:57.912536 22839682574144 run_lib.py:133] step: 18700, training_loss: 1.27298e-01
I0215 23:24:58.070836 22839682574144 run_lib.py:146] step: 18700, eval_loss: 1.25529e-01
I0215 23:25:15.659689 22839682574144 run_lib.py:133] step: 18750, training_loss: 1.26343e-01
I0215 23:25:33.362463 22839682574144 run_lib.py:133] step: 18800, training_loss: 1.24885e-01
I0215 23:25:33.517047 22839682574144 run_lib.py:146] step: 18800, eval_loss: 1.26755e-01
I0215 23:25:51.041863 22839682574144 run_lib.py:133] step: 18850, training_loss: 1.29513e-01
I0215 23:26:08.655995 22839682574144 run_lib.py:133] step: 18900, training_loss: 1.26398e-01
I0215 23:26:08.812941 22839682574144 run_lib.py:146] step: 18900, eval_loss: 1.27857e-01
I0215 23:26:26.360009 22839682574144 run_lib.py:133] step: 18950, training_loss: 1.22352e-01
I0215 23:26:43.887755 22839682574144 run_lib.py:133] step: 19000, training_loss: 1.24460e-01
I0215 23:26:44.047149 22839682574144 run_lib.py:146] step: 19000, eval_loss: 1.25688e-01
I0215 23:27:01.748607 22839682574144 run_lib.py:133] step: 19050, training_loss: 1.25183e-01
I0215 23:27:19.271763 22839682574144 run_lib.py:133] step: 19100, training_loss: 1.28457e-01
I0215 23:27:19.428045 22839682574144 run_lib.py:146] step: 19100, eval_loss: 1.26699e-01
I0215 23:27:37.122351 22839682574144 run_lib.py:133] step: 19150, training_loss: 1.28281e-01
I0215 23:27:54.676230 22839682574144 run_lib.py:133] step: 19200, training_loss: 1.22912e-01
I0215 23:27:54.837247 22839682574144 run_lib.py:146] step: 19200, eval_loss: 1.28828e-01
I0215 23:28:12.572166 22839682574144 run_lib.py:133] step: 19250, training_loss: 1.27142e-01
I0215 23:28:30.088158 22839682574144 run_lib.py:133] step: 19300, training_loss: 1.23498e-01
I0215 23:28:30.242009 22839682574144 run_lib.py:146] step: 19300, eval_loss: 1.25183e-01
I0215 23:28:47.747384 22839682574144 run_lib.py:133] step: 19350, training_loss: 1.22661e-01
I0215 23:29:05.280366 22839682574144 run_lib.py:133] step: 19400, training_loss: 1.27741e-01
I0215 23:29:05.438042 22839682574144 run_lib.py:146] step: 19400, eval_loss: 1.24049e-01
I0215 23:29:23.139273 22839682574144 run_lib.py:133] step: 19450, training_loss: 1.29545e-01
I0215 23:29:40.871095 22839682574144 run_lib.py:133] step: 19500, training_loss: 1.20478e-01
I0215 23:29:41.044959 22839682574144 run_lib.py:146] step: 19500, eval_loss: 1.29567e-01
I0215 23:29:58.549234 22839682574144 run_lib.py:133] step: 19550, training_loss: 1.29856e-01
I0215 23:30:16.083806 22839682574144 run_lib.py:133] step: 19600, training_loss: 1.24177e-01
I0215 23:30:16.241286 22839682574144 run_lib.py:146] step: 19600, eval_loss: 1.28952e-01
I0215 23:30:33.761569 22839682574144 run_lib.py:133] step: 19650, training_loss: 1.24493e-01
I0215 23:30:51.514847 22839682574144 run_lib.py:133] step: 19700, training_loss: 1.28295e-01
I0215 23:30:51.672179 22839682574144 run_lib.py:146] step: 19700, eval_loss: 1.28782e-01
I0215 23:31:09.199404 22839682574144 run_lib.py:133] step: 19750, training_loss: 1.24073e-01
I0215 23:31:26.760014 22839682574144 run_lib.py:133] step: 19800, training_loss: 1.30566e-01
I0215 23:31:26.917096 22839682574144 run_lib.py:146] step: 19800, eval_loss: 1.25392e-01
I0215 23:31:44.447905 22839682574144 run_lib.py:133] step: 19850, training_loss: 1.25745e-01
I0215 23:32:02.176063 22839682574144 run_lib.py:133] step: 19900, training_loss: 1.22678e-01
I0215 23:32:02.344398 22839682574144 run_lib.py:146] step: 19900, eval_loss: 1.21186e-01
I0215 23:32:19.820813 22839682574144 run_lib.py:133] step: 19950, training_loss: 1.23851e-01
I0215 23:32:37.388860 22839682574144 run_lib.py:133] step: 20000, training_loss: 1.22912e-01
I0215 23:32:38.165198 22839682574144 run_lib.py:146] step: 20000, eval_loss: 1.23650e-01
I0215 23:32:58.375653 22839682574144 run_lib.py:133] step: 20050, training_loss: 1.25962e-01
I0215 23:33:15.958361 22839682574144 run_lib.py:133] step: 20100, training_loss: 1.28436e-01
I0215 23:33:16.116317 22839682574144 run_lib.py:146] step: 20100, eval_loss: 1.25075e-01
I0215 23:33:33.599230 22839682574144 run_lib.py:133] step: 20150, training_loss: 1.25872e-01
I0215 23:33:51.318819 22839682574144 run_lib.py:133] step: 20200, training_loss: 1.24451e-01
I0215 23:33:51.476158 22839682574144 run_lib.py:146] step: 20200, eval_loss: 1.26073e-01
I0215 23:34:09.096882 22839682574144 run_lib.py:133] step: 20250, training_loss: 1.25019e-01
I0215 23:34:26.670527 22839682574144 run_lib.py:133] step: 20300, training_loss: 1.27764e-01
I0215 23:34:26.836302 22839682574144 run_lib.py:146] step: 20300, eval_loss: 1.27907e-01
I0215 23:34:44.376664 22839682574144 run_lib.py:133] step: 20350, training_loss: 1.28093e-01
I0215 23:35:01.933349 22839682574144 run_lib.py:133] step: 20400, training_loss: 1.22854e-01
I0215 23:35:02.091026 22839682574144 run_lib.py:146] step: 20400, eval_loss: 1.23829e-01
I0215 23:35:19.830002 22839682574144 run_lib.py:133] step: 20450, training_loss: 1.31284e-01
I0215 23:35:37.463145 22839682574144 run_lib.py:133] step: 20500, training_loss: 1.24663e-01
I0215 23:35:37.631057 22839682574144 run_lib.py:146] step: 20500, eval_loss: 1.25227e-01
I0215 23:35:55.117878 22839682574144 run_lib.py:133] step: 20550, training_loss: 1.24163e-01
I0215 23:36:12.683481 22839682574144 run_lib.py:133] step: 20600, training_loss: 1.23421e-01
I0215 23:36:12.841216 22839682574144 run_lib.py:146] step: 20600, eval_loss: 1.26573e-01
I0215 23:36:30.546870 22839682574144 run_lib.py:133] step: 20650, training_loss: 1.23338e-01
I0215 23:36:48.073247 22839682574144 run_lib.py:133] step: 20700, training_loss: 1.24593e-01
I0215 23:36:48.230172 22839682574144 run_lib.py:146] step: 20700, eval_loss: 1.26688e-01
I0215 23:37:05.744819 22839682574144 run_lib.py:133] step: 20750, training_loss: 1.25597e-01
I0215 23:37:23.449135 22839682574144 run_lib.py:133] step: 20800, training_loss: 1.23833e-01
I0215 23:37:23.603091 22839682574144 run_lib.py:146] step: 20800, eval_loss: 1.26541e-01
I0215 23:37:41.099369 22839682574144 run_lib.py:133] step: 20850, training_loss: 1.22605e-01
I0215 23:37:58.786470 22839682574144 run_lib.py:133] step: 20900, training_loss: 1.22417e-01
I0215 23:37:58.955263 22839682574144 run_lib.py:146] step: 20900, eval_loss: 1.26646e-01
I0215 23:38:16.493684 22839682574144 run_lib.py:133] step: 20950, training_loss: 1.22945e-01
I0215 23:38:34.045362 22839682574144 run_lib.py:133] step: 21000, training_loss: 1.28469e-01
I0215 23:38:34.205173 22839682574144 run_lib.py:146] step: 21000, eval_loss: 1.27672e-01
I0215 23:38:51.927529 22839682574144 run_lib.py:133] step: 21050, training_loss: 1.24039e-01
I0215 23:39:09.408867 22839682574144 run_lib.py:133] step: 21100, training_loss: 1.21296e-01
I0215 23:39:09.567215 22839682574144 run_lib.py:146] step: 21100, eval_loss: 1.29122e-01
I0215 23:39:27.090353 22839682574144 run_lib.py:133] step: 21150, training_loss: 1.26791e-01
I0215 23:39:44.646875 22839682574144 run_lib.py:133] step: 21200, training_loss: 1.20965e-01
I0215 23:39:44.803807 22839682574144 run_lib.py:146] step: 21200, eval_loss: 1.27277e-01
I0215 23:40:02.595098 22839682574144 run_lib.py:133] step: 21250, training_loss: 1.22378e-01
I0215 23:40:20.090341 22839682574144 run_lib.py:133] step: 21300, training_loss: 1.21115e-01
I0215 23:40:20.247106 22839682574144 run_lib.py:146] step: 21300, eval_loss: 1.24163e-01
I0215 23:40:37.824842 22839682574144 run_lib.py:133] step: 21350, training_loss: 1.22619e-01
I0215 23:40:55.319829 22839682574144 run_lib.py:133] step: 21400, training_loss: 1.24200e-01
I0215 23:40:55.483062 22839682574144 run_lib.py:146] step: 21400, eval_loss: 1.25114e-01
I0215 23:41:13.040647 22839682574144 run_lib.py:133] step: 21450, training_loss: 1.26360e-01
I0215 23:41:30.562648 22839682574144 run_lib.py:133] step: 21500, training_loss: 1.27519e-01
I0215 23:41:30.728910 22839682574144 run_lib.py:146] step: 21500, eval_loss: 1.26504e-01
I0215 23:41:48.432445 22839682574144 run_lib.py:133] step: 21550, training_loss: 1.27299e-01
I0215 23:42:06.056261 22839682574144 run_lib.py:133] step: 21600, training_loss: 1.25814e-01
I0215 23:42:06.214052 22839682574144 run_lib.py:146] step: 21600, eval_loss: 1.24922e-01
I0215 23:42:23.705198 22839682574144 run_lib.py:133] step: 21650, training_loss: 1.20952e-01
I0215 23:42:41.254779 22839682574144 run_lib.py:133] step: 21700, training_loss: 1.25282e-01
I0215 23:42:41.411430 22839682574144 run_lib.py:146] step: 21700, eval_loss: 1.25732e-01
I0215 23:42:59.179260 22839682574144 run_lib.py:133] step: 21750, training_loss: 1.24674e-01
I0215 23:43:16.710172 22839682574144 run_lib.py:133] step: 21800, training_loss: 1.20473e-01
I0215 23:43:16.869354 22839682574144 run_lib.py:146] step: 21800, eval_loss: 1.27774e-01
I0215 23:43:34.395471 22839682574144 run_lib.py:133] step: 21850, training_loss: 1.27614e-01
I0215 23:43:52.084548 22839682574144 run_lib.py:133] step: 21900, training_loss: 1.26611e-01
I0215 23:43:52.244387 22839682574144 run_lib.py:146] step: 21900, eval_loss: 1.28941e-01
I0215 23:44:09.760960 22839682574144 run_lib.py:133] step: 21950, training_loss: 1.22275e-01
I0215 23:44:27.477618 22839682574144 run_lib.py:133] step: 22000, training_loss: 1.25960e-01
I0215 23:44:27.632911 22839682574144 run_lib.py:146] step: 22000, eval_loss: 1.28665e-01
I0215 23:44:45.126960 22839682574144 run_lib.py:133] step: 22050, training_loss: 1.27722e-01
I0215 23:45:02.663858 22839682574144 run_lib.py:133] step: 22100, training_loss: 1.27587e-01
I0215 23:45:02.821033 22839682574144 run_lib.py:146] step: 22100, eval_loss: 1.22748e-01
I0215 23:45:20.553699 22839682574144 run_lib.py:133] step: 22150, training_loss: 1.22883e-01
I0215 23:45:38.087020 22839682574144 run_lib.py:133] step: 22200, training_loss: 1.26340e-01
I0215 23:45:38.243224 22839682574144 run_lib.py:146] step: 22200, eval_loss: 1.26974e-01
I0215 23:45:55.814521 22839682574144 run_lib.py:133] step: 22250, training_loss: 1.27314e-01
I0215 23:46:13.527168 22839682574144 run_lib.py:133] step: 22300, training_loss: 1.23096e-01
I0215 23:46:13.684436 22839682574144 run_lib.py:146] step: 22300, eval_loss: 1.27603e-01
I0215 23:46:31.190864 22839682574144 run_lib.py:133] step: 22350, training_loss: 1.22099e-01
I0215 23:46:48.708075 22839682574144 run_lib.py:133] step: 22400, training_loss: 1.22790e-01
I0215 23:46:48.867236 22839682574144 run_lib.py:146] step: 22400, eval_loss: 1.25004e-01
I0215 23:47:06.463688 22839682574144 run_lib.py:133] step: 22450, training_loss: 1.23877e-01
I0215 23:47:24.004825 22839682574144 run_lib.py:133] step: 22500, training_loss: 1.22055e-01
I0215 23:47:24.163082 22839682574144 run_lib.py:146] step: 22500, eval_loss: 1.25395e-01
I0215 23:47:41.681520 22839682574144 run_lib.py:133] step: 22550, training_loss: 1.21153e-01
I0215 23:47:59.261398 22839682574144 run_lib.py:133] step: 22600, training_loss: 1.23330e-01
I0215 23:47:59.419294 22839682574144 run_lib.py:146] step: 22600, eval_loss: 1.24086e-01
I0215 23:48:17.168022 22839682574144 run_lib.py:133] step: 22650, training_loss: 1.19375e-01
I0215 23:48:34.776409 22839682574144 run_lib.py:133] step: 22700, training_loss: 1.24806e-01
I0215 23:48:34.935966 22839682574144 run_lib.py:146] step: 22700, eval_loss: 1.26814e-01
I0215 23:48:52.447102 22839682574144 run_lib.py:133] step: 22750, training_loss: 1.25187e-01
I0215 23:49:09.969069 22839682574144 run_lib.py:133] step: 22800, training_loss: 1.24858e-01
I0215 23:49:10.142427 22839682574144 run_lib.py:146] step: 22800, eval_loss: 1.23864e-01
I0215 23:49:27.932567 22839682574144 run_lib.py:133] step: 22850, training_loss: 1.27895e-01
I0215 23:49:45.462966 22839682574144 run_lib.py:133] step: 22900, training_loss: 1.25672e-01
I0215 23:49:45.620957 22839682574144 run_lib.py:146] step: 22900, eval_loss: 1.26996e-01
I0215 23:50:03.123128 22839682574144 run_lib.py:133] step: 22950, training_loss: 1.20033e-01
I0215 23:50:20.868330 22839682574144 run_lib.py:133] step: 23000, training_loss: 1.29692e-01
I0215 23:50:21.026242 22839682574144 run_lib.py:146] step: 23000, eval_loss: 1.23591e-01
I0215 23:50:38.573114 22839682574144 run_lib.py:133] step: 23050, training_loss: 1.19495e-01
I0215 23:50:56.278712 22839682574144 run_lib.py:133] step: 23100, training_loss: 1.23677e-01
I0215 23:50:56.441094 22839682574144 run_lib.py:146] step: 23100, eval_loss: 1.28906e-01
I0215 23:51:13.963653 22839682574144 run_lib.py:133] step: 23150, training_loss: 1.25684e-01
I0215 23:51:31.514880 22839682574144 run_lib.py:133] step: 23200, training_loss: 1.22792e-01
I0215 23:51:31.671074 22839682574144 run_lib.py:146] step: 23200, eval_loss: 1.23102e-01
I0215 23:51:49.401738 22839682574144 run_lib.py:133] step: 23250, training_loss: 1.27133e-01
I0215 23:52:06.940906 22839682574144 run_lib.py:133] step: 23300, training_loss: 1.22246e-01
I0215 23:52:07.102339 22839682574144 run_lib.py:146] step: 23300, eval_loss: 1.24058e-01
I0215 23:52:24.621420 22839682574144 run_lib.py:133] step: 23350, training_loss: 1.22591e-01
I0215 23:52:42.386329 22839682574144 run_lib.py:133] step: 23400, training_loss: 1.24221e-01
I0215 23:52:42.546314 22839682574144 run_lib.py:146] step: 23400, eval_loss: 1.27399e-01
I0215 23:53:00.048808 22839682574144 run_lib.py:133] step: 23450, training_loss: 1.20865e-01
I0215 23:53:17.572792 22839682574144 run_lib.py:133] step: 23500, training_loss: 1.23938e-01
I0215 23:53:17.730257 22839682574144 run_lib.py:146] step: 23500, eval_loss: 1.25611e-01
I0215 23:53:35.356178 22839682574144 run_lib.py:133] step: 23550, training_loss: 1.22648e-01
I0215 23:53:52.855848 22839682574144 run_lib.py:133] step: 23600, training_loss: 1.18951e-01
I0215 23:53:53.009943 22839682574144 run_lib.py:146] step: 23600, eval_loss: 1.21163e-01
I0215 23:54:10.570683 22839682574144 run_lib.py:133] step: 23650, training_loss: 1.23387e-01
I0215 23:54:28.092007 22839682574144 run_lib.py:133] step: 23700, training_loss: 1.24931e-01
I0215 23:54:28.253223 22839682574144 run_lib.py:146] step: 23700, eval_loss: 1.29172e-01
I0215 23:54:45.966475 22839682574144 run_lib.py:133] step: 23750, training_loss: 1.21995e-01
I0215 23:55:03.583072 22839682574144 run_lib.py:133] step: 23800, training_loss: 1.28740e-01
I0215 23:55:03.742347 22839682574144 run_lib.py:146] step: 23800, eval_loss: 1.22861e-01
I0215 23:55:21.244521 22839682574144 run_lib.py:133] step: 23850, training_loss: 1.24098e-01
I0215 23:55:38.816390 22839682574144 run_lib.py:133] step: 23900, training_loss: 1.20271e-01
I0215 23:55:38.981313 22839682574144 run_lib.py:146] step: 23900, eval_loss: 1.21130e-01
I0215 23:55:56.714979 22839682574144 run_lib.py:133] step: 23950, training_loss: 1.27419e-01
I0215 23:56:14.238763 22839682574144 run_lib.py:133] step: 24000, training_loss: 1.23481e-01
I0215 23:56:14.396244 22839682574144 run_lib.py:146] step: 24000, eval_loss: 1.27967e-01
I0215 23:56:31.922505 22839682574144 run_lib.py:133] step: 24050, training_loss: 1.25048e-01
I0215 23:56:49.600026 22839682574144 run_lib.py:133] step: 24100, training_loss: 1.19352e-01
I0215 23:56:49.753221 22839682574144 run_lib.py:146] step: 24100, eval_loss: 1.27561e-01
I0215 23:57:07.231780 22839682574144 run_lib.py:133] step: 24150, training_loss: 1.27035e-01
I0215 23:57:24.913152 22839682574144 run_lib.py:133] step: 24200, training_loss: 1.22596e-01
I0215 23:57:25.082227 22839682574144 run_lib.py:146] step: 24200, eval_loss: 1.23709e-01
I0215 23:57:42.611904 22839682574144 run_lib.py:133] step: 24250, training_loss: 1.25317e-01
I0215 23:58:00.124393 22839682574144 run_lib.py:133] step: 24300, training_loss: 1.24596e-01
I0215 23:58:00.283158 22839682574144 run_lib.py:146] step: 24300, eval_loss: 1.28736e-01
I0215 23:58:18.000779 22839682574144 run_lib.py:133] step: 24350, training_loss: 1.26379e-01
I0215 23:58:35.543852 22839682574144 run_lib.py:133] step: 24400, training_loss: 1.23268e-01
I0215 23:58:35.707290 22839682574144 run_lib.py:146] step: 24400, eval_loss: 1.27857e-01
I0215 23:58:53.229547 22839682574144 run_lib.py:133] step: 24450, training_loss: 1.24808e-01
I0215 23:59:10.990113 22839682574144 run_lib.py:133] step: 24500, training_loss: 1.14523e-01
I0215 23:59:11.148187 22839682574144 run_lib.py:146] step: 24500, eval_loss: 1.26214e-01
I0215 23:59:28.690165 22839682574144 run_lib.py:133] step: 24550, training_loss: 1.24154e-01
I0215 23:59:46.174269 22839682574144 run_lib.py:133] step: 24600, training_loss: 1.25470e-01
I0215 23:59:46.337502 22839682574144 run_lib.py:146] step: 24600, eval_loss: 1.26891e-01
I0216 00:00:03.946293 22839682574144 run_lib.py:133] step: 24650, training_loss: 1.25749e-01
I0216 00:00:21.488296 22839682574144 run_lib.py:133] step: 24700, training_loss: 1.19839e-01
I0216 00:00:21.645848 22839682574144 run_lib.py:146] step: 24700, eval_loss: 1.23009e-01
I0216 00:00:39.149849 22839682574144 run_lib.py:133] step: 24750, training_loss: 1.23816e-01
I0216 00:00:56.734157 22839682574144 run_lib.py:133] step: 24800, training_loss: 1.25839e-01
I0216 00:00:56.897119 22839682574144 run_lib.py:146] step: 24800, eval_loss: 1.29003e-01
I0216 00:01:14.643305 22839682574144 run_lib.py:133] step: 24850, training_loss: 1.19623e-01
I0216 00:01:32.218194 22839682574144 run_lib.py:133] step: 24900, training_loss: 1.26053e-01
I0216 00:01:32.378795 22839682574144 run_lib.py:146] step: 24900, eval_loss: 1.27080e-01
I0216 00:01:49.874123 22839682574144 run_lib.py:133] step: 24950, training_loss: 1.28164e-01
I0216 00:02:07.408288 22839682574144 run_lib.py:133] step: 25000, training_loss: 1.22071e-01
I0216 00:02:07.566181 22839682574144 run_lib.py:146] step: 25000, eval_loss: 1.22537e-01
I0216 00:02:25.307106 22839682574144 run_lib.py:133] step: 25050, training_loss: 1.23497e-01
I0216 00:02:42.817471 22839682574144 run_lib.py:133] step: 25100, training_loss: 1.21857e-01
I0216 00:02:42.975230 22839682574144 run_lib.py:146] step: 25100, eval_loss: 1.26724e-01
I0216 00:03:00.500349 22839682574144 run_lib.py:133] step: 25150, training_loss: 1.23393e-01
I0216 00:03:18.266336 22839682574144 run_lib.py:133] step: 25200, training_loss: 1.28108e-01
I0216 00:03:18.426272 22839682574144 run_lib.py:146] step: 25200, eval_loss: 1.27910e-01
I0216 00:03:35.968643 22839682574144 run_lib.py:133] step: 25250, training_loss: 1.22884e-01
I0216 00:03:53.698674 22839682574144 run_lib.py:133] step: 25300, training_loss: 1.20120e-01
I0216 00:03:53.864157 22839682574144 run_lib.py:146] step: 25300, eval_loss: 1.22613e-01
I0216 00:04:11.417858 22839682574144 run_lib.py:133] step: 25350, training_loss: 1.26262e-01
I0216 00:04:28.889169 22839682574144 run_lib.py:133] step: 25400, training_loss: 1.27499e-01
I0216 00:04:29.042919 22839682574144 run_lib.py:146] step: 25400, eval_loss: 1.28577e-01
I0216 00:04:46.693814 22839682574144 run_lib.py:133] step: 25450, training_loss: 1.21677e-01
I0216 00:05:04.236166 22839682574144 run_lib.py:133] step: 25500, training_loss: 1.23061e-01
I0216 00:05:04.393073 22839682574144 run_lib.py:146] step: 25500, eval_loss: 1.28758e-01
I0216 00:05:21.893404 22839682574144 run_lib.py:133] step: 25550, training_loss: 1.22775e-01
I0216 00:05:39.609556 22839682574144 run_lib.py:133] step: 25600, training_loss: 1.21117e-01
I0216 00:05:39.775166 22839682574144 run_lib.py:146] step: 25600, eval_loss: 1.26266e-01
I0216 00:05:57.279304 22839682574144 run_lib.py:133] step: 25650, training_loss: 1.27414e-01
I0216 00:06:14.801322 22839682574144 run_lib.py:133] step: 25700, training_loss: 1.19956e-01
I0216 00:06:15.003076 22839682574144 run_lib.py:146] step: 25700, eval_loss: 1.26914e-01
I0216 00:06:32.626329 22839682574144 run_lib.py:133] step: 25750, training_loss: 1.24698e-01
I0216 00:06:50.141387 22839682574144 run_lib.py:133] step: 25800, training_loss: 1.20722e-01
I0216 00:06:50.300047 22839682574144 run_lib.py:146] step: 25800, eval_loss: 1.25579e-01
I0216 00:07:07.824309 22839682574144 run_lib.py:133] step: 25850, training_loss: 1.19374e-01
I0216 00:07:25.397823 22839682574144 run_lib.py:133] step: 25900, training_loss: 1.25135e-01
I0216 00:07:25.559303 22839682574144 run_lib.py:146] step: 25900, eval_loss: 1.21919e-01
I0216 00:07:43.335150 22839682574144 run_lib.py:133] step: 25950, training_loss: 1.25207e-01
I0216 00:08:00.944718 22839682574144 run_lib.py:133] step: 26000, training_loss: 1.23575e-01
I0216 00:08:01.098115 22839682574144 run_lib.py:146] step: 26000, eval_loss: 1.27922e-01
I0216 00:08:18.583062 22839682574144 run_lib.py:133] step: 26050, training_loss: 1.20334e-01
I0216 00:08:36.087388 22839682574144 run_lib.py:133] step: 26100, training_loss: 1.23111e-01
I0216 00:08:36.253331 22839682574144 run_lib.py:146] step: 26100, eval_loss: 1.20200e-01
I0216 00:08:54.026109 22839682574144 run_lib.py:133] step: 26150, training_loss: 1.20682e-01
I0216 00:09:11.551491 22839682574144 run_lib.py:133] step: 26200, training_loss: 1.24284e-01
I0216 00:09:11.710076 22839682574144 run_lib.py:146] step: 26200, eval_loss: 1.28620e-01
I0216 00:09:29.220857 22839682574144 run_lib.py:133] step: 26250, training_loss: 1.21415e-01
I0216 00:09:46.898148 22839682574144 run_lib.py:133] step: 26300, training_loss: 1.20111e-01
I0216 00:09:47.055921 22839682574144 run_lib.py:146] step: 26300, eval_loss: 1.26331e-01
I0216 00:10:04.595523 22839682574144 run_lib.py:133] step: 26350, training_loss: 1.21132e-01
I0216 00:10:22.347977 22839682574144 run_lib.py:133] step: 26400, training_loss: 1.26887e-01
I0216 00:10:22.523315 22839682574144 run_lib.py:146] step: 26400, eval_loss: 1.25364e-01
I0216 00:10:40.051067 22839682574144 run_lib.py:133] step: 26450, training_loss: 1.16731e-01
I0216 00:10:57.544790 22839682574144 run_lib.py:133] step: 26500, training_loss: 1.22470e-01
I0216 00:10:57.698945 22839682574144 run_lib.py:146] step: 26500, eval_loss: 1.23501e-01
I0216 00:11:15.442939 22839682574144 run_lib.py:133] step: 26550, training_loss: 1.22549e-01
I0216 00:11:32.973516 22839682574144 run_lib.py:133] step: 26600, training_loss: 1.24979e-01
I0216 00:11:33.132056 22839682574144 run_lib.py:146] step: 26600, eval_loss: 1.23348e-01
I0216 00:11:50.623404 22839682574144 run_lib.py:133] step: 26650, training_loss: 1.23741e-01
I0216 00:12:08.410323 22839682574144 run_lib.py:133] step: 26700, training_loss: 1.20841e-01
I0216 00:12:08.570159 22839682574144 run_lib.py:146] step: 26700, eval_loss: 1.26184e-01
I0216 00:12:26.088035 22839682574144 run_lib.py:133] step: 26750, training_loss: 1.21096e-01
I0216 00:12:43.632594 22839682574144 run_lib.py:133] step: 26800, training_loss: 1.26354e-01
I0216 00:12:43.791127 22839682574144 run_lib.py:146] step: 26800, eval_loss: 1.25696e-01
I0216 00:13:01.395432 22839682574144 run_lib.py:133] step: 26850, training_loss: 1.24132e-01
I0216 00:13:18.933222 22839682574144 run_lib.py:133] step: 26900, training_loss: 1.24381e-01
I0216 00:13:19.088796 22839682574144 run_lib.py:146] step: 26900, eval_loss: 1.27862e-01
I0216 00:13:36.686775 22839682574144 run_lib.py:133] step: 26950, training_loss: 1.25256e-01
I0216 00:13:54.239731 22839682574144 run_lib.py:133] step: 27000, training_loss: 1.24827e-01
I0216 00:13:54.403257 22839682574144 run_lib.py:146] step: 27000, eval_loss: 1.24469e-01
I0216 00:14:12.120345 22839682574144 run_lib.py:133] step: 27050, training_loss: 1.21883e-01
I0216 00:14:29.741061 22839682574144 run_lib.py:133] step: 27100, training_loss: 1.20690e-01
I0216 00:14:29.900309 22839682574144 run_lib.py:146] step: 27100, eval_loss: 1.26693e-01
I0216 00:14:47.405699 22839682574144 run_lib.py:133] step: 27150, training_loss: 1.26643e-01
I0216 00:15:04.944954 22839682574144 run_lib.py:133] step: 27200, training_loss: 1.24625e-01
I0216 00:15:05.222032 22839682574144 run_lib.py:146] step: 27200, eval_loss: 1.26534e-01
I0216 00:15:22.931782 22839682574144 run_lib.py:133] step: 27250, training_loss: 1.22267e-01
I0216 00:15:40.440412 22839682574144 run_lib.py:133] step: 27300, training_loss: 1.27301e-01
I0216 00:15:40.604021 22839682574144 run_lib.py:146] step: 27300, eval_loss: 1.29044e-01
I0216 00:15:58.112416 22839682574144 run_lib.py:133] step: 27350, training_loss: 1.19315e-01
I0216 00:16:15.790150 22839682574144 run_lib.py:133] step: 27400, training_loss: 1.23738e-01
I0216 00:16:15.941944 22839682574144 run_lib.py:146] step: 27400, eval_loss: 1.23277e-01
I0216 00:16:33.429890 22839682574144 run_lib.py:133] step: 27450, training_loss: 1.26017e-01
I0216 00:16:51.133456 22839682574144 run_lib.py:133] step: 27500, training_loss: 1.19415e-01
I0216 00:16:51.299259 22839682574144 run_lib.py:146] step: 27500, eval_loss: 1.25163e-01
I0216 00:17:08.820832 22839682574144 run_lib.py:133] step: 27550, training_loss: 1.27688e-01
I0216 00:17:26.327100 22839682574144 run_lib.py:133] step: 27600, training_loss: 1.22767e-01
I0216 00:17:26.486042 22839682574144 run_lib.py:146] step: 27600, eval_loss: 1.26558e-01
I0216 00:17:44.181010 22839682574144 run_lib.py:133] step: 27650, training_loss: 1.20208e-01
I0216 00:18:01.719854 22839682574144 run_lib.py:133] step: 27700, training_loss: 1.23667e-01
I0216 00:18:01.876133 22839682574144 run_lib.py:146] step: 27700, eval_loss: 1.25677e-01
I0216 00:18:19.377924 22839682574144 run_lib.py:133] step: 27750, training_loss: 1.20936e-01
I0216 00:18:37.120166 22839682574144 run_lib.py:133] step: 27800, training_loss: 1.21431e-01
I0216 00:18:37.279350 22839682574144 run_lib.py:146] step: 27800, eval_loss: 1.24061e-01
I0216 00:18:54.808206 22839682574144 run_lib.py:133] step: 27850, training_loss: 1.22196e-01
I0216 00:19:12.332646 22839682574144 run_lib.py:133] step: 27900, training_loss: 1.21083e-01
I0216 00:19:12.487112 22839682574144 run_lib.py:146] step: 27900, eval_loss: 1.27720e-01
I0216 00:19:30.131421 22839682574144 run_lib.py:133] step: 27950, training_loss: 1.24925e-01
I0216 00:19:47.643501 22839682574144 run_lib.py:133] step: 28000, training_loss: 1.22396e-01
I0216 00:19:47.812164 22839682574144 run_lib.py:146] step: 28000, eval_loss: 1.25608e-01
I0216 00:20:05.355177 22839682574144 run_lib.py:133] step: 28050, training_loss: 1.17908e-01
I0216 00:20:22.938666 22839682574144 run_lib.py:133] step: 28100, training_loss: 1.24093e-01
I0216 00:20:23.098021 22839682574144 run_lib.py:146] step: 28100, eval_loss: 1.27495e-01
I0216 00:20:40.810408 22839682574144 run_lib.py:133] step: 28150, training_loss: 1.25013e-01
I0216 00:20:58.407359 22839682574144 run_lib.py:133] step: 28200, training_loss: 1.24278e-01
I0216 00:20:58.564874 22839682574144 run_lib.py:146] step: 28200, eval_loss: 1.26016e-01
I0216 00:21:16.059667 22839682574144 run_lib.py:133] step: 28250, training_loss: 1.18446e-01
I0216 00:21:33.375982 22839682574144 run_lib.py:133] step: 28300, training_loss: 1.26732e-01
I0216 00:21:33.529004 22839682574144 run_lib.py:146] step: 28300, eval_loss: 1.23491e-01
I0216 00:21:50.983816 22839682574144 run_lib.py:133] step: 28350, training_loss: 1.19820e-01
I0216 00:22:08.247713 22839682574144 run_lib.py:133] step: 28400, training_loss: 1.24693e-01
I0216 00:22:08.399785 22839682574144 run_lib.py:146] step: 28400, eval_loss: 1.25214e-01
I0216 00:22:25.719094 22839682574144 run_lib.py:133] step: 28450, training_loss: 1.21190e-01
I0216 00:22:43.279467 22839682574144 run_lib.py:133] step: 28500, training_loss: 1.23447e-01
I0216 00:22:43.437406 22839682574144 run_lib.py:146] step: 28500, eval_loss: 1.32932e-01
I0216 00:23:00.913689 22839682574144 run_lib.py:133] step: 28550, training_loss: 1.24841e-01
I0216 00:23:18.621479 22839682574144 run_lib.py:133] step: 28600, training_loss: 1.24712e-01
I0216 00:23:18.792090 22839682574144 run_lib.py:146] step: 28600, eval_loss: 1.24605e-01
I0216 00:23:36.314791 22839682574144 run_lib.py:133] step: 28650, training_loss: 1.26939e-01
I0216 00:23:53.818902 22839682574144 run_lib.py:133] step: 28700, training_loss: 1.24693e-01
I0216 00:23:53.992070 22839682574144 run_lib.py:146] step: 28700, eval_loss: 1.28209e-01
I0216 00:24:11.697202 22839682574144 run_lib.py:133] step: 28750, training_loss: 1.20867e-01
I0216 00:24:29.190437 22839682574144 run_lib.py:133] step: 28800, training_loss: 1.27257e-01
I0216 00:24:29.344750 22839682574144 run_lib.py:146] step: 28800, eval_loss: 1.25567e-01
I0216 00:24:46.831410 22839682574144 run_lib.py:133] step: 28850, training_loss: 1.24784e-01
I0216 00:25:04.566450 22839682574144 run_lib.py:133] step: 28900, training_loss: 1.23966e-01
I0216 00:25:04.729459 22839682574144 run_lib.py:146] step: 28900, eval_loss: 1.26970e-01
I0216 00:25:22.308630 22839682574144 run_lib.py:133] step: 28950, training_loss: 1.18915e-01
I0216 00:25:39.877072 22839682574144 run_lib.py:133] step: 29000, training_loss: 1.22068e-01
I0216 00:25:40.036353 22839682574144 run_lib.py:146] step: 29000, eval_loss: 1.23676e-01
I0216 00:25:57.659941 22839682574144 run_lib.py:133] step: 29050, training_loss: 1.21597e-01
I0216 00:26:15.193067 22839682574144 run_lib.py:133] step: 29100, training_loss: 1.24207e-01
I0216 00:26:15.350125 22839682574144 run_lib.py:146] step: 29100, eval_loss: 1.24986e-01
I0216 00:26:32.875380 22839682574144 run_lib.py:133] step: 29150, training_loss: 1.20341e-01
I0216 00:26:50.452660 22839682574144 run_lib.py:133] step: 29200, training_loss: 1.20132e-01
I0216 00:26:50.613546 22839682574144 run_lib.py:146] step: 29200, eval_loss: 1.26284e-01
I0216 00:27:08.363268 22839682574144 run_lib.py:133] step: 29250, training_loss: 1.18854e-01
I0216 00:27:25.989101 22839682574144 run_lib.py:133] step: 29300, training_loss: 1.21553e-01
I0216 00:27:26.142195 22839682574144 run_lib.py:146] step: 29300, eval_loss: 1.23901e-01
I0216 00:27:43.623626 22839682574144 run_lib.py:133] step: 29350, training_loss: 1.22609e-01
I0216 00:28:01.136415 22839682574144 run_lib.py:133] step: 29400, training_loss: 1.18829e-01
I0216 00:28:01.293042 22839682574144 run_lib.py:146] step: 29400, eval_loss: 1.25389e-01
I0216 00:28:19.034381 22839682574144 run_lib.py:133] step: 29450, training_loss: 1.23584e-01
I0216 00:28:36.563591 22839682574144 run_lib.py:133] step: 29500, training_loss: 1.21166e-01
I0216 00:28:36.724182 22839682574144 run_lib.py:146] step: 29500, eval_loss: 1.26813e-01
I0216 00:28:54.248252 22839682574144 run_lib.py:133] step: 29550, training_loss: 1.17233e-01
I0216 00:29:11.963373 22839682574144 run_lib.py:133] step: 29600, training_loss: 1.18473e-01
I0216 00:29:12.131902 22839682574144 run_lib.py:146] step: 29600, eval_loss: 1.24035e-01
I0216 00:29:29.626334 22839682574144 run_lib.py:133] step: 29650, training_loss: 1.24876e-01
I0216 00:29:47.325214 22839682574144 run_lib.py:133] step: 29700, training_loss: 1.21915e-01
I0216 00:29:47.482052 22839682574144 run_lib.py:146] step: 29700, eval_loss: 1.26292e-01
I0216 00:30:05.003117 22839682574144 run_lib.py:133] step: 29750, training_loss: 1.25493e-01
I0216 00:30:22.541630 22839682574144 run_lib.py:133] step: 29800, training_loss: 1.25315e-01
I0216 00:30:22.703257 22839682574144 run_lib.py:146] step: 29800, eval_loss: 1.27557e-01
I0216 00:30:40.482438 22839682574144 run_lib.py:133] step: 29850, training_loss: 1.19679e-01
I0216 00:30:58.019035 22839682574144 run_lib.py:133] step: 29900, training_loss: 1.25862e-01
I0216 00:30:58.237088 22839682574144 run_lib.py:146] step: 29900, eval_loss: 1.27177e-01
I0216 00:31:15.686221 22839682574144 run_lib.py:133] step: 29950, training_loss: 1.24118e-01
I0216 00:31:33.362514 22839682574144 run_lib.py:133] step: 30000, training_loss: 1.21530e-01
I0216 00:31:34.157975 22839682574144 run_lib.py:146] step: 30000, eval_loss: 1.27828e-01
I0216 00:31:54.423681 22839682574144 run_lib.py:133] step: 30050, training_loss: 1.22660e-01
I0216 00:32:11.951411 22839682574144 run_lib.py:133] step: 30100, training_loss: 1.20268e-01
I0216 00:32:12.111029 22839682574144 run_lib.py:146] step: 30100, eval_loss: 1.26749e-01
I0216 00:32:29.639014 22839682574144 run_lib.py:133] step: 30150, training_loss: 1.21983e-01
I0216 00:32:47.390670 22839682574144 run_lib.py:133] step: 30200, training_loss: 1.23909e-01
I0216 00:32:47.546456 22839682574144 run_lib.py:146] step: 30200, eval_loss: 1.20808e-01
I0216 00:33:05.055958 22839682574144 run_lib.py:133] step: 30250, training_loss: 1.21586e-01
I0216 00:33:22.570499 22839682574144 run_lib.py:133] step: 30300, training_loss: 1.22391e-01
I0216 00:33:22.726210 22839682574144 run_lib.py:146] step: 30300, eval_loss: 1.25710e-01
I0216 00:33:40.482283 22839682574144 run_lib.py:133] step: 30350, training_loss: 1.16845e-01
I0216 00:33:57.977833 22839682574144 run_lib.py:133] step: 30400, training_loss: 1.21005e-01
I0216 00:33:58.134109 22839682574144 run_lib.py:146] step: 30400, eval_loss: 1.23220e-01
I0216 00:34:15.726565 22839682574144 run_lib.py:133] step: 30450, training_loss: 1.20855e-01
I0216 00:34:33.240320 22839682574144 run_lib.py:133] step: 30500, training_loss: 1.20678e-01
I0216 00:34:33.408083 22839682574144 run_lib.py:146] step: 30500, eval_loss: 1.21142e-01
I0216 00:34:50.875823 22839682574144 run_lib.py:133] step: 30550, training_loss: 1.24820e-01
I0216 00:35:08.463224 22839682574144 run_lib.py:133] step: 30600, training_loss: 1.21375e-01
I0216 00:35:08.630483 22839682574144 run_lib.py:146] step: 30600, eval_loss: 1.25789e-01
I0216 00:35:26.358846 22839682574144 run_lib.py:133] step: 30650, training_loss: 1.20135e-01
I0216 00:35:43.989442 22839682574144 run_lib.py:133] step: 30700, training_loss: 1.24194e-01
I0216 00:35:44.146829 22839682574144 run_lib.py:146] step: 30700, eval_loss: 1.28624e-01
I0216 00:36:01.651748 22839682574144 run_lib.py:133] step: 30750, training_loss: 1.17760e-01
I0216 00:36:19.167325 22839682574144 run_lib.py:133] step: 30800, training_loss: 1.22871e-01
I0216 00:36:19.321756 22839682574144 run_lib.py:146] step: 30800, eval_loss: 1.27232e-01
I0216 00:36:37.028104 22839682574144 run_lib.py:133] step: 30850, training_loss: 1.25239e-01
I0216 00:36:54.563785 22839682574144 run_lib.py:133] step: 30900, training_loss: 1.23430e-01
I0216 00:36:54.735351 22839682574144 run_lib.py:146] step: 30900, eval_loss: 1.26120e-01
I0216 00:37:12.264052 22839682574144 run_lib.py:133] step: 30950, training_loss: 1.21598e-01
I0216 00:37:29.994519 22839682574144 run_lib.py:133] step: 31000, training_loss: 1.22052e-01
I0216 00:37:30.153508 22839682574144 run_lib.py:146] step: 31000, eval_loss: 1.24139e-01
I0216 00:37:47.646803 22839682574144 run_lib.py:133] step: 31050, training_loss: 1.27073e-01
I0216 00:38:05.279893 22839682574144 run_lib.py:133] step: 31100, training_loss: 1.23101e-01
I0216 00:38:05.437110 22839682574144 run_lib.py:146] step: 31100, eval_loss: 1.30760e-01
I0216 00:38:22.934040 22839682574144 run_lib.py:133] step: 31150, training_loss: 1.25040e-01
I0216 00:38:40.478926 22839682574144 run_lib.py:133] step: 31200, training_loss: 1.25399e-01
I0216 00:38:40.636410 22839682574144 run_lib.py:146] step: 31200, eval_loss: 1.28124e-01
I0216 00:38:58.430904 22839682574144 run_lib.py:133] step: 31250, training_loss: 1.21525e-01
I0216 00:39:15.914616 22839682574144 run_lib.py:133] step: 31300, training_loss: 1.21316e-01
I0216 00:39:16.074124 22839682574144 run_lib.py:146] step: 31300, eval_loss: 1.28127e-01
I0216 00:39:33.597788 22839682574144 run_lib.py:133] step: 31350, training_loss: 1.25729e-01
I0216 00:39:51.138734 22839682574144 run_lib.py:133] step: 31400, training_loss: 1.24058e-01
I0216 00:39:51.295981 22839682574144 run_lib.py:146] step: 31400, eval_loss: 1.22752e-01
I0216 00:40:08.999529 22839682574144 run_lib.py:133] step: 31450, training_loss: 1.21036e-01
I0216 00:40:26.535198 22839682574144 run_lib.py:133] step: 31500, training_loss: 1.24596e-01
I0216 00:40:26.700245 22839682574144 run_lib.py:146] step: 31500, eval_loss: 1.22747e-01
I0216 00:40:44.356556 22839682574144 run_lib.py:133] step: 31550, training_loss: 1.22104e-01
I0216 00:41:01.884408 22839682574144 run_lib.py:133] step: 31600, training_loss: 1.21273e-01
I0216 00:41:02.039299 22839682574144 run_lib.py:146] step: 31600, eval_loss: 1.24999e-01
I0216 00:41:19.555389 22839682574144 run_lib.py:133] step: 31650, training_loss: 1.20871e-01
I0216 00:41:37.070531 22839682574144 run_lib.py:133] step: 31700, training_loss: 1.22630e-01
I0216 00:41:37.237041 22839682574144 run_lib.py:146] step: 31700, eval_loss: 1.26324e-01
I0216 00:41:54.973215 22839682574144 run_lib.py:133] step: 31750, training_loss: 1.20245e-01
I0216 00:42:12.594429 22839682574144 run_lib.py:133] step: 31800, training_loss: 1.25395e-01
I0216 00:42:12.748996 22839682574144 run_lib.py:146] step: 31800, eval_loss: 1.25992e-01
I0216 00:42:30.224302 22839682574144 run_lib.py:133] step: 31850, training_loss: 1.23516e-01
I0216 00:42:47.737829 22839682574144 run_lib.py:133] step: 31900, training_loss: 1.29992e-01
I0216 00:42:47.900559 22839682574144 run_lib.py:146] step: 31900, eval_loss: 1.26744e-01
I0216 00:43:05.595139 22839682574144 run_lib.py:133] step: 31950, training_loss: 1.24107e-01
I0216 00:43:23.143271 22839682574144 run_lib.py:133] step: 32000, training_loss: 1.20326e-01
I0216 00:43:23.309999 22839682574144 run_lib.py:146] step: 32000, eval_loss: 1.23923e-01
I0216 00:43:40.856709 22839682574144 run_lib.py:133] step: 32050, training_loss: 1.22942e-01
I0216 00:43:58.629595 22839682574144 run_lib.py:133] step: 32100, training_loss: 1.25044e-01
I0216 00:43:58.786961 22839682574144 run_lib.py:146] step: 32100, eval_loss: 1.27043e-01
I0216 00:44:16.313383 22839682574144 run_lib.py:133] step: 32150, training_loss: 1.20264e-01
I0216 00:44:33.966937 22839682574144 run_lib.py:133] step: 32200, training_loss: 1.21630e-01
I0216 00:44:34.120766 22839682574144 run_lib.py:146] step: 32200, eval_loss: 1.27138e-01
I0216 00:44:51.658793 22839682574144 run_lib.py:133] step: 32250, training_loss: 1.21744e-01
I0216 00:45:09.225450 22839682574144 run_lib.py:133] step: 32300, training_loss: 1.26124e-01
I0216 00:45:09.393195 22839682574144 run_lib.py:146] step: 32300, eval_loss: 1.25483e-01
I0216 00:45:27.143319 22839682574144 run_lib.py:133] step: 32350, training_loss: 1.19231e-01
I0216 00:45:44.669698 22839682574144 run_lib.py:133] step: 32400, training_loss: 1.17547e-01
I0216 00:45:44.828277 22839682574144 run_lib.py:146] step: 32400, eval_loss: 1.22622e-01
I0216 00:46:02.328282 22839682574144 run_lib.py:133] step: 32450, training_loss: 1.22286e-01
I0216 00:46:19.991392 22839682574144 run_lib.py:133] step: 32500, training_loss: 1.22159e-01
I0216 00:46:20.149146 22839682574144 run_lib.py:146] step: 32500, eval_loss: 1.27423e-01
I0216 00:46:37.646264 22839682574144 run_lib.py:133] step: 32550, training_loss: 1.23337e-01
I0216 00:46:55.198195 22839682574144 run_lib.py:133] step: 32600, training_loss: 1.21714e-01
I0216 00:46:55.355353 22839682574144 run_lib.py:146] step: 32600, eval_loss: 1.21822e-01
I0216 00:47:12.973886 22839682574144 run_lib.py:133] step: 32650, training_loss: 1.28740e-01
I0216 00:47:30.514862 22839682574144 run_lib.py:133] step: 32700, training_loss: 1.19867e-01
I0216 00:47:30.669019 22839682574144 run_lib.py:146] step: 32700, eval_loss: 1.28161e-01
I0216 00:47:48.168236 22839682574144 run_lib.py:133] step: 32750, training_loss: 1.21579e-01
I0216 00:48:05.682266 22839682574144 run_lib.py:133] step: 32800, training_loss: 1.20277e-01
I0216 00:48:05.839474 22839682574144 run_lib.py:146] step: 32800, eval_loss: 1.27982e-01
I0216 00:48:23.517556 22839682574144 run_lib.py:133] step: 32850, training_loss: 1.18049e-01
I0216 00:48:41.147109 22839682574144 run_lib.py:133] step: 32900, training_loss: 1.22912e-01
I0216 00:48:41.305987 22839682574144 run_lib.py:146] step: 32900, eval_loss: 1.29377e-01
I0216 00:48:58.810947 22839682574144 run_lib.py:133] step: 32950, training_loss: 1.18640e-01
I0216 00:49:16.327490 22839682574144 run_lib.py:133] step: 33000, training_loss: 1.18199e-01
I0216 00:49:16.484165 22839682574144 run_lib.py:146] step: 33000, eval_loss: 1.24549e-01
I0216 00:49:34.194742 22839682574144 run_lib.py:133] step: 33050, training_loss: 1.23005e-01
I0216 00:49:51.650478 22839682574144 run_lib.py:133] step: 33100, training_loss: 1.25432e-01
I0216 00:49:51.804393 22839682574144 run_lib.py:146] step: 33100, eval_loss: 1.21140e-01
I0216 00:50:09.298110 22839682574144 run_lib.py:133] step: 33150, training_loss: 1.19055e-01
I0216 00:50:27.028950 22839682574144 run_lib.py:133] step: 33200, training_loss: 1.19900e-01
I0216 00:50:27.185254 22839682574144 run_lib.py:146] step: 33200, eval_loss: 1.23722e-01
I0216 00:50:44.701485 22839682574144 run_lib.py:133] step: 33250, training_loss: 1.17568e-01
I0216 00:51:02.436311 22839682574144 run_lib.py:133] step: 33300, training_loss: 1.20516e-01
I0216 00:51:02.595162 22839682574144 run_lib.py:146] step: 33300, eval_loss: 1.20872e-01
I0216 00:51:20.122046 22839682574144 run_lib.py:133] step: 33350, training_loss: 1.27006e-01
I0216 00:51:37.658538 22839682574144 run_lib.py:133] step: 33400, training_loss: 1.20119e-01
I0216 00:51:37.822041 22839682574144 run_lib.py:146] step: 33400, eval_loss: 1.24672e-01
I0216 00:51:55.517398 22839682574144 run_lib.py:133] step: 33450, training_loss: 1.21080e-01
I0216 00:52:13.080541 22839682574144 run_lib.py:133] step: 33500, training_loss: 1.21712e-01
I0216 00:52:13.239277 22839682574144 run_lib.py:146] step: 33500, eval_loss: 1.22021e-01
I0216 00:52:30.740306 22839682574144 run_lib.py:133] step: 33550, training_loss: 1.23764e-01
I0216 00:52:48.471779 22839682574144 run_lib.py:133] step: 33600, training_loss: 1.22228e-01
I0216 00:52:48.629148 22839682574144 run_lib.py:146] step: 33600, eval_loss: 1.23791e-01
I0216 00:53:06.161959 22839682574144 run_lib.py:133] step: 33650, training_loss: 1.19705e-01
I0216 00:53:23.703353 22839682574144 run_lib.py:133] step: 33700, training_loss: 1.22398e-01
I0216 00:53:23.862199 22839682574144 run_lib.py:146] step: 33700, eval_loss: 1.23277e-01
I0216 00:53:41.488949 22839682574144 run_lib.py:133] step: 33750, training_loss: 1.19052e-01
I0216 00:53:58.992047 22839682574144 run_lib.py:133] step: 33800, training_loss: 1.21263e-01
I0216 00:53:59.152018 22839682574144 run_lib.py:146] step: 33800, eval_loss: 1.22470e-01
I0216 00:54:16.641412 22839682574144 run_lib.py:133] step: 33850, training_loss: 1.22223e-01
I0216 00:54:34.149440 22839682574144 run_lib.py:133] step: 33900, training_loss: 1.20414e-01
I0216 00:54:34.312266 22839682574144 run_lib.py:146] step: 33900, eval_loss: 1.23722e-01
I0216 00:54:52.004862 22839682574144 run_lib.py:133] step: 33950, training_loss: 1.21282e-01
I0216 00:55:09.635939 22839682574144 run_lib.py:133] step: 34000, training_loss: 1.18623e-01
I0216 00:55:09.802142 22839682574144 run_lib.py:146] step: 34000, eval_loss: 1.25351e-01
I0216 00:55:27.344591 22839682574144 run_lib.py:133] step: 34050, training_loss: 1.23085e-01
I0216 00:55:44.868539 22839682574144 run_lib.py:133] step: 34100, training_loss: 1.24599e-01
I0216 00:55:45.024139 22839682574144 run_lib.py:146] step: 34100, eval_loss: 1.26771e-01
I0216 00:56:02.781429 22839682574144 run_lib.py:133] step: 34150, training_loss: 1.21884e-01
I0216 00:56:20.285689 22839682574144 run_lib.py:133] step: 34200, training_loss: 1.22452e-01
I0216 00:56:20.447111 22839682574144 run_lib.py:146] step: 34200, eval_loss: 1.26469e-01
I0216 00:56:37.971814 22839682574144 run_lib.py:133] step: 34250, training_loss: 1.26177e-01
I0216 00:56:55.655085 22839682574144 run_lib.py:133] step: 34300, training_loss: 1.13261e-01
I0216 00:56:55.830138 22839682574144 run_lib.py:146] step: 34300, eval_loss: 1.22059e-01
I0216 00:57:13.377296 22839682574144 run_lib.py:133] step: 34350, training_loss: 1.24790e-01
I0216 00:57:31.118512 22839682574144 run_lib.py:133] step: 34400, training_loss: 1.20306e-01
I0216 00:57:31.278162 22839682574144 run_lib.py:146] step: 34400, eval_loss: 1.25245e-01
I0216 00:57:48.815160 22839682574144 run_lib.py:133] step: 34450, training_loss: 1.21898e-01
I0216 00:58:06.291670 22839682574144 run_lib.py:133] step: 34500, training_loss: 1.21340e-01
I0216 00:58:06.449060 22839682574144 run_lib.py:146] step: 34500, eval_loss: 1.26263e-01
I0216 00:58:24.129819 22839682574144 run_lib.py:133] step: 34550, training_loss: 1.21373e-01
I0216 00:58:41.702571 22839682574144 run_lib.py:133] step: 34600, training_loss: 1.24317e-01
I0216 00:58:41.858871 22839682574144 run_lib.py:146] step: 34600, eval_loss: 1.24525e-01
I0216 00:58:59.383023 22839682574144 run_lib.py:133] step: 34650, training_loss: 1.20102e-01
I0216 00:59:17.095495 22839682574144 run_lib.py:133] step: 34700, training_loss: 1.21900e-01
I0216 00:59:17.253998 22839682574144 run_lib.py:146] step: 34700, eval_loss: 1.25155e-01
I0216 00:59:34.780803 22839682574144 run_lib.py:133] step: 34750, training_loss: 1.26188e-01
I0216 00:59:52.310091 22839682574144 run_lib.py:133] step: 34800, training_loss: 1.23981e-01
I0216 00:59:52.477296 22839682574144 run_lib.py:146] step: 34800, eval_loss: 1.28302e-01
I0216 01:00:10.116011 22839682574144 run_lib.py:133] step: 34850, training_loss: 1.19964e-01
I0216 01:00:27.647962 22839682574144 run_lib.py:133] step: 34900, training_loss: 1.21543e-01
I0216 01:00:27.803548 22839682574144 run_lib.py:146] step: 34900, eval_loss: 1.24571e-01
I0216 01:00:45.314010 22839682574144 run_lib.py:133] step: 34950, training_loss: 1.21702e-01
I0216 01:01:02.846253 22839682574144 run_lib.py:133] step: 35000, training_loss: 1.20474e-01
I0216 01:01:03.004048 22839682574144 run_lib.py:146] step: 35000, eval_loss: 1.25431e-01
I0216 01:01:20.749887 22839682574144 run_lib.py:133] step: 35050, training_loss: 1.22426e-01
I0216 01:01:38.368607 22839682574144 run_lib.py:133] step: 35100, training_loss: 1.21481e-01
I0216 01:01:38.524399 22839682574144 run_lib.py:146] step: 35100, eval_loss: 1.30729e-01
I0216 01:01:56.090148 22839682574144 run_lib.py:133] step: 35150, training_loss: 1.24752e-01
I0216 01:02:13.669798 22839682574144 run_lib.py:133] step: 35200, training_loss: 1.19938e-01
I0216 01:02:13.828341 22839682574144 run_lib.py:146] step: 35200, eval_loss: 1.24097e-01
I0216 01:02:31.528118 22839682574144 run_lib.py:133] step: 35250, training_loss: 1.20796e-01
I0216 01:02:49.059596 22839682574144 run_lib.py:133] step: 35300, training_loss: 1.20081e-01
I0216 01:02:49.220107 22839682574144 run_lib.py:146] step: 35300, eval_loss: 1.26441e-01
I0216 01:03:06.740669 22839682574144 run_lib.py:133] step: 35350, training_loss: 1.18565e-01
I0216 01:03:24.461218 22839682574144 run_lib.py:133] step: 35400, training_loss: 1.19549e-01
I0216 01:03:24.627733 22839682574144 run_lib.py:146] step: 35400, eval_loss: 1.28489e-01
I0216 01:03:42.159160 22839682574144 run_lib.py:133] step: 35450, training_loss: 1.26070e-01
I0216 01:03:59.901975 22839682574144 run_lib.py:133] step: 35500, training_loss: 1.20189e-01
I0216 01:04:00.064738 22839682574144 run_lib.py:146] step: 35500, eval_loss: 1.25358e-01
I0216 01:04:17.601238 22839682574144 run_lib.py:133] step: 35550, training_loss: 1.20691e-01
I0216 01:04:35.137484 22839682574144 run_lib.py:133] step: 35600, training_loss: 1.17586e-01
I0216 01:04:35.292447 22839682574144 run_lib.py:146] step: 35600, eval_loss: 1.22524e-01
I0216 01:04:53.041554 22839682574144 run_lib.py:133] step: 35650, training_loss: 1.17596e-01
I0216 01:05:10.573027 22839682574144 run_lib.py:133] step: 35700, training_loss: 1.19632e-01
I0216 01:05:10.739243 22839682574144 run_lib.py:146] step: 35700, eval_loss: 1.26674e-01
I0216 01:05:28.279463 22839682574144 run_lib.py:133] step: 35750, training_loss: 1.23505e-01
I0216 01:05:46.034803 22839682574144 run_lib.py:133] step: 35800, training_loss: 1.20255e-01
I0216 01:05:46.193311 22839682574144 run_lib.py:146] step: 35800, eval_loss: 1.27615e-01
I0216 01:06:03.707479 22839682574144 run_lib.py:133] step: 35850, training_loss: 1.24563e-01
I0216 01:06:21.250920 22839682574144 run_lib.py:133] step: 35900, training_loss: 1.20194e-01
I0216 01:06:21.413789 22839682574144 run_lib.py:146] step: 35900, eval_loss: 1.21553e-01
I0216 01:06:39.023507 22839682574144 run_lib.py:133] step: 35950, training_loss: 1.24160e-01
I0216 01:06:56.534560 22839682574144 run_lib.py:133] step: 36000, training_loss: 1.26091e-01
I0216 01:06:56.689404 22839682574144 run_lib.py:146] step: 36000, eval_loss: 1.26496e-01
I0216 01:07:14.195508 22839682574144 run_lib.py:133] step: 36050, training_loss: 1.20026e-01
I0216 01:07:31.724092 22839682574144 run_lib.py:133] step: 36100, training_loss: 1.19303e-01
I0216 01:07:31.880150 22839682574144 run_lib.py:146] step: 36100, eval_loss: 1.28079e-01
I0216 01:07:49.612111 22839682574144 run_lib.py:133] step: 36150, training_loss: 1.24109e-01
I0216 01:08:07.266035 22839682574144 run_lib.py:133] step: 36200, training_loss: 1.20155e-01
I0216 01:08:07.441136 22839682574144 run_lib.py:146] step: 36200, eval_loss: 1.25748e-01
I0216 01:08:24.969929 22839682574144 run_lib.py:133] step: 36250, training_loss: 1.23462e-01
I0216 01:08:42.512595 22839682574144 run_lib.py:133] step: 36300, training_loss: 1.20800e-01
I0216 01:08:42.670241 22839682574144 run_lib.py:146] step: 36300, eval_loss: 1.30233e-01
I0216 01:09:00.366584 22839682574144 run_lib.py:133] step: 36350, training_loss: 1.21238e-01
I0216 01:09:17.898685 22839682574144 run_lib.py:133] step: 36400, training_loss: 1.18730e-01
I0216 01:09:18.056214 22839682574144 run_lib.py:146] step: 36400, eval_loss: 1.26705e-01
I0216 01:09:35.583765 22839682574144 run_lib.py:133] step: 36450, training_loss: 1.22795e-01
I0216 01:09:53.320257 22839682574144 run_lib.py:133] step: 36500, training_loss: 1.24350e-01
I0216 01:09:53.485149 22839682574144 run_lib.py:146] step: 36500, eval_loss: 1.29373e-01
I0216 01:10:10.984612 22839682574144 run_lib.py:133] step: 36550, training_loss: 1.19790e-01
I0216 01:10:28.711205 22839682574144 run_lib.py:133] step: 36600, training_loss: 1.17433e-01
I0216 01:10:28.868220 22839682574144 run_lib.py:146] step: 36600, eval_loss: 1.25573e-01
I0216 01:10:46.381006 22839682574144 run_lib.py:133] step: 36650, training_loss: 1.21046e-01
I0216 01:11:03.892067 22839682574144 run_lib.py:133] step: 36700, training_loss: 1.20811e-01
I0216 01:11:04.067107 22839682574144 run_lib.py:146] step: 36700, eval_loss: 1.19756e-01
I0216 01:11:21.809100 22839682574144 run_lib.py:133] step: 36750, training_loss: 1.18441e-01
I0216 01:11:39.375717 22839682574144 run_lib.py:133] step: 36800, training_loss: 1.20630e-01
I0216 01:11:39.533622 22839682574144 run_lib.py:146] step: 36800, eval_loss: 1.24372e-01
I0216 01:11:57.043165 22839682574144 run_lib.py:133] step: 36850, training_loss: 1.23613e-01
I0216 01:12:14.761184 22839682574144 run_lib.py:133] step: 36900, training_loss: 1.26021e-01
I0216 01:12:14.917068 22839682574144 run_lib.py:146] step: 36900, eval_loss: 1.24302e-01
I0216 01:12:32.438915 22839682574144 run_lib.py:133] step: 36950, training_loss: 1.20805e-01
I0216 01:12:49.966528 22839682574144 run_lib.py:133] step: 37000, training_loss: 1.27326e-01
I0216 01:12:50.124247 22839682574144 run_lib.py:146] step: 37000, eval_loss: 1.29500e-01
I0216 01:13:07.775901 22839682574144 run_lib.py:133] step: 37050, training_loss: 1.24897e-01
I0216 01:13:25.287296 22839682574144 run_lib.py:133] step: 37100, training_loss: 1.20663e-01
I0216 01:13:25.443783 22839682574144 run_lib.py:146] step: 37100, eval_loss: 1.29748e-01
I0216 01:13:42.988322 22839682574144 run_lib.py:133] step: 37150, training_loss: 1.17200e-01
I0216 01:14:00.488151 22839682574144 run_lib.py:133] step: 37200, training_loss: 1.18804e-01
I0216 01:14:00.646430 22839682574144 run_lib.py:146] step: 37200, eval_loss: 1.26065e-01
I0216 01:14:18.375367 22839682574144 run_lib.py:133] step: 37250, training_loss: 1.21977e-01
I0216 01:14:35.980107 22839682574144 run_lib.py:133] step: 37300, training_loss: 1.22591e-01
I0216 01:14:36.153759 22839682574144 run_lib.py:146] step: 37300, eval_loss: 1.26522e-01
I0216 01:14:53.671388 22839682574144 run_lib.py:133] step: 37350, training_loss: 1.18140e-01
I0216 01:15:11.215034 22839682574144 run_lib.py:133] step: 37400, training_loss: 1.18435e-01
I0216 01:15:11.370294 22839682574144 run_lib.py:146] step: 37400, eval_loss: 1.20438e-01
I0216 01:15:29.127750 22839682574144 run_lib.py:133] step: 37450, training_loss: 1.21334e-01
I0216 01:15:46.653418 22839682574144 run_lib.py:133] step: 37500, training_loss: 1.26619e-01
I0216 01:15:46.815121 22839682574144 run_lib.py:146] step: 37500, eval_loss: 1.29690e-01
I0216 01:16:04.327354 22839682574144 run_lib.py:133] step: 37550, training_loss: 1.20451e-01
I0216 01:16:22.032009 22839682574144 run_lib.py:133] step: 37600, training_loss: 1.21079e-01
I0216 01:16:22.209043 22839682574144 run_lib.py:146] step: 37600, eval_loss: 1.23305e-01
I0216 01:16:39.744800 22839682574144 run_lib.py:133] step: 37650, training_loss: 1.24016e-01
I0216 01:16:57.510201 22839682574144 run_lib.py:133] step: 37700, training_loss: 1.24994e-01
I0216 01:16:57.668289 22839682574144 run_lib.py:146] step: 37700, eval_loss: 1.23022e-01
I0216 01:17:15.196086 22839682574144 run_lib.py:133] step: 37750, training_loss: 1.16557e-01
I0216 01:17:32.734779 22839682574144 run_lib.py:133] step: 37800, training_loss: 1.21922e-01
I0216 01:17:32.898023 22839682574144 run_lib.py:146] step: 37800, eval_loss: 1.27884e-01
I0216 01:17:50.601523 22839682574144 run_lib.py:133] step: 37850, training_loss: 1.22260e-01
I0216 01:18:08.192626 22839682574144 run_lib.py:133] step: 37900, training_loss: 1.19359e-01
I0216 01:18:08.357119 22839682574144 run_lib.py:146] step: 37900, eval_loss: 1.30281e-01
I0216 01:18:25.894330 22839682574144 run_lib.py:133] step: 37950, training_loss: 1.19480e-01
I0216 01:18:43.628247 22839682574144 run_lib.py:133] step: 38000, training_loss: 1.20930e-01
I0216 01:18:43.787065 22839682574144 run_lib.py:146] step: 38000, eval_loss: 1.24252e-01
I0216 01:19:01.291921 22839682574144 run_lib.py:133] step: 38050, training_loss: 1.22312e-01
I0216 01:19:18.823482 22839682574144 run_lib.py:133] step: 38100, training_loss: 1.25261e-01
I0216 01:19:18.983313 22839682574144 run_lib.py:146] step: 38100, eval_loss: 1.25591e-01
I0216 01:19:36.614450 22839682574144 run_lib.py:133] step: 38150, training_loss: 1.25374e-01
I0216 01:19:54.168621 22839682574144 run_lib.py:133] step: 38200, training_loss: 1.22139e-01
I0216 01:19:54.336325 22839682574144 run_lib.py:146] step: 38200, eval_loss: 1.22621e-01
I0216 01:20:11.883008 22839682574144 run_lib.py:133] step: 38250, training_loss: 1.26167e-01
I0216 01:20:29.408349 22839682574144 run_lib.py:133] step: 38300, training_loss: 1.20955e-01
I0216 01:20:29.566095 22839682574144 run_lib.py:146] step: 38300, eval_loss: 1.27979e-01
I0216 01:20:47.310741 22839682574144 run_lib.py:133] step: 38350, training_loss: 1.18803e-01
I0216 01:21:04.932305 22839682574144 run_lib.py:133] step: 38400, training_loss: 1.16212e-01
I0216 01:21:05.095169 22839682574144 run_lib.py:146] step: 38400, eval_loss: 1.30147e-01
I0216 01:21:22.672342 22839682574144 run_lib.py:133] step: 38450, training_loss: 1.21921e-01
I0216 01:21:40.190061 22839682574144 run_lib.py:133] step: 38500, training_loss: 1.19260e-01
I0216 01:21:40.365475 22839682574144 run_lib.py:146] step: 38500, eval_loss: 1.29502e-01
I0216 01:21:58.078023 22839682574144 run_lib.py:133] step: 38550, training_loss: 1.18547e-01
I0216 01:22:15.597992 22839682574144 run_lib.py:133] step: 38600, training_loss: 1.17447e-01
I0216 01:22:15.754362 22839682574144 run_lib.py:146] step: 38600, eval_loss: 1.23975e-01
I0216 01:22:33.280242 22839682574144 run_lib.py:133] step: 38650, training_loss: 1.23624e-01
I0216 01:22:51.009415 22839682574144 run_lib.py:133] step: 38700, training_loss: 1.20373e-01
I0216 01:22:51.186918 22839682574144 run_lib.py:146] step: 38700, eval_loss: 1.23506e-01
I0216 01:23:08.716990 22839682574144 run_lib.py:133] step: 38750, training_loss: 1.22706e-01
I0216 01:23:26.438878 22839682574144 run_lib.py:133] step: 38800, training_loss: 1.24438e-01
I0216 01:23:26.595308 22839682574144 run_lib.py:146] step: 38800, eval_loss: 1.26678e-01
I0216 01:23:44.119176 22839682574144 run_lib.py:133] step: 38850, training_loss: 1.21248e-01
I0216 01:24:01.623108 22839682574144 run_lib.py:133] step: 38900, training_loss: 1.21194e-01
I0216 01:24:01.778152 22839682574144 run_lib.py:146] step: 38900, eval_loss: 1.26237e-01
I0216 01:24:19.485203 22839682574144 run_lib.py:133] step: 38950, training_loss: 1.20702e-01
I0216 01:24:37.027760 22839682574144 run_lib.py:133] step: 39000, training_loss: 1.16776e-01
I0216 01:24:37.194137 22839682574144 run_lib.py:146] step: 39000, eval_loss: 1.25689e-01
I0216 01:24:54.763024 22839682574144 run_lib.py:133] step: 39050, training_loss: 1.15522e-01
I0216 01:25:12.512509 22839682574144 run_lib.py:133] step: 39100, training_loss: 1.18989e-01
I0216 01:25:12.669583 22839682574144 run_lib.py:146] step: 39100, eval_loss: 1.27662e-01
I0216 01:25:30.214048 22839682574144 run_lib.py:133] step: 39150, training_loss: 1.22047e-01
I0216 01:25:47.726658 22839682574144 run_lib.py:133] step: 39200, training_loss: 1.20966e-01
I0216 01:25:47.895131 22839682574144 run_lib.py:146] step: 39200, eval_loss: 1.28487e-01
I0216 01:26:05.567963 22839682574144 run_lib.py:133] step: 39250, training_loss: 1.23707e-01
I0216 01:26:23.072452 22839682574144 run_lib.py:133] step: 39300, training_loss: 1.20369e-01
I0216 01:26:23.251750 22839682574144 run_lib.py:146] step: 39300, eval_loss: 1.25171e-01
I0216 01:26:40.749127 22839682574144 run_lib.py:133] step: 39350, training_loss: 1.18146e-01
I0216 01:26:58.239171 22839682574144 run_lib.py:133] step: 39400, training_loss: 1.23445e-01
I0216 01:26:58.395059 22839682574144 run_lib.py:146] step: 39400, eval_loss: 1.30372e-01
I0216 01:27:16.130334 22839682574144 run_lib.py:133] step: 39450, training_loss: 1.20333e-01
I0216 01:27:33.748190 22839682574144 run_lib.py:133] step: 39500, training_loss: 1.24317e-01
I0216 01:27:33.925107 22839682574144 run_lib.py:146] step: 39500, eval_loss: 1.27526e-01
I0216 01:27:51.451958 22839682574144 run_lib.py:133] step: 39550, training_loss: 1.22342e-01
I0216 01:28:08.957917 22839682574144 run_lib.py:133] step: 39600, training_loss: 1.23208e-01
I0216 01:28:09.115227 22839682574144 run_lib.py:146] step: 39600, eval_loss: 1.24497e-01
I0216 01:28:26.847730 22839682574144 run_lib.py:133] step: 39650, training_loss: 1.20235e-01
I0216 01:28:44.350432 22839682574144 run_lib.py:133] step: 39700, training_loss: 1.16176e-01
I0216 01:28:44.507814 22839682574144 run_lib.py:146] step: 39700, eval_loss: 1.23368e-01
I0216 01:29:02.029428 22839682574144 run_lib.py:133] step: 39750, training_loss: 1.19839e-01
I0216 01:29:19.783860 22839682574144 run_lib.py:133] step: 39800, training_loss: 1.19784e-01
I0216 01:29:19.940486 22839682574144 run_lib.py:146] step: 39800, eval_loss: 1.26115e-01
I0216 01:29:37.462628 22839682574144 run_lib.py:133] step: 39850, training_loss: 1.22811e-01
I0216 01:29:55.159082 22839682574144 run_lib.py:133] step: 39900, training_loss: 1.19984e-01
I0216 01:29:55.317017 22839682574144 run_lib.py:146] step: 39900, eval_loss: 1.23755e-01
I0216 01:30:12.827091 22839682574144 run_lib.py:133] step: 39950, training_loss: 1.23890e-01
I0216 01:30:30.408101 22839682574144 run_lib.py:133] step: 40000, training_loss: 1.22862e-01
I0216 01:30:31.526891 22839682574144 run_lib.py:146] step: 40000, eval_loss: 1.25862e-01
I0216 01:30:52.393400 22839682574144 run_lib.py:133] step: 40050, training_loss: 1.21599e-01
I0216 01:31:09.912664 22839682574144 run_lib.py:133] step: 40100, training_loss: 1.21860e-01
I0216 01:31:10.071300 22839682574144 run_lib.py:146] step: 40100, eval_loss: 1.29768e-01
I0216 01:31:27.599395 22839682574144 run_lib.py:133] step: 40150, training_loss: 1.22622e-01
I0216 01:31:45.302159 22839682574144 run_lib.py:133] step: 40200, training_loss: 1.24165e-01
I0216 01:31:45.458787 22839682574144 run_lib.py:146] step: 40200, eval_loss: 1.27698e-01
I0216 01:32:02.985566 22839682574144 run_lib.py:133] step: 40250, training_loss: 1.18133e-01
I0216 01:32:20.533966 22839682574144 run_lib.py:133] step: 40300, training_loss: 1.25803e-01
I0216 01:32:20.692384 22839682574144 run_lib.py:146] step: 40300, eval_loss: 1.24962e-01
I0216 01:32:38.431891 22839682574144 run_lib.py:133] step: 40350, training_loss: 1.19499e-01
I0216 01:32:55.974344 22839682574144 run_lib.py:133] step: 40400, training_loss: 1.18879e-01
I0216 01:32:56.130131 22839682574144 run_lib.py:146] step: 40400, eval_loss: 1.26148e-01
I0216 01:33:13.808262 22839682574144 run_lib.py:133] step: 40450, training_loss: 1.18801e-01
I0216 01:33:31.330511 22839682574144 run_lib.py:133] step: 40500, training_loss: 1.15427e-01
I0216 01:33:31.502385 22839682574144 run_lib.py:146] step: 40500, eval_loss: 1.26811e-01
I0216 01:33:49.054110 22839682574144 run_lib.py:133] step: 40550, training_loss: 1.21732e-01
I0216 01:34:06.608045 22839682574144 run_lib.py:133] step: 40600, training_loss: 1.15779e-01
I0216 01:34:06.793983 22839682574144 run_lib.py:146] step: 40600, eval_loss: 1.22397e-01
I0216 01:34:24.445731 22839682574144 run_lib.py:133] step: 40650, training_loss: 1.19277e-01
I0216 01:34:41.965852 22839682574144 run_lib.py:133] step: 40700, training_loss: 1.19520e-01
I0216 01:34:42.126799 22839682574144 run_lib.py:146] step: 40700, eval_loss: 1.23656e-01
I0216 01:34:59.620519 22839682574144 run_lib.py:133] step: 40750, training_loss: 1.23967e-01
I0216 01:35:17.204919 22839682574144 run_lib.py:133] step: 40800, training_loss: 1.15233e-01
I0216 01:35:17.361362 22839682574144 run_lib.py:146] step: 40800, eval_loss: 1.25069e-01
I0216 01:35:35.073664 22839682574144 run_lib.py:133] step: 40850, training_loss: 1.17125e-01
I0216 01:35:52.665419 22839682574144 run_lib.py:133] step: 40900, training_loss: 1.15905e-01
I0216 01:35:52.853302 22839682574144 run_lib.py:146] step: 40900, eval_loss: 1.23474e-01
I0216 01:36:10.401903 22839682574144 run_lib.py:133] step: 40950, training_loss: 1.21830e-01
I0216 01:36:27.943997 22839682574144 run_lib.py:133] step: 41000, training_loss: 1.23598e-01
I0216 01:36:28.107073 22839682574144 run_lib.py:146] step: 41000, eval_loss: 1.25617e-01
I0216 01:36:45.811096 22839682574144 run_lib.py:133] step: 41050, training_loss: 1.17262e-01
I0216 01:37:03.341769 22839682574144 run_lib.py:133] step: 41100, training_loss: 1.19799e-01
I0216 01:37:03.500307 22839682574144 run_lib.py:146] step: 41100, eval_loss: 1.24091e-01
I0216 01:37:21.004172 22839682574144 run_lib.py:133] step: 41150, training_loss: 1.20225e-01
I0216 01:37:38.732280 22839682574144 run_lib.py:133] step: 41200, training_loss: 1.18417e-01
I0216 01:37:38.890392 22839682574144 run_lib.py:146] step: 41200, eval_loss: 1.28962e-01
I0216 01:37:56.407731 22839682574144 run_lib.py:133] step: 41250, training_loss: 1.21771e-01
I0216 01:38:14.083077 22839682574144 run_lib.py:133] step: 41300, training_loss: 1.20483e-01
I0216 01:38:14.238626 22839682574144 run_lib.py:146] step: 41300, eval_loss: 1.27449e-01
I0216 01:38:31.840512 22839682574144 run_lib.py:133] step: 41350, training_loss: 1.24657e-01
I0216 01:38:49.349015 22839682574144 run_lib.py:133] step: 41400, training_loss: 1.17132e-01
I0216 01:38:49.506779 22839682574144 run_lib.py:146] step: 41400, eval_loss: 1.27179e-01
I0216 01:39:07.195477 22839682574144 run_lib.py:133] step: 41450, training_loss: 1.21816e-01
I0216 01:39:24.744587 22839682574144 run_lib.py:133] step: 41500, training_loss: 1.19581e-01
I0216 01:39:24.904325 22839682574144 run_lib.py:146] step: 41500, eval_loss: 1.25351e-01
I0216 01:39:42.408043 22839682574144 run_lib.py:133] step: 41550, training_loss: 1.16848e-01
I0216 01:40:00.113707 22839682574144 run_lib.py:133] step: 41600, training_loss: 1.18775e-01
I0216 01:40:00.277058 22839682574144 run_lib.py:146] step: 41600, eval_loss: 1.26322e-01
I0216 01:40:17.798755 22839682574144 run_lib.py:133] step: 41650, training_loss: 1.20310e-01
I0216 01:40:35.313482 22839682574144 run_lib.py:133] step: 41700, training_loss: 1.19581e-01
I0216 01:40:35.469840 22839682574144 run_lib.py:146] step: 41700, eval_loss: 1.27276e-01
I0216 01:40:53.111327 22839682574144 run_lib.py:133] step: 41750, training_loss: 1.16644e-01
I0216 01:41:10.645284 22839682574144 run_lib.py:133] step: 41800, training_loss: 1.19232e-01
I0216 01:41:10.799134 22839682574144 run_lib.py:146] step: 41800, eval_loss: 1.28422e-01
I0216 01:41:28.319476 22839682574144 run_lib.py:133] step: 41850, training_loss: 1.23379e-01
I0216 01:41:45.860797 22839682574144 run_lib.py:133] step: 41900, training_loss: 1.22240e-01
I0216 01:41:46.029314 22839682574144 run_lib.py:146] step: 41900, eval_loss: 1.28917e-01
I0216 01:42:03.811561 22839682574144 run_lib.py:133] step: 41950, training_loss: 1.24718e-01
I0216 01:42:21.444155 22839682574144 run_lib.py:133] step: 42000, training_loss: 1.23197e-01
I0216 01:42:21.603291 22839682574144 run_lib.py:146] step: 42000, eval_loss: 1.26306e-01
I0216 01:42:39.099490 22839682574144 run_lib.py:133] step: 42050, training_loss: 1.20996e-01
I0216 01:42:56.630636 22839682574144 run_lib.py:133] step: 42100, training_loss: 1.23045e-01
I0216 01:42:56.798129 22839682574144 run_lib.py:146] step: 42100, eval_loss: 1.29085e-01
I0216 01:43:14.516611 22839682574144 run_lib.py:133] step: 42150, training_loss: 1.17676e-01
I0216 01:43:32.060024 22839682574144 run_lib.py:133] step: 42200, training_loss: 1.18624e-01
I0216 01:43:32.217355 22839682574144 run_lib.py:146] step: 42200, eval_loss: 1.27288e-01
I0216 01:43:49.729663 22839682574144 run_lib.py:133] step: 42250, training_loss: 1.20565e-01
I0216 01:44:07.462690 22839682574144 run_lib.py:133] step: 42300, training_loss: 1.21502e-01
I0216 01:44:07.619185 22839682574144 run_lib.py:146] step: 42300, eval_loss: 1.28168e-01
I0216 01:44:25.149143 22839682574144 run_lib.py:133] step: 42350, training_loss: 1.22162e-01
I0216 01:44:42.876787 22839682574144 run_lib.py:133] step: 42400, training_loss: 1.19852e-01
I0216 01:44:43.051090 22839682574144 run_lib.py:146] step: 42400, eval_loss: 1.24714e-01
I0216 01:45:00.560644 22839682574144 run_lib.py:133] step: 42450, training_loss: 1.21427e-01
I0216 01:45:18.080257 22839682574144 run_lib.py:133] step: 42500, training_loss: 1.23475e-01
I0216 01:45:18.277155 22839682574144 run_lib.py:146] step: 42500, eval_loss: 1.24243e-01
I0216 01:45:36.010366 22839682574144 run_lib.py:133] step: 42550, training_loss: 1.19803e-01
I0216 01:45:53.545175 22839682574144 run_lib.py:133] step: 42600, training_loss: 1.18095e-01
I0216 01:45:53.712041 22839682574144 run_lib.py:146] step: 42600, eval_loss: 1.30243e-01
I0216 01:46:11.256406 22839682574144 run_lib.py:133] step: 42650, training_loss: 1.18364e-01
I0216 01:46:28.970961 22839682574144 run_lib.py:133] step: 42700, training_loss: 1.22526e-01
I0216 01:46:29.127868 22839682574144 run_lib.py:146] step: 42700, eval_loss: 1.20530e-01
I0216 01:46:46.769543 22839682574144 run_lib.py:133] step: 42750, training_loss: 1.21844e-01
I0216 01:47:04.327075 22839682574144 run_lib.py:133] step: 42800, training_loss: 1.14669e-01
I0216 01:47:04.482407 22839682574144 run_lib.py:146] step: 42800, eval_loss: 1.23318e-01
I0216 01:47:22.160781 22839682574144 run_lib.py:133] step: 42850, training_loss: 1.21550e-01
I0216 01:47:39.721868 22839682574144 run_lib.py:133] step: 42900, training_loss: 1.21916e-01
I0216 01:47:39.881361 22839682574144 run_lib.py:146] step: 42900, eval_loss: 1.25515e-01
I0216 01:47:57.399962 22839682574144 run_lib.py:133] step: 42950, training_loss: 1.23184e-01
I0216 01:48:14.960517 22839682574144 run_lib.py:133] step: 43000, training_loss: 1.19289e-01
I0216 01:48:15.118380 22839682574144 run_lib.py:146] step: 43000, eval_loss: 1.27960e-01
I0216 01:48:32.835517 22839682574144 run_lib.py:133] step: 43050, training_loss: 1.17782e-01
I0216 01:48:50.473118 22839682574144 run_lib.py:133] step: 43100, training_loss: 1.22726e-01
I0216 01:48:50.637289 22839682574144 run_lib.py:146] step: 43100, eval_loss: 1.27517e-01
I0216 01:49:08.170720 22839682574144 run_lib.py:133] step: 43150, training_loss: 1.18035e-01
I0216 01:49:25.711213 22839682574144 run_lib.py:133] step: 43200, training_loss: 1.19250e-01
I0216 01:49:25.872452 22839682574144 run_lib.py:146] step: 43200, eval_loss: 1.26517e-01
I0216 01:49:43.612310 22839682574144 run_lib.py:133] step: 43250, training_loss: 1.22818e-01
I0216 01:50:01.121325 22839682574144 run_lib.py:133] step: 43300, training_loss: 1.17311e-01
I0216 01:50:01.279206 22839682574144 run_lib.py:146] step: 43300, eval_loss: 1.28834e-01
I0216 01:50:18.796305 22839682574144 run_lib.py:133] step: 43350, training_loss: 1.25096e-01
I0216 01:50:36.552035 22839682574144 run_lib.py:133] step: 43400, training_loss: 1.20888e-01
I0216 01:50:36.720335 22839682574144 run_lib.py:146] step: 43400, eval_loss: 1.28833e-01
I0216 01:50:54.226191 22839682574144 run_lib.py:133] step: 43450, training_loss: 1.20445e-01
I0216 01:51:11.931098 22839682574144 run_lib.py:133] step: 43500, training_loss: 1.20210e-01
I0216 01:51:12.104068 22839682574144 run_lib.py:146] step: 43500, eval_loss: 1.31691e-01
I0216 01:51:29.678081 22839682574144 run_lib.py:133] step: 43550, training_loss: 1.17942e-01
I0216 01:51:47.186667 22839682574144 run_lib.py:133] step: 43600, training_loss: 1.23983e-01
I0216 01:51:47.393238 22839682574144 run_lib.py:146] step: 43600, eval_loss: 1.26471e-01
I0216 01:52:05.115731 22839682574144 run_lib.py:133] step: 43650, training_loss: 1.20666e-01
I0216 01:52:22.645343 22839682574144 run_lib.py:133] step: 43700, training_loss: 1.20813e-01
I0216 01:52:22.806010 22839682574144 run_lib.py:146] step: 43700, eval_loss: 1.25537e-01
I0216 01:52:40.298666 22839682574144 run_lib.py:133] step: 43750, training_loss: 1.20322e-01
I0216 01:52:58.004316 22839682574144 run_lib.py:133] step: 43800, training_loss: 1.20191e-01
I0216 01:52:58.174419 22839682574144 run_lib.py:146] step: 43800, eval_loss: 1.23456e-01
I0216 01:53:15.715482 22839682574144 run_lib.py:133] step: 43850, training_loss: 1.20081e-01
I0216 01:53:33.264771 22839682574144 run_lib.py:133] step: 43900, training_loss: 1.19224e-01
I0216 01:53:33.423139 22839682574144 run_lib.py:146] step: 43900, eval_loss: 1.29739e-01
I0216 01:53:51.080147 22839682574144 run_lib.py:133] step: 43950, training_loss: 1.20104e-01
I0216 01:54:08.614854 22839682574144 run_lib.py:133] step: 44000, training_loss: 1.20327e-01
I0216 01:54:08.775300 22839682574144 run_lib.py:146] step: 44000, eval_loss: 1.27669e-01
I0216 01:54:26.299719 22839682574144 run_lib.py:133] step: 44050, training_loss: 1.20231e-01
I0216 01:54:43.870994 22839682574144 run_lib.py:133] step: 44100, training_loss: 1.18148e-01
I0216 01:54:44.028349 22839682574144 run_lib.py:146] step: 44100, eval_loss: 1.27249e-01
I0216 01:55:01.761488 22839682574144 run_lib.py:133] step: 44150, training_loss: 1.19031e-01
I0216 01:55:19.200759 22839682574144 run_lib.py:133] step: 44200, training_loss: 1.16602e-01
I0216 01:55:19.356773 22839682574144 run_lib.py:146] step: 44200, eval_loss: 1.26237e-01
I0216 01:55:36.599744 22839682574144 run_lib.py:133] step: 44250, training_loss: 1.18653e-01
I0216 01:55:53.928845 22839682574144 run_lib.py:133] step: 44300, training_loss: 1.21061e-01
I0216 01:55:54.100919 22839682574144 run_lib.py:146] step: 44300, eval_loss: 1.27268e-01
I0216 01:56:11.631952 22839682574144 run_lib.py:133] step: 44350, training_loss: 1.16754e-01
I0216 01:56:29.114931 22839682574144 run_lib.py:133] step: 44400, training_loss: 1.16076e-01
I0216 01:56:29.280463 22839682574144 run_lib.py:146] step: 44400, eval_loss: 1.28623e-01
I0216 01:56:46.779784 22839682574144 run_lib.py:133] step: 44450, training_loss: 1.17694e-01
I0216 01:57:04.446799 22839682574144 run_lib.py:133] step: 44500, training_loss: 1.16436e-01
I0216 01:57:04.603785 22839682574144 run_lib.py:146] step: 44500, eval_loss: 1.28300e-01
I0216 01:57:22.139694 22839682574144 run_lib.py:133] step: 44550, training_loss: 1.24371e-01
I0216 01:57:39.841953 22839682574144 run_lib.py:133] step: 44600, training_loss: 1.19493e-01
I0216 01:57:39.998954 22839682574144 run_lib.py:146] step: 44600, eval_loss: 1.21838e-01
I0216 01:57:57.530751 22839682574144 run_lib.py:133] step: 44650, training_loss: 1.20046e-01
I0216 01:58:15.046812 22839682574144 run_lib.py:133] step: 44700, training_loss: 1.16769e-01
I0216 01:58:15.203080 22839682574144 run_lib.py:146] step: 44700, eval_loss: 1.23943e-01
I0216 01:58:32.903946 22839682574144 run_lib.py:133] step: 44750, training_loss: 1.19896e-01
I0216 01:58:50.437556 22839682574144 run_lib.py:133] step: 44800, training_loss: 1.20317e-01
I0216 01:58:50.597286 22839682574144 run_lib.py:146] step: 44800, eval_loss: 1.25481e-01
I0216 01:59:08.143358 22839682574144 run_lib.py:133] step: 44850, training_loss: 1.18517e-01
I0216 01:59:25.925684 22839682574144 run_lib.py:133] step: 44900, training_loss: 1.18882e-01
I0216 01:59:26.082375 22839682574144 run_lib.py:146] step: 44900, eval_loss: 1.27942e-01
I0216 01:59:43.603096 22839682574144 run_lib.py:133] step: 44950, training_loss: 1.21032e-01
I0216 02:00:01.110865 22839682574144 run_lib.py:133] step: 45000, training_loss: 1.19185e-01
I0216 02:00:01.268154 22839682574144 run_lib.py:146] step: 45000, eval_loss: 1.30754e-01
I0216 02:00:18.898669 22839682574144 run_lib.py:133] step: 45050, training_loss: 1.20265e-01
I0216 02:00:36.430084 22839682574144 run_lib.py:133] step: 45100, training_loss: 1.18873e-01
I0216 02:00:36.586373 22839682574144 run_lib.py:146] step: 45100, eval_loss: 1.26836e-01
I0216 02:00:54.129627 22839682574144 run_lib.py:133] step: 45150, training_loss: 1.14612e-01
I0216 02:01:11.631222 22839682574144 run_lib.py:133] step: 45200, training_loss: 1.22060e-01
I0216 02:01:11.788344 22839682574144 run_lib.py:146] step: 45200, eval_loss: 1.23833e-01
I0216 02:01:29.474706 22839682574144 run_lib.py:133] step: 45250, training_loss: 1.23616e-01
I0216 02:01:47.094385 22839682574144 run_lib.py:133] step: 45300, training_loss: 1.23427e-01
I0216 02:01:47.254527 22839682574144 run_lib.py:146] step: 45300, eval_loss: 1.28655e-01
I0216 02:02:04.742290 22839682574144 run_lib.py:133] step: 45350, training_loss: 1.18089e-01
I0216 02:02:22.302704 22839682574144 run_lib.py:133] step: 45400, training_loss: 1.20383e-01
I0216 02:02:22.457466 22839682574144 run_lib.py:146] step: 45400, eval_loss: 1.23870e-01
I0216 02:02:40.168682 22839682574144 run_lib.py:133] step: 45450, training_loss: 1.17695e-01
I0216 02:02:57.702720 22839682574144 run_lib.py:133] step: 45500, training_loss: 1.20460e-01
I0216 02:02:57.859291 22839682574144 run_lib.py:146] step: 45500, eval_loss: 1.25152e-01
I0216 02:03:15.351154 22839682574144 run_lib.py:133] step: 45550, training_loss: 1.16653e-01
I0216 02:03:32.999208 22839682574144 run_lib.py:133] step: 45600, training_loss: 1.16248e-01
I0216 02:03:33.153073 22839682574144 run_lib.py:146] step: 45600, eval_loss: 1.31703e-01
I0216 02:03:50.683576 22839682574144 run_lib.py:133] step: 45650, training_loss: 1.17961e-01
I0216 02:04:08.418982 22839682574144 run_lib.py:133] step: 45700, training_loss: 1.23542e-01
I0216 02:04:08.585357 22839682574144 run_lib.py:146] step: 45700, eval_loss: 1.24452e-01
I0216 02:04:26.094136 22839682574144 run_lib.py:133] step: 45750, training_loss: 1.18394e-01
I0216 02:04:43.641238 22839682574144 run_lib.py:133] step: 45800, training_loss: 1.17441e-01
I0216 02:04:43.800361 22839682574144 run_lib.py:146] step: 45800, eval_loss: 1.31547e-01
I0216 02:05:01.532653 22839682574144 run_lib.py:133] step: 45850, training_loss: 1.17262e-01
I0216 02:05:19.057513 22839682574144 run_lib.py:133] step: 45900, training_loss: 1.22887e-01
I0216 02:05:19.224027 22839682574144 run_lib.py:146] step: 45900, eval_loss: 1.24433e-01
I0216 02:05:36.749411 22839682574144 run_lib.py:133] step: 45950, training_loss: 1.20513e-01
I0216 02:05:54.513510 22839682574144 run_lib.py:133] step: 46000, training_loss: 1.20626e-01
I0216 02:05:54.674533 22839682574144 run_lib.py:146] step: 46000, eval_loss: 1.26165e-01
I0216 02:06:12.185368 22839682574144 run_lib.py:133] step: 46050, training_loss: 1.21611e-01
I0216 02:06:29.708479 22839682574144 run_lib.py:133] step: 46100, training_loss: 1.19429e-01
I0216 02:06:29.863136 22839682574144 run_lib.py:146] step: 46100, eval_loss: 1.24252e-01
I0216 02:06:47.432451 22839682574144 run_lib.py:133] step: 46150, training_loss: 1.16582e-01
I0216 02:07:04.996352 22839682574144 run_lib.py:133] step: 46200, training_loss: 1.21331e-01
I0216 02:07:05.171144 22839682574144 run_lib.py:146] step: 46200, eval_loss: 1.26014e-01
I0216 02:07:22.737230 22839682574144 run_lib.py:133] step: 46250, training_loss: 1.21063e-01
I0216 02:07:40.260079 22839682574144 run_lib.py:133] step: 46300, training_loss: 1.21074e-01
I0216 02:07:40.417013 22839682574144 run_lib.py:146] step: 46300, eval_loss: 1.25385e-01
I0216 02:07:58.139506 22839682574144 run_lib.py:133] step: 46350, training_loss: 1.20375e-01
I0216 02:08:15.761967 22839682574144 run_lib.py:133] step: 46400, training_loss: 1.19723e-01
I0216 02:08:15.919144 22839682574144 run_lib.py:146] step: 46400, eval_loss: 1.24396e-01
I0216 02:08:33.435111 22839682574144 run_lib.py:133] step: 46450, training_loss: 1.19104e-01
I0216 02:08:50.966884 22839682574144 run_lib.py:133] step: 46500, training_loss: 1.22024e-01
I0216 02:08:51.133279 22839682574144 run_lib.py:146] step: 46500, eval_loss: 1.28135e-01
I0216 02:09:08.889468 22839682574144 run_lib.py:133] step: 46550, training_loss: 1.19321e-01
I0216 02:09:26.415143 22839682574144 run_lib.py:133] step: 46600, training_loss: 1.18751e-01
I0216 02:09:26.577241 22839682574144 run_lib.py:146] step: 46600, eval_loss: 1.27294e-01
I0216 02:09:44.076457 22839682574144 run_lib.py:133] step: 46650, training_loss: 1.17479e-01
I0216 02:10:01.740272 22839682574144 run_lib.py:133] step: 46700, training_loss: 1.19412e-01
I0216 02:10:01.901040 22839682574144 run_lib.py:146] step: 46700, eval_loss: 1.30211e-01
I0216 02:10:19.423214 22839682574144 run_lib.py:133] step: 46750, training_loss: 1.21849e-01
I0216 02:10:37.173607 22839682574144 run_lib.py:133] step: 46800, training_loss: 1.20963e-01
I0216 02:10:37.329740 22839682574144 run_lib.py:146] step: 46800, eval_loss: 1.23455e-01
I0216 02:10:54.819921 22839682574144 run_lib.py:133] step: 46850, training_loss: 1.19222e-01
I0216 02:11:12.359390 22839682574144 run_lib.py:133] step: 46900, training_loss: 1.19218e-01
I0216 02:11:12.516049 22839682574144 run_lib.py:146] step: 46900, eval_loss: 1.23945e-01
I0216 02:11:30.195086 22839682574144 run_lib.py:133] step: 46950, training_loss: 1.21462e-01
I0216 02:11:47.736002 22839682574144 run_lib.py:133] step: 47000, training_loss: 1.19134e-01
I0216 02:11:47.891798 22839682574144 run_lib.py:146] step: 47000, eval_loss: 1.26646e-01
I0216 02:12:05.470753 22839682574144 run_lib.py:133] step: 47050, training_loss: 1.19751e-01
I0216 02:12:23.232070 22839682574144 run_lib.py:133] step: 47100, training_loss: 1.17528e-01
I0216 02:12:23.393110 22839682574144 run_lib.py:146] step: 47100, eval_loss: 1.24792e-01
I0216 02:12:40.918223 22839682574144 run_lib.py:133] step: 47150, training_loss: 1.21595e-01
I0216 02:12:58.460891 22839682574144 run_lib.py:133] step: 47200, training_loss: 1.16659e-01
I0216 02:12:58.619602 22839682574144 run_lib.py:146] step: 47200, eval_loss: 1.27151e-01
I0216 02:13:16.222688 22839682574144 run_lib.py:133] step: 47250, training_loss: 1.21799e-01
I0216 02:13:33.769202 22839682574144 run_lib.py:133] step: 47300, training_loss: 1.18296e-01
I0216 02:13:33.935604 22839682574144 run_lib.py:146] step: 47300, eval_loss: 1.27808e-01
I0216 02:13:51.459900 22839682574144 run_lib.py:133] step: 47350, training_loss: 1.23223e-01
I0216 02:14:09.011168 22839682574144 run_lib.py:133] step: 47400, training_loss: 1.14949e-01
I0216 02:14:09.168069 22839682574144 run_lib.py:146] step: 47400, eval_loss: 1.24682e-01
I0216 02:14:26.864013 22839682574144 run_lib.py:133] step: 47450, training_loss: 1.20887e-01
I0216 02:14:44.481834 22839682574144 run_lib.py:133] step: 47500, training_loss: 1.24772e-01
I0216 02:14:44.639397 22839682574144 run_lib.py:146] step: 47500, eval_loss: 1.26358e-01
I0216 02:15:02.167282 22839682574144 run_lib.py:133] step: 47550, training_loss: 1.16203e-01
I0216 02:15:19.664651 22839682574144 run_lib.py:133] step: 47600, training_loss: 1.18401e-01
I0216 02:15:19.822287 22839682574144 run_lib.py:146] step: 47600, eval_loss: 1.27496e-01
I0216 02:15:37.525391 22839682574144 run_lib.py:133] step: 47650, training_loss: 1.19732e-01
I0216 02:15:55.042244 22839682574144 run_lib.py:133] step: 47700, training_loss: 1.18317e-01
I0216 02:15:55.200895 22839682574144 run_lib.py:146] step: 47700, eval_loss: 1.24573e-01
I0216 02:16:12.734359 22839682574144 run_lib.py:133] step: 47750, training_loss: 1.21606e-01
I0216 02:16:30.460709 22839682574144 run_lib.py:133] step: 47800, training_loss: 1.19508e-01
I0216 02:16:30.617879 22839682574144 run_lib.py:146] step: 47800, eval_loss: 1.24099e-01
I0216 02:16:48.191628 22839682574144 run_lib.py:133] step: 47850, training_loss: 1.15770e-01
I0216 02:17:05.928652 22839682574144 run_lib.py:133] step: 47900, training_loss: 1.22092e-01
I0216 02:17:06.081502 22839682574144 run_lib.py:146] step: 47900, eval_loss: 1.29044e-01
I0216 02:17:23.634939 22839682574144 run_lib.py:133] step: 47950, training_loss: 1.18514e-01
I0216 02:17:41.156279 22839682574144 run_lib.py:133] step: 48000, training_loss: 1.21167e-01
I0216 02:17:41.309955 22839682574144 run_lib.py:146] step: 48000, eval_loss: 1.27064e-01
I0216 02:17:59.026158 22839682574144 run_lib.py:133] step: 48050, training_loss: 1.20716e-01
I0216 02:18:16.583172 22839682574144 run_lib.py:133] step: 48100, training_loss: 1.18215e-01
I0216 02:18:16.746040 22839682574144 run_lib.py:146] step: 48100, eval_loss: 1.27718e-01
I0216 02:18:34.296937 22839682574144 run_lib.py:133] step: 48150, training_loss: 1.21702e-01
I0216 02:18:52.018067 22839682574144 run_lib.py:133] step: 48200, training_loss: 1.18867e-01
I0216 02:18:52.175758 22839682574144 run_lib.py:146] step: 48200, eval_loss: 1.21985e-01
I0216 02:19:09.676108 22839682574144 run_lib.py:133] step: 48250, training_loss: 1.19318e-01
I0216 02:19:27.222286 22839682574144 run_lib.py:133] step: 48300, training_loss: 1.20448e-01
I0216 02:19:27.381344 22839682574144 run_lib.py:146] step: 48300, eval_loss: 1.23426e-01
I0216 02:19:45.000027 22839682574144 run_lib.py:133] step: 48350, training_loss: 1.17351e-01
I0216 02:20:02.525435 22839682574144 run_lib.py:133] step: 48400, training_loss: 1.17343e-01
I0216 02:20:02.680593 22839682574144 run_lib.py:146] step: 48400, eval_loss: 1.28862e-01
I0216 02:20:20.173638 22839682574144 run_lib.py:133] step: 48450, training_loss: 1.17946e-01
I0216 02:20:37.686658 22839682574144 run_lib.py:133] step: 48500, training_loss: 1.18474e-01
I0216 02:20:37.851078 22839682574144 run_lib.py:146] step: 48500, eval_loss: 1.29640e-01
I0216 02:20:55.495865 22839682574144 run_lib.py:133] step: 48550, training_loss: 1.19503e-01
I0216 02:21:13.170668 22839682574144 run_lib.py:133] step: 48600, training_loss: 1.17342e-01
I0216 02:21:13.333277 22839682574144 run_lib.py:146] step: 48600, eval_loss: 1.26221e-01
I0216 02:21:30.861611 22839682574144 run_lib.py:133] step: 48650, training_loss: 1.22413e-01
I0216 02:21:48.366133 22839682574144 run_lib.py:133] step: 48700, training_loss: 1.18600e-01
I0216 02:21:48.523086 22839682574144 run_lib.py:146] step: 48700, eval_loss: 1.26777e-01
I0216 02:22:06.216787 22839682574144 run_lib.py:133] step: 48750, training_loss: 1.15418e-01
I0216 02:22:23.734740 22839682574144 run_lib.py:133] step: 48800, training_loss: 1.16545e-01
I0216 02:22:23.892432 22839682574144 run_lib.py:146] step: 48800, eval_loss: 1.26823e-01
I0216 02:22:41.389686 22839682574144 run_lib.py:133] step: 48850, training_loss: 1.20047e-01
I0216 02:22:59.082329 22839682574144 run_lib.py:133] step: 48900, training_loss: 1.22346e-01
I0216 02:22:59.240413 22839682574144 run_lib.py:146] step: 48900, eval_loss: 1.22692e-01
I0216 02:23:16.785201 22839682574144 run_lib.py:133] step: 48950, training_loss: 1.17650e-01
I0216 02:23:34.483787 22839682574144 run_lib.py:133] step: 49000, training_loss: 1.16349e-01
I0216 02:23:34.642033 22839682574144 run_lib.py:146] step: 49000, eval_loss: 1.29589e-01
I0216 02:23:52.138620 22839682574144 run_lib.py:133] step: 49050, training_loss: 1.19099e-01
I0216 02:24:09.643217 22839682574144 run_lib.py:133] step: 49100, training_loss: 1.17404e-01
I0216 02:24:09.808078 22839682574144 run_lib.py:146] step: 49100, eval_loss: 1.26807e-01
I0216 02:24:27.529413 22839682574144 run_lib.py:133] step: 49150, training_loss: 1.18936e-01
I0216 02:24:45.075672 22839682574144 run_lib.py:133] step: 49200, training_loss: 1.16463e-01
I0216 02:24:45.228830 22839682574144 run_lib.py:146] step: 49200, eval_loss: 1.25964e-01
I0216 02:25:02.724499 22839682574144 run_lib.py:133] step: 49250, training_loss: 1.19612e-01
I0216 02:25:20.425765 22839682574144 run_lib.py:133] step: 49300, training_loss: 1.17034e-01
I0216 02:25:20.584539 22839682574144 run_lib.py:146] step: 49300, eval_loss: 1.29037e-01
I0216 02:25:38.092952 22839682574144 run_lib.py:133] step: 49350, training_loss: 1.17204e-01
I0216 02:25:55.632217 22839682574144 run_lib.py:133] step: 49400, training_loss: 1.15719e-01
I0216 02:25:55.787377 22839682574144 run_lib.py:146] step: 49400, eval_loss: 1.22584e-01
I0216 02:26:13.448098 22839682574144 run_lib.py:133] step: 49450, training_loss: 1.17483e-01
I0216 02:26:30.973800 22839682574144 run_lib.py:133] step: 49500, training_loss: 1.17417e-01
I0216 02:26:31.138810 22839682574144 run_lib.py:146] step: 49500, eval_loss: 1.23050e-01
I0216 02:26:48.651832 22839682574144 run_lib.py:133] step: 49550, training_loss: 1.19914e-01
I0216 02:27:06.183401 22839682574144 run_lib.py:133] step: 49600, training_loss: 1.20370e-01
I0216 02:27:06.342594 22839682574144 run_lib.py:146] step: 49600, eval_loss: 1.29062e-01
I0216 02:27:24.064017 22839682574144 run_lib.py:133] step: 49650, training_loss: 1.18691e-01
I0216 02:27:41.749355 22839682574144 run_lib.py:133] step: 49700, training_loss: 1.17555e-01
I0216 02:27:41.901834 22839682574144 run_lib.py:146] step: 49700, eval_loss: 1.29264e-01
I0216 02:27:59.401434 22839682574144 run_lib.py:133] step: 49750, training_loss: 1.18643e-01
I0216 02:28:16.930583 22839682574144 run_lib.py:133] step: 49800, training_loss: 1.16089e-01
I0216 02:28:17.094078 22839682574144 run_lib.py:146] step: 49800, eval_loss: 1.25296e-01
I0216 02:28:34.835719 22839682574144 run_lib.py:133] step: 49850, training_loss: 1.18267e-01
I0216 02:28:52.352771 22839682574144 run_lib.py:133] step: 49900, training_loss: 1.18423e-01
I0216 02:28:52.507051 22839682574144 run_lib.py:146] step: 49900, eval_loss: 1.27441e-01
I0216 02:29:10.012398 22839682574144 run_lib.py:133] step: 49950, training_loss: 1.19756e-01
I0216 02:29:27.718224 22839682574144 run_lib.py:133] step: 50000, training_loss: 1.14273e-01
I0216 02:29:28.531013 22839682574144 run_lib.py:146] step: 50000, eval_loss: 1.29545e-01
I0216 02:29:48.729722 22839682574144 run_lib.py:133] step: 50050, training_loss: 1.12037e-01
I0216 02:30:06.446940 22839682574144 run_lib.py:133] step: 50100, training_loss: 1.17481e-01
I0216 02:30:06.604938 22839682574144 run_lib.py:146] step: 50100, eval_loss: 1.28580e-01
I0216 02:30:24.123967 22839682574144 run_lib.py:133] step: 50150, training_loss: 1.21390e-01
I0216 02:30:41.740786 22839682574144 run_lib.py:133] step: 50200, training_loss: 1.21268e-01
I0216 02:30:41.904646 22839682574144 run_lib.py:146] step: 50200, eval_loss: 1.23660e-01
I0216 02:30:59.383140 22839682574144 run_lib.py:133] step: 50250, training_loss: 1.22294e-01
I0216 02:31:16.890617 22839682574144 run_lib.py:133] step: 50300, training_loss: 1.14468e-01
I0216 02:31:17.049060 22839682574144 run_lib.py:146] step: 50300, eval_loss: 1.28711e-01
I0216 02:31:34.813036 22839682574144 run_lib.py:133] step: 50350, training_loss: 1.16551e-01
I0216 02:31:52.351096 22839682574144 run_lib.py:133] step: 50400, training_loss: 1.15898e-01
I0216 02:31:52.510287 22839682574144 run_lib.py:146] step: 50400, eval_loss: 1.26303e-01
I0216 02:32:10.249507 22839682574144 run_lib.py:133] step: 50450, training_loss: 1.12466e-01
I0216 02:32:27.746738 22839682574144 run_lib.py:133] step: 50500, training_loss: 1.20083e-01
I0216 02:32:27.909243 22839682574144 run_lib.py:146] step: 50500, eval_loss: 1.29616e-01
I0216 02:32:45.433546 22839682574144 run_lib.py:133] step: 50550, training_loss: 1.20019e-01
I0216 02:33:03.152018 22839682574144 run_lib.py:133] step: 50600, training_loss: 1.18964e-01
I0216 02:33:03.312273 22839682574144 run_lib.py:146] step: 50600, eval_loss: 1.26981e-01
I0216 02:33:20.792879 22839682574144 run_lib.py:133] step: 50650, training_loss: 1.20352e-01
I0216 02:33:38.254212 22839682574144 run_lib.py:133] step: 50700, training_loss: 1.21547e-01
I0216 02:33:38.422899 22839682574144 run_lib.py:146] step: 50700, eval_loss: 1.26375e-01
I0216 02:33:56.142581 22839682574144 run_lib.py:133] step: 50750, training_loss: 1.21354e-01
I0216 02:34:13.653355 22839682574144 run_lib.py:133] step: 50800, training_loss: 1.16117e-01
I0216 02:34:13.811380 22839682574144 run_lib.py:146] step: 50800, eval_loss: 1.27801e-01
I0216 02:34:31.530705 22839682574144 run_lib.py:133] step: 50850, training_loss: 1.23076e-01
I0216 02:34:49.044515 22839682574144 run_lib.py:133] step: 50900, training_loss: 1.19807e-01
I0216 02:34:49.198049 22839682574144 run_lib.py:146] step: 50900, eval_loss: 1.28737e-01
I0216 02:35:06.815585 22839682574144 run_lib.py:133] step: 50950, training_loss: 1.21044e-01
I0216 02:35:24.574918 22839682574144 run_lib.py:133] step: 51000, training_loss: 1.20003e-01
I0216 02:35:24.732165 22839682574144 run_lib.py:146] step: 51000, eval_loss: 1.26816e-01
I0216 02:35:42.244266 22839682574144 run_lib.py:133] step: 51050, training_loss: 1.19634e-01
I0216 02:35:59.737842 22839682574144 run_lib.py:133] step: 51100, training_loss: 1.20855e-01
I0216 02:35:59.897323 22839682574144 run_lib.py:146] step: 51100, eval_loss: 1.30464e-01
I0216 02:36:17.419887 22839682574144 run_lib.py:133] step: 51150, training_loss: 1.17603e-01
I0216 02:36:34.925383 22839682574144 run_lib.py:133] step: 51200, training_loss: 1.19818e-01
I0216 02:36:35.085280 22839682574144 run_lib.py:146] step: 51200, eval_loss: 1.27270e-01
I0216 02:36:52.774296 22839682574144 run_lib.py:133] step: 51250, training_loss: 1.20618e-01
I0216 02:37:10.458575 22839682574144 run_lib.py:133] step: 51300, training_loss: 1.24813e-01
I0216 02:37:10.611643 22839682574144 run_lib.py:146] step: 51300, eval_loss: 1.26818e-01
I0216 02:37:28.161070 22839682574144 run_lib.py:133] step: 51350, training_loss: 1.16997e-01
I0216 02:37:45.706739 22839682574144 run_lib.py:133] step: 51400, training_loss: 1.15614e-01
I0216 02:37:45.862283 22839682574144 run_lib.py:146] step: 51400, eval_loss: 1.24455e-01
I0216 02:38:03.560071 22839682574144 run_lib.py:133] step: 51450, training_loss: 1.22114e-01
I0216 02:38:21.125287 22839682574144 run_lib.py:133] step: 51500, training_loss: 1.27335e-01
I0216 02:38:21.298640 22839682574144 run_lib.py:146] step: 51500, eval_loss: 1.25988e-01
I0216 02:38:39.057384 22839682574144 run_lib.py:133] step: 51550, training_loss: 1.20553e-01
I0216 02:38:56.582785 22839682574144 run_lib.py:133] step: 51600, training_loss: 1.19280e-01
I0216 02:38:56.740011 22839682574144 run_lib.py:146] step: 51600, eval_loss: 1.25096e-01
I0216 02:39:14.239721 22839682574144 run_lib.py:133] step: 51650, training_loss: 1.17106e-01
I0216 02:39:31.926265 22839682574144 run_lib.py:133] step: 51700, training_loss: 1.17350e-01
I0216 02:39:32.086312 22839682574144 run_lib.py:146] step: 51700, eval_loss: 1.29333e-01
I0216 02:39:49.613713 22839682574144 run_lib.py:133] step: 51750, training_loss: 1.19643e-01
I0216 02:40:07.163278 22839682574144 run_lib.py:133] step: 51800, training_loss: 1.13999e-01
I0216 02:40:07.318798 22839682574144 run_lib.py:146] step: 51800, eval_loss: 1.29079e-01
I0216 02:40:25.058197 22839682574144 run_lib.py:133] step: 51850, training_loss: 1.20553e-01
I0216 02:40:42.583699 22839682574144 run_lib.py:133] step: 51900, training_loss: 1.19750e-01
I0216 02:40:42.743037 22839682574144 run_lib.py:146] step: 51900, eval_loss: 1.32043e-01
I0216 02:41:00.387701 22839682574144 run_lib.py:133] step: 51950, training_loss: 1.21001e-01
I0216 02:41:17.923501 22839682574144 run_lib.py:133] step: 52000, training_loss: 1.21938e-01
I0216 02:41:18.102123 22839682574144 run_lib.py:146] step: 52000, eval_loss: 1.30052e-01
I0216 02:41:35.638865 22839682574144 run_lib.py:133] step: 52050, training_loss: 1.18101e-01
I0216 02:41:53.383540 22839682574144 run_lib.py:133] step: 52100, training_loss: 1.13884e-01
I0216 02:41:53.546786 22839682574144 run_lib.py:146] step: 52100, eval_loss: 1.30568e-01
I0216 02:42:11.091530 22839682574144 run_lib.py:133] step: 52150, training_loss: 1.22955e-01
I0216 02:42:28.595528 22839682574144 run_lib.py:133] step: 52200, training_loss: 1.19909e-01
I0216 02:42:28.776038 22839682574144 run_lib.py:146] step: 52200, eval_loss: 1.30760e-01
I0216 02:42:46.319458 22839682574144 run_lib.py:133] step: 52250, training_loss: 1.16612e-01
I0216 02:43:03.880622 22839682574144 run_lib.py:133] step: 52300, training_loss: 1.22431e-01
I0216 02:43:04.036286 22839682574144 run_lib.py:146] step: 52300, eval_loss: 1.25086e-01
I0216 02:43:21.796831 22839682574144 run_lib.py:133] step: 52350, training_loss: 1.22206e-01
I0216 02:43:39.406857 22839682574144 run_lib.py:133] step: 52400, training_loss: 1.19925e-01
I0216 02:43:39.564230 22839682574144 run_lib.py:146] step: 52400, eval_loss: 1.22500e-01
I0216 02:43:57.070904 22839682574144 run_lib.py:133] step: 52450, training_loss: 1.21274e-01
I0216 02:44:14.627575 22839682574144 run_lib.py:133] step: 52500, training_loss: 1.13214e-01
I0216 02:44:14.787261 22839682574144 run_lib.py:146] step: 52500, eval_loss: 1.29220e-01
I0216 02:44:32.519619 22839682574144 run_lib.py:133] step: 52550, training_loss: 1.15656e-01
I0216 02:44:50.076995 22839682574144 run_lib.py:133] step: 52600, training_loss: 1.20001e-01
I0216 02:44:50.233888 22839682574144 run_lib.py:146] step: 52600, eval_loss: 1.24974e-01
I0216 02:45:07.958093 22839682574144 run_lib.py:133] step: 52650, training_loss: 1.17964e-01
I0216 02:45:25.479059 22839682574144 run_lib.py:133] step: 52700, training_loss: 1.15365e-01
I0216 02:45:25.635121 22839682574144 run_lib.py:146] step: 52700, eval_loss: 1.27080e-01
I0216 02:45:43.140017 22839682574144 run_lib.py:133] step: 52750, training_loss: 1.22320e-01
I0216 02:46:00.802292 22839682574144 run_lib.py:133] step: 52800, training_loss: 1.21850e-01
I0216 02:46:00.958625 22839682574144 run_lib.py:146] step: 52800, eval_loss: 1.25067e-01
I0216 02:46:18.529852 22839682574144 run_lib.py:133] step: 52850, training_loss: 1.23706e-01
I0216 02:46:36.070811 22839682574144 run_lib.py:133] step: 52900, training_loss: 1.20690e-01
I0216 02:46:36.229013 22839682574144 run_lib.py:146] step: 52900, eval_loss: 1.30027e-01
I0216 02:46:53.924530 22839682574144 run_lib.py:133] step: 52950, training_loss: 1.21146e-01
I0216 02:47:11.462701 22839682574144 run_lib.py:133] step: 53000, training_loss: 1.15638e-01
I0216 02:47:11.620372 22839682574144 run_lib.py:146] step: 53000, eval_loss: 1.28040e-01
I0216 02:47:29.150552 22839682574144 run_lib.py:133] step: 53050, training_loss: 1.19302e-01
I0216 02:47:46.836367 22839682574144 run_lib.py:133] step: 53100, training_loss: 1.18209e-01
I0216 02:47:47.002814 22839682574144 run_lib.py:146] step: 53100, eval_loss: 1.26483e-01
I0216 02:48:04.507168 22839682574144 run_lib.py:133] step: 53150, training_loss: 1.16241e-01
I0216 02:48:22.032206 22839682574144 run_lib.py:133] step: 53200, training_loss: 1.18622e-01
I0216 02:48:22.187389 22839682574144 run_lib.py:146] step: 53200, eval_loss: 1.29083e-01
I0216 02:48:39.836337 22839682574144 run_lib.py:133] step: 53250, training_loss: 1.17576e-01
I0216 02:48:57.353332 22839682574144 run_lib.py:133] step: 53300, training_loss: 1.22492e-01
I0216 02:48:57.508246 22839682574144 run_lib.py:146] step: 53300, eval_loss: 1.25431e-01
I0216 02:49:15.026447 22839682574144 run_lib.py:133] step: 53350, training_loss: 1.14213e-01
I0216 02:49:32.513383 22839682574144 run_lib.py:133] step: 53400, training_loss: 1.21319e-01
I0216 02:49:32.689917 22839682574144 run_lib.py:146] step: 53400, eval_loss: 1.26136e-01
I0216 02:49:50.411023 22839682574144 run_lib.py:133] step: 53450, training_loss: 1.20666e-01
I0216 02:50:08.070082 22839682574144 run_lib.py:133] step: 53500, training_loss: 1.19520e-01
I0216 02:50:08.229217 22839682574144 run_lib.py:146] step: 53500, eval_loss: 1.24246e-01
I0216 02:50:25.727044 22839682574144 run_lib.py:133] step: 53550, training_loss: 1.18778e-01
I0216 02:50:43.235948 22839682574144 run_lib.py:133] step: 53600, training_loss: 1.17944e-01
I0216 02:50:43.396229 22839682574144 run_lib.py:146] step: 53600, eval_loss: 1.27399e-01
I0216 02:51:01.098657 22839682574144 run_lib.py:133] step: 53650, training_loss: 1.20257e-01
I0216 02:51:18.623623 22839682574144 run_lib.py:133] step: 53700, training_loss: 1.15144e-01
I0216 02:51:18.782778 22839682574144 run_lib.py:146] step: 53700, eval_loss: 1.30506e-01
I0216 02:51:36.300538 22839682574144 run_lib.py:133] step: 53750, training_loss: 1.20827e-01
I0216 02:51:54.031286 22839682574144 run_lib.py:133] step: 53800, training_loss: 1.16217e-01
I0216 02:51:54.213101 22839682574144 run_lib.py:146] step: 53800, eval_loss: 1.25007e-01
I0216 02:52:11.723585 22839682574144 run_lib.py:133] step: 53850, training_loss: 1.18140e-01
I0216 02:52:29.431926 22839682574144 run_lib.py:133] step: 53900, training_loss: 1.17899e-01
I0216 02:52:29.615053 22839682574144 run_lib.py:146] step: 53900, eval_loss: 1.30512e-01
I0216 02:52:47.167275 22839682574144 run_lib.py:133] step: 53950, training_loss: 1.19665e-01
I0216 02:53:04.709854 22839682574144 run_lib.py:133] step: 54000, training_loss: 1.20827e-01
I0216 02:53:04.883363 22839682574144 run_lib.py:146] step: 54000, eval_loss: 1.27263e-01
I0216 02:53:22.649184 22839682574144 run_lib.py:133] step: 54050, training_loss: 1.16913e-01
I0216 02:53:40.139066 22839682574144 run_lib.py:133] step: 54100, training_loss: 1.19893e-01
I0216 02:53:40.292477 22839682574144 run_lib.py:146] step: 54100, eval_loss: 1.31009e-01
I0216 02:53:57.798352 22839682574144 run_lib.py:133] step: 54150, training_loss: 1.17079e-01
I0216 02:54:15.576335 22839682574144 run_lib.py:133] step: 54200, training_loss: 1.16241e-01
I0216 02:54:15.741175 22839682574144 run_lib.py:146] step: 54200, eval_loss: 1.28984e-01
I0216 02:54:33.282815 22839682574144 run_lib.py:133] step: 54250, training_loss: 1.19659e-01
I0216 02:54:50.811709 22839682574144 run_lib.py:133] step: 54300, training_loss: 1.17124e-01
I0216 02:54:50.973059 22839682574144 run_lib.py:146] step: 54300, eval_loss: 1.27469e-01
I0216 02:55:08.572809 22839682574144 run_lib.py:133] step: 54350, training_loss: 1.13428e-01
I0216 02:55:26.104413 22839682574144 run_lib.py:133] step: 54400, training_loss: 1.16081e-01
I0216 02:55:26.267095 22839682574144 run_lib.py:146] step: 54400, eval_loss: 1.26254e-01
I0216 02:55:43.810320 22839682574144 run_lib.py:133] step: 54450, training_loss: 1.18005e-01
I0216 02:56:01.350521 22839682574144 run_lib.py:133] step: 54500, training_loss: 1.19859e-01
I0216 02:56:01.507790 22839682574144 run_lib.py:146] step: 54500, eval_loss: 1.28848e-01
I0216 02:56:19.239946 22839682574144 run_lib.py:133] step: 54550, training_loss: 1.20288e-01
I0216 02:56:36.864219 22839682574144 run_lib.py:133] step: 54600, training_loss: 1.18668e-01
I0216 02:56:37.020453 22839682574144 run_lib.py:146] step: 54600, eval_loss: 1.24056e-01
I0216 02:56:54.558412 22839682574144 run_lib.py:133] step: 54650, training_loss: 1.17095e-01
I0216 02:57:12.145691 22839682574144 run_lib.py:133] step: 54700, training_loss: 1.16158e-01
I0216 02:57:12.302335 22839682574144 run_lib.py:146] step: 54700, eval_loss: 1.26574e-01
I0216 02:57:30.024241 22839682574144 run_lib.py:133] step: 54750, training_loss: 1.14591e-01
I0216 02:57:47.541523 22839682574144 run_lib.py:133] step: 54800, training_loss: 1.20734e-01
I0216 02:57:47.700038 22839682574144 run_lib.py:146] step: 54800, eval_loss: 1.28038e-01
I0216 02:58:05.200966 22839682574144 run_lib.py:133] step: 54850, training_loss: 1.19620e-01
I0216 02:58:22.864844 22839682574144 run_lib.py:133] step: 54900, training_loss: 1.23324e-01
I0216 02:58:23.025105 22839682574144 run_lib.py:146] step: 54900, eval_loss: 1.29037e-01
I0216 02:58:40.553725 22839682574144 run_lib.py:133] step: 54950, training_loss: 1.16023e-01
I0216 02:58:58.265160 22839682574144 run_lib.py:133] step: 55000, training_loss: 1.16901e-01
I0216 02:58:58.422274 22839682574144 run_lib.py:146] step: 55000, eval_loss: 1.27134e-01
I0216 02:59:15.964659 22839682574144 run_lib.py:133] step: 55050, training_loss: 1.19591e-01
I0216 02:59:33.498255 22839682574144 run_lib.py:133] step: 55100, training_loss: 1.16023e-01
I0216 02:59:33.654112 22839682574144 run_lib.py:146] step: 55100, eval_loss: 1.29571e-01
I0216 02:59:51.380308 22839682574144 run_lib.py:133] step: 55150, training_loss: 1.21883e-01
I0216 03:00:08.931398 22839682574144 run_lib.py:133] step: 55200, training_loss: 1.18074e-01
I0216 03:00:09.087014 22839682574144 run_lib.py:146] step: 55200, eval_loss: 1.28176e-01
I0216 03:00:26.638091 22839682574144 run_lib.py:133] step: 55250, training_loss: 1.13765e-01
I0216 03:00:44.353215 22839682574144 run_lib.py:133] step: 55300, training_loss: 1.21318e-01
I0216 03:00:44.513100 22839682574144 run_lib.py:146] step: 55300, eval_loss: 1.27750e-01
I0216 03:01:02.006434 22839682574144 run_lib.py:133] step: 55350, training_loss: 1.20126e-01
I0216 03:01:19.561783 22839682574144 run_lib.py:133] step: 55400, training_loss: 1.19868e-01
I0216 03:01:19.727144 22839682574144 run_lib.py:146] step: 55400, eval_loss: 1.29002e-01
I0216 03:01:37.327675 22839682574144 run_lib.py:133] step: 55450, training_loss: 1.16845e-01
I0216 03:01:54.860044 22839682574144 run_lib.py:133] step: 55500, training_loss: 1.17598e-01
I0216 03:01:55.031939 22839682574144 run_lib.py:146] step: 55500, eval_loss: 1.29159e-01
I0216 03:02:12.560907 22839682574144 run_lib.py:133] step: 55550, training_loss: 1.19850e-01
I0216 03:02:30.050177 22839682574144 run_lib.py:133] step: 55600, training_loss: 1.18658e-01
I0216 03:02:30.204365 22839682574144 run_lib.py:146] step: 55600, eval_loss: 1.30698e-01
I0216 03:02:47.921555 22839682574144 run_lib.py:133] step: 55650, training_loss: 1.17521e-01
I0216 03:03:05.533000 22839682574144 run_lib.py:133] step: 55700, training_loss: 1.19200e-01
I0216 03:03:05.690176 22839682574144 run_lib.py:146] step: 55700, eval_loss: 1.31131e-01
I0216 03:03:23.214452 22839682574144 run_lib.py:133] step: 55750, training_loss: 1.16782e-01
I0216 03:03:40.743805 22839682574144 run_lib.py:133] step: 55800, training_loss: 1.14475e-01
I0216 03:03:40.919113 22839682574144 run_lib.py:146] step: 55800, eval_loss: 1.25316e-01
I0216 03:03:58.679752 22839682574144 run_lib.py:133] step: 55850, training_loss: 1.17928e-01
I0216 03:04:16.188175 22839682574144 run_lib.py:133] step: 55900, training_loss: 1.20709e-01
I0216 03:04:16.345302 22839682574144 run_lib.py:146] step: 55900, eval_loss: 1.29363e-01
I0216 03:04:33.835163 22839682574144 run_lib.py:133] step: 55950, training_loss: 1.17249e-01
I0216 03:04:51.529358 22839682574144 run_lib.py:133] step: 56000, training_loss: 1.20096e-01
I0216 03:04:51.696092 22839682574144 run_lib.py:146] step: 56000, eval_loss: 1.28857e-01
I0216 03:05:09.230587 22839682574144 run_lib.py:133] step: 56050, training_loss: 1.16654e-01
I0216 03:05:26.944472 22839682574144 run_lib.py:133] step: 56100, training_loss: 1.17058e-01
I0216 03:05:27.100291 22839682574144 run_lib.py:146] step: 56100, eval_loss: 1.29533e-01
I0216 03:05:44.622365 22839682574144 run_lib.py:133] step: 56150, training_loss: 1.12462e-01
I0216 03:06:02.135733 22839682574144 run_lib.py:133] step: 56200, training_loss: 1.19474e-01
I0216 03:06:02.293171 22839682574144 run_lib.py:146] step: 56200, eval_loss: 1.29036e-01
I0216 03:06:19.977372 22839682574144 run_lib.py:133] step: 56250, training_loss: 1.20583e-01
I0216 03:06:37.489378 22839682574144 run_lib.py:133] step: 56300, training_loss: 1.21208e-01
I0216 03:06:37.651023 22839682574144 run_lib.py:146] step: 56300, eval_loss: 1.22990e-01
I0216 03:06:55.166705 22839682574144 run_lib.py:133] step: 56350, training_loss: 1.17068e-01
I0216 03:07:12.919437 22839682574144 run_lib.py:133] step: 56400, training_loss: 1.18612e-01
I0216 03:07:13.075690 22839682574144 run_lib.py:146] step: 56400, eval_loss: 1.30456e-01
I0216 03:07:30.599073 22839682574144 run_lib.py:133] step: 56450, training_loss: 1.16051e-01
I0216 03:07:48.126831 22839682574144 run_lib.py:133] step: 56500, training_loss: 1.17576e-01
I0216 03:07:48.284669 22839682574144 run_lib.py:146] step: 56500, eval_loss: 1.27125e-01
I0216 03:08:05.886366 22839682574144 run_lib.py:133] step: 56550, training_loss: 1.21858e-01
I0216 03:08:23.472587 22839682574144 run_lib.py:133] step: 56600, training_loss: 1.14462e-01
I0216 03:08:23.626396 22839682574144 run_lib.py:146] step: 56600, eval_loss: 1.23581e-01
I0216 03:08:41.124562 22839682574144 run_lib.py:133] step: 56650, training_loss: 1.13158e-01
I0216 03:08:58.606310 22839682574144 run_lib.py:133] step: 56700, training_loss: 1.16255e-01
I0216 03:08:58.766070 22839682574144 run_lib.py:146] step: 56700, eval_loss: 1.25527e-01
I0216 03:09:16.473798 22839682574144 run_lib.py:133] step: 56750, training_loss: 1.14109e-01
I0216 03:09:34.059787 22839682574144 run_lib.py:133] step: 56800, training_loss: 1.14984e-01
I0216 03:09:34.218357 22839682574144 run_lib.py:146] step: 56800, eval_loss: 1.28958e-01
I0216 03:09:51.719021 22839682574144 run_lib.py:133] step: 56850, training_loss: 1.20760e-01
I0216 03:10:09.282890 22839682574144 run_lib.py:133] step: 56900, training_loss: 1.16003e-01
I0216 03:10:09.446770 22839682574144 run_lib.py:146] step: 56900, eval_loss: 1.29205e-01
I0216 03:10:27.188058 22839682574144 run_lib.py:133] step: 56950, training_loss: 1.22561e-01
I0216 03:10:44.761076 22839682574144 run_lib.py:133] step: 57000, training_loss: 1.16909e-01
I0216 03:10:44.938734 22839682574144 run_lib.py:146] step: 57000, eval_loss: 1.25547e-01
I0216 03:11:02.475877 22839682574144 run_lib.py:133] step: 57050, training_loss: 1.21696e-01
I0216 03:11:20.156361 22839682574144 run_lib.py:133] step: 57100, training_loss: 1.15025e-01
I0216 03:11:20.312102 22839682574144 run_lib.py:146] step: 57100, eval_loss: 1.26402e-01
I0216 03:11:37.817524 22839682574144 run_lib.py:133] step: 57150, training_loss: 1.18269e-01
I0216 03:11:55.544252 22839682574144 run_lib.py:133] step: 57200, training_loss: 1.15012e-01
I0216 03:11:55.705343 22839682574144 run_lib.py:146] step: 57200, eval_loss: 1.30078e-01
I0216 03:12:13.212280 22839682574144 run_lib.py:133] step: 57250, training_loss: 1.18356e-01
I0216 03:12:30.704262 22839682574144 run_lib.py:133] step: 57300, training_loss: 1.20262e-01
I0216 03:12:30.862132 22839682574144 run_lib.py:146] step: 57300, eval_loss: 1.27039e-01
I0216 03:12:48.542316 22839682574144 run_lib.py:133] step: 57350, training_loss: 1.19348e-01
I0216 03:13:06.066293 22839682574144 run_lib.py:133] step: 57400, training_loss: 1.17854e-01
I0216 03:13:06.233096 22839682574144 run_lib.py:146] step: 57400, eval_loss: 1.28109e-01
I0216 03:13:23.724406 22839682574144 run_lib.py:133] step: 57450, training_loss: 1.15778e-01
I0216 03:13:41.449735 22839682574144 run_lib.py:133] step: 57500, training_loss: 1.16860e-01
I0216 03:13:41.604092 22839682574144 run_lib.py:146] step: 57500, eval_loss: 1.22941e-01
I0216 03:13:59.119348 22839682574144 run_lib.py:133] step: 57550, training_loss: 1.19487e-01
I0216 03:14:16.633638 22839682574144 run_lib.py:133] step: 57600, training_loss: 1.17304e-01
I0216 03:14:16.791035 22839682574144 run_lib.py:146] step: 57600, eval_loss: 1.32678e-01
I0216 03:14:34.359318 22839682574144 run_lib.py:133] step: 57650, training_loss: 1.19281e-01
I0216 03:14:51.917561 22839682574144 run_lib.py:133] step: 57700, training_loss: 1.21480e-01
I0216 03:14:52.092256 22839682574144 run_lib.py:146] step: 57700, eval_loss: 1.24044e-01
I0216 03:15:09.634285 22839682574144 run_lib.py:133] step: 57750, training_loss: 1.19430e-01
I0216 03:15:27.163043 22839682574144 run_lib.py:133] step: 57800, training_loss: 1.16374e-01
I0216 03:15:27.320211 22839682574144 run_lib.py:146] step: 57800, eval_loss: 1.28212e-01
I0216 03:15:45.020436 22839682574144 run_lib.py:133] step: 57850, training_loss: 1.14790e-01
I0216 03:16:02.641434 22839682574144 run_lib.py:133] step: 57900, training_loss: 1.20764e-01
I0216 03:16:02.796684 22839682574144 run_lib.py:146] step: 57900, eval_loss: 1.31778e-01
I0216 03:16:20.295202 22839682574144 run_lib.py:133] step: 57950, training_loss: 1.15595e-01
I0216 03:16:37.872527 22839682574144 run_lib.py:133] step: 58000, training_loss: 1.20187e-01
I0216 03:16:38.029269 22839682574144 run_lib.py:146] step: 58000, eval_loss: 1.28063e-01
I0216 03:16:55.780668 22839682574144 run_lib.py:133] step: 58050, training_loss: 1.16813e-01
I0216 03:17:13.282011 22839682574144 run_lib.py:133] step: 58100, training_loss: 1.21370e-01
I0216 03:17:13.439055 22839682574144 run_lib.py:146] step: 58100, eval_loss: 1.24940e-01
I0216 03:17:30.904997 22839682574144 run_lib.py:133] step: 58150, training_loss: 1.19810e-01
I0216 03:17:48.550148 22839682574144 run_lib.py:133] step: 58200, training_loss: 1.18231e-01
I0216 03:17:48.714099 22839682574144 run_lib.py:146] step: 58200, eval_loss: 1.32290e-01
I0216 03:18:06.297587 22839682574144 run_lib.py:133] step: 58250, training_loss: 1.17567e-01
I0216 03:18:24.033231 22839682574144 run_lib.py:133] step: 58300, training_loss: 1.18508e-01
I0216 03:18:24.191092 22839682574144 run_lib.py:146] step: 58300, eval_loss: 1.26931e-01
I0216 03:18:41.685561 22839682574144 run_lib.py:133] step: 58350, training_loss: 1.21594e-01
I0216 03:18:59.181431 22839682574144 run_lib.py:133] step: 58400, training_loss: 1.21301e-01
I0216 03:18:59.340106 22839682574144 run_lib.py:146] step: 58400, eval_loss: 1.28770e-01
I0216 03:19:17.049213 22839682574144 run_lib.py:133] step: 58450, training_loss: 1.16986e-01
I0216 03:19:34.596342 22839682574144 run_lib.py:133] step: 58500, training_loss: 1.16605e-01
I0216 03:19:34.765112 22839682574144 run_lib.py:146] step: 58500, eval_loss: 1.24787e-01
I0216 03:19:52.313807 22839682574144 run_lib.py:133] step: 58550, training_loss: 1.18346e-01
I0216 03:20:10.057211 22839682574144 run_lib.py:133] step: 58600, training_loss: 1.17541e-01
I0216 03:20:10.216099 22839682574144 run_lib.py:146] step: 58600, eval_loss: 1.30623e-01
I0216 03:20:27.725694 22839682574144 run_lib.py:133] step: 58650, training_loss: 1.19235e-01
I0216 03:20:45.269238 22839682574144 run_lib.py:133] step: 58700, training_loss: 1.19231e-01
I0216 03:20:45.427278 22839682574144 run_lib.py:146] step: 58700, eval_loss: 1.27578e-01
I0216 03:21:03.020884 22839682574144 run_lib.py:133] step: 58750, training_loss: 1.16559e-01
I0216 03:21:20.517457 22839682574144 run_lib.py:133] step: 58800, training_loss: 1.17405e-01
I0216 03:21:20.678729 22839682574144 run_lib.py:146] step: 58800, eval_loss: 1.27841e-01
I0216 03:21:38.224200 22839682574144 run_lib.py:133] step: 58850, training_loss: 1.18328e-01
I0216 03:21:55.762913 22839682574144 run_lib.py:133] step: 58900, training_loss: 1.22734e-01
I0216 03:21:55.919348 22839682574144 run_lib.py:146] step: 58900, eval_loss: 1.27985e-01
I0216 03:22:13.666966 22839682574144 run_lib.py:133] step: 58950, training_loss: 1.17028e-01
I0216 03:22:31.265377 22839682574144 run_lib.py:133] step: 59000, training_loss: 1.19508e-01
I0216 03:22:31.422638 22839682574144 run_lib.py:146] step: 59000, eval_loss: 1.26840e-01
I0216 03:22:48.932282 22839682574144 run_lib.py:133] step: 59050, training_loss: 1.22737e-01
I0216 03:23:06.461291 22839682574144 run_lib.py:133] step: 59100, training_loss: 1.19418e-01
I0216 03:23:06.628019 22839682574144 run_lib.py:146] step: 59100, eval_loss: 1.30927e-01
I0216 03:23:24.377800 22839682574144 run_lib.py:133] step: 59150, training_loss: 1.20324e-01
I0216 03:23:41.906625 22839682574144 run_lib.py:133] step: 59200, training_loss: 1.20557e-01
I0216 03:23:42.065160 22839682574144 run_lib.py:146] step: 59200, eval_loss: 1.26867e-01
I0216 03:23:59.584761 22839682574144 run_lib.py:133] step: 59250, training_loss: 1.20426e-01
I0216 03:24:17.253658 22839682574144 run_lib.py:133] step: 59300, training_loss: 1.17841e-01
I0216 03:24:17.429117 22839682574144 run_lib.py:146] step: 59300, eval_loss: 1.28778e-01
I0216 03:24:35.004228 22839682574144 run_lib.py:133] step: 59350, training_loss: 1.16164e-01
I0216 03:24:52.724737 22839682574144 run_lib.py:133] step: 59400, training_loss: 1.15730e-01
I0216 03:24:52.878796 22839682574144 run_lib.py:146] step: 59400, eval_loss: 1.27254e-01
I0216 03:25:10.399900 22839682574144 run_lib.py:133] step: 59450, training_loss: 1.16624e-01
I0216 03:25:27.884942 22839682574144 run_lib.py:133] step: 59500, training_loss: 1.16746e-01
I0216 03:25:28.042507 22839682574144 run_lib.py:146] step: 59500, eval_loss: 1.24041e-01
I0216 03:25:45.739622 22839682574144 run_lib.py:133] step: 59550, training_loss: 1.18631e-01
I0216 03:26:03.251223 22839682574144 run_lib.py:133] step: 59600, training_loss: 1.17731e-01
I0216 03:26:03.426124 22839682574144 run_lib.py:146] step: 59600, eval_loss: 1.30872e-01
I0216 03:26:20.988656 22839682574144 run_lib.py:133] step: 59650, training_loss: 1.17444e-01
I0216 03:26:38.695792 22839682574144 run_lib.py:133] step: 59700, training_loss: 1.17027e-01
I0216 03:26:38.852622 22839682574144 run_lib.py:146] step: 59700, eval_loss: 1.29795e-01
I0216 03:26:56.342412 22839682574144 run_lib.py:133] step: 59750, training_loss: 1.18583e-01
I0216 03:27:13.886739 22839682574144 run_lib.py:133] step: 59800, training_loss: 1.18369e-01
I0216 03:27:14.045013 22839682574144 run_lib.py:146] step: 59800, eval_loss: 1.26365e-01
I0216 03:27:31.668218 22839682574144 run_lib.py:133] step: 59850, training_loss: 1.22211e-01
I0216 03:27:49.218234 22839682574144 run_lib.py:133] step: 59900, training_loss: 1.16584e-01
I0216 03:27:49.376324 22839682574144 run_lib.py:146] step: 59900, eval_loss: 1.26642e-01
I0216 03:28:06.913665 22839682574144 run_lib.py:133] step: 59950, training_loss: 1.20398e-01
I0216 03:28:24.402395 22839682574144 run_lib.py:133] step: 60000, training_loss: 1.14853e-01
I0216 03:28:25.164061 22839682574144 run_lib.py:146] step: 60000, eval_loss: 1.25841e-01
I0216 03:28:46.007898 22839682574144 run_lib.py:133] step: 60050, training_loss: 1.16025e-01
I0216 03:29:03.521435 22839682574144 run_lib.py:133] step: 60100, training_loss: 1.17769e-01
I0216 03:29:03.698135 22839682574144 run_lib.py:146] step: 60100, eval_loss: 1.25857e-01
I0216 03:29:21.351423 22839682574144 run_lib.py:133] step: 60150, training_loss: 1.20314e-01
I0216 03:29:38.846773 22839682574144 run_lib.py:133] step: 60200, training_loss: 1.17839e-01
I0216 03:29:39.005563 22839682574144 run_lib.py:146] step: 60200, eval_loss: 1.32280e-01
I0216 03:29:56.334994 22839682574144 run_lib.py:133] step: 60250, training_loss: 1.18299e-01
I0216 03:30:13.614272 22839682574144 run_lib.py:133] step: 60300, training_loss: 1.19076e-01
I0216 03:30:13.770158 22839682574144 run_lib.py:146] step: 60300, eval_loss: 1.28487e-01
I0216 03:30:31.273913 22839682574144 run_lib.py:133] step: 60350, training_loss: 1.12212e-01
I0216 03:30:48.742172 22839682574144 run_lib.py:133] step: 60400, training_loss: 1.16355e-01
I0216 03:30:48.894605 22839682574144 run_lib.py:146] step: 60400, eval_loss: 1.25978e-01
I0216 03:31:06.368256 22839682574144 run_lib.py:133] step: 60450, training_loss: 1.14526e-01
I0216 03:31:23.872071 22839682574144 run_lib.py:133] step: 60500, training_loss: 1.15080e-01
I0216 03:31:24.028130 22839682574144 run_lib.py:146] step: 60500, eval_loss: 1.24757e-01
I0216 03:31:41.709954 22839682574144 run_lib.py:133] step: 60550, training_loss: 1.20124e-01
I0216 03:31:59.243863 22839682574144 run_lib.py:133] step: 60600, training_loss: 1.20419e-01
I0216 03:31:59.404565 22839682574144 run_lib.py:146] step: 60600, eval_loss: 1.31710e-01
I0216 03:32:16.974116 22839682574144 run_lib.py:133] step: 60650, training_loss: 1.17325e-01
I0216 03:32:34.764151 22839682574144 run_lib.py:133] step: 60700, training_loss: 1.19313e-01
I0216 03:32:34.922258 22839682574144 run_lib.py:146] step: 60700, eval_loss: 1.23187e-01
I0216 03:32:52.436442 22839682574144 run_lib.py:133] step: 60750, training_loss: 1.17701e-01
I0216 03:33:10.081831 22839682574144 run_lib.py:133] step: 60800, training_loss: 1.21103e-01
I0216 03:33:10.240431 22839682574144 run_lib.py:146] step: 60800, eval_loss: 1.26264e-01
I0216 03:33:27.765322 22839682574144 run_lib.py:133] step: 60850, training_loss: 1.13787e-01
I0216 03:33:45.347498 22839682574144 run_lib.py:133] step: 60900, training_loss: 1.16109e-01
I0216 03:33:45.503364 22839682574144 run_lib.py:146] step: 60900, eval_loss: 1.30885e-01
I0216 03:34:03.233796 22839682574144 run_lib.py:133] step: 60950, training_loss: 1.15823e-01
I0216 03:34:20.739683 22839682574144 run_lib.py:133] step: 61000, training_loss: 1.20132e-01
I0216 03:34:20.903107 22839682574144 run_lib.py:146] step: 61000, eval_loss: 1.30596e-01
I0216 03:34:38.408149 22839682574144 run_lib.py:133] step: 61050, training_loss: 1.18794e-01
I0216 03:34:56.132098 22839682574144 run_lib.py:133] step: 61100, training_loss: 1.20163e-01
I0216 03:34:56.290951 22839682574144 run_lib.py:146] step: 61100, eval_loss: 1.26111e-01
I0216 03:35:13.800091 22839682574144 run_lib.py:133] step: 61150, training_loss: 1.18365e-01
I0216 03:35:31.337373 22839682574144 run_lib.py:133] step: 61200, training_loss: 1.19040e-01
I0216 03:35:31.495876 22839682574144 run_lib.py:146] step: 61200, eval_loss: 1.26364e-01
I0216 03:35:49.193701 22839682574144 run_lib.py:133] step: 61250, training_loss: 1.16760e-01
I0216 03:36:06.732370 22839682574144 run_lib.py:133] step: 61300, training_loss: 1.19030e-01
I0216 03:36:06.889118 22839682574144 run_lib.py:146] step: 61300, eval_loss: 1.29797e-01
I0216 03:36:24.411895 22839682574144 run_lib.py:133] step: 61350, training_loss: 1.16842e-01
I0216 03:36:41.919597 22839682574144 run_lib.py:133] step: 61400, training_loss: 1.13046e-01
I0216 03:36:42.078329 22839682574144 run_lib.py:146] step: 61400, eval_loss: 1.26252e-01
I0216 03:36:59.804676 22839682574144 run_lib.py:133] step: 61450, training_loss: 1.20114e-01
I0216 03:37:17.477623 22839682574144 run_lib.py:133] step: 61500, training_loss: 1.17549e-01
I0216 03:37:17.634940 22839682574144 run_lib.py:146] step: 61500, eval_loss: 1.30009e-01
I0216 03:37:35.173998 22839682574144 run_lib.py:133] step: 61550, training_loss: 1.20152e-01
I0216 03:37:52.706377 22839682574144 run_lib.py:133] step: 61600, training_loss: 1.15637e-01
I0216 03:37:52.867425 22839682574144 run_lib.py:146] step: 61600, eval_loss: 1.25147e-01
I0216 03:38:10.530250 22839682574144 run_lib.py:133] step: 61650, training_loss: 1.17538e-01
I0216 03:38:28.074100 22839682574144 run_lib.py:133] step: 61700, training_loss: 1.16736e-01
I0216 03:38:28.230881 22839682574144 run_lib.py:146] step: 61700, eval_loss: 1.25436e-01
I0216 03:38:45.766648 22839682574144 run_lib.py:133] step: 61750, training_loss: 1.18109e-01
I0216 03:39:03.495463 22839682574144 run_lib.py:133] step: 61800, training_loss: 1.17205e-01
I0216 03:39:03.651049 22839682574144 run_lib.py:146] step: 61800, eval_loss: 1.28749e-01
I0216 03:39:21.138698 22839682574144 run_lib.py:133] step: 61850, training_loss: 1.20693e-01
I0216 03:39:38.806807 22839682574144 run_lib.py:133] step: 61900, training_loss: 1.14582e-01
I0216 03:39:38.963260 22839682574144 run_lib.py:146] step: 61900, eval_loss: 1.23651e-01
I0216 03:39:56.508306 22839682574144 run_lib.py:133] step: 61950, training_loss: 1.14238e-01
I0216 03:40:14.025523 22839682574144 run_lib.py:133] step: 62000, training_loss: 1.17690e-01
I0216 03:40:14.186983 22839682574144 run_lib.py:146] step: 62000, eval_loss: 1.25896e-01
I0216 03:40:31.875249 22839682574144 run_lib.py:133] step: 62050, training_loss: 1.18256e-01
I0216 03:40:49.373531 22839682574144 run_lib.py:133] step: 62100, training_loss: 1.16697e-01
I0216 03:40:49.531066 22839682574144 run_lib.py:146] step: 62100, eval_loss: 1.26520e-01
I0216 03:41:07.021383 22839682574144 run_lib.py:133] step: 62150, training_loss: 1.17050e-01
I0216 03:41:24.832338 22839682574144 run_lib.py:133] step: 62200, training_loss: 1.19218e-01
I0216 03:41:24.992353 22839682574144 run_lib.py:146] step: 62200, eval_loss: 1.25442e-01
I0216 03:41:42.486678 22839682574144 run_lib.py:133] step: 62250, training_loss: 1.14313e-01
I0216 03:41:59.973799 22839682574144 run_lib.py:133] step: 62300, training_loss: 1.18875e-01
I0216 03:42:00.130028 22839682574144 run_lib.py:146] step: 62300, eval_loss: 1.29976e-01
I0216 03:42:17.718702 22839682574144 run_lib.py:133] step: 62350, training_loss: 1.20561e-01
I0216 03:42:35.217785 22839682574144 run_lib.py:133] step: 62400, training_loss: 1.20194e-01
I0216 03:42:35.374093 22839682574144 run_lib.py:146] step: 62400, eval_loss: 1.25922e-01
I0216 03:42:52.893414 22839682574144 run_lib.py:133] step: 62450, training_loss: 1.18474e-01
I0216 03:43:10.449724 22839682574144 run_lib.py:133] step: 62500, training_loss: 1.15927e-01
I0216 03:43:10.621005 22839682574144 run_lib.py:146] step: 62500, eval_loss: 1.33338e-01
I0216 03:43:28.321965 22839682574144 run_lib.py:133] step: 62550, training_loss: 1.18006e-01
I0216 03:43:45.947715 22839682574144 run_lib.py:133] step: 62600, training_loss: 1.18814e-01
I0216 03:43:46.105080 22839682574144 run_lib.py:146] step: 62600, eval_loss: 1.28919e-01
I0216 03:44:03.610931 22839682574144 run_lib.py:133] step: 62650, training_loss: 1.15476e-01
I0216 03:44:21.164405 22839682574144 run_lib.py:133] step: 62700, training_loss: 1.19583e-01
I0216 03:44:21.323200 22839682574144 run_lib.py:146] step: 62700, eval_loss: 1.28179e-01
I0216 03:44:39.019353 22839682574144 run_lib.py:133] step: 62750, training_loss: 1.21066e-01
I0216 03:44:56.596331 22839682574144 run_lib.py:133] step: 62800, training_loss: 1.20383e-01
I0216 03:44:56.753378 22839682574144 run_lib.py:146] step: 62800, eval_loss: 1.29376e-01
I0216 03:45:14.293462 22839682574144 run_lib.py:133] step: 62850, training_loss: 1.20621e-01
I0216 03:45:32.062631 22839682574144 run_lib.py:133] step: 62900, training_loss: 1.19178e-01
I0216 03:45:32.220434 22839682574144 run_lib.py:146] step: 62900, eval_loss: 1.30454e-01
I0216 03:45:49.736401 22839682574144 run_lib.py:133] step: 62950, training_loss: 1.15988e-01
I0216 03:46:07.464720 22839682574144 run_lib.py:133] step: 63000, training_loss: 1.23734e-01
I0216 03:46:07.632445 22839682574144 run_lib.py:146] step: 63000, eval_loss: 1.31539e-01
I0216 03:46:25.197118 22839682574144 run_lib.py:133] step: 63050, training_loss: 1.18875e-01
I0216 03:46:42.731812 22839682574144 run_lib.py:133] step: 63100, training_loss: 1.17529e-01
I0216 03:46:42.890376 22839682574144 run_lib.py:146] step: 63100, eval_loss: 1.27794e-01
I0216 03:47:00.582652 22839682574144 run_lib.py:133] step: 63150, training_loss: 1.21118e-01
I0216 03:47:18.055164 22839682574144 run_lib.py:133] step: 63200, training_loss: 1.17709e-01
I0216 03:47:18.213073 22839682574144 run_lib.py:146] step: 63200, eval_loss: 1.31367e-01
I0216 03:47:35.709113 22839682574144 run_lib.py:133] step: 63250, training_loss: 1.16018e-01
I0216 03:47:53.384242 22839682574144 run_lib.py:133] step: 63300, training_loss: 1.22592e-01
I0216 03:47:53.540345 22839682574144 run_lib.py:146] step: 63300, eval_loss: 1.25209e-01
I0216 03:48:11.089965 22839682574144 run_lib.py:133] step: 63350, training_loss: 1.21354e-01
I0216 03:48:28.608788 22839682574144 run_lib.py:133] step: 63400, training_loss: 1.17207e-01
I0216 03:48:28.767122 22839682574144 run_lib.py:146] step: 63400, eval_loss: 1.34063e-01
I0216 03:48:46.420463 22839682574144 run_lib.py:133] step: 63450, training_loss: 1.15722e-01
I0216 03:49:03.928549 22839682574144 run_lib.py:133] step: 63500, training_loss: 1.12814e-01
I0216 03:49:04.087521 22839682574144 run_lib.py:146] step: 63500, eval_loss: 1.30160e-01
I0216 03:49:21.624654 22839682574144 run_lib.py:133] step: 63550, training_loss: 1.14755e-01
I0216 03:49:39.146955 22839682574144 run_lib.py:133] step: 63600, training_loss: 1.15295e-01
I0216 03:49:39.305199 22839682574144 run_lib.py:146] step: 63600, eval_loss: 1.32890e-01
I0216 03:49:57.022957 22839682574144 run_lib.py:133] step: 63650, training_loss: 1.22052e-01
I0216 03:50:14.641793 22839682574144 run_lib.py:133] step: 63700, training_loss: 1.16905e-01
I0216 03:50:14.797808 22839682574144 run_lib.py:146] step: 63700, eval_loss: 1.27350e-01
I0216 03:50:32.286821 22839682574144 run_lib.py:133] step: 63750, training_loss: 1.16046e-01
I0216 03:50:49.792327 22839682574144 run_lib.py:133] step: 63800, training_loss: 1.19070e-01
I0216 03:50:49.951337 22839682574144 run_lib.py:146] step: 63800, eval_loss: 1.27314e-01
I0216 03:51:07.727616 22839682574144 run_lib.py:133] step: 63850, training_loss: 1.16050e-01
I0216 03:51:25.254784 22839682574144 run_lib.py:133] step: 63900, training_loss: 1.17725e-01
I0216 03:51:25.414020 22839682574144 run_lib.py:146] step: 63900, eval_loss: 1.25882e-01
I0216 03:51:42.876537 22839682574144 run_lib.py:133] step: 63950, training_loss: 1.21644e-01
I0216 03:52:00.535216 22839682574144 run_lib.py:133] step: 64000, training_loss: 1.14157e-01
I0216 03:52:00.692042 22839682574144 run_lib.py:146] step: 64000, eval_loss: 1.28264e-01
I0216 03:52:18.218199 22839682574144 run_lib.py:133] step: 64050, training_loss: 1.12005e-01
I0216 03:52:35.916109 22839682574144 run_lib.py:133] step: 64100, training_loss: 1.13539e-01
I0216 03:52:36.074665 22839682574144 run_lib.py:146] step: 64100, eval_loss: 1.30446e-01
I0216 03:52:53.579050 22839682574144 run_lib.py:133] step: 64150, training_loss: 1.13642e-01
I0216 03:53:11.074157 22839682574144 run_lib.py:133] step: 64200, training_loss: 1.19552e-01
I0216 03:53:11.226969 22839682574144 run_lib.py:146] step: 64200, eval_loss: 1.28187e-01
I0216 03:53:28.941665 22839682574144 run_lib.py:133] step: 64250, training_loss: 1.21255e-01
I0216 03:53:46.475513 22839682574144 run_lib.py:133] step: 64300, training_loss: 1.15287e-01
I0216 03:53:46.642253 22839682574144 run_lib.py:146] step: 64300, eval_loss: 1.29044e-01
I0216 03:54:04.167503 22839682574144 run_lib.py:133] step: 64350, training_loss: 1.18434e-01
I0216 03:54:21.910280 22839682574144 run_lib.py:133] step: 64400, training_loss: 1.21002e-01
I0216 03:54:22.069194 22839682574144 run_lib.py:146] step: 64400, eval_loss: 1.20542e-01
I0216 03:54:39.582760 22839682574144 run_lib.py:133] step: 64450, training_loss: 1.18515e-01
I0216 03:54:57.120290 22839682574144 run_lib.py:133] step: 64500, training_loss: 1.15112e-01
I0216 03:54:57.276482 22839682574144 run_lib.py:146] step: 64500, eval_loss: 1.33003e-01
I0216 03:55:14.873111 22839682574144 run_lib.py:133] step: 64550, training_loss: 1.16224e-01
I0216 03:55:32.410796 22839682574144 run_lib.py:133] step: 64600, training_loss: 1.17631e-01
I0216 03:55:32.569289 22839682574144 run_lib.py:146] step: 64600, eval_loss: 1.31112e-01
I0216 03:55:50.115258 22839682574144 run_lib.py:133] step: 64650, training_loss: 1.17251e-01
I0216 03:56:07.654876 22839682574144 run_lib.py:133] step: 64700, training_loss: 1.15340e-01
I0216 03:56:07.809004 22839682574144 run_lib.py:146] step: 64700, eval_loss: 1.30126e-01
I0216 03:56:25.544848 22839682574144 run_lib.py:133] step: 64750, training_loss: 1.18590e-01
I0216 03:56:43.137007 22839682574144 run_lib.py:133] step: 64800, training_loss: 1.19734e-01
I0216 03:56:43.295231 22839682574144 run_lib.py:146] step: 64800, eval_loss: 1.27076e-01
I0216 03:57:00.820097 22839682574144 run_lib.py:133] step: 64850, training_loss: 1.16838e-01
I0216 03:57:18.403223 22839682574144 run_lib.py:133] step: 64900, training_loss: 1.16875e-01
I0216 03:57:18.563026 22839682574144 run_lib.py:146] step: 64900, eval_loss: 1.30986e-01
I0216 03:57:36.297975 22839682574144 run_lib.py:133] step: 64950, training_loss: 1.14185e-01
I0216 03:57:53.845629 22839682574144 run_lib.py:133] step: 65000, training_loss: 1.20677e-01
I0216 03:57:54.003877 22839682574144 run_lib.py:146] step: 65000, eval_loss: 1.32764e-01
I0216 03:58:11.491459 22839682574144 run_lib.py:133] step: 65050, training_loss: 1.18406e-01
I0216 03:58:29.179508 22839682574144 run_lib.py:133] step: 65100, training_loss: 1.18866e-01
I0216 03:58:29.344300 22839682574144 run_lib.py:146] step: 65100, eval_loss: 1.30230e-01
I0216 03:58:46.903641 22839682574144 run_lib.py:133] step: 65150, training_loss: 1.18222e-01
I0216 03:59:04.662404 22839682574144 run_lib.py:133] step: 65200, training_loss: 1.14871e-01
I0216 03:59:04.816958 22839682574144 run_lib.py:146] step: 65200, eval_loss: 1.29002e-01
I0216 03:59:22.298956 22839682574144 run_lib.py:133] step: 65250, training_loss: 1.18602e-01
I0216 03:59:39.833499 22839682574144 run_lib.py:133] step: 65300, training_loss: 1.15675e-01
I0216 03:59:39.991614 22839682574144 run_lib.py:146] step: 65300, eval_loss: 1.29249e-01
I0216 03:59:57.711241 22839682574144 run_lib.py:133] step: 65350, training_loss: 1.21073e-01
I0216 04:00:15.274230 22839682574144 run_lib.py:133] step: 65400, training_loss: 1.12462e-01
I0216 04:00:15.431066 22839682574144 run_lib.py:146] step: 65400, eval_loss: 1.29738e-01
I0216 04:00:32.946551 22839682574144 run_lib.py:133] step: 65450, training_loss: 1.14612e-01
I0216 04:00:50.656023 22839682574144 run_lib.py:133] step: 65500, training_loss: 1.14552e-01
I0216 04:00:50.814839 22839682574144 run_lib.py:146] step: 65500, eval_loss: 1.32263e-01
I0216 04:01:08.340147 22839682574144 run_lib.py:133] step: 65550, training_loss: 1.21601e-01
I0216 04:01:25.890070 22839682574144 run_lib.py:133] step: 65600, training_loss: 1.18795e-01
I0216 04:01:26.048373 22839682574144 run_lib.py:146] step: 65600, eval_loss: 1.31402e-01
I0216 04:01:43.704131 22839682574144 run_lib.py:133] step: 65650, training_loss: 1.12931e-01
I0216 04:02:01.240701 22839682574144 run_lib.py:133] step: 65700, training_loss: 1.16905e-01
I0216 04:02:01.396319 22839682574144 run_lib.py:146] step: 65700, eval_loss: 1.32562e-01
I0216 04:02:18.922973 22839682574144 run_lib.py:133] step: 65750, training_loss: 1.20626e-01
I0216 04:02:36.421970 22839682574144 run_lib.py:133] step: 65800, training_loss: 1.22355e-01
I0216 04:02:36.582426 22839682574144 run_lib.py:146] step: 65800, eval_loss: 1.26683e-01
I0216 04:02:54.256665 22839682574144 run_lib.py:133] step: 65850, training_loss: 1.16216e-01
I0216 04:03:11.945111 22839682574144 run_lib.py:133] step: 65900, training_loss: 1.12663e-01
I0216 04:03:12.102570 22839682574144 run_lib.py:146] step: 65900, eval_loss: 1.26830e-01
I0216 04:03:29.653476 22839682574144 run_lib.py:133] step: 65950, training_loss: 1.18771e-01
I0216 04:03:47.175031 22839682574144 run_lib.py:133] step: 66000, training_loss: 1.17654e-01
I0216 04:03:47.404329 22839682574144 run_lib.py:146] step: 66000, eval_loss: 1.26739e-01
I0216 04:04:05.111060 22839682574144 run_lib.py:133] step: 66050, training_loss: 1.16361e-01
I0216 04:04:22.622517 22839682574144 run_lib.py:133] step: 66100, training_loss: 1.11318e-01
I0216 04:04:22.791734 22839682574144 run_lib.py:146] step: 66100, eval_loss: 1.31167e-01
I0216 04:04:40.358253 22839682574144 run_lib.py:133] step: 66150, training_loss: 1.15715e-01
I0216 04:04:58.115614 22839682574144 run_lib.py:133] step: 66200, training_loss: 1.14694e-01
I0216 04:04:58.272133 22839682574144 run_lib.py:146] step: 66200, eval_loss: 1.28965e-01
I0216 04:05:15.814587 22839682574144 run_lib.py:133] step: 66250, training_loss: 1.11236e-01
I0216 04:05:33.516450 22839682574144 run_lib.py:133] step: 66300, training_loss: 1.16359e-01
I0216 04:05:33.676362 22839682574144 run_lib.py:146] step: 66300, eval_loss: 1.24057e-01
I0216 04:05:51.226742 22839682574144 run_lib.py:133] step: 66350, training_loss: 1.17263e-01
I0216 04:06:08.780967 22839682574144 run_lib.py:133] step: 66400, training_loss: 1.17496e-01
I0216 04:06:08.939514 22839682574144 run_lib.py:146] step: 66400, eval_loss: 1.28713e-01
I0216 04:06:26.703434 22839682574144 run_lib.py:133] step: 66450, training_loss: 1.13016e-01
I0216 04:06:44.200718 22839682574144 run_lib.py:133] step: 66500, training_loss: 1.16641e-01
I0216 04:06:44.358176 22839682574144 run_lib.py:146] step: 66500, eval_loss: 1.30806e-01
I0216 04:07:01.879270 22839682574144 run_lib.py:133] step: 66550, training_loss: 1.12445e-01
I0216 04:07:19.572754 22839682574144 run_lib.py:133] step: 66600, training_loss: 1.10870e-01
I0216 04:07:19.736735 22839682574144 run_lib.py:146] step: 66600, eval_loss: 1.26522e-01
I0216 04:07:37.319630 22839682574144 run_lib.py:133] step: 66650, training_loss: 1.18444e-01
I0216 04:07:54.837494 22839682574144 run_lib.py:133] step: 66700, training_loss: 1.20245e-01
I0216 04:07:55.011226 22839682574144 run_lib.py:146] step: 66700, eval_loss: 1.31484e-01
I0216 04:08:12.650473 22839682574144 run_lib.py:133] step: 66750, training_loss: 1.13579e-01
I0216 04:08:30.204897 22839682574144 run_lib.py:133] step: 66800, training_loss: 1.13069e-01
I0216 04:08:30.365483 22839682574144 run_lib.py:146] step: 66800, eval_loss: 1.27647e-01
I0216 04:08:47.886448 22839682574144 run_lib.py:133] step: 66850, training_loss: 1.17164e-01
I0216 04:09:05.477334 22839682574144 run_lib.py:133] step: 66900, training_loss: 1.17145e-01
I0216 04:09:05.633995 22839682574144 run_lib.py:146] step: 66900, eval_loss: 1.25821e-01
I0216 04:09:23.428808 22839682574144 run_lib.py:133] step: 66950, training_loss: 1.15571e-01
I0216 04:09:41.043428 22839682574144 run_lib.py:133] step: 67000, training_loss: 1.17223e-01
I0216 04:09:41.201129 22839682574144 run_lib.py:146] step: 67000, eval_loss: 1.29365e-01
I0216 04:09:58.718552 22839682574144 run_lib.py:133] step: 67050, training_loss: 1.11757e-01
I0216 04:10:16.224420 22839682574144 run_lib.py:133] step: 67100, training_loss: 1.18343e-01
I0216 04:10:16.377041 22839682574144 run_lib.py:146] step: 67100, eval_loss: 1.28559e-01
I0216 04:10:34.145545 22839682574144 run_lib.py:133] step: 67150, training_loss: 1.13703e-01
I0216 04:10:51.643690 22839682574144 run_lib.py:133] step: 67200, training_loss: 1.13175e-01
I0216 04:10:51.803021 22839682574144 run_lib.py:146] step: 67200, eval_loss: 1.28614e-01
I0216 04:11:09.317306 22839682574144 run_lib.py:133] step: 67250, training_loss: 1.17111e-01
I0216 04:11:27.063668 22839682574144 run_lib.py:133] step: 67300, training_loss: 1.16528e-01
I0216 04:11:27.222263 22839682574144 run_lib.py:146] step: 67300, eval_loss: 1.32270e-01
I0216 04:11:44.761366 22839682574144 run_lib.py:133] step: 67350, training_loss: 1.18950e-01
I0216 04:12:02.498024 22839682574144 run_lib.py:133] step: 67400, training_loss: 1.15851e-01
I0216 04:12:02.656279 22839682574144 run_lib.py:146] step: 67400, eval_loss: 1.28907e-01
I0216 04:12:20.200716 22839682574144 run_lib.py:133] step: 67450, training_loss: 1.16877e-01
I0216 04:12:37.720592 22839682574144 run_lib.py:133] step: 67500, training_loss: 1.15668e-01
I0216 04:12:37.875744 22839682574144 run_lib.py:146] step: 67500, eval_loss: 1.30954e-01
I0216 04:12:55.630750 22839682574144 run_lib.py:133] step: 67550, training_loss: 1.18981e-01
I0216 04:13:13.188984 22839682574144 run_lib.py:133] step: 67600, training_loss: 1.15031e-01
I0216 04:13:13.343031 22839682574144 run_lib.py:146] step: 67600, eval_loss: 1.26771e-01
I0216 04:13:30.863530 22839682574144 run_lib.py:133] step: 67650, training_loss: 1.16590e-01
I0216 04:13:48.605187 22839682574144 run_lib.py:133] step: 67700, training_loss: 1.15604e-01
I0216 04:13:48.774468 22839682574144 run_lib.py:146] step: 67700, eval_loss: 1.27489e-01
I0216 04:14:06.313759 22839682574144 run_lib.py:133] step: 67750, training_loss: 1.15952e-01
I0216 04:14:23.853808 22839682574144 run_lib.py:133] step: 67800, training_loss: 1.18878e-01
I0216 04:14:24.011129 22839682574144 run_lib.py:146] step: 67800, eval_loss: 1.25821e-01
I0216 04:14:41.649612 22839682574144 run_lib.py:133] step: 67850, training_loss: 1.16277e-01
I0216 04:14:59.192384 22839682574144 run_lib.py:133] step: 67900, training_loss: 1.17938e-01
I0216 04:14:59.360921 22839682574144 run_lib.py:146] step: 67900, eval_loss: 1.27285e-01
I0216 04:15:16.926462 22839682574144 run_lib.py:133] step: 67950, training_loss: 1.16943e-01
I0216 04:15:34.483495 22839682574144 run_lib.py:133] step: 68000, training_loss: 1.15586e-01
I0216 04:15:34.636924 22839682574144 run_lib.py:146] step: 68000, eval_loss: 1.28788e-01
I0216 04:15:52.344042 22839682574144 run_lib.py:133] step: 68050, training_loss: 1.15731e-01
I0216 04:16:09.966034 22839682574144 run_lib.py:133] step: 68100, training_loss: 1.17418e-01
I0216 04:16:10.123214 22839682574144 run_lib.py:146] step: 68100, eval_loss: 1.27892e-01
I0216 04:16:27.628726 22839682574144 run_lib.py:133] step: 68150, training_loss: 1.16564e-01
I0216 04:16:45.215332 22839682574144 run_lib.py:133] step: 68200, training_loss: 1.13736e-01
I0216 04:16:45.377127 22839682574144 run_lib.py:146] step: 68200, eval_loss: 1.26436e-01
I0216 04:17:03.096937 22839682574144 run_lib.py:133] step: 68250, training_loss: 1.15870e-01
I0216 04:17:20.627928 22839682574144 run_lib.py:133] step: 68300, training_loss: 1.14098e-01
I0216 04:17:20.818270 22839682574144 run_lib.py:146] step: 68300, eval_loss: 1.29810e-01
I0216 04:17:38.355958 22839682574144 run_lib.py:133] step: 68350, training_loss: 1.18633e-01
I0216 04:17:56.068453 22839682574144 run_lib.py:133] step: 68400, training_loss: 1.20841e-01
I0216 04:17:56.227707 22839682574144 run_lib.py:146] step: 68400, eval_loss: 1.28723e-01
I0216 04:18:13.792526 22839682574144 run_lib.py:133] step: 68450, training_loss: 1.18948e-01
I0216 04:18:31.500494 22839682574144 run_lib.py:133] step: 68500, training_loss: 1.19055e-01
I0216 04:18:31.654346 22839682574144 run_lib.py:146] step: 68500, eval_loss: 1.26315e-01
I0216 04:18:49.133724 22839682574144 run_lib.py:133] step: 68550, training_loss: 1.15290e-01
I0216 04:19:06.649677 22839682574144 run_lib.py:133] step: 68600, training_loss: 1.15246e-01
I0216 04:19:06.815084 22839682574144 run_lib.py:146] step: 68600, eval_loss: 1.26327e-01
I0216 04:19:24.505623 22839682574144 run_lib.py:133] step: 68650, training_loss: 1.15881e-01
I0216 04:19:42.048904 22839682574144 run_lib.py:133] step: 68700, training_loss: 1.16335e-01
I0216 04:19:42.215116 22839682574144 run_lib.py:146] step: 68700, eval_loss: 1.25076e-01
I0216 04:19:59.762252 22839682574144 run_lib.py:133] step: 68750, training_loss: 1.15964e-01
I0216 04:20:17.490322 22839682574144 run_lib.py:133] step: 68800, training_loss: 1.13897e-01
I0216 04:20:17.657088 22839682574144 run_lib.py:146] step: 68800, eval_loss: 1.29420e-01
I0216 04:20:35.150025 22839682574144 run_lib.py:133] step: 68850, training_loss: 1.18982e-01
I0216 04:20:52.680552 22839682574144 run_lib.py:133] step: 68900, training_loss: 1.14094e-01
I0216 04:20:52.863333 22839682574144 run_lib.py:146] step: 68900, eval_loss: 1.32645e-01
I0216 04:21:10.536025 22839682574144 run_lib.py:133] step: 68950, training_loss: 1.19161e-01
I0216 04:21:28.025644 22839682574144 run_lib.py:133] step: 69000, training_loss: 1.16835e-01
I0216 04:21:28.190048 22839682574144 run_lib.py:146] step: 69000, eval_loss: 1.28650e-01
I0216 04:21:45.676608 22839682574144 run_lib.py:133] step: 69050, training_loss: 1.15363e-01
I0216 04:22:03.217738 22839682574144 run_lib.py:133] step: 69100, training_loss: 1.19148e-01
I0216 04:22:03.376506 22839682574144 run_lib.py:146] step: 69100, eval_loss: 1.23490e-01
I0216 04:22:21.091129 22839682574144 run_lib.py:133] step: 69150, training_loss: 1.19912e-01
I0216 04:22:38.696841 22839682574144 run_lib.py:133] step: 69200, training_loss: 1.16434e-01
I0216 04:22:38.863024 22839682574144 run_lib.py:146] step: 69200, eval_loss: 1.32508e-01
I0216 04:22:56.363793 22839682574144 run_lib.py:133] step: 69250, training_loss: 1.23176e-01
I0216 04:23:13.888484 22839682574144 run_lib.py:133] step: 69300, training_loss: 1.17344e-01
I0216 04:23:14.046827 22839682574144 run_lib.py:146] step: 69300, eval_loss: 1.25616e-01
I0216 04:23:31.752196 22839682574144 run_lib.py:133] step: 69350, training_loss: 1.17034e-01
I0216 04:23:49.239987 22839682574144 run_lib.py:133] step: 69400, training_loss: 1.15161e-01
I0216 04:23:49.396269 22839682574144 run_lib.py:146] step: 69400, eval_loss: 1.29517e-01
I0216 04:24:06.904580 22839682574144 run_lib.py:133] step: 69450, training_loss: 1.18177e-01
I0216 04:24:24.670157 22839682574144 run_lib.py:133] step: 69500, training_loss: 1.20303e-01
I0216 04:24:24.830257 22839682574144 run_lib.py:146] step: 69500, eval_loss: 1.30155e-01
I0216 04:24:42.350242 22839682574144 run_lib.py:133] step: 69550, training_loss: 1.18955e-01
I0216 04:25:00.077871 22839682574144 run_lib.py:133] step: 69600, training_loss: 1.16633e-01
I0216 04:25:00.237503 22839682574144 run_lib.py:146] step: 69600, eval_loss: 1.27708e-01
I0216 04:25:17.720549 22839682574144 run_lib.py:133] step: 69650, training_loss: 1.14349e-01
I0216 04:25:35.222974 22839682574144 run_lib.py:133] step: 69700, training_loss: 1.19014e-01
I0216 04:25:35.380700 22839682574144 run_lib.py:146] step: 69700, eval_loss: 1.29630e-01
I0216 04:25:53.110370 22839682574144 run_lib.py:133] step: 69750, training_loss: 1.18137e-01
I0216 04:26:10.653626 22839682574144 run_lib.py:133] step: 69800, training_loss: 1.17809e-01
I0216 04:26:10.815365 22839682574144 run_lib.py:146] step: 69800, eval_loss: 1.25782e-01
I0216 04:26:28.351641 22839682574144 run_lib.py:133] step: 69850, training_loss: 1.16759e-01
I0216 04:26:46.070712 22839682574144 run_lib.py:133] step: 69900, training_loss: 1.16280e-01
I0216 04:26:46.224115 22839682574144 run_lib.py:146] step: 69900, eval_loss: 1.29702e-01
I0216 04:27:03.805469 22839682574144 run_lib.py:133] step: 69950, training_loss: 1.14705e-01
I0216 04:27:21.337613 22839682574144 run_lib.py:133] step: 70000, training_loss: 1.16536e-01
I0216 04:27:22.110143 22839682574144 run_lib.py:146] step: 70000, eval_loss: 1.28033e-01
I0216 04:27:42.570214 22839682574144 run_lib.py:133] step: 70050, training_loss: 1.15767e-01
I0216 04:28:00.295979 22839682574144 run_lib.py:133] step: 70100, training_loss: 1.17805e-01
I0216 04:28:00.454030 22839682574144 run_lib.py:146] step: 70100, eval_loss: 1.29427e-01
I0216 04:28:17.944414 22839682574144 run_lib.py:133] step: 70150, training_loss: 1.11558e-01
I0216 04:28:35.483430 22839682574144 run_lib.py:133] step: 70200, training_loss: 1.15855e-01
I0216 04:28:35.642405 22839682574144 run_lib.py:146] step: 70200, eval_loss: 1.25799e-01
I0216 04:28:53.137862 22839682574144 run_lib.py:133] step: 70250, training_loss: 1.18857e-01
I0216 04:29:10.888139 22839682574144 run_lib.py:133] step: 70300, training_loss: 1.16835e-01
I0216 04:29:11.046443 22839682574144 run_lib.py:146] step: 70300, eval_loss: 1.28677e-01
I0216 04:29:28.573009 22839682574144 run_lib.py:133] step: 70350, training_loss: 1.13651e-01
I0216 04:29:46.061422 22839682574144 run_lib.py:133] step: 70400, training_loss: 1.14810e-01
I0216 04:29:46.229140 22839682574144 run_lib.py:146] step: 70400, eval_loss: 1.34132e-01
I0216 04:30:03.737006 22839682574144 run_lib.py:133] step: 70450, training_loss: 1.09113e-01
I0216 04:30:21.475749 22839682574144 run_lib.py:133] step: 70500, training_loss: 1.16683e-01
I0216 04:30:21.630155 22839682574144 run_lib.py:146] step: 70500, eval_loss: 1.31152e-01
I0216 04:30:39.166503 22839682574144 run_lib.py:133] step: 70550, training_loss: 1.16359e-01
I0216 04:30:56.825766 22839682574144 run_lib.py:133] step: 70600, training_loss: 1.16076e-01
I0216 04:30:56.985043 22839682574144 run_lib.py:146] step: 70600, eval_loss: 1.31361e-01
I0216 04:31:14.510152 22839682574144 run_lib.py:133] step: 70650, training_loss: 1.16677e-01
I0216 04:31:32.002304 22839682574144 run_lib.py:133] step: 70700, training_loss: 1.18626e-01
I0216 04:31:32.160418 22839682574144 run_lib.py:146] step: 70700, eval_loss: 1.29416e-01
I0216 04:31:49.859879 22839682574144 run_lib.py:133] step: 70750, training_loss: 1.14057e-01
I0216 04:32:07.388381 22839682574144 run_lib.py:133] step: 70800, training_loss: 1.16763e-01
I0216 04:32:07.560058 22839682574144 run_lib.py:146] step: 70800, eval_loss: 1.25801e-01
I0216 04:32:25.327262 22839682574144 run_lib.py:133] step: 70850, training_loss: 1.15905e-01
I0216 04:32:42.890552 22839682574144 run_lib.py:133] step: 70900, training_loss: 1.15900e-01
I0216 04:32:43.046408 22839682574144 run_lib.py:146] step: 70900, eval_loss: 1.30210e-01
I0216 04:33:00.556071 22839682574144 run_lib.py:133] step: 70950, training_loss: 1.12759e-01
I0216 04:33:18.263008 22839682574144 run_lib.py:133] step: 71000, training_loss: 1.13262e-01
I0216 04:33:18.419048 22839682574144 run_lib.py:146] step: 71000, eval_loss: 1.29115e-01
I0216 04:33:35.978597 22839682574144 run_lib.py:133] step: 71050, training_loss: 1.10969e-01
I0216 04:33:53.559516 22839682574144 run_lib.py:133] step: 71100, training_loss: 1.14325e-01
I0216 04:33:53.724990 22839682574144 run_lib.py:146] step: 71100, eval_loss: 1.29413e-01
I0216 04:34:11.442644 22839682574144 run_lib.py:133] step: 71150, training_loss: 1.13668e-01
I0216 04:34:29.008955 22839682574144 run_lib.py:133] step: 71200, training_loss: 1.14025e-01
I0216 04:34:29.166044 22839682574144 run_lib.py:146] step: 71200, eval_loss: 1.25548e-01
I0216 04:34:46.884394 22839682574144 run_lib.py:133] step: 71250, training_loss: 1.19308e-01
I0216 04:35:04.395120 22839682574144 run_lib.py:133] step: 71300, training_loss: 1.13558e-01
I0216 04:35:04.559123 22839682574144 run_lib.py:146] step: 71300, eval_loss: 1.32363e-01
I0216 04:35:22.076781 22839682574144 run_lib.py:133] step: 71350, training_loss: 1.12378e-01
I0216 04:35:39.817326 22839682574144 run_lib.py:133] step: 71400, training_loss: 1.18633e-01
I0216 04:35:39.982021 22839682574144 run_lib.py:146] step: 71400, eval_loss: 1.25540e-01
I0216 04:35:57.543624 22839682574144 run_lib.py:133] step: 71450, training_loss: 1.14204e-01
I0216 04:36:15.077404 22839682574144 run_lib.py:133] step: 71500, training_loss: 1.16705e-01
I0216 04:36:15.240310 22839682574144 run_lib.py:146] step: 71500, eval_loss: 1.28591e-01
I0216 04:36:32.742553 22839682574144 run_lib.py:133] step: 71550, training_loss: 1.16395e-01
I0216 04:36:50.283109 22839682574144 run_lib.py:133] step: 71600, training_loss: 1.15698e-01
I0216 04:36:50.457076 22839682574144 run_lib.py:146] step: 71600, eval_loss: 1.28072e-01
I0216 04:37:08.208593 22839682574144 run_lib.py:133] step: 71650, training_loss: 1.18105e-01
I0216 04:37:25.858623 22839682574144 run_lib.py:133] step: 71700, training_loss: 1.21292e-01
I0216 04:37:26.016387 22839682574144 run_lib.py:146] step: 71700, eval_loss: 1.25811e-01
I0216 04:37:43.551096 22839682574144 run_lib.py:133] step: 71750, training_loss: 1.15268e-01
I0216 04:38:01.034487 22839682574144 run_lib.py:133] step: 71800, training_loss: 1.21067e-01
I0216 04:38:01.202027 22839682574144 run_lib.py:146] step: 71800, eval_loss: 1.28272e-01
I0216 04:38:18.954807 22839682574144 run_lib.py:133] step: 71850, training_loss: 1.15045e-01
I0216 04:38:36.486614 22839682574144 run_lib.py:133] step: 71900, training_loss: 1.15661e-01
I0216 04:38:36.664331 22839682574144 run_lib.py:146] step: 71900, eval_loss: 1.32601e-01
I0216 04:38:54.388035 22839682574144 run_lib.py:133] step: 71950, training_loss: 1.18019e-01
I0216 04:39:11.922393 22839682574144 run_lib.py:133] step: 72000, training_loss: 1.13495e-01
I0216 04:39:12.079113 22839682574144 run_lib.py:146] step: 72000, eval_loss: 1.30465e-01
I0216 04:39:29.595409 22839682574144 run_lib.py:133] step: 72050, training_loss: 1.14751e-01
I0216 04:39:47.270574 22839682574144 run_lib.py:133] step: 72100, training_loss: 1.19117e-01
I0216 04:39:47.429996 22839682574144 run_lib.py:146] step: 72100, eval_loss: 1.28242e-01
I0216 04:40:04.953837 22839682574144 run_lib.py:133] step: 72150, training_loss: 1.16697e-01
I0216 04:40:22.495296 22839682574144 run_lib.py:133] step: 72200, training_loss: 1.18560e-01
I0216 04:40:22.651798 22839682574144 run_lib.py:146] step: 72200, eval_loss: 1.31097e-01
I0216 04:40:40.409734 22839682574144 run_lib.py:133] step: 72250, training_loss: 1.16688e-01
I0216 04:40:57.894361 22839682574144 run_lib.py:133] step: 72300, training_loss: 1.12786e-01
I0216 04:40:58.050975 22839682574144 run_lib.py:146] step: 72300, eval_loss: 1.30661e-01
I0216 04:41:15.724357 22839682574144 run_lib.py:133] step: 72350, training_loss: 1.14860e-01
I0216 04:41:33.259665 22839682574144 run_lib.py:133] step: 72400, training_loss: 1.20052e-01
I0216 04:41:33.417275 22839682574144 run_lib.py:146] step: 72400, eval_loss: 1.25077e-01
I0216 04:41:50.944576 22839682574144 run_lib.py:133] step: 72450, training_loss: 1.18528e-01
I0216 04:42:08.686377 22839682574144 run_lib.py:133] step: 72500, training_loss: 1.16138e-01
I0216 04:42:08.847173 22839682574144 run_lib.py:146] step: 72500, eval_loss: 1.25753e-01
I0216 04:42:26.295199 22839682574144 run_lib.py:133] step: 72550, training_loss: 1.13398e-01
I0216 04:42:43.790362 22839682574144 run_lib.py:133] step: 72600, training_loss: 1.15604e-01
I0216 04:42:43.958209 22839682574144 run_lib.py:146] step: 72600, eval_loss: 1.30008e-01
I0216 04:43:01.479514 22839682574144 run_lib.py:133] step: 72650, training_loss: 1.19698e-01
I0216 04:43:19.003241 22839682574144 run_lib.py:133] step: 72700, training_loss: 1.17834e-01
I0216 04:43:19.162343 22839682574144 run_lib.py:146] step: 72700, eval_loss: 1.30625e-01
I0216 04:43:36.885274 22839682574144 run_lib.py:133] step: 72750, training_loss: 1.20025e-01
I0216 04:43:54.482172 22839682574144 run_lib.py:133] step: 72800, training_loss: 1.20402e-01
I0216 04:43:54.635800 22839682574144 run_lib.py:146] step: 72800, eval_loss: 1.27928e-01
I0216 04:44:12.142436 22839682574144 run_lib.py:133] step: 72850, training_loss: 1.13427e-01
I0216 04:44:29.658434 22839682574144 run_lib.py:133] step: 72900, training_loss: 1.14439e-01
I0216 04:44:29.823244 22839682574144 run_lib.py:146] step: 72900, eval_loss: 1.30042e-01
I0216 04:44:47.585178 22839682574144 run_lib.py:133] step: 72950, training_loss: 1.12134e-01
I0216 04:45:05.090317 22839682574144 run_lib.py:133] step: 73000, training_loss: 1.13125e-01
I0216 04:45:05.250020 22839682574144 run_lib.py:146] step: 73000, eval_loss: 1.32023e-01
I0216 04:45:22.912007 22839682574144 run_lib.py:133] step: 73050, training_loss: 1.14715e-01
I0216 04:45:40.424415 22839682574144 run_lib.py:133] step: 73100, training_loss: 1.17712e-01
I0216 04:45:40.582077 22839682574144 run_lib.py:146] step: 73100, eval_loss: 1.33990e-01
I0216 04:45:58.126738 22839682574144 run_lib.py:133] step: 73150, training_loss: 1.14735e-01
I0216 04:46:15.859332 22839682574144 run_lib.py:133] step: 73200, training_loss: 1.13882e-01
I0216 04:46:16.018607 22839682574144 run_lib.py:146] step: 73200, eval_loss: 1.25499e-01
I0216 04:46:33.543362 22839682574144 run_lib.py:133] step: 73250, training_loss: 1.15872e-01
I0216 04:46:51.029873 22839682574144 run_lib.py:133] step: 73300, training_loss: 1.12926e-01
I0216 04:46:51.184070 22839682574144 run_lib.py:146] step: 73300, eval_loss: 1.29992e-01
I0216 04:47:08.874689 22839682574144 run_lib.py:133] step: 73350, training_loss: 1.14481e-01
I0216 04:47:26.413156 22839682574144 run_lib.py:133] step: 73400, training_loss: 1.16221e-01
I0216 04:47:26.572018 22839682574144 run_lib.py:146] step: 73400, eval_loss: 1.27396e-01
I0216 04:47:44.111419 22839682574144 run_lib.py:133] step: 73450, training_loss: 1.20218e-01
I0216 04:48:01.826957 22839682574144 run_lib.py:133] step: 73500, training_loss: 1.14495e-01
I0216 04:48:01.987188 22839682574144 run_lib.py:146] step: 73500, eval_loss: 1.32954e-01
I0216 04:48:19.470728 22839682574144 run_lib.py:133] step: 73550, training_loss: 1.17137e-01
I0216 04:48:36.988476 22839682574144 run_lib.py:133] step: 73600, training_loss: 1.14739e-01
I0216 04:48:37.146325 22839682574144 run_lib.py:146] step: 73600, eval_loss: 1.25883e-01
I0216 04:48:54.761734 22839682574144 run_lib.py:133] step: 73650, training_loss: 1.16636e-01
I0216 04:49:12.321329 22839682574144 run_lib.py:133] step: 73700, training_loss: 1.18440e-01
I0216 04:49:12.478283 22839682574144 run_lib.py:146] step: 73700, eval_loss: 1.30633e-01
I0216 04:49:29.996515 22839682574144 run_lib.py:133] step: 73750, training_loss: 1.18356e-01
I0216 04:49:47.561658 22839682574144 run_lib.py:133] step: 73800, training_loss: 1.15098e-01
I0216 04:49:47.717085 22839682574144 run_lib.py:146] step: 73800, eval_loss: 1.28752e-01
I0216 04:50:05.441435 22839682574144 run_lib.py:133] step: 73850, training_loss: 1.16944e-01
I0216 04:50:23.052839 22839682574144 run_lib.py:133] step: 73900, training_loss: 1.13821e-01
I0216 04:50:23.212776 22839682574144 run_lib.py:146] step: 73900, eval_loss: 1.28933e-01
I0216 04:50:40.759961 22839682574144 run_lib.py:133] step: 73950, training_loss: 1.16015e-01
I0216 04:50:58.339943 22839682574144 run_lib.py:133] step: 74000, training_loss: 1.18550e-01
I0216 04:50:58.500083 22839682574144 run_lib.py:146] step: 74000, eval_loss: 1.27021e-01
I0216 04:51:16.226852 22839682574144 run_lib.py:133] step: 74050, training_loss: 1.17011e-01
I0216 04:51:33.709939 22839682574144 run_lib.py:133] step: 74100, training_loss: 1.12299e-01
I0216 04:51:33.866014 22839682574144 run_lib.py:146] step: 74100, eval_loss: 1.27191e-01
I0216 04:51:51.413334 22839682574144 run_lib.py:133] step: 74150, training_loss: 1.15558e-01
I0216 04:52:09.077826 22839682574144 run_lib.py:133] step: 74200, training_loss: 1.14404e-01
I0216 04:52:09.238699 22839682574144 run_lib.py:146] step: 74200, eval_loss: 1.30435e-01
I0216 04:52:26.761419 22839682574144 run_lib.py:133] step: 74250, training_loss: 1.16527e-01
I0216 04:52:44.475453 22839682574144 run_lib.py:133] step: 74300, training_loss: 1.16804e-01
I0216 04:52:44.633235 22839682574144 run_lib.py:146] step: 74300, eval_loss: 1.26395e-01
I0216 04:53:02.143322 22839682574144 run_lib.py:133] step: 74350, training_loss: 1.16843e-01
I0216 04:53:19.670338 22839682574144 run_lib.py:133] step: 74400, training_loss: 1.15786e-01
I0216 04:53:19.830348 22839682574144 run_lib.py:146] step: 74400, eval_loss: 1.30347e-01
I0216 04:53:37.493076 22839682574144 run_lib.py:133] step: 74450, training_loss: 1.17406e-01
I0216 04:53:54.998794 22839682574144 run_lib.py:133] step: 74500, training_loss: 1.19886e-01
I0216 04:53:55.158389 22839682574144 run_lib.py:146] step: 74500, eval_loss: 1.30063e-01
I0216 04:54:12.678722 22839682574144 run_lib.py:133] step: 74550, training_loss: 1.19109e-01
I0216 04:54:30.467663 22839682574144 run_lib.py:133] step: 74600, training_loss: 1.18440e-01
I0216 04:54:30.621379 22839682574144 run_lib.py:146] step: 74600, eval_loss: 1.30374e-01
I0216 04:54:48.169268 22839682574144 run_lib.py:133] step: 74650, training_loss: 1.18644e-01
I0216 04:55:05.684343 22839682574144 run_lib.py:133] step: 74700, training_loss: 1.18819e-01
I0216 04:55:05.840059 22839682574144 run_lib.py:146] step: 74700, eval_loss: 1.30153e-01
I0216 04:55:23.422059 22839682574144 run_lib.py:133] step: 74750, training_loss: 1.16947e-01
I0216 04:55:40.971185 22839682574144 run_lib.py:133] step: 74800, training_loss: 1.12514e-01
I0216 04:55:41.136213 22839682574144 run_lib.py:146] step: 74800, eval_loss: 1.28280e-01
I0216 04:55:58.663171 22839682574144 run_lib.py:133] step: 74850, training_loss: 1.16399e-01
I0216 04:56:16.187473 22839682574144 run_lib.py:133] step: 74900, training_loss: 1.17312e-01
I0216 04:56:16.347050 22839682574144 run_lib.py:146] step: 74900, eval_loss: 1.26269e-01
I0216 04:56:34.064079 22839682574144 run_lib.py:133] step: 74950, training_loss: 1.14477e-01
I0216 04:56:51.668440 22839682574144 run_lib.py:133] step: 75000, training_loss: 1.15724e-01
I0216 04:56:51.826043 22839682574144 run_lib.py:146] step: 75000, eval_loss: 1.31397e-01
I0216 04:57:09.353044 22839682574144 run_lib.py:133] step: 75050, training_loss: 1.16410e-01
I0216 04:57:26.867961 22839682574144 run_lib.py:133] step: 75100, training_loss: 1.18851e-01
I0216 04:57:27.026338 22839682574144 run_lib.py:146] step: 75100, eval_loss: 1.29263e-01
I0216 04:57:44.783102 22839682574144 run_lib.py:133] step: 75150, training_loss: 1.09937e-01
I0216 04:58:02.316295 22839682574144 run_lib.py:133] step: 75200, training_loss: 1.19492e-01
I0216 04:58:02.470773 22839682574144 run_lib.py:146] step: 75200, eval_loss: 1.28265e-01
I0216 04:58:19.962590 22839682574144 run_lib.py:133] step: 75250, training_loss: 1.07796e-01
I0216 04:58:37.628921 22839682574144 run_lib.py:133] step: 75300, training_loss: 1.14436e-01
I0216 04:58:37.799365 22839682574144 run_lib.py:146] step: 75300, eval_loss: 1.28935e-01
I0216 04:58:55.365044 22839682574144 run_lib.py:133] step: 75350, training_loss: 1.15093e-01
I0216 04:59:13.097531 22839682574144 run_lib.py:133] step: 75400, training_loss: 1.15467e-01
I0216 04:59:13.255190 22839682574144 run_lib.py:146] step: 75400, eval_loss: 1.27702e-01
I0216 04:59:30.729277 22839682574144 run_lib.py:133] step: 75450, training_loss: 1.12545e-01
I0216 04:59:48.271646 22839682574144 run_lib.py:133] step: 75500, training_loss: 1.16516e-01
I0216 04:59:48.436768 22839682574144 run_lib.py:146] step: 75500, eval_loss: 1.28552e-01
I0216 05:00:06.170821 22839682574144 run_lib.py:133] step: 75550, training_loss: 1.18091e-01
I0216 05:00:23.690671 22839682574144 run_lib.py:133] step: 75600, training_loss: 1.15034e-01
I0216 05:00:23.848237 22839682574144 run_lib.py:146] step: 75600, eval_loss: 1.26317e-01
I0216 05:00:41.371194 22839682574144 run_lib.py:133] step: 75650, training_loss: 1.16509e-01
I0216 05:00:59.091420 22839682574144 run_lib.py:133] step: 75700, training_loss: 1.18191e-01
I0216 05:00:59.245984 22839682574144 run_lib.py:146] step: 75700, eval_loss: 1.27029e-01
I0216 05:01:16.767714 22839682574144 run_lib.py:133] step: 75750, training_loss: 1.14758e-01
I0216 05:01:34.313812 22839682574144 run_lib.py:133] step: 75800, training_loss: 1.15593e-01
I0216 05:01:34.471134 22839682574144 run_lib.py:146] step: 75800, eval_loss: 1.33296e-01
I0216 05:01:52.090644 22839682574144 run_lib.py:133] step: 75850, training_loss: 1.12252e-01
I0216 05:02:09.645040 22839682574144 run_lib.py:133] step: 75900, training_loss: 1.13978e-01
I0216 05:02:09.804136 22839682574144 run_lib.py:146] step: 75900, eval_loss: 1.27437e-01
I0216 05:02:27.305337 22839682574144 run_lib.py:133] step: 75950, training_loss: 1.11331e-01
I0216 05:02:44.851649 22839682574144 run_lib.py:133] step: 76000, training_loss: 1.15876e-01
I0216 05:02:45.017998 22839682574144 run_lib.py:146] step: 76000, eval_loss: 1.26289e-01
I0216 05:03:02.761506 22839682574144 run_lib.py:133] step: 76050, training_loss: 1.17213e-01
I0216 05:03:20.412334 22839682574144 run_lib.py:133] step: 76100, training_loss: 1.16388e-01
I0216 05:03:20.570800 22839682574144 run_lib.py:146] step: 76100, eval_loss: 1.29233e-01
I0216 05:03:38.180134 22839682574144 run_lib.py:133] step: 76150, training_loss: 1.17045e-01
I0216 05:03:55.679337 22839682574144 run_lib.py:133] step: 76200, training_loss: 1.16618e-01
I0216 05:03:55.835119 22839682574144 run_lib.py:146] step: 76200, eval_loss: 1.30361e-01
I0216 05:04:13.575290 22839682574144 run_lib.py:133] step: 76250, training_loss: 1.20379e-01
I0216 05:04:30.863389 22839682574144 run_lib.py:133] step: 76300, training_loss: 1.15650e-01
I0216 05:04:31.019624 22839682574144 run_lib.py:146] step: 76300, eval_loss: 1.29062e-01
I0216 05:04:48.329891 22839682574144 run_lib.py:133] step: 76350, training_loss: 1.15362e-01
I0216 05:05:05.860882 22839682574144 run_lib.py:133] step: 76400, training_loss: 1.10407e-01
I0216 05:05:06.016083 22839682574144 run_lib.py:146] step: 76400, eval_loss: 1.31695e-01
I0216 05:05:23.375661 22839682574144 run_lib.py:133] step: 76450, training_loss: 1.13858e-01
I0216 05:05:41.056799 22839682574144 run_lib.py:133] step: 76500, training_loss: 1.19161e-01
I0216 05:05:41.214268 22839682574144 run_lib.py:146] step: 76500, eval_loss: 1.26420e-01
I0216 05:05:58.738059 22839682574144 run_lib.py:133] step: 76550, training_loss: 1.18073e-01
I0216 05:06:16.253760 22839682574144 run_lib.py:133] step: 76600, training_loss: 1.15614e-01
I0216 05:06:16.406825 22839682574144 run_lib.py:146] step: 76600, eval_loss: 1.27928e-01
I0216 05:06:34.095866 22839682574144 run_lib.py:133] step: 76650, training_loss: 1.18941e-01
I0216 05:06:51.637238 22839682574144 run_lib.py:133] step: 76700, training_loss: 1.18007e-01
I0216 05:06:51.810325 22839682574144 run_lib.py:146] step: 76700, eval_loss: 1.29413e-01
I0216 05:07:09.352778 22839682574144 run_lib.py:133] step: 76750, training_loss: 1.19957e-01
I0216 05:07:27.096830 22839682574144 run_lib.py:133] step: 76800, training_loss: 1.14221e-01
I0216 05:07:27.264274 22839682574144 run_lib.py:146] step: 76800, eval_loss: 1.26305e-01
I0216 05:07:44.761561 22839682574144 run_lib.py:133] step: 76850, training_loss: 1.16299e-01
I0216 05:08:02.281703 22839682574144 run_lib.py:133] step: 76900, training_loss: 1.16891e-01
I0216 05:08:02.441052 22839682574144 run_lib.py:146] step: 76900, eval_loss: 1.26046e-01
I0216 05:08:20.066310 22839682574144 run_lib.py:133] step: 76950, training_loss: 1.14833e-01
I0216 05:08:37.577959 22839682574144 run_lib.py:133] step: 77000, training_loss: 1.16084e-01
I0216 05:08:37.735811 22839682574144 run_lib.py:146] step: 77000, eval_loss: 1.33778e-01
I0216 05:08:55.250704 22839682574144 run_lib.py:133] step: 77050, training_loss: 1.17559e-01
I0216 05:09:12.733054 22839682574144 run_lib.py:133] step: 77100, training_loss: 1.12714e-01
I0216 05:09:12.887364 22839682574144 run_lib.py:146] step: 77100, eval_loss: 1.31252e-01
I0216 05:09:30.595950 22839682574144 run_lib.py:133] step: 77150, training_loss: 1.11580e-01
I0216 05:09:48.233181 22839682574144 run_lib.py:133] step: 77200, training_loss: 1.12989e-01
I0216 05:09:48.411210 22839682574144 run_lib.py:146] step: 77200, eval_loss: 1.28924e-01
I0216 05:10:05.905157 22839682574144 run_lib.py:133] step: 77250, training_loss: 1.17747e-01
I0216 05:10:23.438724 22839682574144 run_lib.py:133] step: 77300, training_loss: 1.14182e-01
I0216 05:10:23.598396 22839682574144 run_lib.py:146] step: 77300, eval_loss: 1.32154e-01
I0216 05:10:41.335115 22839682574144 run_lib.py:133] step: 77350, training_loss: 1.14706e-01
I0216 05:10:58.822941 22839682574144 run_lib.py:133] step: 77400, training_loss: 1.12912e-01
I0216 05:10:58.980144 22839682574144 run_lib.py:146] step: 77400, eval_loss: 1.29709e-01
I0216 05:11:16.506395 22839682574144 run_lib.py:133] step: 77450, training_loss: 1.21970e-01
I0216 05:11:34.233744 22839682574144 run_lib.py:133] step: 77500, training_loss: 1.14453e-01
I0216 05:11:34.391712 22839682574144 run_lib.py:146] step: 77500, eval_loss: 1.26643e-01
I0216 05:11:51.950357 22839682574144 run_lib.py:133] step: 77550, training_loss: 1.14419e-01
I0216 05:12:09.651939 22839682574144 run_lib.py:133] step: 77600, training_loss: 1.16824e-01
I0216 05:12:09.806012 22839682574144 run_lib.py:146] step: 77600, eval_loss: 1.33081e-01
I0216 05:12:27.330210 22839682574144 run_lib.py:133] step: 77650, training_loss: 1.19903e-01
I0216 05:12:44.865043 22839682574144 run_lib.py:133] step: 77700, training_loss: 1.12114e-01
I0216 05:12:45.036248 22839682574144 run_lib.py:146] step: 77700, eval_loss: 1.30345e-01
I0216 05:13:02.772251 22839682574144 run_lib.py:133] step: 77750, training_loss: 1.15438e-01
I0216 05:13:20.296982 22839682574144 run_lib.py:133] step: 77800, training_loss: 1.18114e-01
I0216 05:13:20.457146 22839682574144 run_lib.py:146] step: 77800, eval_loss: 1.32559e-01
I0216 05:13:37.944715 22839682574144 run_lib.py:133] step: 77850, training_loss: 1.19004e-01
I0216 05:13:55.640086 22839682574144 run_lib.py:133] step: 77900, training_loss: 1.17415e-01
I0216 05:13:55.796785 22839682574144 run_lib.py:146] step: 77900, eval_loss: 1.27346e-01
I0216 05:14:13.299710 22839682574144 run_lib.py:133] step: 77950, training_loss: 1.16012e-01
I0216 05:14:30.824608 22839682574144 run_lib.py:133] step: 78000, training_loss: 1.16285e-01
I0216 05:14:31.020815 22839682574144 run_lib.py:146] step: 78000, eval_loss: 1.26415e-01
I0216 05:14:48.653149 22839682574144 run_lib.py:133] step: 78050, training_loss: 1.22268e-01
I0216 05:15:06.174922 22839682574144 run_lib.py:133] step: 78100, training_loss: 1.17228e-01
I0216 05:15:06.331070 22839682574144 run_lib.py:146] step: 78100, eval_loss: 1.29563e-01
I0216 05:15:23.839265 22839682574144 run_lib.py:133] step: 78150, training_loss: 1.18601e-01
I0216 05:15:41.377930 22839682574144 run_lib.py:133] step: 78200, training_loss: 1.18664e-01
I0216 05:15:41.559530 22839682574144 run_lib.py:146] step: 78200, eval_loss: 1.31416e-01
I0216 05:15:59.294120 22839682574144 run_lib.py:133] step: 78250, training_loss: 1.12894e-01
I0216 05:16:16.969130 22839682574144 run_lib.py:133] step: 78300, training_loss: 1.16780e-01
I0216 05:16:17.130933 22839682574144 run_lib.py:146] step: 78300, eval_loss: 1.28410e-01
I0216 05:16:34.626897 22839682574144 run_lib.py:133] step: 78350, training_loss: 1.19405e-01
I0216 05:16:52.167167 22839682574144 run_lib.py:133] step: 78400, training_loss: 1.14546e-01
I0216 05:16:52.334235 22839682574144 run_lib.py:146] step: 78400, eval_loss: 1.31943e-01
I0216 05:17:10.025382 22839682574144 run_lib.py:133] step: 78450, training_loss: 1.11768e-01
I0216 05:17:27.583655 22839682574144 run_lib.py:133] step: 78500, training_loss: 1.17840e-01
I0216 05:17:27.738965 22839682574144 run_lib.py:146] step: 78500, eval_loss: 1.25740e-01
I0216 05:17:45.302868 22839682574144 run_lib.py:133] step: 78550, training_loss: 1.16471e-01
I0216 05:18:03.049534 22839682574144 run_lib.py:133] step: 78600, training_loss: 1.15040e-01
I0216 05:18:03.207134 22839682574144 run_lib.py:146] step: 78600, eval_loss: 1.33417e-01
I0216 05:18:20.721135 22839682574144 run_lib.py:133] step: 78650, training_loss: 1.14191e-01
I0216 05:18:38.392144 22839682574144 run_lib.py:133] step: 78700, training_loss: 1.17277e-01
I0216 05:18:38.552487 22839682574144 run_lib.py:146] step: 78700, eval_loss: 1.28998e-01
I0216 05:18:56.057675 22839682574144 run_lib.py:133] step: 78750, training_loss: 1.17339e-01
I0216 05:19:13.580074 22839682574144 run_lib.py:133] step: 78800, training_loss: 1.14631e-01
I0216 05:19:13.738261 22839682574144 run_lib.py:146] step: 78800, eval_loss: 1.31807e-01
I0216 05:19:31.451275 22839682574144 run_lib.py:133] step: 78850, training_loss: 1.15424e-01
I0216 05:19:48.988250 22839682574144 run_lib.py:133] step: 78900, training_loss: 1.16391e-01
I0216 05:19:49.145090 22839682574144 run_lib.py:146] step: 78900, eval_loss: 1.29315e-01
I0216 05:20:06.677252 22839682574144 run_lib.py:133] step: 78950, training_loss: 1.16320e-01
I0216 05:20:24.337872 22839682574144 run_lib.py:133] step: 79000, training_loss: 1.15407e-01
I0216 05:20:24.494233 22839682574144 run_lib.py:146] step: 79000, eval_loss: 1.25606e-01
I0216 05:20:42.040912 22839682574144 run_lib.py:133] step: 79050, training_loss: 1.14131e-01
I0216 05:20:59.607948 22839682574144 run_lib.py:133] step: 79100, training_loss: 1.13494e-01
I0216 05:20:59.762322 22839682574144 run_lib.py:146] step: 79100, eval_loss: 1.31109e-01
I0216 05:21:17.428266 22839682574144 run_lib.py:133] step: 79150, training_loss: 1.20940e-01
I0216 05:21:34.920842 22839682574144 run_lib.py:133] step: 79200, training_loss: 1.14043e-01
I0216 05:21:35.079772 22839682574144 run_lib.py:146] step: 79200, eval_loss: 1.28194e-01
I0216 05:21:52.600326 22839682574144 run_lib.py:133] step: 79250, training_loss: 1.18405e-01
I0216 05:22:10.131830 22839682574144 run_lib.py:133] step: 79300, training_loss: 1.15223e-01
I0216 05:22:10.294924 22839682574144 run_lib.py:146] step: 79300, eval_loss: 1.25095e-01
I0216 05:22:28.025213 22839682574144 run_lib.py:133] step: 79350, training_loss: 1.13816e-01
I0216 05:22:45.649653 22839682574144 run_lib.py:133] step: 79400, training_loss: 1.15461e-01
I0216 05:22:45.806055 22839682574144 run_lib.py:146] step: 79400, eval_loss: 1.33510e-01
I0216 05:23:03.324708 22839682574144 run_lib.py:133] step: 79450, training_loss: 1.15168e-01
I0216 05:23:20.851272 22839682574144 run_lib.py:133] step: 79500, training_loss: 1.16042e-01
I0216 05:23:21.006045 22839682574144 run_lib.py:146] step: 79500, eval_loss: 1.34570e-01
I0216 05:23:38.658487 22839682574144 run_lib.py:133] step: 79550, training_loss: 1.19496e-01
I0216 05:23:56.170704 22839682574144 run_lib.py:133] step: 79600, training_loss: 1.15127e-01
I0216 05:23:56.356427 22839682574144 run_lib.py:146] step: 79600, eval_loss: 1.27154e-01
I0216 05:24:13.923458 22839682574144 run_lib.py:133] step: 79650, training_loss: 1.16597e-01
I0216 05:24:31.626233 22839682574144 run_lib.py:133] step: 79700, training_loss: 1.15117e-01
I0216 05:24:31.785349 22839682574144 run_lib.py:146] step: 79700, eval_loss: 1.30384e-01
I0216 05:24:49.291063 22839682574144 run_lib.py:133] step: 79750, training_loss: 1.15039e-01
I0216 05:25:06.906399 22839682574144 run_lib.py:133] step: 79800, training_loss: 1.16163e-01
I0216 05:25:07.064105 22839682574144 run_lib.py:146] step: 79800, eval_loss: 1.31509e-01
I0216 05:25:24.628472 22839682574144 run_lib.py:133] step: 79850, training_loss: 1.11771e-01
I0216 05:25:42.170733 22839682574144 run_lib.py:133] step: 79900, training_loss: 1.12684e-01
I0216 05:25:42.327343 22839682574144 run_lib.py:146] step: 79900, eval_loss: 1.32573e-01
I0216 05:26:00.064651 22839682574144 run_lib.py:133] step: 79950, training_loss: 1.18703e-01
I0216 05:26:17.580868 22839682574144 run_lib.py:133] step: 80000, training_loss: 1.14935e-01
I0216 05:26:18.360781 22839682574144 run_lib.py:146] step: 80000, eval_loss: 1.31758e-01
I0216 05:26:38.746084 22839682574144 run_lib.py:133] step: 80050, training_loss: 1.17662e-01
I0216 05:26:56.368969 22839682574144 run_lib.py:133] step: 80100, training_loss: 1.16541e-01
I0216 05:26:56.537269 22839682574144 run_lib.py:146] step: 80100, eval_loss: 1.27945e-01
I0216 05:27:14.082169 22839682574144 run_lib.py:133] step: 80150, training_loss: 1.17789e-01
I0216 05:27:31.604635 22839682574144 run_lib.py:133] step: 80200, training_loss: 1.12625e-01
I0216 05:27:31.760282 22839682574144 run_lib.py:146] step: 80200, eval_loss: 1.24905e-01
I0216 05:27:49.493972 22839682574144 run_lib.py:133] step: 80250, training_loss: 1.13421e-01
I0216 05:28:06.986727 22839682574144 run_lib.py:133] step: 80300, training_loss: 1.19408e-01
I0216 05:28:07.143990 22839682574144 run_lib.py:146] step: 80300, eval_loss: 1.28598e-01
I0216 05:28:24.844338 22839682574144 run_lib.py:133] step: 80350, training_loss: 1.17504e-01
I0216 05:28:42.362866 22839682574144 run_lib.py:133] step: 80400, training_loss: 1.17028e-01
I0216 05:28:42.521224 22839682574144 run_lib.py:146] step: 80400, eval_loss: 1.32898e-01
I0216 05:29:00.057273 22839682574144 run_lib.py:133] step: 80450, training_loss: 1.14728e-01
I0216 05:29:17.766327 22839682574144 run_lib.py:133] step: 80500, training_loss: 1.15237e-01
I0216 05:29:17.921103 22839682574144 run_lib.py:146] step: 80500, eval_loss: 1.31364e-01
I0216 05:29:35.409156 22839682574144 run_lib.py:133] step: 80550, training_loss: 1.16098e-01
I0216 05:29:52.892795 22839682574144 run_lib.py:133] step: 80600, training_loss: 1.19648e-01
I0216 05:29:53.061296 22839682574144 run_lib.py:146] step: 80600, eval_loss: 1.30054e-01
I0216 05:30:10.784402 22839682574144 run_lib.py:133] step: 80650, training_loss: 1.16503e-01
I0216 05:30:28.298493 22839682574144 run_lib.py:133] step: 80700, training_loss: 1.14559e-01
I0216 05:30:28.458091 22839682574144 run_lib.py:146] step: 80700, eval_loss: 1.26592e-01
I0216 05:30:46.147240 22839682574144 run_lib.py:133] step: 80750, training_loss: 1.13556e-01
I0216 05:31:03.644361 22839682574144 run_lib.py:133] step: 80800, training_loss: 1.17927e-01
I0216 05:31:03.807215 22839682574144 run_lib.py:146] step: 80800, eval_loss: 1.31696e-01
I0216 05:31:21.327284 22839682574144 run_lib.py:133] step: 80850, training_loss: 1.17764e-01
I0216 05:31:39.056213 22839682574144 run_lib.py:133] step: 80900, training_loss: 1.14419e-01
I0216 05:31:39.212073 22839682574144 run_lib.py:146] step: 80900, eval_loss: 1.30598e-01
I0216 05:31:56.710058 22839682574144 run_lib.py:133] step: 80950, training_loss: 1.13002e-01
I0216 05:32:14.252745 22839682574144 run_lib.py:133] step: 81000, training_loss: 1.15904e-01
I0216 05:32:14.409041 22839682574144 run_lib.py:146] step: 81000, eval_loss: 1.31411e-01
I0216 05:32:31.920536 22839682574144 run_lib.py:133] step: 81050, training_loss: 1.15946e-01
I0216 05:32:49.444177 22839682574144 run_lib.py:133] step: 81100, training_loss: 1.15634e-01
I0216 05:32:49.619117 22839682574144 run_lib.py:146] step: 81100, eval_loss: 1.32451e-01
I0216 05:33:07.311734 22839682574144 run_lib.py:133] step: 81150, training_loss: 1.12393e-01
I0216 05:33:24.967972 22839682574144 run_lib.py:133] step: 81200, training_loss: 1.22433e-01
I0216 05:33:25.145016 22839682574144 run_lib.py:146] step: 81200, eval_loss: 1.23838e-01
I0216 05:33:42.634448 22839682574144 run_lib.py:133] step: 81250, training_loss: 1.17005e-01
I0216 05:34:00.129865 22839682574144 run_lib.py:133] step: 81300, training_loss: 1.11265e-01
I0216 05:34:00.287809 22839682574144 run_lib.py:146] step: 81300, eval_loss: 1.25126e-01
I0216 05:34:17.949475 22839682574144 run_lib.py:133] step: 81350, training_loss: 1.15883e-01
I0216 05:34:35.478313 22839682574144 run_lib.py:133] step: 81400, training_loss: 1.12634e-01
I0216 05:34:35.634896 22839682574144 run_lib.py:146] step: 81400, eval_loss: 1.23405e-01
I0216 05:34:53.401808 22839682574144 run_lib.py:133] step: 81450, training_loss: 1.14661e-01
I0216 05:35:10.895914 22839682574144 run_lib.py:133] step: 81500, training_loss: 1.14998e-01
I0216 05:35:11.050351 22839682574144 run_lib.py:146] step: 81500, eval_loss: 1.31849e-01
I0216 05:35:28.538679 22839682574144 run_lib.py:133] step: 81550, training_loss: 1.16796e-01
I0216 05:35:46.250244 22839682574144 run_lib.py:133] step: 81600, training_loss: 1.14513e-01
I0216 05:35:46.409385 22839682574144 run_lib.py:146] step: 81600, eval_loss: 1.27714e-01
I0216 05:36:03.930244 22839682574144 run_lib.py:133] step: 81650, training_loss: 1.13243e-01
I0216 05:36:21.497842 22839682574144 run_lib.py:133] step: 81700, training_loss: 1.14278e-01
I0216 05:36:21.662139 22839682574144 run_lib.py:146] step: 81700, eval_loss: 1.28283e-01
I0216 05:36:39.364829 22839682574144 run_lib.py:133] step: 81750, training_loss: 1.15303e-01
I0216 05:36:56.884037 22839682574144 run_lib.py:133] step: 81800, training_loss: 1.11071e-01
I0216 05:36:57.040004 22839682574144 run_lib.py:146] step: 81800, eval_loss: 1.32078e-01
I0216 05:37:14.523877 22839682574144 run_lib.py:133] step: 81850, training_loss: 1.18684e-01
I0216 05:37:32.222582 22839682574144 run_lib.py:133] step: 81900, training_loss: 1.13328e-01
I0216 05:37:32.376044 22839682574144 run_lib.py:146] step: 81900, eval_loss: 1.32523e-01
I0216 05:37:49.924110 22839682574144 run_lib.py:133] step: 81950, training_loss: 1.13344e-01
I0216 05:38:07.422439 22839682574144 run_lib.py:133] step: 82000, training_loss: 1.14205e-01
I0216 05:38:07.586255 22839682574144 run_lib.py:146] step: 82000, eval_loss: 1.30316e-01
I0216 05:38:25.250900 22839682574144 run_lib.py:133] step: 82050, training_loss: 1.13303e-01
I0216 05:38:42.761586 22839682574144 run_lib.py:133] step: 82100, training_loss: 1.16694e-01
I0216 05:38:42.921297 22839682574144 run_lib.py:146] step: 82100, eval_loss: 1.29135e-01
I0216 05:39:00.421482 22839682574144 run_lib.py:133] step: 82150, training_loss: 1.15010e-01
I0216 05:39:17.954069 22839682574144 run_lib.py:133] step: 82200, training_loss: 1.14056e-01
I0216 05:39:18.111519 22839682574144 run_lib.py:146] step: 82200, eval_loss: 1.27128e-01
I0216 05:39:35.821619 22839682574144 run_lib.py:133] step: 82250, training_loss: 1.21374e-01
I0216 05:39:53.460216 22839682574144 run_lib.py:133] step: 82300, training_loss: 1.16371e-01
I0216 05:39:53.686245 22839682574144 run_lib.py:146] step: 82300, eval_loss: 1.37137e-01
I0216 05:40:11.225221 22839682574144 run_lib.py:133] step: 82350, training_loss: 1.16561e-01
I0216 05:40:28.722923 22839682574144 run_lib.py:133] step: 82400, training_loss: 1.17080e-01
I0216 05:40:28.877106 22839682574144 run_lib.py:146] step: 82400, eval_loss: 1.27269e-01
I0216 05:40:46.521063 22839682574144 run_lib.py:133] step: 82450, training_loss: 1.16498e-01
I0216 05:41:04.046320 22839682574144 run_lib.py:133] step: 82500, training_loss: 1.19601e-01
I0216 05:41:04.215403 22839682574144 run_lib.py:146] step: 82500, eval_loss: 1.29363e-01
I0216 05:41:21.726631 22839682574144 run_lib.py:133] step: 82550, training_loss: 1.17138e-01
I0216 05:41:39.442445 22839682574144 run_lib.py:133] step: 82600, training_loss: 1.14254e-01
I0216 05:41:39.601222 22839682574144 run_lib.py:146] step: 82600, eval_loss: 1.31739e-01
I0216 05:41:57.116142 22839682574144 run_lib.py:133] step: 82650, training_loss: 1.11136e-01
I0216 05:42:14.791185 22839682574144 run_lib.py:133] step: 82700, training_loss: 1.16307e-01
I0216 05:42:14.951223 22839682574144 run_lib.py:146] step: 82700, eval_loss: 1.28369e-01
I0216 05:42:32.461874 22839682574144 run_lib.py:133] step: 82750, training_loss: 1.15479e-01
I0216 05:42:49.980547 22839682574144 run_lib.py:133] step: 82800, training_loss: 1.16743e-01
I0216 05:42:50.136799 22839682574144 run_lib.py:146] step: 82800, eval_loss: 1.28899e-01
I0216 05:43:07.853389 22839682574144 run_lib.py:133] step: 82850, training_loss: 1.16026e-01
I0216 05:43:25.371916 22839682574144 run_lib.py:133] step: 82900, training_loss: 1.15037e-01
I0216 05:43:25.527085 22839682574144 run_lib.py:146] step: 82900, eval_loss: 1.30159e-01
I0216 05:43:43.034170 22839682574144 run_lib.py:133] step: 82950, training_loss: 1.14619e-01
I0216 05:44:00.731483 22839682574144 run_lib.py:133] step: 83000, training_loss: 1.14325e-01
I0216 05:44:00.908077 22839682574144 run_lib.py:146] step: 83000, eval_loss: 1.24735e-01
I0216 05:44:18.451839 22839682574144 run_lib.py:133] step: 83050, training_loss: 1.14349e-01
I0216 05:44:35.990061 22839682574144 run_lib.py:133] step: 83100, training_loss: 1.11915e-01
I0216 05:44:36.148166 22839682574144 run_lib.py:146] step: 83100, eval_loss: 1.25300e-01
I0216 05:44:53.734177 22839682574144 run_lib.py:133] step: 83150, training_loss: 1.19654e-01
I0216 05:45:11.209550 22839682574144 run_lib.py:133] step: 83200, training_loss: 1.16706e-01
I0216 05:45:11.368044 22839682574144 run_lib.py:146] step: 83200, eval_loss: 1.28351e-01
I0216 05:45:28.842500 22839682574144 run_lib.py:133] step: 83250, training_loss: 1.16489e-01
I0216 05:45:46.379286 22839682574144 run_lib.py:133] step: 83300, training_loss: 1.16526e-01
I0216 05:45:46.536316 22839682574144 run_lib.py:146] step: 83300, eval_loss: 1.28874e-01
I0216 05:46:04.246368 22839682574144 run_lib.py:133] step: 83350, training_loss: 1.18330e-01
I0216 05:46:21.882484 22839682574144 run_lib.py:133] step: 83400, training_loss: 1.15968e-01
I0216 05:46:22.036165 22839682574144 run_lib.py:146] step: 83400, eval_loss: 1.29956e-01
I0216 05:46:39.531141 22839682574144 run_lib.py:133] step: 83450, training_loss: 1.14839e-01
I0216 05:46:57.062197 22839682574144 run_lib.py:133] step: 83500, training_loss: 1.15624e-01
I0216 05:46:57.222273 22839682574144 run_lib.py:146] step: 83500, eval_loss: 1.30051e-01
I0216 05:47:14.876818 22839682574144 run_lib.py:133] step: 83550, training_loss: 1.17506e-01
I0216 05:47:32.419501 22839682574144 run_lib.py:133] step: 83600, training_loss: 1.15112e-01
I0216 05:47:32.583966 22839682574144 run_lib.py:146] step: 83600, eval_loss: 1.30955e-01
I0216 05:47:50.130910 22839682574144 run_lib.py:133] step: 83650, training_loss: 1.11513e-01
I0216 05:48:07.856069 22839682574144 run_lib.py:133] step: 83700, training_loss: 1.14427e-01
I0216 05:48:08.014020 22839682574144 run_lib.py:146] step: 83700, eval_loss: 1.25438e-01
I0216 05:48:25.526084 22839682574144 run_lib.py:133] step: 83750, training_loss: 1.15475e-01
I0216 05:48:43.167192 22839682574144 run_lib.py:133] step: 83800, training_loss: 1.13828e-01
I0216 05:48:43.372823 22839682574144 run_lib.py:146] step: 83800, eval_loss: 1.31296e-01
I0216 05:49:00.827171 22839682574144 run_lib.py:133] step: 83850, training_loss: 1.17294e-01
I0216 05:49:18.345368 22839682574144 run_lib.py:133] step: 83900, training_loss: 1.17158e-01
I0216 05:49:18.515408 22839682574144 run_lib.py:146] step: 83900, eval_loss: 1.28922e-01
I0216 05:49:36.257485 22839682574144 run_lib.py:133] step: 83950, training_loss: 1.14361e-01
I0216 05:49:53.771189 22839682574144 run_lib.py:133] step: 84000, training_loss: 1.12241e-01
I0216 05:49:53.930300 22839682574144 run_lib.py:146] step: 84000, eval_loss: 1.29118e-01
I0216 05:50:11.442342 22839682574144 run_lib.py:133] step: 84050, training_loss: 1.17213e-01
I0216 05:50:29.077091 22839682574144 run_lib.py:133] step: 84100, training_loss: 1.15307e-01
I0216 05:50:29.234032 22839682574144 run_lib.py:146] step: 84100, eval_loss: 1.35040e-01
I0216 05:50:46.749324 22839682574144 run_lib.py:133] step: 84150, training_loss: 1.15602e-01
I0216 05:51:04.256142 22839682574144 run_lib.py:133] step: 84200, training_loss: 1.13067e-01
I0216 05:51:04.413323 22839682574144 run_lib.py:146] step: 84200, eval_loss: 1.28910e-01
I0216 05:51:22.083377 22839682574144 run_lib.py:133] step: 84250, training_loss: 1.13160e-01
I0216 05:51:39.614551 22839682574144 run_lib.py:133] step: 84300, training_loss: 1.18426e-01
I0216 05:51:39.775097 22839682574144 run_lib.py:146] step: 84300, eval_loss: 1.27234e-01
I0216 05:51:57.258518 22839682574144 run_lib.py:133] step: 84350, training_loss: 1.14763e-01
I0216 05:52:14.797070 22839682574144 run_lib.py:133] step: 84400, training_loss: 1.14508e-01
I0216 05:52:14.964255 22839682574144 run_lib.py:146] step: 84400, eval_loss: 1.30899e-01
I0216 05:52:32.680189 22839682574144 run_lib.py:133] step: 84450, training_loss: 1.12478e-01
I0216 05:52:50.343880 22839682574144 run_lib.py:133] step: 84500, training_loss: 1.16131e-01
I0216 05:52:50.502131 22839682574144 run_lib.py:146] step: 84500, eval_loss: 1.26917e-01
I0216 05:53:08.027826 22839682574144 run_lib.py:133] step: 84550, training_loss: 1.17796e-01
I0216 05:53:25.550168 22839682574144 run_lib.py:133] step: 84600, training_loss: 1.18210e-01
I0216 05:53:25.708081 22839682574144 run_lib.py:146] step: 84600, eval_loss: 1.26675e-01
I0216 05:53:43.335798 22839682574144 run_lib.py:133] step: 84650, training_loss: 1.18036e-01
I0216 05:54:00.865482 22839682574144 run_lib.py:133] step: 84700, training_loss: 1.19222e-01
I0216 05:54:01.022814 22839682574144 run_lib.py:146] step: 84700, eval_loss: 1.30964e-01
I0216 05:54:18.563733 22839682574144 run_lib.py:133] step: 84750, training_loss: 1.14958e-01
I0216 05:54:36.245440 22839682574144 run_lib.py:133] step: 84800, training_loss: 1.15291e-01
I0216 05:54:36.400050 22839682574144 run_lib.py:146] step: 84800, eval_loss: 1.30088e-01
I0216 05:54:53.871979 22839682574144 run_lib.py:133] step: 84850, training_loss: 1.16913e-01
I0216 05:55:11.553700 22839682574144 run_lib.py:133] step: 84900, training_loss: 1.18058e-01
I0216 05:55:11.713316 22839682574144 run_lib.py:146] step: 84900, eval_loss: 1.32018e-01
I0216 05:55:29.199461 22839682574144 run_lib.py:133] step: 84950, training_loss: 1.13599e-01
I0216 05:55:46.758494 22839682574144 run_lib.py:133] step: 85000, training_loss: 1.07482e-01
I0216 05:55:46.919320 22839682574144 run_lib.py:146] step: 85000, eval_loss: 1.32481e-01
I0216 05:56:04.663440 22839682574144 run_lib.py:133] step: 85050, training_loss: 1.15015e-01
I0216 05:56:22.181449 22839682574144 run_lib.py:133] step: 85100, training_loss: 1.17502e-01
I0216 05:56:22.339227 22839682574144 run_lib.py:146] step: 85100, eval_loss: 1.27881e-01
I0216 05:56:39.846538 22839682574144 run_lib.py:133] step: 85150, training_loss: 1.16071e-01
I0216 05:56:57.489990 22839682574144 run_lib.py:133] step: 85200, training_loss: 1.11623e-01
I0216 05:56:57.643897 22839682574144 run_lib.py:146] step: 85200, eval_loss: 1.30010e-01
I0216 05:57:15.142560 22839682574144 run_lib.py:133] step: 85250, training_loss: 1.11723e-01
I0216 05:57:32.685242 22839682574144 run_lib.py:133] step: 85300, training_loss: 1.18045e-01
I0216 05:57:32.863272 22839682574144 run_lib.py:146] step: 85300, eval_loss: 1.32476e-01
I0216 05:57:50.513638 22839682574144 run_lib.py:133] step: 85350, training_loss: 1.19235e-01
I0216 05:58:08.063521 22839682574144 run_lib.py:133] step: 85400, training_loss: 1.16527e-01
I0216 05:58:08.224177 22839682574144 run_lib.py:146] step: 85400, eval_loss: 1.28478e-01
I0216 05:58:25.710304 22839682574144 run_lib.py:133] step: 85450, training_loss: 1.13553e-01
I0216 05:58:43.216836 22839682574144 run_lib.py:133] step: 85500, training_loss: 1.19383e-01
I0216 05:58:43.380748 22839682574144 run_lib.py:146] step: 85500, eval_loss: 1.28269e-01
I0216 05:59:01.089902 22839682574144 run_lib.py:133] step: 85550, training_loss: 1.14288e-01
I0216 05:59:18.704401 22839682574144 run_lib.py:133] step: 85600, training_loss: 1.15551e-01
I0216 05:59:18.865233 22839682574144 run_lib.py:146] step: 85600, eval_loss: 1.28130e-01
I0216 05:59:36.379756 22839682574144 run_lib.py:133] step: 85650, training_loss: 1.13772e-01
I0216 05:59:53.877442 22839682574144 run_lib.py:133] step: 85700, training_loss: 1.13465e-01
I0216 05:59:54.031104 22839682574144 run_lib.py:146] step: 85700, eval_loss: 1.28850e-01
I0216 06:00:11.695500 22839682574144 run_lib.py:133] step: 85750, training_loss: 1.15372e-01
I0216 06:00:29.194214 22839682574144 run_lib.py:133] step: 85800, training_loss: 1.11573e-01
I0216 06:00:29.362829 22839682574144 run_lib.py:146] step: 85800, eval_loss: 1.29726e-01
I0216 06:00:46.868000 22839682574144 run_lib.py:133] step: 85850, training_loss: 1.16292e-01
I0216 06:01:04.576837 22839682574144 run_lib.py:133] step: 85900, training_loss: 1.17059e-01
I0216 06:01:04.736045 22839682574144 run_lib.py:146] step: 85900, eval_loss: 1.34804e-01
I0216 06:01:22.233075 22839682574144 run_lib.py:133] step: 85950, training_loss: 1.12110e-01
I0216 06:01:39.914004 22839682574144 run_lib.py:133] step: 86000, training_loss: 1.16918e-01
I0216 06:01:40.072225 22839682574144 run_lib.py:146] step: 86000, eval_loss: 1.30390e-01
I0216 06:01:57.596340 22839682574144 run_lib.py:133] step: 86050, training_loss: 1.13844e-01
I0216 06:02:15.152578 22839682574144 run_lib.py:133] step: 86100, training_loss: 1.17098e-01
I0216 06:02:15.309241 22839682574144 run_lib.py:146] step: 86100, eval_loss: 1.27418e-01
I0216 06:02:33.007285 22839682574144 run_lib.py:133] step: 86150, training_loss: 1.13006e-01
I0216 06:02:50.472967 22839682574144 run_lib.py:133] step: 86200, training_loss: 1.15975e-01
I0216 06:02:50.628835 22839682574144 run_lib.py:146] step: 86200, eval_loss: 1.27828e-01
I0216 06:03:08.092721 22839682574144 run_lib.py:133] step: 86250, training_loss: 1.11236e-01
I0216 06:03:25.769523 22839682574144 run_lib.py:133] step: 86300, training_loss: 1.16737e-01
I0216 06:03:25.926434 22839682574144 run_lib.py:146] step: 86300, eval_loss: 1.32515e-01
I0216 06:03:43.393538 22839682574144 run_lib.py:133] step: 86350, training_loss: 1.18662e-01
I0216 06:04:00.925081 22839682574144 run_lib.py:133] step: 86400, training_loss: 1.16457e-01
I0216 06:04:01.085079 22839682574144 run_lib.py:146] step: 86400, eval_loss: 1.31614e-01
I0216 06:04:18.728914 22839682574144 run_lib.py:133] step: 86450, training_loss: 1.15696e-01
I0216 06:04:36.228967 22839682574144 run_lib.py:133] step: 86500, training_loss: 1.13297e-01
I0216 06:04:36.393804 22839682574144 run_lib.py:146] step: 86500, eval_loss: 1.30079e-01
I0216 06:04:53.871063 22839682574144 run_lib.py:133] step: 86550, training_loss: 1.14338e-01
I0216 06:05:11.353791 22839682574144 run_lib.py:133] step: 86600, training_loss: 1.14704e-01
I0216 06:05:11.511109 22839682574144 run_lib.py:146] step: 86600, eval_loss: 1.31460e-01
I0216 06:05:29.209903 22839682574144 run_lib.py:133] step: 86650, training_loss: 1.17462e-01
I0216 06:05:46.891164 22839682574144 run_lib.py:133] step: 86700, training_loss: 1.19386e-01
I0216 06:05:47.049345 22839682574144 run_lib.py:146] step: 86700, eval_loss: 1.32919e-01
I0216 06:06:04.541783 22839682574144 run_lib.py:133] step: 86750, training_loss: 1.21209e-01
I0216 06:06:22.080017 22839682574144 run_lib.py:133] step: 86800, training_loss: 1.15797e-01
I0216 06:06:22.239270 22839682574144 run_lib.py:146] step: 86800, eval_loss: 1.28390e-01
I0216 06:06:39.912775 22839682574144 run_lib.py:133] step: 86850, training_loss: 1.10257e-01
I0216 06:06:57.446062 22839682574144 run_lib.py:133] step: 86900, training_loss: 1.13527e-01
I0216 06:06:57.613138 22839682574144 run_lib.py:146] step: 86900, eval_loss: 1.28854e-01
I0216 06:07:15.128479 22839682574144 run_lib.py:133] step: 86950, training_loss: 1.13887e-01
I0216 06:07:32.842631 22839682574144 run_lib.py:133] step: 87000, training_loss: 1.13484e-01
I0216 06:07:32.999374 22839682574144 run_lib.py:146] step: 87000, eval_loss: 1.30737e-01
I0216 06:07:50.525489 22839682574144 run_lib.py:133] step: 87050, training_loss: 1.16077e-01
I0216 06:08:08.167748 22839682574144 run_lib.py:133] step: 87100, training_loss: 1.16725e-01
I0216 06:08:08.324484 22839682574144 run_lib.py:146] step: 87100, eval_loss: 1.30715e-01
I0216 06:08:25.793403 22839682574144 run_lib.py:133] step: 87150, training_loss: 1.14148e-01
I0216 06:08:43.327310 22839682574144 run_lib.py:133] step: 87200, training_loss: 1.14228e-01
I0216 06:08:43.488249 22839682574144 run_lib.py:146] step: 87200, eval_loss: 1.30878e-01
I0216 06:09:01.246405 22839682574144 run_lib.py:133] step: 87250, training_loss: 1.18520e-01
I0216 06:09:18.774274 22839682574144 run_lib.py:133] step: 87300, training_loss: 1.17726e-01
I0216 06:09:18.931998 22839682574144 run_lib.py:146] step: 87300, eval_loss: 1.28895e-01
I0216 06:09:36.423736 22839682574144 run_lib.py:133] step: 87350, training_loss: 1.11028e-01
I0216 06:09:54.071347 22839682574144 run_lib.py:133] step: 87400, training_loss: 1.14181e-01
I0216 06:09:54.227190 22839682574144 run_lib.py:146] step: 87400, eval_loss: 1.33185e-01
I0216 06:10:11.730470 22839682574144 run_lib.py:133] step: 87450, training_loss: 1.18453e-01
I0216 06:10:29.282715 22839682574144 run_lib.py:133] step: 87500, training_loss: 1.16030e-01
I0216 06:10:29.445408 22839682574144 run_lib.py:146] step: 87500, eval_loss: 1.26980e-01
I0216 06:10:47.096577 22839682574144 run_lib.py:133] step: 87550, training_loss: 1.18041e-01
I0216 06:11:04.577627 22839682574144 run_lib.py:133] step: 87600, training_loss: 1.19751e-01
I0216 06:11:04.732107 22839682574144 run_lib.py:146] step: 87600, eval_loss: 1.31548e-01
I0216 06:11:22.214577 22839682574144 run_lib.py:133] step: 87650, training_loss: 1.16203e-01
I0216 06:11:39.762042 22839682574144 run_lib.py:133] step: 87700, training_loss: 1.13575e-01
I0216 06:11:39.922190 22839682574144 run_lib.py:146] step: 87700, eval_loss: 1.32691e-01
I0216 06:11:57.596831 22839682574144 run_lib.py:133] step: 87750, training_loss: 1.12733e-01
I0216 06:12:15.267210 22839682574144 run_lib.py:133] step: 87800, training_loss: 1.15256e-01
I0216 06:12:15.433014 22839682574144 run_lib.py:146] step: 87800, eval_loss: 1.35054e-01
I0216 06:12:32.934370 22839682574144 run_lib.py:133] step: 87850, training_loss: 1.18968e-01
I0216 06:12:50.399969 22839682574144 run_lib.py:133] step: 87900, training_loss: 1.14658e-01
I0216 06:12:50.559128 22839682574144 run_lib.py:146] step: 87900, eval_loss: 1.28432e-01
I0216 06:13:08.218477 22839682574144 run_lib.py:133] step: 87950, training_loss: 1.16937e-01
I0216 06:13:25.664216 22839682574144 run_lib.py:133] step: 88000, training_loss: 1.14424e-01
I0216 06:13:25.823002 22839682574144 run_lib.py:146] step: 88000, eval_loss: 1.28072e-01
I0216 06:13:43.410085 22839682574144 run_lib.py:133] step: 88050, training_loss: 1.12397e-01
I0216 06:14:01.084157 22839682574144 run_lib.py:133] step: 88100, training_loss: 1.16332e-01
I0216 06:14:01.240271 22839682574144 run_lib.py:146] step: 88100, eval_loss: 1.29590e-01
I0216 06:14:18.771182 22839682574144 run_lib.py:133] step: 88150, training_loss: 1.15094e-01
I0216 06:14:36.511945 22839682574144 run_lib.py:133] step: 88200, training_loss: 1.14406e-01
I0216 06:14:36.669186 22839682574144 run_lib.py:146] step: 88200, eval_loss: 1.26869e-01
I0216 06:14:54.163643 22839682574144 run_lib.py:133] step: 88250, training_loss: 1.10447e-01
I0216 06:15:11.684369 22839682574144 run_lib.py:133] step: 88300, training_loss: 1.14572e-01
I0216 06:15:11.844962 22839682574144 run_lib.py:146] step: 88300, eval_loss: 1.23340e-01
I0216 06:15:29.540877 22839682574144 run_lib.py:133] step: 88350, training_loss: 1.14980e-01
I0216 06:15:47.065450 22839682574144 run_lib.py:133] step: 88400, training_loss: 1.15044e-01
I0216 06:15:47.223217 22839682574144 run_lib.py:146] step: 88400, eval_loss: 1.30502e-01
I0216 06:16:04.732005 22839682574144 run_lib.py:133] step: 88450, training_loss: 1.11051e-01
I0216 06:16:22.423112 22839682574144 run_lib.py:133] step: 88500, training_loss: 1.14306e-01
I0216 06:16:22.579064 22839682574144 run_lib.py:146] step: 88500, eval_loss: 1.34733e-01
I0216 06:16:40.098116 22839682574144 run_lib.py:133] step: 88550, training_loss: 1.12807e-01
I0216 06:16:57.595782 22839682574144 run_lib.py:133] step: 88600, training_loss: 1.14887e-01
I0216 06:16:57.757282 22839682574144 run_lib.py:146] step: 88600, eval_loss: 1.26325e-01
I0216 06:17:15.430403 22839682574144 run_lib.py:133] step: 88650, training_loss: 1.17161e-01
I0216 06:17:32.932932 22839682574144 run_lib.py:133] step: 88700, training_loss: 1.17275e-01
I0216 06:17:33.093234 22839682574144 run_lib.py:146] step: 88700, eval_loss: 1.27184e-01
I0216 06:17:50.549001 22839682574144 run_lib.py:133] step: 88750, training_loss: 1.12579e-01
I0216 06:18:08.036959 22839682574144 run_lib.py:133] step: 88800, training_loss: 1.16649e-01
I0216 06:18:08.194068 22839682574144 run_lib.py:146] step: 88800, eval_loss: 1.29858e-01
I0216 06:18:25.919852 22839682574144 run_lib.py:133] step: 88850, training_loss: 1.14122e-01
I0216 06:18:43.560204 22839682574144 run_lib.py:133] step: 88900, training_loss: 1.13110e-01
I0216 06:18:43.718900 22839682574144 run_lib.py:146] step: 88900, eval_loss: 1.28399e-01
I0216 06:19:01.235722 22839682574144 run_lib.py:133] step: 88950, training_loss: 1.19561e-01
I0216 06:19:18.717933 22839682574144 run_lib.py:133] step: 89000, training_loss: 1.12254e-01
I0216 06:19:18.872831 22839682574144 run_lib.py:146] step: 89000, eval_loss: 1.27967e-01
I0216 06:19:36.605707 22839682574144 run_lib.py:133] step: 89050, training_loss: 1.18846e-01
I0216 06:19:54.148540 22839682574144 run_lib.py:133] step: 89100, training_loss: 1.13398e-01
I0216 06:19:54.305140 22839682574144 run_lib.py:146] step: 89100, eval_loss: 1.30591e-01
I0216 06:20:11.773471 22839682574144 run_lib.py:133] step: 89150, training_loss: 1.16151e-01
I0216 06:20:29.522002 22839682574144 run_lib.py:133] step: 89200, training_loss: 1.18651e-01
I0216 06:20:29.683038 22839682574144 run_lib.py:146] step: 89200, eval_loss: 1.30500e-01
I0216 06:20:47.210468 22839682574144 run_lib.py:133] step: 89250, training_loss: 1.13800e-01
I0216 06:21:04.932852 22839682574144 run_lib.py:133] step: 89300, training_loss: 1.17314e-01
I0216 06:21:05.090180 22839682574144 run_lib.py:146] step: 89300, eval_loss: 1.29267e-01
I0216 06:21:22.562972 22839682574144 run_lib.py:133] step: 89350, training_loss: 1.13801e-01
I0216 06:21:40.070995 22839682574144 run_lib.py:133] step: 89400, training_loss: 1.13137e-01
I0216 06:21:40.228426 22839682574144 run_lib.py:146] step: 89400, eval_loss: 1.32018e-01
I0216 06:21:57.980779 22839682574144 run_lib.py:133] step: 89450, training_loss: 1.15873e-01
I0216 06:22:15.518211 22839682574144 run_lib.py:133] step: 89500, training_loss: 1.09064e-01
I0216 06:22:15.674720 22839682574144 run_lib.py:146] step: 89500, eval_loss: 1.31204e-01
I0216 06:22:33.176353 22839682574144 run_lib.py:133] step: 89550, training_loss: 1.17300e-01
I0216 06:22:50.877777 22839682574144 run_lib.py:133] step: 89600, training_loss: 1.19646e-01
I0216 06:22:51.035043 22839682574144 run_lib.py:146] step: 89600, eval_loss: 1.25684e-01
I0216 06:23:08.525647 22839682574144 run_lib.py:133] step: 89650, training_loss: 1.16356e-01
I0216 06:23:26.048673 22839682574144 run_lib.py:133] step: 89700, training_loss: 1.14693e-01
I0216 06:23:26.219022 22839682574144 run_lib.py:146] step: 89700, eval_loss: 1.26349e-01
I0216 06:23:43.845904 22839682574144 run_lib.py:133] step: 89750, training_loss: 1.13636e-01
I0216 06:24:01.373551 22839682574144 run_lib.py:133] step: 89800, training_loss: 1.17209e-01
I0216 06:24:01.530917 22839682574144 run_lib.py:146] step: 89800, eval_loss: 1.27673e-01
I0216 06:24:19.053530 22839682574144 run_lib.py:133] step: 89850, training_loss: 1.16815e-01
I0216 06:24:36.537368 22839682574144 run_lib.py:133] step: 89900, training_loss: 1.15230e-01
I0216 06:24:36.698325 22839682574144 run_lib.py:146] step: 89900, eval_loss: 1.31516e-01
I0216 06:24:54.395281 22839682574144 run_lib.py:133] step: 89950, training_loss: 1.18926e-01
I0216 06:25:12.071099 22839682574144 run_lib.py:133] step: 90000, training_loss: 1.14380e-01
I0216 06:25:12.827633 22839682574144 run_lib.py:146] step: 90000, eval_loss: 1.31674e-01
I0216 06:25:33.065722 22839682574144 run_lib.py:133] step: 90050, training_loss: 1.14235e-01
I0216 06:25:50.562843 22839682574144 run_lib.py:133] step: 90100, training_loss: 1.12621e-01
I0216 06:25:50.720332 22839682574144 run_lib.py:146] step: 90100, eval_loss: 1.30093e-01
I0216 06:26:08.189175 22839682574144 run_lib.py:133] step: 90150, training_loss: 1.13417e-01
I0216 06:26:25.872438 22839682574144 run_lib.py:133] step: 90200, training_loss: 1.14572e-01
I0216 06:26:26.042063 22839682574144 run_lib.py:146] step: 90200, eval_loss: 1.28486e-01
I0216 06:26:43.573582 22839682574144 run_lib.py:133] step: 90250, training_loss: 1.14121e-01
I0216 06:27:01.225890 22839682574144 run_lib.py:133] step: 90300, training_loss: 1.17371e-01
I0216 06:27:01.381077 22839682574144 run_lib.py:146] step: 90300, eval_loss: 1.28105e-01
I0216 06:27:18.895256 22839682574144 run_lib.py:133] step: 90350, training_loss: 1.15929e-01
I0216 06:27:36.398985 22839682574144 run_lib.py:133] step: 90400, training_loss: 1.16263e-01
I0216 06:27:36.559218 22839682574144 run_lib.py:146] step: 90400, eval_loss: 1.30562e-01
I0216 06:27:54.235741 22839682574144 run_lib.py:133] step: 90450, training_loss: 1.18560e-01
I0216 06:28:11.765001 22839682574144 run_lib.py:133] step: 90500, training_loss: 1.13863e-01
I0216 06:28:11.919915 22839682574144 run_lib.py:146] step: 90500, eval_loss: 1.28794e-01
I0216 06:28:29.639839 22839682574144 run_lib.py:133] step: 90550, training_loss: 1.12230e-01
I0216 06:28:47.136013 22839682574144 run_lib.py:133] step: 90600, training_loss: 1.18868e-01
I0216 06:28:47.292071 22839682574144 run_lib.py:146] step: 90600, eval_loss: 1.29238e-01
I0216 06:29:05.052937 22839682574144 run_lib.py:133] step: 90650, training_loss: 1.11710e-01
I0216 06:29:22.601508 22839682574144 run_lib.py:133] step: 90700, training_loss: 1.11095e-01
I0216 06:29:22.764548 22839682574144 run_lib.py:146] step: 90700, eval_loss: 1.30233e-01
I0216 06:29:40.309780 22839682574144 run_lib.py:133] step: 90750, training_loss: 1.15701e-01
I0216 06:29:57.873670 22839682574144 run_lib.py:133] step: 90800, training_loss: 1.14135e-01
I0216 06:29:58.032251 22839682574144 run_lib.py:146] step: 90800, eval_loss: 1.32591e-01
I0216 06:30:15.737265 22839682574144 run_lib.py:133] step: 90850, training_loss: 1.17142e-01
I0216 06:30:33.411166 22839682574144 run_lib.py:133] step: 90900, training_loss: 1.15986e-01
I0216 06:30:33.580143 22839682574144 run_lib.py:146] step: 90900, eval_loss: 1.29793e-01
I0216 06:30:51.082008 22839682574144 run_lib.py:133] step: 90950, training_loss: 1.18475e-01
I0216 06:31:08.614930 22839682574144 run_lib.py:133] step: 91000, training_loss: 1.13064e-01
I0216 06:31:08.769309 22839682574144 run_lib.py:146] step: 91000, eval_loss: 1.32430e-01
I0216 06:31:26.253736 22839682574144 run_lib.py:133] step: 91050, training_loss: 1.15762e-01
I0216 06:31:43.950085 22839682574144 run_lib.py:133] step: 91100, training_loss: 1.16558e-01
I0216 06:31:44.119247 22839682574144 run_lib.py:146] step: 91100, eval_loss: 1.31712e-01
I0216 06:32:01.657103 22839682574144 run_lib.py:133] step: 91150, training_loss: 1.15210e-01
I0216 06:32:19.206630 22839682574144 run_lib.py:133] step: 91200, training_loss: 1.15338e-01
I0216 06:32:19.365378 22839682574144 run_lib.py:146] step: 91200, eval_loss: 1.31460e-01
I0216 06:32:36.893342 22839682574144 run_lib.py:133] step: 91250, training_loss: 1.16237e-01
I0216 06:32:54.597591 22839682574144 run_lib.py:133] step: 91300, training_loss: 1.10300e-01
I0216 06:32:54.764263 22839682574144 run_lib.py:146] step: 91300, eval_loss: 1.31019e-01
I0216 06:33:12.301711 22839682574144 run_lib.py:133] step: 91350, training_loss: 1.13157e-01
I0216 06:33:29.993782 22839682574144 run_lib.py:133] step: 91400, training_loss: 1.13132e-01
I0216 06:33:30.150843 22839682574144 run_lib.py:146] step: 91400, eval_loss: 1.32741e-01
I0216 06:33:47.657829 22839682574144 run_lib.py:133] step: 91450, training_loss: 1.11483e-01
I0216 06:34:05.162756 22839682574144 run_lib.py:133] step: 91500, training_loss: 1.16404e-01
I0216 06:34:05.317851 22839682574144 run_lib.py:146] step: 91500, eval_loss: 1.38057e-01
I0216 06:34:22.970159 22839682574144 run_lib.py:133] step: 91550, training_loss: 1.11408e-01
I0216 06:34:40.514456 22839682574144 run_lib.py:133] step: 91600, training_loss: 1.13318e-01
I0216 06:34:40.690681 22839682574144 run_lib.py:146] step: 91600, eval_loss: 1.29820e-01
I0216 06:34:58.422019 22839682574144 run_lib.py:133] step: 91650, training_loss: 1.10090e-01
I0216 06:35:15.948801 22839682574144 run_lib.py:133] step: 91700, training_loss: 1.12612e-01
I0216 06:35:16.108056 22839682574144 run_lib.py:146] step: 91700, eval_loss: 1.32274e-01
I0216 06:35:33.806017 22839682574144 run_lib.py:133] step: 91750, training_loss: 1.14773e-01
I0216 06:35:51.332867 22839682574144 run_lib.py:133] step: 91800, training_loss: 1.16435e-01
I0216 06:35:51.491188 22839682574144 run_lib.py:146] step: 91800, eval_loss: 1.28608e-01
I0216 06:36:09.007800 22839682574144 run_lib.py:133] step: 91850, training_loss: 1.11564e-01
I0216 06:36:26.538674 22839682574144 run_lib.py:133] step: 91900, training_loss: 1.14684e-01
I0216 06:36:26.693568 22839682574144 run_lib.py:146] step: 91900, eval_loss: 1.28992e-01
I0216 06:36:44.432468 22839682574144 run_lib.py:133] step: 91950, training_loss: 1.19468e-01
I0216 06:37:02.082133 22839682574144 run_lib.py:133] step: 92000, training_loss: 1.14257e-01
I0216 06:37:02.239041 22839682574144 run_lib.py:146] step: 92000, eval_loss: 1.36637e-01
I0216 06:37:19.760981 22839682574144 run_lib.py:133] step: 92050, training_loss: 1.18674e-01
I0216 06:37:37.279481 22839682574144 run_lib.py:133] step: 92100, training_loss: 1.14331e-01
I0216 06:37:37.452068 22839682574144 run_lib.py:146] step: 92100, eval_loss: 1.33375e-01
I0216 06:37:55.041080 22839682574144 run_lib.py:133] step: 92150, training_loss: 1.18579e-01
I0216 06:38:12.799561 22839682574144 run_lib.py:133] step: 92200, training_loss: 1.16441e-01
I0216 06:38:12.957397 22839682574144 run_lib.py:146] step: 92200, eval_loss: 1.36793e-01
I0216 06:38:30.444733 22839682574144 run_lib.py:133] step: 92250, training_loss: 1.14167e-01
I0216 06:38:47.930938 22839682574144 run_lib.py:133] step: 92300, training_loss: 1.15120e-01
I0216 06:38:48.089029 22839682574144 run_lib.py:146] step: 92300, eval_loss: 1.27747e-01
I0216 06:39:05.617881 22839682574144 run_lib.py:133] step: 92350, training_loss: 1.16463e-01
I0216 06:39:23.347303 22839682574144 run_lib.py:133] step: 92400, training_loss: 1.18012e-01
I0216 06:39:23.512570 22839682574144 run_lib.py:146] step: 92400, eval_loss: 1.26779e-01
I0216 06:39:41.025393 22839682574144 run_lib.py:133] step: 92450, training_loss: 1.12795e-01
I0216 06:39:58.645451 22839682574144 run_lib.py:133] step: 92500, training_loss: 1.12767e-01
I0216 06:39:58.827142 22839682574144 run_lib.py:146] step: 92500, eval_loss: 1.36008e-01
I0216 06:40:16.247616 22839682574144 run_lib.py:133] step: 92550, training_loss: 1.20211e-01
I0216 06:40:33.479551 22839682574144 run_lib.py:133] step: 92600, training_loss: 1.12966e-01
I0216 06:40:33.655064 22839682574144 run_lib.py:146] step: 92600, eval_loss: 1.29485e-01
I0216 06:40:51.152487 22839682574144 run_lib.py:133] step: 92650, training_loss: 1.17332e-01
I0216 06:41:08.504749 22839682574144 run_lib.py:133] step: 92700, training_loss: 1.09592e-01
I0216 06:41:08.666005 22839682574144 run_lib.py:146] step: 92700, eval_loss: 1.28808e-01
I0216 06:41:26.242753 22839682574144 run_lib.py:133] step: 92750, training_loss: 1.11986e-01
I0216 06:41:43.755541 22839682574144 run_lib.py:133] step: 92800, training_loss: 1.17619e-01
I0216 06:41:43.912118 22839682574144 run_lib.py:146] step: 92800, eval_loss: 1.32634e-01
I0216 06:42:01.568582 22839682574144 run_lib.py:133] step: 92850, training_loss: 1.11962e-01
I0216 06:42:19.109556 22839682574144 run_lib.py:133] step: 92900, training_loss: 1.16251e-01
I0216 06:42:19.266277 22839682574144 run_lib.py:146] step: 92900, eval_loss: 1.34897e-01
I0216 06:42:36.853682 22839682574144 run_lib.py:133] step: 92950, training_loss: 1.16218e-01
I0216 06:42:54.374242 22839682574144 run_lib.py:133] step: 93000, training_loss: 1.10533e-01
I0216 06:42:54.531106 22839682574144 run_lib.py:146] step: 93000, eval_loss: 1.31061e-01
I0216 06:43:12.234947 22839682574144 run_lib.py:133] step: 93050, training_loss: 1.14522e-01
I0216 06:43:29.862504 22839682574144 run_lib.py:133] step: 93100, training_loss: 1.16249e-01
I0216 06:43:30.022433 22839682574144 run_lib.py:146] step: 93100, eval_loss: 1.30982e-01
I0216 06:43:47.552026 22839682574144 run_lib.py:133] step: 93150, training_loss: 1.14687e-01
I0216 06:44:05.100302 22839682574144 run_lib.py:133] step: 93200, training_loss: 1.11390e-01
I0216 06:44:05.259717 22839682574144 run_lib.py:146] step: 93200, eval_loss: 1.28989e-01
I0216 06:44:22.748844 22839682574144 run_lib.py:133] step: 93250, training_loss: 1.11341e-01
I0216 06:44:40.455101 22839682574144 run_lib.py:133] step: 93300, training_loss: 1.15211e-01
I0216 06:44:40.611707 22839682574144 run_lib.py:146] step: 93300, eval_loss: 1.29480e-01
I0216 06:44:58.137776 22839682574144 run_lib.py:133] step: 93350, training_loss: 1.13651e-01
I0216 06:45:15.625265 22839682574144 run_lib.py:133] step: 93400, training_loss: 1.13267e-01
I0216 06:45:15.779541 22839682574144 run_lib.py:146] step: 93400, eval_loss: 1.29634e-01
I0216 06:45:33.272125 22839682574144 run_lib.py:133] step: 93450, training_loss: 1.16512e-01
I0216 06:45:50.984654 22839682574144 run_lib.py:133] step: 93500, training_loss: 1.08002e-01
I0216 06:45:51.160093 22839682574144 run_lib.py:146] step: 93500, eval_loss: 1.29829e-01
I0216 06:46:08.683001 22839682574144 run_lib.py:133] step: 93550, training_loss: 1.11368e-01
I0216 06:46:26.341638 22839682574144 run_lib.py:133] step: 93600, training_loss: 1.15519e-01
I0216 06:46:26.500273 22839682574144 run_lib.py:146] step: 93600, eval_loss: 1.29165e-01
I0216 06:46:44.018297 22839682574144 run_lib.py:133] step: 93650, training_loss: 1.16945e-01
I0216 06:47:01.538564 22839682574144 run_lib.py:133] step: 93700, training_loss: 1.11450e-01
I0216 06:47:01.695870 22839682574144 run_lib.py:146] step: 93700, eval_loss: 1.32809e-01
I0216 06:47:19.381928 22839682574144 run_lib.py:133] step: 93750, training_loss: 1.16736e-01
I0216 06:47:36.927042 22839682574144 run_lib.py:133] step: 93800, training_loss: 1.15569e-01
I0216 06:47:37.083822 22839682574144 run_lib.py:146] step: 93800, eval_loss: 1.31722e-01
I0216 06:47:54.816715 22839682574144 run_lib.py:133] step: 93850, training_loss: 1.11999e-01
I0216 06:48:12.337749 22839682574144 run_lib.py:133] step: 93900, training_loss: 1.14284e-01
I0216 06:48:12.494026 22839682574144 run_lib.py:146] step: 93900, eval_loss: 1.31902e-01
I0216 06:48:30.190125 22839682574144 run_lib.py:133] step: 93950, training_loss: 1.20036e-01
I0216 06:48:47.683360 22839682574144 run_lib.py:133] step: 94000, training_loss: 1.15517e-01
I0216 06:48:47.843237 22839682574144 run_lib.py:146] step: 94000, eval_loss: 1.29946e-01
I0216 06:49:05.348327 22839682574144 run_lib.py:133] step: 94050, training_loss: 1.18546e-01
I0216 06:49:22.894449 22839682574144 run_lib.py:133] step: 94100, training_loss: 1.15628e-01
I0216 06:49:23.097116 22839682574144 run_lib.py:146] step: 94100, eval_loss: 1.33173e-01
I0216 06:49:40.839432 22839682574144 run_lib.py:133] step: 94150, training_loss: 1.13024e-01
I0216 06:49:58.459072 22839682574144 run_lib.py:133] step: 94200, training_loss: 1.13273e-01
I0216 06:49:58.616003 22839682574144 run_lib.py:146] step: 94200, eval_loss: 1.37090e-01
I0216 06:50:16.117495 22839682574144 run_lib.py:133] step: 94250, training_loss: 1.14843e-01
I0216 06:50:33.620833 22839682574144 run_lib.py:133] step: 94300, training_loss: 1.16396e-01
I0216 06:50:33.776384 22839682574144 run_lib.py:146] step: 94300, eval_loss: 1.28358e-01
I0216 06:50:51.326324 22839682574144 run_lib.py:133] step: 94350, training_loss: 1.11317e-01
I0216 06:51:09.026615 22839682574144 run_lib.py:133] step: 94400, training_loss: 1.15206e-01
I0216 06:51:09.184316 22839682574144 run_lib.py:146] step: 94400, eval_loss: 1.33914e-01
I0216 06:51:26.688070 22839682574144 run_lib.py:133] step: 94450, training_loss: 1.13031e-01
I0216 06:51:44.200447 22839682574144 run_lib.py:133] step: 94500, training_loss: 1.13265e-01
I0216 06:51:44.360361 22839682574144 run_lib.py:146] step: 94500, eval_loss: 1.26182e-01
I0216 06:52:01.844317 22839682574144 run_lib.py:133] step: 94550, training_loss: 1.14170e-01
I0216 06:52:19.556994 22839682574144 run_lib.py:133] step: 94600, training_loss: 1.17256e-01
I0216 06:52:19.723048 22839682574144 run_lib.py:146] step: 94600, eval_loss: 1.28789e-01
I0216 06:52:37.284456 22839682574144 run_lib.py:133] step: 94650, training_loss: 1.16178e-01
I0216 06:52:54.930855 22839682574144 run_lib.py:133] step: 94700, training_loss: 1.13925e-01
I0216 06:52:55.094546 22839682574144 run_lib.py:146] step: 94700, eval_loss: 1.28864e-01
I0216 06:53:12.654254 22839682574144 run_lib.py:133] step: 94750, training_loss: 1.18573e-01
I0216 06:53:30.135693 22839682574144 run_lib.py:133] step: 94800, training_loss: 1.12318e-01
I0216 06:53:30.290028 22839682574144 run_lib.py:146] step: 94800, eval_loss: 1.32447e-01
I0216 06:53:47.977091 22839682574144 run_lib.py:133] step: 94850, training_loss: 1.14386e-01
I0216 06:54:05.534494 22839682574144 run_lib.py:133] step: 94900, training_loss: 1.15747e-01
I0216 06:54:05.704339 22839682574144 run_lib.py:146] step: 94900, eval_loss: 1.30834e-01
I0216 06:54:23.442282 22839682574144 run_lib.py:133] step: 94950, training_loss: 1.13624e-01
I0216 06:54:40.970942 22839682574144 run_lib.py:133] step: 95000, training_loss: 1.18332e-01
I0216 06:54:41.130594 22839682574144 run_lib.py:146] step: 95000, eval_loss: 1.30814e-01
I0216 06:54:58.839393 22839682574144 run_lib.py:133] step: 95050, training_loss: 1.14602e-01
I0216 06:55:16.337782 22839682574144 run_lib.py:133] step: 95100, training_loss: 1.16295e-01
I0216 06:55:16.504125 22839682574144 run_lib.py:146] step: 95100, eval_loss: 1.27212e-01
I0216 06:55:34.012147 22839682574144 run_lib.py:133] step: 95150, training_loss: 1.19296e-01
I0216 06:55:51.522961 22839682574144 run_lib.py:133] step: 95200, training_loss: 1.15423e-01
I0216 06:55:51.680395 22839682574144 run_lib.py:146] step: 95200, eval_loss: 1.30213e-01
I0216 06:56:09.405442 22839682574144 run_lib.py:133] step: 95250, training_loss: 1.07592e-01
I0216 06:56:27.073617 22839682574144 run_lib.py:133] step: 95300, training_loss: 1.14251e-01
I0216 06:56:27.227204 22839682574144 run_lib.py:146] step: 95300, eval_loss: 1.25592e-01
I0216 06:56:44.737405 22839682574144 run_lib.py:133] step: 95350, training_loss: 1.16711e-01
I0216 06:57:02.240801 22839682574144 run_lib.py:133] step: 95400, training_loss: 1.16138e-01
I0216 06:57:02.414546 22839682574144 run_lib.py:146] step: 95400, eval_loss: 1.31004e-01
I0216 06:57:19.958935 22839682574144 run_lib.py:133] step: 95450, training_loss: 1.15771e-01
I0216 06:57:37.727631 22839682574144 run_lib.py:133] step: 95500, training_loss: 1.11857e-01
I0216 06:57:37.885673 22839682574144 run_lib.py:146] step: 95500, eval_loss: 1.32047e-01
I0216 06:57:55.410382 22839682574144 run_lib.py:133] step: 95550, training_loss: 1.12586e-01
I0216 06:58:12.906940 22839682574144 run_lib.py:133] step: 95600, training_loss: 1.15068e-01
I0216 06:58:13.065133 22839682574144 run_lib.py:146] step: 95600, eval_loss: 1.34159e-01
I0216 06:58:30.595651 22839682574144 run_lib.py:133] step: 95650, training_loss: 1.15540e-01
I0216 06:58:48.380058 22839682574144 run_lib.py:133] step: 95700, training_loss: 1.19482e-01
I0216 06:58:48.536280 22839682574144 run_lib.py:146] step: 95700, eval_loss: 1.32563e-01
I0216 06:59:06.096536 22839682574144 run_lib.py:133] step: 95750, training_loss: 1.15683e-01
I0216 06:59:23.705756 22839682574144 run_lib.py:133] step: 95800, training_loss: 1.13550e-01
I0216 06:59:23.862120 22839682574144 run_lib.py:146] step: 95800, eval_loss: 1.39091e-01
I0216 06:59:41.397545 22839682574144 run_lib.py:133] step: 95850, training_loss: 1.11922e-01
I0216 06:59:58.923428 22839682574144 run_lib.py:133] step: 95900, training_loss: 1.16822e-01
I0216 06:59:59.097275 22839682574144 run_lib.py:146] step: 95900, eval_loss: 1.37138e-01
I0216 07:00:16.826014 22839682574144 run_lib.py:133] step: 95950, training_loss: 1.15656e-01
I0216 07:00:34.346753 22839682574144 run_lib.py:133] step: 96000, training_loss: 1.13342e-01
I0216 07:00:34.504150 22839682574144 run_lib.py:146] step: 96000, eval_loss: 1.29294e-01
I0216 07:00:52.233355 22839682574144 run_lib.py:133] step: 96050, training_loss: 1.11840e-01
I0216 07:01:09.773615 22839682574144 run_lib.py:133] step: 96100, training_loss: 1.18204e-01
I0216 07:01:09.931249 22839682574144 run_lib.py:146] step: 96100, eval_loss: 1.30273e-01
I0216 07:01:27.627431 22839682574144 run_lib.py:133] step: 96150, training_loss: 1.16049e-01
I0216 07:01:45.169328 22839682574144 run_lib.py:133] step: 96200, training_loss: 1.18503e-01
I0216 07:01:45.333971 22839682574144 run_lib.py:146] step: 96200, eval_loss: 1.30041e-01
I0216 07:02:02.890027 22839682574144 run_lib.py:133] step: 96250, training_loss: 1.16393e-01
I0216 07:02:20.385283 22839682574144 run_lib.py:133] step: 96300, training_loss: 1.15831e-01
I0216 07:02:20.542059 22839682574144 run_lib.py:146] step: 96300, eval_loss: 1.29314e-01
I0216 07:02:38.284228 22839682574144 run_lib.py:133] step: 96350, training_loss: 1.12589e-01
I0216 07:02:55.973063 22839682574144 run_lib.py:133] step: 96400, training_loss: 1.18518e-01
I0216 07:02:56.133229 22839682574144 run_lib.py:146] step: 96400, eval_loss: 1.29295e-01
I0216 07:03:13.654242 22839682574144 run_lib.py:133] step: 96450, training_loss: 1.12429e-01
I0216 07:03:31.240462 22839682574144 run_lib.py:133] step: 96500, training_loss: 1.16175e-01
I0216 07:03:31.398422 22839682574144 run_lib.py:146] step: 96500, eval_loss: 1.35140e-01
I0216 07:03:48.904305 22839682574144 run_lib.py:133] step: 96550, training_loss: 1.10909e-01
I0216 07:04:06.643492 22839682574144 run_lib.py:133] step: 96600, training_loss: 1.13085e-01
I0216 07:04:06.800132 22839682574144 run_lib.py:146] step: 96600, eval_loss: 1.29970e-01
I0216 07:04:24.323541 22839682574144 run_lib.py:133] step: 96650, training_loss: 1.12839e-01
I0216 07:04:41.849857 22839682574144 run_lib.py:133] step: 96700, training_loss: 1.12110e-01
I0216 07:04:42.007820 22839682574144 run_lib.py:146] step: 96700, eval_loss: 1.29572e-01
I0216 07:04:59.573663 22839682574144 run_lib.py:133] step: 96750, training_loss: 1.16312e-01
I0216 07:05:17.282114 22839682574144 run_lib.py:133] step: 96800, training_loss: 1.15555e-01
I0216 07:05:17.439232 22839682574144 run_lib.py:146] step: 96800, eval_loss: 1.32837e-01
I0216 07:05:34.957040 22839682574144 run_lib.py:133] step: 96850, training_loss: 1.12556e-01
I0216 07:05:52.607851 22839682574144 run_lib.py:133] step: 96900, training_loss: 1.15833e-01
I0216 07:05:52.767230 22839682574144 run_lib.py:146] step: 96900, eval_loss: 1.31049e-01
I0216 07:06:10.282205 22839682574144 run_lib.py:133] step: 96950, training_loss: 1.16352e-01
I0216 07:06:27.830816 22839682574144 run_lib.py:133] step: 97000, training_loss: 1.14489e-01
I0216 07:06:27.988559 22839682574144 run_lib.py:146] step: 97000, eval_loss: 1.32549e-01
I0216 07:06:45.749210 22839682574144 run_lib.py:133] step: 97050, training_loss: 1.15135e-01
I0216 07:07:03.265154 22839682574144 run_lib.py:133] step: 97100, training_loss: 1.14310e-01
I0216 07:07:03.420901 22839682574144 run_lib.py:146] step: 97100, eval_loss: 1.30524e-01
I0216 07:07:21.072466 22839682574144 run_lib.py:133] step: 97150, training_loss: 1.14276e-01
I0216 07:07:38.600608 22839682574144 run_lib.py:133] step: 97200, training_loss: 1.15752e-01
I0216 07:07:38.762045 22839682574144 run_lib.py:146] step: 97200, eval_loss: 1.31876e-01
I0216 07:07:56.461636 22839682574144 run_lib.py:133] step: 97250, training_loss: 1.14565e-01
I0216 07:08:13.962716 22839682574144 run_lib.py:133] step: 97300, training_loss: 1.17020e-01
I0216 07:08:14.130136 22839682574144 run_lib.py:146] step: 97300, eval_loss: 1.29517e-01
I0216 07:08:31.638706 22839682574144 run_lib.py:133] step: 97350, training_loss: 1.14922e-01
I0216 07:08:49.121468 22839682574144 run_lib.py:133] step: 97400, training_loss: 1.13024e-01
I0216 07:08:49.279047 22839682574144 run_lib.py:146] step: 97400, eval_loss: 1.31969e-01
I0216 07:09:07.003993 22839682574144 run_lib.py:133] step: 97450, training_loss: 1.13749e-01
I0216 07:09:24.634291 22839682574144 run_lib.py:133] step: 97500, training_loss: 1.13235e-01
I0216 07:09:24.791803 22839682574144 run_lib.py:146] step: 97500, eval_loss: 1.32550e-01
I0216 07:09:42.318982 22839682574144 run_lib.py:133] step: 97550, training_loss: 1.13939e-01
I0216 07:09:59.848007 22839682574144 run_lib.py:133] step: 97600, training_loss: 1.12630e-01
I0216 07:10:00.012847 22839682574144 run_lib.py:146] step: 97600, eval_loss: 1.28976e-01
I0216 07:10:17.570732 22839682574144 run_lib.py:133] step: 97650, training_loss: 1.14909e-01
I0216 07:10:35.287368 22839682574144 run_lib.py:133] step: 97700, training_loss: 1.15231e-01
I0216 07:10:35.443149 22839682574144 run_lib.py:146] step: 97700, eval_loss: 1.29747e-01
I0216 07:10:52.984130 22839682574144 run_lib.py:133] step: 97750, training_loss: 1.14018e-01
I0216 07:11:10.521730 22839682574144 run_lib.py:133] step: 97800, training_loss: 1.16852e-01
I0216 07:11:10.694016 22839682574144 run_lib.py:146] step: 97800, eval_loss: 1.31781e-01
I0216 07:11:28.203695 22839682574144 run_lib.py:133] step: 97850, training_loss: 1.14112e-01
I0216 07:11:45.914488 22839682574144 run_lib.py:133] step: 97900, training_loss: 1.13105e-01
I0216 07:11:46.075690 22839682574144 run_lib.py:146] step: 97900, eval_loss: 1.31907e-01
I0216 07:12:03.562022 22839682574144 run_lib.py:133] step: 97950, training_loss: 1.14523e-01
I0216 07:12:21.160250 22839682574144 run_lib.py:133] step: 98000, training_loss: 1.10433e-01
I0216 07:12:21.318241 22839682574144 run_lib.py:146] step: 98000, eval_loss: 1.34861e-01
I0216 07:12:38.842251 22839682574144 run_lib.py:133] step: 98050, training_loss: 1.12865e-01
I0216 07:12:56.384837 22839682574144 run_lib.py:133] step: 98100, training_loss: 1.15100e-01
I0216 07:12:56.541808 22839682574144 run_lib.py:146] step: 98100, eval_loss: 1.28129e-01
I0216 07:13:14.253727 22839682574144 run_lib.py:133] step: 98150, training_loss: 1.11776e-01
I0216 07:13:31.773623 22839682574144 run_lib.py:133] step: 98200, training_loss: 1.15907e-01
I0216 07:13:31.931071 22839682574144 run_lib.py:146] step: 98200, eval_loss: 1.30128e-01
I0216 07:13:49.595166 22839682574144 run_lib.py:133] step: 98250, training_loss: 1.18668e-01
I0216 07:14:07.124008 22839682574144 run_lib.py:133] step: 98300, training_loss: 1.15104e-01
I0216 07:14:07.284198 22839682574144 run_lib.py:146] step: 98300, eval_loss: 1.29667e-01
I0216 07:14:24.989296 22839682574144 run_lib.py:133] step: 98350, training_loss: 1.17935e-01
I0216 07:14:42.535172 22839682574144 run_lib.py:133] step: 98400, training_loss: 1.14893e-01
I0216 07:14:42.692377 22839682574144 run_lib.py:146] step: 98400, eval_loss: 1.29759e-01
I0216 07:15:00.176513 22839682574144 run_lib.py:133] step: 98450, training_loss: 1.12100e-01
I0216 07:15:17.720138 22839682574144 run_lib.py:133] step: 98500, training_loss: 1.19084e-01
I0216 07:15:17.877137 22839682574144 run_lib.py:146] step: 98500, eval_loss: 1.28770e-01
I0216 07:15:35.601444 22839682574144 run_lib.py:133] step: 98550, training_loss: 1.11632e-01
I0216 07:15:53.336278 22839682574144 run_lib.py:133] step: 98600, training_loss: 1.15262e-01
I0216 07:15:53.502178 22839682574144 run_lib.py:146] step: 98600, eval_loss: 1.29258e-01
I0216 07:16:11.027891 22839682574144 run_lib.py:133] step: 98650, training_loss: 1.12875e-01
I0216 07:16:28.560242 22839682574144 run_lib.py:133] step: 98700, training_loss: 1.13516e-01
I0216 07:16:28.727815 22839682574144 run_lib.py:146] step: 98700, eval_loss: 1.32831e-01
I0216 07:16:46.247133 22839682574144 run_lib.py:133] step: 98750, training_loss: 1.13908e-01
I0216 07:17:03.958457 22839682574144 run_lib.py:133] step: 98800, training_loss: 1.10196e-01
I0216 07:17:04.117685 22839682574144 run_lib.py:146] step: 98800, eval_loss: 1.29730e-01
I0216 07:17:21.625517 22839682574144 run_lib.py:133] step: 98850, training_loss: 1.15706e-01
I0216 07:17:39.133024 22839682574144 run_lib.py:133] step: 98900, training_loss: 1.15923e-01
I0216 07:17:39.290839 22839682574144 run_lib.py:146] step: 98900, eval_loss: 1.28796e-01
I0216 07:17:56.828304 22839682574144 run_lib.py:133] step: 98950, training_loss: 1.10443e-01
I0216 07:18:14.556129 22839682574144 run_lib.py:133] step: 99000, training_loss: 1.10141e-01
I0216 07:18:14.713013 22839682574144 run_lib.py:146] step: 99000, eval_loss: 1.31998e-01
I0216 07:18:32.198960 22839682574144 run_lib.py:133] step: 99050, training_loss: 1.16393e-01
I0216 07:18:49.826373 22839682574144 run_lib.py:133] step: 99100, training_loss: 1.13447e-01
I0216 07:18:49.994972 22839682574144 run_lib.py:146] step: 99100, eval_loss: 1.29552e-01
I0216 07:19:07.524772 22839682574144 run_lib.py:133] step: 99150, training_loss: 1.11787e-01
I0216 07:19:25.068424 22839682574144 run_lib.py:133] step: 99200, training_loss: 1.18641e-01
I0216 07:19:25.228005 22839682574144 run_lib.py:146] step: 99200, eval_loss: 1.30480e-01
I0216 07:19:42.929032 22839682574144 run_lib.py:133] step: 99250, training_loss: 1.08889e-01
I0216 07:20:00.422072 22839682574144 run_lib.py:133] step: 99300, training_loss: 1.15452e-01
I0216 07:20:00.579164 22839682574144 run_lib.py:146] step: 99300, eval_loss: 1.29495e-01
I0216 07:20:18.253112 22839682574144 run_lib.py:133] step: 99350, training_loss: 1.17160e-01
I0216 07:20:35.812419 22839682574144 run_lib.py:133] step: 99400, training_loss: 1.12096e-01
I0216 07:20:35.970362 22839682574144 run_lib.py:146] step: 99400, eval_loss: 1.30888e-01
I0216 07:20:53.704818 22839682574144 run_lib.py:133] step: 99450, training_loss: 1.20033e-01
I0216 07:21:11.244072 22839682574144 run_lib.py:133] step: 99500, training_loss: 1.14947e-01
I0216 07:21:11.398002 22839682574144 run_lib.py:146] step: 99500, eval_loss: 1.33102e-01
I0216 07:21:28.942137 22839682574144 run_lib.py:133] step: 99550, training_loss: 1.12770e-01
I0216 07:21:46.424937 22839682574144 run_lib.py:133] step: 99600, training_loss: 1.12737e-01
I0216 07:21:46.581037 22839682574144 run_lib.py:146] step: 99600, eval_loss: 1.33017e-01
I0216 07:22:04.256484 22839682574144 run_lib.py:133] step: 99650, training_loss: 1.11170e-01
I0216 07:22:21.985752 22839682574144 run_lib.py:133] step: 99700, training_loss: 1.14586e-01
I0216 07:22:22.161135 22839682574144 run_lib.py:146] step: 99700, eval_loss: 1.26259e-01
I0216 07:22:39.687806 22839682574144 run_lib.py:133] step: 99750, training_loss: 1.14338e-01
I0216 07:22:57.200123 22839682574144 run_lib.py:133] step: 99800, training_loss: 1.11925e-01
I0216 07:22:57.357401 22839682574144 run_lib.py:146] step: 99800, eval_loss: 1.25171e-01
I0216 07:23:14.861634 22839682574144 run_lib.py:133] step: 99850, training_loss: 1.13942e-01
I0216 07:23:32.597921 22839682574144 run_lib.py:133] step: 99900, training_loss: 1.13673e-01
I0216 07:23:32.755047 22839682574144 run_lib.py:146] step: 99900, eval_loss: 1.31286e-01
I0216 07:23:50.283199 22839682574144 run_lib.py:133] step: 99950, training_loss: 1.16333e-01
I0216 07:24:07.825307 22839682574144 run_lib.py:133] step: 100000, training_loss: 1.15137e-01
I0216 07:24:08.588361 22839682574144 run_lib.py:146] step: 100000, eval_loss: 1.34719e-01
I0216 07:24:28.850105 22839682574144 run_lib.py:133] step: 100050, training_loss: 1.08564e-01
I0216 07:24:46.380720 22839682574144 run_lib.py:133] step: 100100, training_loss: 1.14846e-01
I0216 07:24:46.536034 22839682574144 run_lib.py:146] step: 100100, eval_loss: 1.30286e-01
I0216 07:25:04.287924 22839682574144 run_lib.py:133] step: 100150, training_loss: 1.13790e-01
I0216 07:25:21.848104 22839682574144 run_lib.py:133] step: 100200, training_loss: 1.17821e-01
I0216 07:25:22.026178 22839682574144 run_lib.py:146] step: 100200, eval_loss: 1.38050e-01
I0216 07:25:39.674567 22839682574144 run_lib.py:133] step: 100250, training_loss: 1.12213e-01
I0216 07:25:57.208232 22839682574144 run_lib.py:133] step: 100300, training_loss: 1.10581e-01
I0216 07:25:57.367982 22839682574144 run_lib.py:146] step: 100300, eval_loss: 1.28925e-01
I0216 07:26:14.872442 22839682574144 run_lib.py:133] step: 100350, training_loss: 1.14970e-01
I0216 07:26:32.370574 22839682574144 run_lib.py:133] step: 100400, training_loss: 1.16181e-01
I0216 07:26:32.528023 22839682574144 run_lib.py:146] step: 100400, eval_loss: 1.32123e-01
I0216 07:26:50.222453 22839682574144 run_lib.py:133] step: 100450, training_loss: 1.15095e-01
I0216 07:27:07.813630 22839682574144 run_lib.py:133] step: 100500, training_loss: 1.14045e-01
I0216 07:27:07.965338 22839682574144 run_lib.py:146] step: 100500, eval_loss: 1.31612e-01
I0216 07:27:25.535257 22839682574144 run_lib.py:133] step: 100550, training_loss: 1.16223e-01
I0216 07:27:43.063106 22839682574144 run_lib.py:133] step: 100600, training_loss: 1.13360e-01
I0216 07:27:43.225206 22839682574144 run_lib.py:146] step: 100600, eval_loss: 1.29239e-01
I0216 07:28:00.955281 22839682574144 run_lib.py:133] step: 100650, training_loss: 1.11554e-01
I0216 07:28:18.482801 22839682574144 run_lib.py:133] step: 100700, training_loss: 1.15431e-01
I0216 07:28:18.643391 22839682574144 run_lib.py:146] step: 100700, eval_loss: 1.27315e-01
I0216 07:28:36.150285 22839682574144 run_lib.py:133] step: 100750, training_loss: 1.16701e-01
I0216 07:28:53.858433 22839682574144 run_lib.py:133] step: 100800, training_loss: 1.12228e-01
I0216 07:28:54.025221 22839682574144 run_lib.py:146] step: 100800, eval_loss: 1.29599e-01
I0216 07:29:11.563512 22839682574144 run_lib.py:133] step: 100850, training_loss: 1.12774e-01
I0216 07:29:29.279861 22839682574144 run_lib.py:133] step: 100900, training_loss: 1.15730e-01
I0216 07:29:29.437228 22839682574144 run_lib.py:146] step: 100900, eval_loss: 1.33121e-01
I0216 07:29:46.984423 22839682574144 run_lib.py:133] step: 100950, training_loss: 1.16670e-01
I0216 07:30:04.528211 22839682574144 run_lib.py:133] step: 101000, training_loss: 1.15605e-01
I0216 07:30:04.682003 22839682574144 run_lib.py:146] step: 101000, eval_loss: 1.32140e-01
I0216 07:30:22.391659 22839682574144 run_lib.py:133] step: 101050, training_loss: 1.14731e-01
I0216 07:30:39.931794 22839682574144 run_lib.py:133] step: 101100, training_loss: 1.12996e-01
I0216 07:30:40.100248 22839682574144 run_lib.py:146] step: 101100, eval_loss: 1.28805e-01
I0216 07:30:57.657882 22839682574144 run_lib.py:133] step: 101150, training_loss: 1.13801e-01
I0216 07:31:15.412010 22839682574144 run_lib.py:133] step: 101200, training_loss: 1.11200e-01
I0216 07:31:15.576454 22839682574144 run_lib.py:146] step: 101200, eval_loss: 1.31914e-01
I0216 07:31:33.084183 22839682574144 run_lib.py:133] step: 101250, training_loss: 1.11479e-01
I0216 07:31:50.623762 22839682574144 run_lib.py:133] step: 101300, training_loss: 1.13153e-01
I0216 07:31:50.790030 22839682574144 run_lib.py:146] step: 101300, eval_loss: 1.32008e-01
I0216 07:32:08.403130 22839682574144 run_lib.py:133] step: 101350, training_loss: 1.10722e-01
I0216 07:32:25.960027 22839682574144 run_lib.py:133] step: 101400, training_loss: 1.11581e-01
I0216 07:32:26.117841 22839682574144 run_lib.py:146] step: 101400, eval_loss: 1.30521e-01
I0216 07:32:43.659607 22839682574144 run_lib.py:133] step: 101450, training_loss: 1.15489e-01
I0216 07:33:01.158153 22839682574144 run_lib.py:133] step: 101500, training_loss: 1.10652e-01
I0216 07:33:01.312038 22839682574144 run_lib.py:146] step: 101500, eval_loss: 1.32436e-01
I0216 07:33:19.047974 22839682574144 run_lib.py:133] step: 101550, training_loss: 1.14592e-01
I0216 07:33:36.660705 22839682574144 run_lib.py:133] step: 101600, training_loss: 1.13794e-01
I0216 07:33:36.820401 22839682574144 run_lib.py:146] step: 101600, eval_loss: 1.30519e-01
I0216 07:33:54.352705 22839682574144 run_lib.py:133] step: 101650, training_loss: 1.10100e-01
I0216 07:34:11.894901 22839682574144 run_lib.py:133] step: 101700, training_loss: 1.15586e-01
I0216 07:34:12.057148 22839682574144 run_lib.py:146] step: 101700, eval_loss: 1.30546e-01
I0216 07:34:29.748872 22839682574144 run_lib.py:133] step: 101750, training_loss: 1.12793e-01
I0216 07:34:47.282737 22839682574144 run_lib.py:133] step: 101800, training_loss: 1.16816e-01
I0216 07:34:47.439743 22839682574144 run_lib.py:146] step: 101800, eval_loss: 1.31105e-01
I0216 07:35:04.945517 22839682574144 run_lib.py:133] step: 101850, training_loss: 1.16168e-01
I0216 07:35:22.565281 22839682574144 run_lib.py:133] step: 101900, training_loss: 1.12115e-01
I0216 07:35:22.722026 22839682574144 run_lib.py:146] step: 101900, eval_loss: 1.33333e-01
I0216 07:35:40.262077 22839682574144 run_lib.py:133] step: 101950, training_loss: 1.13175e-01
I0216 07:35:57.952331 22839682574144 run_lib.py:133] step: 102000, training_loss: 1.10314e-01
I0216 07:35:58.108353 22839682574144 run_lib.py:146] step: 102000, eval_loss: 1.30482e-01
I0216 07:36:15.635660 22839682574144 run_lib.py:133] step: 102050, training_loss: 1.15214e-01
I0216 07:36:33.173121 22839682574144 run_lib.py:133] step: 102100, training_loss: 1.13309e-01
I0216 07:36:33.330263 22839682574144 run_lib.py:146] step: 102100, eval_loss: 1.26721e-01
I0216 07:36:51.017279 22839682574144 run_lib.py:133] step: 102150, training_loss: 1.13938e-01
I0216 07:37:08.576954 22839682574144 run_lib.py:133] step: 102200, training_loss: 1.13252e-01
I0216 07:37:08.736984 22839682574144 run_lib.py:146] step: 102200, eval_loss: 1.29780e-01
I0216 07:37:26.270886 22839682574144 run_lib.py:133] step: 102250, training_loss: 1.17087e-01
I0216 07:37:44.009453 22839682574144 run_lib.py:133] step: 102300, training_loss: 1.13476e-01
I0216 07:37:44.173790 22839682574144 run_lib.py:146] step: 102300, eval_loss: 1.37074e-01
I0216 07:38:01.701139 22839682574144 run_lib.py:133] step: 102350, training_loss: 1.14077e-01
I0216 07:38:19.251767 22839682574144 run_lib.py:133] step: 102400, training_loss: 1.15979e-01
I0216 07:38:19.407836 22839682574144 run_lib.py:146] step: 102400, eval_loss: 1.28160e-01
I0216 07:38:36.978882 22839682574144 run_lib.py:133] step: 102450, training_loss: 1.12914e-01
I0216 07:38:54.569078 22839682574144 run_lib.py:133] step: 102500, training_loss: 1.15857e-01
I0216 07:38:54.729411 22839682574144 run_lib.py:146] step: 102500, eval_loss: 1.32537e-01
I0216 07:39:12.250915 22839682574144 run_lib.py:133] step: 102550, training_loss: 1.10499e-01
I0216 07:39:29.773268 22839682574144 run_lib.py:133] step: 102600, training_loss: 1.14683e-01
I0216 07:39:29.933287 22839682574144 run_lib.py:146] step: 102600, eval_loss: 1.31959e-01
I0216 07:39:47.641812 22839682574144 run_lib.py:133] step: 102650, training_loss: 1.19276e-01
I0216 07:40:05.290991 22839682574144 run_lib.py:133] step: 102700, training_loss: 1.15180e-01
I0216 07:40:05.447133 22839682574144 run_lib.py:146] step: 102700, eval_loss: 1.32056e-01
I0216 07:40:22.972845 22839682574144 run_lib.py:133] step: 102750, training_loss: 1.12019e-01
I0216 07:40:40.522955 22839682574144 run_lib.py:133] step: 102800, training_loss: 1.08041e-01
I0216 07:40:40.688483 22839682574144 run_lib.py:146] step: 102800, eval_loss: 1.30338e-01
I0216 07:40:58.417135 22839682574144 run_lib.py:133] step: 102850, training_loss: 1.14302e-01
I0216 07:41:15.977036 22839682574144 run_lib.py:133] step: 102900, training_loss: 1.11712e-01
I0216 07:41:16.132343 22839682574144 run_lib.py:146] step: 102900, eval_loss: 1.29778e-01
I0216 07:41:33.594790 22839682574144 run_lib.py:133] step: 102950, training_loss: 1.15605e-01
I0216 07:41:51.262767 22839682574144 run_lib.py:133] step: 103000, training_loss: 1.11651e-01
I0216 07:41:51.421321 22839682574144 run_lib.py:146] step: 103000, eval_loss: 1.31357e-01
I0216 07:42:08.958735 22839682574144 run_lib.py:133] step: 103050, training_loss: 1.14453e-01
I0216 07:42:26.691485 22839682574144 run_lib.py:133] step: 103100, training_loss: 1.14393e-01
I0216 07:42:26.852106 22839682574144 run_lib.py:146] step: 103100, eval_loss: 1.30301e-01
I0216 07:42:44.359219 22839682574144 run_lib.py:133] step: 103150, training_loss: 1.16162e-01
I0216 07:43:01.904092 22839682574144 run_lib.py:133] step: 103200, training_loss: 1.15640e-01
I0216 07:43:02.061346 22839682574144 run_lib.py:146] step: 103200, eval_loss: 1.32420e-01
I0216 07:43:19.784555 22839682574144 run_lib.py:133] step: 103250, training_loss: 1.15400e-01
I0216 07:43:37.323536 22839682574144 run_lib.py:133] step: 103300, training_loss: 1.14298e-01
I0216 07:43:37.481113 22839682574144 run_lib.py:146] step: 103300, eval_loss: 1.31532e-01
I0216 07:43:55.001133 22839682574144 run_lib.py:133] step: 103350, training_loss: 1.14441e-01
I0216 07:44:12.774180 22839682574144 run_lib.py:133] step: 103400, training_loss: 1.17011e-01
I0216 07:44:12.929346 22839682574144 run_lib.py:146] step: 103400, eval_loss: 1.33479e-01
I0216 07:44:30.451081 22839682574144 run_lib.py:133] step: 103450, training_loss: 1.14160e-01
I0216 07:44:47.974742 22839682574144 run_lib.py:133] step: 103500, training_loss: 1.13093e-01
I0216 07:44:48.133234 22839682574144 run_lib.py:146] step: 103500, eval_loss: 1.26792e-01
I0216 07:45:05.699517 22839682574144 run_lib.py:133] step: 103550, training_loss: 1.13279e-01
I0216 07:45:23.165216 22839682574144 run_lib.py:133] step: 103600, training_loss: 1.12773e-01
I0216 07:45:23.342110 22839682574144 run_lib.py:146] step: 103600, eval_loss: 1.29128e-01
I0216 07:45:40.882678 22839682574144 run_lib.py:133] step: 103650, training_loss: 1.14748e-01
I0216 07:45:58.412344 22839682574144 run_lib.py:133] step: 103700, training_loss: 1.15706e-01
I0216 07:45:58.569963 22839682574144 run_lib.py:146] step: 103700, eval_loss: 1.31649e-01
I0216 07:46:16.344958 22839682574144 run_lib.py:133] step: 103750, training_loss: 1.09924e-01
I0216 07:46:33.934775 22839682574144 run_lib.py:133] step: 103800, training_loss: 1.15360e-01
I0216 07:46:34.091107 22839682574144 run_lib.py:146] step: 103800, eval_loss: 1.33505e-01
I0216 07:46:51.595388 22839682574144 run_lib.py:133] step: 103850, training_loss: 1.14438e-01
I0216 07:47:09.151187 22839682574144 run_lib.py:133] step: 103900, training_loss: 1.15110e-01
I0216 07:47:09.304380 22839682574144 run_lib.py:146] step: 103900, eval_loss: 1.26539e-01
I0216 07:47:27.004278 22839682574144 run_lib.py:133] step: 103950, training_loss: 1.14046e-01
I0216 07:47:44.543504 22839682574144 run_lib.py:133] step: 104000, training_loss: 1.11338e-01
I0216 07:47:44.702057 22839682574144 run_lib.py:146] step: 104000, eval_loss: 1.27491e-01
I0216 07:48:02.169945 22839682574144 run_lib.py:133] step: 104050, training_loss: 1.13667e-01
I0216 07:48:19.886365 22839682574144 run_lib.py:133] step: 104100, training_loss: 1.16435e-01
I0216 07:48:20.045352 22839682574144 run_lib.py:146] step: 104100, eval_loss: 1.32650e-01
I0216 07:48:37.569644 22839682574144 run_lib.py:133] step: 104150, training_loss: 1.18273e-01
I0216 07:48:55.277246 22839682574144 run_lib.py:133] step: 104200, training_loss: 1.15714e-01
I0216 07:48:55.438277 22839682574144 run_lib.py:146] step: 104200, eval_loss: 1.38340e-01
I0216 07:49:12.992218 22839682574144 run_lib.py:133] step: 104250, training_loss: 1.11877e-01
I0216 07:49:30.495087 22839682574144 run_lib.py:133] step: 104300, training_loss: 1.13977e-01
I0216 07:49:30.651249 22839682574144 run_lib.py:146] step: 104300, eval_loss: 1.28326e-01
I0216 07:49:48.337093 22839682574144 run_lib.py:133] step: 104350, training_loss: 1.11365e-01
I0216 07:50:05.868476 22839682574144 run_lib.py:133] step: 104400, training_loss: 1.12721e-01
I0216 07:50:06.024059 22839682574144 run_lib.py:146] step: 104400, eval_loss: 1.27290e-01
I0216 07:50:23.544185 22839682574144 run_lib.py:133] step: 104450, training_loss: 1.12164e-01
I0216 07:50:41.233017 22839682574144 run_lib.py:133] step: 104500, training_loss: 1.10496e-01
I0216 07:50:41.406997 22839682574144 run_lib.py:146] step: 104500, eval_loss: 1.27633e-01
I0216 07:50:58.927976 22839682574144 run_lib.py:133] step: 104550, training_loss: 1.11787e-01
I0216 07:51:16.452703 22839682574144 run_lib.py:133] step: 104600, training_loss: 1.11908e-01
I0216 07:51:16.627355 22839682574144 run_lib.py:146] step: 104600, eval_loss: 1.29668e-01
I0216 07:51:34.320743 22839682574144 run_lib.py:133] step: 104650, training_loss: 1.11336e-01
I0216 07:51:51.839231 22839682574144 run_lib.py:133] step: 104700, training_loss: 1.13208e-01
I0216 07:51:51.995901 22839682574144 run_lib.py:146] step: 104700, eval_loss: 1.32756e-01
I0216 07:52:09.493064 22839682574144 run_lib.py:133] step: 104750, training_loss: 1.12533e-01
I0216 07:52:27.004744 22839682574144 run_lib.py:133] step: 104800, training_loss: 1.16948e-01
I0216 07:52:27.160247 22839682574144 run_lib.py:146] step: 104800, eval_loss: 1.29611e-01
I0216 07:52:44.916781 22839682574144 run_lib.py:133] step: 104850, training_loss: 1.14835e-01
I0216 07:53:02.491278 22839682574144 run_lib.py:133] step: 104900, training_loss: 1.13649e-01
I0216 07:53:02.648093 22839682574144 run_lib.py:146] step: 104900, eval_loss: 1.31420e-01
I0216 07:53:20.141903 22839682574144 run_lib.py:133] step: 104950, training_loss: 1.10839e-01
I0216 07:53:37.670570 22839682574144 run_lib.py:133] step: 105000, training_loss: 1.16129e-01
I0216 07:53:37.835335 22839682574144 run_lib.py:146] step: 105000, eval_loss: 1.30041e-01
I0216 07:53:55.571971 22839682574144 run_lib.py:133] step: 105050, training_loss: 1.14771e-01
I0216 07:54:13.079220 22839682574144 run_lib.py:133] step: 105100, training_loss: 1.16978e-01
I0216 07:54:13.241444 22839682574144 run_lib.py:146] step: 105100, eval_loss: 1.37761e-01
I0216 07:54:30.761323 22839682574144 run_lib.py:133] step: 105150, training_loss: 1.12886e-01
I0216 07:54:48.498031 22839682574144 run_lib.py:133] step: 105200, training_loss: 1.15514e-01
I0216 07:54:48.655124 22839682574144 run_lib.py:146] step: 105200, eval_loss: 1.28764e-01
I0216 07:55:06.175594 22839682574144 run_lib.py:133] step: 105250, training_loss: 1.10801e-01
I0216 07:55:23.868426 22839682574144 run_lib.py:133] step: 105300, training_loss: 1.11963e-01
I0216 07:55:24.021113 22839682574144 run_lib.py:146] step: 105300, eval_loss: 1.33386e-01
I0216 07:55:41.540767 22839682574144 run_lib.py:133] step: 105350, training_loss: 1.13665e-01
I0216 07:55:59.057662 22839682574144 run_lib.py:133] step: 105400, training_loss: 1.13512e-01
I0216 07:55:59.226365 22839682574144 run_lib.py:146] step: 105400, eval_loss: 1.37311e-01
I0216 07:56:16.987039 22839682574144 run_lib.py:133] step: 105450, training_loss: 1.13133e-01
I0216 07:56:34.526700 22839682574144 run_lib.py:133] step: 105500, training_loss: 1.14647e-01
I0216 07:56:34.691436 22839682574144 run_lib.py:146] step: 105500, eval_loss: 1.31506e-01
I0216 07:56:52.197210 22839682574144 run_lib.py:133] step: 105550, training_loss: 1.14525e-01
I0216 07:57:09.894184 22839682574144 run_lib.py:133] step: 105600, training_loss: 1.12568e-01
I0216 07:57:10.061265 22839682574144 run_lib.py:146] step: 105600, eval_loss: 1.33724e-01
I0216 07:57:27.617765 22839682574144 run_lib.py:133] step: 105650, training_loss: 1.14323e-01
I0216 07:57:45.155140 22839682574144 run_lib.py:133] step: 105700, training_loss: 1.12557e-01
I0216 07:57:45.311350 22839682574144 run_lib.py:146] step: 105700, eval_loss: 1.28475e-01
I0216 07:58:02.959588 22839682574144 run_lib.py:133] step: 105750, training_loss: 1.14395e-01
I0216 07:58:20.463791 22839682574144 run_lib.py:133] step: 105800, training_loss: 1.14694e-01
I0216 07:58:20.618314 22839682574144 run_lib.py:146] step: 105800, eval_loss: 1.37679e-01
I0216 07:58:38.150808 22839682574144 run_lib.py:133] step: 105850, training_loss: 1.15703e-01
I0216 07:58:55.692838 22839682574144 run_lib.py:133] step: 105900, training_loss: 1.12685e-01
I0216 07:58:55.868396 22839682574144 run_lib.py:146] step: 105900, eval_loss: 1.32923e-01
I0216 07:59:13.595850 22839682574144 run_lib.py:133] step: 105950, training_loss: 1.17043e-01
I0216 07:59:31.220330 22839682574144 run_lib.py:133] step: 106000, training_loss: 1.12921e-01
I0216 07:59:31.380698 22839682574144 run_lib.py:146] step: 106000, eval_loss: 1.32954e-01
I0216 07:59:48.900970 22839682574144 run_lib.py:133] step: 106050, training_loss: 1.18713e-01
I0216 08:00:06.447308 22839682574144 run_lib.py:133] step: 106100, training_loss: 1.12655e-01
I0216 08:00:06.604741 22839682574144 run_lib.py:146] step: 106100, eval_loss: 1.33611e-01
I0216 08:00:24.271344 22839682574144 run_lib.py:133] step: 106150, training_loss: 1.18098e-01
I0216 08:00:41.841144 22839682574144 run_lib.py:133] step: 106200, training_loss: 1.11515e-01
I0216 08:00:41.998877 22839682574144 run_lib.py:146] step: 106200, eval_loss: 1.31108e-01
I0216 08:00:59.555242 22839682574144 run_lib.py:133] step: 106250, training_loss: 1.18084e-01
I0216 08:01:17.259597 22839682574144 run_lib.py:133] step: 106300, training_loss: 1.17168e-01
I0216 08:01:17.416155 22839682574144 run_lib.py:146] step: 106300, eval_loss: 1.34014e-01
I0216 08:01:34.888769 22839682574144 run_lib.py:133] step: 106350, training_loss: 1.21139e-01
I0216 08:01:52.567325 22839682574144 run_lib.py:133] step: 106400, training_loss: 1.13606e-01
I0216 08:01:52.740069 22839682574144 run_lib.py:146] step: 106400, eval_loss: 1.30233e-01
I0216 08:02:10.310659 22839682574144 run_lib.py:133] step: 106450, training_loss: 1.12521e-01
I0216 08:02:27.820720 22839682574144 run_lib.py:133] step: 106500, training_loss: 1.13077e-01
I0216 08:02:27.977291 22839682574144 run_lib.py:146] step: 106500, eval_loss: 1.31856e-01
I0216 08:02:45.700142 22839682574144 run_lib.py:133] step: 106550, training_loss: 1.10931e-01
I0216 08:03:03.218576 22839682574144 run_lib.py:133] step: 106600, training_loss: 1.13655e-01
I0216 08:03:03.373262 22839682574144 run_lib.py:146] step: 106600, eval_loss: 1.32293e-01
I0216 08:03:20.867438 22839682574144 run_lib.py:133] step: 106650, training_loss: 1.09971e-01
I0216 08:03:38.596724 22839682574144 run_lib.py:133] step: 106700, training_loss: 1.16318e-01
I0216 08:03:38.752272 22839682574144 run_lib.py:146] step: 106700, eval_loss: 1.34581e-01
I0216 08:03:56.274436 22839682574144 run_lib.py:133] step: 106750, training_loss: 1.15816e-01
I0216 08:04:13.820068 22839682574144 run_lib.py:133] step: 106800, training_loss: 1.12085e-01
I0216 08:04:13.978145 22839682574144 run_lib.py:146] step: 106800, eval_loss: 1.27447e-01
I0216 08:04:31.604268 22839682574144 run_lib.py:133] step: 106850, training_loss: 1.15309e-01
I0216 08:04:49.131664 22839682574144 run_lib.py:133] step: 106900, training_loss: 1.12208e-01
I0216 08:04:49.287373 22839682574144 run_lib.py:146] step: 106900, eval_loss: 1.29655e-01
I0216 08:05:06.807260 22839682574144 run_lib.py:133] step: 106950, training_loss: 1.16223e-01
I0216 08:05:24.377545 22839682574144 run_lib.py:133] step: 107000, training_loss: 1.14851e-01
I0216 08:05:24.546736 22839682574144 run_lib.py:146] step: 107000, eval_loss: 1.27245e-01
I0216 08:05:42.309210 22839682574144 run_lib.py:133] step: 107050, training_loss: 1.15241e-01
I0216 08:05:59.921637 22839682574144 run_lib.py:133] step: 107100, training_loss: 1.12630e-01
I0216 08:06:00.079069 22839682574144 run_lib.py:146] step: 107100, eval_loss: 1.34261e-01
I0216 08:06:17.595070 22839682574144 run_lib.py:133] step: 107150, training_loss: 1.17763e-01
I0216 08:06:35.110148 22839682574144 run_lib.py:133] step: 107200, training_loss: 1.14530e-01
I0216 08:06:35.263036 22839682574144 run_lib.py:146] step: 107200, eval_loss: 1.30823e-01
I0216 08:06:52.974631 22839682574144 run_lib.py:133] step: 107250, training_loss: 1.19116e-01
I0216 08:07:10.503631 22839682574144 run_lib.py:133] step: 107300, training_loss: 1.14169e-01
I0216 08:07:10.672346 22839682574144 run_lib.py:146] step: 107300, eval_loss: 1.33805e-01
I0216 08:07:28.197514 22839682574144 run_lib.py:133] step: 107350, training_loss: 1.12266e-01
I0216 08:07:45.965244 22839682574144 run_lib.py:133] step: 107400, training_loss: 1.15617e-01
I0216 08:07:46.125508 22839682574144 run_lib.py:146] step: 107400, eval_loss: 1.31638e-01
I0216 08:08:03.628571 22839682574144 run_lib.py:133] step: 107450, training_loss: 1.14794e-01
I0216 08:08:21.281550 22839682574144 run_lib.py:133] step: 107500, training_loss: 1.12256e-01
I0216 08:08:21.438267 22839682574144 run_lib.py:146] step: 107500, eval_loss: 1.29276e-01
I0216 08:08:38.936111 22839682574144 run_lib.py:133] step: 107550, training_loss: 1.15509e-01
I0216 08:08:56.509063 22839682574144 run_lib.py:133] step: 107600, training_loss: 1.19329e-01
I0216 08:08:56.666753 22839682574144 run_lib.py:146] step: 107600, eval_loss: 1.35266e-01
I0216 08:09:14.390635 22839682574144 run_lib.py:133] step: 107650, training_loss: 1.14634e-01
I0216 08:09:31.906753 22839682574144 run_lib.py:133] step: 107700, training_loss: 1.14144e-01
I0216 08:09:32.061067 22839682574144 run_lib.py:146] step: 107700, eval_loss: 1.31930e-01
I0216 08:09:49.592839 22839682574144 run_lib.py:133] step: 107750, training_loss: 1.11417e-01
I0216 08:10:07.261226 22839682574144 run_lib.py:133] step: 107800, training_loss: 1.14961e-01
I0216 08:10:07.432201 22839682574144 run_lib.py:146] step: 107800, eval_loss: 1.31418e-01
I0216 08:10:24.996190 22839682574144 run_lib.py:133] step: 107850, training_loss: 1.11825e-01
I0216 08:10:42.509538 22839682574144 run_lib.py:133] step: 107900, training_loss: 1.14586e-01
I0216 08:10:42.667416 22839682574144 run_lib.py:146] step: 107900, eval_loss: 1.30975e-01
I0216 08:11:00.314861 22839682574144 run_lib.py:133] step: 107950, training_loss: 1.15203e-01
I0216 08:11:17.812907 22839682574144 run_lib.py:133] step: 108000, training_loss: 1.11300e-01
I0216 08:11:17.971136 22839682574144 run_lib.py:146] step: 108000, eval_loss: 1.34095e-01
I0216 08:11:35.489647 22839682574144 run_lib.py:133] step: 108050, training_loss: 1.15525e-01
I0216 08:11:53.022200 22839682574144 run_lib.py:133] step: 108100, training_loss: 1.11123e-01
I0216 08:11:53.184533 22839682574144 run_lib.py:146] step: 108100, eval_loss: 1.30134e-01
I0216 08:12:10.944452 22839682574144 run_lib.py:133] step: 108150, training_loss: 1.11308e-01
I0216 08:12:28.601488 22839682574144 run_lib.py:133] step: 108200, training_loss: 1.12107e-01
I0216 08:12:28.758169 22839682574144 run_lib.py:146] step: 108200, eval_loss: 1.30594e-01
I0216 08:12:46.278444 22839682574144 run_lib.py:133] step: 108250, training_loss: 1.10834e-01
I0216 08:13:03.811086 22839682574144 run_lib.py:133] step: 108300, training_loss: 1.16728e-01
I0216 08:13:03.977833 22839682574144 run_lib.py:146] step: 108300, eval_loss: 1.31903e-01
I0216 08:13:21.675165 22839682574144 run_lib.py:133] step: 108350, training_loss: 1.09351e-01
I0216 08:13:39.245835 22839682574144 run_lib.py:133] step: 108400, training_loss: 1.12870e-01
I0216 08:13:39.412163 22839682574144 run_lib.py:146] step: 108400, eval_loss: 1.29617e-01
I0216 08:13:56.969755 22839682574144 run_lib.py:133] step: 108450, training_loss: 1.16348e-01
I0216 08:14:14.717961 22839682574144 run_lib.py:133] step: 108500, training_loss: 1.12013e-01
I0216 08:14:14.875223 22839682574144 run_lib.py:146] step: 108500, eval_loss: 1.30839e-01
I0216 08:14:32.401161 22839682574144 run_lib.py:133] step: 108550, training_loss: 1.10655e-01
I0216 08:14:50.074824 22839682574144 run_lib.py:133] step: 108600, training_loss: 1.13034e-01
I0216 08:14:50.231806 22839682574144 run_lib.py:146] step: 108600, eval_loss: 1.27729e-01
I0216 08:15:07.595519 22839682574144 run_lib.py:133] step: 108650, training_loss: 1.15089e-01
I0216 08:15:24.869465 22839682574144 run_lib.py:133] step: 108700, training_loss: 1.10711e-01
I0216 08:15:25.022656 22839682574144 run_lib.py:146] step: 108700, eval_loss: 1.32123e-01
I0216 08:15:42.509338 22839682574144 run_lib.py:133] step: 108750, training_loss: 1.16609e-01
I0216 08:15:59.804146 22839682574144 run_lib.py:133] step: 108800, training_loss: 1.13138e-01
I0216 08:15:59.963013 22839682574144 run_lib.py:146] step: 108800, eval_loss: 1.32002e-01
I0216 08:16:17.390708 22839682574144 run_lib.py:133] step: 108850, training_loss: 1.12439e-01
I0216 08:16:35.016919 22839682574144 run_lib.py:133] step: 108900, training_loss: 1.14754e-01
I0216 08:16:35.188064 22839682574144 run_lib.py:146] step: 108900, eval_loss: 1.27762e-01
I0216 08:16:52.748907 22839682574144 run_lib.py:133] step: 108950, training_loss: 1.10813e-01
I0216 08:17:10.274785 22839682574144 run_lib.py:133] step: 109000, training_loss: 1.09964e-01
I0216 08:17:10.436304 22839682574144 run_lib.py:146] step: 109000, eval_loss: 1.30615e-01
I0216 08:17:28.094979 22839682574144 run_lib.py:133] step: 109050, training_loss: 1.16777e-01
I0216 08:17:45.582071 22839682574144 run_lib.py:133] step: 109100, training_loss: 1.14380e-01
I0216 08:17:45.734987 22839682574144 run_lib.py:146] step: 109100, eval_loss: 1.29092e-01
I0216 08:18:03.229663 22839682574144 run_lib.py:133] step: 109150, training_loss: 1.16962e-01
I0216 08:18:20.748588 22839682574144 run_lib.py:133] step: 109200, training_loss: 1.15863e-01
I0216 08:18:20.916303 22839682574144 run_lib.py:146] step: 109200, eval_loss: 1.29566e-01
I0216 08:18:38.610128 22839682574144 run_lib.py:133] step: 109250, training_loss: 1.17677e-01
I0216 08:18:56.242385 22839682574144 run_lib.py:133] step: 109300, training_loss: 1.11690e-01
I0216 08:18:56.401168 22839682574144 run_lib.py:146] step: 109300, eval_loss: 1.31221e-01
I0216 08:19:13.887487 22839682574144 run_lib.py:133] step: 109350, training_loss: 1.13499e-01
I0216 08:19:31.411258 22839682574144 run_lib.py:133] step: 109400, training_loss: 1.09765e-01
I0216 08:19:31.569085 22839682574144 run_lib.py:146] step: 109400, eval_loss: 1.32788e-01
I0216 08:19:49.232378 22839682574144 run_lib.py:133] step: 109450, training_loss: 1.14692e-01
I0216 08:20:06.758332 22839682574144 run_lib.py:133] step: 109500, training_loss: 1.13022e-01
I0216 08:20:06.914816 22839682574144 run_lib.py:146] step: 109500, eval_loss: 1.38614e-01
I0216 08:20:24.485646 22839682574144 run_lib.py:133] step: 109550, training_loss: 1.09732e-01
I0216 08:20:42.220335 22839682574144 run_lib.py:133] step: 109600, training_loss: 1.10701e-01
I0216 08:20:42.375071 22839682574144 run_lib.py:146] step: 109600, eval_loss: 1.31027e-01
I0216 08:20:59.872494 22839682574144 run_lib.py:133] step: 109650, training_loss: 1.13105e-01
I0216 08:21:17.547089 22839682574144 run_lib.py:133] step: 109700, training_loss: 1.09749e-01
I0216 08:21:17.709276 22839682574144 run_lib.py:146] step: 109700, eval_loss: 1.35444e-01
I0216 08:21:35.230588 22839682574144 run_lib.py:133] step: 109750, training_loss: 1.10942e-01
I0216 08:21:52.765988 22839682574144 run_lib.py:133] step: 109800, training_loss: 1.14449e-01
I0216 08:21:52.927300 22839682574144 run_lib.py:146] step: 109800, eval_loss: 1.34138e-01
I0216 08:22:10.682461 22839682574144 run_lib.py:133] step: 109850, training_loss: 1.12204e-01
I0216 08:22:28.186563 22839682574144 run_lib.py:133] step: 109900, training_loss: 1.10628e-01
I0216 08:22:28.344197 22839682574144 run_lib.py:146] step: 109900, eval_loss: 1.32977e-01
I0216 08:22:45.866148 22839682574144 run_lib.py:133] step: 109950, training_loss: 1.15154e-01
I0216 08:23:03.516566 22839682574144 run_lib.py:133] step: 110000, training_loss: 1.10362e-01
I0216 08:23:04.278540 22839682574144 run_lib.py:146] step: 110000, eval_loss: 1.33248e-01
I0216 08:23:24.542555 22839682574144 run_lib.py:133] step: 110050, training_loss: 1.15673e-01
I0216 08:23:42.051479 22839682574144 run_lib.py:133] step: 110100, training_loss: 1.14775e-01
I0216 08:23:42.206135 22839682574144 run_lib.py:146] step: 110100, eval_loss: 1.36650e-01
I0216 08:23:59.731462 22839682574144 run_lib.py:133] step: 110150, training_loss: 1.18258e-01
I0216 08:24:17.475862 22839682574144 run_lib.py:133] step: 110200, training_loss: 1.17527e-01
I0216 08:24:17.633298 22839682574144 run_lib.py:146] step: 110200, eval_loss: 1.34002e-01
I0216 08:24:35.173727 22839682574144 run_lib.py:133] step: 110250, training_loss: 1.16501e-01
I0216 08:24:52.664698 22839682574144 run_lib.py:133] step: 110300, training_loss: 1.14579e-01
I0216 08:24:52.824985 22839682574144 run_lib.py:146] step: 110300, eval_loss: 1.31226e-01
I0216 08:25:10.386102 22839682574144 run_lib.py:133] step: 110350, training_loss: 1.14195e-01
I0216 08:25:28.159132 22839682574144 run_lib.py:133] step: 110400, training_loss: 1.12769e-01
I0216 08:25:28.316367 22839682574144 run_lib.py:146] step: 110400, eval_loss: 1.29416e-01
I0216 08:25:45.947571 22839682574144 run_lib.py:133] step: 110450, training_loss: 1.07970e-01
I0216 08:26:03.485129 22839682574144 run_lib.py:133] step: 110500, training_loss: 1.17155e-01
I0216 08:26:03.676146 22839682574144 run_lib.py:146] step: 110500, eval_loss: 1.33508e-01
I0216 08:26:21.185735 22839682574144 run_lib.py:133] step: 110550, training_loss: 1.15707e-01
I0216 08:26:38.731128 22839682574144 run_lib.py:133] step: 110600, training_loss: 1.10996e-01
I0216 08:26:38.892216 22839682574144 run_lib.py:146] step: 110600, eval_loss: 1.34028e-01
I0216 08:26:56.626742 22839682574144 run_lib.py:133] step: 110650, training_loss: 1.14363e-01
I0216 08:27:14.169717 22839682574144 run_lib.py:133] step: 110700, training_loss: 1.16654e-01
I0216 08:27:14.326837 22839682574144 run_lib.py:146] step: 110700, eval_loss: 1.34276e-01
I0216 08:27:32.038340 22839682574144 run_lib.py:133] step: 110750, training_loss: 1.16857e-01
I0216 08:27:49.543477 22839682574144 run_lib.py:133] step: 110800, training_loss: 1.15404e-01
I0216 08:27:49.701416 22839682574144 run_lib.py:146] step: 110800, eval_loss: 1.30362e-01
I0216 08:28:07.402436 22839682574144 run_lib.py:133] step: 110850, training_loss: 1.14720e-01
I0216 08:28:24.971110 22839682574144 run_lib.py:133] step: 110900, training_loss: 1.14631e-01
I0216 08:28:25.131916 22839682574144 run_lib.py:146] step: 110900, eval_loss: 1.28641e-01
I0216 08:28:42.648175 22839682574144 run_lib.py:133] step: 110950, training_loss: 1.13930e-01
I0216 08:29:00.416529 22839682574144 run_lib.py:133] step: 111000, training_loss: 1.11343e-01
I0216 08:29:00.573003 22839682574144 run_lib.py:146] step: 111000, eval_loss: 1.33502e-01
I0216 08:29:18.102012 22839682574144 run_lib.py:133] step: 111050, training_loss: 1.12963e-01
I0216 08:29:35.812789 22839682574144 run_lib.py:133] step: 111100, training_loss: 1.14262e-01
I0216 08:29:35.968017 22839682574144 run_lib.py:146] step: 111100, eval_loss: 1.31778e-01
I0216 08:29:53.464415 22839682574144 run_lib.py:133] step: 111150, training_loss: 1.12652e-01
I0216 08:30:11.029638 22839682574144 run_lib.py:133] step: 111200, training_loss: 1.14349e-01
I0216 08:30:11.198054 22839682574144 run_lib.py:146] step: 111200, eval_loss: 1.27499e-01
I0216 08:30:28.753537 22839682574144 run_lib.py:133] step: 111250, training_loss: 1.12905e-01
I0216 08:30:46.503427 22839682574144 run_lib.py:133] step: 111300, training_loss: 1.09563e-01
I0216 08:30:46.661085 22839682574144 run_lib.py:146] step: 111300, eval_loss: 1.30981e-01
I0216 08:31:04.228486 22839682574144 run_lib.py:133] step: 111350, training_loss: 1.10158e-01
I0216 08:31:21.799248 22839682574144 run_lib.py:133] step: 111400, training_loss: 1.13897e-01
I0216 08:31:21.964999 22839682574144 run_lib.py:146] step: 111400, eval_loss: 1.35285e-01
I0216 08:31:39.687823 22839682574144 run_lib.py:133] step: 111450, training_loss: 1.19771e-01
I0216 08:31:57.242238 22839682574144 run_lib.py:133] step: 111500, training_loss: 1.15737e-01
I0216 08:31:57.397293 22839682574144 run_lib.py:146] step: 111500, eval_loss: 1.33605e-01
I0216 08:32:15.073516 22839682574144 run_lib.py:133] step: 111550, training_loss: 1.12774e-01
I0216 08:32:32.561314 22839682574144 run_lib.py:133] step: 111600, training_loss: 1.14223e-01
I0216 08:32:32.719656 22839682574144 run_lib.py:146] step: 111600, eval_loss: 1.36087e-01
I0216 08:32:50.218666 22839682574144 run_lib.py:133] step: 111650, training_loss: 1.08824e-01
I0216 08:33:07.713158 22839682574144 run_lib.py:133] step: 111700, training_loss: 1.12276e-01
I0216 08:33:07.908972 22839682574144 run_lib.py:146] step: 111700, eval_loss: 1.31465e-01
I0216 08:33:25.624296 22839682574144 run_lib.py:133] step: 111750, training_loss: 1.16064e-01
I0216 08:33:43.279217 22839682574144 run_lib.py:133] step: 111800, training_loss: 1.13235e-01
I0216 08:33:43.437345 22839682574144 run_lib.py:146] step: 111800, eval_loss: 1.31069e-01
I0216 08:34:00.956591 22839682574144 run_lib.py:133] step: 111850, training_loss: 1.11776e-01
I0216 08:34:18.446394 22839682574144 run_lib.py:133] step: 111900, training_loss: 1.15609e-01
I0216 08:34:18.605008 22839682574144 run_lib.py:146] step: 111900, eval_loss: 1.34659e-01
I0216 08:34:36.287396 22839682574144 run_lib.py:133] step: 111950, training_loss: 1.13990e-01
I0216 08:34:53.818797 22839682574144 run_lib.py:133] step: 112000, training_loss: 1.14593e-01
I0216 08:34:53.974282 22839682574144 run_lib.py:146] step: 112000, eval_loss: 1.30482e-01
I0216 08:35:11.508346 22839682574144 run_lib.py:133] step: 112050, training_loss: 1.12386e-01
I0216 08:35:29.218452 22839682574144 run_lib.py:133] step: 112100, training_loss: 1.16096e-01
I0216 08:35:29.376018 22839682574144 run_lib.py:146] step: 112100, eval_loss: 1.30947e-01
I0216 08:35:46.910349 22839682574144 run_lib.py:133] step: 112150, training_loss: 1.13826e-01
I0216 08:36:04.556929 22839682574144 run_lib.py:133] step: 112200, training_loss: 1.10350e-01
I0216 08:36:04.716313 22839682574144 run_lib.py:146] step: 112200, eval_loss: 1.39184e-01
I0216 08:36:22.240080 22839682574144 run_lib.py:133] step: 112250, training_loss: 1.11506e-01
I0216 08:36:39.817894 22839682574144 run_lib.py:133] step: 112300, training_loss: 1.10650e-01
I0216 08:36:39.984518 22839682574144 run_lib.py:146] step: 112300, eval_loss: 1.35739e-01
I0216 08:36:57.666983 22839682574144 run_lib.py:133] step: 112350, training_loss: 1.10417e-01
I0216 08:37:15.181113 22839682574144 run_lib.py:133] step: 112400, training_loss: 1.09728e-01
I0216 08:37:15.343957 22839682574144 run_lib.py:146] step: 112400, eval_loss: 1.31606e-01
I0216 08:37:32.867541 22839682574144 run_lib.py:133] step: 112450, training_loss: 1.16248e-01
I0216 08:37:50.379362 22839682574144 run_lib.py:133] step: 112500, training_loss: 1.12112e-01
I0216 08:37:50.534125 22839682574144 run_lib.py:146] step: 112500, eval_loss: 1.27781e-01
I0216 08:38:08.246704 22839682574144 run_lib.py:133] step: 112550, training_loss: 1.17922e-01
I0216 08:38:25.764937 22839682574144 run_lib.py:133] step: 112600, training_loss: 1.12744e-01
I0216 08:38:25.933991 22839682574144 run_lib.py:146] step: 112600, eval_loss: 1.28088e-01
I0216 08:38:43.623590 22839682574144 run_lib.py:133] step: 112650, training_loss: 1.12606e-01
I0216 08:39:01.159223 22839682574144 run_lib.py:133] step: 112700, training_loss: 1.14033e-01
I0216 08:39:01.317353 22839682574144 run_lib.py:146] step: 112700, eval_loss: 1.29358e-01
I0216 08:39:18.846905 22839682574144 run_lib.py:133] step: 112750, training_loss: 1.10203e-01
I0216 08:39:36.338945 22839682574144 run_lib.py:133] step: 112800, training_loss: 1.15908e-01
I0216 08:39:36.503048 22839682574144 run_lib.py:146] step: 112800, eval_loss: 1.27452e-01
I0216 08:39:54.220661 22839682574144 run_lib.py:133] step: 112850, training_loss: 1.15230e-01
I0216 08:40:11.871058 22839682574144 run_lib.py:133] step: 112900, training_loss: 1.14584e-01
I0216 08:40:12.032794 22839682574144 run_lib.py:146] step: 112900, eval_loss: 1.25454e-01
I0216 08:40:29.533428 22839682574144 run_lib.py:133] step: 112950, training_loss: 1.15912e-01
I0216 08:40:47.038392 22839682574144 run_lib.py:133] step: 113000, training_loss: 1.10201e-01
I0216 08:40:47.194243 22839682574144 run_lib.py:146] step: 113000, eval_loss: 1.34189e-01
I0216 08:41:04.881921 22839682574144 run_lib.py:133] step: 113050, training_loss: 1.16070e-01
I0216 08:41:22.384004 22839682574144 run_lib.py:133] step: 113100, training_loss: 1.12468e-01
I0216 08:41:22.559043 22839682574144 run_lib.py:146] step: 113100, eval_loss: 1.33519e-01
I0216 08:41:40.088873 22839682574144 run_lib.py:133] step: 113150, training_loss: 1.13128e-01
I0216 08:41:57.798218 22839682574144 run_lib.py:133] step: 113200, training_loss: 1.13171e-01
I0216 08:41:57.956378 22839682574144 run_lib.py:146] step: 113200, eval_loss: 1.32294e-01
I0216 08:42:15.481871 22839682574144 run_lib.py:133] step: 113250, training_loss: 1.12532e-01
I0216 08:42:33.147531 22839682574144 run_lib.py:133] step: 113300, training_loss: 1.17322e-01
I0216 08:42:33.320608 22839682574144 run_lib.py:146] step: 113300, eval_loss: 1.34907e-01
I0216 08:42:50.851377 22839682574144 run_lib.py:133] step: 113350, training_loss: 1.13966e-01
I0216 08:43:08.393591 22839682574144 run_lib.py:133] step: 113400, training_loss: 1.14031e-01
I0216 08:43:08.546868 22839682574144 run_lib.py:146] step: 113400, eval_loss: 1.31036e-01
I0216 08:43:26.321867 22839682574144 run_lib.py:133] step: 113450, training_loss: 1.12180e-01
I0216 08:43:43.862370 22839682574144 run_lib.py:133] step: 113500, training_loss: 1.13290e-01
I0216 08:43:44.021134 22839682574144 run_lib.py:146] step: 113500, eval_loss: 1.28571e-01
I0216 08:44:01.492459 22839682574144 run_lib.py:133] step: 113550, training_loss: 1.15268e-01
I0216 08:44:19.170690 22839682574144 run_lib.py:133] step: 113600, training_loss: 1.13496e-01
I0216 08:44:19.338207 22839682574144 run_lib.py:146] step: 113600, eval_loss: 1.32353e-01
I0216 08:44:36.862927 22839682574144 run_lib.py:133] step: 113650, training_loss: 1.12072e-01
I0216 08:44:54.414654 22839682574144 run_lib.py:133] step: 113700, training_loss: 1.12856e-01
I0216 08:44:54.572355 22839682574144 run_lib.py:146] step: 113700, eval_loss: 1.29763e-01
I0216 08:45:12.238991 22839682574144 run_lib.py:133] step: 113750, training_loss: 1.16966e-01
I0216 08:45:29.777786 22839682574144 run_lib.py:133] step: 113800, training_loss: 1.20308e-01
I0216 08:45:29.934976 22839682574144 run_lib.py:146] step: 113800, eval_loss: 1.28936e-01
I0216 08:45:47.419675 22839682574144 run_lib.py:133] step: 113850, training_loss: 1.14564e-01
I0216 08:46:04.945329 22839682574144 run_lib.py:133] step: 113900, training_loss: 1.12841e-01
I0216 08:46:05.099403 22839682574144 run_lib.py:146] step: 113900, eval_loss: 1.31538e-01
I0216 08:46:22.827671 22839682574144 run_lib.py:133] step: 113950, training_loss: 1.13845e-01
I0216 08:46:40.467820 22839682574144 run_lib.py:133] step: 114000, training_loss: 1.14073e-01
I0216 08:46:40.632249 22839682574144 run_lib.py:146] step: 114000, eval_loss: 1.34422e-01
I0216 08:46:58.169182 22839682574144 run_lib.py:133] step: 114050, training_loss: 1.14915e-01
I0216 08:47:15.698012 22839682574144 run_lib.py:133] step: 114100, training_loss: 1.13950e-01
I0216 08:47:15.862288 22839682574144 run_lib.py:146] step: 114100, eval_loss: 1.32516e-01
I0216 08:47:33.538773 22839682574144 run_lib.py:133] step: 114150, training_loss: 1.15158e-01
I0216 08:47:51.085737 22839682574144 run_lib.py:133] step: 114200, training_loss: 1.08022e-01
I0216 08:47:51.251801 22839682574144 run_lib.py:146] step: 114200, eval_loss: 1.31369e-01
I0216 08:48:08.810695 22839682574144 run_lib.py:133] step: 114250, training_loss: 1.14567e-01
I0216 08:48:26.538043 22839682574144 run_lib.py:133] step: 114300, training_loss: 1.11429e-01
I0216 08:48:26.696350 22839682574144 run_lib.py:146] step: 114300, eval_loss: 1.30223e-01
I0216 08:48:44.220449 22839682574144 run_lib.py:133] step: 114350, training_loss: 1.13195e-01
I0216 08:49:01.896649 22839682574144 run_lib.py:133] step: 114400, training_loss: 1.14119e-01
I0216 08:49:02.050147 22839682574144 run_lib.py:146] step: 114400, eval_loss: 1.33129e-01
I0216 08:49:19.596010 22839682574144 run_lib.py:133] step: 114450, training_loss: 1.08792e-01
I0216 08:49:37.119326 22839682574144 run_lib.py:133] step: 114500, training_loss: 1.14888e-01
I0216 08:49:37.289208 22839682574144 run_lib.py:146] step: 114500, eval_loss: 1.31742e-01
I0216 08:49:54.993689 22839682574144 run_lib.py:133] step: 114550, training_loss: 1.13819e-01
I0216 08:50:12.547686 22839682574144 run_lib.py:133] step: 114600, training_loss: 1.15017e-01
I0216 08:50:12.705043 22839682574144 run_lib.py:146] step: 114600, eval_loss: 1.29464e-01
I0216 08:50:30.224139 22839682574144 run_lib.py:133] step: 114650, training_loss: 1.14913e-01
I0216 08:50:47.931015 22839682574144 run_lib.py:133] step: 114700, training_loss: 1.10099e-01
I0216 08:50:48.088837 22839682574144 run_lib.py:146] step: 114700, eval_loss: 1.30275e-01
I0216 08:51:05.554594 22839682574144 run_lib.py:133] step: 114750, training_loss: 1.13805e-01
I0216 08:51:23.128202 22839682574144 run_lib.py:133] step: 114800, training_loss: 1.14545e-01
I0216 08:51:23.284869 22839682574144 run_lib.py:146] step: 114800, eval_loss: 1.32921e-01
I0216 08:51:40.950161 22839682574144 run_lib.py:133] step: 114850, training_loss: 1.12254e-01
I0216 08:51:58.437088 22839682574144 run_lib.py:133] step: 114900, training_loss: 1.13568e-01
I0216 08:51:58.613095 22839682574144 run_lib.py:146] step: 114900, eval_loss: 1.35560e-01
I0216 08:52:16.126500 22839682574144 run_lib.py:133] step: 114950, training_loss: 1.16455e-01
I0216 08:52:33.676177 22839682574144 run_lib.py:133] step: 115000, training_loss: 1.13212e-01
I0216 08:52:33.835544 22839682574144 run_lib.py:146] step: 115000, eval_loss: 1.31073e-01
I0216 08:52:51.502457 22839682574144 run_lib.py:133] step: 115050, training_loss: 1.11429e-01
I0216 08:53:09.163741 22839682574144 run_lib.py:133] step: 115100, training_loss: 1.13127e-01
I0216 08:53:09.321228 22839682574144 run_lib.py:146] step: 115100, eval_loss: 1.31271e-01
I0216 08:53:26.847764 22839682574144 run_lib.py:133] step: 115150, training_loss: 1.13174e-01
I0216 08:53:44.343204 22839682574144 run_lib.py:133] step: 115200, training_loss: 1.13372e-01
I0216 08:53:44.501236 22839682574144 run_lib.py:146] step: 115200, eval_loss: 1.33121e-01
I0216 08:54:02.175876 22839682574144 run_lib.py:133] step: 115250, training_loss: 1.15596e-01
I0216 08:54:19.698755 22839682574144 run_lib.py:133] step: 115300, training_loss: 1.13487e-01
I0216 08:54:19.852765 22839682574144 run_lib.py:146] step: 115300, eval_loss: 1.31614e-01
I0216 08:54:37.366389 22839682574144 run_lib.py:133] step: 115350, training_loss: 1.11563e-01
I0216 08:54:55.109026 22839682574144 run_lib.py:133] step: 115400, training_loss: 1.10506e-01
I0216 08:54:55.275271 22839682574144 run_lib.py:146] step: 115400, eval_loss: 1.28298e-01
I0216 08:55:12.776025 22839682574144 run_lib.py:133] step: 115450, training_loss: 1.12156e-01
I0216 08:55:30.489687 22839682574144 run_lib.py:133] step: 115500, training_loss: 1.11172e-01
I0216 08:55:30.650290 22839682574144 run_lib.py:146] step: 115500, eval_loss: 1.28713e-01
I0216 08:55:48.184946 22839682574144 run_lib.py:133] step: 115550, training_loss: 1.10650e-01
I0216 08:56:05.667836 22839682574144 run_lib.py:133] step: 115600, training_loss: 1.09803e-01
I0216 08:56:05.836057 22839682574144 run_lib.py:146] step: 115600, eval_loss: 1.28905e-01
I0216 08:56:23.524796 22839682574144 run_lib.py:133] step: 115650, training_loss: 1.08078e-01
I0216 08:56:41.026589 22839682574144 run_lib.py:133] step: 115700, training_loss: 1.12864e-01
I0216 08:56:41.184391 22839682574144 run_lib.py:146] step: 115700, eval_loss: 1.33499e-01
I0216 08:56:58.703114 22839682574144 run_lib.py:133] step: 115750, training_loss: 1.13927e-01
I0216 08:57:16.460376 22839682574144 run_lib.py:133] step: 115800, training_loss: 1.12535e-01
I0216 08:57:16.615034 22839682574144 run_lib.py:146] step: 115800, eval_loss: 1.34281e-01
I0216 08:57:34.087843 22839682574144 run_lib.py:133] step: 115850, training_loss: 1.08511e-01
I0216 08:57:51.600255 22839682574144 run_lib.py:133] step: 115900, training_loss: 1.17048e-01
I0216 08:57:51.768254 22839682574144 run_lib.py:146] step: 115900, eval_loss: 1.30186e-01
I0216 08:58:09.418493 22839682574144 run_lib.py:133] step: 115950, training_loss: 1.10390e-01
I0216 08:58:26.948738 22839682574144 run_lib.py:133] step: 116000, training_loss: 1.14657e-01
I0216 08:58:27.108155 22839682574144 run_lib.py:146] step: 116000, eval_loss: 1.35657e-01
I0216 08:58:44.603384 22839682574144 run_lib.py:133] step: 116050, training_loss: 1.15679e-01
I0216 08:59:02.078218 22839682574144 run_lib.py:133] step: 116100, training_loss: 1.11788e-01
I0216 08:59:02.234804 22839682574144 run_lib.py:146] step: 116100, eval_loss: 1.29266e-01
I0216 08:59:19.906625 22839682574144 run_lib.py:133] step: 116150, training_loss: 1.10750e-01
I0216 08:59:37.533865 22839682574144 run_lib.py:133] step: 116200, training_loss: 1.12951e-01
I0216 08:59:37.692346 22839682574144 run_lib.py:146] step: 116200, eval_loss: 1.26539e-01
I0216 08:59:55.221422 22839682574144 run_lib.py:133] step: 116250, training_loss: 1.17235e-01
I0216 09:00:12.678798 22839682574144 run_lib.py:133] step: 116300, training_loss: 1.15991e-01
I0216 09:00:12.833277 22839682574144 run_lib.py:146] step: 116300, eval_loss: 1.28551e-01
I0216 09:00:30.568487 22839682574144 run_lib.py:133] step: 116350, training_loss: 1.09226e-01
I0216 09:00:48.099524 22839682574144 run_lib.py:133] step: 116400, training_loss: 1.16079e-01
I0216 09:00:48.271374 22839682574144 run_lib.py:146] step: 116400, eval_loss: 1.36983e-01
I0216 09:01:05.769987 22839682574144 run_lib.py:133] step: 116450, training_loss: 1.10870e-01
I0216 09:01:23.521717 22839682574144 run_lib.py:133] step: 116500, training_loss: 1.17228e-01
I0216 09:01:23.720105 22839682574144 run_lib.py:146] step: 116500, eval_loss: 1.29646e-01
I0216 09:01:41.225284 22839682574144 run_lib.py:133] step: 116550, training_loss: 1.10431e-01
I0216 09:01:58.962616 22839682574144 run_lib.py:133] step: 116600, training_loss: 1.13059e-01
I0216 09:01:59.120006 22839682574144 run_lib.py:146] step: 116600, eval_loss: 1.30549e-01
I0216 09:02:16.638049 22839682574144 run_lib.py:133] step: 116650, training_loss: 1.14428e-01
I0216 09:02:34.136976 22839682574144 run_lib.py:133] step: 116700, training_loss: 1.12991e-01
I0216 09:02:34.291059 22839682574144 run_lib.py:146] step: 116700, eval_loss: 1.31483e-01
I0216 09:02:51.983882 22839682574144 run_lib.py:133] step: 116750, training_loss: 1.14393e-01
I0216 09:03:09.543569 22839682574144 run_lib.py:133] step: 116800, training_loss: 1.10187e-01
I0216 09:03:09.712942 22839682574144 run_lib.py:146] step: 116800, eval_loss: 1.30917e-01
I0216 09:03:27.260714 22839682574144 run_lib.py:133] step: 116850, training_loss: 1.08867e-01
I0216 09:03:45.006526 22839682574144 run_lib.py:133] step: 116900, training_loss: 1.13121e-01
I0216 09:03:45.165498 22839682574144 run_lib.py:146] step: 116900, eval_loss: 1.29901e-01
I0216 09:04:02.712754 22839682574144 run_lib.py:133] step: 116950, training_loss: 1.12535e-01
I0216 09:04:20.211924 22839682574144 run_lib.py:133] step: 117000, training_loss: 1.11559e-01
I0216 09:04:20.377636 22839682574144 run_lib.py:146] step: 117000, eval_loss: 1.30252e-01
I0216 09:04:38.011895 22839682574144 run_lib.py:133] step: 117050, training_loss: 1.14239e-01
I0216 09:04:55.510397 22839682574144 run_lib.py:133] step: 117100, training_loss: 1.14536e-01
I0216 09:04:55.667837 22839682574144 run_lib.py:146] step: 117100, eval_loss: 1.34236e-01
I0216 09:05:13.193823 22839682574144 run_lib.py:133] step: 117150, training_loss: 1.11618e-01
I0216 09:05:30.714768 22839682574144 run_lib.py:133] step: 117200, training_loss: 1.12789e-01
I0216 09:05:30.868064 22839682574144 run_lib.py:146] step: 117200, eval_loss: 1.29867e-01
I0216 09:05:48.599027 22839682574144 run_lib.py:133] step: 117250, training_loss: 1.15434e-01
I0216 09:06:06.269842 22839682574144 run_lib.py:133] step: 117300, training_loss: 1.13663e-01
I0216 09:06:06.436302 22839682574144 run_lib.py:146] step: 117300, eval_loss: 1.29047e-01
I0216 09:06:23.997478 22839682574144 run_lib.py:133] step: 117350, training_loss: 1.13820e-01
I0216 09:06:41.494792 22839682574144 run_lib.py:133] step: 117400, training_loss: 1.14464e-01
I0216 09:06:41.654687 22839682574144 run_lib.py:146] step: 117400, eval_loss: 1.33844e-01
I0216 09:06:59.368202 22839682574144 run_lib.py:133] step: 117450, training_loss: 1.15053e-01
I0216 09:07:16.865558 22839682574144 run_lib.py:133] step: 117500, training_loss: 1.13833e-01
I0216 09:07:17.022164 22839682574144 run_lib.py:146] step: 117500, eval_loss: 1.35328e-01
I0216 09:07:34.546586 22839682574144 run_lib.py:133] step: 117550, training_loss: 1.13054e-01
I0216 09:07:52.242536 22839682574144 run_lib.py:133] step: 117600, training_loss: 1.10835e-01
I0216 09:07:52.401378 22839682574144 run_lib.py:146] step: 117600, eval_loss: 1.32750e-01
I0216 09:08:09.911022 22839682574144 run_lib.py:133] step: 117650, training_loss: 1.10627e-01
I0216 09:08:27.654735 22839682574144 run_lib.py:133] step: 117700, training_loss: 1.12874e-01
I0216 09:08:27.809024 22839682574144 run_lib.py:146] step: 117700, eval_loss: 1.34825e-01
I0216 09:08:45.307374 22839682574144 run_lib.py:133] step: 117750, training_loss: 1.12725e-01
I0216 09:09:02.858148 22839682574144 run_lib.py:133] step: 117800, training_loss: 1.13914e-01
I0216 09:09:03.028272 22839682574144 run_lib.py:146] step: 117800, eval_loss: 1.34143e-01
I0216 09:09:20.804981 22839682574144 run_lib.py:133] step: 117850, training_loss: 1.12468e-01
I0216 09:09:38.368309 22839682574144 run_lib.py:133] step: 117900, training_loss: 1.13566e-01
I0216 09:09:38.528483 22839682574144 run_lib.py:146] step: 117900, eval_loss: 1.31543e-01
I0216 09:09:56.021520 22839682574144 run_lib.py:133] step: 117950, training_loss: 1.12778e-01
I0216 09:10:13.749171 22839682574144 run_lib.py:133] step: 118000, training_loss: 1.11212e-01
I0216 09:10:13.907374 22839682574144 run_lib.py:146] step: 118000, eval_loss: 1.36340e-01
I0216 09:10:31.435449 22839682574144 run_lib.py:133] step: 118050, training_loss: 1.12603e-01
I0216 09:10:48.946113 22839682574144 run_lib.py:133] step: 118100, training_loss: 1.13285e-01
I0216 09:10:49.115394 22839682574144 run_lib.py:146] step: 118100, eval_loss: 1.32173e-01
I0216 09:11:06.783060 22839682574144 run_lib.py:133] step: 118150, training_loss: 1.15537e-01
I0216 09:11:24.284733 22839682574144 run_lib.py:133] step: 118200, training_loss: 1.13813e-01
I0216 09:11:24.439422 22839682574144 run_lib.py:146] step: 118200, eval_loss: 1.36019e-01
I0216 09:11:41.986607 22839682574144 run_lib.py:133] step: 118250, training_loss: 1.17225e-01
I0216 09:11:59.534627 22839682574144 run_lib.py:133] step: 118300, training_loss: 1.10131e-01
I0216 09:11:59.701348 22839682574144 run_lib.py:146] step: 118300, eval_loss: 1.32936e-01
I0216 09:12:17.439857 22839682574144 run_lib.py:133] step: 118350, training_loss: 1.16574e-01
I0216 09:12:35.046517 22839682574144 run_lib.py:133] step: 118400, training_loss: 1.14749e-01
I0216 09:12:35.215157 22839682574144 run_lib.py:146] step: 118400, eval_loss: 1.33726e-01
I0216 09:12:52.752935 22839682574144 run_lib.py:133] step: 118450, training_loss: 1.12765e-01
I0216 09:13:10.270299 22839682574144 run_lib.py:133] step: 118500, training_loss: 1.11350e-01
I0216 09:13:10.424382 22839682574144 run_lib.py:146] step: 118500, eval_loss: 1.33835e-01
I0216 09:13:28.150595 22839682574144 run_lib.py:133] step: 118550, training_loss: 1.17811e-01
I0216 09:13:45.672746 22839682574144 run_lib.py:133] step: 118600, training_loss: 1.14205e-01
I0216 09:13:45.826773 22839682574144 run_lib.py:146] step: 118600, eval_loss: 1.32790e-01
I0216 09:14:03.342214 22839682574144 run_lib.py:133] step: 118650, training_loss: 1.12728e-01
I0216 09:14:21.049494 22839682574144 run_lib.py:133] step: 118700, training_loss: 1.11834e-01
I0216 09:14:21.212231 22839682574144 run_lib.py:146] step: 118700, eval_loss: 1.34588e-01
I0216 09:14:38.762936 22839682574144 run_lib.py:133] step: 118750, training_loss: 1.18709e-01
I0216 09:14:56.490193 22839682574144 run_lib.py:133] step: 118800, training_loss: 1.13974e-01
I0216 09:14:56.649135 22839682574144 run_lib.py:146] step: 118800, eval_loss: 1.26187e-01
I0216 09:15:14.160813 22839682574144 run_lib.py:133] step: 118850, training_loss: 1.15199e-01
I0216 09:15:31.677490 22839682574144 run_lib.py:133] step: 118900, training_loss: 1.10009e-01
I0216 09:15:31.835102 22839682574144 run_lib.py:146] step: 118900, eval_loss: 1.32999e-01
I0216 09:15:49.552381 22839682574144 run_lib.py:133] step: 118950, training_loss: 1.11476e-01
I0216 09:16:07.113080 22839682574144 run_lib.py:133] step: 119000, training_loss: 1.14796e-01
I0216 09:16:07.271281 22839682574144 run_lib.py:146] step: 119000, eval_loss: 1.39483e-01
I0216 09:16:24.765567 22839682574144 run_lib.py:133] step: 119050, training_loss: 1.15759e-01
I0216 09:16:42.518324 22839682574144 run_lib.py:133] step: 119100, training_loss: 1.14480e-01
I0216 09:16:42.670180 22839682574144 run_lib.py:146] step: 119100, eval_loss: 1.28886e-01
I0216 09:17:00.174074 22839682574144 run_lib.py:133] step: 119150, training_loss: 1.13413e-01
I0216 09:17:17.721330 22839682574144 run_lib.py:133] step: 119200, training_loss: 1.14996e-01
I0216 09:17:17.880279 22839682574144 run_lib.py:146] step: 119200, eval_loss: 1.34314e-01
I0216 09:17:35.519833 22839682574144 run_lib.py:133] step: 119250, training_loss: 1.16391e-01
I0216 09:17:53.094257 22839682574144 run_lib.py:133] step: 119300, training_loss: 1.14862e-01
I0216 09:17:53.262510 22839682574144 run_lib.py:146] step: 119300, eval_loss: 1.28438e-01
I0216 09:18:10.833065 22839682574144 run_lib.py:133] step: 119350, training_loss: 1.11991e-01
I0216 09:18:28.329527 22839682574144 run_lib.py:133] step: 119400, training_loss: 1.13616e-01
I0216 09:18:28.487101 22839682574144 run_lib.py:146] step: 119400, eval_loss: 1.34221e-01
I0216 09:18:46.215065 22839682574144 run_lib.py:133] step: 119450, training_loss: 1.12047e-01
I0216 09:19:03.865658 22839682574144 run_lib.py:133] step: 119500, training_loss: 1.08763e-01
I0216 09:19:04.030955 22839682574144 run_lib.py:146] step: 119500, eval_loss: 1.32556e-01
I0216 09:19:21.564548 22839682574144 run_lib.py:133] step: 119550, training_loss: 1.09357e-01
I0216 09:19:39.113364 22839682574144 run_lib.py:133] step: 119600, training_loss: 1.08020e-01
I0216 09:19:39.269964 22839682574144 run_lib.py:146] step: 119600, eval_loss: 1.33157e-01
I0216 09:19:56.988469 22839682574144 run_lib.py:133] step: 119650, training_loss: 1.15131e-01
I0216 09:20:14.516369 22839682574144 run_lib.py:133] step: 119700, training_loss: 1.16421e-01
I0216 09:20:14.692015 22839682574144 run_lib.py:146] step: 119700, eval_loss: 1.31356e-01
I0216 09:20:32.191505 22839682574144 run_lib.py:133] step: 119750, training_loss: 1.12633e-01
I0216 09:20:49.871870 22839682574144 run_lib.py:133] step: 119800, training_loss: 1.12560e-01
I0216 09:20:50.045190 22839682574144 run_lib.py:146] step: 119800, eval_loss: 1.31242e-01
I0216 09:21:07.564424 22839682574144 run_lib.py:133] step: 119850, training_loss: 1.10474e-01
I0216 09:21:25.276398 22839682574144 run_lib.py:133] step: 119900, training_loss: 1.12921e-01
I0216 09:21:25.433331 22839682574144 run_lib.py:146] step: 119900, eval_loss: 1.32918e-01
I0216 09:21:42.952442 22839682574144 run_lib.py:133] step: 119950, training_loss: 1.19619e-01
I0216 09:22:00.473333 22839682574144 run_lib.py:133] step: 120000, training_loss: 1.11091e-01
I0216 09:22:01.229961 22839682574144 run_lib.py:146] step: 120000, eval_loss: 1.33169e-01
I0216 09:22:21.733535 22839682574144 run_lib.py:133] step: 120050, training_loss: 1.16172e-01
I0216 09:22:39.282119 22839682574144 run_lib.py:133] step: 120100, training_loss: 1.11187e-01
I0216 09:22:39.439713 22839682574144 run_lib.py:146] step: 120100, eval_loss: 1.28322e-01
I0216 09:22:56.973585 22839682574144 run_lib.py:133] step: 120150, training_loss: 1.13503e-01
I0216 09:23:14.710124 22839682574144 run_lib.py:133] step: 120200, training_loss: 1.11395e-01
I0216 09:23:14.867472 22839682574144 run_lib.py:146] step: 120200, eval_loss: 1.32413e-01
I0216 09:23:32.407253 22839682574144 run_lib.py:133] step: 120250, training_loss: 1.10682e-01
I0216 09:23:49.940988 22839682574144 run_lib.py:133] step: 120300, training_loss: 1.08637e-01
I0216 09:23:50.115978 22839682574144 run_lib.py:146] step: 120300, eval_loss: 1.37043e-01
I0216 09:24:07.827506 22839682574144 run_lib.py:133] step: 120350, training_loss: 1.09787e-01
I0216 09:24:25.368894 22839682574144 run_lib.py:133] step: 120400, training_loss: 1.11454e-01
I0216 09:24:25.527376 22839682574144 run_lib.py:146] step: 120400, eval_loss: 1.28608e-01
I0216 09:24:43.221323 22839682574144 run_lib.py:133] step: 120450, training_loss: 1.13617e-01
I0216 09:25:00.747141 22839682574144 run_lib.py:133] step: 120500, training_loss: 1.13380e-01
I0216 09:25:00.905107 22839682574144 run_lib.py:146] step: 120500, eval_loss: 1.36359e-01
I0216 09:25:18.401587 22839682574144 run_lib.py:133] step: 120550, training_loss: 1.13353e-01
I0216 09:25:36.116560 22839682574144 run_lib.py:133] step: 120600, training_loss: 1.13968e-01
I0216 09:25:36.273863 22839682574144 run_lib.py:146] step: 120600, eval_loss: 1.33773e-01
I0216 09:25:53.814046 22839682574144 run_lib.py:133] step: 120650, training_loss: 1.12879e-01
I0216 09:26:11.315953 22839682574144 run_lib.py:133] step: 120700, training_loss: 1.11896e-01
I0216 09:26:11.477125 22839682574144 run_lib.py:146] step: 120700, eval_loss: 1.37551e-01
I0216 09:26:28.977540 22839682574144 run_lib.py:133] step: 120750, training_loss: 1.12580e-01
I0216 09:26:46.494903 22839682574144 run_lib.py:133] step: 120800, training_loss: 1.09591e-01
I0216 09:26:46.673315 22839682574144 run_lib.py:146] step: 120800, eval_loss: 1.33847e-01
I0216 09:27:04.381992 22839682574144 run_lib.py:133] step: 120850, training_loss: 1.15464e-01
I0216 09:27:22.006564 22839682574144 run_lib.py:133] step: 120900, training_loss: 1.12168e-01
I0216 09:27:22.164360 22839682574144 run_lib.py:146] step: 120900, eval_loss: 1.34669e-01
I0216 09:27:39.652163 22839682574144 run_lib.py:133] step: 120950, training_loss: 1.15979e-01
I0216 09:27:57.147291 22839682574144 run_lib.py:133] step: 121000, training_loss: 1.08626e-01
I0216 09:27:57.304160 22839682574144 run_lib.py:146] step: 121000, eval_loss: 1.29428e-01
I0216 09:28:15.043006 22839682574144 run_lib.py:133] step: 121050, training_loss: 1.15763e-01
I0216 09:28:32.580008 22839682574144 run_lib.py:133] step: 121100, training_loss: 1.15107e-01
I0216 09:28:32.734160 22839682574144 run_lib.py:146] step: 121100, eval_loss: 1.29739e-01
I0216 09:28:50.412755 22839682574144 run_lib.py:133] step: 121150, training_loss: 1.09103e-01
I0216 09:29:07.930871 22839682574144 run_lib.py:133] step: 121200, training_loss: 1.12713e-01
I0216 09:29:08.099262 22839682574144 run_lib.py:146] step: 121200, eval_loss: 1.29230e-01
I0216 09:29:25.619705 22839682574144 run_lib.py:133] step: 121250, training_loss: 1.14603e-01
I0216 09:29:43.395480 22839682574144 run_lib.py:133] step: 121300, training_loss: 1.11737e-01
I0216 09:29:43.557298 22839682574144 run_lib.py:146] step: 121300, eval_loss: 1.34794e-01
I0216 09:30:01.076120 22839682574144 run_lib.py:133] step: 121350, training_loss: 1.13333e-01
I0216 09:30:18.604177 22839682574144 run_lib.py:133] step: 121400, training_loss: 1.13693e-01
I0216 09:30:18.769061 22839682574144 run_lib.py:146] step: 121400, eval_loss: 1.30131e-01
I0216 09:30:36.492920 22839682574144 run_lib.py:133] step: 121450, training_loss: 1.16403e-01
I0216 09:30:54.025522 22839682574144 run_lib.py:133] step: 121500, training_loss: 1.06929e-01
I0216 09:30:54.181900 22839682574144 run_lib.py:146] step: 121500, eval_loss: 1.32148e-01
I0216 09:31:11.684496 22839682574144 run_lib.py:133] step: 121550, training_loss: 1.10673e-01
I0216 09:31:29.419975 22839682574144 run_lib.py:133] step: 121600, training_loss: 1.10581e-01
I0216 09:31:29.575050 22839682574144 run_lib.py:146] step: 121600, eval_loss: 1.30914e-01
I0216 09:31:47.065742 22839682574144 run_lib.py:133] step: 121650, training_loss: 1.12115e-01
I0216 09:32:04.583390 22839682574144 run_lib.py:133] step: 121700, training_loss: 1.11892e-01
I0216 09:32:04.744270 22839682574144 run_lib.py:146] step: 121700, eval_loss: 1.30217e-01
I0216 09:32:22.403581 22839682574144 run_lib.py:133] step: 121750, training_loss: 1.12086e-01
I0216 09:32:39.957623 22839682574144 run_lib.py:133] step: 121800, training_loss: 1.15364e-01
I0216 09:32:40.116476 22839682574144 run_lib.py:146] step: 121800, eval_loss: 1.28154e-01
I0216 09:32:57.640380 22839682574144 run_lib.py:133] step: 121850, training_loss: 1.13881e-01
I0216 09:33:15.131643 22839682574144 run_lib.py:133] step: 121900, training_loss: 1.13383e-01
I0216 09:33:15.289976 22839682574144 run_lib.py:146] step: 121900, eval_loss: 1.32150e-01
I0216 09:33:33.008820 22839682574144 run_lib.py:133] step: 121950, training_loss: 1.13727e-01
I0216 09:33:50.615972 22839682574144 run_lib.py:133] step: 122000, training_loss: 1.12540e-01
I0216 09:33:50.770222 22839682574144 run_lib.py:146] step: 122000, eval_loss: 1.29914e-01
I0216 09:34:08.329994 22839682574144 run_lib.py:133] step: 122050, training_loss: 1.13904e-01
I0216 09:34:25.849714 22839682574144 run_lib.py:133] step: 122100, training_loss: 1.14240e-01
I0216 09:34:26.006982 22839682574144 run_lib.py:146] step: 122100, eval_loss: 1.34253e-01
I0216 09:34:43.703027 22839682574144 run_lib.py:133] step: 122150, training_loss: 1.10298e-01
I0216 09:35:01.231568 22839682574144 run_lib.py:133] step: 122200, training_loss: 1.10529e-01
I0216 09:35:01.393336 22839682574144 run_lib.py:146] step: 122200, eval_loss: 1.28251e-01
I0216 09:35:18.907732 22839682574144 run_lib.py:133] step: 122250, training_loss: 1.15848e-01
I0216 09:35:36.585066 22839682574144 run_lib.py:133] step: 122300, training_loss: 1.08713e-01
I0216 09:35:36.769168 22839682574144 run_lib.py:146] step: 122300, eval_loss: 1.33605e-01
I0216 09:35:54.297710 22839682574144 run_lib.py:133] step: 122350, training_loss: 1.08739e-01
I0216 09:36:12.028831 22839682574144 run_lib.py:133] step: 122400, training_loss: 1.08995e-01
I0216 09:36:12.194098 22839682574144 run_lib.py:146] step: 122400, eval_loss: 1.28442e-01
I0216 09:36:29.749176 22839682574144 run_lib.py:133] step: 122450, training_loss: 1.12912e-01
I0216 09:36:47.249811 22839682574144 run_lib.py:133] step: 122500, training_loss: 1.13589e-01
I0216 09:36:47.404166 22839682574144 run_lib.py:146] step: 122500, eval_loss: 1.31943e-01
I0216 09:37:05.115701 22839682574144 run_lib.py:133] step: 122550, training_loss: 1.10325e-01
I0216 09:37:22.652903 22839682574144 run_lib.py:133] step: 122600, training_loss: 1.12172e-01
I0216 09:37:22.821361 22839682574144 run_lib.py:146] step: 122600, eval_loss: 1.35348e-01
I0216 09:37:40.382529 22839682574144 run_lib.py:133] step: 122650, training_loss: 1.10629e-01
I0216 09:37:58.120210 22839682574144 run_lib.py:133] step: 122700, training_loss: 1.13118e-01
I0216 09:37:58.286108 22839682574144 run_lib.py:146] step: 122700, eval_loss: 1.31753e-01
I0216 09:38:15.837128 22839682574144 run_lib.py:133] step: 122750, training_loss: 1.14459e-01
I0216 09:38:33.329494 22839682574144 run_lib.py:133] step: 122800, training_loss: 1.17822e-01
I0216 09:38:33.495151 22839682574144 run_lib.py:146] step: 122800, eval_loss: 1.31274e-01
I0216 09:38:51.131667 22839682574144 run_lib.py:133] step: 122850, training_loss: 1.15759e-01
I0216 09:39:08.725522 22839682574144 run_lib.py:133] step: 122900, training_loss: 1.11297e-01
I0216 09:39:08.883476 22839682574144 run_lib.py:146] step: 122900, eval_loss: 1.32430e-01
I0216 09:39:26.459538 22839682574144 run_lib.py:133] step: 122950, training_loss: 1.10326e-01
I0216 09:39:43.981346 22839682574144 run_lib.py:133] step: 123000, training_loss: 1.11748e-01
I0216 09:39:44.138238 22839682574144 run_lib.py:146] step: 123000, eval_loss: 1.31797e-01
I0216 09:40:01.884541 22839682574144 run_lib.py:133] step: 123050, training_loss: 1.11544e-01
I0216 09:40:19.481531 22839682574144 run_lib.py:133] step: 123100, training_loss: 1.14914e-01
I0216 09:40:19.638827 22839682574144 run_lib.py:146] step: 123100, eval_loss: 1.32085e-01
I0216 09:40:37.163343 22839682574144 run_lib.py:133] step: 123150, training_loss: 1.08420e-01
I0216 09:40:54.749008 22839682574144 run_lib.py:133] step: 123200, training_loss: 1.12591e-01
I0216 09:40:54.912163 22839682574144 run_lib.py:146] step: 123200, eval_loss: 1.34200e-01
I0216 09:41:12.618815 22839682574144 run_lib.py:133] step: 123250, training_loss: 1.14113e-01
I0216 09:41:30.155013 22839682574144 run_lib.py:133] step: 123300, training_loss: 1.12867e-01
I0216 09:41:30.311845 22839682574144 run_lib.py:146] step: 123300, eval_loss: 1.29924e-01
I0216 09:41:47.848060 22839682574144 run_lib.py:133] step: 123350, training_loss: 1.13466e-01
I0216 09:42:05.574548 22839682574144 run_lib.py:133] step: 123400, training_loss: 1.10645e-01
I0216 09:42:05.729770 22839682574144 run_lib.py:146] step: 123400, eval_loss: 1.34112e-01
I0216 09:42:23.272086 22839682574144 run_lib.py:133] step: 123450, training_loss: 1.09366e-01
I0216 09:42:40.971379 22839682574144 run_lib.py:133] step: 123500, training_loss: 1.11202e-01
I0216 09:42:41.126124 22839682574144 run_lib.py:146] step: 123500, eval_loss: 1.31401e-01
I0216 09:42:58.661333 22839682574144 run_lib.py:133] step: 123550, training_loss: 1.13458e-01
I0216 09:43:16.204898 22839682574144 run_lib.py:133] step: 123600, training_loss: 1.11922e-01
I0216 09:43:16.363408 22839682574144 run_lib.py:146] step: 123600, eval_loss: 1.32141e-01
I0216 09:43:34.037084 22839682574144 run_lib.py:133] step: 123650, training_loss: 1.08175e-01
I0216 09:43:51.604872 22839682574144 run_lib.py:133] step: 123700, training_loss: 1.14047e-01
I0216 09:43:51.768341 22839682574144 run_lib.py:146] step: 123700, eval_loss: 1.34992e-01
I0216 09:44:09.255594 22839682574144 run_lib.py:133] step: 123750, training_loss: 1.13181e-01
I0216 09:44:27.121751 22839682574144 run_lib.py:133] step: 123800, training_loss: 1.14098e-01
I0216 09:44:27.279024 22839682574144 run_lib.py:146] step: 123800, eval_loss: 1.36836e-01
I0216 09:44:44.802179 22839682574144 run_lib.py:133] step: 123850, training_loss: 1.15585e-01
I0216 09:45:02.322405 22839682574144 run_lib.py:133] step: 123900, training_loss: 1.11344e-01
I0216 09:45:02.475775 22839682574144 run_lib.py:146] step: 123900, eval_loss: 1.32398e-01
I0216 09:45:20.079951 22839682574144 run_lib.py:133] step: 123950, training_loss: 1.15027e-01
I0216 09:45:37.646123 22839682574144 run_lib.py:133] step: 124000, training_loss: 1.11193e-01
I0216 09:45:37.816294 22839682574144 run_lib.py:146] step: 124000, eval_loss: 1.33838e-01
I0216 09:45:55.316486 22839682574144 run_lib.py:133] step: 124050, training_loss: 1.13189e-01
I0216 09:46:12.828556 22839682574144 run_lib.py:133] step: 124100, training_loss: 1.13137e-01
I0216 09:46:12.987002 22839682574144 run_lib.py:146] step: 124100, eval_loss: 1.32253e-01
I0216 09:46:30.708104 22839682574144 run_lib.py:133] step: 124150, training_loss: 1.14398e-01
I0216 09:46:48.294594 22839682574144 run_lib.py:133] step: 124200, training_loss: 1.11297e-01
I0216 09:46:48.449966 22839682574144 run_lib.py:146] step: 124200, eval_loss: 1.32008e-01
I0216 09:47:05.974243 22839682574144 run_lib.py:133] step: 124250, training_loss: 1.14033e-01
I0216 09:47:23.536515 22839682574144 run_lib.py:133] step: 124300, training_loss: 1.15925e-01
I0216 09:47:23.695290 22839682574144 run_lib.py:146] step: 124300, eval_loss: 1.34465e-01
I0216 09:47:41.394530 22839682574144 run_lib.py:133] step: 124350, training_loss: 1.12287e-01
I0216 09:47:58.930211 22839682574144 run_lib.py:133] step: 124400, training_loss: 1.13906e-01
I0216 09:47:59.085124 22839682574144 run_lib.py:146] step: 124400, eval_loss: 1.34935e-01
I0216 09:48:16.620978 22839682574144 run_lib.py:133] step: 124450, training_loss: 1.14866e-01
I0216 09:48:34.373758 22839682574144 run_lib.py:133] step: 124500, training_loss: 1.06901e-01
I0216 09:48:34.542427 22839682574144 run_lib.py:146] step: 124500, eval_loss: 1.32599e-01
I0216 09:48:52.076439 22839682574144 run_lib.py:133] step: 124550, training_loss: 1.13208e-01
I0216 09:49:09.789109 22839682574144 run_lib.py:133] step: 124600, training_loss: 1.10011e-01
I0216 09:49:09.947941 22839682574144 run_lib.py:146] step: 124600, eval_loss: 1.35210e-01
I0216 09:49:27.206630 22839682574144 run_lib.py:133] step: 124650, training_loss: 1.09864e-01
I0216 09:49:44.483386 22839682574144 run_lib.py:133] step: 124700, training_loss: 1.13769e-01
I0216 09:49:44.643718 22839682574144 run_lib.py:146] step: 124700, eval_loss: 1.30240e-01
I0216 09:50:02.116879 22839682574144 run_lib.py:133] step: 124750, training_loss: 1.12328e-01
I0216 09:50:19.532150 22839682574144 run_lib.py:133] step: 124800, training_loss: 1.15051e-01
I0216 09:50:19.690218 22839682574144 run_lib.py:146] step: 124800, eval_loss: 1.29716e-01
I0216 09:50:37.188931 22839682574144 run_lib.py:133] step: 124850, training_loss: 1.12265e-01
I0216 09:50:54.876278 22839682574144 run_lib.py:133] step: 124900, training_loss: 1.15372e-01
I0216 09:50:55.031178 22839682574144 run_lib.py:146] step: 124900, eval_loss: 1.28630e-01
I0216 09:51:12.554844 22839682574144 run_lib.py:133] step: 124950, training_loss: 1.11698e-01
I0216 09:51:30.089937 22839682574144 run_lib.py:133] step: 125000, training_loss: 1.13744e-01
I0216 09:51:30.253275 22839682574144 run_lib.py:146] step: 125000, eval_loss: 1.37977e-01
I0216 09:51:47.875357 22839682574144 run_lib.py:133] step: 125050, training_loss: 1.18414e-01
I0216 09:52:05.415216 22839682574144 run_lib.py:133] step: 125100, training_loss: 1.14073e-01
I0216 09:52:05.575170 22839682574144 run_lib.py:146] step: 125100, eval_loss: 1.31378e-01
I0216 09:52:23.032146 22839682574144 run_lib.py:133] step: 125150, training_loss: 1.10858e-01
I0216 09:52:40.512027 22839682574144 run_lib.py:133] step: 125200, training_loss: 1.14951e-01
I0216 09:52:40.670115 22839682574144 run_lib.py:146] step: 125200, eval_loss: 1.37405e-01
I0216 09:52:58.538365 22839682574144 run_lib.py:133] step: 125250, training_loss: 1.12607e-01
I0216 09:53:16.139167 22839682574144 run_lib.py:133] step: 125300, training_loss: 1.13103e-01
I0216 09:53:16.293138 22839682574144 run_lib.py:146] step: 125300, eval_loss: 1.32062e-01
I0216 09:53:33.861109 22839682574144 run_lib.py:133] step: 125350, training_loss: 1.13972e-01
I0216 09:53:51.374475 22839682574144 run_lib.py:133] step: 125400, training_loss: 1.12635e-01
I0216 09:53:51.541783 22839682574144 run_lib.py:146] step: 125400, eval_loss: 1.25767e-01
I0216 09:54:09.262052 22839682574144 run_lib.py:133] step: 125450, training_loss: 1.14678e-01
I0216 09:54:26.772630 22839682574144 run_lib.py:133] step: 125500, training_loss: 1.16446e-01
I0216 09:54:26.931402 22839682574144 run_lib.py:146] step: 125500, eval_loss: 1.32563e-01
I0216 09:54:44.446985 22839682574144 run_lib.py:133] step: 125550, training_loss: 1.13257e-01
I0216 09:55:02.134362 22839682574144 run_lib.py:133] step: 125600, training_loss: 1.07410e-01
I0216 09:55:02.303964 22839682574144 run_lib.py:146] step: 125600, eval_loss: 1.34813e-01
I0216 09:55:19.835732 22839682574144 run_lib.py:133] step: 125650, training_loss: 1.13750e-01
I0216 09:55:37.538094 22839682574144 run_lib.py:133] step: 125700, training_loss: 1.14588e-01
I0216 09:55:37.695404 22839682574144 run_lib.py:146] step: 125700, eval_loss: 1.37229e-01
I0216 09:55:55.258717 22839682574144 run_lib.py:133] step: 125750, training_loss: 1.11456e-01
I0216 09:56:12.769706 22839682574144 run_lib.py:133] step: 125800, training_loss: 1.11975e-01
I0216 09:56:12.924176 22839682574144 run_lib.py:146] step: 125800, eval_loss: 1.33496e-01
I0216 09:56:30.617335 22839682574144 run_lib.py:133] step: 125850, training_loss: 1.11068e-01
I0216 09:56:48.172831 22839682574144 run_lib.py:133] step: 125900, training_loss: 1.09906e-01
I0216 09:56:48.339355 22839682574144 run_lib.py:146] step: 125900, eval_loss: 1.32886e-01
I0216 09:57:05.911577 22839682574144 run_lib.py:133] step: 125950, training_loss: 1.13934e-01
I0216 09:57:23.654818 22839682574144 run_lib.py:133] step: 126000, training_loss: 1.17580e-01
I0216 09:57:23.823036 22839682574144 run_lib.py:146] step: 126000, eval_loss: 1.36011e-01
I0216 09:57:41.314801 22839682574144 run_lib.py:133] step: 126050, training_loss: 1.10409e-01
I0216 09:57:58.819789 22839682574144 run_lib.py:133] step: 126100, training_loss: 1.13273e-01
I0216 09:57:58.974279 22839682574144 run_lib.py:146] step: 126100, eval_loss: 1.28941e-01
I0216 09:58:16.632002 22839682574144 run_lib.py:133] step: 126150, training_loss: 1.15000e-01
I0216 09:58:34.186910 22839682574144 run_lib.py:133] step: 126200, training_loss: 1.14477e-01
I0216 09:58:34.351322 22839682574144 run_lib.py:146] step: 126200, eval_loss: 1.34195e-01
I0216 09:58:51.904956 22839682574144 run_lib.py:133] step: 126250, training_loss: 1.11822e-01
I0216 09:59:09.434172 22839682574144 run_lib.py:133] step: 126300, training_loss: 1.14364e-01
I0216 09:59:09.589097 22839682574144 run_lib.py:146] step: 126300, eval_loss: 1.39469e-01
I0216 09:59:27.294352 22839682574144 run_lib.py:133] step: 126350, training_loss: 1.16349e-01
I0216 09:59:44.908403 22839682574144 run_lib.py:133] step: 126400, training_loss: 1.10206e-01
I0216 09:59:45.072705 22839682574144 run_lib.py:146] step: 126400, eval_loss: 1.35057e-01
I0216 10:00:02.593812 22839682574144 run_lib.py:133] step: 126450, training_loss: 1.13975e-01
I0216 10:00:20.122769 22839682574144 run_lib.py:133] step: 126500, training_loss: 1.14538e-01
I0216 10:00:20.283688 22839682574144 run_lib.py:146] step: 126500, eval_loss: 1.31544e-01
I0216 10:00:37.995328 22839682574144 run_lib.py:133] step: 126550, training_loss: 1.12697e-01
I0216 10:00:55.494178 22839682574144 run_lib.py:133] step: 126600, training_loss: 1.11181e-01
I0216 10:00:55.652747 22839682574144 run_lib.py:146] step: 126600, eval_loss: 1.33524e-01
I0216 10:01:13.190960 22839682574144 run_lib.py:133] step: 126650, training_loss: 1.13444e-01
I0216 10:01:30.851104 22839682574144 run_lib.py:133] step: 126700, training_loss: 1.13448e-01
I0216 10:01:31.023020 22839682574144 run_lib.py:146] step: 126700, eval_loss: 1.26202e-01
I0216 10:01:48.542727 22839682574144 run_lib.py:133] step: 126750, training_loss: 1.09617e-01
I0216 10:02:06.231093 22839682574144 run_lib.py:133] step: 126800, training_loss: 1.15167e-01
I0216 10:02:06.389355 22839682574144 run_lib.py:146] step: 126800, eval_loss: 1.32885e-01
I0216 10:02:23.903859 22839682574144 run_lib.py:133] step: 126850, training_loss: 1.10918e-01
I0216 10:02:41.421524 22839682574144 run_lib.py:133] step: 126900, training_loss: 1.12751e-01
I0216 10:02:41.580377 22839682574144 run_lib.py:146] step: 126900, eval_loss: 1.33449e-01
I0216 10:02:59.291410 22839682574144 run_lib.py:133] step: 126950, training_loss: 1.16503e-01
I0216 10:03:16.798205 22839682574144 run_lib.py:133] step: 127000, training_loss: 1.13469e-01
I0216 10:03:16.958615 22839682574144 run_lib.py:146] step: 127000, eval_loss: 1.32134e-01
I0216 10:03:34.509104 22839682574144 run_lib.py:133] step: 127050, training_loss: 1.17150e-01
I0216 10:03:52.232991 22839682574144 run_lib.py:133] step: 127100, training_loss: 1.12581e-01
I0216 10:03:52.398840 22839682574144 run_lib.py:146] step: 127100, eval_loss: 1.32619e-01
I0216 10:04:09.936618 22839682574144 run_lib.py:133] step: 127150, training_loss: 1.12070e-01
I0216 10:04:27.449412 22839682574144 run_lib.py:133] step: 127200, training_loss: 1.12672e-01
I0216 10:04:27.604826 22839682574144 run_lib.py:146] step: 127200, eval_loss: 1.35928e-01
I0216 10:04:45.200057 22839682574144 run_lib.py:133] step: 127250, training_loss: 1.14758e-01
I0216 10:05:02.704169 22839682574144 run_lib.py:133] step: 127300, training_loss: 1.12544e-01
I0216 10:05:02.858087 22839682574144 run_lib.py:146] step: 127300, eval_loss: 1.31731e-01
I0216 10:05:20.377404 22839682574144 run_lib.py:133] step: 127350, training_loss: 1.11002e-01
I0216 10:05:37.907415 22839682574144 run_lib.py:133] step: 127400, training_loss: 1.11468e-01
I0216 10:05:38.067967 22839682574144 run_lib.py:146] step: 127400, eval_loss: 1.34660e-01
I0216 10:05:55.796550 22839682574144 run_lib.py:133] step: 127450, training_loss: 1.12736e-01
I0216 10:06:13.398651 22839682574144 run_lib.py:133] step: 127500, training_loss: 1.16553e-01
I0216 10:06:13.559109 22839682574144 run_lib.py:146] step: 127500, eval_loss: 1.32897e-01
I0216 10:06:31.068931 22839682574144 run_lib.py:133] step: 127550, training_loss: 1.11376e-01
I0216 10:06:48.570154 22839682574144 run_lib.py:133] step: 127600, training_loss: 1.14855e-01
I0216 10:06:48.728218 22839682574144 run_lib.py:146] step: 127600, eval_loss: 1.31941e-01
I0216 10:07:06.436145 22839682574144 run_lib.py:133] step: 127650, training_loss: 1.11607e-01
I0216 10:07:24.056924 22839682574144 run_lib.py:133] step: 127700, training_loss: 1.08639e-01
I0216 10:07:24.214783 22839682574144 run_lib.py:146] step: 127700, eval_loss: 1.39044e-01
I0216 10:07:41.739639 22839682574144 run_lib.py:133] step: 127750, training_loss: 1.14480e-01
I0216 10:07:59.442003 22839682574144 run_lib.py:133] step: 127800, training_loss: 1.12767e-01
I0216 10:07:59.599207 22839682574144 run_lib.py:146] step: 127800, eval_loss: 1.33490e-01
I0216 10:08:17.092309 22839682574144 run_lib.py:133] step: 127850, training_loss: 1.11472e-01
I0216 10:08:34.761318 22839682574144 run_lib.py:133] step: 127900, training_loss: 1.12814e-01
I0216 10:08:34.921103 22839682574144 run_lib.py:146] step: 127900, eval_loss: 1.35602e-01
I0216 10:08:52.450784 22839682574144 run_lib.py:133] step: 127950, training_loss: 1.10802e-01
I0216 10:09:10.032859 22839682574144 run_lib.py:133] step: 128000, training_loss: 1.14553e-01
I0216 10:09:10.191343 22839682574144 run_lib.py:146] step: 128000, eval_loss: 1.35060e-01
I0216 10:09:27.954421 22839682574144 run_lib.py:133] step: 128050, training_loss: 1.19088e-01
I0216 10:09:45.492995 22839682574144 run_lib.py:133] step: 128100, training_loss: 1.10828e-01
I0216 10:09:45.651033 22839682574144 run_lib.py:146] step: 128100, eval_loss: 1.30590e-01
I0216 10:10:03.163391 22839682574144 run_lib.py:133] step: 128150, training_loss: 1.13460e-01
I0216 10:10:20.877976 22839682574144 run_lib.py:133] step: 128200, training_loss: 1.11280e-01
I0216 10:10:21.034759 22839682574144 run_lib.py:146] step: 128200, eval_loss: 1.38873e-01
I0216 10:10:38.605400 22839682574144 run_lib.py:133] step: 128250, training_loss: 1.11745e-01
I0216 10:10:56.096359 22839682574144 run_lib.py:133] step: 128300, training_loss: 1.11736e-01
I0216 10:10:56.254051 22839682574144 run_lib.py:146] step: 128300, eval_loss: 1.33785e-01
I0216 10:11:13.888309 22839682574144 run_lib.py:133] step: 128350, training_loss: 1.12769e-01
I0216 10:11:31.370712 22839682574144 run_lib.py:133] step: 128400, training_loss: 1.13596e-01
I0216 10:11:31.530319 22839682574144 run_lib.py:146] step: 128400, eval_loss: 1.32452e-01
I0216 10:11:49.046815 22839682574144 run_lib.py:133] step: 128450, training_loss: 1.14229e-01
I0216 10:12:06.609793 22839682574144 run_lib.py:133] step: 128500, training_loss: 1.13562e-01
I0216 10:12:06.767865 22839682574144 run_lib.py:146] step: 128500, eval_loss: 1.34340e-01
I0216 10:12:24.468249 22839682574144 run_lib.py:133] step: 128550, training_loss: 1.10064e-01
I0216 10:12:42.073834 22839682574144 run_lib.py:133] step: 128600, training_loss: 1.10285e-01
I0216 10:12:42.234066 22839682574144 run_lib.py:146] step: 128600, eval_loss: 1.37169e-01
I0216 10:12:59.766588 22839682574144 run_lib.py:133] step: 128650, training_loss: 1.12119e-01
I0216 10:13:17.256010 22839682574144 run_lib.py:133] step: 128700, training_loss: 1.13988e-01
I0216 10:13:17.412128 22839682574144 run_lib.py:146] step: 128700, eval_loss: 1.30897e-01
I0216 10:13:35.034684 22839682574144 run_lib.py:133] step: 128750, training_loss: 1.12427e-01
I0216 10:13:52.554325 22839682574144 run_lib.py:133] step: 128800, training_loss: 1.13906e-01
I0216 10:13:52.724062 22839682574144 run_lib.py:146] step: 128800, eval_loss: 1.34880e-01
I0216 10:14:10.256787 22839682574144 run_lib.py:133] step: 128850, training_loss: 1.13424e-01
I0216 10:14:27.965314 22839682574144 run_lib.py:133] step: 128900, training_loss: 1.09481e-01
I0216 10:14:28.123289 22839682574144 run_lib.py:146] step: 128900, eval_loss: 1.32007e-01
I0216 10:14:45.615938 22839682574144 run_lib.py:133] step: 128950, training_loss: 1.11009e-01
I0216 10:15:03.272923 22839682574144 run_lib.py:133] step: 129000, training_loss: 1.10543e-01
I0216 10:15:03.433063 22839682574144 run_lib.py:146] step: 129000, eval_loss: 1.35698e-01
I0216 10:15:20.944585 22839682574144 run_lib.py:133] step: 129050, training_loss: 1.11043e-01
I0216 10:15:38.506115 22839682574144 run_lib.py:133] step: 129100, training_loss: 1.11585e-01
I0216 10:15:38.662420 22839682574144 run_lib.py:146] step: 129100, eval_loss: 1.29780e-01
I0216 10:15:56.407947 22839682574144 run_lib.py:133] step: 129150, training_loss: 1.11880e-01
I0216 10:16:13.891981 22839682574144 run_lib.py:133] step: 129200, training_loss: 1.13136e-01
I0216 10:16:14.046228 22839682574144 run_lib.py:146] step: 129200, eval_loss: 1.33320e-01
I0216 10:16:31.555361 22839682574144 run_lib.py:133] step: 129250, training_loss: 1.12562e-01
I0216 10:16:49.257187 22839682574144 run_lib.py:133] step: 129300, training_loss: 1.12696e-01
I0216 10:16:49.439028 22839682574144 run_lib.py:146] step: 129300, eval_loss: 1.32929e-01
I0216 10:17:06.973736 22839682574144 run_lib.py:133] step: 129350, training_loss: 1.09845e-01
I0216 10:17:24.468910 22839682574144 run_lib.py:133] step: 129400, training_loss: 1.13565e-01
I0216 10:17:24.626183 22839682574144 run_lib.py:146] step: 129400, eval_loss: 1.32847e-01
I0216 10:17:42.235280 22839682574144 run_lib.py:133] step: 129450, training_loss: 1.10094e-01
I0216 10:17:59.735950 22839682574144 run_lib.py:133] step: 129500, training_loss: 1.11989e-01
I0216 10:17:59.900799 22839682574144 run_lib.py:146] step: 129500, eval_loss: 1.34056e-01
I0216 10:18:17.367121 22839682574144 run_lib.py:133] step: 129550, training_loss: 1.11600e-01
I0216 10:18:34.874205 22839682574144 run_lib.py:133] step: 129600, training_loss: 1.10288e-01
I0216 10:18:35.029864 22839682574144 run_lib.py:146] step: 129600, eval_loss: 1.29723e-01
I0216 10:18:52.795543 22839682574144 run_lib.py:133] step: 129650, training_loss: 1.10817e-01
I0216 10:19:10.468504 22839682574144 run_lib.py:133] step: 129700, training_loss: 1.10458e-01
I0216 10:19:10.632964 22839682574144 run_lib.py:146] step: 129700, eval_loss: 1.36001e-01
I0216 10:19:28.142608 22839682574144 run_lib.py:133] step: 129750, training_loss: 1.08493e-01
I0216 10:19:45.669142 22839682574144 run_lib.py:133] step: 129800, training_loss: 1.10253e-01
I0216 10:19:45.828333 22839682574144 run_lib.py:146] step: 129800, eval_loss: 1.34816e-01
I0216 10:20:03.526738 22839682574144 run_lib.py:133] step: 129850, training_loss: 1.14164e-01
I0216 10:20:21.039016 22839682574144 run_lib.py:133] step: 129900, training_loss: 1.08978e-01
I0216 10:20:21.196343 22839682574144 run_lib.py:146] step: 129900, eval_loss: 1.35564e-01
I0216 10:20:38.689255 22839682574144 run_lib.py:133] step: 129950, training_loss: 1.12475e-01
I0216 10:20:56.389133 22839682574144 run_lib.py:133] step: 130000, training_loss: 1.14025e-01
I0216 10:20:57.274798 22839682574144 run_lib.py:146] step: 130000, eval_loss: 1.32419e-01
I0216 10:21:17.474642 22839682574144 run_lib.py:133] step: 130050, training_loss: 1.14890e-01
I0216 10:21:34.970039 22839682574144 run_lib.py:133] step: 130100, training_loss: 1.12062e-01
I0216 10:21:35.128300 22839682574144 run_lib.py:146] step: 130100, eval_loss: 1.35631e-01
I0216 10:21:52.825216 22839682574144 run_lib.py:133] step: 130150, training_loss: 1.10254e-01
I0216 10:22:10.459024 22839682574144 run_lib.py:133] step: 130200, training_loss: 1.15890e-01
I0216 10:22:10.614231 22839682574144 run_lib.py:146] step: 130200, eval_loss: 1.30831e-01
I0216 10:22:28.110988 22839682574144 run_lib.py:133] step: 130250, training_loss: 1.09935e-01
I0216 10:22:45.607305 22839682574144 run_lib.py:133] step: 130300, training_loss: 1.10568e-01
I0216 10:22:45.772412 22839682574144 run_lib.py:146] step: 130300, eval_loss: 1.34067e-01
I0216 10:23:03.416843 22839682574144 run_lib.py:133] step: 130350, training_loss: 1.10735e-01
I0216 10:23:20.953320 22839682574144 run_lib.py:133] step: 130400, training_loss: 1.12430e-01
I0216 10:23:21.119096 22839682574144 run_lib.py:146] step: 130400, eval_loss: 1.33538e-01
I0216 10:23:38.840514 22839682574144 run_lib.py:133] step: 130450, training_loss: 1.10865e-01
I0216 10:23:56.358611 22839682574144 run_lib.py:133] step: 130500, training_loss: 1.13849e-01
I0216 10:23:56.516800 22839682574144 run_lib.py:146] step: 130500, eval_loss: 1.30639e-01
I0216 10:24:14.032738 22839682574144 run_lib.py:133] step: 130550, training_loss: 1.11682e-01
I0216 10:24:31.731349 22839682574144 run_lib.py:133] step: 130600, training_loss: 1.10961e-01
I0216 10:24:31.886227 22839682574144 run_lib.py:146] step: 130600, eval_loss: 1.32960e-01
I0216 10:24:49.376289 22839682574144 run_lib.py:133] step: 130650, training_loss: 1.15529e-01
I0216 10:25:06.899719 22839682574144 run_lib.py:133] step: 130700, training_loss: 1.11192e-01
I0216 10:25:07.062172 22839682574144 run_lib.py:146] step: 130700, eval_loss: 1.28438e-01
I0216 10:25:24.813582 22839682574144 run_lib.py:133] step: 130750, training_loss: 1.11430e-01
I0216 10:25:42.331459 22839682574144 run_lib.py:133] step: 130800, training_loss: 1.17043e-01
I0216 10:25:42.492245 22839682574144 run_lib.py:146] step: 130800, eval_loss: 1.36934e-01
I0216 10:26:00.146134 22839682574144 run_lib.py:133] step: 130850, training_loss: 1.09074e-01
I0216 10:26:17.634311 22839682574144 run_lib.py:133] step: 130900, training_loss: 1.10274e-01
I0216 10:26:17.794053 22839682574144 run_lib.py:146] step: 130900, eval_loss: 1.35127e-01
I0216 10:26:35.318406 22839682574144 run_lib.py:133] step: 130950, training_loss: 1.15037e-01
I0216 10:26:53.062495 22839682574144 run_lib.py:133] step: 131000, training_loss: 1.09624e-01
I0216 10:26:53.220364 22839682574144 run_lib.py:146] step: 131000, eval_loss: 1.32258e-01
I0216 10:27:10.783894 22839682574144 run_lib.py:133] step: 131050, training_loss: 1.17076e-01
I0216 10:27:28.325299 22839682574144 run_lib.py:133] step: 131100, training_loss: 1.10328e-01
I0216 10:27:28.479081 22839682574144 run_lib.py:146] step: 131100, eval_loss: 1.30503e-01
I0216 10:27:45.954495 22839682574144 run_lib.py:133] step: 131150, training_loss: 1.14592e-01
I0216 10:28:03.514325 22839682574144 run_lib.py:133] step: 131200, training_loss: 1.09753e-01
I0216 10:28:03.689270 22839682574144 run_lib.py:146] step: 131200, eval_loss: 1.32369e-01
I0216 10:28:21.409423 22839682574144 run_lib.py:133] step: 131250, training_loss: 1.15376e-01
I0216 10:28:39.014878 22839682574144 run_lib.py:133] step: 131300, training_loss: 1.10852e-01
I0216 10:28:39.173328 22839682574144 run_lib.py:146] step: 131300, eval_loss: 1.32317e-01
I0216 10:28:56.655654 22839682574144 run_lib.py:133] step: 131350, training_loss: 1.13597e-01
I0216 10:29:14.158427 22839682574144 run_lib.py:133] step: 131400, training_loss: 1.13121e-01
I0216 10:29:14.315007 22839682574144 run_lib.py:146] step: 131400, eval_loss: 1.30045e-01
I0216 10:29:31.994809 22839682574144 run_lib.py:133] step: 131450, training_loss: 1.13536e-01
I0216 10:29:49.511783 22839682574144 run_lib.py:133] step: 131500, training_loss: 1.14640e-01
I0216 10:29:49.670274 22839682574144 run_lib.py:146] step: 131500, eval_loss: 1.31754e-01
I0216 10:30:07.444430 22839682574144 run_lib.py:133] step: 131550, training_loss: 1.12924e-01
I0216 10:30:24.954917 22839682574144 run_lib.py:133] step: 131600, training_loss: 1.12718e-01
I0216 10:30:25.108149 22839682574144 run_lib.py:146] step: 131600, eval_loss: 1.33514e-01
I0216 10:30:42.613771 22839682574144 run_lib.py:133] step: 131650, training_loss: 1.13282e-01
I0216 10:31:00.319140 22839682574144 run_lib.py:133] step: 131700, training_loss: 1.08936e-01
I0216 10:31:00.477160 22839682574144 run_lib.py:146] step: 131700, eval_loss: 1.33521e-01
I0216 10:31:17.967555 22839682574144 run_lib.py:133] step: 131750, training_loss: 1.11788e-01
I0216 10:31:35.545565 22839682574144 run_lib.py:133] step: 131800, training_loss: 1.14364e-01
I0216 10:31:35.706105 22839682574144 run_lib.py:146] step: 131800, eval_loss: 1.34658e-01
I0216 10:31:53.433779 22839682574144 run_lib.py:133] step: 131850, training_loss: 1.14050e-01
I0216 10:32:10.923361 22839682574144 run_lib.py:133] step: 131900, training_loss: 1.12498e-01
I0216 10:32:11.080039 22839682574144 run_lib.py:146] step: 131900, eval_loss: 1.31633e-01
I0216 10:32:28.614757 22839682574144 run_lib.py:133] step: 131950, training_loss: 1.12670e-01
I0216 10:32:46.292982 22839682574144 run_lib.py:133] step: 132000, training_loss: 1.11283e-01
I0216 10:32:46.449083 22839682574144 run_lib.py:146] step: 132000, eval_loss: 1.34368e-01
I0216 10:33:03.984704 22839682574144 run_lib.py:133] step: 132050, training_loss: 1.12106e-01
I0216 10:33:21.510192 22839682574144 run_lib.py:133] step: 132100, training_loss: 1.12902e-01
I0216 10:33:21.668262 22839682574144 run_lib.py:146] step: 132100, eval_loss: 1.26514e-01
I0216 10:33:39.306546 22839682574144 run_lib.py:133] step: 132150, training_loss: 1.07610e-01
I0216 10:33:56.867337 22839682574144 run_lib.py:133] step: 132200, training_loss: 1.11332e-01
I0216 10:33:57.027379 22839682574144 run_lib.py:146] step: 132200, eval_loss: 1.30793e-01
I0216 10:34:14.527809 22839682574144 run_lib.py:133] step: 132250, training_loss: 1.20719e-01
I0216 10:34:32.038511 22839682574144 run_lib.py:133] step: 132300, training_loss: 1.11961e-01
I0216 10:34:32.206129 22839682574144 run_lib.py:146] step: 132300, eval_loss: 1.33115e-01
I0216 10:34:49.896324 22839682574144 run_lib.py:133] step: 132350, training_loss: 1.13315e-01
I0216 10:35:07.539484 22839682574144 run_lib.py:133] step: 132400, training_loss: 1.10134e-01
I0216 10:35:07.698497 22839682574144 run_lib.py:146] step: 132400, eval_loss: 1.32905e-01
I0216 10:35:25.242434 22839682574144 run_lib.py:133] step: 132450, training_loss: 1.09687e-01
I0216 10:35:42.724113 22839682574144 run_lib.py:133] step: 132500, training_loss: 1.13146e-01
I0216 10:35:42.883076 22839682574144 run_lib.py:146] step: 132500, eval_loss: 1.35616e-01
I0216 10:36:00.550775 22839682574144 run_lib.py:133] step: 132550, training_loss: 1.08101e-01
I0216 10:36:18.115328 22839682574144 run_lib.py:133] step: 132600, training_loss: 1.10349e-01
I0216 10:36:18.306234 22839682574144 run_lib.py:146] step: 132600, eval_loss: 1.28369e-01
I0216 10:36:35.819236 22839682574144 run_lib.py:133] step: 132650, training_loss: 1.11424e-01
I0216 10:36:53.539416 22839682574144 run_lib.py:133] step: 132700, training_loss: 1.09533e-01
I0216 10:36:53.698974 22839682574144 run_lib.py:146] step: 132700, eval_loss: 1.29783e-01
I0216 10:37:11.241218 22839682574144 run_lib.py:133] step: 132750, training_loss: 1.15129e-01
I0216 10:37:28.923909 22839682574144 run_lib.py:133] step: 132800, training_loss: 1.11607e-01
I0216 10:37:29.081058 22839682574144 run_lib.py:146] step: 132800, eval_loss: 1.34844e-01
I0216 10:37:46.611715 22839682574144 run_lib.py:133] step: 132850, training_loss: 1.13546e-01
I0216 10:38:04.137686 22839682574144 run_lib.py:133] step: 132900, training_loss: 1.10409e-01
I0216 10:38:04.297350 22839682574144 run_lib.py:146] step: 132900, eval_loss: 1.33364e-01
I0216 10:38:22.050660 22839682574144 run_lib.py:133] step: 132950, training_loss: 1.09382e-01
I0216 10:38:39.538653 22839682574144 run_lib.py:133] step: 133000, training_loss: 1.14068e-01
I0216 10:38:39.690842 22839682574144 run_lib.py:146] step: 133000, eval_loss: 1.33960e-01
I0216 10:38:57.190927 22839682574144 run_lib.py:133] step: 133050, training_loss: 1.10766e-01
I0216 10:39:14.876323 22839682574144 run_lib.py:133] step: 133100, training_loss: 1.15495e-01
I0216 10:39:15.033988 22839682574144 run_lib.py:146] step: 133100, eval_loss: 1.35351e-01
I0216 10:39:32.519007 22839682574144 run_lib.py:133] step: 133150, training_loss: 1.11988e-01
I0216 10:39:50.050265 22839682574144 run_lib.py:133] step: 133200, training_loss: 1.14299e-01
I0216 10:39:50.225016 22839682574144 run_lib.py:146] step: 133200, eval_loss: 1.32061e-01
I0216 10:40:07.868811 22839682574144 run_lib.py:133] step: 133250, training_loss: 1.07775e-01
I0216 10:40:25.371146 22839682574144 run_lib.py:133] step: 133300, training_loss: 1.13561e-01
I0216 10:40:25.529194 22839682574144 run_lib.py:146] step: 133300, eval_loss: 1.36021e-01
I0216 10:40:43.037837 22839682574144 run_lib.py:133] step: 133350, training_loss: 1.13101e-01
I0216 10:41:00.557535 22839682574144 run_lib.py:133] step: 133400, training_loss: 1.13337e-01
I0216 10:41:00.713051 22839682574144 run_lib.py:146] step: 133400, eval_loss: 1.33716e-01
I0216 10:41:18.383497 22839682574144 run_lib.py:133] step: 133450, training_loss: 1.08683e-01
I0216 10:41:36.006620 22839682574144 run_lib.py:133] step: 133500, training_loss: 1.10806e-01
I0216 10:41:36.168299 22839682574144 run_lib.py:146] step: 133500, eval_loss: 1.29086e-01
I0216 10:41:53.701734 22839682574144 run_lib.py:133] step: 133550, training_loss: 1.13239e-01
I0216 10:42:11.229266 22839682574144 run_lib.py:133] step: 133600, training_loss: 1.13275e-01
I0216 10:42:11.394157 22839682574144 run_lib.py:146] step: 133600, eval_loss: 1.34050e-01
I0216 10:42:29.070333 22839682574144 run_lib.py:133] step: 133650, training_loss: 1.14146e-01
I0216 10:42:46.623878 22839682574144 run_lib.py:133] step: 133700, training_loss: 1.13859e-01
I0216 10:42:46.785281 22839682574144 run_lib.py:146] step: 133700, eval_loss: 1.37837e-01
I0216 10:43:04.313889 22839682574144 run_lib.py:133] step: 133750, training_loss: 1.13765e-01
I0216 10:43:22.031482 22839682574144 run_lib.py:133] step: 133800, training_loss: 1.13350e-01
I0216 10:43:22.198247 22839682574144 run_lib.py:146] step: 133800, eval_loss: 1.30221e-01
I0216 10:43:39.701479 22839682574144 run_lib.py:133] step: 133850, training_loss: 1.12395e-01
I0216 10:43:57.400566 22839682574144 run_lib.py:133] step: 133900, training_loss: 1.11775e-01
I0216 10:43:57.558772 22839682574144 run_lib.py:146] step: 133900, eval_loss: 1.33547e-01
I0216 10:44:15.083935 22839682574144 run_lib.py:133] step: 133950, training_loss: 1.13456e-01
I0216 10:44:32.561918 22839682574144 run_lib.py:133] step: 134000, training_loss: 1.13789e-01
I0216 10:44:32.720341 22839682574144 run_lib.py:146] step: 134000, eval_loss: 1.37589e-01
I0216 10:44:50.512643 22839682574144 run_lib.py:133] step: 134050, training_loss: 1.09900e-01
I0216 10:45:08.078464 22839682574144 run_lib.py:133] step: 134100, training_loss: 1.06985e-01
I0216 10:45:08.238146 22839682574144 run_lib.py:146] step: 134100, eval_loss: 1.32555e-01
I0216 10:45:25.721112 22839682574144 run_lib.py:133] step: 134150, training_loss: 1.17634e-01
I0216 10:45:43.420928 22839682574144 run_lib.py:133] step: 134200, training_loss: 1.14611e-01
I0216 10:45:43.577618 22839682574144 run_lib.py:146] step: 134200, eval_loss: 1.38263e-01
I0216 10:46:01.074996 22839682574144 run_lib.py:133] step: 134250, training_loss: 1.12510e-01
I0216 10:46:18.618162 22839682574144 run_lib.py:133] step: 134300, training_loss: 1.12330e-01
I0216 10:46:18.778746 22839682574144 run_lib.py:146] step: 134300, eval_loss: 1.37042e-01
I0216 10:46:36.414265 22839682574144 run_lib.py:133] step: 134350, training_loss: 1.10869e-01
I0216 10:46:53.947786 22839682574144 run_lib.py:133] step: 134400, training_loss: 1.07984e-01
I0216 10:46:54.102895 22839682574144 run_lib.py:146] step: 134400, eval_loss: 1.35264e-01
I0216 10:47:11.633648 22839682574144 run_lib.py:133] step: 134450, training_loss: 1.15471e-01
I0216 10:47:29.130728 22839682574144 run_lib.py:133] step: 134500, training_loss: 1.10321e-01
I0216 10:47:29.286119 22839682574144 run_lib.py:146] step: 134500, eval_loss: 1.33124e-01
I0216 10:47:47.017817 22839682574144 run_lib.py:133] step: 134550, training_loss: 1.09629e-01
I0216 10:48:04.702049 22839682574144 run_lib.py:133] step: 134600, training_loss: 1.11576e-01
I0216 10:48:04.865099 22839682574144 run_lib.py:146] step: 134600, eval_loss: 1.29064e-01
I0216 10:48:22.379024 22839682574144 run_lib.py:133] step: 134650, training_loss: 1.12438e-01
I0216 10:48:39.902854 22839682574144 run_lib.py:133] step: 134700, training_loss: 1.09301e-01
I0216 10:48:40.059990 22839682574144 run_lib.py:146] step: 134700, eval_loss: 1.31825e-01
I0216 10:48:57.767570 22839682574144 run_lib.py:133] step: 134750, training_loss: 1.14759e-01
I0216 10:49:15.298795 22839682574144 run_lib.py:133] step: 134800, training_loss: 1.10288e-01
I0216 10:49:15.469192 22839682574144 run_lib.py:146] step: 134800, eval_loss: 1.33332e-01
I0216 10:49:33.005553 22839682574144 run_lib.py:133] step: 134850, training_loss: 1.12895e-01
I0216 10:49:50.726228 22839682574144 run_lib.py:133] step: 134900, training_loss: 1.16479e-01
I0216 10:49:50.881380 22839682574144 run_lib.py:146] step: 134900, eval_loss: 1.29135e-01
I0216 10:50:08.399949 22839682574144 run_lib.py:133] step: 134950, training_loss: 1.14759e-01
I0216 10:50:26.078963 22839682574144 run_lib.py:133] step: 135000, training_loss: 1.09932e-01
I0216 10:50:26.233119 22839682574144 run_lib.py:146] step: 135000, eval_loss: 1.36232e-01
I0216 10:50:43.702980 22839682574144 run_lib.py:133] step: 135050, training_loss: 1.13387e-01
I0216 10:51:01.208301 22839682574144 run_lib.py:133] step: 135100, training_loss: 1.15470e-01
I0216 10:51:01.377070 22839682574144 run_lib.py:146] step: 135100, eval_loss: 1.36135e-01
I0216 10:51:19.090534 22839682574144 run_lib.py:133] step: 135150, training_loss: 1.12303e-01
I0216 10:51:36.615344 22839682574144 run_lib.py:133] step: 135200, training_loss: 1.14469e-01
I0216 10:51:36.773439 22839682574144 run_lib.py:146] step: 135200, eval_loss: 1.31175e-01
I0216 10:51:54.296162 22839682574144 run_lib.py:133] step: 135250, training_loss: 1.12160e-01
I0216 10:52:12.037282 22839682574144 run_lib.py:133] step: 135300, training_loss: 1.12316e-01
I0216 10:52:12.193102 22839682574144 run_lib.py:146] step: 135300, eval_loss: 1.30044e-01
I0216 10:52:29.720376 22839682574144 run_lib.py:133] step: 135350, training_loss: 1.12760e-01
I0216 10:52:47.269896 22839682574144 run_lib.py:133] step: 135400, training_loss: 1.12517e-01
I0216 10:52:47.434393 22839682574144 run_lib.py:146] step: 135400, eval_loss: 1.34398e-01
I0216 10:53:05.085413 22839682574144 run_lib.py:133] step: 135450, training_loss: 1.14349e-01
I0216 10:53:22.599181 22839682574144 run_lib.py:133] step: 135500, training_loss: 1.11382e-01
I0216 10:53:22.755791 22839682574144 run_lib.py:146] step: 135500, eval_loss: 1.37334e-01
I0216 10:53:40.300502 22839682574144 run_lib.py:133] step: 135550, training_loss: 1.11829e-01
I0216 10:53:57.810264 22839682574144 run_lib.py:133] step: 135600, training_loss: 1.09801e-01
I0216 10:53:57.970296 22839682574144 run_lib.py:146] step: 135600, eval_loss: 1.34443e-01
I0216 10:54:15.719286 22839682574144 run_lib.py:133] step: 135650, training_loss: 1.12113e-01
I0216 10:54:33.385508 22839682574144 run_lib.py:133] step: 135700, training_loss: 1.14677e-01
I0216 10:54:33.541823 22839682574144 run_lib.py:146] step: 135700, eval_loss: 1.39262e-01
I0216 10:54:51.017922 22839682574144 run_lib.py:133] step: 135750, training_loss: 1.05714e-01
I0216 10:55:08.541645 22839682574144 run_lib.py:133] step: 135800, training_loss: 1.10808e-01
I0216 10:55:08.699012 22839682574144 run_lib.py:146] step: 135800, eval_loss: 1.32212e-01
I0216 10:55:26.388380 22839682574144 run_lib.py:133] step: 135850, training_loss: 1.10250e-01
I0216 10:55:43.926852 22839682574144 run_lib.py:133] step: 135900, training_loss: 1.13094e-01
I0216 10:55:44.083048 22839682574144 run_lib.py:146] step: 135900, eval_loss: 1.33760e-01
I0216 10:56:01.609378 22839682574144 run_lib.py:133] step: 135950, training_loss: 1.10735e-01
I0216 10:56:19.334532 22839682574144 run_lib.py:133] step: 136000, training_loss: 1.14015e-01
I0216 10:56:19.492030 22839682574144 run_lib.py:146] step: 136000, eval_loss: 1.32225e-01
I0216 10:56:36.984461 22839682574144 run_lib.py:133] step: 136050, training_loss: 1.11008e-01
I0216 10:56:54.722416 22839682574144 run_lib.py:133] step: 136100, training_loss: 1.12529e-01
I0216 10:56:54.880021 22839682574144 run_lib.py:146] step: 136100, eval_loss: 1.33190e-01
I0216 10:57:12.401841 22839682574144 run_lib.py:133] step: 136150, training_loss: 1.11467e-01
I0216 10:57:29.957179 22839682574144 run_lib.py:133] step: 136200, training_loss: 1.12690e-01
I0216 10:57:30.114078 22839682574144 run_lib.py:146] step: 136200, eval_loss: 1.33662e-01
I0216 10:57:47.822522 22839682574144 run_lib.py:133] step: 136250, training_loss: 1.13879e-01
I0216 10:58:05.416570 22839682574144 run_lib.py:133] step: 136300, training_loss: 1.15460e-01
I0216 10:58:05.574474 22839682574144 run_lib.py:146] step: 136300, eval_loss: 1.34126e-01
I0216 10:58:23.090749 22839682574144 run_lib.py:133] step: 136350, training_loss: 1.08922e-01
I0216 10:58:40.800507 22839682574144 run_lib.py:133] step: 136400, training_loss: 1.09387e-01
I0216 10:58:40.969049 22839682574144 run_lib.py:146] step: 136400, eval_loss: 1.35175e-01
I0216 10:58:58.494519 22839682574144 run_lib.py:133] step: 136450, training_loss: 1.14528e-01
I0216 10:59:16.028930 22839682574144 run_lib.py:133] step: 136500, training_loss: 1.13298e-01
I0216 10:59:16.186210 22839682574144 run_lib.py:146] step: 136500, eval_loss: 1.33014e-01
I0216 10:59:33.810986 22839682574144 run_lib.py:133] step: 136550, training_loss: 1.09227e-01
I0216 10:59:51.360102 22839682574144 run_lib.py:133] step: 136600, training_loss: 1.13803e-01
I0216 10:59:51.518277 22839682574144 run_lib.py:146] step: 136600, eval_loss: 1.30852e-01
I0216 11:00:09.028718 22839682574144 run_lib.py:133] step: 136650, training_loss: 1.13412e-01
I0216 11:00:26.542581 22839682574144 run_lib.py:133] step: 136700, training_loss: 1.11356e-01
I0216 11:00:26.699996 22839682574144 run_lib.py:146] step: 136700, eval_loss: 1.34715e-01
I0216 11:00:44.431250 22839682574144 run_lib.py:133] step: 136750, training_loss: 1.14803e-01
I0216 11:01:02.086920 22839682574144 run_lib.py:133] step: 136800, training_loss: 1.10663e-01
I0216 11:01:02.243319 22839682574144 run_lib.py:146] step: 136800, eval_loss: 1.37112e-01
I0216 11:01:19.786334 22839682574144 run_lib.py:133] step: 136850, training_loss: 1.08691e-01
I0216 11:01:37.340337 22839682574144 run_lib.py:133] step: 136900, training_loss: 1.12429e-01
I0216 11:01:37.498035 22839682574144 run_lib.py:146] step: 136900, eval_loss: 1.27139e-01
I0216 11:01:55.227391 22839682574144 run_lib.py:133] step: 136950, training_loss: 1.13968e-01
I0216 11:02:12.722318 22839682574144 run_lib.py:133] step: 137000, training_loss: 1.10677e-01
I0216 11:02:12.882309 22839682574144 run_lib.py:146] step: 137000, eval_loss: 1.33952e-01
I0216 11:02:30.440580 22839682574144 run_lib.py:133] step: 137050, training_loss: 1.13428e-01
I0216 11:02:48.193669 22839682574144 run_lib.py:133] step: 137100, training_loss: 1.06816e-01
I0216 11:02:48.353586 22839682574144 run_lib.py:146] step: 137100, eval_loss: 1.36499e-01
I0216 11:03:05.878197 22839682574144 run_lib.py:133] step: 137150, training_loss: 1.11753e-01
I0216 11:03:23.618569 22839682574144 run_lib.py:133] step: 137200, training_loss: 1.08343e-01
I0216 11:03:23.794093 22839682574144 run_lib.py:146] step: 137200, eval_loss: 1.31287e-01
I0216 11:03:41.301504 22839682574144 run_lib.py:133] step: 137250, training_loss: 1.11494e-01
I0216 11:03:58.804982 22839682574144 run_lib.py:133] step: 137300, training_loss: 1.11705e-01
I0216 11:03:58.960319 22839682574144 run_lib.py:146] step: 137300, eval_loss: 1.36472e-01
I0216 11:04:16.683550 22839682574144 run_lib.py:133] step: 137350, training_loss: 1.06516e-01
I0216 11:04:34.205780 22839682574144 run_lib.py:133] step: 137400, training_loss: 1.11304e-01
I0216 11:04:34.364042 22839682574144 run_lib.py:146] step: 137400, eval_loss: 1.29971e-01
I0216 11:04:51.878817 22839682574144 run_lib.py:133] step: 137450, training_loss: 1.12837e-01
I0216 11:05:09.607844 22839682574144 run_lib.py:133] step: 137500, training_loss: 1.09641e-01
I0216 11:05:09.774402 22839682574144 run_lib.py:146] step: 137500, eval_loss: 1.32048e-01
I0216 11:05:27.291167 22839682574144 run_lib.py:133] step: 137550, training_loss: 1.08741e-01
I0216 11:05:44.790267 22839682574144 run_lib.py:133] step: 137600, training_loss: 1.11934e-01
I0216 11:05:44.958224 22839682574144 run_lib.py:146] step: 137600, eval_loss: 1.35643e-01
I0216 11:06:02.572017 22839682574144 run_lib.py:133] step: 137650, training_loss: 1.09306e-01
I0216 11:06:20.110405 22839682574144 run_lib.py:133] step: 137700, training_loss: 1.13244e-01
I0216 11:06:20.266788 22839682574144 run_lib.py:146] step: 137700, eval_loss: 1.30856e-01
I0216 11:06:37.783446 22839682574144 run_lib.py:133] step: 137750, training_loss: 1.12068e-01
I0216 11:06:55.319430 22839682574144 run_lib.py:133] step: 137800, training_loss: 1.13558e-01
I0216 11:06:55.474129 22839682574144 run_lib.py:146] step: 137800, eval_loss: 1.34231e-01
I0216 11:07:13.221191 22839682574144 run_lib.py:133] step: 137850, training_loss: 1.11497e-01
I0216 11:07:30.853931 22839682574144 run_lib.py:133] step: 137900, training_loss: 1.14693e-01
I0216 11:07:31.036005 22839682574144 run_lib.py:146] step: 137900, eval_loss: 1.32023e-01
I0216 11:07:48.579236 22839682574144 run_lib.py:133] step: 137950, training_loss: 1.14727e-01
I0216 11:08:06.111238 22839682574144 run_lib.py:133] step: 138000, training_loss: 1.10651e-01
I0216 11:08:06.269358 22839682574144 run_lib.py:146] step: 138000, eval_loss: 1.34766e-01
I0216 11:08:23.945762 22839682574144 run_lib.py:133] step: 138050, training_loss: 1.12543e-01
I0216 11:08:41.456330 22839682574144 run_lib.py:133] step: 138100, training_loss: 1.10249e-01
I0216 11:08:41.614434 22839682574144 run_lib.py:146] step: 138100, eval_loss: 1.31258e-01
I0216 11:08:59.136928 22839682574144 run_lib.py:133] step: 138150, training_loss: 1.10593e-01
I0216 11:09:16.861030 22839682574144 run_lib.py:133] step: 138200, training_loss: 1.11105e-01
I0216 11:09:17.018595 22839682574144 run_lib.py:146] step: 138200, eval_loss: 1.34563e-01
I0216 11:09:34.583744 22839682574144 run_lib.py:133] step: 138250, training_loss: 1.10665e-01
I0216 11:09:52.307860 22839682574144 run_lib.py:133] step: 138300, training_loss: 1.13645e-01
I0216 11:09:52.465051 22839682574144 run_lib.py:146] step: 138300, eval_loss: 1.32753e-01
I0216 11:10:09.957608 22839682574144 run_lib.py:133] step: 138350, training_loss: 1.11296e-01
I0216 11:10:27.494351 22839682574144 run_lib.py:133] step: 138400, training_loss: 1.14042e-01
I0216 11:10:27.654249 22839682574144 run_lib.py:146] step: 138400, eval_loss: 1.35805e-01
I0216 11:10:45.376164 22839682574144 run_lib.py:133] step: 138450, training_loss: 1.11169e-01
I0216 11:11:02.890405 22839682574144 run_lib.py:133] step: 138500, training_loss: 1.12023e-01
I0216 11:11:03.087308 22839682574144 run_lib.py:146] step: 138500, eval_loss: 1.30907e-01
I0216 11:11:20.595251 22839682574144 run_lib.py:133] step: 138550, training_loss: 1.11693e-01
I0216 11:11:38.321197 22839682574144 run_lib.py:133] step: 138600, training_loss: 1.10339e-01
I0216 11:11:38.479192 22839682574144 run_lib.py:146] step: 138600, eval_loss: 1.33486e-01
I0216 11:11:56.030674 22839682574144 run_lib.py:133] step: 138650, training_loss: 1.14891e-01
I0216 11:12:13.539672 22839682574144 run_lib.py:133] step: 138700, training_loss: 1.11400e-01
I0216 11:12:13.694243 22839682574144 run_lib.py:146] step: 138700, eval_loss: 1.35028e-01
I0216 11:12:31.356608 22839682574144 run_lib.py:133] step: 138750, training_loss: 1.13362e-01
I0216 11:12:48.856380 22839682574144 run_lib.py:133] step: 138800, training_loss: 1.08108e-01
I0216 11:12:49.050240 22839682574144 run_lib.py:146] step: 138800, eval_loss: 1.32488e-01
I0216 11:13:06.597460 22839682574144 run_lib.py:133] step: 138850, training_loss: 1.11383e-01
I0216 11:13:24.125640 22839682574144 run_lib.py:133] step: 138900, training_loss: 1.10192e-01
I0216 11:13:24.284117 22839682574144 run_lib.py:146] step: 138900, eval_loss: 1.34214e-01
I0216 11:13:42.012502 22839682574144 run_lib.py:133] step: 138950, training_loss: 1.09775e-01
I0216 11:13:59.624135 22839682574144 run_lib.py:133] step: 139000, training_loss: 1.11337e-01
I0216 11:13:59.791907 22839682574144 run_lib.py:146] step: 139000, eval_loss: 1.30890e-01
I0216 11:14:17.355223 22839682574144 run_lib.py:133] step: 139050, training_loss: 1.13902e-01
I0216 11:14:34.905489 22839682574144 run_lib.py:133] step: 139100, training_loss: 1.11195e-01
I0216 11:14:35.062391 22839682574144 run_lib.py:146] step: 139100, eval_loss: 1.36535e-01
I0216 11:14:52.790375 22839682574144 run_lib.py:133] step: 139150, training_loss: 1.14850e-01
I0216 11:15:10.325528 22839682574144 run_lib.py:133] step: 139200, training_loss: 1.11081e-01
I0216 11:15:10.479037 22839682574144 run_lib.py:146] step: 139200, eval_loss: 1.36924e-01
I0216 11:15:27.992036 22839682574144 run_lib.py:133] step: 139250, training_loss: 1.12715e-01
I0216 11:15:45.650557 22839682574144 run_lib.py:133] step: 139300, training_loss: 1.13168e-01
I0216 11:15:45.821131 22839682574144 run_lib.py:146] step: 139300, eval_loss: 1.33283e-01
I0216 11:16:03.375538 22839682574144 run_lib.py:133] step: 139350, training_loss: 1.11086e-01
I0216 11:16:21.144341 22839682574144 run_lib.py:133] step: 139400, training_loss: 1.14301e-01
I0216 11:16:21.302311 22839682574144 run_lib.py:146] step: 139400, eval_loss: 1.33681e-01
I0216 11:16:38.828065 22839682574144 run_lib.py:133] step: 139450, training_loss: 1.10767e-01
I0216 11:16:56.339566 22839682574144 run_lib.py:133] step: 139500, training_loss: 1.12358e-01
I0216 11:16:56.495861 22839682574144 run_lib.py:146] step: 139500, eval_loss: 1.33391e-01
I0216 11:17:14.202220 22839682574144 run_lib.py:133] step: 139550, training_loss: 1.10586e-01
I0216 11:17:31.771759 22839682574144 run_lib.py:133] step: 139600, training_loss: 1.13950e-01
I0216 11:17:31.928805 22839682574144 run_lib.py:146] step: 139600, eval_loss: 1.32100e-01
I0216 11:17:49.461339 22839682574144 run_lib.py:133] step: 139650, training_loss: 1.09795e-01
I0216 11:18:07.170859 22839682574144 run_lib.py:133] step: 139700, training_loss: 1.13936e-01
I0216 11:18:07.326048 22839682574144 run_lib.py:146] step: 139700, eval_loss: 1.34068e-01
I0216 11:18:24.850756 22839682574144 run_lib.py:133] step: 139750, training_loss: 1.17309e-01
I0216 11:18:42.384892 22839682574144 run_lib.py:133] step: 139800, training_loss: 1.17381e-01
I0216 11:18:42.545178 22839682574144 run_lib.py:146] step: 139800, eval_loss: 1.33659e-01
I0216 11:19:00.216021 22839682574144 run_lib.py:133] step: 139850, training_loss: 1.12565e-01
I0216 11:19:17.770979 22839682574144 run_lib.py:133] step: 139900, training_loss: 1.12211e-01
I0216 11:19:17.928228 22839682574144 run_lib.py:146] step: 139900, eval_loss: 1.31732e-01
I0216 11:19:35.441798 22839682574144 run_lib.py:133] step: 139950, training_loss: 1.13305e-01
I0216 11:19:52.981856 22839682574144 run_lib.py:133] step: 140000, training_loss: 1.14414e-01
I0216 11:19:53.765811 22839682574144 run_lib.py:146] step: 140000, eval_loss: 1.31972e-01
I0216 11:20:14.168527 22839682574144 run_lib.py:133] step: 140050, training_loss: 1.14385e-01
I0216 11:20:31.690900 22839682574144 run_lib.py:133] step: 140100, training_loss: 1.10272e-01
I0216 11:20:31.855831 22839682574144 run_lib.py:146] step: 140100, eval_loss: 1.32701e-01
I0216 11:20:49.488906 22839682574144 run_lib.py:133] step: 140150, training_loss: 1.12666e-01
I0216 11:21:07.048851 22839682574144 run_lib.py:133] step: 140200, training_loss: 1.14883e-01
I0216 11:21:07.203080 22839682574144 run_lib.py:146] step: 140200, eval_loss: 1.34463e-01
I0216 11:21:24.724167 22839682574144 run_lib.py:133] step: 140250, training_loss: 1.15681e-01
I0216 11:21:42.217583 22839682574144 run_lib.py:133] step: 140300, training_loss: 1.11286e-01
I0216 11:21:42.378141 22839682574144 run_lib.py:146] step: 140300, eval_loss: 1.33123e-01
I0216 11:22:00.110842 22839682574144 run_lib.py:133] step: 140350, training_loss: 1.09134e-01
I0216 11:22:17.777211 22839682574144 run_lib.py:133] step: 140400, training_loss: 1.09465e-01
I0216 11:22:17.974725 22839682574144 run_lib.py:146] step: 140400, eval_loss: 1.27070e-01
I0216 11:22:35.492292 22839682574144 run_lib.py:133] step: 140450, training_loss: 1.12349e-01
I0216 11:22:53.001559 22839682574144 run_lib.py:133] step: 140500, training_loss: 1.18607e-01
I0216 11:22:53.158948 22839682574144 run_lib.py:146] step: 140500, eval_loss: 1.37593e-01
I0216 11:23:10.873667 22839682574144 run_lib.py:133] step: 140550, training_loss: 1.13818e-01
I0216 11:23:28.412944 22839682574144 run_lib.py:133] step: 140600, training_loss: 1.08522e-01
I0216 11:23:28.569886 22839682574144 run_lib.py:146] step: 140600, eval_loss: 1.32588e-01
I0216 11:23:46.111660 22839682574144 run_lib.py:133] step: 140650, training_loss: 1.12027e-01
I0216 11:24:03.811710 22839682574144 run_lib.py:133] step: 140700, training_loss: 1.13356e-01
I0216 11:24:03.969307 22839682574144 run_lib.py:146] step: 140700, eval_loss: 1.35535e-01
I0216 11:24:21.490582 22839682574144 run_lib.py:133] step: 140750, training_loss: 1.16647e-01
I0216 11:24:39.219588 22839682574144 run_lib.py:133] step: 140800, training_loss: 1.10630e-01
I0216 11:24:39.378285 22839682574144 run_lib.py:146] step: 140800, eval_loss: 1.33342e-01
I0216 11:24:56.873055 22839682574144 run_lib.py:133] step: 140850, training_loss: 1.15570e-01
I0216 11:25:14.380647 22839682574144 run_lib.py:133] step: 140900, training_loss: 1.15088e-01
I0216 11:25:14.537438 22839682574144 run_lib.py:146] step: 140900, eval_loss: 1.29674e-01
I0216 11:25:31.991949 22839682574144 run_lib.py:133] step: 140950, training_loss: 1.15300e-01
I0216 11:25:49.355702 22839682574144 run_lib.py:133] step: 141000, training_loss: 1.13732e-01
I0216 11:25:49.510992 22839682574144 run_lib.py:146] step: 141000, eval_loss: 1.32121e-01
I0216 11:26:06.765057 22839682574144 run_lib.py:133] step: 141050, training_loss: 1.12130e-01
I0216 11:26:24.217626 22839682574144 run_lib.py:133] step: 141100, training_loss: 1.13794e-01
I0216 11:26:24.374852 22839682574144 run_lib.py:146] step: 141100, eval_loss: 1.38290e-01
I0216 11:26:41.687105 22839682574144 run_lib.py:133] step: 141150, training_loss: 1.14064e-01
I0216 11:26:59.073784 22839682574144 run_lib.py:133] step: 141200, training_loss: 1.08813e-01
I0216 11:26:59.227038 22839682574144 run_lib.py:146] step: 141200, eval_loss: 1.30498e-01
I0216 11:27:16.792268 22839682574144 run_lib.py:133] step: 141250, training_loss: 1.14003e-01
I0216 11:27:34.348556 22839682574144 run_lib.py:133] step: 141300, training_loss: 1.11534e-01
I0216 11:27:34.512065 22839682574144 run_lib.py:146] step: 141300, eval_loss: 1.40022e-01
I0216 11:27:52.031484 22839682574144 run_lib.py:133] step: 141350, training_loss: 1.15939e-01
I0216 11:28:09.533293 22839682574144 run_lib.py:133] step: 141400, training_loss: 1.12838e-01
I0216 11:28:09.692115 22839682574144 run_lib.py:146] step: 141400, eval_loss: 1.35931e-01
I0216 11:28:27.414391 22839682574144 run_lib.py:133] step: 141450, training_loss: 1.10534e-01
I0216 11:28:44.974992 22839682574144 run_lib.py:133] step: 141500, training_loss: 1.12005e-01
I0216 11:28:45.130899 22839682574144 run_lib.py:146] step: 141500, eval_loss: 1.35569e-01
I0216 11:29:02.626358 22839682574144 run_lib.py:133] step: 141550, training_loss: 1.08680e-01
I0216 11:29:20.175654 22839682574144 run_lib.py:133] step: 141600, training_loss: 1.11818e-01
I0216 11:29:20.331902 22839682574144 run_lib.py:146] step: 141600, eval_loss: 1.33563e-01
I0216 11:29:38.061368 22839682574144 run_lib.py:133] step: 141650, training_loss: 1.12772e-01
I0216 11:29:55.583004 22839682574144 run_lib.py:133] step: 141700, training_loss: 1.09829e-01
I0216 11:29:55.736655 22839682574144 run_lib.py:146] step: 141700, eval_loss: 1.32852e-01
I0216 11:30:13.286407 22839682574144 run_lib.py:133] step: 141750, training_loss: 1.13117e-01
I0216 11:30:30.972909 22839682574144 run_lib.py:133] step: 141800, training_loss: 1.10347e-01
I0216 11:30:31.151479 22839682574144 run_lib.py:146] step: 141800, eval_loss: 1.34808e-01
I0216 11:30:48.666691 22839682574144 run_lib.py:133] step: 141850, training_loss: 1.12921e-01
I0216 11:31:06.397519 22839682574144 run_lib.py:133] step: 141900, training_loss: 1.11514e-01
I0216 11:31:06.559251 22839682574144 run_lib.py:146] step: 141900, eval_loss: 1.30551e-01
I0216 11:31:24.068864 22839682574144 run_lib.py:133] step: 141950, training_loss: 1.15029e-01
I0216 11:31:41.538784 22839682574144 run_lib.py:133] step: 142000, training_loss: 1.13361e-01
I0216 11:31:41.710048 22839682574144 run_lib.py:146] step: 142000, eval_loss: 1.33182e-01
I0216 11:31:59.381386 22839682574144 run_lib.py:133] step: 142050, training_loss: 1.08216e-01
I0216 11:32:16.889908 22839682574144 run_lib.py:133] step: 142100, training_loss: 1.13214e-01
I0216 11:32:17.043607 22839682574144 run_lib.py:146] step: 142100, eval_loss: 1.34046e-01
I0216 11:32:34.621014 22839682574144 run_lib.py:133] step: 142150, training_loss: 1.09786e-01
I0216 11:32:52.348555 22839682574144 run_lib.py:133] step: 142200, training_loss: 1.14346e-01
I0216 11:32:52.510238 22839682574144 run_lib.py:146] step: 142200, eval_loss: 1.31436e-01
I0216 11:33:09.998930 22839682574144 run_lib.py:133] step: 142250, training_loss: 1.10113e-01
I0216 11:33:27.477414 22839682574144 run_lib.py:133] step: 142300, training_loss: 1.09496e-01
I0216 11:33:27.637308 22839682574144 run_lib.py:146] step: 142300, eval_loss: 1.36178e-01
I0216 11:33:45.235935 22839682574144 run_lib.py:133] step: 142350, training_loss: 1.11547e-01
I0216 11:34:02.718860 22839682574144 run_lib.py:133] step: 142400, training_loss: 1.11685e-01
I0216 11:34:02.886169 22839682574144 run_lib.py:146] step: 142400, eval_loss: 1.34875e-01
I0216 11:34:20.408365 22839682574144 run_lib.py:133] step: 142450, training_loss: 1.09305e-01
I0216 11:34:37.945230 22839682574144 run_lib.py:133] step: 142500, training_loss: 1.08315e-01
I0216 11:34:38.101818 22839682574144 run_lib.py:146] step: 142500, eval_loss: 1.35232e-01
I0216 11:34:55.847148 22839682574144 run_lib.py:133] step: 142550, training_loss: 1.14160e-01
I0216 11:35:13.467586 22839682574144 run_lib.py:133] step: 142600, training_loss: 1.10006e-01
I0216 11:35:13.622902 22839682574144 run_lib.py:146] step: 142600, eval_loss: 1.33089e-01
I0216 11:35:31.086424 22839682574144 run_lib.py:133] step: 142650, training_loss: 1.10492e-01
I0216 11:35:48.605345 22839682574144 run_lib.py:133] step: 142700, training_loss: 1.12860e-01
I0216 11:35:48.779282 22839682574144 run_lib.py:146] step: 142700, eval_loss: 1.36159e-01
I0216 11:36:06.530451 22839682574144 run_lib.py:133] step: 142750, training_loss: 1.13178e-01
I0216 11:36:24.014431 22839682574144 run_lib.py:133] step: 142800, training_loss: 1.12544e-01
I0216 11:36:24.173743 22839682574144 run_lib.py:146] step: 142800, eval_loss: 1.33034e-01
I0216 11:36:41.708479 22839682574144 run_lib.py:133] step: 142850, training_loss: 1.12598e-01
I0216 11:36:59.367931 22839682574144 run_lib.py:133] step: 142900, training_loss: 1.08491e-01
I0216 11:36:59.541925 22839682574144 run_lib.py:146] step: 142900, eval_loss: 1.31154e-01
I0216 11:37:17.075844 22839682574144 run_lib.py:133] step: 142950, training_loss: 1.12315e-01
I0216 11:37:34.826029 22839682574144 run_lib.py:133] step: 143000, training_loss: 1.07832e-01
I0216 11:37:34.981858 22839682574144 run_lib.py:146] step: 143000, eval_loss: 1.31420e-01
I0216 11:37:52.507774 22839682574144 run_lib.py:133] step: 143050, training_loss: 1.07782e-01
I0216 11:38:10.019625 22839682574144 run_lib.py:133] step: 143100, training_loss: 1.16493e-01
I0216 11:38:10.176149 22839682574144 run_lib.py:146] step: 143100, eval_loss: 1.34281e-01
I0216 11:38:27.892832 22839682574144 run_lib.py:133] step: 143150, training_loss: 1.12977e-01
I0216 11:38:45.431562 22839682574144 run_lib.py:133] step: 143200, training_loss: 1.14174e-01
I0216 11:38:45.601417 22839682574144 run_lib.py:146] step: 143200, eval_loss: 1.30706e-01
I0216 11:39:03.145065 22839682574144 run_lib.py:133] step: 143250, training_loss: 1.08248e-01
I0216 11:39:20.849379 22839682574144 run_lib.py:133] step: 143300, training_loss: 1.14065e-01
I0216 11:39:21.006849 22839682574144 run_lib.py:146] step: 143300, eval_loss: 1.36313e-01
I0216 11:39:38.520457 22839682574144 run_lib.py:133] step: 143350, training_loss: 1.12712e-01
I0216 11:39:55.992075 22839682574144 run_lib.py:133] step: 143400, training_loss: 1.12590e-01
I0216 11:39:56.149829 22839682574144 run_lib.py:146] step: 143400, eval_loss: 1.36837e-01
I0216 11:40:13.743778 22839682574144 run_lib.py:133] step: 143450, training_loss: 1.09274e-01
I0216 11:40:31.252823 22839682574144 run_lib.py:133] step: 143500, training_loss: 1.16384e-01
I0216 11:40:31.417266 22839682574144 run_lib.py:146] step: 143500, eval_loss: 1.33024e-01
I0216 11:40:48.968955 22839682574144 run_lib.py:133] step: 143550, training_loss: 1.11852e-01
I0216 11:41:06.502265 22839682574144 run_lib.py:133] step: 143600, training_loss: 1.10866e-01
I0216 11:41:06.673109 22839682574144 run_lib.py:146] step: 143600, eval_loss: 1.26069e-01
I0216 11:41:24.408666 22839682574144 run_lib.py:133] step: 143650, training_loss: 1.14104e-01
I0216 11:41:42.004138 22839682574144 run_lib.py:133] step: 143700, training_loss: 1.12014e-01
I0216 11:41:42.163239 22839682574144 run_lib.py:146] step: 143700, eval_loss: 1.36373e-01
I0216 11:41:59.684178 22839682574144 run_lib.py:133] step: 143750, training_loss: 1.12180e-01
I0216 11:42:17.246636 22839682574144 run_lib.py:133] step: 143800, training_loss: 1.10647e-01
I0216 11:42:17.404346 22839682574144 run_lib.py:146] step: 143800, eval_loss: 1.32525e-01
I0216 11:42:35.096345 22839682574144 run_lib.py:133] step: 143850, training_loss: 1.08410e-01
I0216 11:42:52.642488 22839682574144 run_lib.py:133] step: 143900, training_loss: 1.12140e-01
I0216 11:42:52.800829 22839682574144 run_lib.py:146] step: 143900, eval_loss: 1.34924e-01
I0216 11:43:10.309897 22839682574144 run_lib.py:133] step: 143950, training_loss: 1.09270e-01
I0216 11:43:28.010428 22839682574144 run_lib.py:133] step: 144000, training_loss: 1.11438e-01
I0216 11:43:28.164423 22839682574144 run_lib.py:146] step: 144000, eval_loss: 1.32901e-01
I0216 11:43:45.732275 22839682574144 run_lib.py:133] step: 144050, training_loss: 1.16949e-01
I0216 11:44:03.503275 22839682574144 run_lib.py:133] step: 144100, training_loss: 1.07050e-01
I0216 11:44:03.660569 22839682574144 run_lib.py:146] step: 144100, eval_loss: 1.37196e-01
I0216 11:44:21.183190 22839682574144 run_lib.py:133] step: 144150, training_loss: 1.08804e-01
I0216 11:44:38.703167 22839682574144 run_lib.py:133] step: 144200, training_loss: 1.11152e-01
I0216 11:44:38.871103 22839682574144 run_lib.py:146] step: 144200, eval_loss: 1.36710e-01
I0216 11:44:56.579974 22839682574144 run_lib.py:133] step: 144250, training_loss: 1.11973e-01
I0216 11:45:14.169861 22839682574144 run_lib.py:133] step: 144300, training_loss: 1.11946e-01
I0216 11:45:14.327341 22839682574144 run_lib.py:146] step: 144300, eval_loss: 1.33096e-01
I0216 11:45:31.836899 22839682574144 run_lib.py:133] step: 144350, training_loss: 1.17080e-01
I0216 11:45:49.536817 22839682574144 run_lib.py:133] step: 144400, training_loss: 1.11493e-01
I0216 11:45:49.704120 22839682574144 run_lib.py:146] step: 144400, eval_loss: 1.33128e-01
I0216 11:46:07.220755 22839682574144 run_lib.py:133] step: 144450, training_loss: 1.17379e-01
I0216 11:46:24.759354 22839682574144 run_lib.py:133] step: 144500, training_loss: 1.11268e-01
I0216 11:46:24.914089 22839682574144 run_lib.py:146] step: 144500, eval_loss: 1.33889e-01
I0216 11:46:42.514875 22839682574144 run_lib.py:133] step: 144550, training_loss: 1.07801e-01
I0216 11:47:00.045532 22839682574144 run_lib.py:133] step: 144600, training_loss: 1.17461e-01
I0216 11:47:00.222089 22839682574144 run_lib.py:146] step: 144600, eval_loss: 1.35504e-01
I0216 11:47:17.746496 22839682574144 run_lib.py:133] step: 144650, training_loss: 1.13771e-01
I0216 11:47:35.312066 22839682574144 run_lib.py:133] step: 144700, training_loss: 1.14635e-01
I0216 11:47:35.470202 22839682574144 run_lib.py:146] step: 144700, eval_loss: 1.35886e-01
I0216 11:47:53.214740 22839682574144 run_lib.py:133] step: 144750, training_loss: 1.08056e-01
I0216 11:48:10.807027 22839682574144 run_lib.py:133] step: 144800, training_loss: 1.14631e-01
I0216 11:48:10.964027 22839682574144 run_lib.py:146] step: 144800, eval_loss: 1.34554e-01
I0216 11:48:28.501700 22839682574144 run_lib.py:133] step: 144850, training_loss: 1.15213e-01
I0216 11:48:46.124494 22839682574144 run_lib.py:133] step: 144900, training_loss: 1.12417e-01
I0216 11:48:46.289096 22839682574144 run_lib.py:146] step: 144900, eval_loss: 1.29822e-01
I0216 11:49:04.010241 22839682574144 run_lib.py:133] step: 144950, training_loss: 1.05633e-01
I0216 11:49:21.507754 22839682574144 run_lib.py:133] step: 145000, training_loss: 1.10892e-01
I0216 11:49:21.665166 22839682574144 run_lib.py:146] step: 145000, eval_loss: 1.36558e-01
I0216 11:49:39.188332 22839682574144 run_lib.py:133] step: 145050, training_loss: 1.12077e-01
I0216 11:49:56.870950 22839682574144 run_lib.py:133] step: 145100, training_loss: 1.12888e-01
I0216 11:49:57.043156 22839682574144 run_lib.py:146] step: 145100, eval_loss: 1.40305e-01
I0216 11:50:14.607187 22839682574144 run_lib.py:133] step: 145150, training_loss: 1.12258e-01
I0216 11:50:32.354875 22839682574144 run_lib.py:133] step: 145200, training_loss: 1.09405e-01
I0216 11:50:32.559314 22839682574144 run_lib.py:146] step: 145200, eval_loss: 1.30847e-01
I0216 11:50:50.051482 22839682574144 run_lib.py:133] step: 145250, training_loss: 1.14605e-01
I0216 11:51:07.516052 22839682574144 run_lib.py:133] step: 145300, training_loss: 1.12363e-01
I0216 11:51:07.673232 22839682574144 run_lib.py:146] step: 145300, eval_loss: 1.34279e-01
I0216 11:51:25.350065 22839682574144 run_lib.py:133] step: 145350, training_loss: 1.12728e-01
I0216 11:51:42.868126 22839682574144 run_lib.py:133] step: 145400, training_loss: 1.12649e-01
I0216 11:51:43.023814 22839682574144 run_lib.py:146] step: 145400, eval_loss: 1.34143e-01
I0216 11:52:00.532816 22839682574144 run_lib.py:133] step: 145450, training_loss: 1.13757e-01
I0216 11:52:18.237092 22839682574144 run_lib.py:133] step: 145500, training_loss: 1.10942e-01
I0216 11:52:18.395004 22839682574144 run_lib.py:146] step: 145500, eval_loss: 1.30791e-01
I0216 11:52:35.871046 22839682574144 run_lib.py:133] step: 145550, training_loss: 1.11011e-01
I0216 11:52:53.404963 22839682574144 run_lib.py:133] step: 145600, training_loss: 1.07605e-01
I0216 11:52:53.565214 22839682574144 run_lib.py:146] step: 145600, eval_loss: 1.33261e-01
I0216 11:53:11.182019 22839682574144 run_lib.py:133] step: 145650, training_loss: 1.11622e-01
I0216 11:53:28.732850 22839682574144 run_lib.py:133] step: 145700, training_loss: 1.09590e-01
I0216 11:53:28.891457 22839682574144 run_lib.py:146] step: 145700, eval_loss: 1.32544e-01
I0216 11:53:46.430176 22839682574144 run_lib.py:133] step: 145750, training_loss: 1.15160e-01
I0216 11:54:03.933216 22839682574144 run_lib.py:133] step: 145800, training_loss: 1.08236e-01
I0216 11:54:04.091169 22839682574144 run_lib.py:146] step: 145800, eval_loss: 1.32992e-01
I0216 11:54:21.816021 22839682574144 run_lib.py:133] step: 145850, training_loss: 1.12404e-01
I0216 11:54:39.473530 22839682574144 run_lib.py:133] step: 145900, training_loss: 1.12176e-01
I0216 11:54:39.629320 22839682574144 run_lib.py:146] step: 145900, eval_loss: 1.34781e-01
I0216 11:54:57.148782 22839682574144 run_lib.py:133] step: 145950, training_loss: 1.14265e-01
I0216 11:55:14.654280 22839682574144 run_lib.py:133] step: 146000, training_loss: 1.13177e-01
I0216 11:55:14.815294 22839682574144 run_lib.py:146] step: 146000, eval_loss: 1.34125e-01
I0216 11:55:32.570544 22839682574144 run_lib.py:133] step: 146050, training_loss: 1.12693e-01
I0216 11:55:50.104441 22839682574144 run_lib.py:133] step: 146100, training_loss: 1.12467e-01
I0216 11:55:50.260768 22839682574144 run_lib.py:146] step: 146100, eval_loss: 1.34330e-01
I0216 11:56:07.779961 22839682574144 run_lib.py:133] step: 146150, training_loss: 1.11799e-01
I0216 11:56:25.433516 22839682574144 run_lib.py:133] step: 146200, training_loss: 1.10608e-01
I0216 11:56:25.604183 22839682574144 run_lib.py:146] step: 146200, eval_loss: 1.36313e-01
I0216 11:56:43.154782 22839682574144 run_lib.py:133] step: 146250, training_loss: 1.11090e-01
I0216 11:57:00.891175 22839682574144 run_lib.py:133] step: 146300, training_loss: 1.06604e-01
I0216 11:57:01.046287 22839682574144 run_lib.py:146] step: 146300, eval_loss: 1.30261e-01
I0216 11:57:18.576615 22839682574144 run_lib.py:133] step: 146350, training_loss: 1.14814e-01
I0216 11:57:36.127254 22839682574144 run_lib.py:133] step: 146400, training_loss: 1.13947e-01
I0216 11:57:36.283052 22839682574144 run_lib.py:146] step: 146400, eval_loss: 1.39053e-01
I0216 11:57:53.974796 22839682574144 run_lib.py:133] step: 146450, training_loss: 1.10769e-01
I0216 11:58:11.505989 22839682574144 run_lib.py:133] step: 146500, training_loss: 1.09634e-01
I0216 11:58:11.680083 22839682574144 run_lib.py:146] step: 146500, eval_loss: 1.30313e-01
I0216 11:58:29.199924 22839682574144 run_lib.py:133] step: 146550, training_loss: 1.13550e-01
I0216 11:58:46.949896 22839682574144 run_lib.py:133] step: 146600, training_loss: 1.12247e-01
I0216 11:58:47.108511 22839682574144 run_lib.py:146] step: 146600, eval_loss: 1.35643e-01
I0216 11:59:04.627864 22839682574144 run_lib.py:133] step: 146650, training_loss: 1.15597e-01
I0216 11:59:22.142966 22839682574144 run_lib.py:133] step: 146700, training_loss: 1.13672e-01
I0216 11:59:22.300182 22839682574144 run_lib.py:146] step: 146700, eval_loss: 1.34308e-01
I0216 11:59:39.928442 22839682574144 run_lib.py:133] step: 146750, training_loss: 1.12747e-01
I0216 11:59:57.502392 22839682574144 run_lib.py:133] step: 146800, training_loss: 1.11281e-01
I0216 11:59:57.666759 22839682574144 run_lib.py:146] step: 146800, eval_loss: 1.31319e-01
I0216 12:00:15.232264 22839682574144 run_lib.py:133] step: 146850, training_loss: 1.12211e-01
I0216 12:00:32.749156 22839682574144 run_lib.py:133] step: 146900, training_loss: 1.12538e-01
I0216 12:00:32.912120 22839682574144 run_lib.py:146] step: 146900, eval_loss: 1.31599e-01
I0216 12:00:50.617996 22839682574144 run_lib.py:133] step: 146950, training_loss: 1.15711e-01
I0216 12:01:08.180490 22839682574144 run_lib.py:133] step: 147000, training_loss: 1.12378e-01
I0216 12:01:08.351208 22839682574144 run_lib.py:146] step: 147000, eval_loss: 1.30911e-01
I0216 12:01:25.876095 22839682574144 run_lib.py:133] step: 147050, training_loss: 1.13394e-01
I0216 12:01:43.387107 22839682574144 run_lib.py:133] step: 147100, training_loss: 1.14620e-01
I0216 12:01:43.545252 22839682574144 run_lib.py:146] step: 147100, eval_loss: 1.31272e-01
I0216 12:02:01.247443 22839682574144 run_lib.py:133] step: 147150, training_loss: 1.11909e-01
I0216 12:02:18.736723 22839682574144 run_lib.py:133] step: 147200, training_loss: 1.14765e-01
I0216 12:02:18.894284 22839682574144 run_lib.py:146] step: 147200, eval_loss: 1.35972e-01
I0216 12:02:36.424219 22839682574144 run_lib.py:133] step: 147250, training_loss: 1.11501e-01
I0216 12:02:54.126752 22839682574144 run_lib.py:133] step: 147300, training_loss: 1.07479e-01
I0216 12:02:54.290363 22839682574144 run_lib.py:146] step: 147300, eval_loss: 1.35244e-01
I0216 12:03:11.902583 22839682574144 run_lib.py:133] step: 147350, training_loss: 1.09417e-01
I0216 12:03:29.643099 22839682574144 run_lib.py:133] step: 147400, training_loss: 1.07646e-01
I0216 12:03:29.801179 22839682574144 run_lib.py:146] step: 147400, eval_loss: 1.31355e-01
I0216 12:03:47.351510 22839682574144 run_lib.py:133] step: 147450, training_loss: 1.11794e-01
I0216 12:04:04.881505 22839682574144 run_lib.py:133] step: 147500, training_loss: 1.13093e-01
I0216 12:04:05.041262 22839682574144 run_lib.py:146] step: 147500, eval_loss: 1.34988e-01
I0216 12:04:22.746136 22839682574144 run_lib.py:133] step: 147550, training_loss: 1.10702e-01
I0216 12:04:40.288220 22839682574144 run_lib.py:133] step: 147600, training_loss: 1.17590e-01
I0216 12:04:40.455540 22839682574144 run_lib.py:146] step: 147600, eval_loss: 1.33072e-01
I0216 12:04:57.976855 22839682574144 run_lib.py:133] step: 147650, training_loss: 1.10100e-01
I0216 12:05:15.731079 22839682574144 run_lib.py:133] step: 147700, training_loss: 1.08757e-01
I0216 12:05:15.889301 22839682574144 run_lib.py:146] step: 147700, eval_loss: 1.32283e-01
I0216 12:05:33.410694 22839682574144 run_lib.py:133] step: 147750, training_loss: 1.09385e-01
I0216 12:05:50.928517 22839682574144 run_lib.py:133] step: 147800, training_loss: 1.14863e-01
I0216 12:05:51.083055 22839682574144 run_lib.py:146] step: 147800, eval_loss: 1.32131e-01
I0216 12:06:08.691652 22839682574144 run_lib.py:133] step: 147850, training_loss: 1.09978e-01
I0216 12:06:26.226577 22839682574144 run_lib.py:133] step: 147900, training_loss: 1.12454e-01
I0216 12:06:26.393105 22839682574144 run_lib.py:146] step: 147900, eval_loss: 1.30425e-01
I0216 12:06:43.907119 22839682574144 run_lib.py:133] step: 147950, training_loss: 1.06438e-01
I0216 12:07:01.419409 22839682574144 run_lib.py:133] step: 148000, training_loss: 1.16652e-01
I0216 12:07:01.579230 22839682574144 run_lib.py:146] step: 148000, eval_loss: 1.38493e-01
I0216 12:07:19.294692 22839682574144 run_lib.py:133] step: 148050, training_loss: 1.09122e-01
I0216 12:07:36.852798 22839682574144 run_lib.py:133] step: 148100, training_loss: 1.07551e-01
I0216 12:07:37.013876 22839682574144 run_lib.py:146] step: 148100, eval_loss: 1.34269e-01
I0216 12:07:54.527772 22839682574144 run_lib.py:133] step: 148150, training_loss: 1.12758e-01
I0216 12:08:12.093734 22839682574144 run_lib.py:133] step: 148200, training_loss: 1.12294e-01
I0216 12:08:12.247936 22839682574144 run_lib.py:146] step: 148200, eval_loss: 1.31016e-01
I0216 12:08:29.962957 22839682574144 run_lib.py:133] step: 148250, training_loss: 1.12533e-01
I0216 12:08:47.480562 22839682574144 run_lib.py:133] step: 148300, training_loss: 1.09385e-01
I0216 12:08:47.635087 22839682574144 run_lib.py:146] step: 148300, eval_loss: 1.31408e-01
I0216 12:09:05.118352 22839682574144 run_lib.py:133] step: 148350, training_loss: 1.11892e-01
I0216 12:09:22.830594 22839682574144 run_lib.py:133] step: 148400, training_loss: 1.12566e-01
I0216 12:09:22.995870 22839682574144 run_lib.py:146] step: 148400, eval_loss: 1.30366e-01
I0216 12:09:40.491148 22839682574144 run_lib.py:133] step: 148450, training_loss: 1.10265e-01
I0216 12:09:58.205651 22839682574144 run_lib.py:133] step: 148500, training_loss: 1.11213e-01
I0216 12:09:58.365224 22839682574144 run_lib.py:146] step: 148500, eval_loss: 1.36859e-01
I0216 12:10:15.879514 22839682574144 run_lib.py:133] step: 148550, training_loss: 1.11291e-01
I0216 12:10:33.407942 22839682574144 run_lib.py:133] step: 148600, training_loss: 1.11731e-01
I0216 12:10:33.565051 22839682574144 run_lib.py:146] step: 148600, eval_loss: 1.34717e-01
I0216 12:10:51.238536 22839682574144 run_lib.py:133] step: 148650, training_loss: 1.10946e-01
I0216 12:11:08.761845 22839682574144 run_lib.py:133] step: 148700, training_loss: 1.12770e-01
I0216 12:11:08.918295 22839682574144 run_lib.py:146] step: 148700, eval_loss: 1.38044e-01
I0216 12:11:26.446010 22839682574144 run_lib.py:133] step: 148750, training_loss: 1.10723e-01
I0216 12:11:44.197844 22839682574144 run_lib.py:133] step: 148800, training_loss: 1.17347e-01
I0216 12:11:44.408010 22839682574144 run_lib.py:146] step: 148800, eval_loss: 1.35928e-01
I0216 12:12:01.891705 22839682574144 run_lib.py:133] step: 148850, training_loss: 1.12203e-01
I0216 12:12:19.389478 22839682574144 run_lib.py:133] step: 148900, training_loss: 1.13269e-01
I0216 12:12:19.557996 22839682574144 run_lib.py:146] step: 148900, eval_loss: 1.29947e-01
I0216 12:12:37.145645 22839682574144 run_lib.py:133] step: 148950, training_loss: 1.11968e-01
I0216 12:12:54.706068 22839682574144 run_lib.py:133] step: 149000, training_loss: 1.12625e-01
I0216 12:12:54.864248 22839682574144 run_lib.py:146] step: 149000, eval_loss: 1.35061e-01
I0216 12:13:12.390666 22839682574144 run_lib.py:133] step: 149050, training_loss: 1.11678e-01
I0216 12:13:29.882954 22839682574144 run_lib.py:133] step: 149100, training_loss: 1.10121e-01
I0216 12:13:30.041014 22839682574144 run_lib.py:146] step: 149100, eval_loss: 1.37100e-01
I0216 12:13:47.761286 22839682574144 run_lib.py:133] step: 149150, training_loss: 1.09064e-01
I0216 12:14:05.379508 22839682574144 run_lib.py:133] step: 149200, training_loss: 1.10730e-01
I0216 12:14:05.533095 22839682574144 run_lib.py:146] step: 149200, eval_loss: 1.31076e-01
I0216 12:14:23.034335 22839682574144 run_lib.py:133] step: 149250, training_loss: 1.12303e-01
I0216 12:14:40.568540 22839682574144 run_lib.py:133] step: 149300, training_loss: 1.12849e-01
I0216 12:14:40.744352 22839682574144 run_lib.py:146] step: 149300, eval_loss: 1.30368e-01
I0216 12:14:58.490801 22839682574144 run_lib.py:133] step: 149350, training_loss: 1.08089e-01
I0216 12:15:16.049253 22839682574144 run_lib.py:133] step: 149400, training_loss: 1.11455e-01
I0216 12:15:16.208283 22839682574144 run_lib.py:146] step: 149400, eval_loss: 1.36728e-01
I0216 12:15:33.758505 22839682574144 run_lib.py:133] step: 149450, training_loss: 1.12177e-01
I0216 12:15:51.462413 22839682574144 run_lib.py:133] step: 149500, training_loss: 1.09017e-01
I0216 12:15:51.629988 22839682574144 run_lib.py:146] step: 149500, eval_loss: 1.31709e-01
I0216 12:16:09.138136 22839682574144 run_lib.py:133] step: 149550, training_loss: 1.11563e-01
I0216 12:16:26.860837 22839682574144 run_lib.py:133] step: 149600, training_loss: 1.12364e-01
I0216 12:16:27.018377 22839682574144 run_lib.py:146] step: 149600, eval_loss: 1.34009e-01
I0216 12:16:44.562139 22839682574144 run_lib.py:133] step: 149650, training_loss: 1.13009e-01
I0216 12:17:02.103656 22839682574144 run_lib.py:133] step: 149700, training_loss: 1.09559e-01
I0216 12:17:02.259072 22839682574144 run_lib.py:146] step: 149700, eval_loss: 1.28221e-01
I0216 12:17:19.965843 22839682574144 run_lib.py:133] step: 149750, training_loss: 1.09653e-01
I0216 12:17:37.474972 22839682574144 run_lib.py:133] step: 149800, training_loss: 1.13628e-01
I0216 12:17:37.643053 22839682574144 run_lib.py:146] step: 149800, eval_loss: 1.34396e-01
I0216 12:17:55.194974 22839682574144 run_lib.py:133] step: 149850, training_loss: 1.10020e-01
I0216 12:18:12.926948 22839682574144 run_lib.py:133] step: 149900, training_loss: 1.09916e-01
I0216 12:18:13.086068 22839682574144 run_lib.py:146] step: 149900, eval_loss: 1.27719e-01
I0216 12:18:30.583084 22839682574144 run_lib.py:133] step: 149950, training_loss: 1.11145e-01
I0216 12:18:48.114779 22839682574144 run_lib.py:133] step: 150000, training_loss: 1.10491e-01
I0216 12:18:48.930731 22839682574144 run_lib.py:146] step: 150000, eval_loss: 1.34192e-01
I0216 12:19:09.256285 22839682574144 run_lib.py:133] step: 150050, training_loss: 1.11887e-01
I0216 12:19:26.949238 22839682574144 run_lib.py:133] step: 150100, training_loss: 1.06589e-01
I0216 12:19:27.116482 22839682574144 run_lib.py:146] step: 150100, eval_loss: 1.36732e-01
I0216 12:19:44.650516 22839682574144 run_lib.py:133] step: 150150, training_loss: 1.12036e-01
I0216 12:20:02.191077 22839682574144 run_lib.py:133] step: 150200, training_loss: 1.14285e-01
I0216 12:20:02.344769 22839682574144 run_lib.py:146] step: 150200, eval_loss: 1.34407e-01
I0216 12:20:19.824168 22839682574144 run_lib.py:133] step: 150250, training_loss: 1.09751e-01
I0216 12:20:37.568922 22839682574144 run_lib.py:133] step: 150300, training_loss: 1.09960e-01
I0216 12:20:37.726088 22839682574144 run_lib.py:146] step: 150300, eval_loss: 1.36241e-01
I0216 12:20:55.275231 22839682574144 run_lib.py:133] step: 150350, training_loss: 1.15010e-01
I0216 12:21:12.787486 22839682574144 run_lib.py:133] step: 150400, training_loss: 1.13395e-01
I0216 12:21:12.948163 22839682574144 run_lib.py:146] step: 150400, eval_loss: 1.35962e-01
I0216 12:21:30.673025 22839682574144 run_lib.py:133] step: 150450, training_loss: 1.09693e-01
I0216 12:21:48.165170 22839682574144 run_lib.py:133] step: 150500, training_loss: 1.11941e-01
I0216 12:21:48.323007 22839682574144 run_lib.py:146] step: 150500, eval_loss: 1.39028e-01
I0216 12:22:05.920326 22839682574144 run_lib.py:133] step: 150550, training_loss: 1.05262e-01
I0216 12:22:23.460376 22839682574144 run_lib.py:133] step: 150600, training_loss: 1.16039e-01
I0216 12:22:23.619084 22839682574144 run_lib.py:146] step: 150600, eval_loss: 1.32936e-01
I0216 12:22:41.151414 22839682574144 run_lib.py:133] step: 150650, training_loss: 1.09464e-01
I0216 12:22:58.678255 22839682574144 run_lib.py:133] step: 150700, training_loss: 1.12829e-01
I0216 12:22:58.834491 22839682574144 run_lib.py:146] step: 150700, eval_loss: 1.32993e-01
I0216 12:23:16.573727 22839682574144 run_lib.py:133] step: 150750, training_loss: 1.13323e-01
I0216 12:23:34.160780 22839682574144 run_lib.py:133] step: 150800, training_loss: 1.07236e-01
I0216 12:23:34.318699 22839682574144 run_lib.py:146] step: 150800, eval_loss: 1.33829e-01
I0216 12:23:51.791102 22839682574144 run_lib.py:133] step: 150850, training_loss: 1.11283e-01
I0216 12:24:09.327786 22839682574144 run_lib.py:133] step: 150900, training_loss: 1.09394e-01
I0216 12:24:09.503055 22839682574144 run_lib.py:146] step: 150900, eval_loss: 1.36157e-01
I0216 12:24:27.271898 22839682574144 run_lib.py:133] step: 150950, training_loss: 1.10853e-01
I0216 12:24:44.820718 22839682574144 run_lib.py:133] step: 151000, training_loss: 1.09930e-01
I0216 12:24:44.984793 22839682574144 run_lib.py:146] step: 151000, eval_loss: 1.35397e-01
I0216 12:25:02.534533 22839682574144 run_lib.py:133] step: 151050, training_loss: 1.12713e-01
I0216 12:25:20.292140 22839682574144 run_lib.py:133] step: 151100, training_loss: 1.10737e-01
I0216 12:25:20.448985 22839682574144 run_lib.py:146] step: 151100, eval_loss: 1.38291e-01
I0216 12:25:37.944966 22839682574144 run_lib.py:133] step: 151150, training_loss: 1.10401e-01
I0216 12:25:55.635483 22839682574144 run_lib.py:133] step: 151200, training_loss: 1.12109e-01
I0216 12:25:55.793318 22839682574144 run_lib.py:146] step: 151200, eval_loss: 1.35029e-01
I0216 12:26:13.320014 22839682574144 run_lib.py:133] step: 151250, training_loss: 1.10468e-01
I0216 12:26:30.837572 22839682574144 run_lib.py:133] step: 151300, training_loss: 1.09320e-01
I0216 12:26:30.995237 22839682574144 run_lib.py:146] step: 151300, eval_loss: 1.35074e-01
I0216 12:26:48.712731 22839682574144 run_lib.py:133] step: 151350, training_loss: 1.05705e-01
I0216 12:27:06.246119 22839682574144 run_lib.py:133] step: 151400, training_loss: 1.12655e-01
I0216 12:27:06.400653 22839682574144 run_lib.py:146] step: 151400, eval_loss: 1.32178e-01
I0216 12:27:23.920515 22839682574144 run_lib.py:133] step: 151450, training_loss: 1.17104e-01
I0216 12:27:41.443921 22839682574144 run_lib.py:133] step: 151500, training_loss: 1.12168e-01
I0216 12:27:41.609522 22839682574144 run_lib.py:146] step: 151500, eval_loss: 1.33999e-01
I0216 12:27:59.344856 22839682574144 run_lib.py:133] step: 151550, training_loss: 1.10168e-01
I0216 12:28:16.894314 22839682574144 run_lib.py:133] step: 151600, training_loss: 1.12685e-01
I0216 12:28:17.048879 22839682574144 run_lib.py:146] step: 151600, eval_loss: 1.32888e-01
I0216 12:28:34.667646 22839682574144 run_lib.py:133] step: 151650, training_loss: 1.11501e-01
I0216 12:28:52.186556 22839682574144 run_lib.py:133] step: 151700, training_loss: 1.13741e-01
I0216 12:28:52.342998 22839682574144 run_lib.py:146] step: 151700, eval_loss: 1.35367e-01
I0216 12:29:09.869438 22839682574144 run_lib.py:133] step: 151750, training_loss: 1.15483e-01
I0216 12:29:27.563702 22839682574144 run_lib.py:133] step: 151800, training_loss: 1.08277e-01
I0216 12:29:27.740051 22839682574144 run_lib.py:146] step: 151800, eval_loss: 1.35096e-01
I0216 12:29:45.484205 22839682574144 run_lib.py:133] step: 151850, training_loss: 1.12090e-01
I0216 12:30:03.089779 22839682574144 run_lib.py:133] step: 151900, training_loss: 1.12060e-01
I0216 12:30:03.247402 22839682574144 run_lib.py:146] step: 151900, eval_loss: 1.34651e-01
I0216 12:30:20.782132 22839682574144 run_lib.py:133] step: 151950, training_loss: 1.12079e-01
I0216 12:30:38.269352 22839682574144 run_lib.py:133] step: 152000, training_loss: 1.12713e-01
I0216 12:30:38.431258 22839682574144 run_lib.py:146] step: 152000, eval_loss: 1.34479e-01
I0216 12:30:56.093146 22839682574144 run_lib.py:133] step: 152050, training_loss: 1.10686e-01
I0216 12:31:13.651347 22839682574144 run_lib.py:133] step: 152100, training_loss: 1.12313e-01
I0216 12:31:13.806846 22839682574144 run_lib.py:146] step: 152100, eval_loss: 1.37887e-01
I0216 12:31:31.346020 22839682574144 run_lib.py:133] step: 152150, training_loss: 1.13681e-01
I0216 12:31:49.088100 22839682574144 run_lib.py:133] step: 152200, training_loss: 1.07303e-01
I0216 12:31:49.246042 22839682574144 run_lib.py:146] step: 152200, eval_loss: 1.28951e-01
I0216 12:32:06.778276 22839682574144 run_lib.py:133] step: 152250, training_loss: 1.14507e-01
I0216 12:32:24.462995 22839682574144 run_lib.py:133] step: 152300, training_loss: 1.15121e-01
I0216 12:32:24.622298 22839682574144 run_lib.py:146] step: 152300, eval_loss: 1.37265e-01
I0216 12:32:42.155402 22839682574144 run_lib.py:133] step: 152350, training_loss: 1.11229e-01
I0216 12:32:59.710852 22839682574144 run_lib.py:133] step: 152400, training_loss: 1.13668e-01
I0216 12:32:59.875383 22839682574144 run_lib.py:146] step: 152400, eval_loss: 1.31516e-01
I0216 12:33:17.656538 22839682574144 run_lib.py:133] step: 152450, training_loss: 1.07949e-01
I0216 12:33:35.206985 22839682574144 run_lib.py:133] step: 152500, training_loss: 1.12832e-01
I0216 12:33:35.368752 22839682574144 run_lib.py:146] step: 152500, eval_loss: 1.39800e-01
I0216 12:33:52.889215 22839682574144 run_lib.py:133] step: 152550, training_loss: 1.11132e-01
I0216 12:34:10.549263 22839682574144 run_lib.py:133] step: 152600, training_loss: 1.08094e-01
I0216 12:34:10.703105 22839682574144 run_lib.py:146] step: 152600, eval_loss: 1.31653e-01
I0216 12:34:28.271635 22839682574144 run_lib.py:133] step: 152650, training_loss: 1.10732e-01
I0216 12:34:45.844327 22839682574144 run_lib.py:133] step: 152700, training_loss: 1.12948e-01
I0216 12:34:46.009689 22839682574144 run_lib.py:146] step: 152700, eval_loss: 1.33699e-01
I0216 12:35:03.658630 22839682574144 run_lib.py:133] step: 152750, training_loss: 1.09727e-01
I0216 12:35:21.193477 22839682574144 run_lib.py:133] step: 152800, training_loss: 1.12611e-01
I0216 12:35:21.354376 22839682574144 run_lib.py:146] step: 152800, eval_loss: 1.34289e-01
I0216 12:35:38.878412 22839682574144 run_lib.py:133] step: 152850, training_loss: 1.09029e-01
I0216 12:35:56.405607 22839682574144 run_lib.py:133] step: 152900, training_loss: 1.11741e-01
I0216 12:35:56.577755 22839682574144 run_lib.py:146] step: 152900, eval_loss: 1.32987e-01
I0216 12:36:14.266064 22839682574144 run_lib.py:133] step: 152950, training_loss: 1.13845e-01
I0216 12:36:31.928463 22839682574144 run_lib.py:133] step: 153000, training_loss: 1.09740e-01
I0216 12:36:32.084326 22839682574144 run_lib.py:146] step: 153000, eval_loss: 1.37461e-01
I0216 12:36:49.598293 22839682574144 run_lib.py:133] step: 153050, training_loss: 1.12024e-01
I0216 12:37:07.132666 22839682574144 run_lib.py:133] step: 153100, training_loss: 1.12386e-01
I0216 12:37:07.287005 22839682574144 run_lib.py:146] step: 153100, eval_loss: 1.32983e-01
I0216 12:37:25.008744 22839682574144 run_lib.py:133] step: 153150, training_loss: 1.09864e-01
I0216 12:37:42.521023 22839682574144 run_lib.py:133] step: 153200, training_loss: 1.11172e-01
I0216 12:37:42.695021 22839682574144 run_lib.py:146] step: 153200, eval_loss: 1.30308e-01
I0216 12:38:00.251209 22839682574144 run_lib.py:133] step: 153250, training_loss: 1.08766e-01
I0216 12:38:17.994446 22839682574144 run_lib.py:133] step: 153300, training_loss: 1.10056e-01
I0216 12:38:18.154079 22839682574144 run_lib.py:146] step: 153300, eval_loss: 1.32909e-01
I0216 12:38:35.654698 22839682574144 run_lib.py:133] step: 153350, training_loss: 1.13405e-01
I0216 12:38:53.320737 22839682574144 run_lib.py:133] step: 153400, training_loss: 1.11128e-01
I0216 12:38:53.480943 22839682574144 run_lib.py:146] step: 153400, eval_loss: 1.34945e-01
I0216 12:39:10.990953 22839682574144 run_lib.py:133] step: 153450, training_loss: 1.10753e-01
I0216 12:39:28.551763 22839682574144 run_lib.py:133] step: 153500, training_loss: 1.13473e-01
I0216 12:39:28.709240 22839682574144 run_lib.py:146] step: 153500, eval_loss: 1.34346e-01
I0216 12:39:46.435245 22839682574144 run_lib.py:133] step: 153550, training_loss: 1.09927e-01
I0216 12:40:03.964242 22839682574144 run_lib.py:133] step: 153600, training_loss: 1.12845e-01
I0216 12:40:04.121082 22839682574144 run_lib.py:146] step: 153600, eval_loss: 1.33675e-01
I0216 12:40:21.632406 22839682574144 run_lib.py:133] step: 153650, training_loss: 1.11165e-01
I0216 12:40:39.350374 22839682574144 run_lib.py:133] step: 153700, training_loss: 1.11776e-01
I0216 12:40:39.512310 22839682574144 run_lib.py:146] step: 153700, eval_loss: 1.31238e-01
I0216 12:40:57.127084 22839682574144 run_lib.py:133] step: 153750, training_loss: 1.06601e-01
I0216 12:41:14.662694 22839682574144 run_lib.py:133] step: 153800, training_loss: 1.12784e-01
I0216 12:41:14.826323 22839682574144 run_lib.py:146] step: 153800, eval_loss: 1.29493e-01
I0216 12:41:32.466073 22839682574144 run_lib.py:133] step: 153850, training_loss: 1.08536e-01
I0216 12:41:49.996860 22839682574144 run_lib.py:133] step: 153900, training_loss: 1.14020e-01
I0216 12:41:50.154787 22839682574144 run_lib.py:146] step: 153900, eval_loss: 1.37544e-01
I0216 12:42:07.670835 22839682574144 run_lib.py:133] step: 153950, training_loss: 1.10052e-01
I0216 12:42:25.219097 22839682574144 run_lib.py:133] step: 154000, training_loss: 1.13966e-01
I0216 12:42:25.375351 22839682574144 run_lib.py:146] step: 154000, eval_loss: 1.30340e-01
I0216 12:42:43.120912 22839682574144 run_lib.py:133] step: 154050, training_loss: 1.09658e-01
I0216 12:43:00.761330 22839682574144 run_lib.py:133] step: 154100, training_loss: 1.13699e-01
I0216 12:43:00.919054 22839682574144 run_lib.py:146] step: 154100, eval_loss: 1.29175e-01
I0216 12:43:18.434030 22839682574144 run_lib.py:133] step: 154150, training_loss: 1.10155e-01
I0216 12:43:35.967342 22839682574144 run_lib.py:133] step: 154200, training_loss: 1.12435e-01
I0216 12:43:36.136150 22839682574144 run_lib.py:146] step: 154200, eval_loss: 1.36278e-01
I0216 12:43:53.838721 22839682574144 run_lib.py:133] step: 154250, training_loss: 1.14604e-01
I0216 12:44:11.369068 22839682574144 run_lib.py:133] step: 154300, training_loss: 1.13493e-01
I0216 12:44:11.534208 22839682574144 run_lib.py:146] step: 154300, eval_loss: 1.34370e-01
I0216 12:44:29.061804 22839682574144 run_lib.py:133] step: 154350, training_loss: 1.08118e-01
I0216 12:44:46.794901 22839682574144 run_lib.py:133] step: 154400, training_loss: 1.17160e-01
I0216 12:44:46.953011 22839682574144 run_lib.py:146] step: 154400, eval_loss: 1.37051e-01
I0216 12:45:04.473462 22839682574144 run_lib.py:133] step: 154450, training_loss: 1.11807e-01
I0216 12:45:22.135493 22839682574144 run_lib.py:133] step: 154500, training_loss: 1.16151e-01
I0216 12:45:22.289726 22839682574144 run_lib.py:146] step: 154500, eval_loss: 1.32994e-01
I0216 12:45:39.838496 22839682574144 run_lib.py:133] step: 154550, training_loss: 1.09970e-01
I0216 12:45:57.356911 22839682574144 run_lib.py:133] step: 154600, training_loss: 1.10846e-01
I0216 12:45:57.525329 22839682574144 run_lib.py:146] step: 154600, eval_loss: 1.35666e-01
I0216 12:46:15.280532 22839682574144 run_lib.py:133] step: 154650, training_loss: 1.08560e-01
I0216 12:46:32.820369 22839682574144 run_lib.py:133] step: 154700, training_loss: 1.11621e-01
I0216 12:46:33.152963 22839682574144 run_lib.py:146] step: 154700, eval_loss: 1.34364e-01
I0216 12:46:50.676218 22839682574144 run_lib.py:133] step: 154750, training_loss: 1.09659e-01
I0216 12:47:08.315165 22839682574144 run_lib.py:133] step: 154800, training_loss: 1.09920e-01
I0216 12:47:08.473243 22839682574144 run_lib.py:146] step: 154800, eval_loss: 1.36214e-01
I0216 12:47:25.972489 22839682574144 run_lib.py:133] step: 154850, training_loss: 1.10982e-01
I0216 12:47:43.535657 22839682574144 run_lib.py:133] step: 154900, training_loss: 1.11778e-01
I0216 12:47:43.699938 22839682574144 run_lib.py:146] step: 154900, eval_loss: 1.31628e-01
I0216 12:48:01.377838 22839682574144 run_lib.py:133] step: 154950, training_loss: 1.11301e-01
I0216 12:48:18.875008 22839682574144 run_lib.py:133] step: 155000, training_loss: 1.11665e-01
I0216 12:48:19.030082 22839682574144 run_lib.py:146] step: 155000, eval_loss: 1.33652e-01
I0216 12:48:36.557738 22839682574144 run_lib.py:133] step: 155050, training_loss: 1.11060e-01
I0216 12:48:54.107924 22839682574144 run_lib.py:133] step: 155100, training_loss: 1.13183e-01
I0216 12:48:54.268408 22839682574144 run_lib.py:146] step: 155100, eval_loss: 1.35455e-01
I0216 12:49:11.928927 22839682574144 run_lib.py:133] step: 155150, training_loss: 1.08889e-01
I0216 12:49:29.614383 22839682574144 run_lib.py:133] step: 155200, training_loss: 1.09376e-01
I0216 12:49:29.772083 22839682574144 run_lib.py:146] step: 155200, eval_loss: 1.42594e-01
I0216 12:49:47.304406 22839682574144 run_lib.py:133] step: 155250, training_loss: 1.13145e-01
I0216 12:50:04.815065 22839682574144 run_lib.py:133] step: 155300, training_loss: 1.11941e-01
I0216 12:50:04.975158 22839682574144 run_lib.py:146] step: 155300, eval_loss: 1.35449e-01
I0216 12:50:22.648482 22839682574144 run_lib.py:133] step: 155350, training_loss: 1.10860e-01
I0216 12:50:40.166531 22839682574144 run_lib.py:133] step: 155400, training_loss: 1.08591e-01
I0216 12:50:40.321273 22839682574144 run_lib.py:146] step: 155400, eval_loss: 1.33973e-01
