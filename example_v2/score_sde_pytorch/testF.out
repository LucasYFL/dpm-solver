1
WARNING:tensorflow:From /home/yifulu/.conda/envs/dpm/lib/python3.9/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.

W0209 21:52:00.588532 22509476222784 utils.py:10] No checkpoint found at experiments/dpm_fewer/checkpoints-meta/checkpoint.pth. Returned the same state as input
I0209 21:52:00.592412 22509476222784 xla_bridge.py:355] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0209 21:52:00.592614 22509476222784 xla_bridge.py:355] Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0209 21:52:00.592692 22509476222784 xla_bridge.py:355] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0209 21:52:00.593471 22509476222784 xla_bridge.py:355] Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.
I0209 21:52:00.593593 22509476222784 xla_bridge.py:355] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
W0209 21:52:00.593685 22509476222784 xla_bridge.py:362] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0209 21:52:00.595899 22509476222784 dataset_info.py:358] Load dataset info from /home/yifulu/tensorflow_datasets/cifar10/3.0.2
W0209 21:52:00.598267 22509476222784 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
W0209 21:52:00.598382 22509476222784 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
I0209 21:52:00.598524 22509476222784 dataset_builder.py:351] Reusing dataset cifar10 (/home/yifulu/tensorflow_datasets/cifar10/3.0.2)
I0209 21:52:00.598627 22509476222784 logging_logger.py:35] Constructing tf.data.Dataset cifar10 for split train, from /home/yifulu/tensorflow_datasets/cifar10/3.0.2
W0209 21:52:00.780400 22509476222784 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
W0209 21:52:00.780648 22509476222784 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
I0209 21:52:00.780790 22509476222784 dataset_builder.py:351] Reusing dataset cifar10 (/home/yifulu/tensorflow_datasets/cifar10/3.0.2)
I0209 21:52:00.780888 22509476222784 logging_logger.py:35] Constructing tf.data.Dataset cifar10 for split test, from /home/yifulu/tensorflow_datasets/cifar10/3.0.2
I0209 21:52:00.898777 22509476222784 losses.py:57] Sde loss
I0209 21:52:00.899034 22509476222784 losses.py:59] Fewer: 1
I0209 21:52:00.899165 22509476222784 losses.py:68] fewer step set
I0209 21:52:00.899245 22509476222784 losses.py:57] Sde loss
I0209 21:52:00.899310 22509476222784 losses.py:59] Fewer: 1
I0209 21:52:00.899387 22509476222784 losses.py:68] fewer step set
I0209 21:52:00.899524 22509476222784 run_lib.py:123] Starting training loop at step 0.
I0209 21:52:09.983129 22509476222784 run_lib.py:133] step: 0, training_loss: 1.00004e+00
I0209 21:52:11.599703 22509476222784 run_lib.py:146] step: 0, eval_loss: 1.00101e+00
I0209 21:52:32.139978 22509476222784 run_lib.py:133] step: 50, training_loss: 9.90149e-01
I0209 21:52:52.967980 22509476222784 run_lib.py:133] step: 100, training_loss: 9.57616e-01
I0209 21:52:53.136300 22509476222784 run_lib.py:146] step: 100, eval_loss: 9.65566e-01
I0209 21:53:13.676102 22509476222784 run_lib.py:133] step: 150, training_loss: 8.95289e-01
I0209 21:53:32.272247 22509476222784 run_lib.py:133] step: 200, training_loss: 8.05763e-01
I0209 21:53:32.439685 22509476222784 run_lib.py:146] step: 200, eval_loss: 8.42077e-01
I0209 21:53:51.172888 22509476222784 run_lib.py:133] step: 250, training_loss: 7.10466e-01
I0209 21:54:09.654950 22509476222784 run_lib.py:133] step: 300, training_loss: 6.04283e-01
I0209 21:54:09.822709 22509476222784 run_lib.py:146] step: 300, eval_loss: 6.62230e-01
I0209 21:54:28.539347 22509476222784 run_lib.py:133] step: 350, training_loss: 4.98594e-01
I0209 21:54:47.066704 22509476222784 run_lib.py:133] step: 400, training_loss: 3.78482e-01
I0209 21:54:47.232264 22509476222784 run_lib.py:146] step: 400, eval_loss: 4.61699e-01
I0209 21:55:05.715380 22509476222784 run_lib.py:133] step: 450, training_loss: 2.89747e-01
I0209 21:55:24.293905 22509476222784 run_lib.py:133] step: 500, training_loss: 1.94391e-01
I0209 21:55:24.459698 22509476222784 run_lib.py:146] step: 500, eval_loss: 2.65886e-01
I0209 21:55:43.148600 22509476222784 run_lib.py:133] step: 550, training_loss: 1.21039e-01
I0209 21:56:01.692136 22509476222784 run_lib.py:133] step: 600, training_loss: 9.31287e-02
I0209 21:56:01.894650 22509476222784 run_lib.py:146] step: 600, eval_loss: 1.14285e-01
I0209 21:56:20.509147 22509476222784 run_lib.py:133] step: 650, training_loss: 5.61990e-02
I0209 21:56:39.005857 22509476222784 run_lib.py:133] step: 700, training_loss: 9.39391e-02
I0209 21:56:39.411847 22509476222784 run_lib.py:146] step: 700, eval_loss: 7.65625e-02
I0209 21:56:58.145074 22509476222784 run_lib.py:133] step: 750, training_loss: 6.60345e-02
I0209 21:57:16.688248 22509476222784 run_lib.py:133] step: 800, training_loss: 7.38784e-02
I0209 21:57:16.882533 22509476222784 run_lib.py:146] step: 800, eval_loss: 4.71598e-02
I0209 21:57:35.526246 22509476222784 run_lib.py:133] step: 850, training_loss: 5.88075e-02
I0209 21:57:54.106873 22509476222784 run_lib.py:133] step: 900, training_loss: 7.00827e-02
I0209 21:57:54.331552 22509476222784 run_lib.py:146] step: 900, eval_loss: 5.51698e-02
I0209 21:58:13.084269 22509476222784 run_lib.py:133] step: 950, training_loss: 5.96994e-02
I0209 21:58:31.604725 22509476222784 run_lib.py:133] step: 1000, training_loss: 6.04408e-02
I0209 21:58:31.805421 22509476222784 run_lib.py:146] step: 1000, eval_loss: 6.69475e-02
I0209 21:58:50.335655 22509476222784 run_lib.py:133] step: 1050, training_loss: 6.15133e-02
I0209 21:59:09.015933 22509476222784 run_lib.py:133] step: 1100, training_loss: 6.69352e-02
I0209 21:59:09.211167 22509476222784 run_lib.py:146] step: 1100, eval_loss: 6.61052e-02
I0209 21:59:27.823291 22509476222784 run_lib.py:133] step: 1150, training_loss: 6.44292e-02
I0209 21:59:46.521145 22509476222784 run_lib.py:133] step: 1200, training_loss: 4.26322e-02
I0209 21:59:46.723836 22509476222784 run_lib.py:146] step: 1200, eval_loss: 4.24524e-02
I0209 22:00:05.223054 22509476222784 run_lib.py:133] step: 1250, training_loss: 5.65180e-02
I0209 22:00:23.733015 22509476222784 run_lib.py:133] step: 1300, training_loss: 4.91422e-02
I0209 22:00:23.896568 22509476222784 run_lib.py:146] step: 1300, eval_loss: 5.13675e-02
I0209 22:00:42.507822 22509476222784 run_lib.py:133] step: 1350, training_loss: 4.51136e-02
I0209 22:01:01.035247 22509476222784 run_lib.py:133] step: 1400, training_loss: 6.27060e-02
I0209 22:01:01.218583 22509476222784 run_lib.py:146] step: 1400, eval_loss: 3.45039e-02
I0209 22:01:19.783180 22509476222784 run_lib.py:133] step: 1450, training_loss: 5.93597e-02
I0209 22:01:38.599184 22509476222784 run_lib.py:133] step: 1500, training_loss: 4.93591e-02
I0209 22:01:38.769038 22509476222784 run_lib.py:146] step: 1500, eval_loss: 3.42443e-02
I0209 22:01:57.312789 22509476222784 run_lib.py:133] step: 1550, training_loss: 3.49457e-02
I0209 22:02:16.120954 22509476222784 run_lib.py:133] step: 1600, training_loss: 6.15610e-02
I0209 22:02:16.290669 22509476222784 run_lib.py:146] step: 1600, eval_loss: 5.09193e-02
I0209 22:02:34.789526 22509476222784 run_lib.py:133] step: 1650, training_loss: 4.74660e-02
I0209 22:02:53.411441 22509476222784 run_lib.py:133] step: 1700, training_loss: 6.13736e-02
I0209 22:02:53.579788 22509476222784 run_lib.py:146] step: 1700, eval_loss: 4.41747e-02
I0209 22:03:12.124522 22509476222784 run_lib.py:133] step: 1750, training_loss: 5.21242e-02
I0209 22:03:30.641881 22509476222784 run_lib.py:133] step: 1800, training_loss: 4.71479e-02
I0209 22:03:30.806730 22509476222784 run_lib.py:146] step: 1800, eval_loss: 5.94122e-02
I0209 22:03:49.416186 22509476222784 run_lib.py:133] step: 1850, training_loss: 5.69740e-02
I0209 22:04:08.030001 22509476222784 run_lib.py:133] step: 1900, training_loss: 5.23989e-02
I0209 22:04:08.206543 22509476222784 run_lib.py:146] step: 1900, eval_loss: 5.13383e-02
I0209 22:04:26.728501 22509476222784 run_lib.py:133] step: 1950, training_loss: 4.28977e-02
I0209 22:04:45.241536 22509476222784 run_lib.py:133] step: 2000, training_loss: 4.78980e-02
I0209 22:04:45.410703 22509476222784 run_lib.py:146] step: 2000, eval_loss: 4.99041e-02
I0209 22:05:04.064779 22509476222784 run_lib.py:133] step: 2050, training_loss: 4.80473e-02
I0209 22:05:22.593855 22509476222784 run_lib.py:133] step: 2100, training_loss: 4.41840e-02
I0209 22:05:22.755492 22509476222784 run_lib.py:146] step: 2100, eval_loss: 4.67391e-02
I0209 22:05:41.272446 22509476222784 run_lib.py:133] step: 2150, training_loss: 6.33071e-02
I0209 22:05:59.873343 22509476222784 run_lib.py:133] step: 2200, training_loss: 5.87693e-02
I0209 22:06:00.040883 22509476222784 run_lib.py:146] step: 2200, eval_loss: 5.72795e-02
I0209 22:06:18.738117 22509476222784 run_lib.py:133] step: 2250, training_loss: 4.29092e-02
I0209 22:06:37.291209 22509476222784 run_lib.py:133] step: 2300, training_loss: 3.73933e-02
I0209 22:06:37.460688 22509476222784 run_lib.py:146] step: 2300, eval_loss: 5.38141e-02
I0209 22:06:56.073443 22509476222784 run_lib.py:133] step: 2350, training_loss: 6.51888e-02
I0209 22:07:14.578949 22509476222784 run_lib.py:133] step: 2400, training_loss: 5.56294e-02
I0209 22:07:14.753801 22509476222784 run_lib.py:146] step: 2400, eval_loss: 5.03740e-02
I0209 22:07:33.396670 22509476222784 run_lib.py:133] step: 2450, training_loss: 6.81676e-02
I0209 22:07:51.960249 22509476222784 run_lib.py:133] step: 2500, training_loss: 6.49418e-02
I0209 22:07:52.153403 22509476222784 run_lib.py:146] step: 2500, eval_loss: 6.21849e-02
I0209 22:08:10.653253 22509476222784 run_lib.py:133] step: 2550, training_loss: 6.18611e-02
I0209 22:08:29.265307 22509476222784 run_lib.py:133] step: 2600, training_loss: 4.74701e-02
I0209 22:08:29.475371 22509476222784 run_lib.py:146] step: 2600, eval_loss: 5.19142e-02
I0209 22:08:47.947679 22509476222784 run_lib.py:133] step: 2650, training_loss: 5.45533e-02
I0209 22:09:06.644258 22509476222784 run_lib.py:133] step: 2700, training_loss: 5.66236e-02
I0209 22:09:06.846870 22509476222784 run_lib.py:146] step: 2700, eval_loss: 4.36072e-02
I0209 22:09:25.355194 22509476222784 run_lib.py:133] step: 2750, training_loss: 4.62430e-02
I0209 22:09:43.879254 22509476222784 run_lib.py:133] step: 2800, training_loss: 4.27427e-02
I0209 22:09:44.062673 22509476222784 run_lib.py:146] step: 2800, eval_loss: 5.01089e-02
I0209 22:10:02.718504 22509476222784 run_lib.py:133] step: 2850, training_loss: 5.67837e-02
I0209 22:10:21.200463 22509476222784 run_lib.py:133] step: 2900, training_loss: 4.70971e-02
I0209 22:10:21.410481 22509476222784 run_lib.py:146] step: 2900, eval_loss: 4.44429e-02
I0209 22:10:39.910557 22509476222784 run_lib.py:133] step: 2950, training_loss: 5.26198e-02
I0209 22:10:58.413997 22509476222784 run_lib.py:133] step: 3000, training_loss: 5.39142e-02
I0209 22:10:58.633906 22509476222784 run_lib.py:146] step: 3000, eval_loss: 4.45342e-02
I0209 22:11:17.322619 22509476222784 run_lib.py:133] step: 3050, training_loss: 4.95613e-02
I0209 22:11:35.829753 22509476222784 run_lib.py:133] step: 3100, training_loss: 5.51969e-02
I0209 22:11:36.012433 22509476222784 run_lib.py:146] step: 3100, eval_loss: 5.13069e-02
I0209 22:11:54.528806 22509476222784 run_lib.py:133] step: 3150, training_loss: 5.63549e-02
I0209 22:12:13.018491 22509476222784 run_lib.py:133] step: 3200, training_loss: 5.75710e-02
I0209 22:12:13.223929 22509476222784 run_lib.py:146] step: 3200, eval_loss: 5.65117e-02
I0209 22:12:31.788200 22509476222784 run_lib.py:133] step: 3250, training_loss: 4.58143e-02
I0209 22:12:50.322911 22509476222784 run_lib.py:133] step: 3300, training_loss: 6.05922e-02
I0209 22:12:50.532814 22509476222784 run_lib.py:146] step: 3300, eval_loss: 5.67378e-02
I0209 22:13:09.173817 22509476222784 run_lib.py:133] step: 3350, training_loss: 4.84130e-02
I0209 22:13:27.763647 22509476222784 run_lib.py:133] step: 3400, training_loss: 4.74930e-02
I0209 22:13:27.956047 22509476222784 run_lib.py:146] step: 3400, eval_loss: 4.69975e-02
I0209 22:13:46.372590 22509476222784 run_lib.py:133] step: 3450, training_loss: 4.60148e-02
I0209 22:14:04.821191 22509476222784 run_lib.py:133] step: 3500, training_loss: 4.72669e-02
I0209 22:14:04.982601 22509476222784 run_lib.py:146] step: 3500, eval_loss: 5.48104e-02
I0209 22:14:23.596422 22509476222784 run_lib.py:133] step: 3550, training_loss: 5.12416e-02
I0209 22:14:42.068407 22509476222784 run_lib.py:133] step: 3600, training_loss: 4.40579e-02
I0209 22:14:42.284624 22509476222784 run_lib.py:146] step: 3600, eval_loss: 5.53417e-02
I0209 22:15:00.930364 22509476222784 run_lib.py:133] step: 3650, training_loss: 3.52414e-02
I0209 22:15:19.429686 22509476222784 run_lib.py:133] step: 3700, training_loss: 4.10136e-02
I0209 22:15:19.611569 22509476222784 run_lib.py:146] step: 3700, eval_loss: 3.77052e-02
I0209 22:15:38.269753 22509476222784 run_lib.py:133] step: 3750, training_loss: 4.96381e-02
I0209 22:15:56.735323 22509476222784 run_lib.py:133] step: 3800, training_loss: 4.77046e-02
I0209 22:15:56.898510 22509476222784 run_lib.py:146] step: 3800, eval_loss: 5.10215e-02
I0209 22:16:15.550141 22509476222784 run_lib.py:133] step: 3850, training_loss: 4.71297e-02
I0209 22:16:34.025029 22509476222784 run_lib.py:133] step: 3900, training_loss: 6.58304e-02
I0209 22:16:34.188271 22509476222784 run_lib.py:146] step: 3900, eval_loss: 4.43667e-02
I0209 22:16:52.636294 22509476222784 run_lib.py:133] step: 3950, training_loss: 5.74525e-02
I0209 22:17:11.294262 22509476222784 run_lib.py:133] step: 4000, training_loss: 3.52925e-02
I0209 22:17:11.456198 22509476222784 run_lib.py:146] step: 4000, eval_loss: 5.25169e-02
I0209 22:17:29.943653 22509476222784 run_lib.py:133] step: 4050, training_loss: 4.43384e-02
I0209 22:17:48.458066 22509476222784 run_lib.py:133] step: 4100, training_loss: 5.80096e-02
I0209 22:17:48.654949 22509476222784 run_lib.py:146] step: 4100, eval_loss: 4.30561e-02
I0209 22:18:07.312035 22509476222784 run_lib.py:133] step: 4150, training_loss: 5.22428e-02
I0209 22:18:25.924887 22509476222784 run_lib.py:133] step: 4200, training_loss: 5.29411e-02
I0209 22:18:26.219663 22509476222784 run_lib.py:146] step: 4200, eval_loss: 5.52568e-02
I0209 22:18:44.634854 22509476222784 run_lib.py:133] step: 4250, training_loss: 5.48862e-02
I0209 22:19:03.120747 22509476222784 run_lib.py:133] step: 4300, training_loss: 5.53512e-02
I0209 22:19:03.316517 22509476222784 run_lib.py:146] step: 4300, eval_loss: 6.28257e-02
I0209 22:19:21.839772 22509476222784 run_lib.py:133] step: 4350, training_loss: 6.09711e-02
I0209 22:19:40.586206 22509476222784 run_lib.py:133] step: 4400, training_loss: 3.84994e-02
I0209 22:19:40.787876 22509476222784 run_lib.py:146] step: 4400, eval_loss: 6.10012e-02
I0209 22:19:59.280448 22509476222784 run_lib.py:133] step: 4450, training_loss: 6.16927e-02
I0209 22:20:17.740772 22509476222784 run_lib.py:133] step: 4500, training_loss: 3.90920e-02
I0209 22:20:17.920500 22509476222784 run_lib.py:146] step: 4500, eval_loss: 4.90820e-02
I0209 22:20:36.389355 22509476222784 run_lib.py:133] step: 4550, training_loss: 5.33604e-02
I0209 22:20:55.021758 22509476222784 run_lib.py:133] step: 4600, training_loss: 4.91812e-02
I0209 22:20:55.251771 22509476222784 run_lib.py:146] step: 4600, eval_loss: 4.56862e-02
I0209 22:21:13.802692 22509476222784 run_lib.py:133] step: 4650, training_loss: 4.91639e-02
I0209 22:21:32.314731 22509476222784 run_lib.py:133] step: 4700, training_loss: 3.49530e-02
I0209 22:21:32.477563 22509476222784 run_lib.py:146] step: 4700, eval_loss: 4.65956e-02
I0209 22:21:50.920634 22509476222784 run_lib.py:133] step: 4750, training_loss: 5.19642e-02
I0209 22:22:09.387664 22509476222784 run_lib.py:133] step: 4800, training_loss: 5.09222e-02
I0209 22:22:09.551516 22509476222784 run_lib.py:146] step: 4800, eval_loss: 3.86309e-02
I0209 22:22:28.225746 22509476222784 run_lib.py:133] step: 4850, training_loss: 4.42562e-02
I0209 22:22:46.897646 22509476222784 run_lib.py:133] step: 4900, training_loss: 5.40141e-02
I0209 22:22:47.069669 22509476222784 run_lib.py:146] step: 4900, eval_loss: 6.95948e-02
I0209 22:23:05.586940 22509476222784 run_lib.py:133] step: 4950, training_loss: 5.06238e-02
I0209 22:23:24.082706 22509476222784 run_lib.py:133] step: 5000, training_loss: 6.62155e-02
I0209 22:23:24.244468 22509476222784 run_lib.py:146] step: 5000, eval_loss: 4.62727e-02
I0209 22:23:42.877710 22509476222784 run_lib.py:133] step: 5050, training_loss: 6.44310e-02
I0209 22:24:01.358251 22509476222784 run_lib.py:133] step: 5100, training_loss: 5.39158e-02
I0209 22:24:01.521775 22509476222784 run_lib.py:146] step: 5100, eval_loss: 4.03479e-02
I0209 22:24:20.242228 22509476222784 run_lib.py:133] step: 5150, training_loss: 3.70155e-02
I0209 22:24:38.758880 22509476222784 run_lib.py:133] step: 5200, training_loss: 5.14389e-02
I0209 22:24:38.922572 22509476222784 run_lib.py:146] step: 5200, eval_loss: 6.72853e-02
I0209 22:24:57.518837 22509476222784 run_lib.py:133] step: 5250, training_loss: 4.48989e-02
I0209 22:25:15.988400 22509476222784 run_lib.py:133] step: 5300, training_loss: 6.09549e-02
I0209 22:25:16.166612 22509476222784 run_lib.py:146] step: 5300, eval_loss: 3.96389e-02
I0209 22:25:34.685121 22509476222784 run_lib.py:133] step: 5350, training_loss: 5.83326e-02
I0209 22:25:53.259542 22509476222784 run_lib.py:133] step: 5400, training_loss: 5.32993e-02
I0209 22:25:53.446666 22509476222784 run_lib.py:146] step: 5400, eval_loss: 6.80876e-02
I0209 22:26:11.975301 22509476222784 run_lib.py:133] step: 5450, training_loss: 6.32619e-02
I0209 22:26:30.630007 22509476222784 run_lib.py:133] step: 5500, training_loss: 6.01563e-02
I0209 22:26:30.794777 22509476222784 run_lib.py:146] step: 5500, eval_loss: 4.70791e-02
I0209 22:26:49.238422 22509476222784 run_lib.py:133] step: 5550, training_loss: 4.16084e-02
I0209 22:27:07.615294 22509476222784 run_lib.py:133] step: 5600, training_loss: 6.45147e-02
I0209 22:27:07.784943 22509476222784 run_lib.py:146] step: 5600, eval_loss: 4.08630e-02
I0209 22:27:26.316479 22509476222784 run_lib.py:133] step: 5650, training_loss: 4.06500e-02
I0209 22:27:44.844511 22509476222784 run_lib.py:133] step: 5700, training_loss: 5.29565e-02
I0209 22:27:45.056613 22509476222784 run_lib.py:146] step: 5700, eval_loss: 5.59478e-02
I0209 22:28:03.794790 22509476222784 run_lib.py:133] step: 5750, training_loss: 5.10360e-02
I0209 22:28:22.310577 22509476222784 run_lib.py:133] step: 5800, training_loss: 5.90717e-02
I0209 22:28:22.516201 22509476222784 run_lib.py:146] step: 5800, eval_loss: 6.37448e-02
I0209 22:28:41.067103 22509476222784 run_lib.py:133] step: 5850, training_loss: 5.62617e-02
I0209 22:28:59.651000 22509476222784 run_lib.py:133] step: 5900, training_loss: 6.87328e-02
I0209 22:28:59.811452 22509476222784 run_lib.py:146] step: 5900, eval_loss: 3.92187e-02
I0209 22:29:18.200263 22509476222784 run_lib.py:133] step: 5950, training_loss: 4.11931e-02
I0209 22:29:36.737691 22509476222784 run_lib.py:133] step: 6000, training_loss: 6.52453e-02
I0209 22:29:36.903827 22509476222784 run_lib.py:146] step: 6000, eval_loss: 4.44502e-02
I0209 22:29:55.413854 22509476222784 run_lib.py:133] step: 6050, training_loss: 5.95643e-02
I0209 22:30:13.915281 22509476222784 run_lib.py:133] step: 6100, training_loss: 7.68140e-02
I0209 22:30:14.187383 22509476222784 run_lib.py:146] step: 6100, eval_loss: 4.87758e-02
I0209 22:30:32.832527 22509476222784 run_lib.py:133] step: 6150, training_loss: 4.98629e-02
I0209 22:30:51.381395 22509476222784 run_lib.py:133] step: 6200, training_loss: 4.27712e-02
I0209 22:30:51.579643 22509476222784 run_lib.py:146] step: 6200, eval_loss: 4.64516e-02
I0209 22:31:10.086032 22509476222784 run_lib.py:133] step: 6250, training_loss: 4.24695e-02
I0209 22:31:28.651386 22509476222784 run_lib.py:133] step: 6300, training_loss: 4.75461e-02
I0209 22:31:28.872969 22509476222784 run_lib.py:146] step: 6300, eval_loss: 7.27389e-02
I0209 22:31:47.554316 22509476222784 run_lib.py:133] step: 6350, training_loss: 5.14212e-02
I0209 22:32:06.103499 22509476222784 run_lib.py:133] step: 6400, training_loss: 5.42078e-02
I0209 22:32:06.478145 22509476222784 run_lib.py:146] step: 6400, eval_loss: 4.94280e-02
I0209 22:32:24.935408 22509476222784 run_lib.py:133] step: 6450, training_loss: 3.45071e-02
I0209 22:32:43.432143 22509476222784 run_lib.py:133] step: 6500, training_loss: 4.36697e-02
I0209 22:32:43.626564 22509476222784 run_lib.py:146] step: 6500, eval_loss: 5.27233e-02
I0209 22:33:02.254980 22509476222784 run_lib.py:133] step: 6550, training_loss: 4.78324e-02
I0209 22:33:20.842543 22509476222784 run_lib.py:133] step: 6600, training_loss: 6.19909e-02
I0209 22:33:21.042531 22509476222784 run_lib.py:146] step: 6600, eval_loss: 4.26767e-02
I0209 22:33:39.752305 22509476222784 run_lib.py:133] step: 6650, training_loss: 4.60740e-02
I0209 22:33:58.249482 22509476222784 run_lib.py:133] step: 6700, training_loss: 5.89131e-02
I0209 22:33:58.413700 22509476222784 run_lib.py:146] step: 6700, eval_loss: 5.19125e-02
I0209 22:34:17.040461 22509476222784 run_lib.py:133] step: 6750, training_loss: 3.79113e-02
I0209 22:34:35.559065 22509476222784 run_lib.py:133] step: 6800, training_loss: 5.03947e-02
I0209 22:34:35.722543 22509476222784 run_lib.py:146] step: 6800, eval_loss: 4.66901e-02
I0209 22:34:54.246611 22509476222784 run_lib.py:133] step: 6850, training_loss: 4.89276e-02
I0209 22:35:12.983241 22509476222784 run_lib.py:133] step: 6900, training_loss: 4.04760e-02
I0209 22:35:13.146558 22509476222784 run_lib.py:146] step: 6900, eval_loss: 4.54386e-02
I0209 22:35:31.554092 22509476222784 run_lib.py:133] step: 6950, training_loss: 5.71727e-02
I0209 22:35:50.157795 22509476222784 run_lib.py:133] step: 7000, training_loss: 3.07831e-02
I0209 22:35:50.321640 22509476222784 run_lib.py:146] step: 7000, eval_loss: 2.96354e-02
I0209 22:36:08.761743 22509476222784 run_lib.py:133] step: 7050, training_loss: 4.80800e-02
I0209 22:36:27.200250 22509476222784 run_lib.py:133] step: 7100, training_loss: 5.72349e-02
I0209 22:36:27.382579 22509476222784 run_lib.py:146] step: 7100, eval_loss: 5.74422e-02
I0209 22:36:45.910314 22509476222784 run_lib.py:133] step: 7150, training_loss: 5.92267e-02
I0209 22:37:04.693914 22509476222784 run_lib.py:133] step: 7200, training_loss: 4.10100e-02
I0209 22:37:04.857875 22509476222784 run_lib.py:146] step: 7200, eval_loss: 5.22981e-02
I0209 22:37:23.369943 22509476222784 run_lib.py:133] step: 7250, training_loss: 4.52237e-02
I0209 22:37:41.880983 22509476222784 run_lib.py:133] step: 7300, training_loss: 4.70560e-02
I0209 22:37:42.051599 22509476222784 run_lib.py:146] step: 7300, eval_loss: 3.49271e-02
I0209 22:38:00.677768 22509476222784 run_lib.py:133] step: 7350, training_loss: 5.59832e-02
I0209 22:38:19.565213 22509476222784 run_lib.py:133] step: 7400, training_loss: 5.55229e-02
I0209 22:38:19.729699 22509476222784 run_lib.py:146] step: 7400, eval_loss: 5.36316e-02
I0209 22:38:38.361926 22509476222784 run_lib.py:133] step: 7450, training_loss: 4.66314e-02
I0209 22:38:56.923748 22509476222784 run_lib.py:133] step: 7500, training_loss: 4.98665e-02
I0209 22:38:57.091564 22509476222784 run_lib.py:146] step: 7500, eval_loss: 4.59263e-02
I0209 22:39:15.590200 22509476222784 run_lib.py:133] step: 7550, training_loss: 4.89145e-02
I0209 22:39:34.138161 22509476222784 run_lib.py:133] step: 7600, training_loss: 4.70812e-02
I0209 22:39:34.302861 22509476222784 run_lib.py:146] step: 7600, eval_loss: 5.27859e-02
I0209 22:39:52.982665 22509476222784 run_lib.py:133] step: 7650, training_loss: 4.07341e-02
I0209 22:40:11.627718 22509476222784 run_lib.py:133] step: 7700, training_loss: 5.53306e-02
I0209 22:40:11.794300 22509476222784 run_lib.py:146] step: 7700, eval_loss: 4.88658e-02
I0209 22:40:30.318120 22509476222784 run_lib.py:133] step: 7750, training_loss: 4.60676e-02
I0209 22:40:48.894459 22509476222784 run_lib.py:133] step: 7800, training_loss: 5.19943e-02
I0209 22:40:49.055346 22509476222784 run_lib.py:146] step: 7800, eval_loss: 4.57226e-02
I0209 22:41:07.731120 22509476222784 run_lib.py:133] step: 7850, training_loss: 4.74103e-02
I0209 22:41:26.220878 22509476222784 run_lib.py:133] step: 7900, training_loss: 5.51959e-02
I0209 22:41:26.384530 22509476222784 run_lib.py:146] step: 7900, eval_loss: 3.88823e-02
I0209 22:41:44.976060 22509476222784 run_lib.py:133] step: 7950, training_loss: 4.70671e-02
I0209 22:42:03.441503 22509476222784 run_lib.py:133] step: 8000, training_loss: 5.42901e-02
I0209 22:42:03.624399 22509476222784 run_lib.py:146] step: 8000, eval_loss: 3.66328e-02
I0209 22:42:22.307691 22509476222784 run_lib.py:133] step: 8050, training_loss: 3.78527e-02
I0209 22:42:40.757173 22509476222784 run_lib.py:133] step: 8100, training_loss: 4.33848e-02
I0209 22:42:40.920712 22509476222784 run_lib.py:146] step: 8100, eval_loss: 5.52444e-02
I0209 22:42:59.533887 22509476222784 run_lib.py:133] step: 8150, training_loss: 4.79066e-02
I0209 22:43:17.995602 22509476222784 run_lib.py:133] step: 8200, training_loss: 5.21506e-02
I0209 22:43:18.158646 22509476222784 run_lib.py:146] step: 8200, eval_loss: 5.30654e-02
I0209 22:43:36.631432 22509476222784 run_lib.py:133] step: 8250, training_loss: 4.07253e-02
I0209 22:43:55.338165 22509476222784 run_lib.py:133] step: 8300, training_loss: 6.04633e-02
I0209 22:43:55.501758 22509476222784 run_lib.py:146] step: 8300, eval_loss: 5.06631e-02
I0209 22:44:13.984296 22509476222784 run_lib.py:133] step: 8350, training_loss: 3.80126e-02
I0209 22:44:32.493137 22509476222784 run_lib.py:133] step: 8400, training_loss: 5.08814e-02
I0209 22:44:32.657696 22509476222784 run_lib.py:146] step: 8400, eval_loss: 6.14568e-02
I0209 22:44:51.304440 22509476222784 run_lib.py:133] step: 8450, training_loss: 4.13078e-02
I0209 22:45:09.828613 22509476222784 run_lib.py:133] step: 8500, training_loss: 4.35733e-02
I0209 22:45:10.007508 22509476222784 run_lib.py:146] step: 8500, eval_loss: 6.01881e-02
I0209 22:45:28.628868 22509476222784 run_lib.py:133] step: 8550, training_loss: 5.07930e-02
I0209 22:45:47.234393 22509476222784 run_lib.py:133] step: 8600, training_loss: 4.99645e-02
I0209 22:45:47.398917 22509476222784 run_lib.py:146] step: 8600, eval_loss: 3.91954e-02
I0209 22:46:05.911252 22509476222784 run_lib.py:133] step: 8650, training_loss: 4.77387e-02
I0209 22:46:24.612174 22509476222784 run_lib.py:133] step: 8700, training_loss: 4.65236e-02
I0209 22:46:24.775743 22509476222784 run_lib.py:146] step: 8700, eval_loss: 5.23869e-02
I0209 22:46:43.253880 22509476222784 run_lib.py:133] step: 8750, training_loss: 4.48426e-02
I0209 22:47:01.820721 22509476222784 run_lib.py:133] step: 8800, training_loss: 5.42797e-02
I0209 22:47:01.982672 22509476222784 run_lib.py:146] step: 8800, eval_loss: 3.94263e-02
I0209 22:47:20.637190 22509476222784 run_lib.py:133] step: 8850, training_loss: 5.27445e-02
I0209 22:47:39.369721 22509476222784 run_lib.py:133] step: 8900, training_loss: 5.97693e-02
I0209 22:47:39.533990 22509476222784 run_lib.py:146] step: 8900, eval_loss: 4.52176e-02
I0209 22:47:58.074940 22509476222784 run_lib.py:133] step: 8950, training_loss: 4.25445e-02
I0209 22:48:16.675738 22509476222784 run_lib.py:133] step: 9000, training_loss: 5.27659e-02
I0209 22:48:16.896823 22509476222784 run_lib.py:146] step: 9000, eval_loss: 5.59527e-02
I0209 22:48:35.415931 22509476222784 run_lib.py:133] step: 9050, training_loss: 3.38375e-02
I0209 22:48:54.012575 22509476222784 run_lib.py:133] step: 9100, training_loss: 5.83304e-02
I0209 22:48:54.176879 22509476222784 run_lib.py:146] step: 9100, eval_loss: 5.15213e-02
I0209 22:49:12.947585 22509476222784 run_lib.py:133] step: 9150, training_loss: 5.58282e-02
I0209 22:49:31.670629 22509476222784 run_lib.py:133] step: 9200, training_loss: 4.05662e-02
I0209 22:49:31.833566 22509476222784 run_lib.py:146] step: 9200, eval_loss: 6.27538e-02
I0209 22:49:50.361988 22509476222784 run_lib.py:133] step: 9250, training_loss: 4.77154e-02
I0209 22:50:08.914225 22509476222784 run_lib.py:133] step: 9300, training_loss: 4.86761e-02
I0209 22:50:09.110707 22509476222784 run_lib.py:146] step: 9300, eval_loss: 4.66260e-02
I0209 22:50:27.840465 22509476222784 run_lib.py:133] step: 9350, training_loss: 3.71265e-02
I0209 22:50:46.458178 22509476222784 run_lib.py:133] step: 9400, training_loss: 3.93705e-02
I0209 22:50:46.636696 22509476222784 run_lib.py:146] step: 9400, eval_loss: 4.84734e-02
I0209 22:51:05.429411 22509476222784 run_lib.py:133] step: 9450, training_loss: 5.04586e-02
I0209 22:51:24.251719 22509476222784 run_lib.py:133] step: 9500, training_loss: 5.63061e-02
I0209 22:51:24.415730 22509476222784 run_lib.py:146] step: 9500, eval_loss: 4.37670e-02
I0209 22:51:43.151218 22509476222784 run_lib.py:133] step: 9550, training_loss: 6.00192e-02
I0209 22:52:01.725249 22509476222784 run_lib.py:133] step: 9600, training_loss: 6.33789e-02
I0209 22:52:01.921511 22509476222784 run_lib.py:146] step: 9600, eval_loss: 4.54500e-02
I0209 22:52:20.471646 22509476222784 run_lib.py:133] step: 9650, training_loss: 5.51265e-02
I0209 22:52:39.269156 22509476222784 run_lib.py:133] step: 9700, training_loss: 5.10006e-02
I0209 22:52:39.449964 22509476222784 run_lib.py:146] step: 9700, eval_loss: 5.87353e-02
I0209 22:52:58.084501 22509476222784 run_lib.py:133] step: 9750, training_loss: 7.76746e-02
I0209 22:53:16.884413 22509476222784 run_lib.py:133] step: 9800, training_loss: 4.62002e-02
I0209 22:53:17.076506 22509476222784 run_lib.py:146] step: 9800, eval_loss: 4.87195e-02
I0209 22:53:35.599343 22509476222784 run_lib.py:133] step: 9850, training_loss: 4.85398e-02
I0209 22:53:54.175998 22509476222784 run_lib.py:133] step: 9900, training_loss: 4.20014e-02
I0209 22:53:54.370746 22509476222784 run_lib.py:146] step: 9900, eval_loss: 3.97788e-02
I0209 22:54:13.097041 22509476222784 run_lib.py:133] step: 9950, training_loss: 3.11691e-02
I0209 22:54:31.755198 22509476222784 run_lib.py:133] step: 10000, training_loss: 5.17527e-02
I0209 22:54:32.996564 22509476222784 run_lib.py:146] step: 10000, eval_loss: 4.65935e-02
I0209 22:54:55.054286 22509476222784 run_lib.py:133] step: 10050, training_loss: 5.99946e-02
I0209 22:55:13.704957 22509476222784 run_lib.py:133] step: 10100, training_loss: 4.28857e-02
I0209 22:55:13.891782 22509476222784 run_lib.py:146] step: 10100, eval_loss: 5.22587e-02
I0209 22:55:32.596103 22509476222784 run_lib.py:133] step: 10150, training_loss: 3.68785e-02
I0209 22:55:51.133083 22509476222784 run_lib.py:133] step: 10200, training_loss: 4.27978e-02
I0209 22:55:51.343273 22509476222784 run_lib.py:146] step: 10200, eval_loss: 5.89811e-02
I0209 22:56:10.085641 22509476222784 run_lib.py:133] step: 10250, training_loss: 3.99849e-02
I0209 22:56:28.680911 22509476222784 run_lib.py:133] step: 10300, training_loss: 5.93621e-02
I0209 22:56:28.874906 22509476222784 run_lib.py:146] step: 10300, eval_loss: 4.89634e-02
I0209 22:56:47.648751 22509476222784 run_lib.py:133] step: 10350, training_loss: 5.36647e-02
I0209 22:57:06.223531 22509476222784 run_lib.py:133] step: 10400, training_loss: 4.67395e-02
I0209 22:57:06.434662 22509476222784 run_lib.py:146] step: 10400, eval_loss: 6.06188e-02
I0209 22:57:25.119608 22509476222784 run_lib.py:133] step: 10450, training_loss: 4.30711e-02
I0209 22:57:43.688935 22509476222784 run_lib.py:133] step: 10500, training_loss: 5.17686e-02
I0209 22:57:43.920685 22509476222784 run_lib.py:146] step: 10500, eval_loss: 4.95382e-02
I0209 22:58:02.543377 22509476222784 run_lib.py:133] step: 10550, training_loss: 3.60089e-02
I0209 22:58:21.284348 22509476222784 run_lib.py:133] step: 10600, training_loss: 5.78547e-02
I0209 22:58:21.506887 22509476222784 run_lib.py:146] step: 10600, eval_loss: 4.09969e-02
I0209 22:58:40.037674 22509476222784 run_lib.py:133] step: 10650, training_loss: 5.12447e-02
I0209 22:58:58.612773 22509476222784 run_lib.py:133] step: 10700, training_loss: 3.43571e-02
I0209 22:58:58.806775 22509476222784 run_lib.py:146] step: 10700, eval_loss: 5.97273e-02
I0209 22:59:17.496556 22509476222784 run_lib.py:133] step: 10750, training_loss: 5.15702e-02
I0209 22:59:36.242464 22509476222784 run_lib.py:133] step: 10800, training_loss: 4.94682e-02
I0209 22:59:36.455953 22509476222784 run_lib.py:146] step: 10800, eval_loss: 5.59782e-02
I0209 22:59:55.070626 22509476222784 run_lib.py:133] step: 10850, training_loss: 4.94224e-02
I0209 23:00:13.632015 22509476222784 run_lib.py:133] step: 10900, training_loss: 4.72507e-02
I0209 23:00:13.869607 22509476222784 run_lib.py:146] step: 10900, eval_loss: 4.26476e-02
I0209 23:00:32.403429 22509476222784 run_lib.py:133] step: 10950, training_loss: 4.05373e-02
I0209 23:00:51.127760 22509476222784 run_lib.py:133] step: 11000, training_loss: 4.11736e-02
I0209 23:00:51.351597 22509476222784 run_lib.py:146] step: 11000, eval_loss: 3.51916e-02
I0209 23:01:09.893213 22509476222784 run_lib.py:133] step: 11050, training_loss: 4.97063e-02
I0209 23:01:28.514029 22509476222784 run_lib.py:133] step: 11100, training_loss: 4.59235e-02
I0209 23:01:28.680036 22509476222784 run_lib.py:146] step: 11100, eval_loss: 4.62429e-02
I0209 23:01:47.221265 22509476222784 run_lib.py:133] step: 11150, training_loss: 5.77939e-02
I0209 23:02:05.981117 22509476222784 run_lib.py:133] step: 11200, training_loss: 3.93430e-02
I0209 23:02:06.186646 22509476222784 run_lib.py:146] step: 11200, eval_loss: 5.41588e-02
I0209 23:02:24.789499 22509476222784 run_lib.py:133] step: 11250, training_loss: 4.66544e-02
I0209 23:02:43.473461 22509476222784 run_lib.py:133] step: 11300, training_loss: 5.86961e-02
I0209 23:02:43.638811 22509476222784 run_lib.py:146] step: 11300, eval_loss: 4.65240e-02
I0209 23:03:02.256401 22509476222784 run_lib.py:133] step: 11350, training_loss: 4.32216e-02
I0209 23:03:20.890170 22509476222784 run_lib.py:133] step: 11400, training_loss: 4.68041e-02
I0209 23:03:21.083841 22509476222784 run_lib.py:146] step: 11400, eval_loss: 4.42810e-02
I0209 23:03:39.809317 22509476222784 run_lib.py:133] step: 11450, training_loss: 4.72840e-02
I0209 23:03:58.471865 22509476222784 run_lib.py:133] step: 11500, training_loss: 5.56886e-02
I0209 23:03:58.662795 22509476222784 run_lib.py:146] step: 11500, eval_loss: 4.44579e-02
I0209 23:04:17.228215 22509476222784 run_lib.py:133] step: 11550, training_loss: 5.00715e-02
I0209 23:04:35.805231 22509476222784 run_lib.py:133] step: 11600, training_loss: 5.15835e-02
I0209 23:04:35.972972 22509476222784 run_lib.py:146] step: 11600, eval_loss: 4.86874e-02
I0209 23:04:54.720551 22509476222784 run_lib.py:133] step: 11650, training_loss: 4.99935e-02
I0209 23:05:13.278322 22509476222784 run_lib.py:133] step: 11700, training_loss: 4.94172e-02
I0209 23:05:13.439686 22509476222784 run_lib.py:146] step: 11700, eval_loss: 4.36533e-02
I0209 23:05:32.126009 22509476222784 run_lib.py:133] step: 11750, training_loss: 5.57016e-02
I0209 23:05:50.728808 22509476222784 run_lib.py:133] step: 11800, training_loss: 4.32827e-02
I0209 23:05:50.896718 22509476222784 run_lib.py:146] step: 11800, eval_loss: 5.46051e-02
I0209 23:06:09.598908 22509476222784 run_lib.py:133] step: 11850, training_loss: 3.89894e-02
I0209 23:06:28.288625 22509476222784 run_lib.py:133] step: 11900, training_loss: 5.04105e-02
I0209 23:06:28.457583 22509476222784 run_lib.py:146] step: 11900, eval_loss: 5.04128e-02
I0209 23:06:47.054021 22509476222784 run_lib.py:133] step: 11950, training_loss: 5.61482e-02
I0209 23:07:05.874249 22509476222784 run_lib.py:133] step: 12000, training_loss: 5.29347e-02
I0209 23:07:06.040878 22509476222784 run_lib.py:146] step: 12000, eval_loss: 4.61873e-02
I0209 23:07:24.585289 22509476222784 run_lib.py:133] step: 12050, training_loss: 4.94802e-02
I0209 23:07:43.294967 22509476222784 run_lib.py:133] step: 12100, training_loss: 3.31745e-02
I0209 23:07:43.457660 22509476222784 run_lib.py:146] step: 12100, eval_loss: 5.46528e-02
I0209 23:08:02.000712 22509476222784 run_lib.py:133] step: 12150, training_loss: 4.26939e-02
I0209 23:08:20.615600 22509476222784 run_lib.py:133] step: 12200, training_loss: 4.39900e-02
I0209 23:08:20.783050 22509476222784 run_lib.py:146] step: 12200, eval_loss: 4.58449e-02
I0209 23:08:39.588273 22509476222784 run_lib.py:133] step: 12250, training_loss: 4.31130e-02
I0209 23:08:58.173160 22509476222784 run_lib.py:133] step: 12300, training_loss: 5.62093e-02
I0209 23:08:58.346691 22509476222784 run_lib.py:146] step: 12300, eval_loss: 4.33960e-02
I0209 23:09:16.882902 22509476222784 run_lib.py:133] step: 12350, training_loss: 3.84280e-02
I0209 23:09:35.630107 22509476222784 run_lib.py:133] step: 12400, training_loss: 5.26415e-02
I0209 23:09:35.819606 22509476222784 run_lib.py:146] step: 12400, eval_loss: 5.24514e-02
I0209 23:09:54.463093 22509476222784 run_lib.py:133] step: 12450, training_loss: 4.40867e-02
I0209 23:10:13.070853 22509476222784 run_lib.py:133] step: 12500, training_loss: 4.91781e-02
I0209 23:10:13.245872 22509476222784 run_lib.py:146] step: 12500, eval_loss: 5.22465e-02
I0209 23:10:31.914945 22509476222784 run_lib.py:133] step: 12550, training_loss: 4.83294e-02
I0209 23:10:50.459198 22509476222784 run_lib.py:133] step: 12600, training_loss: 5.41364e-02
I0209 23:10:50.623652 22509476222784 run_lib.py:146] step: 12600, eval_loss: 5.50886e-02
I0209 23:11:09.191982 22509476222784 run_lib.py:133] step: 12650, training_loss: 5.08714e-02
I0209 23:11:27.849190 22509476222784 run_lib.py:133] step: 12700, training_loss: 4.11484e-02
I0209 23:11:28.017973 22509476222784 run_lib.py:146] step: 12700, eval_loss: 5.03827e-02
I0209 23:11:46.808698 22509476222784 run_lib.py:133] step: 12750, training_loss: 3.11894e-02
I0209 23:12:05.562602 22509476222784 run_lib.py:133] step: 12800, training_loss: 4.18716e-02
I0209 23:12:05.771698 22509476222784 run_lib.py:146] step: 12800, eval_loss: 6.06053e-02
I0209 23:12:24.346979 22509476222784 run_lib.py:133] step: 12850, training_loss: 3.92261e-02
I0209 23:12:42.895936 22509476222784 run_lib.py:133] step: 12900, training_loss: 4.00635e-02
I0209 23:12:43.060603 22509476222784 run_lib.py:146] step: 12900, eval_loss: 4.50146e-02
I0209 23:13:01.824223 22509476222784 run_lib.py:133] step: 12950, training_loss: 3.18703e-02
I0209 23:13:20.549785 22509476222784 run_lib.py:133] step: 13000, training_loss: 5.69732e-02
I0209 23:13:20.719240 22509476222784 run_lib.py:146] step: 13000, eval_loss: 4.16469e-02
I0209 23:13:39.510092 22509476222784 run_lib.py:133] step: 13050, training_loss: 4.81421e-02
I0209 23:13:58.123391 22509476222784 run_lib.py:133] step: 13100, training_loss: 5.27285e-02
I0209 23:13:58.286606 22509476222784 run_lib.py:146] step: 13100, eval_loss: 4.34301e-02
I0209 23:14:17.000751 22509476222784 run_lib.py:133] step: 13150, training_loss: 4.65522e-02
I0209 23:14:35.620766 22509476222784 run_lib.py:133] step: 13200, training_loss: 3.58202e-02
I0209 23:14:35.785728 22509476222784 run_lib.py:146] step: 13200, eval_loss: 5.41872e-02
I0209 23:14:54.571539 22509476222784 run_lib.py:133] step: 13250, training_loss: 5.39966e-02
I0209 23:15:13.217905 22509476222784 run_lib.py:133] step: 13300, training_loss: 4.76046e-02
I0209 23:15:13.386694 22509476222784 run_lib.py:146] step: 13300, eval_loss: 3.13041e-02
I0209 23:15:31.956989 22509476222784 run_lib.py:133] step: 13350, training_loss: 4.26274e-02
I0209 23:15:50.684732 22509476222784 run_lib.py:133] step: 13400, training_loss: 4.46840e-02
I0209 23:15:50.881669 22509476222784 run_lib.py:146] step: 13400, eval_loss: 5.32406e-02
I0209 23:16:09.465307 22509476222784 run_lib.py:133] step: 13450, training_loss: 4.78750e-02
I0209 23:16:28.027506 22509476222784 run_lib.py:133] step: 13500, training_loss: 5.22427e-02
I0209 23:16:28.194883 22509476222784 run_lib.py:146] step: 13500, eval_loss: 5.23732e-02
I0209 23:16:46.938635 22509476222784 run_lib.py:133] step: 13550, training_loss: 4.74064e-02
I0209 23:17:05.503384 22509476222784 run_lib.py:133] step: 13600, training_loss: 3.52428e-02
I0209 23:17:05.733733 22509476222784 run_lib.py:146] step: 13600, eval_loss: 6.94673e-02
I0209 23:17:24.457687 22509476222784 run_lib.py:133] step: 13650, training_loss: 2.75115e-02
I0209 23:17:43.057056 22509476222784 run_lib.py:133] step: 13700, training_loss: 4.04919e-02
I0209 23:17:43.281259 22509476222784 run_lib.py:146] step: 13700, eval_loss: 4.79670e-02
I0209 23:18:01.809392 22509476222784 run_lib.py:133] step: 13750, training_loss: 3.47386e-02
I0209 23:18:20.612971 22509476222784 run_lib.py:133] step: 13800, training_loss: 4.27219e-02
I0209 23:18:20.831595 22509476222784 run_lib.py:146] step: 13800, eval_loss: 3.07141e-02
I0209 23:18:39.403213 22509476222784 run_lib.py:133] step: 13850, training_loss: 5.74575e-02
I0209 23:18:57.953912 22509476222784 run_lib.py:133] step: 13900, training_loss: 4.08452e-02
I0209 23:18:58.146924 22509476222784 run_lib.py:146] step: 13900, eval_loss: 4.90985e-02
I0209 23:19:16.729145 22509476222784 run_lib.py:133] step: 13950, training_loss: 4.47508e-02
I0209 23:19:35.459518 22509476222784 run_lib.py:133] step: 14000, training_loss: 4.58282e-02
I0209 23:19:35.705733 22509476222784 run_lib.py:146] step: 14000, eval_loss: 4.73864e-02
I0209 23:19:54.225282 22509476222784 run_lib.py:133] step: 14050, training_loss: 5.10968e-02
I0209 23:20:12.916151 22509476222784 run_lib.py:133] step: 14100, training_loss: 4.94962e-02
I0209 23:20:13.107853 22509476222784 run_lib.py:146] step: 14100, eval_loss: 4.41575e-02
I0209 23:20:31.703455 22509476222784 run_lib.py:133] step: 14150, training_loss: 4.70192e-02
I0209 23:20:50.268413 22509476222784 run_lib.py:133] step: 14200, training_loss: 4.25646e-02
I0209 23:20:50.503875 22509476222784 run_lib.py:146] step: 14200, eval_loss: 4.67231e-02
I0209 23:21:09.268198 22509476222784 run_lib.py:133] step: 14250, training_loss: 3.77188e-02
I0209 23:21:27.877827 22509476222784 run_lib.py:133] step: 14300, training_loss: 5.30748e-02
I0209 23:21:28.074878 22509476222784 run_lib.py:146] step: 14300, eval_loss: 5.36029e-02
I0209 23:21:46.650504 22509476222784 run_lib.py:133] step: 14350, training_loss: 5.64008e-02
I0209 23:22:05.291503 22509476222784 run_lib.py:133] step: 14400, training_loss: 3.92317e-02
I0209 23:22:05.501099 22509476222784 run_lib.py:146] step: 14400, eval_loss: 4.05264e-02
I0209 23:22:24.282160 22509476222784 run_lib.py:133] step: 14450, training_loss: 3.99588e-02
I0209 23:22:42.848222 22509476222784 run_lib.py:133] step: 14500, training_loss: 4.00703e-02
I0209 23:22:43.012697 22509476222784 run_lib.py:146] step: 14500, eval_loss: 4.26518e-02
I0209 23:23:01.722602 22509476222784 run_lib.py:133] step: 14550, training_loss: 4.23000e-02
I0209 23:23:20.297894 22509476222784 run_lib.py:133] step: 14600, training_loss: 4.27555e-02
I0209 23:23:20.494637 22509476222784 run_lib.py:146] step: 14600, eval_loss: 4.85612e-02
I0209 23:23:39.255501 22509476222784 run_lib.py:133] step: 14650, training_loss: 4.28477e-02
I0209 23:23:57.865554 22509476222784 run_lib.py:133] step: 14700, training_loss: 4.16923e-02
I0209 23:23:58.071778 22509476222784 run_lib.py:146] step: 14700, eval_loss: 3.51566e-02
I0209 23:24:16.608594 22509476222784 run_lib.py:133] step: 14750, training_loss: 4.06816e-02
I0209 23:24:35.401968 22509476222784 run_lib.py:133] step: 14800, training_loss: 6.41827e-02
I0209 23:24:35.567746 22509476222784 run_lib.py:146] step: 14800, eval_loss: 4.53639e-02
I0209 23:24:54.127374 22509476222784 run_lib.py:133] step: 14850, training_loss: 5.10347e-02
I0209 23:25:12.820153 22509476222784 run_lib.py:133] step: 14900, training_loss: 3.39742e-02
I0209 23:25:12.991858 22509476222784 run_lib.py:146] step: 14900, eval_loss: 4.31368e-02
I0209 23:25:31.563577 22509476222784 run_lib.py:133] step: 14950, training_loss: 4.49410e-02
I0209 23:25:50.162350 22509476222784 run_lib.py:133] step: 15000, training_loss: 5.15318e-02
I0209 23:25:50.330036 22509476222784 run_lib.py:146] step: 15000, eval_loss: 5.42255e-02
I0209 23:26:09.050824 22509476222784 run_lib.py:133] step: 15050, training_loss: 3.89028e-02
I0209 23:26:27.603043 22509476222784 run_lib.py:133] step: 15100, training_loss: 5.66291e-02
I0209 23:26:27.767697 22509476222784 run_lib.py:146] step: 15100, eval_loss: 5.07475e-02
I0209 23:26:46.330858 22509476222784 run_lib.py:133] step: 15150, training_loss: 5.11567e-02
I0209 23:27:05.138601 22509476222784 run_lib.py:133] step: 15200, training_loss: 4.75677e-02
I0209 23:27:05.310657 22509476222784 run_lib.py:146] step: 15200, eval_loss: 5.04458e-02
I0209 23:27:23.835099 22509476222784 run_lib.py:133] step: 15250, training_loss: 5.46892e-02
I0209 23:27:42.389985 22509476222784 run_lib.py:133] step: 15300, training_loss: 4.56027e-02
I0209 23:27:42.785620 22509476222784 run_lib.py:146] step: 15300, eval_loss: 5.03125e-02
I0209 23:28:01.383499 22509476222784 run_lib.py:133] step: 15350, training_loss: 4.23210e-02
I0209 23:28:19.955362 22509476222784 run_lib.py:133] step: 15400, training_loss: 6.62128e-02
I0209 23:28:20.129857 22509476222784 run_lib.py:146] step: 15400, eval_loss: 4.52531e-02
I0209 23:28:38.774060 22509476222784 run_lib.py:133] step: 15450, training_loss: 4.03612e-02
I0209 23:28:57.360929 22509476222784 run_lib.py:133] step: 15500, training_loss: 4.84504e-02
I0209 23:28:57.523765 22509476222784 run_lib.py:146] step: 15500, eval_loss: 4.64232e-02
I0209 23:29:16.299992 22509476222784 run_lib.py:133] step: 15550, training_loss: 4.24294e-02
I0209 23:29:34.953641 22509476222784 run_lib.py:133] step: 15600, training_loss: 5.54085e-02
I0209 23:29:35.118618 22509476222784 run_lib.py:146] step: 15600, eval_loss: 6.18757e-02
I0209 23:29:53.635516 22509476222784 run_lib.py:133] step: 15650, training_loss: 4.07457e-02
I0209 23:30:12.191328 22509476222784 run_lib.py:133] step: 15700, training_loss: 4.26001e-02
I0209 23:30:12.372719 22509476222784 run_lib.py:146] step: 15700, eval_loss: 5.43484e-02
I0209 23:30:31.086707 22509476222784 run_lib.py:133] step: 15750, training_loss: 6.02240e-02
I0209 23:30:49.798273 22509476222784 run_lib.py:133] step: 15800, training_loss: 5.68901e-02
I0209 23:30:49.968905 22509476222784 run_lib.py:146] step: 15800, eval_loss: 5.32322e-02
I0209 23:31:08.476666 22509476222784 run_lib.py:133] step: 15850, training_loss: 4.36230e-02
I0209 23:31:27.018441 22509476222784 run_lib.py:133] step: 15900, training_loss: 5.04976e-02
I0209 23:31:27.184728 22509476222784 run_lib.py:146] step: 15900, eval_loss: 4.50516e-02
I0209 23:31:45.913662 22509476222784 run_lib.py:133] step: 15950, training_loss: 4.08883e-02
I0209 23:32:04.511920 22509476222784 run_lib.py:133] step: 16000, training_loss: 3.93126e-02
I0209 23:32:04.913627 22509476222784 run_lib.py:146] step: 16000, eval_loss: 4.93271e-02
I0209 23:32:23.667895 22509476222784 run_lib.py:133] step: 16050, training_loss: 4.10774e-02
I0209 23:32:42.201299 22509476222784 run_lib.py:133] step: 16100, training_loss: 4.24098e-02
I0209 23:32:42.388818 22509476222784 run_lib.py:146] step: 16100, eval_loss: 5.26127e-02
I0209 23:33:01.149486 22509476222784 run_lib.py:133] step: 16150, training_loss: 3.79537e-02
I0209 23:33:19.748907 22509476222784 run_lib.py:133] step: 16200, training_loss: 5.32975e-02
I0209 23:33:19.931923 22509476222784 run_lib.py:146] step: 16200, eval_loss: 4.53905e-02
I0209 23:33:38.491749 22509476222784 run_lib.py:133] step: 16250, training_loss: 5.57613e-02
I0209 23:33:57.256645 22509476222784 run_lib.py:133] step: 16300, training_loss: 5.25668e-02
I0209 23:33:57.463409 22509476222784 run_lib.py:146] step: 16300, eval_loss: 4.61639e-02
I0209 23:34:16.199454 22509476222784 run_lib.py:133] step: 16350, training_loss: 2.68691e-02
I0209 23:34:34.951536 22509476222784 run_lib.py:133] step: 16400, training_loss: 3.74620e-02
I0209 23:34:35.115670 22509476222784 run_lib.py:146] step: 16400, eval_loss: 3.77577e-02
I0209 23:34:53.672652 22509476222784 run_lib.py:133] step: 16450, training_loss: 4.28385e-02
I0209 23:35:12.214548 22509476222784 run_lib.py:133] step: 16500, training_loss: 5.28024e-02
I0209 23:35:12.411777 22509476222784 run_lib.py:146] step: 16500, eval_loss: 6.35357e-02
I0209 23:35:31.083726 22509476222784 run_lib.py:133] step: 16550, training_loss: 3.83221e-02
I0209 23:35:49.710183 22509476222784 run_lib.py:133] step: 16600, training_loss: 4.95743e-02
I0209 23:35:49.927605 22509476222784 run_lib.py:146] step: 16600, eval_loss: 3.66976e-02
I0209 23:36:08.540364 22509476222784 run_lib.py:133] step: 16650, training_loss: 3.88926e-02
I0209 23:36:27.162981 22509476222784 run_lib.py:133] step: 16700, training_loss: 5.64571e-02
I0209 23:36:27.328945 22509476222784 run_lib.py:146] step: 16700, eval_loss: 5.14155e-02
I0209 23:36:46.120789 22509476222784 run_lib.py:133] step: 16750, training_loss: 4.20110e-02
I0209 23:37:04.679317 22509476222784 run_lib.py:133] step: 16800, training_loss: 4.35794e-02
I0209 23:37:04.876825 22509476222784 run_lib.py:146] step: 16800, eval_loss: 5.60340e-02
I0209 23:37:23.542353 22509476222784 run_lib.py:133] step: 16850, training_loss: 4.60797e-02
I0209 23:37:42.132940 22509476222784 run_lib.py:133] step: 16900, training_loss: 4.62740e-02
I0209 23:37:42.316989 22509476222784 run_lib.py:146] step: 16900, eval_loss: 5.25407e-02
I0209 23:38:00.952997 22509476222784 run_lib.py:133] step: 16950, training_loss: 4.60834e-02
I0209 23:38:19.544608 22509476222784 run_lib.py:133] step: 17000, training_loss: 4.70450e-02
I0209 23:38:19.737534 22509476222784 run_lib.py:146] step: 17000, eval_loss: 4.44772e-02
I0209 23:38:38.468725 22509476222784 run_lib.py:133] step: 17050, training_loss: 4.23173e-02
I0209 23:38:57.135950 22509476222784 run_lib.py:133] step: 17100, training_loss: 4.01033e-02
I0209 23:38:57.316588 22509476222784 run_lib.py:146] step: 17100, eval_loss: 4.75070e-02
I0209 23:39:15.954288 22509476222784 run_lib.py:133] step: 17150, training_loss: 5.31408e-02
I0209 23:39:34.565740 22509476222784 run_lib.py:133] step: 17200, training_loss: 4.02868e-02
I0209 23:39:34.730893 22509476222784 run_lib.py:146] step: 17200, eval_loss: 4.30873e-02
I0209 23:39:53.480622 22509476222784 run_lib.py:133] step: 17250, training_loss: 4.47975e-02
I0209 23:40:12.113969 22509476222784 run_lib.py:133] step: 17300, training_loss: 5.84017e-02
I0209 23:40:12.279357 22509476222784 run_lib.py:146] step: 17300, eval_loss: 4.13775e-02
I0209 23:40:31.011188 22509476222784 run_lib.py:133] step: 17350, training_loss: 4.46109e-02
I0209 23:40:49.557090 22509476222784 run_lib.py:133] step: 17400, training_loss: 5.36759e-02
I0209 23:40:49.790882 22509476222784 run_lib.py:146] step: 17400, eval_loss: 4.24596e-02
I0209 23:41:08.612635 22509476222784 run_lib.py:133] step: 17450, training_loss: 3.71942e-02
I0209 23:41:27.155445 22509476222784 run_lib.py:133] step: 17500, training_loss: 6.36608e-02
I0209 23:41:27.367824 22509476222784 run_lib.py:146] step: 17500, eval_loss: 4.08491e-02
I0209 23:41:46.071849 22509476222784 run_lib.py:133] step: 17550, training_loss: 3.65654e-02
I0209 23:42:04.623481 22509476222784 run_lib.py:133] step: 17600, training_loss: 4.50917e-02
I0209 23:42:04.828590 22509476222784 run_lib.py:146] step: 17600, eval_loss: 4.48348e-02
I0209 23:42:23.374685 22509476222784 run_lib.py:133] step: 17650, training_loss: 5.13518e-02
I0209 23:42:42.143861 22509476222784 run_lib.py:133] step: 17700, training_loss: 4.64614e-02
I0209 23:42:42.455933 22509476222784 run_lib.py:146] step: 17700, eval_loss: 4.17676e-02
I0209 23:43:00.989215 22509476222784 run_lib.py:133] step: 17750, training_loss: 4.74485e-02
I0209 23:43:19.513545 22509476222784 run_lib.py:133] step: 17800, training_loss: 3.99055e-02
I0209 23:43:19.677325 22509476222784 run_lib.py:146] step: 17800, eval_loss: 5.08834e-02
I0209 23:43:38.444271 22509476222784 run_lib.py:133] step: 17850, training_loss: 4.26615e-02
I0209 23:43:57.154186 22509476222784 run_lib.py:133] step: 17900, training_loss: 3.87965e-02
I0209 23:43:57.321716 22509476222784 run_lib.py:146] step: 17900, eval_loss: 4.35324e-02
I0209 23:44:15.929753 22509476222784 run_lib.py:133] step: 17950, training_loss: 5.34969e-02
I0209 23:44:34.539936 22509476222784 run_lib.py:133] step: 18000, training_loss: 4.78269e-02
I0209 23:44:34.707582 22509476222784 run_lib.py:146] step: 18000, eval_loss: 5.55273e-02
I0209 23:44:53.226849 22509476222784 run_lib.py:133] step: 18050, training_loss: 3.69621e-02
I0209 23:45:12.016115 22509476222784 run_lib.py:133] step: 18100, training_loss: 4.92818e-02
I0209 23:45:12.182810 22509476222784 run_lib.py:146] step: 18100, eval_loss: 4.43156e-02
I0209 23:45:30.717626 22509476222784 run_lib.py:133] step: 18150, training_loss: 6.51610e-02
I0209 23:45:49.334780 22509476222784 run_lib.py:133] step: 18200, training_loss: 5.79533e-02
I0209 23:45:49.500214 22509476222784 run_lib.py:146] step: 18200, eval_loss: 4.83270e-02
I0209 23:46:08.051805 22509476222784 run_lib.py:133] step: 18250, training_loss: 3.96564e-02
I0209 23:46:26.787343 22509476222784 run_lib.py:133] step: 18300, training_loss: 5.29641e-02
I0209 23:46:26.965546 22509476222784 run_lib.py:146] step: 18300, eval_loss: 5.40512e-02
I0209 23:46:45.506535 22509476222784 run_lib.py:133] step: 18350, training_loss: 6.27138e-02
I0209 23:47:04.200426 22509476222784 run_lib.py:133] step: 18400, training_loss: 4.93808e-02
I0209 23:47:04.365377 22509476222784 run_lib.py:146] step: 18400, eval_loss: 3.78451e-02
I0209 23:47:23.028884 22509476222784 run_lib.py:133] step: 18450, training_loss: 5.21061e-02
I0209 23:47:41.681494 22509476222784 run_lib.py:133] step: 18500, training_loss: 5.02504e-02
I0209 23:47:41.851181 22509476222784 run_lib.py:146] step: 18500, eval_loss: 3.83887e-02
I0209 23:48:00.634423 22509476222784 run_lib.py:133] step: 18550, training_loss: 5.08369e-02
I0209 23:48:19.266708 22509476222784 run_lib.py:133] step: 18600, training_loss: 4.47085e-02
I0209 23:48:19.431815 22509476222784 run_lib.py:146] step: 18600, eval_loss: 4.05789e-02
I0209 23:48:37.987212 22509476222784 run_lib.py:133] step: 18650, training_loss: 4.47798e-02
I0209 23:48:56.473859 22509476222784 run_lib.py:133] step: 18700, training_loss: 4.50718e-02
I0209 23:48:56.640290 22509476222784 run_lib.py:146] step: 18700, eval_loss: 3.93834e-02
I0209 23:49:15.429001 22509476222784 run_lib.py:133] step: 18750, training_loss: 5.18603e-02
I0209 23:49:34.058613 22509476222784 run_lib.py:133] step: 18800, training_loss: 3.68728e-02
I0209 23:49:34.229247 22509476222784 run_lib.py:146] step: 18800, eval_loss: 4.17058e-02
I0209 23:49:53.017451 22509476222784 run_lib.py:133] step: 18850, training_loss: 5.55939e-02
I0209 23:50:11.573050 22509476222784 run_lib.py:133] step: 18900, training_loss: 3.32803e-02
I0209 23:50:11.745439 22509476222784 run_lib.py:146] step: 18900, eval_loss: 4.55969e-02
I0209 23:50:30.423646 22509476222784 run_lib.py:133] step: 18950, training_loss: 4.56402e-02
I0209 23:50:48.996752 22509476222784 run_lib.py:133] step: 19000, training_loss: 4.67195e-02
I0209 23:50:49.198787 22509476222784 run_lib.py:146] step: 19000, eval_loss: 5.62108e-02
I0209 23:51:07.745379 22509476222784 run_lib.py:133] step: 19050, training_loss: 4.83632e-02
I0209 23:51:26.533323 22509476222784 run_lib.py:133] step: 19100, training_loss: 2.76289e-02
I0209 23:51:26.726891 22509476222784 run_lib.py:146] step: 19100, eval_loss: 3.72881e-02
I0209 23:51:45.269066 22509476222784 run_lib.py:133] step: 19150, training_loss: 5.01617e-02
I0209 23:52:03.942316 22509476222784 run_lib.py:133] step: 19200, training_loss: 5.17326e-02
I0209 23:52:04.109471 22509476222784 run_lib.py:146] step: 19200, eval_loss: 4.61080e-02
I0209 23:52:22.613890 22509476222784 run_lib.py:133] step: 19250, training_loss: 4.55736e-02
I0209 23:52:41.200631 22509476222784 run_lib.py:133] step: 19300, training_loss: 6.16962e-02
I0209 23:52:41.405754 22509476222784 run_lib.py:146] step: 19300, eval_loss: 4.57103e-02
I0209 23:53:00.160676 22509476222784 run_lib.py:133] step: 19350, training_loss: 3.92328e-02
I0209 23:53:18.728470 22509476222784 run_lib.py:133] step: 19400, training_loss: 5.34016e-02
I0209 23:53:18.943534 22509476222784 run_lib.py:146] step: 19400, eval_loss: 3.93219e-02
I0209 23:53:37.484386 22509476222784 run_lib.py:133] step: 19450, training_loss: 4.15604e-02
I0209 23:53:56.217459 22509476222784 run_lib.py:133] step: 19500, training_loss: 5.23187e-02
I0209 23:53:56.384741 22509476222784 run_lib.py:146] step: 19500, eval_loss: 3.49234e-02
I0209 23:54:14.962090 22509476222784 run_lib.py:133] step: 19550, training_loss: 3.90974e-02
I0209 23:54:33.614562 22509476222784 run_lib.py:133] step: 19600, training_loss: 5.34802e-02
I0209 23:54:33.780680 22509476222784 run_lib.py:146] step: 19600, eval_loss: 4.89165e-02
I0209 23:54:52.380577 22509476222784 run_lib.py:133] step: 19650, training_loss: 4.19061e-02
I0209 23:55:10.943062 22509476222784 run_lib.py:133] step: 19700, training_loss: 4.68045e-02
I0209 23:55:11.108611 22509476222784 run_lib.py:146] step: 19700, eval_loss: 5.24747e-02
I0209 23:55:29.781773 22509476222784 run_lib.py:133] step: 19750, training_loss: 4.37014e-02
I0209 23:55:48.327768 22509476222784 run_lib.py:133] step: 19800, training_loss: 4.85711e-02
I0209 23:55:48.505639 22509476222784 run_lib.py:146] step: 19800, eval_loss: 3.65349e-02
I0209 23:56:07.281675 22509476222784 run_lib.py:133] step: 19850, training_loss: 4.35881e-02
I0209 23:56:25.973007 22509476222784 run_lib.py:133] step: 19900, training_loss: 4.72190e-02
I0209 23:56:26.192593 22509476222784 run_lib.py:146] step: 19900, eval_loss: 4.00829e-02
I0209 23:56:44.717417 22509476222784 run_lib.py:133] step: 19950, training_loss: 5.05265e-02
I0209 23:57:03.228234 22509476222784 run_lib.py:133] step: 20000, training_loss: 5.33158e-02
I0209 23:57:03.968599 22509476222784 run_lib.py:146] step: 20000, eval_loss: 3.65456e-02
I0209 23:57:25.246198 22509476222784 run_lib.py:133] step: 20050, training_loss: 3.55019e-02
I0209 23:57:43.885448 22509476222784 run_lib.py:133] step: 20100, training_loss: 4.51931e-02
I0209 23:57:44.063376 22509476222784 run_lib.py:146] step: 20100, eval_loss: 4.00024e-02
I0209 23:58:02.715762 22509476222784 run_lib.py:133] step: 20150, training_loss: 4.58891e-02
I0209 23:58:21.287537 22509476222784 run_lib.py:133] step: 20200, training_loss: 5.18528e-02
I0209 23:58:21.452693 22509476222784 run_lib.py:146] step: 20200, eval_loss: 5.26282e-02
I0209 23:58:39.981290 22509476222784 run_lib.py:133] step: 20250, training_loss: 4.40222e-02
I0209 23:58:58.560763 22509476222784 run_lib.py:133] step: 20300, training_loss: 4.28317e-02
I0209 23:58:58.728525 22509476222784 run_lib.py:146] step: 20300, eval_loss: 4.60041e-02
I0209 23:59:17.435640 22509476222784 run_lib.py:133] step: 20350, training_loss: 4.12654e-02
I0209 23:59:36.148990 22509476222784 run_lib.py:133] step: 20400, training_loss: 6.50830e-02
I0209 23:59:36.322764 22509476222784 run_lib.py:146] step: 20400, eval_loss: 4.51544e-02
I0209 23:59:54.925717 22509476222784 run_lib.py:133] step: 20450, training_loss: 5.80587e-02
I0210 00:00:13.559655 22509476222784 run_lib.py:133] step: 20500, training_loss: 4.12972e-02
I0210 00:00:13.726844 22509476222784 run_lib.py:146] step: 20500, eval_loss: 4.94164e-02
I0210 00:00:32.410696 22509476222784 run_lib.py:133] step: 20550, training_loss: 4.68242e-02
I0210 00:00:50.959797 22509476222784 run_lib.py:133] step: 20600, training_loss: 4.76809e-02
I0210 00:00:51.150687 22509476222784 run_lib.py:146] step: 20600, eval_loss: 5.20336e-02
I0210 00:01:09.857864 22509476222784 run_lib.py:133] step: 20650, training_loss: 3.96131e-02
I0210 00:01:28.457387 22509476222784 run_lib.py:133] step: 20700, training_loss: 6.05998e-02
I0210 00:01:28.664296 22509476222784 run_lib.py:146] step: 20700, eval_loss: 4.59207e-02
I0210 00:01:47.385865 22509476222784 run_lib.py:133] step: 20750, training_loss: 5.34221e-02
I0210 00:02:05.941897 22509476222784 run_lib.py:133] step: 20800, training_loss: 5.74338e-02
I0210 00:02:06.124915 22509476222784 run_lib.py:146] step: 20800, eval_loss: 4.10696e-02
I0210 00:02:24.787274 22509476222784 run_lib.py:133] step: 20850, training_loss: 4.70409e-02
I0210 00:02:43.375755 22509476222784 run_lib.py:133] step: 20900, training_loss: 4.53489e-02
I0210 00:02:43.551855 22509476222784 run_lib.py:146] step: 20900, eval_loss: 5.36036e-02
I0210 00:03:02.130215 22509476222784 run_lib.py:133] step: 20950, training_loss: 4.68083e-02
I0210 00:03:20.890679 22509476222784 run_lib.py:133] step: 21000, training_loss: 4.34185e-02
I0210 00:03:21.094387 22509476222784 run_lib.py:146] step: 21000, eval_loss: 4.44733e-02
I0210 00:03:39.654390 22509476222784 run_lib.py:133] step: 21050, training_loss: 4.27266e-02
I0210 00:03:58.165225 22509476222784 run_lib.py:133] step: 21100, training_loss: 3.99519e-02
I0210 00:03:58.330465 22509476222784 run_lib.py:146] step: 21100, eval_loss: 3.72939e-02
I0210 00:04:17.017538 22509476222784 run_lib.py:133] step: 21150, training_loss: 4.38699e-02
I0210 00:04:35.815230 22509476222784 run_lib.py:133] step: 21200, training_loss: 4.97907e-02
I0210 00:04:36.024109 22509476222784 run_lib.py:146] step: 21200, eval_loss: 4.84242e-02
I0210 00:04:54.694990 22509476222784 run_lib.py:133] step: 21250, training_loss: 3.52677e-02
I0210 00:05:13.219705 22509476222784 run_lib.py:133] step: 21300, training_loss: 3.75447e-02
I0210 00:05:13.416533 22509476222784 run_lib.py:146] step: 21300, eval_loss: 3.85308e-02
I0210 00:05:31.939385 22509476222784 run_lib.py:133] step: 21350, training_loss: 4.71021e-02
I0210 00:05:50.649423 22509476222784 run_lib.py:133] step: 21400, training_loss: 4.95036e-02
I0210 00:05:50.822911 22509476222784 run_lib.py:146] step: 21400, eval_loss: 4.91789e-02
I0210 00:06:09.347024 22509476222784 run_lib.py:133] step: 21450, training_loss: 4.83238e-02
I0210 00:06:27.914527 22509476222784 run_lib.py:133] step: 21500, training_loss: 5.53757e-02
I0210 00:06:28.088487 22509476222784 run_lib.py:146] step: 21500, eval_loss: 5.35137e-02
I0210 00:06:46.674187 22509476222784 run_lib.py:133] step: 21550, training_loss: 3.58441e-02
I0210 00:07:05.450808 22509476222784 run_lib.py:133] step: 21600, training_loss: 4.51881e-02
I0210 00:07:05.627925 22509476222784 run_lib.py:146] step: 21600, eval_loss: 5.64456e-02
I0210 00:07:24.190109 22509476222784 run_lib.py:133] step: 21650, training_loss: 3.44532e-02
I0210 00:07:42.912317 22509476222784 run_lib.py:133] step: 21700, training_loss: 5.57955e-02
I0210 00:07:43.077312 22509476222784 run_lib.py:146] step: 21700, eval_loss: 3.46969e-02
I0210 00:08:01.645133 22509476222784 run_lib.py:133] step: 21750, training_loss: 4.30327e-02
I0210 00:08:20.222908 22509476222784 run_lib.py:133] step: 21800, training_loss: 5.28059e-02
I0210 00:08:20.388812 22509476222784 run_lib.py:146] step: 21800, eval_loss: 4.11155e-02
I0210 00:08:39.219641 22509476222784 run_lib.py:133] step: 21850, training_loss: 4.47134e-02
I0210 00:08:57.904330 22509476222784 run_lib.py:133] step: 21900, training_loss: 4.18070e-02
I0210 00:08:58.071819 22509476222784 run_lib.py:146] step: 21900, eval_loss: 3.67182e-02
I0210 00:09:16.614073 22509476222784 run_lib.py:133] step: 21950, training_loss: 4.19768e-02
I0210 00:09:35.239697 22509476222784 run_lib.py:133] step: 22000, training_loss: 4.08400e-02
I0210 00:09:35.421834 22509476222784 run_lib.py:146] step: 22000, eval_loss: 4.45551e-02
I0210 00:09:54.223187 22509476222784 run_lib.py:133] step: 22050, training_loss: 4.87009e-02
I0210 00:10:12.795860 22509476222784 run_lib.py:133] step: 22100, training_loss: 5.27657e-02
I0210 00:10:12.968404 22509476222784 run_lib.py:146] step: 22100, eval_loss: 4.61221e-02
I0210 00:10:31.695389 22509476222784 run_lib.py:133] step: 22150, training_loss: 5.71014e-02
I0210 00:10:50.321073 22509476222784 run_lib.py:133] step: 22200, training_loss: 3.01580e-02
I0210 00:10:50.483268 22509476222784 run_lib.py:146] step: 22200, eval_loss: 4.54227e-02
I0210 00:11:09.171239 22509476222784 run_lib.py:133] step: 22250, training_loss: 4.62323e-02
I0210 00:11:27.756302 22509476222784 run_lib.py:133] step: 22300, training_loss: 5.46376e-02
I0210 00:11:27.941570 22509476222784 run_lib.py:146] step: 22300, eval_loss: 4.07676e-02
I0210 00:11:46.533389 22509476222784 run_lib.py:133] step: 22350, training_loss: 6.19460e-02
I0210 00:12:05.268060 22509476222784 run_lib.py:133] step: 22400, training_loss: 4.68933e-02
I0210 00:12:05.443715 22509476222784 run_lib.py:146] step: 22400, eval_loss: 3.65969e-02
I0210 00:12:23.979994 22509476222784 run_lib.py:133] step: 22450, training_loss: 3.97889e-02
I0210 00:12:42.699578 22509476222784 run_lib.py:133] step: 22500, training_loss: 4.74819e-02
I0210 00:12:42.864671 22509476222784 run_lib.py:146] step: 22500, eval_loss: 5.06314e-02
I0210 00:13:01.471552 22509476222784 run_lib.py:133] step: 22550, training_loss: 4.23065e-02
I0210 00:13:20.108400 22509476222784 run_lib.py:133] step: 22600, training_loss: 4.67497e-02
I0210 00:13:20.321437 22509476222784 run_lib.py:146] step: 22600, eval_loss: 4.10668e-02
I0210 00:13:39.110932 22509476222784 run_lib.py:133] step: 22650, training_loss: 4.00181e-02
I0210 00:13:57.665938 22509476222784 run_lib.py:133] step: 22700, training_loss: 7.18886e-02
I0210 00:13:57.829105 22509476222784 run_lib.py:146] step: 22700, eval_loss: 4.15521e-02
I0210 00:14:16.406507 22509476222784 run_lib.py:133] step: 22750, training_loss: 5.43054e-02
I0210 00:14:35.200390 22509476222784 run_lib.py:133] step: 22800, training_loss: 4.37928e-02
I0210 00:14:35.383009 22509476222784 run_lib.py:146] step: 22800, eval_loss: 4.60726e-02
I0210 00:14:53.936511 22509476222784 run_lib.py:133] step: 22850, training_loss: 6.00641e-02
I0210 00:15:12.514105 22509476222784 run_lib.py:133] step: 22900, training_loss: 5.20958e-02
I0210 00:15:12.681884 22509476222784 run_lib.py:146] step: 22900, eval_loss: 5.53866e-02
I0210 00:15:31.284142 22509476222784 run_lib.py:133] step: 22950, training_loss: 5.82632e-02
I0210 00:15:49.838383 22509476222784 run_lib.py:133] step: 23000, training_loss: 6.43660e-02
I0210 00:15:50.006539 22509476222784 run_lib.py:146] step: 23000, eval_loss: 5.32720e-02
I0210 00:16:08.569039 22509476222784 run_lib.py:133] step: 23050, training_loss: 4.25359e-02
I0210 00:16:27.148445 22509476222784 run_lib.py:133] step: 23100, training_loss: 5.07020e-02
I0210 00:16:27.316879 22509476222784 run_lib.py:146] step: 23100, eval_loss: 4.00586e-02
I0210 00:16:46.085717 22509476222784 run_lib.py:133] step: 23150, training_loss: 5.44840e-02
I0210 00:17:04.720871 22509476222784 run_lib.py:133] step: 23200, training_loss: 3.62086e-02
I0210 00:17:04.899631 22509476222784 run_lib.py:146] step: 23200, eval_loss: 3.90590e-02
I0210 00:17:23.448522 22509476222784 run_lib.py:133] step: 23250, training_loss: 3.50904e-02
I0210 00:17:42.032056 22509476222784 run_lib.py:133] step: 23300, training_loss: 5.76575e-02
I0210 00:17:42.213570 22509476222784 run_lib.py:146] step: 23300, eval_loss: 4.38048e-02
I0210 00:18:01.019925 22509476222784 run_lib.py:133] step: 23350, training_loss: 5.10878e-02
I0210 00:18:19.677316 22509476222784 run_lib.py:133] step: 23400, training_loss: 3.85285e-02
I0210 00:18:19.844289 22509476222784 run_lib.py:146] step: 23400, eval_loss: 4.10358e-02
I0210 00:18:38.574440 22509476222784 run_lib.py:133] step: 23450, training_loss: 3.90509e-02
I0210 00:18:57.100675 22509476222784 run_lib.py:133] step: 23500, training_loss: 5.46296e-02
I0210 00:18:57.273768 22509476222784 run_lib.py:146] step: 23500, eval_loss: 3.31356e-02
I0210 00:19:16.026433 22509476222784 run_lib.py:133] step: 23550, training_loss: 4.20098e-02
I0210 00:19:34.609571 22509476222784 run_lib.py:133] step: 23600, training_loss: 4.96961e-02
I0210 00:19:34.774498 22509476222784 run_lib.py:146] step: 23600, eval_loss: 3.60573e-02
I0210 00:19:53.536523 22509476222784 run_lib.py:133] step: 23650, training_loss: 4.70438e-02
I0210 00:20:12.088205 22509476222784 run_lib.py:133] step: 23700, training_loss: 5.59704e-02
I0210 00:20:12.270620 22509476222784 run_lib.py:146] step: 23700, eval_loss: 4.79030e-02
I0210 00:20:30.798221 22509476222784 run_lib.py:133] step: 23750, training_loss: 4.70875e-02
I0210 00:20:49.530813 22509476222784 run_lib.py:133] step: 23800, training_loss: 5.20246e-02
I0210 00:20:49.712619 22509476222784 run_lib.py:146] step: 23800, eval_loss: 4.40254e-02
I0210 00:21:08.278519 22509476222784 run_lib.py:133] step: 23850, training_loss: 5.13505e-02
I0210 00:21:26.875988 22509476222784 run_lib.py:133] step: 23900, training_loss: 3.50975e-02
I0210 00:21:27.041695 22509476222784 run_lib.py:146] step: 23900, eval_loss: 5.69304e-02
I0210 00:21:45.801476 22509476222784 run_lib.py:133] step: 23950, training_loss: 4.91676e-02
I0210 00:22:04.384196 22509476222784 run_lib.py:133] step: 24000, training_loss: 3.89956e-02
I0210 00:22:04.550723 22509476222784 run_lib.py:146] step: 24000, eval_loss: 4.73844e-02
I0210 00:22:23.245295 22509476222784 run_lib.py:133] step: 24050, training_loss: 4.58061e-02
I0210 00:22:41.845385 22509476222784 run_lib.py:133] step: 24100, training_loss: 3.80346e-02
I0210 00:22:42.010883 22509476222784 run_lib.py:146] step: 24100, eval_loss: 4.55761e-02
I0210 00:23:00.605066 22509476222784 run_lib.py:133] step: 24150, training_loss: 4.38330e-02
I0210 00:23:19.380393 22509476222784 run_lib.py:133] step: 24200, training_loss: 5.09667e-02
I0210 00:23:19.546470 22509476222784 run_lib.py:146] step: 24200, eval_loss: 4.06655e-02
I0210 00:23:38.053882 22509476222784 run_lib.py:133] step: 24250, training_loss: 4.46367e-02
I0210 00:23:56.642260 22509476222784 run_lib.py:133] step: 24300, training_loss: 3.88236e-02
I0210 00:23:56.844824 22509476222784 run_lib.py:146] step: 24300, eval_loss: 3.93436e-02
I0210 00:24:15.438172 22509476222784 run_lib.py:133] step: 24350, training_loss: 5.71366e-02
I0210 00:24:34.252793 22509476222784 run_lib.py:133] step: 24400, training_loss: 3.99295e-02
I0210 00:24:34.477773 22509476222784 run_lib.py:146] step: 24400, eval_loss: 5.08609e-02
I0210 00:24:53.001089 22509476222784 run_lib.py:133] step: 24450, training_loss: 5.45080e-02
I0210 00:25:11.598196 22509476222784 run_lib.py:133] step: 24500, training_loss: 5.07780e-02
I0210 00:25:11.786536 22509476222784 run_lib.py:146] step: 24500, eval_loss: 4.63977e-02
I0210 00:25:30.339824 22509476222784 run_lib.py:133] step: 24550, training_loss: 4.30826e-02
I0210 00:25:48.918093 22509476222784 run_lib.py:133] step: 24600, training_loss: 4.86971e-02
I0210 00:25:49.104340 22509476222784 run_lib.py:146] step: 24600, eval_loss: 3.23694e-02
I0210 00:26:07.914029 22509476222784 run_lib.py:133] step: 24650, training_loss: 4.94359e-02
I0210 00:26:26.605959 22509476222784 run_lib.py:133] step: 24700, training_loss: 5.21469e-02
I0210 00:26:26.785572 22509476222784 run_lib.py:146] step: 24700, eval_loss: 3.55904e-02
I0210 00:26:45.365055 22509476222784 run_lib.py:133] step: 24750, training_loss: 5.69234e-02
I0210 00:27:03.959064 22509476222784 run_lib.py:133] step: 24800, training_loss: 6.28805e-02
I0210 00:27:04.158541 22509476222784 run_lib.py:146] step: 24800, eval_loss: 3.68634e-02
I0210 00:27:22.885244 22509476222784 run_lib.py:133] step: 24850, training_loss: 5.48914e-02
I0210 00:27:41.514220 22509476222784 run_lib.py:133] step: 24900, training_loss: 5.48504e-02
I0210 00:27:41.680871 22509476222784 run_lib.py:146] step: 24900, eval_loss: 4.50788e-02
I0210 00:28:00.455278 22509476222784 run_lib.py:133] step: 24950, training_loss: 5.09989e-02
I0210 00:28:18.986124 22509476222784 run_lib.py:133] step: 25000, training_loss: 4.41211e-02
I0210 00:28:19.150568 22509476222784 run_lib.py:146] step: 25000, eval_loss: 3.87291e-02
I0210 00:28:37.877338 22509476222784 run_lib.py:133] step: 25050, training_loss: 6.47757e-02
I0210 00:28:56.452844 22509476222784 run_lib.py:133] step: 25100, training_loss: 4.53611e-02
I0210 00:28:56.630754 22509476222784 run_lib.py:146] step: 25100, eval_loss: 4.22753e-02
I0210 00:29:15.243606 22509476222784 run_lib.py:133] step: 25150, training_loss: 4.42024e-02
I0210 00:29:34.065890 22509476222784 run_lib.py:133] step: 25200, training_loss: 4.68332e-02
I0210 00:29:34.233578 22509476222784 run_lib.py:146] step: 25200, eval_loss: 4.99624e-02
I0210 00:29:52.785661 22509476222784 run_lib.py:133] step: 25250, training_loss: 5.15504e-02
I0210 00:30:11.747041 22509476222784 run_lib.py:133] step: 25300, training_loss: 4.77644e-02
I0210 00:30:11.920500 22509476222784 run_lib.py:146] step: 25300, eval_loss: 4.95890e-02
I0210 00:30:30.489435 22509476222784 run_lib.py:133] step: 25350, training_loss: 3.61599e-02
I0210 00:30:49.146189 22509476222784 run_lib.py:133] step: 25400, training_loss: 4.36773e-02
I0210 00:30:49.314031 22509476222784 run_lib.py:146] step: 25400, eval_loss: 4.07776e-02
I0210 00:31:08.117630 22509476222784 run_lib.py:133] step: 25450, training_loss: 5.42950e-02
I0210 00:31:26.683954 22509476222784 run_lib.py:133] step: 25500, training_loss: 4.80659e-02
I0210 00:31:26.846564 22509476222784 run_lib.py:146] step: 25500, eval_loss: 4.42978e-02
I0210 00:31:45.420555 22509476222784 run_lib.py:133] step: 25550, training_loss: 3.49207e-02
I0210 00:32:04.299536 22509476222784 run_lib.py:133] step: 25600, training_loss: 5.64499e-02
I0210 00:32:04.472712 22509476222784 run_lib.py:146] step: 25600, eval_loss: 3.26641e-02
I0210 00:32:23.077191 22509476222784 run_lib.py:133] step: 25650, training_loss: 4.52670e-02
I0210 00:32:41.676445 22509476222784 run_lib.py:133] step: 25700, training_loss: 4.42468e-02
I0210 00:32:42.035524 22509476222784 run_lib.py:146] step: 25700, eval_loss: 3.90436e-02
I0210 00:33:00.586385 22509476222784 run_lib.py:133] step: 25750, training_loss: 4.34176e-02
I0210 00:33:19.149257 22509476222784 run_lib.py:133] step: 25800, training_loss: 5.64984e-02
I0210 00:33:19.312924 22509476222784 run_lib.py:146] step: 25800, eval_loss: 3.59343e-02
I0210 00:33:37.856752 22509476222784 run_lib.py:133] step: 25850, training_loss: 4.70289e-02
I0210 00:33:56.473988 22509476222784 run_lib.py:133] step: 25900, training_loss: 5.38538e-02
I0210 00:33:56.710710 22509476222784 run_lib.py:146] step: 25900, eval_loss: 4.87263e-02
I0210 00:34:15.514235 22509476222784 run_lib.py:133] step: 25950, training_loss: 4.25929e-02
I0210 00:34:34.108790 22509476222784 run_lib.py:133] step: 26000, training_loss: 4.07412e-02
I0210 00:34:34.271717 22509476222784 run_lib.py:146] step: 26000, eval_loss: 5.65214e-02
I0210 00:34:52.827767 22509476222784 run_lib.py:133] step: 26050, training_loss: 3.87611e-02
I0210 00:35:11.415157 22509476222784 run_lib.py:133] step: 26100, training_loss: 4.48088e-02
I0210 00:35:11.581601 22509476222784 run_lib.py:146] step: 26100, eval_loss: 4.22377e-02
I0210 00:35:30.318939 22509476222784 run_lib.py:133] step: 26150, training_loss: 5.06357e-02
I0210 00:35:49.044118 22509476222784 run_lib.py:133] step: 26200, training_loss: 5.44790e-02
I0210 00:35:49.213675 22509476222784 run_lib.py:146] step: 26200, eval_loss: 4.72882e-02
I0210 00:36:07.743551 22509476222784 run_lib.py:133] step: 26250, training_loss: 3.37285e-02
I0210 00:36:26.296509 22509476222784 run_lib.py:133] step: 26300, training_loss: 2.38698e-02
I0210 00:36:26.508065 22509476222784 run_lib.py:146] step: 26300, eval_loss: 4.24577e-02
I0210 00:36:45.213677 22509476222784 run_lib.py:133] step: 26350, training_loss: 3.59991e-02
I0210 00:37:03.784565 22509476222784 run_lib.py:133] step: 26400, training_loss: 3.53109e-02
I0210 00:37:03.982376 22509476222784 run_lib.py:146] step: 26400, eval_loss: 5.15317e-02
I0210 00:37:22.792533 22509476222784 run_lib.py:133] step: 26450, training_loss: 5.08232e-02
I0210 00:37:41.423181 22509476222784 run_lib.py:133] step: 26500, training_loss: 4.61008e-02
I0210 00:37:41.589764 22509476222784 run_lib.py:146] step: 26500, eval_loss: 4.17205e-02
I0210 00:38:00.423197 22509476222784 run_lib.py:133] step: 26550, training_loss: 4.18413e-02
I0210 00:38:19.052123 22509476222784 run_lib.py:133] step: 26600, training_loss: 3.64413e-02
I0210 00:38:19.218974 22509476222784 run_lib.py:146] step: 26600, eval_loss: 5.35572e-02
I0210 00:38:37.776304 22509476222784 run_lib.py:133] step: 26650, training_loss: 4.28789e-02
I0210 00:38:56.593559 22509476222784 run_lib.py:133] step: 26700, training_loss: 4.83789e-02
I0210 00:38:56.773226 22509476222784 run_lib.py:146] step: 26700, eval_loss: 4.51877e-02
I0210 00:39:15.366672 22509476222784 run_lib.py:133] step: 26750, training_loss: 4.77611e-02
I0210 00:39:34.066686 22509476222784 run_lib.py:133] step: 26800, training_loss: 4.38611e-02
I0210 00:39:34.232963 22509476222784 run_lib.py:146] step: 26800, eval_loss: 5.07148e-02
I0210 00:39:52.828726 22509476222784 run_lib.py:133] step: 26850, training_loss: 4.94890e-02
I0210 00:40:11.375357 22509476222784 run_lib.py:133] step: 26900, training_loss: 5.58735e-02
I0210 00:40:11.539644 22509476222784 run_lib.py:146] step: 26900, eval_loss: 3.69495e-02
I0210 00:40:30.111452 22509476222784 run_lib.py:133] step: 26950, training_loss: 3.78620e-02
I0210 00:40:48.893454 22509476222784 run_lib.py:133] step: 27000, training_loss: 5.68665e-02
I0210 00:40:49.075012 22509476222784 run_lib.py:146] step: 27000, eval_loss: 4.38858e-02
I0210 00:41:07.689361 22509476222784 run_lib.py:133] step: 27050, training_loss: 3.83182e-02
I0210 00:41:26.264827 22509476222784 run_lib.py:133] step: 27100, training_loss: 4.42010e-02
I0210 00:41:26.432128 22509476222784 run_lib.py:146] step: 27100, eval_loss: 5.41699e-02
I0210 00:41:45.138729 22509476222784 run_lib.py:133] step: 27150, training_loss: 3.93496e-02
I0210 00:42:03.708674 22509476222784 run_lib.py:133] step: 27200, training_loss: 4.08581e-02
I0210 00:42:03.874760 22509476222784 run_lib.py:146] step: 27200, eval_loss: 4.04296e-02
I0210 00:42:22.519395 22509476222784 run_lib.py:133] step: 27250, training_loss: 3.88294e-02
I0210 00:42:41.215202 22509476222784 run_lib.py:133] step: 27300, training_loss: 3.82821e-02
I0210 00:42:41.382407 22509476222784 run_lib.py:146] step: 27300, eval_loss: 3.86142e-02
I0210 00:42:59.957762 22509476222784 run_lib.py:133] step: 27350, training_loss: 3.99344e-02
I0210 00:43:18.514349 22509476222784 run_lib.py:133] step: 27400, training_loss: 5.22816e-02
I0210 00:43:18.676537 22509476222784 run_lib.py:146] step: 27400, eval_loss: 4.29108e-02
I0210 00:43:37.411701 22509476222784 run_lib.py:133] step: 27450, training_loss: 3.85520e-02
I0210 00:43:56.123097 22509476222784 run_lib.py:133] step: 27500, training_loss: 3.90204e-02
I0210 00:43:56.297938 22509476222784 run_lib.py:146] step: 27500, eval_loss: 4.88749e-02
I0210 00:44:14.948626 22509476222784 run_lib.py:133] step: 27550, training_loss: 4.32714e-02
I0210 00:44:33.586478 22509476222784 run_lib.py:133] step: 27600, training_loss: 4.68155e-02
I0210 00:44:33.754715 22509476222784 run_lib.py:146] step: 27600, eval_loss: 3.91049e-02
I0210 00:44:52.554650 22509476222784 run_lib.py:133] step: 27650, training_loss: 5.64360e-02
I0210 00:45:11.136867 22509476222784 run_lib.py:133] step: 27700, training_loss: 4.36013e-02
I0210 00:45:11.307649 22509476222784 run_lib.py:146] step: 27700, eval_loss: 4.41148e-02
I0210 00:45:29.983587 22509476222784 run_lib.py:133] step: 27750, training_loss: 4.85401e-02
I0210 00:45:48.617113 22509476222784 run_lib.py:133] step: 27800, training_loss: 4.50904e-02
I0210 00:45:48.791260 22509476222784 run_lib.py:146] step: 27800, eval_loss: 4.20117e-02
I0210 00:46:07.614307 22509476222784 run_lib.py:133] step: 27850, training_loss: 4.57825e-02
I0210 00:46:26.254225 22509476222784 run_lib.py:133] step: 27900, training_loss: 5.78390e-02
I0210 00:46:26.445611 22509476222784 run_lib.py:146] step: 27900, eval_loss: 4.49989e-02
I0210 00:46:45.149300 22509476222784 run_lib.py:133] step: 27950, training_loss: 3.40787e-02
I0210 00:47:03.706235 22509476222784 run_lib.py:133] step: 28000, training_loss: 3.81498e-02
I0210 00:47:03.871590 22509476222784 run_lib.py:146] step: 28000, eval_loss: 4.67190e-02
I0210 00:47:22.453445 22509476222784 run_lib.py:133] step: 28050, training_loss: 6.17501e-02
I0210 00:47:41.249957 22509476222784 run_lib.py:133] step: 28100, training_loss: 4.32632e-02
I0210 00:47:41.421601 22509476222784 run_lib.py:146] step: 28100, eval_loss: 4.14539e-02
I0210 00:47:59.962014 22509476222784 run_lib.py:133] step: 28150, training_loss: 4.19708e-02
I0210 00:48:18.497042 22509476222784 run_lib.py:133] step: 28200, training_loss: 5.76590e-02
I0210 00:48:18.687666 22509476222784 run_lib.py:146] step: 28200, eval_loss: 4.76013e-02
I0210 00:48:37.428436 22509476222784 run_lib.py:133] step: 28250, training_loss: 4.80529e-02
I0210 00:48:56.122639 22509476222784 run_lib.py:133] step: 28300, training_loss: 4.45272e-02
I0210 00:48:56.286655 22509476222784 run_lib.py:146] step: 28300, eval_loss: 4.76916e-02
I0210 00:49:14.856715 22509476222784 run_lib.py:133] step: 28350, training_loss: 5.00622e-02
I0210 00:49:33.424163 22509476222784 run_lib.py:133] step: 28400, training_loss: 4.03119e-02
I0210 00:49:33.592032 22509476222784 run_lib.py:146] step: 28400, eval_loss: 4.41921e-02
I0210 00:49:52.225897 22509476222784 run_lib.py:133] step: 28450, training_loss: 4.26528e-02
I0210 00:50:11.050350 22509476222784 run_lib.py:133] step: 28500, training_loss: 3.77902e-02
I0210 00:50:11.219309 22509476222784 run_lib.py:146] step: 28500, eval_loss: 5.36680e-02
I0210 00:50:29.770396 22509476222784 run_lib.py:133] step: 28550, training_loss: 3.89682e-02
I0210 00:50:48.358371 22509476222784 run_lib.py:133] step: 28600, training_loss: 4.31293e-02
I0210 00:50:48.534714 22509476222784 run_lib.py:146] step: 28600, eval_loss: 3.97784e-02
I0210 00:51:07.160967 22509476222784 run_lib.py:133] step: 28650, training_loss: 3.55702e-02
I0210 00:51:25.950383 22509476222784 run_lib.py:133] step: 28700, training_loss: 4.13043e-02
I0210 00:51:26.116449 22509476222784 run_lib.py:146] step: 28700, eval_loss: 6.12356e-02
I0210 00:51:44.664177 22509476222784 run_lib.py:133] step: 28750, training_loss: 3.40348e-02
I0210 00:52:03.286608 22509476222784 run_lib.py:133] step: 28800, training_loss: 4.62013e-02
I0210 00:52:03.450728 22509476222784 run_lib.py:146] step: 28800, eval_loss: 4.30966e-02
I0210 00:52:21.983197 22509476222784 run_lib.py:133] step: 28850, training_loss: 4.57179e-02
I0210 00:52:40.648556 22509476222784 run_lib.py:133] step: 28900, training_loss: 4.82356e-02
I0210 00:52:40.816951 22509476222784 run_lib.py:146] step: 28900, eval_loss: 5.46868e-02
I0210 00:52:59.639419 22509476222784 run_lib.py:133] step: 28950, training_loss: 4.52848e-02
I0210 00:53:18.360599 22509476222784 run_lib.py:133] step: 29000, training_loss: 4.49026e-02
I0210 00:53:18.527512 22509476222784 run_lib.py:146] step: 29000, eval_loss: 4.64462e-02
I0210 00:53:37.077698 22509476222784 run_lib.py:133] step: 29050, training_loss: 5.55402e-02
I0210 00:53:55.696883 22509476222784 run_lib.py:133] step: 29100, training_loss: 6.66232e-02
I0210 00:53:55.863719 22509476222784 run_lib.py:146] step: 29100, eval_loss: 4.01607e-02
I0210 00:54:14.555808 22509476222784 run_lib.py:133] step: 29150, training_loss: 3.89511e-02
I0210 00:54:33.146783 22509476222784 run_lib.py:133] step: 29200, training_loss: 4.69464e-02
I0210 00:54:33.315734 22509476222784 run_lib.py:146] step: 29200, eval_loss: 4.79752e-02
I0210 00:54:52.089475 22509476222784 run_lib.py:133] step: 29250, training_loss: 3.89739e-02
I0210 00:55:10.673617 22509476222784 run_lib.py:133] step: 29300, training_loss: 4.79721e-02
I0210 00:55:10.856695 22509476222784 run_lib.py:146] step: 29300, eval_loss: 3.48581e-02
I0210 00:55:29.619545 22509476222784 run_lib.py:133] step: 29350, training_loss: 4.68734e-02
I0210 00:55:48.166229 22509476222784 run_lib.py:133] step: 29400, training_loss: 4.81538e-02
I0210 00:55:48.334416 22509476222784 run_lib.py:146] step: 29400, eval_loss: 4.27447e-02
I0210 00:56:06.987782 22509476222784 run_lib.py:133] step: 29450, training_loss: 4.29990e-02
I0210 00:56:25.787220 22509476222784 run_lib.py:133] step: 29500, training_loss: 4.80756e-02
I0210 00:56:25.956533 22509476222784 run_lib.py:146] step: 29500, eval_loss: 5.11748e-02
I0210 00:56:44.534049 22509476222784 run_lib.py:133] step: 29550, training_loss: 4.94587e-02
I0210 00:57:03.269655 22509476222784 run_lib.py:133] step: 29600, training_loss: 5.51007e-02
I0210 00:57:03.438539 22509476222784 run_lib.py:146] step: 29600, eval_loss: 4.08094e-02
I0210 00:57:22.010944 22509476222784 run_lib.py:133] step: 29650, training_loss: 3.97904e-02
I0210 00:57:40.563767 22509476222784 run_lib.py:133] step: 29700, training_loss: 3.86413e-02
I0210 00:57:40.731742 22509476222784 run_lib.py:146] step: 29700, eval_loss: 4.35166e-02
I0210 00:57:59.577538 22509476222784 run_lib.py:133] step: 29750, training_loss: 4.86587e-02
I0210 00:58:18.236852 22509476222784 run_lib.py:133] step: 29800, training_loss: 4.72332e-02
I0210 00:58:18.401841 22509476222784 run_lib.py:146] step: 29800, eval_loss: 5.43502e-02
I0210 00:58:37.011379 22509476222784 run_lib.py:133] step: 29850, training_loss: 5.04131e-02
I0210 00:58:55.741909 22509476222784 run_lib.py:133] step: 29900, training_loss: 5.21883e-02
I0210 00:58:55.907678 22509476222784 run_lib.py:146] step: 29900, eval_loss: 3.82618e-02
I0210 00:59:14.415563 22509476222784 run_lib.py:133] step: 29950, training_loss: 4.00171e-02
I0210 00:59:33.034336 22509476222784 run_lib.py:133] step: 30000, training_loss: 4.68274e-02
I0210 00:59:33.861273 22509476222784 run_lib.py:146] step: 30000, eval_loss: 4.78215e-02
I0210 00:59:55.272068 22509476222784 run_lib.py:133] step: 30050, training_loss: 4.56706e-02
I0210 01:00:13.802164 22509476222784 run_lib.py:133] step: 30100, training_loss: 6.46741e-02
I0210 01:00:13.968538 22509476222784 run_lib.py:146] step: 30100, eval_loss: 4.10132e-02
I0210 01:00:32.600199 22509476222784 run_lib.py:133] step: 30150, training_loss: 5.81734e-02
I0210 01:00:51.164452 22509476222784 run_lib.py:133] step: 30200, training_loss: 4.95849e-02
I0210 01:00:51.332244 22509476222784 run_lib.py:146] step: 30200, eval_loss: 5.44433e-02
I0210 01:01:09.920630 22509476222784 run_lib.py:133] step: 30250, training_loss: 3.96232e-02
I0210 01:01:28.575841 22509476222784 run_lib.py:133] step: 30300, training_loss: 5.28189e-02
I0210 01:01:28.740867 22509476222784 run_lib.py:146] step: 30300, eval_loss: 3.90295e-02
I0210 01:01:47.566559 22509476222784 run_lib.py:133] step: 30350, training_loss: 3.86457e-02
I0210 01:02:06.201857 22509476222784 run_lib.py:133] step: 30400, training_loss: 4.56514e-02
I0210 01:02:06.367668 22509476222784 run_lib.py:146] step: 30400, eval_loss: 5.88218e-02
I0210 01:02:24.937296 22509476222784 run_lib.py:133] step: 30450, training_loss: 4.81197e-02
I0210 01:02:43.545015 22509476222784 run_lib.py:133] step: 30500, training_loss: 3.31678e-02
I0210 01:02:43.725443 22509476222784 run_lib.py:146] step: 30500, eval_loss: 4.32919e-02
I0210 01:03:02.507456 22509476222784 run_lib.py:133] step: 30550, training_loss: 4.35301e-02
I0210 01:03:21.171247 22509476222784 run_lib.py:133] step: 30600, training_loss: 5.37166e-02
I0210 01:03:21.338788 22509476222784 run_lib.py:146] step: 30600, eval_loss: 5.70814e-02
I0210 01:03:39.904405 22509476222784 run_lib.py:133] step: 30650, training_loss: 4.22479e-02
I0210 01:03:58.444677 22509476222784 run_lib.py:133] step: 30700, training_loss: 4.52939e-02
I0210 01:03:58.651519 22509476222784 run_lib.py:146] step: 30700, eval_loss: 5.57872e-02
I0210 01:04:17.433393 22509476222784 run_lib.py:133] step: 30750, training_loss: 4.27870e-02
I0210 01:04:36.016305 22509476222784 run_lib.py:133] step: 30800, training_loss: 5.10038e-02
I0210 01:04:36.225418 22509476222784 run_lib.py:146] step: 30800, eval_loss: 5.35189e-02
I0210 01:04:55.037941 22509476222784 run_lib.py:133] step: 30850, training_loss: 5.81403e-02
I0210 01:05:13.558016 22509476222784 run_lib.py:133] step: 30900, training_loss: 5.41956e-02
I0210 01:05:13.735078 22509476222784 run_lib.py:146] step: 30900, eval_loss: 4.37837e-02
I0210 01:05:32.439971 22509476222784 run_lib.py:133] step: 30950, training_loss: 4.23173e-02
I0210 01:05:51.103680 22509476222784 run_lib.py:133] step: 31000, training_loss: 3.37731e-02
I0210 01:05:51.285752 22509476222784 run_lib.py:146] step: 31000, eval_loss: 3.20164e-02
I0210 01:06:09.902878 22509476222784 run_lib.py:133] step: 31050, training_loss: 3.98020e-02
I0210 01:06:28.673169 22509476222784 run_lib.py:133] step: 31100, training_loss: 4.06600e-02
I0210 01:06:28.839909 22509476222784 run_lib.py:146] step: 31100, eval_loss: 4.78025e-02
I0210 01:06:47.437949 22509476222784 run_lib.py:133] step: 31150, training_loss: 5.11255e-02
I0210 01:07:06.197082 22509476222784 run_lib.py:133] step: 31200, training_loss: 3.83789e-02
I0210 01:07:06.362648 22509476222784 run_lib.py:146] step: 31200, eval_loss: 3.97504e-02
I0210 01:07:24.943361 22509476222784 run_lib.py:133] step: 31250, training_loss: 5.41598e-02
I0210 01:07:43.910718 22509476222784 run_lib.py:133] step: 31300, training_loss: 4.99448e-02
I0210 01:07:44.075894 22509476222784 run_lib.py:146] step: 31300, eval_loss: 4.45570e-02
I0210 01:08:02.861162 22509476222784 run_lib.py:133] step: 31350, training_loss: 4.15948e-02
I0210 01:08:21.442962 22509476222784 run_lib.py:133] step: 31400, training_loss: 5.04579e-02
I0210 01:08:21.609159 22509476222784 run_lib.py:146] step: 31400, eval_loss: 3.58323e-02
I0210 01:08:40.216079 22509476222784 run_lib.py:133] step: 31450, training_loss: 4.01788e-02
I0210 01:08:58.883883 22509476222784 run_lib.py:133] step: 31500, training_loss: 4.52692e-02
I0210 01:08:59.065674 22509476222784 run_lib.py:146] step: 31500, eval_loss: 4.43458e-02
I0210 01:09:17.864348 22509476222784 run_lib.py:133] step: 31550, training_loss: 4.03132e-02
I0210 01:09:36.440665 22509476222784 run_lib.py:133] step: 31600, training_loss: 2.94511e-02
I0210 01:09:36.607861 22509476222784 run_lib.py:146] step: 31600, eval_loss: 4.98685e-02
I0210 01:09:55.324220 22509476222784 run_lib.py:133] step: 31650, training_loss: 4.17431e-02
I0210 01:10:13.832911 22509476222784 run_lib.py:133] step: 31700, training_loss: 4.93091e-02
I0210 01:10:13.998825 22509476222784 run_lib.py:146] step: 31700, eval_loss: 5.87752e-02
I0210 01:10:32.573201 22509476222784 run_lib.py:133] step: 31750, training_loss: 5.80496e-02
I0210 01:10:51.229134 22509476222784 run_lib.py:133] step: 31800, training_loss: 2.68795e-02
I0210 01:10:51.425921 22509476222784 run_lib.py:146] step: 31800, eval_loss: 5.55528e-02
I0210 01:11:10.261994 22509476222784 run_lib.py:133] step: 31850, training_loss: 4.17684e-02
I0210 01:11:28.913967 22509476222784 run_lib.py:133] step: 31900, training_loss: 4.09060e-02
I0210 01:11:29.081670 22509476222784 run_lib.py:146] step: 31900, eval_loss: 5.02332e-02
I0210 01:11:47.646280 22509476222784 run_lib.py:133] step: 31950, training_loss: 6.25120e-02
I0210 01:12:06.284870 22509476222784 run_lib.py:133] step: 32000, training_loss: 5.35927e-02
I0210 01:12:06.452904 22509476222784 run_lib.py:146] step: 32000, eval_loss: 3.25110e-02
I0210 01:12:25.224684 22509476222784 run_lib.py:133] step: 32050, training_loss: 3.76967e-02
I0210 01:12:43.917567 22509476222784 run_lib.py:133] step: 32100, training_loss: 5.48847e-02
I0210 01:12:44.084517 22509476222784 run_lib.py:146] step: 32100, eval_loss: 5.36177e-02
I0210 01:13:02.881345 22509476222784 run_lib.py:133] step: 32150, training_loss: 4.68432e-02
I0210 01:13:21.497305 22509476222784 run_lib.py:133] step: 32200, training_loss: 4.75161e-02
I0210 01:13:21.661532 22509476222784 run_lib.py:146] step: 32200, eval_loss: 6.91537e-02
I0210 01:13:40.324718 22509476222784 run_lib.py:133] step: 32250, training_loss: 3.91632e-02
I0210 01:13:58.884619 22509476222784 run_lib.py:133] step: 32300, training_loss: 5.15602e-02
I0210 01:13:59.048775 22509476222784 run_lib.py:146] step: 32300, eval_loss: 4.41940e-02
I0210 01:14:17.840281 22509476222784 run_lib.py:133] step: 32350, training_loss: 4.44977e-02
I0210 01:14:36.453160 22509476222784 run_lib.py:133] step: 32400, training_loss: 4.30626e-02
I0210 01:14:36.622756 22509476222784 run_lib.py:146] step: 32400, eval_loss: 4.63472e-02
I0210 01:14:55.244726 22509476222784 run_lib.py:133] step: 32450, training_loss: 3.05652e-02
I0210 01:15:13.993428 22509476222784 run_lib.py:133] step: 32500, training_loss: 5.96851e-02
I0210 01:15:14.159709 22509476222784 run_lib.py:146] step: 32500, eval_loss: 5.96931e-02
I0210 01:15:32.733100 22509476222784 run_lib.py:133] step: 32550, training_loss: 5.23025e-02
I0210 01:15:51.385736 22509476222784 run_lib.py:133] step: 32600, training_loss: 5.60674e-02
I0210 01:15:51.552366 22509476222784 run_lib.py:146] step: 32600, eval_loss: 4.99550e-02
I0210 01:16:10.365230 22509476222784 run_lib.py:133] step: 32650, training_loss: 4.69579e-02
I0210 01:16:29.278256 22509476222784 run_lib.py:133] step: 32700, training_loss: 4.86449e-02
I0210 01:16:29.440659 22509476222784 run_lib.py:146] step: 32700, eval_loss: 4.35397e-02
I0210 01:16:47.986909 22509476222784 run_lib.py:133] step: 32750, training_loss: 3.11957e-02
I0210 01:17:06.642451 22509476222784 run_lib.py:133] step: 32800, training_loss: 5.26834e-02
I0210 01:17:06.808997 22509476222784 run_lib.py:146] step: 32800, eval_loss: 4.24887e-02
I0210 01:17:25.382464 22509476222784 run_lib.py:133] step: 32850, training_loss: 4.69739e-02
I0210 01:17:44.157435 22509476222784 run_lib.py:133] step: 32900, training_loss: 5.02876e-02
I0210 01:17:44.394540 22509476222784 run_lib.py:146] step: 32900, eval_loss: 4.14593e-02
I0210 01:18:02.979730 22509476222784 run_lib.py:133] step: 32950, training_loss: 4.92404e-02
I0210 01:18:21.529595 22509476222784 run_lib.py:133] step: 33000, training_loss: 3.73848e-02
I0210 01:18:21.725680 22509476222784 run_lib.py:146] step: 33000, eval_loss: 3.47389e-02
I0210 01:18:40.295329 22509476222784 run_lib.py:133] step: 33050, training_loss: 4.97533e-02
I0210 01:18:59.014611 22509476222784 run_lib.py:133] step: 33100, training_loss: 4.65055e-02
I0210 01:18:59.219618 22509476222784 run_lib.py:146] step: 33100, eval_loss: 6.34585e-02
I0210 01:19:17.852659 22509476222784 run_lib.py:133] step: 33150, training_loss: 4.16421e-02
I0210 01:19:36.558266 22509476222784 run_lib.py:133] step: 33200, training_loss: 5.57290e-02
I0210 01:19:36.743915 22509476222784 run_lib.py:146] step: 33200, eval_loss: 4.85674e-02
I0210 01:19:55.306708 22509476222784 run_lib.py:133] step: 33250, training_loss: 4.69384e-02
I0210 01:20:13.906563 22509476222784 run_lib.py:133] step: 33300, training_loss: 4.57114e-02
I0210 01:20:14.107731 22509476222784 run_lib.py:146] step: 33300, eval_loss: 3.48168e-02
I0210 01:20:32.855321 22509476222784 run_lib.py:133] step: 33350, training_loss: 4.65102e-02
I0210 01:20:51.701437 22509476222784 run_lib.py:133] step: 33400, training_loss: 4.52888e-02
I0210 01:20:51.924535 22509476222784 run_lib.py:146] step: 33400, eval_loss: 4.57418e-02
I0210 01:21:10.514243 22509476222784 run_lib.py:133] step: 33450, training_loss: 4.75751e-02
I0210 01:21:29.071194 22509476222784 run_lib.py:133] step: 33500, training_loss: 5.07642e-02
I0210 01:21:29.236545 22509476222784 run_lib.py:146] step: 33500, eval_loss: 4.55070e-02
I0210 01:21:47.962959 22509476222784 run_lib.py:133] step: 33550, training_loss: 5.00489e-02
I0210 01:22:06.492830 22509476222784 run_lib.py:133] step: 33600, training_loss: 5.66991e-02
I0210 01:22:06.655773 22509476222784 run_lib.py:146] step: 33600, eval_loss: 3.20566e-02
I0210 01:22:25.323488 22509476222784 run_lib.py:133] step: 33650, training_loss: 4.65336e-02
I0210 01:22:43.919408 22509476222784 run_lib.py:133] step: 33700, training_loss: 3.63478e-02
I0210 01:22:44.084686 22509476222784 run_lib.py:146] step: 33700, eval_loss: 4.13373e-02
I0210 01:23:02.974322 22509476222784 run_lib.py:133] step: 33750, training_loss: 4.36751e-02
I0210 01:23:21.528035 22509476222784 run_lib.py:133] step: 33800, training_loss: 4.55326e-02
I0210 01:23:21.696860 22509476222784 run_lib.py:146] step: 33800, eval_loss: 5.24672e-02
I0210 01:23:40.179977 22509476222784 run_lib.py:133] step: 33850, training_loss: 5.26888e-02
I0210 01:23:58.860412 22509476222784 run_lib.py:133] step: 33900, training_loss: 4.46759e-02
I0210 01:23:59.084549 22509476222784 run_lib.py:146] step: 33900, eval_loss: 4.90210e-02
I0210 01:24:17.710570 22509476222784 run_lib.py:133] step: 33950, training_loss: 5.69408e-02
I0210 01:24:36.478813 22509476222784 run_lib.py:133] step: 34000, training_loss: 4.22816e-02
I0210 01:24:36.673290 22509476222784 run_lib.py:146] step: 34000, eval_loss: 4.72217e-02
I0210 01:24:55.204522 22509476222784 run_lib.py:133] step: 34050, training_loss: 5.06664e-02
I0210 01:25:13.710329 22509476222784 run_lib.py:133] step: 34100, training_loss: 3.61924e-02
I0210 01:25:13.873604 22509476222784 run_lib.py:146] step: 34100, eval_loss: 4.84019e-02
I0210 01:25:32.556257 22509476222784 run_lib.py:133] step: 34150, training_loss: 4.46471e-02
I0210 01:25:51.146679 22509476222784 run_lib.py:133] step: 34200, training_loss: 4.85420e-02
I0210 01:25:51.345767 22509476222784 run_lib.py:146] step: 34200, eval_loss: 4.21493e-02
I0210 01:26:09.922286 22509476222784 run_lib.py:133] step: 34250, training_loss: 5.04908e-02
I0210 01:26:28.678694 22509476222784 run_lib.py:133] step: 34300, training_loss: 3.80298e-02
I0210 01:26:28.886515 22509476222784 run_lib.py:146] step: 34300, eval_loss: 4.67337e-02
I0210 01:26:47.480184 22509476222784 run_lib.py:133] step: 34350, training_loss: 5.55157e-02
I0210 01:27:06.018503 22509476222784 run_lib.py:133] step: 34400, training_loss: 6.42863e-02
I0210 01:27:06.184639 22509476222784 run_lib.py:146] step: 34400, eval_loss: 4.32239e-02
I0210 01:27:24.811691 22509476222784 run_lib.py:133] step: 34450, training_loss: 4.55464e-02
I0210 01:27:43.421217 22509476222784 run_lib.py:133] step: 34500, training_loss: 5.03115e-02
I0210 01:27:43.599380 22509476222784 run_lib.py:146] step: 34500, eval_loss: 4.07287e-02
I0210 01:28:02.161207 22509476222784 run_lib.py:133] step: 34550, training_loss: 4.33175e-02
I0210 01:28:20.710963 22509476222784 run_lib.py:133] step: 34600, training_loss: 4.02534e-02
I0210 01:28:20.872373 22509476222784 run_lib.py:146] step: 34600, eval_loss: 5.84459e-02
I0210 01:28:39.590548 22509476222784 run_lib.py:133] step: 34650, training_loss: 5.08653e-02
I0210 01:28:58.247798 22509476222784 run_lib.py:133] step: 34700, training_loss: 5.35519e-02
I0210 01:28:58.428822 22509476222784 run_lib.py:146] step: 34700, eval_loss: 4.56731e-02
I0210 01:29:17.035870 22509476222784 run_lib.py:133] step: 34750, training_loss: 5.46364e-02
I0210 01:29:35.648838 22509476222784 run_lib.py:133] step: 34800, training_loss: 4.86018e-02
I0210 01:29:35.819998 22509476222784 run_lib.py:146] step: 34800, eval_loss: 3.46166e-02
I0210 01:29:54.560594 22509476222784 run_lib.py:133] step: 34850, training_loss: 5.83928e-02
I0210 01:30:13.108977 22509476222784 run_lib.py:133] step: 34900, training_loss: 4.69470e-02
I0210 01:30:13.273688 22509476222784 run_lib.py:146] step: 34900, eval_loss: 5.12714e-02
I0210 01:30:31.966905 22509476222784 run_lib.py:133] step: 34950, training_loss: 4.94758e-02
I0210 01:30:50.561650 22509476222784 run_lib.py:133] step: 35000, training_loss: 4.93522e-02
I0210 01:30:50.726869 22509476222784 run_lib.py:146] step: 35000, eval_loss: 4.59036e-02
I0210 01:31:09.473955 22509476222784 run_lib.py:133] step: 35050, training_loss: 5.68412e-02
I0210 01:31:27.981842 22509476222784 run_lib.py:133] step: 35100, training_loss: 4.26049e-02
I0210 01:31:28.144520 22509476222784 run_lib.py:146] step: 35100, eval_loss: 6.62367e-02
I0210 01:31:46.885208 22509476222784 run_lib.py:133] step: 35150, training_loss: 4.54532e-02
I0210 01:32:05.397307 22509476222784 run_lib.py:133] step: 35200, training_loss: 4.40630e-02
I0210 01:32:05.560500 22509476222784 run_lib.py:146] step: 35200, eval_loss: 4.74768e-02
I0210 01:32:24.051805 22509476222784 run_lib.py:133] step: 35250, training_loss: 5.55554e-02
I0210 01:32:42.807474 22509476222784 run_lib.py:133] step: 35300, training_loss: 4.06832e-02
I0210 01:32:42.982530 22509476222784 run_lib.py:146] step: 35300, eval_loss: 4.81315e-02
I0210 01:33:01.556689 22509476222784 run_lib.py:133] step: 35350, training_loss: 4.95538e-02
I0210 01:33:20.113341 22509476222784 run_lib.py:133] step: 35400, training_loss: 5.61223e-02
I0210 01:33:20.279832 22509476222784 run_lib.py:146] step: 35400, eval_loss: 4.95211e-02
I0210 01:33:39.013089 22509476222784 run_lib.py:133] step: 35450, training_loss: 4.69832e-02
I0210 01:33:57.531990 22509476222784 run_lib.py:133] step: 35500, training_loss: 5.00729e-02
I0210 01:33:57.695500 22509476222784 run_lib.py:146] step: 35500, eval_loss: 5.18096e-02
I0210 01:34:16.440995 22509476222784 run_lib.py:133] step: 35550, training_loss: 5.00657e-02
I0210 01:34:35.000397 22509476222784 run_lib.py:133] step: 35600, training_loss: 5.56765e-02
I0210 01:34:35.220819 22509476222784 run_lib.py:146] step: 35600, eval_loss: 3.79654e-02
I0210 01:34:53.827372 22509476222784 run_lib.py:133] step: 35650, training_loss: 4.65010e-02
I0210 01:35:12.611587 22509476222784 run_lib.py:133] step: 35700, training_loss: 4.50566e-02
I0210 01:35:12.779741 22509476222784 run_lib.py:146] step: 35700, eval_loss: 4.10605e-02
I0210 01:35:31.298184 22509476222784 run_lib.py:133] step: 35750, training_loss: 4.50225e-02
I0210 01:35:49.876555 22509476222784 run_lib.py:133] step: 35800, training_loss: 5.01070e-02
I0210 01:35:50.049899 22509476222784 run_lib.py:146] step: 35800, eval_loss: 4.34770e-02
I0210 01:36:08.561790 22509476222784 run_lib.py:133] step: 35850, training_loss: 4.00615e-02
I0210 01:36:27.325012 22509476222784 run_lib.py:133] step: 35900, training_loss: 5.02573e-02
I0210 01:36:27.529829 22509476222784 run_lib.py:146] step: 35900, eval_loss: 4.98683e-02
I0210 01:36:46.069589 22509476222784 run_lib.py:133] step: 35950, training_loss: 5.67600e-02
I0210 01:37:04.662633 22509476222784 run_lib.py:133] step: 36000, training_loss: 3.55698e-02
I0210 01:37:04.825455 22509476222784 run_lib.py:146] step: 36000, eval_loss: 4.31297e-02
I0210 01:37:23.391156 22509476222784 run_lib.py:133] step: 36050, training_loss: 3.86297e-02
I0210 01:37:41.969298 22509476222784 run_lib.py:133] step: 36100, training_loss: 6.09052e-02
I0210 01:37:42.154044 22509476222784 run_lib.py:146] step: 36100, eval_loss: 4.44789e-02
I0210 01:38:00.893570 22509476222784 run_lib.py:133] step: 36150, training_loss: 4.14846e-02
I0210 01:38:19.542904 22509476222784 run_lib.py:133] step: 36200, training_loss: 4.41592e-02
I0210 01:38:19.742707 22509476222784 run_lib.py:146] step: 36200, eval_loss: 4.36111e-02
I0210 01:38:38.252181 22509476222784 run_lib.py:133] step: 36250, training_loss: 4.49250e-02
I0210 01:38:56.807752 22509476222784 run_lib.py:133] step: 36300, training_loss: 6.19208e-02
I0210 01:38:57.007570 22509476222784 run_lib.py:146] step: 36300, eval_loss: 4.55944e-02
I0210 01:39:15.727221 22509476222784 run_lib.py:133] step: 36350, training_loss: 4.39826e-02
I0210 01:39:34.296621 22509476222784 run_lib.py:133] step: 36400, training_loss: 4.55340e-02
I0210 01:39:34.464692 22509476222784 run_lib.py:146] step: 36400, eval_loss: 5.54986e-02
I0210 01:39:53.201318 22509476222784 run_lib.py:133] step: 36450, training_loss: 3.51615e-02
I0210 01:40:11.763003 22509476222784 run_lib.py:133] step: 36500, training_loss: 4.90609e-02
I0210 01:40:11.924667 22509476222784 run_lib.py:146] step: 36500, eval_loss: 4.08415e-02
I0210 01:40:30.626468 22509476222784 run_lib.py:133] step: 36550, training_loss: 3.70857e-02
I0210 01:40:49.174347 22509476222784 run_lib.py:133] step: 36600, training_loss: 4.27747e-02
I0210 01:40:49.347815 22509476222784 run_lib.py:146] step: 36600, eval_loss: 4.47778e-02
I0210 01:41:07.945771 22509476222784 run_lib.py:133] step: 36650, training_loss: 4.98366e-02
I0210 01:41:26.713356 22509476222784 run_lib.py:133] step: 36700, training_loss: 3.90766e-02
I0210 01:41:26.879470 22509476222784 run_lib.py:146] step: 36700, eval_loss: 3.07881e-02
I0210 01:41:45.391189 22509476222784 run_lib.py:133] step: 36750, training_loss: 5.91342e-02
I0210 01:42:04.042370 22509476222784 run_lib.py:133] step: 36800, training_loss: 4.10413e-02
I0210 01:42:04.207085 22509476222784 run_lib.py:146] step: 36800, eval_loss: 4.22824e-02
I0210 01:42:22.722072 22509476222784 run_lib.py:133] step: 36850, training_loss: 5.00381e-02
I0210 01:42:41.304811 22509476222784 run_lib.py:133] step: 36900, training_loss: 4.98439e-02
I0210 01:42:41.469926 22509476222784 run_lib.py:146] step: 36900, eval_loss: 5.53599e-02
I0210 01:43:00.271529 22509476222784 run_lib.py:133] step: 36950, training_loss: 4.79175e-02
I0210 01:43:18.850174 22509476222784 run_lib.py:133] step: 37000, training_loss: 5.12029e-02
I0210 01:43:19.013061 22509476222784 run_lib.py:146] step: 37000, eval_loss: 3.52912e-02
I0210 01:43:37.520191 22509476222784 run_lib.py:133] step: 37050, training_loss: 3.61313e-02
I0210 01:43:56.227272 22509476222784 run_lib.py:133] step: 37100, training_loss: 3.32648e-02
I0210 01:43:56.390285 22509476222784 run_lib.py:146] step: 37100, eval_loss: 3.86704e-02
I0210 01:44:14.945847 22509476222784 run_lib.py:133] step: 37150, training_loss: 5.07752e-02
I0210 01:44:33.643196 22509476222784 run_lib.py:133] step: 37200, training_loss: 5.63970e-02
I0210 01:44:34.004375 22509476222784 run_lib.py:146] step: 37200, eval_loss: 3.16432e-02
I0210 01:44:52.543758 22509476222784 run_lib.py:133] step: 37250, training_loss: 3.85595e-02
I0210 01:45:11.097928 22509476222784 run_lib.py:133] step: 37300, training_loss: 4.38176e-02
I0210 01:45:11.263518 22509476222784 run_lib.py:146] step: 37300, eval_loss: 5.61213e-02
I0210 01:45:29.812850 22509476222784 run_lib.py:133] step: 37350, training_loss: 5.00191e-02
I0210 01:45:48.347924 22509476222784 run_lib.py:133] step: 37400, training_loss: 4.24233e-02
I0210 01:45:48.510535 22509476222784 run_lib.py:146] step: 37400, eval_loss: 5.57683e-02
I0210 01:46:07.239349 22509476222784 run_lib.py:133] step: 37450, training_loss: 3.72287e-02
I0210 01:46:25.904991 22509476222784 run_lib.py:133] step: 37500, training_loss: 3.50990e-02
I0210 01:46:26.072757 22509476222784 run_lib.py:146] step: 37500, eval_loss: 4.01070e-02
I0210 01:46:44.626152 22509476222784 run_lib.py:133] step: 37550, training_loss: 5.44622e-02
I0210 01:47:03.186105 22509476222784 run_lib.py:133] step: 37600, training_loss: 4.26853e-02
I0210 01:47:03.352687 22509476222784 run_lib.py:146] step: 37600, eval_loss: 5.30773e-02
I0210 01:47:22.029033 22509476222784 run_lib.py:133] step: 37650, training_loss: 3.56378e-02
I0210 01:47:40.711385 22509476222784 run_lib.py:133] step: 37700, training_loss: 4.54086e-02
I0210 01:47:40.884498 22509476222784 run_lib.py:146] step: 37700, eval_loss: 3.88800e-02
I0210 01:47:59.503604 22509476222784 run_lib.py:133] step: 37750, training_loss: 4.06001e-02
I0210 01:48:18.208112 22509476222784 run_lib.py:133] step: 37800, training_loss: 3.81750e-02
I0210 01:48:18.372950 22509476222784 run_lib.py:146] step: 37800, eval_loss: 4.65725e-02
I0210 01:48:37.165870 22509476222784 run_lib.py:133] step: 37850, training_loss: 4.82639e-02
I0210 01:48:55.725559 22509476222784 run_lib.py:133] step: 37900, training_loss: 3.86753e-02
I0210 01:48:55.882834 22509476222784 run_lib.py:146] step: 37900, eval_loss: 4.51784e-02
I0210 01:49:14.569569 22509476222784 run_lib.py:133] step: 37950, training_loss: 4.37284e-02
I0210 01:49:33.169596 22509476222784 run_lib.py:133] step: 38000, training_loss: 5.84843e-02
I0210 01:49:33.375773 22509476222784 run_lib.py:146] step: 38000, eval_loss: 4.47761e-02
I0210 01:49:52.200250 22509476222784 run_lib.py:133] step: 38050, training_loss: 4.13167e-02
I0210 01:50:10.787618 22509476222784 run_lib.py:133] step: 38100, training_loss: 3.71724e-02
I0210 01:50:11.022559 22509476222784 run_lib.py:146] step: 38100, eval_loss: 4.02483e-02
I0210 01:50:29.522190 22509476222784 run_lib.py:133] step: 38150, training_loss: 4.07725e-02
I0210 01:50:48.197952 22509476222784 run_lib.py:133] step: 38200, training_loss: 4.64975e-02
I0210 01:50:48.406656 22509476222784 run_lib.py:146] step: 38200, eval_loss: 3.96964e-02
I0210 01:51:06.921920 22509476222784 run_lib.py:133] step: 38250, training_loss: 4.96663e-02
I0210 01:51:25.720044 22509476222784 run_lib.py:133] step: 38300, training_loss: 4.76804e-02
I0210 01:51:25.918751 22509476222784 run_lib.py:146] step: 38300, eval_loss: 4.67442e-02
I0210 01:51:44.487002 22509476222784 run_lib.py:133] step: 38350, training_loss: 3.84887e-02
I0210 01:52:03.028490 22509476222784 run_lib.py:133] step: 38400, training_loss: 4.43455e-02
I0210 01:52:03.283568 22509476222784 run_lib.py:146] step: 38400, eval_loss: 4.13300e-02
I0210 01:52:21.859005 22509476222784 run_lib.py:133] step: 38450, training_loss: 4.36620e-02
I0210 01:52:40.612036 22509476222784 run_lib.py:133] step: 38500, training_loss: 4.95406e-02
I0210 01:52:40.842890 22509476222784 run_lib.py:146] step: 38500, eval_loss: 5.05945e-02
I0210 01:52:59.500312 22509476222784 run_lib.py:133] step: 38550, training_loss: 3.14385e-02
I0210 01:53:18.122611 22509476222784 run_lib.py:133] step: 38600, training_loss: 5.23187e-02
I0210 01:53:18.377522 22509476222784 run_lib.py:146] step: 38600, eval_loss: 5.43190e-02
I0210 01:53:37.084289 22509476222784 run_lib.py:133] step: 38650, training_loss: 4.97835e-02
I0210 01:53:55.590792 22509476222784 run_lib.py:133] step: 38700, training_loss: 4.94626e-02
I0210 01:53:55.758542 22509476222784 run_lib.py:146] step: 38700, eval_loss: 4.42685e-02
I0210 01:54:14.371146 22509476222784 run_lib.py:133] step: 38750, training_loss: 5.02513e-02
I0210 01:54:33.035065 22509476222784 run_lib.py:133] step: 38800, training_loss: 4.36622e-02
I0210 01:54:33.200837 22509476222784 run_lib.py:146] step: 38800, eval_loss: 3.82407e-02
I0210 01:54:51.767603 22509476222784 run_lib.py:133] step: 38850, training_loss: 4.23670e-02
I0210 01:55:10.276095 22509476222784 run_lib.py:133] step: 38900, training_loss: 4.07984e-02
I0210 01:55:10.437226 22509476222784 run_lib.py:146] step: 38900, eval_loss: 3.64337e-02
I0210 01:55:29.233277 22509476222784 run_lib.py:133] step: 38950, training_loss: 5.14944e-02
I0210 01:55:47.834463 22509476222784 run_lib.py:133] step: 39000, training_loss: 4.19339e-02
I0210 01:55:48.009977 22509476222784 run_lib.py:146] step: 39000, eval_loss: 4.75211e-02
I0210 01:56:06.605302 22509476222784 run_lib.py:133] step: 39050, training_loss: 4.24269e-02
I0210 01:56:25.157415 22509476222784 run_lib.py:133] step: 39100, training_loss: 5.66500e-02
I0210 01:56:25.323457 22509476222784 run_lib.py:146] step: 39100, eval_loss: 4.65679e-02
I0210 01:56:44.044231 22509476222784 run_lib.py:133] step: 39150, training_loss: 4.86093e-02
I0210 01:57:02.591396 22509476222784 run_lib.py:133] step: 39200, training_loss: 4.31795e-02
I0210 01:57:02.784616 22509476222784 run_lib.py:146] step: 39200, eval_loss: 3.69159e-02
I0210 01:57:21.496521 22509476222784 run_lib.py:133] step: 39250, training_loss: 3.54131e-02
I0210 01:57:40.095232 22509476222784 run_lib.py:133] step: 39300, training_loss: 3.81808e-02
I0210 01:57:40.286845 22509476222784 run_lib.py:146] step: 39300, eval_loss: 3.87291e-02
I0210 01:57:59.047774 22509476222784 run_lib.py:133] step: 39350, training_loss: 3.16707e-02
I0210 01:58:17.638313 22509476222784 run_lib.py:133] step: 39400, training_loss: 5.38336e-02
I0210 01:58:17.800471 22509476222784 run_lib.py:146] step: 39400, eval_loss: 3.94026e-02
I0210 01:58:36.513083 22509476222784 run_lib.py:133] step: 39450, training_loss: 3.49578e-02
I0210 01:58:55.098597 22509476222784 run_lib.py:133] step: 39500, training_loss: 4.14731e-02
I0210 01:58:55.280006 22509476222784 run_lib.py:146] step: 39500, eval_loss: 5.55524e-02
I0210 01:59:13.865702 22509476222784 run_lib.py:133] step: 39550, training_loss: 5.57976e-02
I0210 01:59:32.670621 22509476222784 run_lib.py:133] step: 39600, training_loss: 4.22414e-02
I0210 01:59:32.834797 22509476222784 run_lib.py:146] step: 39600, eval_loss: 3.65642e-02
I0210 01:59:51.423207 22509476222784 run_lib.py:133] step: 39650, training_loss: 4.62745e-02
I0210 02:00:09.978750 22509476222784 run_lib.py:133] step: 39700, training_loss: 5.53813e-02
I0210 02:00:10.148252 22509476222784 run_lib.py:146] step: 39700, eval_loss: 5.40879e-02
I0210 02:00:28.918327 22509476222784 run_lib.py:133] step: 39750, training_loss: 3.73820e-02
I0210 02:00:47.730502 22509476222784 run_lib.py:133] step: 39800, training_loss: 2.30180e-02
I0210 02:00:47.893190 22509476222784 run_lib.py:146] step: 39800, eval_loss: 4.22293e-02
I0210 02:01:06.523897 22509476222784 run_lib.py:133] step: 39850, training_loss: 3.59195e-02
I0210 02:01:25.108742 22509476222784 run_lib.py:133] step: 39900, training_loss: 3.64775e-02
I0210 02:01:25.301472 22509476222784 run_lib.py:146] step: 39900, eval_loss: 3.10328e-02
I0210 02:01:43.849177 22509476222784 run_lib.py:133] step: 39950, training_loss: 4.28969e-02
I0210 02:02:02.596220 22509476222784 run_lib.py:133] step: 40000, training_loss: 4.90295e-02
I0210 02:02:03.692379 22509476222784 run_lib.py:146] step: 40000, eval_loss: 4.39258e-02
I0210 02:02:25.367846 22509476222784 run_lib.py:133] step: 40050, training_loss: 5.91801e-02
I0210 02:02:43.947065 22509476222784 run_lib.py:133] step: 40100, training_loss: 3.54866e-02
I0210 02:02:44.116596 22509476222784 run_lib.py:146] step: 40100, eval_loss: 3.53543e-02
I0210 02:03:02.677521 22509476222784 run_lib.py:133] step: 40150, training_loss: 3.39384e-02
I0210 02:03:21.422486 22509476222784 run_lib.py:133] step: 40200, training_loss: 4.83134e-02
I0210 02:03:21.586517 22509476222784 run_lib.py:146] step: 40200, eval_loss: 3.66748e-02
I0210 02:03:40.122774 22509476222784 run_lib.py:133] step: 40250, training_loss: 4.70437e-02
I0210 02:03:58.817551 22509476222784 run_lib.py:133] step: 40300, training_loss: 4.26526e-02
I0210 02:03:58.981847 22509476222784 run_lib.py:146] step: 40300, eval_loss: 4.94975e-02
I0210 02:04:17.593653 22509476222784 run_lib.py:133] step: 40350, training_loss: 3.85317e-02
I0210 02:04:36.160878 22509476222784 run_lib.py:133] step: 40400, training_loss: 4.83444e-02
I0210 02:04:36.322680 22509476222784 run_lib.py:146] step: 40400, eval_loss: 3.68207e-02
I0210 02:04:55.074099 22509476222784 run_lib.py:133] step: 40450, training_loss: 5.80039e-02
I0210 02:05:13.607109 22509476222784 run_lib.py:133] step: 40500, training_loss: 5.66110e-02
I0210 02:05:13.772961 22509476222784 run_lib.py:146] step: 40500, eval_loss: 5.91025e-02
I0210 02:05:32.342217 22509476222784 run_lib.py:133] step: 40550, training_loss: 4.22247e-02
I0210 02:05:51.107796 22509476222784 run_lib.py:133] step: 40600, training_loss: 5.85831e-02
I0210 02:05:51.273820 22509476222784 run_lib.py:146] step: 40600, eval_loss: 4.74495e-02
I0210 02:06:09.806751 22509476222784 run_lib.py:133] step: 40650, training_loss: 5.44063e-02
I0210 02:06:28.384292 22509476222784 run_lib.py:133] step: 40700, training_loss: 3.66823e-02
I0210 02:06:28.567375 22509476222784 run_lib.py:146] step: 40700, eval_loss: 4.25704e-02
I0210 02:06:47.264672 22509476222784 run_lib.py:133] step: 40750, training_loss: 3.17793e-02
I0210 02:07:05.837026 22509476222784 run_lib.py:133] step: 40800, training_loss: 3.95258e-02
I0210 02:07:05.999584 22509476222784 run_lib.py:146] step: 40800, eval_loss: 4.83860e-02
I0210 02:07:24.588154 22509476222784 run_lib.py:133] step: 40850, training_loss: 3.75258e-02
I0210 02:07:43.201242 22509476222784 run_lib.py:133] step: 40900, training_loss: 4.38693e-02
I0210 02:07:43.367670 22509476222784 run_lib.py:146] step: 40900, eval_loss: 3.75185e-02
I0210 02:08:02.142838 22509476222784 run_lib.py:133] step: 40950, training_loss: 3.94186e-02
I0210 02:08:20.768852 22509476222784 run_lib.py:133] step: 41000, training_loss: 5.25493e-02
I0210 02:08:20.935867 22509476222784 run_lib.py:146] step: 41000, eval_loss: 4.02883e-02
I0210 02:08:39.452451 22509476222784 run_lib.py:133] step: 41050, training_loss: 3.40017e-02
I0210 02:08:58.025208 22509476222784 run_lib.py:133] step: 41100, training_loss: 4.19076e-02
I0210 02:08:58.200716 22509476222784 run_lib.py:146] step: 41100, eval_loss: 5.16308e-02
I0210 02:09:16.938065 22509476222784 run_lib.py:133] step: 41150, training_loss: 4.23039e-02
I0210 02:09:35.498577 22509476222784 run_lib.py:133] step: 41200, training_loss: 4.94644e-02
I0210 02:09:35.663905 22509476222784 run_lib.py:146] step: 41200, eval_loss: 6.69067e-02
I0210 02:09:54.401193 22509476222784 run_lib.py:133] step: 41250, training_loss: 6.69355e-02
I0210 02:10:12.948405 22509476222784 run_lib.py:133] step: 41300, training_loss: 4.88753e-02
I0210 02:10:13.109694 22509476222784 run_lib.py:146] step: 41300, eval_loss: 3.48697e-02
I0210 02:10:31.832625 22509476222784 run_lib.py:133] step: 41350, training_loss: 4.23954e-02
I0210 02:10:50.458531 22509476222784 run_lib.py:133] step: 41400, training_loss: 4.56550e-02
I0210 02:10:50.691262 22509476222784 run_lib.py:146] step: 41400, eval_loss: 4.52603e-02
I0210 02:11:09.492916 22509476222784 run_lib.py:133] step: 41450, training_loss: 4.59916e-02
I0210 02:11:28.129256 22509476222784 run_lib.py:133] step: 41500, training_loss: 3.78140e-02
I0210 02:11:28.313715 22509476222784 run_lib.py:146] step: 41500, eval_loss: 4.27199e-02
I0210 02:11:46.861806 22509476222784 run_lib.py:133] step: 41550, training_loss: 3.23874e-02
I0210 02:12:05.501607 22509476222784 run_lib.py:133] step: 41600, training_loss: 3.03896e-02
I0210 02:12:05.665666 22509476222784 run_lib.py:146] step: 41600, eval_loss: 4.17219e-02
I0210 02:12:24.187769 22509476222784 run_lib.py:133] step: 41650, training_loss: 3.90652e-02
I0210 02:12:42.813354 22509476222784 run_lib.py:133] step: 41700, training_loss: 3.26738e-02
I0210 02:12:42.998059 22509476222784 run_lib.py:146] step: 41700, eval_loss: 3.64783e-02
I0210 02:13:01.778117 22509476222784 run_lib.py:133] step: 41750, training_loss: 5.20267e-02
I0210 02:13:20.300602 22509476222784 run_lib.py:133] step: 41800, training_loss: 4.90964e-02
I0210 02:13:20.460679 22509476222784 run_lib.py:146] step: 41800, eval_loss: 4.62697e-02
I0210 02:13:39.137384 22509476222784 run_lib.py:133] step: 41850, training_loss: 5.21234e-02
I0210 02:13:57.686395 22509476222784 run_lib.py:133] step: 41900, training_loss: 3.48043e-02
I0210 02:13:57.849574 22509476222784 run_lib.py:146] step: 41900, eval_loss: 5.29311e-02
I0210 02:14:16.400905 22509476222784 run_lib.py:133] step: 41950, training_loss: 3.93119e-02
I0210 02:14:35.163562 22509476222784 run_lib.py:133] step: 42000, training_loss: 6.02884e-02
I0210 02:14:35.375646 22509476222784 run_lib.py:146] step: 42000, eval_loss: 4.61022e-02
I0210 02:14:53.890971 22509476222784 run_lib.py:133] step: 42050, training_loss: 4.52111e-02
I0210 02:15:12.441460 22509476222784 run_lib.py:133] step: 42100, training_loss: 5.04353e-02
I0210 02:15:12.606598 22509476222784 run_lib.py:146] step: 42100, eval_loss: 4.19807e-02
I0210 02:15:31.193415 22509476222784 run_lib.py:133] step: 42150, training_loss: 5.19549e-02
I0210 02:15:49.957749 22509476222784 run_lib.py:133] step: 42200, training_loss: 5.67641e-02
I0210 02:15:50.121741 22509476222784 run_lib.py:146] step: 42200, eval_loss: 4.79294e-02
I0210 02:16:08.747084 22509476222784 run_lib.py:133] step: 42250, training_loss: 4.73824e-02
I0210 02:16:27.417318 22509476222784 run_lib.py:133] step: 42300, training_loss: 4.68540e-02
I0210 02:16:27.578659 22509476222784 run_lib.py:146] step: 42300, eval_loss: 5.22611e-02
I0210 02:16:46.141393 22509476222784 run_lib.py:133] step: 42350, training_loss: 5.65477e-02
I0210 02:17:04.693848 22509476222784 run_lib.py:133] step: 42400, training_loss: 4.10664e-02
I0210 02:17:04.862945 22509476222784 run_lib.py:146] step: 42400, eval_loss: 4.62583e-02
I0210 02:17:23.555390 22509476222784 run_lib.py:133] step: 42450, training_loss: 2.66860e-02
I0210 02:17:42.244874 22509476222784 run_lib.py:133] step: 42500, training_loss: 6.37052e-02
I0210 02:17:42.415551 22509476222784 run_lib.py:146] step: 42500, eval_loss: 5.68602e-02
I0210 02:18:00.992911 22509476222784 run_lib.py:133] step: 42550, training_loss: 6.47893e-02
I0210 02:18:19.543427 22509476222784 run_lib.py:133] step: 42600, training_loss: 4.45404e-02
I0210 02:18:19.752832 22509476222784 run_lib.py:146] step: 42600, eval_loss: 4.77533e-02
I0210 02:18:38.471473 22509476222784 run_lib.py:133] step: 42650, training_loss: 5.18595e-02
I0210 02:18:56.958702 22509476222784 run_lib.py:133] step: 42700, training_loss: 5.08395e-02
I0210 02:18:57.121506 22509476222784 run_lib.py:146] step: 42700, eval_loss: 4.83117e-02
I0210 02:19:15.832751 22509476222784 run_lib.py:133] step: 42750, training_loss: 4.92162e-02
I0210 02:19:34.384796 22509476222784 run_lib.py:133] step: 42800, training_loss: 6.50575e-02
I0210 02:19:34.583981 22509476222784 run_lib.py:146] step: 42800, eval_loss: 5.01323e-02
I0210 02:19:53.361481 22509476222784 run_lib.py:133] step: 42850, training_loss: 3.67014e-02
I0210 02:20:11.942292 22509476222784 run_lib.py:133] step: 42900, training_loss: 4.79198e-02
I0210 02:20:12.274692 22509476222784 run_lib.py:146] step: 42900, eval_loss: 5.42150e-02
I0210 02:20:30.825020 22509476222784 run_lib.py:133] step: 42950, training_loss: 5.31159e-02
I0210 02:20:49.538184 22509476222784 run_lib.py:133] step: 43000, training_loss: 3.98333e-02
I0210 02:20:49.713537 22509476222784 run_lib.py:146] step: 43000, eval_loss: 4.75975e-02
I0210 02:21:08.324106 22509476222784 run_lib.py:133] step: 43050, training_loss: 4.29886e-02
I0210 02:21:27.098765 22509476222784 run_lib.py:133] step: 43100, training_loss: 4.73400e-02
I0210 02:21:27.263721 22509476222784 run_lib.py:146] step: 43100, eval_loss: 5.79011e-02
I0210 02:21:45.824759 22509476222784 run_lib.py:133] step: 43150, training_loss: 5.75424e-02
I0210 02:22:04.360644 22509476222784 run_lib.py:133] step: 43200, training_loss: 4.87273e-02
I0210 02:22:04.521564 22509476222784 run_lib.py:146] step: 43200, eval_loss: 2.90416e-02
I0210 02:22:23.205957 22509476222784 run_lib.py:133] step: 43250, training_loss: 3.60804e-02
I0210 02:22:41.782811 22509476222784 run_lib.py:133] step: 43300, training_loss: 4.12763e-02
I0210 02:22:41.956472 22509476222784 run_lib.py:146] step: 43300, eval_loss: 4.70609e-02
I0210 02:23:00.540075 22509476222784 run_lib.py:133] step: 43350, training_loss: 3.67010e-02
I0210 02:23:19.273282 22509476222784 run_lib.py:133] step: 43400, training_loss: 5.12331e-02
I0210 02:23:19.439865 22509476222784 run_lib.py:146] step: 43400, eval_loss: 3.85422e-02
I0210 02:23:37.990790 22509476222784 run_lib.py:133] step: 43450, training_loss: 4.36834e-02
I0210 02:23:56.529702 22509476222784 run_lib.py:133] step: 43500, training_loss: 4.79935e-02
I0210 02:23:56.850419 22509476222784 run_lib.py:146] step: 43500, eval_loss: 3.59736e-02
I0210 02:24:15.392502 22509476222784 run_lib.py:133] step: 43550, training_loss: 5.47254e-02
I0210 02:24:34.014997 22509476222784 run_lib.py:133] step: 43600, training_loss: 4.46890e-02
I0210 02:24:34.180753 22509476222784 run_lib.py:146] step: 43600, eval_loss: 3.83758e-02
I0210 02:24:52.802644 22509476222784 run_lib.py:133] step: 43650, training_loss: 3.36757e-02
I0210 02:25:11.451415 22509476222784 run_lib.py:133] step: 43700, training_loss: 4.51623e-02
I0210 02:25:11.612504 22509476222784 run_lib.py:146] step: 43700, eval_loss: 3.93656e-02
I0210 02:25:30.375822 22509476222784 run_lib.py:133] step: 43750, training_loss: 5.65377e-02
I0210 02:25:49.107798 22509476222784 run_lib.py:133] step: 43800, training_loss: 5.08770e-02
I0210 02:25:49.282718 22509476222784 run_lib.py:146] step: 43800, eval_loss: 4.93171e-02
I0210 02:26:07.920917 22509476222784 run_lib.py:133] step: 43850, training_loss: 4.16775e-02
I0210 02:26:26.532074 22509476222784 run_lib.py:133] step: 43900, training_loss: 4.70042e-02
I0210 02:26:26.697808 22509476222784 run_lib.py:146] step: 43900, eval_loss: 5.25224e-02
I0210 02:26:45.454346 22509476222784 run_lib.py:133] step: 43950, training_loss: 3.46027e-02
I0210 02:27:04.085561 22509476222784 run_lib.py:133] step: 44000, training_loss: 5.88756e-02
I0210 02:27:04.267484 22509476222784 run_lib.py:146] step: 44000, eval_loss: 5.15808e-02
I0210 02:27:22.856609 22509476222784 run_lib.py:133] step: 44050, training_loss: 5.49979e-02
I0210 02:27:41.471366 22509476222784 run_lib.py:133] step: 44100, training_loss: 5.52708e-02
I0210 02:27:41.656785 22509476222784 run_lib.py:146] step: 44100, eval_loss: 4.17370e-02
I0210 02:28:00.421740 22509476222784 run_lib.py:133] step: 44150, training_loss: 4.39838e-02
I0210 02:28:18.976600 22509476222784 run_lib.py:133] step: 44200, training_loss: 4.03730e-02
I0210 02:28:19.137619 22509476222784 run_lib.py:146] step: 44200, eval_loss: 5.35309e-02
I0210 02:28:37.851786 22509476222784 run_lib.py:133] step: 44250, training_loss: 4.57606e-02
I0210 02:28:56.472297 22509476222784 run_lib.py:133] step: 44300, training_loss: 4.52843e-02
I0210 02:28:56.654689 22509476222784 run_lib.py:146] step: 44300, eval_loss: 4.16125e-02
I0210 02:29:15.440013 22509476222784 run_lib.py:133] step: 44350, training_loss: 5.06941e-02
I0210 02:29:34.048756 22509476222784 run_lib.py:133] step: 44400, training_loss: 5.20913e-02
I0210 02:29:34.213765 22509476222784 run_lib.py:146] step: 44400, eval_loss: 5.29247e-02
I0210 02:29:52.754364 22509476222784 run_lib.py:133] step: 44450, training_loss: 4.26913e-02
I0210 02:30:11.509781 22509476222784 run_lib.py:133] step: 44500, training_loss: 3.41374e-02
I0210 02:30:11.678718 22509476222784 run_lib.py:146] step: 44500, eval_loss: 6.00411e-02
I0210 02:30:30.310255 22509476222784 run_lib.py:133] step: 44550, training_loss: 5.68853e-02
I0210 02:30:49.175364 22509476222784 run_lib.py:133] step: 44600, training_loss: 5.89745e-02
I0210 02:30:49.339995 22509476222784 run_lib.py:146] step: 44600, eval_loss: 4.44818e-02
I0210 02:31:07.933280 22509476222784 run_lib.py:133] step: 44650, training_loss: 4.34208e-02
I0210 02:31:26.515974 22509476222784 run_lib.py:133] step: 44700, training_loss: 3.30135e-02
I0210 02:31:26.676583 22509476222784 run_lib.py:146] step: 44700, eval_loss: 4.46834e-02
I0210 02:31:45.320942 22509476222784 run_lib.py:133] step: 44750, training_loss: 3.57550e-02
I0210 02:32:03.862314 22509476222784 run_lib.py:133] step: 44800, training_loss: 3.12299e-02
I0210 02:32:04.045547 22509476222784 run_lib.py:146] step: 44800, eval_loss: 3.28461e-02
I0210 02:32:22.587348 22509476222784 run_lib.py:133] step: 44850, training_loss: 4.41568e-02
I0210 02:32:41.187373 22509476222784 run_lib.py:133] step: 44900, training_loss: 4.70474e-02
I0210 02:32:41.387642 22509476222784 run_lib.py:146] step: 44900, eval_loss: 4.23937e-02
I0210 02:33:00.115602 22509476222784 run_lib.py:133] step: 44950, training_loss: 4.77680e-02
I0210 02:33:18.639467 22509476222784 run_lib.py:133] step: 45000, training_loss: 5.72843e-02
I0210 02:33:18.811683 22509476222784 run_lib.py:146] step: 45000, eval_loss: 4.08360e-02
I0210 02:33:37.472912 22509476222784 run_lib.py:133] step: 45050, training_loss: 4.48150e-02
I0210 02:33:56.053056 22509476222784 run_lib.py:133] step: 45100, training_loss: 3.34038e-02
I0210 02:33:56.218912 22509476222784 run_lib.py:146] step: 45100, eval_loss: 4.60012e-02
I0210 02:34:14.827609 22509476222784 run_lib.py:133] step: 45150, training_loss: 5.25546e-02
I0210 02:34:33.336436 22509476222784 run_lib.py:133] step: 45200, training_loss: 4.63715e-02
I0210 02:34:33.501710 22509476222784 run_lib.py:146] step: 45200, eval_loss: 5.21917e-02
I0210 02:34:52.261246 22509476222784 run_lib.py:133] step: 45250, training_loss: 6.04718e-02
I0210 02:35:10.941787 22509476222784 run_lib.py:133] step: 45300, training_loss: 5.52184e-02
I0210 02:35:11.156678 22509476222784 run_lib.py:146] step: 45300, eval_loss: 5.03640e-02
I0210 02:35:29.769547 22509476222784 run_lib.py:133] step: 45350, training_loss: 4.37958e-02
I0210 02:35:48.376866 22509476222784 run_lib.py:133] step: 45400, training_loss: 6.60911e-02
I0210 02:35:48.542721 22509476222784 run_lib.py:146] step: 45400, eval_loss: 5.59932e-02
I0210 02:36:07.303599 22509476222784 run_lib.py:133] step: 45450, training_loss: 3.92200e-02
I0210 02:36:25.840127 22509476222784 run_lib.py:133] step: 45500, training_loss: 5.27941e-02
I0210 02:36:26.061313 22509476222784 run_lib.py:146] step: 45500, eval_loss: 5.18098e-02
I0210 02:36:44.770391 22509476222784 run_lib.py:133] step: 45550, training_loss: 4.29212e-02
I0210 02:37:03.323572 22509476222784 run_lib.py:133] step: 45600, training_loss: 3.04419e-02
I0210 02:37:03.492974 22509476222784 run_lib.py:146] step: 45600, eval_loss: 4.03122e-02
I0210 02:37:22.266133 22509476222784 run_lib.py:133] step: 45650, training_loss: 5.09164e-02
I0210 02:37:40.802132 22509476222784 run_lib.py:133] step: 45700, training_loss: 5.02322e-02
I0210 02:37:40.973531 22509476222784 run_lib.py:146] step: 45700, eval_loss: 4.62878e-02
I0210 02:37:59.617260 22509476222784 run_lib.py:133] step: 45750, training_loss: 4.56481e-02
I0210 02:38:18.162090 22509476222784 run_lib.py:133] step: 45800, training_loss: 4.01081e-02
I0210 02:38:18.371740 22509476222784 run_lib.py:146] step: 45800, eval_loss: 4.84611e-02
I0210 02:38:36.948154 22509476222784 run_lib.py:133] step: 45850, training_loss: 5.30732e-02
I0210 02:38:55.749199 22509476222784 run_lib.py:133] step: 45900, training_loss: 5.14888e-02
I0210 02:38:55.914744 22509476222784 run_lib.py:146] step: 45900, eval_loss: 4.25718e-02
I0210 02:39:14.454769 22509476222784 run_lib.py:133] step: 45950, training_loss: 5.02160e-02
I0210 02:39:32.969280 22509476222784 run_lib.py:133] step: 46000, training_loss: 4.93206e-02
I0210 02:39:33.132559 22509476222784 run_lib.py:146] step: 46000, eval_loss: 5.34824e-02
I0210 02:39:51.849844 22509476222784 run_lib.py:133] step: 46050, training_loss: 4.80001e-02
I0210 02:40:10.611032 22509476222784 run_lib.py:133] step: 46100, training_loss: 4.49339e-02
I0210 02:40:10.780674 22509476222784 run_lib.py:146] step: 46100, eval_loss: 5.31804e-02
I0210 02:40:29.339018 22509476222784 run_lib.py:133] step: 46150, training_loss: 4.77700e-02
I0210 02:40:47.880940 22509476222784 run_lib.py:133] step: 46200, training_loss: 3.94663e-02
I0210 02:40:48.046839 22509476222784 run_lib.py:146] step: 46200, eval_loss: 3.96020e-02
I0210 02:41:06.570304 22509476222784 run_lib.py:133] step: 46250, training_loss: 3.72435e-02
I0210 02:41:25.293375 22509476222784 run_lib.py:133] step: 46300, training_loss: 4.91659e-02
I0210 02:41:25.475451 22509476222784 run_lib.py:146] step: 46300, eval_loss: 5.02924e-02
I0210 02:41:44.050128 22509476222784 run_lib.py:133] step: 46350, training_loss: 4.54454e-02
I0210 02:42:02.602257 22509476222784 run_lib.py:133] step: 46400, training_loss: 3.28139e-02
I0210 02:42:02.768619 22509476222784 run_lib.py:146] step: 46400, eval_loss: 4.55810e-02
I0210 02:42:21.333708 22509476222784 run_lib.py:133] step: 46450, training_loss: 3.95660e-02
I0210 02:42:40.006167 22509476222784 run_lib.py:133] step: 46500, training_loss: 4.73144e-02
I0210 02:42:40.171259 22509476222784 run_lib.py:146] step: 46500, eval_loss: 4.31706e-02
I0210 02:42:58.738806 22509476222784 run_lib.py:133] step: 46550, training_loss: 4.47587e-02
I0210 02:43:17.409794 22509476222784 run_lib.py:133] step: 46600, training_loss: 3.83218e-02
I0210 02:43:17.580807 22509476222784 run_lib.py:146] step: 46600, eval_loss: 3.90710e-02
I0210 02:43:36.173655 22509476222784 run_lib.py:133] step: 46650, training_loss: 5.04111e-02
I0210 02:43:54.708243 22509476222784 run_lib.py:133] step: 46700, training_loss: 4.66166e-02
I0210 02:43:54.873835 22509476222784 run_lib.py:146] step: 46700, eval_loss: 4.05856e-02
I0210 02:44:13.558734 22509476222784 run_lib.py:133] step: 46750, training_loss: 5.55515e-02
I0210 02:44:32.160357 22509476222784 run_lib.py:133] step: 46800, training_loss: 3.30034e-02
I0210 02:44:32.332599 22509476222784 run_lib.py:146] step: 46800, eval_loss: 3.62713e-02
I0210 02:44:50.937247 22509476222784 run_lib.py:133] step: 46850, training_loss: 4.72696e-02
I0210 02:45:09.547376 22509476222784 run_lib.py:133] step: 46900, training_loss: 4.33658e-02
I0210 02:45:09.769213 22509476222784 run_lib.py:146] step: 46900, eval_loss: 4.06062e-02
I0210 02:45:28.555781 22509476222784 run_lib.py:133] step: 46950, training_loss: 3.32962e-02
I0210 02:45:47.039752 22509476222784 run_lib.py:133] step: 47000, training_loss: 6.86067e-02
I0210 02:45:47.203792 22509476222784 run_lib.py:146] step: 47000, eval_loss: 4.29060e-02
I0210 02:46:05.931638 22509476222784 run_lib.py:133] step: 47050, training_loss: 3.68590e-02
I0210 02:46:24.466758 22509476222784 run_lib.py:133] step: 47100, training_loss: 4.21651e-02
I0210 02:46:24.642610 22509476222784 run_lib.py:146] step: 47100, eval_loss: 4.52579e-02
I0210 02:46:43.433279 22509476222784 run_lib.py:133] step: 47150, training_loss: 4.53355e-02
I0210 02:47:02.025765 22509476222784 run_lib.py:133] step: 47200, training_loss: 4.01983e-02
I0210 02:47:02.193104 22509476222784 run_lib.py:146] step: 47200, eval_loss: 4.24990e-02
I0210 02:47:20.760179 22509476222784 run_lib.py:133] step: 47250, training_loss: 4.04610e-02
I0210 02:47:39.451663 22509476222784 run_lib.py:133] step: 47300, training_loss: 4.28691e-02
I0210 02:47:39.616638 22509476222784 run_lib.py:146] step: 47300, eval_loss: 3.97480e-02
I0210 02:47:58.199533 22509476222784 run_lib.py:133] step: 47350, training_loss: 4.13204e-02
I0210 02:48:16.998814 22509476222784 run_lib.py:133] step: 47400, training_loss: 4.26631e-02
I0210 02:48:17.181737 22509476222784 run_lib.py:146] step: 47400, eval_loss: 4.69690e-02
I0210 02:48:35.819849 22509476222784 run_lib.py:133] step: 47450, training_loss: 5.22402e-02
I0210 02:48:54.416836 22509476222784 run_lib.py:133] step: 47500, training_loss: 3.70250e-02
I0210 02:48:54.599613 22509476222784 run_lib.py:146] step: 47500, eval_loss: 4.02297e-02
I0210 02:49:13.299156 22509476222784 run_lib.py:133] step: 47550, training_loss: 4.90580e-02
I0210 02:49:31.832396 22509476222784 run_lib.py:133] step: 47600, training_loss: 4.44261e-02
I0210 02:49:32.010138 22509476222784 run_lib.py:146] step: 47600, eval_loss: 4.17716e-02
I0210 02:49:50.658778 22509476222784 run_lib.py:133] step: 47650, training_loss: 4.18262e-02
I0210 02:50:09.450367 22509476222784 run_lib.py:133] step: 47700, training_loss: 4.39792e-02
I0210 02:50:09.617537 22509476222784 run_lib.py:146] step: 47700, eval_loss: 4.12969e-02
I0210 02:50:28.120460 22509476222784 run_lib.py:133] step: 47750, training_loss: 4.65176e-02
I0210 02:50:46.651053 22509476222784 run_lib.py:133] step: 47800, training_loss: 4.04417e-02
I0210 02:50:46.834983 22509476222784 run_lib.py:146] step: 47800, eval_loss: 3.81579e-02
I0210 02:51:05.461343 22509476222784 run_lib.py:133] step: 47850, training_loss: 5.19152e-02
I0210 02:51:24.098511 22509476222784 run_lib.py:133] step: 47900, training_loss: 4.05297e-02
I0210 02:51:24.300746 22509476222784 run_lib.py:146] step: 47900, eval_loss: 5.45515e-02
I0210 02:51:42.916761 22509476222784 run_lib.py:133] step: 47950, training_loss: 4.95786e-02
I0210 02:52:01.458914 22509476222784 run_lib.py:133] step: 48000, training_loss: 5.25852e-02
I0210 02:52:01.621533 22509476222784 run_lib.py:146] step: 48000, eval_loss: 5.19526e-02
I0210 02:52:20.357127 22509476222784 run_lib.py:133] step: 48050, training_loss: 5.41924e-02
I0210 02:52:39.019468 22509476222784 run_lib.py:133] step: 48100, training_loss: 3.83003e-02
I0210 02:52:39.220782 22509476222784 run_lib.py:146] step: 48100, eval_loss: 4.34620e-02
I0210 02:52:57.785676 22509476222784 run_lib.py:133] step: 48150, training_loss: 4.08844e-02
I0210 02:53:16.414716 22509476222784 run_lib.py:133] step: 48200, training_loss: 3.76922e-02
I0210 02:53:16.579859 22509476222784 run_lib.py:146] step: 48200, eval_loss: 5.53817e-02
I0210 02:53:35.323611 22509476222784 run_lib.py:133] step: 48250, training_loss: 5.53807e-02
I0210 02:53:53.853280 22509476222784 run_lib.py:133] step: 48300, training_loss: 3.86878e-02
I0210 02:53:54.017773 22509476222784 run_lib.py:146] step: 48300, eval_loss: 4.92535e-02
I0210 02:54:12.689920 22509476222784 run_lib.py:133] step: 48350, training_loss: 4.05795e-02
I0210 02:54:31.187025 22509476222784 run_lib.py:133] step: 48400, training_loss: 4.73056e-02
I0210 02:54:31.349378 22509476222784 run_lib.py:146] step: 48400, eval_loss: 3.93664e-02
I0210 02:54:50.174687 22509476222784 run_lib.py:133] step: 48450, training_loss: 4.41542e-02
I0210 02:55:08.777476 22509476222784 run_lib.py:133] step: 48500, training_loss: 4.83573e-02
I0210 02:55:08.941754 22509476222784 run_lib.py:146] step: 48500, eval_loss: 5.20823e-02
I0210 02:55:27.611838 22509476222784 run_lib.py:133] step: 48550, training_loss: 4.60679e-02
I0210 02:55:46.195547 22509476222784 run_lib.py:133] step: 48600, training_loss: 4.57366e-02
I0210 02:55:46.361771 22509476222784 run_lib.py:146] step: 48600, eval_loss: 3.93761e-02
I0210 02:56:04.980360 22509476222784 run_lib.py:133] step: 48650, training_loss: 4.96964e-02
I0210 02:56:23.817094 22509476222784 run_lib.py:133] step: 48700, training_loss: 4.08195e-02
I0210 02:56:23.982745 22509476222784 run_lib.py:146] step: 48700, eval_loss: 5.11226e-02
I0210 02:56:42.547389 22509476222784 run_lib.py:133] step: 48750, training_loss: 4.01562e-02
I0210 02:57:01.105942 22509476222784 run_lib.py:133] step: 48800, training_loss: 4.27279e-02
I0210 02:57:01.271662 22509476222784 run_lib.py:146] step: 48800, eval_loss: 3.83464e-02
I0210 02:57:20.053209 22509476222784 run_lib.py:133] step: 48850, training_loss: 4.21825e-02
I0210 02:57:38.630551 22509476222784 run_lib.py:133] step: 48900, training_loss: 4.52852e-02
I0210 02:57:38.818949 22509476222784 run_lib.py:146] step: 48900, eval_loss: 3.87260e-02
I0210 02:57:57.595760 22509476222784 run_lib.py:133] step: 48950, training_loss: 2.63015e-02
I0210 02:58:16.190143 22509476222784 run_lib.py:133] step: 49000, training_loss: 4.50207e-02
I0210 02:58:16.382417 22509476222784 run_lib.py:146] step: 49000, eval_loss: 4.29077e-02
I0210 02:58:34.952535 22509476222784 run_lib.py:133] step: 49050, training_loss: 5.02516e-02
I0210 02:58:53.703277 22509476222784 run_lib.py:133] step: 49100, training_loss: 5.26681e-02
I0210 02:58:53.903829 22509476222784 run_lib.py:146] step: 49100, eval_loss: 2.87682e-02
I0210 02:59:12.463864 22509476222784 run_lib.py:133] step: 49150, training_loss: 4.06656e-02
I0210 02:59:31.078961 22509476222784 run_lib.py:133] step: 49200, training_loss: 5.40797e-02
I0210 02:59:31.243790 22509476222784 run_lib.py:146] step: 49200, eval_loss: 4.71777e-02
I0210 02:59:49.760229 22509476222784 run_lib.py:133] step: 49250, training_loss: 5.41569e-02
I0210 03:00:08.477116 22509476222784 run_lib.py:133] step: 49300, training_loss: 4.15757e-02
I0210 03:00:08.640693 22509476222784 run_lib.py:146] step: 49300, eval_loss: 3.40766e-02
I0210 03:00:27.159633 22509476222784 run_lib.py:133] step: 49350, training_loss: 3.53815e-02
I0210 03:00:45.781178 22509476222784 run_lib.py:133] step: 49400, training_loss: 3.87979e-02
I0210 03:00:45.941657 22509476222784 run_lib.py:146] step: 49400, eval_loss: 3.84839e-02
I0210 03:01:04.501105 22509476222784 run_lib.py:133] step: 49450, training_loss: 5.16926e-02
I0210 03:01:23.074242 22509476222784 run_lib.py:133] step: 49500, training_loss: 5.29041e-02
I0210 03:01:23.257364 22509476222784 run_lib.py:146] step: 49500, eval_loss: 5.48836e-02
I0210 03:01:42.009016 22509476222784 run_lib.py:133] step: 49550, training_loss: 3.64030e-02
I0210 03:02:00.609768 22509476222784 run_lib.py:133] step: 49600, training_loss: 4.13893e-02
I0210 03:02:00.825896 22509476222784 run_lib.py:146] step: 49600, eval_loss: 4.75221e-02
I0210 03:02:19.356276 22509476222784 run_lib.py:133] step: 49650, training_loss: 3.96053e-02
I0210 03:02:37.886626 22509476222784 run_lib.py:133] step: 49700, training_loss: 3.76703e-02
I0210 03:02:38.055477 22509476222784 run_lib.py:146] step: 49700, eval_loss: 3.64602e-02
I0210 03:02:56.769162 22509476222784 run_lib.py:133] step: 49750, training_loss: 4.81090e-02
I0210 03:03:15.384855 22509476222784 run_lib.py:133] step: 49800, training_loss: 5.63461e-02
I0210 03:03:15.559842 22509476222784 run_lib.py:146] step: 49800, eval_loss: 5.42988e-02
I0210 03:03:34.285241 22509476222784 run_lib.py:133] step: 49850, training_loss: 4.38137e-02
I0210 03:03:52.843568 22509476222784 run_lib.py:133] step: 49900, training_loss: 4.22131e-02
I0210 03:03:53.006620 22509476222784 run_lib.py:146] step: 49900, eval_loss: 3.90831e-02
I0210 03:04:11.679100 22509476222784 run_lib.py:133] step: 49950, training_loss: 4.80111e-02
I0210 03:04:30.288120 22509476222784 run_lib.py:133] step: 50000, training_loss: 2.84173e-02
I0210 03:04:31.077387 22509476222784 run_lib.py:146] step: 50000, eval_loss: 4.31280e-02
I0210 03:04:52.828887 22509476222784 run_lib.py:133] step: 50050, training_loss: 5.16711e-02
I0210 03:05:11.374564 22509476222784 run_lib.py:133] step: 50100, training_loss: 3.81085e-02
I0210 03:05:11.539691 22509476222784 run_lib.py:146] step: 50100, eval_loss: 3.86996e-02
I0210 03:05:30.031445 22509476222784 run_lib.py:133] step: 50150, training_loss: 4.64421e-02
I0210 03:05:48.566434 22509476222784 run_lib.py:133] step: 50200, training_loss: 3.86076e-02
I0210 03:05:48.730566 22509476222784 run_lib.py:146] step: 50200, eval_loss: 4.49395e-02
I0210 03:06:07.443665 22509476222784 run_lib.py:133] step: 50250, training_loss: 4.85021e-02
I0210 03:06:26.173759 22509476222784 run_lib.py:133] step: 50300, training_loss: 4.00425e-02
I0210 03:06:26.366816 22509476222784 run_lib.py:146] step: 50300, eval_loss: 4.04880e-02
I0210 03:06:44.957595 22509476222784 run_lib.py:133] step: 50350, training_loss: 4.41938e-02
I0210 03:07:03.497709 22509476222784 run_lib.py:133] step: 50400, training_loss: 4.76977e-02
I0210 03:07:03.669596 22509476222784 run_lib.py:146] step: 50400, eval_loss: 4.69884e-02
I0210 03:07:22.334158 22509476222784 run_lib.py:133] step: 50450, training_loss: 4.47092e-02
I0210 03:07:40.926911 22509476222784 run_lib.py:133] step: 50500, training_loss: 4.09021e-02
I0210 03:07:41.101729 22509476222784 run_lib.py:146] step: 50500, eval_loss: 4.58270e-02
I0210 03:07:59.885317 22509476222784 run_lib.py:133] step: 50550, training_loss: 5.36119e-02
I0210 03:08:18.464318 22509476222784 run_lib.py:133] step: 50600, training_loss: 3.96788e-02
I0210 03:08:18.629540 22509476222784 run_lib.py:146] step: 50600, eval_loss: 5.06499e-02
I0210 03:08:37.364391 22509476222784 run_lib.py:133] step: 50650, training_loss: 3.84412e-02
I0210 03:08:55.911016 22509476222784 run_lib.py:133] step: 50700, training_loss: 4.25593e-02
I0210 03:08:56.075528 22509476222784 run_lib.py:146] step: 50700, eval_loss: 3.99207e-02
I0210 03:09:14.807015 22509476222784 run_lib.py:133] step: 50750, training_loss: 4.91039e-02
I0210 03:09:33.399169 22509476222784 run_lib.py:133] step: 50800, training_loss: 5.55755e-02
I0210 03:09:33.563312 22509476222784 run_lib.py:146] step: 50800, eval_loss: 4.02645e-02
I0210 03:09:52.149237 22509476222784 run_lib.py:133] step: 50850, training_loss: 3.83498e-02
I0210 03:10:10.843174 22509476222784 run_lib.py:133] step: 50900, training_loss: 4.15301e-02
I0210 03:10:11.004627 22509476222784 run_lib.py:146] step: 50900, eval_loss: 4.24426e-02
I0210 03:10:29.531861 22509476222784 run_lib.py:133] step: 50950, training_loss: 5.04623e-02
I0210 03:10:48.068214 22509476222784 run_lib.py:133] step: 51000, training_loss: 4.12356e-02
I0210 03:10:48.233841 22509476222784 run_lib.py:146] step: 51000, eval_loss: 3.94472e-02
I0210 03:11:06.990257 22509476222784 run_lib.py:133] step: 51050, training_loss: 4.75645e-02
I0210 03:11:25.657550 22509476222784 run_lib.py:133] step: 51100, training_loss: 3.79482e-02
I0210 03:11:25.823599 22509476222784 run_lib.py:146] step: 51100, eval_loss: 3.14589e-02
I0210 03:11:44.564826 22509476222784 run_lib.py:133] step: 51150, training_loss: 4.28416e-02
I0210 03:12:03.134392 22509476222784 run_lib.py:133] step: 51200, training_loss: 4.36334e-02
I0210 03:12:03.303205 22509476222784 run_lib.py:146] step: 51200, eval_loss: 3.95138e-02
I0210 03:12:21.861266 22509476222784 run_lib.py:133] step: 51250, training_loss: 5.40889e-02
I0210 03:12:40.586660 22509476222784 run_lib.py:133] step: 51300, training_loss: 3.89906e-02
I0210 03:12:40.750823 22509476222784 run_lib.py:146] step: 51300, eval_loss: 5.53453e-02
I0210 03:12:59.419280 22509476222784 run_lib.py:133] step: 51350, training_loss: 3.67083e-02
I0210 03:13:17.971291 22509476222784 run_lib.py:133] step: 51400, training_loss: 5.06666e-02
I0210 03:13:18.132544 22509476222784 run_lib.py:146] step: 51400, eval_loss: 4.65142e-02
I0210 03:13:36.648012 22509476222784 run_lib.py:133] step: 51450, training_loss: 4.86832e-02
I0210 03:13:55.357557 22509476222784 run_lib.py:133] step: 51500, training_loss: 5.11212e-02
I0210 03:13:55.525773 22509476222784 run_lib.py:146] step: 51500, eval_loss: 4.34977e-02
I0210 03:14:14.060061 22509476222784 run_lib.py:133] step: 51550, training_loss: 5.22626e-02
I0210 03:14:32.747355 22509476222784 run_lib.py:133] step: 51600, training_loss: 4.63338e-02
I0210 03:14:32.913125 22509476222784 run_lib.py:146] step: 51600, eval_loss: 5.79772e-02
I0210 03:14:51.402307 22509476222784 run_lib.py:133] step: 51650, training_loss: 4.87885e-02
I0210 03:15:09.918778 22509476222784 run_lib.py:133] step: 51700, training_loss: 4.88720e-02
I0210 03:15:10.083421 22509476222784 run_lib.py:146] step: 51700, eval_loss: 3.98460e-02
I0210 03:15:28.834615 22509476222784 run_lib.py:133] step: 51750, training_loss: 4.55028e-02
I0210 03:15:47.448676 22509476222784 run_lib.py:133] step: 51800, training_loss: 3.89285e-02
I0210 03:15:47.611577 22509476222784 run_lib.py:146] step: 51800, eval_loss: 3.47779e-02
I0210 03:16:06.266017 22509476222784 run_lib.py:133] step: 51850, training_loss: 4.16791e-02
I0210 03:16:24.887089 22509476222784 run_lib.py:133] step: 51900, training_loss: 4.07732e-02
I0210 03:16:25.051783 22509476222784 run_lib.py:146] step: 51900, eval_loss: 3.88686e-02
I0210 03:16:43.767397 22509476222784 run_lib.py:133] step: 51950, training_loss: 4.50306e-02
I0210 03:17:02.349812 22509476222784 run_lib.py:133] step: 52000, training_loss: 4.77442e-02
I0210 03:17:02.514780 22509476222784 run_lib.py:146] step: 52000, eval_loss: 4.54322e-02
I0210 03:17:21.228755 22509476222784 run_lib.py:133] step: 52050, training_loss: 4.40850e-02
I0210 03:17:39.846810 22509476222784 run_lib.py:133] step: 52100, training_loss: 4.82269e-02
I0210 03:17:40.011771 22509476222784 run_lib.py:146] step: 52100, eval_loss: 4.89482e-02
I0210 03:17:58.742897 22509476222784 run_lib.py:133] step: 52150, training_loss: 4.69388e-02
I0210 03:18:17.289918 22509476222784 run_lib.py:133] step: 52200, training_loss: 4.09167e-02
I0210 03:18:17.454244 22509476222784 run_lib.py:146] step: 52200, eval_loss: 5.14895e-02
I0210 03:18:35.990655 22509476222784 run_lib.py:133] step: 52250, training_loss: 3.64610e-02
I0210 03:18:54.720660 22509476222784 run_lib.py:133] step: 52300, training_loss: 4.26838e-02
I0210 03:18:54.884850 22509476222784 run_lib.py:146] step: 52300, eval_loss: 4.72049e-02
I0210 03:19:13.491485 22509476222784 run_lib.py:133] step: 52350, training_loss: 5.10798e-02
I0210 03:19:32.217554 22509476222784 run_lib.py:133] step: 52400, training_loss: 4.69643e-02
I0210 03:19:32.381402 22509476222784 run_lib.py:146] step: 52400, eval_loss: 4.20016e-02
I0210 03:19:50.886247 22509476222784 run_lib.py:133] step: 52450, training_loss: 4.06427e-02
I0210 03:20:09.444454 22509476222784 run_lib.py:133] step: 52500, training_loss: 4.24555e-02
I0210 03:20:09.610747 22509476222784 run_lib.py:146] step: 52500, eval_loss: 4.99968e-02
I0210 03:20:28.273491 22509476222784 run_lib.py:133] step: 52550, training_loss: 3.85334e-02
I0210 03:20:46.918200 22509476222784 run_lib.py:133] step: 52600, training_loss: 4.86088e-02
I0210 03:20:47.086819 22509476222784 run_lib.py:146] step: 52600, eval_loss: 3.67762e-02
I0210 03:21:05.674752 22509476222784 run_lib.py:133] step: 52650, training_loss: 3.76900e-02
I0210 03:21:24.462091 22509476222784 run_lib.py:133] step: 52700, training_loss: 4.90705e-02
I0210 03:21:24.626734 22509476222784 run_lib.py:146] step: 52700, eval_loss: 5.52010e-02
I0210 03:21:43.174526 22509476222784 run_lib.py:133] step: 52750, training_loss: 2.61617e-02
I0210 03:22:01.700927 22509476222784 run_lib.py:133] step: 52800, training_loss: 4.81008e-02
I0210 03:22:02.012976 22509476222784 run_lib.py:146] step: 52800, eval_loss: 4.33768e-02
I0210 03:22:20.608876 22509476222784 run_lib.py:133] step: 52850, training_loss: 3.39059e-02
I0210 03:22:39.187405 22509476222784 run_lib.py:133] step: 52900, training_loss: 5.25186e-02
I0210 03:22:39.356550 22509476222784 run_lib.py:146] step: 52900, eval_loss: 3.36183e-02
I0210 03:22:57.934483 22509476222784 run_lib.py:133] step: 52950, training_loss: 5.44365e-02
I0210 03:23:16.488018 22509476222784 run_lib.py:133] step: 53000, training_loss: 3.23763e-02
I0210 03:23:16.653717 22509476222784 run_lib.py:146] step: 53000, eval_loss: 3.26897e-02
I0210 03:23:35.336773 22509476222784 run_lib.py:133] step: 53050, training_loss: 5.69874e-02
I0210 03:23:53.912637 22509476222784 run_lib.py:133] step: 53100, training_loss: 4.23483e-02
I0210 03:23:54.084330 22509476222784 run_lib.py:146] step: 53100, eval_loss: 5.88951e-02
I0210 03:24:12.701015 22509476222784 run_lib.py:133] step: 53150, training_loss: 5.73722e-02
I0210 03:24:31.302793 22509476222784 run_lib.py:133] step: 53200, training_loss: 4.77693e-02
I0210 03:24:31.465321 22509476222784 run_lib.py:146] step: 53200, eval_loss: 5.04365e-02
I0210 03:24:50.217442 22509476222784 run_lib.py:133] step: 53250, training_loss: 4.80333e-02
I0210 03:25:08.850938 22509476222784 run_lib.py:133] step: 53300, training_loss: 3.83077e-02
I0210 03:25:09.016623 22509476222784 run_lib.py:146] step: 53300, eval_loss: 4.20147e-02
I0210 03:25:27.545873 22509476222784 run_lib.py:133] step: 53350, training_loss: 3.89663e-02
I0210 03:25:46.133622 22509476222784 run_lib.py:133] step: 53400, training_loss: 3.40520e-02
I0210 03:25:46.314638 22509476222784 run_lib.py:146] step: 53400, eval_loss: 5.26742e-02
I0210 03:26:05.033114 22509476222784 run_lib.py:133] step: 53450, training_loss: 4.83280e-02
I0210 03:26:23.616507 22509476222784 run_lib.py:133] step: 53500, training_loss: 4.79670e-02
I0210 03:26:23.780838 22509476222784 run_lib.py:146] step: 53500, eval_loss: 3.87510e-02
I0210 03:26:42.465148 22509476222784 run_lib.py:133] step: 53550, training_loss: 4.98780e-02
I0210 03:27:00.960803 22509476222784 run_lib.py:133] step: 53600, training_loss: 5.79524e-02
I0210 03:27:01.124628 22509476222784 run_lib.py:146] step: 53600, eval_loss: 2.92453e-02
I0210 03:27:19.789130 22509476222784 run_lib.py:133] step: 53650, training_loss: 4.96540e-02
I0210 03:27:38.420545 22509476222784 run_lib.py:133] step: 53700, training_loss: 3.87770e-02
I0210 03:27:38.586732 22509476222784 run_lib.py:146] step: 53700, eval_loss: 4.96178e-02
I0210 03:27:57.179108 22509476222784 run_lib.py:133] step: 53750, training_loss: 4.59870e-02
I0210 03:28:15.949798 22509476222784 run_lib.py:133] step: 53800, training_loss: 2.74596e-02
I0210 03:28:16.115662 22509476222784 run_lib.py:146] step: 53800, eval_loss: 4.98757e-02
I0210 03:28:34.648966 22509476222784 run_lib.py:133] step: 53850, training_loss: 5.44330e-02
I0210 03:28:53.347695 22509476222784 run_lib.py:133] step: 53900, training_loss: 4.54528e-02
I0210 03:28:53.528754 22509476222784 run_lib.py:146] step: 53900, eval_loss: 3.03467e-02
I0210 03:29:12.082187 22509476222784 run_lib.py:133] step: 53950, training_loss: 4.86599e-02
I0210 03:29:30.627915 22509476222784 run_lib.py:133] step: 54000, training_loss: 5.20126e-02
I0210 03:29:30.791877 22509476222784 run_lib.py:146] step: 54000, eval_loss: 4.09495e-02
I0210 03:29:49.568032 22509476222784 run_lib.py:133] step: 54050, training_loss: 3.84831e-02
I0210 03:30:08.164131 22509476222784 run_lib.py:133] step: 54100, training_loss: 3.97457e-02
I0210 03:30:08.329570 22509476222784 run_lib.py:146] step: 54100, eval_loss: 3.74243e-02
I0210 03:30:26.879223 22509476222784 run_lib.py:133] step: 54150, training_loss: 5.18542e-02
I0210 03:30:45.510515 22509476222784 run_lib.py:133] step: 54200, training_loss: 4.97305e-02
I0210 03:30:45.674774 22509476222784 run_lib.py:146] step: 54200, eval_loss: 4.21665e-02
I0210 03:31:04.481056 22509476222784 run_lib.py:133] step: 54250, training_loss: 4.41990e-02
I0210 03:31:23.057101 22509476222784 run_lib.py:133] step: 54300, training_loss: 4.72268e-02
I0210 03:31:23.226595 22509476222784 run_lib.py:146] step: 54300, eval_loss: 5.04201e-02
I0210 03:31:41.859922 22509476222784 run_lib.py:133] step: 54350, training_loss: 5.40818e-02
I0210 03:32:00.391666 22509476222784 run_lib.py:133] step: 54400, training_loss: 4.50809e-02
I0210 03:32:00.557815 22509476222784 run_lib.py:146] step: 54400, eval_loss: 5.48950e-02
I0210 03:32:19.130401 22509476222784 run_lib.py:133] step: 54450, training_loss: 4.17145e-02
I0210 03:32:37.775911 22509476222784 run_lib.py:133] step: 54500, training_loss: 3.82703e-02
I0210 03:32:37.941777 22509476222784 run_lib.py:146] step: 54500, eval_loss: 5.49965e-02
I0210 03:32:56.739936 22509476222784 run_lib.py:133] step: 54550, training_loss: 4.28290e-02
I0210 03:33:15.368896 22509476222784 run_lib.py:133] step: 54600, training_loss: 4.95194e-02
I0210 03:33:15.533659 22509476222784 run_lib.py:146] step: 54600, eval_loss: 4.56268e-02
I0210 03:33:34.061730 22509476222784 run_lib.py:133] step: 54650, training_loss: 5.14225e-02
I0210 03:33:52.621895 22509476222784 run_lib.py:133] step: 54700, training_loss: 4.50576e-02
I0210 03:33:52.795615 22509476222784 run_lib.py:146] step: 54700, eval_loss: 4.73162e-02
I0210 03:34:11.590180 22509476222784 run_lib.py:133] step: 54750, training_loss: 3.44646e-02
I0210 03:34:30.182214 22509476222784 run_lib.py:133] step: 54800, training_loss: 5.66102e-02
I0210 03:34:30.349570 22509476222784 run_lib.py:146] step: 54800, eval_loss: 5.23890e-02
I0210 03:34:49.057669 22509476222784 run_lib.py:133] step: 54850, training_loss: 4.66333e-02
I0210 03:35:07.637574 22509476222784 run_lib.py:133] step: 54900, training_loss: 4.26828e-02
I0210 03:35:07.806945 22509476222784 run_lib.py:146] step: 54900, eval_loss: 4.59448e-02
I0210 03:35:26.521883 22509476222784 run_lib.py:133] step: 54950, training_loss: 4.28580e-02
I0210 03:35:45.191860 22509476222784 run_lib.py:133] step: 55000, training_loss: 3.98902e-02
I0210 03:35:45.357139 22509476222784 run_lib.py:146] step: 55000, eval_loss: 3.57430e-02
I0210 03:36:04.135566 22509476222784 run_lib.py:133] step: 55050, training_loss: 4.19228e-02
I0210 03:36:22.635669 22509476222784 run_lib.py:133] step: 55100, training_loss: 3.97991e-02
I0210 03:36:22.799697 22509476222784 run_lib.py:146] step: 55100, eval_loss: 3.21645e-02
I0210 03:36:41.327996 22509476222784 run_lib.py:133] step: 55150, training_loss: 5.32142e-02
I0210 03:37:00.027644 22509476222784 run_lib.py:133] step: 55200, training_loss: 4.21361e-02
I0210 03:37:00.197920 22509476222784 run_lib.py:146] step: 55200, eval_loss: 3.98585e-02
I0210 03:37:18.766547 22509476222784 run_lib.py:133] step: 55250, training_loss: 4.62660e-02
I0210 03:37:37.324627 22509476222784 run_lib.py:133] step: 55300, training_loss: 6.04887e-02
I0210 03:37:37.492730 22509476222784 run_lib.py:146] step: 55300, eval_loss: 4.28081e-02
I0210 03:37:56.220071 22509476222784 run_lib.py:133] step: 55350, training_loss: 4.50801e-02
I0210 03:38:14.921842 22509476222784 run_lib.py:133] step: 55400, training_loss: 4.48314e-02
I0210 03:38:15.086573 22509476222784 run_lib.py:146] step: 55400, eval_loss: 4.55533e-02
I0210 03:38:33.628746 22509476222784 run_lib.py:133] step: 55450, training_loss: 5.07581e-02
I0210 03:38:52.198043 22509476222784 run_lib.py:133] step: 55500, training_loss: 5.11697e-02
I0210 03:38:52.362352 22509476222784 run_lib.py:146] step: 55500, eval_loss: 5.30484e-02
I0210 03:39:10.926139 22509476222784 run_lib.py:133] step: 55550, training_loss: 5.43384e-02
I0210 03:39:29.701687 22509476222784 run_lib.py:133] step: 55600, training_loss: 4.51456e-02
I0210 03:39:29.914452 22509476222784 run_lib.py:146] step: 55600, eval_loss: 4.20980e-02
I0210 03:39:48.451739 22509476222784 run_lib.py:133] step: 55650, training_loss: 4.16386e-02
I0210 03:40:07.022010 22509476222784 run_lib.py:133] step: 55700, training_loss: 5.78414e-02
I0210 03:40:07.186678 22509476222784 run_lib.py:146] step: 55700, eval_loss: 4.83728e-02
I0210 03:40:25.792181 22509476222784 run_lib.py:133] step: 55750, training_loss: 4.05028e-02
I0210 03:40:44.608077 22509476222784 run_lib.py:133] step: 55800, training_loss: 3.63480e-02
I0210 03:40:44.774424 22509476222784 run_lib.py:146] step: 55800, eval_loss: 5.17692e-02
I0210 03:41:03.334348 22509476222784 run_lib.py:133] step: 55850, training_loss: 4.71873e-02
I0210 03:41:21.953981 22509476222784 run_lib.py:133] step: 55900, training_loss: 3.34085e-02
I0210 03:41:22.118656 22509476222784 run_lib.py:146] step: 55900, eval_loss: 4.64504e-02
I0210 03:41:40.700994 22509476222784 run_lib.py:133] step: 55950, training_loss: 4.99529e-02
I0210 03:41:59.282118 22509476222784 run_lib.py:133] step: 56000, training_loss: 3.57403e-02
I0210 03:41:59.447932 22509476222784 run_lib.py:146] step: 56000, eval_loss: 5.29330e-02
I0210 03:42:18.287116 22509476222784 run_lib.py:133] step: 56050, training_loss: 3.74321e-02
I0210 03:42:37.029875 22509476222784 run_lib.py:133] step: 56100, training_loss: 4.89219e-02
I0210 03:42:37.191869 22509476222784 run_lib.py:146] step: 56100, eval_loss: 5.25484e-02
I0210 03:42:55.772747 22509476222784 run_lib.py:133] step: 56150, training_loss: 3.96204e-02
I0210 03:43:14.272607 22509476222784 run_lib.py:133] step: 56200, training_loss: 4.51373e-02
I0210 03:43:14.437736 22509476222784 run_lib.py:146] step: 56200, eval_loss: 4.39594e-02
I0210 03:43:33.125100 22509476222784 run_lib.py:133] step: 56250, training_loss: 3.73144e-02
I0210 03:43:51.796524 22509476222784 run_lib.py:133] step: 56300, training_loss: 4.93396e-02
I0210 03:43:51.992080 22509476222784 run_lib.py:146] step: 56300, eval_loss: 4.59024e-02
I0210 03:44:10.772879 22509476222784 run_lib.py:133] step: 56350, training_loss: 4.08510e-02
I0210 03:44:29.331472 22509476222784 run_lib.py:133] step: 56400, training_loss: 3.89256e-02
I0210 03:44:29.497660 22509476222784 run_lib.py:146] step: 56400, eval_loss: 4.73740e-02
I0210 03:44:48.196001 22509476222784 run_lib.py:133] step: 56450, training_loss: 4.67044e-02
I0210 03:45:06.766733 22509476222784 run_lib.py:133] step: 56500, training_loss: 4.11026e-02
I0210 03:45:06.936868 22509476222784 run_lib.py:146] step: 56500, eval_loss: 4.45757e-02
I0210 03:45:25.592367 22509476222784 run_lib.py:133] step: 56550, training_loss: 3.93254e-02
I0210 03:45:44.414462 22509476222784 run_lib.py:133] step: 56600, training_loss: 4.47015e-02
I0210 03:45:44.578943 22509476222784 run_lib.py:146] step: 56600, eval_loss: 4.11886e-02
I0210 03:46:03.197330 22509476222784 run_lib.py:133] step: 56650, training_loss: 5.82586e-02
I0210 03:46:21.940495 22509476222784 run_lib.py:133] step: 56700, training_loss: 3.29413e-02
I0210 03:46:22.107979 22509476222784 run_lib.py:146] step: 56700, eval_loss: 4.57166e-02
I0210 03:46:40.668908 22509476222784 run_lib.py:133] step: 56750, training_loss: 4.26551e-02
I0210 03:46:59.269645 22509476222784 run_lib.py:133] step: 56800, training_loss: 4.74918e-02
I0210 03:46:59.450807 22509476222784 run_lib.py:146] step: 56800, eval_loss: 4.55054e-02
I0210 03:47:18.192380 22509476222784 run_lib.py:133] step: 56850, training_loss: 4.23458e-02
I0210 03:47:36.771670 22509476222784 run_lib.py:133] step: 56900, training_loss: 4.81028e-02
I0210 03:47:36.936910 22509476222784 run_lib.py:146] step: 56900, eval_loss: 4.11597e-02
I0210 03:47:55.519095 22509476222784 run_lib.py:133] step: 56950, training_loss: 5.28554e-02
I0210 03:48:14.228667 22509476222784 run_lib.py:133] step: 57000, training_loss: 5.16700e-02
I0210 03:48:14.390732 22509476222784 run_lib.py:146] step: 57000, eval_loss: 4.75670e-02
I0210 03:48:32.963610 22509476222784 run_lib.py:133] step: 57050, training_loss: 5.44303e-02
I0210 03:48:51.709169 22509476222784 run_lib.py:133] step: 57100, training_loss: 4.12659e-02
I0210 03:48:51.894825 22509476222784 run_lib.py:146] step: 57100, eval_loss: 4.71506e-02
I0210 03:49:10.625553 22509476222784 run_lib.py:133] step: 57150, training_loss: 6.00053e-02
I0210 03:49:29.282127 22509476222784 run_lib.py:133] step: 57200, training_loss: 3.87334e-02
I0210 03:49:29.449842 22509476222784 run_lib.py:146] step: 57200, eval_loss: 4.66843e-02
I0210 03:49:48.025228 22509476222784 run_lib.py:133] step: 57250, training_loss: 4.22547e-02
I0210 03:50:06.661387 22509476222784 run_lib.py:133] step: 57300, training_loss: 4.71475e-02
I0210 03:50:06.831924 22509476222784 run_lib.py:146] step: 57300, eval_loss: 4.43966e-02
I0210 03:50:25.581890 22509476222784 run_lib.py:133] step: 57350, training_loss: 4.04805e-02
I0210 03:50:44.231026 22509476222784 run_lib.py:133] step: 57400, training_loss: 4.25325e-02
I0210 03:50:44.396809 22509476222784 run_lib.py:146] step: 57400, eval_loss: 3.22154e-02
I0210 03:51:02.971580 22509476222784 run_lib.py:133] step: 57450, training_loss: 4.64407e-02
I0210 03:51:21.539288 22509476222784 run_lib.py:133] step: 57500, training_loss: 4.67479e-02
I0210 03:51:21.702889 22509476222784 run_lib.py:146] step: 57500, eval_loss: 4.58453e-02
I0210 03:51:40.514646 22509476222784 run_lib.py:133] step: 57550, training_loss: 4.57854e-02
I0210 03:51:59.112196 22509476222784 run_lib.py:133] step: 57600, training_loss: 4.46721e-02
I0210 03:51:59.277918 22509476222784 run_lib.py:146] step: 57600, eval_loss: 5.10678e-02
I0210 03:52:18.021203 22509476222784 run_lib.py:133] step: 57650, training_loss: 4.09994e-02
I0210 03:52:36.614328 22509476222784 run_lib.py:133] step: 57700, training_loss: 3.98196e-02
I0210 03:52:36.779958 22509476222784 run_lib.py:146] step: 57700, eval_loss: 4.70686e-02
I0210 03:52:55.477009 22509476222784 run_lib.py:133] step: 57750, training_loss: 4.45446e-02
I0210 03:53:14.147883 22509476222784 run_lib.py:133] step: 57800, training_loss: 3.08891e-02
I0210 03:53:14.315230 22509476222784 run_lib.py:146] step: 57800, eval_loss: 4.81055e-02
I0210 03:53:33.116317 22509476222784 run_lib.py:133] step: 57850, training_loss: 3.33342e-02
I0210 03:53:51.717740 22509476222784 run_lib.py:133] step: 57900, training_loss: 3.95865e-02
I0210 03:53:51.881901 22509476222784 run_lib.py:146] step: 57900, eval_loss: 4.56174e-02
I0210 03:54:10.457518 22509476222784 run_lib.py:133] step: 57950, training_loss: 5.00117e-02
I0210 03:54:29.212271 22509476222784 run_lib.py:133] step: 58000, training_loss: 5.38754e-02
I0210 03:54:29.373676 22509476222784 run_lib.py:146] step: 58000, eval_loss: 5.55392e-02
I0210 03:54:47.973587 22509476222784 run_lib.py:133] step: 58050, training_loss: 5.55185e-02
I0210 03:55:06.547219 22509476222784 run_lib.py:133] step: 58100, training_loss: 4.85972e-02
I0210 03:55:06.715125 22509476222784 run_lib.py:146] step: 58100, eval_loss: 4.58525e-02
I0210 03:55:25.469404 22509476222784 run_lib.py:133] step: 58150, training_loss: 4.90867e-02
I0210 03:55:44.022011 22509476222784 run_lib.py:133] step: 58200, training_loss: 5.09673e-02
I0210 03:55:44.188755 22509476222784 run_lib.py:146] step: 58200, eval_loss: 4.52594e-02
I0210 03:56:02.908035 22509476222784 run_lib.py:133] step: 58250, training_loss: 5.94970e-02
I0210 03:56:21.517195 22509476222784 run_lib.py:133] step: 58300, training_loss: 4.64615e-02
I0210 03:56:21.690808 22509476222784 run_lib.py:146] step: 58300, eval_loss: 4.37073e-02
I0210 03:56:40.300572 22509476222784 run_lib.py:133] step: 58350, training_loss: 4.30564e-02
I0210 03:56:59.098452 22509476222784 run_lib.py:133] step: 58400, training_loss: 3.40938e-02
I0210 03:56:59.262982 22509476222784 run_lib.py:146] step: 58400, eval_loss: 4.42710e-02
I0210 03:57:17.822236 22509476222784 run_lib.py:133] step: 58450, training_loss: 4.53132e-02
I0210 03:57:36.370908 22509476222784 run_lib.py:133] step: 58500, training_loss: 5.35932e-02
I0210 03:57:36.533730 22509476222784 run_lib.py:146] step: 58500, eval_loss: 3.52303e-02
I0210 03:57:55.127952 22509476222784 run_lib.py:133] step: 58550, training_loss: 5.42102e-02
I0210 03:58:13.900706 22509476222784 run_lib.py:133] step: 58600, training_loss: 4.50011e-02
I0210 03:58:14.082805 22509476222784 run_lib.py:146] step: 58600, eval_loss: 5.04017e-02
I0210 03:58:32.709911 22509476222784 run_lib.py:133] step: 58650, training_loss: 5.18092e-02
I0210 03:58:51.393328 22509476222784 run_lib.py:133] step: 58700, training_loss: 4.07914e-02
I0210 03:58:51.567946 22509476222784 run_lib.py:146] step: 58700, eval_loss: 6.24591e-02
I0210 03:59:10.151114 22509476222784 run_lib.py:133] step: 58750, training_loss: 3.75926e-02
I0210 03:59:28.714840 22509476222784 run_lib.py:133] step: 58800, training_loss: 4.93410e-02
I0210 03:59:28.889343 22509476222784 run_lib.py:146] step: 58800, eval_loss: 4.44700e-02
I0210 03:59:47.660761 22509476222784 run_lib.py:133] step: 58850, training_loss: 4.77769e-02
I0210 04:00:06.378955 22509476222784 run_lib.py:133] step: 58900, training_loss: 5.19513e-02
I0210 04:00:06.541585 22509476222784 run_lib.py:146] step: 58900, eval_loss: 4.46922e-02
I0210 04:00:25.113617 22509476222784 run_lib.py:133] step: 58950, training_loss: 4.26235e-02
I0210 04:00:43.633777 22509476222784 run_lib.py:133] step: 59000, training_loss: 3.95287e-02
I0210 04:00:43.793777 22509476222784 run_lib.py:146] step: 59000, eval_loss: 3.79656e-02
I0210 04:01:02.442121 22509476222784 run_lib.py:133] step: 59050, training_loss: 5.54083e-02
I0210 04:01:20.997736 22509476222784 run_lib.py:133] step: 59100, training_loss: 5.49334e-02
I0210 04:01:21.211733 22509476222784 run_lib.py:146] step: 59100, eval_loss: 4.09727e-02
I0210 04:01:40.005312 22509476222784 run_lib.py:133] step: 59150, training_loss: 4.23520e-02
I0210 04:01:58.562450 22509476222784 run_lib.py:133] step: 59200, training_loss: 4.65295e-02
I0210 04:01:58.727876 22509476222784 run_lib.py:146] step: 59200, eval_loss: 3.72467e-02
I0210 04:02:17.467110 22509476222784 run_lib.py:133] step: 59250, training_loss: 3.72657e-02
I0210 04:02:36.014914 22509476222784 run_lib.py:133] step: 59300, training_loss: 3.36518e-02
I0210 04:02:36.178511 22509476222784 run_lib.py:146] step: 59300, eval_loss: 3.70457e-02
I0210 04:02:54.802469 22509476222784 run_lib.py:133] step: 59350, training_loss: 4.04502e-02
I0210 04:03:13.560580 22509476222784 run_lib.py:133] step: 59400, training_loss: 3.75519e-02
I0210 04:03:13.723383 22509476222784 run_lib.py:146] step: 59400, eval_loss: 3.95351e-02
I0210 04:03:32.353235 22509476222784 run_lib.py:133] step: 59450, training_loss: 5.63140e-02
I0210 04:03:51.137799 22509476222784 run_lib.py:133] step: 59500, training_loss: 3.89507e-02
I0210 04:03:51.308067 22509476222784 run_lib.py:146] step: 59500, eval_loss: 4.74763e-02
I0210 04:04:09.892334 22509476222784 run_lib.py:133] step: 59550, training_loss: 5.85528e-02
I0210 04:04:28.486363 22509476222784 run_lib.py:133] step: 59600, training_loss: 4.04186e-02
I0210 04:04:28.668708 22509476222784 run_lib.py:146] step: 59600, eval_loss: 3.92994e-02
I0210 04:04:47.421980 22509476222784 run_lib.py:133] step: 59650, training_loss: 4.17312e-02
I0210 04:05:06.031406 22509476222784 run_lib.py:133] step: 59700, training_loss: 4.30851e-02
I0210 04:05:06.199941 22509476222784 run_lib.py:146] step: 59700, eval_loss: 4.07482e-02
I0210 04:05:24.787544 22509476222784 run_lib.py:133] step: 59750, training_loss: 4.14891e-02
I0210 04:05:43.495392 22509476222784 run_lib.py:133] step: 59800, training_loss: 5.59570e-02
I0210 04:05:43.658944 22509476222784 run_lib.py:146] step: 59800, eval_loss: 4.68348e-02
I0210 04:06:02.250318 22509476222784 run_lib.py:133] step: 59850, training_loss: 3.81526e-02
I0210 04:06:20.854658 22509476222784 run_lib.py:133] step: 59900, training_loss: 5.08578e-02
I0210 04:06:21.209495 22509476222784 run_lib.py:146] step: 59900, eval_loss: 4.16301e-02
I0210 04:06:39.834129 22509476222784 run_lib.py:133] step: 59950, training_loss: 4.19267e-02
I0210 04:06:58.386919 22509476222784 run_lib.py:133] step: 60000, training_loss: 4.76263e-02
I0210 04:06:59.150548 22509476222784 run_lib.py:146] step: 60000, eval_loss: 6.16254e-02
I0210 04:07:20.436447 22509476222784 run_lib.py:133] step: 60050, training_loss: 2.98064e-02
I0210 04:07:38.951380 22509476222784 run_lib.py:133] step: 60100, training_loss: 4.16521e-02
I0210 04:07:39.120568 22509476222784 run_lib.py:146] step: 60100, eval_loss: 5.44285e-02
I0210 04:07:57.820557 22509476222784 run_lib.py:133] step: 60150, training_loss: 4.79224e-02
I0210 04:08:16.423546 22509476222784 run_lib.py:133] step: 60200, training_loss: 3.99138e-02
I0210 04:08:16.588911 22509476222784 run_lib.py:146] step: 60200, eval_loss: 5.54959e-02
I0210 04:08:35.250509 22509476222784 run_lib.py:133] step: 60250, training_loss: 4.59889e-02
I0210 04:08:53.790680 22509476222784 run_lib.py:133] step: 60300, training_loss: 3.46511e-02
I0210 04:08:53.993826 22509476222784 run_lib.py:146] step: 60300, eval_loss: 5.59100e-02
I0210 04:09:12.490669 22509476222784 run_lib.py:133] step: 60350, training_loss: 4.15197e-02
I0210 04:09:31.056982 22509476222784 run_lib.py:133] step: 60400, training_loss: 4.54723e-02
I0210 04:09:31.221487 22509476222784 run_lib.py:146] step: 60400, eval_loss: 5.20143e-02
I0210 04:09:50.013587 22509476222784 run_lib.py:133] step: 60450, training_loss: 3.95617e-02
I0210 04:10:08.642422 22509476222784 run_lib.py:133] step: 60500, training_loss: 5.87799e-02
I0210 04:10:08.806781 22509476222784 run_lib.py:146] step: 60500, eval_loss: 4.45796e-02
I0210 04:10:27.381666 22509476222784 run_lib.py:133] step: 60550, training_loss: 4.59562e-02
I0210 04:10:46.024950 22509476222784 run_lib.py:133] step: 60600, training_loss: 4.27892e-02
I0210 04:10:46.192800 22509476222784 run_lib.py:146] step: 60600, eval_loss: 5.70981e-02
I0210 04:11:04.910934 22509476222784 run_lib.py:133] step: 60650, training_loss: 4.32657e-02
I0210 04:11:23.554236 22509476222784 run_lib.py:133] step: 60700, training_loss: 6.99188e-02
I0210 04:11:23.720008 22509476222784 run_lib.py:146] step: 60700, eval_loss: 3.77614e-02
I0210 04:11:42.390757 22509476222784 run_lib.py:133] step: 60750, training_loss: 4.36603e-02
I0210 04:12:00.885336 22509476222784 run_lib.py:133] step: 60800, training_loss: 6.13228e-02
I0210 04:12:01.050683 22509476222784 run_lib.py:146] step: 60800, eval_loss: 4.54948e-02
I0210 04:12:19.743239 22509476222784 run_lib.py:133] step: 60850, training_loss: 4.87373e-02
I0210 04:12:38.366150 22509476222784 run_lib.py:133] step: 60900, training_loss: 4.38564e-02
I0210 04:12:38.529911 22509476222784 run_lib.py:146] step: 60900, eval_loss: 3.54868e-02
I0210 04:12:57.312950 22509476222784 run_lib.py:133] step: 60950, training_loss: 3.54948e-02
I0210 04:13:15.848185 22509476222784 run_lib.py:133] step: 61000, training_loss: 5.95535e-02
I0210 04:13:16.013568 22509476222784 run_lib.py:146] step: 61000, eval_loss: 4.93109e-02
I0210 04:13:34.492332 22509476222784 run_lib.py:133] step: 61050, training_loss: 4.39387e-02
I0210 04:13:53.240472 22509476222784 run_lib.py:133] step: 61100, training_loss: 4.98778e-02
I0210 04:13:53.465918 22509476222784 run_lib.py:146] step: 61100, eval_loss: 5.13300e-02
I0210 04:14:12.058974 22509476222784 run_lib.py:133] step: 61150, training_loss: 3.84042e-02
I0210 04:14:30.651913 22509476222784 run_lib.py:133] step: 61200, training_loss: 3.51918e-02
I0210 04:14:30.816766 22509476222784 run_lib.py:146] step: 61200, eval_loss: 4.89185e-02
I0210 04:14:49.592058 22509476222784 run_lib.py:133] step: 61250, training_loss: 3.87043e-02
I0210 04:15:08.306137 22509476222784 run_lib.py:133] step: 61300, training_loss: 6.79932e-02
I0210 04:15:08.471557 22509476222784 run_lib.py:146] step: 61300, eval_loss: 4.29541e-02
I0210 04:15:27.017050 22509476222784 run_lib.py:133] step: 61350, training_loss: 5.05638e-02
I0210 04:15:45.654757 22509476222784 run_lib.py:133] step: 61400, training_loss: 5.08202e-02
I0210 04:15:45.821731 22509476222784 run_lib.py:146] step: 61400, eval_loss: 3.91452e-02
I0210 04:16:04.451220 22509476222784 run_lib.py:133] step: 61450, training_loss: 3.33332e-02
I0210 04:16:23.223636 22509476222784 run_lib.py:133] step: 61500, training_loss: 5.45706e-02
I0210 04:16:23.400442 22509476222784 run_lib.py:146] step: 61500, eval_loss: 5.44159e-02
I0210 04:16:41.975356 22509476222784 run_lib.py:133] step: 61550, training_loss: 4.31101e-02
I0210 04:17:00.556800 22509476222784 run_lib.py:133] step: 61600, training_loss: 3.15683e-02
I0210 04:17:00.722891 22509476222784 run_lib.py:146] step: 61600, eval_loss: 4.09644e-02
I0210 04:17:19.311609 22509476222784 run_lib.py:133] step: 61650, training_loss: 4.26806e-02
I0210 04:17:38.191540 22509476222784 run_lib.py:133] step: 61700, training_loss: 4.39900e-02
I0210 04:17:38.356669 22509476222784 run_lib.py:146] step: 61700, eval_loss: 3.84488e-02
I0210 04:17:56.934287 22509476222784 run_lib.py:133] step: 61750, training_loss: 4.37261e-02
I0210 04:18:15.569152 22509476222784 run_lib.py:133] step: 61800, training_loss: 4.81649e-02
I0210 04:18:15.731627 22509476222784 run_lib.py:146] step: 61800, eval_loss: 5.46090e-02
I0210 04:18:34.301706 22509476222784 run_lib.py:133] step: 61850, training_loss: 4.35342e-02
I0210 04:18:52.875966 22509476222784 run_lib.py:133] step: 61900, training_loss: 4.22132e-02
I0210 04:18:53.056703 22509476222784 run_lib.py:146] step: 61900, eval_loss: 4.32841e-02
I0210 04:19:11.827253 22509476222784 run_lib.py:133] step: 61950, training_loss: 3.77063e-02
I0210 04:19:30.514652 22509476222784 run_lib.py:133] step: 62000, training_loss: 5.26940e-02
I0210 04:19:30.680632 22509476222784 run_lib.py:146] step: 62000, eval_loss: 4.03951e-02
I0210 04:19:49.218261 22509476222784 run_lib.py:133] step: 62050, training_loss: 5.82408e-02
I0210 04:20:07.811785 22509476222784 run_lib.py:133] step: 62100, training_loss: 5.82035e-02
I0210 04:20:07.979056 22509476222784 run_lib.py:146] step: 62100, eval_loss: 4.81648e-02
I0210 04:20:26.642627 22509476222784 run_lib.py:133] step: 62150, training_loss: 3.18476e-02
I0210 04:20:45.226583 22509476222784 run_lib.py:133] step: 62200, training_loss: 5.11574e-02
I0210 04:20:45.394597 22509476222784 run_lib.py:146] step: 62200, eval_loss: 3.92515e-02
I0210 04:21:04.165100 22509476222784 run_lib.py:133] step: 62250, training_loss: 4.72288e-02
I0210 04:21:22.763340 22509476222784 run_lib.py:133] step: 62300, training_loss: 4.59668e-02
I0210 04:21:22.926552 22509476222784 run_lib.py:146] step: 62300, eval_loss: 4.49971e-02
I0210 04:21:41.654012 22509476222784 run_lib.py:133] step: 62350, training_loss: 5.71911e-02
I0210 04:22:00.245315 22509476222784 run_lib.py:133] step: 62400, training_loss: 4.05569e-02
I0210 04:22:00.432689 22509476222784 run_lib.py:146] step: 62400, eval_loss: 4.46724e-02
I0210 04:22:18.946899 22509476222784 run_lib.py:133] step: 62450, training_loss: 4.55051e-02
I0210 04:22:37.751737 22509476222784 run_lib.py:133] step: 62500, training_loss: 3.25314e-02
I0210 04:22:37.933602 22509476222784 run_lib.py:146] step: 62500, eval_loss: 3.88486e-02
I0210 04:22:56.434390 22509476222784 run_lib.py:133] step: 62550, training_loss: 3.64837e-02
I0210 04:23:15.147211 22509476222784 run_lib.py:133] step: 62600, training_loss: 3.62895e-02
I0210 04:23:15.312587 22509476222784 run_lib.py:146] step: 62600, eval_loss: 3.77228e-02
I0210 04:23:33.837261 22509476222784 run_lib.py:133] step: 62650, training_loss: 4.44262e-02
I0210 04:23:52.418669 22509476222784 run_lib.py:133] step: 62700, training_loss: 4.04615e-02
I0210 04:23:52.623747 22509476222784 run_lib.py:146] step: 62700, eval_loss: 4.54060e-02
I0210 04:24:11.380708 22509476222784 run_lib.py:133] step: 62750, training_loss: 5.14742e-02
I0210 04:24:29.940421 22509476222784 run_lib.py:133] step: 62800, training_loss: 3.97446e-02
I0210 04:24:30.135771 22509476222784 run_lib.py:146] step: 62800, eval_loss: 5.00507e-02
I0210 04:24:48.687849 22509476222784 run_lib.py:133] step: 62850, training_loss: 4.20543e-02
I0210 04:25:07.429078 22509476222784 run_lib.py:133] step: 62900, training_loss: 4.58976e-02
I0210 04:25:07.594543 22509476222784 run_lib.py:146] step: 62900, eval_loss: 3.27157e-02
I0210 04:25:26.083595 22509476222784 run_lib.py:133] step: 62950, training_loss: 5.57959e-02
I0210 04:25:44.677067 22509476222784 run_lib.py:133] step: 63000, training_loss: 3.81688e-02
I0210 04:25:44.868910 22509476222784 run_lib.py:146] step: 63000, eval_loss: 4.57612e-02
I0210 04:26:03.587327 22509476222784 run_lib.py:133] step: 63050, training_loss: 4.47326e-02
I0210 04:26:22.131534 22509476222784 run_lib.py:133] step: 63100, training_loss: 4.05000e-02
I0210 04:26:22.299695 22509476222784 run_lib.py:146] step: 63100, eval_loss: 4.84642e-02
I0210 04:26:40.816943 22509476222784 run_lib.py:133] step: 63150, training_loss: 4.50172e-02
I0210 04:26:59.378477 22509476222784 run_lib.py:133] step: 63200, training_loss: 4.63340e-02
I0210 04:26:59.543700 22509476222784 run_lib.py:146] step: 63200, eval_loss: 3.95970e-02
I0210 04:27:18.308814 22509476222784 run_lib.py:133] step: 63250, training_loss: 3.93800e-02
I0210 04:27:37.003306 22509476222784 run_lib.py:133] step: 63300, training_loss: 4.58245e-02
I0210 04:27:37.169823 22509476222784 run_lib.py:146] step: 63300, eval_loss: 4.47201e-02
I0210 04:27:55.770813 22509476222784 run_lib.py:133] step: 63350, training_loss: 4.76123e-02
I0210 04:28:14.385739 22509476222784 run_lib.py:133] step: 63400, training_loss: 5.89766e-02
I0210 04:28:14.552757 22509476222784 run_lib.py:146] step: 63400, eval_loss: 4.47791e-02
I0210 04:28:33.238856 22509476222784 run_lib.py:133] step: 63450, training_loss: 2.63711e-02
I0210 04:28:51.838201 22509476222784 run_lib.py:133] step: 63500, training_loss: 5.05715e-02
I0210 04:28:52.018579 22509476222784 run_lib.py:146] step: 63500, eval_loss: 3.13605e-02
I0210 04:29:10.786868 22509476222784 run_lib.py:133] step: 63550, training_loss: 5.13749e-02
I0210 04:29:29.352495 22509476222784 run_lib.py:133] step: 63600, training_loss: 3.96251e-02
I0210 04:29:29.543028 22509476222784 run_lib.py:146] step: 63600, eval_loss: 5.23650e-02
I0210 04:29:48.309761 22509476222784 run_lib.py:133] step: 63650, training_loss: 6.32351e-02
I0210 04:30:06.850312 22509476222784 run_lib.py:133] step: 63700, training_loss: 2.91512e-02
I0210 04:30:07.015671 22509476222784 run_lib.py:146] step: 63700, eval_loss: 6.02444e-02
I0210 04:30:25.713760 22509476222784 run_lib.py:133] step: 63750, training_loss: 3.85025e-02
I0210 04:30:44.244680 22509476222784 run_lib.py:133] step: 63800, training_loss: 4.66321e-02
I0210 04:30:44.410913 22509476222784 run_lib.py:146] step: 63800, eval_loss: 2.50746e-02
I0210 04:31:02.993030 22509476222784 run_lib.py:133] step: 63850, training_loss: 4.48050e-02
I0210 04:31:21.781105 22509476222784 run_lib.py:133] step: 63900, training_loss: 4.61521e-02
I0210 04:31:21.947684 22509476222784 run_lib.py:146] step: 63900, eval_loss: 4.65020e-02
I0210 04:31:40.452943 22509476222784 run_lib.py:133] step: 63950, training_loss: 4.75579e-02
I0210 04:31:59.065412 22509476222784 run_lib.py:133] step: 64000, training_loss: 4.38918e-02
I0210 04:31:59.235785 22509476222784 run_lib.py:146] step: 64000, eval_loss: 5.28482e-02
I0210 04:32:17.974811 22509476222784 run_lib.py:133] step: 64050, training_loss: 5.00427e-02
I0210 04:32:36.542850 22509476222784 run_lib.py:133] step: 64100, training_loss: 3.96521e-02
I0210 04:32:36.707856 22509476222784 run_lib.py:146] step: 64100, eval_loss: 3.96349e-02
I0210 04:32:55.411795 22509476222784 run_lib.py:133] step: 64150, training_loss: 2.48841e-02
I0210 04:33:13.923114 22509476222784 run_lib.py:133] step: 64200, training_loss: 3.29889e-02
I0210 04:33:14.131345 22509476222784 run_lib.py:146] step: 64200, eval_loss: 3.76680e-02
I0210 04:33:32.656695 22509476222784 run_lib.py:133] step: 64250, training_loss: 3.43479e-02
I0210 04:33:51.356059 22509476222784 run_lib.py:133] step: 64300, training_loss: 3.73871e-02
I0210 04:33:51.526856 22509476222784 run_lib.py:146] step: 64300, eval_loss: 3.98753e-02
I0210 04:34:10.112533 22509476222784 run_lib.py:133] step: 64350, training_loss: 3.14799e-02
I0210 04:34:28.656089 22509476222784 run_lib.py:133] step: 64400, training_loss: 5.03346e-02
I0210 04:34:28.855081 22509476222784 run_lib.py:146] step: 64400, eval_loss: 3.86940e-02
I0210 04:34:47.419267 22509476222784 run_lib.py:133] step: 64450, training_loss: 4.90972e-02
I0210 04:35:06.160825 22509476222784 run_lib.py:133] step: 64500, training_loss: 5.61714e-02
I0210 04:35:06.335548 22509476222784 run_lib.py:146] step: 64500, eval_loss: 4.48198e-02
I0210 04:35:24.857984 22509476222784 run_lib.py:133] step: 64550, training_loss: 4.13675e-02
I0210 04:35:43.702450 22509476222784 run_lib.py:133] step: 64600, training_loss: 4.17198e-02
I0210 04:35:43.877136 22509476222784 run_lib.py:146] step: 64600, eval_loss: 3.46796e-02
I0210 04:36:02.532571 22509476222784 run_lib.py:133] step: 64650, training_loss: 4.56048e-02
I0210 04:36:21.072158 22509476222784 run_lib.py:133] step: 64700, training_loss: 4.54818e-02
I0210 04:36:21.232486 22509476222784 run_lib.py:146] step: 64700, eval_loss: 3.66654e-02
I0210 04:36:39.926405 22509476222784 run_lib.py:133] step: 64750, training_loss: 4.10356e-02
I0210 04:36:58.541286 22509476222784 run_lib.py:133] step: 64800, training_loss: 3.98611e-02
I0210 04:36:58.717954 22509476222784 run_lib.py:146] step: 64800, eval_loss: 4.41661e-02
I0210 04:37:17.264261 22509476222784 run_lib.py:133] step: 64850, training_loss: 5.12291e-02
I0210 04:37:35.844875 22509476222784 run_lib.py:133] step: 64900, training_loss: 3.72232e-02
I0210 04:37:36.011628 22509476222784 run_lib.py:146] step: 64900, eval_loss: 4.14634e-02
I0210 04:37:54.729533 22509476222784 run_lib.py:133] step: 64950, training_loss: 3.96473e-02
I0210 04:38:13.340348 22509476222784 run_lib.py:133] step: 65000, training_loss: 3.86283e-02
I0210 04:38:13.505711 22509476222784 run_lib.py:146] step: 65000, eval_loss: 4.60968e-02
I0210 04:38:32.171987 22509476222784 run_lib.py:133] step: 65050, training_loss: 4.75587e-02
I0210 04:38:50.724384 22509476222784 run_lib.py:133] step: 65100, training_loss: 5.39225e-02
I0210 04:38:50.909825 22509476222784 run_lib.py:146] step: 65100, eval_loss: 4.30451e-02
I0210 04:39:09.727759 22509476222784 run_lib.py:133] step: 65150, training_loss: 5.00601e-02
I0210 04:39:28.248610 22509476222784 run_lib.py:133] step: 65200, training_loss: 4.37829e-02
I0210 04:39:28.418630 22509476222784 run_lib.py:146] step: 65200, eval_loss: 4.08785e-02
I0210 04:39:46.977941 22509476222784 run_lib.py:133] step: 65250, training_loss: 5.60504e-02
I0210 04:40:05.685084 22509476222784 run_lib.py:133] step: 65300, training_loss: 4.96371e-02
I0210 04:40:05.854783 22509476222784 run_lib.py:146] step: 65300, eval_loss: 3.56656e-02
I0210 04:40:24.385095 22509476222784 run_lib.py:133] step: 65350, training_loss: 3.52790e-02
I0210 04:40:43.154258 22509476222784 run_lib.py:133] step: 65400, training_loss: 5.22538e-02
I0210 04:40:43.323675 22509476222784 run_lib.py:146] step: 65400, eval_loss: 3.76309e-02
I0210 04:41:01.854242 22509476222784 run_lib.py:133] step: 65450, training_loss: 4.33928e-02
I0210 04:41:20.377973 22509476222784 run_lib.py:133] step: 65500, training_loss: 3.25656e-02
I0210 04:41:20.542532 22509476222784 run_lib.py:146] step: 65500, eval_loss: 3.73907e-02
I0210 04:41:39.297763 22509476222784 run_lib.py:133] step: 65550, training_loss: 3.55010e-02
I0210 04:41:57.855195 22509476222784 run_lib.py:133] step: 65600, training_loss: 3.75620e-02
I0210 04:41:58.018624 22509476222784 run_lib.py:146] step: 65600, eval_loss: 3.86996e-02
I0210 04:42:16.676130 22509476222784 run_lib.py:133] step: 65650, training_loss: 5.78713e-02
I0210 04:42:35.412037 22509476222784 run_lib.py:133] step: 65700, training_loss: 5.00211e-02
I0210 04:42:35.575630 22509476222784 run_lib.py:146] step: 65700, eval_loss: 3.36137e-02
I0210 04:42:54.132727 22509476222784 run_lib.py:133] step: 65750, training_loss: 3.87495e-02
I0210 04:43:12.718651 22509476222784 run_lib.py:133] step: 65800, training_loss: 4.51984e-02
I0210 04:43:13.039736 22509476222784 run_lib.py:146] step: 65800, eval_loss: 4.34341e-02
I0210 04:43:31.583384 22509476222784 run_lib.py:133] step: 65850, training_loss: 4.67539e-02
I0210 04:43:50.174519 22509476222784 run_lib.py:133] step: 65900, training_loss: 3.71151e-02
I0210 04:43:50.342771 22509476222784 run_lib.py:146] step: 65900, eval_loss: 5.30532e-02
I0210 04:44:08.906596 22509476222784 run_lib.py:133] step: 65950, training_loss: 6.68635e-02
I0210 04:44:27.483044 22509476222784 run_lib.py:133] step: 66000, training_loss: 4.55431e-02
I0210 04:44:27.684857 22509476222784 run_lib.py:146] step: 66000, eval_loss: 5.03831e-02
I0210 04:44:46.417113 22509476222784 run_lib.py:133] step: 66050, training_loss: 4.10124e-02
I0210 04:45:05.047317 22509476222784 run_lib.py:133] step: 66100, training_loss: 4.43105e-02
I0210 04:45:05.216883 22509476222784 run_lib.py:146] step: 66100, eval_loss: 4.94565e-02
I0210 04:45:23.875035 22509476222784 run_lib.py:133] step: 66150, training_loss: 4.54860e-02
I0210 04:45:42.453187 22509476222784 run_lib.py:133] step: 66200, training_loss: 4.61018e-02
I0210 04:45:42.616739 22509476222784 run_lib.py:146] step: 66200, eval_loss: 3.03713e-02
I0210 04:46:01.357507 22509476222784 run_lib.py:133] step: 66250, training_loss: 3.89463e-02
I0210 04:46:20.003387 22509476222784 run_lib.py:133] step: 66300, training_loss: 2.92818e-02
I0210 04:46:20.170864 22509476222784 run_lib.py:146] step: 66300, eval_loss: 5.23372e-02
I0210 04:46:38.765567 22509476222784 run_lib.py:133] step: 66350, training_loss: 4.74011e-02
I0210 04:46:57.416014 22509476222784 run_lib.py:133] step: 66400, training_loss: 4.06660e-02
I0210 04:46:57.581739 22509476222784 run_lib.py:146] step: 66400, eval_loss: 4.63552e-02
I0210 04:47:16.365685 22509476222784 run_lib.py:133] step: 66450, training_loss: 3.97998e-02
I0210 04:47:34.901789 22509476222784 run_lib.py:133] step: 66500, training_loss: 4.13614e-02
I0210 04:47:35.067321 22509476222784 run_lib.py:146] step: 66500, eval_loss: 4.20122e-02
I0210 04:47:53.770223 22509476222784 run_lib.py:133] step: 66550, training_loss: 5.89600e-02
I0210 04:48:12.335241 22509476222784 run_lib.py:133] step: 66600, training_loss: 4.80293e-02
I0210 04:48:12.499783 22509476222784 run_lib.py:146] step: 66600, eval_loss: 3.53259e-02
I0210 04:48:31.337691 22509476222784 run_lib.py:133] step: 66650, training_loss: 5.07376e-02
I0210 04:48:49.892347 22509476222784 run_lib.py:133] step: 66700, training_loss: 4.86473e-02
I0210 04:48:50.055128 22509476222784 run_lib.py:146] step: 66700, eval_loss: 4.28316e-02
I0210 04:49:08.611711 22509476222784 run_lib.py:133] step: 66750, training_loss: 5.28275e-02
I0210 04:49:27.271517 22509476222784 run_lib.py:133] step: 66800, training_loss: 6.05550e-02
I0210 04:49:27.437763 22509476222784 run_lib.py:146] step: 66800, eval_loss: 6.03525e-02
I0210 04:49:46.001642 22509476222784 run_lib.py:133] step: 66850, training_loss: 4.78661e-02
I0210 04:50:04.840615 22509476222784 run_lib.py:133] step: 66900, training_loss: 3.04156e-02
I0210 04:50:05.048780 22509476222784 run_lib.py:146] step: 66900, eval_loss: 6.60639e-02
I0210 04:50:23.619137 22509476222784 run_lib.py:133] step: 66950, training_loss: 4.34437e-02
I0210 04:50:42.187433 22509476222784 run_lib.py:133] step: 67000, training_loss: 5.16648e-02
I0210 04:50:42.351254 22509476222784 run_lib.py:146] step: 67000, eval_loss: 3.38387e-02
I0210 04:51:00.919869 22509476222784 run_lib.py:133] step: 67050, training_loss: 3.17865e-02
I0210 04:51:19.728707 22509476222784 run_lib.py:133] step: 67100, training_loss: 5.16816e-02
I0210 04:51:19.890324 22509476222784 run_lib.py:146] step: 67100, eval_loss: 3.78800e-02
I0210 04:51:38.485697 22509476222784 run_lib.py:133] step: 67150, training_loss: 3.58854e-02
I0210 04:51:57.090366 22509476222784 run_lib.py:133] step: 67200, training_loss: 4.80663e-02
I0210 04:51:57.270606 22509476222784 run_lib.py:146] step: 67200, eval_loss: 4.10357e-02
I0210 04:52:16.000308 22509476222784 run_lib.py:133] step: 67250, training_loss: 3.68920e-02
I0210 04:52:34.528410 22509476222784 run_lib.py:133] step: 67300, training_loss: 5.23272e-02
I0210 04:52:34.694827 22509476222784 run_lib.py:146] step: 67300, eval_loss: 4.40376e-02
I0210 04:52:53.328870 22509476222784 run_lib.py:133] step: 67350, training_loss: 5.53926e-02
I0210 04:53:11.876940 22509476222784 run_lib.py:133] step: 67400, training_loss: 4.47625e-02
I0210 04:53:12.040956 22509476222784 run_lib.py:146] step: 67400, eval_loss: 4.24209e-02
I0210 04:53:30.571269 22509476222784 run_lib.py:133] step: 67450, training_loss: 5.96399e-02
I0210 04:53:49.165524 22509476222784 run_lib.py:133] step: 67500, training_loss: 4.87754e-02
I0210 04:53:49.347904 22509476222784 run_lib.py:146] step: 67500, eval_loss: 5.19243e-02
I0210 04:54:08.163568 22509476222784 run_lib.py:133] step: 67550, training_loss: 4.14925e-02
I0210 04:54:26.790855 22509476222784 run_lib.py:133] step: 67600, training_loss: 3.76430e-02
I0210 04:54:26.951991 22509476222784 run_lib.py:146] step: 67600, eval_loss: 5.01008e-02
I0210 04:54:45.438936 22509476222784 run_lib.py:133] step: 67650, training_loss: 4.57193e-02
I0210 04:55:03.993553 22509476222784 run_lib.py:133] step: 67700, training_loss: 4.79357e-02
I0210 04:55:04.175682 22509476222784 run_lib.py:146] step: 67700, eval_loss: 3.85013e-02
I0210 04:55:22.955562 22509476222784 run_lib.py:133] step: 67750, training_loss: 4.40617e-02
I0210 04:55:41.509713 22509476222784 run_lib.py:133] step: 67800, training_loss: 3.89145e-02
I0210 04:55:41.698016 22509476222784 run_lib.py:146] step: 67800, eval_loss: 4.74332e-02
I0210 04:56:00.391404 22509476222784 run_lib.py:133] step: 67850, training_loss: 6.20504e-02
I0210 04:56:18.980760 22509476222784 run_lib.py:133] step: 67900, training_loss: 4.06160e-02
I0210 04:56:19.145340 22509476222784 run_lib.py:146] step: 67900, eval_loss: 4.94138e-02
I0210 04:56:37.904948 22509476222784 run_lib.py:133] step: 67950, training_loss: 3.60461e-02
I0210 04:56:56.524120 22509476222784 run_lib.py:133] step: 68000, training_loss: 3.64914e-02
I0210 04:56:56.687648 22509476222784 run_lib.py:146] step: 68000, eval_loss: 4.83594e-02
I0210 04:57:15.499218 22509476222784 run_lib.py:133] step: 68050, training_loss: 5.38564e-02
I0210 04:57:34.074128 22509476222784 run_lib.py:133] step: 68100, training_loss: 3.52687e-02
I0210 04:57:34.240757 22509476222784 run_lib.py:146] step: 68100, eval_loss: 5.53632e-02
I0210 04:57:52.799795 22509476222784 run_lib.py:133] step: 68150, training_loss: 5.38354e-02
I0210 04:58:11.513165 22509476222784 run_lib.py:133] step: 68200, training_loss: 3.78617e-02
I0210 04:58:11.683972 22509476222784 run_lib.py:146] step: 68200, eval_loss: 5.97136e-02
I0210 04:58:30.268903 22509476222784 run_lib.py:133] step: 68250, training_loss: 3.69837e-02
I0210 04:58:48.941593 22509476222784 run_lib.py:133] step: 68300, training_loss: 4.39330e-02
I0210 04:58:49.136914 22509476222784 run_lib.py:146] step: 68300, eval_loss: 3.09462e-02
I0210 04:59:07.853699 22509476222784 run_lib.py:133] step: 68350, training_loss: 4.56415e-02
I0210 04:59:26.541342 22509476222784 run_lib.py:133] step: 68400, training_loss: 4.52462e-02
I0210 04:59:26.729566 22509476222784 run_lib.py:146] step: 68400, eval_loss: 4.16382e-02
I0210 04:59:45.274106 22509476222784 run_lib.py:133] step: 68450, training_loss: 4.98093e-02
I0210 05:00:03.854456 22509476222784 run_lib.py:133] step: 68500, training_loss: 3.67099e-02
I0210 05:00:04.022885 22509476222784 run_lib.py:146] step: 68500, eval_loss: 5.45838e-02
I0210 05:00:22.626663 22509476222784 run_lib.py:133] step: 68550, training_loss: 3.19229e-02
I0210 05:00:41.368701 22509476222784 run_lib.py:133] step: 68600, training_loss: 5.30751e-02
I0210 05:00:41.561974 22509476222784 run_lib.py:146] step: 68600, eval_loss: 5.46204e-02
I0210 05:01:00.107927 22509476222784 run_lib.py:133] step: 68650, training_loss: 4.00334e-02
I0210 05:01:18.679393 22509476222784 run_lib.py:133] step: 68700, training_loss: 4.33078e-02
I0210 05:01:18.845967 22509476222784 run_lib.py:146] step: 68700, eval_loss: 3.69311e-02
I0210 05:01:37.413224 22509476222784 run_lib.py:133] step: 68750, training_loss: 3.47407e-02
I0210 05:01:56.163282 22509476222784 run_lib.py:133] step: 68800, training_loss: 4.90763e-02
I0210 05:01:56.328854 22509476222784 run_lib.py:146] step: 68800, eval_loss: 4.18660e-02
I0210 05:02:14.881500 22509476222784 run_lib.py:133] step: 68850, training_loss: 4.03260e-02
I0210 05:02:33.528851 22509476222784 run_lib.py:133] step: 68900, training_loss: 4.24112e-02
I0210 05:02:33.692547 22509476222784 run_lib.py:146] step: 68900, eval_loss: 3.60878e-02
I0210 05:02:52.244871 22509476222784 run_lib.py:133] step: 68950, training_loss: 4.15442e-02
I0210 05:03:10.878183 22509476222784 run_lib.py:133] step: 69000, training_loss: 3.12539e-02
I0210 05:03:11.058640 22509476222784 run_lib.py:146] step: 69000, eval_loss: 3.92363e-02
I0210 05:03:29.837544 22509476222784 run_lib.py:133] step: 69050, training_loss: 4.70739e-02
I0210 05:03:48.548560 22509476222784 run_lib.py:133] step: 69100, training_loss: 5.44087e-02
I0210 05:03:48.715617 22509476222784 run_lib.py:146] step: 69100, eval_loss: 4.87485e-02
I0210 05:04:07.258351 22509476222784 run_lib.py:133] step: 69150, training_loss: 4.08229e-02
I0210 05:04:25.769083 22509476222784 run_lib.py:133] step: 69200, training_loss: 3.78362e-02
I0210 05:04:25.933811 22509476222784 run_lib.py:146] step: 69200, eval_loss: 4.12519e-02
I0210 05:04:44.638022 22509476222784 run_lib.py:133] step: 69250, training_loss: 5.34111e-02
I0210 05:05:03.298269 22509476222784 run_lib.py:133] step: 69300, training_loss: 4.28379e-02
I0210 05:05:03.464044 22509476222784 run_lib.py:146] step: 69300, eval_loss: 4.19549e-02
I0210 05:05:22.230056 22509476222784 run_lib.py:133] step: 69350, training_loss: 5.01447e-02
I0210 05:05:40.858776 22509476222784 run_lib.py:133] step: 69400, training_loss: 5.44568e-02
I0210 05:05:41.022854 22509476222784 run_lib.py:146] step: 69400, eval_loss: 5.45605e-02
I0210 05:05:59.759116 22509476222784 run_lib.py:133] step: 69450, training_loss: 3.94889e-02
I0210 05:06:18.366771 22509476222784 run_lib.py:133] step: 69500, training_loss: 3.35453e-02
I0210 05:06:18.528858 22509476222784 run_lib.py:146] step: 69500, eval_loss: 3.74394e-02
I0210 05:06:37.135724 22509476222784 run_lib.py:133] step: 69550, training_loss: 5.37155e-02
I0210 05:06:55.906898 22509476222784 run_lib.py:133] step: 69600, training_loss: 4.54193e-02
I0210 05:06:56.073707 22509476222784 run_lib.py:146] step: 69600, eval_loss: 4.26574e-02
I0210 05:07:14.602630 22509476222784 run_lib.py:133] step: 69650, training_loss: 3.54702e-02
I0210 05:07:33.340193 22509476222784 run_lib.py:133] step: 69700, training_loss: 5.10346e-02
I0210 05:07:33.503706 22509476222784 run_lib.py:146] step: 69700, eval_loss: 4.99834e-02
I0210 05:07:52.054097 22509476222784 run_lib.py:133] step: 69750, training_loss: 5.17419e-02
I0210 05:08:10.670050 22509476222784 run_lib.py:133] step: 69800, training_loss: 5.27869e-02
I0210 05:08:10.836412 22509476222784 run_lib.py:146] step: 69800, eval_loss: 4.37054e-02
I0210 05:08:29.611273 22509476222784 run_lib.py:133] step: 69850, training_loss: 4.68495e-02
I0210 05:08:48.214873 22509476222784 run_lib.py:133] step: 69900, training_loss: 6.00549e-02
I0210 05:08:48.379636 22509476222784 run_lib.py:146] step: 69900, eval_loss: 4.45067e-02
I0210 05:09:06.943452 22509476222784 run_lib.py:133] step: 69950, training_loss: 4.61224e-02
I0210 05:09:25.654426 22509476222784 run_lib.py:133] step: 70000, training_loss: 4.34344e-02
I0210 05:09:26.547040 22509476222784 run_lib.py:146] step: 70000, eval_loss: 5.74111e-02
I0210 05:09:48.155640 22509476222784 run_lib.py:133] step: 70050, training_loss: 4.36019e-02
I0210 05:10:06.705695 22509476222784 run_lib.py:133] step: 70100, training_loss: 3.70849e-02
I0210 05:10:06.869828 22509476222784 run_lib.py:146] step: 70100, eval_loss: 3.99084e-02
I0210 05:10:25.386237 22509476222784 run_lib.py:133] step: 70150, training_loss: 4.88885e-02
I0210 05:10:44.169720 22509476222784 run_lib.py:133] step: 70200, training_loss: 4.12272e-02
I0210 05:10:44.335960 22509476222784 run_lib.py:146] step: 70200, eval_loss: 4.78235e-02
I0210 05:11:02.938210 22509476222784 run_lib.py:133] step: 70250, training_loss: 4.37890e-02
I0210 05:11:21.591926 22509476222784 run_lib.py:133] step: 70300, training_loss: 3.54581e-02
I0210 05:11:21.756796 22509476222784 run_lib.py:146] step: 70300, eval_loss: 4.90064e-02
I0210 05:11:40.516036 22509476222784 run_lib.py:133] step: 70350, training_loss: 3.95817e-02
I0210 05:11:59.080152 22509476222784 run_lib.py:133] step: 70400, training_loss: 3.57684e-02
I0210 05:11:59.243736 22509476222784 run_lib.py:146] step: 70400, eval_loss: 3.59079e-02
I0210 05:12:17.871381 22509476222784 run_lib.py:133] step: 70450, training_loss: 4.61743e-02
I0210 05:12:36.436561 22509476222784 run_lib.py:133] step: 70500, training_loss: 4.39398e-02
I0210 05:12:36.601877 22509476222784 run_lib.py:146] step: 70500, eval_loss: 3.40570e-02
I0210 05:12:55.214125 22509476222784 run_lib.py:133] step: 70550, training_loss: 5.55098e-02
I0210 05:13:13.784986 22509476222784 run_lib.py:133] step: 70600, training_loss: 3.64828e-02
I0210 05:13:13.974762 22509476222784 run_lib.py:146] step: 70600, eval_loss: 4.18282e-02
I0210 05:13:32.672889 22509476222784 run_lib.py:133] step: 70650, training_loss: 4.33862e-02
I0210 05:13:51.299461 22509476222784 run_lib.py:133] step: 70700, training_loss: 5.21216e-02
I0210 05:13:51.468812 22509476222784 run_lib.py:146] step: 70700, eval_loss: 4.31676e-02
I0210 05:14:10.056576 22509476222784 run_lib.py:133] step: 70750, training_loss: 6.06693e-02
I0210 05:14:28.672081 22509476222784 run_lib.py:133] step: 70800, training_loss: 4.78859e-02
I0210 05:14:28.861346 22509476222784 run_lib.py:146] step: 70800, eval_loss: 3.78041e-02
I0210 05:14:47.645621 22509476222784 run_lib.py:133] step: 70850, training_loss: 5.42437e-02
I0210 05:15:06.169724 22509476222784 run_lib.py:133] step: 70900, training_loss: 3.37709e-02
I0210 05:15:06.332501 22509476222784 run_lib.py:146] step: 70900, eval_loss: 4.02948e-02
I0210 05:15:25.040096 22509476222784 run_lib.py:133] step: 70950, training_loss: 3.28457e-02
I0210 05:15:43.588155 22509476222784 run_lib.py:133] step: 71000, training_loss: 3.83651e-02
I0210 05:15:43.780705 22509476222784 run_lib.py:146] step: 71000, eval_loss: 3.28953e-02
I0210 05:16:02.483043 22509476222784 run_lib.py:133] step: 71050, training_loss: 4.26371e-02
I0210 05:16:21.071087 22509476222784 run_lib.py:133] step: 71100, training_loss: 4.64100e-02
I0210 05:16:21.247654 22509476222784 run_lib.py:146] step: 71100, eval_loss: 4.55538e-02
I0210 05:16:40.056144 22509476222784 run_lib.py:133] step: 71150, training_loss: 5.18074e-02
I0210 05:16:58.597535 22509476222784 run_lib.py:133] step: 71200, training_loss: 4.83913e-02
I0210 05:16:58.762817 22509476222784 run_lib.py:146] step: 71200, eval_loss: 4.76558e-02
I0210 05:17:17.339808 22509476222784 run_lib.py:133] step: 71250, training_loss: 4.36788e-02
I0210 05:17:36.053336 22509476222784 run_lib.py:133] step: 71300, training_loss: 5.51964e-02
I0210 05:17:36.225800 22509476222784 run_lib.py:146] step: 71300, eval_loss: 5.05844e-02
I0210 05:17:54.837993 22509476222784 run_lib.py:133] step: 71350, training_loss: 3.72054e-02
I0210 05:18:13.441491 22509476222784 run_lib.py:133] step: 71400, training_loss: 4.48183e-02
I0210 05:18:13.634478 22509476222784 run_lib.py:146] step: 71400, eval_loss: 4.38873e-02
I0210 05:18:32.446867 22509476222784 run_lib.py:133] step: 71450, training_loss: 5.41914e-02
I0210 05:18:51.040791 22509476222784 run_lib.py:133] step: 71500, training_loss: 5.01089e-02
I0210 05:18:51.205924 22509476222784 run_lib.py:146] step: 71500, eval_loss: 5.43694e-02
I0210 05:19:09.895543 22509476222784 run_lib.py:133] step: 71550, training_loss: 3.91319e-02
I0210 05:19:28.443314 22509476222784 run_lib.py:133] step: 71600, training_loss: 4.72450e-02
I0210 05:19:28.655634 22509476222784 run_lib.py:146] step: 71600, eval_loss: 4.21449e-02
I0210 05:19:47.257858 22509476222784 run_lib.py:133] step: 71650, training_loss: 5.23654e-02
I0210 05:20:06.021287 22509476222784 run_lib.py:133] step: 71700, training_loss: 4.26718e-02
I0210 05:20:06.185992 22509476222784 run_lib.py:146] step: 71700, eval_loss: 4.34114e-02
I0210 05:20:24.708547 22509476222784 run_lib.py:133] step: 71750, training_loss: 4.32254e-02
I0210 05:20:43.242261 22509476222784 run_lib.py:133] step: 71800, training_loss: 5.61347e-02
I0210 05:20:43.406734 22509476222784 run_lib.py:146] step: 71800, eval_loss: 4.55981e-02
I0210 05:21:01.956118 22509476222784 run_lib.py:133] step: 71850, training_loss: 6.17263e-02
I0210 05:21:20.733612 22509476222784 run_lib.py:133] step: 71900, training_loss: 3.93212e-02
I0210 05:21:20.906771 22509476222784 run_lib.py:146] step: 71900, eval_loss: 4.13967e-02
I0210 05:21:39.589758 22509476222784 run_lib.py:133] step: 71950, training_loss: 4.54587e-02
I0210 05:21:58.594791 22509476222784 run_lib.py:133] step: 72000, training_loss: 4.95400e-02
I0210 05:21:58.759742 22509476222784 run_lib.py:146] step: 72000, eval_loss: 4.21309e-02
I0210 05:22:17.324930 22509476222784 run_lib.py:133] step: 72050, training_loss: 3.96596e-02
I0210 05:22:35.823973 22509476222784 run_lib.py:133] step: 72100, training_loss: 3.34653e-02
I0210 05:22:35.995759 22509476222784 run_lib.py:146] step: 72100, eval_loss: 5.20574e-02
I0210 05:22:54.710252 22509476222784 run_lib.py:133] step: 72150, training_loss: 3.69799e-02
I0210 05:23:13.452818 22509476222784 run_lib.py:133] step: 72200, training_loss: 4.59650e-02
I0210 05:23:13.617924 22509476222784 run_lib.py:146] step: 72200, eval_loss: 3.46643e-02
I0210 05:23:32.175334 22509476222784 run_lib.py:133] step: 72250, training_loss: 6.74130e-02
I0210 05:23:50.695776 22509476222784 run_lib.py:133] step: 72300, training_loss: 4.27998e-02
I0210 05:23:50.859679 22509476222784 run_lib.py:146] step: 72300, eval_loss: 4.73704e-02
I0210 05:24:09.569599 22509476222784 run_lib.py:133] step: 72350, training_loss: 4.75076e-02
I0210 05:24:28.156096 22509476222784 run_lib.py:133] step: 72400, training_loss: 5.15391e-02
I0210 05:24:28.320881 22509476222784 run_lib.py:146] step: 72400, eval_loss: 5.36754e-02
I0210 05:24:47.171090 22509476222784 run_lib.py:133] step: 72450, training_loss: 4.08046e-02
I0210 05:25:05.716971 22509476222784 run_lib.py:133] step: 72500, training_loss: 5.10769e-02
I0210 05:25:05.882898 22509476222784 run_lib.py:146] step: 72500, eval_loss: 3.72510e-02
I0210 05:25:24.588322 22509476222784 run_lib.py:133] step: 72550, training_loss: 4.15036e-02
I0210 05:25:43.149556 22509476222784 run_lib.py:133] step: 72600, training_loss: 4.63017e-02
I0210 05:25:43.315717 22509476222784 run_lib.py:146] step: 72600, eval_loss: 3.38454e-02
I0210 05:26:01.905416 22509476222784 run_lib.py:133] step: 72650, training_loss: 4.52369e-02
I0210 05:26:20.660605 22509476222784 run_lib.py:133] step: 72700, training_loss: 5.37097e-02
I0210 05:26:20.826125 22509476222784 run_lib.py:146] step: 72700, eval_loss: 4.10465e-02
I0210 05:26:39.431266 22509476222784 run_lib.py:133] step: 72750, training_loss: 3.40183e-02
I0210 05:26:58.187879 22509476222784 run_lib.py:133] step: 72800, training_loss: 5.14340e-02
I0210 05:26:58.350599 22509476222784 run_lib.py:146] step: 72800, eval_loss: 5.11370e-02
I0210 05:27:16.911841 22509476222784 run_lib.py:133] step: 72850, training_loss: 4.57015e-02
I0210 05:27:35.465186 22509476222784 run_lib.py:133] step: 72900, training_loss: 4.47914e-02
I0210 05:27:35.632350 22509476222784 run_lib.py:146] step: 72900, eval_loss: 5.42063e-02
I0210 05:27:54.418949 22509476222784 run_lib.py:133] step: 72950, training_loss: 6.23603e-02
I0210 05:28:12.958966 22509476222784 run_lib.py:133] step: 73000, training_loss: 4.13214e-02
I0210 05:28:13.125650 22509476222784 run_lib.py:146] step: 73000, eval_loss: 3.79208e-02
I0210 05:28:31.657249 22509476222784 run_lib.py:133] step: 73050, training_loss: 4.93241e-02
I0210 05:28:50.382220 22509476222784 run_lib.py:133] step: 73100, training_loss: 3.98815e-02
I0210 05:28:50.548710 22509476222784 run_lib.py:146] step: 73100, eval_loss: 5.22657e-02
I0210 05:29:09.116059 22509476222784 run_lib.py:133] step: 73150, training_loss: 5.44377e-02
I0210 05:29:27.707483 22509476222784 run_lib.py:133] step: 73200, training_loss: 3.80966e-02
I0210 05:29:28.041861 22509476222784 run_lib.py:146] step: 73200, eval_loss: 4.34558e-02
I0210 05:29:46.660564 22509476222784 run_lib.py:133] step: 73250, training_loss: 4.97329e-02
I0210 05:30:05.218869 22509476222784 run_lib.py:133] step: 73300, training_loss: 4.03848e-02
I0210 05:30:05.380814 22509476222784 run_lib.py:146] step: 73300, eval_loss: 4.57814e-02
I0210 05:30:23.939565 22509476222784 run_lib.py:133] step: 73350, training_loss: 2.94808e-02
I0210 05:30:42.515992 22509476222784 run_lib.py:133] step: 73400, training_loss: 4.97482e-02
I0210 05:30:42.682746 22509476222784 run_lib.py:146] step: 73400, eval_loss: 4.79505e-02
I0210 05:31:01.457878 22509476222784 run_lib.py:133] step: 73450, training_loss: 4.30893e-02
I0210 05:31:20.164582 22509476222784 run_lib.py:133] step: 73500, training_loss: 5.04720e-02
I0210 05:31:20.332772 22509476222784 run_lib.py:146] step: 73500, eval_loss: 4.52616e-02
I0210 05:31:38.903660 22509476222784 run_lib.py:133] step: 73550, training_loss: 3.91413e-02
I0210 05:31:57.516345 22509476222784 run_lib.py:133] step: 73600, training_loss: 4.55521e-02
I0210 05:31:57.680649 22509476222784 run_lib.py:146] step: 73600, eval_loss: 4.32574e-02
I0210 05:32:16.423534 22509476222784 run_lib.py:133] step: 73650, training_loss: 4.32112e-02
I0210 05:32:35.100471 22509476222784 run_lib.py:133] step: 73700, training_loss: 4.12414e-02
I0210 05:32:35.266839 22509476222784 run_lib.py:146] step: 73700, eval_loss: 3.84668e-02
I0210 05:32:53.880787 22509476222784 run_lib.py:133] step: 73750, training_loss: 4.24402e-02
I0210 05:33:12.460312 22509476222784 run_lib.py:133] step: 73800, training_loss: 4.79896e-02
I0210 05:33:12.621648 22509476222784 run_lib.py:146] step: 73800, eval_loss: 3.47840e-02
I0210 05:33:31.302893 22509476222784 run_lib.py:133] step: 73850, training_loss: 5.04031e-02
I0210 05:33:49.829321 22509476222784 run_lib.py:133] step: 73900, training_loss: 3.89196e-02
I0210 05:33:49.996437 22509476222784 run_lib.py:146] step: 73900, eval_loss: 4.11888e-02
I0210 05:34:08.682373 22509476222784 run_lib.py:133] step: 73950, training_loss: 4.37631e-02
I0210 05:34:27.300913 22509476222784 run_lib.py:133] step: 74000, training_loss: 4.59953e-02
I0210 05:34:27.521635 22509476222784 run_lib.py:146] step: 74000, eval_loss: 5.47419e-02
I0210 05:34:46.297411 22509476222784 run_lib.py:133] step: 74050, training_loss: 3.99600e-02
I0210 05:35:04.909262 22509476222784 run_lib.py:133] step: 74100, training_loss: 4.77016e-02
I0210 05:35:05.101910 22509476222784 run_lib.py:146] step: 74100, eval_loss: 4.74089e-02
I0210 05:35:23.714366 22509476222784 run_lib.py:133] step: 74150, training_loss: 4.22863e-02
I0210 05:35:42.448002 22509476222784 run_lib.py:133] step: 74200, training_loss: 4.55426e-02
I0210 05:35:42.610640 22509476222784 run_lib.py:146] step: 74200, eval_loss: 3.39233e-02
I0210 05:36:01.258446 22509476222784 run_lib.py:133] step: 74250, training_loss: 4.91694e-02
I0210 05:36:20.026906 22509476222784 run_lib.py:133] step: 74300, training_loss: 3.36647e-02
I0210 05:36:20.193049 22509476222784 run_lib.py:146] step: 74300, eval_loss: 3.57457e-02
I0210 05:36:38.800633 22509476222784 run_lib.py:133] step: 74350, training_loss: 4.26572e-02
I0210 05:36:57.409353 22509476222784 run_lib.py:133] step: 74400, training_loss: 5.29638e-02
I0210 05:36:57.574869 22509476222784 run_lib.py:146] step: 74400, eval_loss: 3.99687e-02
I0210 05:37:16.107758 22509476222784 run_lib.py:133] step: 74450, training_loss: 4.61370e-02
I0210 05:37:34.855090 22509476222784 run_lib.py:133] step: 74500, training_loss: 4.23198e-02
I0210 05:37:35.061614 22509476222784 run_lib.py:146] step: 74500, eval_loss: 3.81139e-02
I0210 05:37:53.662393 22509476222784 run_lib.py:133] step: 74550, training_loss: 3.55071e-02
I0210 05:38:12.305960 22509476222784 run_lib.py:133] step: 74600, training_loss: 4.53803e-02
I0210 05:38:12.473904 22509476222784 run_lib.py:146] step: 74600, eval_loss: 4.72244e-02
I0210 05:38:31.271392 22509476222784 run_lib.py:133] step: 74650, training_loss: 4.51306e-02
I0210 05:38:49.856022 22509476222784 run_lib.py:133] step: 74700, training_loss: 4.07009e-02
I0210 05:38:50.017898 22509476222784 run_lib.py:146] step: 74700, eval_loss: 5.40114e-02
I0210 05:39:08.703789 22509476222784 run_lib.py:133] step: 74750, training_loss: 5.79669e-02
I0210 05:39:27.290440 22509476222784 run_lib.py:133] step: 74800, training_loss: 4.03419e-02
I0210 05:39:27.477972 22509476222784 run_lib.py:146] step: 74800, eval_loss: 3.82800e-02
I0210 05:39:46.076775 22509476222784 run_lib.py:133] step: 74850, training_loss: 4.03660e-02
I0210 05:40:04.653091 22509476222784 run_lib.py:133] step: 74900, training_loss: 5.03208e-02
I0210 05:40:04.841988 22509476222784 run_lib.py:146] step: 74900, eval_loss: 4.77653e-02
I0210 05:40:23.592709 22509476222784 run_lib.py:133] step: 74950, training_loss: 6.10005e-02
I0210 05:40:42.315199 22509476222784 run_lib.py:133] step: 75000, training_loss: 4.23656e-02
I0210 05:40:42.480647 22509476222784 run_lib.py:146] step: 75000, eval_loss: 4.80473e-02
I0210 05:41:01.033626 22509476222784 run_lib.py:133] step: 75050, training_loss: 4.13230e-02
I0210 05:41:19.628955 22509476222784 run_lib.py:133] step: 75100, training_loss: 4.29416e-02
I0210 05:41:19.795778 22509476222784 run_lib.py:146] step: 75100, eval_loss: 3.78134e-02
I0210 05:41:38.596062 22509476222784 run_lib.py:133] step: 75150, training_loss: 4.04940e-02
I0210 05:41:57.167316 22509476222784 run_lib.py:133] step: 75200, training_loss: 4.37834e-02
I0210 05:41:57.335119 22509476222784 run_lib.py:146] step: 75200, eval_loss: 6.02656e-02
I0210 05:42:16.050220 22509476222784 run_lib.py:133] step: 75250, training_loss: 5.08122e-02
I0210 05:42:34.606777 22509476222784 run_lib.py:133] step: 75300, training_loss: 5.76732e-02
I0210 05:42:34.782999 22509476222784 run_lib.py:146] step: 75300, eval_loss: 3.73060e-02
I0210 05:42:53.543709 22509476222784 run_lib.py:133] step: 75350, training_loss: 5.13297e-02
I0210 05:43:12.135829 22509476222784 run_lib.py:133] step: 75400, training_loss: 4.90256e-02
I0210 05:43:12.302693 22509476222784 run_lib.py:146] step: 75400, eval_loss: 5.72725e-02
I0210 05:43:31.006049 22509476222784 run_lib.py:133] step: 75450, training_loss: 5.00867e-02
I0210 05:43:49.571910 22509476222784 run_lib.py:133] step: 75500, training_loss: 3.42749e-02
I0210 05:43:49.736602 22509476222784 run_lib.py:146] step: 75500, eval_loss: 4.80947e-02
I0210 05:44:08.315009 22509476222784 run_lib.py:133] step: 75550, training_loss: 4.47970e-02
I0210 05:44:27.036696 22509476222784 run_lib.py:133] step: 75600, training_loss: 4.31589e-02
I0210 05:44:27.208972 22509476222784 run_lib.py:146] step: 75600, eval_loss: 4.35630e-02
I0210 05:44:45.859480 22509476222784 run_lib.py:133] step: 75650, training_loss: 4.82535e-02
I0210 05:45:04.421650 22509476222784 run_lib.py:133] step: 75700, training_loss: 3.98081e-02
I0210 05:45:04.583730 22509476222784 run_lib.py:146] step: 75700, eval_loss: 4.30731e-02
I0210 05:45:23.402802 22509476222784 run_lib.py:133] step: 75750, training_loss: 2.85580e-02
I0210 05:45:42.127918 22509476222784 run_lib.py:133] step: 75800, training_loss: 4.82063e-02
I0210 05:45:42.292817 22509476222784 run_lib.py:146] step: 75800, eval_loss: 3.52191e-02
I0210 05:46:00.844663 22509476222784 run_lib.py:133] step: 75850, training_loss: 4.10446e-02
I0210 05:46:19.459368 22509476222784 run_lib.py:133] step: 75900, training_loss: 4.00423e-02
I0210 05:46:19.625688 22509476222784 run_lib.py:146] step: 75900, eval_loss: 4.20161e-02
I0210 05:46:38.226645 22509476222784 run_lib.py:133] step: 75950, training_loss: 4.26224e-02
I0210 05:46:56.966130 22509476222784 run_lib.py:133] step: 76000, training_loss: 5.60633e-02
I0210 05:46:57.136731 22509476222784 run_lib.py:146] step: 76000, eval_loss: 3.87022e-02
I0210 05:47:15.720233 22509476222784 run_lib.py:133] step: 76050, training_loss: 3.92101e-02
I0210 05:47:34.273758 22509476222784 run_lib.py:133] step: 76100, training_loss: 4.77223e-02
I0210 05:47:34.445822 22509476222784 run_lib.py:146] step: 76100, eval_loss: 4.09806e-02
I0210 05:47:53.086989 22509476222784 run_lib.py:133] step: 76150, training_loss: 4.97154e-02
I0210 05:48:11.885846 22509476222784 run_lib.py:133] step: 76200, training_loss: 4.06209e-02
I0210 05:48:12.079912 22509476222784 run_lib.py:146] step: 76200, eval_loss: 5.11690e-02
I0210 05:48:30.615873 22509476222784 run_lib.py:133] step: 76250, training_loss: 3.93189e-02
I0210 05:48:49.230558 22509476222784 run_lib.py:133] step: 76300, training_loss: 4.09656e-02
I0210 05:48:49.397962 22509476222784 run_lib.py:146] step: 76300, eval_loss: 4.38235e-02
I0210 05:49:07.939159 22509476222784 run_lib.py:133] step: 76350, training_loss: 5.40537e-02
I0210 05:49:26.540431 22509476222784 run_lib.py:133] step: 76400, training_loss: 3.05642e-02
I0210 05:49:26.762609 22509476222784 run_lib.py:146] step: 76400, eval_loss: 4.34119e-02
I0210 05:49:45.521553 22509476222784 run_lib.py:133] step: 76450, training_loss: 4.27598e-02
I0210 05:50:04.220111 22509476222784 run_lib.py:133] step: 76500, training_loss: 5.19642e-02
I0210 05:50:04.384584 22509476222784 run_lib.py:146] step: 76500, eval_loss: 4.57660e-02
I0210 05:50:22.983786 22509476222784 run_lib.py:133] step: 76550, training_loss: 5.82856e-02
I0210 05:50:41.527678 22509476222784 run_lib.py:133] step: 76600, training_loss: 4.07517e-02
I0210 05:50:41.690767 22509476222784 run_lib.py:146] step: 76600, eval_loss: 4.57253e-02
I0210 05:51:00.394124 22509476222784 run_lib.py:133] step: 76650, training_loss: 5.05811e-02
I0210 05:51:18.985466 22509476222784 run_lib.py:133] step: 76700, training_loss: 4.11671e-02
I0210 05:51:19.202716 22509476222784 run_lib.py:146] step: 76700, eval_loss: 4.58399e-02
I0210 05:51:37.982287 22509476222784 run_lib.py:133] step: 76750, training_loss: 4.28250e-02
I0210 05:51:56.574339 22509476222784 run_lib.py:133] step: 76800, training_loss: 5.14593e-02
I0210 05:51:56.800878 22509476222784 run_lib.py:146] step: 76800, eval_loss: 2.81654e-02
I0210 05:52:15.450396 22509476222784 run_lib.py:133] step: 76850, training_loss: 4.27095e-02
I0210 05:52:33.954683 22509476222784 run_lib.py:133] step: 76900, training_loss: 5.04638e-02
I0210 05:52:34.123729 22509476222784 run_lib.py:146] step: 76900, eval_loss: 6.51287e-02
I0210 05:52:52.673099 22509476222784 run_lib.py:133] step: 76950, training_loss: 3.90625e-02
I0210 05:53:11.435081 22509476222784 run_lib.py:133] step: 77000, training_loss: 5.72981e-02
I0210 05:53:11.600892 22509476222784 run_lib.py:146] step: 77000, eval_loss: 4.47859e-02
I0210 05:53:30.217039 22509476222784 run_lib.py:133] step: 77050, training_loss: 3.63134e-02
I0210 05:53:48.954654 22509476222784 run_lib.py:133] step: 77100, training_loss: 4.14697e-02
I0210 05:53:49.115794 22509476222784 run_lib.py:146] step: 77100, eval_loss: 4.31702e-02
I0210 05:54:07.700846 22509476222784 run_lib.py:133] step: 77150, training_loss: 4.48391e-02
I0210 05:54:26.249340 22509476222784 run_lib.py:133] step: 77200, training_loss: 4.32151e-02
I0210 05:54:26.424851 22509476222784 run_lib.py:146] step: 77200, eval_loss: 5.70513e-02
I0210 05:54:45.189785 22509476222784 run_lib.py:133] step: 77250, training_loss: 5.18678e-02
I0210 05:55:03.782793 22509476222784 run_lib.py:133] step: 77300, training_loss: 3.69715e-02
I0210 05:55:03.948926 22509476222784 run_lib.py:146] step: 77300, eval_loss: 3.19734e-02
I0210 05:55:22.505145 22509476222784 run_lib.py:133] step: 77350, training_loss: 4.00607e-02
I0210 05:55:41.216974 22509476222784 run_lib.py:133] step: 77400, training_loss: 5.03307e-02
I0210 05:55:41.422614 22509476222784 run_lib.py:146] step: 77400, eval_loss: 4.60825e-02
I0210 05:55:59.976921 22509476222784 run_lib.py:133] step: 77450, training_loss: 4.34902e-02
I0210 05:56:18.613800 22509476222784 run_lib.py:133] step: 77500, training_loss: 5.24703e-02
I0210 05:56:18.783083 22509476222784 run_lib.py:146] step: 77500, eval_loss: 4.55040e-02
I0210 05:56:37.435128 22509476222784 run_lib.py:133] step: 77550, training_loss: 5.75691e-02
I0210 05:56:55.991247 22509476222784 run_lib.py:133] step: 77600, training_loss: 5.67408e-02
I0210 05:56:56.152663 22509476222784 run_lib.py:146] step: 77600, eval_loss: 4.26975e-02
I0210 05:57:14.685913 22509476222784 run_lib.py:133] step: 77650, training_loss: 5.53211e-02
I0210 05:57:33.332926 22509476222784 run_lib.py:133] step: 77700, training_loss: 4.78809e-02
I0210 05:57:33.498044 22509476222784 run_lib.py:146] step: 77700, eval_loss: 4.61561e-02
I0210 05:57:52.277309 22509476222784 run_lib.py:133] step: 77750, training_loss: 4.08875e-02
I0210 05:58:11.087768 22509476222784 run_lib.py:133] step: 77800, training_loss: 4.37833e-02
I0210 05:58:11.311817 22509476222784 run_lib.py:146] step: 77800, eval_loss: 3.68017e-02
I0210 05:58:29.821486 22509476222784 run_lib.py:133] step: 77850, training_loss: 4.03993e-02
I0210 05:58:48.384622 22509476222784 run_lib.py:133] step: 77900, training_loss: 3.24388e-02
I0210 05:58:48.577388 22509476222784 run_lib.py:146] step: 77900, eval_loss: 4.75614e-02
I0210 05:59:07.238247 22509476222784 run_lib.py:133] step: 77950, training_loss: 4.64247e-02
I0210 05:59:25.827819 22509476222784 run_lib.py:133] step: 78000, training_loss: 5.22782e-02
I0210 05:59:25.996021 22509476222784 run_lib.py:146] step: 78000, eval_loss: 3.80745e-02
I0210 05:59:44.789934 22509476222784 run_lib.py:133] step: 78050, training_loss: 5.13390e-02
I0210 06:00:03.346600 22509476222784 run_lib.py:133] step: 78100, training_loss: 4.82992e-02
I0210 06:00:03.509759 22509476222784 run_lib.py:146] step: 78100, eval_loss: 4.96384e-02
I0210 06:00:22.260800 22509476222784 run_lib.py:133] step: 78150, training_loss: 5.27571e-02
I0210 06:00:40.874613 22509476222784 run_lib.py:133] step: 78200, training_loss: 3.82993e-02
I0210 06:00:41.044821 22509476222784 run_lib.py:146] step: 78200, eval_loss: 4.45454e-02
I0210 06:00:59.859274 22509476222784 run_lib.py:133] step: 78250, training_loss: 5.26699e-02
I0210 06:01:18.708475 22509476222784 run_lib.py:133] step: 78300, training_loss: 3.68724e-02
I0210 06:01:18.875010 22509476222784 run_lib.py:146] step: 78300, eval_loss: 3.65823e-02
I0210 06:01:37.420856 22509476222784 run_lib.py:133] step: 78350, training_loss: 3.92726e-02
I0210 06:01:56.198751 22509476222784 run_lib.py:133] step: 78400, training_loss: 4.14796e-02
I0210 06:01:56.363758 22509476222784 run_lib.py:146] step: 78400, eval_loss: 5.47627e-02
I0210 06:02:14.996925 22509476222784 run_lib.py:133] step: 78450, training_loss: 4.03451e-02
I0210 06:02:33.619523 22509476222784 run_lib.py:133] step: 78500, training_loss: 4.28338e-02
I0210 06:02:33.784878 22509476222784 run_lib.py:146] step: 78500, eval_loss: 3.67503e-02
I0210 06:02:52.621688 22509476222784 run_lib.py:133] step: 78550, training_loss: 4.17181e-02
I0210 06:03:11.173724 22509476222784 run_lib.py:133] step: 78600, training_loss: 3.90218e-02
I0210 06:03:11.338808 22509476222784 run_lib.py:146] step: 78600, eval_loss: 5.03058e-02
I0210 06:03:30.024012 22509476222784 run_lib.py:133] step: 78650, training_loss: 4.56344e-02
I0210 06:03:48.589995 22509476222784 run_lib.py:133] step: 78700, training_loss: 4.17349e-02
I0210 06:03:48.753893 22509476222784 run_lib.py:146] step: 78700, eval_loss: 5.27485e-02
I0210 06:04:07.332652 22509476222784 run_lib.py:133] step: 78750, training_loss: 3.46704e-02
I0210 06:04:26.162485 22509476222784 run_lib.py:133] step: 78800, training_loss: 5.00778e-02
I0210 06:04:26.327681 22509476222784 run_lib.py:146] step: 78800, eval_loss: 3.45088e-02
I0210 06:04:44.888251 22509476222784 run_lib.py:133] step: 78850, training_loss: 3.94475e-02
I0210 06:05:03.426716 22509476222784 run_lib.py:133] step: 78900, training_loss: 3.33498e-02
I0210 06:05:03.595583 22509476222784 run_lib.py:146] step: 78900, eval_loss: 4.27705e-02
I0210 06:05:22.106778 22509476222784 run_lib.py:133] step: 78950, training_loss: 5.14360e-02
I0210 06:05:40.836992 22509476222784 run_lib.py:133] step: 79000, training_loss: 4.37854e-02
I0210 06:05:40.999625 22509476222784 run_lib.py:146] step: 79000, eval_loss: 3.83823e-02
I0210 06:05:59.586679 22509476222784 run_lib.py:133] step: 79050, training_loss: 4.14409e-02
I0210 06:06:18.278941 22509476222784 run_lib.py:133] step: 79100, training_loss: 4.05664e-02
I0210 06:06:18.448904 22509476222784 run_lib.py:146] step: 79100, eval_loss: 3.46876e-02
I0210 06:06:37.015616 22509476222784 run_lib.py:133] step: 79150, training_loss: 5.16257e-02
I0210 06:06:55.543392 22509476222784 run_lib.py:133] step: 79200, training_loss: 4.54441e-02
I0210 06:06:55.711155 22509476222784 run_lib.py:146] step: 79200, eval_loss: 5.23936e-02
I0210 06:07:14.451295 22509476222784 run_lib.py:133] step: 79250, training_loss: 4.14046e-02
I0210 06:07:33.261887 22509476222784 run_lib.py:133] step: 79300, training_loss: 3.58168e-02
I0210 06:07:33.426780 22509476222784 run_lib.py:146] step: 79300, eval_loss: 4.75420e-02
I0210 06:07:52.014097 22509476222784 run_lib.py:133] step: 79350, training_loss: 3.87096e-02
I0210 06:08:10.598387 22509476222784 run_lib.py:133] step: 79400, training_loss: 4.58084e-02
I0210 06:08:10.763712 22509476222784 run_lib.py:146] step: 79400, eval_loss: 4.61843e-02
I0210 06:08:29.518256 22509476222784 run_lib.py:133] step: 79450, training_loss: 4.15779e-02
I0210 06:08:48.118429 22509476222784 run_lib.py:133] step: 79500, training_loss: 4.02572e-02
I0210 06:08:48.280849 22509476222784 run_lib.py:146] step: 79500, eval_loss: 3.74638e-02
I0210 06:09:07.037384 22509476222784 run_lib.py:133] step: 79550, training_loss: 4.58988e-02
I0210 06:09:25.644022 22509476222784 run_lib.py:133] step: 79600, training_loss: 4.83628e-02
I0210 06:09:25.816764 22509476222784 run_lib.py:146] step: 79600, eval_loss: 4.47950e-02
I0210 06:09:44.635202 22509476222784 run_lib.py:133] step: 79650, training_loss: 4.48819e-02
I0210 06:10:03.195837 22509476222784 run_lib.py:133] step: 79700, training_loss: 3.98990e-02
I0210 06:10:03.411947 22509476222784 run_lib.py:146] step: 79700, eval_loss: 5.34734e-02
I0210 06:10:22.000385 22509476222784 run_lib.py:133] step: 79750, training_loss: 4.40058e-02
I0210 06:10:40.791375 22509476222784 run_lib.py:133] step: 79800, training_loss: 4.04379e-02
I0210 06:10:40.957144 22509476222784 run_lib.py:146] step: 79800, eval_loss: 4.39779e-02
I0210 06:10:59.545245 22509476222784 run_lib.py:133] step: 79850, training_loss: 4.63127e-02
I0210 06:11:18.321582 22509476222784 run_lib.py:133] step: 79900, training_loss: 5.34441e-02
I0210 06:11:18.485710 22509476222784 run_lib.py:146] step: 79900, eval_loss: 5.11579e-02
I0210 06:11:37.024543 22509476222784 run_lib.py:133] step: 79950, training_loss: 5.07123e-02
I0210 06:11:55.623066 22509476222784 run_lib.py:133] step: 80000, training_loss: 4.92994e-02
I0210 06:11:56.360752 22509476222784 run_lib.py:146] step: 80000, eval_loss: 3.54658e-02
I0210 06:12:17.990189 22509476222784 run_lib.py:133] step: 80050, training_loss: 4.35124e-02
I0210 06:12:36.532079 22509476222784 run_lib.py:133] step: 80100, training_loss: 5.39896e-02
I0210 06:12:36.698553 22509476222784 run_lib.py:146] step: 80100, eval_loss: 3.76226e-02
I0210 06:12:55.369711 22509476222784 run_lib.py:133] step: 80150, training_loss: 3.16543e-02
I0210 06:13:13.907888 22509476222784 run_lib.py:133] step: 80200, training_loss: 4.22842e-02
I0210 06:13:14.076006 22509476222784 run_lib.py:146] step: 80200, eval_loss: 4.76818e-02
I0210 06:13:32.679535 22509476222784 run_lib.py:133] step: 80250, training_loss: 4.73824e-02
I0210 06:13:51.527848 22509476222784 run_lib.py:133] step: 80300, training_loss: 5.17921e-02
I0210 06:13:51.693759 22509476222784 run_lib.py:146] step: 80300, eval_loss: 4.61078e-02
I0210 06:14:10.260480 22509476222784 run_lib.py:133] step: 80350, training_loss: 3.81011e-02
I0210 06:14:28.936311 22509476222784 run_lib.py:133] step: 80400, training_loss: 4.84826e-02
I0210 06:14:29.099425 22509476222784 run_lib.py:146] step: 80400, eval_loss: 5.25515e-02
I0210 06:14:47.652781 22509476222784 run_lib.py:133] step: 80450, training_loss: 3.75576e-02
I0210 06:15:06.229879 22509476222784 run_lib.py:133] step: 80500, training_loss: 4.38971e-02
I0210 06:15:06.395433 22509476222784 run_lib.py:146] step: 80500, eval_loss: 5.25281e-02
I0210 06:15:25.031249 22509476222784 run_lib.py:133] step: 80550, training_loss: 4.37448e-02
I0210 06:15:43.779130 22509476222784 run_lib.py:133] step: 80600, training_loss: 5.24607e-02
I0210 06:15:43.944724 22509476222784 run_lib.py:146] step: 80600, eval_loss: 4.49139e-02
I0210 06:16:02.495543 22509476222784 run_lib.py:133] step: 80650, training_loss: 4.02941e-02
I0210 06:16:21.055559 22509476222784 run_lib.py:133] step: 80700, training_loss: 4.44650e-02
I0210 06:16:21.222957 22509476222784 run_lib.py:146] step: 80700, eval_loss: 4.28025e-02
I0210 06:16:39.969821 22509476222784 run_lib.py:133] step: 80750, training_loss: 5.32684e-02
I0210 06:16:58.676916 22509476222784 run_lib.py:133] step: 80800, training_loss: 3.94094e-02
I0210 06:16:58.843870 22509476222784 run_lib.py:146] step: 80800, eval_loss: 4.29734e-02
I0210 06:17:17.526001 22509476222784 run_lib.py:133] step: 80850, training_loss: 4.46106e-02
I0210 06:17:36.114515 22509476222784 run_lib.py:133] step: 80900, training_loss: 4.53829e-02
I0210 06:17:36.278703 22509476222784 run_lib.py:146] step: 80900, eval_loss: 5.18841e-02
I0210 06:17:54.825607 22509476222784 run_lib.py:133] step: 80950, training_loss: 6.69855e-02
I0210 06:18:13.394269 22509476222784 run_lib.py:133] step: 81000, training_loss: 3.68353e-02
I0210 06:18:13.561764 22509476222784 run_lib.py:146] step: 81000, eval_loss: 3.75568e-02
I0210 06:18:32.380782 22509476222784 run_lib.py:133] step: 81050, training_loss: 4.18017e-02
I0210 06:18:51.114254 22509476222784 run_lib.py:133] step: 81100, training_loss: 4.39597e-02
I0210 06:18:51.281739 22509476222784 run_lib.py:146] step: 81100, eval_loss: 3.14073e-02
I0210 06:19:09.869621 22509476222784 run_lib.py:133] step: 81150, training_loss: 4.20395e-02
I0210 06:19:28.435902 22509476222784 run_lib.py:133] step: 81200, training_loss: 4.29179e-02
I0210 06:19:28.601126 22509476222784 run_lib.py:146] step: 81200, eval_loss: 4.05152e-02
I0210 06:19:47.325897 22509476222784 run_lib.py:133] step: 81250, training_loss: 3.95773e-02
I0210 06:20:05.963406 22509476222784 run_lib.py:133] step: 81300, training_loss: 4.88338e-02
I0210 06:20:06.153144 22509476222784 run_lib.py:146] step: 81300, eval_loss: 3.59434e-02
I0210 06:20:24.887024 22509476222784 run_lib.py:133] step: 81350, training_loss: 5.36185e-02
I0210 06:20:43.443268 22509476222784 run_lib.py:133] step: 81400, training_loss: 4.76224e-02
I0210 06:20:43.605672 22509476222784 run_lib.py:146] step: 81400, eval_loss: 4.12030e-02
I0210 06:21:02.347529 22509476222784 run_lib.py:133] step: 81450, training_loss: 3.75347e-02
I0210 06:21:20.898426 22509476222784 run_lib.py:133] step: 81500, training_loss: 4.08536e-02
I0210 06:21:21.061715 22509476222784 run_lib.py:146] step: 81500, eval_loss: 3.61459e-02
I0210 06:21:39.822491 22509476222784 run_lib.py:133] step: 81550, training_loss: 4.15176e-02
I0210 06:21:58.471770 22509476222784 run_lib.py:133] step: 81600, training_loss: 4.56062e-02
I0210 06:21:58.678697 22509476222784 run_lib.py:146] step: 81600, eval_loss: 3.32148e-02
I0210 06:22:17.247054 22509476222784 run_lib.py:133] step: 81650, training_loss: 3.75583e-02
I0210 06:22:36.000992 22509476222784 run_lib.py:133] step: 81700, training_loss: 4.38323e-02
I0210 06:22:36.177658 22509476222784 run_lib.py:146] step: 81700, eval_loss: 3.90510e-02
I0210 06:22:54.688290 22509476222784 run_lib.py:133] step: 81750, training_loss: 6.41159e-02
I0210 06:23:13.216966 22509476222784 run_lib.py:133] step: 81800, training_loss: 5.97510e-02
I0210 06:23:13.385941 22509476222784 run_lib.py:146] step: 81800, eval_loss: 3.87691e-02
I0210 06:23:32.110050 22509476222784 run_lib.py:133] step: 81850, training_loss: 4.07579e-02
I0210 06:23:50.698572 22509476222784 run_lib.py:133] step: 81900, training_loss: 3.85729e-02
I0210 06:23:50.859907 22509476222784 run_lib.py:146] step: 81900, eval_loss: 4.44995e-02
I0210 06:24:09.617160 22509476222784 run_lib.py:133] step: 81950, training_loss: 4.14642e-02
I0210 06:24:28.173883 22509476222784 run_lib.py:133] step: 82000, training_loss: 3.27276e-02
I0210 06:24:28.338599 22509476222784 run_lib.py:146] step: 82000, eval_loss: 5.88562e-02
I0210 06:24:46.915883 22509476222784 run_lib.py:133] step: 82050, training_loss: 4.89531e-02
I0210 06:25:05.749663 22509476222784 run_lib.py:133] step: 82100, training_loss: 5.15293e-02
I0210 06:25:05.932672 22509476222784 run_lib.py:146] step: 82100, eval_loss: 5.37517e-02
I0210 06:25:24.490745 22509476222784 run_lib.py:133] step: 82150, training_loss: 3.11279e-02
I0210 06:25:43.081879 22509476222784 run_lib.py:133] step: 82200, training_loss: 4.87573e-02
I0210 06:25:43.246503 22509476222784 run_lib.py:146] step: 82200, eval_loss: 3.91387e-02
I0210 06:26:01.838881 22509476222784 run_lib.py:133] step: 82250, training_loss: 5.56469e-02
I0210 06:26:20.545502 22509476222784 run_lib.py:133] step: 82300, training_loss: 4.22793e-02
I0210 06:26:20.708714 22509476222784 run_lib.py:146] step: 82300, eval_loss: 3.90940e-02
I0210 06:26:39.297880 22509476222784 run_lib.py:133] step: 82350, training_loss: 3.40348e-02
I0210 06:26:58.051804 22509476222784 run_lib.py:133] step: 82400, training_loss: 5.14921e-02
I0210 06:26:58.218938 22509476222784 run_lib.py:146] step: 82400, eval_loss: 4.47587e-02
I0210 06:27:16.814535 22509476222784 run_lib.py:133] step: 82450, training_loss: 4.08284e-02
I0210 06:27:35.398578 22509476222784 run_lib.py:133] step: 82500, training_loss: 4.32009e-02
I0210 06:27:35.566656 22509476222784 run_lib.py:146] step: 82500, eval_loss: 4.34572e-02
I0210 06:27:54.268103 22509476222784 run_lib.py:133] step: 82550, training_loss: 4.90818e-02
I0210 06:28:12.985470 22509476222784 run_lib.py:133] step: 82600, training_loss: 3.97757e-02
I0210 06:28:13.159601 22509476222784 run_lib.py:146] step: 82600, eval_loss: 4.60397e-02
I0210 06:28:31.721700 22509476222784 run_lib.py:133] step: 82650, training_loss: 4.54609e-02
I0210 06:28:50.279405 22509476222784 run_lib.py:133] step: 82700, training_loss: 5.26749e-02
I0210 06:28:50.443669 22509476222784 run_lib.py:146] step: 82700, eval_loss: 5.16971e-02
I0210 06:29:09.199325 22509476222784 run_lib.py:133] step: 82750, training_loss: 5.23861e-02
I0210 06:29:27.739808 22509476222784 run_lib.py:133] step: 82800, training_loss: 3.94631e-02
I0210 06:29:27.908887 22509476222784 run_lib.py:146] step: 82800, eval_loss: 3.40096e-02
I0210 06:29:46.660979 22509476222784 run_lib.py:133] step: 82850, training_loss: 4.63262e-02
I0210 06:30:05.301269 22509476222784 run_lib.py:133] step: 82900, training_loss: 4.64817e-02
I0210 06:30:05.480978 22509476222784 run_lib.py:146] step: 82900, eval_loss: 4.53720e-02
I0210 06:30:24.295040 22509476222784 run_lib.py:133] step: 82950, training_loss: 4.78290e-02
I0210 06:30:42.898279 22509476222784 run_lib.py:133] step: 83000, training_loss: 4.99011e-02
I0210 06:30:43.063979 22509476222784 run_lib.py:146] step: 83000, eval_loss: 4.36968e-02
I0210 06:31:01.628888 22509476222784 run_lib.py:133] step: 83050, training_loss: 4.76808e-02
I0210 06:31:20.382974 22509476222784 run_lib.py:133] step: 83100, training_loss: 4.82080e-02
I0210 06:31:20.557626 22509476222784 run_lib.py:146] step: 83100, eval_loss: 4.76845e-02
I0210 06:31:39.115405 22509476222784 run_lib.py:133] step: 83150, training_loss: 4.99154e-02
I0210 06:31:57.926130 22509476222784 run_lib.py:133] step: 83200, training_loss: 4.08784e-02
I0210 06:31:58.091477 22509476222784 run_lib.py:146] step: 83200, eval_loss: 4.00085e-02
I0210 06:32:16.673088 22509476222784 run_lib.py:133] step: 83250, training_loss: 3.61584e-02
I0210 06:32:35.242618 22509476222784 run_lib.py:133] step: 83300, training_loss: 4.79708e-02
I0210 06:32:35.404563 22509476222784 run_lib.py:146] step: 83300, eval_loss: 4.93417e-02
I0210 06:32:54.150104 22509476222784 run_lib.py:133] step: 83350, training_loss: 4.75983e-02
I0210 06:33:12.768650 22509476222784 run_lib.py:133] step: 83400, training_loss: 3.44421e-02
I0210 06:33:12.946624 22509476222784 run_lib.py:146] step: 83400, eval_loss: 3.50494e-02
I0210 06:33:31.578092 22509476222784 run_lib.py:133] step: 83450, training_loss: 3.92200e-02
I0210 06:33:50.353224 22509476222784 run_lib.py:133] step: 83500, training_loss: 3.11202e-02
I0210 06:33:50.523947 22509476222784 run_lib.py:146] step: 83500, eval_loss: 5.65740e-02
I0210 06:34:09.077163 22509476222784 run_lib.py:133] step: 83550, training_loss: 4.60748e-02
I0210 06:34:27.675479 22509476222784 run_lib.py:133] step: 83600, training_loss: 4.80713e-02
I0210 06:34:28.001604 22509476222784 run_lib.py:146] step: 83600, eval_loss: 4.11606e-02
I0210 06:34:46.596297 22509476222784 run_lib.py:133] step: 83650, training_loss: 3.54721e-02
I0210 06:35:05.243620 22509476222784 run_lib.py:133] step: 83700, training_loss: 4.51283e-02
I0210 06:35:05.416218 22509476222784 run_lib.py:146] step: 83700, eval_loss: 5.15065e-02
I0210 06:35:24.043751 22509476222784 run_lib.py:133] step: 83750, training_loss: 4.42044e-02
I0210 06:35:42.590090 22509476222784 run_lib.py:133] step: 83800, training_loss: 5.26977e-02
I0210 06:35:42.750426 22509476222784 run_lib.py:146] step: 83800, eval_loss: 4.26196e-02
I0210 06:36:01.507295 22509476222784 run_lib.py:133] step: 83850, training_loss: 4.74093e-02
I0210 06:36:20.137262 22509476222784 run_lib.py:133] step: 83900, training_loss: 3.33612e-02
I0210 06:36:20.326923 22509476222784 run_lib.py:146] step: 83900, eval_loss: 4.28057e-02
I0210 06:36:38.950897 22509476222784 run_lib.py:133] step: 83950, training_loss: 4.46008e-02
I0210 06:36:57.502445 22509476222784 run_lib.py:133] step: 84000, training_loss: 3.91533e-02
I0210 06:36:57.697848 22509476222784 run_lib.py:146] step: 84000, eval_loss: 4.22803e-02
I0210 06:37:16.448487 22509476222784 run_lib.py:133] step: 84050, training_loss: 4.12593e-02
I0210 06:37:35.048900 22509476222784 run_lib.py:133] step: 84100, training_loss: 5.19297e-02
I0210 06:37:35.219674 22509476222784 run_lib.py:146] step: 84100, eval_loss: 4.68266e-02
I0210 06:37:53.735066 22509476222784 run_lib.py:133] step: 84150, training_loss: 3.45489e-02
I0210 06:38:12.361920 22509476222784 run_lib.py:133] step: 84200, training_loss: 4.26563e-02
I0210 06:38:12.527987 22509476222784 run_lib.py:146] step: 84200, eval_loss: 4.54030e-02
I0210 06:38:31.354767 22509476222784 run_lib.py:133] step: 84250, training_loss: 4.40935e-02
I0210 06:38:49.960194 22509476222784 run_lib.py:133] step: 84300, training_loss: 5.21277e-02
I0210 06:38:50.122701 22509476222784 run_lib.py:146] step: 84300, eval_loss: 4.04990e-02
I0210 06:39:08.876744 22509476222784 run_lib.py:133] step: 84350, training_loss: 5.79850e-02
I0210 06:39:27.444123 22509476222784 run_lib.py:133] step: 84400, training_loss: 4.74944e-02
I0210 06:39:27.625937 22509476222784 run_lib.py:146] step: 84400, eval_loss: 6.51734e-02
I0210 06:39:46.461414 22509476222784 run_lib.py:133] step: 84450, training_loss: 4.63098e-02
I0210 06:40:05.077958 22509476222784 run_lib.py:133] step: 84500, training_loss: 5.13707e-02
I0210 06:40:05.255580 22509476222784 run_lib.py:146] step: 84500, eval_loss: 3.31709e-02
I0210 06:40:23.819778 22509476222784 run_lib.py:133] step: 84550, training_loss: 5.45982e-02
I0210 06:40:42.520149 22509476222784 run_lib.py:133] step: 84600, training_loss: 4.87766e-02
I0210 06:40:42.688757 22509476222784 run_lib.py:146] step: 84600, eval_loss: 3.58955e-02
I0210 06:41:01.278893 22509476222784 run_lib.py:133] step: 84650, training_loss: 3.22486e-02
I0210 06:41:20.090745 22509476222784 run_lib.py:133] step: 84700, training_loss: 4.93339e-02
I0210 06:41:20.254864 22509476222784 run_lib.py:146] step: 84700, eval_loss: 4.50386e-02
I0210 06:41:38.906787 22509476222784 run_lib.py:133] step: 84750, training_loss: 4.13802e-02
I0210 06:41:57.438992 22509476222784 run_lib.py:133] step: 84800, training_loss: 4.63500e-02
I0210 06:41:57.602713 22509476222784 run_lib.py:146] step: 84800, eval_loss: 4.33106e-02
I0210 06:42:16.132181 22509476222784 run_lib.py:133] step: 84850, training_loss: 4.96541e-02
I0210 06:42:34.846573 22509476222784 run_lib.py:133] step: 84900, training_loss: 4.11704e-02
I0210 06:42:35.016478 22509476222784 run_lib.py:146] step: 84900, eval_loss: 4.57536e-02
I0210 06:42:53.600726 22509476222784 run_lib.py:133] step: 84950, training_loss: 5.00620e-02
I0210 06:43:12.188086 22509476222784 run_lib.py:133] step: 85000, training_loss: 2.99816e-02
I0210 06:43:12.352709 22509476222784 run_lib.py:146] step: 85000, eval_loss: 5.84892e-02
I0210 06:43:31.082969 22509476222784 run_lib.py:133] step: 85050, training_loss: 5.13541e-02
I0210 06:43:49.627785 22509476222784 run_lib.py:133] step: 85100, training_loss: 6.39971e-02
I0210 06:43:49.792730 22509476222784 run_lib.py:146] step: 85100, eval_loss: 4.21917e-02
I0210 06:44:08.438860 22509476222784 run_lib.py:133] step: 85150, training_loss: 5.27550e-02
I0210 06:44:26.976757 22509476222784 run_lib.py:133] step: 85200, training_loss: 4.00659e-02
I0210 06:44:27.145218 22509476222784 run_lib.py:146] step: 85200, eval_loss: 4.35703e-02
I0210 06:44:45.745470 22509476222784 run_lib.py:133] step: 85250, training_loss: 4.32107e-02
I0210 06:45:04.245921 22509476222784 run_lib.py:133] step: 85300, training_loss: 4.42079e-02
I0210 06:45:04.409852 22509476222784 run_lib.py:146] step: 85300, eval_loss: 4.37768e-02
I0210 06:45:23.172444 22509476222784 run_lib.py:133] step: 85350, training_loss: 4.11270e-02
I0210 06:45:41.806893 22509476222784 run_lib.py:133] step: 85400, training_loss: 5.04303e-02
I0210 06:45:41.972879 22509476222784 run_lib.py:146] step: 85400, eval_loss: 4.84753e-02
I0210 06:46:00.543116 22509476222784 run_lib.py:133] step: 85450, training_loss: 4.16610e-02
I0210 06:46:19.165275 22509476222784 run_lib.py:133] step: 85500, training_loss: 4.67745e-02
I0210 06:46:19.331159 22509476222784 run_lib.py:146] step: 85500, eval_loss: 2.96580e-02
I0210 06:46:38.091772 22509476222784 run_lib.py:133] step: 85550, training_loss: 4.80667e-02
I0210 06:46:56.660741 22509476222784 run_lib.py:133] step: 85600, training_loss: 4.16529e-02
I0210 06:46:56.828861 22509476222784 run_lib.py:146] step: 85600, eval_loss: 4.21224e-02
I0210 06:47:15.550243 22509476222784 run_lib.py:133] step: 85650, training_loss: 5.18978e-02
I0210 06:47:34.144964 22509476222784 run_lib.py:133] step: 85700, training_loss: 4.74741e-02
I0210 06:47:34.305906 22509476222784 run_lib.py:146] step: 85700, eval_loss: 4.99394e-02
I0210 06:47:53.088468 22509476222784 run_lib.py:133] step: 85750, training_loss: 3.94078e-02
I0210 06:48:11.753606 22509476222784 run_lib.py:133] step: 85800, training_loss: 3.74688e-02
I0210 06:48:11.923764 22509476222784 run_lib.py:146] step: 85800, eval_loss: 4.34838e-02
I0210 06:48:30.713031 22509476222784 run_lib.py:133] step: 85850, training_loss: 4.37018e-02
I0210 06:48:49.295159 22509476222784 run_lib.py:133] step: 85900, training_loss: 4.24482e-02
I0210 06:48:49.461813 22509476222784 run_lib.py:146] step: 85900, eval_loss: 3.67851e-02
I0210 06:49:07.986160 22509476222784 run_lib.py:133] step: 85950, training_loss: 4.07932e-02
I0210 06:49:26.702156 22509476222784 run_lib.py:133] step: 86000, training_loss: 4.86428e-02
I0210 06:49:26.877808 22509476222784 run_lib.py:146] step: 86000, eval_loss: 4.18031e-02
I0210 06:49:45.443103 22509476222784 run_lib.py:133] step: 86050, training_loss: 5.19588e-02
I0210 06:50:04.047080 22509476222784 run_lib.py:133] step: 86100, training_loss: 4.73764e-02
I0210 06:50:04.229867 22509476222784 run_lib.py:146] step: 86100, eval_loss: 4.64816e-02
I0210 06:50:23.010444 22509476222784 run_lib.py:133] step: 86150, training_loss: 4.74095e-02
I0210 06:50:41.725991 22509476222784 run_lib.py:133] step: 86200, training_loss: 3.92502e-02
I0210 06:50:41.887778 22509476222784 run_lib.py:146] step: 86200, eval_loss: 3.08553e-02
I0210 06:51:00.445855 22509476222784 run_lib.py:133] step: 86250, training_loss: 4.59979e-02
I0210 06:51:19.147487 22509476222784 run_lib.py:133] step: 86300, training_loss: 3.64328e-02
I0210 06:51:19.322497 22509476222784 run_lib.py:146] step: 86300, eval_loss: 5.00752e-02
I0210 06:51:37.909105 22509476222784 run_lib.py:133] step: 86350, training_loss: 4.17079e-02
I0210 06:51:56.679143 22509476222784 run_lib.py:133] step: 86400, training_loss: 5.64673e-02
I0210 06:51:56.844842 22509476222784 run_lib.py:146] step: 86400, eval_loss: 3.42750e-02
I0210 06:52:15.375343 22509476222784 run_lib.py:133] step: 86450, training_loss: 4.28955e-02
I0210 06:52:33.924716 22509476222784 run_lib.py:133] step: 86500, training_loss: 5.13033e-02
I0210 06:52:34.088759 22509476222784 run_lib.py:146] step: 86500, eval_loss: 4.57143e-02
I0210 06:52:52.636347 22509476222784 run_lib.py:133] step: 86550, training_loss: 5.39274e-02
I0210 06:53:11.459703 22509476222784 run_lib.py:133] step: 86600, training_loss: 5.41521e-02
I0210 06:53:11.623835 22509476222784 run_lib.py:146] step: 86600, eval_loss: 4.98764e-02
I0210 06:53:30.241469 22509476222784 run_lib.py:133] step: 86650, training_loss: 4.23160e-02
I0210 06:53:48.897723 22509476222784 run_lib.py:133] step: 86700, training_loss: 5.55959e-02
I0210 06:53:49.059843 22509476222784 run_lib.py:146] step: 86700, eval_loss: 5.44553e-02
I0210 06:54:07.583857 22509476222784 run_lib.py:133] step: 86750, training_loss: 4.70967e-02
I0210 06:54:26.113801 22509476222784 run_lib.py:133] step: 86800, training_loss: 4.46124e-02
I0210 06:54:26.279737 22509476222784 run_lib.py:146] step: 86800, eval_loss: 3.68425e-02
I0210 06:54:45.039750 22509476222784 run_lib.py:133] step: 86850, training_loss: 4.74783e-02
I0210 06:55:03.796272 22509476222784 run_lib.py:133] step: 86900, training_loss: 5.25474e-02
I0210 06:55:03.968891 22509476222784 run_lib.py:146] step: 86900, eval_loss: 4.14522e-02
I0210 06:55:22.566222 22509476222784 run_lib.py:133] step: 86950, training_loss: 3.59307e-02
I0210 06:55:41.102073 22509476222784 run_lib.py:133] step: 87000, training_loss: 3.13384e-02
I0210 06:55:41.267712 22509476222784 run_lib.py:146] step: 87000, eval_loss: 4.74231e-02
I0210 06:56:00.008256 22509476222784 run_lib.py:133] step: 87050, training_loss: 4.53438e-02
I0210 06:56:18.611901 22509476222784 run_lib.py:133] step: 87100, training_loss: 4.01829e-02
I0210 06:56:18.783005 22509476222784 run_lib.py:146] step: 87100, eval_loss: 4.03006e-02
I0210 06:56:37.615111 22509476222784 run_lib.py:133] step: 87150, training_loss: 4.46182e-02
I0210 06:56:56.175687 22509476222784 run_lib.py:133] step: 87200, training_loss: 4.12663e-02
I0210 06:56:56.337259 22509476222784 run_lib.py:146] step: 87200, eval_loss: 4.71531e-02
I0210 06:57:15.081484 22509476222784 run_lib.py:133] step: 87250, training_loss: 4.48245e-02
I0210 06:57:33.700093 22509476222784 run_lib.py:133] step: 87300, training_loss: 4.33926e-02
I0210 06:57:33.867058 22509476222784 run_lib.py:146] step: 87300, eval_loss: 4.76886e-02
I0210 06:57:52.442855 22509476222784 run_lib.py:133] step: 87350, training_loss: 3.66155e-02
I0210 06:58:11.288118 22509476222784 run_lib.py:133] step: 87400, training_loss: 3.50948e-02
I0210 06:58:11.453982 22509476222784 run_lib.py:146] step: 87400, eval_loss: 4.22721e-02
I0210 06:58:30.030564 22509476222784 run_lib.py:133] step: 87450, training_loss: 5.18672e-02
I0210 06:58:48.770838 22509476222784 run_lib.py:133] step: 87500, training_loss: 4.22715e-02
I0210 06:58:48.934649 22509476222784 run_lib.py:146] step: 87500, eval_loss: 3.64433e-02
I0210 06:59:07.475667 22509476222784 run_lib.py:133] step: 87550, training_loss: 5.58482e-02
I0210 06:59:25.968316 22509476222784 run_lib.py:133] step: 87600, training_loss: 4.50090e-02
I0210 06:59:26.137937 22509476222784 run_lib.py:146] step: 87600, eval_loss: 4.25199e-02
I0210 06:59:44.974036 22509476222784 run_lib.py:133] step: 87650, training_loss: 5.59844e-02
I0210 07:00:03.525053 22509476222784 run_lib.py:133] step: 87700, training_loss: 4.45876e-02
I0210 07:00:03.699827 22509476222784 run_lib.py:146] step: 87700, eval_loss: 4.94291e-02
I0210 07:00:22.210785 22509476222784 run_lib.py:133] step: 87750, training_loss: 5.15196e-02
I0210 07:00:40.904114 22509476222784 run_lib.py:133] step: 87800, training_loss: 5.30198e-02
I0210 07:00:41.256862 22509476222784 run_lib.py:146] step: 87800, eval_loss: 4.61368e-02
I0210 07:00:59.822193 22509476222784 run_lib.py:133] step: 87850, training_loss: 4.43499e-02
I0210 07:01:18.482589 22509476222784 run_lib.py:133] step: 87900, training_loss: 4.82657e-02
I0210 07:01:18.654980 22509476222784 run_lib.py:146] step: 87900, eval_loss: 3.85081e-02
I0210 07:01:37.341897 22509476222784 run_lib.py:133] step: 87950, training_loss: 4.07380e-02
I0210 07:01:55.903412 22509476222784 run_lib.py:133] step: 88000, training_loss: 5.14994e-02
I0210 07:01:56.089541 22509476222784 run_lib.py:146] step: 88000, eval_loss: 4.59240e-02
I0210 07:02:14.652127 22509476222784 run_lib.py:133] step: 88050, training_loss: 4.83613e-02
I0210 07:02:33.200433 22509476222784 run_lib.py:133] step: 88100, training_loss: 3.84098e-02
I0210 07:02:33.389845 22509476222784 run_lib.py:146] step: 88100, eval_loss: 3.27646e-02
I0210 07:02:52.175506 22509476222784 run_lib.py:133] step: 88150, training_loss: 5.09355e-02
I0210 07:03:10.841412 22509476222784 run_lib.py:133] step: 88200, training_loss: 5.95788e-02
I0210 07:03:11.006643 22509476222784 run_lib.py:146] step: 88200, eval_loss: 4.32990e-02
I0210 07:03:29.586078 22509476222784 run_lib.py:133] step: 88250, training_loss: 4.34634e-02
I0210 07:03:48.137415 22509476222784 run_lib.py:133] step: 88300, training_loss: 4.18894e-02
I0210 07:03:48.307018 22509476222784 run_lib.py:146] step: 88300, eval_loss: 4.37716e-02
I0210 07:04:06.999212 22509476222784 run_lib.py:133] step: 88350, training_loss: 4.25142e-02
I0210 07:04:25.646451 22509476222784 run_lib.py:133] step: 88400, training_loss: 3.92707e-02
I0210 07:04:26.116647 22509476222784 run_lib.py:146] step: 88400, eval_loss: 5.40204e-02
I0210 07:04:44.915346 22509476222784 run_lib.py:133] step: 88450, training_loss: 4.50627e-02
I0210 07:05:03.509464 22509476222784 run_lib.py:133] step: 88500, training_loss: 4.55143e-02
I0210 07:05:03.672678 22509476222784 run_lib.py:146] step: 88500, eval_loss: 3.72961e-02
I0210 07:05:22.401175 22509476222784 run_lib.py:133] step: 88550, training_loss: 4.21189e-02
I0210 07:05:40.950577 22509476222784 run_lib.py:133] step: 88600, training_loss: 3.42687e-02
I0210 07:05:41.119701 22509476222784 run_lib.py:146] step: 88600, eval_loss: 4.11286e-02
I0210 07:05:59.847585 22509476222784 run_lib.py:133] step: 88650, training_loss: 4.12718e-02
I0210 07:06:18.458549 22509476222784 run_lib.py:133] step: 88700, training_loss: 4.00094e-02
I0210 07:06:18.627602 22509476222784 run_lib.py:146] step: 88700, eval_loss: 4.55275e-02
I0210 07:06:37.201403 22509476222784 run_lib.py:133] step: 88750, training_loss: 4.77407e-02
I0210 07:06:55.962084 22509476222784 run_lib.py:133] step: 88800, training_loss: 4.73944e-02
I0210 07:06:56.127655 22509476222784 run_lib.py:146] step: 88800, eval_loss: 4.58550e-02
I0210 07:07:14.678751 22509476222784 run_lib.py:133] step: 88850, training_loss: 3.35230e-02
I0210 07:07:33.213779 22509476222784 run_lib.py:133] step: 88900, training_loss: 5.68347e-02
I0210 07:07:33.391242 22509476222784 run_lib.py:146] step: 88900, eval_loss: 5.12545e-02
I0210 07:07:52.176264 22509476222784 run_lib.py:133] step: 88950, training_loss: 4.88674e-02
I0210 07:08:10.752353 22509476222784 run_lib.py:133] step: 89000, training_loss: 5.17322e-02
I0210 07:08:10.912346 22509476222784 run_lib.py:146] step: 89000, eval_loss: 4.53859e-02
I0210 07:08:29.716071 22509476222784 run_lib.py:133] step: 89050, training_loss: 3.00717e-02
I0210 07:08:48.276715 22509476222784 run_lib.py:133] step: 89100, training_loss: 4.30233e-02
I0210 07:08:48.439674 22509476222784 run_lib.py:146] step: 89100, eval_loss: 4.68224e-02
I0210 07:09:07.002671 22509476222784 run_lib.py:133] step: 89150, training_loss: 5.15891e-02
I0210 07:09:25.958169 22509476222784 run_lib.py:133] step: 89200, training_loss: 4.07193e-02
I0210 07:09:26.127665 22509476222784 run_lib.py:146] step: 89200, eval_loss: 5.18194e-02
I0210 07:09:44.702024 22509476222784 run_lib.py:133] step: 89250, training_loss: 5.55914e-02
I0210 07:10:03.286397 22509476222784 run_lib.py:133] step: 89300, training_loss: 3.84020e-02
I0210 07:10:03.452776 22509476222784 run_lib.py:146] step: 89300, eval_loss: 5.12380e-02
I0210 07:10:22.040789 22509476222784 run_lib.py:133] step: 89350, training_loss: 5.35956e-02
I0210 07:10:40.793569 22509476222784 run_lib.py:133] step: 89400, training_loss: 4.16527e-02
I0210 07:10:40.957076 22509476222784 run_lib.py:146] step: 89400, eval_loss: 4.23725e-02
I0210 07:10:59.604505 22509476222784 run_lib.py:133] step: 89450, training_loss: 5.24743e-02
I0210 07:11:18.348205 22509476222784 run_lib.py:133] step: 89500, training_loss: 4.47081e-02
I0210 07:11:18.512777 22509476222784 run_lib.py:146] step: 89500, eval_loss: 3.09655e-02
I0210 07:11:37.047637 22509476222784 run_lib.py:133] step: 89550, training_loss: 3.90099e-02
I0210 07:11:55.565985 22509476222784 run_lib.py:133] step: 89600, training_loss: 4.47047e-02
I0210 07:11:55.729615 22509476222784 run_lib.py:146] step: 89600, eval_loss: 3.48700e-02
I0210 07:12:14.402747 22509476222784 run_lib.py:133] step: 89650, training_loss: 4.42113e-02
I0210 07:12:33.140448 22509476222784 run_lib.py:133] step: 89700, training_loss: 4.29227e-02
I0210 07:12:33.314666 22509476222784 run_lib.py:146] step: 89700, eval_loss: 3.65988e-02
I0210 07:12:51.846129 22509476222784 run_lib.py:133] step: 89750, training_loss: 3.20555e-02
I0210 07:13:10.404091 22509476222784 run_lib.py:133] step: 89800, training_loss: 3.78839e-02
I0210 07:13:10.589707 22509476222784 run_lib.py:146] step: 89800, eval_loss: 5.46450e-02
I0210 07:13:29.300488 22509476222784 run_lib.py:133] step: 89850, training_loss: 3.53352e-02
I0210 07:13:47.830955 22509476222784 run_lib.py:133] step: 89900, training_loss: 4.99140e-02
I0210 07:13:48.001935 22509476222784 run_lib.py:146] step: 89900, eval_loss: 3.37659e-02
I0210 07:14:06.786532 22509476222784 run_lib.py:133] step: 89950, training_loss: 5.11025e-02
I0210 07:14:25.373677 22509476222784 run_lib.py:133] step: 90000, training_loss: 6.19711e-02
I0210 07:14:26.112783 22509476222784 run_lib.py:146] step: 90000, eval_loss: 3.88146e-02
I0210 07:14:47.588255 22509476222784 run_lib.py:133] step: 90050, training_loss: 3.15589e-02
I0210 07:15:06.186053 22509476222784 run_lib.py:133] step: 90100, training_loss: 3.92661e-02
I0210 07:15:06.348635 22509476222784 run_lib.py:146] step: 90100, eval_loss: 3.53675e-02
I0210 07:15:25.026749 22509476222784 run_lib.py:133] step: 90150, training_loss: 3.99005e-02
I0210 07:15:43.640203 22509476222784 run_lib.py:133] step: 90200, training_loss: 4.50589e-02
I0210 07:15:43.807861 22509476222784 run_lib.py:146] step: 90200, eval_loss: 4.20143e-02
I0210 07:16:02.355246 22509476222784 run_lib.py:133] step: 90250, training_loss: 4.10126e-02
I0210 07:16:20.912497 22509476222784 run_lib.py:133] step: 90300, training_loss: 4.38455e-02
I0210 07:16:21.076786 22509476222784 run_lib.py:146] step: 90300, eval_loss: 4.23085e-02
I0210 07:16:39.867532 22509476222784 run_lib.py:133] step: 90350, training_loss: 4.07157e-02
I0210 07:16:58.505151 22509476222784 run_lib.py:133] step: 90400, training_loss: 4.39369e-02
I0210 07:16:58.680954 22509476222784 run_lib.py:146] step: 90400, eval_loss: 4.48541e-02
I0210 07:17:17.280992 22509476222784 run_lib.py:133] step: 90450, training_loss: 4.58946e-02
I0210 07:17:36.009067 22509476222784 run_lib.py:133] step: 90500, training_loss: 3.58330e-02
I0210 07:17:36.172000 22509476222784 run_lib.py:146] step: 90500, eval_loss: 6.00021e-02
I0210 07:17:54.960423 22509476222784 run_lib.py:133] step: 90550, training_loss: 3.92295e-02
I0210 07:18:13.592199 22509476222784 run_lib.py:133] step: 90600, training_loss: 5.19023e-02
I0210 07:18:13.755642 22509476222784 run_lib.py:146] step: 90600, eval_loss: 5.11973e-02
I0210 07:18:32.462777 22509476222784 run_lib.py:133] step: 90650, training_loss: 4.82052e-02
I0210 07:18:51.082278 22509476222784 run_lib.py:133] step: 90700, training_loss: 4.58840e-02
I0210 07:18:51.263668 22509476222784 run_lib.py:146] step: 90700, eval_loss: 4.04883e-02
I0210 07:19:10.009545 22509476222784 run_lib.py:133] step: 90750, training_loss: 4.22002e-02
I0210 07:19:28.591256 22509476222784 run_lib.py:133] step: 90800, training_loss: 6.85271e-02
I0210 07:19:28.756942 22509476222784 run_lib.py:146] step: 90800, eval_loss: 4.30098e-02
I0210 07:19:47.270213 22509476222784 run_lib.py:133] step: 90850, training_loss: 4.78323e-02
I0210 07:20:05.938665 22509476222784 run_lib.py:133] step: 90900, training_loss: 6.50338e-02
I0210 07:20:06.104634 22509476222784 run_lib.py:146] step: 90900, eval_loss: 3.39703e-02
I0210 07:20:24.701934 22509476222784 run_lib.py:133] step: 90950, training_loss: 4.73263e-02
I0210 07:20:43.471726 22509476222784 run_lib.py:133] step: 91000, training_loss: 4.71355e-02
I0210 07:20:43.641712 22509476222784 run_lib.py:146] step: 91000, eval_loss: 4.63297e-02
I0210 07:21:02.201360 22509476222784 run_lib.py:133] step: 91050, training_loss: 3.84937e-02
I0210 07:21:20.770256 22509476222784 run_lib.py:133] step: 91100, training_loss: 4.18224e-02
I0210 07:21:20.935665 22509476222784 run_lib.py:146] step: 91100, eval_loss: 4.09246e-02
I0210 07:21:39.612101 22509476222784 run_lib.py:133] step: 91150, training_loss: 4.56603e-02
I0210 07:21:58.211125 22509476222784 run_lib.py:133] step: 91200, training_loss: 4.74984e-02
I0210 07:21:58.391595 22509476222784 run_lib.py:146] step: 91200, eval_loss: 4.32695e-02
I0210 07:22:16.973564 22509476222784 run_lib.py:133] step: 91250, training_loss: 4.70125e-02
I0210 07:22:35.777603 22509476222784 run_lib.py:133] step: 91300, training_loss: 4.41068e-02
I0210 07:22:35.965641 22509476222784 run_lib.py:146] step: 91300, eval_loss: 3.42408e-02
I0210 07:22:54.527338 22509476222784 run_lib.py:133] step: 91350, training_loss: 4.64216e-02
I0210 07:23:13.103264 22509476222784 run_lib.py:133] step: 91400, training_loss: 5.62489e-02
I0210 07:23:13.422615 22509476222784 run_lib.py:146] step: 91400, eval_loss: 5.26397e-02
I0210 07:23:31.970155 22509476222784 run_lib.py:133] step: 91450, training_loss: 6.15320e-02
I0210 07:23:50.506980 22509476222784 run_lib.py:133] step: 91500, training_loss: 3.90788e-02
I0210 07:23:50.673922 22509476222784 run_lib.py:146] step: 91500, eval_loss: 3.94982e-02
I0210 07:24:09.332461 22509476222784 run_lib.py:133] step: 91550, training_loss: 3.94447e-02
I0210 07:24:27.930887 22509476222784 run_lib.py:133] step: 91600, training_loss: 3.40512e-02
I0210 07:24:28.097745 22509476222784 run_lib.py:146] step: 91600, eval_loss: 4.02396e-02
I0210 07:24:46.824928 22509476222784 run_lib.py:133] step: 91650, training_loss: 5.16829e-02
I0210 07:25:05.516024 22509476222784 run_lib.py:133] step: 91700, training_loss: 4.46702e-02
I0210 07:25:05.687846 22509476222784 run_lib.py:146] step: 91700, eval_loss: 4.49169e-02
I0210 07:25:24.314257 22509476222784 run_lib.py:133] step: 91750, training_loss: 4.24794e-02
I0210 07:25:42.942674 22509476222784 run_lib.py:133] step: 91800, training_loss: 4.41646e-02
I0210 07:25:43.107313 22509476222784 run_lib.py:146] step: 91800, eval_loss: 4.26193e-02
I0210 07:26:01.829974 22509476222784 run_lib.py:133] step: 91850, training_loss: 3.56864e-02
I0210 07:26:20.441723 22509476222784 run_lib.py:133] step: 91900, training_loss: 5.76809e-02
I0210 07:26:20.606706 22509476222784 run_lib.py:146] step: 91900, eval_loss: 4.74728e-02
I0210 07:26:39.154412 22509476222784 run_lib.py:133] step: 91950, training_loss: 4.18214e-02
I0210 07:26:57.764245 22509476222784 run_lib.py:133] step: 92000, training_loss: 3.34720e-02
I0210 07:26:57.934998 22509476222784 run_lib.py:146] step: 92000, eval_loss: 4.05001e-02
I0210 07:27:16.685485 22509476222784 run_lib.py:133] step: 92050, training_loss: 5.11917e-02
I0210 07:27:35.276586 22509476222784 run_lib.py:133] step: 92100, training_loss: 6.21920e-02
I0210 07:27:35.443878 22509476222784 run_lib.py:146] step: 92100, eval_loss: 5.06270e-02
I0210 07:27:54.160323 22509476222784 run_lib.py:133] step: 92150, training_loss: 3.80027e-02
I0210 07:28:12.704260 22509476222784 run_lib.py:133] step: 92200, training_loss: 4.42961e-02
I0210 07:28:12.872583 22509476222784 run_lib.py:146] step: 92200, eval_loss: 4.76268e-02
I0210 07:28:31.591117 22509476222784 run_lib.py:133] step: 92250, training_loss: 4.05805e-02
I0210 07:28:50.188353 22509476222784 run_lib.py:133] step: 92300, training_loss: 4.63603e-02
I0210 07:28:50.353492 22509476222784 run_lib.py:146] step: 92300, eval_loss: 5.09742e-02
I0210 07:29:08.974541 22509476222784 run_lib.py:133] step: 92350, training_loss: 5.13988e-02
I0210 07:29:27.703405 22509476222784 run_lib.py:133] step: 92400, training_loss: 3.69768e-02
I0210 07:29:27.863389 22509476222784 run_lib.py:146] step: 92400, eval_loss: 4.87605e-02
I0210 07:29:46.414915 22509476222784 run_lib.py:133] step: 92450, training_loss: 5.60855e-02
I0210 07:30:05.094364 22509476222784 run_lib.py:133] step: 92500, training_loss: 4.37272e-02
I0210 07:30:05.269919 22509476222784 run_lib.py:146] step: 92500, eval_loss: 3.61700e-02
I0210 07:30:23.882768 22509476222784 run_lib.py:133] step: 92550, training_loss: 4.47528e-02
I0210 07:30:42.440253 22509476222784 run_lib.py:133] step: 92600, training_loss: 3.98543e-02
I0210 07:30:42.611775 22509476222784 run_lib.py:146] step: 92600, eval_loss: 4.43769e-02
I0210 07:31:01.320179 22509476222784 run_lib.py:133] step: 92650, training_loss: 3.88733e-02
I0210 07:31:19.852713 22509476222784 run_lib.py:133] step: 92700, training_loss: 3.86709e-02
I0210 07:31:20.016624 22509476222784 run_lib.py:146] step: 92700, eval_loss: 4.46664e-02
I0210 07:31:38.621691 22509476222784 run_lib.py:133] step: 92750, training_loss: 4.22909e-02
I0210 07:31:57.217376 22509476222784 run_lib.py:133] step: 92800, training_loss: 4.56387e-02
I0210 07:31:57.404754 22509476222784 run_lib.py:146] step: 92800, eval_loss: 3.96404e-02
I0210 07:32:16.187673 22509476222784 run_lib.py:133] step: 92850, training_loss: 3.60740e-02
I0210 07:32:34.745045 22509476222784 run_lib.py:133] step: 92900, training_loss: 3.87271e-02
I0210 07:32:34.911643 22509476222784 run_lib.py:146] step: 92900, eval_loss: 3.41320e-02
I0210 07:32:53.567629 22509476222784 run_lib.py:133] step: 92950, training_loss: 4.05155e-02
I0210 07:33:12.155558 22509476222784 run_lib.py:133] step: 93000, training_loss: 4.37848e-02
I0210 07:33:12.337191 22509476222784 run_lib.py:146] step: 93000, eval_loss: 4.83269e-02
I0210 07:33:30.931444 22509476222784 run_lib.py:133] step: 93050, training_loss: 6.23728e-02
I0210 07:33:49.531060 22509476222784 run_lib.py:133] step: 93100, training_loss: 4.08919e-02
I0210 07:33:49.696695 22509476222784 run_lib.py:146] step: 93100, eval_loss: 4.41474e-02
I0210 07:34:08.453434 22509476222784 run_lib.py:133] step: 93150, training_loss: 4.34173e-02
I0210 07:34:27.114542 22509476222784 run_lib.py:133] step: 93200, training_loss: 4.37139e-02
I0210 07:34:27.279656 22509476222784 run_lib.py:146] step: 93200, eval_loss: 3.30867e-02
I0210 07:34:45.839514 22509476222784 run_lib.py:133] step: 93250, training_loss: 4.30786e-02
I0210 07:35:04.426588 22509476222784 run_lib.py:133] step: 93300, training_loss: 3.51187e-02
I0210 07:35:04.597155 22509476222784 run_lib.py:146] step: 93300, eval_loss: 3.94070e-02
I0210 07:35:23.426412 22509476222784 run_lib.py:133] step: 93350, training_loss: 3.81836e-02
I0210 07:35:41.965804 22509476222784 run_lib.py:133] step: 93400, training_loss: 6.29110e-02
I0210 07:35:42.131736 22509476222784 run_lib.py:146] step: 93400, eval_loss: 5.73081e-02
I0210 07:36:00.836080 22509476222784 run_lib.py:133] step: 93450, training_loss: 3.63415e-02
I0210 07:36:19.431335 22509476222784 run_lib.py:133] step: 93500, training_loss: 4.05238e-02
I0210 07:36:19.598990 22509476222784 run_lib.py:146] step: 93500, eval_loss: 4.25946e-02
I0210 07:36:38.330136 22509476222784 run_lib.py:133] step: 93550, training_loss: 5.11635e-02
I0210 07:36:56.988518 22509476222784 run_lib.py:133] step: 93600, training_loss: 3.61778e-02
I0210 07:36:57.154884 22509476222784 run_lib.py:146] step: 93600, eval_loss: 4.41162e-02
I0210 07:37:15.917392 22509476222784 run_lib.py:133] step: 93650, training_loss: 4.96958e-02
I0210 07:37:34.534281 22509476222784 run_lib.py:133] step: 93700, training_loss: 4.70515e-02
I0210 07:37:34.699775 22509476222784 run_lib.py:146] step: 93700, eval_loss: 3.89276e-02
I0210 07:37:53.273160 22509476222784 run_lib.py:133] step: 93750, training_loss: 3.29092e-02
I0210 07:38:11.999595 22509476222784 run_lib.py:133] step: 93800, training_loss: 4.70650e-02
I0210 07:38:12.163057 22509476222784 run_lib.py:146] step: 93800, eval_loss: 4.77440e-02
I0210 07:38:30.774391 22509476222784 run_lib.py:133] step: 93850, training_loss: 4.03438e-02
I0210 07:38:49.316848 22509476222784 run_lib.py:133] step: 93900, training_loss: 4.28587e-02
I0210 07:38:49.479659 22509476222784 run_lib.py:146] step: 93900, eval_loss: 3.51969e-02
I0210 07:39:08.228069 22509476222784 run_lib.py:133] step: 93950, training_loss: 3.61275e-02
I0210 07:39:26.881942 22509476222784 run_lib.py:133] step: 94000, training_loss: 5.21125e-02
I0210 07:39:27.048885 22509476222784 run_lib.py:146] step: 94000, eval_loss: 5.65131e-02
I0210 07:39:45.586390 22509476222784 run_lib.py:133] step: 94050, training_loss: 4.61907e-02
I0210 07:40:04.193018 22509476222784 run_lib.py:133] step: 94100, training_loss: 2.82953e-02
I0210 07:40:04.367837 22509476222784 run_lib.py:146] step: 94100, eval_loss: 4.89740e-02
I0210 07:40:22.892714 22509476222784 run_lib.py:133] step: 94150, training_loss: 4.86133e-02
I0210 07:40:41.639981 22509476222784 run_lib.py:133] step: 94200, training_loss: 4.57160e-02
I0210 07:40:41.874783 22509476222784 run_lib.py:146] step: 94200, eval_loss: 3.31591e-02
I0210 07:41:00.414735 22509476222784 run_lib.py:133] step: 94250, training_loss: 4.46986e-02
I0210 07:41:19.015466 22509476222784 run_lib.py:133] step: 94300, training_loss: 4.30608e-02
I0210 07:41:19.188764 22509476222784 run_lib.py:146] step: 94300, eval_loss: 4.07423e-02
I0210 07:41:37.793558 22509476222784 run_lib.py:133] step: 94350, training_loss: 4.39991e-02
I0210 07:41:56.541774 22509476222784 run_lib.py:133] step: 94400, training_loss: 4.18904e-02
I0210 07:41:56.706901 22509476222784 run_lib.py:146] step: 94400, eval_loss: 4.86951e-02
I0210 07:42:15.270432 22509476222784 run_lib.py:133] step: 94450, training_loss: 4.42170e-02
I0210 07:42:33.940030 22509476222784 run_lib.py:133] step: 94500, training_loss: 3.63668e-02
I0210 07:42:34.112047 22509476222784 run_lib.py:146] step: 94500, eval_loss: 4.42616e-02
I0210 07:42:52.683747 22509476222784 run_lib.py:133] step: 94550, training_loss: 4.64541e-02
I0210 07:43:11.299937 22509476222784 run_lib.py:133] step: 94600, training_loss: 5.31559e-02
I0210 07:43:11.468781 22509476222784 run_lib.py:146] step: 94600, eval_loss: 4.97765e-02
I0210 07:43:30.275928 22509476222784 run_lib.py:133] step: 94650, training_loss: 4.25188e-02
I0210 07:43:48.984349 22509476222784 run_lib.py:133] step: 94700, training_loss: 5.15580e-02
I0210 07:43:49.149693 22509476222784 run_lib.py:146] step: 94700, eval_loss: 3.94330e-02
I0210 07:44:07.710944 22509476222784 run_lib.py:133] step: 94750, training_loss: 4.22162e-02
I0210 07:44:26.267939 22509476222784 run_lib.py:133] step: 94800, training_loss: 5.14423e-02
I0210 07:44:26.432543 22509476222784 run_lib.py:146] step: 94800, eval_loss: 4.63253e-02
I0210 07:44:45.161393 22509476222784 run_lib.py:133] step: 94850, training_loss: 5.23488e-02
I0210 07:45:03.772968 22509476222784 run_lib.py:133] step: 94900, training_loss: 4.59971e-02
I0210 07:45:03.941747 22509476222784 run_lib.py:146] step: 94900, eval_loss: 3.93470e-02
I0210 07:45:22.696345 22509476222784 run_lib.py:133] step: 94950, training_loss: 4.94961e-02
I0210 07:45:41.221659 22509476222784 run_lib.py:133] step: 95000, training_loss: 4.77422e-02
I0210 07:45:41.388250 22509476222784 run_lib.py:146] step: 95000, eval_loss: 4.32325e-02
I0210 07:46:00.102174 22509476222784 run_lib.py:133] step: 95050, training_loss: 3.09218e-02
I0210 07:46:18.783812 22509476222784 run_lib.py:133] step: 95100, training_loss: 4.20236e-02
I0210 07:46:18.968858 22509476222784 run_lib.py:146] step: 95100, eval_loss: 3.84561e-02
I0210 07:46:37.498962 22509476222784 run_lib.py:133] step: 95150, training_loss: 5.12231e-02
I0210 07:46:56.247003 22509476222784 run_lib.py:133] step: 95200, training_loss: 5.36904e-02
I0210 07:46:56.451849 22509476222784 run_lib.py:146] step: 95200, eval_loss: 4.21020e-02
I0210 07:47:15.019283 22509476222784 run_lib.py:133] step: 95250, training_loss: 3.12778e-02
I0210 07:47:33.711338 22509476222784 run_lib.py:133] step: 95300, training_loss: 3.50085e-02
I0210 07:47:33.873769 22509476222784 run_lib.py:146] step: 95300, eval_loss: 4.03847e-02
I0210 07:47:52.490464 22509476222784 run_lib.py:133] step: 95350, training_loss: 4.19815e-02
I0210 07:48:11.041137 22509476222784 run_lib.py:133] step: 95400, training_loss: 4.84063e-02
I0210 07:48:11.206548 22509476222784 run_lib.py:146] step: 95400, eval_loss: 3.35866e-02
I0210 07:48:30.009564 22509476222784 run_lib.py:133] step: 95450, training_loss: 4.54473e-02
I0210 07:48:48.593548 22509476222784 run_lib.py:133] step: 95500, training_loss: 3.92447e-02
I0210 07:48:48.759058 22509476222784 run_lib.py:146] step: 95500, eval_loss: 5.26335e-02
I0210 07:49:07.302144 22509476222784 run_lib.py:133] step: 95550, training_loss: 4.82649e-02
I0210 07:49:26.035824 22509476222784 run_lib.py:133] step: 95600, training_loss: 4.69001e-02
I0210 07:49:26.203618 22509476222784 run_lib.py:146] step: 95600, eval_loss: 4.47917e-02
I0210 07:49:44.781966 22509476222784 run_lib.py:133] step: 95650, training_loss: 4.64850e-02
I0210 07:50:03.399286 22509476222784 run_lib.py:133] step: 95700, training_loss: 4.84673e-02
I0210 07:50:03.571013 22509476222784 run_lib.py:146] step: 95700, eval_loss: 4.39423e-02
I0210 07:50:22.233837 22509476222784 run_lib.py:133] step: 95750, training_loss: 5.67126e-02
I0210 07:50:40.807044 22509476222784 run_lib.py:133] step: 95800, training_loss: 5.68007e-02
I0210 07:50:40.970431 22509476222784 run_lib.py:146] step: 95800, eval_loss: 4.33980e-02
I0210 07:50:59.496625 22509476222784 run_lib.py:133] step: 95850, training_loss: 5.74003e-02
I0210 07:51:18.081902 22509476222784 run_lib.py:133] step: 95900, training_loss: 5.27197e-02
I0210 07:51:18.262676 22509476222784 run_lib.py:146] step: 95900, eval_loss: 4.86463e-02
I0210 07:51:37.026525 22509476222784 run_lib.py:133] step: 95950, training_loss: 4.49073e-02
I0210 07:51:55.698942 22509476222784 run_lib.py:133] step: 96000, training_loss: 4.29411e-02
I0210 07:51:55.863955 22509476222784 run_lib.py:146] step: 96000, eval_loss: 4.92099e-02
I0210 07:52:14.428258 22509476222784 run_lib.py:133] step: 96050, training_loss: 5.04739e-02
I0210 07:52:32.993695 22509476222784 run_lib.py:133] step: 96100, training_loss: 4.11157e-02
I0210 07:52:33.161486 22509476222784 run_lib.py:146] step: 96100, eval_loss: 5.05559e-02
I0210 07:52:51.880944 22509476222784 run_lib.py:133] step: 96150, training_loss: 3.85254e-02
I0210 07:53:10.431741 22509476222784 run_lib.py:133] step: 96200, training_loss: 3.62212e-02
I0210 07:53:10.596443 22509476222784 run_lib.py:146] step: 96200, eval_loss: 4.75164e-02
I0210 07:53:29.393927 22509476222784 run_lib.py:133] step: 96250, training_loss: 4.41512e-02
I0210 07:53:47.963230 22509476222784 run_lib.py:133] step: 96300, training_loss: 4.58587e-02
I0210 07:53:48.133819 22509476222784 run_lib.py:146] step: 96300, eval_loss: 5.62299e-02
I0210 07:54:06.837070 22509476222784 run_lib.py:133] step: 96350, training_loss: 4.56124e-02
I0210 07:54:25.388015 22509476222784 run_lib.py:133] step: 96400, training_loss: 4.89784e-02
I0210 07:54:25.569814 22509476222784 run_lib.py:146] step: 96400, eval_loss: 4.36925e-02
I0210 07:54:44.353580 22509476222784 run_lib.py:133] step: 96450, training_loss: 4.56737e-02
I0210 07:55:02.967895 22509476222784 run_lib.py:133] step: 96500, training_loss: 4.15334e-02
I0210 07:55:03.133013 22509476222784 run_lib.py:146] step: 96500, eval_loss: 3.58861e-02
I0210 07:55:21.685282 22509476222784 run_lib.py:133] step: 96550, training_loss: 6.75042e-02
I0210 07:55:40.360839 22509476222784 run_lib.py:133] step: 96600, training_loss: 4.86934e-02
I0210 07:55:40.525842 22509476222784 run_lib.py:146] step: 96600, eval_loss: 3.89481e-02
I0210 07:55:59.083501 22509476222784 run_lib.py:133] step: 96650, training_loss: 5.49550e-02
I0210 07:56:17.683978 22509476222784 run_lib.py:133] step: 96700, training_loss: 4.26688e-02
I0210 07:56:17.882920 22509476222784 run_lib.py:146] step: 96700, eval_loss: 4.07049e-02
I0210 07:56:36.678135 22509476222784 run_lib.py:133] step: 96750, training_loss: 4.67357e-02
I0210 07:56:55.248658 22509476222784 run_lib.py:133] step: 96800, training_loss: 5.31868e-02
I0210 07:56:55.413626 22509476222784 run_lib.py:146] step: 96800, eval_loss: 4.74325e-02
I0210 07:57:14.103871 22509476222784 run_lib.py:133] step: 96850, training_loss: 4.45470e-02
I0210 07:57:32.658108 22509476222784 run_lib.py:133] step: 96900, training_loss: 4.20715e-02
I0210 07:57:32.826892 22509476222784 run_lib.py:146] step: 96900, eval_loss: 4.88501e-02
I0210 07:57:51.417854 22509476222784 run_lib.py:133] step: 96950, training_loss: 4.86751e-02
I0210 07:58:10.187362 22509476222784 run_lib.py:133] step: 97000, training_loss: 4.09591e-02
I0210 07:58:10.352899 22509476222784 run_lib.py:146] step: 97000, eval_loss: 4.67071e-02
I0210 07:58:28.923504 22509476222784 run_lib.py:133] step: 97050, training_loss: 4.45302e-02
I0210 07:58:47.459400 22509476222784 run_lib.py:133] step: 97100, training_loss: 4.65043e-02
I0210 07:58:47.627591 22509476222784 run_lib.py:146] step: 97100, eval_loss: 4.28536e-02
I0210 07:59:06.147166 22509476222784 run_lib.py:133] step: 97150, training_loss: 4.60936e-02
I0210 07:59:24.883691 22509476222784 run_lib.py:133] step: 97200, training_loss: 4.93678e-02
I0210 07:59:25.051033 22509476222784 run_lib.py:146] step: 97200, eval_loss: 4.17903e-02
I0210 07:59:43.667582 22509476222784 run_lib.py:133] step: 97250, training_loss: 4.98818e-02
I0210 08:00:02.361918 22509476222784 run_lib.py:133] step: 97300, training_loss: 3.18422e-02
I0210 08:00:02.624866 22509476222784 run_lib.py:146] step: 97300, eval_loss: 4.61089e-02
I0210 08:00:21.167508 22509476222784 run_lib.py:133] step: 97350, training_loss: 4.05713e-02
I0210 08:00:39.744001 22509476222784 run_lib.py:133] step: 97400, training_loss: 4.49856e-02
I0210 08:00:39.919664 22509476222784 run_lib.py:146] step: 97400, eval_loss: 5.58739e-02
I0210 08:00:58.701624 22509476222784 run_lib.py:133] step: 97450, training_loss: 4.49139e-02
I0210 08:01:17.408789 22509476222784 run_lib.py:133] step: 97500, training_loss: 5.79734e-02
I0210 08:01:17.574230 22509476222784 run_lib.py:146] step: 97500, eval_loss: 4.56436e-02
I0210 08:01:36.174701 22509476222784 run_lib.py:133] step: 97550, training_loss: 6.10724e-02
I0210 08:01:54.738781 22509476222784 run_lib.py:133] step: 97600, training_loss: 3.97762e-02
I0210 08:01:54.896520 22509476222784 run_lib.py:146] step: 97600, eval_loss: 4.08891e-02
I0210 08:02:13.572848 22509476222784 run_lib.py:133] step: 97650, training_loss: 3.69135e-02
I0210 08:02:32.156508 22509476222784 run_lib.py:133] step: 97700, training_loss: 3.75536e-02
I0210 08:02:32.324760 22509476222784 run_lib.py:146] step: 97700, eval_loss: 5.25025e-02
I0210 08:02:51.056351 22509476222784 run_lib.py:133] step: 97750, training_loss: 3.94170e-02
I0210 08:03:09.669133 22509476222784 run_lib.py:133] step: 97800, training_loss: 5.48794e-02
I0210 08:03:09.835624 22509476222784 run_lib.py:146] step: 97800, eval_loss: 3.60844e-02
I0210 08:03:28.559518 22509476222784 run_lib.py:133] step: 97850, training_loss: 5.57762e-02
I0210 08:03:47.077493 22509476222784 run_lib.py:133] step: 97900, training_loss: 4.42712e-02
I0210 08:03:47.274641 22509476222784 run_lib.py:146] step: 97900, eval_loss: 3.40241e-02
I0210 08:04:05.843178 22509476222784 run_lib.py:133] step: 97950, training_loss: 4.43359e-02
I0210 08:04:24.619967 22509476222784 run_lib.py:133] step: 98000, training_loss: 3.88823e-02
I0210 08:04:24.785361 22509476222784 run_lib.py:146] step: 98000, eval_loss: 5.58263e-02
I0210 08:04:43.378848 22509476222784 run_lib.py:133] step: 98050, training_loss: 4.73579e-02
I0210 08:05:02.101406 22509476222784 run_lib.py:133] step: 98100, training_loss: 5.45373e-02
I0210 08:05:02.310760 22509476222784 run_lib.py:146] step: 98100, eval_loss: 4.09671e-02
I0210 08:05:20.868418 22509476222784 run_lib.py:133] step: 98150, training_loss: 4.54390e-02
I0210 08:05:39.417369 22509476222784 run_lib.py:133] step: 98200, training_loss: 3.62072e-02
I0210 08:05:39.608711 22509476222784 run_lib.py:146] step: 98200, eval_loss: 5.30949e-02
I0210 08:05:58.343599 22509476222784 run_lib.py:133] step: 98250, training_loss: 4.43088e-02
I0210 08:06:16.944993 22509476222784 run_lib.py:133] step: 98300, training_loss: 4.23094e-02
I0210 08:06:17.111732 22509476222784 run_lib.py:146] step: 98300, eval_loss: 4.64091e-02
I0210 08:06:35.670854 22509476222784 run_lib.py:133] step: 98350, training_loss: 4.20796e-02
I0210 08:06:54.423074 22509476222784 run_lib.py:133] step: 98400, training_loss: 4.48427e-02
I0210 08:06:54.587732 22509476222784 run_lib.py:146] step: 98400, eval_loss: 4.73586e-02
I0210 08:07:13.161747 22509476222784 run_lib.py:133] step: 98450, training_loss: 2.84049e-02
I0210 08:07:31.746551 22509476222784 run_lib.py:133] step: 98500, training_loss: 3.69562e-02
I0210 08:07:32.066062 22509476222784 run_lib.py:146] step: 98500, eval_loss: 3.12261e-02
I0210 08:07:50.664396 22509476222784 run_lib.py:133] step: 98550, training_loss: 3.84721e-02
I0210 08:08:09.288792 22509476222784 run_lib.py:133] step: 98600, training_loss: 4.82781e-02
I0210 08:08:09.457773 22509476222784 run_lib.py:146] step: 98600, eval_loss: 4.02719e-02
I0210 08:08:28.038740 22509476222784 run_lib.py:133] step: 98650, training_loss: 4.58592e-02
I0210 08:08:46.592910 22509476222784 run_lib.py:133] step: 98700, training_loss: 3.21059e-02
I0210 08:08:46.757465 22509476222784 run_lib.py:146] step: 98700, eval_loss: 4.80115e-02
I0210 08:09:05.515291 22509476222784 run_lib.py:133] step: 98750, training_loss: 4.03833e-02
I0210 08:09:24.216004 22509476222784 run_lib.py:133] step: 98800, training_loss: 3.92777e-02
I0210 08:09:24.395785 22509476222784 run_lib.py:146] step: 98800, eval_loss: 4.78628e-02
I0210 08:09:42.948739 22509476222784 run_lib.py:133] step: 98850, training_loss: 4.51292e-02
I0210 08:10:01.551342 22509476222784 run_lib.py:133] step: 98900, training_loss: 5.56232e-02
I0210 08:10:01.718001 22509476222784 run_lib.py:146] step: 98900, eval_loss: 3.90200e-02
I0210 08:10:20.486877 22509476222784 run_lib.py:133] step: 98950, training_loss: 3.94435e-02
I0210 08:10:39.151009 22509476222784 run_lib.py:133] step: 99000, training_loss: 4.94845e-02
I0210 08:10:39.337565 22509476222784 run_lib.py:146] step: 99000, eval_loss: 3.92777e-02
I0210 08:10:57.941207 22509476222784 run_lib.py:133] step: 99050, training_loss: 3.28212e-02
I0210 08:11:16.544277 22509476222784 run_lib.py:133] step: 99100, training_loss: 4.60513e-02
I0210 08:11:16.718880 22509476222784 run_lib.py:146] step: 99100, eval_loss: 3.97390e-02
I0210 08:11:35.502562 22509476222784 run_lib.py:133] step: 99150, training_loss: 3.03216e-02
I0210 08:11:54.067733 22509476222784 run_lib.py:133] step: 99200, training_loss: 4.80144e-02
I0210 08:11:54.278914 22509476222784 run_lib.py:146] step: 99200, eval_loss: 3.90107e-02
I0210 08:12:12.989800 22509476222784 run_lib.py:133] step: 99250, training_loss: 5.00734e-02
I0210 08:12:31.528258 22509476222784 run_lib.py:133] step: 99300, training_loss: 4.39470e-02
I0210 08:12:31.703637 22509476222784 run_lib.py:146] step: 99300, eval_loss: 4.37085e-02
I0210 08:12:50.509493 22509476222784 run_lib.py:133] step: 99350, training_loss: 3.59159e-02
I0210 08:13:09.131773 22509476222784 run_lib.py:133] step: 99400, training_loss: 3.74866e-02
I0210 08:13:09.298967 22509476222784 run_lib.py:146] step: 99400, eval_loss: 3.67875e-02
I0210 08:13:27.868663 22509476222784 run_lib.py:133] step: 99450, training_loss: 4.70609e-02
I0210 08:13:46.535224 22509476222784 run_lib.py:133] step: 99500, training_loss: 4.51940e-02
I0210 08:13:46.696608 22509476222784 run_lib.py:146] step: 99500, eval_loss: 4.25548e-02
I0210 08:14:05.246301 22509476222784 run_lib.py:133] step: 99550, training_loss: 5.05260e-02
I0210 08:14:24.076567 22509476222784 run_lib.py:133] step: 99600, training_loss: 3.72087e-02
I0210 08:14:24.247911 22509476222784 run_lib.py:146] step: 99600, eval_loss: 3.52520e-02
I0210 08:14:42.821660 22509476222784 run_lib.py:133] step: 99650, training_loss: 4.30289e-02
I0210 08:15:01.397610 22509476222784 run_lib.py:133] step: 99700, training_loss: 4.09498e-02
I0210 08:15:01.565977 22509476222784 run_lib.py:146] step: 99700, eval_loss: 4.31626e-02
I0210 08:15:20.286725 22509476222784 run_lib.py:133] step: 99750, training_loss: 4.60057e-02
I0210 08:15:38.873469 22509476222784 run_lib.py:133] step: 99800, training_loss: 4.64124e-02
I0210 08:15:39.049727 22509476222784 run_lib.py:146] step: 99800, eval_loss: 4.13639e-02
I0210 08:15:57.641487 22509476222784 run_lib.py:133] step: 99850, training_loss: 4.16785e-02
I0210 08:16:16.233878 22509476222784 run_lib.py:133] step: 99900, training_loss: 4.43843e-02
I0210 08:16:16.398960 22509476222784 run_lib.py:146] step: 99900, eval_loss: 5.53532e-02
I0210 08:16:35.199122 22509476222784 run_lib.py:133] step: 99950, training_loss: 3.67466e-02
I0210 08:16:53.792117 22509476222784 run_lib.py:133] step: 100000, training_loss: 2.85222e-02
I0210 08:16:54.542821 22509476222784 run_lib.py:146] step: 100000, eval_loss: 4.74356e-02
I0210 08:17:16.008270 22509476222784 run_lib.py:133] step: 100050, training_loss: 3.44665e-02
I0210 08:17:34.671256 22509476222784 run_lib.py:133] step: 100100, training_loss: 4.59744e-02
I0210 08:17:34.837005 22509476222784 run_lib.py:146] step: 100100, eval_loss: 4.41109e-02
I0210 08:17:53.648408 22509476222784 run_lib.py:133] step: 100150, training_loss: 4.72923e-02
I0210 08:18:12.250195 22509476222784 run_lib.py:133] step: 100200, training_loss: 3.87082e-02
I0210 08:18:12.416059 22509476222784 run_lib.py:146] step: 100200, eval_loss: 3.63369e-02
I0210 08:18:31.004762 22509476222784 run_lib.py:133] step: 100250, training_loss: 5.01423e-02
I0210 08:18:49.718676 22509476222784 run_lib.py:133] step: 100300, training_loss: 4.03520e-02
I0210 08:18:49.899621 22509476222784 run_lib.py:146] step: 100300, eval_loss: 3.86071e-02
I0210 08:19:08.531797 22509476222784 run_lib.py:133] step: 100350, training_loss: 4.19916e-02
I0210 08:19:27.113955 22509476222784 run_lib.py:133] step: 100400, training_loss: 6.63319e-02
I0210 08:19:27.277988 22509476222784 run_lib.py:146] step: 100400, eval_loss: 4.83642e-02
I0210 08:19:45.869356 22509476222784 run_lib.py:133] step: 100450, training_loss: 3.95435e-02
I0210 08:20:04.620330 22509476222784 run_lib.py:133] step: 100500, training_loss: 5.00212e-02
I0210 08:20:04.784727 22509476222784 run_lib.py:146] step: 100500, eval_loss: 4.25257e-02
I0210 08:20:23.332881 22509476222784 run_lib.py:133] step: 100550, training_loss: 4.53045e-02
I0210 08:20:42.053986 22509476222784 run_lib.py:133] step: 100600, training_loss: 4.34491e-02
I0210 08:20:42.248774 22509476222784 run_lib.py:146] step: 100600, eval_loss: 4.92832e-02
I0210 08:21:00.871120 22509476222784 run_lib.py:133] step: 100650, training_loss: 4.15962e-02
I0210 08:21:19.469924 22509476222784 run_lib.py:133] step: 100700, training_loss: 4.27568e-02
I0210 08:21:19.637613 22509476222784 run_lib.py:146] step: 100700, eval_loss: 4.61549e-02
I0210 08:21:38.369458 22509476222784 run_lib.py:133] step: 100750, training_loss: 3.70898e-02
I0210 08:21:57.068274 22509476222784 run_lib.py:133] step: 100800, training_loss: 5.50475e-02
I0210 08:21:57.232852 22509476222784 run_lib.py:146] step: 100800, eval_loss: 5.63056e-02
I0210 08:22:15.751326 22509476222784 run_lib.py:133] step: 100850, training_loss: 4.11607e-02
I0210 08:22:34.378131 22509476222784 run_lib.py:133] step: 100900, training_loss: 4.13007e-02
I0210 08:22:34.543339 22509476222784 run_lib.py:146] step: 100900, eval_loss: 5.07048e-02
I0210 08:22:53.330688 22509476222784 run_lib.py:133] step: 100950, training_loss: 4.58473e-02
I0210 08:23:11.897471 22509476222784 run_lib.py:133] step: 101000, training_loss: 3.62340e-02
I0210 08:23:12.065450 22509476222784 run_lib.py:146] step: 101000, eval_loss: 5.09284e-02
I0210 08:23:30.766933 22509476222784 run_lib.py:133] step: 101050, training_loss: 4.11303e-02
I0210 08:23:49.333416 22509476222784 run_lib.py:133] step: 101100, training_loss: 5.48485e-02
I0210 08:23:49.504843 22509476222784 run_lib.py:146] step: 101100, eval_loss: 5.83321e-02
I0210 08:24:08.347934 22509476222784 run_lib.py:133] step: 101150, training_loss: 5.05672e-02
I0210 08:24:26.963600 22509476222784 run_lib.py:133] step: 101200, training_loss: 3.20941e-02
I0210 08:24:27.131762 22509476222784 run_lib.py:146] step: 101200, eval_loss: 2.79308e-02
I0210 08:24:45.683705 22509476222784 run_lib.py:133] step: 101250, training_loss: 3.77511e-02
I0210 08:25:04.382192 22509476222784 run_lib.py:133] step: 101300, training_loss: 3.55745e-02
I0210 08:25:04.546622 22509476222784 run_lib.py:146] step: 101300, eval_loss: 4.15087e-02
I0210 08:25:23.125549 22509476222784 run_lib.py:133] step: 101350, training_loss: 3.70038e-02
I0210 08:25:41.928294 22509476222784 run_lib.py:133] step: 101400, training_loss: 4.01452e-02
I0210 08:25:42.119949 22509476222784 run_lib.py:146] step: 101400, eval_loss: 3.53707e-02
I0210 08:26:00.739133 22509476222784 run_lib.py:133] step: 101450, training_loss: 4.49825e-02
I0210 08:26:19.348224 22509476222784 run_lib.py:133] step: 101500, training_loss: 4.04121e-02
I0210 08:26:19.523745 22509476222784 run_lib.py:146] step: 101500, eval_loss: 3.53786e-02
I0210 08:26:38.105396 22509476222784 run_lib.py:133] step: 101550, training_loss: 5.63258e-02
I0210 08:26:56.822891 22509476222784 run_lib.py:133] step: 101600, training_loss: 5.15713e-02
I0210 08:26:57.008653 22509476222784 run_lib.py:146] step: 101600, eval_loss: 5.65787e-02
I0210 08:27:15.613923 22509476222784 run_lib.py:133] step: 101650, training_loss: 3.92070e-02
I0210 08:27:34.218574 22509476222784 run_lib.py:133] step: 101700, training_loss: 5.30231e-02
I0210 08:27:34.470515 22509476222784 run_lib.py:146] step: 101700, eval_loss: 5.29973e-02
I0210 08:27:53.214789 22509476222784 run_lib.py:133] step: 101750, training_loss: 4.15917e-02
I0210 08:28:11.733765 22509476222784 run_lib.py:133] step: 101800, training_loss: 4.29037e-02
I0210 08:28:11.899682 22509476222784 run_lib.py:146] step: 101800, eval_loss: 2.74923e-02
I0210 08:28:30.565369 22509476222784 run_lib.py:133] step: 101850, training_loss: 4.98268e-02
I0210 08:28:49.133203 22509476222784 run_lib.py:133] step: 101900, training_loss: 4.06135e-02
I0210 08:28:49.297621 22509476222784 run_lib.py:146] step: 101900, eval_loss: 4.40176e-02
I0210 08:29:07.940363 22509476222784 run_lib.py:133] step: 101950, training_loss: 4.41854e-02
I0210 08:29:26.524899 22509476222784 run_lib.py:133] step: 102000, training_loss: 3.87576e-02
I0210 08:29:26.689987 22509476222784 run_lib.py:146] step: 102000, eval_loss: 3.57772e-02
I0210 08:29:45.503570 22509476222784 run_lib.py:133] step: 102050, training_loss: 4.94412e-02
I0210 08:30:04.163608 22509476222784 run_lib.py:133] step: 102100, training_loss: 4.86968e-02
I0210 08:30:04.329018 22509476222784 run_lib.py:146] step: 102100, eval_loss: 5.07243e-02
I0210 08:30:22.897171 22509476222784 run_lib.py:133] step: 102150, training_loss: 4.05481e-02
I0210 08:30:41.513752 22509476222784 run_lib.py:133] step: 102200, training_loss: 3.76539e-02
I0210 08:30:41.731798 22509476222784 run_lib.py:146] step: 102200, eval_loss: 4.70129e-02
I0210 08:31:00.475246 22509476222784 run_lib.py:133] step: 102250, training_loss: 4.27881e-02
I0210 08:31:19.048224 22509476222784 run_lib.py:133] step: 102300, training_loss: 5.52657e-02
I0210 08:31:19.213443 22509476222784 run_lib.py:146] step: 102300, eval_loss: 5.79515e-02
I0210 08:31:37.914849 22509476222784 run_lib.py:133] step: 102350, training_loss: 3.63790e-02
I0210 08:31:56.439239 22509476222784 run_lib.py:133] step: 102400, training_loss: 4.50788e-02
I0210 08:31:56.601676 22509476222784 run_lib.py:146] step: 102400, eval_loss: 4.20593e-02
I0210 08:32:15.329672 22509476222784 run_lib.py:133] step: 102450, training_loss: 5.34320e-02
I0210 08:32:33.926737 22509476222784 run_lib.py:133] step: 102500, training_loss: 4.26746e-02
I0210 08:32:34.092820 22509476222784 run_lib.py:146] step: 102500, eval_loss: 4.87296e-02
I0210 08:32:52.826578 22509476222784 run_lib.py:133] step: 102550, training_loss: 3.99094e-02
I0210 08:33:11.386029 22509476222784 run_lib.py:133] step: 102600, training_loss: 5.27628e-02
I0210 08:33:11.556951 22509476222784 run_lib.py:146] step: 102600, eval_loss: 3.48218e-02
I0210 08:33:30.084027 22509476222784 run_lib.py:133] step: 102650, training_loss: 4.84570e-02
I0210 08:33:48.750352 22509476222784 run_lib.py:133] step: 102700, training_loss: 4.35021e-02
I0210 08:33:48.924733 22509476222784 run_lib.py:146] step: 102700, eval_loss: 4.75019e-02
I0210 08:34:07.595249 22509476222784 run_lib.py:133] step: 102750, training_loss: 3.38685e-02
I0210 08:34:26.164598 22509476222784 run_lib.py:133] step: 102800, training_loss: 4.55247e-02
I0210 08:34:26.389935 22509476222784 run_lib.py:146] step: 102800, eval_loss: 5.19497e-02
I0210 08:34:45.166334 22509476222784 run_lib.py:133] step: 102850, training_loss: 3.69441e-02
I0210 08:35:03.858639 22509476222784 run_lib.py:133] step: 102900, training_loss: 5.02063e-02
I0210 08:35:04.018703 22509476222784 run_lib.py:146] step: 102900, eval_loss: 4.95020e-02
I0210 08:35:22.567741 22509476222784 run_lib.py:133] step: 102950, training_loss: 4.73582e-02
I0210 08:35:41.116645 22509476222784 run_lib.py:133] step: 103000, training_loss: 3.74709e-02
I0210 08:35:41.291843 22509476222784 run_lib.py:146] step: 103000, eval_loss: 2.82379e-02
I0210 08:35:59.878619 22509476222784 run_lib.py:133] step: 103050, training_loss: 3.18295e-02
I0210 08:36:18.660106 22509476222784 run_lib.py:133] step: 103100, training_loss: 3.74377e-02
I0210 08:36:18.826915 22509476222784 run_lib.py:146] step: 103100, eval_loss: 3.40359e-02
I0210 08:36:37.342433 22509476222784 run_lib.py:133] step: 103150, training_loss: 4.53782e-02
I0210 08:36:55.924973 22509476222784 run_lib.py:133] step: 103200, training_loss: 4.40684e-02
I0210 08:36:56.089811 22509476222784 run_lib.py:146] step: 103200, eval_loss: 4.44848e-02
I0210 08:37:14.695477 22509476222784 run_lib.py:133] step: 103250, training_loss: 4.91729e-02
I0210 08:37:33.531550 22509476222784 run_lib.py:133] step: 103300, training_loss: 4.42830e-02
I0210 08:37:33.695884 22509476222784 run_lib.py:146] step: 103300, eval_loss: 4.71553e-02
I0210 08:37:52.369810 22509476222784 run_lib.py:133] step: 103350, training_loss: 4.08074e-02
I0210 08:38:10.977838 22509476222784 run_lib.py:133] step: 103400, training_loss: 4.24174e-02
I0210 08:38:11.138703 22509476222784 run_lib.py:146] step: 103400, eval_loss: 4.62200e-02
I0210 08:38:29.695801 22509476222784 run_lib.py:133] step: 103450, training_loss: 3.95258e-02
I0210 08:38:48.288107 22509476222784 run_lib.py:133] step: 103500, training_loss: 4.78844e-02
I0210 08:38:48.466005 22509476222784 run_lib.py:146] step: 103500, eval_loss: 3.97151e-02
I0210 08:39:07.275355 22509476222784 run_lib.py:133] step: 103550, training_loss: 4.35738e-02
I0210 08:39:25.969952 22509476222784 run_lib.py:133] step: 103600, training_loss: 3.79555e-02
I0210 08:39:26.175645 22509476222784 run_lib.py:146] step: 103600, eval_loss: 4.85904e-02
I0210 08:39:44.743348 22509476222784 run_lib.py:133] step: 103650, training_loss: 4.62305e-02
I0210 08:40:03.347532 22509476222784 run_lib.py:133] step: 103700, training_loss: 5.30910e-02
I0210 08:40:03.512788 22509476222784 run_lib.py:146] step: 103700, eval_loss: 4.32017e-02
I0210 08:40:22.205599 22509476222784 run_lib.py:133] step: 103750, training_loss: 4.96769e-02
I0210 08:40:40.861243 22509476222784 run_lib.py:133] step: 103800, training_loss: 4.73957e-02
I0210 08:40:41.059838 22509476222784 run_lib.py:146] step: 103800, eval_loss: 4.35798e-02
I0210 08:40:59.852251 22509476222784 run_lib.py:133] step: 103850, training_loss: 4.64091e-02
I0210 08:41:18.448526 22509476222784 run_lib.py:133] step: 103900, training_loss: 3.14712e-02
I0210 08:41:18.611706 22509476222784 run_lib.py:146] step: 103900, eval_loss: 4.41988e-02
I0210 08:41:37.320760 22509476222784 run_lib.py:133] step: 103950, training_loss: 4.63763e-02
I0210 08:41:55.844550 22509476222784 run_lib.py:133] step: 104000, training_loss: 3.97454e-02
I0210 08:41:56.013755 22509476222784 run_lib.py:146] step: 104000, eval_loss: 4.01188e-02
I0210 08:42:14.644371 22509476222784 run_lib.py:133] step: 104050, training_loss: 4.22338e-02
I0210 08:42:33.501245 22509476222784 run_lib.py:133] step: 104100, training_loss: 5.17148e-02
I0210 08:42:33.667679 22509476222784 run_lib.py:146] step: 104100, eval_loss: 6.22455e-02
I0210 08:42:52.237004 22509476222784 run_lib.py:133] step: 104150, training_loss: 4.69515e-02
I0210 08:43:10.982930 22509476222784 run_lib.py:133] step: 104200, training_loss: 3.82862e-02
I0210 08:43:11.147818 22509476222784 run_lib.py:146] step: 104200, eval_loss: 5.73821e-02
I0210 08:43:29.739931 22509476222784 run_lib.py:133] step: 104250, training_loss: 4.20617e-02
I0210 08:43:48.373205 22509476222784 run_lib.py:133] step: 104300, training_loss: 5.24730e-02
I0210 08:43:48.538823 22509476222784 run_lib.py:146] step: 104300, eval_loss: 3.40979e-02
I0210 08:44:07.380589 22509476222784 run_lib.py:133] step: 104350, training_loss: 3.45945e-02
I0210 08:44:25.934592 22509476222784 run_lib.py:133] step: 104400, training_loss: 3.46518e-02
I0210 08:44:26.097796 22509476222784 run_lib.py:146] step: 104400, eval_loss: 5.71658e-02
I0210 08:44:44.699949 22509476222784 run_lib.py:133] step: 104450, training_loss: 4.73773e-02
I0210 08:45:03.467161 22509476222784 run_lib.py:133] step: 104500, training_loss: 4.82000e-02
I0210 08:45:03.633922 22509476222784 run_lib.py:146] step: 104500, eval_loss: 4.53282e-02
I0210 08:45:22.215928 22509476222784 run_lib.py:133] step: 104550, training_loss: 4.77032e-02
I0210 08:45:40.875801 22509476222784 run_lib.py:133] step: 104600, training_loss: 3.77174e-02
I0210 08:45:41.041964 22509476222784 run_lib.py:146] step: 104600, eval_loss: 2.56035e-02
I0210 08:45:59.676192 22509476222784 run_lib.py:133] step: 104650, training_loss: 5.23891e-02
I0210 08:46:18.247856 22509476222784 run_lib.py:133] step: 104700, training_loss: 4.69724e-02
I0210 08:46:18.413390 22509476222784 run_lib.py:146] step: 104700, eval_loss: 3.31181e-02
I0210 08:46:36.958124 22509476222784 run_lib.py:133] step: 104750, training_loss: 4.18062e-02
I0210 08:46:55.518320 22509476222784 run_lib.py:133] step: 104800, training_loss: 3.79095e-02
I0210 08:46:55.681531 22509476222784 run_lib.py:146] step: 104800, eval_loss: 5.56395e-02
I0210 08:47:14.462319 22509476222784 run_lib.py:133] step: 104850, training_loss: 4.25571e-02
I0210 08:47:33.308975 22509476222784 run_lib.py:133] step: 104900, training_loss: 3.93251e-02
I0210 08:47:33.473923 22509476222784 run_lib.py:146] step: 104900, eval_loss: 4.20829e-02
I0210 08:47:52.021977 22509476222784 run_lib.py:133] step: 104950, training_loss: 3.46940e-02
I0210 08:48:10.644709 22509476222784 run_lib.py:133] step: 105000, training_loss: 4.73184e-02
I0210 08:48:10.810463 22509476222784 run_lib.py:146] step: 105000, eval_loss: 5.32359e-02
I0210 08:48:29.570923 22509476222784 run_lib.py:133] step: 105050, training_loss: 4.11128e-02
I0210 08:48:48.230104 22509476222784 run_lib.py:133] step: 105100, training_loss: 3.51313e-02
I0210 08:48:48.398606 22509476222784 run_lib.py:146] step: 105100, eval_loss: 4.44815e-02
I0210 08:49:07.131741 22509476222784 run_lib.py:133] step: 105150, training_loss: 4.96125e-02
I0210 08:49:25.645253 22509476222784 run_lib.py:133] step: 105200, training_loss: 5.84391e-02
I0210 08:49:25.810569 22509476222784 run_lib.py:146] step: 105200, eval_loss: 3.93260e-02
I0210 08:49:44.558532 22509476222784 run_lib.py:133] step: 105250, training_loss: 3.96791e-02
I0210 08:50:03.120097 22509476222784 run_lib.py:133] step: 105300, training_loss: 3.99390e-02
I0210 08:50:03.280826 22509476222784 run_lib.py:146] step: 105300, eval_loss: 4.28587e-02
I0210 08:50:22.010174 22509476222784 run_lib.py:133] step: 105350, training_loss: 4.75852e-02
I0210 08:50:40.570772 22509476222784 run_lib.py:133] step: 105400, training_loss: 5.09971e-02
I0210 08:50:40.754910 22509476222784 run_lib.py:146] step: 105400, eval_loss: 5.00756e-02
I0210 08:50:59.397829 22509476222784 run_lib.py:133] step: 105450, training_loss: 5.27152e-02
I0210 08:51:18.215824 22509476222784 run_lib.py:133] step: 105500, training_loss: 4.40803e-02
I0210 08:51:18.382018 22509476222784 run_lib.py:146] step: 105500, eval_loss: 3.86995e-02
I0210 08:51:36.885981 22509476222784 run_lib.py:133] step: 105550, training_loss: 4.50094e-02
I0210 08:51:55.442896 22509476222784 run_lib.py:133] step: 105600, training_loss: 4.19823e-02
I0210 08:51:55.623595 22509476222784 run_lib.py:146] step: 105600, eval_loss: 4.83022e-02
I0210 08:52:14.447100 22509476222784 run_lib.py:133] step: 105650, training_loss: 5.38782e-02
I0210 08:52:33.018613 22509476222784 run_lib.py:133] step: 105700, training_loss: 4.24507e-02
I0210 08:52:33.181856 22509476222784 run_lib.py:146] step: 105700, eval_loss: 4.72063e-02
I0210 08:52:51.905875 22509476222784 run_lib.py:133] step: 105750, training_loss: 4.42083e-02
I0210 08:53:10.440350 22509476222784 run_lib.py:133] step: 105800, training_loss: 4.34010e-02
I0210 08:53:10.601709 22509476222784 run_lib.py:146] step: 105800, eval_loss: 3.67867e-02
I0210 08:53:29.154514 22509476222784 run_lib.py:133] step: 105850, training_loss: 5.27650e-02
I0210 08:53:47.899754 22509476222784 run_lib.py:133] step: 105900, training_loss: 4.61186e-02
I0210 08:53:48.077617 22509476222784 run_lib.py:146] step: 105900, eval_loss: 4.09660e-02
I0210 08:54:06.673362 22509476222784 run_lib.py:133] step: 105950, training_loss: 4.15465e-02
I0210 08:54:25.304247 22509476222784 run_lib.py:133] step: 106000, training_loss: 3.56107e-02
I0210 08:54:25.470165 22509476222784 run_lib.py:146] step: 106000, eval_loss: 4.40455e-02
I0210 08:54:44.081315 22509476222784 run_lib.py:133] step: 106050, training_loss: 4.64228e-02
I0210 08:55:02.903239 22509476222784 run_lib.py:133] step: 106100, training_loss: 5.88582e-02
I0210 08:55:03.076855 22509476222784 run_lib.py:146] step: 106100, eval_loss: 4.55690e-02
I0210 08:55:21.734458 22509476222784 run_lib.py:133] step: 106150, training_loss: 4.30310e-02
I0210 08:55:40.429865 22509476222784 run_lib.py:133] step: 106200, training_loss: 4.41153e-02
I0210 08:55:40.592410 22509476222784 run_lib.py:146] step: 106200, eval_loss: 5.08044e-02
I0210 08:55:59.187285 22509476222784 run_lib.py:133] step: 106250, training_loss: 5.75552e-02
I0210 08:56:17.739423 22509476222784 run_lib.py:133] step: 106300, training_loss: 4.90468e-02
I0210 08:56:17.900747 22509476222784 run_lib.py:146] step: 106300, eval_loss: 3.79319e-02
I0210 08:56:36.644121 22509476222784 run_lib.py:133] step: 106350, training_loss: 3.17908e-02
I0210 08:56:55.380066 22509476222784 run_lib.py:133] step: 106400, training_loss: 3.72231e-02
I0210 08:56:55.554761 22509476222784 run_lib.py:146] step: 106400, eval_loss: 3.16374e-02
I0210 08:57:14.157439 22509476222784 run_lib.py:133] step: 106450, training_loss: 4.59812e-02
I0210 08:57:32.704501 22509476222784 run_lib.py:133] step: 106500, training_loss: 3.44170e-02
I0210 08:57:32.870919 22509476222784 run_lib.py:146] step: 106500, eval_loss: 4.66503e-02
I0210 08:57:51.555093 22509476222784 run_lib.py:133] step: 106550, training_loss: 4.18252e-02
I0210 08:58:10.158262 22509476222784 run_lib.py:133] step: 106600, training_loss: 4.66741e-02
I0210 08:58:10.325122 22509476222784 run_lib.py:146] step: 106600, eval_loss: 5.90361e-02
I0210 08:58:29.105168 22509476222784 run_lib.py:133] step: 106650, training_loss: 3.84595e-02
I0210 08:58:47.702075 22509476222784 run_lib.py:133] step: 106700, training_loss: 5.00466e-02
I0210 08:58:47.863855 22509476222784 run_lib.py:146] step: 106700, eval_loss: 5.44390e-02
I0210 08:59:06.621602 22509476222784 run_lib.py:133] step: 106750, training_loss: 2.95726e-02
I0210 08:59:25.215804 22509476222784 run_lib.py:133] step: 106800, training_loss: 4.22929e-02
I0210 08:59:25.382664 22509476222784 run_lib.py:146] step: 106800, eval_loss: 4.44398e-02
I0210 08:59:43.943596 22509476222784 run_lib.py:133] step: 106850, training_loss: 4.47213e-02
I0210 09:00:02.744381 22509476222784 run_lib.py:133] step: 106900, training_loss: 4.63361e-02
I0210 09:00:02.911763 22509476222784 run_lib.py:146] step: 106900, eval_loss: 4.09703e-02
I0210 09:00:21.477455 22509476222784 run_lib.py:133] step: 106950, training_loss: 4.63887e-02
I0210 09:00:40.285804 22509476222784 run_lib.py:133] step: 107000, training_loss: 4.55490e-02
I0210 09:00:40.483711 22509476222784 run_lib.py:146] step: 107000, eval_loss: 3.79497e-02
I0210 09:00:59.008228 22509476222784 run_lib.py:133] step: 107050, training_loss: 3.34944e-02
I0210 09:01:17.557731 22509476222784 run_lib.py:133] step: 107100, training_loss: 3.69950e-02
I0210 09:01:17.726980 22509476222784 run_lib.py:146] step: 107100, eval_loss: 4.89868e-02
I0210 09:01:36.537086 22509476222784 run_lib.py:133] step: 107150, training_loss: 4.81111e-02
I0210 09:01:55.114223 22509476222784 run_lib.py:133] step: 107200, training_loss: 5.45303e-02
I0210 09:01:55.280717 22509476222784 run_lib.py:146] step: 107200, eval_loss: 4.27563e-02
I0210 09:02:13.860192 22509476222784 run_lib.py:133] step: 107250, training_loss: 3.93598e-02
I0210 09:02:32.628265 22509476222784 run_lib.py:133] step: 107300, training_loss: 4.17477e-02
I0210 09:02:32.790927 22509476222784 run_lib.py:146] step: 107300, eval_loss: 4.70185e-02
I0210 09:02:51.354645 22509476222784 run_lib.py:133] step: 107350, training_loss: 4.84056e-02
I0210 09:03:09.955205 22509476222784 run_lib.py:133] step: 107400, training_loss: 3.21180e-02
I0210 09:03:10.293642 22509476222784 run_lib.py:146] step: 107400, eval_loss: 4.14830e-02
I0210 09:03:28.844416 22509476222784 run_lib.py:133] step: 107450, training_loss: 6.25443e-02
I0210 09:03:47.403083 22509476222784 run_lib.py:133] step: 107500, training_loss: 5.37145e-02
I0210 09:03:47.569094 22509476222784 run_lib.py:146] step: 107500, eval_loss: 4.83872e-02
I0210 09:04:06.133335 22509476222784 run_lib.py:133] step: 107550, training_loss: 3.45312e-02
I0210 09:04:24.694405 22509476222784 run_lib.py:133] step: 107600, training_loss: 5.60795e-02
I0210 09:04:24.868584 22509476222784 run_lib.py:146] step: 107600, eval_loss: 4.66830e-02
I0210 09:04:43.606028 22509476222784 run_lib.py:133] step: 107650, training_loss: 3.89458e-02
I0210 09:05:02.300137 22509476222784 run_lib.py:133] step: 107700, training_loss: 4.77000e-02
I0210 09:05:02.467085 22509476222784 run_lib.py:146] step: 107700, eval_loss: 5.64199e-02
I0210 09:05:21.065582 22509476222784 run_lib.py:133] step: 107750, training_loss: 4.18027e-02
I0210 09:05:39.702739 22509476222784 run_lib.py:133] step: 107800, training_loss: 4.65064e-02
I0210 09:05:39.869879 22509476222784 run_lib.py:146] step: 107800, eval_loss: 2.99034e-02
I0210 09:05:58.555556 22509476222784 run_lib.py:133] step: 107850, training_loss: 4.40646e-02
I0210 09:06:17.225812 22509476222784 run_lib.py:133] step: 107900, training_loss: 5.17609e-02
I0210 09:06:17.401652 22509476222784 run_lib.py:146] step: 107900, eval_loss: 4.53420e-02
I0210 09:06:35.986194 22509476222784 run_lib.py:133] step: 107950, training_loss: 4.12109e-02
I0210 09:06:54.567425 22509476222784 run_lib.py:133] step: 108000, training_loss: 4.27557e-02
I0210 09:06:54.731411 22509476222784 run_lib.py:146] step: 108000, eval_loss: 3.95717e-02
I0210 09:07:13.505378 22509476222784 run_lib.py:133] step: 108050, training_loss: 4.72652e-02
I0210 09:07:32.044809 22509476222784 run_lib.py:133] step: 108100, training_loss: 5.23951e-02
I0210 09:07:32.206497 22509476222784 run_lib.py:146] step: 108100, eval_loss: 3.63753e-02
I0210 09:07:50.910760 22509476222784 run_lib.py:133] step: 108150, training_loss: 4.88772e-02
I0210 09:08:09.500271 22509476222784 run_lib.py:133] step: 108200, training_loss: 5.70278e-02
I0210 09:08:09.669911 22509476222784 run_lib.py:146] step: 108200, eval_loss: 4.50144e-02
I0210 09:08:28.461492 22509476222784 run_lib.py:133] step: 108250, training_loss: 3.74975e-02
I0210 09:08:47.077189 22509476222784 run_lib.py:133] step: 108300, training_loss: 4.54795e-02
I0210 09:08:47.242826 22509476222784 run_lib.py:146] step: 108300, eval_loss: 4.65410e-02
I0210 09:09:05.796202 22509476222784 run_lib.py:133] step: 108350, training_loss: 3.66219e-02
I0210 09:09:24.501790 22509476222784 run_lib.py:133] step: 108400, training_loss: 4.79840e-02
I0210 09:09:24.675801 22509476222784 run_lib.py:146] step: 108400, eval_loss: 4.22915e-02
I0210 09:09:43.316427 22509476222784 run_lib.py:133] step: 108450, training_loss: 4.03667e-02
I0210 09:10:02.136492 22509476222784 run_lib.py:133] step: 108500, training_loss: 4.13787e-02
I0210 09:10:02.451396 22509476222784 run_lib.py:146] step: 108500, eval_loss: 4.64857e-02
I0210 09:10:21.076020 22509476222784 run_lib.py:133] step: 108550, training_loss: 4.59465e-02
I0210 09:10:39.705603 22509476222784 run_lib.py:133] step: 108600, training_loss: 4.89242e-02
I0210 09:10:39.884384 22509476222784 run_lib.py:146] step: 108600, eval_loss: 3.63841e-02
I0210 09:10:58.559462 22509476222784 run_lib.py:133] step: 108650, training_loss: 3.97987e-02
I0210 09:11:17.138962 22509476222784 run_lib.py:133] step: 108700, training_loss: 4.25265e-02
I0210 09:11:17.314845 22509476222784 run_lib.py:146] step: 108700, eval_loss: 5.08659e-02
I0210 09:11:35.939627 22509476222784 run_lib.py:133] step: 108750, training_loss: 4.59030e-02
I0210 09:11:54.508880 22509476222784 run_lib.py:133] step: 108800, training_loss: 3.23345e-02
I0210 09:11:54.674875 22509476222784 run_lib.py:146] step: 108800, eval_loss: 5.12898e-02
I0210 09:12:13.397718 22509476222784 run_lib.py:133] step: 108850, training_loss: 4.17266e-02
I0210 09:12:31.923468 22509476222784 run_lib.py:133] step: 108900, training_loss: 3.83872e-02
I0210 09:12:32.089643 22509476222784 run_lib.py:146] step: 108900, eval_loss: 4.86993e-02
I0210 09:12:50.788513 22509476222784 run_lib.py:133] step: 108950, training_loss: 4.52903e-02
I0210 09:13:09.352893 22509476222784 run_lib.py:133] step: 109000, training_loss: 4.72879e-02
I0210 09:13:09.520925 22509476222784 run_lib.py:146] step: 109000, eval_loss: 3.16446e-02
I0210 09:13:28.124294 22509476222784 run_lib.py:133] step: 109050, training_loss: 5.12348e-02
I0210 09:13:46.689253 22509476222784 run_lib.py:133] step: 109100, training_loss: 3.88053e-02
I0210 09:13:46.864659 22509476222784 run_lib.py:146] step: 109100, eval_loss: 4.66159e-02
I0210 09:14:05.676042 22509476222784 run_lib.py:133] step: 109150, training_loss: 3.72432e-02
I0210 09:14:24.388498 22509476222784 run_lib.py:133] step: 109200, training_loss: 4.28113e-02
I0210 09:14:24.563891 22509476222784 run_lib.py:146] step: 109200, eval_loss: 4.65659e-02
I0210 09:14:43.188627 22509476222784 run_lib.py:133] step: 109250, training_loss: 4.67039e-02
I0210 09:15:01.826005 22509476222784 run_lib.py:133] step: 109300, training_loss: 3.22912e-02
I0210 09:15:01.995993 22509476222784 run_lib.py:146] step: 109300, eval_loss: 5.40287e-02
I0210 09:15:20.758075 22509476222784 run_lib.py:133] step: 109350, training_loss: 4.57702e-02
I0210 09:15:39.290197 22509476222784 run_lib.py:133] step: 109400, training_loss: 3.85485e-02
I0210 09:15:39.456746 22509476222784 run_lib.py:146] step: 109400, eval_loss: 5.13940e-02
I0210 09:15:58.199316 22509476222784 run_lib.py:133] step: 109450, training_loss: 3.72974e-02
I0210 09:16:16.835777 22509476222784 run_lib.py:133] step: 109500, training_loss: 4.11715e-02
I0210 09:16:17.000810 22509476222784 run_lib.py:146] step: 109500, eval_loss: 4.31519e-02
I0210 09:16:35.790215 22509476222784 run_lib.py:133] step: 109550, training_loss: 3.74857e-02
I0210 09:16:54.380136 22509476222784 run_lib.py:133] step: 109600, training_loss: 5.06144e-02
I0210 09:16:54.788462 22509476222784 run_lib.py:146] step: 109600, eval_loss: 3.74334e-02
I0210 09:17:13.495853 22509476222784 run_lib.py:133] step: 109650, training_loss: 4.76938e-02
I0210 09:17:32.080973 22509476222784 run_lib.py:133] step: 109700, training_loss: 5.12500e-02
I0210 09:17:32.262567 22509476222784 run_lib.py:146] step: 109700, eval_loss: 5.08216e-02
I0210 09:17:50.876017 22509476222784 run_lib.py:133] step: 109750, training_loss: 3.83897e-02
I0210 09:18:09.637016 22509476222784 run_lib.py:133] step: 109800, training_loss: 5.23528e-02
I0210 09:18:09.802868 22509476222784 run_lib.py:146] step: 109800, eval_loss: 5.02394e-02
I0210 09:18:28.334371 22509476222784 run_lib.py:133] step: 109850, training_loss: 4.00941e-02
I0210 09:18:46.845410 22509476222784 run_lib.py:133] step: 109900, training_loss: 4.01363e-02
I0210 09:18:47.010802 22509476222784 run_lib.py:146] step: 109900, eval_loss: 4.24910e-02
I0210 09:19:05.719267 22509476222784 run_lib.py:133] step: 109950, training_loss: 4.38809e-02
I0210 09:19:24.562648 22509476222784 run_lib.py:133] step: 110000, training_loss: 3.88859e-02
I0210 09:19:25.314388 22509476222784 run_lib.py:146] step: 110000, eval_loss: 3.41747e-02
I0210 09:19:46.635967 22509476222784 run_lib.py:133] step: 110050, training_loss: 4.63718e-02
I0210 09:20:05.281024 22509476222784 run_lib.py:133] step: 110100, training_loss: 5.20235e-02
I0210 09:20:05.444080 22509476222784 run_lib.py:146] step: 110100, eval_loss: 3.85896e-02
I0210 09:20:24.021085 22509476222784 run_lib.py:133] step: 110150, training_loss: 3.04189e-02
I0210 09:20:42.619351 22509476222784 run_lib.py:133] step: 110200, training_loss: 4.29985e-02
I0210 09:20:42.787896 22509476222784 run_lib.py:146] step: 110200, eval_loss: 5.22979e-02
I0210 09:21:01.567573 22509476222784 run_lib.py:133] step: 110250, training_loss: 3.89694e-02
I0210 09:21:20.307441 22509476222784 run_lib.py:133] step: 110300, training_loss: 4.07296e-02
I0210 09:21:20.474758 22509476222784 run_lib.py:146] step: 110300, eval_loss: 5.55342e-02
I0210 09:21:39.077072 22509476222784 run_lib.py:133] step: 110350, training_loss: 4.68825e-02
I0210 09:21:57.639900 22509476222784 run_lib.py:133] step: 110400, training_loss: 5.45465e-02
I0210 09:21:57.804677 22509476222784 run_lib.py:146] step: 110400, eval_loss: 3.92814e-02
I0210 09:22:16.510013 22509476222784 run_lib.py:133] step: 110450, training_loss: 4.64117e-02
I0210 09:22:35.135152 22509476222784 run_lib.py:133] step: 110500, training_loss: 4.46249e-02
I0210 09:22:35.307920 22509476222784 run_lib.py:146] step: 110500, eval_loss: 3.27080e-02
I0210 09:22:54.149970 22509476222784 run_lib.py:133] step: 110550, training_loss: 3.94032e-02
I0210 09:23:12.705863 22509476222784 run_lib.py:133] step: 110600, training_loss: 4.12048e-02
I0210 09:23:12.867604 22509476222784 run_lib.py:146] step: 110600, eval_loss: 5.11850e-02
I0210 09:23:31.599138 22509476222784 run_lib.py:133] step: 110650, training_loss: 3.92090e-02
I0210 09:23:50.174939 22509476222784 run_lib.py:133] step: 110700, training_loss: 4.61887e-02
I0210 09:23:50.342530 22509476222784 run_lib.py:146] step: 110700, eval_loss: 4.57002e-02
I0210 09:24:08.962800 22509476222784 run_lib.py:133] step: 110750, training_loss: 4.13455e-02
I0210 09:24:27.782809 22509476222784 run_lib.py:133] step: 110800, training_loss: 4.58805e-02
I0210 09:24:27.948898 22509476222784 run_lib.py:146] step: 110800, eval_loss: 4.82833e-02
I0210 09:24:46.497980 22509476222784 run_lib.py:133] step: 110850, training_loss: 4.66038e-02
I0210 09:25:05.203913 22509476222784 run_lib.py:133] step: 110900, training_loss: 5.46943e-02
I0210 09:25:05.369550 22509476222784 run_lib.py:146] step: 110900, eval_loss: 5.73594e-02
I0210 09:25:23.918120 22509476222784 run_lib.py:133] step: 110950, training_loss: 5.00546e-02
I0210 09:25:42.470759 22509476222784 run_lib.py:133] step: 111000, training_loss: 4.03282e-02
I0210 09:25:42.635920 22509476222784 run_lib.py:146] step: 111000, eval_loss: 4.31267e-02
I0210 09:26:01.433197 22509476222784 run_lib.py:133] step: 111050, training_loss: 5.48073e-02
I0210 09:26:19.991941 22509476222784 run_lib.py:133] step: 111100, training_loss: 5.52817e-02
I0210 09:26:20.153966 22509476222784 run_lib.py:146] step: 111100, eval_loss: 3.93619e-02
I0210 09:26:38.720665 22509476222784 run_lib.py:133] step: 111150, training_loss: 5.46256e-02
I0210 09:26:57.410914 22509476222784 run_lib.py:133] step: 111200, training_loss: 5.55004e-02
I0210 09:26:57.577002 22509476222784 run_lib.py:146] step: 111200, eval_loss: 5.30769e-02
I0210 09:27:16.161230 22509476222784 run_lib.py:133] step: 111250, training_loss: 3.57232e-02
I0210 09:27:34.782646 22509476222784 run_lib.py:133] step: 111300, training_loss: 3.91951e-02
I0210 09:27:34.946897 22509476222784 run_lib.py:146] step: 111300, eval_loss: 5.24438e-02
I0210 09:27:53.615055 22509476222784 run_lib.py:133] step: 111350, training_loss: 4.04392e-02
I0210 09:28:12.172003 22509476222784 run_lib.py:133] step: 111400, training_loss: 4.31495e-02
I0210 09:28:12.340653 22509476222784 run_lib.py:146] step: 111400, eval_loss: 4.10433e-02
I0210 09:28:30.903794 22509476222784 run_lib.py:133] step: 111450, training_loss: 4.84841e-02
I0210 09:28:49.496349 22509476222784 run_lib.py:133] step: 111500, training_loss: 4.15253e-02
I0210 09:28:49.659894 22509476222784 run_lib.py:146] step: 111500, eval_loss: 4.69330e-02
I0210 09:29:08.448690 22509476222784 run_lib.py:133] step: 111550, training_loss: 4.69865e-02
I0210 09:29:27.118196 22509476222784 run_lib.py:133] step: 111600, training_loss: 4.98498e-02
I0210 09:29:27.281752 22509476222784 run_lib.py:146] step: 111600, eval_loss: 4.55669e-02
I0210 09:29:45.827049 22509476222784 run_lib.py:133] step: 111650, training_loss: 4.68613e-02
I0210 09:30:04.418510 22509476222784 run_lib.py:133] step: 111700, training_loss: 4.35731e-02
I0210 09:30:04.584816 22509476222784 run_lib.py:146] step: 111700, eval_loss: 4.67368e-02
I0210 09:30:23.301041 22509476222784 run_lib.py:133] step: 111750, training_loss: 3.13504e-02
I0210 09:30:41.963990 22509476222784 run_lib.py:133] step: 111800, training_loss: 3.23453e-02
I0210 09:30:42.138791 22509476222784 run_lib.py:146] step: 111800, eval_loss: 3.89226e-02
I0210 09:31:00.947293 22509476222784 run_lib.py:133] step: 111850, training_loss: 3.70080e-02
I0210 09:31:19.528708 22509476222784 run_lib.py:133] step: 111900, training_loss: 4.91608e-02
I0210 09:31:19.694785 22509476222784 run_lib.py:146] step: 111900, eval_loss: 4.35263e-02
I0210 09:31:38.411206 22509476222784 run_lib.py:133] step: 111950, training_loss: 4.51201e-02
I0210 09:31:56.999389 22509476222784 run_lib.py:133] step: 112000, training_loss: 3.59507e-02
I0210 09:31:57.160719 22509476222784 run_lib.py:146] step: 112000, eval_loss: 4.90784e-02
I0210 09:32:15.877010 22509476222784 run_lib.py:133] step: 112050, training_loss: 4.48155e-02
I0210 09:32:34.468105 22509476222784 run_lib.py:133] step: 112100, training_loss: 3.68576e-02
I0210 09:32:34.643904 22509476222784 run_lib.py:146] step: 112100, eval_loss: 4.27857e-02
I0210 09:32:53.214297 22509476222784 run_lib.py:133] step: 112150, training_loss: 3.71777e-02
I0210 09:33:11.977749 22509476222784 run_lib.py:133] step: 112200, training_loss: 5.00384e-02
I0210 09:33:12.144104 22509476222784 run_lib.py:146] step: 112200, eval_loss: 3.98552e-02
I0210 09:33:30.665799 22509476222784 run_lib.py:133] step: 112250, training_loss: 4.82897e-02
I0210 09:33:49.215466 22509476222784 run_lib.py:133] step: 112300, training_loss: 4.66135e-02
I0210 09:33:49.389606 22509476222784 run_lib.py:146] step: 112300, eval_loss: 3.48230e-02
I0210 09:34:08.177621 22509476222784 run_lib.py:133] step: 112350, training_loss: 4.93578e-02
I0210 09:34:26.787130 22509476222784 run_lib.py:133] step: 112400, training_loss: 4.13046e-02
I0210 09:34:26.951553 22509476222784 run_lib.py:146] step: 112400, eval_loss: 4.78872e-02
I0210 09:34:45.690962 22509476222784 run_lib.py:133] step: 112450, training_loss: 4.06932e-02
I0210 09:35:04.238484 22509476222784 run_lib.py:133] step: 112500, training_loss: 2.58358e-02
I0210 09:35:04.400729 22509476222784 run_lib.py:146] step: 112500, eval_loss: 5.61905e-02
I0210 09:35:22.940278 22509476222784 run_lib.py:133] step: 112550, training_loss: 4.80837e-02
I0210 09:35:41.668963 22509476222784 run_lib.py:133] step: 112600, training_loss: 6.23195e-02
I0210 09:35:41.843694 22509476222784 run_lib.py:146] step: 112600, eval_loss: 4.30657e-02
I0210 09:36:00.426664 22509476222784 run_lib.py:133] step: 112650, training_loss: 4.52750e-02
I0210 09:36:19.027231 22509476222784 run_lib.py:133] step: 112700, training_loss: 4.91833e-02
I0210 09:36:19.193906 22509476222784 run_lib.py:146] step: 112700, eval_loss: 3.29107e-02
I0210 09:36:37.789128 22509476222784 run_lib.py:133] step: 112750, training_loss: 3.72390e-02
I0210 09:36:56.534345 22509476222784 run_lib.py:133] step: 112800, training_loss: 5.20144e-02
I0210 09:36:56.703811 22509476222784 run_lib.py:146] step: 112800, eval_loss: 4.69031e-02
I0210 09:37:15.303372 22509476222784 run_lib.py:133] step: 112850, training_loss: 3.66112e-02
I0210 09:37:33.977158 22509476222784 run_lib.py:133] step: 112900, training_loss: 4.66535e-02
I0210 09:37:34.145013 22509476222784 run_lib.py:146] step: 112900, eval_loss: 5.32064e-02
I0210 09:37:52.732948 22509476222784 run_lib.py:133] step: 112950, training_loss: 5.02971e-02
I0210 09:38:11.300604 22509476222784 run_lib.py:133] step: 113000, training_loss: 3.66234e-02
I0210 09:38:11.462614 22509476222784 run_lib.py:146] step: 113000, eval_loss: 4.76793e-02
I0210 09:38:30.174638 22509476222784 run_lib.py:133] step: 113050, training_loss: 4.39235e-02
I0210 09:38:48.789052 22509476222784 run_lib.py:133] step: 113100, training_loss: 3.66951e-02
I0210 09:38:48.970762 22509476222784 run_lib.py:146] step: 113100, eval_loss: 4.34043e-02
I0210 09:39:07.550843 22509476222784 run_lib.py:133] step: 113150, training_loss: 3.81690e-02
I0210 09:39:26.138078 22509476222784 run_lib.py:133] step: 113200, training_loss: 4.42145e-02
I0210 09:39:26.305096 22509476222784 run_lib.py:146] step: 113200, eval_loss: 5.17848e-02
I0210 09:39:45.081478 22509476222784 run_lib.py:133] step: 113250, training_loss: 5.57931e-02
I0210 09:40:03.629667 22509476222784 run_lib.py:133] step: 113300, training_loss: 5.33969e-02
I0210 09:40:03.793792 22509476222784 run_lib.py:146] step: 113300, eval_loss: 4.06801e-02
I0210 09:40:22.471031 22509476222784 run_lib.py:133] step: 113350, training_loss: 3.16583e-02
I0210 09:40:41.158799 22509476222784 run_lib.py:133] step: 113400, training_loss: 3.97885e-02
I0210 09:40:41.333399 22509476222784 run_lib.py:146] step: 113400, eval_loss: 4.27954e-02
I0210 09:41:00.143977 22509476222784 run_lib.py:133] step: 113450, training_loss: 3.93983e-02
I0210 09:41:18.705976 22509476222784 run_lib.py:133] step: 113500, training_loss: 4.18011e-02
I0210 09:41:18.881735 22509476222784 run_lib.py:146] step: 113500, eval_loss: 4.26471e-02
I0210 09:41:37.450669 22509476222784 run_lib.py:133] step: 113550, training_loss: 3.60135e-02
I0210 09:41:56.161113 22509476222784 run_lib.py:133] step: 113600, training_loss: 5.40548e-02
I0210 09:41:56.340518 22509476222784 run_lib.py:146] step: 113600, eval_loss: 4.57319e-02
I0210 09:42:14.968634 22509476222784 run_lib.py:133] step: 113650, training_loss: 5.29534e-02
I0210 09:42:33.691059 22509476222784 run_lib.py:133] step: 113700, training_loss: 3.98681e-02
I0210 09:42:33.855876 22509476222784 run_lib.py:146] step: 113700, eval_loss: 5.04217e-02
I0210 09:42:52.437542 22509476222784 run_lib.py:133] step: 113750, training_loss: 5.51911e-02
I0210 09:43:10.987397 22509476222784 run_lib.py:133] step: 113800, training_loss: 7.21196e-02
I0210 09:43:11.151637 22509476222784 run_lib.py:146] step: 113800, eval_loss: 4.22638e-02
I0210 09:43:29.873763 22509476222784 run_lib.py:133] step: 113850, training_loss: 5.15976e-02
I0210 09:43:48.489291 22509476222784 run_lib.py:133] step: 113900, training_loss: 4.16976e-02
I0210 09:43:48.655994 22509476222784 run_lib.py:146] step: 113900, eval_loss: 4.73390e-02
I0210 09:44:07.284588 22509476222784 run_lib.py:133] step: 113950, training_loss: 3.71244e-02
I0210 09:44:26.072576 22509476222784 run_lib.py:133] step: 114000, training_loss: 4.56650e-02
I0210 09:44:26.238556 22509476222784 run_lib.py:146] step: 114000, eval_loss: 3.95086e-02
I0210 09:44:44.820589 22509476222784 run_lib.py:133] step: 114050, training_loss: 4.24683e-02
I0210 09:45:03.382910 22509476222784 run_lib.py:133] step: 114100, training_loss: 4.24375e-02
I0210 09:45:03.707917 22509476222784 run_lib.py:146] step: 114100, eval_loss: 5.03683e-02
I0210 09:45:22.268744 22509476222784 run_lib.py:133] step: 114150, training_loss: 4.19691e-02
I0210 09:45:40.875546 22509476222784 run_lib.py:133] step: 114200, training_loss: 4.97827e-02
I0210 09:45:41.040928 22509476222784 run_lib.py:146] step: 114200, eval_loss: 4.46076e-02
I0210 09:45:59.606976 22509476222784 run_lib.py:133] step: 114250, training_loss: 4.51299e-02
I0210 09:46:18.115639 22509476222784 run_lib.py:133] step: 114300, training_loss: 5.09067e-02
I0210 09:46:18.279835 22509476222784 run_lib.py:146] step: 114300, eval_loss: 3.41858e-02
I0210 09:46:36.969400 22509476222784 run_lib.py:133] step: 114350, training_loss: 4.05633e-02
I0210 09:46:55.640571 22509476222784 run_lib.py:133] step: 114400, training_loss: 3.71663e-02
I0210 09:46:55.808058 22509476222784 run_lib.py:146] step: 114400, eval_loss: 5.42517e-02
I0210 09:47:14.397620 22509476222784 run_lib.py:133] step: 114450, training_loss: 4.29579e-02
I0210 09:47:32.960555 22509476222784 run_lib.py:133] step: 114500, training_loss: 3.61708e-02
I0210 09:47:33.127122 22509476222784 run_lib.py:146] step: 114500, eval_loss: 4.22352e-02
I0210 09:47:51.825101 22509476222784 run_lib.py:133] step: 114550, training_loss: 4.03311e-02
I0210 09:48:10.449977 22509476222784 run_lib.py:133] step: 114600, training_loss: 4.75772e-02
I0210 09:48:10.615040 22509476222784 run_lib.py:146] step: 114600, eval_loss: 4.06551e-02
I0210 09:48:29.189815 22509476222784 run_lib.py:133] step: 114650, training_loss: 4.70857e-02
I0210 09:48:47.825526 22509476222784 run_lib.py:133] step: 114700, training_loss: 4.19214e-02
I0210 09:48:47.995455 22509476222784 run_lib.py:146] step: 114700, eval_loss: 4.67598e-02
I0210 09:49:06.699534 22509476222784 run_lib.py:133] step: 114750, training_loss: 5.74338e-02
I0210 09:49:25.244911 22509476222784 run_lib.py:133] step: 114800, training_loss: 4.52485e-02
I0210 09:49:25.408691 22509476222784 run_lib.py:146] step: 114800, eval_loss: 4.54367e-02
I0210 09:49:44.136638 22509476222784 run_lib.py:133] step: 114850, training_loss: 5.32654e-02
I0210 09:50:02.713927 22509476222784 run_lib.py:133] step: 114900, training_loss: 3.50073e-02
I0210 09:50:02.881806 22509476222784 run_lib.py:146] step: 114900, eval_loss: 4.01675e-02
I0210 09:50:21.780220 22509476222784 run_lib.py:133] step: 114950, training_loss: 4.60528e-02
I0210 09:50:40.407995 22509476222784 run_lib.py:133] step: 115000, training_loss: 4.17182e-02
I0210 09:50:40.598712 22509476222784 run_lib.py:146] step: 115000, eval_loss: 4.50186e-02
I0210 09:50:59.133925 22509476222784 run_lib.py:133] step: 115050, training_loss: 5.57689e-02
I0210 09:51:17.859854 22509476222784 run_lib.py:133] step: 115100, training_loss: 5.53989e-02
I0210 09:51:18.024737 22509476222784 run_lib.py:146] step: 115100, eval_loss: 2.98317e-02
I0210 09:51:36.591237 22509476222784 run_lib.py:133] step: 115150, training_loss: 4.32877e-02
I0210 09:51:55.383097 22509476222784 run_lib.py:133] step: 115200, training_loss: 3.48252e-02
I0210 09:51:55.548976 22509476222784 run_lib.py:146] step: 115200, eval_loss: 3.34995e-02
I0210 09:52:14.101043 22509476222784 run_lib.py:133] step: 115250, training_loss: 4.63120e-02
I0210 09:52:32.611475 22509476222784 run_lib.py:133] step: 115300, training_loss: 3.85424e-02
I0210 09:52:32.774444 22509476222784 run_lib.py:146] step: 115300, eval_loss: 3.71610e-02
I0210 09:52:51.361665 22509476222784 run_lib.py:133] step: 115350, training_loss: 4.04543e-02
I0210 09:53:10.165091 22509476222784 run_lib.py:133] step: 115400, training_loss: 5.32573e-02
I0210 09:53:10.332800 22509476222784 run_lib.py:146] step: 115400, eval_loss: 4.08485e-02
I0210 09:53:28.971497 22509476222784 run_lib.py:133] step: 115450, training_loss: 4.17164e-02
I0210 09:53:47.565023 22509476222784 run_lib.py:133] step: 115500, training_loss: 4.90668e-02
I0210 09:53:47.731620 22509476222784 run_lib.py:146] step: 115500, eval_loss: 4.94106e-02
I0210 09:54:06.502583 22509476222784 run_lib.py:133] step: 115550, training_loss: 4.35111e-02
I0210 09:54:25.101431 22509476222784 run_lib.py:133] step: 115600, training_loss: 3.19537e-02
I0210 09:54:25.266596 22509476222784 run_lib.py:146] step: 115600, eval_loss: 5.15717e-02
I0210 09:54:43.875145 22509476222784 run_lib.py:133] step: 115650, training_loss: 4.04727e-02
I0210 09:55:02.446743 22509476222784 run_lib.py:133] step: 115700, training_loss: 4.38187e-02
I0210 09:55:02.613052 22509476222784 run_lib.py:146] step: 115700, eval_loss: 4.10829e-02
I0210 09:55:21.239648 22509476222784 run_lib.py:133] step: 115750, training_loss: 4.39194e-02
I0210 09:55:39.832207 22509476222784 run_lib.py:133] step: 115800, training_loss: 3.94298e-02
I0210 09:55:40.000649 22509476222784 run_lib.py:146] step: 115800, eval_loss: 5.66657e-02
I0210 09:55:58.748250 22509476222784 run_lib.py:133] step: 115850, training_loss: 4.89327e-02
I0210 09:56:17.343003 22509476222784 run_lib.py:133] step: 115900, training_loss: 3.98812e-02
I0210 09:56:17.507923 22509476222784 run_lib.py:146] step: 115900, eval_loss: 5.26408e-02
I0210 09:56:36.118337 22509476222784 run_lib.py:133] step: 115950, training_loss: 3.42758e-02
I0210 09:56:54.737428 22509476222784 run_lib.py:133] step: 116000, training_loss: 3.92381e-02
I0210 09:56:54.904604 22509476222784 run_lib.py:146] step: 116000, eval_loss: 3.47169e-02
I0210 09:57:13.670625 22509476222784 run_lib.py:133] step: 116050, training_loss: 3.97150e-02
I0210 09:57:32.253661 22509476222784 run_lib.py:133] step: 116100, training_loss: 5.56838e-02
I0210 09:57:32.418667 22509476222784 run_lib.py:146] step: 116100, eval_loss: 4.50587e-02
I0210 09:57:51.148880 22509476222784 run_lib.py:133] step: 116150, training_loss: 4.27895e-02
I0210 09:58:09.754203 22509476222784 run_lib.py:133] step: 116200, training_loss: 3.48801e-02
I0210 09:58:09.918170 22509476222784 run_lib.py:146] step: 116200, eval_loss: 3.55625e-02
I0210 09:58:28.717465 22509476222784 run_lib.py:133] step: 116250, training_loss: 3.17820e-02
I0210 09:58:47.228747 22509476222784 run_lib.py:133] step: 116300, training_loss: 4.03065e-02
I0210 09:58:47.393729 22509476222784 run_lib.py:146] step: 116300, eval_loss: 4.26612e-02
I0210 09:59:06.099889 22509476222784 run_lib.py:133] step: 116350, training_loss: 5.90742e-02
I0210 09:59:24.651680 22509476222784 run_lib.py:133] step: 116400, training_loss: 4.36476e-02
I0210 09:59:24.817677 22509476222784 run_lib.py:146] step: 116400, eval_loss: 3.73947e-02
I0210 09:59:43.432365 22509476222784 run_lib.py:133] step: 116450, training_loss: 2.63671e-02
I0210 10:00:02.155247 22509476222784 run_lib.py:133] step: 116500, training_loss: 5.06870e-02
I0210 10:00:02.321521 22509476222784 run_lib.py:146] step: 116500, eval_loss: 4.39540e-02
I0210 10:00:20.877390 22509476222784 run_lib.py:133] step: 116550, training_loss: 4.36277e-02
I0210 10:00:39.460944 22509476222784 run_lib.py:133] step: 116600, training_loss: 4.44679e-02
I0210 10:00:39.633750 22509476222784 run_lib.py:146] step: 116600, eval_loss: 3.36202e-02
I0210 10:00:58.412000 22509476222784 run_lib.py:133] step: 116650, training_loss: 4.34488e-02
I0210 10:01:17.110855 22509476222784 run_lib.py:133] step: 116700, training_loss: 5.04950e-02
I0210 10:01:17.276869 22509476222784 run_lib.py:146] step: 116700, eval_loss: 3.59066e-02
I0210 10:01:35.882868 22509476222784 run_lib.py:133] step: 116750, training_loss: 3.67726e-02
I0210 10:01:54.435724 22509476222784 run_lib.py:133] step: 116800, training_loss: 4.74927e-02
I0210 10:01:54.607800 22509476222784 run_lib.py:146] step: 116800, eval_loss: 3.45785e-02
I0210 10:02:13.133145 22509476222784 run_lib.py:133] step: 116850, training_loss: 4.62852e-02
I0210 10:02:31.871982 22509476222784 run_lib.py:133] step: 116900, training_loss: 3.85899e-02
I0210 10:02:32.039109 22509476222784 run_lib.py:146] step: 116900, eval_loss: 3.05332e-02
I0210 10:02:50.580399 22509476222784 run_lib.py:133] step: 116950, training_loss: 4.12372e-02
I0210 10:03:09.142743 22509476222784 run_lib.py:133] step: 117000, training_loss: 3.92519e-02
I0210 10:03:09.312311 22509476222784 run_lib.py:146] step: 117000, eval_loss: 3.90360e-02
I0210 10:03:27.876618 22509476222784 run_lib.py:133] step: 117050, training_loss: 4.66638e-02
I0210 10:03:46.648312 22509476222784 run_lib.py:133] step: 117100, training_loss: 3.10210e-02
I0210 10:03:46.812426 22509476222784 run_lib.py:146] step: 117100, eval_loss: 3.89265e-02
I0210 10:04:05.435500 22509476222784 run_lib.py:133] step: 117150, training_loss: 4.02491e-02
I0210 10:04:24.015726 22509476222784 run_lib.py:133] step: 117200, training_loss: 5.53416e-02
I0210 10:04:24.176252 22509476222784 run_lib.py:146] step: 117200, eval_loss: 5.38035e-02
I0210 10:04:42.725826 22509476222784 run_lib.py:133] step: 117250, training_loss: 3.71899e-02
I0210 10:05:01.360196 22509476222784 run_lib.py:133] step: 117300, training_loss: 4.33301e-02
I0210 10:05:01.539814 22509476222784 run_lib.py:146] step: 117300, eval_loss: 5.55198e-02
I0210 10:05:20.343710 22509476222784 run_lib.py:133] step: 117350, training_loss: 4.08088e-02
I0210 10:05:39.025142 22509476222784 run_lib.py:133] step: 117400, training_loss: 4.69180e-02
I0210 10:05:39.193712 22509476222784 run_lib.py:146] step: 117400, eval_loss: 4.02096e-02
I0210 10:05:57.728665 22509476222784 run_lib.py:133] step: 117450, training_loss: 5.22335e-02
I0210 10:06:16.321204 22509476222784 run_lib.py:133] step: 117500, training_loss: 3.60710e-02
I0210 10:06:16.504612 22509476222784 run_lib.py:146] step: 117500, eval_loss: 5.01441e-02
I0210 10:06:35.340793 22509476222784 run_lib.py:133] step: 117550, training_loss: 5.20731e-02
I0210 10:06:53.926750 22509476222784 run_lib.py:133] step: 117600, training_loss: 3.92894e-02
I0210 10:06:54.092462 22509476222784 run_lib.py:146] step: 117600, eval_loss: 5.02243e-02
I0210 10:07:12.802004 22509476222784 run_lib.py:133] step: 117650, training_loss: 4.52059e-02
I0210 10:07:31.345390 22509476222784 run_lib.py:133] step: 117700, training_loss: 4.02766e-02
I0210 10:07:31.506604 22509476222784 run_lib.py:146] step: 117700, eval_loss: 3.51689e-02
I0210 10:07:50.198446 22509476222784 run_lib.py:133] step: 117750, training_loss: 4.22931e-02
I0210 10:08:08.754796 22509476222784 run_lib.py:133] step: 117800, training_loss: 4.27100e-02
I0210 10:08:08.937875 22509476222784 run_lib.py:146] step: 117800, eval_loss: 4.35654e-02
I0210 10:08:27.558126 22509476222784 run_lib.py:133] step: 117850, training_loss: 4.83292e-02
I0210 10:08:46.358035 22509476222784 run_lib.py:133] step: 117900, training_loss: 5.69918e-02
I0210 10:08:46.717754 22509476222784 run_lib.py:146] step: 117900, eval_loss: 3.82101e-02
I0210 10:09:05.275711 22509476222784 run_lib.py:133] step: 117950, training_loss: 4.83874e-02
I0210 10:09:24.002901 22509476222784 run_lib.py:133] step: 118000, training_loss: 4.45118e-02
I0210 10:09:24.169616 22509476222784 run_lib.py:146] step: 118000, eval_loss: 5.01787e-02
I0210 10:09:42.754503 22509476222784 run_lib.py:133] step: 118050, training_loss: 3.75846e-02
I0210 10:10:01.357067 22509476222784 run_lib.py:133] step: 118100, training_loss: 4.55448e-02
I0210 10:10:01.520894 22509476222784 run_lib.py:146] step: 118100, eval_loss: 4.43306e-02
I0210 10:10:20.306684 22509476222784 run_lib.py:133] step: 118150, training_loss: 3.64279e-02
I0210 10:10:38.848692 22509476222784 run_lib.py:133] step: 118200, training_loss: 5.27227e-02
I0210 10:10:39.010676 22509476222784 run_lib.py:146] step: 118200, eval_loss: 5.64775e-02
I0210 10:10:57.519314 22509476222784 run_lib.py:133] step: 118250, training_loss: 5.50958e-02
I0210 10:11:16.193254 22509476222784 run_lib.py:133] step: 118300, training_loss: 4.96756e-02
I0210 10:11:16.375631 22509476222784 run_lib.py:146] step: 118300, eval_loss: 5.36551e-02
I0210 10:11:34.971644 22509476222784 run_lib.py:133] step: 118350, training_loss: 5.19197e-02
I0210 10:11:53.505818 22509476222784 run_lib.py:133] step: 118400, training_loss: 4.97965e-02
I0210 10:11:53.670756 22509476222784 run_lib.py:146] step: 118400, eval_loss: 5.30708e-02
I0210 10:12:12.368731 22509476222784 run_lib.py:133] step: 118450, training_loss: 5.21108e-02
I0210 10:12:30.932346 22509476222784 run_lib.py:133] step: 118500, training_loss: 4.56262e-02
I0210 10:12:31.097675 22509476222784 run_lib.py:146] step: 118500, eval_loss: 4.77654e-02
I0210 10:12:49.644934 22509476222784 run_lib.py:133] step: 118550, training_loss: 3.86965e-02
I0210 10:13:08.224356 22509476222784 run_lib.py:133] step: 118600, training_loss: 4.72638e-02
I0210 10:13:08.387389 22509476222784 run_lib.py:146] step: 118600, eval_loss: 3.90086e-02
I0210 10:13:27.146080 22509476222784 run_lib.py:133] step: 118650, training_loss: 5.11486e-02
I0210 10:13:45.776345 22509476222784 run_lib.py:133] step: 118700, training_loss: 5.54900e-02
I0210 10:13:45.939620 22509476222784 run_lib.py:146] step: 118700, eval_loss: 2.94308e-02
I0210 10:14:04.476972 22509476222784 run_lib.py:133] step: 118750, training_loss: 4.72119e-02
I0210 10:14:23.046144 22509476222784 run_lib.py:133] step: 118800, training_loss: 4.33566e-02
I0210 10:14:23.216869 22509476222784 run_lib.py:146] step: 118800, eval_loss: 4.34049e-02
I0210 10:14:41.961965 22509476222784 run_lib.py:133] step: 118850, training_loss: 3.79455e-02
I0210 10:15:00.602439 22509476222784 run_lib.py:133] step: 118900, training_loss: 3.20352e-02
I0210 10:15:00.764823 22509476222784 run_lib.py:146] step: 118900, eval_loss: 4.56136e-02
I0210 10:15:19.471128 22509476222784 run_lib.py:133] step: 118950, training_loss: 4.47731e-02
I0210 10:15:38.046283 22509476222784 run_lib.py:133] step: 119000, training_loss: 4.30835e-02
I0210 10:15:38.211776 22509476222784 run_lib.py:146] step: 119000, eval_loss: 4.56558e-02
I0210 10:15:56.945278 22509476222784 run_lib.py:133] step: 119050, training_loss: 3.90533e-02
I0210 10:16:15.569018 22509476222784 run_lib.py:133] step: 119100, training_loss: 3.10940e-02
I0210 10:16:15.734925 22509476222784 run_lib.py:146] step: 119100, eval_loss: 3.10990e-02
I0210 10:16:34.523725 22509476222784 run_lib.py:133] step: 119150, training_loss: 3.56611e-02
I0210 10:16:53.041714 22509476222784 run_lib.py:133] step: 119200, training_loss: 4.93264e-02
I0210 10:16:53.206648 22509476222784 run_lib.py:146] step: 119200, eval_loss: 4.53641e-02
I0210 10:17:11.749754 22509476222784 run_lib.py:133] step: 119250, training_loss: 4.94542e-02
I0210 10:17:30.479024 22509476222784 run_lib.py:133] step: 119300, training_loss: 4.87851e-02
I0210 10:17:30.649795 22509476222784 run_lib.py:146] step: 119300, eval_loss: 4.86524e-02
I0210 10:17:49.221168 22509476222784 run_lib.py:133] step: 119350, training_loss: 4.13790e-02
I0210 10:18:07.839935 22509476222784 run_lib.py:133] step: 119400, training_loss: 5.62283e-02
I0210 10:18:08.020753 22509476222784 run_lib.py:146] step: 119400, eval_loss: 3.82328e-02
I0210 10:18:26.743227 22509476222784 run_lib.py:133] step: 119450, training_loss: 2.40380e-02
I0210 10:18:45.265849 22509476222784 run_lib.py:133] step: 119500, training_loss: 5.02901e-02
I0210 10:18:45.430393 22509476222784 run_lib.py:146] step: 119500, eval_loss: 3.93677e-02
I0210 10:19:04.125020 22509476222784 run_lib.py:133] step: 119550, training_loss: 3.45178e-02
I0210 10:19:22.679838 22509476222784 run_lib.py:133] step: 119600, training_loss: 4.83681e-02
I0210 10:19:22.852898 22509476222784 run_lib.py:146] step: 119600, eval_loss: 3.94972e-02
I0210 10:19:41.498944 22509476222784 run_lib.py:133] step: 119650, training_loss: 4.65854e-02
I0210 10:20:00.272424 22509476222784 run_lib.py:133] step: 119700, training_loss: 5.92349e-02
I0210 10:20:00.436623 22509476222784 run_lib.py:146] step: 119700, eval_loss: 4.13068e-02
I0210 10:20:18.975904 22509476222784 run_lib.py:133] step: 119750, training_loss: 3.90787e-02
I0210 10:20:37.553517 22509476222784 run_lib.py:133] step: 119800, training_loss: 4.66845e-02
I0210 10:20:37.721837 22509476222784 run_lib.py:146] step: 119800, eval_loss: 4.86251e-02
I0210 10:20:56.287440 22509476222784 run_lib.py:133] step: 119850, training_loss: 5.38030e-02
I0210 10:21:15.071184 22509476222784 run_lib.py:133] step: 119900, training_loss: 4.76191e-02
I0210 10:21:15.237845 22509476222784 run_lib.py:146] step: 119900, eval_loss: 3.49772e-02
I0210 10:21:33.762746 22509476222784 run_lib.py:133] step: 119950, training_loss: 2.93054e-02
I0210 10:21:52.414643 22509476222784 run_lib.py:133] step: 120000, training_loss: 4.06726e-02
I0210 10:21:54.498767 22509476222784 run_lib.py:146] step: 120000, eval_loss: 5.18725e-02
I0210 10:22:16.919403 22509476222784 run_lib.py:133] step: 120050, training_loss: 4.25600e-02
I0210 10:22:35.532496 22509476222784 run_lib.py:133] step: 120100, training_loss: 5.13239e-02
I0210 10:22:35.699226 22509476222784 run_lib.py:146] step: 120100, eval_loss: 3.33220e-02
I0210 10:22:54.509042 22509476222784 run_lib.py:133] step: 120150, training_loss: 5.62504e-02
I0210 10:23:13.067673 22509476222784 run_lib.py:133] step: 120200, training_loss: 3.65501e-02
I0210 10:23:13.231710 22509476222784 run_lib.py:146] step: 120200, eval_loss: 4.48205e-02
I0210 10:23:31.868326 22509476222784 run_lib.py:133] step: 120250, training_loss: 5.69959e-02
I0210 10:23:50.471813 22509476222784 run_lib.py:133] step: 120300, training_loss: 3.86642e-02
I0210 10:23:50.638865 22509476222784 run_lib.py:146] step: 120300, eval_loss: 4.04834e-02
I0210 10:24:09.215111 22509476222784 run_lib.py:133] step: 120350, training_loss: 3.43900e-02
I0210 10:24:27.813893 22509476222784 run_lib.py:133] step: 120400, training_loss: 4.11160e-02
I0210 10:24:27.982717 22509476222784 run_lib.py:146] step: 120400, eval_loss: 4.87603e-02
I0210 10:24:46.728239 22509476222784 run_lib.py:133] step: 120450, training_loss: 4.66260e-02
I0210 10:25:05.388691 22509476222784 run_lib.py:133] step: 120500, training_loss: 4.10307e-02
I0210 10:25:05.554482 22509476222784 run_lib.py:146] step: 120500, eval_loss: 4.66385e-02
I0210 10:25:24.112680 22509476222784 run_lib.py:133] step: 120550, training_loss: 5.84858e-02
I0210 10:25:42.633468 22509476222784 run_lib.py:133] step: 120600, training_loss: 5.40033e-02
I0210 10:25:42.800855 22509476222784 run_lib.py:146] step: 120600, eval_loss: 4.54671e-02
I0210 10:26:01.492734 22509476222784 run_lib.py:133] step: 120650, training_loss: 3.74971e-02
I0210 10:26:20.099682 22509476222784 run_lib.py:133] step: 120700, training_loss: 4.04295e-02
I0210 10:26:20.281064 22509476222784 run_lib.py:146] step: 120700, eval_loss: 4.13012e-02
I0210 10:26:39.012302 22509476222784 run_lib.py:133] step: 120750, training_loss: 4.57175e-02
I0210 10:26:57.573703 22509476222784 run_lib.py:133] step: 120800, training_loss: 3.08616e-02
I0210 10:26:57.740809 22509476222784 run_lib.py:146] step: 120800, eval_loss: 4.45437e-02
I0210 10:27:16.401978 22509476222784 run_lib.py:133] step: 120850, training_loss: 3.50907e-02
I0210 10:27:35.033109 22509476222784 run_lib.py:133] step: 120900, training_loss: 3.90276e-02
I0210 10:27:35.224650 22509476222784 run_lib.py:146] step: 120900, eval_loss: 4.35296e-02
I0210 10:27:53.809551 22509476222784 run_lib.py:133] step: 120950, training_loss: 4.63945e-02
I0210 10:28:12.593151 22509476222784 run_lib.py:133] step: 121000, training_loss: 3.61909e-02
I0210 10:28:12.765833 22509476222784 run_lib.py:146] step: 121000, eval_loss: 4.02504e-02
I0210 10:28:31.371404 22509476222784 run_lib.py:133] step: 121050, training_loss: 5.34490e-02
I0210 10:28:50.070824 22509476222784 run_lib.py:133] step: 121100, training_loss: 4.24615e-02
I0210 10:28:50.231669 22509476222784 run_lib.py:146] step: 121100, eval_loss: 4.15922e-02
I0210 10:29:08.783842 22509476222784 run_lib.py:133] step: 121150, training_loss: 4.57165e-02
I0210 10:29:27.323443 22509476222784 run_lib.py:133] step: 121200, training_loss: 4.67764e-02
I0210 10:29:27.487822 22509476222784 run_lib.py:146] step: 121200, eval_loss: 4.85560e-02
I0210 10:29:46.290935 22509476222784 run_lib.py:133] step: 121250, training_loss: 3.86854e-02
I0210 10:30:04.897818 22509476222784 run_lib.py:133] step: 121300, training_loss: 4.83750e-02
I0210 10:30:05.110578 22509476222784 run_lib.py:146] step: 121300, eval_loss: 4.65269e-02
I0210 10:30:23.675029 22509476222784 run_lib.py:133] step: 121350, training_loss: 3.78257e-02
I0210 10:30:42.397717 22509476222784 run_lib.py:133] step: 121400, training_loss: 4.81867e-02
I0210 10:30:42.567797 22509476222784 run_lib.py:146] step: 121400, eval_loss: 3.57364e-02
I0210 10:31:01.127589 22509476222784 run_lib.py:133] step: 121450, training_loss: 4.06866e-02
I0210 10:31:19.734322 22509476222784 run_lib.py:133] step: 121500, training_loss: 3.82185e-02
I0210 10:31:20.098877 22509476222784 run_lib.py:146] step: 121500, eval_loss: 4.61520e-02
I0210 10:31:38.655709 22509476222784 run_lib.py:133] step: 121550, training_loss: 5.07890e-02
I0210 10:31:57.235337 22509476222784 run_lib.py:133] step: 121600, training_loss: 4.19175e-02
I0210 10:31:57.397619 22509476222784 run_lib.py:146] step: 121600, eval_loss: 3.56562e-02
I0210 10:32:15.969372 22509476222784 run_lib.py:133] step: 121650, training_loss: 4.62984e-02
I0210 10:32:34.559926 22509476222784 run_lib.py:133] step: 121700, training_loss: 5.40346e-02
I0210 10:32:34.726096 22509476222784 run_lib.py:146] step: 121700, eval_loss: 4.63034e-02
I0210 10:32:53.480055 22509476222784 run_lib.py:133] step: 121750, training_loss: 3.48845e-02
I0210 10:33:12.271524 22509476222784 run_lib.py:133] step: 121800, training_loss: 3.84116e-02
I0210 10:33:12.436775 22509476222784 run_lib.py:146] step: 121800, eval_loss: 5.69266e-02
I0210 10:33:31.001973 22509476222784 run_lib.py:133] step: 121850, training_loss: 4.03940e-02
I0210 10:33:49.561115 22509476222784 run_lib.py:133] step: 121900, training_loss: 4.72092e-02
I0210 10:33:49.725764 22509476222784 run_lib.py:146] step: 121900, eval_loss: 5.22289e-02
I0210 10:34:08.435353 22509476222784 run_lib.py:133] step: 121950, training_loss: 3.67842e-02
I0210 10:34:27.082516 22509476222784 run_lib.py:133] step: 122000, training_loss: 4.27178e-02
I0210 10:34:27.245463 22509476222784 run_lib.py:146] step: 122000, eval_loss: 4.53278e-02
I0210 10:34:45.886882 22509476222784 run_lib.py:133] step: 122050, training_loss: 4.35856e-02
I0210 10:35:04.461939 22509476222784 run_lib.py:133] step: 122100, training_loss: 3.76705e-02
I0210 10:35:04.624897 22509476222784 run_lib.py:146] step: 122100, eval_loss: 4.37255e-02
I0210 10:35:23.357939 22509476222784 run_lib.py:133] step: 122150, training_loss: 4.69688e-02
I0210 10:35:41.957765 22509476222784 run_lib.py:133] step: 122200, training_loss: 4.53910e-02
I0210 10:35:42.123907 22509476222784 run_lib.py:146] step: 122200, eval_loss: 3.64338e-02
I0210 10:36:00.907886 22509476222784 run_lib.py:133] step: 122250, training_loss: 4.98740e-02
I0210 10:36:19.556236 22509476222784 run_lib.py:133] step: 122300, training_loss: 3.94579e-02
I0210 10:36:19.722974 22509476222784 run_lib.py:146] step: 122300, eval_loss: 4.86450e-02
I0210 10:36:38.557074 22509476222784 run_lib.py:133] step: 122350, training_loss: 4.34747e-02
I0210 10:36:57.113374 22509476222784 run_lib.py:133] step: 122400, training_loss: 4.26464e-02
I0210 10:36:57.283719 22509476222784 run_lib.py:146] step: 122400, eval_loss: 4.38544e-02
I0210 10:37:15.881946 22509476222784 run_lib.py:133] step: 122450, training_loss: 3.27581e-02
I0210 10:37:34.627514 22509476222784 run_lib.py:133] step: 122500, training_loss: 4.37629e-02
I0210 10:37:34.791971 22509476222784 run_lib.py:146] step: 122500, eval_loss: 3.71601e-02
I0210 10:37:53.471398 22509476222784 run_lib.py:133] step: 122550, training_loss: 5.38218e-02
I0210 10:38:12.241136 22509476222784 run_lib.py:133] step: 122600, training_loss: 5.03703e-02
I0210 10:38:12.405669 22509476222784 run_lib.py:146] step: 122600, eval_loss: 5.79801e-02
I0210 10:38:30.957860 22509476222784 run_lib.py:133] step: 122650, training_loss: 3.87988e-02
I0210 10:38:49.503679 22509476222784 run_lib.py:133] step: 122700, training_loss: 3.70036e-02
I0210 10:38:49.669904 22509476222784 run_lib.py:146] step: 122700, eval_loss: 4.32517e-02
I0210 10:39:08.211774 22509476222784 run_lib.py:133] step: 122750, training_loss: 3.94574e-02
I0210 10:39:26.979238 22509476222784 run_lib.py:133] step: 122800, training_loss: 4.55594e-02
I0210 10:39:27.148791 22509476222784 run_lib.py:146] step: 122800, eval_loss: 4.42823e-02
I0210 10:39:45.698168 22509476222784 run_lib.py:133] step: 122850, training_loss: 4.39591e-02
I0210 10:40:04.253518 22509476222784 run_lib.py:133] step: 122900, training_loss: 3.29356e-02
I0210 10:40:04.418742 22509476222784 run_lib.py:146] step: 122900, eval_loss: 4.30812e-02
I0210 10:40:23.189169 22509476222784 run_lib.py:133] step: 122950, training_loss: 4.67851e-02
I0210 10:40:41.730627 22509476222784 run_lib.py:133] step: 123000, training_loss: 4.34084e-02
I0210 10:40:41.891656 22509476222784 run_lib.py:146] step: 123000, eval_loss: 3.73248e-02
I0210 10:41:00.518572 22509476222784 run_lib.py:133] step: 123050, training_loss: 3.61544e-02
I0210 10:41:19.104577 22509476222784 run_lib.py:133] step: 123100, training_loss: 4.52842e-02
I0210 10:41:19.277700 22509476222784 run_lib.py:146] step: 123100, eval_loss: 3.43303e-02
I0210 10:41:37.856646 22509476222784 run_lib.py:133] step: 123150, training_loss: 4.21486e-02
I0210 10:41:56.458216 22509476222784 run_lib.py:133] step: 123200, training_loss: 2.86873e-02
I0210 10:41:56.623829 22509476222784 run_lib.py:146] step: 123200, eval_loss: 4.19686e-02
I0210 10:42:15.359804 22509476222784 run_lib.py:133] step: 123250, training_loss: 3.82146e-02
I0210 10:42:34.042165 22509476222784 run_lib.py:133] step: 123300, training_loss: 5.25497e-02
I0210 10:42:34.210904 22509476222784 run_lib.py:146] step: 123300, eval_loss: 3.90238e-02
I0210 10:42:52.796336 22509476222784 run_lib.py:133] step: 123350, training_loss: 4.96123e-02
I0210 10:43:11.383019 22509476222784 run_lib.py:133] step: 123400, training_loss: 5.25409e-02
I0210 10:43:11.545629 22509476222784 run_lib.py:146] step: 123400, eval_loss: 4.74803e-02
I0210 10:43:30.279252 22509476222784 run_lib.py:133] step: 123450, training_loss: 4.08396e-02
I0210 10:43:48.792895 22509476222784 run_lib.py:133] step: 123500, training_loss: 5.44794e-02
I0210 10:43:48.955655 22509476222784 run_lib.py:146] step: 123500, eval_loss: 4.36748e-02
I0210 10:44:07.706489 22509476222784 run_lib.py:133] step: 123550, training_loss: 3.76300e-02
I0210 10:44:26.323779 22509476222784 run_lib.py:133] step: 123600, training_loss: 4.14226e-02
I0210 10:44:26.503804 22509476222784 run_lib.py:146] step: 123600, eval_loss: 4.26899e-02
I0210 10:44:45.193547 22509476222784 run_lib.py:133] step: 123650, training_loss: 4.80514e-02
I0210 10:45:03.679800 22509476222784 run_lib.py:133] step: 123700, training_loss: 4.71828e-02
I0210 10:45:03.843469 22509476222784 run_lib.py:146] step: 123700, eval_loss: 5.34443e-02
I0210 10:45:22.482209 22509476222784 run_lib.py:133] step: 123750, training_loss: 4.71718e-02
I0210 10:45:40.914445 22509476222784 run_lib.py:133] step: 123800, training_loss: 4.09791e-02
I0210 10:45:41.109649 22509476222784 run_lib.py:146] step: 123800, eval_loss: 4.18618e-02
I0210 10:45:59.599819 22509476222784 run_lib.py:133] step: 123850, training_loss: 4.04191e-02
I0210 10:46:18.187951 22509476222784 run_lib.py:133] step: 123900, training_loss: 4.54821e-02
I0210 10:46:18.350096 22509476222784 run_lib.py:146] step: 123900, eval_loss: 4.36692e-02
I0210 10:46:36.836525 22509476222784 run_lib.py:133] step: 123950, training_loss: 4.62219e-02
I0210 10:46:55.302436 22509476222784 run_lib.py:133] step: 124000, training_loss: 4.36938e-02
I0210 10:46:55.464616 22509476222784 run_lib.py:146] step: 124000, eval_loss: 5.48555e-02
I0210 10:47:14.026879 22509476222784 run_lib.py:133] step: 124050, training_loss: 4.92041e-02
I0210 10:47:32.686978 22509476222784 run_lib.py:133] step: 124100, training_loss: 4.10569e-02
I0210 10:47:32.862566 22509476222784 run_lib.py:146] step: 124100, eval_loss: 3.23828e-02
I0210 10:47:51.375753 22509476222784 run_lib.py:133] step: 124150, training_loss: 4.64902e-02
I0210 10:48:09.911255 22509476222784 run_lib.py:133] step: 124200, training_loss: 4.29983e-02
I0210 10:48:10.076811 22509476222784 run_lib.py:146] step: 124200, eval_loss: 3.47117e-02
I0210 10:48:28.560353 22509476222784 run_lib.py:133] step: 124250, training_loss: 4.47311e-02
I0210 10:48:47.183861 22509476222784 run_lib.py:133] step: 124300, training_loss: 3.24492e-02
I0210 10:48:47.349556 22509476222784 run_lib.py:146] step: 124300, eval_loss: 3.63506e-02
I0210 10:49:05.807726 22509476222784 run_lib.py:133] step: 124350, training_loss: 2.73652e-02
I0210 10:49:24.324646 22509476222784 run_lib.py:133] step: 124400, training_loss: 4.41008e-02
I0210 10:49:24.486858 22509476222784 run_lib.py:146] step: 124400, eval_loss: 4.07862e-02
I0210 10:49:42.985025 22509476222784 run_lib.py:133] step: 124450, training_loss: 6.19042e-02
I0210 10:50:01.642808 22509476222784 run_lib.py:133] step: 124500, training_loss: 4.44326e-02
I0210 10:50:01.833566 22509476222784 run_lib.py:146] step: 124500, eval_loss: 4.66367e-02
I0210 10:50:20.269733 22509476222784 run_lib.py:133] step: 124550, training_loss: 4.24219e-02
I0210 10:50:38.831399 22509476222784 run_lib.py:133] step: 124600, training_loss: 4.39659e-02
I0210 10:50:39.013526 22509476222784 run_lib.py:146] step: 124600, eval_loss: 5.35721e-02
I0210 10:50:57.423698 22509476222784 run_lib.py:133] step: 124650, training_loss: 4.91921e-02
I0210 10:51:15.910370 22509476222784 run_lib.py:133] step: 124700, training_loss: 4.87504e-02
I0210 10:51:16.076776 22509476222784 run_lib.py:146] step: 124700, eval_loss: 4.97413e-02
I0210 10:51:34.784670 22509476222784 run_lib.py:133] step: 124750, training_loss: 4.19892e-02
I0210 10:51:53.297188 22509476222784 run_lib.py:133] step: 124800, training_loss: 5.46219e-02
I0210 10:51:53.466927 22509476222784 run_lib.py:146] step: 124800, eval_loss: 3.42280e-02
I0210 10:52:11.942600 22509476222784 run_lib.py:133] step: 124850, training_loss: 3.91941e-02
I0210 10:52:30.470304 22509476222784 run_lib.py:133] step: 124900, training_loss: 6.08665e-02
I0210 10:52:30.642809 22509476222784 run_lib.py:146] step: 124900, eval_loss: 3.86995e-02
I0210 10:52:49.353335 22509476222784 run_lib.py:133] step: 124950, training_loss: 3.92540e-02
I0210 10:53:07.750446 22509476222784 run_lib.py:133] step: 125000, training_loss: 4.12796e-02
I0210 10:53:07.914787 22509476222784 run_lib.py:146] step: 125000, eval_loss: 4.33530e-02
I0210 10:53:26.523624 22509476222784 run_lib.py:133] step: 125050, training_loss: 4.28643e-02
I0210 10:53:45.017537 22509476222784 run_lib.py:133] step: 125100, training_loss: 3.81438e-02
I0210 10:53:45.182962 22509476222784 run_lib.py:146] step: 125100, eval_loss: 4.10469e-02
I0210 10:54:03.815068 22509476222784 run_lib.py:133] step: 125150, training_loss: 3.46450e-02
I0210 10:54:22.332224 22509476222784 run_lib.py:133] step: 125200, training_loss: 3.96865e-02
I0210 10:54:22.498347 22509476222784 run_lib.py:146] step: 125200, eval_loss: 4.26987e-02
I0210 10:54:40.960272 22509476222784 run_lib.py:133] step: 125250, training_loss: 3.94579e-02
I0210 10:54:59.603159 22509476222784 run_lib.py:133] step: 125300, training_loss: 5.52240e-02
I0210 10:54:59.766545 22509476222784 run_lib.py:146] step: 125300, eval_loss: 2.38227e-02
I0210 10:55:18.256737 22509476222784 run_lib.py:133] step: 125350, training_loss: 4.89622e-02
I0210 10:55:36.915910 22509476222784 run_lib.py:133] step: 125400, training_loss: 4.46871e-02
I0210 10:55:37.081835 22509476222784 run_lib.py:146] step: 125400, eval_loss: 4.56427e-02
I0210 10:55:55.611750 22509476222784 run_lib.py:133] step: 125450, training_loss: 4.00290e-02
I0210 10:56:14.099407 22509476222784 run_lib.py:133] step: 125500, training_loss: 4.74638e-02
I0210 10:56:14.264688 22509476222784 run_lib.py:146] step: 125500, eval_loss: 3.38633e-02
I0210 10:56:32.930903 22509476222784 run_lib.py:133] step: 125550, training_loss: 4.89867e-02
I0210 10:56:51.500714 22509476222784 run_lib.py:133] step: 125600, training_loss: 4.10693e-02
I0210 10:56:51.664648 22509476222784 run_lib.py:146] step: 125600, eval_loss: 3.45093e-02
I0210 10:57:10.144992 22509476222784 run_lib.py:133] step: 125650, training_loss: 5.88449e-02
I0210 10:57:28.814693 22509476222784 run_lib.py:133] step: 125700, training_loss: 3.99609e-02
I0210 10:57:28.978454 22509476222784 run_lib.py:146] step: 125700, eval_loss: 4.51737e-02
I0210 10:57:47.501071 22509476222784 run_lib.py:133] step: 125750, training_loss: 5.12877e-02
I0210 10:58:05.957569 22509476222784 run_lib.py:133] step: 125800, training_loss: 6.15628e-02
I0210 10:58:06.119623 22509476222784 run_lib.py:146] step: 125800, eval_loss: 5.45765e-02
I0210 10:58:24.690459 22509476222784 run_lib.py:133] step: 125850, training_loss: 4.03032e-02
I0210 10:58:43.173620 22509476222784 run_lib.py:133] step: 125900, training_loss: 6.31821e-02
I0210 10:58:43.338734 22509476222784 run_lib.py:146] step: 125900, eval_loss: 4.90684e-02
I0210 10:59:01.876221 22509476222784 run_lib.py:133] step: 125950, training_loss: 3.84655e-02
I0210 10:59:20.311779 22509476222784 run_lib.py:133] step: 126000, training_loss: 4.36110e-02
I0210 10:59:20.477501 22509476222784 run_lib.py:146] step: 126000, eval_loss: 3.62355e-02
I0210 10:59:39.095679 22509476222784 run_lib.py:133] step: 126050, training_loss: 4.66171e-02
I0210 10:59:57.644876 22509476222784 run_lib.py:133] step: 126100, training_loss: 4.21247e-02
I0210 10:59:57.867568 22509476222784 run_lib.py:146] step: 126100, eval_loss: 4.43625e-02
I0210 11:00:16.322310 22509476222784 run_lib.py:133] step: 126150, training_loss: 4.09497e-02
I0210 11:00:34.889326 22509476222784 run_lib.py:133] step: 126200, training_loss: 3.76858e-02
I0210 11:00:35.053916 22509476222784 run_lib.py:146] step: 126200, eval_loss: 4.78210e-02
I0210 11:00:53.881123 22509476222784 run_lib.py:133] step: 126250, training_loss: 5.48486e-02
I0210 11:01:12.413789 22509476222784 run_lib.py:133] step: 126300, training_loss: 4.63723e-02
I0210 11:01:12.583258 22509476222784 run_lib.py:146] step: 126300, eval_loss: 4.38340e-02
I0210 11:01:31.309763 22509476222784 run_lib.py:133] step: 126350, training_loss: 4.09061e-02
I0210 11:01:49.888691 22509476222784 run_lib.py:133] step: 126400, training_loss: 3.84541e-02
I0210 11:01:50.053557 22509476222784 run_lib.py:146] step: 126400, eval_loss: 5.05543e-02
I0210 11:02:08.797298 22509476222784 run_lib.py:133] step: 126450, training_loss: 4.25059e-02
I0210 11:02:27.463047 22509476222784 run_lib.py:133] step: 126500, training_loss: 6.10704e-02
I0210 11:02:27.629588 22509476222784 run_lib.py:146] step: 126500, eval_loss: 4.11918e-02
I0210 11:02:46.414749 22509476222784 run_lib.py:133] step: 126550, training_loss: 4.70807e-02
I0210 11:03:04.985627 22509476222784 run_lib.py:133] step: 126600, training_loss: 4.53633e-02
I0210 11:03:05.149556 22509476222784 run_lib.py:146] step: 126600, eval_loss: 4.77101e-02
I0210 11:03:23.722758 22509476222784 run_lib.py:133] step: 126650, training_loss: 5.83768e-02
I0210 11:03:42.438190 22509476222784 run_lib.py:133] step: 126700, training_loss: 5.04131e-02
I0210 11:03:42.601633 22509476222784 run_lib.py:146] step: 126700, eval_loss: 4.36081e-02
I0210 11:04:01.234888 22509476222784 run_lib.py:133] step: 126750, training_loss: 4.89835e-02
I0210 11:04:19.826493 22509476222784 run_lib.py:133] step: 126800, training_loss: 4.32787e-02
I0210 11:04:20.019713 22509476222784 run_lib.py:146] step: 126800, eval_loss: 4.19223e-02
I0210 11:04:38.836519 22509476222784 run_lib.py:133] step: 126850, training_loss: 5.01306e-02
I0210 11:04:57.434158 22509476222784 run_lib.py:133] step: 126900, training_loss: 3.19342e-02
I0210 11:04:57.599907 22509476222784 run_lib.py:146] step: 126900, eval_loss: 3.33396e-02
I0210 11:05:16.292432 22509476222784 run_lib.py:133] step: 126950, training_loss: 2.93660e-02
I0210 11:05:34.871096 22509476222784 run_lib.py:133] step: 127000, training_loss: 3.89000e-02
I0210 11:05:35.047921 22509476222784 run_lib.py:146] step: 127000, eval_loss: 5.08376e-02
I0210 11:05:53.657582 22509476222784 run_lib.py:133] step: 127050, training_loss: 3.77548e-02
I0210 11:06:12.470691 22509476222784 run_lib.py:133] step: 127100, training_loss: 4.31765e-02
I0210 11:06:12.635562 22509476222784 run_lib.py:146] step: 127100, eval_loss: 4.45559e-02
I0210 11:06:31.243895 22509476222784 run_lib.py:133] step: 127150, training_loss: 4.44216e-02
I0210 11:06:49.790611 22509476222784 run_lib.py:133] step: 127200, training_loss: 4.57985e-02
I0210 11:06:49.953766 22509476222784 run_lib.py:146] step: 127200, eval_loss: 2.86930e-02
I0210 11:07:08.517265 22509476222784 run_lib.py:133] step: 127250, training_loss: 4.74741e-02
I0210 11:07:27.269127 22509476222784 run_lib.py:133] step: 127300, training_loss: 4.56658e-02
I0210 11:07:27.436019 22509476222784 run_lib.py:146] step: 127300, eval_loss: 5.75439e-02
I0210 11:07:46.015754 22509476222784 run_lib.py:133] step: 127350, training_loss: 5.33547e-02
I0210 11:08:04.699418 22509476222784 run_lib.py:133] step: 127400, training_loss: 3.95904e-02
I0210 11:08:04.864914 22509476222784 run_lib.py:146] step: 127400, eval_loss: 4.90080e-02
I0210 11:08:23.410512 22509476222784 run_lib.py:133] step: 127450, training_loss: 4.92832e-02
I0210 11:08:41.936023 22509476222784 run_lib.py:133] step: 127500, training_loss: 4.80259e-02
I0210 11:08:42.101661 22509476222784 run_lib.py:146] step: 127500, eval_loss: 3.30247e-02
I0210 11:09:00.812544 22509476222784 run_lib.py:133] step: 127550, training_loss: 3.68735e-02
I0210 11:09:19.526149 22509476222784 run_lib.py:133] step: 127600, training_loss: 3.76550e-02
I0210 11:09:19.692338 22509476222784 run_lib.py:146] step: 127600, eval_loss: 3.18900e-02
I0210 11:09:38.277126 22509476222784 run_lib.py:133] step: 127650, training_loss: 3.92964e-02
I0210 11:09:56.828068 22509476222784 run_lib.py:133] step: 127700, training_loss: 4.27724e-02
I0210 11:09:57.005623 22509476222784 run_lib.py:146] step: 127700, eval_loss: 4.59226e-02
I0210 11:10:15.688879 22509476222784 run_lib.py:133] step: 127750, training_loss: 4.43364e-02
I0210 11:10:34.192167 22509476222784 run_lib.py:133] step: 127800, training_loss: 4.01223e-02
I0210 11:10:34.364861 22509476222784 run_lib.py:146] step: 127800, eval_loss: 3.47233e-02
I0210 11:10:53.193658 22509476222784 run_lib.py:133] step: 127850, training_loss: 4.27391e-02
I0210 11:11:11.796195 22509476222784 run_lib.py:133] step: 127900, training_loss: 4.14348e-02
I0210 11:11:11.968738 22509476222784 run_lib.py:146] step: 127900, eval_loss: 3.54788e-02
I0210 11:11:30.704056 22509476222784 run_lib.py:133] step: 127950, training_loss: 3.25785e-02
I0210 11:11:49.221872 22509476222784 run_lib.py:133] step: 128000, training_loss: 4.25095e-02
I0210 11:11:49.385619 22509476222784 run_lib.py:146] step: 128000, eval_loss: 5.47944e-02
I0210 11:12:07.935906 22509476222784 run_lib.py:133] step: 128050, training_loss: 3.58310e-02
I0210 11:12:26.754582 22509476222784 run_lib.py:133] step: 128100, training_loss: 3.89012e-02
I0210 11:12:26.919976 22509476222784 run_lib.py:146] step: 128100, eval_loss: 3.95027e-02
I0210 11:12:45.513043 22509476222784 run_lib.py:133] step: 128150, training_loss: 5.82318e-02
I0210 11:13:04.223392 22509476222784 run_lib.py:133] step: 128200, training_loss: 3.18952e-02
I0210 11:13:04.384448 22509476222784 run_lib.py:146] step: 128200, eval_loss: 3.42687e-02
I0210 11:13:22.965662 22509476222784 run_lib.py:133] step: 128250, training_loss: 5.05204e-02
I0210 11:13:41.517258 22509476222784 run_lib.py:133] step: 128300, training_loss: 4.87334e-02
I0210 11:13:41.683756 22509476222784 run_lib.py:146] step: 128300, eval_loss: 4.32148e-02
I0210 11:14:00.445021 22509476222784 run_lib.py:133] step: 128350, training_loss: 3.99050e-02
I0210 11:14:19.031690 22509476222784 run_lib.py:133] step: 128400, training_loss: 3.74534e-02
I0210 11:14:19.198667 22509476222784 run_lib.py:146] step: 128400, eval_loss: 3.31963e-02
I0210 11:14:37.725605 22509476222784 run_lib.py:133] step: 128450, training_loss: 4.27794e-02
I0210 11:14:56.505109 22509476222784 run_lib.py:133] step: 128500, training_loss: 3.52599e-02
I0210 11:14:56.669739 22509476222784 run_lib.py:146] step: 128500, eval_loss: 2.83520e-02
I0210 11:15:15.191483 22509476222784 run_lib.py:133] step: 128550, training_loss: 4.24427e-02
I0210 11:15:33.704257 22509476222784 run_lib.py:133] step: 128600, training_loss: 4.36574e-02
I0210 11:15:34.023836 22509476222784 run_lib.py:146] step: 128600, eval_loss: 4.49094e-02
I0210 11:15:52.650406 22509476222784 run_lib.py:133] step: 128650, training_loss: 5.04012e-02
I0210 11:16:11.244004 22509476222784 run_lib.py:133] step: 128700, training_loss: 3.95094e-02
I0210 11:16:11.407744 22509476222784 run_lib.py:146] step: 128700, eval_loss: 4.47373e-02
I0210 11:16:29.991896 22509476222784 run_lib.py:133] step: 128750, training_loss: 3.82238e-02
I0210 11:16:48.564212 22509476222784 run_lib.py:133] step: 128800, training_loss: 3.84540e-02
I0210 11:16:48.731006 22509476222784 run_lib.py:146] step: 128800, eval_loss: 4.26128e-02
I0210 11:17:07.443607 22509476222784 run_lib.py:133] step: 128850, training_loss: 3.65047e-02
I0210 11:17:26.134081 22509476222784 run_lib.py:133] step: 128900, training_loss: 4.76666e-02
I0210 11:17:26.314723 22509476222784 run_lib.py:146] step: 128900, eval_loss: 4.11425e-02
I0210 11:17:44.941101 22509476222784 run_lib.py:133] step: 128950, training_loss: 4.99948e-02
I0210 11:18:03.544178 22509476222784 run_lib.py:133] step: 129000, training_loss: 4.01173e-02
I0210 11:18:03.708956 22509476222784 run_lib.py:146] step: 129000, eval_loss: 3.75374e-02
I0210 11:18:22.538123 22509476222784 run_lib.py:133] step: 129050, training_loss: 4.35149e-02
I0210 11:18:41.163562 22509476222784 run_lib.py:133] step: 129100, training_loss: 4.44754e-02
I0210 11:18:41.326689 22509476222784 run_lib.py:146] step: 129100, eval_loss: 4.08286e-02
I0210 11:18:59.894371 22509476222784 run_lib.py:133] step: 129150, training_loss: 3.74729e-02
I0210 11:19:18.515492 22509476222784 run_lib.py:133] step: 129200, training_loss: 3.90944e-02
I0210 11:19:18.688648 22509476222784 run_lib.py:146] step: 129200, eval_loss: 4.83351e-02
I0210 11:19:37.489430 22509476222784 run_lib.py:133] step: 129250, training_loss: 4.39836e-02
I0210 11:19:56.118286 22509476222784 run_lib.py:133] step: 129300, training_loss: 3.63946e-02
I0210 11:19:56.297053 22509476222784 run_lib.py:146] step: 129300, eval_loss: 3.64801e-02
I0210 11:20:14.984479 22509476222784 run_lib.py:133] step: 129350, training_loss: 6.01645e-02
I0210 11:20:33.562771 22509476222784 run_lib.py:133] step: 129400, training_loss: 4.89626e-02
I0210 11:20:33.805702 22509476222784 run_lib.py:146] step: 129400, eval_loss: 3.38924e-02
I0210 11:20:52.620449 22509476222784 run_lib.py:133] step: 129450, training_loss: 4.00060e-02
I0210 11:21:11.189018 22509476222784 run_lib.py:133] step: 129500, training_loss: 4.25154e-02
I0210 11:21:11.353468 22509476222784 run_lib.py:146] step: 129500, eval_loss: 3.23100e-02
I0210 11:21:29.911871 22509476222784 run_lib.py:133] step: 129550, training_loss: 5.11185e-02
I0210 11:21:48.611229 22509476222784 run_lib.py:133] step: 129600, training_loss: 4.31533e-02
I0210 11:21:48.778355 22509476222784 run_lib.py:146] step: 129600, eval_loss: 3.85684e-02
I0210 11:22:07.361400 22509476222784 run_lib.py:133] step: 129650, training_loss: 4.98060e-02
I0210 11:22:26.064050 22509476222784 run_lib.py:133] step: 129700, training_loss: 3.92592e-02
I0210 11:22:26.320848 22509476222784 run_lib.py:146] step: 129700, eval_loss: 4.02284e-02
I0210 11:22:44.918445 22509476222784 run_lib.py:133] step: 129750, training_loss: 4.70265e-02
I0210 11:23:03.526210 22509476222784 run_lib.py:133] step: 129800, training_loss: 3.70450e-02
I0210 11:23:03.692665 22509476222784 run_lib.py:146] step: 129800, eval_loss: 3.68544e-02
I0210 11:23:22.420557 22509476222784 run_lib.py:133] step: 129850, training_loss: 4.09772e-02
I0210 11:23:40.932730 22509476222784 run_lib.py:133] step: 129900, training_loss: 4.20549e-02
I0210 11:23:41.098654 22509476222784 run_lib.py:146] step: 129900, eval_loss: 4.66507e-02
I0210 11:23:59.647022 22509476222784 run_lib.py:133] step: 129950, training_loss: 5.84785e-02
I0210 11:24:18.312767 22509476222784 run_lib.py:133] step: 130000, training_loss: 3.12594e-02
I0210 11:24:19.711817 22509476222784 run_lib.py:146] step: 130000, eval_loss: 5.34997e-02
I0210 11:24:41.596224 22509476222784 run_lib.py:133] step: 130050, training_loss: 4.52151e-02
I0210 11:25:00.335572 22509476222784 run_lib.py:133] step: 130100, training_loss: 3.69727e-02
I0210 11:25:00.499754 22509476222784 run_lib.py:146] step: 130100, eval_loss: 3.69867e-02
I0210 11:25:19.035754 22509476222784 run_lib.py:133] step: 130150, training_loss: 3.68649e-02
I0210 11:25:37.596894 22509476222784 run_lib.py:133] step: 130200, training_loss: 5.38877e-02
I0210 11:25:37.764738 22509476222784 run_lib.py:146] step: 130200, eval_loss: 4.10448e-02
I0210 11:25:56.530522 22509476222784 run_lib.py:133] step: 130250, training_loss: 4.70860e-02
I0210 11:26:15.111468 22509476222784 run_lib.py:133] step: 130300, training_loss: 3.75555e-02
I0210 11:26:15.276302 22509476222784 run_lib.py:146] step: 130300, eval_loss: 4.17315e-02
I0210 11:26:33.815475 22509476222784 run_lib.py:133] step: 130350, training_loss: 5.09239e-02
I0210 11:26:52.369750 22509476222784 run_lib.py:133] step: 130400, training_loss: 5.53804e-02
I0210 11:26:52.534066 22509476222784 run_lib.py:146] step: 130400, eval_loss: 4.30781e-02
I0210 11:27:11.303903 22509476222784 run_lib.py:133] step: 130450, training_loss: 3.92704e-02
I0210 11:27:29.975739 22509476222784 run_lib.py:133] step: 130500, training_loss: 3.74175e-02
I0210 11:27:30.142278 22509476222784 run_lib.py:146] step: 130500, eval_loss: 4.26863e-02
I0210 11:27:48.884145 22509476222784 run_lib.py:133] step: 130550, training_loss: 4.95408e-02
I0210 11:28:07.412955 22509476222784 run_lib.py:133] step: 130600, training_loss: 5.46099e-02
I0210 11:28:07.577324 22509476222784 run_lib.py:146] step: 130600, eval_loss: 4.07202e-02
I0210 11:28:26.152609 22509476222784 run_lib.py:133] step: 130650, training_loss: 4.75106e-02
I0210 11:28:44.700442 22509476222784 run_lib.py:133] step: 130700, training_loss: 5.80811e-02
I0210 11:28:44.862739 22509476222784 run_lib.py:146] step: 130700, eval_loss: 4.72668e-02
I0210 11:29:03.559049 22509476222784 run_lib.py:133] step: 130750, training_loss: 4.00748e-02
I0210 11:29:22.244996 22509476222784 run_lib.py:133] step: 130800, training_loss: 4.61712e-02
I0210 11:29:22.421677 22509476222784 run_lib.py:146] step: 130800, eval_loss: 4.19281e-02
I0210 11:29:41.005666 22509476222784 run_lib.py:133] step: 130850, training_loss: 3.85182e-02
I0210 11:29:59.526513 22509476222784 run_lib.py:133] step: 130900, training_loss: 2.56885e-02
I0210 11:29:59.707903 22509476222784 run_lib.py:146] step: 130900, eval_loss: 3.23992e-02
I0210 11:30:18.468817 22509476222784 run_lib.py:133] step: 130950, training_loss: 3.60035e-02
I0210 11:30:37.015273 22509476222784 run_lib.py:133] step: 131000, training_loss: 4.09462e-02
I0210 11:30:37.190749 22509476222784 run_lib.py:146] step: 131000, eval_loss: 4.46758e-02
I0210 11:30:55.993334 22509476222784 run_lib.py:133] step: 131050, training_loss: 3.95224e-02
I0210 11:31:14.562955 22509476222784 run_lib.py:133] step: 131100, training_loss: 3.73373e-02
I0210 11:31:14.727952 22509476222784 run_lib.py:146] step: 131100, eval_loss: 4.96098e-02
I0210 11:31:33.505923 22509476222784 run_lib.py:133] step: 131150, training_loss: 4.29818e-02
I0210 11:31:52.073863 22509476222784 run_lib.py:133] step: 131200, training_loss: 6.32183e-02
I0210 11:31:52.244668 22509476222784 run_lib.py:146] step: 131200, eval_loss: 3.61652e-02
I0210 11:32:10.932186 22509476222784 run_lib.py:133] step: 131250, training_loss: 4.65065e-02
I0210 11:32:29.525466 22509476222784 run_lib.py:133] step: 131300, training_loss: 4.13448e-02
I0210 11:32:29.704655 22509476222784 run_lib.py:146] step: 131300, eval_loss: 4.39584e-02
I0210 11:32:48.338102 22509476222784 run_lib.py:133] step: 131350, training_loss: 3.67004e-02
I0210 11:33:07.175557 22509476222784 run_lib.py:133] step: 131400, training_loss: 5.38065e-02
I0210 11:33:07.346938 22509476222784 run_lib.py:146] step: 131400, eval_loss: 4.23760e-02
I0210 11:33:25.915140 22509476222784 run_lib.py:133] step: 131450, training_loss: 4.08543e-02
I0210 11:33:44.448222 22509476222784 run_lib.py:133] step: 131500, training_loss: 4.08478e-02
I0210 11:33:44.613665 22509476222784 run_lib.py:146] step: 131500, eval_loss: 3.98439e-02
I0210 11:34:03.339120 22509476222784 run_lib.py:133] step: 131550, training_loss: 3.35458e-02
I0210 11:34:21.974417 22509476222784 run_lib.py:133] step: 131600, training_loss: 4.11344e-02
I0210 11:34:22.138824 22509476222784 run_lib.py:146] step: 131600, eval_loss: 3.78280e-02
I0210 11:34:40.938723 22509476222784 run_lib.py:133] step: 131650, training_loss: 5.12886e-02
I0210 11:34:59.504013 22509476222784 run_lib.py:133] step: 131700, training_loss: 5.10571e-02
I0210 11:34:59.670771 22509476222784 run_lib.py:146] step: 131700, eval_loss: 3.91672e-02
I0210 11:35:18.254659 22509476222784 run_lib.py:133] step: 131750, training_loss: 3.41446e-02
I0210 11:35:37.022637 22509476222784 run_lib.py:133] step: 131800, training_loss: 4.35880e-02
I0210 11:35:37.204821 22509476222784 run_lib.py:146] step: 131800, eval_loss: 4.38279e-02
I0210 11:35:55.757241 22509476222784 run_lib.py:133] step: 131850, training_loss: 5.01660e-02
I0210 11:36:14.318076 22509476222784 run_lib.py:133] step: 131900, training_loss: 3.97981e-02
I0210 11:36:14.484035 22509476222784 run_lib.py:146] step: 131900, eval_loss: 5.03559e-02
I0210 11:36:33.057897 22509476222784 run_lib.py:133] step: 131950, training_loss: 4.59819e-02
I0210 11:36:51.805431 22509476222784 run_lib.py:133] step: 132000, training_loss: 4.91402e-02
I0210 11:36:51.968670 22509476222784 run_lib.py:146] step: 132000, eval_loss: 4.34508e-02
I0210 11:37:10.528618 22509476222784 run_lib.py:133] step: 132050, training_loss: 3.59016e-02
I0210 11:37:29.192572 22509476222784 run_lib.py:133] step: 132100, training_loss: 3.66881e-02
I0210 11:37:29.359756 22509476222784 run_lib.py:146] step: 132100, eval_loss: 4.49555e-02
I0210 11:37:47.963798 22509476222784 run_lib.py:133] step: 132150, training_loss: 5.16985e-02
I0210 11:38:06.519823 22509476222784 run_lib.py:133] step: 132200, training_loss: 3.76217e-02
I0210 11:38:06.686986 22509476222784 run_lib.py:146] step: 132200, eval_loss: 4.30891e-02
I0210 11:38:25.405052 22509476222784 run_lib.py:133] step: 132250, training_loss: 5.00024e-02
I0210 11:38:44.059043 22509476222784 run_lib.py:133] step: 132300, training_loss: 3.95977e-02
I0210 11:38:44.222888 22509476222784 run_lib.py:146] step: 132300, eval_loss: 3.63247e-02
I0210 11:39:02.799841 22509476222784 run_lib.py:133] step: 132350, training_loss: 5.07200e-02
I0210 11:39:21.413300 22509476222784 run_lib.py:133] step: 132400, training_loss: 4.90287e-02
I0210 11:39:21.578415 22509476222784 run_lib.py:146] step: 132400, eval_loss: 4.69213e-02
I0210 11:39:40.303513 22509476222784 run_lib.py:133] step: 132450, training_loss: 4.27116e-02
I0210 11:39:58.834278 22509476222784 run_lib.py:133] step: 132500, training_loss: 4.22762e-02
I0210 11:39:59.012384 22509476222784 run_lib.py:146] step: 132500, eval_loss: 3.55512e-02
I0210 11:40:17.711193 22509476222784 run_lib.py:133] step: 132550, training_loss: 4.25023e-02
I0210 11:40:36.267549 22509476222784 run_lib.py:133] step: 132600, training_loss: 5.65312e-02
I0210 11:40:36.438901 22509476222784 run_lib.py:146] step: 132600, eval_loss: 5.85121e-02
I0210 11:40:55.249150 22509476222784 run_lib.py:133] step: 132650, training_loss: 4.38538e-02
I0210 11:41:13.856143 22509476222784 run_lib.py:133] step: 132700, training_loss: 3.71527e-02
I0210 11:41:14.032675 22509476222784 run_lib.py:146] step: 132700, eval_loss: 5.13638e-02
I0210 11:41:32.584567 22509476222784 run_lib.py:133] step: 132750, training_loss: 5.20115e-02
I0210 11:41:51.338025 22509476222784 run_lib.py:133] step: 132800, training_loss: 3.26195e-02
I0210 11:41:51.502887 22509476222784 run_lib.py:146] step: 132800, eval_loss: 4.03946e-02
I0210 11:42:10.074288 22509476222784 run_lib.py:133] step: 132850, training_loss: 4.87992e-02
I0210 11:42:28.816778 22509476222784 run_lib.py:133] step: 132900, training_loss: 5.15686e-02
I0210 11:42:28.982398 22509476222784 run_lib.py:146] step: 132900, eval_loss: 4.74983e-02
I0210 11:42:47.589047 22509476222784 run_lib.py:133] step: 132950, training_loss: 2.86557e-02
I0210 11:43:06.160660 22509476222784 run_lib.py:133] step: 133000, training_loss: 3.50260e-02
I0210 11:43:06.322523 22509476222784 run_lib.py:146] step: 133000, eval_loss: 3.68992e-02
I0210 11:43:25.071441 22509476222784 run_lib.py:133] step: 133050, training_loss: 4.45493e-02
I0210 11:43:43.641330 22509476222784 run_lib.py:133] step: 133100, training_loss: 4.31128e-02
I0210 11:43:43.808658 22509476222784 run_lib.py:146] step: 133100, eval_loss: 4.35427e-02
I0210 11:44:02.459857 22509476222784 run_lib.py:133] step: 133150, training_loss: 4.09482e-02
I0210 11:44:21.294855 22509476222784 run_lib.py:133] step: 133200, training_loss: 3.71575e-02
I0210 11:44:21.461753 22509476222784 run_lib.py:146] step: 133200, eval_loss: 4.70549e-02
I0210 11:44:39.974525 22509476222784 run_lib.py:133] step: 133250, training_loss: 3.56444e-02
I0210 11:44:58.515959 22509476222784 run_lib.py:133] step: 133300, training_loss: 4.39345e-02
I0210 11:44:58.834615 22509476222784 run_lib.py:146] step: 133300, eval_loss: 4.01996e-02
I0210 11:45:17.430464 22509476222784 run_lib.py:133] step: 133350, training_loss: 4.85124e-02
I0210 11:45:36.082315 22509476222784 run_lib.py:133] step: 133400, training_loss: 4.23328e-02
I0210 11:45:36.246305 22509476222784 run_lib.py:146] step: 133400, eval_loss: 3.76854e-02
I0210 11:45:54.903178 22509476222784 run_lib.py:133] step: 133450, training_loss: 4.02047e-02
I0210 11:46:13.485441 22509476222784 run_lib.py:133] step: 133500, training_loss: 4.00103e-02
I0210 11:46:13.646749 22509476222784 run_lib.py:146] step: 133500, eval_loss: 5.26376e-02
I0210 11:46:32.385848 22509476222784 run_lib.py:133] step: 133550, training_loss: 3.88295e-02
I0210 11:46:51.016041 22509476222784 run_lib.py:133] step: 133600, training_loss: 5.19903e-02
I0210 11:46:51.180698 22509476222784 run_lib.py:146] step: 133600, eval_loss: 3.98350e-02
I0210 11:47:09.672564 22509476222784 run_lib.py:133] step: 133650, training_loss: 4.13685e-02
I0210 11:47:28.215193 22509476222784 run_lib.py:133] step: 133700, training_loss: 3.54218e-02
I0210 11:47:28.397692 22509476222784 run_lib.py:146] step: 133700, eval_loss: 3.85715e-02
I0210 11:47:47.198156 22509476222784 run_lib.py:133] step: 133750, training_loss: 3.48023e-02
I0210 11:48:05.815993 22509476222784 run_lib.py:133] step: 133800, training_loss: 4.67460e-02
I0210 11:48:05.981928 22509476222784 run_lib.py:146] step: 133800, eval_loss: 5.40629e-02
I0210 11:48:24.516732 22509476222784 run_lib.py:133] step: 133850, training_loss: 5.27476e-02
I0210 11:48:43.000665 22509476222784 run_lib.py:133] step: 133900, training_loss: 5.13452e-02
I0210 11:48:43.163755 22509476222784 run_lib.py:146] step: 133900, eval_loss: 3.64883e-02
I0210 11:49:01.883275 22509476222784 run_lib.py:133] step: 133950, training_loss: 4.54966e-02
I0210 11:49:20.460017 22509476222784 run_lib.py:133] step: 134000, training_loss: 4.28631e-02
I0210 11:49:20.631476 22509476222784 run_lib.py:146] step: 134000, eval_loss: 3.93047e-02
I0210 11:49:39.378598 22509476222784 run_lib.py:133] step: 134050, training_loss: 3.07366e-02
I0210 11:49:57.953092 22509476222784 run_lib.py:133] step: 134100, training_loss: 4.78121e-02
I0210 11:49:58.120873 22509476222784 run_lib.py:146] step: 134100, eval_loss: 4.16840e-02
I0210 11:50:16.830725 22509476222784 run_lib.py:133] step: 134150, training_loss: 4.39152e-02
I0210 11:50:35.417722 22509476222784 run_lib.py:133] step: 134200, training_loss: 3.85191e-02
I0210 11:50:35.593910 22509476222784 run_lib.py:146] step: 134200, eval_loss: 3.48200e-02
I0210 11:50:54.221722 22509476222784 run_lib.py:133] step: 134250, training_loss: 4.12024e-02
I0210 11:51:12.997646 22509476222784 run_lib.py:133] step: 134300, training_loss: 3.39437e-02
I0210 11:51:13.163084 22509476222784 run_lib.py:146] step: 134300, eval_loss: 5.20755e-02
I0210 11:51:31.744801 22509476222784 run_lib.py:133] step: 134350, training_loss: 4.63787e-02
I0210 11:51:50.414498 22509476222784 run_lib.py:133] step: 134400, training_loss: 4.23510e-02
I0210 11:51:50.576375 22509476222784 run_lib.py:146] step: 134400, eval_loss: 4.18805e-02
I0210 11:52:09.111510 22509476222784 run_lib.py:133] step: 134450, training_loss: 4.85078e-02
I0210 11:52:27.643541 22509476222784 run_lib.py:133] step: 134500, training_loss: 5.35465e-02
I0210 11:52:27.811949 22509476222784 run_lib.py:146] step: 134500, eval_loss: 2.47315e-02
I0210 11:52:46.417853 22509476222784 run_lib.py:133] step: 134550, training_loss: 4.73801e-02
I0210 11:53:05.130510 22509476222784 run_lib.py:133] step: 134600, training_loss: 3.79457e-02
I0210 11:53:05.297693 22509476222784 run_lib.py:146] step: 134600, eval_loss: 3.58897e-02
I0210 11:53:23.823860 22509476222784 run_lib.py:133] step: 134650, training_loss: 4.26438e-02
I0210 11:53:42.348781 22509476222784 run_lib.py:133] step: 134700, training_loss: 3.78183e-02
I0210 11:53:42.512631 22509476222784 run_lib.py:146] step: 134700, eval_loss: 5.53971e-02
I0210 11:54:01.250424 22509476222784 run_lib.py:133] step: 134750, training_loss: 3.69153e-02
I0210 11:54:19.875765 22509476222784 run_lib.py:133] step: 134800, training_loss: 5.68420e-02
I0210 11:54:20.047944 22509476222784 run_lib.py:146] step: 134800, eval_loss: 5.14204e-02
I0210 11:54:38.810265 22509476222784 run_lib.py:133] step: 134850, training_loss: 4.42608e-02
I0210 11:54:57.374842 22509476222784 run_lib.py:133] step: 134900, training_loss: 4.84761e-02
I0210 11:54:57.535939 22509476222784 run_lib.py:146] step: 134900, eval_loss: 4.69604e-02
I0210 11:55:16.162371 22509476222784 run_lib.py:133] step: 134950, training_loss: 3.73275e-02
I0210 11:55:34.768135 22509476222784 run_lib.py:133] step: 135000, training_loss: 5.39479e-02
I0210 11:55:34.932755 22509476222784 run_lib.py:146] step: 135000, eval_loss: 4.65667e-02
I0210 11:55:53.655100 22509476222784 run_lib.py:133] step: 135050, training_loss: 3.98932e-02
I0210 11:56:12.360869 22509476222784 run_lib.py:133] step: 135100, training_loss: 4.41752e-02
I0210 11:56:12.528761 22509476222784 run_lib.py:146] step: 135100, eval_loss: 5.42878e-02
I0210 11:56:31.104141 22509476222784 run_lib.py:133] step: 135150, training_loss: 5.23388e-02
I0210 11:56:49.717164 22509476222784 run_lib.py:133] step: 135200, training_loss: 6.26514e-02
I0210 11:56:49.882552 22509476222784 run_lib.py:146] step: 135200, eval_loss: 4.63077e-02
I0210 11:57:08.645079 22509476222784 run_lib.py:133] step: 135250, training_loss: 4.10081e-02
I0210 11:57:27.160019 22509476222784 run_lib.py:133] step: 135300, training_loss: 4.44284e-02
I0210 11:57:27.329910 22509476222784 run_lib.py:146] step: 135300, eval_loss: 4.88651e-02
I0210 11:57:46.088467 22509476222784 run_lib.py:133] step: 135350, training_loss: 4.09797e-02
I0210 11:58:04.693706 22509476222784 run_lib.py:133] step: 135400, training_loss: 4.92140e-02
I0210 11:58:04.864756 22509476222784 run_lib.py:146] step: 135400, eval_loss: 2.50480e-02
I0210 11:58:23.587738 22509476222784 run_lib.py:133] step: 135450, training_loss: 4.01567e-02
I0210 11:58:42.100148 22509476222784 run_lib.py:133] step: 135500, training_loss: 3.95470e-02
I0210 11:58:42.265515 22509476222784 run_lib.py:146] step: 135500, eval_loss: 3.45744e-02
I0210 11:59:00.988031 22509476222784 run_lib.py:133] step: 135550, training_loss: 2.88589e-02
I0210 11:59:19.536252 22509476222784 run_lib.py:133] step: 135600, training_loss: 3.57258e-02
I0210 11:59:19.749615 22509476222784 run_lib.py:146] step: 135600, eval_loss: 4.37696e-02
I0210 11:59:38.301176 22509476222784 run_lib.py:133] step: 135650, training_loss: 5.23019e-02
I0210 11:59:57.136393 22509476222784 run_lib.py:133] step: 135700, training_loss: 4.11339e-02
I0210 11:59:57.312878 22509476222784 run_lib.py:146] step: 135700, eval_loss: 3.87977e-02
I0210 12:00:15.883885 22509476222784 run_lib.py:133] step: 135750, training_loss: 4.75205e-02
I0210 12:00:34.422438 22509476222784 run_lib.py:133] step: 135800, training_loss: 4.86698e-02
I0210 12:00:34.586696 22509476222784 run_lib.py:146] step: 135800, eval_loss: 3.62300e-02
I0210 12:00:53.283111 22509476222784 run_lib.py:133] step: 135850, training_loss: 4.06128e-02
I0210 12:01:12.032803 22509476222784 run_lib.py:133] step: 135900, training_loss: 4.41099e-02
I0210 12:01:12.199378 22509476222784 run_lib.py:146] step: 135900, eval_loss: 4.55887e-02
I0210 12:01:30.776206 22509476222784 run_lib.py:133] step: 135950, training_loss: 3.86258e-02
I0210 12:01:49.330865 22509476222784 run_lib.py:133] step: 136000, training_loss: 3.60534e-02
I0210 12:01:49.496822 22509476222784 run_lib.py:146] step: 136000, eval_loss: 3.97959e-02
I0210 12:02:08.016129 22509476222784 run_lib.py:133] step: 136050, training_loss: 4.38544e-02
I0210 12:02:26.745784 22509476222784 run_lib.py:133] step: 136100, training_loss: 4.85066e-02
I0210 12:02:26.911878 22509476222784 run_lib.py:146] step: 136100, eval_loss: 3.33094e-02
I0210 12:02:45.481248 22509476222784 run_lib.py:133] step: 136150, training_loss: 3.84392e-02
I0210 12:03:04.084072 22509476222784 run_lib.py:133] step: 136200, training_loss: 4.17319e-02
I0210 12:03:04.250423 22509476222784 run_lib.py:146] step: 136200, eval_loss: 4.00208e-02
I0210 12:03:22.837058 22509476222784 run_lib.py:133] step: 136250, training_loss: 3.43240e-02
I0210 12:03:41.579825 22509476222784 run_lib.py:133] step: 136300, training_loss: 4.66614e-02
I0210 12:03:41.742834 22509476222784 run_lib.py:146] step: 136300, eval_loss: 4.59749e-02
I0210 12:04:00.311114 22509476222784 run_lib.py:133] step: 136350, training_loss: 4.51250e-02
I0210 12:04:18.932878 22509476222784 run_lib.py:133] step: 136400, training_loss: 4.11523e-02
I0210 12:04:19.098834 22509476222784 run_lib.py:146] step: 136400, eval_loss: 4.97582e-02
I0210 12:04:37.723300 22509476222784 run_lib.py:133] step: 136450, training_loss: 5.44088e-02
I0210 12:04:56.300781 22509476222784 run_lib.py:133] step: 136500, training_loss: 3.63003e-02
I0210 12:04:56.468682 22509476222784 run_lib.py:146] step: 136500, eval_loss: 4.65292e-02
I0210 12:05:15.188331 22509476222784 run_lib.py:133] step: 136550, training_loss: 4.88660e-02
I0210 12:05:33.794397 22509476222784 run_lib.py:133] step: 136600, training_loss: 4.12728e-02
I0210 12:05:33.956247 22509476222784 run_lib.py:146] step: 136600, eval_loss: 3.37745e-02
I0210 12:05:52.473355 22509476222784 run_lib.py:133] step: 136650, training_loss: 4.25294e-02
I0210 12:06:11.049156 22509476222784 run_lib.py:133] step: 136700, training_loss: 4.15635e-02
I0210 12:06:11.216756 22509476222784 run_lib.py:146] step: 136700, eval_loss: 4.44760e-02
I0210 12:06:29.984274 22509476222784 run_lib.py:133] step: 136750, training_loss: 5.77133e-02
I0210 12:06:48.562582 22509476222784 run_lib.py:133] step: 136800, training_loss: 4.65410e-02
I0210 12:06:48.723790 22509476222784 run_lib.py:146] step: 136800, eval_loss: 5.02133e-02
I0210 12:07:07.467222 22509476222784 run_lib.py:133] step: 136850, training_loss: 3.92829e-02
I0210 12:07:26.010338 22509476222784 run_lib.py:133] step: 136900, training_loss: 4.07256e-02
I0210 12:07:26.179197 22509476222784 run_lib.py:146] step: 136900, eval_loss: 4.54428e-02
I0210 12:07:44.870419 22509476222784 run_lib.py:133] step: 136950, training_loss: 4.28632e-02
I0210 12:08:03.458911 22509476222784 run_lib.py:133] step: 137000, training_loss: 4.58195e-02
I0210 12:08:03.640723 22509476222784 run_lib.py:146] step: 137000, eval_loss: 5.09924e-02
I0210 12:08:22.216928 22509476222784 run_lib.py:133] step: 137050, training_loss: 5.92924e-02
I0210 12:08:41.086036 22509476222784 run_lib.py:133] step: 137100, training_loss: 3.89570e-02
I0210 12:08:41.264963 22509476222784 run_lib.py:146] step: 137100, eval_loss: 4.93387e-02
I0210 12:08:59.840118 22509476222784 run_lib.py:133] step: 137150, training_loss: 3.57972e-02
I0210 12:09:18.533480 22509476222784 run_lib.py:133] step: 137200, training_loss: 4.88926e-02
I0210 12:09:18.698407 22509476222784 run_lib.py:146] step: 137200, eval_loss: 5.47398e-02
I0210 12:09:37.214652 22509476222784 run_lib.py:133] step: 137250, training_loss: 5.20278e-02
I0210 12:09:55.848676 22509476222784 run_lib.py:133] step: 137300, training_loss: 4.01681e-02
I0210 12:09:56.016943 22509476222784 run_lib.py:146] step: 137300, eval_loss: 4.14285e-02
I0210 12:10:14.811260 22509476222784 run_lib.py:133] step: 137350, training_loss: 4.17627e-02
I0210 12:10:33.379568 22509476222784 run_lib.py:133] step: 137400, training_loss: 4.29135e-02
I0210 12:10:33.543783 22509476222784 run_lib.py:146] step: 137400, eval_loss: 4.14778e-02
I0210 12:10:52.101777 22509476222784 run_lib.py:133] step: 137450, training_loss: 4.37703e-02
I0210 12:11:10.819783 22509476222784 run_lib.py:133] step: 137500, training_loss: 5.32253e-02
I0210 12:11:10.999760 22509476222784 run_lib.py:146] step: 137500, eval_loss: 4.47747e-02
I0210 12:11:29.685885 22509476222784 run_lib.py:133] step: 137550, training_loss: 3.20438e-02
I0210 12:11:48.298770 22509476222784 run_lib.py:133] step: 137600, training_loss: 4.36326e-02
I0210 12:11:48.463986 22509476222784 run_lib.py:146] step: 137600, eval_loss: 3.51866e-02
I0210 12:12:07.142395 22509476222784 run_lib.py:133] step: 137650, training_loss: 4.49233e-02
I0210 12:12:25.758873 22509476222784 run_lib.py:133] step: 137700, training_loss: 3.85932e-02
I0210 12:12:25.922544 22509476222784 run_lib.py:146] step: 137700, eval_loss: 3.59996e-02
I0210 12:12:44.489734 22509476222784 run_lib.py:133] step: 137750, training_loss: 5.18104e-02
I0210 12:13:03.065441 22509476222784 run_lib.py:133] step: 137800, training_loss: 4.97096e-02
I0210 12:13:03.232005 22509476222784 run_lib.py:146] step: 137800, eval_loss: 3.98437e-02
I0210 12:13:22.027714 22509476222784 run_lib.py:133] step: 137850, training_loss: 4.37240e-02
I0210 12:13:40.676268 22509476222784 run_lib.py:133] step: 137900, training_loss: 4.78424e-02
I0210 12:13:40.842325 22509476222784 run_lib.py:146] step: 137900, eval_loss: 4.63195e-02
I0210 12:13:59.395478 22509476222784 run_lib.py:133] step: 137950, training_loss: 4.42925e-02
I0210 12:14:17.979098 22509476222784 run_lib.py:133] step: 138000, training_loss: 4.16004e-02
I0210 12:14:18.144626 22509476222784 run_lib.py:146] step: 138000, eval_loss: 4.45398e-02
I0210 12:14:36.929396 22509476222784 run_lib.py:133] step: 138050, training_loss: 5.98350e-02
I0210 12:14:55.540714 22509476222784 run_lib.py:133] step: 138100, training_loss: 3.42414e-02
I0210 12:14:55.707505 22509476222784 run_lib.py:146] step: 138100, eval_loss: 5.03067e-02
I0210 12:15:14.520139 22509476222784 run_lib.py:133] step: 138150, training_loss: 4.05816e-02
I0210 12:15:33.051875 22509476222784 run_lib.py:133] step: 138200, training_loss: 4.94357e-02
I0210 12:15:33.214534 22509476222784 run_lib.py:146] step: 138200, eval_loss: 4.04491e-02
I0210 12:15:51.917338 22509476222784 run_lib.py:133] step: 138250, training_loss: 5.96339e-02
I0210 12:16:10.464236 22509476222784 run_lib.py:133] step: 138300, training_loss: 3.92313e-02
I0210 12:16:10.635859 22509476222784 run_lib.py:146] step: 138300, eval_loss: 4.41850e-02
I0210 12:16:29.422799 22509476222784 run_lib.py:133] step: 138350, training_loss: 5.12907e-02
I0210 12:16:48.022699 22509476222784 run_lib.py:133] step: 138400, training_loss: 4.63286e-02
I0210 12:16:48.189502 22509476222784 run_lib.py:146] step: 138400, eval_loss: 3.57638e-02
I0210 12:17:06.724293 22509476222784 run_lib.py:133] step: 138450, training_loss: 6.12518e-02
I0210 12:17:25.385149 22509476222784 run_lib.py:133] step: 138500, training_loss: 3.85830e-02
I0210 12:17:25.550725 22509476222784 run_lib.py:146] step: 138500, eval_loss: 4.27703e-02
I0210 12:17:44.188389 22509476222784 run_lib.py:133] step: 138550, training_loss: 5.12074e-02
I0210 12:18:02.802405 22509476222784 run_lib.py:133] step: 138600, training_loss: 5.07679e-02
I0210 12:18:02.968888 22509476222784 run_lib.py:146] step: 138600, eval_loss: 5.02566e-02
I0210 12:18:21.794136 22509476222784 run_lib.py:133] step: 138650, training_loss: 3.91869e-02
I0210 12:18:40.368269 22509476222784 run_lib.py:133] step: 138700, training_loss: 4.13715e-02
I0210 12:18:40.531853 22509476222784 run_lib.py:146] step: 138700, eval_loss: 3.47603e-02
I0210 12:18:59.288626 22509476222784 run_lib.py:133] step: 138750, training_loss: 3.76808e-02
I0210 12:19:17.905737 22509476222784 run_lib.py:133] step: 138800, training_loss: 4.65589e-02
I0210 12:19:18.082907 22509476222784 run_lib.py:146] step: 138800, eval_loss: 4.12941e-02
I0210 12:19:36.726915 22509476222784 run_lib.py:133] step: 138850, training_loss: 3.94421e-02
I0210 12:19:55.538278 22509476222784 run_lib.py:133] step: 138900, training_loss: 4.07277e-02
I0210 12:19:55.903669 22509476222784 run_lib.py:146] step: 138900, eval_loss: 5.92274e-02
I0210 12:20:14.455008 22509476222784 run_lib.py:133] step: 138950, training_loss: 4.20370e-02
I0210 12:20:33.052747 22509476222784 run_lib.py:133] step: 139000, training_loss: 3.78794e-02
I0210 12:20:33.218791 22509476222784 run_lib.py:146] step: 139000, eval_loss: 4.23711e-02
I0210 12:20:51.746939 22509476222784 run_lib.py:133] step: 139050, training_loss: 4.04928e-02
I0210 12:21:10.467340 22509476222784 run_lib.py:133] step: 139100, training_loss: 3.46338e-02
I0210 12:21:10.635866 22509476222784 run_lib.py:146] step: 139100, eval_loss: 4.86537e-02
I0210 12:21:29.274695 22509476222784 run_lib.py:133] step: 139150, training_loss: 3.70918e-02
I0210 12:21:47.997827 22509476222784 run_lib.py:133] step: 139200, training_loss: 3.82788e-02
I0210 12:21:48.161798 22509476222784 run_lib.py:146] step: 139200, eval_loss: 4.31561e-02
I0210 12:22:06.850302 22509476222784 run_lib.py:133] step: 139250, training_loss: 4.70700e-02
I0210 12:22:25.445127 22509476222784 run_lib.py:133] step: 139300, training_loss: 3.44187e-02
I0210 12:22:25.657873 22509476222784 run_lib.py:146] step: 139300, eval_loss: 4.60457e-02
I0210 12:22:44.394939 22509476222784 run_lib.py:133] step: 139350, training_loss: 3.66249e-02
I0210 12:23:02.993024 22509476222784 run_lib.py:133] step: 139400, training_loss: 4.59280e-02
I0210 12:23:03.170789 22509476222784 run_lib.py:146] step: 139400, eval_loss: 4.16472e-02
I0210 12:23:21.804997 22509476222784 run_lib.py:133] step: 139450, training_loss: 3.48019e-02
I0210 12:23:40.401651 22509476222784 run_lib.py:133] step: 139500, training_loss: 3.68815e-02
I0210 12:23:40.566372 22509476222784 run_lib.py:146] step: 139500, eval_loss: 3.17963e-02
I0210 12:23:59.332425 22509476222784 run_lib.py:133] step: 139550, training_loss: 4.33352e-02
I0210 12:24:17.890419 22509476222784 run_lib.py:133] step: 139600, training_loss: 4.82718e-02
I0210 12:24:18.050124 22509476222784 run_lib.py:146] step: 139600, eval_loss: 5.97407e-02
I0210 12:24:36.816354 22509476222784 run_lib.py:133] step: 139650, training_loss: 5.43339e-02
I0210 12:24:55.411836 22509476222784 run_lib.py:133] step: 139700, training_loss: 4.45389e-02
I0210 12:24:55.579919 22509476222784 run_lib.py:146] step: 139700, eval_loss: 4.55461e-02
I0210 12:25:14.403269 22509476222784 run_lib.py:133] step: 139750, training_loss: 4.30120e-02
I0210 12:25:32.971615 22509476222784 run_lib.py:133] step: 139800, training_loss: 4.28208e-02
I0210 12:25:33.139626 22509476222784 run_lib.py:146] step: 139800, eval_loss: 3.96565e-02
I0210 12:25:51.676819 22509476222784 run_lib.py:133] step: 139850, training_loss: 4.63946e-02
I0210 12:26:10.413105 22509476222784 run_lib.py:133] step: 139900, training_loss: 5.21269e-02
I0210 12:26:10.579760 22509476222784 run_lib.py:146] step: 139900, eval_loss: 5.12476e-02
I0210 12:26:29.130285 22509476222784 run_lib.py:133] step: 139950, training_loss: 5.94209e-02
I0210 12:26:47.987406 22509476222784 run_lib.py:133] step: 140000, training_loss: 3.95987e-02
I0210 12:26:49.115884 22509476222784 run_lib.py:146] step: 140000, eval_loss: 6.27225e-02
I0210 12:27:10.621855 22509476222784 run_lib.py:133] step: 140050, training_loss: 4.79903e-02
I0210 12:27:29.213375 22509476222784 run_lib.py:133] step: 140100, training_loss: 5.00458e-02
I0210 12:27:29.380520 22509476222784 run_lib.py:146] step: 140100, eval_loss: 3.74689e-02
I0210 12:27:47.941130 22509476222784 run_lib.py:133] step: 140150, training_loss: 4.71804e-02
I0210 12:28:06.513281 22509476222784 run_lib.py:133] step: 140200, training_loss: 4.65964e-02
I0210 12:28:06.680980 22509476222784 run_lib.py:146] step: 140200, eval_loss: 4.21155e-02
I0210 12:28:25.518653 22509476222784 run_lib.py:133] step: 140250, training_loss: 4.80492e-02
I0210 12:28:44.302943 22509476222784 run_lib.py:133] step: 140300, training_loss: 4.70434e-02
I0210 12:28:44.481050 22509476222784 run_lib.py:146] step: 140300, eval_loss: 5.83833e-02
I0210 12:29:03.035751 22509476222784 run_lib.py:133] step: 140350, training_loss: 4.77265e-02
I0210 12:29:21.633275 22509476222784 run_lib.py:133] step: 140400, training_loss: 4.71211e-02
I0210 12:29:21.810284 22509476222784 run_lib.py:146] step: 140400, eval_loss: 4.96410e-02
I0210 12:29:40.545019 22509476222784 run_lib.py:133] step: 140450, training_loss: 4.49279e-02
I0210 12:29:59.201698 22509476222784 run_lib.py:133] step: 140500, training_loss: 4.47371e-02
I0210 12:29:59.368757 22509476222784 run_lib.py:146] step: 140500, eval_loss: 3.97800e-02
I0210 12:30:18.188487 22509476222784 run_lib.py:133] step: 140550, training_loss: 4.50514e-02
I0210 12:30:36.740297 22509476222784 run_lib.py:133] step: 140600, training_loss: 5.39537e-02
I0210 12:30:36.905834 22509476222784 run_lib.py:146] step: 140600, eval_loss: 3.56663e-02
I0210 12:30:55.598326 22509476222784 run_lib.py:133] step: 140650, training_loss: 4.33870e-02
I0210 12:31:14.195413 22509476222784 run_lib.py:133] step: 140700, training_loss: 4.74691e-02
I0210 12:31:14.364012 22509476222784 run_lib.py:146] step: 140700, eval_loss: 3.45942e-02
I0210 12:31:33.209009 22509476222784 run_lib.py:133] step: 140750, training_loss: 3.94339e-02
I0210 12:31:51.815308 22509476222784 run_lib.py:133] step: 140800, training_loss: 4.77195e-02
I0210 12:31:51.982796 22509476222784 run_lib.py:146] step: 140800, eval_loss: 5.73679e-02
I0210 12:32:10.546519 22509476222784 run_lib.py:133] step: 140850, training_loss: 3.96936e-02
I0210 12:32:29.280135 22509476222784 run_lib.py:133] step: 140900, training_loss: 3.93102e-02
I0210 12:32:29.446990 22509476222784 run_lib.py:146] step: 140900, eval_loss: 5.65534e-02
I0210 12:32:48.014458 22509476222784 run_lib.py:133] step: 140950, training_loss: 4.61332e-02
I0210 12:33:06.627774 22509476222784 run_lib.py:133] step: 141000, training_loss: 4.01885e-02
I0210 12:33:06.795554 22509476222784 run_lib.py:146] step: 141000, eval_loss: 3.93951e-02
I0210 12:33:25.540051 22509476222784 run_lib.py:133] step: 141050, training_loss: 3.78299e-02
I0210 12:33:44.267526 22509476222784 run_lib.py:133] step: 141100, training_loss: 4.16717e-02
I0210 12:33:44.431721 22509476222784 run_lib.py:146] step: 141100, eval_loss: 5.26214e-02
I0210 12:34:02.971375 22509476222784 run_lib.py:133] step: 141150, training_loss: 3.40538e-02
I0210 12:34:21.542897 22509476222784 run_lib.py:133] step: 141200, training_loss: 4.06869e-02
I0210 12:34:21.705700 22509476222784 run_lib.py:146] step: 141200, eval_loss: 4.35980e-02
I0210 12:34:40.249131 22509476222784 run_lib.py:133] step: 141250, training_loss: 4.01093e-02
I0210 12:34:59.030034 22509476222784 run_lib.py:133] step: 141300, training_loss: 5.20492e-02
I0210 12:34:59.211625 22509476222784 run_lib.py:146] step: 141300, eval_loss: 5.12776e-02
I0210 12:35:17.822773 22509476222784 run_lib.py:133] step: 141350, training_loss: 4.18582e-02
I0210 12:35:36.413122 22509476222784 run_lib.py:133] step: 141400, training_loss: 4.76800e-02
I0210 12:35:36.578689 22509476222784 run_lib.py:146] step: 141400, eval_loss: 5.28989e-02
I0210 12:35:55.299702 22509476222784 run_lib.py:133] step: 141450, training_loss: 4.89684e-02
I0210 12:36:14.099890 22509476222784 run_lib.py:133] step: 141500, training_loss: 4.42423e-02
I0210 12:36:14.279410 22509476222784 run_lib.py:146] step: 141500, eval_loss: 3.82067e-02
I0210 12:36:32.889017 22509476222784 run_lib.py:133] step: 141550, training_loss: 3.99572e-02
I0210 12:36:51.628539 22509476222784 run_lib.py:133] step: 141600, training_loss: 4.04753e-02
I0210 12:36:51.786423 22509476222784 run_lib.py:146] step: 141600, eval_loss: 4.84032e-02
I0210 12:37:10.359822 22509476222784 run_lib.py:133] step: 141650, training_loss: 4.74044e-02
I0210 12:37:28.905334 22509476222784 run_lib.py:133] step: 141700, training_loss: 4.17691e-02
I0210 12:37:29.070661 22509476222784 run_lib.py:146] step: 141700, eval_loss: 5.38416e-02
I0210 12:37:47.715891 22509476222784 run_lib.py:133] step: 141750, training_loss: 3.78755e-02
I0210 12:38:06.450073 22509476222784 run_lib.py:133] step: 141800, training_loss: 4.91738e-02
I0210 12:38:06.632676 22509476222784 run_lib.py:146] step: 141800, eval_loss: 2.76536e-02
I0210 12:38:25.301390 22509476222784 run_lib.py:133] step: 141850, training_loss: 4.27217e-02
I0210 12:38:43.914154 22509476222784 run_lib.py:133] step: 141900, training_loss: 5.57715e-02
I0210 12:38:44.079910 22509476222784 run_lib.py:146] step: 141900, eval_loss: 3.41523e-02
I0210 12:39:02.837956 22509476222784 run_lib.py:133] step: 141950, training_loss: 4.76136e-02
I0210 12:39:21.401803 22509476222784 run_lib.py:133] step: 142000, training_loss: 4.54646e-02
I0210 12:39:21.567843 22509476222784 run_lib.py:146] step: 142000, eval_loss: 4.22182e-02
I0210 12:39:40.384456 22509476222784 run_lib.py:133] step: 142050, training_loss: 4.23070e-02
I0210 12:39:59.033926 22509476222784 run_lib.py:133] step: 142100, training_loss: 4.24098e-02
I0210 12:39:59.199904 22509476222784 run_lib.py:146] step: 142100, eval_loss: 4.15171e-02
I0210 12:40:18.043072 22509476222784 run_lib.py:133] step: 142150, training_loss: 5.27661e-02
I0210 12:40:36.569791 22509476222784 run_lib.py:133] step: 142200, training_loss: 5.23300e-02
I0210 12:40:36.737709 22509476222784 run_lib.py:146] step: 142200, eval_loss: 3.16631e-02
I0210 12:40:55.254143 22509476222784 run_lib.py:133] step: 142250, training_loss: 4.85251e-02
I0210 12:41:13.916538 22509476222784 run_lib.py:133] step: 142300, training_loss: 4.14545e-02
I0210 12:41:14.085945 22509476222784 run_lib.py:146] step: 142300, eval_loss: 3.17477e-02
I0210 12:41:32.713570 22509476222784 run_lib.py:133] step: 142350, training_loss: 4.52451e-02
I0210 12:41:51.511330 22509476222784 run_lib.py:133] step: 142400, training_loss: 5.25471e-02
I0210 12:41:51.679090 22509476222784 run_lib.py:146] step: 142400, eval_loss: 3.88290e-02
I0210 12:42:10.233952 22509476222784 run_lib.py:133] step: 142450, training_loss: 5.26148e-02
I0210 12:42:28.783558 22509476222784 run_lib.py:133] step: 142500, training_loss: 4.14423e-02
I0210 12:42:28.948751 22509476222784 run_lib.py:146] step: 142500, eval_loss: 5.84089e-02
I0210 12:42:47.692614 22509476222784 run_lib.py:133] step: 142550, training_loss: 4.93822e-02
I0210 12:43:06.241436 22509476222784 run_lib.py:133] step: 142600, training_loss: 4.71651e-02
I0210 12:43:06.409945 22509476222784 run_lib.py:146] step: 142600, eval_loss: 5.52261e-02
I0210 12:43:25.071647 22509476222784 run_lib.py:133] step: 142650, training_loss: 3.96140e-02
I0210 12:43:43.862476 22509476222784 run_lib.py:133] step: 142700, training_loss: 4.79539e-02
I0210 12:43:44.030755 22509476222784 run_lib.py:146] step: 142700, eval_loss: 4.46669e-02
I0210 12:44:02.619475 22509476222784 run_lib.py:133] step: 142750, training_loss: 4.51526e-02
I0210 12:44:21.155877 22509476222784 run_lib.py:133] step: 142800, training_loss: 3.24816e-02
I0210 12:44:21.326251 22509476222784 run_lib.py:146] step: 142800, eval_loss: 4.86422e-02
I0210 12:44:39.973947 22509476222784 run_lib.py:133] step: 142850, training_loss: 4.47090e-02
I0210 12:44:58.614854 22509476222784 run_lib.py:133] step: 142900, training_loss: 3.78619e-02
I0210 12:44:58.783206 22509476222784 run_lib.py:146] step: 142900, eval_loss: 4.68027e-02
I0210 12:45:17.379235 22509476222784 run_lib.py:133] step: 142950, training_loss: 4.69111e-02
I0210 12:45:35.993447 22509476222784 run_lib.py:133] step: 143000, training_loss: 5.28321e-02
I0210 12:45:36.266679 22509476222784 run_lib.py:146] step: 143000, eval_loss: 4.63748e-02
I0210 12:45:55.011887 22509476222784 run_lib.py:133] step: 143050, training_loss: 4.18309e-02
I0210 12:46:13.650858 22509476222784 run_lib.py:133] step: 143100, training_loss: 4.21515e-02
I0210 12:46:13.813056 22509476222784 run_lib.py:146] step: 143100, eval_loss: 4.03921e-02
I0210 12:46:32.395097 22509476222784 run_lib.py:133] step: 143150, training_loss: 4.07291e-02
I0210 12:46:51.021936 22509476222784 run_lib.py:133] step: 143200, training_loss: 4.43323e-02
I0210 12:46:51.197691 22509476222784 run_lib.py:146] step: 143200, eval_loss: 5.00119e-02
I0210 12:47:09.968014 22509476222784 run_lib.py:133] step: 143250, training_loss: 5.99062e-02
I0210 12:47:28.555573 22509476222784 run_lib.py:133] step: 143300, training_loss: 3.99960e-02
I0210 12:47:28.730183 22509476222784 run_lib.py:146] step: 143300, eval_loss: 3.84129e-02
I0210 12:47:47.452308 22509476222784 run_lib.py:133] step: 143350, training_loss: 5.14068e-02
I0210 12:48:06.033024 22509476222784 run_lib.py:133] step: 143400, training_loss: 5.00081e-02
I0210 12:48:06.203469 22509476222784 run_lib.py:146] step: 143400, eval_loss: 4.17558e-02
I0210 12:48:25.016389 22509476222784 run_lib.py:133] step: 143450, training_loss: 3.31261e-02
I0210 12:48:43.577353 22509476222784 run_lib.py:133] step: 143500, training_loss: 4.22495e-02
I0210 12:48:43.739809 22509476222784 run_lib.py:146] step: 143500, eval_loss: 4.55020e-02
I0210 12:49:02.450199 22509476222784 run_lib.py:133] step: 143550, training_loss: 3.65272e-02
I0210 12:49:20.958402 22509476222784 run_lib.py:133] step: 143600, training_loss: 4.36124e-02
I0210 12:49:21.123667 22509476222784 run_lib.py:146] step: 143600, eval_loss: 3.47285e-02
I0210 12:49:39.812509 22509476222784 run_lib.py:133] step: 143650, training_loss: 3.03801e-02
I0210 12:49:58.515737 22509476222784 run_lib.py:133] step: 143700, training_loss: 3.64722e-02
I0210 12:49:58.696663 22509476222784 run_lib.py:146] step: 143700, eval_loss: 4.48452e-02
I0210 12:50:17.308320 22509476222784 run_lib.py:133] step: 143750, training_loss: 4.93538e-02
I0210 12:50:35.838182 22509476222784 run_lib.py:133] step: 143800, training_loss: 4.63205e-02
I0210 12:50:36.003916 22509476222784 run_lib.py:146] step: 143800, eval_loss: 4.19406e-02
I0210 12:50:54.751863 22509476222784 run_lib.py:133] step: 143850, training_loss: 3.82117e-02
I0210 12:51:13.321740 22509476222784 run_lib.py:133] step: 143900, training_loss: 2.98059e-02
I0210 12:51:13.485481 22509476222784 run_lib.py:146] step: 143900, eval_loss: 4.65688e-02
I0210 12:51:32.236029 22509476222784 run_lib.py:133] step: 143950, training_loss: 4.69329e-02
I0210 12:51:50.859022 22509476222784 run_lib.py:133] step: 144000, training_loss: 3.67317e-02
I0210 12:51:51.022898 22509476222784 run_lib.py:146] step: 144000, eval_loss: 4.81304e-02
I0210 12:52:09.642930 22509476222784 run_lib.py:133] step: 144050, training_loss: 5.03234e-02
I0210 12:52:28.418931 22509476222784 run_lib.py:133] step: 144100, training_loss: 5.33691e-02
I0210 12:52:28.584677 22509476222784 run_lib.py:146] step: 144100, eval_loss: 3.94654e-02
I0210 12:52:47.117616 22509476222784 run_lib.py:133] step: 144150, training_loss: 3.82506e-02
I0210 12:53:05.651545 22509476222784 run_lib.py:133] step: 144200, training_loss: 4.37667e-02
I0210 12:53:05.821047 22509476222784 run_lib.py:146] step: 144200, eval_loss: 3.32737e-02
I0210 12:53:24.344734 22509476222784 run_lib.py:133] step: 144250, training_loss: 4.68321e-02
I0210 12:53:43.161452 22509476222784 run_lib.py:133] step: 144300, training_loss: 5.56478e-02
I0210 12:53:43.330871 22509476222784 run_lib.py:146] step: 144300, eval_loss: 3.53862e-02
I0210 12:54:01.884911 22509476222784 run_lib.py:133] step: 144350, training_loss: 5.83376e-02
I0210 12:54:20.528978 22509476222784 run_lib.py:133] step: 144400, training_loss: 4.66071e-02
I0210 12:54:20.699616 22509476222784 run_lib.py:146] step: 144400, eval_loss: 3.91720e-02
I0210 12:54:39.304065 22509476222784 run_lib.py:133] step: 144450, training_loss: 4.90544e-02
I0210 12:54:57.827861 22509476222784 run_lib.py:133] step: 144500, training_loss: 4.56883e-02
I0210 12:54:57.995672 22509476222784 run_lib.py:146] step: 144500, eval_loss: 3.21691e-02
I0210 12:55:16.725584 22509476222784 run_lib.py:133] step: 144550, training_loss: 4.05483e-02
I0210 12:55:35.434264 22509476222784 run_lib.py:133] step: 144600, training_loss: 3.65850e-02
I0210 12:55:35.600813 22509476222784 run_lib.py:146] step: 144600, eval_loss: 4.52212e-02
I0210 12:55:54.146802 22509476222784 run_lib.py:133] step: 144650, training_loss: 4.63846e-02
I0210 12:56:12.734581 22509476222784 run_lib.py:133] step: 144700, training_loss: 4.21462e-02
I0210 12:56:12.902304 22509476222784 run_lib.py:146] step: 144700, eval_loss: 4.07961e-02
I0210 12:56:31.597270 22509476222784 run_lib.py:133] step: 144750, training_loss: 3.61822e-02
I0210 12:56:50.146148 22509476222784 run_lib.py:133] step: 144800, training_loss: 3.57808e-02
I0210 12:56:50.321449 22509476222784 run_lib.py:146] step: 144800, eval_loss: 4.42475e-02
I0210 12:57:09.045579 22509476222784 run_lib.py:133] step: 144850, training_loss: 4.85052e-02
I0210 12:57:27.720322 22509476222784 run_lib.py:133] step: 144900, training_loss: 4.11283e-02
I0210 12:57:27.884371 22509476222784 run_lib.py:146] step: 144900, eval_loss: 4.11755e-02
I0210 12:57:46.691442 22509476222784 run_lib.py:133] step: 144950, training_loss: 4.80197e-02
I0210 12:58:05.266797 22509476222784 run_lib.py:133] step: 145000, training_loss: 3.84390e-02
I0210 12:58:05.431810 22509476222784 run_lib.py:146] step: 145000, eval_loss: 4.41054e-02
I0210 12:58:23.959268 22509476222784 run_lib.py:133] step: 145050, training_loss: 4.57813e-02
I0210 12:58:42.701745 22509476222784 run_lib.py:133] step: 145100, training_loss: 5.22273e-02
I0210 12:58:42.883567 22509476222784 run_lib.py:146] step: 145100, eval_loss: 5.42690e-02
I0210 12:59:01.463155 22509476222784 run_lib.py:133] step: 145150, training_loss: 5.36989e-02
I0210 12:59:20.229534 22509476222784 run_lib.py:133] step: 145200, training_loss: 3.91602e-02
I0210 12:59:20.398434 22509476222784 run_lib.py:146] step: 145200, eval_loss: 4.63694e-02
I0210 12:59:39.047696 22509476222784 run_lib.py:133] step: 145250, training_loss: 5.11968e-02
I0210 12:59:57.622847 22509476222784 run_lib.py:133] step: 145300, training_loss: 4.28104e-02
I0210 12:59:57.790570 22509476222784 run_lib.py:146] step: 145300, eval_loss: 5.53426e-02
I0210 13:00:16.477569 22509476222784 run_lib.py:133] step: 145350, training_loss: 3.15481e-02
I0210 13:00:35.058856 22509476222784 run_lib.py:133] step: 145400, training_loss: 5.51973e-02
I0210 13:00:35.229311 22509476222784 run_lib.py:146] step: 145400, eval_loss: 4.57168e-02
I0210 13:00:53.910545 22509476222784 run_lib.py:133] step: 145450, training_loss: 3.92261e-02
I0210 13:01:12.699470 22509476222784 run_lib.py:133] step: 145500, training_loss: 3.87818e-02
I0210 13:01:12.865708 22509476222784 run_lib.py:146] step: 145500, eval_loss: 3.53888e-02
I0210 13:01:31.383416 22509476222784 run_lib.py:133] step: 145550, training_loss: 4.91400e-02
I0210 13:01:49.941696 22509476222784 run_lib.py:133] step: 145600, training_loss: 3.90734e-02
I0210 13:01:50.271586 22509476222784 run_lib.py:146] step: 145600, eval_loss: 4.20237e-02
I0210 13:02:08.849768 22509476222784 run_lib.py:133] step: 145650, training_loss: 4.25675e-02
I0210 13:02:27.462862 22509476222784 run_lib.py:133] step: 145700, training_loss: 4.11196e-02
I0210 13:02:27.629012 22509476222784 run_lib.py:146] step: 145700, eval_loss: 3.41684e-02
I0210 13:02:46.160851 22509476222784 run_lib.py:133] step: 145750, training_loss: 4.17772e-02
I0210 13:03:04.712890 22509476222784 run_lib.py:133] step: 145800, training_loss: 4.31533e-02
I0210 13:03:04.876684 22509476222784 run_lib.py:146] step: 145800, eval_loss: 4.58786e-02
I0210 13:03:23.625895 22509476222784 run_lib.py:133] step: 145850, training_loss: 4.70778e-02
I0210 13:03:42.320421 22509476222784 run_lib.py:133] step: 145900, training_loss: 2.96079e-02
I0210 13:03:42.500759 22509476222784 run_lib.py:146] step: 145900, eval_loss: 3.89681e-02
I0210 13:04:01.199124 22509476222784 run_lib.py:133] step: 145950, training_loss: 4.00550e-02
I0210 13:04:19.839326 22509476222784 run_lib.py:133] step: 146000, training_loss: 4.08096e-02
I0210 13:04:20.005853 22509476222784 run_lib.py:146] step: 146000, eval_loss: 3.81387e-02
I0210 13:04:38.737486 22509476222784 run_lib.py:133] step: 146050, training_loss: 4.18841e-02
I0210 13:04:57.355154 22509476222784 run_lib.py:133] step: 146100, training_loss: 3.91072e-02
I0210 13:04:57.532911 22509476222784 run_lib.py:146] step: 146100, eval_loss: 5.35718e-02
I0210 13:05:16.080588 22509476222784 run_lib.py:133] step: 146150, training_loss: 2.55901e-02
I0210 13:05:34.710750 22509476222784 run_lib.py:133] step: 146200, training_loss: 4.37604e-02
I0210 13:05:34.876855 22509476222784 run_lib.py:146] step: 146200, eval_loss: 3.82694e-02
I0210 13:05:53.629039 22509476222784 run_lib.py:133] step: 146250, training_loss: 4.84470e-02
I0210 13:06:12.187751 22509476222784 run_lib.py:133] step: 146300, training_loss: 3.89218e-02
I0210 13:06:12.361540 22509476222784 run_lib.py:146] step: 146300, eval_loss: 4.74526e-02
I0210 13:06:31.135468 22509476222784 run_lib.py:133] step: 146350, training_loss: 5.92088e-02
I0210 13:06:49.725114 22509476222784 run_lib.py:133] step: 146400, training_loss: 3.89989e-02
I0210 13:06:49.889226 22509476222784 run_lib.py:146] step: 146400, eval_loss: 4.31336e-02
I0210 13:07:08.683545 22509476222784 run_lib.py:133] step: 146450, training_loss: 3.59475e-02
I0210 13:07:27.285942 22509476222784 run_lib.py:133] step: 146500, training_loss: 3.53740e-02
I0210 13:07:27.471577 22509476222784 run_lib.py:146] step: 146500, eval_loss: 5.45452e-02
I0210 13:07:46.047441 22509476222784 run_lib.py:133] step: 146550, training_loss: 4.96727e-02
I0210 13:08:04.831021 22509476222784 run_lib.py:133] step: 146600, training_loss: 3.53037e-02
I0210 13:08:04.994088 22509476222784 run_lib.py:146] step: 146600, eval_loss: 4.26879e-02
I0210 13:08:23.533127 22509476222784 run_lib.py:133] step: 146650, training_loss: 4.83869e-02
I0210 13:08:42.194719 22509476222784 run_lib.py:133] step: 146700, training_loss: 4.38580e-02
I0210 13:08:42.365661 22509476222784 run_lib.py:146] step: 146700, eval_loss: 5.30050e-02
I0210 13:09:00.943446 22509476222784 run_lib.py:133] step: 146750, training_loss: 3.75549e-02
I0210 13:09:19.506241 22509476222784 run_lib.py:133] step: 146800, training_loss: 4.32933e-02
I0210 13:09:19.671433 22509476222784 run_lib.py:146] step: 146800, eval_loss: 4.78335e-02
I0210 13:09:38.314350 22509476222784 run_lib.py:133] step: 146850, training_loss: 3.83002e-02
I0210 13:09:57.052002 22509476222784 run_lib.py:133] step: 146900, training_loss: 4.76944e-02
I0210 13:09:57.215670 22509476222784 run_lib.py:146] step: 146900, eval_loss: 4.52001e-02
I0210 13:10:15.750349 22509476222784 run_lib.py:133] step: 146950, training_loss: 4.38720e-02
I0210 13:10:34.353146 22509476222784 run_lib.py:133] step: 147000, training_loss: 4.28850e-02
I0210 13:10:34.533934 22509476222784 run_lib.py:146] step: 147000, eval_loss: 4.67910e-02
I0210 13:10:53.338451 22509476222784 run_lib.py:133] step: 147050, training_loss: 4.63700e-02
I0210 13:11:11.879772 22509476222784 run_lib.py:133] step: 147100, training_loss: 4.19962e-02
I0210 13:11:12.045922 22509476222784 run_lib.py:146] step: 147100, eval_loss: 5.07853e-02
I0210 13:11:30.683278 22509476222784 run_lib.py:133] step: 147150, training_loss: 4.72526e-02
I0210 13:11:49.241575 22509476222784 run_lib.py:133] step: 147200, training_loss: 4.31886e-02
I0210 13:11:49.406886 22509476222784 run_lib.py:146] step: 147200, eval_loss: 4.51694e-02
I0210 13:12:07.997496 22509476222784 run_lib.py:133] step: 147250, training_loss: 3.90420e-02
I0210 13:12:26.611796 22509476222784 run_lib.py:133] step: 147300, training_loss: 3.99667e-02
I0210 13:12:26.783021 22509476222784 run_lib.py:146] step: 147300, eval_loss: 4.40681e-02
I0210 13:12:45.592868 22509476222784 run_lib.py:133] step: 147350, training_loss: 4.74487e-02
I0210 13:13:04.243402 22509476222784 run_lib.py:133] step: 147400, training_loss: 5.08933e-02
I0210 13:13:04.435641 22509476222784 run_lib.py:146] step: 147400, eval_loss: 3.34374e-02
I0210 13:13:23.084478 22509476222784 run_lib.py:133] step: 147450, training_loss: 4.38426e-02
I0210 13:13:41.642618 22509476222784 run_lib.py:133] step: 147500, training_loss: 4.05297e-02
I0210 13:13:41.809842 22509476222784 run_lib.py:146] step: 147500, eval_loss: 5.11112e-02
I0210 13:14:00.563037 22509476222784 run_lib.py:133] step: 147550, training_loss: 3.68848e-02
I0210 13:14:19.230158 22509476222784 run_lib.py:133] step: 147600, training_loss: 4.14865e-02
I0210 13:14:19.396950 22509476222784 run_lib.py:146] step: 147600, eval_loss: 3.30968e-02
I0210 13:14:38.187271 22509476222784 run_lib.py:133] step: 147650, training_loss: 4.49163e-02
I0210 13:14:56.762572 22509476222784 run_lib.py:133] step: 147700, training_loss: 5.38458e-02
I0210 13:14:56.927128 22509476222784 run_lib.py:146] step: 147700, eval_loss: 4.76659e-02
I0210 13:15:15.662356 22509476222784 run_lib.py:133] step: 147750, training_loss: 5.65512e-02
I0210 13:15:34.249392 22509476222784 run_lib.py:133] step: 147800, training_loss: 3.65615e-02
I0210 13:15:34.418087 22509476222784 run_lib.py:146] step: 147800, eval_loss: 4.76770e-02
I0210 13:15:53.295653 22509476222784 run_lib.py:133] step: 147850, training_loss: 3.97970e-02
I0210 13:16:11.875155 22509476222784 run_lib.py:133] step: 147900, training_loss: 4.37821e-02
I0210 13:16:12.041497 22509476222784 run_lib.py:146] step: 147900, eval_loss: 5.29561e-02
I0210 13:16:30.557188 22509476222784 run_lib.py:133] step: 147950, training_loss: 4.60144e-02
I0210 13:16:49.264356 22509476222784 run_lib.py:133] step: 148000, training_loss: 3.37198e-02
I0210 13:16:49.431852 22509476222784 run_lib.py:146] step: 148000, eval_loss: 3.98057e-02
I0210 13:17:08.007469 22509476222784 run_lib.py:133] step: 148050, training_loss: 4.32125e-02
I0210 13:17:26.630683 22509476222784 run_lib.py:133] step: 148100, training_loss: 4.18697e-02
I0210 13:17:26.799851 22509476222784 run_lib.py:146] step: 148100, eval_loss: 4.72054e-02
I0210 13:17:45.588679 22509476222784 run_lib.py:133] step: 148150, training_loss: 4.22701e-02
I0210 13:18:04.350773 22509476222784 run_lib.py:133] step: 148200, training_loss: 4.02424e-02
I0210 13:18:04.520633 22509476222784 run_lib.py:146] step: 148200, eval_loss: 4.44465e-02
I0210 13:18:23.080097 22509476222784 run_lib.py:133] step: 148250, training_loss: 4.26605e-02
I0210 13:18:41.643294 22509476222784 run_lib.py:133] step: 148300, training_loss: 4.25996e-02
I0210 13:18:41.805566 22509476222784 run_lib.py:146] step: 148300, eval_loss: 3.63221e-02
I0210 13:19:00.410502 22509476222784 run_lib.py:133] step: 148350, training_loss: 4.50798e-02
I0210 13:19:19.197667 22509476222784 run_lib.py:133] step: 148400, training_loss: 4.56629e-02
I0210 13:19:19.364778 22509476222784 run_lib.py:146] step: 148400, eval_loss: 3.71211e-02
I0210 13:19:37.947892 22509476222784 run_lib.py:133] step: 148450, training_loss: 3.95081e-02
I0210 13:19:56.480509 22509476222784 run_lib.py:133] step: 148500, training_loss: 3.12220e-02
I0210 13:19:56.649760 22509476222784 run_lib.py:146] step: 148500, eval_loss: 5.25930e-02
I0210 13:20:15.213813 22509476222784 run_lib.py:133] step: 148550, training_loss: 3.93832e-02
I0210 13:20:33.955617 22509476222784 run_lib.py:133] step: 148600, training_loss: 5.34043e-02
I0210 13:20:34.159881 22509476222784 run_lib.py:146] step: 148600, eval_loss: 4.17096e-02
I0210 13:20:52.772274 22509476222784 run_lib.py:133] step: 148650, training_loss: 4.12675e-02
I0210 13:21:11.474430 22509476222784 run_lib.py:133] step: 148700, training_loss: 4.01815e-02
I0210 13:21:11.637897 22509476222784 run_lib.py:146] step: 148700, eval_loss: 4.06206e-02
I0210 13:21:30.224320 22509476222784 run_lib.py:133] step: 148750, training_loss: 3.12521e-02
I0210 13:21:48.810076 22509476222784 run_lib.py:133] step: 148800, training_loss: 5.59302e-02
I0210 13:21:48.974558 22509476222784 run_lib.py:146] step: 148800, eval_loss: 4.37678e-02
I0210 13:22:07.649459 22509476222784 run_lib.py:133] step: 148850, training_loss: 5.24731e-02
I0210 13:22:26.342713 22509476222784 run_lib.py:133] step: 148900, training_loss: 4.13877e-02
I0210 13:22:26.572663 22509476222784 run_lib.py:146] step: 148900, eval_loss: 4.64515e-02
I0210 13:22:45.146846 22509476222784 run_lib.py:133] step: 148950, training_loss: 4.26544e-02
I0210 13:23:03.717392 22509476222784 run_lib.py:133] step: 149000, training_loss: 3.47701e-02
I0210 13:23:03.892780 22509476222784 run_lib.py:146] step: 149000, eval_loss: 4.40724e-02
I0210 13:23:22.624889 22509476222784 run_lib.py:133] step: 149050, training_loss: 4.56044e-02
I0210 13:23:41.174207 22509476222784 run_lib.py:133] step: 149100, training_loss: 3.61662e-02
I0210 13:23:41.338583 22509476222784 run_lib.py:146] step: 149100, eval_loss: 4.03681e-02
I0210 13:24:00.032652 22509476222784 run_lib.py:133] step: 149150, training_loss: 3.46640e-02
I0210 13:24:18.663506 22509476222784 run_lib.py:133] step: 149200, training_loss: 4.44985e-02
I0210 13:24:18.827983 22509476222784 run_lib.py:146] step: 149200, eval_loss: 5.24975e-02
I0210 13:24:37.661077 22509476222784 run_lib.py:133] step: 149250, training_loss: 5.49128e-02
I0210 13:24:56.215185 22509476222784 run_lib.py:133] step: 149300, training_loss: 3.93168e-02
I0210 13:24:56.399553 22509476222784 run_lib.py:146] step: 149300, eval_loss: 4.90494e-02
I0210 13:25:14.988240 22509476222784 run_lib.py:133] step: 149350, training_loss: 4.45538e-02
I0210 13:25:33.710376 22509476222784 run_lib.py:133] step: 149400, training_loss: 3.02320e-02
I0210 13:25:33.880914 22509476222784 run_lib.py:146] step: 149400, eval_loss: 4.97146e-02
I0210 13:25:52.448137 22509476222784 run_lib.py:133] step: 149450, training_loss: 4.78636e-02
I0210 13:26:11.257034 22509476222784 run_lib.py:133] step: 149500, training_loss: 5.18499e-02
I0210 13:26:11.423856 22509476222784 run_lib.py:146] step: 149500, eval_loss: 4.87443e-02
I0210 13:26:29.988115 22509476222784 run_lib.py:133] step: 149550, training_loss: 4.21019e-02
I0210 13:26:48.543050 22509476222784 run_lib.py:133] step: 149600, training_loss: 4.16829e-02
I0210 13:26:48.708038 22509476222784 run_lib.py:146] step: 149600, eval_loss: 5.37185e-02
I0210 13:27:07.666133 22509476222784 run_lib.py:133] step: 149650, training_loss: 4.11780e-02
I0210 13:27:26.207844 22509476222784 run_lib.py:133] step: 149700, training_loss: 5.63017e-02
I0210 13:27:26.371937 22509476222784 run_lib.py:146] step: 149700, eval_loss: 4.27456e-02
I0210 13:27:45.019490 22509476222784 run_lib.py:133] step: 149750, training_loss: 2.59257e-02
I0210 13:28:03.808930 22509476222784 run_lib.py:133] step: 149800, training_loss: 5.01758e-02
I0210 13:28:03.973544 22509476222784 run_lib.py:146] step: 149800, eval_loss: 3.28010e-02
I0210 13:28:22.554180 22509476222784 run_lib.py:133] step: 149850, training_loss: 3.94096e-02
I0210 13:28:41.117923 22509476222784 run_lib.py:133] step: 149900, training_loss: 3.96885e-02
I0210 13:28:41.284838 22509476222784 run_lib.py:146] step: 149900, eval_loss: 4.76932e-02
I0210 13:28:59.938395 22509476222784 run_lib.py:133] step: 149950, training_loss: 5.34725e-02
I0210 13:29:18.470852 22509476222784 run_lib.py:133] step: 150000, training_loss: 4.44708e-02
I0210 13:29:19.673773 22509476222784 run_lib.py:146] step: 150000, eval_loss: 4.21398e-02
I0210 13:29:41.400316 22509476222784 run_lib.py:133] step: 150050, training_loss: 4.01570e-02
I0210 13:30:00.026106 22509476222784 run_lib.py:133] step: 150100, training_loss: 4.83612e-02
I0210 13:30:00.192442 22509476222784 run_lib.py:146] step: 150100, eval_loss: 4.27789e-02
I0210 13:30:18.957560 22509476222784 run_lib.py:133] step: 150150, training_loss: 4.08319e-02
I0210 13:30:37.527550 22509476222784 run_lib.py:133] step: 150200, training_loss: 4.12836e-02
I0210 13:30:37.690511 22509476222784 run_lib.py:146] step: 150200, eval_loss: 3.85082e-02
I0210 13:30:56.284922 22509476222784 run_lib.py:133] step: 150250, training_loss: 3.96781e-02
I0210 13:31:14.846161 22509476222784 run_lib.py:133] step: 150300, training_loss: 3.89115e-02
I0210 13:31:15.015331 22509476222784 run_lib.py:146] step: 150300, eval_loss: 2.89592e-02
I0210 13:31:33.632771 22509476222784 run_lib.py:133] step: 150350, training_loss: 5.39450e-02
I0210 13:31:52.171847 22509476222784 run_lib.py:133] step: 150400, training_loss: 4.30536e-02
I0210 13:31:52.339543 22509476222784 run_lib.py:146] step: 150400, eval_loss: 4.82175e-02
I0210 13:32:11.033398 22509476222784 run_lib.py:133] step: 150450, training_loss: 3.67522e-02
I0210 13:32:29.708500 22509476222784 run_lib.py:133] step: 150500, training_loss: 3.38194e-02
I0210 13:32:29.874629 22509476222784 run_lib.py:146] step: 150500, eval_loss: 4.96852e-02
I0210 13:32:48.457190 22509476222784 run_lib.py:133] step: 150550, training_loss: 5.27874e-02
I0210 13:33:07.055190 22509476222784 run_lib.py:133] step: 150600, training_loss: 5.41816e-02
I0210 13:33:07.221939 22509476222784 run_lib.py:146] step: 150600, eval_loss: 4.63681e-02
I0210 13:33:26.056887 22509476222784 run_lib.py:133] step: 150650, training_loss: 4.29884e-02
I0210 13:33:44.632977 22509476222784 run_lib.py:133] step: 150700, training_loss: 3.25611e-02
I0210 13:33:44.798828 22509476222784 run_lib.py:146] step: 150700, eval_loss: 4.76351e-02
I0210 13:34:03.527946 22509476222784 run_lib.py:133] step: 150750, training_loss: 4.95142e-02
I0210 13:34:22.073092 22509476222784 run_lib.py:133] step: 150800, training_loss: 3.44266e-02
I0210 13:34:22.243929 22509476222784 run_lib.py:146] step: 150800, eval_loss: 4.22893e-02
I0210 13:34:40.980992 22509476222784 run_lib.py:133] step: 150850, training_loss: 3.88310e-02
I0210 13:34:59.557245 22509476222784 run_lib.py:133] step: 150900, training_loss: 4.61724e-02
I0210 13:34:59.721990 22509476222784 run_lib.py:146] step: 150900, eval_loss: 3.50959e-02
I0210 13:35:18.444545 22509476222784 run_lib.py:133] step: 150950, training_loss: 3.60579e-02
I0210 13:35:36.988741 22509476222784 run_lib.py:133] step: 151000, training_loss: 3.83882e-02
I0210 13:35:37.154696 22509476222784 run_lib.py:146] step: 151000, eval_loss: 4.73357e-02
I0210 13:35:55.720751 22509476222784 run_lib.py:133] step: 151050, training_loss: 5.32796e-02
I0210 13:36:14.401568 22509476222784 run_lib.py:133] step: 151100, training_loss: 3.99554e-02
I0210 13:36:14.574697 22509476222784 run_lib.py:146] step: 151100, eval_loss: 4.73398e-02
I0210 13:36:33.228965 22509476222784 run_lib.py:133] step: 151150, training_loss: 3.61045e-02
I0210 13:36:51.779535 22509476222784 run_lib.py:133] step: 151200, training_loss: 3.64705e-02
I0210 13:36:51.941732 22509476222784 run_lib.py:146] step: 151200, eval_loss: 4.41948e-02
I0210 13:37:10.686859 22509476222784 run_lib.py:133] step: 151250, training_loss: 3.41546e-02
I0210 13:37:29.232201 22509476222784 run_lib.py:133] step: 151300, training_loss: 4.29785e-02
I0210 13:37:29.398836 22509476222784 run_lib.py:146] step: 151300, eval_loss: 3.48945e-02
I0210 13:37:48.436001 22509476222784 run_lib.py:133] step: 151350, training_loss: 4.03133e-02
I0210 13:38:07.098611 22509476222784 run_lib.py:133] step: 151400, training_loss: 5.79330e-02
I0210 13:38:07.263675 22509476222784 run_lib.py:146] step: 151400, eval_loss: 4.47693e-02
I0210 13:38:25.854269 22509476222784 run_lib.py:133] step: 151450, training_loss: 2.96430e-02
I0210 13:38:44.598685 22509476222784 run_lib.py:133] step: 151500, training_loss: 4.91043e-02
I0210 13:38:44.766321 22509476222784 run_lib.py:146] step: 151500, eval_loss: 4.78597e-02
I0210 13:39:03.357816 22509476222784 run_lib.py:133] step: 151550, training_loss: 4.55181e-02
I0210 13:39:21.889349 22509476222784 run_lib.py:133] step: 151600, training_loss: 4.75201e-02
I0210 13:39:22.068614 22509476222784 run_lib.py:146] step: 151600, eval_loss: 3.75044e-02
I0210 13:39:40.652113 22509476222784 run_lib.py:133] step: 151650, training_loss: 3.08490e-02
I0210 13:39:59.469736 22509476222784 run_lib.py:133] step: 151700, training_loss: 4.33310e-02
I0210 13:39:59.633013 22509476222784 run_lib.py:146] step: 151700, eval_loss: 3.38444e-02
I0210 13:40:18.225626 22509476222784 run_lib.py:133] step: 151750, training_loss: 3.69455e-02
I0210 13:40:36.881289 22509476222784 run_lib.py:133] step: 151800, training_loss: 3.80385e-02
I0210 13:40:37.074696 22509476222784 run_lib.py:146] step: 151800, eval_loss: 4.20546e-02
I0210 13:40:55.601035 22509476222784 run_lib.py:133] step: 151850, training_loss: 4.46323e-02
I0210 13:41:14.205866 22509476222784 run_lib.py:133] step: 151900, training_loss: 3.53598e-02
I0210 13:41:14.380615 22509476222784 run_lib.py:146] step: 151900, eval_loss: 4.51472e-02
I0210 13:41:33.216292 22509476222784 run_lib.py:133] step: 151950, training_loss: 4.15149e-02
I0210 13:41:51.923075 22509476222784 run_lib.py:133] step: 152000, training_loss: 4.03856e-02
I0210 13:41:52.096256 22509476222784 run_lib.py:146] step: 152000, eval_loss: 4.19770e-02
I0210 13:42:10.680571 22509476222784 run_lib.py:133] step: 152050, training_loss: 5.20381e-02
I0210 13:42:29.271520 22509476222784 run_lib.py:133] step: 152100, training_loss: 4.05159e-02
I0210 13:42:29.434574 22509476222784 run_lib.py:146] step: 152100, eval_loss: 5.40715e-02
I0210 13:42:48.146173 22509476222784 run_lib.py:133] step: 152150, training_loss: 3.36185e-02
I0210 13:43:06.736569 22509476222784 run_lib.py:133] step: 152200, training_loss: 5.87653e-02
I0210 13:43:06.918914 22509476222784 run_lib.py:146] step: 152200, eval_loss: 5.11832e-02
I0210 13:43:25.702647 22509476222784 run_lib.py:133] step: 152250, training_loss: 3.78191e-02
I0210 13:43:44.294922 22509476222784 run_lib.py:133] step: 152300, training_loss: 3.79144e-02
I0210 13:43:44.461790 22509476222784 run_lib.py:146] step: 152300, eval_loss: 4.62710e-02
I0210 13:44:03.177046 22509476222784 run_lib.py:133] step: 152350, training_loss: 4.22751e-02
I0210 13:44:21.693852 22509476222784 run_lib.py:133] step: 152400, training_loss: 4.60749e-02
I0210 13:44:21.859568 22509476222784 run_lib.py:146] step: 152400, eval_loss: 5.41628e-02
I0210 13:44:40.446642 22509476222784 run_lib.py:133] step: 152450, training_loss: 3.59409e-02
I0210 13:44:59.201454 22509476222784 run_lib.py:133] step: 152500, training_loss: 3.49259e-02
I0210 13:44:59.370351 22509476222784 run_lib.py:146] step: 152500, eval_loss: 3.04866e-02
I0210 13:45:17.952478 22509476222784 run_lib.py:133] step: 152550, training_loss: 4.08365e-02
I0210 13:45:36.758100 22509476222784 run_lib.py:133] step: 152600, training_loss: 5.31189e-02
I0210 13:45:36.920602 22509476222784 run_lib.py:146] step: 152600, eval_loss: 4.65981e-02
I0210 13:45:55.568283 22509476222784 run_lib.py:133] step: 152650, training_loss: 4.86290e-02
I0210 13:46:14.202404 22509476222784 run_lib.py:133] step: 152700, training_loss: 5.06220e-02
I0210 13:46:14.381029 22509476222784 run_lib.py:146] step: 152700, eval_loss: 5.72852e-02
I0210 13:46:33.422308 22509476222784 run_lib.py:133] step: 152750, training_loss: 5.05585e-02
I0210 13:46:52.055176 22509476222784 run_lib.py:133] step: 152800, training_loss: 4.30805e-02
I0210 13:46:52.221876 22509476222784 run_lib.py:146] step: 152800, eval_loss: 3.70240e-02
I0210 13:47:10.826727 22509476222784 run_lib.py:133] step: 152850, training_loss: 4.87340e-02
I0210 13:47:29.591380 22509476222784 run_lib.py:133] step: 152900, training_loss: 6.29626e-02
I0210 13:47:29.758694 22509476222784 run_lib.py:146] step: 152900, eval_loss: 5.41686e-02
I0210 13:47:48.317475 22509476222784 run_lib.py:133] step: 152950, training_loss: 4.23013e-02
I0210 13:48:06.891768 22509476222784 run_lib.py:133] step: 153000, training_loss: 3.54804e-02
I0210 13:48:07.208793 22509476222784 run_lib.py:146] step: 153000, eval_loss: 3.78612e-02
I0210 13:48:25.855669 22509476222784 run_lib.py:133] step: 153050, training_loss: 4.28580e-02
I0210 13:48:44.437788 22509476222784 run_lib.py:133] step: 153100, training_loss: 3.70679e-02
I0210 13:48:44.601872 22509476222784 run_lib.py:146] step: 153100, eval_loss: 4.64271e-02
I0210 13:49:03.146369 22509476222784 run_lib.py:133] step: 153150, training_loss: 4.08507e-02
I0210 13:49:21.739645 22509476222784 run_lib.py:133] step: 153200, training_loss: 4.47948e-02
I0210 13:49:21.995117 22509476222784 run_lib.py:146] step: 153200, eval_loss: 5.90154e-02
I0210 13:49:40.750900 22509476222784 run_lib.py:133] step: 153250, training_loss: 5.58150e-02
I0210 13:49:59.514488 22509476222784 run_lib.py:133] step: 153300, training_loss: 4.28985e-02
I0210 13:49:59.696671 22509476222784 run_lib.py:146] step: 153300, eval_loss: 3.93015e-02
I0210 13:50:18.336704 22509476222784 run_lib.py:133] step: 153350, training_loss: 3.68898e-02
I0210 13:50:36.943726 22509476222784 run_lib.py:133] step: 153400, training_loss: 3.87434e-02
I0210 13:50:37.108999 22509476222784 run_lib.py:146] step: 153400, eval_loss: 3.86476e-02
I0210 13:50:56.104629 22509476222784 run_lib.py:133] step: 153450, training_loss: 4.24866e-02
I0210 13:51:14.769852 22509476222784 run_lib.py:133] step: 153500, training_loss: 5.05184e-02
I0210 13:51:14.934757 22509476222784 run_lib.py:146] step: 153500, eval_loss: 4.60823e-02
I0210 13:51:33.496581 22509476222784 run_lib.py:133] step: 153550, training_loss: 5.25330e-02
I0210 13:51:52.051358 22509476222784 run_lib.py:133] step: 153600, training_loss: 2.44195e-02
I0210 13:51:52.221806 22509476222784 run_lib.py:146] step: 153600, eval_loss: 3.38197e-02
I0210 13:52:11.115256 22509476222784 run_lib.py:133] step: 153650, training_loss: 4.00479e-02
I0210 13:52:29.737804 22509476222784 run_lib.py:133] step: 153700, training_loss: 3.69096e-02
I0210 13:52:29.907609 22509476222784 run_lib.py:146] step: 153700, eval_loss: 3.69380e-02
I0210 13:52:48.649109 22509476222784 run_lib.py:133] step: 153750, training_loss: 3.98152e-02
I0210 13:53:07.261391 22509476222784 run_lib.py:133] step: 153800, training_loss: 5.95023e-02
I0210 13:53:07.428007 22509476222784 run_lib.py:146] step: 153800, eval_loss: 4.17135e-02
I0210 13:53:26.140972 22509476222784 run_lib.py:133] step: 153850, training_loss: 4.55622e-02
I0210 13:53:44.784871 22509476222784 run_lib.py:133] step: 153900, training_loss: 4.69631e-02
I0210 13:53:44.951571 22509476222784 run_lib.py:146] step: 153900, eval_loss: 4.06434e-02
I0210 13:54:03.530233 22509476222784 run_lib.py:133] step: 153950, training_loss: 3.22911e-02
I0210 13:54:22.256655 22509476222784 run_lib.py:133] step: 154000, training_loss: 2.78411e-02
I0210 13:54:22.419353 22509476222784 run_lib.py:146] step: 154000, eval_loss: 4.15676e-02
I0210 13:54:40.935728 22509476222784 run_lib.py:133] step: 154050, training_loss: 3.76628e-02
I0210 13:54:59.645719 22509476222784 run_lib.py:133] step: 154100, training_loss: 5.20390e-02
I0210 13:54:59.810669 22509476222784 run_lib.py:146] step: 154100, eval_loss: 5.07199e-02
I0210 13:55:18.390385 22509476222784 run_lib.py:133] step: 154150, training_loss: 3.88347e-02
I0210 13:55:37.017604 22509476222784 run_lib.py:133] step: 154200, training_loss: 4.12524e-02
I0210 13:55:37.186691 22509476222784 run_lib.py:146] step: 154200, eval_loss: 4.24024e-02
I0210 13:55:55.954130 22509476222784 run_lib.py:133] step: 154250, training_loss: 5.25572e-02
I0210 13:56:14.536902 22509476222784 run_lib.py:133] step: 154300, training_loss: 3.22520e-02
I0210 13:56:14.701616 22509476222784 run_lib.py:146] step: 154300, eval_loss: 3.41030e-02
I0210 13:56:33.282898 22509476222784 run_lib.py:133] step: 154350, training_loss: 4.32265e-02
I0210 13:56:51.816863 22509476222784 run_lib.py:133] step: 154400, training_loss: 4.25032e-02
I0210 13:56:51.981625 22509476222784 run_lib.py:146] step: 154400, eval_loss: 4.85786e-02
I0210 13:57:10.668395 22509476222784 run_lib.py:133] step: 154450, training_loss: 4.01542e-02
I0210 13:57:29.287981 22509476222784 run_lib.py:133] step: 154500, training_loss: 4.67044e-02
I0210 13:57:29.453859 22509476222784 run_lib.py:146] step: 154500, eval_loss: 3.99965e-02
I0210 13:57:48.307338 22509476222784 run_lib.py:133] step: 154550, training_loss: 4.75184e-02
I0210 13:58:06.852442 22509476222784 run_lib.py:133] step: 154600, training_loss: 4.05256e-02
I0210 13:58:07.024768 22509476222784 run_lib.py:146] step: 154600, eval_loss: 3.64002e-02
I0210 13:58:25.564038 22509476222784 run_lib.py:133] step: 154650, training_loss: 4.74266e-02
I0210 13:58:44.124274 22509476222784 run_lib.py:133] step: 154700, training_loss: 3.89391e-02
I0210 13:58:44.292892 22509476222784 run_lib.py:146] step: 154700, eval_loss: 3.58055e-02
I0210 13:59:03.016490 22509476222784 run_lib.py:133] step: 154750, training_loss: 3.35332e-02
I0210 13:59:21.787779 22509476222784 run_lib.py:133] step: 154800, training_loss: 4.08612e-02
I0210 13:59:21.997801 22509476222784 run_lib.py:146] step: 154800, eval_loss: 4.05256e-02
I0210 13:59:40.612562 22509476222784 run_lib.py:133] step: 154850, training_loss: 5.93122e-02
I0210 13:59:59.141324 22509476222784 run_lib.py:133] step: 154900, training_loss: 5.10159e-02
I0210 13:59:59.306681 22509476222784 run_lib.py:146] step: 154900, eval_loss: 4.40935e-02
I0210 14:00:18.040987 22509476222784 run_lib.py:133] step: 154950, training_loss: 4.13944e-02
I0210 14:00:36.584969 22509476222784 run_lib.py:133] step: 155000, training_loss: 5.80602e-02
I0210 14:00:36.753857 22509476222784 run_lib.py:146] step: 155000, eval_loss: 4.82470e-02
I0210 14:00:55.564818 22509476222784 run_lib.py:133] step: 155050, training_loss: 5.12716e-02
I0210 14:01:14.156764 22509476222784 run_lib.py:133] step: 155100, training_loss: 4.91978e-02
I0210 14:01:14.325608 22509476222784 run_lib.py:146] step: 155100, eval_loss: 3.93990e-02
I0210 14:01:33.271181 22509476222784 run_lib.py:133] step: 155150, training_loss: 4.89417e-02
I0210 14:01:51.827580 22509476222784 run_lib.py:133] step: 155200, training_loss: 4.26915e-02
I0210 14:01:52.000811 22509476222784 run_lib.py:146] step: 155200, eval_loss: 4.32475e-02
I0210 14:02:10.711372 22509476222784 run_lib.py:133] step: 155250, training_loss: 4.44723e-02
I0210 14:02:29.387141 22509476222784 run_lib.py:133] step: 155300, training_loss: 4.84396e-02
I0210 14:02:29.553312 22509476222784 run_lib.py:146] step: 155300, eval_loss: 3.60532e-02
I0210 14:02:48.231248 22509476222784 run_lib.py:133] step: 155350, training_loss: 4.53241e-02
I0210 14:03:06.988861 22509476222784 run_lib.py:133] step: 155400, training_loss: 4.93754e-02
I0210 14:03:07.151602 22509476222784 run_lib.py:146] step: 155400, eval_loss: 4.18297e-02
I0210 14:03:25.758450 22509476222784 run_lib.py:133] step: 155450, training_loss: 4.74126e-02
I0210 14:03:44.305623 22509476222784 run_lib.py:133] step: 155500, training_loss: 4.47518e-02
I0210 14:03:44.470590 22509476222784 run_lib.py:146] step: 155500, eval_loss: 3.45888e-02
I0210 14:04:03.229110 22509476222784 run_lib.py:133] step: 155550, training_loss: 4.10671e-02
I0210 14:04:22.024871 22509476222784 run_lib.py:133] step: 155600, training_loss: 3.99916e-02
I0210 14:04:22.205597 22509476222784 run_lib.py:146] step: 155600, eval_loss: 3.68136e-02
I0210 14:04:40.819946 22509476222784 run_lib.py:133] step: 155650, training_loss: 2.85683e-02
I0210 14:04:59.385840 22509476222784 run_lib.py:133] step: 155700, training_loss: 2.94935e-02
I0210 14:04:59.551612 22509476222784 run_lib.py:146] step: 155700, eval_loss: 4.34739e-02
I0210 14:05:18.097466 22509476222784 run_lib.py:133] step: 155750, training_loss: 3.92628e-02
I0210 14:05:36.784476 22509476222784 run_lib.py:133] step: 155800, training_loss: 3.89712e-02
I0210 14:05:36.956528 22509476222784 run_lib.py:146] step: 155800, eval_loss: 4.52155e-02
I0210 14:05:55.528596 22509476222784 run_lib.py:133] step: 155850, training_loss: 3.17258e-02
I0210 14:06:14.150067 22509476222784 run_lib.py:133] step: 155900, training_loss: 3.45919e-02
I0210 14:06:14.321816 22509476222784 run_lib.py:146] step: 155900, eval_loss: 4.26781e-02
I0210 14:06:32.918431 22509476222784 run_lib.py:133] step: 155950, training_loss: 5.29310e-02
I0210 14:06:51.694998 22509476222784 run_lib.py:133] step: 156000, training_loss: 5.54451e-02
I0210 14:06:51.860624 22509476222784 run_lib.py:146] step: 156000, eval_loss: 4.64816e-02
I0210 14:07:10.440410 22509476222784 run_lib.py:133] step: 156050, training_loss: 4.65127e-02
I0210 14:07:29.098681 22509476222784 run_lib.py:133] step: 156100, training_loss: 4.82825e-02
I0210 14:07:29.280614 22509476222784 run_lib.py:146] step: 156100, eval_loss: 5.45950e-02
I0210 14:07:47.933881 22509476222784 run_lib.py:133] step: 156150, training_loss: 5.65254e-02
I0210 14:08:06.541756 22509476222784 run_lib.py:133] step: 156200, training_loss: 4.03336e-02
I0210 14:08:06.707884 22509476222784 run_lib.py:146] step: 156200, eval_loss: 5.04421e-02
I0210 14:08:25.538398 22509476222784 run_lib.py:133] step: 156250, training_loss: 5.47787e-02
I0210 14:08:44.174248 22509476222784 run_lib.py:133] step: 156300, training_loss: 3.71270e-02
I0210 14:08:44.340598 22509476222784 run_lib.py:146] step: 156300, eval_loss: 4.83748e-02
I0210 14:09:02.937467 22509476222784 run_lib.py:133] step: 156350, training_loss: 5.07869e-02
I0210 14:09:21.540745 22509476222784 run_lib.py:133] step: 156400, training_loss: 4.68388e-02
I0210 14:09:21.751738 22509476222784 run_lib.py:146] step: 156400, eval_loss: 3.61754e-02
I0210 14:09:40.570775 22509476222784 run_lib.py:133] step: 156450, training_loss: 5.00592e-02
I0210 14:09:59.119501 22509476222784 run_lib.py:133] step: 156500, training_loss: 4.63334e-02
I0210 14:09:59.285756 22509476222784 run_lib.py:146] step: 156500, eval_loss: 4.35671e-02
I0210 14:10:17.988224 22509476222784 run_lib.py:133] step: 156550, training_loss: 4.37293e-02
I0210 14:10:36.583004 22509476222784 run_lib.py:133] step: 156600, training_loss: 4.10359e-02
I0210 14:10:36.750855 22509476222784 run_lib.py:146] step: 156600, eval_loss: 4.21576e-02
I0210 14:10:55.504119 22509476222784 run_lib.py:133] step: 156650, training_loss: 4.06753e-02
I0210 14:11:14.132566 22509476222784 run_lib.py:133] step: 156700, training_loss: 4.32794e-02
I0210 14:11:14.307985 22509476222784 run_lib.py:146] step: 156700, eval_loss: 4.33993e-02
I0210 14:11:32.921269 22509476222784 run_lib.py:133] step: 156750, training_loss: 4.01189e-02
I0210 14:11:51.676612 22509476222784 run_lib.py:133] step: 156800, training_loss: 3.81370e-02
I0210 14:11:51.846695 22509476222784 run_lib.py:146] step: 156800, eval_loss: 4.29597e-02
I0210 14:12:10.383369 22509476222784 run_lib.py:133] step: 156850, training_loss: 4.93908e-02
I0210 14:12:29.110461 22509476222784 run_lib.py:133] step: 156900, training_loss: 4.42678e-02
I0210 14:12:29.273859 22509476222784 run_lib.py:146] step: 156900, eval_loss: 3.94936e-02
I0210 14:12:47.896612 22509476222784 run_lib.py:133] step: 156950, training_loss: 3.80236e-02
I0210 14:13:06.446136 22509476222784 run_lib.py:133] step: 157000, training_loss: 4.60652e-02
I0210 14:13:06.614704 22509476222784 run_lib.py:146] step: 157000, eval_loss: 5.34812e-02
I0210 14:13:25.332374 22509476222784 run_lib.py:133] step: 157050, training_loss: 3.66058e-02
I0210 14:13:43.899576 22509476222784 run_lib.py:133] step: 157100, training_loss: 3.51609e-02
I0210 14:13:44.066125 22509476222784 run_lib.py:146] step: 157100, eval_loss: 4.48674e-02
I0210 14:14:02.909960 22509476222784 run_lib.py:133] step: 157150, training_loss: 5.31663e-02
I0210 14:14:21.709531 22509476222784 run_lib.py:133] step: 157200, training_loss: 3.83314e-02
I0210 14:14:21.874395 22509476222784 run_lib.py:146] step: 157200, eval_loss: 5.58202e-02
I0210 14:14:40.435398 22509476222784 run_lib.py:133] step: 157250, training_loss: 4.00775e-02
I0210 14:14:58.987181 22509476222784 run_lib.py:133] step: 157300, training_loss: 3.55728e-02
I0210 14:14:59.149610 22509476222784 run_lib.py:146] step: 157300, eval_loss: 4.15560e-02
I0210 14:15:17.845045 22509476222784 run_lib.py:133] step: 157350, training_loss: 5.65970e-02
I0210 14:15:36.444957 22509476222784 run_lib.py:133] step: 157400, training_loss: 3.95769e-02
I0210 14:15:36.609817 22509476222784 run_lib.py:146] step: 157400, eval_loss: 4.37338e-02
I0210 14:15:55.196533 22509476222784 run_lib.py:133] step: 157450, training_loss: 4.72882e-02
I0210 14:16:13.799638 22509476222784 run_lib.py:133] step: 157500, training_loss: 4.33918e-02
I0210 14:16:13.981788 22509476222784 run_lib.py:146] step: 157500, eval_loss: 4.05993e-02
I0210 14:16:32.832597 22509476222784 run_lib.py:133] step: 157550, training_loss: 3.86219e-02
I0210 14:16:51.556123 22509476222784 run_lib.py:133] step: 157600, training_loss: 4.71304e-02
I0210 14:16:51.722855 22509476222784 run_lib.py:146] step: 157600, eval_loss: 4.59007e-02
I0210 14:17:10.315386 22509476222784 run_lib.py:133] step: 157650, training_loss: 3.68741e-02
I0210 14:17:28.887517 22509476222784 run_lib.py:133] step: 157700, training_loss: 4.54263e-02
I0210 14:17:29.077763 22509476222784 run_lib.py:146] step: 157700, eval_loss: 3.38545e-02
I0210 14:17:47.843381 22509476222784 run_lib.py:133] step: 157750, training_loss: 3.89349e-02
I0210 14:18:06.449468 22509476222784 run_lib.py:133] step: 157800, training_loss: 4.68171e-02
I0210 14:18:06.615592 22509476222784 run_lib.py:146] step: 157800, eval_loss: 4.30365e-02
I0210 14:18:25.420271 22509476222784 run_lib.py:133] step: 157850, training_loss: 4.35868e-02
I0210 14:18:43.979576 22509476222784 run_lib.py:133] step: 157900, training_loss: 3.89798e-02
I0210 14:18:44.145747 22509476222784 run_lib.py:146] step: 157900, eval_loss: 4.12194e-02
I0210 14:19:02.837939 22509476222784 run_lib.py:133] step: 157950, training_loss: 4.54509e-02
I0210 14:19:21.417245 22509476222784 run_lib.py:133] step: 158000, training_loss: 3.99020e-02
I0210 14:19:21.584604 22509476222784 run_lib.py:146] step: 158000, eval_loss: 4.37106e-02
I0210 14:19:40.319856 22509476222784 run_lib.py:133] step: 158050, training_loss: 4.85577e-02
I0210 14:19:58.919073 22509476222784 run_lib.py:133] step: 158100, training_loss: 6.17843e-02
I0210 14:19:59.083899 22509476222784 run_lib.py:146] step: 158100, eval_loss: 4.19457e-02
I0210 14:20:17.620824 22509476222784 run_lib.py:133] step: 158150, training_loss: 4.45478e-02
I0210 14:20:36.371858 22509476222784 run_lib.py:133] step: 158200, training_loss: 5.43811e-02
I0210 14:20:36.537406 22509476222784 run_lib.py:146] step: 158200, eval_loss: 4.34730e-02
I0210 14:20:55.133728 22509476222784 run_lib.py:133] step: 158250, training_loss: 4.22659e-02
I0210 14:21:13.767471 22509476222784 run_lib.py:133] step: 158300, training_loss: 3.74935e-02
I0210 14:21:13.942096 22509476222784 run_lib.py:146] step: 158300, eval_loss: 4.90127e-02
I0210 14:21:32.779143 22509476222784 run_lib.py:133] step: 158350, training_loss: 4.55285e-02
I0210 14:21:51.387920 22509476222784 run_lib.py:133] step: 158400, training_loss: 4.80755e-02
I0210 14:21:51.554649 22509476222784 run_lib.py:146] step: 158400, eval_loss: 4.14200e-02
I0210 14:22:10.269934 22509476222784 run_lib.py:133] step: 158450, training_loss: 5.63917e-02
I0210 14:22:28.870558 22509476222784 run_lib.py:133] step: 158500, training_loss: 4.73931e-02
I0210 14:22:29.050649 22509476222784 run_lib.py:146] step: 158500, eval_loss: 4.48427e-02
I0210 14:22:47.624310 22509476222784 run_lib.py:133] step: 158550, training_loss: 5.30719e-02
I0210 14:23:06.437098 22509476222784 run_lib.py:133] step: 158600, training_loss: 4.45392e-02
I0210 14:23:06.602809 22509476222784 run_lib.py:146] step: 158600, eval_loss: 3.79566e-02
I0210 14:23:25.217783 22509476222784 run_lib.py:133] step: 158650, training_loss: 4.26115e-02
I0210 14:23:43.777076 22509476222784 run_lib.py:133] step: 158700, training_loss: 3.08158e-02
I0210 14:23:43.941785 22509476222784 run_lib.py:146] step: 158700, eval_loss: 4.26418e-02
I0210 14:24:02.563452 22509476222784 run_lib.py:133] step: 158750, training_loss: 4.50999e-02
I0210 14:24:21.269134 22509476222784 run_lib.py:133] step: 158800, training_loss: 4.72995e-02
I0210 14:24:21.437869 22509476222784 run_lib.py:146] step: 158800, eval_loss: 4.26175e-02
I0210 14:24:40.026858 22509476222784 run_lib.py:133] step: 158850, training_loss: 3.68127e-02
I0210 14:24:58.721889 22509476222784 run_lib.py:133] step: 158900, training_loss: 3.78247e-02
I0210 14:24:58.890019 22509476222784 run_lib.py:146] step: 158900, eval_loss: 4.59811e-02
I0210 14:25:17.441722 22509476222784 run_lib.py:133] step: 158950, training_loss: 3.36411e-02
I0210 14:25:35.979649 22509476222784 run_lib.py:133] step: 159000, training_loss: 4.69435e-02
I0210 14:25:36.156745 22509476222784 run_lib.py:146] step: 159000, eval_loss: 3.82566e-02
I0210 14:25:54.957010 22509476222784 run_lib.py:133] step: 159050, training_loss: 3.95735e-02
I0210 14:26:13.650262 22509476222784 run_lib.py:133] step: 159100, training_loss: 4.09831e-02
I0210 14:26:13.816133 22509476222784 run_lib.py:146] step: 159100, eval_loss: 5.60831e-02
I0210 14:26:32.377017 22509476222784 run_lib.py:133] step: 159150, training_loss: 5.16211e-02
I0210 14:26:50.930710 22509476222784 run_lib.py:133] step: 159200, training_loss: 4.54892e-02
I0210 14:26:51.093589 22509476222784 run_lib.py:146] step: 159200, eval_loss: 5.07264e-02
I0210 14:27:09.925353 22509476222784 run_lib.py:133] step: 159250, training_loss: 3.95971e-02
I0210 14:27:28.499195 22509476222784 run_lib.py:133] step: 159300, training_loss: 3.52805e-02
I0210 14:27:28.668664 22509476222784 run_lib.py:146] step: 159300, eval_loss: 4.40423e-02
I0210 14:27:47.480843 22509476222784 run_lib.py:133] step: 159350, training_loss: 4.65777e-02
I0210 14:28:06.048824 22509476222784 run_lib.py:133] step: 159400, training_loss: 4.96178e-02
I0210 14:28:06.217715 22509476222784 run_lib.py:146] step: 159400, eval_loss: 4.58206e-02
I0210 14:28:24.935734 22509476222784 run_lib.py:133] step: 159450, training_loss: 2.70964e-02
I0210 14:28:43.459618 22509476222784 run_lib.py:133] step: 159500, training_loss: 3.61080e-02
I0210 14:28:43.626798 22509476222784 run_lib.py:146] step: 159500, eval_loss: 4.03592e-02
I0210 14:29:02.286640 22509476222784 run_lib.py:133] step: 159550, training_loss: 4.25698e-02
I0210 14:29:21.059758 22509476222784 run_lib.py:133] step: 159600, training_loss: 5.28931e-02
I0210 14:29:21.229895 22509476222784 run_lib.py:146] step: 159600, eval_loss: 3.62912e-02
I0210 14:29:39.827790 22509476222784 run_lib.py:133] step: 159650, training_loss: 3.55252e-02
I0210 14:29:58.526869 22509476222784 run_lib.py:133] step: 159700, training_loss: 3.90065e-02
I0210 14:29:58.689738 22509476222784 run_lib.py:146] step: 159700, eval_loss: 5.06914e-02
I0210 14:30:17.289314 22509476222784 run_lib.py:133] step: 159750, training_loss: 5.13264e-02
I0210 14:30:35.857338 22509476222784 run_lib.py:133] step: 159800, training_loss: 3.50142e-02
I0210 14:30:36.045731 22509476222784 run_lib.py:146] step: 159800, eval_loss: 3.97537e-02
I0210 14:30:54.838942 22509476222784 run_lib.py:133] step: 159850, training_loss: 4.32955e-02
I0210 14:31:13.436109 22509476222784 run_lib.py:133] step: 159900, training_loss: 5.24345e-02
I0210 14:31:13.607758 22509476222784 run_lib.py:146] step: 159900, eval_loss: 4.15542e-02
I0210 14:31:32.160775 22509476222784 run_lib.py:133] step: 159950, training_loss: 3.95991e-02
I0210 14:31:50.869354 22509476222784 run_lib.py:133] step: 160000, training_loss: 4.23899e-02
I0210 14:31:52.185093 22509476222784 run_lib.py:146] step: 160000, eval_loss: 3.95999e-02
I0210 14:32:13.920892 22509476222784 run_lib.py:133] step: 160050, training_loss: 4.75289e-02
I0210 14:32:32.576150 22509476222784 run_lib.py:133] step: 160100, training_loss: 4.70720e-02
I0210 14:32:32.743964 22509476222784 run_lib.py:146] step: 160100, eval_loss: 4.30406e-02
I0210 14:32:51.536580 22509476222784 run_lib.py:133] step: 160150, training_loss: 5.07100e-02
I0210 14:33:10.099652 22509476222784 run_lib.py:133] step: 160200, training_loss: 4.21618e-02
I0210 14:33:10.264894 22509476222784 run_lib.py:146] step: 160200, eval_loss: 4.51641e-02
I0210 14:33:28.837321 22509476222784 run_lib.py:133] step: 160250, training_loss: 3.76041e-02
I0210 14:33:47.419044 22509476222784 run_lib.py:133] step: 160300, training_loss: 4.14795e-02
I0210 14:33:47.581510 22509476222784 run_lib.py:146] step: 160300, eval_loss: 4.85796e-02
I0210 14:34:06.259700 22509476222784 run_lib.py:133] step: 160350, training_loss: 5.62888e-02
I0210 14:34:24.810364 22509476222784 run_lib.py:133] step: 160400, training_loss: 4.28451e-02
I0210 14:34:24.995678 22509476222784 run_lib.py:146] step: 160400, eval_loss: 3.27812e-02
I0210 14:34:43.694195 22509476222784 run_lib.py:133] step: 160450, training_loss: 4.57174e-02
I0210 14:35:02.275244 22509476222784 run_lib.py:133] step: 160500, training_loss: 4.01537e-02
I0210 14:35:02.441747 22509476222784 run_lib.py:146] step: 160500, eval_loss: 3.52422e-02
I0210 14:35:20.975794 22509476222784 run_lib.py:133] step: 160550, training_loss: 4.96909e-02
I0210 14:35:39.480278 22509476222784 run_lib.py:133] step: 160600, training_loss: 4.74662e-02
I0210 14:35:39.646919 22509476222784 run_lib.py:146] step: 160600, eval_loss: 4.53972e-02
I0210 14:35:58.338489 22509476222784 run_lib.py:133] step: 160650, training_loss: 4.10762e-02
I0210 14:36:17.091871 22509476222784 run_lib.py:133] step: 160700, training_loss: 5.44043e-02
I0210 14:36:17.253480 22509476222784 run_lib.py:146] step: 160700, eval_loss: 6.35188e-02
I0210 14:36:35.851558 22509476222784 run_lib.py:133] step: 160750, training_loss: 3.34701e-02
I0210 14:36:54.400828 22509476222784 run_lib.py:133] step: 160800, training_loss: 4.70197e-02
I0210 14:36:54.572713 22509476222784 run_lib.py:146] step: 160800, eval_loss: 5.00084e-02
I0210 14:37:13.299712 22509476222784 run_lib.py:133] step: 160850, training_loss: 4.21203e-02
I0210 14:37:31.892907 22509476222784 run_lib.py:133] step: 160900, training_loss: 4.55323e-02
I0210 14:37:32.083771 22509476222784 run_lib.py:146] step: 160900, eval_loss: 5.30560e-02
I0210 14:37:50.850481 22509476222784 run_lib.py:133] step: 160950, training_loss: 4.80912e-02
I0210 14:38:09.472789 22509476222784 run_lib.py:133] step: 161000, training_loss: 4.65158e-02
I0210 14:38:09.639068 22509476222784 run_lib.py:146] step: 161000, eval_loss: 4.21305e-02
I0210 14:38:28.417443 22509476222784 run_lib.py:133] step: 161050, training_loss: 3.57578e-02
I0210 14:38:46.976437 22509476222784 run_lib.py:133] step: 161100, training_loss: 3.84395e-02
I0210 14:38:47.141669 22509476222784 run_lib.py:146] step: 161100, eval_loss: 5.24375e-02
I0210 14:39:05.867321 22509476222784 run_lib.py:133] step: 161150, training_loss: 4.64424e-02
I0210 14:39:24.487614 22509476222784 run_lib.py:133] step: 161200, training_loss: 4.99433e-02
I0210 14:39:24.652893 22509476222784 run_lib.py:146] step: 161200, eval_loss: 4.96368e-02
I0210 14:39:43.265688 22509476222784 run_lib.py:133] step: 161250, training_loss: 4.19969e-02
I0210 14:40:02.007919 22509476222784 run_lib.py:133] step: 161300, training_loss: 5.09876e-02
I0210 14:40:02.174703 22509476222784 run_lib.py:146] step: 161300, eval_loss: 4.32019e-02
I0210 14:40:20.694649 22509476222784 run_lib.py:133] step: 161350, training_loss: 3.67925e-02
I0210 14:40:39.285870 22509476222784 run_lib.py:133] step: 161400, training_loss: 4.56872e-02
I0210 14:40:39.453979 22509476222784 run_lib.py:146] step: 161400, eval_loss: 2.99188e-02
I0210 14:40:58.194402 22509476222784 run_lib.py:133] step: 161450, training_loss: 4.71074e-02
I0210 14:41:17.047336 22509476222784 run_lib.py:133] step: 161500, training_loss: 4.57532e-02
I0210 14:41:17.212776 22509476222784 run_lib.py:146] step: 161500, eval_loss: 4.49304e-02
I0210 14:41:35.738296 22509476222784 run_lib.py:133] step: 161550, training_loss: 4.79638e-02
I0210 14:41:54.301347 22509476222784 run_lib.py:133] step: 161600, training_loss: 3.89998e-02
I0210 14:41:54.466715 22509476222784 run_lib.py:146] step: 161600, eval_loss: 5.62774e-02
I0210 14:42:13.018806 22509476222784 run_lib.py:133] step: 161650, training_loss: 3.85643e-02
I0210 14:42:31.724145 22509476222784 run_lib.py:133] step: 161700, training_loss: 5.57240e-02
I0210 14:42:31.885808 22509476222784 run_lib.py:146] step: 161700, eval_loss: 5.39200e-02
I0210 14:42:50.423905 22509476222784 run_lib.py:133] step: 161750, training_loss: 4.68723e-02
I0210 14:43:09.017440 22509476222784 run_lib.py:133] step: 161800, training_loss: 3.40484e-02
I0210 14:43:09.189701 22509476222784 run_lib.py:146] step: 161800, eval_loss: 5.11915e-02
I0210 14:43:27.792293 22509476222784 run_lib.py:133] step: 161850, training_loss: 5.28165e-02
I0210 14:43:46.648266 22509476222784 run_lib.py:133] step: 161900, training_loss: 4.47789e-02
I0210 14:43:46.814912 22509476222784 run_lib.py:146] step: 161900, eval_loss: 5.28414e-02
I0210 14:44:05.356916 22509476222784 run_lib.py:133] step: 161950, training_loss: 4.09285e-02
I0210 14:44:23.961109 22509476222784 run_lib.py:133] step: 162000, training_loss: 4.54005e-02
I0210 14:44:24.136909 22509476222784 run_lib.py:146] step: 162000, eval_loss: 3.82159e-02
I0210 14:44:42.759339 22509476222784 run_lib.py:133] step: 162050, training_loss: 4.38742e-02
I0210 14:45:01.367820 22509476222784 run_lib.py:133] step: 162100, training_loss: 4.16413e-02
I0210 14:45:01.549963 22509476222784 run_lib.py:146] step: 162100, eval_loss: 4.06667e-02
I0210 14:45:20.515364 22509476222784 run_lib.py:133] step: 162150, training_loss: 3.47758e-02
I0210 14:45:39.110408 22509476222784 run_lib.py:133] step: 162200, training_loss: 4.24557e-02
I0210 14:45:39.274757 22509476222784 run_lib.py:146] step: 162200, eval_loss: 4.70123e-02
I0210 14:45:57.817029 22509476222784 run_lib.py:133] step: 162250, training_loss: 3.24427e-02
I0210 14:46:16.387655 22509476222784 run_lib.py:133] step: 162300, training_loss: 3.13592e-02
I0210 14:46:16.571580 22509476222784 run_lib.py:146] step: 162300, eval_loss: 5.63328e-02
I0210 14:46:35.403769 22509476222784 run_lib.py:133] step: 162350, training_loss: 4.53133e-02
I0210 14:46:54.053566 22509476222784 run_lib.py:133] step: 162400, training_loss: 3.92768e-02
I0210 14:46:54.219980 22509476222784 run_lib.py:146] step: 162400, eval_loss: 4.46146e-02
I0210 14:47:12.925414 22509476222784 run_lib.py:133] step: 162450, training_loss: 4.48902e-02
I0210 14:47:31.512504 22509476222784 run_lib.py:133] step: 162500, training_loss: 4.25659e-02
I0210 14:47:31.678408 22509476222784 run_lib.py:146] step: 162500, eval_loss: 3.37561e-02
I0210 14:47:50.412072 22509476222784 run_lib.py:133] step: 162550, training_loss: 5.39977e-02
I0210 14:48:09.006895 22509476222784 run_lib.py:133] step: 162600, training_loss: 4.02662e-02
I0210 14:48:09.172481 22509476222784 run_lib.py:146] step: 162600, eval_loss: 3.35451e-02
I0210 14:48:27.813733 22509476222784 run_lib.py:133] step: 162650, training_loss: 3.02476e-02
I0210 14:48:46.593466 22509476222784 run_lib.py:133] step: 162700, training_loss: 3.12996e-02
I0210 14:48:46.756827 22509476222784 run_lib.py:146] step: 162700, eval_loss: 4.45367e-02
I0210 14:49:05.306622 22509476222784 run_lib.py:133] step: 162750, training_loss: 4.25436e-02
I0210 14:49:24.013614 22509476222784 run_lib.py:133] step: 162800, training_loss: 4.81068e-02
I0210 14:49:24.195384 22509476222784 run_lib.py:146] step: 162800, eval_loss: 4.19018e-02
I0210 14:49:42.765603 22509476222784 run_lib.py:133] step: 162850, training_loss: 3.97721e-02
I0210 14:50:01.389072 22509476222784 run_lib.py:133] step: 162900, training_loss: 3.57567e-02
I0210 14:50:01.555881 22509476222784 run_lib.py:146] step: 162900, eval_loss: 4.08717e-02
I0210 14:50:20.329354 22509476222784 run_lib.py:133] step: 162950, training_loss: 4.69052e-02
I0210 14:50:38.886191 22509476222784 run_lib.py:133] step: 163000, training_loss: 4.69659e-02
I0210 14:50:39.051584 22509476222784 run_lib.py:146] step: 163000, eval_loss: 4.33063e-02
I0210 14:50:57.633700 22509476222784 run_lib.py:133] step: 163050, training_loss: 4.49601e-02
I0210 14:51:16.342698 22509476222784 run_lib.py:133] step: 163100, training_loss: 4.05487e-02
I0210 14:51:16.509178 22509476222784 run_lib.py:146] step: 163100, eval_loss: 2.66278e-02
I0210 14:51:35.186952 22509476222784 run_lib.py:133] step: 163150, training_loss: 4.35359e-02
I0210 14:51:53.761787 22509476222784 run_lib.py:133] step: 163200, training_loss: 3.91535e-02
I0210 14:51:53.927969 22509476222784 run_lib.py:146] step: 163200, eval_loss: 4.58052e-02
I0210 14:52:12.636581 22509476222784 run_lib.py:133] step: 163250, training_loss: 4.23668e-02
I0210 14:52:31.202415 22509476222784 run_lib.py:133] step: 163300, training_loss: 3.64472e-02
I0210 14:52:31.370994 22509476222784 run_lib.py:146] step: 163300, eval_loss: 3.84848e-02
I0210 14:52:49.908581 22509476222784 run_lib.py:133] step: 163350, training_loss: 5.56546e-02
I0210 14:53:08.557545 22509476222784 run_lib.py:133] step: 163400, training_loss: 3.44341e-02
I0210 14:53:08.727798 22509476222784 run_lib.py:146] step: 163400, eval_loss: 3.41425e-02
I0210 14:53:27.543425 22509476222784 run_lib.py:133] step: 163450, training_loss: 5.16756e-02
I0210 14:53:46.218352 22509476222784 run_lib.py:133] step: 163500, training_loss: 5.09236e-02
I0210 14:53:46.387547 22509476222784 run_lib.py:146] step: 163500, eval_loss: 4.51430e-02
I0210 14:54:04.972592 22509476222784 run_lib.py:133] step: 163550, training_loss: 3.86718e-02
I0210 14:54:23.526408 22509476222784 run_lib.py:133] step: 163600, training_loss: 4.24200e-02
I0210 14:54:23.700538 22509476222784 run_lib.py:146] step: 163600, eval_loss: 4.23407e-02
I0210 14:54:42.451665 22509476222784 run_lib.py:133] step: 163650, training_loss: 4.96423e-02
I0210 14:55:01.053053 22509476222784 run_lib.py:133] step: 163700, training_loss: 5.09586e-02
I0210 14:55:01.234688 22509476222784 run_lib.py:146] step: 163700, eval_loss: 4.24291e-02
I0210 14:55:20.037333 22509476222784 run_lib.py:133] step: 163750, training_loss: 3.30768e-02
I0210 14:55:38.670608 22509476222784 run_lib.py:133] step: 163800, training_loss: 4.24526e-02
I0210 14:55:38.834857 22509476222784 run_lib.py:146] step: 163800, eval_loss: 4.82908e-02
I0210 14:55:57.624503 22509476222784 run_lib.py:133] step: 163850, training_loss: 3.98619e-02
I0210 14:56:16.194479 22509476222784 run_lib.py:133] step: 163900, training_loss: 4.48322e-02
I0210 14:56:16.358360 22509476222784 run_lib.py:146] step: 163900, eval_loss: 3.66404e-02
I0210 14:56:35.092477 22509476222784 run_lib.py:133] step: 163950, training_loss: 3.65388e-02
I0210 14:56:53.714771 22509476222784 run_lib.py:133] step: 164000, training_loss: 3.63209e-02
I0210 14:56:53.881036 22509476222784 run_lib.py:146] step: 164000, eval_loss: 2.75043e-02
I0210 14:57:12.557564 22509476222784 run_lib.py:133] step: 164050, training_loss: 4.64482e-02
I0210 14:57:31.271696 22509476222784 run_lib.py:133] step: 164100, training_loss: 4.73427e-02
I0210 14:57:31.436813 22509476222784 run_lib.py:146] step: 164100, eval_loss: 4.50521e-02
I0210 14:57:50.021555 22509476222784 run_lib.py:133] step: 164150, training_loss: 4.60214e-02
I0210 14:58:08.625662 22509476222784 run_lib.py:133] step: 164200, training_loss: 5.30427e-02
I0210 14:58:08.798947 22509476222784 run_lib.py:146] step: 164200, eval_loss: 4.03417e-02
I0210 14:58:27.565387 22509476222784 run_lib.py:133] step: 164250, training_loss: 4.45664e-02
I0210 14:58:46.172105 22509476222784 run_lib.py:133] step: 164300, training_loss: 4.67795e-02
I0210 14:58:46.339888 22509476222784 run_lib.py:146] step: 164300, eval_loss: 4.47406e-02
I0210 14:59:05.106071 22509476222784 run_lib.py:133] step: 164350, training_loss: 4.78738e-02
I0210 14:59:23.713499 22509476222784 run_lib.py:133] step: 164400, training_loss: 4.61205e-02
I0210 14:59:23.878943 22509476222784 run_lib.py:146] step: 164400, eval_loss: 5.40965e-02
I0210 14:59:42.426565 22509476222784 run_lib.py:133] step: 164450, training_loss: 5.34799e-02
I0210 15:00:01.205322 22509476222784 run_lib.py:133] step: 164500, training_loss: 4.97238e-02
I0210 15:00:01.370992 22509476222784 run_lib.py:146] step: 164500, eval_loss: 4.39886e-02
I0210 15:00:19.948922 22509476222784 run_lib.py:133] step: 164550, training_loss: 4.69555e-02
I0210 15:00:38.507964 22509476222784 run_lib.py:133] step: 164600, training_loss: 3.84839e-02
I0210 15:00:38.673675 22509476222784 run_lib.py:146] step: 164600, eval_loss: 4.63659e-02
I0210 15:00:57.229140 22509476222784 run_lib.py:133] step: 164650, training_loss: 5.10462e-02
I0210 15:01:16.040630 22509476222784 run_lib.py:133] step: 164700, training_loss: 4.85493e-02
I0210 15:01:16.209882 22509476222784 run_lib.py:146] step: 164700, eval_loss: 5.30101e-02
I0210 15:01:34.959694 22509476222784 run_lib.py:133] step: 164750, training_loss: 4.52085e-02
I0210 15:01:53.660691 22509476222784 run_lib.py:133] step: 164800, training_loss: 4.59596e-02
I0210 15:01:53.826795 22509476222784 run_lib.py:146] step: 164800, eval_loss: 4.21792e-02
I0210 15:02:12.412677 22509476222784 run_lib.py:133] step: 164850, training_loss: 4.19768e-02
I0210 15:02:30.968290 22509476222784 run_lib.py:133] step: 164900, training_loss: 4.68037e-02
I0210 15:02:31.133786 22509476222784 run_lib.py:146] step: 164900, eval_loss: 2.81200e-02
I0210 15:02:49.853908 22509476222784 run_lib.py:133] step: 164950, training_loss: 4.15781e-02
I0210 15:03:08.486355 22509476222784 run_lib.py:133] step: 165000, training_loss: 4.30909e-02
I0210 15:03:08.648752 22509476222784 run_lib.py:146] step: 165000, eval_loss: 4.81497e-02
I0210 15:03:27.337098 22509476222784 run_lib.py:133] step: 165050, training_loss: 3.44781e-02
I0210 15:03:45.944175 22509476222784 run_lib.py:133] step: 165100, training_loss: 3.48559e-02
I0210 15:03:46.115891 22509476222784 run_lib.py:146] step: 165100, eval_loss: 4.95856e-02
I0210 15:04:04.910882 22509476222784 run_lib.py:133] step: 165150, training_loss: 4.14753e-02
I0210 15:04:23.527390 22509476222784 run_lib.py:133] step: 165200, training_loss: 3.84542e-02
I0210 15:04:23.695043 22509476222784 run_lib.py:146] step: 165200, eval_loss: 3.03169e-02
I0210 15:04:42.414422 22509476222784 run_lib.py:133] step: 165250, training_loss: 4.32700e-02
I0210 15:05:01.013148 22509476222784 run_lib.py:133] step: 165300, training_loss: 4.59538e-02
I0210 15:05:01.188856 22509476222784 run_lib.py:146] step: 165300, eval_loss: 5.97544e-02
I0210 15:05:19.987665 22509476222784 run_lib.py:133] step: 165350, training_loss: 4.15780e-02
I0210 15:05:38.590500 22509476222784 run_lib.py:133] step: 165400, training_loss: 4.41707e-02
I0210 15:05:38.755769 22509476222784 run_lib.py:146] step: 165400, eval_loss: 5.08121e-02
I0210 15:05:57.320067 22509476222784 run_lib.py:133] step: 165450, training_loss: 5.00755e-02
I0210 15:06:16.049829 22509476222784 run_lib.py:133] step: 165500, training_loss: 3.96999e-02
I0210 15:06:16.212596 22509476222784 run_lib.py:146] step: 165500, eval_loss: 3.84600e-02
I0210 15:06:34.820218 22509476222784 run_lib.py:133] step: 165550, training_loss: 4.81683e-02
I0210 15:06:53.588052 22509476222784 run_lib.py:133] step: 165600, training_loss: 4.27423e-02
I0210 15:06:53.759636 22509476222784 run_lib.py:146] step: 165600, eval_loss: 4.40036e-02
I0210 15:07:12.336363 22509476222784 run_lib.py:133] step: 165650, training_loss: 4.64774e-02
I0210 15:07:30.916918 22509476222784 run_lib.py:133] step: 165700, training_loss: 5.65340e-02
I0210 15:07:31.084024 22509476222784 run_lib.py:146] step: 165700, eval_loss: 4.84838e-02
I0210 15:07:49.862207 22509476222784 run_lib.py:133] step: 165750, training_loss: 3.45429e-02
I0210 15:08:08.469364 22509476222784 run_lib.py:133] step: 165800, training_loss: 4.02356e-02
I0210 15:08:08.649886 22509476222784 run_lib.py:146] step: 165800, eval_loss: 3.87436e-02
I0210 15:08:27.271646 22509476222784 run_lib.py:133] step: 165850, training_loss: 4.90064e-02
I0210 15:08:46.103185 22509476222784 run_lib.py:133] step: 165900, training_loss: 3.66858e-02
I0210 15:08:46.269032 22509476222784 run_lib.py:146] step: 165900, eval_loss: 4.08476e-02
I0210 15:09:04.873204 22509476222784 run_lib.py:133] step: 165950, training_loss: 5.45172e-02
I0210 15:09:23.496208 22509476222784 run_lib.py:133] step: 166000, training_loss: 3.44712e-02
I0210 15:09:23.825616 22509476222784 run_lib.py:146] step: 166000, eval_loss: 4.87999e-02
I0210 15:09:42.381944 22509476222784 run_lib.py:133] step: 166050, training_loss: 4.31542e-02
I0210 15:10:00.996715 22509476222784 run_lib.py:133] step: 166100, training_loss: 4.37761e-02
I0210 15:10:01.180636 22509476222784 run_lib.py:146] step: 166100, eval_loss: 4.78345e-02
I0210 15:10:19.807446 22509476222784 run_lib.py:133] step: 166150, training_loss: 4.69079e-02
I0210 15:10:38.449066 22509476222784 run_lib.py:133] step: 166200, training_loss: 4.61411e-02
I0210 15:10:38.616843 22509476222784 run_lib.py:146] step: 166200, eval_loss: 3.45375e-02
I0210 15:10:57.385428 22509476222784 run_lib.py:133] step: 166250, training_loss: 3.87948e-02
I0210 15:11:16.016808 22509476222784 run_lib.py:133] step: 166300, training_loss: 3.61296e-02
I0210 15:11:16.182579 22509476222784 run_lib.py:146] step: 166300, eval_loss: 4.26395e-02
I0210 15:11:34.765360 22509476222784 run_lib.py:133] step: 166350, training_loss: 4.82804e-02
I0210 15:11:53.394843 22509476222784 run_lib.py:133] step: 166400, training_loss: 4.07687e-02
I0210 15:11:53.560357 22509476222784 run_lib.py:146] step: 166400, eval_loss: 4.68333e-02
I0210 15:12:12.432046 22509476222784 run_lib.py:133] step: 166450, training_loss: 3.34168e-02
I0210 15:12:31.103663 22509476222784 run_lib.py:133] step: 166500, training_loss: 5.46151e-02
I0210 15:12:31.268641 22509476222784 run_lib.py:146] step: 166500, eval_loss: 4.94532e-02
I0210 15:12:49.805613 22509476222784 run_lib.py:133] step: 166550, training_loss: 4.73011e-02
I0210 15:13:08.355741 22509476222784 run_lib.py:133] step: 166600, training_loss: 3.53701e-02
I0210 15:13:08.537619 22509476222784 run_lib.py:146] step: 166600, eval_loss: 4.41665e-02
I0210 15:13:27.329300 22509476222784 run_lib.py:133] step: 166650, training_loss: 3.92645e-02
I0210 15:13:45.932716 22509476222784 run_lib.py:133] step: 166700, training_loss: 3.01189e-02
I0210 15:13:46.098846 22509476222784 run_lib.py:146] step: 166700, eval_loss: 4.27140e-02
I0210 15:14:04.824978 22509476222784 run_lib.py:133] step: 166750, training_loss: 3.91469e-02
I0210 15:14:23.352228 22509476222784 run_lib.py:133] step: 166800, training_loss: 4.79493e-02
I0210 15:14:23.517360 22509476222784 run_lib.py:146] step: 166800, eval_loss: 3.95102e-02
I0210 15:14:42.289913 22509476222784 run_lib.py:133] step: 166850, training_loss: 4.97378e-02
I0210 15:15:00.858516 22509476222784 run_lib.py:133] step: 166900, training_loss: 5.99975e-02
I0210 15:15:01.023811 22509476222784 run_lib.py:146] step: 166900, eval_loss: 4.99767e-02
I0210 15:15:19.618690 22509476222784 run_lib.py:133] step: 166950, training_loss: 5.06000e-02
I0210 15:15:38.331846 22509476222784 run_lib.py:133] step: 167000, training_loss: 4.45297e-02
I0210 15:15:38.496746 22509476222784 run_lib.py:146] step: 167000, eval_loss: 4.08771e-02
I0210 15:15:57.065535 22509476222784 run_lib.py:133] step: 167050, training_loss: 5.54620e-02
I0210 15:16:15.783456 22509476222784 run_lib.py:133] step: 167100, training_loss: 3.56473e-02
I0210 15:16:15.968707 22509476222784 run_lib.py:146] step: 167100, eval_loss: 4.58829e-02
I0210 15:16:34.649771 22509476222784 run_lib.py:133] step: 167150, training_loss: 3.62443e-02
I0210 15:16:53.239148 22509476222784 run_lib.py:133] step: 167200, training_loss: 5.36497e-02
I0210 15:16:53.412930 22509476222784 run_lib.py:146] step: 167200, eval_loss: 4.41661e-02
I0210 15:17:12.012765 22509476222784 run_lib.py:133] step: 167250, training_loss: 4.22154e-02
I0210 15:17:30.808635 22509476222784 run_lib.py:133] step: 167300, training_loss: 6.36887e-02
I0210 15:17:30.974781 22509476222784 run_lib.py:146] step: 167300, eval_loss: 3.82334e-02
I0210 15:17:49.572892 22509476222784 run_lib.py:133] step: 167350, training_loss: 4.23108e-02
I0210 15:18:08.172804 22509476222784 run_lib.py:133] step: 167400, training_loss: 3.85431e-02
I0210 15:18:08.341976 22509476222784 run_lib.py:146] step: 167400, eval_loss: 4.47613e-02
I0210 15:18:27.194070 22509476222784 run_lib.py:133] step: 167450, training_loss: 3.83052e-02
I0210 15:18:45.794762 22509476222784 run_lib.py:133] step: 167500, training_loss: 4.10793e-02
I0210 15:18:45.968699 22509476222784 run_lib.py:146] step: 167500, eval_loss: 3.82336e-02
I0210 15:19:04.634460 22509476222784 run_lib.py:133] step: 167550, training_loss: 5.24180e-02
I0210 15:19:23.214853 22509476222784 run_lib.py:133] step: 167600, training_loss: 3.71647e-02
I0210 15:19:23.382288 22509476222784 run_lib.py:146] step: 167600, eval_loss: 4.71266e-02
I0210 15:19:41.968949 22509476222784 run_lib.py:133] step: 167650, training_loss: 4.58232e-02
I0210 15:20:00.595121 22509476222784 run_lib.py:133] step: 167700, training_loss: 3.34015e-02
I0210 15:20:00.763012 22509476222784 run_lib.py:146] step: 167700, eval_loss: 3.47271e-02
I0210 15:20:19.539579 22509476222784 run_lib.py:133] step: 167750, training_loss: 4.30809e-02
I0210 15:20:38.132157 22509476222784 run_lib.py:133] step: 167800, training_loss: 5.17971e-02
I0210 15:20:38.304504 22509476222784 run_lib.py:146] step: 167800, eval_loss: 4.27176e-02
I0210 15:20:56.901687 22509476222784 run_lib.py:133] step: 167850, training_loss: 4.63479e-02
I0210 15:21:15.469652 22509476222784 run_lib.py:133] step: 167900, training_loss: 4.32864e-02
I0210 15:21:15.632534 22509476222784 run_lib.py:146] step: 167900, eval_loss: 3.89805e-02
I0210 15:21:34.392124 22509476222784 run_lib.py:133] step: 167950, training_loss: 4.71904e-02
I0210 15:21:52.976440 22509476222784 run_lib.py:133] step: 168000, training_loss: 4.04254e-02
I0210 15:21:53.171014 22509476222784 run_lib.py:146] step: 168000, eval_loss: 4.49260e-02
I0210 15:22:11.976660 22509476222784 run_lib.py:133] step: 168050, training_loss: 4.00665e-02
I0210 15:22:30.607894 22509476222784 run_lib.py:133] step: 168100, training_loss: 4.60365e-02
I0210 15:22:30.775643 22509476222784 run_lib.py:146] step: 168100, eval_loss: 3.72009e-02
I0210 15:22:49.517329 22509476222784 run_lib.py:133] step: 168150, training_loss: 3.61240e-02
I0210 15:23:08.095744 22509476222784 run_lib.py:133] step: 168200, training_loss: 5.40156e-02
I0210 15:23:08.263324 22509476222784 run_lib.py:146] step: 168200, eval_loss: 3.96969e-02
I0210 15:23:27.077039 22509476222784 run_lib.py:133] step: 168250, training_loss: 3.74135e-02
I0210 15:23:45.682348 22509476222784 run_lib.py:133] step: 168300, training_loss: 4.02960e-02
I0210 15:23:45.844649 22509476222784 run_lib.py:146] step: 168300, eval_loss: 3.90480e-02
I0210 15:24:04.435783 22509476222784 run_lib.py:133] step: 168350, training_loss: 4.03481e-02
I0210 15:24:23.133813 22509476222784 run_lib.py:133] step: 168400, training_loss: 3.90631e-02
I0210 15:24:23.307857 22509476222784 run_lib.py:146] step: 168400, eval_loss: 5.24501e-02
I0210 15:24:41.851418 22509476222784 run_lib.py:133] step: 168450, training_loss: 5.88752e-02
I0210 15:25:00.468989 22509476222784 run_lib.py:133] step: 168500, training_loss: 3.65609e-02
I0210 15:25:00.652861 22509476222784 run_lib.py:146] step: 168500, eval_loss: 4.51070e-02
I0210 15:25:19.472846 22509476222784 run_lib.py:133] step: 168550, training_loss: 4.49070e-02
I0210 15:25:38.187053 22509476222784 run_lib.py:133] step: 168600, training_loss: 5.55024e-02
I0210 15:25:38.353902 22509476222784 run_lib.py:146] step: 168600, eval_loss: 4.37151e-02
I0210 15:25:56.956252 22509476222784 run_lib.py:133] step: 168650, training_loss: 5.18812e-02
I0210 15:26:15.526388 22509476222784 run_lib.py:133] step: 168700, training_loss: 4.08087e-02
I0210 15:26:15.695616 22509476222784 run_lib.py:146] step: 168700, eval_loss: 5.45397e-02
I0210 15:26:34.306890 22509476222784 run_lib.py:133] step: 168750, training_loss: 3.90530e-02
I0210 15:26:53.087828 22509476222784 run_lib.py:133] step: 168800, training_loss: 3.93856e-02
I0210 15:26:53.251868 22509476222784 run_lib.py:146] step: 168800, eval_loss: 4.15222e-02
I0210 15:27:11.830329 22509476222784 run_lib.py:133] step: 168850, training_loss: 3.56746e-02
I0210 15:27:30.411561 22509476222784 run_lib.py:133] step: 168900, training_loss: 4.75122e-02
I0210 15:27:30.577239 22509476222784 run_lib.py:146] step: 168900, eval_loss: 4.66469e-02
I0210 15:27:49.091420 22509476222784 run_lib.py:133] step: 168950, training_loss: 4.31373e-02
I0210 15:28:07.830670 22509476222784 run_lib.py:133] step: 169000, training_loss: 4.64489e-02
I0210 15:28:08.011963 22509476222784 run_lib.py:146] step: 169000, eval_loss: 4.08087e-02
I0210 15:28:26.584446 22509476222784 run_lib.py:133] step: 169050, training_loss: 3.44169e-02
I0210 15:28:45.314378 22509476222784 run_lib.py:133] step: 169100, training_loss: 3.82647e-02
I0210 15:28:45.481038 22509476222784 run_lib.py:146] step: 169100, eval_loss: 4.08613e-02
I0210 15:29:04.093979 22509476222784 run_lib.py:133] step: 169150, training_loss: 4.55380e-02
I0210 15:29:22.666927 22509476222784 run_lib.py:133] step: 169200, training_loss: 4.24236e-02
I0210 15:29:22.832860 22509476222784 run_lib.py:146] step: 169200, eval_loss: 4.91978e-02
I0210 15:29:41.616318 22509476222784 run_lib.py:133] step: 169250, training_loss: 5.12399e-02
I0210 15:30:00.341281 22509476222784 run_lib.py:133] step: 169300, training_loss: 4.37366e-02
I0210 15:30:00.504837 22509476222784 run_lib.py:146] step: 169300, eval_loss: 3.67514e-02
I0210 15:30:19.190135 22509476222784 run_lib.py:133] step: 169350, training_loss: 5.21693e-02
I0210 15:30:37.753712 22509476222784 run_lib.py:133] step: 169400, training_loss: 3.81751e-02
I0210 15:30:37.923048 22509476222784 run_lib.py:146] step: 169400, eval_loss: 5.39765e-02
I0210 15:30:56.647196 22509476222784 run_lib.py:133] step: 169450, training_loss: 3.92410e-02
I0210 15:31:15.288609 22509476222784 run_lib.py:133] step: 169500, training_loss: 4.09252e-02
I0210 15:31:15.483787 22509476222784 run_lib.py:146] step: 169500, eval_loss: 5.60211e-02
I0210 15:31:34.270656 22509476222784 run_lib.py:133] step: 169550, training_loss: 4.26406e-02
I0210 15:31:52.904788 22509476222784 run_lib.py:133] step: 169600, training_loss: 4.47211e-02
I0210 15:31:53.070482 22509476222784 run_lib.py:146] step: 169600, eval_loss: 4.57923e-02
I0210 15:32:11.817433 22509476222784 run_lib.py:133] step: 169650, training_loss: 4.22186e-02
I0210 15:32:30.388860 22509476222784 run_lib.py:133] step: 169700, training_loss: 4.62998e-02
I0210 15:32:30.552431 22509476222784 run_lib.py:146] step: 169700, eval_loss: 4.19117e-02
I0210 15:32:49.124907 22509476222784 run_lib.py:133] step: 169750, training_loss: 3.62601e-02
I0210 15:33:07.875228 22509476222784 run_lib.py:133] step: 169800, training_loss: 4.43814e-02
I0210 15:33:08.042807 22509476222784 run_lib.py:146] step: 169800, eval_loss: 3.91062e-02
I0210 15:33:26.664793 22509476222784 run_lib.py:133] step: 169850, training_loss: 4.21056e-02
I0210 15:33:45.501083 22509476222784 run_lib.py:133] step: 169900, training_loss: 4.35958e-02
I0210 15:33:45.668969 22509476222784 run_lib.py:146] step: 169900, eval_loss: 5.18309e-02
I0210 15:34:04.252449 22509476222784 run_lib.py:133] step: 169950, training_loss: 3.13076e-02
I0210 15:34:22.803159 22509476222784 run_lib.py:133] step: 170000, training_loss: 3.91273e-02
I0210 15:34:23.628707 22509476222784 run_lib.py:146] step: 170000, eval_loss: 4.27077e-02
I0210 15:34:44.896307 22509476222784 run_lib.py:133] step: 170050, training_loss: 4.96050e-02
I0210 15:35:03.690497 22509476222784 run_lib.py:133] step: 170100, training_loss: 4.14638e-02
I0210 15:35:03.856956 22509476222784 run_lib.py:146] step: 170100, eval_loss: 4.14292e-02
I0210 15:35:22.388672 22509476222784 run_lib.py:133] step: 170150, training_loss: 3.78251e-02
I0210 15:35:41.066185 22509476222784 run_lib.py:133] step: 170200, training_loss: 3.97736e-02
I0210 15:35:41.232568 22509476222784 run_lib.py:146] step: 170200, eval_loss: 3.86784e-02
I0210 15:35:59.800050 22509476222784 run_lib.py:133] step: 170250, training_loss: 4.57262e-02
I0210 15:36:18.402870 22509476222784 run_lib.py:133] step: 170300, training_loss: 4.74632e-02
I0210 15:36:18.566957 22509476222784 run_lib.py:146] step: 170300, eval_loss: 4.03930e-02
I0210 15:36:37.395567 22509476222784 run_lib.py:133] step: 170350, training_loss: 5.06048e-02
I0210 15:36:55.953571 22509476222784 run_lib.py:133] step: 170400, training_loss: 4.52684e-02
I0210 15:36:56.120893 22509476222784 run_lib.py:146] step: 170400, eval_loss: 4.05682e-02
I0210 15:37:14.798258 22509476222784 run_lib.py:133] step: 170450, training_loss: 4.17658e-02
I0210 15:37:33.386784 22509476222784 run_lib.py:133] step: 170500, training_loss: 4.32855e-02
I0210 15:37:33.553881 22509476222784 run_lib.py:146] step: 170500, eval_loss: 5.49301e-02
I0210 15:37:52.120520 22509476222784 run_lib.py:133] step: 170550, training_loss: 6.00260e-02
I0210 15:38:10.939800 22509476222784 run_lib.py:133] step: 170600, training_loss: 5.13361e-02
I0210 15:38:11.106993 22509476222784 run_lib.py:146] step: 170600, eval_loss: 4.40538e-02
I0210 15:38:29.684522 22509476222784 run_lib.py:133] step: 170650, training_loss: 5.11113e-02
I0210 15:38:48.249822 22509476222784 run_lib.py:133] step: 170700, training_loss: 3.48432e-02
I0210 15:38:48.414675 22509476222784 run_lib.py:146] step: 170700, eval_loss: 6.39615e-02
I0210 15:39:07.002272 22509476222784 run_lib.py:133] step: 170750, training_loss: 4.03075e-02
I0210 15:39:25.740368 22509476222784 run_lib.py:133] step: 170800, training_loss: 4.66392e-02
I0210 15:39:25.905769 22509476222784 run_lib.py:146] step: 170800, eval_loss: 4.72641e-02
I0210 15:39:44.522128 22509476222784 run_lib.py:133] step: 170850, training_loss: 3.12855e-02
I0210 15:40:03.230075 22509476222784 run_lib.py:133] step: 170900, training_loss: 3.99721e-02
I0210 15:40:03.397665 22509476222784 run_lib.py:146] step: 170900, eval_loss: 2.92143e-02
I0210 15:40:21.928009 22509476222784 run_lib.py:133] step: 170950, training_loss: 5.17449e-02
I0210 15:40:40.491687 22509476222784 run_lib.py:133] step: 171000, training_loss: 5.00753e-02
I0210 15:40:40.673537 22509476222784 run_lib.py:146] step: 171000, eval_loss: 5.19088e-02
I0210 15:40:59.366657 22509476222784 run_lib.py:133] step: 171050, training_loss: 4.93950e-02
I0210 15:41:18.138810 22509476222784 run_lib.py:133] step: 171100, training_loss: 5.47870e-02
I0210 15:41:18.305212 22509476222784 run_lib.py:146] step: 171100, eval_loss: 4.86793e-02
I0210 15:41:36.875779 22509476222784 run_lib.py:133] step: 171150, training_loss: 5.04193e-02
I0210 15:41:55.395770 22509476222784 run_lib.py:133] step: 171200, training_loss: 4.26576e-02
I0210 15:41:55.559390 22509476222784 run_lib.py:146] step: 171200, eval_loss: 4.51365e-02
I0210 15:42:14.299269 22509476222784 run_lib.py:133] step: 171250, training_loss: 4.53588e-02
I0210 15:42:32.811544 22509476222784 run_lib.py:133] step: 171300, training_loss: 4.40755e-02
I0210 15:42:32.975559 22509476222784 run_lib.py:146] step: 171300, eval_loss: 3.26683e-02
I0210 15:42:51.699196 22509476222784 run_lib.py:133] step: 171350, training_loss: 4.12764e-02
I0210 15:43:10.264960 22509476222784 run_lib.py:133] step: 171400, training_loss: 4.48127e-02
I0210 15:43:10.434536 22509476222784 run_lib.py:146] step: 171400, eval_loss: 4.25216e-02
I0210 15:43:29.165665 22509476222784 run_lib.py:133] step: 171450, training_loss: 4.67904e-02
I0210 15:43:47.724494 22509476222784 run_lib.py:133] step: 171500, training_loss: 4.15196e-02
I0210 15:43:47.893724 22509476222784 run_lib.py:146] step: 171500, eval_loss: 5.03802e-02
I0210 15:44:06.425318 22509476222784 run_lib.py:133] step: 171550, training_loss: 5.68747e-02
I0210 15:44:25.153070 22509476222784 run_lib.py:133] step: 171600, training_loss: 4.59431e-02
I0210 15:44:25.320151 22509476222784 run_lib.py:146] step: 171600, eval_loss: 4.51285e-02
I0210 15:44:43.981100 22509476222784 run_lib.py:133] step: 171650, training_loss: 5.75554e-02
I0210 15:45:02.709203 22509476222784 run_lib.py:133] step: 171700, training_loss: 4.30966e-02
I0210 15:45:02.872781 22509476222784 run_lib.py:146] step: 171700, eval_loss: 5.39548e-02
I0210 15:45:21.404768 22509476222784 run_lib.py:133] step: 171750, training_loss: 4.54510e-02
I0210 15:45:39.954132 22509476222784 run_lib.py:133] step: 171800, training_loss: 4.69169e-02
I0210 15:45:40.119606 22509476222784 run_lib.py:146] step: 171800, eval_loss: 4.38682e-02
I0210 15:45:58.821479 22509476222784 run_lib.py:133] step: 171850, training_loss: 3.70933e-02
I0210 15:46:17.516352 22509476222784 run_lib.py:133] step: 171900, training_loss: 3.35520e-02
I0210 15:46:17.695538 22509476222784 run_lib.py:146] step: 171900, eval_loss: 3.55357e-02
I0210 15:46:36.272025 22509476222784 run_lib.py:133] step: 171950, training_loss: 5.37097e-02
I0210 15:46:55.044828 22509476222784 run_lib.py:133] step: 172000, training_loss: 5.31509e-02
I0210 15:46:55.210745 22509476222784 run_lib.py:146] step: 172000, eval_loss: 3.46309e-02
I0210 15:47:13.763904 22509476222784 run_lib.py:133] step: 172050, training_loss: 6.08791e-02
I0210 15:47:32.315301 22509476222784 run_lib.py:133] step: 172100, training_loss: 3.49890e-02
I0210 15:47:32.481598 22509476222784 run_lib.py:146] step: 172100, eval_loss: 4.54905e-02
I0210 15:47:51.148575 22509476222784 run_lib.py:133] step: 172150, training_loss: 3.98077e-02
I0210 15:48:09.727027 22509476222784 run_lib.py:133] step: 172200, training_loss: 3.99429e-02
I0210 15:48:09.892856 22509476222784 run_lib.py:146] step: 172200, eval_loss: 3.63096e-02
I0210 15:48:28.486481 22509476222784 run_lib.py:133] step: 172250, training_loss: 4.76443e-02
I0210 15:48:47.061785 22509476222784 run_lib.py:133] step: 172300, training_loss: 4.99348e-02
I0210 15:48:47.227321 22509476222784 run_lib.py:146] step: 172300, eval_loss: 4.19564e-02
I0210 15:49:06.010325 22509476222784 run_lib.py:133] step: 172350, training_loss: 4.20636e-02
I0210 15:49:24.680893 22509476222784 run_lib.py:133] step: 172400, training_loss: 4.24809e-02
I0210 15:49:24.859581 22509476222784 run_lib.py:146] step: 172400, eval_loss: 4.86910e-02
I0210 15:49:43.462923 22509476222784 run_lib.py:133] step: 172450, training_loss: 4.23704e-02
I0210 15:50:02.027697 22509476222784 run_lib.py:133] step: 172500, training_loss: 5.54645e-02
I0210 15:50:02.195024 22509476222784 run_lib.py:146] step: 172500, eval_loss: 4.14601e-02
I0210 15:50:20.968358 22509476222784 run_lib.py:133] step: 172550, training_loss: 3.53486e-02
I0210 15:50:39.526644 22509476222784 run_lib.py:133] step: 172600, training_loss: 3.69746e-02
I0210 15:50:39.691783 22509476222784 run_lib.py:146] step: 172600, eval_loss: 3.32060e-02
I0210 15:50:58.444305 22509476222784 run_lib.py:133] step: 172650, training_loss: 4.00024e-02
I0210 15:51:17.011564 22509476222784 run_lib.py:133] step: 172700, training_loss: 3.40183e-02
I0210 15:51:17.176701 22509476222784 run_lib.py:146] step: 172700, eval_loss: 4.67346e-02
I0210 15:51:35.920540 22509476222784 run_lib.py:133] step: 172750, training_loss: 4.95467e-02
I0210 15:51:54.501680 22509476222784 run_lib.py:133] step: 172800, training_loss: 3.44160e-02
I0210 15:51:54.668960 22509476222784 run_lib.py:146] step: 172800, eval_loss: 3.24829e-02
I0210 15:52:13.354176 22509476222784 run_lib.py:133] step: 172850, training_loss: 5.61091e-02
I0210 15:52:31.920430 22509476222784 run_lib.py:133] step: 172900, training_loss: 4.35254e-02
I0210 15:52:32.101703 22509476222784 run_lib.py:146] step: 172900, eval_loss: 5.07024e-02
I0210 15:52:50.669269 22509476222784 run_lib.py:133] step: 172950, training_loss: 3.82336e-02
I0210 15:53:09.474203 22509476222784 run_lib.py:133] step: 173000, training_loss: 3.60058e-02
I0210 15:53:09.642110 22509476222784 run_lib.py:146] step: 173000, eval_loss: 3.75039e-02
I0210 15:53:28.242793 22509476222784 run_lib.py:133] step: 173050, training_loss: 3.45282e-02
I0210 15:53:46.761336 22509476222784 run_lib.py:133] step: 173100, training_loss: 4.26883e-02
I0210 15:53:46.924927 22509476222784 run_lib.py:146] step: 173100, eval_loss: 4.09637e-02
I0210 15:54:05.647931 22509476222784 run_lib.py:133] step: 173150, training_loss: 3.85990e-02
I0210 15:54:24.286932 22509476222784 run_lib.py:133] step: 173200, training_loss: 4.31562e-02
I0210 15:54:24.460926 22509476222784 run_lib.py:146] step: 173200, eval_loss: 3.27235e-02
I0210 15:54:43.163565 22509476222784 run_lib.py:133] step: 173250, training_loss: 3.53751e-02
I0210 15:55:01.747045 22509476222784 run_lib.py:133] step: 173300, training_loss: 5.85835e-02
I0210 15:55:01.914940 22509476222784 run_lib.py:146] step: 173300, eval_loss: 5.01017e-02
I0210 15:55:20.493820 22509476222784 run_lib.py:133] step: 173350, training_loss: 3.36647e-02
I0210 15:55:39.187103 22509476222784 run_lib.py:133] step: 173400, training_loss: 5.62419e-02
I0210 15:55:39.356786 22509476222784 run_lib.py:146] step: 173400, eval_loss: 4.92496e-02
I0210 15:55:57.897041 22509476222784 run_lib.py:133] step: 173450, training_loss: 4.00386e-02
I0210 15:56:16.462350 22509476222784 run_lib.py:133] step: 173500, training_loss: 4.62016e-02
I0210 15:56:16.628871 22509476222784 run_lib.py:146] step: 173500, eval_loss: 5.13768e-02
I0210 15:56:35.216217 22509476222784 run_lib.py:133] step: 173550, training_loss: 4.26903e-02
I0210 15:56:53.935940 22509476222784 run_lib.py:133] step: 173600, training_loss: 3.05936e-02
I0210 15:56:54.097530 22509476222784 run_lib.py:146] step: 173600, eval_loss: 4.43113e-02
I0210 15:57:12.601876 22509476222784 run_lib.py:133] step: 173650, training_loss: 4.17065e-02
I0210 15:57:31.215075 22509476222784 run_lib.py:133] step: 173700, training_loss: 4.91120e-02
I0210 15:57:31.391840 22509476222784 run_lib.py:146] step: 173700, eval_loss: 4.49938e-02
I0210 15:57:49.981565 22509476222784 run_lib.py:133] step: 173750, training_loss: 3.78325e-02
I0210 15:58:08.563418 22509476222784 run_lib.py:133] step: 173800, training_loss: 4.05928e-02
I0210 15:58:08.739915 22509476222784 run_lib.py:146] step: 173800, eval_loss: 4.55308e-02
I0210 15:58:27.451877 22509476222784 run_lib.py:133] step: 173850, training_loss: 3.77273e-02
I0210 15:58:46.063214 22509476222784 run_lib.py:133] step: 173900, training_loss: 3.96221e-02
I0210 15:58:46.239665 22509476222784 run_lib.py:146] step: 173900, eval_loss: 4.38415e-02
I0210 15:59:04.815086 22509476222784 run_lib.py:133] step: 173950, training_loss: 3.66703e-02
I0210 15:59:23.607522 22509476222784 run_lib.py:133] step: 174000, training_loss: 4.57455e-02
I0210 15:59:23.773035 22509476222784 run_lib.py:146] step: 174000, eval_loss: 4.14066e-02
I0210 15:59:42.536118 22509476222784 run_lib.py:133] step: 174050, training_loss: 4.03823e-02
I0210 16:00:01.038913 22509476222784 run_lib.py:133] step: 174100, training_loss: 3.83819e-02
I0210 16:00:01.202733 22509476222784 run_lib.py:146] step: 174100, eval_loss: 3.18948e-02
I0210 16:00:19.878252 22509476222784 run_lib.py:133] step: 174150, training_loss: 4.81273e-02
I0210 16:00:38.467260 22509476222784 run_lib.py:133] step: 174200, training_loss: 3.76227e-02
I0210 16:00:38.642629 22509476222784 run_lib.py:146] step: 174200, eval_loss: 4.98651e-02
I0210 16:00:57.404546 22509476222784 run_lib.py:133] step: 174250, training_loss: 5.21175e-02
I0210 16:01:15.955445 22509476222784 run_lib.py:133] step: 174300, training_loss: 3.85934e-02
I0210 16:01:16.123546 22509476222784 run_lib.py:146] step: 174300, eval_loss: 5.56001e-02
I0210 16:01:34.662110 22509476222784 run_lib.py:133] step: 174350, training_loss: 3.53768e-02
I0210 16:01:53.321646 22509476222784 run_lib.py:133] step: 174400, training_loss: 4.44669e-02
I0210 16:01:53.487762 22509476222784 run_lib.py:146] step: 174400, eval_loss: 3.32787e-02
I0210 16:02:12.051676 22509476222784 run_lib.py:133] step: 174450, training_loss: 4.86831e-02
I0210 16:02:30.766162 22509476222784 run_lib.py:133] step: 174500, training_loss: 4.63223e-02
I0210 16:02:30.931070 22509476222784 run_lib.py:146] step: 174500, eval_loss: 4.00463e-02
I0210 16:02:49.494044 22509476222784 run_lib.py:133] step: 174550, training_loss: 4.43248e-02
I0210 16:03:08.069920 22509476222784 run_lib.py:133] step: 174600, training_loss: 4.59361e-02
I0210 16:03:08.234888 22509476222784 run_lib.py:146] step: 174600, eval_loss: 3.44495e-02
I0210 16:03:26.942670 22509476222784 run_lib.py:133] step: 174650, training_loss: 4.24068e-02
I0210 16:03:45.521618 22509476222784 run_lib.py:133] step: 174700, training_loss: 4.04580e-02
I0210 16:03:45.703680 22509476222784 run_lib.py:146] step: 174700, eval_loss: 3.71305e-02
I0210 16:04:04.351425 22509476222784 run_lib.py:133] step: 174750, training_loss: 4.09347e-02
I0210 16:04:23.182410 22509476222784 run_lib.py:133] step: 174800, training_loss: 4.04486e-02
I0210 16:04:23.347805 22509476222784 run_lib.py:146] step: 174800, eval_loss: 5.21218e-02
I0210 16:04:41.887617 22509476222784 run_lib.py:133] step: 174850, training_loss: 3.45491e-02
I0210 16:05:00.446877 22509476222784 run_lib.py:133] step: 174900, training_loss: 4.11610e-02
I0210 16:05:00.766701 22509476222784 run_lib.py:146] step: 174900, eval_loss: 5.45071e-02
I0210 16:05:19.362729 22509476222784 run_lib.py:133] step: 174950, training_loss: 4.39830e-02
I0210 16:05:38.007398 22509476222784 run_lib.py:133] step: 175000, training_loss: 4.28596e-02
I0210 16:05:38.177421 22509476222784 run_lib.py:146] step: 175000, eval_loss: 4.43979e-02
I0210 16:05:56.784131 22509476222784 run_lib.py:133] step: 175050, training_loss: 4.76355e-02
I0210 16:06:15.374735 22509476222784 run_lib.py:133] step: 175100, training_loss: 5.34908e-02
I0210 16:06:15.544878 22509476222784 run_lib.py:146] step: 175100, eval_loss: 3.95161e-02
I0210 16:06:34.251957 22509476222784 run_lib.py:133] step: 175150, training_loss: 4.84990e-02
I0210 16:06:52.935338 22509476222784 run_lib.py:133] step: 175200, training_loss: 4.78046e-02
I0210 16:06:53.105657 22509476222784 run_lib.py:146] step: 175200, eval_loss: 4.45930e-02
I0210 16:07:11.699957 22509476222784 run_lib.py:133] step: 175250, training_loss: 3.78922e-02
I0210 16:07:30.309508 22509476222784 run_lib.py:133] step: 175300, training_loss: 5.00288e-02
I0210 16:07:30.475850 22509476222784 run_lib.py:146] step: 175300, eval_loss: 4.41824e-02
I0210 16:07:49.262291 22509476222784 run_lib.py:133] step: 175350, training_loss: 5.61542e-02
I0210 16:08:08.108818 22509476222784 run_lib.py:133] step: 175400, training_loss: 3.83949e-02
I0210 16:08:08.289646 22509476222784 run_lib.py:146] step: 175400, eval_loss: 4.33035e-02
I0210 16:08:26.848500 22509476222784 run_lib.py:133] step: 175450, training_loss: 4.24731e-02
I0210 16:08:45.379929 22509476222784 run_lib.py:133] step: 175500, training_loss: 3.78664e-02
I0210 16:08:45.554793 22509476222784 run_lib.py:146] step: 175500, eval_loss: 3.60844e-02
I0210 16:09:04.369225 22509476222784 run_lib.py:133] step: 175550, training_loss: 4.53614e-02
I0210 16:09:22.899562 22509476222784 run_lib.py:133] step: 175600, training_loss: 3.64458e-02
I0210 16:09:23.067646 22509476222784 run_lib.py:146] step: 175600, eval_loss: 4.34775e-02
I0210 16:09:41.751666 22509476222784 run_lib.py:133] step: 175650, training_loss: 4.09891e-02
I0210 16:10:00.296797 22509476222784 run_lib.py:133] step: 175700, training_loss: 3.40327e-02
I0210 16:10:00.462940 22509476222784 run_lib.py:146] step: 175700, eval_loss: 4.14231e-02
I0210 16:10:19.201466 22509476222784 run_lib.py:133] step: 175750, training_loss: 3.97580e-02
I0210 16:10:37.903350 22509476222784 run_lib.py:133] step: 175800, training_loss: 3.59001e-02
I0210 16:10:38.071922 22509476222784 run_lib.py:146] step: 175800, eval_loss: 4.58895e-02
I0210 16:10:56.613142 22509476222784 run_lib.py:133] step: 175850, training_loss: 4.90760e-02
I0210 16:11:15.322381 22509476222784 run_lib.py:133] step: 175900, training_loss: 4.73282e-02
I0210 16:11:15.487719 22509476222784 run_lib.py:146] step: 175900, eval_loss: 4.01399e-02
I0210 16:11:34.036670 22509476222784 run_lib.py:133] step: 175950, training_loss: 4.59198e-02
I0210 16:11:52.773441 22509476222784 run_lib.py:133] step: 176000, training_loss: 4.52784e-02
I0210 16:11:52.940803 22509476222784 run_lib.py:146] step: 176000, eval_loss: 4.46030e-02
I0210 16:12:11.542109 22509476222784 run_lib.py:133] step: 176050, training_loss: 3.84581e-02
I0210 16:12:30.132956 22509476222784 run_lib.py:133] step: 176100, training_loss: 4.77047e-02
I0210 16:12:30.298849 22509476222784 run_lib.py:146] step: 176100, eval_loss: 5.77236e-02
I0210 16:12:48.831528 22509476222784 run_lib.py:133] step: 176150, training_loss: 4.20013e-02
I0210 16:13:07.558151 22509476222784 run_lib.py:133] step: 176200, training_loss: 3.00681e-02
I0210 16:13:07.724418 22509476222784 run_lib.py:146] step: 176200, eval_loss: 4.67800e-02
I0210 16:13:26.260989 22509476222784 run_lib.py:133] step: 176250, training_loss: 5.21794e-02
I0210 16:13:44.877836 22509476222784 run_lib.py:133] step: 176300, training_loss: 4.03318e-02
I0210 16:13:45.044379 22509476222784 run_lib.py:146] step: 176300, eval_loss: 4.49786e-02
I0210 16:14:03.789649 22509476222784 run_lib.py:133] step: 176350, training_loss: 3.89218e-02
I0210 16:14:22.287526 22509476222784 run_lib.py:133] step: 176400, training_loss: 3.52394e-02
I0210 16:14:22.453562 22509476222784 run_lib.py:146] step: 176400, eval_loss: 4.34899e-02
I0210 16:14:41.038581 22509476222784 run_lib.py:133] step: 176450, training_loss: 3.69815e-02
I0210 16:14:59.553895 22509476222784 run_lib.py:133] step: 176500, training_loss: 5.11645e-02
I0210 16:14:59.716608 22509476222784 run_lib.py:146] step: 176500, eval_loss: 4.34253e-02
I0210 16:15:18.313656 22509476222784 run_lib.py:133] step: 176550, training_loss: 4.64913e-02
I0210 16:15:36.882380 22509476222784 run_lib.py:133] step: 176600, training_loss: 4.40797e-02
I0210 16:15:37.050453 22509476222784 run_lib.py:146] step: 176600, eval_loss: 4.34476e-02
I0210 16:15:55.781462 22509476222784 run_lib.py:133] step: 176650, training_loss: 3.68888e-02
I0210 16:16:14.372278 22509476222784 run_lib.py:133] step: 176700, training_loss: 4.47927e-02
I0210 16:16:14.538727 22509476222784 run_lib.py:146] step: 176700, eval_loss: 4.24045e-02
I0210 16:16:33.172868 22509476222784 run_lib.py:133] step: 176750, training_loss: 3.86888e-02
I0210 16:16:51.695986 22509476222784 run_lib.py:133] step: 176800, training_loss: 4.75585e-02
I0210 16:16:51.867720 22509476222784 run_lib.py:146] step: 176800, eval_loss: 4.42170e-02
I0210 16:17:10.637585 22509476222784 run_lib.py:133] step: 176850, training_loss: 4.33371e-02
I0210 16:17:29.245204 22509476222784 run_lib.py:133] step: 176900, training_loss: 5.08841e-02
I0210 16:17:29.406389 22509476222784 run_lib.py:146] step: 176900, eval_loss: 3.83717e-02
I0210 16:17:48.181470 22509476222784 run_lib.py:133] step: 176950, training_loss: 3.52956e-02
I0210 16:18:06.714180 22509476222784 run_lib.py:133] step: 177000, training_loss: 3.74290e-02
I0210 16:18:06.879738 22509476222784 run_lib.py:146] step: 177000, eval_loss: 4.74580e-02
I0210 16:18:25.587840 22509476222784 run_lib.py:133] step: 177050, training_loss: 3.83690e-02
I0210 16:18:44.161876 22509476222784 run_lib.py:133] step: 177100, training_loss: 4.48928e-02
I0210 16:18:44.354660 22509476222784 run_lib.py:146] step: 177100, eval_loss: 4.28711e-02
I0210 16:19:03.129419 22509476222784 run_lib.py:133] step: 177150, training_loss: 3.85554e-02
I0210 16:19:21.744156 22509476222784 run_lib.py:133] step: 177200, training_loss: 4.22538e-02
I0210 16:19:21.908921 22509476222784 run_lib.py:146] step: 177200, eval_loss: 4.44348e-02
I0210 16:19:40.459504 22509476222784 run_lib.py:133] step: 177250, training_loss: 4.34451e-02
I0210 16:19:59.174174 22509476222784 run_lib.py:133] step: 177300, training_loss: 4.64856e-02
I0210 16:19:59.337565 22509476222784 run_lib.py:146] step: 177300, eval_loss: 5.43882e-02
I0210 16:20:17.888039 22509476222784 run_lib.py:133] step: 177350, training_loss: 4.65532e-02
I0210 16:20:36.499110 22509476222784 run_lib.py:133] step: 177400, training_loss: 3.74275e-02
I0210 16:20:36.664812 22509476222784 run_lib.py:146] step: 177400, eval_loss: 3.40651e-02
I0210 16:20:55.441424 22509476222784 run_lib.py:133] step: 177450, training_loss: 4.69149e-02
I0210 16:21:14.196268 22509476222784 run_lib.py:133] step: 177500, training_loss: 4.08790e-02
I0210 16:21:14.360672 22509476222784 run_lib.py:146] step: 177500, eval_loss: 4.37718e-02
I0210 16:21:32.900399 22509476222784 run_lib.py:133] step: 177550, training_loss: 4.29720e-02
I0210 16:21:51.470331 22509476222784 run_lib.py:133] step: 177600, training_loss: 4.83965e-02
I0210 16:21:51.635077 22509476222784 run_lib.py:146] step: 177600, eval_loss: 4.13656e-02
I0210 16:22:10.214027 22509476222784 run_lib.py:133] step: 177650, training_loss: 3.68851e-02
I0210 16:22:29.006449 22509476222784 run_lib.py:133] step: 177700, training_loss: 3.16018e-02
I0210 16:22:29.177912 22509476222784 run_lib.py:146] step: 177700, eval_loss: 4.76659e-02
I0210 16:22:47.736083 22509476222784 run_lib.py:133] step: 177750, training_loss: 3.02924e-02
I0210 16:23:06.307607 22509476222784 run_lib.py:133] step: 177800, training_loss: 4.28608e-02
I0210 16:23:06.472698 22509476222784 run_lib.py:146] step: 177800, eval_loss: 4.93867e-02
I0210 16:23:25.047692 22509476222784 run_lib.py:133] step: 177850, training_loss: 3.79683e-02
I0210 16:23:43.807759 22509476222784 run_lib.py:133] step: 177900, training_loss: 3.68066e-02
I0210 16:23:43.969498 22509476222784 run_lib.py:146] step: 177900, eval_loss: 4.30051e-02
I0210 16:24:02.504754 22509476222784 run_lib.py:133] step: 177950, training_loss: 6.32877e-02
I0210 16:24:21.195891 22509476222784 run_lib.py:133] step: 178000, training_loss: 5.29077e-02
I0210 16:24:21.373694 22509476222784 run_lib.py:146] step: 178000, eval_loss: 5.19077e-02
I0210 16:24:39.991903 22509476222784 run_lib.py:133] step: 178050, training_loss: 4.58668e-02
I0210 16:24:58.585315 22509476222784 run_lib.py:133] step: 178100, training_loss: 3.96551e-02
I0210 16:24:58.752186 22509476222784 run_lib.py:146] step: 178100, eval_loss: 4.45982e-02
I0210 16:25:17.472602 22509476222784 run_lib.py:133] step: 178150, training_loss: 3.09972e-02
I0210 16:25:36.086862 22509476222784 run_lib.py:133] step: 178200, training_loss: 4.51775e-02
I0210 16:25:36.253741 22509476222784 run_lib.py:146] step: 178200, eval_loss: 4.09228e-02
I0210 16:25:54.804074 22509476222784 run_lib.py:133] step: 178250, training_loss: 4.80911e-02
I0210 16:26:13.403034 22509476222784 run_lib.py:133] step: 178300, training_loss: 4.84817e-02
I0210 16:26:13.567929 22509476222784 run_lib.py:146] step: 178300, eval_loss: 4.71699e-02
I0210 16:26:32.339362 22509476222784 run_lib.py:133] step: 178350, training_loss: 3.88752e-02
I0210 16:26:50.869133 22509476222784 run_lib.py:133] step: 178400, training_loss: 4.27698e-02
I0210 16:26:51.038622 22509476222784 run_lib.py:146] step: 178400, eval_loss: 5.42314e-02
I0210 16:27:09.715415 22509476222784 run_lib.py:133] step: 178450, training_loss: 5.00656e-02
I0210 16:27:28.309700 22509476222784 run_lib.py:133] step: 178500, training_loss: 5.62277e-02
I0210 16:27:28.490866 22509476222784 run_lib.py:146] step: 178500, eval_loss: 4.49979e-02
I0210 16:27:47.231910 22509476222784 run_lib.py:133] step: 178550, training_loss: 4.89742e-02
I0210 16:28:05.854106 22509476222784 run_lib.py:133] step: 178600, training_loss: 3.18520e-02
I0210 16:28:06.018875 22509476222784 run_lib.py:146] step: 178600, eval_loss: 3.59089e-02
I0210 16:28:24.630570 22509476222784 run_lib.py:133] step: 178650, training_loss: 2.99274e-02
I0210 16:28:43.324598 22509476222784 run_lib.py:133] step: 178700, training_loss: 3.83710e-02
I0210 16:28:43.511794 22509476222784 run_lib.py:146] step: 178700, eval_loss: 3.42447e-02
I0210 16:29:02.103907 22509476222784 run_lib.py:133] step: 178750, training_loss: 4.40270e-02
I0210 16:29:20.892710 22509476222784 run_lib.py:133] step: 178800, training_loss: 5.30730e-02
I0210 16:29:21.056554 22509476222784 run_lib.py:146] step: 178800, eval_loss: 4.91242e-02
I0210 16:29:39.659384 22509476222784 run_lib.py:133] step: 178850, training_loss: 5.39166e-02
I0210 16:29:58.257617 22509476222784 run_lib.py:133] step: 178900, training_loss: 4.34933e-02
I0210 16:29:58.422744 22509476222784 run_lib.py:146] step: 178900, eval_loss: 4.08351e-02
I0210 16:30:17.136281 22509476222784 run_lib.py:133] step: 178950, training_loss: 4.18655e-02
I0210 16:30:35.699242 22509476222784 run_lib.py:133] step: 179000, training_loss: 3.82112e-02
I0210 16:30:35.903935 22509476222784 run_lib.py:146] step: 179000, eval_loss: 4.54673e-02
I0210 16:30:54.466600 22509476222784 run_lib.py:133] step: 179050, training_loss: 3.81656e-02
I0210 16:31:13.286380 22509476222784 run_lib.py:133] step: 179100, training_loss: 3.63955e-02
I0210 16:31:13.452825 22509476222784 run_lib.py:146] step: 179100, eval_loss: 3.97359e-02
I0210 16:31:31.986274 22509476222784 run_lib.py:133] step: 179150, training_loss: 5.04376e-02
I0210 16:31:50.517974 22509476222784 run_lib.py:133] step: 179200, training_loss: 3.68032e-02
I0210 16:31:50.683713 22509476222784 run_lib.py:146] step: 179200, eval_loss: 3.87908e-02
I0210 16:32:09.357405 22509476222784 run_lib.py:133] step: 179250, training_loss: 4.88363e-02
I0210 16:32:27.936885 22509476222784 run_lib.py:133] step: 179300, training_loss: 4.11217e-02
I0210 16:32:28.116790 22509476222784 run_lib.py:146] step: 179300, eval_loss: 5.06473e-02
I0210 16:32:46.799390 22509476222784 run_lib.py:133] step: 179350, training_loss: 4.19155e-02
I0210 16:33:05.332003 22509476222784 run_lib.py:133] step: 179400, training_loss: 5.35226e-02
I0210 16:33:05.497580 22509476222784 run_lib.py:146] step: 179400, eval_loss: 4.19221e-02
I0210 16:33:24.202820 22509476222784 run_lib.py:133] step: 179450, training_loss: 6.04189e-02
I0210 16:33:42.814799 22509476222784 run_lib.py:133] step: 179500, training_loss: 4.76466e-02
I0210 16:33:42.980839 22509476222784 run_lib.py:146] step: 179500, eval_loss: 4.54433e-02
I0210 16:34:01.530078 22509476222784 run_lib.py:133] step: 179550, training_loss: 4.48273e-02
I0210 16:34:20.175414 22509476222784 run_lib.py:133] step: 179600, training_loss: 3.69109e-02
I0210 16:34:20.341034 22509476222784 run_lib.py:146] step: 179600, eval_loss: 3.51920e-02
I0210 16:34:39.136004 22509476222784 run_lib.py:133] step: 179650, training_loss: 3.81955e-02
I0210 16:34:57.658602 22509476222784 run_lib.py:133] step: 179700, training_loss: 4.68729e-02
I0210 16:34:57.826342 22509476222784 run_lib.py:146] step: 179700, eval_loss: 4.35345e-02
I0210 16:35:16.501898 22509476222784 run_lib.py:133] step: 179750, training_loss: 3.41514e-02
I0210 16:35:35.033817 22509476222784 run_lib.py:133] step: 179800, training_loss: 4.80405e-02
I0210 16:35:35.208694 22509476222784 run_lib.py:146] step: 179800, eval_loss: 3.05600e-02
I0210 16:35:53.939607 22509476222784 run_lib.py:133] step: 179850, training_loss: 4.39233e-02
I0210 16:36:12.514726 22509476222784 run_lib.py:133] step: 179900, training_loss: 4.81357e-02
I0210 16:36:12.694724 22509476222784 run_lib.py:146] step: 179900, eval_loss: 4.27026e-02
I0210 16:36:31.475034 22509476222784 run_lib.py:133] step: 179950, training_loss: 3.47323e-02
I0210 16:36:50.052753 22509476222784 run_lib.py:133] step: 180000, training_loss: 3.41464e-02
I0210 16:36:51.057870 22509476222784 run_lib.py:146] step: 180000, eval_loss: 4.22434e-02
I0210 16:37:13.006156 22509476222784 run_lib.py:133] step: 180050, training_loss: 5.02129e-02
I0210 16:37:31.685363 22509476222784 run_lib.py:133] step: 180100, training_loss: 6.20400e-02
I0210 16:37:31.852682 22509476222784 run_lib.py:146] step: 180100, eval_loss: 3.62623e-02
I0210 16:37:50.395025 22509476222784 run_lib.py:133] step: 180150, training_loss: 3.48238e-02
I0210 16:38:09.126891 22509476222784 run_lib.py:133] step: 180200, training_loss: 4.19384e-02
I0210 16:38:09.292989 22509476222784 run_lib.py:146] step: 180200, eval_loss: 3.60555e-02
I0210 16:38:27.928082 22509476222784 run_lib.py:133] step: 180250, training_loss: 4.30221e-02
I0210 16:38:46.514640 22509476222784 run_lib.py:133] step: 180300, training_loss: 4.91297e-02
I0210 16:38:46.695771 22509476222784 run_lib.py:146] step: 180300, eval_loss: 4.98600e-02
I0210 16:39:05.421516 22509476222784 run_lib.py:133] step: 180350, training_loss: 4.71835e-02
I0210 16:39:24.217790 22509476222784 run_lib.py:133] step: 180400, training_loss: 4.92776e-02
I0210 16:39:24.391755 22509476222784 run_lib.py:146] step: 180400, eval_loss: 4.08300e-02
I0210 16:39:43.094464 22509476222784 run_lib.py:133] step: 180450, training_loss: 5.47734e-02
I0210 16:40:01.715829 22509476222784 run_lib.py:133] step: 180500, training_loss: 5.69170e-02
I0210 16:40:01.883732 22509476222784 run_lib.py:146] step: 180500, eval_loss: 4.53389e-02
I0210 16:40:20.643001 22509476222784 run_lib.py:133] step: 180550, training_loss: 4.55255e-02
I0210 16:40:39.201561 22509476222784 run_lib.py:133] step: 180600, training_loss: 3.57509e-02
I0210 16:40:39.367660 22509476222784 run_lib.py:146] step: 180600, eval_loss: 3.66408e-02
I0210 16:40:58.124484 22509476222784 run_lib.py:133] step: 180650, training_loss: 4.43444e-02
I0210 16:41:16.752371 22509476222784 run_lib.py:133] step: 180700, training_loss: 4.01732e-02
I0210 16:41:16.917929 22509476222784 run_lib.py:146] step: 180700, eval_loss: 6.24655e-02
I0210 16:41:35.763451 22509476222784 run_lib.py:133] step: 180750, training_loss: 5.63685e-02
I0210 16:41:54.353630 22509476222784 run_lib.py:133] step: 180800, training_loss: 3.61393e-02
I0210 16:41:54.514765 22509476222784 run_lib.py:146] step: 180800, eval_loss: 4.21067e-02
I0210 16:42:13.157866 22509476222784 run_lib.py:133] step: 180850, training_loss: 3.89480e-02
I0210 16:42:31.922120 22509476222784 run_lib.py:133] step: 180900, training_loss: 5.52324e-02
I0210 16:42:32.094693 22509476222784 run_lib.py:146] step: 180900, eval_loss: 4.53093e-02
I0210 16:42:50.640574 22509476222784 run_lib.py:133] step: 180950, training_loss: 3.69067e-02
I0210 16:43:09.396611 22509476222784 run_lib.py:133] step: 181000, training_loss: 3.84365e-02
I0210 16:43:09.575777 22509476222784 run_lib.py:146] step: 181000, eval_loss: 5.09866e-02
I0210 16:43:28.174637 22509476222784 run_lib.py:133] step: 181050, training_loss: 3.82234e-02
I0210 16:43:46.796508 22509476222784 run_lib.py:133] step: 181100, training_loss: 5.35708e-02
I0210 16:43:46.969965 22509476222784 run_lib.py:146] step: 181100, eval_loss: 3.52166e-02
I0210 16:44:05.731276 22509476222784 run_lib.py:133] step: 181150, training_loss: 4.80184e-02
I0210 16:44:24.271677 22509476222784 run_lib.py:133] step: 181200, training_loss: 3.90567e-02
I0210 16:44:24.435717 22509476222784 run_lib.py:146] step: 181200, eval_loss: 4.24353e-02
I0210 16:44:43.034727 22509476222784 run_lib.py:133] step: 181250, training_loss: 3.47566e-02
I0210 16:45:01.902751 22509476222784 run_lib.py:133] step: 181300, training_loss: 3.40915e-02
I0210 16:45:02.084877 22509476222784 run_lib.py:146] step: 181300, eval_loss: 3.34181e-02
I0210 16:45:20.724843 22509476222784 run_lib.py:133] step: 181350, training_loss: 5.11882e-02
I0210 16:45:39.305064 22509476222784 run_lib.py:133] step: 181400, training_loss: 3.78299e-02
I0210 16:45:39.473845 22509476222784 run_lib.py:146] step: 181400, eval_loss: 5.44242e-02
I0210 16:45:58.128380 22509476222784 run_lib.py:133] step: 181450, training_loss: 3.54706e-02
I0210 16:46:16.688001 22509476222784 run_lib.py:133] step: 181500, training_loss: 3.75039e-02
I0210 16:46:16.857939 22509476222784 run_lib.py:146] step: 181500, eval_loss: 3.73716e-02
I0210 16:46:35.469265 22509476222784 run_lib.py:133] step: 181550, training_loss: 3.99016e-02
I0210 16:46:54.164663 22509476222784 run_lib.py:133] step: 181600, training_loss: 3.63895e-02
I0210 16:46:54.331545 22509476222784 run_lib.py:146] step: 181600, eval_loss: 3.82281e-02
I0210 16:47:13.126563 22509476222784 run_lib.py:133] step: 181650, training_loss: 4.65178e-02
I0210 16:47:31.754042 22509476222784 run_lib.py:133] step: 181700, training_loss: 3.89700e-02
I0210 16:47:31.916656 22509476222784 run_lib.py:146] step: 181700, eval_loss: 3.64505e-02
I0210 16:47:50.482207 22509476222784 run_lib.py:133] step: 181750, training_loss: 6.06738e-02
I0210 16:48:09.082552 22509476222784 run_lib.py:133] step: 181800, training_loss: 4.53707e-02
I0210 16:48:09.251300 22509476222784 run_lib.py:146] step: 181800, eval_loss: 4.00115e-02
I0210 16:48:28.036244 22509476222784 run_lib.py:133] step: 181850, training_loss: 4.20374e-02
I0210 16:48:46.659901 22509476222784 run_lib.py:133] step: 181900, training_loss: 4.49790e-02
I0210 16:48:46.881607 22509476222784 run_lib.py:146] step: 181900, eval_loss: 5.40628e-02
I0210 16:49:05.640147 22509476222784 run_lib.py:133] step: 181950, training_loss: 4.10423e-02
I0210 16:49:24.241931 22509476222784 run_lib.py:133] step: 182000, training_loss: 4.56853e-02
I0210 16:49:24.407739 22509476222784 run_lib.py:146] step: 182000, eval_loss: 3.51675e-02
I0210 16:49:43.142052 22509476222784 run_lib.py:133] step: 182050, training_loss: 4.25949e-02
I0210 16:50:01.793148 22509476222784 run_lib.py:133] step: 182100, training_loss: 4.81769e-02
I0210 16:50:01.956238 22509476222784 run_lib.py:146] step: 182100, eval_loss: 5.51879e-02
I0210 16:50:20.755341 22509476222784 run_lib.py:133] step: 182150, training_loss: 3.85422e-02
I0210 16:50:39.334212 22509476222784 run_lib.py:133] step: 182200, training_loss: 4.17559e-02
I0210 16:50:39.496560 22509476222784 run_lib.py:146] step: 182200, eval_loss: 5.34730e-02
I0210 16:50:58.072230 22509476222784 run_lib.py:133] step: 182250, training_loss: 4.15057e-02
I0210 16:51:16.830911 22509476222784 run_lib.py:133] step: 182300, training_loss: 5.15369e-02
I0210 16:51:16.995763 22509476222784 run_lib.py:146] step: 182300, eval_loss: 4.30734e-02
I0210 16:51:35.592725 22509476222784 run_lib.py:133] step: 182350, training_loss: 3.91653e-02
I0210 16:51:54.286615 22509476222784 run_lib.py:133] step: 182400, training_loss: 3.33387e-02
I0210 16:51:54.455592 22509476222784 run_lib.py:146] step: 182400, eval_loss: 4.61284e-02
I0210 16:52:13.239244 22509476222784 run_lib.py:133] step: 182450, training_loss: 3.96837e-02
I0210 16:52:31.834746 22509476222784 run_lib.py:133] step: 182500, training_loss: 3.68471e-02
I0210 16:52:31.999650 22509476222784 run_lib.py:146] step: 182500, eval_loss: 5.83771e-02
I0210 16:52:50.782540 22509476222784 run_lib.py:133] step: 182550, training_loss: 5.13666e-02
I0210 16:53:09.403135 22509476222784 run_lib.py:133] step: 182600, training_loss: 5.07583e-02
I0210 16:53:09.567838 22509476222784 run_lib.py:146] step: 182600, eval_loss: 4.51327e-02
I0210 16:53:28.259087 22509476222784 run_lib.py:133] step: 182650, training_loss: 5.28545e-02
I0210 16:53:47.123593 22509476222784 run_lib.py:133] step: 182700, training_loss: 5.14173e-02
I0210 16:53:47.286693 22509476222784 run_lib.py:146] step: 182700, eval_loss: 3.92698e-02
I0210 16:54:05.899514 22509476222784 run_lib.py:133] step: 182750, training_loss: 4.23604e-02
I0210 16:54:24.464776 22509476222784 run_lib.py:133] step: 182800, training_loss: 3.96235e-02
I0210 16:54:24.628641 22509476222784 run_lib.py:146] step: 182800, eval_loss: 5.17134e-02
I0210 16:54:43.226390 22509476222784 run_lib.py:133] step: 182850, training_loss: 3.70201e-02
I0210 16:55:01.980108 22509476222784 run_lib.py:133] step: 182900, training_loss: 5.52847e-02
I0210 16:55:02.160687 22509476222784 run_lib.py:146] step: 182900, eval_loss: 3.73625e-02
I0210 16:55:20.807758 22509476222784 run_lib.py:133] step: 182950, training_loss: 3.25735e-02
I0210 16:55:39.566701 22509476222784 run_lib.py:133] step: 183000, training_loss: 3.47144e-02
I0210 16:55:39.731856 22509476222784 run_lib.py:146] step: 183000, eval_loss: 5.26835e-02
I0210 16:55:58.322481 22509476222784 run_lib.py:133] step: 183050, training_loss: 4.78011e-02
I0210 16:56:16.877064 22509476222784 run_lib.py:133] step: 183100, training_loss: 3.66707e-02
I0210 16:56:17.045773 22509476222784 run_lib.py:146] step: 183100, eval_loss: 4.06755e-02
I0210 16:56:35.817787 22509476222784 run_lib.py:133] step: 183150, training_loss: 4.36784e-02
I0210 16:56:54.548706 22509476222784 run_lib.py:133] step: 183200, training_loss: 3.65817e-02
I0210 16:56:54.720849 22509476222784 run_lib.py:146] step: 183200, eval_loss: 5.30881e-02
I0210 16:57:13.323482 22509476222784 run_lib.py:133] step: 183250, training_loss: 3.62010e-02
I0210 16:57:31.897883 22509476222784 run_lib.py:133] step: 183300, training_loss: 3.63640e-02
I0210 16:57:32.065826 22509476222784 run_lib.py:146] step: 183300, eval_loss: 4.70140e-02
I0210 16:57:50.755532 22509476222784 run_lib.py:133] step: 183350, training_loss: 4.55218e-02
I0210 16:58:09.298879 22509476222784 run_lib.py:133] step: 183400, training_loss: 3.01964e-02
I0210 16:58:09.463791 22509476222784 run_lib.py:146] step: 183400, eval_loss: 4.56031e-02
I0210 16:58:28.195368 22509476222784 run_lib.py:133] step: 183450, training_loss: 3.44134e-02
I0210 16:58:46.867523 22509476222784 run_lib.py:133] step: 183500, training_loss: 5.10719e-02
I0210 16:58:47.063636 22509476222784 run_lib.py:146] step: 183500, eval_loss: 3.68511e-02
I0210 16:59:05.859661 22509476222784 run_lib.py:133] step: 183550, training_loss: 5.29281e-02
I0210 16:59:24.402274 22509476222784 run_lib.py:133] step: 183600, training_loss: 3.46663e-02
I0210 16:59:24.565484 22509476222784 run_lib.py:146] step: 183600, eval_loss: 4.72497e-02
I0210 16:59:43.108078 22509476222784 run_lib.py:133] step: 183650, training_loss: 4.67084e-02
I0210 17:00:01.839459 22509476222784 run_lib.py:133] step: 183700, training_loss: 4.51983e-02
I0210 17:00:02.010881 22509476222784 run_lib.py:146] step: 183700, eval_loss: 4.33005e-02
I0210 17:00:20.724134 22509476222784 run_lib.py:133] step: 183750, training_loss: 3.32141e-02
I0210 17:00:39.488281 22509476222784 run_lib.py:133] step: 183800, training_loss: 4.37955e-02
I0210 17:00:39.654620 22509476222784 run_lib.py:146] step: 183800, eval_loss: 4.57399e-02
I0210 17:00:58.242325 22509476222784 run_lib.py:133] step: 183850, training_loss: 5.31460e-02
I0210 17:01:16.867342 22509476222784 run_lib.py:133] step: 183900, training_loss: 4.61542e-02
I0210 17:01:17.032846 22509476222784 run_lib.py:146] step: 183900, eval_loss: 4.06366e-02
I0210 17:01:35.801772 22509476222784 run_lib.py:133] step: 183950, training_loss: 4.62138e-02
I0210 17:01:54.415306 22509476222784 run_lib.py:133] step: 184000, training_loss: 3.59340e-02
I0210 17:01:54.579971 22509476222784 run_lib.py:146] step: 184000, eval_loss: 4.22373e-02
I0210 17:02:13.244838 22509476222784 run_lib.py:133] step: 184050, training_loss: 4.39884e-02
I0210 17:02:32.042721 22509476222784 run_lib.py:133] step: 184100, training_loss: 4.08249e-02
I0210 17:02:32.203975 22509476222784 run_lib.py:146] step: 184100, eval_loss: 3.92004e-02
I0210 17:02:50.787888 22509476222784 run_lib.py:133] step: 184150, training_loss: 4.62314e-02
I0210 17:03:09.378650 22509476222784 run_lib.py:133] step: 184200, training_loss: 4.58205e-02
I0210 17:03:09.761676 22509476222784 run_lib.py:146] step: 184200, eval_loss: 4.26167e-02
I0210 17:03:28.336995 22509476222784 run_lib.py:133] step: 184250, training_loss: 4.22576e-02
I0210 17:03:46.942636 22509476222784 run_lib.py:133] step: 184300, training_loss: 5.11284e-02
I0210 17:03:47.122570 22509476222784 run_lib.py:146] step: 184300, eval_loss: 4.57810e-02
I0210 17:04:05.736420 22509476222784 run_lib.py:133] step: 184350, training_loss: 5.24867e-02
I0210 17:04:24.310107 22509476222784 run_lib.py:133] step: 184400, training_loss: 5.06004e-02
I0210 17:04:24.475102 22509476222784 run_lib.py:146] step: 184400, eval_loss: 3.89557e-02
I0210 17:04:43.224945 22509476222784 run_lib.py:133] step: 184450, training_loss: 4.61293e-02
I0210 17:05:01.809576 22509476222784 run_lib.py:133] step: 184500, training_loss: 4.53055e-02
I0210 17:05:01.973717 22509476222784 run_lib.py:146] step: 184500, eval_loss: 3.12027e-02
I0210 17:05:20.565421 22509476222784 run_lib.py:133] step: 184550, training_loss: 4.77269e-02
I0210 17:05:39.192358 22509476222784 run_lib.py:133] step: 184600, training_loss: 4.82249e-02
I0210 17:05:39.357257 22509476222784 run_lib.py:146] step: 184600, eval_loss: 4.83410e-02
I0210 17:05:58.220327 22509476222784 run_lib.py:133] step: 184650, training_loss: 5.79297e-02
I0210 17:06:16.887550 22509476222784 run_lib.py:133] step: 184700, training_loss: 4.01264e-02
I0210 17:06:17.052489 22509476222784 run_lib.py:146] step: 184700, eval_loss: 5.53892e-02
I0210 17:06:35.609619 22509476222784 run_lib.py:133] step: 184750, training_loss: 4.86160e-02
I0210 17:06:54.174968 22509476222784 run_lib.py:133] step: 184800, training_loss: 4.15642e-02
I0210 17:06:54.342052 22509476222784 run_lib.py:146] step: 184800, eval_loss: 4.09249e-02
I0210 17:07:13.103491 22509476222784 run_lib.py:133] step: 184850, training_loss: 4.71739e-02
I0210 17:07:31.781714 22509476222784 run_lib.py:133] step: 184900, training_loss: 4.18773e-02
I0210 17:07:31.947852 22509476222784 run_lib.py:146] step: 184900, eval_loss: 4.39442e-02
I0210 17:07:50.730428 22509476222784 run_lib.py:133] step: 184950, training_loss: 4.06850e-02
I0210 17:08:09.284166 22509476222784 run_lib.py:133] step: 185000, training_loss: 5.71300e-02
I0210 17:08:09.448632 22509476222784 run_lib.py:146] step: 185000, eval_loss: 4.63329e-02
I0210 17:08:28.160931 22509476222784 run_lib.py:133] step: 185050, training_loss: 4.96213e-02
I0210 17:08:46.727377 22509476222784 run_lib.py:133] step: 185100, training_loss: 5.56062e-02
I0210 17:08:46.993770 22509476222784 run_lib.py:146] step: 185100, eval_loss: 5.10380e-02
I0210 17:09:05.652412 22509476222784 run_lib.py:133] step: 185150, training_loss: 4.24361e-02
I0210 17:09:24.433707 22509476222784 run_lib.py:133] step: 185200, training_loss: 5.13917e-02
I0210 17:09:24.600857 22509476222784 run_lib.py:146] step: 185200, eval_loss: 3.94759e-02
I0210 17:09:43.171696 22509476222784 run_lib.py:133] step: 185250, training_loss: 5.59333e-02
I0210 17:10:01.902755 22509476222784 run_lib.py:133] step: 185300, training_loss: 3.91673e-02
I0210 17:10:02.066573 22509476222784 run_lib.py:146] step: 185300, eval_loss: 3.46042e-02
I0210 17:10:20.672546 22509476222784 run_lib.py:133] step: 185350, training_loss: 5.36181e-02
I0210 17:10:39.301959 22509476222784 run_lib.py:133] step: 185400, training_loss: 4.60724e-02
I0210 17:10:39.471561 22509476222784 run_lib.py:146] step: 185400, eval_loss: 3.65319e-02
I0210 17:10:58.120789 22509476222784 run_lib.py:133] step: 185450, training_loss: 3.50732e-02
I0210 17:11:16.914849 22509476222784 run_lib.py:133] step: 185500, training_loss: 3.51961e-02
I0210 17:11:17.078195 22509476222784 run_lib.py:146] step: 185500, eval_loss: 4.06355e-02
I0210 17:11:35.708413 22509476222784 run_lib.py:133] step: 185550, training_loss: 3.35809e-02
I0210 17:11:54.275512 22509476222784 run_lib.py:133] step: 185600, training_loss: 3.96123e-02
I0210 17:11:54.440919 22509476222784 run_lib.py:146] step: 185600, eval_loss: 4.80198e-02
I0210 17:12:13.216889 22509476222784 run_lib.py:133] step: 185650, training_loss: 3.43260e-02
I0210 17:12:31.894070 22509476222784 run_lib.py:133] step: 185700, training_loss: 3.38756e-02
I0210 17:12:32.086636 22509476222784 run_lib.py:146] step: 185700, eval_loss: 4.13196e-02
I0210 17:12:50.824159 22509476222784 run_lib.py:133] step: 185750, training_loss: 3.76011e-02
I0210 17:13:09.446485 22509476222784 run_lib.py:133] step: 185800, training_loss: 3.99671e-02
I0210 17:13:09.611938 22509476222784 run_lib.py:146] step: 185800, eval_loss: 3.61382e-02
I0210 17:13:28.214932 22509476222784 run_lib.py:133] step: 185850, training_loss: 5.09420e-02
I0210 17:13:46.804703 22509476222784 run_lib.py:133] step: 185900, training_loss: 3.18696e-02
I0210 17:13:46.971786 22509476222784 run_lib.py:146] step: 185900, eval_loss: 6.00213e-02
I0210 17:14:05.709814 22509476222784 run_lib.py:133] step: 185950, training_loss: 3.28886e-02
I0210 17:14:24.423169 22509476222784 run_lib.py:133] step: 186000, training_loss: 5.85128e-02
I0210 17:14:24.587910 22509476222784 run_lib.py:146] step: 186000, eval_loss: 4.12012e-02
I0210 17:14:43.232931 22509476222784 run_lib.py:133] step: 186050, training_loss: 3.68711e-02
I0210 17:15:01.862468 22509476222784 run_lib.py:133] step: 186100, training_loss: 4.27555e-02
I0210 17:15:02.027710 22509476222784 run_lib.py:146] step: 186100, eval_loss: 3.19560e-02
I0210 17:15:20.735403 22509476222784 run_lib.py:133] step: 186150, training_loss: 3.63193e-02
I0210 17:15:39.316685 22509476222784 run_lib.py:133] step: 186200, training_loss: 3.40425e-02
I0210 17:15:39.495912 22509476222784 run_lib.py:146] step: 186200, eval_loss: 3.53909e-02
I0210 17:15:58.305342 22509476222784 run_lib.py:133] step: 186250, training_loss: 4.92940e-02
I0210 17:16:16.930700 22509476222784 run_lib.py:133] step: 186300, training_loss: 5.35891e-02
I0210 17:16:17.096024 22509476222784 run_lib.py:146] step: 186300, eval_loss: 3.23457e-02
I0210 17:16:35.906371 22509476222784 run_lib.py:133] step: 186350, training_loss: 4.08800e-02
I0210 17:16:54.480017 22509476222784 run_lib.py:133] step: 186400, training_loss: 3.76909e-02
I0210 17:16:54.831605 22509476222784 run_lib.py:146] step: 186400, eval_loss: 5.18712e-02
I0210 17:17:13.544544 22509476222784 run_lib.py:133] step: 186450, training_loss: 3.91614e-02
I0210 17:17:32.420542 22509476222784 run_lib.py:133] step: 186500, training_loss: 4.57121e-02
I0210 17:17:32.585827 22509476222784 run_lib.py:146] step: 186500, eval_loss: 3.47633e-02
I0210 17:17:51.176664 22509476222784 run_lib.py:133] step: 186550, training_loss: 2.87895e-02
I0210 17:18:09.925792 22509476222784 run_lib.py:133] step: 186600, training_loss: 3.42056e-02
I0210 17:18:10.091048 22509476222784 run_lib.py:146] step: 186600, eval_loss: 3.79552e-02
I0210 17:18:28.623954 22509476222784 run_lib.py:133] step: 186650, training_loss: 4.57668e-02
I0210 17:18:47.203988 22509476222784 run_lib.py:133] step: 186700, training_loss: 3.35895e-02
I0210 17:18:47.370814 22509476222784 run_lib.py:146] step: 186700, eval_loss: 4.40564e-02
I0210 17:19:06.076009 22509476222784 run_lib.py:133] step: 186750, training_loss: 3.07737e-02
I0210 17:19:24.855121 22509476222784 run_lib.py:133] step: 186800, training_loss: 3.04569e-02
I0210 17:19:25.020187 22509476222784 run_lib.py:146] step: 186800, eval_loss: 3.14973e-02
I0210 17:19:43.566772 22509476222784 run_lib.py:133] step: 186850, training_loss: 3.75851e-02
I0210 17:20:02.085666 22509476222784 run_lib.py:133] step: 186900, training_loss: 3.44129e-02
I0210 17:20:02.249665 22509476222784 run_lib.py:146] step: 186900, eval_loss: 3.82068e-02
I0210 17:20:20.798387 22509476222784 run_lib.py:133] step: 186950, training_loss: 4.29209e-02
I0210 17:20:39.484738 22509476222784 run_lib.py:133] step: 187000, training_loss: 5.22859e-02
I0210 17:20:39.646702 22509476222784 run_lib.py:146] step: 187000, eval_loss: 3.88650e-02
I0210 17:20:58.285035 22509476222784 run_lib.py:133] step: 187050, training_loss: 3.82854e-02
I0210 17:21:16.882045 22509476222784 run_lib.py:133] step: 187100, training_loss: 3.57773e-02
I0210 17:21:17.049732 22509476222784 run_lib.py:146] step: 187100, eval_loss: 4.64990e-02
I0210 17:21:35.595612 22509476222784 run_lib.py:133] step: 187150, training_loss: 4.98055e-02
I0210 17:21:54.321897 22509476222784 run_lib.py:133] step: 187200, training_loss: 4.62521e-02
I0210 17:21:54.503680 22509476222784 run_lib.py:146] step: 187200, eval_loss: 5.05186e-02
I0210 17:22:13.070117 22509476222784 run_lib.py:133] step: 187250, training_loss: 4.34400e-02
I0210 17:22:31.697331 22509476222784 run_lib.py:133] step: 187300, training_loss: 4.47762e-02
I0210 17:22:31.865663 22509476222784 run_lib.py:146] step: 187300, eval_loss: 5.16629e-02
I0210 17:22:50.432080 22509476222784 run_lib.py:133] step: 187350, training_loss: 4.30600e-02
I0210 17:23:08.996851 22509476222784 run_lib.py:133] step: 187400, training_loss: 4.63694e-02
I0210 17:23:09.165498 22509476222784 run_lib.py:146] step: 187400, eval_loss: 4.37206e-02
I0210 17:23:27.971139 22509476222784 run_lib.py:133] step: 187450, training_loss: 4.36673e-02
I0210 17:23:46.673361 22509476222784 run_lib.py:133] step: 187500, training_loss: 4.04898e-02
I0210 17:23:46.836829 22509476222784 run_lib.py:146] step: 187500, eval_loss: 5.42871e-02
I0210 17:24:05.366886 22509476222784 run_lib.py:133] step: 187550, training_loss: 4.54238e-02
I0210 17:24:23.963776 22509476222784 run_lib.py:133] step: 187600, training_loss: 4.70271e-02
I0210 17:24:24.144829 22509476222784 run_lib.py:146] step: 187600, eval_loss: 4.50408e-02
I0210 17:24:42.940761 22509476222784 run_lib.py:133] step: 187650, training_loss: 4.04357e-02
I0210 17:25:01.538048 22509476222784 run_lib.py:133] step: 187700, training_loss: 3.97597e-02
I0210 17:25:01.703914 22509476222784 run_lib.py:146] step: 187700, eval_loss: 3.80686e-02
I0210 17:25:20.423017 22509476222784 run_lib.py:133] step: 187750, training_loss: 4.73981e-02
I0210 17:25:38.956717 22509476222784 run_lib.py:133] step: 187800, training_loss: 4.42386e-02
I0210 17:25:39.119371 22509476222784 run_lib.py:146] step: 187800, eval_loss: 4.33360e-02
I0210 17:25:57.902212 22509476222784 run_lib.py:133] step: 187850, training_loss: 3.80387e-02
I0210 17:26:16.510444 22509476222784 run_lib.py:133] step: 187900, training_loss: 5.24346e-02
I0210 17:26:16.679805 22509476222784 run_lib.py:146] step: 187900, eval_loss: 3.66468e-02
I0210 17:26:35.302278 22509476222784 run_lib.py:133] step: 187950, training_loss: 4.20504e-02
I0210 17:26:54.060590 22509476222784 run_lib.py:133] step: 188000, training_loss: 4.82206e-02
I0210 17:26:54.225844 22509476222784 run_lib.py:146] step: 188000, eval_loss: 4.14248e-02
I0210 17:27:12.798440 22509476222784 run_lib.py:133] step: 188050, training_loss: 5.55635e-02
I0210 17:27:31.505758 22509476222784 run_lib.py:133] step: 188100, training_loss: 3.64806e-02
I0210 17:27:31.672901 22509476222784 run_lib.py:146] step: 188100, eval_loss: 3.96739e-02
I0210 17:27:50.265821 22509476222784 run_lib.py:133] step: 188150, training_loss: 4.06765e-02
I0210 17:28:08.969329 22509476222784 run_lib.py:133] step: 188200, training_loss: 3.70784e-02
I0210 17:28:09.136090 22509476222784 run_lib.py:146] step: 188200, eval_loss: 5.04547e-02
I0210 17:28:27.911996 22509476222784 run_lib.py:133] step: 188250, training_loss: 5.25801e-02
I0210 17:28:46.503682 22509476222784 run_lib.py:133] step: 188300, training_loss: 4.00962e-02
I0210 17:28:46.668845 22509476222784 run_lib.py:146] step: 188300, eval_loss: 4.70670e-02
I0210 17:29:05.236429 22509476222784 run_lib.py:133] step: 188350, training_loss: 4.67323e-02
I0210 17:29:23.902170 22509476222784 run_lib.py:133] step: 188400, training_loss: 4.48909e-02
I0210 17:29:24.067844 22509476222784 run_lib.py:146] step: 188400, eval_loss: 3.61021e-02
I0210 17:29:42.722339 22509476222784 run_lib.py:133] step: 188450, training_loss: 4.10632e-02
I0210 17:30:01.277329 22509476222784 run_lib.py:133] step: 188500, training_loss: 4.51852e-02
I0210 17:30:01.442681 22509476222784 run_lib.py:146] step: 188500, eval_loss: 4.71428e-02
I0210 17:30:20.098493 22509476222784 run_lib.py:133] step: 188550, training_loss: 4.38031e-02
I0210 17:30:38.679912 22509476222784 run_lib.py:133] step: 188600, training_loss: 5.03124e-02
I0210 17:30:38.845015 22509476222784 run_lib.py:146] step: 188600, eval_loss: 5.76764e-02
I0210 17:30:57.433725 22509476222784 run_lib.py:133] step: 188650, training_loss: 4.43690e-02
I0210 17:31:16.029955 22509476222784 run_lib.py:133] step: 188700, training_loss: 4.71706e-02
I0210 17:31:16.202471 22509476222784 run_lib.py:146] step: 188700, eval_loss: 4.09410e-02
I0210 17:31:34.934851 22509476222784 run_lib.py:133] step: 188750, training_loss: 3.30982e-02
I0210 17:31:53.665712 22509476222784 run_lib.py:133] step: 188800, training_loss: 5.82589e-02
I0210 17:31:53.829568 22509476222784 run_lib.py:146] step: 188800, eval_loss: 4.58831e-02
I0210 17:32:12.458699 22509476222784 run_lib.py:133] step: 188850, training_loss: 3.97302e-02
I0210 17:32:31.002407 22509476222784 run_lib.py:133] step: 188900, training_loss: 4.26696e-02
I0210 17:32:31.164691 22509476222784 run_lib.py:146] step: 188900, eval_loss: 4.98970e-02
I0210 17:32:49.846993 22509476222784 run_lib.py:133] step: 188950, training_loss: 3.90020e-02
I0210 17:33:08.412215 22509476222784 run_lib.py:133] step: 189000, training_loss: 4.94533e-02
I0210 17:33:08.591785 22509476222784 run_lib.py:146] step: 189000, eval_loss: 3.60852e-02
I0210 17:33:27.436907 22509476222784 run_lib.py:133] step: 189050, training_loss: 3.93416e-02
I0210 17:33:46.057694 22509476222784 run_lib.py:133] step: 189100, training_loss: 4.83467e-02
I0210 17:33:46.225623 22509476222784 run_lib.py:146] step: 189100, eval_loss: 4.07794e-02
I0210 17:34:04.959768 22509476222784 run_lib.py:133] step: 189150, training_loss: 3.65742e-02
I0210 17:34:23.504248 22509476222784 run_lib.py:133] step: 189200, training_loss: 4.34036e-02
I0210 17:34:23.668945 22509476222784 run_lib.py:146] step: 189200, eval_loss: 4.07194e-02
I0210 17:34:42.344166 22509476222784 run_lib.py:133] step: 189250, training_loss: 4.56224e-02
I0210 17:35:00.962858 22509476222784 run_lib.py:133] step: 189300, training_loss: 5.45471e-02
I0210 17:35:01.127881 22509476222784 run_lib.py:146] step: 189300, eval_loss: 5.14187e-02
I0210 17:35:19.811296 22509476222784 run_lib.py:133] step: 189350, training_loss: 5.01876e-02
I0210 17:35:38.609105 22509476222784 run_lib.py:133] step: 189400, training_loss: 3.56024e-02
I0210 17:35:38.769652 22509476222784 run_lib.py:146] step: 189400, eval_loss: 3.62339e-02
I0210 17:35:57.310298 22509476222784 run_lib.py:133] step: 189450, training_loss: 4.08321e-02
I0210 17:36:15.883412 22509476222784 run_lib.py:133] step: 189500, training_loss: 4.01131e-02
I0210 17:36:16.048894 22509476222784 run_lib.py:146] step: 189500, eval_loss: 5.54659e-02
I0210 17:36:34.795689 22509476222784 run_lib.py:133] step: 189550, training_loss: 4.12294e-02
I0210 17:36:53.448490 22509476222784 run_lib.py:133] step: 189600, training_loss: 4.22947e-02
I0210 17:36:53.613954 22509476222784 run_lib.py:146] step: 189600, eval_loss: 4.37604e-02
I0210 17:37:12.402681 22509476222784 run_lib.py:133] step: 189650, training_loss: 4.53758e-02
I0210 17:37:30.939124 22509476222784 run_lib.py:133] step: 189700, training_loss: 6.30014e-02
I0210 17:37:31.103693 22509476222784 run_lib.py:146] step: 189700, eval_loss: 4.38886e-02
I0210 17:37:49.658149 22509476222784 run_lib.py:133] step: 189750, training_loss: 4.64723e-02
I0210 17:38:08.372645 22509476222784 run_lib.py:133] step: 189800, training_loss: 4.06749e-02
I0210 17:38:08.575903 22509476222784 run_lib.py:146] step: 189800, eval_loss: 4.16889e-02
I0210 17:38:27.265956 22509476222784 run_lib.py:133] step: 189850, training_loss: 4.73622e-02
I0210 17:38:45.861363 22509476222784 run_lib.py:133] step: 189900, training_loss: 4.36686e-02
I0210 17:38:46.025943 22509476222784 run_lib.py:146] step: 189900, eval_loss: 3.77125e-02
I0210 17:39:04.583385 22509476222784 run_lib.py:133] step: 189950, training_loss: 3.86830e-02
I0210 17:39:23.372776 22509476222784 run_lib.py:133] step: 190000, training_loss: 3.82381e-02
I0210 17:39:24.279798 22509476222784 run_lib.py:146] step: 190000, eval_loss: 4.87399e-02
I0210 17:39:45.835083 22509476222784 run_lib.py:133] step: 190050, training_loss: 3.61733e-02
I0210 17:40:04.590658 22509476222784 run_lib.py:133] step: 190100, training_loss: 5.36564e-02
I0210 17:40:04.823698 22509476222784 run_lib.py:146] step: 190100, eval_loss: 4.67773e-02
I0210 17:40:23.471473 22509476222784 run_lib.py:133] step: 190150, training_loss: 5.29996e-02
I0210 17:40:42.075597 22509476222784 run_lib.py:133] step: 190200, training_loss: 4.68578e-02
I0210 17:40:42.240982 22509476222784 run_lib.py:146] step: 190200, eval_loss: 4.90780e-02
I0210 17:41:00.866230 22509476222784 run_lib.py:133] step: 190250, training_loss: 5.02736e-02
I0210 17:41:19.589905 22509476222784 run_lib.py:133] step: 190300, training_loss: 4.46162e-02
I0210 17:41:19.753646 22509476222784 run_lib.py:146] step: 190300, eval_loss: 4.11820e-02
I0210 17:41:38.411503 22509476222784 run_lib.py:133] step: 190350, training_loss: 5.18095e-02
I0210 17:41:57.080546 22509476222784 run_lib.py:133] step: 190400, training_loss: 5.18123e-02
I0210 17:41:57.247911 22509476222784 run_lib.py:146] step: 190400, eval_loss: 5.05690e-02
I0210 17:42:15.844808 22509476222784 run_lib.py:133] step: 190450, training_loss: 5.45963e-02
I0210 17:42:34.431322 22509476222784 run_lib.py:133] step: 190500, training_loss: 3.64360e-02
I0210 17:42:34.598808 22509476222784 run_lib.py:146] step: 190500, eval_loss: 3.31701e-02
I0210 17:42:53.341344 22509476222784 run_lib.py:133] step: 190550, training_loss: 4.26790e-02
I0210 17:43:12.054628 22509476222784 run_lib.py:133] step: 190600, training_loss: 3.56094e-02
I0210 17:43:12.221850 22509476222784 run_lib.py:146] step: 190600, eval_loss: 4.65359e-02
I0210 17:43:30.872080 22509476222784 run_lib.py:133] step: 190650, training_loss: 4.61182e-02
I0210 17:43:49.494316 22509476222784 run_lib.py:133] step: 190700, training_loss: 4.67606e-02
I0210 17:43:49.659679 22509476222784 run_lib.py:146] step: 190700, eval_loss: 3.95682e-02
I0210 17:44:08.464820 22509476222784 run_lib.py:133] step: 190750, training_loss: 4.35404e-02
I0210 17:44:27.032569 22509476222784 run_lib.py:133] step: 190800, training_loss: 4.44952e-02
I0210 17:44:27.192520 22509476222784 run_lib.py:146] step: 190800, eval_loss: 4.93704e-02
I0210 17:44:45.890816 22509476222784 run_lib.py:133] step: 190850, training_loss: 4.81536e-02
I0210 17:45:04.434757 22509476222784 run_lib.py:133] step: 190900, training_loss: 4.44527e-02
I0210 17:45:04.606959 22509476222784 run_lib.py:146] step: 190900, eval_loss: 3.31439e-02
I0210 17:45:23.417996 22509476222784 run_lib.py:133] step: 190950, training_loss: 4.30934e-02
I0210 17:45:42.055563 22509476222784 run_lib.py:133] step: 191000, training_loss: 4.01110e-02
I0210 17:45:42.231704 22509476222784 run_lib.py:146] step: 191000, eval_loss: 3.59272e-02
I0210 17:46:00.778191 22509476222784 run_lib.py:133] step: 191050, training_loss: 3.74173e-02
I0210 17:46:19.475782 22509476222784 run_lib.py:133] step: 191100, training_loss: 4.79763e-02
I0210 17:46:19.643712 22509476222784 run_lib.py:146] step: 191100, eval_loss: 4.04337e-02
I0210 17:46:38.198317 22509476222784 run_lib.py:133] step: 191150, training_loss: 4.09064e-02
I0210 17:46:56.942975 22509476222784 run_lib.py:133] step: 191200, training_loss: 3.86220e-02
I0210 17:46:57.108823 22509476222784 run_lib.py:146] step: 191200, eval_loss: 4.28406e-02
I0210 17:47:15.721639 22509476222784 run_lib.py:133] step: 191250, training_loss: 4.79501e-02
I0210 17:47:34.256096 22509476222784 run_lib.py:133] step: 191300, training_loss: 5.56721e-02
I0210 17:47:34.416728 22509476222784 run_lib.py:146] step: 191300, eval_loss: 4.22717e-02
I0210 17:47:53.144538 22509476222784 run_lib.py:133] step: 191350, training_loss: 3.64511e-02
I0210 17:48:11.702929 22509476222784 run_lib.py:133] step: 191400, training_loss: 5.07192e-02
I0210 17:48:11.868909 22509476222784 run_lib.py:146] step: 191400, eval_loss: 4.17031e-02
I0210 17:48:30.486825 22509476222784 run_lib.py:133] step: 191450, training_loss: 4.83484e-02
I0210 17:48:49.330451 22509476222784 run_lib.py:133] step: 191500, training_loss: 3.79407e-02
I0210 17:48:49.522838 22509476222784 run_lib.py:146] step: 191500, eval_loss: 4.18779e-02
I0210 17:49:08.072266 22509476222784 run_lib.py:133] step: 191550, training_loss: 4.71447e-02
I0210 17:49:26.663213 22509476222784 run_lib.py:133] step: 191600, training_loss: 3.62056e-02
I0210 17:49:27.050607 22509476222784 run_lib.py:146] step: 191600, eval_loss: 3.55098e-02
I0210 17:49:45.565739 22509476222784 run_lib.py:133] step: 191650, training_loss: 3.56230e-02
I0210 17:50:04.118150 22509476222784 run_lib.py:133] step: 191700, training_loss: 3.41869e-02
I0210 17:50:04.286861 22509476222784 run_lib.py:146] step: 191700, eval_loss: 4.70323e-02
I0210 17:50:22.899226 22509476222784 run_lib.py:133] step: 191750, training_loss: 3.96914e-02
I0210 17:50:41.514224 22509476222784 run_lib.py:133] step: 191800, training_loss: 4.92701e-02
I0210 17:50:41.676950 22509476222784 run_lib.py:146] step: 191800, eval_loss: 5.00297e-02
I0210 17:51:00.494264 22509476222784 run_lib.py:133] step: 191850, training_loss: 4.36090e-02
I0210 17:51:19.144472 22509476222784 run_lib.py:133] step: 191900, training_loss: 4.55746e-02
I0210 17:51:19.312186 22509476222784 run_lib.py:146] step: 191900, eval_loss: 3.88958e-02
I0210 17:51:37.860430 22509476222784 run_lib.py:133] step: 191950, training_loss: 5.14427e-02
I0210 17:51:56.440792 22509476222784 run_lib.py:133] step: 192000, training_loss: 3.76647e-02
I0210 17:51:56.615726 22509476222784 run_lib.py:146] step: 192000, eval_loss: 4.39337e-02
I0210 17:52:15.381415 22509476222784 run_lib.py:133] step: 192050, training_loss: 4.74245e-02
I0210 17:52:34.071390 22509476222784 run_lib.py:133] step: 192100, training_loss: 5.18074e-02
I0210 17:52:34.237045 22509476222784 run_lib.py:146] step: 192100, eval_loss: 4.34936e-02
I0210 17:52:52.847186 22509476222784 run_lib.py:133] step: 192150, training_loss: 4.01604e-02
I0210 17:53:11.405887 22509476222784 run_lib.py:133] step: 192200, training_loss: 3.95402e-02
I0210 17:53:11.576492 22509476222784 run_lib.py:146] step: 192200, eval_loss: 3.19056e-02
I0210 17:53:30.339258 22509476222784 run_lib.py:133] step: 192250, training_loss: 4.86554e-02
I0210 17:53:48.959309 22509476222784 run_lib.py:133] step: 192300, training_loss: 5.04714e-02
I0210 17:53:49.126106 22509476222784 run_lib.py:146] step: 192300, eval_loss: 4.90079e-02
I0210 17:54:08.032502 22509476222784 run_lib.py:133] step: 192350, training_loss: 3.81607e-02
I0210 17:54:26.661469 22509476222784 run_lib.py:133] step: 192400, training_loss: 4.07764e-02
I0210 17:54:26.829673 22509476222784 run_lib.py:146] step: 192400, eval_loss: 3.57311e-02
I0210 17:54:45.555638 22509476222784 run_lib.py:133] step: 192450, training_loss: 4.82116e-02
I0210 17:55:04.161050 22509476222784 run_lib.py:133] step: 192500, training_loss: 3.98990e-02
I0210 17:55:04.326684 22509476222784 run_lib.py:146] step: 192500, eval_loss: 4.64077e-02
I0210 17:55:22.923645 22509476222784 run_lib.py:133] step: 192550, training_loss: 4.19393e-02
I0210 17:55:41.733115 22509476222784 run_lib.py:133] step: 192600, training_loss: 5.12322e-02
I0210 17:55:41.899611 22509476222784 run_lib.py:146] step: 192600, eval_loss: 3.52574e-02
I0210 17:56:00.559291 22509476222784 run_lib.py:133] step: 192650, training_loss: 3.77763e-02
I0210 17:56:19.265992 22509476222784 run_lib.py:133] step: 192700, training_loss: 4.95873e-02
I0210 17:56:19.428010 22509476222784 run_lib.py:146] step: 192700, eval_loss: 5.11144e-02
I0210 17:56:38.017785 22509476222784 run_lib.py:133] step: 192750, training_loss: 4.32564e-02
I0210 17:56:56.589447 22509476222784 run_lib.py:133] step: 192800, training_loss: 4.23390e-02
I0210 17:56:56.754899 22509476222784 run_lib.py:146] step: 192800, eval_loss: 4.68460e-02
I0210 17:57:15.350668 22509476222784 run_lib.py:133] step: 192850, training_loss: 5.05947e-02
I0210 17:57:34.149687 22509476222784 run_lib.py:133] step: 192900, training_loss: 4.41208e-02
I0210 17:57:34.316680 22509476222784 run_lib.py:146] step: 192900, eval_loss: 4.69643e-02
I0210 17:57:52.907630 22509476222784 run_lib.py:133] step: 192950, training_loss: 4.83727e-02
I0210 17:58:11.483825 22509476222784 run_lib.py:133] step: 193000, training_loss: 5.30490e-02
I0210 17:58:11.653820 22509476222784 run_lib.py:146] step: 193000, eval_loss: 3.97741e-02
I0210 17:58:30.438272 22509476222784 run_lib.py:133] step: 193050, training_loss: 5.06771e-02
I0210 17:58:49.005982 22509476222784 run_lib.py:133] step: 193100, training_loss: 4.06278e-02
I0210 17:58:49.192846 22509476222784 run_lib.py:146] step: 193100, eval_loss: 3.13135e-02
I0210 17:59:07.875176 22509476222784 run_lib.py:133] step: 193150, training_loss: 3.92026e-02
I0210 17:59:26.476791 22509476222784 run_lib.py:133] step: 193200, training_loss: 5.12001e-02
I0210 17:59:26.647666 22509476222784 run_lib.py:146] step: 193200, eval_loss: 4.78612e-02
I0210 17:59:45.260698 22509476222784 run_lib.py:133] step: 193250, training_loss: 4.40362e-02
I0210 18:00:03.859442 22509476222784 run_lib.py:133] step: 193300, training_loss: 3.73044e-02
I0210 18:00:04.031763 22509476222784 run_lib.py:146] step: 193300, eval_loss: 4.59392e-02
I0210 18:00:22.771817 22509476222784 run_lib.py:133] step: 193350, training_loss: 4.70555e-02
I0210 18:00:41.426484 22509476222784 run_lib.py:133] step: 193400, training_loss: 3.88570e-02
I0210 18:00:41.596737 22509476222784 run_lib.py:146] step: 193400, eval_loss: 4.16637e-02
I0210 18:01:00.191307 22509476222784 run_lib.py:133] step: 193450, training_loss: 4.75375e-02
I0210 18:01:18.844067 22509476222784 run_lib.py:133] step: 193500, training_loss: 3.32710e-02
I0210 18:01:19.042899 22509476222784 run_lib.py:146] step: 193500, eval_loss: 4.42092e-02
I0210 18:01:37.773661 22509476222784 run_lib.py:133] step: 193550, training_loss: 4.50829e-02
I0210 18:01:56.377515 22509476222784 run_lib.py:133] step: 193600, training_loss: 3.15940e-02
I0210 18:01:56.541742 22509476222784 run_lib.py:146] step: 193600, eval_loss: 4.83835e-02
I0210 18:02:15.284432 22509476222784 run_lib.py:133] step: 193650, training_loss: 4.48045e-02
I0210 18:02:33.910220 22509476222784 run_lib.py:133] step: 193700, training_loss: 3.46563e-02
I0210 18:02:34.076968 22509476222784 run_lib.py:146] step: 193700, eval_loss: 3.92638e-02
I0210 18:02:52.941746 22509476222784 run_lib.py:133] step: 193750, training_loss: 5.38198e-02
I0210 18:03:11.487558 22509476222784 run_lib.py:133] step: 193800, training_loss: 3.74229e-02
I0210 18:03:11.654699 22509476222784 run_lib.py:146] step: 193800, eval_loss: 5.02656e-02
I0210 18:03:30.300844 22509476222784 run_lib.py:133] step: 193850, training_loss: 3.21916e-02
I0210 18:03:48.780281 22509476222784 run_lib.py:133] step: 193900, training_loss: 4.13734e-02
I0210 18:03:48.944874 22509476222784 run_lib.py:146] step: 193900, eval_loss: 5.10310e-02
I0210 18:04:07.432583 22509476222784 run_lib.py:133] step: 193950, training_loss: 3.99294e-02
I0210 18:04:26.108335 22509476222784 run_lib.py:133] step: 194000, training_loss: 3.21881e-02
I0210 18:04:26.271425 22509476222784 run_lib.py:146] step: 194000, eval_loss: 3.58158e-02
I0210 18:04:44.779177 22509476222784 run_lib.py:133] step: 194050, training_loss: 4.46135e-02
I0210 18:05:03.247299 22509476222784 run_lib.py:133] step: 194100, training_loss: 3.74531e-02
I0210 18:05:03.413455 22509476222784 run_lib.py:146] step: 194100, eval_loss: 5.52610e-02
I0210 18:05:22.093184 22509476222784 run_lib.py:133] step: 194150, training_loss: 4.18256e-02
I0210 18:05:40.699249 22509476222784 run_lib.py:133] step: 194200, training_loss: 3.33207e-02
I0210 18:05:40.860600 22509476222784 run_lib.py:146] step: 194200, eval_loss: 4.00928e-02
I0210 18:05:59.389528 22509476222784 run_lib.py:133] step: 194250, training_loss: 5.57829e-02
I0210 18:06:17.936527 22509476222784 run_lib.py:133] step: 194300, training_loss: 4.41074e-02
I0210 18:06:18.107603 22509476222784 run_lib.py:146] step: 194300, eval_loss: 3.77791e-02
I0210 18:06:36.631351 22509476222784 run_lib.py:133] step: 194350, training_loss: 4.08018e-02
I0210 18:06:55.292060 22509476222784 run_lib.py:133] step: 194400, training_loss: 5.66576e-02
I0210 18:06:55.455545 22509476222784 run_lib.py:146] step: 194400, eval_loss: 3.27814e-02
I0210 18:07:13.928524 22509476222784 run_lib.py:133] step: 194450, training_loss: 5.21611e-02
I0210 18:07:32.360696 22509476222784 run_lib.py:133] step: 194500, training_loss: 5.14170e-02
I0210 18:07:32.524408 22509476222784 run_lib.py:146] step: 194500, eval_loss: 4.51266e-02
I0210 18:07:51.004950 22509476222784 run_lib.py:133] step: 194550, training_loss: 6.16537e-02
I0210 18:08:09.678908 22509476222784 run_lib.py:133] step: 194600, training_loss: 3.04917e-02
I0210 18:08:09.839611 22509476222784 run_lib.py:146] step: 194600, eval_loss: 4.82546e-02
I0210 18:08:28.537185 22509476222784 run_lib.py:133] step: 194650, training_loss: 3.70787e-02
I0210 18:08:47.119908 22509476222784 run_lib.py:133] step: 194700, training_loss: 4.80515e-02
I0210 18:08:47.308632 22509476222784 run_lib.py:146] step: 194700, eval_loss: 3.78924e-02
I0210 18:09:05.800198 22509476222784 run_lib.py:133] step: 194750, training_loss: 4.56525e-02
I0210 18:09:24.296329 22509476222784 run_lib.py:133] step: 194800, training_loss: 3.77926e-02
I0210 18:09:24.477687 22509476222784 run_lib.py:146] step: 194800, eval_loss: 5.38449e-02
I0210 18:09:43.105298 22509476222784 run_lib.py:133] step: 194850, training_loss: 4.71559e-02
I0210 18:10:01.763056 22509476222784 run_lib.py:133] step: 194900, training_loss: 4.67149e-02
I0210 18:10:01.926949 22509476222784 run_lib.py:146] step: 194900, eval_loss: 4.17855e-02
I0210 18:10:20.467603 22509476222784 run_lib.py:133] step: 194950, training_loss: 4.48903e-02
I0210 18:10:38.986519 22509476222784 run_lib.py:133] step: 195000, training_loss: 4.70053e-02
I0210 18:10:39.151570 22509476222784 run_lib.py:146] step: 195000, eval_loss: 5.28793e-02
I0210 18:10:57.754476 22509476222784 run_lib.py:133] step: 195050, training_loss: 4.43416e-02
I0210 18:11:16.264245 22509476222784 run_lib.py:133] step: 195100, training_loss: 5.02036e-02
I0210 18:11:16.428922 22509476222784 run_lib.py:146] step: 195100, eval_loss: 4.94899e-02
I0210 18:11:35.098375 22509476222784 run_lib.py:133] step: 195150, training_loss: 4.80291e-02
I0210 18:11:53.609447 22509476222784 run_lib.py:133] step: 195200, training_loss: 3.71313e-02
I0210 18:11:53.773691 22509476222784 run_lib.py:146] step: 195200, eval_loss: 4.00857e-02
I0210 18:12:12.394498 22509476222784 run_lib.py:133] step: 195250, training_loss: 5.27322e-02
I0210 18:12:30.866389 22509476222784 run_lib.py:133] step: 195300, training_loss: 4.29945e-02
I0210 18:12:31.030736 22509476222784 run_lib.py:146] step: 195300, eval_loss: 4.48178e-02
I0210 18:12:49.525353 22509476222784 run_lib.py:133] step: 195350, training_loss: 4.34017e-02
I0210 18:13:08.232501 22509476222784 run_lib.py:133] step: 195400, training_loss: 4.72820e-02
I0210 18:13:08.397315 22509476222784 run_lib.py:146] step: 195400, eval_loss: 5.33990e-02
I0210 18:13:26.893652 22509476222784 run_lib.py:133] step: 195450, training_loss: 3.23404e-02
I0210 18:13:45.601610 22509476222784 run_lib.py:133] step: 195500, training_loss: 4.80793e-02
I0210 18:13:45.767534 22509476222784 run_lib.py:146] step: 195500, eval_loss: 5.04221e-02
I0210 18:14:04.258774 22509476222784 run_lib.py:133] step: 195550, training_loss: 4.75938e-02
I0210 18:14:22.785693 22509476222784 run_lib.py:133] step: 195600, training_loss: 4.34530e-02
I0210 18:14:22.944570 22509476222784 run_lib.py:146] step: 195600, eval_loss: 4.98876e-02
I0210 18:14:41.597198 22509476222784 run_lib.py:133] step: 195650, training_loss: 4.45429e-02
I0210 18:15:00.130761 22509476222784 run_lib.py:133] step: 195700, training_loss: 4.46484e-02
I0210 18:15:00.304672 22509476222784 run_lib.py:146] step: 195700, eval_loss: 3.25259e-02
I0210 18:15:18.814555 22509476222784 run_lib.py:133] step: 195750, training_loss: 3.52390e-02
I0210 18:15:37.484388 22509476222784 run_lib.py:133] step: 195800, training_loss: 5.17277e-02
I0210 18:15:37.649718 22509476222784 run_lib.py:146] step: 195800, eval_loss: 5.32774e-02
I0210 18:15:56.157987 22509476222784 run_lib.py:133] step: 195850, training_loss: 4.10677e-02
I0210 18:16:14.652513 22509476222784 run_lib.py:133] step: 195900, training_loss: 3.28829e-02
I0210 18:16:14.817778 22509476222784 run_lib.py:146] step: 195900, eval_loss: 4.37969e-02
I0210 18:16:33.483218 22509476222784 run_lib.py:133] step: 195950, training_loss: 3.33636e-02
I0210 18:16:52.091615 22509476222784 run_lib.py:133] step: 196000, training_loss: 4.24456e-02
I0210 18:16:52.295047 22509476222784 run_lib.py:146] step: 196000, eval_loss: 3.09294e-02
I0210 18:17:10.861509 22509476222784 run_lib.py:133] step: 196050, training_loss: 4.63459e-02
I0210 18:17:29.399651 22509476222784 run_lib.py:133] step: 196100, training_loss: 3.88291e-02
I0210 18:17:29.563668 22509476222784 run_lib.py:146] step: 196100, eval_loss: 5.77476e-02
I0210 18:17:48.236410 22509476222784 run_lib.py:133] step: 196150, training_loss: 3.95612e-02
I0210 18:18:06.852991 22509476222784 run_lib.py:133] step: 196200, training_loss: 4.87004e-02
I0210 18:18:07.035305 22509476222784 run_lib.py:146] step: 196200, eval_loss: 4.29809e-02
I0210 18:18:25.587206 22509476222784 run_lib.py:133] step: 196250, training_loss: 3.98627e-02
I0210 18:18:44.065144 22509476222784 run_lib.py:133] step: 196300, training_loss: 3.30096e-02
I0210 18:18:44.231133 22509476222784 run_lib.py:146] step: 196300, eval_loss: 4.68482e-02
I0210 18:19:02.879706 22509476222784 run_lib.py:133] step: 196350, training_loss: 5.11276e-02
I0210 18:19:21.426312 22509476222784 run_lib.py:133] step: 196400, training_loss: 5.11086e-02
I0210 18:19:21.592020 22509476222784 run_lib.py:146] step: 196400, eval_loss: 4.72755e-02
I0210 18:19:40.347666 22509476222784 run_lib.py:133] step: 196450, training_loss: 2.32336e-02
I0210 18:19:58.906266 22509476222784 run_lib.py:133] step: 196500, training_loss: 4.44248e-02
I0210 18:19:59.082012 22509476222784 run_lib.py:146] step: 196500, eval_loss: 3.31639e-02
I0210 18:20:17.906054 22509476222784 run_lib.py:133] step: 196550, training_loss: 3.93403e-02
I0210 18:20:36.496181 22509476222784 run_lib.py:133] step: 196600, training_loss: 4.78201e-02
I0210 18:20:36.662744 22509476222784 run_lib.py:146] step: 196600, eval_loss: 3.95523e-02
I0210 18:20:55.384029 22509476222784 run_lib.py:133] step: 196650, training_loss: 3.89169e-02
I0210 18:21:13.954626 22509476222784 run_lib.py:133] step: 196700, training_loss: 4.93731e-02
I0210 18:21:14.140703 22509476222784 run_lib.py:146] step: 196700, eval_loss: 4.35605e-02
I0210 18:21:32.749192 22509476222784 run_lib.py:133] step: 196750, training_loss: 3.62691e-02
I0210 18:21:51.497430 22509476222784 run_lib.py:133] step: 196800, training_loss: 4.70869e-02
I0210 18:21:51.662876 22509476222784 run_lib.py:146] step: 196800, eval_loss: 4.61689e-02
I0210 18:22:10.239771 22509476222784 run_lib.py:133] step: 196850, training_loss: 2.92494e-02
I0210 18:22:28.796249 22509476222784 run_lib.py:133] step: 196900, training_loss: 3.84718e-02
I0210 18:22:28.959895 22509476222784 run_lib.py:146] step: 196900, eval_loss: 4.21002e-02
I0210 18:22:47.777251 22509476222784 run_lib.py:133] step: 196950, training_loss: 4.64011e-02
I0210 18:23:06.382661 22509476222784 run_lib.py:133] step: 197000, training_loss: 3.99467e-02
I0210 18:23:06.549734 22509476222784 run_lib.py:146] step: 197000, eval_loss: 3.72025e-02
I0210 18:23:25.394648 22509476222784 run_lib.py:133] step: 197050, training_loss: 3.37827e-02
I0210 18:23:44.011414 22509476222784 run_lib.py:133] step: 197100, training_loss: 4.79720e-02
I0210 18:23:44.176419 22509476222784 run_lib.py:146] step: 197100, eval_loss: 4.65991e-02
I0210 18:24:02.732133 22509476222784 run_lib.py:133] step: 197150, training_loss: 4.36885e-02
I0210 18:24:21.500226 22509476222784 run_lib.py:133] step: 197200, training_loss: 4.76811e-02
I0210 18:24:21.680698 22509476222784 run_lib.py:146] step: 197200, eval_loss: 4.84481e-02
I0210 18:24:40.270521 22509476222784 run_lib.py:133] step: 197250, training_loss: 3.56999e-02
I0210 18:24:58.830949 22509476222784 run_lib.py:133] step: 197300, training_loss: 4.61235e-02
I0210 18:24:59.005701 22509476222784 run_lib.py:146] step: 197300, eval_loss: 5.57550e-02
I0210 18:25:17.590343 22509476222784 run_lib.py:133] step: 197350, training_loss: 4.23945e-02
I0210 18:25:36.338034 22509476222784 run_lib.py:133] step: 197400, training_loss: 5.00985e-02
I0210 18:25:36.501748 22509476222784 run_lib.py:146] step: 197400, eval_loss: 2.98165e-02
I0210 18:25:55.085478 22509476222784 run_lib.py:133] step: 197450, training_loss: 3.96591e-02
I0210 18:26:13.734111 22509476222784 run_lib.py:133] step: 197500, training_loss: 5.26156e-02
I0210 18:26:13.925903 22509476222784 run_lib.py:146] step: 197500, eval_loss: 4.10148e-02
I0210 18:26:32.517785 22509476222784 run_lib.py:133] step: 197550, training_loss: 4.16953e-02
I0210 18:26:51.116031 22509476222784 run_lib.py:133] step: 197600, training_loss: 3.93698e-02
I0210 18:26:51.282814 22509476222784 run_lib.py:146] step: 197600, eval_loss: 5.00152e-02
I0210 18:27:10.014499 22509476222784 run_lib.py:133] step: 197650, training_loss: 5.82624e-02
I0210 18:27:28.646636 22509476222784 run_lib.py:133] step: 197700, training_loss: 4.08653e-02
I0210 18:27:28.811765 22509476222784 run_lib.py:146] step: 197700, eval_loss: 3.44556e-02
I0210 18:27:47.418821 22509476222784 run_lib.py:133] step: 197750, training_loss: 4.01964e-02
I0210 18:28:06.024152 22509476222784 run_lib.py:133] step: 197800, training_loss: 6.50327e-02
I0210 18:28:06.190335 22509476222784 run_lib.py:146] step: 197800, eval_loss: 5.16682e-02
I0210 18:28:24.969755 22509476222784 run_lib.py:133] step: 197850, training_loss: 3.96667e-02
I0210 18:28:43.530863 22509476222784 run_lib.py:133] step: 197900, training_loss: 4.21757e-02
I0210 18:28:43.692633 22509476222784 run_lib.py:146] step: 197900, eval_loss: 4.56027e-02
I0210 18:29:02.409414 22509476222784 run_lib.py:133] step: 197950, training_loss: 3.96253e-02
I0210 18:29:20.977333 22509476222784 run_lib.py:133] step: 198000, training_loss: 3.69198e-02
I0210 18:29:21.141617 22509476222784 run_lib.py:146] step: 198000, eval_loss: 4.12718e-02
I0210 18:29:39.898175 22509476222784 run_lib.py:133] step: 198050, training_loss: 4.54900e-02
I0210 18:29:58.518930 22509476222784 run_lib.py:133] step: 198100, training_loss: 4.35241e-02
I0210 18:29:58.686724 22509476222784 run_lib.py:146] step: 198100, eval_loss: 4.56079e-02
I0210 18:30:17.215508 22509476222784 run_lib.py:133] step: 198150, training_loss: 3.50145e-02
I0210 18:30:35.968975 22509476222784 run_lib.py:133] step: 198200, training_loss: 4.99573e-02
I0210 18:30:36.133702 22509476222784 run_lib.py:146] step: 198200, eval_loss: 3.83580e-02
I0210 18:30:54.683067 22509476222784 run_lib.py:133] step: 198250, training_loss: 5.35409e-02
I0210 18:31:13.385933 22509476222784 run_lib.py:133] step: 198300, training_loss: 6.37143e-02
I0210 18:31:13.558474 22509476222784 run_lib.py:146] step: 198300, eval_loss: 4.66635e-02
I0210 18:31:32.166110 22509476222784 run_lib.py:133] step: 198350, training_loss: 5.18721e-02
I0210 18:31:50.754205 22509476222784 run_lib.py:133] step: 198400, training_loss: 3.54893e-02
I0210 18:31:50.915914 22509476222784 run_lib.py:146] step: 198400, eval_loss: 4.29105e-02
I0210 18:32:09.706941 22509476222784 run_lib.py:133] step: 198450, training_loss: 3.50030e-02
I0210 18:32:28.275276 22509476222784 run_lib.py:133] step: 198500, training_loss: 3.73151e-02
I0210 18:32:28.441632 22509476222784 run_lib.py:146] step: 198500, eval_loss: 4.17949e-02
I0210 18:32:46.971981 22509476222784 run_lib.py:133] step: 198550, training_loss: 3.52856e-02
I0210 18:33:05.761249 22509476222784 run_lib.py:133] step: 198600, training_loss: 3.35120e-02
I0210 18:33:05.944729 22509476222784 run_lib.py:146] step: 198600, eval_loss: 3.55185e-02
I0210 18:33:24.512285 22509476222784 run_lib.py:133] step: 198650, training_loss: 3.06124e-02
I0210 18:33:43.079735 22509476222784 run_lib.py:133] step: 198700, training_loss: 3.83755e-02
I0210 18:33:43.439756 22509476222784 run_lib.py:146] step: 198700, eval_loss: 4.93930e-02
I0210 18:34:02.002943 22509476222784 run_lib.py:133] step: 198750, training_loss: 4.14590e-02
I0210 18:34:20.524984 22509476222784 run_lib.py:133] step: 198800, training_loss: 5.07759e-02
I0210 18:34:20.689655 22509476222784 run_lib.py:146] step: 198800, eval_loss: 4.65265e-02
I0210 18:34:39.281474 22509476222784 run_lib.py:133] step: 198850, training_loss: 4.67847e-02
I0210 18:34:57.863628 22509476222784 run_lib.py:133] step: 198900, training_loss: 3.87612e-02
I0210 18:34:58.033800 22509476222784 run_lib.py:146] step: 198900, eval_loss: 4.48528e-02
I0210 18:35:16.884582 22509476222784 run_lib.py:133] step: 198950, training_loss: 5.70188e-02
I0210 18:35:35.562039 22509476222784 run_lib.py:133] step: 199000, training_loss: 4.51235e-02
I0210 18:35:35.726921 22509476222784 run_lib.py:146] step: 199000, eval_loss: 5.56240e-02
I0210 18:35:54.263433 22509476222784 run_lib.py:133] step: 199050, training_loss: 3.34139e-02
I0210 18:36:12.801472 22509476222784 run_lib.py:133] step: 199100, training_loss: 3.72722e-02
I0210 18:36:12.979749 22509476222784 run_lib.py:146] step: 199100, eval_loss: 4.70766e-02
I0210 18:36:31.760788 22509476222784 run_lib.py:133] step: 199150, training_loss: 4.85050e-02
I0210 18:36:50.572558 22509476222784 run_lib.py:133] step: 199200, training_loss: 6.39999e-02
I0210 18:36:50.736817 22509476222784 run_lib.py:146] step: 199200, eval_loss: 3.42242e-02
I0210 18:37:09.345324 22509476222784 run_lib.py:133] step: 199250, training_loss: 5.01969e-02
I0210 18:37:27.906895 22509476222784 run_lib.py:133] step: 199300, training_loss: 4.22664e-02
I0210 18:37:28.070761 22509476222784 run_lib.py:146] step: 199300, eval_loss: 3.75082e-02
I0210 18:37:46.803397 22509476222784 run_lib.py:133] step: 199350, training_loss: 4.17966e-02
I0210 18:38:05.382169 22509476222784 run_lib.py:133] step: 199400, training_loss: 3.95065e-02
I0210 18:38:05.548966 22509476222784 run_lib.py:146] step: 199400, eval_loss: 3.54061e-02
I0210 18:38:24.385611 22509476222784 run_lib.py:133] step: 199450, training_loss: 4.03697e-02
I0210 18:38:42.973326 22509476222784 run_lib.py:133] step: 199500, training_loss: 5.25718e-02
I0210 18:38:43.139781 22509476222784 run_lib.py:146] step: 199500, eval_loss: 4.07129e-02
I0210 18:39:01.821353 22509476222784 run_lib.py:133] step: 199550, training_loss: 4.60321e-02
I0210 18:39:20.410536 22509476222784 run_lib.py:133] step: 199600, training_loss: 4.58383e-02
I0210 18:39:20.573754 22509476222784 run_lib.py:146] step: 199600, eval_loss: 4.44924e-02
I0210 18:39:39.164733 22509476222784 run_lib.py:133] step: 199650, training_loss: 4.95841e-02
I0210 18:39:58.029274 22509476222784 run_lib.py:133] step: 199700, training_loss: 3.23212e-02
I0210 18:39:58.193427 22509476222784 run_lib.py:146] step: 199700, eval_loss: 3.70884e-02
I0210 18:40:16.804273 22509476222784 run_lib.py:133] step: 199750, training_loss: 3.82744e-02
I0210 18:40:35.510259 22509476222784 run_lib.py:133] step: 199800, training_loss: 4.77177e-02
I0210 18:40:35.672348 22509476222784 run_lib.py:146] step: 199800, eval_loss: 4.67524e-02
I0210 18:40:54.174608 22509476222784 run_lib.py:133] step: 199850, training_loss: 3.98861e-02
I0210 18:41:12.733731 22509476222784 run_lib.py:133] step: 199900, training_loss: 5.98395e-02
I0210 18:41:12.897638 22509476222784 run_lib.py:146] step: 199900, eval_loss: 3.88503e-02
I0210 18:41:31.471775 22509476222784 run_lib.py:133] step: 199950, training_loss: 5.28879e-02
I0210 18:41:50.267971 22509476222784 run_lib.py:133] step: 200000, training_loss: 4.72174e-02
I0210 18:41:51.050706 22509476222784 run_lib.py:146] step: 200000, eval_loss: 4.04873e-02
I0210 18:42:12.438440 22509476222784 run_lib.py:133] step: 200050, training_loss: 4.44426e-02
I0210 18:42:31.071462 22509476222784 run_lib.py:133] step: 200100, training_loss: 3.31489e-02
I0210 18:42:31.238039 22509476222784 run_lib.py:146] step: 200100, eval_loss: 3.75688e-02
I0210 18:42:49.754687 22509476222784 run_lib.py:133] step: 200150, training_loss: 3.90668e-02
I0210 18:43:08.306925 22509476222784 run_lib.py:133] step: 200200, training_loss: 3.86697e-02
I0210 18:43:08.474740 22509476222784 run_lib.py:146] step: 200200, eval_loss: 5.12360e-02
I0210 18:43:27.173698 22509476222784 run_lib.py:133] step: 200250, training_loss: 4.46462e-02
I0210 18:43:45.806179 22509476222784 run_lib.py:133] step: 200300, training_loss: 4.27789e-02
I0210 18:43:45.979759 22509476222784 run_lib.py:146] step: 200300, eval_loss: 4.12776e-02
I0210 18:44:04.813291 22509476222784 run_lib.py:133] step: 200350, training_loss: 5.45979e-02
I0210 18:44:23.337879 22509476222784 run_lib.py:133] step: 200400, training_loss: 4.65846e-02
I0210 18:44:23.504807 22509476222784 run_lib.py:146] step: 200400, eval_loss: 4.42270e-02
I0210 18:44:42.226321 22509476222784 run_lib.py:133] step: 200450, training_loss: 4.10234e-02
I0210 18:45:00.808459 22509476222784 run_lib.py:133] step: 200500, training_loss: 5.01046e-02
I0210 18:45:00.982668 22509476222784 run_lib.py:146] step: 200500, eval_loss: 3.37672e-02
I0210 18:45:19.772624 22509476222784 run_lib.py:133] step: 200550, training_loss: 3.68630e-02
I0210 18:45:38.310502 22509476222784 run_lib.py:133] step: 200600, training_loss: 3.91049e-02
I0210 18:45:38.473231 22509476222784 run_lib.py:146] step: 200600, eval_loss: 4.53974e-02
I0210 18:45:57.013352 22509476222784 run_lib.py:133] step: 200650, training_loss: 3.65240e-02
I0210 18:46:15.735284 22509476222784 run_lib.py:133] step: 200700, training_loss: 3.78348e-02
I0210 18:46:15.899449 22509476222784 run_lib.py:146] step: 200700, eval_loss: 3.90237e-02
I0210 18:46:34.437814 22509476222784 run_lib.py:133] step: 200750, training_loss: 4.41405e-02
I0210 18:46:52.949130 22509476222784 run_lib.py:133] step: 200800, training_loss: 5.23752e-02
I0210 18:46:53.112971 22509476222784 run_lib.py:146] step: 200800, eval_loss: 3.38142e-02
I0210 18:47:11.944764 22509476222784 run_lib.py:133] step: 200850, training_loss: 5.35039e-02
I0210 18:47:30.731252 22509476222784 run_lib.py:133] step: 200900, training_loss: 4.36073e-02
I0210 18:47:30.894059 22509476222784 run_lib.py:146] step: 200900, eval_loss: 4.46672e-02
I0210 18:47:49.467505 22509476222784 run_lib.py:133] step: 200950, training_loss: 3.82843e-02
I0210 18:48:08.031903 22509476222784 run_lib.py:133] step: 201000, training_loss: 5.57561e-02
I0210 18:48:08.206857 22509476222784 run_lib.py:146] step: 201000, eval_loss: 4.58588e-02
I0210 18:48:26.758253 22509476222784 run_lib.py:133] step: 201050, training_loss: 5.58216e-02
I0210 18:48:45.545663 22509476222784 run_lib.py:133] step: 201100, training_loss: 4.20199e-02
I0210 18:48:45.712013 22509476222784 run_lib.py:146] step: 201100, eval_loss: 3.42581e-02
I0210 18:49:04.253028 22509476222784 run_lib.py:133] step: 201150, training_loss: 4.35163e-02
I0210 18:49:22.783497 22509476222784 run_lib.py:133] step: 201200, training_loss: 5.53001e-02
I0210 18:49:22.948856 22509476222784 run_lib.py:146] step: 201200, eval_loss: 3.61694e-02
I0210 18:49:41.493365 22509476222784 run_lib.py:133] step: 201250, training_loss: 5.15179e-02
I0210 18:50:00.199428 22509476222784 run_lib.py:133] step: 201300, training_loss: 4.05036e-02
I0210 18:50:00.360693 22509476222784 run_lib.py:146] step: 201300, eval_loss: 4.81739e-02
I0210 18:50:18.907683 22509476222784 run_lib.py:133] step: 201350, training_loss: 3.87504e-02
I0210 18:50:37.540696 22509476222784 run_lib.py:133] step: 201400, training_loss: 5.31018e-02
I0210 18:50:37.713845 22509476222784 run_lib.py:146] step: 201400, eval_loss: 3.96244e-02
I0210 18:50:56.300025 22509476222784 run_lib.py:133] step: 201450, training_loss: 3.95271e-02
I0210 18:51:14.881591 22509476222784 run_lib.py:133] step: 201500, training_loss: 3.59097e-02
I0210 18:51:15.047894 22509476222784 run_lib.py:146] step: 201500, eval_loss: 4.34754e-02
I0210 18:51:33.815106 22509476222784 run_lib.py:133] step: 201550, training_loss: 4.65272e-02
I0210 18:51:52.418393 22509476222784 run_lib.py:133] step: 201600, training_loss: 4.44319e-02
I0210 18:51:52.592216 22509476222784 run_lib.py:146] step: 201600, eval_loss: 4.08080e-02
I0210 18:52:11.192839 22509476222784 run_lib.py:133] step: 201650, training_loss: 5.84530e-02
I0210 18:52:29.848824 22509476222784 run_lib.py:133] step: 201700, training_loss: 3.56263e-02
I0210 18:52:30.015910 22509476222784 run_lib.py:146] step: 201700, eval_loss: 4.33645e-02
I0210 18:52:48.814648 22509476222784 run_lib.py:133] step: 201750, training_loss: 5.37969e-02
I0210 18:53:07.377813 22509476222784 run_lib.py:133] step: 201800, training_loss: 4.42584e-02
I0210 18:53:07.538726 22509476222784 run_lib.py:146] step: 201800, eval_loss: 6.01117e-02
I0210 18:53:26.276114 22509476222784 run_lib.py:133] step: 201850, training_loss: 5.34810e-02
I0210 18:53:44.857006 22509476222784 run_lib.py:133] step: 201900, training_loss: 4.44291e-02
I0210 18:53:45.042976 22509476222784 run_lib.py:146] step: 201900, eval_loss: 4.36632e-02
I0210 18:54:03.883326 22509476222784 run_lib.py:133] step: 201950, training_loss: 5.12562e-02
I0210 18:54:22.453102 22509476222784 run_lib.py:133] step: 202000, training_loss: 3.94755e-02
I0210 18:54:22.622040 22509476222784 run_lib.py:146] step: 202000, eval_loss: 5.39227e-02
I0210 18:54:41.180553 22509476222784 run_lib.py:133] step: 202050, training_loss: 4.93386e-02
I0210 18:54:59.877651 22509476222784 run_lib.py:133] step: 202100, training_loss: 4.33765e-02
I0210 18:55:00.043601 22509476222784 run_lib.py:146] step: 202100, eval_loss: 5.79593e-02
I0210 18:55:18.584023 22509476222784 run_lib.py:133] step: 202150, training_loss: 5.09601e-02
I0210 18:55:37.407679 22509476222784 run_lib.py:133] step: 202200, training_loss: 4.56064e-02
I0210 18:55:37.572762 22509476222784 run_lib.py:146] step: 202200, eval_loss: 5.06159e-02
I0210 18:55:56.150688 22509476222784 run_lib.py:133] step: 202250, training_loss: 4.41751e-02
I0210 18:56:14.681850 22509476222784 run_lib.py:133] step: 202300, training_loss: 5.20785e-02
I0210 18:56:14.843755 22509476222784 run_lib.py:146] step: 202300, eval_loss: 3.53647e-02
I0210 18:56:33.603307 22509476222784 run_lib.py:133] step: 202350, training_loss: 4.17341e-02
I0210 18:56:52.128260 22509476222784 run_lib.py:133] step: 202400, training_loss: 4.00210e-02
I0210 18:56:52.294946 22509476222784 run_lib.py:146] step: 202400, eval_loss: 3.84585e-02
I0210 18:57:10.855332 22509476222784 run_lib.py:133] step: 202450, training_loss: 3.73297e-02
I0210 18:57:29.702792 22509476222784 run_lib.py:133] step: 202500, training_loss: 4.60790e-02
I0210 18:57:29.868667 22509476222784 run_lib.py:146] step: 202500, eval_loss: 4.71517e-02
I0210 18:57:48.407231 22509476222784 run_lib.py:133] step: 202550, training_loss: 4.17619e-02
I0210 18:58:06.920454 22509476222784 run_lib.py:133] step: 202600, training_loss: 3.48497e-02
I0210 18:58:07.092947 22509476222784 run_lib.py:146] step: 202600, eval_loss: 5.27463e-02
I0210 18:58:25.732369 22509476222784 run_lib.py:133] step: 202650, training_loss: 5.18999e-02
I0210 18:58:44.331205 22509476222784 run_lib.py:133] step: 202700, training_loss: 4.08788e-02
I0210 18:58:44.503777 22509476222784 run_lib.py:146] step: 202700, eval_loss: 3.54571e-02
I0210 18:59:03.100302 22509476222784 run_lib.py:133] step: 202750, training_loss: 3.89654e-02
I0210 18:59:21.672420 22509476222784 run_lib.py:133] step: 202800, training_loss: 4.36223e-02
I0210 18:59:21.838624 22509476222784 run_lib.py:146] step: 202800, eval_loss: 5.01600e-02
I0210 18:59:40.555730 22509476222784 run_lib.py:133] step: 202850, training_loss: 3.82031e-02
I0210 18:59:59.189057 22509476222784 run_lib.py:133] step: 202900, training_loss: 3.84435e-02
I0210 18:59:59.356946 22509476222784 run_lib.py:146] step: 202900, eval_loss: 5.23380e-02
I0210 19:00:17.919967 22509476222784 run_lib.py:133] step: 202950, training_loss: 4.44195e-02
I0210 19:00:36.494079 22509476222784 run_lib.py:133] step: 203000, training_loss: 3.59444e-02
I0210 19:00:36.662720 22509476222784 run_lib.py:146] step: 203000, eval_loss: 4.57139e-02
I0210 19:00:55.427274 22509476222784 run_lib.py:133] step: 203050, training_loss: 3.82641e-02
I0210 19:01:14.017753 22509476222784 run_lib.py:133] step: 203100, training_loss: 4.19602e-02
I0210 19:01:14.182375 22509476222784 run_lib.py:146] step: 203100, eval_loss: 4.11492e-02
I0210 19:01:32.914367 22509476222784 run_lib.py:133] step: 203150, training_loss: 4.44359e-02
I0210 19:01:51.435008 22509476222784 run_lib.py:133] step: 203200, training_loss: 4.92845e-02
I0210 19:01:51.624499 22509476222784 run_lib.py:146] step: 203200, eval_loss: 4.73302e-02
I0210 19:02:10.301755 22509476222784 run_lib.py:133] step: 203250, training_loss: 3.93081e-02
I0210 19:02:28.928343 22509476222784 run_lib.py:133] step: 203300, training_loss: 3.97910e-02
I0210 19:02:29.101880 22509476222784 run_lib.py:146] step: 203300, eval_loss: 2.36834e-02
I0210 19:02:47.886885 22509476222784 run_lib.py:133] step: 203350, training_loss: 3.70616e-02
I0210 19:03:06.657450 22509476222784 run_lib.py:133] step: 203400, training_loss: 4.53143e-02
I0210 19:03:06.819846 22509476222784 run_lib.py:146] step: 203400, eval_loss: 4.32150e-02
I0210 19:03:25.341180 22509476222784 run_lib.py:133] step: 203450, training_loss: 4.24243e-02
I0210 19:03:44.060982 22509476222784 run_lib.py:133] step: 203500, training_loss: 5.70598e-02
I0210 19:03:44.224622 22509476222784 run_lib.py:146] step: 203500, eval_loss: 4.29308e-02
I0210 19:04:02.763629 22509476222784 run_lib.py:133] step: 203550, training_loss: 3.88699e-02
I0210 19:04:21.424488 22509476222784 run_lib.py:133] step: 203600, training_loss: 5.86532e-02
I0210 19:04:21.589784 22509476222784 run_lib.py:146] step: 203600, eval_loss: 4.57479e-02
I0210 19:04:40.414857 22509476222784 run_lib.py:133] step: 203650, training_loss: 3.61227e-02
I0210 19:04:58.988952 22509476222784 run_lib.py:133] step: 203700, training_loss: 3.89679e-02
I0210 19:04:59.151791 22509476222784 run_lib.py:146] step: 203700, eval_loss: 4.91462e-02
I0210 19:05:17.890878 22509476222784 run_lib.py:133] step: 203750, training_loss: 4.29750e-02
I0210 19:05:36.461592 22509476222784 run_lib.py:133] step: 203800, training_loss: 6.01902e-02
I0210 19:05:36.626900 22509476222784 run_lib.py:146] step: 203800, eval_loss: 4.47622e-02
I0210 19:05:55.214644 22509476222784 run_lib.py:133] step: 203850, training_loss: 4.79441e-02
I0210 19:06:14.057625 22509476222784 run_lib.py:133] step: 203900, training_loss: 4.59666e-02
I0210 19:06:14.232619 22509476222784 run_lib.py:146] step: 203900, eval_loss: 3.32319e-02
I0210 19:06:32.745660 22509476222784 run_lib.py:133] step: 203950, training_loss: 5.64455e-02
I0210 19:06:51.263036 22509476222784 run_lib.py:133] step: 204000, training_loss: 4.02955e-02
I0210 19:06:51.433537 22509476222784 run_lib.py:146] step: 204000, eval_loss: 3.88273e-02
I0210 19:07:09.992024 22509476222784 run_lib.py:133] step: 204050, training_loss: 4.33262e-02
I0210 19:07:28.725489 22509476222784 run_lib.py:133] step: 204100, training_loss: 4.06712e-02
I0210 19:07:28.890895 22509476222784 run_lib.py:146] step: 204100, eval_loss: 4.29531e-02
I0210 19:07:47.535720 22509476222784 run_lib.py:133] step: 204150, training_loss: 4.61277e-02
I0210 19:08:06.479367 22509476222784 run_lib.py:133] step: 204200, training_loss: 3.99642e-02
I0210 19:08:06.661877 22509476222784 run_lib.py:146] step: 204200, eval_loss: 4.09301e-02
I0210 19:08:25.221888 22509476222784 run_lib.py:133] step: 204250, training_loss: 3.98883e-02
I0210 19:08:43.778138 22509476222784 run_lib.py:133] step: 204300, training_loss: 5.56430e-02
I0210 19:08:43.945180 22509476222784 run_lib.py:146] step: 204300, eval_loss: 4.35041e-02
I0210 19:09:02.660514 22509476222784 run_lib.py:133] step: 204350, training_loss: 4.83290e-02
I0210 19:09:21.323978 22509476222784 run_lib.py:133] step: 204400, training_loss: 3.95790e-02
I0210 19:09:21.499721 22509476222784 run_lib.py:146] step: 204400, eval_loss: 4.33764e-02
I0210 19:09:40.147521 22509476222784 run_lib.py:133] step: 204450, training_loss: 5.10125e-02
I0210 19:09:58.742288 22509476222784 run_lib.py:133] step: 204500, training_loss: 4.56937e-02
I0210 19:09:58.909150 22509476222784 run_lib.py:146] step: 204500, eval_loss: 5.48692e-02
I0210 19:10:17.719792 22509476222784 run_lib.py:133] step: 204550, training_loss: 3.89484e-02
I0210 19:10:36.267189 22509476222784 run_lib.py:133] step: 204600, training_loss: 5.44514e-02
I0210 19:10:36.428607 22509476222784 run_lib.py:146] step: 204600, eval_loss: 3.49825e-02
I0210 19:10:55.125073 22509476222784 run_lib.py:133] step: 204650, training_loss: 4.14060e-02
I0210 19:11:13.732522 22509476222784 run_lib.py:133] step: 204700, training_loss: 4.70060e-02
I0210 19:11:13.898081 22509476222784 run_lib.py:146] step: 204700, eval_loss: 4.86752e-02
I0210 19:11:32.709126 22509476222784 run_lib.py:133] step: 204750, training_loss: 4.36290e-02
I0210 19:11:51.299244 22509476222784 run_lib.py:133] step: 204800, training_loss: 4.45337e-02
I0210 19:11:51.515699 22509476222784 run_lib.py:146] step: 204800, eval_loss: 3.78824e-02
I0210 19:12:10.095872 22509476222784 run_lib.py:133] step: 204850, training_loss: 3.94656e-02
I0210 19:12:28.827416 22509476222784 run_lib.py:133] step: 204900, training_loss: 3.36617e-02
I0210 19:12:28.995595 22509476222784 run_lib.py:146] step: 204900, eval_loss: 3.93223e-02
I0210 19:12:47.532430 22509476222784 run_lib.py:133] step: 204950, training_loss: 4.61601e-02
I0210 19:13:06.298738 22509476222784 run_lib.py:133] step: 205000, training_loss: 3.73770e-02
I0210 19:13:06.464054 22509476222784 run_lib.py:146] step: 205000, eval_loss: 3.99397e-02
I0210 19:13:25.092161 22509476222784 run_lib.py:133] step: 205050, training_loss: 3.89489e-02
I0210 19:13:43.648494 22509476222784 run_lib.py:133] step: 205100, training_loss: 5.05079e-02
I0210 19:13:43.810765 22509476222784 run_lib.py:146] step: 205100, eval_loss: 5.70362e-02
I0210 19:14:02.559789 22509476222784 run_lib.py:133] step: 205150, training_loss: 4.94877e-02
I0210 19:14:21.126302 22509476222784 run_lib.py:133] step: 205200, training_loss: 3.49714e-02
I0210 19:14:21.291710 22509476222784 run_lib.py:146] step: 205200, eval_loss: 5.28926e-02
I0210 19:14:39.864566 22509476222784 run_lib.py:133] step: 205250, training_loss: 4.47702e-02
I0210 19:14:58.624201 22509476222784 run_lib.py:133] step: 205300, training_loss: 4.86423e-02
I0210 19:14:58.794651 22509476222784 run_lib.py:146] step: 205300, eval_loss: 3.97420e-02
I0210 19:15:17.329590 22509476222784 run_lib.py:133] step: 205350, training_loss: 4.25427e-02
I0210 19:15:35.897154 22509476222784 run_lib.py:133] step: 205400, training_loss: 4.60178e-02
I0210 19:15:36.252588 22509476222784 run_lib.py:146] step: 205400, eval_loss: 4.32940e-02
I0210 19:15:54.861013 22509476222784 run_lib.py:133] step: 205450, training_loss: 3.15557e-02
I0210 19:16:13.384793 22509476222784 run_lib.py:133] step: 205500, training_loss: 5.04434e-02
I0210 19:16:13.549677 22509476222784 run_lib.py:146] step: 205500, eval_loss: 4.46031e-02
I0210 19:16:32.126313 22509476222784 run_lib.py:133] step: 205550, training_loss: 4.06097e-02
I0210 19:16:50.737742 22509476222784 run_lib.py:133] step: 205600, training_loss: 3.01935e-02
I0210 19:16:50.917986 22509476222784 run_lib.py:146] step: 205600, eval_loss: 4.81101e-02
I0210 19:17:09.783248 22509476222784 run_lib.py:133] step: 205650, training_loss: 4.98077e-02
I0210 19:17:28.376968 22509476222784 run_lib.py:133] step: 205700, training_loss: 5.52689e-02
I0210 19:17:28.542507 22509476222784 run_lib.py:146] step: 205700, eval_loss: 5.25981e-02
I0210 19:17:47.052319 22509476222784 run_lib.py:133] step: 205750, training_loss: 3.96604e-02
I0210 19:18:05.612203 22509476222784 run_lib.py:133] step: 205800, training_loss: 3.98487e-02
I0210 19:18:05.803665 22509476222784 run_lib.py:146] step: 205800, eval_loss: 3.87425e-02
I0210 19:18:24.631021 22509476222784 run_lib.py:133] step: 205850, training_loss: 3.63177e-02
I0210 19:18:43.339285 22509476222784 run_lib.py:133] step: 205900, training_loss: 4.02379e-02
I0210 19:18:43.500503 22509476222784 run_lib.py:146] step: 205900, eval_loss: 5.00751e-02
I0210 19:19:02.039788 22509476222784 run_lib.py:133] step: 205950, training_loss: 3.12881e-02
I0210 19:19:20.560263 22509476222784 run_lib.py:133] step: 206000, training_loss: 3.87434e-02
I0210 19:19:20.725627 22509476222784 run_lib.py:146] step: 206000, eval_loss: 5.36690e-02
I0210 19:19:39.408693 22509476222784 run_lib.py:133] step: 206050, training_loss: 4.92267e-02
I0210 19:19:57.988574 22509476222784 run_lib.py:133] step: 206100, training_loss: 4.80697e-02
I0210 19:19:58.152732 22509476222784 run_lib.py:146] step: 206100, eval_loss: 3.84478e-02
I0210 19:20:16.958093 22509476222784 run_lib.py:133] step: 206150, training_loss: 5.89176e-02
I0210 19:20:35.488934 22509476222784 run_lib.py:133] step: 206200, training_loss: 3.88700e-02
I0210 19:20:35.655619 22509476222784 run_lib.py:146] step: 206200, eval_loss: 4.32768e-02
I0210 19:20:54.333764 22509476222784 run_lib.py:133] step: 206250, training_loss: 4.09420e-02
I0210 19:21:12.878731 22509476222784 run_lib.py:133] step: 206300, training_loss: 4.89770e-02
I0210 19:21:13.057875 22509476222784 run_lib.py:146] step: 206300, eval_loss: 4.53676e-02
I0210 19:21:31.612149 22509476222784 run_lib.py:133] step: 206350, training_loss: 3.44840e-02
I0210 19:21:50.464420 22509476222784 run_lib.py:133] step: 206400, training_loss: 3.80307e-02
I0210 19:21:50.629489 22509476222784 run_lib.py:146] step: 206400, eval_loss: 3.31376e-02
I0210 19:22:09.242929 22509476222784 run_lib.py:133] step: 206450, training_loss: 4.39198e-02
I0210 19:22:27.953113 22509476222784 run_lib.py:133] step: 206500, training_loss: 2.87362e-02
I0210 19:22:28.112433 22509476222784 run_lib.py:146] step: 206500, eval_loss: 5.21711e-02
I0210 19:22:46.626410 22509476222784 run_lib.py:133] step: 206550, training_loss: 3.48680e-02
I0210 19:23:05.205539 22509476222784 run_lib.py:133] step: 206600, training_loss: 4.47603e-02
I0210 19:23:05.368890 22509476222784 run_lib.py:146] step: 206600, eval_loss: 4.25236e-02
I0210 19:23:23.982221 22509476222784 run_lib.py:133] step: 206650, training_loss: 4.87312e-02
I0210 19:23:42.734685 22509476222784 run_lib.py:133] step: 206700, training_loss: 3.35340e-02
I0210 19:23:42.904526 22509476222784 run_lib.py:146] step: 206700, eval_loss: 3.90302e-02
I0210 19:24:01.448712 22509476222784 run_lib.py:133] step: 206750, training_loss: 4.65482e-02
I0210 19:24:20.028332 22509476222784 run_lib.py:133] step: 206800, training_loss: 5.01301e-02
I0210 19:24:20.305636 22509476222784 run_lib.py:146] step: 206800, eval_loss: 3.76280e-02
I0210 19:24:39.052779 22509476222784 run_lib.py:133] step: 206850, training_loss: 4.52437e-02
I0210 19:24:57.617446 22509476222784 run_lib.py:133] step: 206900, training_loss: 3.89284e-02
I0210 19:24:57.782481 22509476222784 run_lib.py:146] step: 206900, eval_loss: 3.86892e-02
I0210 19:25:16.526182 22509476222784 run_lib.py:133] step: 206950, training_loss: 4.13071e-02
I0210 19:25:35.118313 22509476222784 run_lib.py:133] step: 207000, training_loss: 4.49083e-02
I0210 19:25:35.279520 22509476222784 run_lib.py:146] step: 207000, eval_loss: 3.20634e-02
I0210 19:25:53.807031 22509476222784 run_lib.py:133] step: 207050, training_loss: 4.98535e-02
I0210 19:26:12.319711 22509476222784 run_lib.py:133] step: 207100, training_loss: 3.77903e-02
I0210 19:26:12.484606 22509476222784 run_lib.py:146] step: 207100, eval_loss: 4.83894e-02
I0210 19:26:31.177732 22509476222784 run_lib.py:133] step: 207150, training_loss: 3.84631e-02
I0210 19:26:49.928381 22509476222784 run_lib.py:133] step: 207200, training_loss: 3.15173e-02
I0210 19:26:50.105687 22509476222784 run_lib.py:146] step: 207200, eval_loss: 3.55259e-02
I0210 19:27:08.697187 22509476222784 run_lib.py:133] step: 207250, training_loss: 5.46021e-02
I0210 19:27:27.316412 22509476222784 run_lib.py:133] step: 207300, training_loss: 5.25942e-02
I0210 19:27:27.481857 22509476222784 run_lib.py:146] step: 207300, eval_loss: 5.52946e-02
I0210 19:27:46.248385 22509476222784 run_lib.py:133] step: 207350, training_loss: 4.65828e-02
I0210 19:28:04.814802 22509476222784 run_lib.py:133] step: 207400, training_loss: 3.61616e-02
I0210 19:28:04.996240 22509476222784 run_lib.py:146] step: 207400, eval_loss: 3.78666e-02
I0210 19:28:23.783709 22509476222784 run_lib.py:133] step: 207450, training_loss: 5.14325e-02
I0210 19:28:42.424473 22509476222784 run_lib.py:133] step: 207500, training_loss: 3.93886e-02
I0210 19:28:42.591322 22509476222784 run_lib.py:146] step: 207500, eval_loss: 4.72354e-02
I0210 19:29:01.382139 22509476222784 run_lib.py:133] step: 207550, training_loss: 4.00372e-02
I0210 19:29:19.941859 22509476222784 run_lib.py:133] step: 207600, training_loss: 3.80063e-02
I0210 19:29:20.106737 22509476222784 run_lib.py:146] step: 207600, eval_loss: 5.25468e-02
I0210 19:29:38.781842 22509476222784 run_lib.py:133] step: 207650, training_loss: 3.25266e-02
I0210 19:29:57.337692 22509476222784 run_lib.py:133] step: 207700, training_loss: 4.04810e-02
I0210 19:29:57.506623 22509476222784 run_lib.py:146] step: 207700, eval_loss: 3.62690e-02
I0210 19:30:16.103399 22509476222784 run_lib.py:133] step: 207750, training_loss: 6.19941e-02
I0210 19:30:34.875907 22509476222784 run_lib.py:133] step: 207800, training_loss: 2.96390e-02
I0210 19:30:35.053949 22509476222784 run_lib.py:146] step: 207800, eval_loss: 4.22164e-02
I0210 19:30:53.625205 22509476222784 run_lib.py:133] step: 207850, training_loss: 4.09497e-02
I0210 19:31:12.207007 22509476222784 run_lib.py:133] step: 207900, training_loss: 5.13349e-02
I0210 19:31:12.370744 22509476222784 run_lib.py:146] step: 207900, eval_loss: 4.72410e-02
I0210 19:31:31.094499 22509476222784 run_lib.py:133] step: 207950, training_loss: 4.78404e-02
I0210 19:31:49.904863 22509476222784 run_lib.py:133] step: 208000, training_loss: 3.74726e-02
I0210 19:31:50.072921 22509476222784 run_lib.py:146] step: 208000, eval_loss: 4.56056e-02
I0210 19:32:08.764406 22509476222784 run_lib.py:133] step: 208050, training_loss: 6.39107e-02
I0210 19:32:27.350463 22509476222784 run_lib.py:133] step: 208100, training_loss: 4.24144e-02
I0210 19:32:27.574905 22509476222784 run_lib.py:146] step: 208100, eval_loss: 5.31414e-02
I0210 19:32:46.138700 22509476222784 run_lib.py:133] step: 208150, training_loss: 3.82596e-02
I0210 19:33:04.927992 22509476222784 run_lib.py:133] step: 208200, training_loss: 4.56410e-02
I0210 19:33:05.093783 22509476222784 run_lib.py:146] step: 208200, eval_loss: 5.28544e-02
I0210 19:33:23.614214 22509476222784 run_lib.py:133] step: 208250, training_loss: 4.70669e-02
I0210 19:33:42.217699 22509476222784 run_lib.py:133] step: 208300, training_loss: 3.51000e-02
I0210 19:33:42.383102 22509476222784 run_lib.py:146] step: 208300, eval_loss: 5.23539e-02
I0210 19:34:00.929694 22509476222784 run_lib.py:133] step: 208350, training_loss: 5.75448e-02
I0210 19:34:19.720280 22509476222784 run_lib.py:133] step: 208400, training_loss: 4.97571e-02
I0210 19:34:19.883424 22509476222784 run_lib.py:146] step: 208400, eval_loss: 3.38505e-02
I0210 19:34:38.468453 22509476222784 run_lib.py:133] step: 208450, training_loss: 4.41558e-02
I0210 19:34:57.118492 22509476222784 run_lib.py:133] step: 208500, training_loss: 4.29220e-02
I0210 19:34:57.281920 22509476222784 run_lib.py:146] step: 208500, eval_loss: 4.96721e-02
I0210 19:35:15.893581 22509476222784 run_lib.py:133] step: 208550, training_loss: 3.80368e-02
I0210 19:35:34.487622 22509476222784 run_lib.py:133] step: 208600, training_loss: 4.15869e-02
I0210 19:35:34.653664 22509476222784 run_lib.py:146] step: 208600, eval_loss: 3.20151e-02
I0210 19:35:53.400163 22509476222784 run_lib.py:133] step: 208650, training_loss: 5.62124e-02
I0210 19:36:12.017706 22509476222784 run_lib.py:133] step: 208700, training_loss: 4.90942e-02
I0210 19:36:12.182780 22509476222784 run_lib.py:146] step: 208700, eval_loss: 5.03970e-02
I0210 19:36:30.750278 22509476222784 run_lib.py:133] step: 208750, training_loss: 3.40276e-02
I0210 19:36:49.368586 22509476222784 run_lib.py:133] step: 208800, training_loss: 3.92100e-02
I0210 19:36:49.534006 22509476222784 run_lib.py:146] step: 208800, eval_loss: 4.25918e-02
I0210 19:37:08.371568 22509476222784 run_lib.py:133] step: 208850, training_loss: 5.26486e-02
I0210 19:37:26.925805 22509476222784 run_lib.py:133] step: 208900, training_loss: 4.53288e-02
I0210 19:37:27.086664 22509476222784 run_lib.py:146] step: 208900, eval_loss: 4.70897e-02
I0210 19:37:45.811158 22509476222784 run_lib.py:133] step: 208950, training_loss: 4.34391e-02
I0210 19:38:04.435375 22509476222784 run_lib.py:133] step: 209000, training_loss: 4.31532e-02
I0210 19:38:04.599776 22509476222784 run_lib.py:146] step: 209000, eval_loss: 4.68257e-02
I0210 19:38:23.328366 22509476222784 run_lib.py:133] step: 209050, training_loss: 5.80649e-02
I0210 19:38:41.953367 22509476222784 run_lib.py:133] step: 209100, training_loss: 4.33536e-02
I0210 19:38:42.154874 22509476222784 run_lib.py:146] step: 209100, eval_loss: 5.26316e-02
I0210 19:39:00.800808 22509476222784 run_lib.py:133] step: 209150, training_loss: 4.19739e-02
I0210 19:39:19.566960 22509476222784 run_lib.py:133] step: 209200, training_loss: 3.82701e-02
I0210 19:39:19.733032 22509476222784 run_lib.py:146] step: 209200, eval_loss: 3.79837e-02
I0210 19:39:38.331531 22509476222784 run_lib.py:133] step: 209250, training_loss: 5.83782e-02
I0210 19:39:57.039072 22509476222784 run_lib.py:133] step: 209300, training_loss: 4.76043e-02
I0210 19:39:57.214792 22509476222784 run_lib.py:146] step: 209300, eval_loss: 5.31892e-02
I0210 19:40:15.828527 22509476222784 run_lib.py:133] step: 209350, training_loss: 4.16637e-02
I0210 19:40:34.426724 22509476222784 run_lib.py:133] step: 209400, training_loss: 4.47820e-02
I0210 19:40:34.594960 22509476222784 run_lib.py:146] step: 209400, eval_loss: 3.96069e-02
I0210 19:40:53.411604 22509476222784 run_lib.py:133] step: 209450, training_loss: 3.22765e-02
I0210 19:41:12.015814 22509476222784 run_lib.py:133] step: 209500, training_loss: 4.43591e-02
I0210 19:41:12.181601 22509476222784 run_lib.py:146] step: 209500, eval_loss: 3.84066e-02
I0210 19:41:30.747900 22509476222784 run_lib.py:133] step: 209550, training_loss: 5.02675e-02
I0210 19:41:49.544988 22509476222784 run_lib.py:133] step: 209600, training_loss: 3.15798e-02
I0210 19:41:49.724692 22509476222784 run_lib.py:146] step: 209600, eval_loss: 4.42225e-02
I0210 19:42:08.417057 22509476222784 run_lib.py:133] step: 209650, training_loss: 4.36797e-02
I0210 19:42:27.076758 22509476222784 run_lib.py:133] step: 209700, training_loss: 4.33430e-02
I0210 19:42:27.242953 22509476222784 run_lib.py:146] step: 209700, eval_loss: 3.70215e-02
I0210 19:42:45.956302 22509476222784 run_lib.py:133] step: 209750, training_loss: 4.72261e-02
I0210 19:43:04.500782 22509476222784 run_lib.py:133] step: 209800, training_loss: 5.05555e-02
I0210 19:43:04.672770 22509476222784 run_lib.py:146] step: 209800, eval_loss: 4.02283e-02
I0210 19:43:23.223362 22509476222784 run_lib.py:133] step: 209850, training_loss: 4.81509e-02
I0210 19:43:41.823524 22509476222784 run_lib.py:133] step: 209900, training_loss: 4.83724e-02
I0210 19:43:41.996128 22509476222784 run_lib.py:146] step: 209900, eval_loss: 5.70174e-02
I0210 19:44:00.845702 22509476222784 run_lib.py:133] step: 209950, training_loss: 4.41984e-02
I0210 19:44:19.509843 22509476222784 run_lib.py:133] step: 210000, training_loss: 3.66964e-02
I0210 19:44:20.438675 22509476222784 run_lib.py:146] step: 210000, eval_loss: 4.74814e-02
I0210 19:44:41.696256 22509476222784 run_lib.py:133] step: 210050, training_loss: 4.97628e-02
I0210 19:45:00.287890 22509476222784 run_lib.py:133] step: 210100, training_loss: 5.08230e-02
I0210 19:45:00.454986 22509476222784 run_lib.py:146] step: 210100, eval_loss: 3.55522e-02
I0210 19:45:19.068254 22509476222784 run_lib.py:133] step: 210150, training_loss: 3.49961e-02
I0210 19:45:37.956691 22509476222784 run_lib.py:133] step: 210200, training_loss: 4.97765e-02
I0210 19:45:38.124048 22509476222784 run_lib.py:146] step: 210200, eval_loss: 4.29908e-02
I0210 19:45:56.709509 22509476222784 run_lib.py:133] step: 210250, training_loss: 4.50783e-02
I0210 19:46:15.350277 22509476222784 run_lib.py:133] step: 210300, training_loss: 4.33856e-02
I0210 19:46:15.515650 22509476222784 run_lib.py:146] step: 210300, eval_loss: 3.29068e-02
I0210 19:46:34.145647 22509476222784 run_lib.py:133] step: 210350, training_loss: 4.66748e-02
I0210 19:46:52.745752 22509476222784 run_lib.py:133] step: 210400, training_loss: 5.04660e-02
I0210 19:46:52.908991 22509476222784 run_lib.py:146] step: 210400, eval_loss: 2.64517e-02
I0210 19:47:11.699353 22509476222784 run_lib.py:133] step: 210450, training_loss: 5.18071e-02
I0210 19:47:30.461981 22509476222784 run_lib.py:133] step: 210500, training_loss: 5.52261e-02
I0210 19:47:30.630160 22509476222784 run_lib.py:146] step: 210500, eval_loss: 4.82442e-02
I0210 19:47:49.217903 22509476222784 run_lib.py:133] step: 210550, training_loss: 4.01350e-02
I0210 19:48:07.797297 22509476222784 run_lib.py:133] step: 210600, training_loss: 3.54432e-02
I0210 19:48:07.982785 22509476222784 run_lib.py:146] step: 210600, eval_loss: 4.34865e-02
I0210 19:48:26.690753 22509476222784 run_lib.py:133] step: 210650, training_loss: 4.28790e-02
I0210 19:48:45.299546 22509476222784 run_lib.py:133] step: 210700, training_loss: 4.14651e-02
I0210 19:48:45.472717 22509476222784 run_lib.py:146] step: 210700, eval_loss: 4.30365e-02
I0210 19:49:04.322302 22509476222784 run_lib.py:133] step: 210750, training_loss: 4.91538e-02
I0210 19:49:22.984308 22509476222784 run_lib.py:133] step: 210800, training_loss: 5.06796e-02
I0210 19:49:23.148391 22509476222784 run_lib.py:146] step: 210800, eval_loss: 3.90029e-02
I0210 19:49:41.953416 22509476222784 run_lib.py:133] step: 210850, training_loss: 4.76935e-02
I0210 19:50:00.571914 22509476222784 run_lib.py:133] step: 210900, training_loss: 4.14795e-02
I0210 19:50:00.733762 22509476222784 run_lib.py:146] step: 210900, eval_loss: 4.78619e-02
I0210 19:50:19.298949 22509476222784 run_lib.py:133] step: 210950, training_loss: 3.51296e-02
I0210 19:50:38.175589 22509476222784 run_lib.py:133] step: 211000, training_loss: 4.06166e-02
I0210 19:50:38.359799 22509476222784 run_lib.py:146] step: 211000, eval_loss: 4.17082e-02
I0210 19:50:57.059797 22509476222784 run_lib.py:133] step: 211050, training_loss: 5.14044e-02
I0210 19:51:15.910432 22509476222784 run_lib.py:133] step: 211100, training_loss: 4.68322e-02
I0210 19:51:16.074846 22509476222784 run_lib.py:146] step: 211100, eval_loss: 3.79781e-02
I0210 19:51:34.651982 22509476222784 run_lib.py:133] step: 211150, training_loss: 4.85096e-02
I0210 19:51:53.298571 22509476222784 run_lib.py:133] step: 211200, training_loss: 4.10091e-02
I0210 19:51:53.462864 22509476222784 run_lib.py:146] step: 211200, eval_loss: 5.78806e-02
I0210 19:52:12.215173 22509476222784 run_lib.py:133] step: 211250, training_loss: 5.03507e-02
I0210 19:52:30.975728 22509476222784 run_lib.py:133] step: 211300, training_loss: 5.07703e-02
I0210 19:52:31.145901 22509476222784 run_lib.py:146] step: 211300, eval_loss: 3.77846e-02
I0210 19:52:49.758131 22509476222784 run_lib.py:133] step: 211350, training_loss: 3.80200e-02
I0210 19:53:08.521867 22509476222784 run_lib.py:133] step: 211400, training_loss: 4.42639e-02
I0210 19:53:08.684801 22509476222784 run_lib.py:146] step: 211400, eval_loss: 4.35788e-02
I0210 19:53:27.221547 22509476222784 run_lib.py:133] step: 211450, training_loss: 4.97717e-02
I0210 19:53:45.804083 22509476222784 run_lib.py:133] step: 211500, training_loss: 5.52551e-02
I0210 19:53:45.992888 22509476222784 run_lib.py:146] step: 211500, eval_loss: 4.25344e-02
I0210 19:54:04.667140 22509476222784 run_lib.py:133] step: 211550, training_loss: 6.20591e-02
I0210 19:54:23.265469 22509476222784 run_lib.py:133] step: 211600, training_loss: 4.55492e-02
I0210 19:54:23.431929 22509476222784 run_lib.py:146] step: 211600, eval_loss: 4.70717e-02
I0210 19:54:42.013582 22509476222784 run_lib.py:133] step: 211650, training_loss: 3.66655e-02
I0210 19:55:00.558139 22509476222784 run_lib.py:133] step: 211700, training_loss: 4.14927e-02
I0210 19:55:00.723526 22509476222784 run_lib.py:146] step: 211700, eval_loss: 4.26485e-02
I0210 19:55:19.471282 22509476222784 run_lib.py:133] step: 211750, training_loss: 4.08560e-02
I0210 19:55:38.248787 22509476222784 run_lib.py:133] step: 211800, training_loss: 5.00597e-02
I0210 19:55:38.411370 22509476222784 run_lib.py:146] step: 211800, eval_loss: 4.58076e-02
I0210 19:55:57.021005 22509476222784 run_lib.py:133] step: 211850, training_loss: 4.55700e-02
I0210 19:56:15.594311 22509476222784 run_lib.py:133] step: 211900, training_loss: 3.37640e-02
I0210 19:56:15.758744 22509476222784 run_lib.py:146] step: 211900, eval_loss: 4.55357e-02
I0210 19:56:34.472758 22509476222784 run_lib.py:133] step: 211950, training_loss: 4.55099e-02
I0210 19:56:53.049315 22509476222784 run_lib.py:133] step: 212000, training_loss: 3.43675e-02
I0210 19:56:53.217213 22509476222784 run_lib.py:146] step: 212000, eval_loss: 4.89600e-02
I0210 19:57:11.929644 22509476222784 run_lib.py:133] step: 212050, training_loss: 4.95837e-02
I0210 19:57:30.613471 22509476222784 run_lib.py:133] step: 212100, training_loss: 5.57310e-02
I0210 19:57:30.782996 22509476222784 run_lib.py:146] step: 212100, eval_loss: 3.72858e-02
I0210 19:57:49.546286 22509476222784 run_lib.py:133] step: 212150, training_loss: 5.15512e-02
I0210 19:58:08.080815 22509476222784 run_lib.py:133] step: 212200, training_loss: 3.70482e-02
I0210 19:58:08.252710 22509476222784 run_lib.py:146] step: 212200, eval_loss: 3.90347e-02
I0210 19:58:26.988078 22509476222784 run_lib.py:133] step: 212250, training_loss: 4.10301e-02
I0210 19:58:45.545695 22509476222784 run_lib.py:133] step: 212300, training_loss: 3.69212e-02
I0210 19:58:45.707813 22509476222784 run_lib.py:146] step: 212300, eval_loss: 4.32823e-02
I0210 19:59:04.277484 22509476222784 run_lib.py:133] step: 212350, training_loss: 4.48504e-02
I0210 19:59:23.054929 22509476222784 run_lib.py:133] step: 212400, training_loss: 4.64153e-02
I0210 19:59:23.232982 22509476222784 run_lib.py:146] step: 212400, eval_loss: 3.38153e-02
I0210 19:59:41.821479 22509476222784 run_lib.py:133] step: 212450, training_loss: 4.29635e-02
I0210 20:00:00.477553 22509476222784 run_lib.py:133] step: 212500, training_loss: 3.60531e-02
I0210 20:00:00.644009 22509476222784 run_lib.py:146] step: 212500, eval_loss: 5.88564e-02
I0210 20:00:19.417207 22509476222784 run_lib.py:133] step: 212550, training_loss: 4.80127e-02
I0210 20:00:37.984516 22509476222784 run_lib.py:133] step: 212600, training_loss: 4.45137e-02
I0210 20:00:38.151700 22509476222784 run_lib.py:146] step: 212600, eval_loss: 3.38813e-02
I0210 20:00:56.897916 22509476222784 run_lib.py:133] step: 212650, training_loss: 4.62872e-02
I0210 20:01:15.512795 22509476222784 run_lib.py:133] step: 212700, training_loss: 4.94969e-02
I0210 20:01:15.677726 22509476222784 run_lib.py:146] step: 212700, eval_loss: 4.86736e-02
I0210 20:01:34.225037 22509476222784 run_lib.py:133] step: 212750, training_loss: 4.22773e-02
I0210 20:01:53.021051 22509476222784 run_lib.py:133] step: 212800, training_loss: 4.66189e-02
I0210 20:01:53.186645 22509476222784 run_lib.py:146] step: 212800, eval_loss: 4.37703e-02
I0210 20:02:11.809644 22509476222784 run_lib.py:133] step: 212850, training_loss: 3.53805e-02
I0210 20:02:30.427158 22509476222784 run_lib.py:133] step: 212900, training_loss: 4.06658e-02
I0210 20:02:30.604726 22509476222784 run_lib.py:146] step: 212900, eval_loss: 3.72429e-02
I0210 20:02:49.261359 22509476222784 run_lib.py:133] step: 212950, training_loss: 3.58858e-02
I0210 20:03:08.149322 22509476222784 run_lib.py:133] step: 213000, training_loss: 4.64718e-02
I0210 20:03:08.313815 22509476222784 run_lib.py:146] step: 213000, eval_loss: 4.36845e-02
I0210 20:03:26.885646 22509476222784 run_lib.py:133] step: 213050, training_loss: 4.13096e-02
I0210 20:03:45.513089 22509476222784 run_lib.py:133] step: 213100, training_loss: 5.02923e-02
I0210 20:03:45.679417 22509476222784 run_lib.py:146] step: 213100, eval_loss: 4.14869e-02
I0210 20:04:04.280140 22509476222784 run_lib.py:133] step: 213150, training_loss: 5.09824e-02
I0210 20:04:22.885684 22509476222784 run_lib.py:133] step: 213200, training_loss: 4.12112e-02
I0210 20:04:23.049474 22509476222784 run_lib.py:146] step: 213200, eval_loss: 3.60839e-02
I0210 20:04:41.859716 22509476222784 run_lib.py:133] step: 213250, training_loss: 4.61559e-02
I0210 20:05:00.534102 22509476222784 run_lib.py:133] step: 213300, training_loss: 3.25564e-02
I0210 20:05:00.696828 22509476222784 run_lib.py:146] step: 213300, eval_loss: 4.26755e-02
I0210 20:05:19.267128 22509476222784 run_lib.py:133] step: 213350, training_loss: 4.89720e-02
I0210 20:05:37.859072 22509476222784 run_lib.py:133] step: 213400, training_loss: 3.53206e-02
I0210 20:05:38.037810 22509476222784 run_lib.py:146] step: 213400, eval_loss: 3.43618e-02
I0210 20:05:56.860372 22509476222784 run_lib.py:133] step: 213450, training_loss: 4.73760e-02
I0210 20:06:15.452825 22509476222784 run_lib.py:133] step: 213500, training_loss: 3.39707e-02
I0210 20:06:15.622102 22509476222784 run_lib.py:146] step: 213500, eval_loss: 3.89881e-02
I0210 20:06:34.372715 22509476222784 run_lib.py:133] step: 213550, training_loss: 4.18048e-02
I0210 20:06:52.923440 22509476222784 run_lib.py:133] step: 213600, training_loss: 4.17203e-02
I0210 20:06:53.088875 22509476222784 run_lib.py:146] step: 213600, eval_loss: 4.33219e-02
I0210 20:07:11.807704 22509476222784 run_lib.py:133] step: 213650, training_loss: 4.21398e-02
I0210 20:07:30.461675 22509476222784 run_lib.py:133] step: 213700, training_loss: 4.54591e-02
I0210 20:07:30.654414 22509476222784 run_lib.py:146] step: 213700, eval_loss: 3.58815e-02
I0210 20:07:49.319754 22509476222784 run_lib.py:133] step: 213750, training_loss: 3.29534e-02
I0210 20:08:08.065019 22509476222784 run_lib.py:133] step: 213800, training_loss: 3.83573e-02
I0210 20:08:08.243626 22509476222784 run_lib.py:146] step: 213800, eval_loss: 3.04655e-02
I0210 20:08:26.781589 22509476222784 run_lib.py:133] step: 213850, training_loss: 3.94247e-02
I0210 20:08:45.482412 22509476222784 run_lib.py:133] step: 213900, training_loss: 3.65611e-02
I0210 20:08:45.648929 22509476222784 run_lib.py:146] step: 213900, eval_loss: 4.61178e-02
I0210 20:09:04.215117 22509476222784 run_lib.py:133] step: 213950, training_loss: 4.86200e-02
I0210 20:09:22.838386 22509476222784 run_lib.py:133] step: 214000, training_loss: 4.04655e-02
I0210 20:09:23.003756 22509476222784 run_lib.py:146] step: 214000, eval_loss: 3.86715e-02
I0210 20:09:41.762453 22509476222784 run_lib.py:133] step: 214050, training_loss: 4.32211e-02
I0210 20:10:00.299269 22509476222784 run_lib.py:133] step: 214100, training_loss: 5.43184e-02
I0210 20:10:00.463724 22509476222784 run_lib.py:146] step: 214100, eval_loss: 3.76555e-02
I0210 20:10:18.989056 22509476222784 run_lib.py:133] step: 214150, training_loss: 3.85083e-02
I0210 20:10:37.676218 22509476222784 run_lib.py:133] step: 214200, training_loss: 3.27021e-02
I0210 20:10:37.843644 22509476222784 run_lib.py:146] step: 214200, eval_loss: 4.79486e-02
I0210 20:10:56.422925 22509476222784 run_lib.py:133] step: 214250, training_loss: 5.55279e-02
I0210 20:11:15.012795 22509476222784 run_lib.py:133] step: 214300, training_loss: 3.78042e-02
I0210 20:11:15.379902 22509476222784 run_lib.py:146] step: 214300, eval_loss: 4.85954e-02
I0210 20:11:33.968081 22509476222784 run_lib.py:133] step: 214350, training_loss: 4.41019e-02
I0210 20:11:52.558778 22509476222784 run_lib.py:133] step: 214400, training_loss: 4.47645e-02
I0210 20:11:52.728092 22509476222784 run_lib.py:146] step: 214400, eval_loss: 3.61277e-02
I0210 20:12:11.281326 22509476222784 run_lib.py:133] step: 214450, training_loss: 3.23624e-02
I0210 20:12:29.808495 22509476222784 run_lib.py:133] step: 214500, training_loss: 4.43893e-02
I0210 20:12:29.984531 22509476222784 run_lib.py:146] step: 214500, eval_loss: 4.64428e-02
I0210 20:12:48.694717 22509476222784 run_lib.py:133] step: 214550, training_loss: 6.13368e-02
I0210 20:13:07.396142 22509476222784 run_lib.py:133] step: 214600, training_loss: 6.33102e-02
I0210 20:13:07.561888 22509476222784 run_lib.py:146] step: 214600, eval_loss: 3.14558e-02
I0210 20:13:26.187908 22509476222784 run_lib.py:133] step: 214650, training_loss: 5.02331e-02
I0210 20:13:44.762267 22509476222784 run_lib.py:133] step: 214700, training_loss: 3.28478e-02
I0210 20:13:44.923801 22509476222784 run_lib.py:146] step: 214700, eval_loss: 4.55823e-02
I0210 20:14:03.641376 22509476222784 run_lib.py:133] step: 214750, training_loss: 3.53113e-02
I0210 20:14:22.244076 22509476222784 run_lib.py:133] step: 214800, training_loss: 5.23570e-02
I0210 20:14:22.425594 22509476222784 run_lib.py:146] step: 214800, eval_loss: 4.95796e-02
I0210 20:14:41.043574 22509476222784 run_lib.py:133] step: 214850, training_loss: 4.77205e-02
I0210 20:14:59.585355 22509476222784 run_lib.py:133] step: 214900, training_loss: 4.71239e-02
I0210 20:14:59.749563 22509476222784 run_lib.py:146] step: 214900, eval_loss: 4.26384e-02
I0210 20:15:18.475524 22509476222784 run_lib.py:133] step: 214950, training_loss: 4.54341e-02
I0210 20:15:37.037731 22509476222784 run_lib.py:133] step: 215000, training_loss: 4.42264e-02
I0210 20:15:37.202798 22509476222784 run_lib.py:146] step: 215000, eval_loss: 3.98370e-02
I0210 20:15:55.909329 22509476222784 run_lib.py:133] step: 215050, training_loss: 5.61639e-02
I0210 20:16:14.491566 22509476222784 run_lib.py:133] step: 215100, training_loss: 5.54163e-02
I0210 20:16:14.655931 22509476222784 run_lib.py:146] step: 215100, eval_loss: 5.40869e-02
I0210 20:16:33.494114 22509476222784 run_lib.py:133] step: 215150, training_loss: 3.24378e-02
I0210 20:16:52.052888 22509476222784 run_lib.py:133] step: 215200, training_loss: 3.62599e-02
I0210 20:16:52.241928 22509476222784 run_lib.py:146] step: 215200, eval_loss: 3.89547e-02
I0210 20:17:10.778807 22509476222784 run_lib.py:133] step: 215250, training_loss: 3.52538e-02
I0210 20:17:29.455138 22509476222784 run_lib.py:133] step: 215300, training_loss: 3.61914e-02
I0210 20:17:29.620949 22509476222784 run_lib.py:146] step: 215300, eval_loss: 4.98751e-02
I0210 20:17:48.147149 22509476222784 run_lib.py:133] step: 215350, training_loss: 4.62353e-02
I0210 20:18:06.877812 22509476222784 run_lib.py:133] step: 215400, training_loss: 4.05397e-02
I0210 20:18:07.042782 22509476222784 run_lib.py:146] step: 215400, eval_loss: 5.17911e-02
I0210 20:18:25.569502 22509476222784 run_lib.py:133] step: 215450, training_loss: 3.87283e-02
I0210 20:18:44.093005 22509476222784 run_lib.py:133] step: 215500, training_loss: 2.83815e-02
I0210 20:18:44.256464 22509476222784 run_lib.py:146] step: 215500, eval_loss: 4.08015e-02
I0210 20:19:02.850605 22509476222784 run_lib.py:133] step: 215550, training_loss: 4.39601e-02
I0210 20:19:21.630444 22509476222784 run_lib.py:133] step: 215600, training_loss: 5.14508e-02
I0210 20:19:21.792671 22509476222784 run_lib.py:146] step: 215600, eval_loss: 3.37062e-02
I0210 20:19:40.324285 22509476222784 run_lib.py:133] step: 215650, training_loss: 3.71454e-02
I0210 20:19:58.913022 22509476222784 run_lib.py:133] step: 215700, training_loss: 4.19214e-02
I0210 20:19:59.087050 22509476222784 run_lib.py:146] step: 215700, eval_loss: 4.34535e-02
I0210 20:20:17.898915 22509476222784 run_lib.py:133] step: 215750, training_loss: 3.86239e-02
I0210 20:20:36.500058 22509476222784 run_lib.py:133] step: 215800, training_loss: 3.56771e-02
I0210 20:20:36.666099 22509476222784 run_lib.py:146] step: 215800, eval_loss: 3.91666e-02
I0210 20:20:55.295484 22509476222784 run_lib.py:133] step: 215850, training_loss: 3.77275e-02
I0210 20:21:13.838367 22509476222784 run_lib.py:133] step: 215900, training_loss: 3.88615e-02
I0210 20:21:14.002784 22509476222784 run_lib.py:146] step: 215900, eval_loss: 4.89921e-02
I0210 20:21:32.556562 22509476222784 run_lib.py:133] step: 215950, training_loss: 4.43174e-02
I0210 20:21:51.202201 22509476222784 run_lib.py:133] step: 216000, training_loss: 3.69673e-02
I0210 20:21:51.366897 22509476222784 run_lib.py:146] step: 216000, eval_loss: 4.85998e-02
I0210 20:22:10.148618 22509476222784 run_lib.py:133] step: 216050, training_loss: 4.12730e-02
I0210 20:22:28.773015 22509476222784 run_lib.py:133] step: 216100, training_loss: 5.27858e-02
I0210 20:22:28.935781 22509476222784 run_lib.py:146] step: 216100, eval_loss: 4.55737e-02
I0210 20:22:47.510856 22509476222784 run_lib.py:133] step: 216150, training_loss: 5.07045e-02
I0210 20:23:06.089730 22509476222784 run_lib.py:133] step: 216200, training_loss: 4.65796e-02
I0210 20:23:06.258044 22509476222784 run_lib.py:146] step: 216200, eval_loss: 4.49589e-02
I0210 20:23:25.018586 22509476222784 run_lib.py:133] step: 216250, training_loss: 4.10227e-02
I0210 20:23:43.696187 22509476222784 run_lib.py:133] step: 216300, training_loss: 3.18209e-02
I0210 20:23:43.863828 22509476222784 run_lib.py:146] step: 216300, eval_loss: 4.90909e-02
I0210 20:24:02.615571 22509476222784 run_lib.py:133] step: 216350, training_loss: 4.30845e-02
I0210 20:24:21.167828 22509476222784 run_lib.py:133] step: 216400, training_loss: 3.77485e-02
I0210 20:24:21.332635 22509476222784 run_lib.py:146] step: 216400, eval_loss: 3.90817e-02
I0210 20:24:40.003441 22509476222784 run_lib.py:133] step: 216450, training_loss: 2.88998e-02
I0210 20:24:58.558157 22509476222784 run_lib.py:133] step: 216500, training_loss: 4.35573e-02
I0210 20:24:58.724931 22509476222784 run_lib.py:146] step: 216500, eval_loss: 4.49830e-02
I0210 20:25:17.548751 22509476222784 run_lib.py:133] step: 216550, training_loss: 3.92517e-02
I0210 20:25:36.136438 22509476222784 run_lib.py:133] step: 216600, training_loss: 3.91520e-02
I0210 20:25:36.297771 22509476222784 run_lib.py:146] step: 216600, eval_loss: 3.42839e-02
I0210 20:25:54.846076 22509476222784 run_lib.py:133] step: 216650, training_loss: 5.14636e-02
I0210 20:26:13.512950 22509476222784 run_lib.py:133] step: 216700, training_loss: 6.69281e-02
I0210 20:26:13.681038 22509476222784 run_lib.py:146] step: 216700, eval_loss: 4.04257e-02
I0210 20:26:32.217927 22509476222784 run_lib.py:133] step: 216750, training_loss: 5.21759e-02
I0210 20:26:50.853204 22509476222784 run_lib.py:133] step: 216800, training_loss: 4.75334e-02
I0210 20:26:51.020606 22509476222784 run_lib.py:146] step: 216800, eval_loss: 4.59593e-02
I0210 20:27:09.799094 22509476222784 run_lib.py:133] step: 216850, training_loss: 3.88897e-02
I0210 20:27:28.538796 22509476222784 run_lib.py:133] step: 216900, training_loss: 3.52896e-02
I0210 20:27:28.704018 22509476222784 run_lib.py:146] step: 216900, eval_loss: 3.82015e-02
I0210 20:27:47.273523 22509476222784 run_lib.py:133] step: 216950, training_loss: 4.95987e-02
I0210 20:28:05.821548 22509476222784 run_lib.py:133] step: 217000, training_loss: 4.47166e-02
I0210 20:28:06.024441 22509476222784 run_lib.py:146] step: 217000, eval_loss: 3.63236e-02
I0210 20:28:24.629154 22509476222784 run_lib.py:133] step: 217050, training_loss: 3.75065e-02
I0210 20:28:43.383416 22509476222784 run_lib.py:133] step: 217100, training_loss: 6.06834e-02
I0210 20:28:43.547857 22509476222784 run_lib.py:146] step: 217100, eval_loss: 4.27350e-02
I0210 20:29:02.154342 22509476222784 run_lib.py:133] step: 217150, training_loss: 3.18049e-02
I0210 20:29:20.709961 22509476222784 run_lib.py:133] step: 217200, training_loss: 4.94318e-02
I0210 20:29:20.875715 22509476222784 run_lib.py:146] step: 217200, eval_loss: 4.52248e-02
I0210 20:29:39.403692 22509476222784 run_lib.py:133] step: 217250, training_loss: 3.31784e-02
I0210 20:29:58.099907 22509476222784 run_lib.py:133] step: 217300, training_loss: 4.69560e-02
I0210 20:29:58.270953 22509476222784 run_lib.py:146] step: 217300, eval_loss: 4.62774e-02
I0210 20:30:16.857244 22509476222784 run_lib.py:133] step: 217350, training_loss: 5.31478e-02
I0210 20:30:35.548010 22509476222784 run_lib.py:133] step: 217400, training_loss: 3.85822e-02
I0210 20:30:35.712950 22509476222784 run_lib.py:146] step: 217400, eval_loss: 4.40457e-02
I0210 20:30:54.258119 22509476222784 run_lib.py:133] step: 217450, training_loss: 3.77698e-02
I0210 20:31:12.823128 22509476222784 run_lib.py:133] step: 217500, training_loss: 3.84216e-02
I0210 20:31:12.982674 22509476222784 run_lib.py:146] step: 217500, eval_loss: 4.26718e-02
I0210 20:31:31.699518 22509476222784 run_lib.py:133] step: 217550, training_loss: 4.46175e-02
I0210 20:31:50.407517 22509476222784 run_lib.py:133] step: 217600, training_loss: 3.82352e-02
I0210 20:31:50.578957 22509476222784 run_lib.py:146] step: 217600, eval_loss: 3.84651e-02
I0210 20:32:09.189047 22509476222784 run_lib.py:133] step: 217650, training_loss: 4.79705e-02
I0210 20:32:27.818963 22509476222784 run_lib.py:133] step: 217700, training_loss: 4.80115e-02
I0210 20:32:27.982760 22509476222784 run_lib.py:146] step: 217700, eval_loss: 4.21857e-02
I0210 20:32:46.658522 22509476222784 run_lib.py:133] step: 217750, training_loss: 4.95052e-02
I0210 20:33:05.216250 22509476222784 run_lib.py:133] step: 217800, training_loss: 4.41983e-02
I0210 20:33:05.387749 22509476222784 run_lib.py:146] step: 217800, eval_loss: 4.22246e-02
I0210 20:33:24.121103 22509476222784 run_lib.py:133] step: 217850, training_loss: 4.65601e-02
I0210 20:33:42.720802 22509476222784 run_lib.py:133] step: 217900, training_loss: 4.02219e-02
I0210 20:33:42.886929 22509476222784 run_lib.py:146] step: 217900, eval_loss: 5.27322e-02
I0210 20:34:01.672954 22509476222784 run_lib.py:133] step: 217950, training_loss: 2.96444e-02
I0210 20:34:20.197075 22509476222784 run_lib.py:133] step: 218000, training_loss: 3.78078e-02
I0210 20:34:20.358735 22509476222784 run_lib.py:146] step: 218000, eval_loss: 4.64034e-02
I0210 20:34:38.869497 22509476222784 run_lib.py:133] step: 218050, training_loss: 4.50759e-02
I0210 20:34:57.534950 22509476222784 run_lib.py:133] step: 218100, training_loss: 5.21419e-02
I0210 20:34:57.733876 22509476222784 run_lib.py:146] step: 218100, eval_loss: 4.31365e-02
I0210 20:35:16.360144 22509476222784 run_lib.py:133] step: 218150, training_loss: 3.64521e-02
I0210 20:35:35.135193 22509476222784 run_lib.py:133] step: 218200, training_loss: 3.99141e-02
I0210 20:35:35.307699 22509476222784 run_lib.py:146] step: 218200, eval_loss: 3.03168e-02
I0210 20:35:53.811089 22509476222784 run_lib.py:133] step: 218250, training_loss: 5.44063e-02
I0210 20:36:12.366064 22509476222784 run_lib.py:133] step: 218300, training_loss: 4.78801e-02
I0210 20:36:12.536593 22509476222784 run_lib.py:146] step: 218300, eval_loss: 4.30850e-02
I0210 20:36:31.239236 22509476222784 run_lib.py:133] step: 218350, training_loss: 3.63597e-02
I0210 20:36:49.849065 22509476222784 run_lib.py:133] step: 218400, training_loss: 4.00008e-02
I0210 20:36:50.017901 22509476222784 run_lib.py:146] step: 218400, eval_loss: 4.76166e-02
I0210 20:37:08.623529 22509476222784 run_lib.py:133] step: 218450, training_loss: 4.30419e-02
I0210 20:37:27.323634 22509476222784 run_lib.py:133] step: 218500, training_loss: 4.85931e-02
I0210 20:37:27.485749 22509476222784 run_lib.py:146] step: 218500, eval_loss: 4.37665e-02
I0210 20:37:46.094753 22509476222784 run_lib.py:133] step: 218550, training_loss: 4.27625e-02
I0210 20:38:04.636646 22509476222784 run_lib.py:133] step: 218600, training_loss: 4.42700e-02
I0210 20:38:04.808932 22509476222784 run_lib.py:146] step: 218600, eval_loss: 4.42060e-02
I0210 20:38:23.455373 22509476222784 run_lib.py:133] step: 218650, training_loss: 4.16498e-02
I0210 20:38:42.100451 22509476222784 run_lib.py:133] step: 218700, training_loss: 4.84946e-02
I0210 20:38:42.266569 22509476222784 run_lib.py:146] step: 218700, eval_loss: 3.70952e-02
I0210 20:39:00.849339 22509476222784 run_lib.py:133] step: 218750, training_loss: 5.35016e-02
I0210 20:39:19.405055 22509476222784 run_lib.py:133] step: 218800, training_loss: 4.75502e-02
I0210 20:39:19.569377 22509476222784 run_lib.py:146] step: 218800, eval_loss: 4.38730e-02
I0210 20:39:38.305466 22509476222784 run_lib.py:133] step: 218850, training_loss: 4.10547e-02
I0210 20:39:56.936190 22509476222784 run_lib.py:133] step: 218900, training_loss: 3.56923e-02
I0210 20:39:57.097547 22509476222784 run_lib.py:146] step: 218900, eval_loss: 3.45297e-02
I0210 20:40:15.727162 22509476222784 run_lib.py:133] step: 218950, training_loss: 3.51994e-02
I0210 20:40:34.333543 22509476222784 run_lib.py:133] step: 219000, training_loss: 3.50530e-02
I0210 20:40:34.499961 22509476222784 run_lib.py:146] step: 219000, eval_loss: 4.02500e-02
I0210 20:40:53.239955 22509476222784 run_lib.py:133] step: 219050, training_loss: 3.81807e-02
I0210 20:41:11.858149 22509476222784 run_lib.py:133] step: 219100, training_loss: 4.73481e-02
I0210 20:41:12.026002 22509476222784 run_lib.py:146] step: 219100, eval_loss: 4.22128e-02
I0210 20:41:30.759354 22509476222784 run_lib.py:133] step: 219150, training_loss: 4.08270e-02
I0210 20:41:49.383997 22509476222784 run_lib.py:133] step: 219200, training_loss: 5.33190e-02
I0210 20:41:49.564882 22509476222784 run_lib.py:146] step: 219200, eval_loss: 3.86874e-02
I0210 20:42:08.341014 22509476222784 run_lib.py:133] step: 219250, training_loss: 4.96662e-02
I0210 20:42:26.989221 22509476222784 run_lib.py:133] step: 219300, training_loss: 3.96278e-02
I0210 20:42:27.153578 22509476222784 run_lib.py:146] step: 219300, eval_loss: 3.94352e-02
I0210 20:42:45.927692 22509476222784 run_lib.py:133] step: 219350, training_loss: 4.52509e-02
I0210 20:43:04.480594 22509476222784 run_lib.py:133] step: 219400, training_loss: 2.64832e-02
I0210 20:43:04.641381 22509476222784 run_lib.py:146] step: 219400, eval_loss: 2.39084e-02
I0210 20:43:23.253267 22509476222784 run_lib.py:133] step: 219450, training_loss: 4.99506e-02
I0210 20:43:42.020044 22509476222784 run_lib.py:133] step: 219500, training_loss: 4.98100e-02
I0210 20:43:42.184712 22509476222784 run_lib.py:146] step: 219500, eval_loss: 3.68941e-02
I0210 20:44:00.807825 22509476222784 run_lib.py:133] step: 219550, training_loss: 3.52076e-02
I0210 20:44:19.466667 22509476222784 run_lib.py:133] step: 219600, training_loss: 4.02682e-02
I0210 20:44:19.642618 22509476222784 run_lib.py:146] step: 219600, eval_loss: 4.15269e-02
I0210 20:44:38.451127 22509476222784 run_lib.py:133] step: 219650, training_loss: 4.37424e-02
I0210 20:44:57.054001 22509476222784 run_lib.py:133] step: 219700, training_loss: 3.37188e-02
I0210 20:44:57.219607 22509476222784 run_lib.py:146] step: 219700, eval_loss: 4.63278e-02
I0210 20:45:16.001033 22509476222784 run_lib.py:133] step: 219750, training_loss: 5.31780e-02
I0210 20:45:34.609888 22509476222784 run_lib.py:133] step: 219800, training_loss: 4.36109e-02
I0210 20:45:34.775956 22509476222784 run_lib.py:146] step: 219800, eval_loss: 3.02584e-02
I0210 20:45:53.444840 22509476222784 run_lib.py:133] step: 219850, training_loss: 3.37192e-02
I0210 20:46:12.337110 22509476222784 run_lib.py:133] step: 219900, training_loss: 3.49372e-02
I0210 20:46:12.499633 22509476222784 run_lib.py:146] step: 219900, eval_loss: 4.67527e-02
I0210 20:46:31.121013 22509476222784 run_lib.py:133] step: 219950, training_loss: 3.89506e-02
I0210 20:46:49.739284 22509476222784 run_lib.py:133] step: 220000, training_loss: 5.24303e-02
I0210 20:46:50.942638 22509476222784 run_lib.py:146] step: 220000, eval_loss: 5.17566e-02
I0210 20:47:12.423543 22509476222784 run_lib.py:133] step: 220050, training_loss: 4.32156e-02
I0210 20:47:31.124399 22509476222784 run_lib.py:133] step: 220100, training_loss: 4.83587e-02
I0210 20:47:31.307660 22509476222784 run_lib.py:146] step: 220100, eval_loss: 3.32963e-02
I0210 20:47:50.099601 22509476222784 run_lib.py:133] step: 220150, training_loss: 3.36302e-02
I0210 20:48:08.729848 22509476222784 run_lib.py:133] step: 220200, training_loss: 4.78652e-02
I0210 20:48:08.895991 22509476222784 run_lib.py:146] step: 220200, eval_loss: 4.32887e-02
I0210 20:48:27.625624 22509476222784 run_lib.py:133] step: 220250, training_loss: 4.27709e-02
I0210 20:48:46.214794 22509476222784 run_lib.py:133] step: 220300, training_loss: 5.25794e-02
I0210 20:48:46.381001 22509476222784 run_lib.py:146] step: 220300, eval_loss: 3.55815e-02
I0210 20:49:04.971278 22509476222784 run_lib.py:133] step: 220350, training_loss: 3.87107e-02
I0210 20:49:23.614440 22509476222784 run_lib.py:133] step: 220400, training_loss: 3.73939e-02
I0210 20:49:23.780049 22509476222784 run_lib.py:146] step: 220400, eval_loss: 4.98592e-02
I0210 20:49:42.589344 22509476222784 run_lib.py:133] step: 220450, training_loss: 4.87866e-02
I0210 20:50:01.244984 22509476222784 run_lib.py:133] step: 220500, training_loss: 4.73431e-02
I0210 20:50:01.408739 22509476222784 run_lib.py:146] step: 220500, eval_loss: 4.72681e-02
I0210 20:50:19.940710 22509476222784 run_lib.py:133] step: 220550, training_loss: 4.14118e-02
I0210 20:50:38.549331 22509476222784 run_lib.py:133] step: 220600, training_loss: 3.84978e-02
I0210 20:50:38.724498 22509476222784 run_lib.py:146] step: 220600, eval_loss: 5.08978e-02
I0210 20:50:57.535038 22509476222784 run_lib.py:133] step: 220650, training_loss: 3.18913e-02
I0210 20:51:16.187662 22509476222784 run_lib.py:133] step: 220700, training_loss: 3.76770e-02
I0210 20:51:16.353016 22509476222784 run_lib.py:146] step: 220700, eval_loss: 5.13993e-02
I0210 20:51:35.112312 22509476222784 run_lib.py:133] step: 220750, training_loss: 3.75599e-02
I0210 20:51:53.650333 22509476222784 run_lib.py:133] step: 220800, training_loss: 4.44642e-02
I0210 20:51:53.821851 22509476222784 run_lib.py:146] step: 220800, eval_loss: 4.73156e-02
I0210 20:52:12.585426 22509476222784 run_lib.py:133] step: 220850, training_loss: 4.92509e-02
I0210 20:52:31.230965 22509476222784 run_lib.py:133] step: 220900, training_loss: 5.38219e-02
I0210 20:52:31.396930 22509476222784 run_lib.py:146] step: 220900, eval_loss: 4.00968e-02
I0210 20:52:50.214595 22509476222784 run_lib.py:133] step: 220950, training_loss: 3.79135e-02
I0210 20:53:08.803601 22509476222784 run_lib.py:133] step: 221000, training_loss: 3.29568e-02
I0210 20:53:08.969730 22509476222784 run_lib.py:146] step: 221000, eval_loss: 4.11581e-02
I0210 20:53:27.573264 22509476222784 run_lib.py:133] step: 221050, training_loss: 4.14879e-02
I0210 20:53:46.333760 22509476222784 run_lib.py:133] step: 221100, training_loss: 4.14211e-02
I0210 20:53:46.502106 22509476222784 run_lib.py:146] step: 221100, eval_loss: 3.91517e-02
I0210 20:54:05.170701 22509476222784 run_lib.py:133] step: 221150, training_loss: 3.90487e-02
I0210 20:54:23.845445 22509476222784 run_lib.py:133] step: 221200, training_loss: 3.47007e-02
I0210 20:54:24.011168 22509476222784 run_lib.py:146] step: 221200, eval_loss: 4.31237e-02
I0210 20:54:42.817505 22509476222784 run_lib.py:133] step: 221250, training_loss: 4.01659e-02
I0210 20:55:01.519513 22509476222784 run_lib.py:133] step: 221300, training_loss: 4.04728e-02
I0210 20:55:01.683778 22509476222784 run_lib.py:146] step: 221300, eval_loss: 3.24779e-02
I0210 20:55:20.282579 22509476222784 run_lib.py:133] step: 221350, training_loss: 4.60041e-02
I0210 20:55:38.840341 22509476222784 run_lib.py:133] step: 221400, training_loss: 4.36733e-02
I0210 20:55:39.006428 22509476222784 run_lib.py:146] step: 221400, eval_loss: 3.93185e-02
I0210 20:55:57.662079 22509476222784 run_lib.py:133] step: 221450, training_loss: 4.35762e-02
I0210 20:56:16.400439 22509476222784 run_lib.py:133] step: 221500, training_loss: 3.27671e-02
I0210 20:56:16.564392 22509476222784 run_lib.py:146] step: 221500, eval_loss: 3.79862e-02
I0210 20:56:35.084661 22509476222784 run_lib.py:133] step: 221550, training_loss: 4.30037e-02
I0210 20:56:53.598574 22509476222784 run_lib.py:133] step: 221600, training_loss: 4.42394e-02
I0210 20:56:53.764706 22509476222784 run_lib.py:146] step: 221600, eval_loss: 4.43123e-02
I0210 20:57:12.297858 22509476222784 run_lib.py:133] step: 221650, training_loss: 3.70338e-02
I0210 20:57:31.132219 22509476222784 run_lib.py:133] step: 221700, training_loss: 3.58736e-02
I0210 20:57:31.295195 22509476222784 run_lib.py:146] step: 221700, eval_loss: 4.52581e-02
I0210 20:57:49.878798 22509476222784 run_lib.py:133] step: 221750, training_loss: 3.53625e-02
I0210 20:58:08.526525 22509476222784 run_lib.py:133] step: 221800, training_loss: 3.72925e-02
I0210 20:58:08.691681 22509476222784 run_lib.py:146] step: 221800, eval_loss: 3.77268e-02
I0210 20:58:27.229858 22509476222784 run_lib.py:133] step: 221850, training_loss: 3.54094e-02
I0210 20:58:45.742432 22509476222784 run_lib.py:133] step: 221900, training_loss: 4.01139e-02
I0210 20:58:45.905650 22509476222784 run_lib.py:146] step: 221900, eval_loss: 4.47863e-02
I0210 20:59:04.644048 22509476222784 run_lib.py:133] step: 221950, training_loss: 4.25293e-02
I0210 20:59:23.322562 22509476222784 run_lib.py:133] step: 222000, training_loss: 3.95623e-02
I0210 20:59:23.487944 22509476222784 run_lib.py:146] step: 222000, eval_loss: 4.03871e-02
I0210 20:59:42.011327 22509476222784 run_lib.py:133] step: 222050, training_loss: 3.82231e-02
I0210 21:00:00.525324 22509476222784 run_lib.py:133] step: 222100, training_loss: 4.44814e-02
I0210 21:00:00.695751 22509476222784 run_lib.py:146] step: 222100, eval_loss: 3.66434e-02
I0210 21:00:19.342904 22509476222784 run_lib.py:133] step: 222150, training_loss: 4.17396e-02
I0210 21:00:37.869278 22509476222784 run_lib.py:133] step: 222200, training_loss: 4.47324e-02
I0210 21:00:38.037978 22509476222784 run_lib.py:146] step: 222200, eval_loss: 4.06227e-02
I0210 21:00:56.787839 22509476222784 run_lib.py:133] step: 222250, training_loss: 5.12944e-02
I0210 21:01:15.325365 22509476222784 run_lib.py:133] step: 222300, training_loss: 5.71098e-02
I0210 21:01:15.495877 22509476222784 run_lib.py:146] step: 222300, eval_loss: 4.82078e-02
I0210 21:01:34.234050 22509476222784 run_lib.py:133] step: 222350, training_loss: 5.11288e-02
I0210 21:01:52.841036 22509476222784 run_lib.py:133] step: 222400, training_loss: 4.29261e-02
I0210 21:01:53.007707 22509476222784 run_lib.py:146] step: 222400, eval_loss: 5.25059e-02
I0210 21:02:11.605067 22509476222784 run_lib.py:133] step: 222450, training_loss: 4.06407e-02
I0210 21:02:30.319421 22509476222784 run_lib.py:133] step: 222500, training_loss: 3.77912e-02
I0210 21:02:30.500693 22509476222784 run_lib.py:146] step: 222500, eval_loss: 5.19086e-02
I0210 21:02:49.094450 22509476222784 run_lib.py:133] step: 222550, training_loss: 3.62667e-02
I0210 21:03:07.899008 22509476222784 run_lib.py:133] step: 222600, training_loss: 3.95998e-02
I0210 21:03:08.072716 22509476222784 run_lib.py:146] step: 222600, eval_loss: 4.16727e-02
I0210 21:03:26.658973 22509476222784 run_lib.py:133] step: 222650, training_loss: 3.86353e-02
I0210 21:03:45.164997 22509476222784 run_lib.py:133] step: 222700, training_loss: 4.52331e-02
I0210 21:03:45.331726 22509476222784 run_lib.py:146] step: 222700, eval_loss: 4.91198e-02
I0210 21:04:04.081575 22509476222784 run_lib.py:133] step: 222750, training_loss: 4.77046e-02
I0210 21:04:22.632277 22509476222784 run_lib.py:133] step: 222800, training_loss: 4.65467e-02
I0210 21:04:22.801922 22509476222784 run_lib.py:146] step: 222800, eval_loss: 3.85684e-02
I0210 21:04:41.405691 22509476222784 run_lib.py:133] step: 222850, training_loss: 3.32839e-02
I0210 21:05:00.121459 22509476222784 run_lib.py:133] step: 222900, training_loss: 4.60057e-02
I0210 21:05:00.286732 22509476222784 run_lib.py:146] step: 222900, eval_loss: 4.31119e-02
I0210 21:05:18.822870 22509476222784 run_lib.py:133] step: 222950, training_loss: 3.94638e-02
I0210 21:05:37.372435 22509476222784 run_lib.py:133] step: 223000, training_loss: 4.89077e-02
I0210 21:05:37.539857 22509476222784 run_lib.py:146] step: 223000, eval_loss: 4.44372e-02
I0210 21:05:56.242933 22509476222784 run_lib.py:133] step: 223050, training_loss: 5.22589e-02
I0210 21:06:14.880019 22509476222784 run_lib.py:133] step: 223100, training_loss: 5.26041e-02
I0210 21:06:15.050931 22509476222784 run_lib.py:146] step: 223100, eval_loss: 5.51393e-02
I0210 21:06:33.632289 22509476222784 run_lib.py:133] step: 223150, training_loss: 5.26718e-02
I0210 21:06:52.190019 22509476222784 run_lib.py:133] step: 223200, training_loss: 5.35106e-02
I0210 21:06:52.355614 22509476222784 run_lib.py:146] step: 223200, eval_loss: 3.72926e-02
I0210 21:07:11.139666 22509476222784 run_lib.py:133] step: 223250, training_loss: 4.60162e-02
I0210 21:07:29.808789 22509476222784 run_lib.py:133] step: 223300, training_loss: 3.56500e-02
I0210 21:07:29.974134 22509476222784 run_lib.py:146] step: 223300, eval_loss: 4.32066e-02
I0210 21:07:48.625955 22509476222784 run_lib.py:133] step: 223350, training_loss: 3.93180e-02
I0210 21:08:07.192545 22509476222784 run_lib.py:133] step: 223400, training_loss: 4.08450e-02
I0210 21:08:07.358796 22509476222784 run_lib.py:146] step: 223400, eval_loss: 4.75788e-02
I0210 21:08:26.065889 22509476222784 run_lib.py:133] step: 223450, training_loss: 3.55692e-02
I0210 21:08:44.617647 22509476222784 run_lib.py:133] step: 223500, training_loss: 4.30274e-02
I0210 21:08:44.783544 22509476222784 run_lib.py:146] step: 223500, eval_loss: 5.03766e-02
I0210 21:09:03.507674 22509476222784 run_lib.py:133] step: 223550, training_loss: 4.91468e-02
I0210 21:09:22.187238 22509476222784 run_lib.py:133] step: 223600, training_loss: 3.59587e-02
I0210 21:09:22.351939 22509476222784 run_lib.py:146] step: 223600, eval_loss: 3.19909e-02
I0210 21:09:41.110162 22509476222784 run_lib.py:133] step: 223650, training_loss: 4.56318e-02
I0210 21:09:59.632569 22509476222784 run_lib.py:133] step: 223700, training_loss: 4.54927e-02
I0210 21:09:59.802674 22509476222784 run_lib.py:146] step: 223700, eval_loss: 5.13346e-02
I0210 21:10:18.480682 22509476222784 run_lib.py:133] step: 223750, training_loss: 4.52192e-02
I0210 21:10:37.050175 22509476222784 run_lib.py:133] step: 223800, training_loss: 3.45554e-02
I0210 21:10:37.218765 22509476222784 run_lib.py:146] step: 223800, eval_loss: 6.08841e-02
I0210 21:10:55.802068 22509476222784 run_lib.py:133] step: 223850, training_loss: 5.11489e-02
I0210 21:11:14.621056 22509476222784 run_lib.py:133] step: 223900, training_loss: 4.55984e-02
I0210 21:11:14.798712 22509476222784 run_lib.py:146] step: 223900, eval_loss: 4.21836e-02
I0210 21:11:33.446481 22509476222784 run_lib.py:133] step: 223950, training_loss: 4.74185e-02
I0210 21:11:52.036421 22509476222784 run_lib.py:133] step: 224000, training_loss: 5.04783e-02
I0210 21:11:52.216909 22509476222784 run_lib.py:146] step: 224000, eval_loss: 3.96622e-02
I0210 21:12:10.978357 22509476222784 run_lib.py:133] step: 224050, training_loss: 3.26470e-02
I0210 21:12:29.533160 22509476222784 run_lib.py:133] step: 224100, training_loss: 3.95923e-02
I0210 21:12:29.697465 22509476222784 run_lib.py:146] step: 224100, eval_loss: 4.75446e-02
I0210 21:12:48.475924 22509476222784 run_lib.py:133] step: 224150, training_loss: 4.19294e-02
I0210 21:13:07.123167 22509476222784 run_lib.py:133] step: 224200, training_loss: 4.16481e-02
I0210 21:13:07.288187 22509476222784 run_lib.py:146] step: 224200, eval_loss: 5.54318e-02
I0210 21:13:25.921697 22509476222784 run_lib.py:133] step: 224250, training_loss: 3.86901e-02
I0210 21:13:44.767142 22509476222784 run_lib.py:133] step: 224300, training_loss: 3.53373e-02
I0210 21:13:44.932699 22509476222784 run_lib.py:146] step: 224300, eval_loss: 4.31304e-02
I0210 21:14:03.470362 22509476222784 run_lib.py:133] step: 224350, training_loss: 4.36360e-02
I0210 21:14:22.073721 22509476222784 run_lib.py:133] step: 224400, training_loss: 3.06504e-02
I0210 21:14:22.255761 22509476222784 run_lib.py:146] step: 224400, eval_loss: 4.91962e-02
I0210 21:14:40.873053 22509476222784 run_lib.py:133] step: 224450, training_loss: 2.87994e-02
I0210 21:14:59.687006 22509476222784 run_lib.py:133] step: 224500, training_loss: 4.00839e-02
I0210 21:14:59.851914 22509476222784 run_lib.py:146] step: 224500, eval_loss: 4.33904e-02
I0210 21:15:18.433249 22509476222784 run_lib.py:133] step: 224550, training_loss: 4.19502e-02
I0210 21:15:37.073385 22509476222784 run_lib.py:133] step: 224600, training_loss: 6.06967e-02
I0210 21:15:37.237756 22509476222784 run_lib.py:146] step: 224600, eval_loss: 4.56650e-02
I0210 21:15:55.794986 22509476222784 run_lib.py:133] step: 224650, training_loss: 4.18276e-02
I0210 21:16:14.366319 22509476222784 run_lib.py:133] step: 224700, training_loss: 3.38979e-02
I0210 21:16:14.532824 22509476222784 run_lib.py:146] step: 224700, eval_loss: 5.41418e-02
I0210 21:16:33.399133 22509476222784 run_lib.py:133] step: 224750, training_loss: 3.61311e-02
I0210 21:16:52.101737 22509476222784 run_lib.py:133] step: 224800, training_loss: 4.46770e-02
I0210 21:16:52.268658 22509476222784 run_lib.py:146] step: 224800, eval_loss: 5.12719e-02
I0210 21:17:10.815204 22509476222784 run_lib.py:133] step: 224850, training_loss: 3.63216e-02
I0210 21:17:29.364031 22509476222784 run_lib.py:133] step: 224900, training_loss: 4.07253e-02
I0210 21:17:29.535886 22509476222784 run_lib.py:146] step: 224900, eval_loss: 3.66572e-02
I0210 21:17:48.306444 22509476222784 run_lib.py:133] step: 224950, training_loss: 5.06094e-02
I0210 21:18:06.932070 22509476222784 run_lib.py:133] step: 225000, training_loss: 3.21378e-02
I0210 21:18:07.098295 22509476222784 run_lib.py:146] step: 225000, eval_loss: 4.69168e-02
I0210 21:18:25.857533 22509476222784 run_lib.py:133] step: 225050, training_loss: 4.08566e-02
I0210 21:18:44.399772 22509476222784 run_lib.py:133] step: 225100, training_loss: 4.73794e-02
I0210 21:18:44.570769 22509476222784 run_lib.py:146] step: 225100, eval_loss: 3.93017e-02
I0210 21:19:03.272760 22509476222784 run_lib.py:133] step: 225150, training_loss: 2.97170e-02
I0210 21:19:21.854203 22509476222784 run_lib.py:133] step: 225200, training_loss: 5.08804e-02
I0210 21:19:22.015767 22509476222784 run_lib.py:146] step: 225200, eval_loss: 4.14788e-02
I0210 21:19:40.586716 22509476222784 run_lib.py:133] step: 225250, training_loss: 4.97038e-02
I0210 21:19:59.336945 22509476222784 run_lib.py:133] step: 225300, training_loss: 4.54887e-02
I0210 21:19:59.513719 22509476222784 run_lib.py:146] step: 225300, eval_loss: 4.45261e-02
I0210 21:20:18.162682 22509476222784 run_lib.py:133] step: 225350, training_loss: 3.23346e-02
I0210 21:20:36.907080 22509476222784 run_lib.py:133] step: 225400, training_loss: 4.12749e-02
I0210 21:20:37.072002 22509476222784 run_lib.py:146] step: 225400, eval_loss: 3.15030e-02
I0210 21:20:55.637563 22509476222784 run_lib.py:133] step: 225450, training_loss: 3.60873e-02
I0210 21:21:14.291829 22509476222784 run_lib.py:133] step: 225500, training_loss: 4.17660e-02
I0210 21:21:14.456867 22509476222784 run_lib.py:146] step: 225500, eval_loss: 4.37728e-02
I0210 21:21:33.230167 22509476222784 run_lib.py:133] step: 225550, training_loss: 5.18499e-02
I0210 21:21:51.797769 22509476222784 run_lib.py:133] step: 225600, training_loss: 4.71491e-02
I0210 21:21:51.969164 22509476222784 run_lib.py:146] step: 225600, eval_loss: 4.58493e-02
I0210 21:22:10.570180 22509476222784 run_lib.py:133] step: 225650, training_loss: 4.89745e-02
I0210 21:22:29.286580 22509476222784 run_lib.py:133] step: 225700, training_loss: 4.91876e-02
I0210 21:22:29.457879 22509476222784 run_lib.py:146] step: 225700, eval_loss: 4.89737e-02
I0210 21:22:47.974905 22509476222784 run_lib.py:133] step: 225750, training_loss: 4.46401e-02
I0210 21:23:06.504836 22509476222784 run_lib.py:133] step: 225800, training_loss: 4.68636e-02
I0210 21:23:06.818841 22509476222784 run_lib.py:146] step: 225800, eval_loss: 5.44721e-02
I0210 21:23:25.375094 22509476222784 run_lib.py:133] step: 225850, training_loss: 3.96057e-02
I0210 21:23:44.015391 22509476222784 run_lib.py:133] step: 225900, training_loss: 4.27772e-02
I0210 21:23:44.180849 22509476222784 run_lib.py:146] step: 225900, eval_loss: 4.33802e-02
I0210 21:24:02.747088 22509476222784 run_lib.py:133] step: 225950, training_loss: 4.38098e-02
I0210 21:24:21.293375 22509476222784 run_lib.py:133] step: 226000, training_loss: 4.96836e-02
I0210 21:24:21.458928 22509476222784 run_lib.py:146] step: 226000, eval_loss: 4.81035e-02
I0210 21:24:40.239980 22509476222784 run_lib.py:133] step: 226050, training_loss: 4.29307e-02
I0210 21:24:58.886119 22509476222784 run_lib.py:133] step: 226100, training_loss: 4.76196e-02
I0210 21:24:59.048724 22509476222784 run_lib.py:146] step: 226100, eval_loss: 4.28725e-02
I0210 21:25:17.672289 22509476222784 run_lib.py:133] step: 226150, training_loss: 4.08554e-02
I0210 21:25:36.231796 22509476222784 run_lib.py:133] step: 226200, training_loss: 4.85025e-02
I0210 21:25:36.409917 22509476222784 run_lib.py:146] step: 226200, eval_loss: 5.10270e-02
I0210 21:25:55.131190 22509476222784 run_lib.py:133] step: 226250, training_loss: 4.17067e-02
I0210 21:26:13.783158 22509476222784 run_lib.py:133] step: 226300, training_loss: 4.65609e-02
I0210 21:26:13.948611 22509476222784 run_lib.py:146] step: 226300, eval_loss: 4.25436e-02
I0210 21:26:32.516160 22509476222784 run_lib.py:133] step: 226350, training_loss: 3.52347e-02
I0210 21:26:51.040162 22509476222784 run_lib.py:133] step: 226400, training_loss: 4.29351e-02
I0210 21:26:51.205836 22509476222784 run_lib.py:146] step: 226400, eval_loss: 3.79632e-02
I0210 21:27:09.939571 22509476222784 run_lib.py:133] step: 226450, training_loss: 3.97808e-02
I0210 21:27:28.530713 22509476222784 run_lib.py:133] step: 226500, training_loss: 4.06938e-02
I0210 21:27:28.711998 22509476222784 run_lib.py:146] step: 226500, eval_loss: 4.34167e-02
I0210 21:27:47.509703 22509476222784 run_lib.py:133] step: 226550, training_loss: 5.11349e-02
I0210 21:28:06.017067 22509476222784 run_lib.py:133] step: 226600, training_loss: 3.85069e-02
I0210 21:28:06.179710 22509476222784 run_lib.py:146] step: 226600, eval_loss: 3.72889e-02
I0210 21:28:24.840911 22509476222784 run_lib.py:133] step: 226650, training_loss: 3.95552e-02
I0210 21:28:43.401012 22509476222784 run_lib.py:133] step: 226700, training_loss: 2.98474e-02
I0210 21:28:43.582855 22509476222784 run_lib.py:146] step: 226700, eval_loss: 3.89249e-02
I0210 21:29:02.162369 22509476222784 run_lib.py:133] step: 226750, training_loss: 5.11294e-02
I0210 21:29:20.877700 22509476222784 run_lib.py:133] step: 226800, training_loss: 3.33755e-02
I0210 21:29:21.043658 22509476222784 run_lib.py:146] step: 226800, eval_loss: 5.26645e-02
I0210 21:29:39.595783 22509476222784 run_lib.py:133] step: 226850, training_loss: 4.21381e-02
I0210 21:29:58.320568 22509476222784 run_lib.py:133] step: 226900, training_loss: 3.87617e-02
I0210 21:29:58.485668 22509476222784 run_lib.py:146] step: 226900, eval_loss: 4.56021e-02
I0210 21:30:17.062534 22509476222784 run_lib.py:133] step: 226950, training_loss: 3.85262e-02
I0210 21:30:35.701021 22509476222784 run_lib.py:133] step: 227000, training_loss: 3.83879e-02
I0210 21:30:35.870538 22509476222784 run_lib.py:146] step: 227000, eval_loss: 4.45358e-02
I0210 21:30:54.631052 22509476222784 run_lib.py:133] step: 227050, training_loss: 4.88738e-02
I0210 21:31:13.187680 22509476222784 run_lib.py:133] step: 227100, training_loss: 3.83822e-02
I0210 21:31:13.348715 22509476222784 run_lib.py:146] step: 227100, eval_loss: 3.53229e-02
I0210 21:31:31.901567 22509476222784 run_lib.py:133] step: 227150, training_loss: 4.64789e-02
I0210 21:31:50.415877 22509476222784 run_lib.py:133] step: 227200, training_loss: 5.06005e-02
I0210 21:31:50.598605 22509476222784 run_lib.py:146] step: 227200, eval_loss: 3.67545e-02
I0210 21:32:09.333915 22509476222784 run_lib.py:133] step: 227250, training_loss: 4.83566e-02
I0210 21:32:27.923848 22509476222784 run_lib.py:133] step: 227300, training_loss: 4.95221e-02
I0210 21:32:28.089659 22509476222784 run_lib.py:146] step: 227300, eval_loss: 3.79098e-02
I0210 21:32:46.734575 22509476222784 run_lib.py:133] step: 227350, training_loss: 4.20647e-02
I0210 21:33:05.225717 22509476222784 run_lib.py:133] step: 227400, training_loss: 5.10012e-02
I0210 21:33:05.390782 22509476222784 run_lib.py:146] step: 227400, eval_loss: 4.90671e-02
I0210 21:33:23.940003 22509476222784 run_lib.py:133] step: 227450, training_loss: 6.20363e-02
I0210 21:33:42.600064 22509476222784 run_lib.py:133] step: 227500, training_loss: 4.40167e-02
I0210 21:33:42.765965 22509476222784 run_lib.py:146] step: 227500, eval_loss: 5.04764e-02
I0210 21:34:01.496737 22509476222784 run_lib.py:133] step: 227550, training_loss: 6.13339e-02
I0210 21:34:20.175042 22509476222784 run_lib.py:133] step: 227600, training_loss: 4.52742e-02
I0210 21:34:20.346663 22509476222784 run_lib.py:146] step: 227600, eval_loss: 3.47030e-02
I0210 21:34:38.914204 22509476222784 run_lib.py:133] step: 227650, training_loss: 3.65144e-02
I0210 21:34:57.489355 22509476222784 run_lib.py:133] step: 227700, training_loss: 4.38439e-02
I0210 21:34:57.656100 22509476222784 run_lib.py:146] step: 227700, eval_loss: 4.22086e-02
I0210 21:35:16.340579 22509476222784 run_lib.py:133] step: 227750, training_loss: 4.93873e-02
I0210 21:35:34.975691 22509476222784 run_lib.py:133] step: 227800, training_loss: 4.94601e-02
I0210 21:35:35.141896 22509476222784 run_lib.py:146] step: 227800, eval_loss: 3.28502e-02
I0210 21:35:53.892080 22509476222784 run_lib.py:133] step: 227850, training_loss: 3.38944e-02
I0210 21:36:12.430451 22509476222784 run_lib.py:133] step: 227900, training_loss: 4.05415e-02
I0210 21:36:12.602423 22509476222784 run_lib.py:146] step: 227900, eval_loss: 4.50459e-02
I0210 21:36:31.305008 22509476222784 run_lib.py:133] step: 227950, training_loss: 4.05695e-02
I0210 21:36:49.891151 22509476222784 run_lib.py:133] step: 228000, training_loss: 4.89152e-02
I0210 21:36:50.054451 22509476222784 run_lib.py:146] step: 228000, eval_loss: 3.90841e-02
I0210 21:37:08.863873 22509476222784 run_lib.py:133] step: 228050, training_loss: 3.76578e-02
I0210 21:37:27.464114 22509476222784 run_lib.py:133] step: 228100, training_loss: 3.62803e-02
I0210 21:37:27.649027 22509476222784 run_lib.py:146] step: 228100, eval_loss: 4.89665e-02
I0210 21:37:46.162533 22509476222784 run_lib.py:133] step: 228150, training_loss: 4.55506e-02
I0210 21:38:04.883029 22509476222784 run_lib.py:133] step: 228200, training_loss: 4.15190e-02
I0210 21:38:05.050098 22509476222784 run_lib.py:146] step: 228200, eval_loss: 4.41896e-02
I0210 21:38:23.588088 22509476222784 run_lib.py:133] step: 228250, training_loss: 3.68374e-02
I0210 21:38:42.169648 22509476222784 run_lib.py:133] step: 228300, training_loss: 4.79677e-02
I0210 21:38:42.350661 22509476222784 run_lib.py:146] step: 228300, eval_loss: 5.18262e-02
I0210 21:39:01.082796 22509476222784 run_lib.py:133] step: 228350, training_loss: 5.56347e-02
I0210 21:39:19.835118 22509476222784 run_lib.py:133] step: 228400, training_loss: 5.66690e-02
I0210 21:39:20.057968 22509476222784 run_lib.py:146] step: 228400, eval_loss: 5.04781e-02
I0210 21:39:38.653153 22509476222784 run_lib.py:133] step: 228450, training_loss: 4.45974e-02
I0210 21:39:57.187965 22509476222784 run_lib.py:133] step: 228500, training_loss: 3.64580e-02
I0210 21:39:57.348618 22509476222784 run_lib.py:146] step: 228500, eval_loss: 4.98195e-02
I0210 21:40:15.910636 22509476222784 run_lib.py:133] step: 228550, training_loss: 5.22857e-02
I0210 21:40:34.650139 22509476222784 run_lib.py:133] step: 228600, training_loss: 4.25953e-02
I0210 21:40:34.833847 22509476222784 run_lib.py:146] step: 228600, eval_loss: 4.44794e-02
I0210 21:40:53.392804 22509476222784 run_lib.py:133] step: 228650, training_loss: 4.62139e-02
I0210 21:41:12.021753 22509476222784 run_lib.py:133] step: 228700, training_loss: 4.88901e-02
I0210 21:41:12.187827 22509476222784 run_lib.py:146] step: 228700, eval_loss: 4.44027e-02
I0210 21:41:30.741118 22509476222784 run_lib.py:133] step: 228750, training_loss: 4.71147e-02
I0210 21:41:49.494208 22509476222784 run_lib.py:133] step: 228800, training_loss: 4.80318e-02
I0210 21:41:49.669897 22509476222784 run_lib.py:146] step: 228800, eval_loss: 4.24239e-02
I0210 21:42:08.203323 22509476222784 run_lib.py:133] step: 228850, training_loss: 3.89416e-02
I0210 21:42:26.835413 22509476222784 run_lib.py:133] step: 228900, training_loss: 4.37665e-02
I0210 21:42:26.999069 22509476222784 run_lib.py:146] step: 228900, eval_loss: 4.95401e-02
I0210 21:42:45.552340 22509476222784 run_lib.py:133] step: 228950, training_loss: 4.20055e-02
I0210 21:43:04.087047 22509476222784 run_lib.py:133] step: 229000, training_loss: 4.21122e-02
I0210 21:43:04.248708 22509476222784 run_lib.py:146] step: 229000, eval_loss: 4.00328e-02
I0210 21:43:22.974115 22509476222784 run_lib.py:133] step: 229050, training_loss: 3.89192e-02
I0210 21:43:41.652845 22509476222784 run_lib.py:133] step: 229100, training_loss: 3.67187e-02
I0210 21:43:41.833744 22509476222784 run_lib.py:146] step: 229100, eval_loss: 4.54332e-02
I0210 21:44:00.457743 22509476222784 run_lib.py:133] step: 229150, training_loss: 2.67662e-02
I0210 21:44:19.027945 22509476222784 run_lib.py:133] step: 229200, training_loss: 5.11440e-02
I0210 21:44:19.192704 22509476222784 run_lib.py:146] step: 229200, eval_loss: 4.22273e-02
I0210 21:44:37.904977 22509476222784 run_lib.py:133] step: 229250, training_loss: 4.06788e-02
I0210 21:44:56.423627 22509476222784 run_lib.py:133] step: 229300, training_loss: 4.97595e-02
I0210 21:44:56.589844 22509476222784 run_lib.py:146] step: 229300, eval_loss: 3.44540e-02
I0210 21:45:15.277608 22509476222784 run_lib.py:133] step: 229350, training_loss: 4.02272e-02
I0210 21:45:33.876725 22509476222784 run_lib.py:133] step: 229400, training_loss: 5.34606e-02
I0210 21:45:34.039411 22509476222784 run_lib.py:146] step: 229400, eval_loss: 4.78024e-02
I0210 21:45:52.889739 22509476222784 run_lib.py:133] step: 229450, training_loss: 4.72768e-02
I0210 21:46:11.403729 22509476222784 run_lib.py:133] step: 229500, training_loss: 5.11489e-02
I0210 21:46:11.565677 22509476222784 run_lib.py:146] step: 229500, eval_loss: 4.26384e-02
I0210 21:46:30.059574 22509476222784 run_lib.py:133] step: 229550, training_loss: 5.53777e-02
I0210 21:46:48.730265 22509476222784 run_lib.py:133] step: 229600, training_loss: 3.78062e-02
I0210 21:46:48.901076 22509476222784 run_lib.py:146] step: 229600, eval_loss: 4.14936e-02
I0210 21:47:07.462646 22509476222784 run_lib.py:133] step: 229650, training_loss: 3.81962e-02
I0210 21:47:26.232748 22509476222784 run_lib.py:133] step: 229700, training_loss: 4.06950e-02
I0210 21:47:26.411867 22509476222784 run_lib.py:146] step: 229700, eval_loss: 5.12187e-02
I0210 21:47:44.961530 22509476222784 run_lib.py:133] step: 229750, training_loss: 2.86180e-02
I0210 21:48:03.498643 22509476222784 run_lib.py:133] step: 229800, training_loss: 4.78869e-02
I0210 21:48:03.662989 22509476222784 run_lib.py:146] step: 229800, eval_loss: 3.36213e-02
I0210 21:48:22.440674 22509476222784 run_lib.py:133] step: 229850, training_loss: 5.82553e-02
I0210 21:48:40.961304 22509476222784 run_lib.py:133] step: 229900, training_loss: 5.58616e-02
I0210 21:48:41.154692 22509476222784 run_lib.py:146] step: 229900, eval_loss: 3.04221e-02
I0210 21:48:59.707275 22509476222784 run_lib.py:133] step: 229950, training_loss: 3.92050e-02
I0210 21:49:18.472272 22509476222784 run_lib.py:133] step: 230000, training_loss: 3.91691e-02
I0210 21:49:19.706898 22509476222784 run_lib.py:146] step: 230000, eval_loss: 4.25063e-02
I0210 21:49:41.046627 22509476222784 run_lib.py:133] step: 230050, training_loss: 5.08093e-02
I0210 21:49:59.631420 22509476222784 run_lib.py:133] step: 230100, training_loss: 4.19801e-02
I0210 21:49:59.799743 22509476222784 run_lib.py:146] step: 230100, eval_loss: 3.62011e-02
I0210 21:50:18.346971 22509476222784 run_lib.py:133] step: 230150, training_loss: 3.71461e-02
I0210 21:50:37.067540 22509476222784 run_lib.py:133] step: 230200, training_loss: 4.20284e-02
I0210 21:50:37.249756 22509476222784 run_lib.py:146] step: 230200, eval_loss: 4.39475e-02
I0210 21:50:55.857205 22509476222784 run_lib.py:133] step: 230250, training_loss: 3.42209e-02
I0210 21:51:14.426626 22509476222784 run_lib.py:133] step: 230300, training_loss: 4.41549e-02
I0210 21:51:14.591906 22509476222784 run_lib.py:146] step: 230300, eval_loss: 5.96205e-02
I0210 21:51:33.322458 22509476222784 run_lib.py:133] step: 230350, training_loss: 4.50567e-02
I0210 21:51:51.814303 22509476222784 run_lib.py:133] step: 230400, training_loss: 3.78931e-02
I0210 21:51:51.978672 22509476222784 run_lib.py:146] step: 230400, eval_loss: 4.04761e-02
I0210 21:52:10.590905 22509476222784 run_lib.py:133] step: 230450, training_loss: 3.49591e-02
I0210 21:52:29.153175 22509476222784 run_lib.py:133] step: 230500, training_loss: 5.27848e-02
I0210 21:52:29.319844 22509476222784 run_lib.py:146] step: 230500, eval_loss: 3.96830e-02
I0210 21:52:47.940006 22509476222784 run_lib.py:133] step: 230550, training_loss: 3.52141e-02
I0210 21:53:06.504742 22509476222784 run_lib.py:133] step: 230600, training_loss: 3.67576e-02
I0210 21:53:06.671608 22509476222784 run_lib.py:146] step: 230600, eval_loss: 3.91425e-02
I0210 21:53:25.389736 22509476222784 run_lib.py:133] step: 230650, training_loss: 3.30977e-02
I0210 21:53:43.979040 22509476222784 run_lib.py:133] step: 230700, training_loss: 4.49669e-02
I0210 21:53:44.144958 22509476222784 run_lib.py:146] step: 230700, eval_loss: 4.11748e-02
I0210 21:54:02.699744 22509476222784 run_lib.py:133] step: 230750, training_loss: 3.05775e-02
I0210 21:54:21.331007 22509476222784 run_lib.py:133] step: 230800, training_loss: 4.34022e-02
I0210 21:54:21.496026 22509476222784 run_lib.py:146] step: 230800, eval_loss: 4.58691e-02
I0210 21:54:40.247282 22509476222784 run_lib.py:133] step: 230850, training_loss: 4.56572e-02
I0210 21:54:58.790615 22509476222784 run_lib.py:133] step: 230900, training_loss: 5.18032e-02
I0210 21:54:58.953384 22509476222784 run_lib.py:146] step: 230900, eval_loss: 3.61552e-02
I0210 21:55:17.667079 22509476222784 run_lib.py:133] step: 230950, training_loss: 4.19506e-02
I0210 21:55:36.243506 22509476222784 run_lib.py:133] step: 231000, training_loss: 6.15268e-02
I0210 21:55:36.412006 22509476222784 run_lib.py:146] step: 231000, eval_loss: 3.95451e-02
I0210 21:55:55.195591 22509476222784 run_lib.py:133] step: 231050, training_loss: 4.49773e-02
I0210 21:56:13.798940 22509476222784 run_lib.py:133] step: 231100, training_loss: 4.24590e-02
I0210 21:56:13.968710 22509476222784 run_lib.py:146] step: 231100, eval_loss: 4.06005e-02
I0210 21:56:32.720715 22509476222784 run_lib.py:133] step: 231150, training_loss: 3.77748e-02
I0210 21:56:51.290813 22509476222784 run_lib.py:133] step: 231200, training_loss: 5.12072e-02
I0210 21:56:51.455731 22509476222784 run_lib.py:146] step: 231200, eval_loss: 3.90018e-02
I0210 21:57:10.050302 22509476222784 run_lib.py:133] step: 231250, training_loss: 4.69858e-02
I0210 21:57:28.769615 22509476222784 run_lib.py:133] step: 231300, training_loss: 3.92565e-02
I0210 21:57:28.951615 22509476222784 run_lib.py:146] step: 231300, eval_loss: 3.96780e-02
I0210 21:57:47.585210 22509476222784 run_lib.py:133] step: 231350, training_loss: 4.14171e-02
I0210 21:58:06.160580 22509476222784 run_lib.py:133] step: 231400, training_loss: 4.05327e-02
I0210 21:58:06.340543 22509476222784 run_lib.py:146] step: 231400, eval_loss: 4.22600e-02
I0210 21:58:25.084957 22509476222784 run_lib.py:133] step: 231450, training_loss: 4.64777e-02
I0210 21:58:43.623196 22509476222784 run_lib.py:133] step: 231500, training_loss: 5.30355e-02
I0210 21:58:43.786704 22509476222784 run_lib.py:146] step: 231500, eval_loss: 3.76308e-02
I0210 21:59:02.485697 22509476222784 run_lib.py:133] step: 231550, training_loss: 4.33978e-02
I0210 21:59:21.112647 22509476222784 run_lib.py:133] step: 231600, training_loss: 3.33328e-02
I0210 21:59:21.277560 22509476222784 run_lib.py:146] step: 231600, eval_loss: 4.35301e-02
I0210 21:59:39.810612 22509476222784 run_lib.py:133] step: 231650, training_loss: 3.34255e-02
I0210 21:59:58.539171 22509476222784 run_lib.py:133] step: 231700, training_loss: 4.37984e-02
I0210 21:59:58.704663 22509476222784 run_lib.py:146] step: 231700, eval_loss: 3.98727e-02
I0210 22:00:17.269738 22509476222784 run_lib.py:133] step: 231750, training_loss: 4.18750e-02
I0210 22:00:35.839354 22509476222784 run_lib.py:133] step: 231800, training_loss: 3.46421e-02
I0210 22:00:36.003786 22509476222784 run_lib.py:146] step: 231800, eval_loss: 4.78299e-02
I0210 22:00:54.594913 22509476222784 run_lib.py:133] step: 231850, training_loss: 4.09442e-02
I0210 22:01:13.394016 22509476222784 run_lib.py:133] step: 231900, training_loss: 5.38188e-02
I0210 22:01:13.559979 22509476222784 run_lib.py:146] step: 231900, eval_loss: 4.23680e-02
I0210 22:01:32.195387 22509476222784 run_lib.py:133] step: 231950, training_loss: 3.64081e-02
I0210 22:01:50.866345 22509476222784 run_lib.py:133] step: 232000, training_loss: 3.97871e-02
I0210 22:01:51.030616 22509476222784 run_lib.py:146] step: 232000, eval_loss: 5.00299e-02
I0210 22:02:09.558080 22509476222784 run_lib.py:133] step: 232050, training_loss: 4.88772e-02
I0210 22:02:28.068190 22509476222784 run_lib.py:133] step: 232100, training_loss: 3.81042e-02
I0210 22:02:28.248925 22509476222784 run_lib.py:146] step: 232100, eval_loss: 4.94177e-02
I0210 22:02:46.978986 22509476222784 run_lib.py:133] step: 232150, training_loss: 2.64678e-02
I0210 22:03:05.712735 22509476222784 run_lib.py:133] step: 232200, training_loss: 4.40367e-02
I0210 22:03:05.877938 22509476222784 run_lib.py:146] step: 232200, eval_loss: 2.94806e-02
I0210 22:03:24.445939 22509476222784 run_lib.py:133] step: 232250, training_loss: 4.42326e-02
I0210 22:03:42.970796 22509476222784 run_lib.py:133] step: 232300, training_loss: 3.58416e-02
I0210 22:03:43.133746 22509476222784 run_lib.py:146] step: 232300, eval_loss: 3.75761e-02
I0210 22:04:01.867782 22509476222784 run_lib.py:133] step: 232350, training_loss: 3.49160e-02
I0210 22:04:20.470023 22509476222784 run_lib.py:133] step: 232400, training_loss: 3.12145e-02
I0210 22:04:20.635801 22509476222784 run_lib.py:146] step: 232400, eval_loss: 3.36998e-02
I0210 22:04:39.411089 22509476222784 run_lib.py:133] step: 232450, training_loss: 5.40954e-02
I0210 22:04:57.968055 22509476222784 run_lib.py:133] step: 232500, training_loss: 3.24621e-02
I0210 22:04:58.133758 22509476222784 run_lib.py:146] step: 232500, eval_loss: 4.53338e-02
I0210 22:05:16.832539 22509476222784 run_lib.py:133] step: 232550, training_loss: 4.63073e-02
I0210 22:05:35.402044 22509476222784 run_lib.py:133] step: 232600, training_loss: 4.07415e-02
I0210 22:05:35.565158 22509476222784 run_lib.py:146] step: 232600, eval_loss: 3.56723e-02
I0210 22:05:54.174233 22509476222784 run_lib.py:133] step: 232650, training_loss: 4.07851e-02
I0210 22:06:12.973149 22509476222784 run_lib.py:133] step: 232700, training_loss: 3.40006e-02
I0210 22:06:13.140153 22509476222784 run_lib.py:146] step: 232700, eval_loss: 3.83167e-02
I0210 22:06:31.730453 22509476222784 run_lib.py:133] step: 232750, training_loss: 3.89925e-02
I0210 22:06:50.447015 22509476222784 run_lib.py:133] step: 232800, training_loss: 4.67315e-02
I0210 22:06:50.608332 22509476222784 run_lib.py:146] step: 232800, eval_loss: 4.06250e-02
I0210 22:07:09.133395 22509476222784 run_lib.py:133] step: 232850, training_loss: 4.28557e-02
I0210 22:07:27.700230 22509476222784 run_lib.py:133] step: 232900, training_loss: 4.44937e-02
I0210 22:07:27.883716 22509476222784 run_lib.py:146] step: 232900, eval_loss: 3.87662e-02
I0210 22:07:46.685716 22509476222784 run_lib.py:133] step: 232950, training_loss: 3.72195e-02
I0210 22:08:05.257294 22509476222784 run_lib.py:133] step: 233000, training_loss: 4.02885e-02
I0210 22:08:05.422646 22509476222784 run_lib.py:146] step: 233000, eval_loss: 4.53171e-02
I0210 22:08:23.971720 22509476222784 run_lib.py:133] step: 233050, training_loss: 4.56495e-02
I0210 22:08:42.653446 22509476222784 run_lib.py:133] step: 233100, training_loss: 4.30146e-02
I0210 22:08:42.821574 22509476222784 run_lib.py:146] step: 233100, eval_loss: 3.99148e-02
I0210 22:09:01.398918 22509476222784 run_lib.py:133] step: 233150, training_loss: 4.79847e-02
I0210 22:09:19.992912 22509476222784 run_lib.py:133] step: 233200, training_loss: 3.89737e-02
I0210 22:09:20.325959 22509476222784 run_lib.py:146] step: 233200, eval_loss: 4.69709e-02
I0210 22:09:38.925732 22509476222784 run_lib.py:133] step: 233250, training_loss: 4.48906e-02
I0210 22:09:57.460780 22509476222784 run_lib.py:133] step: 233300, training_loss: 5.54073e-02
I0210 22:09:57.621941 22509476222784 run_lib.py:146] step: 233300, eval_loss: 4.81276e-02
I0210 22:10:16.174810 22509476222784 run_lib.py:133] step: 233350, training_loss: 3.22371e-02
I0210 22:10:34.725807 22509476222784 run_lib.py:133] step: 233400, training_loss: 4.78156e-02
I0210 22:10:34.908788 22509476222784 run_lib.py:146] step: 233400, eval_loss: 4.14289e-02
I0210 22:10:53.684190 22509476222784 run_lib.py:133] step: 233450, training_loss: 4.39720e-02
I0210 22:11:12.367001 22509476222784 run_lib.py:133] step: 233500, training_loss: 5.22051e-02
I0210 22:11:12.532702 22509476222784 run_lib.py:146] step: 233500, eval_loss: 3.47796e-02
I0210 22:11:31.051081 22509476222784 run_lib.py:133] step: 233550, training_loss: 4.30502e-02
I0210 22:11:49.595459 22509476222784 run_lib.py:133] step: 233600, training_loss: 4.18171e-02
I0210 22:11:49.759851 22509476222784 run_lib.py:146] step: 233600, eval_loss: 3.73526e-02
I0210 22:12:08.459131 22509476222784 run_lib.py:133] step: 233650, training_loss: 2.70733e-02
I0210 22:12:27.079384 22509476222784 run_lib.py:133] step: 233700, training_loss: 4.79429e-02
I0210 22:12:27.243821 22509476222784 run_lib.py:146] step: 233700, eval_loss: 4.52275e-02
I0210 22:12:45.875746 22509476222784 run_lib.py:133] step: 233750, training_loss: 3.58519e-02
I0210 22:13:04.414064 22509476222784 run_lib.py:133] step: 233800, training_loss: 5.04577e-02
I0210 22:13:04.573112 22509476222784 run_lib.py:146] step: 233800, eval_loss: 4.30600e-02
I0210 22:13:23.318390 22509476222784 run_lib.py:133] step: 233850, training_loss: 4.53057e-02
I0210 22:13:41.885663 22509476222784 run_lib.py:133] step: 233900, training_loss: 3.68614e-02
I0210 22:13:42.050417 22509476222784 run_lib.py:146] step: 233900, eval_loss: 3.40470e-02
I0210 22:14:00.745191 22509476222784 run_lib.py:133] step: 233950, training_loss: 3.44014e-02
I0210 22:14:19.378981 22509476222784 run_lib.py:133] step: 234000, training_loss: 5.21426e-02
I0210 22:14:19.556709 22509476222784 run_lib.py:146] step: 234000, eval_loss: 3.74867e-02
I0210 22:14:38.295604 22509476222784 run_lib.py:133] step: 234050, training_loss: 3.85979e-02
I0210 22:14:56.821448 22509476222784 run_lib.py:133] step: 234100, training_loss: 3.22540e-02
I0210 22:14:56.994190 22509476222784 run_lib.py:146] step: 234100, eval_loss: 4.34367e-02
I0210 22:15:15.544879 22509476222784 run_lib.py:133] step: 234150, training_loss: 4.12742e-02
I0210 22:15:34.214238 22509476222784 run_lib.py:133] step: 234200, training_loss: 3.74519e-02
I0210 22:15:34.376602 22509476222784 run_lib.py:146] step: 234200, eval_loss: 3.74519e-02
I0210 22:15:52.893431 22509476222784 run_lib.py:133] step: 234250, training_loss: 3.76456e-02
I0210 22:16:11.621668 22509476222784 run_lib.py:133] step: 234300, training_loss: 4.85194e-02
I0210 22:16:11.806874 22509476222784 run_lib.py:146] step: 234300, eval_loss: 4.01080e-02
I0210 22:16:30.428801 22509476222784 run_lib.py:133] step: 234350, training_loss: 3.72859e-02
I0210 22:16:49.005570 22509476222784 run_lib.py:133] step: 234400, training_loss: 3.13934e-02
I0210 22:16:49.176880 22509476222784 run_lib.py:146] step: 234400, eval_loss: 5.11482e-02
I0210 22:17:07.724733 22509476222784 run_lib.py:133] step: 234450, training_loss: 4.00280e-02
I0210 22:17:26.530551 22509476222784 run_lib.py:133] step: 234500, training_loss: 5.61260e-02
I0210 22:17:26.694552 22509476222784 run_lib.py:146] step: 234500, eval_loss: 3.30594e-02
I0210 22:17:45.265319 22509476222784 run_lib.py:133] step: 234550, training_loss: 5.04276e-02
I0210 22:18:03.853362 22509476222784 run_lib.py:133] step: 234600, training_loss: 4.44187e-02
I0210 22:18:04.019027 22509476222784 run_lib.py:146] step: 234600, eval_loss: 3.73331e-02
I0210 22:18:22.785730 22509476222784 run_lib.py:133] step: 234650, training_loss: 3.93427e-02
I0210 22:18:41.283228 22509476222784 run_lib.py:133] step: 234700, training_loss: 5.86844e-02
I0210 22:18:41.444850 22509476222784 run_lib.py:146] step: 234700, eval_loss: 4.66766e-02
I0210 22:19:00.092400 22509476222784 run_lib.py:133] step: 234750, training_loss: 3.18515e-02
I0210 22:19:18.694172 22509476222784 run_lib.py:133] step: 234800, training_loss: 5.01447e-02
I0210 22:19:18.865982 22509476222784 run_lib.py:146] step: 234800, eval_loss: 5.05285e-02
I0210 22:19:37.482554 22509476222784 run_lib.py:133] step: 234850, training_loss: 3.62746e-02
I0210 22:19:56.054765 22509476222784 run_lib.py:133] step: 234900, training_loss: 5.47758e-02
I0210 22:19:56.223995 22509476222784 run_lib.py:146] step: 234900, eval_loss: 3.40503e-02
I0210 22:20:14.970449 22509476222784 run_lib.py:133] step: 234950, training_loss: 5.96686e-02
I0210 22:20:33.592572 22509476222784 run_lib.py:133] step: 235000, training_loss: 5.09389e-02
I0210 22:20:33.756816 22509476222784 run_lib.py:146] step: 235000, eval_loss: 4.61548e-02
I0210 22:20:52.330886 22509476222784 run_lib.py:133] step: 235050, training_loss: 4.87107e-02
I0210 22:21:10.958868 22509476222784 run_lib.py:133] step: 235100, training_loss: 4.48723e-02
I0210 22:21:11.124969 22509476222784 run_lib.py:146] step: 235100, eval_loss: 4.63624e-02
I0210 22:21:29.919930 22509476222784 run_lib.py:133] step: 235150, training_loss: 4.47675e-02
I0210 22:21:48.469610 22509476222784 run_lib.py:133] step: 235200, training_loss: 3.45579e-02
I0210 22:21:48.631707 22509476222784 run_lib.py:146] step: 235200, eval_loss: 3.82837e-02
I0210 22:22:07.336738 22509476222784 run_lib.py:133] step: 235250, training_loss: 4.35170e-02
I0210 22:22:25.919688 22509476222784 run_lib.py:133] step: 235300, training_loss: 4.56239e-02
I0210 22:22:26.083880 22509476222784 run_lib.py:146] step: 235300, eval_loss: 4.04216e-02
I0210 22:22:44.821749 22509476222784 run_lib.py:133] step: 235350, training_loss: 5.09183e-02
I0210 22:23:03.487054 22509476222784 run_lib.py:133] step: 235400, training_loss: 5.78890e-02
I0210 22:23:03.653636 22509476222784 run_lib.py:146] step: 235400, eval_loss: 3.70735e-02
I0210 22:23:22.385292 22509476222784 run_lib.py:133] step: 235450, training_loss: 4.38893e-02
I0210 22:23:40.938729 22509476222784 run_lib.py:133] step: 235500, training_loss: 5.01484e-02
I0210 22:23:41.103628 22509476222784 run_lib.py:146] step: 235500, eval_loss: 5.49725e-02
I0210 22:23:59.690470 22509476222784 run_lib.py:133] step: 235550, training_loss: 5.75203e-02
I0210 22:24:18.362107 22509476222784 run_lib.py:133] step: 235600, training_loss: 3.69338e-02
I0210 22:24:18.531619 22509476222784 run_lib.py:146] step: 235600, eval_loss: 3.75738e-02
I0210 22:24:37.095940 22509476222784 run_lib.py:133] step: 235650, training_loss: 4.16174e-02
I0210 22:24:55.669125 22509476222784 run_lib.py:133] step: 235700, training_loss: 4.10959e-02
I0210 22:24:55.834752 22509476222784 run_lib.py:146] step: 235700, eval_loss: 2.98554e-02
I0210 22:25:14.592468 22509476222784 run_lib.py:133] step: 235750, training_loss: 3.38512e-02
I0210 22:25:33.340025 22509476222784 run_lib.py:133] step: 235800, training_loss: 4.43819e-02
I0210 22:25:33.507803 22509476222784 run_lib.py:146] step: 235800, eval_loss: 4.97541e-02
I0210 22:25:52.011662 22509476222784 run_lib.py:133] step: 235850, training_loss: 5.23854e-02
I0210 22:26:10.614934 22509476222784 run_lib.py:133] step: 235900, training_loss: 4.31809e-02
I0210 22:26:10.794310 22509476222784 run_lib.py:146] step: 235900, eval_loss: 3.79184e-02
I0210 22:26:29.403306 22509476222784 run_lib.py:133] step: 235950, training_loss: 2.75992e-02
I0210 22:26:48.201813 22509476222784 run_lib.py:133] step: 236000, training_loss: 4.69952e-02
I0210 22:26:48.367154 22509476222784 run_lib.py:146] step: 236000, eval_loss: 4.26066e-02
I0210 22:27:06.922720 22509476222784 run_lib.py:133] step: 236050, training_loss: 3.49239e-02
I0210 22:27:25.451296 22509476222784 run_lib.py:133] step: 236100, training_loss: 3.96542e-02
I0210 22:27:25.615630 22509476222784 run_lib.py:146] step: 236100, eval_loss: 4.00680e-02
I0210 22:27:44.147360 22509476222784 run_lib.py:133] step: 236150, training_loss: 5.80362e-02
I0210 22:28:02.882156 22509476222784 run_lib.py:133] step: 236200, training_loss: 4.45688e-02
I0210 22:28:03.047837 22509476222784 run_lib.py:146] step: 236200, eval_loss: 2.90105e-02
I0210 22:28:21.693870 22509476222784 run_lib.py:133] step: 236250, training_loss: 3.47308e-02
I0210 22:28:40.379374 22509476222784 run_lib.py:133] step: 236300, training_loss: 5.04967e-02
I0210 22:28:40.545624 22509476222784 run_lib.py:146] step: 236300, eval_loss: 5.10015e-02
I0210 22:28:59.097541 22509476222784 run_lib.py:133] step: 236350, training_loss: 4.37846e-02
I0210 22:29:17.655945 22509476222784 run_lib.py:133] step: 236400, training_loss: 5.04492e-02
I0210 22:29:17.820603 22509476222784 run_lib.py:146] step: 236400, eval_loss: 3.63369e-02
I0210 22:29:36.539095 22509476222784 run_lib.py:133] step: 236450, training_loss: 4.33208e-02
I0210 22:29:55.174556 22509476222784 run_lib.py:133] step: 236500, training_loss: 4.22562e-02
I0210 22:29:55.337476 22509476222784 run_lib.py:146] step: 236500, eval_loss: 3.62548e-02
I0210 22:30:13.903509 22509476222784 run_lib.py:133] step: 236550, training_loss: 5.35362e-02
I0210 22:30:32.461594 22509476222784 run_lib.py:133] step: 236600, training_loss: 4.98450e-02
I0210 22:30:32.622558 22509476222784 run_lib.py:146] step: 236600, eval_loss: 5.82191e-02
I0210 22:30:51.370605 22509476222784 run_lib.py:133] step: 236650, training_loss: 2.99805e-02
I0210 22:31:09.941116 22509476222784 run_lib.py:133] step: 236700, training_loss: 4.34655e-02
I0210 22:31:10.107751 22509476222784 run_lib.py:146] step: 236700, eval_loss: 3.82486e-02
I0210 22:31:28.821682 22509476222784 run_lib.py:133] step: 236750, training_loss: 4.58961e-02
I0210 22:31:47.430676 22509476222784 run_lib.py:133] step: 236800, training_loss: 4.02975e-02
I0210 22:31:47.612790 22509476222784 run_lib.py:146] step: 236800, eval_loss: 4.49659e-02
I0210 22:32:06.417942 22509476222784 run_lib.py:133] step: 236850, training_loss: 3.96134e-02
I0210 22:32:25.024430 22509476222784 run_lib.py:133] step: 236900, training_loss: 3.02015e-02
I0210 22:32:25.189974 22509476222784 run_lib.py:146] step: 236900, eval_loss: 3.04131e-02
I0210 22:32:43.740624 22509476222784 run_lib.py:133] step: 236950, training_loss: 4.72526e-02
I0210 22:33:02.407093 22509476222784 run_lib.py:133] step: 237000, training_loss: 5.27317e-02
I0210 22:33:02.570685 22509476222784 run_lib.py:146] step: 237000, eval_loss: 3.54626e-02
I0210 22:33:21.132979 22509476222784 run_lib.py:133] step: 237050, training_loss: 3.37859e-02
I0210 22:33:39.889242 22509476222784 run_lib.py:133] step: 237100, training_loss: 3.84128e-02
I0210 22:33:40.059970 22509476222784 run_lib.py:146] step: 237100, eval_loss: 3.40445e-02
I0210 22:33:58.616368 22509476222784 run_lib.py:133] step: 237150, training_loss: 4.94493e-02
I0210 22:34:17.161748 22509476222784 run_lib.py:133] step: 237200, training_loss: 3.88930e-02
I0210 22:34:17.326623 22509476222784 run_lib.py:146] step: 237200, eval_loss: 4.11649e-02
I0210 22:34:36.038955 22509476222784 run_lib.py:133] step: 237250, training_loss: 5.00615e-02
I0210 22:34:54.571628 22509476222784 run_lib.py:133] step: 237300, training_loss: 5.51359e-02
I0210 22:34:54.737807 22509476222784 run_lib.py:146] step: 237300, eval_loss: 4.52373e-02
I0210 22:35:13.325694 22509476222784 run_lib.py:133] step: 237350, training_loss: 3.83354e-02
I0210 22:35:32.097276 22509476222784 run_lib.py:133] step: 237400, training_loss: 3.84859e-02
I0210 22:35:32.262813 22509476222784 run_lib.py:146] step: 237400, eval_loss: 4.44764e-02
I0210 22:35:50.820546 22509476222784 run_lib.py:133] step: 237450, training_loss: 4.90792e-02
I0210 22:36:09.362609 22509476222784 run_lib.py:133] step: 237500, training_loss: 5.19456e-02
I0210 22:36:09.526626 22509476222784 run_lib.py:146] step: 237500, eval_loss: 4.78613e-02
I0210 22:36:28.174551 22509476222784 run_lib.py:133] step: 237550, training_loss: 3.71970e-02
I0210 22:36:46.728677 22509476222784 run_lib.py:133] step: 237600, training_loss: 5.26287e-02
I0210 22:36:46.889619 22509476222784 run_lib.py:146] step: 237600, eval_loss: 4.47155e-02
I0210 22:37:05.433915 22509476222784 run_lib.py:133] step: 237650, training_loss: 4.83207e-02
I0210 22:37:24.038432 22509476222784 run_lib.py:133] step: 237700, training_loss: 5.14540e-02
I0210 22:37:24.233587 22509476222784 run_lib.py:146] step: 237700, eval_loss: 5.18997e-02
I0210 22:37:42.966003 22509476222784 run_lib.py:133] step: 237750, training_loss: 5.49217e-02
I0210 22:38:01.626442 22509476222784 run_lib.py:133] step: 237800, training_loss: 5.02524e-02
I0210 22:38:01.797842 22509476222784 run_lib.py:146] step: 237800, eval_loss: 4.26811e-02
I0210 22:38:20.384271 22509476222784 run_lib.py:133] step: 237850, training_loss: 2.95730e-02
I0210 22:38:38.935163 22509476222784 run_lib.py:133] step: 237900, training_loss: 4.21621e-02
I0210 22:38:39.118340 22509476222784 run_lib.py:146] step: 237900, eval_loss: 3.91641e-02
I0210 22:38:57.849793 22509476222784 run_lib.py:133] step: 237950, training_loss: 4.25280e-02
I0210 22:39:16.461683 22509476222784 run_lib.py:133] step: 238000, training_loss: 5.24488e-02
I0210 22:39:16.624351 22509476222784 run_lib.py:146] step: 238000, eval_loss: 3.55022e-02
I0210 22:39:35.397627 22509476222784 run_lib.py:133] step: 238050, training_loss: 4.86984e-02
I0210 22:39:53.969942 22509476222784 run_lib.py:133] step: 238100, training_loss: 4.46153e-02
I0210 22:39:54.131759 22509476222784 run_lib.py:146] step: 238100, eval_loss: 3.72852e-02
I0210 22:40:12.787110 22509476222784 run_lib.py:133] step: 238150, training_loss: 3.60599e-02
I0210 22:40:31.332886 22509476222784 run_lib.py:133] step: 238200, training_loss: 4.82797e-02
I0210 22:40:31.514600 22509476222784 run_lib.py:146] step: 238200, eval_loss: 5.29674e-02
I0210 22:40:50.284060 22509476222784 run_lib.py:133] step: 238250, training_loss: 4.46034e-02
I0210 22:41:08.854189 22509476222784 run_lib.py:133] step: 238300, training_loss: 4.36768e-02
I0210 22:41:09.018784 22509476222784 run_lib.py:146] step: 238300, eval_loss: 4.40853e-02
I0210 22:41:27.514074 22509476222784 run_lib.py:133] step: 238350, training_loss: 5.95187e-02
I0210 22:41:46.188045 22509476222784 run_lib.py:133] step: 238400, training_loss: 3.97073e-02
I0210 22:41:46.352875 22509476222784 run_lib.py:146] step: 238400, eval_loss: 4.31921e-02
I0210 22:42:04.944309 22509476222784 run_lib.py:133] step: 238450, training_loss: 3.64689e-02
I0210 22:42:23.512996 22509476222784 run_lib.py:133] step: 238500, training_loss: 3.90874e-02
I0210 22:42:23.676882 22509476222784 run_lib.py:146] step: 238500, eval_loss: 4.72883e-02
I0210 22:42:42.461416 22509476222784 run_lib.py:133] step: 238550, training_loss: 4.81973e-02
I0210 22:43:01.014513 22509476222784 run_lib.py:133] step: 238600, training_loss: 4.06776e-02
I0210 22:43:01.187167 22509476222784 run_lib.py:146] step: 238600, eval_loss: 3.29988e-02
I0210 22:43:19.869339 22509476222784 run_lib.py:133] step: 238650, training_loss: 4.39648e-02
I0210 22:43:38.425746 22509476222784 run_lib.py:133] step: 238700, training_loss: 4.29471e-02
I0210 22:43:38.605698 22509476222784 run_lib.py:146] step: 238700, eval_loss: 4.29232e-02
I0210 22:43:57.228131 22509476222784 run_lib.py:133] step: 238750, training_loss: 4.16144e-02
I0210 22:44:16.023952 22509476222784 run_lib.py:133] step: 238800, training_loss: 4.69498e-02
I0210 22:44:16.189961 22509476222784 run_lib.py:146] step: 238800, eval_loss: 4.93635e-02
I0210 22:44:34.737720 22509476222784 run_lib.py:133] step: 238850, training_loss: 4.64412e-02
I0210 22:44:53.236485 22509476222784 run_lib.py:133] step: 238900, training_loss: 4.16956e-02
I0210 22:44:53.409685 22509476222784 run_lib.py:146] step: 238900, eval_loss: 4.46512e-02
I0210 22:45:12.000363 22509476222784 run_lib.py:133] step: 238950, training_loss: 5.25334e-02
I0210 22:45:30.775388 22509476222784 run_lib.py:133] step: 239000, training_loss: 5.72968e-02
I0210 22:45:30.941237 22509476222784 run_lib.py:146] step: 239000, eval_loss: 4.72177e-02
I0210 22:45:49.611124 22509476222784 run_lib.py:133] step: 239050, training_loss: 4.28061e-02
I0210 22:46:08.308436 22509476222784 run_lib.py:133] step: 239100, training_loss: 4.55568e-02
I0210 22:46:08.472615 22509476222784 run_lib.py:146] step: 239100, eval_loss: 4.65021e-02
I0210 22:46:27.051078 22509476222784 run_lib.py:133] step: 239150, training_loss: 4.18695e-02
I0210 22:46:45.627973 22509476222784 run_lib.py:133] step: 239200, training_loss: 3.85635e-02
I0210 22:46:45.796786 22509476222784 run_lib.py:146] step: 239200, eval_loss: 3.88236e-02
I0210 22:47:04.444552 22509476222784 run_lib.py:133] step: 239250, training_loss: 4.13068e-02
I0210 22:47:23.084844 22509476222784 run_lib.py:133] step: 239300, training_loss: 3.63091e-02
I0210 22:47:23.264624 22509476222784 run_lib.py:146] step: 239300, eval_loss: 4.65582e-02
I0210 22:47:41.706566 22509476222784 run_lib.py:133] step: 239350, training_loss: 5.21142e-02
I0210 22:48:00.141495 22509476222784 run_lib.py:133] step: 239400, training_loss: 3.84999e-02
I0210 22:48:00.304585 22509476222784 run_lib.py:146] step: 239400, eval_loss: 4.74215e-02
I0210 22:48:18.873328 22509476222784 run_lib.py:133] step: 239450, training_loss: 4.10651e-02
I0210 22:48:37.333015 22509476222784 run_lib.py:133] step: 239500, training_loss: 4.59042e-02
I0210 22:48:37.496714 22509476222784 run_lib.py:146] step: 239500, eval_loss: 4.18243e-02
I0210 22:48:56.114594 22509476222784 run_lib.py:133] step: 239550, training_loss: 4.35925e-02
I0210 22:49:14.634220 22509476222784 run_lib.py:133] step: 239600, training_loss: 4.66718e-02
I0210 22:49:14.804747 22509476222784 run_lib.py:146] step: 239600, eval_loss: 3.16170e-02
I0210 22:49:33.422190 22509476222784 run_lib.py:133] step: 239650, training_loss: 5.18551e-02
I0210 22:49:51.878081 22509476222784 run_lib.py:133] step: 239700, training_loss: 4.78533e-02
I0210 22:49:52.041937 22509476222784 run_lib.py:146] step: 239700, eval_loss: 4.93617e-02
I0210 22:50:10.407665 22509476222784 run_lib.py:133] step: 239750, training_loss: 4.21689e-02
I0210 22:50:29.074702 22509476222784 run_lib.py:133] step: 239800, training_loss: 5.09605e-02
I0210 22:50:29.240346 22509476222784 run_lib.py:146] step: 239800, eval_loss: 3.35716e-02
I0210 22:50:47.769572 22509476222784 run_lib.py:133] step: 239850, training_loss: 5.28952e-02
I0210 22:51:06.460369 22509476222784 run_lib.py:133] step: 239900, training_loss: 4.56669e-02
I0210 22:51:06.622581 22509476222784 run_lib.py:146] step: 239900, eval_loss: 3.98153e-02
I0210 22:51:25.105678 22509476222784 run_lib.py:133] step: 239950, training_loss: 5.55871e-02
I0210 22:51:43.643791 22509476222784 run_lib.py:133] step: 240000, training_loss: 5.66438e-02
I0210 22:51:44.744458 22509476222784 run_lib.py:146] step: 240000, eval_loss: 3.70239e-02
I0210 22:52:06.303943 22509476222784 run_lib.py:133] step: 240050, training_loss: 4.30638e-02
I0210 22:52:24.856524 22509476222784 run_lib.py:133] step: 240100, training_loss: 4.31315e-02
I0210 22:52:25.027796 22509476222784 run_lib.py:146] step: 240100, eval_loss: 4.10696e-02
I0210 22:52:43.710747 22509476222784 run_lib.py:133] step: 240150, training_loss: 4.49942e-02
I0210 22:53:02.186593 22509476222784 run_lib.py:133] step: 240200, training_loss: 4.77606e-02
I0210 22:53:02.370671 22509476222784 run_lib.py:146] step: 240200, eval_loss: 3.51786e-02
I0210 22:53:20.824537 22509476222784 run_lib.py:133] step: 240250, training_loss: 4.82249e-02
I0210 22:53:39.324905 22509476222784 run_lib.py:133] step: 240300, training_loss: 5.11352e-02
I0210 22:53:39.501645 22509476222784 run_lib.py:146] step: 240300, eval_loss: 4.05184e-02
I0210 22:53:58.004391 22509476222784 run_lib.py:133] step: 240350, training_loss: 5.10701e-02
I0210 22:54:16.672558 22509476222784 run_lib.py:133] step: 240400, training_loss: 4.36258e-02
I0210 22:54:16.837728 22509476222784 run_lib.py:146] step: 240400, eval_loss: 4.37483e-02
I0210 22:54:35.343698 22509476222784 run_lib.py:133] step: 240450, training_loss: 3.60748e-02
I0210 22:54:53.791490 22509476222784 run_lib.py:133] step: 240500, training_loss: 3.05069e-02
I0210 22:54:53.952588 22509476222784 run_lib.py:146] step: 240500, eval_loss: 4.45509e-02
I0210 22:55:12.424170 22509476222784 run_lib.py:133] step: 240550, training_loss: 4.23853e-02
I0210 22:55:31.062602 22509476222784 run_lib.py:133] step: 240600, training_loss: 3.69701e-02
I0210 22:55:31.235939 22509476222784 run_lib.py:146] step: 240600, eval_loss: 3.78327e-02
I0210 22:55:49.751311 22509476222784 run_lib.py:133] step: 240650, training_loss: 4.72257e-02
I0210 22:56:08.239023 22509476222784 run_lib.py:133] step: 240700, training_loss: 3.95517e-02
I0210 22:56:08.404653 22509476222784 run_lib.py:146] step: 240700, eval_loss: 3.83187e-02
I0210 22:56:27.059524 22509476222784 run_lib.py:133] step: 240750, training_loss: 4.67714e-02
I0210 22:56:45.565855 22509476222784 run_lib.py:133] step: 240800, training_loss: 4.36434e-02
I0210 22:56:45.729487 22509476222784 run_lib.py:146] step: 240800, eval_loss: 4.58527e-02
I0210 22:57:04.226222 22509476222784 run_lib.py:133] step: 240850, training_loss: 4.52251e-02
I0210 22:57:22.660619 22509476222784 run_lib.py:133] step: 240900, training_loss: 4.12866e-02
I0210 22:57:22.822310 22509476222784 run_lib.py:146] step: 240900, eval_loss: 4.03496e-02
I0210 22:57:41.293920 22509476222784 run_lib.py:133] step: 240950, training_loss: 4.56949e-02
I0210 22:57:59.799154 22509476222784 run_lib.py:133] step: 241000, training_loss: 4.87852e-02
I0210 22:57:59.967683 22509476222784 run_lib.py:146] step: 241000, eval_loss: 3.67020e-02
I0210 22:58:18.622393 22509476222784 run_lib.py:133] step: 241050, training_loss: 3.06413e-02
I0210 22:58:37.196123 22509476222784 run_lib.py:133] step: 241100, training_loss: 4.58054e-02
I0210 22:58:37.363012 22509476222784 run_lib.py:146] step: 241100, eval_loss: 3.76984e-02
I0210 22:58:55.785751 22509476222784 run_lib.py:133] step: 241150, training_loss: 4.81001e-02
I0210 22:59:14.185382 22509476222784 run_lib.py:133] step: 241200, training_loss: 3.71872e-02
I0210 22:59:14.355600 22509476222784 run_lib.py:146] step: 241200, eval_loss: 4.44187e-02
I0210 22:59:32.906019 22509476222784 run_lib.py:133] step: 241250, training_loss: 3.14539e-02
I0210 22:59:51.375786 22509476222784 run_lib.py:133] step: 241300, training_loss: 3.76584e-02
I0210 22:59:51.539755 22509476222784 run_lib.py:146] step: 241300, eval_loss: 4.78067e-02
I0210 23:00:10.129934 22509476222784 run_lib.py:133] step: 241350, training_loss: 3.55471e-02
I0210 23:00:28.595317 22509476222784 run_lib.py:133] step: 241400, training_loss: 5.90925e-02
I0210 23:00:28.764419 22509476222784 run_lib.py:146] step: 241400, eval_loss: 3.40063e-02
I0210 23:00:47.419852 22509476222784 run_lib.py:133] step: 241450, training_loss: 4.78969e-02
I0210 23:01:05.921797 22509476222784 run_lib.py:133] step: 241500, training_loss: 4.68056e-02
I0210 23:01:06.087738 22509476222784 run_lib.py:146] step: 241500, eval_loss: 4.66841e-02
I0210 23:01:24.745034 22509476222784 run_lib.py:133] step: 241550, training_loss: 3.79656e-02
I0210 23:01:43.217361 22509476222784 run_lib.py:133] step: 241600, training_loss: 4.11933e-02
I0210 23:01:43.383946 22509476222784 run_lib.py:146] step: 241600, eval_loss: 3.67483e-02
I0210 23:02:01.829810 22509476222784 run_lib.py:133] step: 241650, training_loss: 4.03887e-02
I0210 23:02:20.433508 22509476222784 run_lib.py:133] step: 241700, training_loss: 4.94871e-02
I0210 23:02:20.638577 22509476222784 run_lib.py:146] step: 241700, eval_loss: 4.19495e-02
I0210 23:02:39.161611 22509476222784 run_lib.py:133] step: 241750, training_loss: 5.57843e-02
I0210 23:02:57.660336 22509476222784 run_lib.py:133] step: 241800, training_loss: 4.67048e-02
I0210 23:02:57.829963 22509476222784 run_lib.py:146] step: 241800, eval_loss: 4.35311e-02
I0210 23:03:16.499527 22509476222784 run_lib.py:133] step: 241850, training_loss: 4.48317e-02
I0210 23:03:34.984316 22509476222784 run_lib.py:133] step: 241900, training_loss: 4.57383e-02
I0210 23:03:35.143566 22509476222784 run_lib.py:146] step: 241900, eval_loss: 4.36326e-02
I0210 23:03:53.764343 22509476222784 run_lib.py:133] step: 241950, training_loss: 4.94021e-02
I0210 23:04:12.212939 22509476222784 run_lib.py:133] step: 242000, training_loss: 4.27091e-02
I0210 23:04:12.384327 22509476222784 run_lib.py:146] step: 242000, eval_loss: 4.32346e-02
I0210 23:04:30.890491 22509476222784 run_lib.py:133] step: 242050, training_loss: 4.46071e-02
I0210 23:04:49.583941 22509476222784 run_lib.py:133] step: 242100, training_loss: 4.97176e-02
I0210 23:04:49.750630 22509476222784 run_lib.py:146] step: 242100, eval_loss: 3.89955e-02
I0210 23:05:08.218458 22509476222784 run_lib.py:133] step: 242150, training_loss: 4.75281e-02
I0210 23:05:26.666431 22509476222784 run_lib.py:133] step: 242200, training_loss: 4.77800e-02
I0210 23:05:26.828731 22509476222784 run_lib.py:146] step: 242200, eval_loss: 3.90641e-02
I0210 23:05:45.188056 22509476222784 run_lib.py:133] step: 242250, training_loss: 3.87779e-02
I0210 23:06:03.798715 22509476222784 run_lib.py:133] step: 242300, training_loss: 4.01248e-02
I0210 23:06:03.962546 22509476222784 run_lib.py:146] step: 242300, eval_loss: 3.44690e-02
I0210 23:06:22.482951 22509476222784 run_lib.py:133] step: 242350, training_loss: 4.77220e-02
I0210 23:06:41.033080 22509476222784 run_lib.py:133] step: 242400, training_loss: 3.27359e-02
I0210 23:06:41.193598 22509476222784 run_lib.py:146] step: 242400, eval_loss: 4.25396e-02
I0210 23:06:59.645619 22509476222784 run_lib.py:133] step: 242450, training_loss: 3.54842e-02
I0210 23:07:18.163243 22509476222784 run_lib.py:133] step: 242500, training_loss: 4.94000e-02
I0210 23:07:18.345605 22509476222784 run_lib.py:146] step: 242500, eval_loss: 5.25839e-02
I0210 23:07:37.034173 22509476222784 run_lib.py:133] step: 242550, training_loss: 4.62244e-02
I0210 23:07:55.693648 22509476222784 run_lib.py:133] step: 242600, training_loss: 4.48866e-02
I0210 23:07:55.859559 22509476222784 run_lib.py:146] step: 242600, eval_loss: 4.50018e-02
I0210 23:08:14.370975 22509476222784 run_lib.py:133] step: 242650, training_loss: 3.63103e-02
I0210 23:08:32.854033 22509476222784 run_lib.py:133] step: 242700, training_loss: 4.75227e-02
I0210 23:08:33.017593 22509476222784 run_lib.py:146] step: 242700, eval_loss: 3.49035e-02
I0210 23:08:51.640784 22509476222784 run_lib.py:133] step: 242750, training_loss: 5.24514e-02
I0210 23:09:10.175166 22509476222784 run_lib.py:133] step: 242800, training_loss: 4.13517e-02
I0210 23:09:10.338388 22509476222784 run_lib.py:146] step: 242800, eval_loss: 3.36473e-02
I0210 23:09:29.039705 22509476222784 run_lib.py:133] step: 242850, training_loss: 5.61387e-02
I0210 23:09:47.529655 22509476222784 run_lib.py:133] step: 242900, training_loss: 4.18009e-02
I0210 23:09:47.690699 22509476222784 run_lib.py:146] step: 242900, eval_loss: 4.57040e-02
I0210 23:10:06.324987 22509476222784 run_lib.py:133] step: 242950, training_loss: 4.89932e-02
I0210 23:10:24.750969 22509476222784 run_lib.py:133] step: 243000, training_loss: 3.93634e-02
I0210 23:10:24.915781 22509476222784 run_lib.py:146] step: 243000, eval_loss: 4.76592e-02
I0210 23:10:43.355180 22509476222784 run_lib.py:133] step: 243050, training_loss: 4.05784e-02
I0210 23:11:02.021878 22509476222784 run_lib.py:133] step: 243100, training_loss: 4.00999e-02
I0210 23:11:02.192682 22509476222784 run_lib.py:146] step: 243100, eval_loss: 3.88216e-02
I0210 23:11:20.859994 22509476222784 run_lib.py:133] step: 243150, training_loss: 3.52626e-02
I0210 23:11:39.526103 22509476222784 run_lib.py:133] step: 243200, training_loss: 3.92517e-02
I0210 23:11:39.689367 22509476222784 run_lib.py:146] step: 243200, eval_loss: 3.95880e-02
I0210 23:11:58.213141 22509476222784 run_lib.py:133] step: 243250, training_loss: 4.49152e-02
I0210 23:12:16.650178 22509476222784 run_lib.py:133] step: 243300, training_loss: 4.62976e-02
I0210 23:12:16.810381 22509476222784 run_lib.py:146] step: 243300, eval_loss: 3.65528e-02
I0210 23:12:35.442128 22509476222784 run_lib.py:133] step: 243350, training_loss: 5.26645e-02
I0210 23:12:53.977705 22509476222784 run_lib.py:133] step: 243400, training_loss: 3.59641e-02
I0210 23:12:54.148476 22509476222784 run_lib.py:146] step: 243400, eval_loss: 4.70094e-02
I0210 23:13:12.621759 22509476222784 run_lib.py:133] step: 243450, training_loss: 4.67059e-02
I0210 23:13:31.315058 22509476222784 run_lib.py:133] step: 243500, training_loss: 5.11654e-02
I0210 23:13:31.480227 22509476222784 run_lib.py:146] step: 243500, eval_loss: 3.81317e-02
I0210 23:13:49.881289 22509476222784 run_lib.py:133] step: 243550, training_loss: 3.74987e-02
I0210 23:14:08.318655 22509476222784 run_lib.py:133] step: 243600, training_loss: 4.44376e-02
I0210 23:14:08.627476 22509476222784 run_lib.py:146] step: 243600, eval_loss: 5.71001e-02
I0210 23:14:27.125143 22509476222784 run_lib.py:133] step: 243650, training_loss: 3.42250e-02
I0210 23:14:45.622853 22509476222784 run_lib.py:133] step: 243700, training_loss: 3.68998e-02
I0210 23:14:45.790392 22509476222784 run_lib.py:146] step: 243700, eval_loss: 4.62696e-02
I0210 23:15:04.320818 22509476222784 run_lib.py:133] step: 243750, training_loss: 4.31215e-02
I0210 23:15:22.807743 22509476222784 run_lib.py:133] step: 243800, training_loss: 4.65321e-02
I0210 23:15:22.968320 22509476222784 run_lib.py:146] step: 243800, eval_loss: 3.59685e-02
I0210 23:15:41.614423 22509476222784 run_lib.py:133] step: 243850, training_loss: 3.64237e-02
I0210 23:16:00.161785 22509476222784 run_lib.py:133] step: 243900, training_loss: 4.89233e-02
I0210 23:16:00.344143 22509476222784 run_lib.py:146] step: 243900, eval_loss: 4.23840e-02
I0210 23:16:18.853523 22509476222784 run_lib.py:133] step: 243950, training_loss: 4.78728e-02
I0210 23:16:37.340495 22509476222784 run_lib.py:133] step: 244000, training_loss: 4.70522e-02
I0210 23:16:37.504606 22509476222784 run_lib.py:146] step: 244000, eval_loss: 2.84658e-02
I0210 23:16:56.358970 22509476222784 run_lib.py:133] step: 244050, training_loss: 3.31543e-02
I0210 23:17:14.920578 22509476222784 run_lib.py:133] step: 244100, training_loss: 4.71545e-02
I0210 23:17:15.084558 22509476222784 run_lib.py:146] step: 244100, eval_loss: 4.70308e-02
I0210 23:17:33.558095 22509476222784 run_lib.py:133] step: 244150, training_loss: 3.73956e-02
I0210 23:17:52.122901 22509476222784 run_lib.py:133] step: 244200, training_loss: 5.59714e-02
I0210 23:17:52.293781 22509476222784 run_lib.py:146] step: 244200, eval_loss: 5.19269e-02
I0210 23:18:11.018388 22509476222784 run_lib.py:133] step: 244250, training_loss: 4.17580e-02
I0210 23:18:29.440534 22509476222784 run_lib.py:133] step: 244300, training_loss: 3.67986e-02
I0210 23:18:29.599519 22509476222784 run_lib.py:146] step: 244300, eval_loss: 4.71700e-02
I0210 23:18:48.168449 22509476222784 run_lib.py:133] step: 244350, training_loss: 3.91961e-02
I0210 23:19:06.619705 22509476222784 run_lib.py:133] step: 244400, training_loss: 5.08261e-02
I0210 23:19:06.784648 22509476222784 run_lib.py:146] step: 244400, eval_loss: 4.76872e-02
I0210 23:19:25.407578 22509476222784 run_lib.py:133] step: 244450, training_loss: 4.38469e-02
I0210 23:19:43.952525 22509476222784 run_lib.py:133] step: 244500, training_loss: 3.50776e-02
I0210 23:19:44.117766 22509476222784 run_lib.py:146] step: 244500, eval_loss: 2.94463e-02
I0210 23:20:02.597023 22509476222784 run_lib.py:133] step: 244550, training_loss: 3.75219e-02
I0210 23:20:21.228426 22509476222784 run_lib.py:133] step: 244600, training_loss: 4.82854e-02
I0210 23:20:21.392532 22509476222784 run_lib.py:146] step: 244600, eval_loss: 4.43963e-02
I0210 23:20:39.828937 22509476222784 run_lib.py:133] step: 244650, training_loss: 4.70898e-02
I0210 23:20:58.433087 22509476222784 run_lib.py:133] step: 244700, training_loss: 5.09399e-02
I0210 23:20:58.597562 22509476222784 run_lib.py:146] step: 244700, eval_loss: 4.37920e-02
I0210 23:21:17.082899 22509476222784 run_lib.py:133] step: 244750, training_loss: 4.88766e-02
I0210 23:21:35.555498 22509476222784 run_lib.py:133] step: 244800, training_loss: 4.94308e-02
I0210 23:21:35.723982 22509476222784 run_lib.py:146] step: 244800, eval_loss: 4.18429e-02
I0210 23:21:54.440206 22509476222784 run_lib.py:133] step: 244850, training_loss: 3.70890e-02
I0210 23:22:12.955922 22509476222784 run_lib.py:133] step: 244900, training_loss: 4.73859e-02
I0210 23:22:13.121758 22509476222784 run_lib.py:146] step: 244900, eval_loss: 4.33241e-02
I0210 23:22:31.555402 22509476222784 run_lib.py:133] step: 244950, training_loss: 5.52250e-02
I0210 23:22:49.971485 22509476222784 run_lib.py:133] step: 245000, training_loss: 3.49497e-02
I0210 23:22:50.141542 22509476222784 run_lib.py:146] step: 245000, eval_loss: 3.63317e-02
I0210 23:23:08.777902 22509476222784 run_lib.py:133] step: 245050, training_loss: 3.21478e-02
I0210 23:23:27.291506 22509476222784 run_lib.py:133] step: 245100, training_loss: 4.75545e-02
I0210 23:23:27.456745 22509476222784 run_lib.py:146] step: 245100, eval_loss: 3.49803e-02
I0210 23:23:46.010304 22509476222784 run_lib.py:133] step: 245150, training_loss: 3.35211e-02
I0210 23:24:04.438743 22509476222784 run_lib.py:133] step: 245200, training_loss: 3.37102e-02
I0210 23:24:04.600366 22509476222784 run_lib.py:146] step: 245200, eval_loss: 4.50762e-02
I0210 23:24:23.045186 22509476222784 run_lib.py:133] step: 245250, training_loss: 3.65230e-02
I0210 23:24:41.542113 22509476222784 run_lib.py:133] step: 245300, training_loss: 3.71904e-02
I0210 23:24:41.712008 22509476222784 run_lib.py:146] step: 245300, eval_loss: 4.09444e-02
I0210 23:25:00.400634 22509476222784 run_lib.py:133] step: 245350, training_loss: 4.31791e-02
I0210 23:25:18.972105 22509476222784 run_lib.py:133] step: 245400, training_loss: 4.04602e-02
I0210 23:25:19.135076 22509476222784 run_lib.py:146] step: 245400, eval_loss: 4.19118e-02
I0210 23:25:37.594792 22509476222784 run_lib.py:133] step: 245450, training_loss: 3.20244e-02
I0210 23:25:56.047120 22509476222784 run_lib.py:133] step: 245500, training_loss: 3.96392e-02
I0210 23:25:56.219468 22509476222784 run_lib.py:146] step: 245500, eval_loss: 3.96686e-02
I0210 23:26:14.846899 22509476222784 run_lib.py:133] step: 245550, training_loss: 4.22787e-02
I0210 23:26:33.346024 22509476222784 run_lib.py:133] step: 245600, training_loss: 4.41272e-02
I0210 23:26:33.508655 22509476222784 run_lib.py:146] step: 245600, eval_loss: 4.05297e-02
I0210 23:26:52.200366 22509476222784 run_lib.py:133] step: 245650, training_loss: 4.10864e-02
I0210 23:27:10.663853 22509476222784 run_lib.py:133] step: 245700, training_loss: 4.90844e-02
I0210 23:27:10.827787 22509476222784 run_lib.py:146] step: 245700, eval_loss: 4.82947e-02
I0210 23:27:29.446152 22509476222784 run_lib.py:133] step: 245750, training_loss: 4.10825e-02
I0210 23:27:47.892633 22509476222784 run_lib.py:133] step: 245800, training_loss: 4.48677e-02
I0210 23:27:48.056529 22509476222784 run_lib.py:146] step: 245800, eval_loss: 5.36081e-02
I0210 23:28:06.632647 22509476222784 run_lib.py:133] step: 245850, training_loss: 4.20348e-02
I0210 23:28:25.101140 22509476222784 run_lib.py:133] step: 245900, training_loss: 4.09882e-02
I0210 23:28:25.268659 22509476222784 run_lib.py:146] step: 245900, eval_loss: 4.55346e-02
I0210 23:28:43.764792 22509476222784 run_lib.py:133] step: 245950, training_loss: 4.90436e-02
I0210 23:29:02.460233 22509476222784 run_lib.py:133] step: 246000, training_loss: 5.40378e-02
I0210 23:29:02.625598 22509476222784 run_lib.py:146] step: 246000, eval_loss: 3.88514e-02
I0210 23:29:21.112173 22509476222784 run_lib.py:133] step: 246050, training_loss: 4.39188e-02
I0210 23:29:39.553535 22509476222784 run_lib.py:133] step: 246100, training_loss: 5.39113e-02
I0210 23:29:39.740538 22509476222784 run_lib.py:146] step: 246100, eval_loss: 3.28975e-02
I0210 23:29:58.363192 22509476222784 run_lib.py:133] step: 246150, training_loss: 5.12419e-02
I0210 23:30:17.016798 22509476222784 run_lib.py:133] step: 246200, training_loss: 5.01294e-02
I0210 23:30:17.179842 22509476222784 run_lib.py:146] step: 246200, eval_loss: 4.17341e-02
I0210 23:30:35.706868 22509476222784 run_lib.py:133] step: 246250, training_loss: 3.51602e-02
I0210 23:30:54.139260 22509476222784 run_lib.py:133] step: 246300, training_loss: 4.08600e-02
I0210 23:30:54.303418 22509476222784 run_lib.py:146] step: 246300, eval_loss: 3.68231e-02
I0210 23:31:12.736424 22509476222784 run_lib.py:133] step: 246350, training_loss: 4.16020e-02
I0210 23:31:31.383479 22509476222784 run_lib.py:133] step: 246400, training_loss: 4.41433e-02
I0210 23:31:31.561555 22509476222784 run_lib.py:146] step: 246400, eval_loss: 4.13876e-02
I0210 23:31:50.109641 22509476222784 run_lib.py:133] step: 246450, training_loss: 4.02858e-02
I0210 23:32:08.599781 22509476222784 run_lib.py:133] step: 246500, training_loss: 5.26186e-02
I0210 23:32:08.764892 22509476222784 run_lib.py:146] step: 246500, eval_loss: 4.79040e-02
I0210 23:32:27.186549 22509476222784 run_lib.py:133] step: 246550, training_loss: 4.16138e-02
I0210 23:32:45.756937 22509476222784 run_lib.py:133] step: 246600, training_loss: 3.86811e-02
I0210 23:32:45.919636 22509476222784 run_lib.py:146] step: 246600, eval_loss: 4.26132e-02
I0210 23:33:04.395570 22509476222784 run_lib.py:133] step: 246650, training_loss: 4.96051e-02
I0210 23:33:22.981801 22509476222784 run_lib.py:133] step: 246700, training_loss: 4.58179e-02
I0210 23:33:23.147984 22509476222784 run_lib.py:146] step: 246700, eval_loss: 3.94449e-02
I0210 23:33:41.716250 22509476222784 run_lib.py:133] step: 246750, training_loss: 5.86190e-02
I0210 23:34:00.268462 22509476222784 run_lib.py:133] step: 246800, training_loss: 3.45927e-02
I0210 23:34:00.434751 22509476222784 run_lib.py:146] step: 246800, eval_loss: 3.79240e-02
I0210 23:34:19.111765 22509476222784 run_lib.py:133] step: 246850, training_loss: 4.61682e-02
I0210 23:34:37.658469 22509476222784 run_lib.py:133] step: 246900, training_loss: 4.85052e-02
I0210 23:34:37.822718 22509476222784 run_lib.py:146] step: 246900, eval_loss: 3.78438e-02
I0210 23:34:56.294976 22509476222784 run_lib.py:133] step: 246950, training_loss: 3.85922e-02
I0210 23:35:14.828839 22509476222784 run_lib.py:133] step: 247000, training_loss: 5.10826e-02
I0210 23:35:14.996423 22509476222784 run_lib.py:146] step: 247000, eval_loss: 4.70730e-02
I0210 23:35:33.722660 22509476222784 run_lib.py:133] step: 247050, training_loss: 5.33516e-02
I0210 23:35:52.213062 22509476222784 run_lib.py:133] step: 247100, training_loss: 4.09216e-02
I0210 23:35:52.375627 22509476222784 run_lib.py:146] step: 247100, eval_loss: 3.60130e-02
I0210 23:36:10.988533 22509476222784 run_lib.py:133] step: 247150, training_loss: 3.58367e-02
I0210 23:36:29.501734 22509476222784 run_lib.py:133] step: 247200, training_loss: 4.57850e-02
I0210 23:36:29.666691 22509476222784 run_lib.py:146] step: 247200, eval_loss: 3.85918e-02
I0210 23:36:48.391246 22509476222784 run_lib.py:133] step: 247250, training_loss: 5.47498e-02
I0210 23:37:06.924501 22509476222784 run_lib.py:133] step: 247300, training_loss: 3.73248e-02
I0210 23:37:07.089718 22509476222784 run_lib.py:146] step: 247300, eval_loss: 4.86811e-02
I0210 23:37:25.562262 22509476222784 run_lib.py:133] step: 247350, training_loss: 4.99085e-02
I0210 23:37:44.241291 22509476222784 run_lib.py:133] step: 247400, training_loss: 4.24315e-02
I0210 23:37:44.405560 22509476222784 run_lib.py:146] step: 247400, eval_loss: 4.20510e-02
I0210 23:38:02.884816 22509476222784 run_lib.py:133] step: 247450, training_loss: 4.47818e-02
I0210 23:38:21.447750 22509476222784 run_lib.py:133] step: 247500, training_loss: 5.17295e-02
I0210 23:38:21.613415 22509476222784 run_lib.py:146] step: 247500, eval_loss: 3.05318e-02
I0210 23:38:40.121263 22509476222784 run_lib.py:133] step: 247550, training_loss: 5.39918e-02
I0210 23:38:58.664411 22509476222784 run_lib.py:133] step: 247600, training_loss: 4.66508e-02
I0210 23:38:58.851944 22509476222784 run_lib.py:146] step: 247600, eval_loss: 5.44084e-02
I0210 23:39:17.527750 22509476222784 run_lib.py:133] step: 247650, training_loss: 3.45562e-02
I0210 23:39:35.972502 22509476222784 run_lib.py:133] step: 247700, training_loss: 4.96693e-02
I0210 23:39:36.136634 22509476222784 run_lib.py:146] step: 247700, eval_loss: 4.04936e-02
I0210 23:39:54.549164 22509476222784 run_lib.py:133] step: 247750, training_loss: 4.86195e-02
I0210 23:40:13.165932 22509476222784 run_lib.py:133] step: 247800, training_loss: 4.88259e-02
I0210 23:40:13.348548 22509476222784 run_lib.py:146] step: 247800, eval_loss: 3.85652e-02
I0210 23:40:31.873285 22509476222784 run_lib.py:133] step: 247850, training_loss: 3.57031e-02
I0210 23:40:50.282269 22509476222784 run_lib.py:133] step: 247900, training_loss: 4.62129e-02
I0210 23:40:50.446897 22509476222784 run_lib.py:146] step: 247900, eval_loss: 4.11908e-02
I0210 23:41:09.075446 22509476222784 run_lib.py:133] step: 247950, training_loss: 4.70365e-02
I0210 23:41:27.537421 22509476222784 run_lib.py:133] step: 248000, training_loss: 6.06468e-02
I0210 23:41:27.700643 22509476222784 run_lib.py:146] step: 248000, eval_loss: 3.88331e-02
I0210 23:41:46.187939 22509476222784 run_lib.py:133] step: 248050, training_loss: 5.24646e-02
I0210 23:42:04.692671 22509476222784 run_lib.py:133] step: 248100, training_loss: 4.43041e-02
I0210 23:42:04.857249 22509476222784 run_lib.py:146] step: 248100, eval_loss: 4.65581e-02
I0210 23:42:23.573872 22509476222784 run_lib.py:133] step: 248150, training_loss: 3.62136e-02
I0210 23:42:42.160978 22509476222784 run_lib.py:133] step: 248200, training_loss: 5.13772e-02
I0210 23:42:42.327702 22509476222784 run_lib.py:146] step: 248200, eval_loss: 5.80149e-02
I0210 23:43:00.802945 22509476222784 run_lib.py:133] step: 248250, training_loss: 5.42868e-02
I0210 23:43:19.227390 22509476222784 run_lib.py:133] step: 248300, training_loss: 3.64320e-02
I0210 23:43:19.392675 22509476222784 run_lib.py:146] step: 248300, eval_loss: 4.36373e-02
I0210 23:43:38.026990 22509476222784 run_lib.py:133] step: 248350, training_loss: 3.54428e-02
I0210 23:43:56.555387 22509476222784 run_lib.py:133] step: 248400, training_loss: 3.49850e-02
I0210 23:43:56.718788 22509476222784 run_lib.py:146] step: 248400, eval_loss: 4.45993e-02
I0210 23:44:15.364600 22509476222784 run_lib.py:133] step: 248450, training_loss: 3.19340e-02
I0210 23:44:33.822228 22509476222784 run_lib.py:133] step: 248500, training_loss: 4.09395e-02
I0210 23:44:33.982597 22509476222784 run_lib.py:146] step: 248500, eval_loss: 3.55698e-02
I0210 23:44:52.555471 22509476222784 run_lib.py:133] step: 248550, training_loss: 4.06004e-02
I0210 23:45:10.974206 22509476222784 run_lib.py:133] step: 248600, training_loss: 4.27684e-02
I0210 23:45:11.147114 22509476222784 run_lib.py:146] step: 248600, eval_loss: 4.80939e-02
I0210 23:45:29.863039 22509476222784 run_lib.py:133] step: 248650, training_loss: 4.76508e-02
I0210 23:45:48.327131 22509476222784 run_lib.py:133] step: 248700, training_loss: 4.35270e-02
I0210 23:45:48.491552 22509476222784 run_lib.py:146] step: 248700, eval_loss: 4.53929e-02
I0210 23:46:06.875756 22509476222784 run_lib.py:133] step: 248750, training_loss: 4.07531e-02
I0210 23:46:25.486291 22509476222784 run_lib.py:133] step: 248800, training_loss: 4.84580e-02
I0210 23:46:25.651754 22509476222784 run_lib.py:146] step: 248800, eval_loss: 4.24744e-02
I0210 23:46:44.191903 22509476222784 run_lib.py:133] step: 248850, training_loss: 3.88940e-02
I0210 23:47:02.709695 22509476222784 run_lib.py:133] step: 248900, training_loss: 4.10092e-02
I0210 23:47:02.875682 22509476222784 run_lib.py:146] step: 248900, eval_loss: 4.15384e-02
I0210 23:47:21.581740 22509476222784 run_lib.py:133] step: 248950, training_loss: 3.70077e-02
I0210 23:47:40.076164 22509476222784 run_lib.py:133] step: 249000, training_loss: 4.80855e-02
I0210 23:47:40.237485 22509476222784 run_lib.py:146] step: 249000, eval_loss: 3.73538e-02
I0210 23:47:58.936504 22509476222784 run_lib.py:133] step: 249050, training_loss: 4.79458e-02
I0210 23:48:17.434475 22509476222784 run_lib.py:133] step: 249100, training_loss: 4.09085e-02
I0210 23:48:17.599546 22509476222784 run_lib.py:146] step: 249100, eval_loss: 4.52517e-02
I0210 23:48:36.065890 22509476222784 run_lib.py:133] step: 249150, training_loss: 4.73073e-02
I0210 23:48:54.706441 22509476222784 run_lib.py:133] step: 249200, training_loss: 5.05705e-02
I0210 23:48:54.883521 22509476222784 run_lib.py:146] step: 249200, eval_loss: 3.76851e-02
I0210 23:49:13.412442 22509476222784 run_lib.py:133] step: 249250, training_loss: 3.45419e-02
I0210 23:49:31.903815 22509476222784 run_lib.py:133] step: 249300, training_loss: 4.58635e-02
I0210 23:49:32.067844 22509476222784 run_lib.py:146] step: 249300, eval_loss: 4.70755e-02
I0210 23:49:50.584311 22509476222784 run_lib.py:133] step: 249350, training_loss: 4.91454e-02
I0210 23:50:09.239676 22509476222784 run_lib.py:133] step: 249400, training_loss: 3.91044e-02
I0210 23:50:09.402585 22509476222784 run_lib.py:146] step: 249400, eval_loss: 4.80489e-02
I0210 23:50:27.905723 22509476222784 run_lib.py:133] step: 249450, training_loss: 4.36223e-02
I0210 23:50:46.506381 22509476222784 run_lib.py:133] step: 249500, training_loss: 5.11705e-02
I0210 23:50:46.671775 22509476222784 run_lib.py:146] step: 249500, eval_loss: 5.55034e-02
I0210 23:51:05.186454 22509476222784 run_lib.py:133] step: 249550, training_loss: 3.34532e-02
I0210 23:51:23.658665 22509476222784 run_lib.py:133] step: 249600, training_loss: 4.31916e-02
I0210 23:51:23.823566 22509476222784 run_lib.py:146] step: 249600, eval_loss: 4.19072e-02
I0210 23:51:42.465392 22509476222784 run_lib.py:133] step: 249650, training_loss: 3.61014e-02
I0210 23:52:01.004253 22509476222784 run_lib.py:133] step: 249700, training_loss: 3.68768e-02
I0210 23:52:01.170980 22509476222784 run_lib.py:146] step: 249700, eval_loss: 4.46285e-02
I0210 23:52:19.710155 22509476222784 run_lib.py:133] step: 249750, training_loss: 3.92222e-02
I0210 23:52:38.277337 22509476222784 run_lib.py:133] step: 249800, training_loss: 3.60615e-02
I0210 23:52:38.441691 22509476222784 run_lib.py:146] step: 249800, eval_loss: 4.90190e-02
I0210 23:52:57.135195 22509476222784 run_lib.py:133] step: 249850, training_loss: 4.24177e-02
I0210 23:53:15.629739 22509476222784 run_lib.py:133] step: 249900, training_loss: 4.02047e-02
I0210 23:53:15.793524 22509476222784 run_lib.py:146] step: 249900, eval_loss: 4.04857e-02
I0210 23:53:34.435809 22509476222784 run_lib.py:133] step: 249950, training_loss: 4.02039e-02
I0210 23:53:52.939842 22509476222784 run_lib.py:133] step: 250000, training_loss: 4.77979e-02
I0210 23:53:54.122794 22509476222784 run_lib.py:146] step: 250000, eval_loss: 5.31041e-02
I0210 23:54:16.536216 22509476222784 run_lib.py:133] step: 250050, training_loss: 5.06482e-02
I0210 23:54:35.053665 22509476222784 run_lib.py:133] step: 250100, training_loss: 4.35525e-02
I0210 23:54:35.214565 22509476222784 run_lib.py:146] step: 250100, eval_loss: 3.42841e-02
I0210 23:54:53.757105 22509476222784 run_lib.py:133] step: 250150, training_loss: 3.35429e-02
I0210 23:55:12.231169 22509476222784 run_lib.py:133] step: 250200, training_loss: 4.67668e-02
I0210 23:55:12.396821 22509476222784 run_lib.py:146] step: 250200, eval_loss: 5.35989e-02
I0210 23:55:30.922791 22509476222784 run_lib.py:133] step: 250250, training_loss: 3.98020e-02
I0210 23:55:49.463685 22509476222784 run_lib.py:133] step: 250300, training_loss: 3.81328e-02
I0210 23:55:49.628695 22509476222784 run_lib.py:146] step: 250300, eval_loss: 4.02366e-02
I0210 23:56:08.242224 22509476222784 run_lib.py:133] step: 250350, training_loss: 4.35464e-02
I0210 23:56:26.750955 22509476222784 run_lib.py:133] step: 250400, training_loss: 4.15571e-02
I0210 23:56:26.914654 22509476222784 run_lib.py:146] step: 250400, eval_loss: 4.99944e-02
I0210 23:56:45.455555 22509476222784 run_lib.py:133] step: 250450, training_loss: 4.23749e-02
I0210 23:57:03.939607 22509476222784 run_lib.py:133] step: 250500, training_loss: 3.24915e-02
I0210 23:57:04.100792 22509476222784 run_lib.py:146] step: 250500, eval_loss: 4.69135e-02
I0210 23:57:22.796336 22509476222784 run_lib.py:133] step: 250550, training_loss: 3.82103e-02
I0210 23:57:41.279685 22509476222784 run_lib.py:133] step: 250600, training_loss: 4.12143e-02
I0210 23:57:41.460855 22509476222784 run_lib.py:146] step: 250600, eval_loss: 3.93874e-02
I0210 23:58:00.127354 22509476222784 run_lib.py:133] step: 250650, training_loss: 5.67855e-02
I0210 23:58:18.588115 22509476222784 run_lib.py:133] step: 250700, training_loss: 4.05474e-02
I0210 23:58:18.753806 22509476222784 run_lib.py:146] step: 250700, eval_loss: 3.97700e-02
I0210 23:58:37.407732 22509476222784 run_lib.py:133] step: 250750, training_loss: 3.93848e-02
I0210 23:58:55.868191 22509476222784 run_lib.py:133] step: 250800, training_loss: 4.72441e-02
I0210 23:58:56.046590 22509476222784 run_lib.py:146] step: 250800, eval_loss: 3.29488e-02
I0210 23:59:14.555168 22509476222784 run_lib.py:133] step: 250850, training_loss: 5.22917e-02
I0210 23:59:33.163730 22509476222784 run_lib.py:133] step: 250900, training_loss: 4.97597e-02
I0210 23:59:33.326993 22509476222784 run_lib.py:146] step: 250900, eval_loss: 4.05157e-02
I0210 23:59:51.865870 22509476222784 run_lib.py:133] step: 250950, training_loss: 4.91682e-02
I0211 00:00:10.455226 22509476222784 run_lib.py:133] step: 251000, training_loss: 3.91781e-02
I0211 00:00:10.615678 22509476222784 run_lib.py:146] step: 251000, eval_loss: 3.74716e-02
I0211 00:00:29.020711 22509476222784 run_lib.py:133] step: 251050, training_loss: 4.21826e-02
I0211 00:00:47.475239 22509476222784 run_lib.py:133] step: 251100, training_loss: 4.05469e-02
I0211 00:00:47.649898 22509476222784 run_lib.py:146] step: 251100, eval_loss: 4.11144e-02
I0211 00:01:06.403894 22509476222784 run_lib.py:133] step: 251150, training_loss: 3.73882e-02
I0211 00:01:24.899572 22509476222784 run_lib.py:133] step: 251200, training_loss: 3.94901e-02
I0211 00:01:25.064646 22509476222784 run_lib.py:146] step: 251200, eval_loss: 5.82268e-02
I0211 00:01:43.500247 22509476222784 run_lib.py:133] step: 251250, training_loss: 5.06887e-02
I0211 00:02:02.111301 22509476222784 run_lib.py:133] step: 251300, training_loss: 5.00921e-02
I0211 00:02:02.275732 22509476222784 run_lib.py:146] step: 251300, eval_loss: 3.94523e-02
I0211 00:02:20.758898 22509476222784 run_lib.py:133] step: 251350, training_loss: 3.85665e-02
I0211 00:02:39.224616 22509476222784 run_lib.py:133] step: 251400, training_loss: 3.27392e-02
I0211 00:02:39.547568 22509476222784 run_lib.py:146] step: 251400, eval_loss: 4.14204e-02
I0211 00:02:58.095487 22509476222784 run_lib.py:133] step: 251450, training_loss: 4.39818e-02
I0211 00:03:16.558527 22509476222784 run_lib.py:133] step: 251500, training_loss: 3.90939e-02
I0211 00:03:16.720594 22509476222784 run_lib.py:146] step: 251500, eval_loss: 3.76169e-02
I0211 00:03:35.238957 22509476222784 run_lib.py:133] step: 251550, training_loss: 4.19518e-02
I0211 00:03:53.680488 22509476222784 run_lib.py:133] step: 251600, training_loss: 4.43902e-02
I0211 00:03:53.844699 22509476222784 run_lib.py:146] step: 251600, eval_loss: 3.93054e-02
I0211 00:04:12.444564 22509476222784 run_lib.py:133] step: 251650, training_loss: 4.25735e-02
I0211 00:04:31.084467 22509476222784 run_lib.py:133] step: 251700, training_loss: 5.50822e-02
I0211 00:04:31.250728 22509476222784 run_lib.py:146] step: 251700, eval_loss: 3.67648e-02
I0211 00:04:49.796414 22509476222784 run_lib.py:133] step: 251750, training_loss: 4.17769e-02
I0211 00:05:08.270263 22509476222784 run_lib.py:133] step: 251800, training_loss: 5.20474e-02
I0211 00:05:08.434779 22509476222784 run_lib.py:146] step: 251800, eval_loss: 4.33522e-02
I0211 00:05:27.100677 22509476222784 run_lib.py:133] step: 251850, training_loss: 2.96064e-02
I0211 00:05:45.632336 22509476222784 run_lib.py:133] step: 251900, training_loss: 3.45129e-02
I0211 00:05:45.793433 22509476222784 run_lib.py:146] step: 251900, eval_loss: 4.69289e-02
I0211 00:06:04.186796 22509476222784 run_lib.py:133] step: 251950, training_loss: 4.66841e-02
I0211 00:06:22.677160 22509476222784 run_lib.py:133] step: 252000, training_loss: 3.76686e-02
I0211 00:06:22.871365 22509476222784 run_lib.py:146] step: 252000, eval_loss: 4.48314e-02
I0211 00:06:41.497396 22509476222784 run_lib.py:133] step: 252050, training_loss: 4.59844e-02
I0211 00:07:00.028851 22509476222784 run_lib.py:133] step: 252100, training_loss: 3.95327e-02
I0211 00:07:00.193904 22509476222784 run_lib.py:146] step: 252100, eval_loss: 5.00263e-02
I0211 00:07:18.824773 22509476222784 run_lib.py:133] step: 252150, training_loss: 4.64772e-02
I0211 00:07:37.288546 22509476222784 run_lib.py:133] step: 252200, training_loss: 3.08559e-02
I0211 00:07:37.451487 22509476222784 run_lib.py:146] step: 252200, eval_loss: 3.99116e-02
I0211 00:07:56.065082 22509476222784 run_lib.py:133] step: 252250, training_loss: 4.66077e-02
I0211 00:08:14.524675 22509476222784 run_lib.py:133] step: 252300, training_loss: 3.45116e-02
I0211 00:08:14.689488 22509476222784 run_lib.py:146] step: 252300, eval_loss: 4.26911e-02
I0211 00:08:33.218070 22509476222784 run_lib.py:133] step: 252350, training_loss: 4.51655e-02
I0211 00:08:51.753066 22509476222784 run_lib.py:133] step: 252400, training_loss: 4.16298e-02
I0211 00:08:51.911345 22509476222784 run_lib.py:146] step: 252400, eval_loss: 3.64114e-02
I0211 00:09:10.338660 22509476222784 run_lib.py:133] step: 252450, training_loss: 4.31090e-02
I0211 00:09:28.949048 22509476222784 run_lib.py:133] step: 252500, training_loss: 4.67435e-02
I0211 00:09:29.113961 22509476222784 run_lib.py:146] step: 252500, eval_loss: 4.72516e-02
I0211 00:09:47.624933 22509476222784 run_lib.py:133] step: 252550, training_loss: 4.61342e-02
I0211 00:10:06.152651 22509476222784 run_lib.py:133] step: 252600, training_loss: 4.23212e-02
I0211 00:10:06.318558 22509476222784 run_lib.py:146] step: 252600, eval_loss: 3.71289e-02
I0211 00:10:24.768477 22509476222784 run_lib.py:133] step: 252650, training_loss: 4.99765e-02
I0211 00:10:43.468753 22509476222784 run_lib.py:133] step: 252700, training_loss: 4.76579e-02
I0211 00:10:43.632684 22509476222784 run_lib.py:146] step: 252700, eval_loss: 3.97663e-02
I0211 00:11:02.083473 22509476222784 run_lib.py:133] step: 252750, training_loss: 4.65439e-02
I0211 00:11:20.605675 22509476222784 run_lib.py:133] step: 252800, training_loss: 3.97396e-02
I0211 00:11:20.769854 22509476222784 run_lib.py:146] step: 252800, eval_loss: 3.25639e-02
I0211 00:11:39.489692 22509476222784 run_lib.py:133] step: 252850, training_loss: 3.95518e-02
I0211 00:11:57.992697 22509476222784 run_lib.py:133] step: 252900, training_loss: 3.69462e-02
I0211 00:11:58.153603 22509476222784 run_lib.py:146] step: 252900, eval_loss: 5.20729e-02
I0211 00:12:16.708472 22509476222784 run_lib.py:133] step: 252950, training_loss: 4.07606e-02
I0211 00:12:35.213470 22509476222784 run_lib.py:133] step: 253000, training_loss: 4.68850e-02
I0211 00:12:35.383469 22509476222784 run_lib.py:146] step: 253000, eval_loss: 4.37873e-02
I0211 00:12:53.788064 22509476222784 run_lib.py:133] step: 253050, training_loss: 4.63771e-02
I0211 00:13:12.337463 22509476222784 run_lib.py:133] step: 253100, training_loss: 3.99386e-02
I0211 00:13:12.506715 22509476222784 run_lib.py:146] step: 253100, eval_loss: 4.81773e-02
I0211 00:13:31.196669 22509476222784 run_lib.py:133] step: 253150, training_loss: 4.99961e-02
I0211 00:13:49.759525 22509476222784 run_lib.py:133] step: 253200, training_loss: 4.00443e-02
I0211 00:13:49.932748 22509476222784 run_lib.py:146] step: 253200, eval_loss: 3.97806e-02
I0211 00:14:08.417401 22509476222784 run_lib.py:133] step: 253250, training_loss: 3.87172e-02
I0211 00:14:26.875846 22509476222784 run_lib.py:133] step: 253300, training_loss: 4.83485e-02
I0211 00:14:27.036312 22509476222784 run_lib.py:146] step: 253300, eval_loss: 4.29983e-02
I0211 00:14:45.633848 22509476222784 run_lib.py:133] step: 253350, training_loss: 4.42591e-02
I0211 00:15:04.127035 22509476222784 run_lib.py:133] step: 253400, training_loss: 6.22562e-02
I0211 00:15:04.294857 22509476222784 run_lib.py:146] step: 253400, eval_loss: 3.58981e-02
I0211 00:15:23.044912 22509476222784 run_lib.py:133] step: 253450, training_loss: 4.15544e-02
I0211 00:15:41.587640 22509476222784 run_lib.py:133] step: 253500, training_loss: 5.01570e-02
I0211 00:15:41.757265 22509476222784 run_lib.py:146] step: 253500, eval_loss: 4.15991e-02
I0211 00:16:00.357853 22509476222784 run_lib.py:133] step: 253550, training_loss: 3.72380e-02
I0211 00:16:18.826675 22509476222784 run_lib.py:133] step: 253600, training_loss: 3.80251e-02
I0211 00:16:19.050161 22509476222784 run_lib.py:146] step: 253600, eval_loss: 3.91456e-02
I0211 00:16:37.797107 22509476222784 run_lib.py:133] step: 253650, training_loss: 4.76417e-02
I0211 00:16:56.404664 22509476222784 run_lib.py:133] step: 253700, training_loss: 4.53781e-02
I0211 00:16:56.569789 22509476222784 run_lib.py:146] step: 253700, eval_loss: 3.77784e-02
I0211 00:17:15.082411 22509476222784 run_lib.py:133] step: 253750, training_loss: 4.17076e-02
I0211 00:17:33.697748 22509476222784 run_lib.py:133] step: 253800, training_loss: 5.74602e-02
I0211 00:17:33.859641 22509476222784 run_lib.py:146] step: 253800, eval_loss: 3.14509e-02
I0211 00:17:52.317937 22509476222784 run_lib.py:133] step: 253850, training_loss: 5.05724e-02
I0211 00:18:10.887413 22509476222784 run_lib.py:133] step: 253900, training_loss: 4.37783e-02
I0211 00:18:11.048804 22509476222784 run_lib.py:146] step: 253900, eval_loss: 5.54944e-02
I0211 00:18:29.712162 22509476222784 run_lib.py:133] step: 253950, training_loss: 6.50318e-02
I0211 00:18:48.337494 22509476222784 run_lib.py:133] step: 254000, training_loss: 3.38940e-02
I0211 00:18:48.502787 22509476222784 run_lib.py:146] step: 254000, eval_loss: 4.64750e-02
I0211 00:19:06.927489 22509476222784 run_lib.py:133] step: 254050, training_loss: 4.70448e-02
I0211 00:19:25.363481 22509476222784 run_lib.py:133] step: 254100, training_loss: 3.57331e-02
I0211 00:19:25.526567 22509476222784 run_lib.py:146] step: 254100, eval_loss: 3.72978e-02
I0211 00:19:43.988101 22509476222784 run_lib.py:133] step: 254150, training_loss: 5.45995e-02
I0211 00:20:02.706840 22509476222784 run_lib.py:133] step: 254200, training_loss: 5.23250e-02
I0211 00:20:02.871958 22509476222784 run_lib.py:146] step: 254200, eval_loss: 5.38901e-02
I0211 00:20:21.365539 22509476222784 run_lib.py:133] step: 254250, training_loss: 4.52995e-02
I0211 00:20:39.755714 22509476222784 run_lib.py:133] step: 254300, training_loss: 4.50252e-02
I0211 00:20:39.920693 22509476222784 run_lib.py:146] step: 254300, eval_loss: 4.75269e-02
I0211 00:20:58.347347 22509476222784 run_lib.py:133] step: 254350, training_loss: 5.48966e-02
I0211 00:21:16.971421 22509476222784 run_lib.py:133] step: 254400, training_loss: 5.37303e-02
I0211 00:21:17.145226 22509476222784 run_lib.py:146] step: 254400, eval_loss: 4.46599e-02
I0211 00:21:35.705150 22509476222784 run_lib.py:133] step: 254450, training_loss: 3.20086e-02
I0211 00:21:54.214407 22509476222784 run_lib.py:133] step: 254500, training_loss: 4.16084e-02
I0211 00:21:54.383594 22509476222784 run_lib.py:146] step: 254500, eval_loss: 4.19438e-02
I0211 00:22:12.818472 22509476222784 run_lib.py:133] step: 254550, training_loss: 3.78926e-02
I0211 00:22:31.324291 22509476222784 run_lib.py:133] step: 254600, training_loss: 3.86504e-02
I0211 00:22:31.488634 22509476222784 run_lib.py:146] step: 254600, eval_loss: 3.87258e-02
I0211 00:22:50.100504 22509476222784 run_lib.py:133] step: 254650, training_loss: 4.31953e-02
I0211 00:23:08.763067 22509476222784 run_lib.py:133] step: 254700, training_loss: 4.27726e-02
I0211 00:23:08.927826 22509476222784 run_lib.py:146] step: 254700, eval_loss: 3.38018e-02
I0211 00:23:27.432963 22509476222784 run_lib.py:133] step: 254750, training_loss: 4.30239e-02
I0211 00:23:45.934431 22509476222784 run_lib.py:133] step: 254800, training_loss: 4.00909e-02
I0211 00:23:46.095777 22509476222784 run_lib.py:146] step: 254800, eval_loss: 5.70504e-02
I0211 00:24:04.761774 22509476222784 run_lib.py:133] step: 254850, training_loss: 3.63934e-02
I0211 00:24:23.287344 22509476222784 run_lib.py:133] step: 254900, training_loss: 5.92619e-02
I0211 00:24:23.450552 22509476222784 run_lib.py:146] step: 254900, eval_loss: 3.74514e-02
I0211 00:24:42.154742 22509476222784 run_lib.py:133] step: 254950, training_loss: 3.90172e-02
I0211 00:25:00.727348 22509476222784 run_lib.py:133] step: 255000, training_loss: 4.22258e-02
I0211 00:25:00.893664 22509476222784 run_lib.py:146] step: 255000, eval_loss: 3.86304e-02
I0211 00:25:19.570725 22509476222784 run_lib.py:133] step: 255050, training_loss: 5.18965e-02
I0211 00:25:38.061499 22509476222784 run_lib.py:133] step: 255100, training_loss: 3.50738e-02
I0211 00:25:38.227605 22509476222784 run_lib.py:146] step: 255100, eval_loss: 3.51208e-02
I0211 00:25:56.683351 22509476222784 run_lib.py:133] step: 255150, training_loss: 3.26534e-02
I0211 00:26:15.375506 22509476222784 run_lib.py:133] step: 255200, training_loss: 4.11311e-02
I0211 00:26:15.801758 22509476222784 run_lib.py:146] step: 255200, eval_loss: 4.30711e-02
I0211 00:26:34.406824 22509476222784 run_lib.py:133] step: 255250, training_loss: 4.44877e-02
I0211 00:26:53.063995 22509476222784 run_lib.py:133] step: 255300, training_loss: 3.42713e-02
I0211 00:26:53.224634 22509476222784 run_lib.py:146] step: 255300, eval_loss: 4.47513e-02
I0211 00:27:11.700121 22509476222784 run_lib.py:133] step: 255350, training_loss: 4.14134e-02
I0211 00:27:30.112045 22509476222784 run_lib.py:133] step: 255400, training_loss: 4.80431e-02
I0211 00:27:30.277993 22509476222784 run_lib.py:146] step: 255400, eval_loss: 4.69225e-02
I0211 00:27:48.897342 22509476222784 run_lib.py:133] step: 255450, training_loss: 3.72126e-02
I0211 00:28:07.365428 22509476222784 run_lib.py:133] step: 255500, training_loss: 4.50620e-02
I0211 00:28:07.534548 22509476222784 run_lib.py:146] step: 255500, eval_loss: 3.88112e-02
I0211 00:28:26.024764 22509476222784 run_lib.py:133] step: 255550, training_loss: 4.00455e-02
I0211 00:28:44.733323 22509476222784 run_lib.py:133] step: 255600, training_loss: 5.24894e-02
I0211 00:28:44.897398 22509476222784 run_lib.py:146] step: 255600, eval_loss: 4.34461e-02
I0211 00:29:03.422400 22509476222784 run_lib.py:133] step: 255650, training_loss: 3.75679e-02
I0211 00:29:21.887506 22509476222784 run_lib.py:133] step: 255700, training_loss: 3.84261e-02
I0211 00:29:22.048353 22509476222784 run_lib.py:146] step: 255700, eval_loss: 4.26186e-02
I0211 00:29:40.641756 22509476222784 run_lib.py:133] step: 255750, training_loss: 4.36730e-02
I0211 00:29:59.066084 22509476222784 run_lib.py:133] step: 255800, training_loss: 4.09585e-02
I0211 00:29:59.243651 22509476222784 run_lib.py:146] step: 255800, eval_loss: 4.83831e-02
I0211 00:30:17.741378 22509476222784 run_lib.py:133] step: 255850, training_loss: 5.66327e-02
I0211 00:30:36.269015 22509476222784 run_lib.py:133] step: 255900, training_loss: 3.32799e-02
I0211 00:30:36.433931 22509476222784 run_lib.py:146] step: 255900, eval_loss: 4.61923e-02
I0211 00:30:55.110971 22509476222784 run_lib.py:133] step: 255950, training_loss: 5.04828e-02
I0211 00:31:13.664269 22509476222784 run_lib.py:133] step: 256000, training_loss: 3.80690e-02
I0211 00:31:13.828604 22509476222784 run_lib.py:146] step: 256000, eval_loss: 4.27044e-02
I0211 00:31:32.315579 22509476222784 run_lib.py:133] step: 256050, training_loss: 4.45163e-02
I0211 00:31:50.714514 22509476222784 run_lib.py:133] step: 256100, training_loss: 3.80514e-02
I0211 00:31:50.877380 22509476222784 run_lib.py:146] step: 256100, eval_loss: 5.14866e-02
I0211 00:32:09.426105 22509476222784 run_lib.py:133] step: 256150, training_loss: 4.81412e-02
I0211 00:32:27.791810 22509476222784 run_lib.py:133] step: 256200, training_loss: 4.42988e-02
I0211 00:32:27.952368 22509476222784 run_lib.py:146] step: 256200, eval_loss: 4.83895e-02
I0211 00:32:46.537453 22509476222784 run_lib.py:133] step: 256250, training_loss: 5.56247e-02
I0211 00:33:04.960955 22509476222784 run_lib.py:133] step: 256300, training_loss: 4.97920e-02
I0211 00:33:05.122290 22509476222784 run_lib.py:146] step: 256300, eval_loss: 5.11071e-02
I0211 00:33:23.763520 22509476222784 run_lib.py:133] step: 256350, training_loss: 4.27215e-02
I0211 00:33:42.315700 22509476222784 run_lib.py:133] step: 256400, training_loss: 4.34493e-02
I0211 00:33:42.491698 22509476222784 run_lib.py:146] step: 256400, eval_loss: 4.63802e-02
I0211 00:34:01.233541 22509476222784 run_lib.py:133] step: 256450, training_loss: 2.76864e-02
I0211 00:34:19.725964 22509476222784 run_lib.py:133] step: 256500, training_loss: 4.65182e-02
I0211 00:34:19.890687 22509476222784 run_lib.py:146] step: 256500, eval_loss: 5.18485e-02
I0211 00:34:38.375756 22509476222784 run_lib.py:133] step: 256550, training_loss: 3.91119e-02
I0211 00:34:57.023229 22509476222784 run_lib.py:133] step: 256600, training_loss: 4.49570e-02
I0211 00:34:57.188884 22509476222784 run_lib.py:146] step: 256600, eval_loss: 3.73862e-02
I0211 00:35:15.690890 22509476222784 run_lib.py:133] step: 256650, training_loss: 3.91324e-02
I0211 00:35:34.129233 22509476222784 run_lib.py:133] step: 256700, training_loss: 4.59695e-02
I0211 00:35:34.289603 22509476222784 run_lib.py:146] step: 256700, eval_loss: 4.62325e-02
I0211 00:35:53.016036 22509476222784 run_lib.py:133] step: 256750, training_loss: 4.75069e-02
I0211 00:36:11.508013 22509476222784 run_lib.py:133] step: 256800, training_loss: 3.69976e-02
I0211 00:36:11.686501 22509476222784 run_lib.py:146] step: 256800, eval_loss: 4.80994e-02
I0211 00:36:30.283922 22509476222784 run_lib.py:133] step: 256850, training_loss: 4.97320e-02
I0211 00:36:48.824454 22509476222784 run_lib.py:133] step: 256900, training_loss: 5.00238e-02
I0211 00:36:49.001590 22509476222784 run_lib.py:146] step: 256900, eval_loss: 2.96375e-02
I0211 00:37:07.525287 22509476222784 run_lib.py:133] step: 256950, training_loss: 3.83994e-02
I0211 00:37:26.254689 22509476222784 run_lib.py:133] step: 257000, training_loss: 5.54868e-02
I0211 00:37:26.441913 22509476222784 run_lib.py:146] step: 257000, eval_loss: 4.94120e-02
I0211 00:37:44.959189 22509476222784 run_lib.py:133] step: 257050, training_loss: 3.43258e-02
I0211 00:38:03.404940 22509476222784 run_lib.py:133] step: 257100, training_loss: 5.02844e-02
I0211 00:38:03.565206 22509476222784 run_lib.py:146] step: 257100, eval_loss: 4.51527e-02
I0211 00:38:22.032077 22509476222784 run_lib.py:133] step: 257150, training_loss: 5.53143e-02
I0211 00:38:40.704533 22509476222784 run_lib.py:133] step: 257200, training_loss: 4.84339e-02
I0211 00:38:40.879585 22509476222784 run_lib.py:146] step: 257200, eval_loss: 3.78876e-02
I0211 00:38:59.346449 22509476222784 run_lib.py:133] step: 257250, training_loss: 4.69734e-02
I0211 00:39:17.937660 22509476222784 run_lib.py:133] step: 257300, training_loss: 4.21574e-02
I0211 00:39:18.103758 22509476222784 run_lib.py:146] step: 257300, eval_loss: 4.08887e-02
I0211 00:39:36.570114 22509476222784 run_lib.py:133] step: 257350, training_loss: 3.93202e-02
I0211 00:39:55.076670 22509476222784 run_lib.py:133] step: 257400, training_loss: 2.99344e-02
I0211 00:39:55.240643 22509476222784 run_lib.py:146] step: 257400, eval_loss: 5.04854e-02
I0211 00:40:13.918157 22509476222784 run_lib.py:133] step: 257450, training_loss: 5.73816e-02
I0211 00:40:32.583920 22509476222784 run_lib.py:133] step: 257500, training_loss: 5.92354e-02
I0211 00:40:32.751071 22509476222784 run_lib.py:146] step: 257500, eval_loss: 4.00096e-02
I0211 00:40:51.298405 22509476222784 run_lib.py:133] step: 257550, training_loss: 4.50781e-02
I0211 00:41:09.767547 22509476222784 run_lib.py:133] step: 257600, training_loss: 5.24875e-02
I0211 00:41:09.927497 22509476222784 run_lib.py:146] step: 257600, eval_loss: 5.28974e-02
I0211 00:41:28.492483 22509476222784 run_lib.py:133] step: 257650, training_loss: 4.62844e-02
I0211 00:41:46.990719 22509476222784 run_lib.py:133] step: 257700, training_loss: 3.81786e-02
I0211 00:41:47.153839 22509476222784 run_lib.py:146] step: 257700, eval_loss: 3.65230e-02
I0211 00:42:05.849328 22509476222784 run_lib.py:133] step: 257750, training_loss: 4.21424e-02
I0211 00:42:24.412334 22509476222784 run_lib.py:133] step: 257800, training_loss: 4.35741e-02
I0211 00:42:24.578871 22509476222784 run_lib.py:146] step: 257800, eval_loss: 3.91313e-02
I0211 00:42:43.203236 22509476222784 run_lib.py:133] step: 257850, training_loss: 5.05621e-02
I0211 00:43:01.700997 22509476222784 run_lib.py:133] step: 257900, training_loss: 4.50641e-02
I0211 00:43:01.870729 22509476222784 run_lib.py:146] step: 257900, eval_loss: 4.76118e-02
I0211 00:43:20.361162 22509476222784 run_lib.py:133] step: 257950, training_loss: 4.02277e-02
I0211 00:43:39.063129 22509476222784 run_lib.py:133] step: 258000, training_loss: 4.96554e-02
I0211 00:43:39.231064 22509476222784 run_lib.py:146] step: 258000, eval_loss: 4.45541e-02
I0211 00:43:57.783900 22509476222784 run_lib.py:133] step: 258050, training_loss: 4.56711e-02
I0211 00:44:16.414804 22509476222784 run_lib.py:133] step: 258100, training_loss: 5.30873e-02
I0211 00:44:16.575313 22509476222784 run_lib.py:146] step: 258100, eval_loss: 4.57916e-02
I0211 00:44:35.081928 22509476222784 run_lib.py:133] step: 258150, training_loss: 5.12626e-02
I0211 00:44:53.583371 22509476222784 run_lib.py:133] step: 258200, training_loss: 5.08246e-02
I0211 00:44:53.755744 22509476222784 run_lib.py:146] step: 258200, eval_loss: 3.29134e-02
I0211 00:45:12.445543 22509476222784 run_lib.py:133] step: 258250, training_loss: 4.89898e-02
I0211 00:45:30.964842 22509476222784 run_lib.py:133] step: 258300, training_loss: 4.34779e-02
I0211 00:45:31.130206 22509476222784 run_lib.py:146] step: 258300, eval_loss: 4.65807e-02
I0211 00:45:49.606134 22509476222784 run_lib.py:133] step: 258350, training_loss: 3.60962e-02
I0211 00:46:08.215506 22509476222784 run_lib.py:133] step: 258400, training_loss: 5.50156e-02
I0211 00:46:08.413545 22509476222784 run_lib.py:146] step: 258400, eval_loss: 3.39087e-02
I0211 00:46:26.872677 22509476222784 run_lib.py:133] step: 258450, training_loss: 4.43514e-02
I0211 00:46:45.399295 22509476222784 run_lib.py:133] step: 258500, training_loss: 5.34759e-02
I0211 00:46:45.712780 22509476222784 run_lib.py:146] step: 258500, eval_loss: 5.90793e-02
I0211 00:47:04.276209 22509476222784 run_lib.py:133] step: 258550, training_loss: 5.30453e-02
I0211 00:47:22.753157 22509476222784 run_lib.py:133] step: 258600, training_loss: 4.08711e-02
I0211 00:47:22.914650 22509476222784 run_lib.py:146] step: 258600, eval_loss: 3.93477e-02
I0211 00:47:41.429235 22509476222784 run_lib.py:133] step: 258650, training_loss: 4.51935e-02
I0211 00:47:59.904648 22509476222784 run_lib.py:133] step: 258700, training_loss: 4.05604e-02
I0211 00:48:00.073339 22509476222784 run_lib.py:146] step: 258700, eval_loss: 3.82493e-02
I0211 00:48:18.788800 22509476222784 run_lib.py:133] step: 258750, training_loss: 4.30601e-02
I0211 00:48:37.339102 22509476222784 run_lib.py:133] step: 258800, training_loss: 5.56574e-02
I0211 00:48:37.519618 22509476222784 run_lib.py:146] step: 258800, eval_loss: 4.22450e-02
I0211 00:48:56.025440 22509476222784 run_lib.py:133] step: 258850, training_loss: 5.15724e-02
I0211 00:49:14.557953 22509476222784 run_lib.py:133] step: 258900, training_loss: 5.61507e-02
I0211 00:49:14.721827 22509476222784 run_lib.py:146] step: 258900, eval_loss: 4.04045e-02
I0211 00:49:33.436429 22509476222784 run_lib.py:133] step: 258950, training_loss: 4.10764e-02
I0211 00:49:51.972728 22509476222784 run_lib.py:133] step: 259000, training_loss: 3.13349e-02
I0211 00:49:52.183604 22509476222784 run_lib.py:146] step: 259000, eval_loss: 3.95529e-02
I0211 00:50:10.695716 22509476222784 run_lib.py:133] step: 259050, training_loss: 4.86050e-02
I0211 00:50:29.187918 22509476222784 run_lib.py:133] step: 259100, training_loss: 4.59684e-02
I0211 00:50:29.352815 22509476222784 run_lib.py:146] step: 259100, eval_loss: 4.08137e-02
I0211 00:50:48.070389 22509476222784 run_lib.py:133] step: 259150, training_loss: 3.34090e-02
I0211 00:51:06.556451 22509476222784 run_lib.py:133] step: 259200, training_loss: 4.00144e-02
I0211 00:51:06.720709 22509476222784 run_lib.py:146] step: 259200, eval_loss: 3.91509e-02
I0211 00:51:25.327601 22509476222784 run_lib.py:133] step: 259250, training_loss: 3.71553e-02
I0211 00:51:43.851960 22509476222784 run_lib.py:133] step: 259300, training_loss: 3.90909e-02
I0211 00:51:44.014698 22509476222784 run_lib.py:146] step: 259300, eval_loss: 3.81640e-02
I0211 00:52:02.705152 22509476222784 run_lib.py:133] step: 259350, training_loss: 3.65158e-02
I0211 00:52:21.200133 22509476222784 run_lib.py:133] step: 259400, training_loss: 4.78665e-02
I0211 00:52:21.365018 22509476222784 run_lib.py:146] step: 259400, eval_loss: 3.68567e-02
I0211 00:52:39.832113 22509476222784 run_lib.py:133] step: 259450, training_loss: 4.08643e-02
I0211 00:52:58.487837 22509476222784 run_lib.py:133] step: 259500, training_loss: 3.71441e-02
I0211 00:52:58.692650 22509476222784 run_lib.py:146] step: 259500, eval_loss: 4.16086e-02
I0211 00:53:17.213473 22509476222784 run_lib.py:133] step: 259550, training_loss: 5.45286e-02
I0211 00:53:35.860288 22509476222784 run_lib.py:133] step: 259600, training_loss: 3.47760e-02
I0211 00:53:36.054713 22509476222784 run_lib.py:146] step: 259600, eval_loss: 3.92311e-02
I0211 00:53:54.613481 22509476222784 run_lib.py:133] step: 259650, training_loss: 4.72544e-02
I0211 00:54:13.137369 22509476222784 run_lib.py:133] step: 259700, training_loss: 4.04274e-02
I0211 00:54:13.302568 22509476222784 run_lib.py:146] step: 259700, eval_loss: 4.04276e-02
I0211 00:54:31.779675 22509476222784 run_lib.py:133] step: 259750, training_loss: 4.57028e-02
I0211 00:54:50.385818 22509476222784 run_lib.py:133] step: 259800, training_loss: 3.43965e-02
I0211 00:54:50.549685 22509476222784 run_lib.py:146] step: 259800, eval_loss: 4.78848e-02
I0211 00:55:08.985656 22509476222784 run_lib.py:133] step: 259850, training_loss: 3.42208e-02
I0211 00:55:27.555457 22509476222784 run_lib.py:133] step: 259900, training_loss: 4.27378e-02
I0211 00:55:27.760000 22509476222784 run_lib.py:146] step: 259900, eval_loss: 4.27658e-02
I0211 00:55:46.500493 22509476222784 run_lib.py:133] step: 259950, training_loss: 4.60168e-02
I0211 00:56:04.971102 22509476222784 run_lib.py:133] step: 260000, training_loss: 5.87147e-02
I0211 00:56:06.066532 22509476222784 run_lib.py:146] step: 260000, eval_loss: 3.70698e-02
I0211 00:56:27.722937 22509476222784 run_lib.py:133] step: 260050, training_loss: 5.38048e-02
I0211 00:56:46.256301 22509476222784 run_lib.py:133] step: 260100, training_loss: 2.97581e-02
I0211 00:56:46.416839 22509476222784 run_lib.py:146] step: 260100, eval_loss: 5.05957e-02
I0211 00:57:04.930371 22509476222784 run_lib.py:133] step: 260150, training_loss: 4.40838e-02
I0211 00:57:23.590049 22509476222784 run_lib.py:133] step: 260200, training_loss: 3.26610e-02
I0211 00:57:23.754689 22509476222784 run_lib.py:146] step: 260200, eval_loss: 3.99445e-02
I0211 00:57:42.281177 22509476222784 run_lib.py:133] step: 260250, training_loss: 5.74678e-02
I0211 00:58:00.747627 22509476222784 run_lib.py:133] step: 260300, training_loss: 4.66091e-02
I0211 00:58:01.053658 22509476222784 run_lib.py:146] step: 260300, eval_loss: 4.25456e-02
I0211 00:58:19.499545 22509476222784 run_lib.py:133] step: 260350, training_loss: 5.27111e-02
I0211 00:58:38.010021 22509476222784 run_lib.py:133] step: 260400, training_loss: 3.64463e-02
I0211 00:58:38.177622 22509476222784 run_lib.py:146] step: 260400, eval_loss: 3.69356e-02
I0211 00:58:56.750214 22509476222784 run_lib.py:133] step: 260450, training_loss: 4.11672e-02
I0211 00:59:15.303491 22509476222784 run_lib.py:133] step: 260500, training_loss: 5.20553e-02
I0211 00:59:15.466589 22509476222784 run_lib.py:146] step: 260500, eval_loss: 3.75815e-02
I0211 00:59:34.161135 22509476222784 run_lib.py:133] step: 260550, training_loss: 4.75644e-02
I0211 00:59:52.722401 22509476222784 run_lib.py:133] step: 260600, training_loss: 3.46815e-02
I0211 00:59:52.883628 22509476222784 run_lib.py:146] step: 260600, eval_loss: 2.58662e-02
I0211 01:00:11.355870 22509476222784 run_lib.py:133] step: 260650, training_loss: 3.58366e-02
I0211 01:00:29.895494 22509476222784 run_lib.py:133] step: 260700, training_loss: 3.04672e-02
I0211 01:00:30.075673 22509476222784 run_lib.py:146] step: 260700, eval_loss: 4.24541e-02
I0211 01:00:48.745587 22509476222784 run_lib.py:133] step: 260750, training_loss: 2.83291e-02
I0211 01:01:07.335424 22509476222784 run_lib.py:133] step: 260800, training_loss: 4.47023e-02
I0211 01:01:07.504694 22509476222784 run_lib.py:146] step: 260800, eval_loss: 3.88597e-02
I0211 01:01:26.023574 22509476222784 run_lib.py:133] step: 260850, training_loss: 4.41269e-02
I0211 01:01:44.498235 22509476222784 run_lib.py:133] step: 260900, training_loss: 3.95958e-02
I0211 01:01:44.656828 22509476222784 run_lib.py:146] step: 260900, eval_loss: 4.77392e-02
I0211 01:02:03.394618 22509476222784 run_lib.py:133] step: 260950, training_loss: 4.94454e-02
I0211 01:02:21.956140 22509476222784 run_lib.py:133] step: 261000, training_loss: 4.96347e-02
I0211 01:02:22.122270 22509476222784 run_lib.py:146] step: 261000, eval_loss: 3.86358e-02
I0211 01:02:40.779855 22509476222784 run_lib.py:133] step: 261050, training_loss: 3.64883e-02
I0211 01:02:59.283350 22509476222784 run_lib.py:133] step: 261100, training_loss: 4.67697e-02
I0211 01:02:59.445447 22509476222784 run_lib.py:146] step: 261100, eval_loss: 3.33310e-02
I0211 01:03:18.078642 22509476222784 run_lib.py:133] step: 261150, training_loss: 3.50608e-02
I0211 01:03:36.621637 22509476222784 run_lib.py:133] step: 261200, training_loss: 4.38721e-02
I0211 01:03:36.804598 22509476222784 run_lib.py:146] step: 261200, eval_loss: 4.99648e-02
I0211 01:03:55.329252 22509476222784 run_lib.py:133] step: 261250, training_loss: 4.04194e-02
I0211 01:04:13.990248 22509476222784 run_lib.py:133] step: 261300, training_loss: 3.35180e-02
I0211 01:04:14.153674 22509476222784 run_lib.py:146] step: 261300, eval_loss: 4.75891e-02
I0211 01:04:32.643341 22509476222784 run_lib.py:133] step: 261350, training_loss: 4.39562e-02
I0211 01:04:51.224586 22509476222784 run_lib.py:133] step: 261400, training_loss: 4.66523e-02
I0211 01:04:51.390480 22509476222784 run_lib.py:146] step: 261400, eval_loss: 5.54357e-02
I0211 01:05:09.848681 22509476222784 run_lib.py:133] step: 261450, training_loss: 4.21668e-02
I0211 01:05:28.393654 22509476222784 run_lib.py:133] step: 261500, training_loss: 3.76863e-02
I0211 01:05:28.560020 22509476222784 run_lib.py:146] step: 261500, eval_loss: 4.19903e-02
I0211 01:05:47.247717 22509476222784 run_lib.py:133] step: 261550, training_loss: 3.75164e-02
I0211 01:06:05.985854 22509476222784 run_lib.py:133] step: 261600, training_loss: 4.05049e-02
I0211 01:06:06.155607 22509476222784 run_lib.py:146] step: 261600, eval_loss: 4.39581e-02
I0211 01:06:24.628737 22509476222784 run_lib.py:133] step: 261650, training_loss: 3.33290e-02
I0211 01:06:43.150698 22509476222784 run_lib.py:133] step: 261700, training_loss: 4.30234e-02
I0211 01:06:43.315822 22509476222784 run_lib.py:146] step: 261700, eval_loss: 4.55699e-02
I0211 01:07:01.984519 22509476222784 run_lib.py:133] step: 261750, training_loss: 4.55135e-02
I0211 01:07:20.561027 22509476222784 run_lib.py:133] step: 261800, training_loss: 3.50469e-02
I0211 01:07:20.725752 22509476222784 run_lib.py:146] step: 261800, eval_loss: 4.63168e-02
I0211 01:07:39.353106 22509476222784 run_lib.py:133] step: 261850, training_loss: 4.17091e-02
I0211 01:07:57.744455 22509476222784 run_lib.py:133] step: 261900, training_loss: 3.22168e-02
I0211 01:07:57.906458 22509476222784 run_lib.py:146] step: 261900, eval_loss: 4.69940e-02
I0211 01:08:16.313462 22509476222784 run_lib.py:133] step: 261950, training_loss: 3.82910e-02
I0211 01:08:34.826604 22509476222784 run_lib.py:133] step: 262000, training_loss: 3.87440e-02
I0211 01:08:34.995319 22509476222784 run_lib.py:146] step: 262000, eval_loss: 4.55913e-02
I0211 01:08:53.714860 22509476222784 run_lib.py:133] step: 262050, training_loss: 4.28464e-02
I0211 01:09:12.311060 22509476222784 run_lib.py:133] step: 262100, training_loss: 4.55459e-02
I0211 01:09:12.475591 22509476222784 run_lib.py:146] step: 262100, eval_loss: 4.37669e-02
I0211 01:09:30.913047 22509476222784 run_lib.py:133] step: 262150, training_loss: 3.61756e-02
I0211 01:09:49.374654 22509476222784 run_lib.py:133] step: 262200, training_loss: 4.98539e-02
I0211 01:09:49.539850 22509476222784 run_lib.py:146] step: 262200, eval_loss: 3.96409e-02
I0211 01:10:08.124989 22509476222784 run_lib.py:133] step: 262250, training_loss: 5.01270e-02
I0211 01:10:26.672521 22509476222784 run_lib.py:133] step: 262300, training_loss: 4.11312e-02
I0211 01:10:26.867382 22509476222784 run_lib.py:146] step: 262300, eval_loss: 3.84226e-02
I0211 01:10:45.523733 22509476222784 run_lib.py:133] step: 262350, training_loss: 4.86406e-02
I0211 01:11:04.038742 22509476222784 run_lib.py:133] step: 262400, training_loss: 4.31241e-02
I0211 01:11:04.201902 22509476222784 run_lib.py:146] step: 262400, eval_loss: 3.78998e-02
I0211 01:11:22.912599 22509476222784 run_lib.py:133] step: 262450, training_loss: 4.07197e-02
I0211 01:11:41.405377 22509476222784 run_lib.py:133] step: 262500, training_loss: 4.81137e-02
I0211 01:11:41.567626 22509476222784 run_lib.py:146] step: 262500, eval_loss: 4.56641e-02
I0211 01:12:00.130822 22509476222784 run_lib.py:133] step: 262550, training_loss: 5.46352e-02
I0211 01:12:18.627031 22509476222784 run_lib.py:133] step: 262600, training_loss: 4.10840e-02
I0211 01:12:18.806594 22509476222784 run_lib.py:146] step: 262600, eval_loss: 5.08209e-02
I0211 01:12:37.357732 22509476222784 run_lib.py:133] step: 262650, training_loss: 5.24814e-02
I0211 01:12:56.098159 22509476222784 run_lib.py:133] step: 262700, training_loss: 4.73141e-02
I0211 01:12:56.262743 22509476222784 run_lib.py:146] step: 262700, eval_loss: 4.14639e-02
I0211 01:13:14.720858 22509476222784 run_lib.py:133] step: 262750, training_loss: 4.20910e-02
I0211 01:13:33.154996 22509476222784 run_lib.py:133] step: 262800, training_loss: 3.80058e-02
I0211 01:13:33.314137 22509476222784 run_lib.py:146] step: 262800, eval_loss: 4.81573e-02
I0211 01:13:51.920199 22509476222784 run_lib.py:133] step: 262850, training_loss: 4.80832e-02
I0211 01:14:10.597178 22509476222784 run_lib.py:133] step: 262900, training_loss: 3.70996e-02
I0211 01:14:10.758816 22509476222784 run_lib.py:146] step: 262900, eval_loss: 4.22092e-02
I0211 01:14:29.300464 22509476222784 run_lib.py:133] step: 262950, training_loss: 4.83132e-02
I0211 01:14:47.773921 22509476222784 run_lib.py:133] step: 263000, training_loss: 3.48791e-02
I0211 01:14:47.945517 22509476222784 run_lib.py:146] step: 263000, eval_loss: 3.48052e-02
I0211 01:15:06.450098 22509476222784 run_lib.py:133] step: 263050, training_loss: 3.41132e-02
I0211 01:15:25.024654 22509476222784 run_lib.py:133] step: 263100, training_loss: 3.82597e-02
I0211 01:15:25.196520 22509476222784 run_lib.py:146] step: 263100, eval_loss: 4.16520e-02
I0211 01:15:43.704102 22509476222784 run_lib.py:133] step: 263150, training_loss: 4.16416e-02
I0211 01:16:02.232532 22509476222784 run_lib.py:133] step: 263200, training_loss: 4.52893e-02
I0211 01:16:02.411734 22509476222784 run_lib.py:146] step: 263200, eval_loss: 3.91490e-02
I0211 01:16:20.936647 22509476222784 run_lib.py:133] step: 263250, training_loss: 4.76777e-02
I0211 01:16:39.543558 22509476222784 run_lib.py:133] step: 263300, training_loss: 4.08892e-02
I0211 01:16:39.705234 22509476222784 run_lib.py:146] step: 263300, eval_loss: 4.33112e-02
I0211 01:16:58.135751 22509476222784 run_lib.py:133] step: 263350, training_loss: 2.75715e-02
I0211 01:17:16.755989 22509476222784 run_lib.py:133] step: 263400, training_loss: 4.83084e-02
I0211 01:17:16.918902 22509476222784 run_lib.py:146] step: 263400, eval_loss: 3.62389e-02
I0211 01:17:35.531133 22509476222784 run_lib.py:133] step: 263450, training_loss: 4.92526e-02
I0211 01:17:54.041057 22509476222784 run_lib.py:133] step: 263500, training_loss: 4.55567e-02
I0211 01:17:54.210654 22509476222784 run_lib.py:146] step: 263500, eval_loss: 3.75760e-02
I0211 01:18:12.896973 22509476222784 run_lib.py:133] step: 263550, training_loss: 3.62757e-02
I0211 01:18:31.435091 22509476222784 run_lib.py:133] step: 263600, training_loss: 4.75027e-02
I0211 01:18:31.598005 22509476222784 run_lib.py:146] step: 263600, eval_loss: 5.64942e-02
I0211 01:18:50.126907 22509476222784 run_lib.py:133] step: 263650, training_loss: 4.90029e-02
I0211 01:19:08.666287 22509476222784 run_lib.py:133] step: 263700, training_loss: 5.46375e-02
I0211 01:19:08.865925 22509476222784 run_lib.py:146] step: 263700, eval_loss: 5.76767e-02
I0211 01:19:27.535475 22509476222784 run_lib.py:133] step: 263750, training_loss: 3.58352e-02
I0211 01:19:46.057825 22509476222784 run_lib.py:133] step: 263800, training_loss: 4.87216e-02
I0211 01:19:46.258562 22509476222784 run_lib.py:146] step: 263800, eval_loss: 4.66089e-02
I0211 01:20:04.925722 22509476222784 run_lib.py:133] step: 263850, training_loss: 3.45876e-02
I0211 01:20:23.414289 22509476222784 run_lib.py:133] step: 263900, training_loss: 5.20703e-02
I0211 01:20:23.577946 22509476222784 run_lib.py:146] step: 263900, eval_loss: 3.10053e-02
I0211 01:20:42.348282 22509476222784 run_lib.py:133] step: 263950, training_loss: 4.83080e-02
I0211 01:21:00.853957 22509476222784 run_lib.py:133] step: 264000, training_loss: 4.44528e-02
I0211 01:21:01.049662 22509476222784 run_lib.py:146] step: 264000, eval_loss: 4.71034e-02
I0211 01:21:19.526136 22509476222784 run_lib.py:133] step: 264050, training_loss: 4.04388e-02
I0211 01:21:38.141073 22509476222784 run_lib.py:133] step: 264100, training_loss: 3.85939e-02
I0211 01:21:38.314707 22509476222784 run_lib.py:146] step: 264100, eval_loss: 4.86444e-02
I0211 01:21:56.793927 22509476222784 run_lib.py:133] step: 264150, training_loss: 5.25231e-02
I0211 01:22:15.497745 22509476222784 run_lib.py:133] step: 264200, training_loss: 2.83740e-02
I0211 01:22:15.689278 22509476222784 run_lib.py:146] step: 264200, eval_loss: 4.12653e-02
I0211 01:22:34.237455 22509476222784 run_lib.py:133] step: 264250, training_loss: 3.72549e-02
I0211 01:22:52.769574 22509476222784 run_lib.py:133] step: 264300, training_loss: 4.77726e-02
I0211 01:22:52.932636 22509476222784 run_lib.py:146] step: 264300, eval_loss: 4.67102e-02
I0211 01:23:11.624074 22509476222784 run_lib.py:133] step: 264350, training_loss: 4.27622e-02
I0211 01:23:30.162510 22509476222784 run_lib.py:133] step: 264400, training_loss: 3.70438e-02
I0211 01:23:30.323528 22509476222784 run_lib.py:146] step: 264400, eval_loss: 3.19457e-02
I0211 01:23:48.710169 22509476222784 run_lib.py:133] step: 264450, training_loss: 4.67228e-02
I0211 01:24:07.273017 22509476222784 run_lib.py:133] step: 264500, training_loss: 4.76274e-02
I0211 01:24:07.452527 22509476222784 run_lib.py:146] step: 264500, eval_loss: 4.24702e-02
I0211 01:24:25.950981 22509476222784 run_lib.py:133] step: 264550, training_loss: 4.09152e-02
I0211 01:24:44.452950 22509476222784 run_lib.py:133] step: 264600, training_loss: 4.26061e-02
I0211 01:24:44.616918 22509476222784 run_lib.py:146] step: 264600, eval_loss: 4.46262e-02
I0211 01:25:03.218048 22509476222784 run_lib.py:133] step: 264650, training_loss: 4.48027e-02
I0211 01:25:21.714759 22509476222784 run_lib.py:133] step: 264700, training_loss: 4.35121e-02
I0211 01:25:21.877406 22509476222784 run_lib.py:146] step: 264700, eval_loss: 4.40842e-02
I0211 01:25:40.296826 22509476222784 run_lib.py:133] step: 264750, training_loss: 4.95501e-02
I0211 01:25:58.897091 22509476222784 run_lib.py:133] step: 264800, training_loss: 4.07357e-02
I0211 01:25:59.134331 22509476222784 run_lib.py:146] step: 264800, eval_loss: 4.49534e-02
I0211 01:26:17.862768 22509476222784 run_lib.py:133] step: 264850, training_loss: 3.59506e-02
I0211 01:26:36.432020 22509476222784 run_lib.py:133] step: 264900, training_loss: 3.45471e-02
I0211 01:26:36.629614 22509476222784 run_lib.py:146] step: 264900, eval_loss: 5.32469e-02
I0211 01:26:55.096605 22509476222784 run_lib.py:133] step: 264950, training_loss: 4.47349e-02
I0211 01:27:13.574287 22509476222784 run_lib.py:133] step: 265000, training_loss: 3.87766e-02
I0211 01:27:13.783844 22509476222784 run_lib.py:146] step: 265000, eval_loss: 3.82088e-02
I0211 01:27:32.423336 22509476222784 run_lib.py:133] step: 265050, training_loss: 3.75159e-02
I0211 01:27:50.850003 22509476222784 run_lib.py:133] step: 265100, training_loss: 4.38991e-02
I0211 01:27:51.016875 22509476222784 run_lib.py:146] step: 265100, eval_loss: 5.13286e-02
I0211 01:28:09.615576 22509476222784 run_lib.py:133] step: 265150, training_loss: 4.77994e-02
I0211 01:28:28.121788 22509476222784 run_lib.py:133] step: 265200, training_loss: 5.30335e-02
I0211 01:28:28.317639 22509476222784 run_lib.py:146] step: 265200, eval_loss: 3.27169e-02
I0211 01:28:46.982552 22509476222784 run_lib.py:133] step: 265250, training_loss: 5.13899e-02
I0211 01:29:05.530148 22509476222784 run_lib.py:133] step: 265300, training_loss: 4.44669e-02
I0211 01:29:05.713660 22509476222784 run_lib.py:146] step: 265300, eval_loss: 3.45740e-02
I0211 01:29:24.291582 22509476222784 run_lib.py:133] step: 265350, training_loss: 4.02491e-02
I0211 01:29:42.876291 22509476222784 run_lib.py:133] step: 265400, training_loss: 5.43709e-02
I0211 01:29:43.074745 22509476222784 run_lib.py:146] step: 265400, eval_loss: 3.80627e-02
I0211 01:30:01.567850 22509476222784 run_lib.py:133] step: 265450, training_loss: 5.53871e-02
I0211 01:30:20.252742 22509476222784 run_lib.py:133] step: 265500, training_loss: 4.55259e-02
I0211 01:30:20.418834 22509476222784 run_lib.py:146] step: 265500, eval_loss: 3.08600e-02
I0211 01:30:38.884042 22509476222784 run_lib.py:133] step: 265550, training_loss: 3.37174e-02
I0211 01:30:57.356464 22509476222784 run_lib.py:133] step: 265600, training_loss: 4.00986e-02
I0211 01:30:57.530612 22509476222784 run_lib.py:146] step: 265600, eval_loss: 4.73680e-02
I0211 01:31:16.174249 22509476222784 run_lib.py:133] step: 265650, training_loss: 4.00951e-02
I0211 01:31:34.603974 22509476222784 run_lib.py:133] step: 265700, training_loss: 4.80969e-02
I0211 01:31:34.771814 22509476222784 run_lib.py:146] step: 265700, eval_loss: 3.71285e-02
I0211 01:31:53.531822 22509476222784 run_lib.py:133] step: 265750, training_loss: 4.19232e-02
I0211 01:32:12.111166 22509476222784 run_lib.py:133] step: 265800, training_loss: 5.40086e-02
I0211 01:32:12.272783 22509476222784 run_lib.py:146] step: 265800, eval_loss: 4.42263e-02
I0211 01:32:30.779779 22509476222784 run_lib.py:133] step: 265850, training_loss: 3.40911e-02
I0211 01:32:49.448220 22509476222784 run_lib.py:133] step: 265900, training_loss: 3.91464e-02
I0211 01:32:49.629693 22509476222784 run_lib.py:146] step: 265900, eval_loss: 5.01898e-02
I0211 01:33:08.139754 22509476222784 run_lib.py:133] step: 265950, training_loss: 4.24688e-02
I0211 01:33:26.678400 22509476222784 run_lib.py:133] step: 266000, training_loss: 4.66930e-02
I0211 01:33:26.843581 22509476222784 run_lib.py:146] step: 266000, eval_loss: 5.72038e-02
I0211 01:33:45.349367 22509476222784 run_lib.py:133] step: 266050, training_loss: 4.73062e-02
I0211 01:34:03.977395 22509476222784 run_lib.py:133] step: 266100, training_loss: 4.84671e-02
I0211 01:34:04.141618 22509476222784 run_lib.py:146] step: 266100, eval_loss: 3.24156e-02
I0211 01:34:22.597261 22509476222784 run_lib.py:133] step: 266150, training_loss: 3.91457e-02
I0211 01:34:41.211110 22509476222784 run_lib.py:133] step: 266200, training_loss: 3.57195e-02
I0211 01:34:41.375457 22509476222784 run_lib.py:146] step: 266200, eval_loss: 4.00153e-02
I0211 01:34:59.892647 22509476222784 run_lib.py:133] step: 266250, training_loss: 4.04363e-02
I0211 01:35:18.395717 22509476222784 run_lib.py:133] step: 266300, training_loss: 4.69929e-02
I0211 01:35:18.587581 22509476222784 run_lib.py:146] step: 266300, eval_loss: 5.59200e-02
I0211 01:35:37.300864 22509476222784 run_lib.py:133] step: 266350, training_loss: 4.38088e-02
I0211 01:35:55.903810 22509476222784 run_lib.py:133] step: 266400, training_loss: 3.83751e-02
I0211 01:35:56.077796 22509476222784 run_lib.py:146] step: 266400, eval_loss: 4.80391e-02
I0211 01:36:14.598373 22509476222784 run_lib.py:133] step: 266450, training_loss: 3.51944e-02
I0211 01:36:33.172565 22509476222784 run_lib.py:133] step: 266500, training_loss: 3.76846e-02
I0211 01:36:33.346938 22509476222784 run_lib.py:146] step: 266500, eval_loss: 4.82169e-02
I0211 01:36:51.970422 22509476222784 run_lib.py:133] step: 266550, training_loss: 4.72794e-02
I0211 01:37:10.391968 22509476222784 run_lib.py:133] step: 266600, training_loss: 3.57835e-02
I0211 01:37:10.554728 22509476222784 run_lib.py:146] step: 266600, eval_loss: 3.93453e-02
I0211 01:37:29.166864 22509476222784 run_lib.py:133] step: 266650, training_loss: 3.33797e-02
I0211 01:37:47.693084 22509476222784 run_lib.py:133] step: 266700, training_loss: 5.40480e-02
I0211 01:37:47.852599 22509476222784 run_lib.py:146] step: 266700, eval_loss: 4.65141e-02
I0211 01:38:06.583855 22509476222784 run_lib.py:133] step: 266750, training_loss: 3.82803e-02
I0211 01:38:25.154953 22509476222784 run_lib.py:133] step: 266800, training_loss: 4.58878e-02
I0211 01:38:25.324800 22509476222784 run_lib.py:146] step: 266800, eval_loss: 3.79218e-02
I0211 01:38:43.768056 22509476222784 run_lib.py:133] step: 266850, training_loss: 4.16295e-02
I0211 01:39:02.438821 22509476222784 run_lib.py:133] step: 266900, training_loss: 4.23439e-02
I0211 01:39:02.603784 22509476222784 run_lib.py:146] step: 266900, eval_loss: 5.11151e-02
I0211 01:39:21.100976 22509476222784 run_lib.py:133] step: 266950, training_loss: 4.80041e-02
I0211 01:39:39.745435 22509476222784 run_lib.py:133] step: 267000, training_loss: 3.81589e-02
I0211 01:39:39.915929 22509476222784 run_lib.py:146] step: 267000, eval_loss: 5.32334e-02
I0211 01:39:58.443395 22509476222784 run_lib.py:133] step: 267050, training_loss: 3.33311e-02
I0211 01:40:16.896144 22509476222784 run_lib.py:133] step: 267100, training_loss: 4.25755e-02
I0211 01:40:17.058812 22509476222784 run_lib.py:146] step: 267100, eval_loss: 4.84386e-02
I0211 01:40:35.760330 22509476222784 run_lib.py:133] step: 267150, training_loss: 3.80919e-02
I0211 01:40:54.249824 22509476222784 run_lib.py:133] step: 267200, training_loss: 4.66854e-02
I0211 01:40:54.411744 22509476222784 run_lib.py:146] step: 267200, eval_loss: 3.49362e-02
I0211 01:41:12.893899 22509476222784 run_lib.py:133] step: 267250, training_loss: 3.44046e-02
I0211 01:41:31.473038 22509476222784 run_lib.py:133] step: 267300, training_loss: 4.67329e-02
I0211 01:41:31.646658 22509476222784 run_lib.py:146] step: 267300, eval_loss: 4.99306e-02
I0211 01:41:50.200581 22509476222784 run_lib.py:133] step: 267350, training_loss: 4.70549e-02
I0211 01:42:08.735416 22509476222784 run_lib.py:133] step: 267400, training_loss: 5.37999e-02
I0211 01:42:09.089493 22509476222784 run_lib.py:146] step: 267400, eval_loss: 4.97996e-02
I0211 01:42:27.572190 22509476222784 run_lib.py:133] step: 267450, training_loss: 3.87952e-02
I0211 01:42:46.081189 22509476222784 run_lib.py:133] step: 267500, training_loss: 4.24358e-02
I0211 01:42:46.255722 22509476222784 run_lib.py:146] step: 267500, eval_loss: 3.77579e-02
I0211 01:43:04.743367 22509476222784 run_lib.py:133] step: 267550, training_loss: 4.74928e-02
I0211 01:43:23.313952 22509476222784 run_lib.py:133] step: 267600, training_loss: 5.15468e-02
I0211 01:43:23.476828 22509476222784 run_lib.py:146] step: 267600, eval_loss: 6.01006e-02
I0211 01:43:42.220171 22509476222784 run_lib.py:133] step: 267650, training_loss: 4.62506e-02
I0211 01:44:00.817460 22509476222784 run_lib.py:133] step: 267700, training_loss: 4.53689e-02
I0211 01:44:00.979698 22509476222784 run_lib.py:146] step: 267700, eval_loss: 4.37578e-02
I0211 01:44:19.457571 22509476222784 run_lib.py:133] step: 267750, training_loss: 3.62047e-02
I0211 01:44:37.904590 22509476222784 run_lib.py:133] step: 267800, training_loss: 6.10995e-02
I0211 01:44:38.070632 22509476222784 run_lib.py:146] step: 267800, eval_loss: 5.32935e-02
I0211 01:44:56.734839 22509476222784 run_lib.py:133] step: 267850, training_loss: 3.87327e-02
I0211 01:45:15.373243 22509476222784 run_lib.py:133] step: 267900, training_loss: 3.26064e-02
I0211 01:45:15.562588 22509476222784 run_lib.py:146] step: 267900, eval_loss: 4.67767e-02
I0211 01:45:34.061274 22509476222784 run_lib.py:133] step: 267950, training_loss: 3.28388e-02
I0211 01:45:52.587414 22509476222784 run_lib.py:133] step: 268000, training_loss: 4.65649e-02
I0211 01:45:52.767460 22509476222784 run_lib.py:146] step: 268000, eval_loss: 4.09453e-02
I0211 01:46:11.376444 22509476222784 run_lib.py:133] step: 268050, training_loss: 2.99289e-02
I0211 01:46:29.879210 22509476222784 run_lib.py:133] step: 268100, training_loss: 5.11740e-02
I0211 01:46:30.043161 22509476222784 run_lib.py:146] step: 268100, eval_loss: 5.23651e-02
I0211 01:46:48.717635 22509476222784 run_lib.py:133] step: 268150, training_loss: 4.01847e-02
I0211 01:47:07.210953 22509476222784 run_lib.py:133] step: 268200, training_loss: 4.19569e-02
I0211 01:47:07.404722 22509476222784 run_lib.py:146] step: 268200, eval_loss: 4.20595e-02
I0211 01:47:26.017802 22509476222784 run_lib.py:133] step: 268250, training_loss: 2.69369e-02
I0211 01:47:44.488862 22509476222784 run_lib.py:133] step: 268300, training_loss: 5.57083e-02
I0211 01:47:44.653727 22509476222784 run_lib.py:146] step: 268300, eval_loss: 3.44300e-02
I0211 01:48:03.167902 22509476222784 run_lib.py:133] step: 268350, training_loss: 3.97668e-02
I0211 01:48:21.829662 22509476222784 run_lib.py:133] step: 268400, training_loss: 4.24427e-02
I0211 01:48:21.995799 22509476222784 run_lib.py:146] step: 268400, eval_loss: 3.91161e-02
I0211 01:48:40.531414 22509476222784 run_lib.py:133] step: 268450, training_loss: 4.01344e-02
I0211 01:48:59.281928 22509476222784 run_lib.py:133] step: 268500, training_loss: 3.60494e-02
I0211 01:48:59.444378 22509476222784 run_lib.py:146] step: 268500, eval_loss: 3.69099e-02
I0211 01:49:17.965842 22509476222784 run_lib.py:133] step: 268550, training_loss: 4.19747e-02
I0211 01:49:36.411550 22509476222784 run_lib.py:133] step: 268600, training_loss: 4.98915e-02
I0211 01:49:36.571447 22509476222784 run_lib.py:146] step: 268600, eval_loss: 5.78395e-02
I0211 01:49:55.054190 22509476222784 run_lib.py:133] step: 268650, training_loss: 3.34365e-02
I0211 01:50:13.712419 22509476222784 run_lib.py:133] step: 268700, training_loss: 4.85131e-02
I0211 01:50:13.887881 22509476222784 run_lib.py:146] step: 268700, eval_loss: 4.12619e-02
I0211 01:50:32.390096 22509476222784 run_lib.py:133] step: 268750, training_loss: 3.75138e-02
I0211 01:50:50.905336 22509476222784 run_lib.py:133] step: 268800, training_loss: 4.60599e-02
I0211 01:50:51.091048 22509476222784 run_lib.py:146] step: 268800, eval_loss: 4.38655e-02
I0211 01:51:09.779646 22509476222784 run_lib.py:133] step: 268850, training_loss: 3.95972e-02
I0211 01:51:28.306552 22509476222784 run_lib.py:133] step: 268900, training_loss: 3.29569e-02
I0211 01:51:28.479670 22509476222784 run_lib.py:146] step: 268900, eval_loss: 4.44432e-02
I0211 01:51:47.026225 22509476222784 run_lib.py:133] step: 268950, training_loss: 3.90742e-02
I0211 01:52:05.537364 22509476222784 run_lib.py:133] step: 269000, training_loss: 3.92929e-02
I0211 01:52:05.725767 22509476222784 run_lib.py:146] step: 269000, eval_loss: 4.09248e-02
I0211 01:52:24.213157 22509476222784 run_lib.py:133] step: 269050, training_loss: 2.84520e-02
I0211 01:52:42.662636 22509476222784 run_lib.py:133] step: 269100, training_loss: 4.65948e-02
I0211 01:52:42.829586 22509476222784 run_lib.py:146] step: 269100, eval_loss: 5.35201e-02
I0211 01:53:01.447484 22509476222784 run_lib.py:133] step: 269150, training_loss: 3.61805e-02
I0211 01:53:20.057562 22509476222784 run_lib.py:133] step: 269200, training_loss: 4.77932e-02
I0211 01:53:20.239849 22509476222784 run_lib.py:146] step: 269200, eval_loss: 4.32181e-02
I0211 01:53:38.805255 22509476222784 run_lib.py:133] step: 269250, training_loss: 5.42353e-02
I0211 01:53:57.431974 22509476222784 run_lib.py:133] step: 269300, training_loss: 3.32121e-02
I0211 01:53:57.597887 22509476222784 run_lib.py:146] step: 269300, eval_loss: 5.56206e-02
I0211 01:54:16.256067 22509476222784 run_lib.py:133] step: 269350, training_loss: 3.79586e-02
I0211 01:54:34.715993 22509476222784 run_lib.py:133] step: 269400, training_loss: 5.39651e-02
I0211 01:54:34.880627 22509476222784 run_lib.py:146] step: 269400, eval_loss: 4.98062e-02
I0211 01:54:53.537323 22509476222784 run_lib.py:133] step: 269450, training_loss: 4.12109e-02
I0211 01:55:12.121449 22509476222784 run_lib.py:133] step: 269500, training_loss: 4.09999e-02
I0211 01:55:12.284849 22509476222784 run_lib.py:146] step: 269500, eval_loss: 3.73006e-02
I0211 01:55:31.045687 22509476222784 run_lib.py:133] step: 269550, training_loss: 4.18160e-02
I0211 01:55:49.539076 22509476222784 run_lib.py:133] step: 269600, training_loss: 3.87669e-02
I0211 01:55:49.700633 22509476222784 run_lib.py:146] step: 269600, eval_loss: 4.47260e-02
I0211 01:56:08.347270 22509476222784 run_lib.py:133] step: 269650, training_loss: 4.86144e-02
I0211 01:56:26.875942 22509476222784 run_lib.py:133] step: 269700, training_loss: 4.15521e-02
I0211 01:56:27.053667 22509476222784 run_lib.py:146] step: 269700, eval_loss: 3.84546e-02
I0211 01:56:45.649881 22509476222784 run_lib.py:133] step: 269750, training_loss: 3.98150e-02
I0211 01:57:04.389759 22509476222784 run_lib.py:133] step: 269800, training_loss: 4.18801e-02
I0211 01:57:04.562951 22509476222784 run_lib.py:146] step: 269800, eval_loss: 5.47490e-02
I0211 01:57:23.042233 22509476222784 run_lib.py:133] step: 269850, training_loss: 4.77921e-02
I0211 01:57:41.565351 22509476222784 run_lib.py:133] step: 269900, training_loss: 4.30832e-02
I0211 01:57:41.730813 22509476222784 run_lib.py:146] step: 269900, eval_loss: 3.22886e-02
I0211 01:58:00.285966 22509476222784 run_lib.py:133] step: 269950, training_loss: 4.15392e-02
I0211 01:58:18.940005 22509476222784 run_lib.py:133] step: 270000, training_loss: 3.51133e-02
I0211 01:58:19.815903 22509476222784 run_lib.py:146] step: 270000, eval_loss: 5.02775e-02
I0211 01:58:41.081499 22509476222784 run_lib.py:133] step: 270050, training_loss: 4.47327e-02
I0211 01:58:59.712538 22509476222784 run_lib.py:133] step: 270100, training_loss: 3.77751e-02
I0211 01:58:59.874747 22509476222784 run_lib.py:146] step: 270100, eval_loss: 4.08086e-02
I0211 01:59:18.356371 22509476222784 run_lib.py:133] step: 270150, training_loss: 3.84662e-02
I0211 01:59:36.867229 22509476222784 run_lib.py:133] step: 270200, training_loss: 4.30254e-02
I0211 01:59:37.029059 22509476222784 run_lib.py:146] step: 270200, eval_loss: 3.76717e-02
I0211 01:59:55.642956 22509476222784 run_lib.py:133] step: 270250, training_loss: 4.10622e-02
I0211 02:00:14.297563 22509476222784 run_lib.py:133] step: 270300, training_loss: 3.58451e-02
I0211 02:00:14.477380 22509476222784 run_lib.py:146] step: 270300, eval_loss: 4.08065e-02
I0211 02:00:32.995724 22509476222784 run_lib.py:133] step: 270350, training_loss: 4.49981e-02
I0211 02:00:51.555594 22509476222784 run_lib.py:133] step: 270400, training_loss: 4.16210e-02
I0211 02:00:51.718965 22509476222784 run_lib.py:146] step: 270400, eval_loss: 4.04285e-02
I0211 02:01:10.296213 22509476222784 run_lib.py:133] step: 270450, training_loss: 4.32621e-02
I0211 02:01:28.772108 22509476222784 run_lib.py:133] step: 270500, training_loss: 4.50910e-02
I0211 02:01:28.934594 22509476222784 run_lib.py:146] step: 270500, eval_loss: 3.54582e-02
I0211 02:01:47.593962 22509476222784 run_lib.py:133] step: 270550, training_loss: 3.24305e-02
I0211 02:02:06.156154 22509476222784 run_lib.py:133] step: 270600, training_loss: 3.74377e-02
I0211 02:02:06.321891 22509476222784 run_lib.py:146] step: 270600, eval_loss: 4.44789e-02
I0211 02:02:25.044069 22509476222784 run_lib.py:133] step: 270650, training_loss: 3.80068e-02
I0211 02:02:43.549810 22509476222784 run_lib.py:133] step: 270700, training_loss: 3.68058e-02
I0211 02:02:43.713334 22509476222784 run_lib.py:146] step: 270700, eval_loss: 5.10426e-02
I0211 02:03:02.190110 22509476222784 run_lib.py:133] step: 270750, training_loss: 4.84237e-02
I0211 02:03:20.844158 22509476222784 run_lib.py:133] step: 270800, training_loss: 4.17185e-02
I0211 02:03:21.027587 22509476222784 run_lib.py:146] step: 270800, eval_loss: 4.95715e-02
I0211 02:03:39.593977 22509476222784 run_lib.py:133] step: 270850, training_loss: 4.13281e-02
I0211 02:03:58.290172 22509476222784 run_lib.py:133] step: 270900, training_loss: 5.07381e-02
I0211 02:03:58.454804 22509476222784 run_lib.py:146] step: 270900, eval_loss: 3.66380e-02
I0211 02:04:16.887129 22509476222784 run_lib.py:133] step: 270950, training_loss: 4.41769e-02
I0211 02:04:35.368568 22509476222784 run_lib.py:133] step: 271000, training_loss: 4.60451e-02
I0211 02:04:35.531608 22509476222784 run_lib.py:146] step: 271000, eval_loss: 3.23641e-02
I0211 02:04:54.174385 22509476222784 run_lib.py:133] step: 271050, training_loss: 3.45018e-02
I0211 02:05:12.626194 22509476222784 run_lib.py:133] step: 271100, training_loss: 4.91904e-02
I0211 02:05:12.785605 22509476222784 run_lib.py:146] step: 271100, eval_loss: 4.33185e-02
I0211 02:05:31.408526 22509476222784 run_lib.py:133] step: 271150, training_loss: 4.14405e-02
I0211 02:05:50.058190 22509476222784 run_lib.py:133] step: 271200, training_loss: 4.25321e-02
I0211 02:05:50.222444 22509476222784 run_lib.py:146] step: 271200, eval_loss: 4.29780e-02
I0211 02:06:08.721877 22509476222784 run_lib.py:133] step: 271250, training_loss: 4.34211e-02
I0211 02:06:27.185074 22509476222784 run_lib.py:133] step: 271300, training_loss: 3.94544e-02
I0211 02:06:27.348599 22509476222784 run_lib.py:146] step: 271300, eval_loss: 4.72209e-02
I0211 02:06:45.908755 22509476222784 run_lib.py:133] step: 271350, training_loss: 5.61365e-02
I0211 02:07:04.393633 22509476222784 run_lib.py:133] step: 271400, training_loss: 3.34466e-02
I0211 02:07:04.564783 22509476222784 run_lib.py:146] step: 271400, eval_loss: 5.24536e-02
I0211 02:07:23.114541 22509476222784 run_lib.py:133] step: 271450, training_loss: 4.07927e-02
I0211 02:07:41.644737 22509476222784 run_lib.py:133] step: 271500, training_loss: 5.38842e-02
I0211 02:07:41.807083 22509476222784 run_lib.py:146] step: 271500, eval_loss: 3.87129e-02
I0211 02:08:00.514983 22509476222784 run_lib.py:133] step: 271550, training_loss: 5.52228e-02
I0211 02:08:19.107096 22509476222784 run_lib.py:133] step: 271600, training_loss: 4.52929e-02
I0211 02:08:19.268599 22509476222784 run_lib.py:146] step: 271600, eval_loss: 4.36991e-02
I0211 02:08:37.709497 22509476222784 run_lib.py:133] step: 271650, training_loss: 4.93018e-02
I0211 02:08:56.187109 22509476222784 run_lib.py:133] step: 271700, training_loss: 4.75881e-02
I0211 02:08:56.368866 22509476222784 run_lib.py:146] step: 271700, eval_loss: 3.37805e-02
I0211 02:09:15.075781 22509476222784 run_lib.py:133] step: 271750, training_loss: 4.80713e-02
I0211 02:09:33.573972 22509476222784 run_lib.py:133] step: 271800, training_loss: 5.04335e-02
I0211 02:09:33.738847 22509476222784 run_lib.py:146] step: 271800, eval_loss: 4.66687e-02
I0211 02:09:52.400362 22509476222784 run_lib.py:133] step: 271850, training_loss: 3.60059e-02
I0211 02:10:10.847701 22509476222784 run_lib.py:133] step: 271900, training_loss: 5.46317e-02
I0211 02:10:11.010519 22509476222784 run_lib.py:146] step: 271900, eval_loss: 3.68217e-02
I0211 02:10:29.552572 22509476222784 run_lib.py:133] step: 271950, training_loss: 3.96772e-02
I0211 02:10:48.030137 22509476222784 run_lib.py:133] step: 272000, training_loss: 4.07348e-02
I0211 02:10:48.192852 22509476222784 run_lib.py:146] step: 272000, eval_loss: 4.48952e-02
I0211 02:11:06.935050 22509476222784 run_lib.py:133] step: 272050, training_loss: 3.22451e-02
I0211 02:11:25.396366 22509476222784 run_lib.py:133] step: 272100, training_loss: 4.05347e-02
I0211 02:11:25.561621 22509476222784 run_lib.py:146] step: 272100, eval_loss: 4.58543e-02
I0211 02:11:44.007352 22509476222784 run_lib.py:133] step: 272150, training_loss: 5.12571e-02
I0211 02:12:02.642211 22509476222784 run_lib.py:133] step: 272200, training_loss: 4.09034e-02
I0211 02:12:02.808786 22509476222784 run_lib.py:146] step: 272200, eval_loss: 4.54931e-02
I0211 02:12:21.315284 22509476222784 run_lib.py:133] step: 272250, training_loss: 4.82007e-02
I0211 02:12:39.901335 22509476222784 run_lib.py:133] step: 272300, training_loss: 5.19075e-02
I0211 02:12:40.076826 22509476222784 run_lib.py:146] step: 272300, eval_loss: 4.32449e-02
I0211 02:12:58.793243 22509476222784 run_lib.py:133] step: 272350, training_loss: 4.19513e-02
I0211 02:13:17.280334 22509476222784 run_lib.py:133] step: 272400, training_loss: 3.79039e-02
I0211 02:13:17.449438 22509476222784 run_lib.py:146] step: 272400, eval_loss: 4.75407e-02
I0211 02:13:36.114876 22509476222784 run_lib.py:133] step: 272450, training_loss: 5.24662e-02
I0211 02:13:54.617630 22509476222784 run_lib.py:133] step: 272500, training_loss: 6.04026e-02
I0211 02:13:54.782474 22509476222784 run_lib.py:146] step: 272500, eval_loss: 3.82792e-02
I0211 02:14:13.340361 22509476222784 run_lib.py:133] step: 272550, training_loss: 4.77907e-02
I0211 02:14:32.064619 22509476222784 run_lib.py:133] step: 272600, training_loss: 4.81213e-02
I0211 02:14:32.244792 22509476222784 run_lib.py:146] step: 272600, eval_loss: 4.62572e-02
I0211 02:14:50.787241 22509476222784 run_lib.py:133] step: 272650, training_loss: 4.32327e-02
I0211 02:15:09.280991 22509476222784 run_lib.py:133] step: 272700, training_loss: 5.30344e-02
I0211 02:15:09.445411 22509476222784 run_lib.py:146] step: 272700, eval_loss: 5.56904e-02
I0211 02:15:27.972403 22509476222784 run_lib.py:133] step: 272750, training_loss: 4.53632e-02
I0211 02:15:46.636078 22509476222784 run_lib.py:133] step: 272800, training_loss: 4.51280e-02
I0211 02:15:46.801686 22509476222784 run_lib.py:146] step: 272800, eval_loss: 3.98954e-02
I0211 02:16:05.296312 22509476222784 run_lib.py:133] step: 272850, training_loss: 4.55070e-02
I0211 02:16:23.862093 22509476222784 run_lib.py:133] step: 272900, training_loss: 4.94622e-02
I0211 02:16:24.025987 22509476222784 run_lib.py:146] step: 272900, eval_loss: 4.40518e-02
I0211 02:16:42.469994 22509476222784 run_lib.py:133] step: 272950, training_loss: 6.23239e-02
I0211 02:17:00.989372 22509476222784 run_lib.py:133] step: 273000, training_loss: 4.35611e-02
I0211 02:17:01.152672 22509476222784 run_lib.py:146] step: 273000, eval_loss: 3.62095e-02
I0211 02:17:19.821023 22509476222784 run_lib.py:133] step: 273050, training_loss: 5.24677e-02
I0211 02:17:38.366640 22509476222784 run_lib.py:133] step: 273100, training_loss: 6.06933e-02
I0211 02:17:38.538588 22509476222784 run_lib.py:146] step: 273100, eval_loss: 3.46529e-02
I0211 02:17:57.123903 22509476222784 run_lib.py:133] step: 273150, training_loss: 4.53565e-02
I0211 02:18:15.655700 22509476222784 run_lib.py:133] step: 273200, training_loss: 4.23354e-02
I0211 02:18:15.843825 22509476222784 run_lib.py:146] step: 273200, eval_loss: 4.52648e-02
I0211 02:18:34.463687 22509476222784 run_lib.py:133] step: 273250, training_loss: 4.17591e-02
I0211 02:18:52.937784 22509476222784 run_lib.py:133] step: 273300, training_loss: 3.95281e-02
I0211 02:18:53.102402 22509476222784 run_lib.py:146] step: 273300, eval_loss: 4.26817e-02
I0211 02:19:11.770198 22509476222784 run_lib.py:133] step: 273350, training_loss: 4.19669e-02
I0211 02:19:30.298974 22509476222784 run_lib.py:133] step: 273400, training_loss: 3.89550e-02
I0211 02:19:30.461266 22509476222784 run_lib.py:146] step: 273400, eval_loss: 4.03034e-02
I0211 02:19:49.152633 22509476222784 run_lib.py:133] step: 273450, training_loss: 4.98298e-02
I0211 02:20:07.657735 22509476222784 run_lib.py:133] step: 273500, training_loss: 2.88643e-02
I0211 02:20:07.821733 22509476222784 run_lib.py:146] step: 273500, eval_loss: 3.96794e-02
I0211 02:20:26.312744 22509476222784 run_lib.py:133] step: 273550, training_loss: 3.80543e-02
I0211 02:20:44.956909 22509476222784 run_lib.py:133] step: 273600, training_loss: 4.57801e-02
I0211 02:20:45.121586 22509476222784 run_lib.py:146] step: 273600, eval_loss: 4.63886e-02
I0211 02:21:03.484349 22509476222784 run_lib.py:133] step: 273650, training_loss: 3.53375e-02
I0211 02:21:22.156851 22509476222784 run_lib.py:133] step: 273700, training_loss: 3.32726e-02
I0211 02:21:22.330565 22509476222784 run_lib.py:146] step: 273700, eval_loss: 3.67353e-02
I0211 02:21:40.812956 22509476222784 run_lib.py:133] step: 273750, training_loss: 5.85521e-02
I0211 02:21:59.365689 22509476222784 run_lib.py:133] step: 273800, training_loss: 3.57041e-02
I0211 02:21:59.547855 22509476222784 run_lib.py:146] step: 273800, eval_loss: 3.74451e-02
I0211 02:22:18.240169 22509476222784 run_lib.py:133] step: 273850, training_loss: 4.58212e-02
I0211 02:22:36.710889 22509476222784 run_lib.py:133] step: 273900, training_loss: 5.62801e-02
I0211 02:22:36.870596 22509476222784 run_lib.py:146] step: 273900, eval_loss: 4.08063e-02
I0211 02:22:55.339202 22509476222784 run_lib.py:133] step: 273950, training_loss: 5.59253e-02
I0211 02:23:13.868980 22509476222784 run_lib.py:133] step: 274000, training_loss: 4.16460e-02
I0211 02:23:14.042886 22509476222784 run_lib.py:146] step: 274000, eval_loss: 4.33224e-02
I0211 02:23:32.537787 22509476222784 run_lib.py:133] step: 274050, training_loss: 3.88963e-02
I0211 02:23:50.986548 22509476222784 run_lib.py:133] step: 274100, training_loss: 4.93113e-02
I0211 02:23:51.347593 22509476222784 run_lib.py:146] step: 274100, eval_loss: 4.37022e-02
I0211 02:24:09.846731 22509476222784 run_lib.py:133] step: 274150, training_loss: 4.32794e-02
I0211 02:24:28.303881 22509476222784 run_lib.py:133] step: 274200, training_loss: 5.29145e-02
I0211 02:24:28.466635 22509476222784 run_lib.py:146] step: 274200, eval_loss: 5.30968e-02
I0211 02:24:46.939953 22509476222784 run_lib.py:133] step: 274250, training_loss: 4.43219e-02
I0211 02:25:05.496578 22509476222784 run_lib.py:133] step: 274300, training_loss: 4.87040e-02
I0211 02:25:05.660940 22509476222784 run_lib.py:146] step: 274300, eval_loss: 3.81240e-02
I0211 02:25:24.417891 22509476222784 run_lib.py:133] step: 274350, training_loss: 3.72745e-02
I0211 02:25:42.971140 22509476222784 run_lib.py:133] step: 274400, training_loss: 4.56855e-02
I0211 02:25:43.132642 22509476222784 run_lib.py:146] step: 274400, eval_loss: 3.93199e-02
I0211 02:26:01.594108 22509476222784 run_lib.py:133] step: 274450, training_loss: 3.64332e-02
I0211 02:26:20.118068 22509476222784 run_lib.py:133] step: 274500, training_loss: 3.92386e-02
I0211 02:26:20.284856 22509476222784 run_lib.py:146] step: 274500, eval_loss: 4.69239e-02
I0211 02:26:38.915374 22509476222784 run_lib.py:133] step: 274550, training_loss: 3.62438e-02
I0211 02:26:57.546992 22509476222784 run_lib.py:133] step: 274600, training_loss: 4.38992e-02
I0211 02:26:57.711716 22509476222784 run_lib.py:146] step: 274600, eval_loss: 4.94919e-02
I0211 02:27:16.122174 22509476222784 run_lib.py:133] step: 274650, training_loss: 4.96279e-02
I0211 02:27:34.616482 22509476222784 run_lib.py:133] step: 274700, training_loss: 5.80700e-02
I0211 02:27:34.791341 22509476222784 run_lib.py:146] step: 274700, eval_loss: 3.85170e-02
I0211 02:27:53.424062 22509476222784 run_lib.py:133] step: 274750, training_loss: 4.79796e-02
I0211 02:28:11.897709 22509476222784 run_lib.py:133] step: 274800, training_loss: 3.55837e-02
I0211 02:28:12.061606 22509476222784 run_lib.py:146] step: 274800, eval_loss: 5.14394e-02
I0211 02:28:30.743439 22509476222784 run_lib.py:133] step: 274850, training_loss: 4.98865e-02
I0211 02:28:49.282711 22509476222784 run_lib.py:133] step: 274900, training_loss: 6.18807e-02
I0211 02:28:49.447797 22509476222784 run_lib.py:146] step: 274900, eval_loss: 4.16809e-02
I0211 02:29:08.083285 22509476222784 run_lib.py:133] step: 274950, training_loss: 3.84945e-02
I0211 02:29:26.588763 22509476222784 run_lib.py:133] step: 275000, training_loss: 5.39140e-02
I0211 02:29:26.754754 22509476222784 run_lib.py:146] step: 275000, eval_loss: 5.17030e-02
I0211 02:29:45.190829 22509476222784 run_lib.py:133] step: 275050, training_loss: 3.24953e-02
I0211 02:30:03.760996 22509476222784 run_lib.py:133] step: 275100, training_loss: 3.91782e-02
I0211 02:30:03.935659 22509476222784 run_lib.py:146] step: 275100, eval_loss: 4.17025e-02
I0211 02:30:22.351438 22509476222784 run_lib.py:133] step: 275150, training_loss: 3.58178e-02
I0211 02:30:41.050302 22509476222784 run_lib.py:133] step: 275200, training_loss: 4.59138e-02
I0211 02:30:41.237811 22509476222784 run_lib.py:146] step: 275200, eval_loss: 5.63625e-02
I0211 02:30:59.749972 22509476222784 run_lib.py:133] step: 275250, training_loss: 4.08949e-02
I0211 02:31:18.174234 22509476222784 run_lib.py:133] step: 275300, training_loss: 3.01893e-02
I0211 02:31:18.334703 22509476222784 run_lib.py:146] step: 275300, eval_loss: 4.75753e-02
I0211 02:31:36.831776 22509476222784 run_lib.py:133] step: 275350, training_loss: 5.28607e-02
I0211 02:31:55.495548 22509476222784 run_lib.py:133] step: 275400, training_loss: 4.60553e-02
I0211 02:31:55.677821 22509476222784 run_lib.py:146] step: 275400, eval_loss: 3.75393e-02
I0211 02:32:14.235866 22509476222784 run_lib.py:133] step: 275450, training_loss: 4.35770e-02
I0211 02:32:32.802648 22509476222784 run_lib.py:133] step: 275500, training_loss: 5.52311e-02
I0211 02:32:32.968976 22509476222784 run_lib.py:146] step: 275500, eval_loss: 3.72869e-02
I0211 02:32:51.641053 22509476222784 run_lib.py:133] step: 275550, training_loss: 5.58635e-02
I0211 02:33:10.206130 22509476222784 run_lib.py:133] step: 275600, training_loss: 4.01907e-02
I0211 02:33:10.370693 22509476222784 run_lib.py:146] step: 275600, eval_loss: 4.94297e-02
I0211 02:33:28.966839 22509476222784 run_lib.py:133] step: 275650, training_loss: 5.25662e-02
I0211 02:33:47.609724 22509476222784 run_lib.py:133] step: 275700, training_loss: 4.10917e-02
I0211 02:33:47.774899 22509476222784 run_lib.py:146] step: 275700, eval_loss: 4.83732e-02
I0211 02:34:06.380099 22509476222784 run_lib.py:133] step: 275750, training_loss: 3.42677e-02
I0211 02:34:24.919107 22509476222784 run_lib.py:133] step: 275800, training_loss: 4.33174e-02
I0211 02:34:25.080680 22509476222784 run_lib.py:146] step: 275800, eval_loss: 4.06795e-02
I0211 02:34:43.794360 22509476222784 run_lib.py:133] step: 275850, training_loss: 4.36993e-02
I0211 02:35:02.390525 22509476222784 run_lib.py:133] step: 275900, training_loss: 3.77585e-02
I0211 02:35:02.551991 22509476222784 run_lib.py:146] step: 275900, eval_loss: 3.52198e-02
I0211 02:35:21.087047 22509476222784 run_lib.py:133] step: 275950, training_loss: 3.48911e-02
I0211 02:35:39.861164 22509476222784 run_lib.py:133] step: 276000, training_loss: 5.16638e-02
I0211 02:35:40.026585 22509476222784 run_lib.py:146] step: 276000, eval_loss: 4.12359e-02
I0211 02:35:58.579078 22509476222784 run_lib.py:133] step: 276050, training_loss: 3.91059e-02
I0211 02:36:17.038391 22509476222784 run_lib.py:133] step: 276100, training_loss: 4.05797e-02
I0211 02:36:17.219691 22509476222784 run_lib.py:146] step: 276100, eval_loss: 3.21102e-02
I0211 02:36:35.899216 22509476222784 run_lib.py:133] step: 276150, training_loss: 5.62130e-02
I0211 02:36:54.351568 22509476222784 run_lib.py:133] step: 276200, training_loss: 4.00739e-02
I0211 02:36:54.514569 22509476222784 run_lib.py:146] step: 276200, eval_loss: 4.44355e-02
I0211 02:37:13.192015 22509476222784 run_lib.py:133] step: 276250, training_loss: 3.38342e-02
I0211 02:37:31.743749 22509476222784 run_lib.py:133] step: 276300, training_loss: 3.22361e-02
I0211 02:37:31.909842 22509476222784 run_lib.py:146] step: 276300, eval_loss: 3.80534e-02
I0211 02:37:50.665189 22509476222784 run_lib.py:133] step: 276350, training_loss: 4.68996e-02
I0211 02:38:09.165860 22509476222784 run_lib.py:133] step: 276400, training_loss: 3.26659e-02
I0211 02:38:09.331886 22509476222784 run_lib.py:146] step: 276400, eval_loss: 4.63516e-02
I0211 02:38:27.773815 22509476222784 run_lib.py:133] step: 276450, training_loss: 6.06122e-02
I0211 02:38:46.419711 22509476222784 run_lib.py:133] step: 276500, training_loss: 5.35736e-02
I0211 02:38:46.599614 22509476222784 run_lib.py:146] step: 276500, eval_loss: 3.90462e-02
I0211 02:39:05.126283 22509476222784 run_lib.py:133] step: 276550, training_loss: 3.73894e-02
I0211 02:39:23.587609 22509476222784 run_lib.py:133] step: 276600, training_loss: 4.14791e-02
I0211 02:39:23.751931 22509476222784 run_lib.py:146] step: 276600, eval_loss: 4.12293e-02
I0211 02:39:42.345973 22509476222784 run_lib.py:133] step: 276650, training_loss: 5.01882e-02
I0211 02:40:00.923810 22509476222784 run_lib.py:133] step: 276700, training_loss: 5.47995e-02
I0211 02:40:01.084519 22509476222784 run_lib.py:146] step: 276700, eval_loss: 4.16407e-02
I0211 02:40:19.574106 22509476222784 run_lib.py:133] step: 276750, training_loss: 5.17112e-02
I0211 02:40:38.072614 22509476222784 run_lib.py:133] step: 276800, training_loss: 4.01686e-02
I0211 02:40:38.240869 22509476222784 run_lib.py:146] step: 276800, eval_loss: 4.01644e-02
I0211 02:40:56.804159 22509476222784 run_lib.py:133] step: 276850, training_loss: 5.03665e-02
I0211 02:41:15.471630 22509476222784 run_lib.py:133] step: 276900, training_loss: 3.81953e-02
I0211 02:41:15.638698 22509476222784 run_lib.py:146] step: 276900, eval_loss: 5.15622e-02
I0211 02:41:34.090286 22509476222784 run_lib.py:133] step: 276950, training_loss: 4.42896e-02
I0211 02:41:52.550355 22509476222784 run_lib.py:133] step: 277000, training_loss: 3.61364e-02
I0211 02:41:52.714306 22509476222784 run_lib.py:146] step: 277000, eval_loss: 3.40903e-02
I0211 02:42:11.217990 22509476222784 run_lib.py:133] step: 277050, training_loss: 4.76938e-02
I0211 02:42:29.748784 22509476222784 run_lib.py:133] step: 277100, training_loss: 3.42133e-02
I0211 02:42:29.913368 22509476222784 run_lib.py:146] step: 277100, eval_loss: 4.36936e-02
I0211 02:42:48.509517 22509476222784 run_lib.py:133] step: 277150, training_loss: 2.44157e-02
I0211 02:43:07.049146 22509476222784 run_lib.py:133] step: 277200, training_loss: 4.51631e-02
I0211 02:43:07.209508 22509476222784 run_lib.py:146] step: 277200, eval_loss: 5.44167e-02
I0211 02:43:25.705990 22509476222784 run_lib.py:133] step: 277250, training_loss: 4.19312e-02
I0211 02:43:44.257045 22509476222784 run_lib.py:133] step: 277300, training_loss: 3.27014e-02
I0211 02:43:44.428710 22509476222784 run_lib.py:146] step: 277300, eval_loss: 4.78750e-02
I0211 02:44:03.082451 22509476222784 run_lib.py:133] step: 277350, training_loss: 3.97246e-02
I0211 02:44:21.666468 22509476222784 run_lib.py:133] step: 277400, training_loss: 4.94164e-02
I0211 02:44:21.846636 22509476222784 run_lib.py:146] step: 277400, eval_loss: 4.51637e-02
I0211 02:44:40.337114 22509476222784 run_lib.py:133] step: 277450, training_loss: 4.01197e-02
I0211 02:44:58.878767 22509476222784 run_lib.py:133] step: 277500, training_loss: 3.60823e-02
I0211 02:44:59.061657 22509476222784 run_lib.py:146] step: 277500, eval_loss: 4.91691e-02
I0211 02:45:17.712971 22509476222784 run_lib.py:133] step: 277550, training_loss: 3.51106e-02
I0211 02:45:36.201570 22509476222784 run_lib.py:133] step: 277600, training_loss: 3.55637e-02
I0211 02:45:36.364574 22509476222784 run_lib.py:146] step: 277600, eval_loss: 5.44830e-02
I0211 02:45:55.017391 22509476222784 run_lib.py:133] step: 277650, training_loss: 4.49471e-02
I0211 02:46:13.639387 22509476222784 run_lib.py:133] step: 277700, training_loss: 3.37384e-02
I0211 02:46:13.852824 22509476222784 run_lib.py:146] step: 277700, eval_loss: 4.30499e-02
I0211 02:46:32.612444 22509476222784 run_lib.py:133] step: 277750, training_loss: 3.24360e-02
I0211 02:46:51.134888 22509476222784 run_lib.py:133] step: 277800, training_loss: 5.28780e-02
I0211 02:46:51.294330 22509476222784 run_lib.py:146] step: 277800, eval_loss: 3.74308e-02
I0211 02:47:09.734382 22509476222784 run_lib.py:133] step: 277850, training_loss: 3.80713e-02
I0211 02:47:28.390321 22509476222784 run_lib.py:133] step: 277900, training_loss: 4.28490e-02
I0211 02:47:28.553768 22509476222784 run_lib.py:146] step: 277900, eval_loss: 4.94868e-02
I0211 02:47:47.062974 22509476222784 run_lib.py:133] step: 277950, training_loss: 3.72889e-02
I0211 02:48:05.657322 22509476222784 run_lib.py:133] step: 278000, training_loss: 4.55960e-02
I0211 02:48:05.819727 22509476222784 run_lib.py:146] step: 278000, eval_loss: 3.85521e-02
I0211 02:48:24.247916 22509476222784 run_lib.py:133] step: 278050, training_loss: 4.69286e-02
I0211 02:48:42.763421 22509476222784 run_lib.py:133] step: 278100, training_loss: 3.74328e-02
I0211 02:48:42.972567 22509476222784 run_lib.py:146] step: 278100, eval_loss: 5.33261e-02
I0211 02:49:01.696439 22509476222784 run_lib.py:133] step: 278150, training_loss: 4.03579e-02
I0211 02:49:20.199250 22509476222784 run_lib.py:133] step: 278200, training_loss: 4.87773e-02
I0211 02:49:20.361581 22509476222784 run_lib.py:146] step: 278200, eval_loss: 5.30313e-02
I0211 02:49:38.782035 22509476222784 run_lib.py:133] step: 278250, training_loss: 3.99077e-02
I0211 02:49:57.473019 22509476222784 run_lib.py:133] step: 278300, training_loss: 4.64413e-02
I0211 02:49:57.654641 22509476222784 run_lib.py:146] step: 278300, eval_loss: 4.93828e-02
I0211 02:50:16.057750 22509476222784 run_lib.py:133] step: 278350, training_loss: 4.40079e-02
I0211 02:50:34.441551 22509476222784 run_lib.py:133] step: 278400, training_loss: 4.01699e-02
I0211 02:50:34.604768 22509476222784 run_lib.py:146] step: 278400, eval_loss: 5.07098e-02
I0211 02:50:53.138565 22509476222784 run_lib.py:133] step: 278450, training_loss: 5.49795e-02
I0211 02:51:11.546775 22509476222784 run_lib.py:133] step: 278500, training_loss: 4.28770e-02
I0211 02:51:11.760011 22509476222784 run_lib.py:146] step: 278500, eval_loss: 4.40996e-02
I0211 02:51:30.241015 22509476222784 run_lib.py:133] step: 278550, training_loss: 4.22253e-02
I0211 02:51:48.799296 22509476222784 run_lib.py:133] step: 278600, training_loss: 2.94911e-02
I0211 02:51:48.962211 22509476222784 run_lib.py:146] step: 278600, eval_loss: 4.38645e-02
I0211 02:52:07.624400 22509476222784 run_lib.py:133] step: 278650, training_loss: 3.90840e-02
I0211 02:52:26.224101 22509476222784 run_lib.py:133] step: 278700, training_loss: 3.56060e-02
I0211 02:52:26.388052 22509476222784 run_lib.py:146] step: 278700, eval_loss: 3.80780e-02
I0211 02:52:44.868670 22509476222784 run_lib.py:133] step: 278750, training_loss: 3.71088e-02
I0211 02:53:03.380247 22509476222784 run_lib.py:133] step: 278800, training_loss: 4.01836e-02
I0211 02:53:03.554659 22509476222784 run_lib.py:146] step: 278800, eval_loss: 4.59222e-02
I0211 02:53:22.174813 22509476222784 run_lib.py:133] step: 278850, training_loss: 4.57546e-02
I0211 02:53:40.808439 22509476222784 run_lib.py:133] step: 278900, training_loss: 3.52550e-02
I0211 02:53:40.982744 22509476222784 run_lib.py:146] step: 278900, eval_loss: 3.80071e-02
I0211 02:53:59.688278 22509476222784 run_lib.py:133] step: 278950, training_loss: 4.22176e-02
I0211 02:54:18.137786 22509476222784 run_lib.py:133] step: 279000, training_loss: 4.80152e-02
I0211 02:54:18.305796 22509476222784 run_lib.py:146] step: 279000, eval_loss: 3.77930e-02
I0211 02:54:36.939954 22509476222784 run_lib.py:133] step: 279050, training_loss: 4.66399e-02
I0211 02:54:55.372291 22509476222784 run_lib.py:133] step: 279100, training_loss: 3.56242e-02
I0211 02:54:55.544625 22509476222784 run_lib.py:146] step: 279100, eval_loss: 3.33597e-02
I0211 02:55:14.193139 22509476222784 run_lib.py:133] step: 279150, training_loss: 5.02097e-02
I0211 02:55:32.699594 22509476222784 run_lib.py:133] step: 279200, training_loss: 4.49498e-02
I0211 02:55:32.866779 22509476222784 run_lib.py:146] step: 279200, eval_loss: 4.99099e-02
I0211 02:55:51.298715 22509476222784 run_lib.py:133] step: 279250, training_loss: 5.09138e-02
I0211 02:56:09.929429 22509476222784 run_lib.py:133] step: 279300, training_loss: 4.68392e-02
I0211 02:56:10.096903 22509476222784 run_lib.py:146] step: 279300, eval_loss: 4.07322e-02
I0211 02:56:28.613565 22509476222784 run_lib.py:133] step: 279350, training_loss: 3.65271e-02
I0211 02:56:47.139828 22509476222784 run_lib.py:133] step: 279400, training_loss: 5.07136e-02
I0211 02:56:47.307806 22509476222784 run_lib.py:146] step: 279400, eval_loss: 5.01724e-02
I0211 02:57:06.040277 22509476222784 run_lib.py:133] step: 279450, training_loss: 3.49253e-02
I0211 02:57:24.522763 22509476222784 run_lib.py:133] step: 279500, training_loss: 3.47999e-02
I0211 02:57:24.687638 22509476222784 run_lib.py:146] step: 279500, eval_loss: 3.45605e-02
I0211 02:57:43.220146 22509476222784 run_lib.py:133] step: 279550, training_loss: 3.94242e-02
I0211 02:58:01.617077 22509476222784 run_lib.py:133] step: 279600, training_loss: 4.59103e-02
I0211 02:58:01.778092 22509476222784 run_lib.py:146] step: 279600, eval_loss: 5.10914e-02
I0211 02:58:20.356819 22509476222784 run_lib.py:133] step: 279650, training_loss: 4.75722e-02
I0211 02:58:39.024416 22509476222784 run_lib.py:133] step: 279700, training_loss: 4.03309e-02
I0211 02:58:39.193839 22509476222784 run_lib.py:146] step: 279700, eval_loss: 4.66904e-02
I0211 02:58:57.707821 22509476222784 run_lib.py:133] step: 279750, training_loss: 4.75069e-02
I0211 02:59:16.258701 22509476222784 run_lib.py:133] step: 279800, training_loss: 3.26053e-02
I0211 02:59:16.423789 22509476222784 run_lib.py:146] step: 279800, eval_loss: 6.50997e-02
I0211 02:59:34.923535 22509476222784 run_lib.py:133] step: 279850, training_loss: 3.79022e-02
I0211 02:59:53.542996 22509476222784 run_lib.py:133] step: 279900, training_loss: 4.22598e-02
I0211 02:59:53.715630 22509476222784 run_lib.py:146] step: 279900, eval_loss: 5.52904e-02
I0211 03:00:12.239306 22509476222784 run_lib.py:133] step: 279950, training_loss: 4.42808e-02
I0211 03:00:30.887498 22509476222784 run_lib.py:133] step: 280000, training_loss: 4.03517e-02
I0211 03:00:31.661761 22509476222784 run_lib.py:146] step: 280000, eval_loss: 5.72157e-02
I0211 03:00:52.857986 22509476222784 run_lib.py:133] step: 280050, training_loss: 4.91573e-02
I0211 03:01:11.324783 22509476222784 run_lib.py:133] step: 280100, training_loss: 3.76393e-02
I0211 03:01:11.485313 22509476222784 run_lib.py:146] step: 280100, eval_loss: 3.74797e-02
I0211 03:01:30.058748 22509476222784 run_lib.py:133] step: 280150, training_loss: 4.07138e-02
I0211 03:01:48.614202 22509476222784 run_lib.py:133] step: 280200, training_loss: 4.17382e-02
I0211 03:01:48.806717 22509476222784 run_lib.py:146] step: 280200, eval_loss: 3.63816e-02
I0211 03:02:07.473337 22509476222784 run_lib.py:133] step: 280250, training_loss: 4.35337e-02
I0211 03:02:25.928767 22509476222784 run_lib.py:133] step: 280300, training_loss: 5.15321e-02
I0211 03:02:26.096911 22509476222784 run_lib.py:146] step: 280300, eval_loss: 4.49038e-02
I0211 03:02:44.582313 22509476222784 run_lib.py:133] step: 280350, training_loss: 4.83470e-02
I0211 03:03:03.087184 22509476222784 run_lib.py:133] step: 280400, training_loss: 5.26469e-02
I0211 03:03:03.259530 22509476222784 run_lib.py:146] step: 280400, eval_loss: 5.11253e-02
I0211 03:03:21.976498 22509476222784 run_lib.py:133] step: 280450, training_loss: 5.78952e-02
I0211 03:03:40.613080 22509476222784 run_lib.py:133] step: 280500, training_loss: 4.14784e-02
I0211 03:03:40.805433 22509476222784 run_lib.py:146] step: 280500, eval_loss: 5.14201e-02
I0211 03:03:59.339386 22509476222784 run_lib.py:133] step: 280550, training_loss: 4.87022e-02
I0211 03:04:17.863620 22509476222784 run_lib.py:133] step: 280600, training_loss: 4.54195e-02
I0211 03:04:18.024405 22509476222784 run_lib.py:146] step: 280600, eval_loss: 4.50957e-02
I0211 03:04:36.680630 22509476222784 run_lib.py:133] step: 280650, training_loss: 4.98127e-02
I0211 03:04:55.158552 22509476222784 run_lib.py:133] step: 280700, training_loss: 4.96322e-02
I0211 03:04:55.338883 22509476222784 run_lib.py:146] step: 280700, eval_loss: 4.17409e-02
I0211 03:05:13.995005 22509476222784 run_lib.py:133] step: 280750, training_loss: 4.79224e-02
I0211 03:05:32.513460 22509476222784 run_lib.py:133] step: 280800, training_loss: 3.19870e-02
I0211 03:05:32.679730 22509476222784 run_lib.py:146] step: 280800, eval_loss: 4.45446e-02
I0211 03:05:51.358436 22509476222784 run_lib.py:133] step: 280850, training_loss: 3.93933e-02
I0211 03:06:09.848810 22509476222784 run_lib.py:133] step: 280900, training_loss: 4.75887e-02
I0211 03:06:10.015523 22509476222784 run_lib.py:146] step: 280900, eval_loss: 4.72085e-02
I0211 03:06:28.467570 22509476222784 run_lib.py:133] step: 280950, training_loss: 4.58323e-02
I0211 03:06:47.188145 22509476222784 run_lib.py:133] step: 281000, training_loss: 4.11594e-02
I0211 03:06:47.353851 22509476222784 run_lib.py:146] step: 281000, eval_loss: 4.83104e-02
I0211 03:07:05.923870 22509476222784 run_lib.py:133] step: 281050, training_loss: 3.45427e-02
I0211 03:07:24.556113 22509476222784 run_lib.py:133] step: 281100, training_loss: 4.12380e-02
I0211 03:07:24.716840 22509476222784 run_lib.py:146] step: 281100, eval_loss: 4.05125e-02
I0211 03:07:43.132293 22509476222784 run_lib.py:133] step: 281150, training_loss: 2.79068e-02
I0211 03:08:01.583196 22509476222784 run_lib.py:133] step: 281200, training_loss: 5.45490e-02
I0211 03:08:01.756773 22509476222784 run_lib.py:146] step: 281200, eval_loss: 4.28923e-02
I0211 03:08:20.416325 22509476222784 run_lib.py:133] step: 281250, training_loss: 4.38059e-02
I0211 03:08:39.007942 22509476222784 run_lib.py:133] step: 281300, training_loss: 3.97940e-02
I0211 03:08:39.174627 22509476222784 run_lib.py:146] step: 281300, eval_loss: 3.64044e-02
I0211 03:08:57.664482 22509476222784 run_lib.py:133] step: 281350, training_loss: 5.12632e-02
I0211 03:09:16.383103 22509476222784 run_lib.py:133] step: 281400, training_loss: 3.46022e-02
I0211 03:09:16.573594 22509476222784 run_lib.py:146] step: 281400, eval_loss: 4.21601e-02
I0211 03:09:35.076938 22509476222784 run_lib.py:133] step: 281450, training_loss: 3.67903e-02
I0211 03:09:53.568378 22509476222784 run_lib.py:133] step: 281500, training_loss: 3.17477e-02
I0211 03:09:53.873708 22509476222784 run_lib.py:146] step: 281500, eval_loss: 4.81702e-02
I0211 03:10:12.434537 22509476222784 run_lib.py:133] step: 281550, training_loss: 5.40327e-02
I0211 03:10:30.935099 22509476222784 run_lib.py:133] step: 281600, training_loss: 6.12669e-02
I0211 03:10:31.097965 22509476222784 run_lib.py:146] step: 281600, eval_loss: 4.63774e-02
I0211 03:10:49.587111 22509476222784 run_lib.py:133] step: 281650, training_loss: 5.09839e-02
I0211 03:11:08.080123 22509476222784 run_lib.py:133] step: 281700, training_loss: 3.62835e-02
I0211 03:11:08.244905 22509476222784 run_lib.py:146] step: 281700, eval_loss: 3.52509e-02
I0211 03:11:26.821405 22509476222784 run_lib.py:133] step: 281750, training_loss: 3.99694e-02
I0211 03:11:45.421160 22509476222784 run_lib.py:133] step: 281800, training_loss: 4.48173e-02
I0211 03:11:45.603840 22509476222784 run_lib.py:146] step: 281800, eval_loss: 4.36579e-02
I0211 03:12:04.080457 22509476222784 run_lib.py:133] step: 281850, training_loss: 5.14912e-02
I0211 03:12:22.571247 22509476222784 run_lib.py:133] step: 281900, training_loss: 4.14805e-02
I0211 03:12:22.761709 22509476222784 run_lib.py:146] step: 281900, eval_loss: 4.13776e-02
I0211 03:12:41.443281 22509476222784 run_lib.py:133] step: 281950, training_loss: 4.71408e-02
I0211 03:12:59.986904 22509476222784 run_lib.py:133] step: 282000, training_loss: 4.05588e-02
I0211 03:13:00.147295 22509476222784 run_lib.py:146] step: 282000, eval_loss: 2.59359e-02
I0211 03:13:18.695339 22509476222784 run_lib.py:133] step: 282050, training_loss: 5.46684e-02
I0211 03:13:37.136399 22509476222784 run_lib.py:133] step: 282100, training_loss: 4.31220e-02
I0211 03:13:37.303712 22509476222784 run_lib.py:146] step: 282100, eval_loss: 4.61445e-02
I0211 03:13:55.908708 22509476222784 run_lib.py:133] step: 282150, training_loss: 4.56603e-02
I0211 03:14:14.421258 22509476222784 run_lib.py:133] step: 282200, training_loss: 4.46901e-02
I0211 03:14:14.587686 22509476222784 run_lib.py:146] step: 282200, eval_loss: 4.77761e-02
I0211 03:14:33.213773 22509476222784 run_lib.py:133] step: 282250, training_loss: 3.60917e-02
I0211 03:14:51.680204 22509476222784 run_lib.py:133] step: 282300, training_loss: 5.31484e-02
I0211 03:14:51.860639 22509476222784 run_lib.py:146] step: 282300, eval_loss: 4.47913e-02
I0211 03:15:10.561957 22509476222784 run_lib.py:133] step: 282350, training_loss: 4.44452e-02
I0211 03:15:29.139132 22509476222784 run_lib.py:133] step: 282400, training_loss: 5.10743e-02
I0211 03:15:29.302900 22509476222784 run_lib.py:146] step: 282400, eval_loss: 4.74644e-02
I0211 03:15:47.792938 22509476222784 run_lib.py:133] step: 282450, training_loss: 4.40115e-02
I0211 03:16:06.423086 22509476222784 run_lib.py:133] step: 282500, training_loss: 4.04233e-02
I0211 03:16:06.583733 22509476222784 run_lib.py:146] step: 282500, eval_loss: 4.91157e-02
I0211 03:16:25.073003 22509476222784 run_lib.py:133] step: 282550, training_loss: 4.55228e-02
I0211 03:16:43.701751 22509476222784 run_lib.py:133] step: 282600, training_loss: 4.13815e-02
I0211 03:16:43.875855 22509476222784 run_lib.py:146] step: 282600, eval_loss: 4.21866e-02
I0211 03:17:02.431172 22509476222784 run_lib.py:133] step: 282650, training_loss: 3.50524e-02
I0211 03:17:20.936489 22509476222784 run_lib.py:133] step: 282700, training_loss: 3.20303e-02
I0211 03:17:21.101633 22509476222784 run_lib.py:146] step: 282700, eval_loss: 5.26411e-02
I0211 03:17:39.567035 22509476222784 run_lib.py:133] step: 282750, training_loss: 4.76107e-02
I0211 03:17:58.269441 22509476222784 run_lib.py:133] step: 282800, training_loss: 4.26087e-02
I0211 03:17:58.434724 22509476222784 run_lib.py:146] step: 282800, eval_loss: 3.83293e-02
I0211 03:18:16.937995 22509476222784 run_lib.py:133] step: 282850, training_loss: 4.26372e-02
I0211 03:18:35.508596 22509476222784 run_lib.py:133] step: 282900, training_loss: 4.85124e-02
I0211 03:18:35.672915 22509476222784 run_lib.py:146] step: 282900, eval_loss: 3.36495e-02
I0211 03:18:54.438532 22509476222784 run_lib.py:133] step: 282950, training_loss: 3.32648e-02
I0211 03:19:12.882042 22509476222784 run_lib.py:133] step: 283000, training_loss: 3.28110e-02
I0211 03:19:13.042690 22509476222784 run_lib.py:146] step: 283000, eval_loss: 4.69988e-02
I0211 03:19:31.615324 22509476222784 run_lib.py:133] step: 283050, training_loss: 4.44798e-02
I0211 03:19:50.139779 22509476222784 run_lib.py:133] step: 283100, training_loss: 5.48791e-02
I0211 03:19:50.303429 22509476222784 run_lib.py:146] step: 283100, eval_loss: 4.11018e-02
I0211 03:20:08.764457 22509476222784 run_lib.py:133] step: 283150, training_loss: 4.34260e-02
I0211 03:20:27.359895 22509476222784 run_lib.py:133] step: 283200, training_loss: 4.73791e-02
I0211 03:20:27.542642 22509476222784 run_lib.py:146] step: 283200, eval_loss: 4.96651e-02
I0211 03:20:46.196809 22509476222784 run_lib.py:133] step: 283250, training_loss: 3.74107e-02
I0211 03:21:04.803249 22509476222784 run_lib.py:133] step: 283300, training_loss: 4.93243e-02
I0211 03:21:04.972938 22509476222784 run_lib.py:146] step: 283300, eval_loss: 3.95378e-02
I0211 03:21:23.464132 22509476222784 run_lib.py:133] step: 283350, training_loss: 4.70723e-02
I0211 03:21:41.957875 22509476222784 run_lib.py:133] step: 283400, training_loss: 5.31494e-02
I0211 03:21:42.120837 22509476222784 run_lib.py:146] step: 283400, eval_loss: 4.81386e-02
I0211 03:22:00.772291 22509476222784 run_lib.py:133] step: 283450, training_loss: 3.57754e-02
I0211 03:22:19.347761 22509476222784 run_lib.py:133] step: 283500, training_loss: 4.57320e-02
I0211 03:22:19.512969 22509476222784 run_lib.py:146] step: 283500, eval_loss: 4.15967e-02
I0211 03:22:38.245795 22509476222784 run_lib.py:133] step: 283550, training_loss: 5.63656e-02
I0211 03:22:56.742018 22509476222784 run_lib.py:133] step: 283600, training_loss: 4.42054e-02
I0211 03:22:56.907827 22509476222784 run_lib.py:146] step: 283600, eval_loss: 4.21143e-02
I0211 03:23:15.555065 22509476222784 run_lib.py:133] step: 283650, training_loss: 2.97384e-02
I0211 03:23:34.097688 22509476222784 run_lib.py:133] step: 283700, training_loss: 4.04692e-02
I0211 03:23:34.273603 22509476222784 run_lib.py:146] step: 283700, eval_loss: 3.53208e-02
I0211 03:23:53.036656 22509476222784 run_lib.py:133] step: 283750, training_loss: 3.21643e-02
I0211 03:24:11.530292 22509476222784 run_lib.py:133] step: 283800, training_loss: 3.94001e-02
I0211 03:24:11.695996 22509476222784 run_lib.py:146] step: 283800, eval_loss: 4.29843e-02
I0211 03:24:30.236770 22509476222784 run_lib.py:133] step: 283850, training_loss: 5.25578e-02
I0211 03:24:48.824899 22509476222784 run_lib.py:133] step: 283900, training_loss: 4.25414e-02
I0211 03:24:48.995538 22509476222784 run_lib.py:146] step: 283900, eval_loss: 5.12652e-02
I0211 03:25:07.402530 22509476222784 run_lib.py:133] step: 283950, training_loss: 3.74016e-02
I0211 03:25:25.912978 22509476222784 run_lib.py:133] step: 284000, training_loss: 3.54922e-02
I0211 03:25:26.098824 22509476222784 run_lib.py:146] step: 284000, eval_loss: 3.33811e-02
I0211 03:25:44.852684 22509476222784 run_lib.py:133] step: 284050, training_loss: 3.27165e-02
I0211 03:26:03.470927 22509476222784 run_lib.py:133] step: 284100, training_loss: 4.04129e-02
I0211 03:26:03.636884 22509476222784 run_lib.py:146] step: 284100, eval_loss: 3.69470e-02
I0211 03:26:22.111784 22509476222784 run_lib.py:133] step: 284150, training_loss: 3.44772e-02
I0211 03:26:40.620151 22509476222784 run_lib.py:133] step: 284200, training_loss: 4.31912e-02
I0211 03:26:40.784756 22509476222784 run_lib.py:146] step: 284200, eval_loss: 3.56013e-02
I0211 03:26:59.334041 22509476222784 run_lib.py:133] step: 284250, training_loss: 3.51935e-02
I0211 03:27:18.048451 22509476222784 run_lib.py:133] step: 284300, training_loss: 3.94504e-02
I0211 03:27:18.221947 22509476222784 run_lib.py:146] step: 284300, eval_loss: 4.47644e-02
I0211 03:27:36.701160 22509476222784 run_lib.py:133] step: 284350, training_loss: 3.87526e-02
I0211 03:27:55.188200 22509476222784 run_lib.py:133] step: 284400, training_loss: 2.89796e-02
I0211 03:27:55.410369 22509476222784 run_lib.py:146] step: 284400, eval_loss: 3.55996e-02
I0211 03:28:13.935396 22509476222784 run_lib.py:133] step: 284450, training_loss: 4.36243e-02
I0211 03:28:32.629810 22509476222784 run_lib.py:133] step: 284500, training_loss: 4.46023e-02
I0211 03:28:32.801690 22509476222784 run_lib.py:146] step: 284500, eval_loss: 3.29730e-02
I0211 03:28:51.280377 22509476222784 run_lib.py:133] step: 284550, training_loss: 4.66593e-02
I0211 03:29:09.896680 22509476222784 run_lib.py:133] step: 284600, training_loss: 5.05681e-02
I0211 03:29:10.061818 22509476222784 run_lib.py:146] step: 284600, eval_loss: 4.81254e-02
I0211 03:29:28.551710 22509476222784 run_lib.py:133] step: 284650, training_loss: 4.85555e-02
I0211 03:29:47.058041 22509476222784 run_lib.py:133] step: 284700, training_loss: 4.40386e-02
I0211 03:29:47.220556 22509476222784 run_lib.py:146] step: 284700, eval_loss: 3.34945e-02
I0211 03:30:05.913362 22509476222784 run_lib.py:133] step: 284750, training_loss: 4.48670e-02
I0211 03:30:24.472738 22509476222784 run_lib.py:133] step: 284800, training_loss: 3.88795e-02
I0211 03:30:24.658741 22509476222784 run_lib.py:146] step: 284800, eval_loss: 3.95504e-02
I0211 03:30:43.171619 22509476222784 run_lib.py:133] step: 284850, training_loss: 4.42415e-02
I0211 03:31:01.669824 22509476222784 run_lib.py:133] step: 284900, training_loss: 3.90196e-02
I0211 03:31:01.832772 22509476222784 run_lib.py:146] step: 284900, eval_loss: 3.81147e-02
I0211 03:31:20.534104 22509476222784 run_lib.py:133] step: 284950, training_loss: 4.00780e-02
I0211 03:31:38.936740 22509476222784 run_lib.py:133] step: 285000, training_loss: 2.33804e-02
I0211 03:31:39.107833 22509476222784 run_lib.py:146] step: 285000, eval_loss: 3.31127e-02
I0211 03:31:57.765863 22509476222784 run_lib.py:133] step: 285050, training_loss: 4.57691e-02
I0211 03:32:16.176974 22509476222784 run_lib.py:133] step: 285100, training_loss: 5.08850e-02
I0211 03:32:16.352535 22509476222784 run_lib.py:146] step: 285100, eval_loss: 4.79512e-02
I0211 03:32:35.065665 22509476222784 run_lib.py:133] step: 285150, training_loss: 3.53461e-02
I0211 03:32:53.533992 22509476222784 run_lib.py:133] step: 285200, training_loss: 3.52655e-02
I0211 03:32:53.703545 22509476222784 run_lib.py:146] step: 285200, eval_loss: 3.44443e-02
I0211 03:33:12.202400 22509476222784 run_lib.py:133] step: 285250, training_loss: 4.76609e-02
I0211 03:33:30.798283 22509476222784 run_lib.py:133] step: 285300, training_loss: 4.02374e-02
I0211 03:33:30.967641 22509476222784 run_lib.py:146] step: 285300, eval_loss: 3.75768e-02
I0211 03:33:49.487588 22509476222784 run_lib.py:133] step: 285350, training_loss: 4.57155e-02
I0211 03:34:08.141880 22509476222784 run_lib.py:133] step: 285400, training_loss: 4.34960e-02
I0211 03:34:08.328883 22509476222784 run_lib.py:146] step: 285400, eval_loss: 4.51378e-02
I0211 03:34:26.899513 22509476222784 run_lib.py:133] step: 285450, training_loss: 4.42260e-02
I0211 03:34:45.471548 22509476222784 run_lib.py:133] step: 285500, training_loss: 4.00341e-02
I0211 03:34:45.642623 22509476222784 run_lib.py:146] step: 285500, eval_loss: 4.25529e-02
I0211 03:35:04.281372 22509476222784 run_lib.py:133] step: 285550, training_loss: 4.99531e-02
I0211 03:35:22.787945 22509476222784 run_lib.py:133] step: 285600, training_loss: 4.94653e-02
I0211 03:35:22.956161 22509476222784 run_lib.py:146] step: 285600, eval_loss: 4.87256e-02
I0211 03:35:41.494999 22509476222784 run_lib.py:133] step: 285650, training_loss: 3.68849e-02
I0211 03:36:00.234851 22509476222784 run_lib.py:133] step: 285700, training_loss: 3.96604e-02
I0211 03:36:00.397233 22509476222784 run_lib.py:146] step: 285700, eval_loss: 3.87407e-02
I0211 03:36:18.887239 22509476222784 run_lib.py:133] step: 285750, training_loss: 6.25867e-02
I0211 03:36:37.317336 22509476222784 run_lib.py:133] step: 285800, training_loss: 4.29329e-02
I0211 03:36:37.478333 22509476222784 run_lib.py:146] step: 285800, eval_loss: 4.35400e-02
I0211 03:36:55.992900 22509476222784 run_lib.py:133] step: 285850, training_loss: 3.06207e-02
I0211 03:37:14.455766 22509476222784 run_lib.py:133] step: 285900, training_loss: 4.13409e-02
I0211 03:37:14.617561 22509476222784 run_lib.py:146] step: 285900, eval_loss: 5.06581e-02
I0211 03:37:33.116716 22509476222784 run_lib.py:133] step: 285950, training_loss: 5.11952e-02
I0211 03:37:51.644882 22509476222784 run_lib.py:133] step: 286000, training_loss: 4.30327e-02
I0211 03:37:51.809560 22509476222784 run_lib.py:146] step: 286000, eval_loss: 4.60657e-02
I0211 03:38:10.469298 22509476222784 run_lib.py:133] step: 286050, training_loss: 3.72298e-02
I0211 03:38:29.059248 22509476222784 run_lib.py:133] step: 286100, training_loss: 4.85220e-02
I0211 03:38:29.223637 22509476222784 run_lib.py:146] step: 286100, eval_loss: 5.60313e-02
I0211 03:38:47.669915 22509476222784 run_lib.py:133] step: 286150, training_loss: 4.37312e-02
I0211 03:39:06.199265 22509476222784 run_lib.py:133] step: 286200, training_loss: 5.41905e-02
I0211 03:39:06.366823 22509476222784 run_lib.py:146] step: 286200, eval_loss: 4.76151e-02
I0211 03:39:25.098208 22509476222784 run_lib.py:133] step: 286250, training_loss: 5.93637e-02
I0211 03:39:43.625651 22509476222784 run_lib.py:133] step: 286300, training_loss: 4.18495e-02
I0211 03:39:43.786780 22509476222784 run_lib.py:146] step: 286300, eval_loss: 5.03581e-02
I0211 03:40:02.439089 22509476222784 run_lib.py:133] step: 286350, training_loss: 4.29359e-02
I0211 03:40:20.910362 22509476222784 run_lib.py:133] step: 286400, training_loss: 4.84058e-02
I0211 03:40:21.075671 22509476222784 run_lib.py:146] step: 286400, eval_loss: 4.77324e-02
I0211 03:40:39.703942 22509476222784 run_lib.py:133] step: 286450, training_loss: 5.59618e-02
I0211 03:40:58.297922 22509476222784 run_lib.py:133] step: 286500, training_loss: 4.12330e-02
I0211 03:40:58.485721 22509476222784 run_lib.py:146] step: 286500, eval_loss: 5.01813e-02
I0211 03:41:17.218103 22509476222784 run_lib.py:133] step: 286550, training_loss: 4.22415e-02
I0211 03:41:35.705807 22509476222784 run_lib.py:133] step: 286600, training_loss: 3.25684e-02
I0211 03:41:35.870695 22509476222784 run_lib.py:146] step: 286600, eval_loss: 4.77818e-02
I0211 03:41:54.338675 22509476222784 run_lib.py:133] step: 286650, training_loss: 3.90336e-02
I0211 03:42:12.907330 22509476222784 run_lib.py:133] step: 286700, training_loss: 3.77405e-02
I0211 03:42:13.074480 22509476222784 run_lib.py:146] step: 286700, eval_loss: 3.82680e-02
I0211 03:42:31.512505 22509476222784 run_lib.py:133] step: 286750, training_loss: 3.80361e-02
I0211 03:42:50.096315 22509476222784 run_lib.py:133] step: 286800, training_loss: 4.15755e-02
I0211 03:42:50.263168 22509476222784 run_lib.py:146] step: 286800, eval_loss: 4.97509e-02
I0211 03:43:09.027073 22509476222784 run_lib.py:133] step: 286850, training_loss: 5.00441e-02
I0211 03:43:27.582194 22509476222784 run_lib.py:133] step: 286900, training_loss: 4.17730e-02
I0211 03:43:27.774784 22509476222784 run_lib.py:146] step: 286900, eval_loss: 4.95906e-02
I0211 03:43:46.291001 22509476222784 run_lib.py:133] step: 286950, training_loss: 4.62413e-02
I0211 03:44:04.674498 22509476222784 run_lib.py:133] step: 287000, training_loss: 4.88113e-02
I0211 03:44:04.840900 22509476222784 run_lib.py:146] step: 287000, eval_loss: 5.09826e-02
I0211 03:44:23.380070 22509476222784 run_lib.py:133] step: 287050, training_loss: 3.70577e-02
I0211 03:44:42.190173 22509476222784 run_lib.py:133] step: 287100, training_loss: 4.31894e-02
I0211 03:44:42.388496 22509476222784 run_lib.py:146] step: 287100, eval_loss: 5.14816e-02
I0211 03:45:00.897799 22509476222784 run_lib.py:133] step: 287150, training_loss: 4.13708e-02
I0211 03:45:19.362707 22509476222784 run_lib.py:133] step: 287200, training_loss: 4.95615e-02
I0211 03:45:19.526686 22509476222784 run_lib.py:146] step: 287200, eval_loss: 4.64277e-02
I0211 03:45:38.020243 22509476222784 run_lib.py:133] step: 287250, training_loss: 4.29469e-02
I0211 03:45:56.678304 22509476222784 run_lib.py:133] step: 287300, training_loss: 4.47852e-02
I0211 03:45:56.843824 22509476222784 run_lib.py:146] step: 287300, eval_loss: 5.44064e-02
I0211 03:46:15.399303 22509476222784 run_lib.py:133] step: 287350, training_loss: 4.17064e-02
I0211 03:46:34.062660 22509476222784 run_lib.py:133] step: 287400, training_loss: 5.30233e-02
I0211 03:46:34.228475 22509476222784 run_lib.py:146] step: 287400, eval_loss: 3.69574e-02
I0211 03:46:52.680605 22509476222784 run_lib.py:133] step: 287450, training_loss: 4.33743e-02
I0211 03:47:11.174071 22509476222784 run_lib.py:133] step: 287500, training_loss: 3.98265e-02
I0211 03:47:11.357655 22509476222784 run_lib.py:146] step: 287500, eval_loss: 4.77712e-02
I0211 03:47:29.959188 22509476222784 run_lib.py:133] step: 287550, training_loss: 6.62267e-02
I0211 03:47:48.609264 22509476222784 run_lib.py:133] step: 287600, training_loss: 3.84865e-02
I0211 03:47:48.780180 22509476222784 run_lib.py:146] step: 287600, eval_loss: 4.68088e-02
I0211 03:48:07.340978 22509476222784 run_lib.py:133] step: 287650, training_loss: 4.21270e-02
I0211 03:48:25.857498 22509476222784 run_lib.py:133] step: 287700, training_loss: 4.35259e-02
I0211 03:48:26.017617 22509476222784 run_lib.py:146] step: 287700, eval_loss: 4.30644e-02
I0211 03:48:44.662973 22509476222784 run_lib.py:133] step: 287750, training_loss: 4.99972e-02
I0211 03:49:03.127110 22509476222784 run_lib.py:133] step: 287800, training_loss: 4.26067e-02
I0211 03:49:03.309005 22509476222784 run_lib.py:146] step: 287800, eval_loss: 4.88560e-02
I0211 03:49:22.005801 22509476222784 run_lib.py:133] step: 287850, training_loss: 3.31096e-02
I0211 03:49:40.555536 22509476222784 run_lib.py:133] step: 287900, training_loss: 3.81086e-02
I0211 03:49:40.729768 22509476222784 run_lib.py:146] step: 287900, eval_loss: 4.19303e-02
I0211 03:49:59.253485 22509476222784 run_lib.py:133] step: 287950, training_loss: 4.81705e-02
I0211 03:50:17.717809 22509476222784 run_lib.py:133] step: 288000, training_loss: 4.67357e-02
I0211 03:50:17.882834 22509476222784 run_lib.py:146] step: 288000, eval_loss: 3.00145e-02
I0211 03:50:36.437004 22509476222784 run_lib.py:133] step: 288050, training_loss: 3.79030e-02
I0211 03:50:55.067778 22509476222784 run_lib.py:133] step: 288100, training_loss: 4.65009e-02
I0211 03:50:55.237520 22509476222784 run_lib.py:146] step: 288100, eval_loss: 4.38871e-02
I0211 03:51:13.765626 22509476222784 run_lib.py:133] step: 288150, training_loss: 4.11221e-02
I0211 03:51:32.464405 22509476222784 run_lib.py:133] step: 288200, training_loss: 4.03163e-02
I0211 03:51:32.624256 22509476222784 run_lib.py:146] step: 288200, eval_loss: 4.12253e-02
I0211 03:51:51.184323 22509476222784 run_lib.py:133] step: 288250, training_loss: 4.83619e-02
I0211 03:52:09.665334 22509476222784 run_lib.py:133] step: 288300, training_loss: 4.98444e-02
I0211 03:52:09.829644 22509476222784 run_lib.py:146] step: 288300, eval_loss: 4.37119e-02
I0211 03:52:28.450594 22509476222784 run_lib.py:133] step: 288350, training_loss: 3.80812e-02
I0211 03:52:47.020896 22509476222784 run_lib.py:133] step: 288400, training_loss: 4.16258e-02
I0211 03:52:47.202604 22509476222784 run_lib.py:146] step: 288400, eval_loss: 4.70160e-02
I0211 03:53:05.753938 22509476222784 run_lib.py:133] step: 288450, training_loss: 3.45794e-02
I0211 03:53:24.484453 22509476222784 run_lib.py:133] step: 288500, training_loss: 3.01017e-02
I0211 03:53:24.648998 22509476222784 run_lib.py:146] step: 288500, eval_loss: 3.60622e-02
I0211 03:53:43.163288 22509476222784 run_lib.py:133] step: 288550, training_loss: 4.40069e-02
I0211 03:54:01.648115 22509476222784 run_lib.py:133] step: 288600, training_loss: 4.31731e-02
I0211 03:54:01.955913 22509476222784 run_lib.py:146] step: 288600, eval_loss: 5.21179e-02
I0211 03:54:20.492296 22509476222784 run_lib.py:133] step: 288650, training_loss: 4.23951e-02
I0211 03:54:38.995826 22509476222784 run_lib.py:133] step: 288700, training_loss: 2.80624e-02
I0211 03:54:39.168128 22509476222784 run_lib.py:146] step: 288700, eval_loss: 4.52873e-02
I0211 03:54:57.687605 22509476222784 run_lib.py:133] step: 288750, training_loss: 4.21534e-02
I0211 03:55:16.145472 22509476222784 run_lib.py:133] step: 288800, training_loss: 4.54311e-02
I0211 03:55:16.311855 22509476222784 run_lib.py:146] step: 288800, eval_loss: 4.72591e-02
I0211 03:55:34.955693 22509476222784 run_lib.py:133] step: 288850, training_loss: 4.13593e-02
I0211 03:55:53.565855 22509476222784 run_lib.py:133] step: 288900, training_loss: 4.65503e-02
I0211 03:55:53.731736 22509476222784 run_lib.py:146] step: 288900, eval_loss: 5.03819e-02
I0211 03:56:12.186351 22509476222784 run_lib.py:133] step: 288950, training_loss: 3.59733e-02
I0211 03:56:30.784935 22509476222784 run_lib.py:133] step: 289000, training_loss: 5.11346e-02
I0211 03:56:30.950044 22509476222784 run_lib.py:146] step: 289000, eval_loss: 4.05747e-02
I0211 03:56:49.625112 22509476222784 run_lib.py:133] step: 289050, training_loss: 4.22842e-02
I0211 03:57:08.172929 22509476222784 run_lib.py:133] step: 289100, training_loss: 3.50351e-02
I0211 03:57:08.336649 22509476222784 run_lib.py:146] step: 289100, eval_loss: 3.27910e-02
I0211 03:57:26.840647 22509476222784 run_lib.py:133] step: 289150, training_loss: 4.50312e-02
I0211 03:57:45.335844 22509476222784 run_lib.py:133] step: 289200, training_loss: 3.93980e-02
I0211 03:57:45.498905 22509476222784 run_lib.py:146] step: 289200, eval_loss: 3.72178e-02
I0211 03:58:04.221006 22509476222784 run_lib.py:133] step: 289250, training_loss: 3.54697e-02
I0211 03:58:22.771691 22509476222784 run_lib.py:133] step: 289300, training_loss: 3.47138e-02
I0211 03:58:22.968664 22509476222784 run_lib.py:146] step: 289300, eval_loss: 3.98183e-02
I0211 03:58:41.670193 22509476222784 run_lib.py:133] step: 289350, training_loss: 3.95165e-02
I0211 03:59:00.116131 22509476222784 run_lib.py:133] step: 289400, training_loss: 4.53482e-02
I0211 03:59:00.280724 22509476222784 run_lib.py:146] step: 289400, eval_loss: 3.88899e-02
I0211 03:59:18.938776 22509476222784 run_lib.py:133] step: 289450, training_loss: 3.40701e-02
I0211 03:59:37.509934 22509476222784 run_lib.py:133] step: 289500, training_loss: 4.48100e-02
I0211 03:59:37.673432 22509476222784 run_lib.py:146] step: 289500, eval_loss: 4.93793e-02
I0211 03:59:56.240558 22509476222784 run_lib.py:133] step: 289550, training_loss: 4.25059e-02
I0211 04:00:14.871016 22509476222784 run_lib.py:133] step: 289600, training_loss: 3.75610e-02
I0211 04:00:15.031301 22509476222784 run_lib.py:146] step: 289600, eval_loss: 3.74373e-02
I0211 04:00:33.505071 22509476222784 run_lib.py:133] step: 289650, training_loss: 3.64347e-02
I0211 04:00:52.146157 22509476222784 run_lib.py:133] step: 289700, training_loss: 3.58787e-02
I0211 04:00:52.308447 22509476222784 run_lib.py:146] step: 289700, eval_loss: 4.59471e-02
I0211 04:01:10.796572 22509476222784 run_lib.py:133] step: 289750, training_loss: 4.11366e-02
I0211 04:01:29.391041 22509476222784 run_lib.py:133] step: 289800, training_loss: 4.82815e-02
I0211 04:01:29.563708 22509476222784 run_lib.py:146] step: 289800, eval_loss: 3.67566e-02
I0211 04:01:48.129710 22509476222784 run_lib.py:133] step: 289850, training_loss: 5.80295e-02
I0211 04:02:06.775736 22509476222784 run_lib.py:133] step: 289900, training_loss: 2.95307e-02
I0211 04:02:06.943475 22509476222784 run_lib.py:146] step: 289900, eval_loss: 4.59602e-02
I0211 04:02:25.408442 22509476222784 run_lib.py:133] step: 289950, training_loss: 4.21915e-02
I0211 04:02:43.900375 22509476222784 run_lib.py:133] step: 290000, training_loss: 4.17675e-02
I0211 04:02:44.635530 22509476222784 run_lib.py:146] step: 290000, eval_loss: 3.87313e-02
I0211 04:03:06.237493 22509476222784 run_lib.py:133] step: 290050, training_loss: 3.45393e-02
I0211 04:03:24.788871 22509476222784 run_lib.py:133] step: 290100, training_loss: 4.86085e-02
I0211 04:03:24.953407 22509476222784 run_lib.py:146] step: 290100, eval_loss: 3.69288e-02
I0211 04:03:43.516630 22509476222784 run_lib.py:133] step: 290150, training_loss: 4.04085e-02
I0211 04:04:02.302747 22509476222784 run_lib.py:133] step: 290200, training_loss: 4.76844e-02
I0211 04:04:02.463715 22509476222784 run_lib.py:146] step: 290200, eval_loss: 5.85204e-02
I0211 04:04:20.977877 22509476222784 run_lib.py:133] step: 290250, training_loss: 4.71222e-02
I0211 04:04:39.556665 22509476222784 run_lib.py:133] step: 290300, training_loss: 3.43577e-02
I0211 04:04:39.754622 22509476222784 run_lib.py:146] step: 290300, eval_loss: 4.00099e-02
I0211 04:04:58.332939 22509476222784 run_lib.py:133] step: 290350, training_loss: 4.19029e-02
I0211 04:05:16.945479 22509476222784 run_lib.py:133] step: 290400, training_loss: 4.03874e-02
I0211 04:05:17.109757 22509476222784 run_lib.py:146] step: 290400, eval_loss: 3.99034e-02
I0211 04:05:35.625805 22509476222784 run_lib.py:133] step: 290450, training_loss: 4.98782e-02
I0211 04:05:54.215470 22509476222784 run_lib.py:133] step: 290500, training_loss: 3.46369e-02
I0211 04:05:54.378656 22509476222784 run_lib.py:146] step: 290500, eval_loss: 4.25633e-02
I0211 04:06:12.895913 22509476222784 run_lib.py:133] step: 290550, training_loss: 4.04738e-02
I0211 04:06:31.482913 22509476222784 run_lib.py:133] step: 290600, training_loss: 3.53254e-02
I0211 04:06:31.646566 22509476222784 run_lib.py:146] step: 290600, eval_loss: 4.38479e-02
I0211 04:06:50.348489 22509476222784 run_lib.py:133] step: 290650, training_loss: 4.97215e-02
I0211 04:07:08.936407 22509476222784 run_lib.py:133] step: 290700, training_loss: 4.78833e-02
I0211 04:07:09.101804 22509476222784 run_lib.py:146] step: 290700, eval_loss: 4.60515e-02
I0211 04:07:27.623435 22509476222784 run_lib.py:133] step: 290750, training_loss: 4.58599e-02
I0211 04:07:46.096363 22509476222784 run_lib.py:133] step: 290800, training_loss: 4.37535e-02
I0211 04:07:46.262005 22509476222784 run_lib.py:146] step: 290800, eval_loss: 4.96727e-02
I0211 04:08:04.944901 22509476222784 run_lib.py:133] step: 290850, training_loss: 4.50564e-02
I0211 04:08:23.477010 22509476222784 run_lib.py:133] step: 290900, training_loss: 3.98531e-02
I0211 04:08:23.641886 22509476222784 run_lib.py:146] step: 290900, eval_loss: 3.93491e-02
I0211 04:08:42.238927 22509476222784 run_lib.py:133] step: 290950, training_loss: 4.97422e-02
I0211 04:09:00.681157 22509476222784 run_lib.py:133] step: 291000, training_loss: 5.27449e-02
I0211 04:09:00.845822 22509476222784 run_lib.py:146] step: 291000, eval_loss: 4.92982e-02
I0211 04:09:19.490470 22509476222784 run_lib.py:133] step: 291050, training_loss: 6.05189e-02
I0211 04:09:37.981451 22509476222784 run_lib.py:133] step: 291100, training_loss: 3.75260e-02
I0211 04:09:38.143769 22509476222784 run_lib.py:146] step: 291100, eval_loss: 4.57509e-02
I0211 04:09:56.668026 22509476222784 run_lib.py:133] step: 291150, training_loss: 3.25327e-02
I0211 04:10:15.383828 22509476222784 run_lib.py:133] step: 291200, training_loss: 5.00832e-02
I0211 04:10:15.548752 22509476222784 run_lib.py:146] step: 291200, eval_loss: 4.32489e-02
I0211 04:10:34.026016 22509476222784 run_lib.py:133] step: 291250, training_loss: 4.31371e-02
I0211 04:10:52.613262 22509476222784 run_lib.py:133] step: 291300, training_loss: 5.39584e-02
I0211 04:10:52.779897 22509476222784 run_lib.py:146] step: 291300, eval_loss: 4.85867e-02
I0211 04:11:11.244184 22509476222784 run_lib.py:133] step: 291350, training_loss: 3.17943e-02
I0211 04:11:29.807969 22509476222784 run_lib.py:133] step: 291400, training_loss: 3.78332e-02
I0211 04:11:29.972896 22509476222784 run_lib.py:146] step: 291400, eval_loss: 4.16154e-02
I0211 04:11:48.660454 22509476222784 run_lib.py:133] step: 291450, training_loss: 4.27865e-02
I0211 04:12:07.129843 22509476222784 run_lib.py:133] step: 291500, training_loss: 4.03891e-02
I0211 04:12:07.292676 22509476222784 run_lib.py:146] step: 291500, eval_loss: 4.83903e-02
I0211 04:12:25.828046 22509476222784 run_lib.py:133] step: 291550, training_loss: 3.50853e-02
I0211 04:12:44.481849 22509476222784 run_lib.py:133] step: 291600, training_loss: 4.37639e-02
I0211 04:12:44.641582 22509476222784 run_lib.py:146] step: 291600, eval_loss: 3.44418e-02
I0211 04:13:03.087477 22509476222784 run_lib.py:133] step: 291650, training_loss: 5.16256e-02
I0211 04:13:21.497041 22509476222784 run_lib.py:133] step: 291700, training_loss: 3.98189e-02
I0211 04:13:21.672899 22509476222784 run_lib.py:146] step: 291700, eval_loss: 4.93429e-02
I0211 04:13:40.298870 22509476222784 run_lib.py:133] step: 291750, training_loss: 4.49660e-02
I0211 04:13:58.866146 22509476222784 run_lib.py:133] step: 291800, training_loss: 4.76965e-02
I0211 04:13:59.040695 22509476222784 run_lib.py:146] step: 291800, eval_loss: 4.16700e-02
I0211 04:14:17.502601 22509476222784 run_lib.py:133] step: 291850, training_loss: 3.91891e-02
I0211 04:14:36.024636 22509476222784 run_lib.py:133] step: 291900, training_loss: 4.90333e-02
I0211 04:14:36.187718 22509476222784 run_lib.py:146] step: 291900, eval_loss: 3.06379e-02
I0211 04:14:54.871782 22509476222784 run_lib.py:133] step: 291950, training_loss: 5.54806e-02
I0211 04:15:13.472065 22509476222784 run_lib.py:133] step: 292000, training_loss: 4.39626e-02
I0211 04:15:13.635797 22509476222784 run_lib.py:146] step: 292000, eval_loss: 4.00737e-02
I0211 04:15:32.127670 22509476222784 run_lib.py:133] step: 292050, training_loss: 3.23876e-02
I0211 04:15:50.612713 22509476222784 run_lib.py:133] step: 292100, training_loss: 4.82293e-02
I0211 04:15:50.773679 22509476222784 run_lib.py:146] step: 292100, eval_loss: 4.86766e-02
I0211 04:16:09.430347 22509476222784 run_lib.py:133] step: 292150, training_loss: 3.44287e-02
I0211 04:16:27.952336 22509476222784 run_lib.py:133] step: 292200, training_loss: 3.90882e-02
I0211 04:16:28.120623 22509476222784 run_lib.py:146] step: 292200, eval_loss: 4.89403e-02
I0211 04:16:46.775171 22509476222784 run_lib.py:133] step: 292250, training_loss: 4.50484e-02
I0211 04:17:05.371091 22509476222784 run_lib.py:133] step: 292300, training_loss: 5.76834e-02
I0211 04:17:05.536747 22509476222784 run_lib.py:146] step: 292300, eval_loss: 3.78551e-02
I0211 04:17:24.234908 22509476222784 run_lib.py:133] step: 292350, training_loss: 4.47683e-02
I0211 04:17:42.732987 22509476222784 run_lib.py:133] step: 292400, training_loss: 4.99733e-02
I0211 04:17:42.896429 22509476222784 run_lib.py:146] step: 292400, eval_loss: 3.99694e-02
I0211 04:18:01.543695 22509476222784 run_lib.py:133] step: 292450, training_loss: 3.30461e-02
I0211 04:18:20.007492 22509476222784 run_lib.py:133] step: 292500, training_loss: 3.90454e-02
I0211 04:18:20.171343 22509476222784 run_lib.py:146] step: 292500, eval_loss: 3.91626e-02
I0211 04:18:38.784217 22509476222784 run_lib.py:133] step: 292550, training_loss: 4.69230e-02
I0211 04:18:57.523324 22509476222784 run_lib.py:133] step: 292600, training_loss: 3.99886e-02
I0211 04:18:57.689783 22509476222784 run_lib.py:146] step: 292600, eval_loss: 4.04886e-02
I0211 04:19:16.110174 22509476222784 run_lib.py:133] step: 292650, training_loss: 4.41486e-02
I0211 04:19:34.609152 22509476222784 run_lib.py:133] step: 292700, training_loss: 4.20984e-02
I0211 04:19:34.793440 22509476222784 run_lib.py:146] step: 292700, eval_loss: 3.48168e-02
I0211 04:19:53.386590 22509476222784 run_lib.py:133] step: 292750, training_loss: 4.00936e-02
I0211 04:20:11.850878 22509476222784 run_lib.py:133] step: 292800, training_loss: 4.66777e-02
I0211 04:20:12.025655 22509476222784 run_lib.py:146] step: 292800, eval_loss: 4.41059e-02
I0211 04:20:30.732154 22509476222784 run_lib.py:133] step: 292850, training_loss: 4.54988e-02
I0211 04:20:49.224299 22509476222784 run_lib.py:133] step: 292900, training_loss: 4.88629e-02
I0211 04:20:49.388812 22509476222784 run_lib.py:146] step: 292900, eval_loss: 4.62747e-02
I0211 04:21:07.935724 22509476222784 run_lib.py:133] step: 292950, training_loss: 4.49301e-02
I0211 04:21:26.621508 22509476222784 run_lib.py:133] step: 293000, training_loss: 3.98296e-02
I0211 04:21:26.782350 22509476222784 run_lib.py:146] step: 293000, eval_loss: 4.96346e-02
I0211 04:21:45.283400 22509476222784 run_lib.py:133] step: 293050, training_loss: 4.29669e-02
I0211 04:22:03.818770 22509476222784 run_lib.py:133] step: 293100, training_loss: 3.73196e-02
I0211 04:22:03.995867 22509476222784 run_lib.py:146] step: 293100, eval_loss: 3.39738e-02
I0211 04:22:22.595649 22509476222784 run_lib.py:133] step: 293150, training_loss: 4.26315e-02
I0211 04:22:41.318012 22509476222784 run_lib.py:133] step: 293200, training_loss: 4.40402e-02
I0211 04:22:41.482846 22509476222784 run_lib.py:146] step: 293200, eval_loss: 3.90236e-02
I0211 04:23:00.003680 22509476222784 run_lib.py:133] step: 293250, training_loss: 4.36689e-02
I0211 04:23:18.555187 22509476222784 run_lib.py:133] step: 293300, training_loss: 4.36830e-02
I0211 04:23:18.719824 22509476222784 run_lib.py:146] step: 293300, eval_loss: 3.04493e-02
I0211 04:23:37.134326 22509476222784 run_lib.py:133] step: 293350, training_loss: 5.49422e-02
I0211 04:23:55.672447 22509476222784 run_lib.py:133] step: 293400, training_loss: 3.91939e-02
I0211 04:23:55.839489 22509476222784 run_lib.py:146] step: 293400, eval_loss: 4.72921e-02
I0211 04:24:14.555173 22509476222784 run_lib.py:133] step: 293450, training_loss: 3.69969e-02
I0211 04:24:33.111717 22509476222784 run_lib.py:133] step: 293500, training_loss: 4.66387e-02
I0211 04:24:33.273650 22509476222784 run_lib.py:146] step: 293500, eval_loss: 5.09813e-02
I0211 04:24:51.813324 22509476222784 run_lib.py:133] step: 293550, training_loss: 4.44903e-02
I0211 04:25:10.308126 22509476222784 run_lib.py:133] step: 293600, training_loss: 4.19750e-02
I0211 04:25:10.478523 22509476222784 run_lib.py:146] step: 293600, eval_loss: 4.74988e-02
I0211 04:25:29.164013 22509476222784 run_lib.py:133] step: 293650, training_loss: 4.96033e-02
I0211 04:25:47.729789 22509476222784 run_lib.py:133] step: 293700, training_loss: 2.62662e-02
I0211 04:25:47.894651 22509476222784 run_lib.py:146] step: 293700, eval_loss: 5.26614e-02
I0211 04:26:06.627571 22509476222784 run_lib.py:133] step: 293750, training_loss: 5.27886e-02
I0211 04:26:25.161271 22509476222784 run_lib.py:133] step: 293800, training_loss: 3.64394e-02
I0211 04:26:25.326564 22509476222784 run_lib.py:146] step: 293800, eval_loss: 4.83802e-02
I0211 04:26:43.964077 22509476222784 run_lib.py:133] step: 293850, training_loss: 5.09272e-02
I0211 04:27:02.557267 22509476222784 run_lib.py:133] step: 293900, training_loss: 4.26827e-02
I0211 04:27:02.720270 22509476222784 run_lib.py:146] step: 293900, eval_loss: 4.45887e-02
I0211 04:27:21.299552 22509476222784 run_lib.py:133] step: 293950, training_loss: 4.19194e-02
I0211 04:27:39.874805 22509476222784 run_lib.py:133] step: 294000, training_loss: 3.48014e-02
I0211 04:27:40.034548 22509476222784 run_lib.py:146] step: 294000, eval_loss: 4.34181e-02
I0211 04:27:58.529860 22509476222784 run_lib.py:133] step: 294050, training_loss: 3.58006e-02
I0211 04:28:17.216030 22509476222784 run_lib.py:133] step: 294100, training_loss: 4.80272e-02
I0211 04:28:17.381822 22509476222784 run_lib.py:146] step: 294100, eval_loss: 3.88563e-02
I0211 04:28:35.892457 22509476222784 run_lib.py:133] step: 294150, training_loss: 3.86528e-02
I0211 04:28:54.417775 22509476222784 run_lib.py:133] step: 294200, training_loss: 3.63900e-02
I0211 04:28:54.581877 22509476222784 run_lib.py:146] step: 294200, eval_loss: 4.10607e-02
I0211 04:29:13.263911 22509476222784 run_lib.py:133] step: 294250, training_loss: 4.07690e-02
I0211 04:29:31.786392 22509476222784 run_lib.py:133] step: 294300, training_loss: 4.06268e-02
I0211 04:29:31.952789 22509476222784 run_lib.py:146] step: 294300, eval_loss: 5.87924e-02
I0211 04:29:50.468278 22509476222784 run_lib.py:133] step: 294350, training_loss: 5.08285e-02
I0211 04:30:09.157949 22509476222784 run_lib.py:133] step: 294400, training_loss: 4.12057e-02
I0211 04:30:09.319694 22509476222784 run_lib.py:146] step: 294400, eval_loss: 5.03196e-02
I0211 04:30:27.818728 22509476222784 run_lib.py:133] step: 294450, training_loss: 4.71252e-02
I0211 04:30:46.358675 22509476222784 run_lib.py:133] step: 294500, training_loss: 3.86932e-02
I0211 04:30:46.705599 22509476222784 run_lib.py:146] step: 294500, eval_loss: 3.54648e-02
I0211 04:31:05.142022 22509476222784 run_lib.py:133] step: 294550, training_loss: 4.27740e-02
I0211 04:31:23.627396 22509476222784 run_lib.py:133] step: 294600, training_loss: 3.69568e-02
I0211 04:31:23.793889 22509476222784 run_lib.py:146] step: 294600, eval_loss: 4.28961e-02
I0211 04:31:42.295457 22509476222784 run_lib.py:133] step: 294650, training_loss: 4.05069e-02
I0211 04:32:00.806701 22509476222784 run_lib.py:133] step: 294700, training_loss: 4.98551e-02
I0211 04:32:00.970652 22509476222784 run_lib.py:146] step: 294700, eval_loss: 4.60532e-02
I0211 04:32:19.570335 22509476222784 run_lib.py:133] step: 294750, training_loss: 3.34927e-02
I0211 04:32:38.297971 22509476222784 run_lib.py:133] step: 294800, training_loss: 4.11319e-02
I0211 04:32:38.463857 22509476222784 run_lib.py:146] step: 294800, eval_loss: 5.15711e-02
I0211 04:32:56.930898 22509476222784 run_lib.py:133] step: 294850, training_loss: 4.90043e-02
I0211 04:33:15.442296 22509476222784 run_lib.py:133] step: 294900, training_loss: 3.81599e-02
I0211 04:33:15.603683 22509476222784 run_lib.py:146] step: 294900, eval_loss: 3.76330e-02
I0211 04:33:34.278156 22509476222784 run_lib.py:133] step: 294950, training_loss: 2.78432e-02
I0211 04:33:52.880966 22509476222784 run_lib.py:133] step: 295000, training_loss: 4.75615e-02
I0211 04:33:53.053961 22509476222784 run_lib.py:146] step: 295000, eval_loss: 4.03018e-02
I0211 04:34:11.617878 22509476222784 run_lib.py:133] step: 295050, training_loss: 3.88508e-02
I0211 04:34:30.057569 22509476222784 run_lib.py:133] step: 295100, training_loss: 4.46936e-02
I0211 04:34:30.222607 22509476222784 run_lib.py:146] step: 295100, eval_loss: 4.62990e-02
I0211 04:34:48.760388 22509476222784 run_lib.py:133] step: 295150, training_loss: 4.54031e-02
I0211 04:35:07.219424 22509476222784 run_lib.py:133] step: 295200, training_loss: 4.24784e-02
I0211 04:35:07.383733 22509476222784 run_lib.py:146] step: 295200, eval_loss: 5.02660e-02
I0211 04:35:26.029357 22509476222784 run_lib.py:133] step: 295250, training_loss: 4.89420e-02
I0211 04:35:44.618699 22509476222784 run_lib.py:133] step: 295300, training_loss: 4.85613e-02
I0211 04:35:44.782801 22509476222784 run_lib.py:146] step: 295300, eval_loss: 4.35767e-02
I0211 04:36:03.481428 22509476222784 run_lib.py:133] step: 295350, training_loss: 4.27102e-02
I0211 04:36:21.925827 22509476222784 run_lib.py:133] step: 295400, training_loss: 4.35095e-02
I0211 04:36:22.086621 22509476222784 run_lib.py:146] step: 295400, eval_loss: 3.64560e-02
I0211 04:36:40.610002 22509476222784 run_lib.py:133] step: 295450, training_loss: 4.85280e-02
I0211 04:36:59.309021 22509476222784 run_lib.py:133] step: 295500, training_loss: 4.00447e-02
I0211 04:36:59.472485 22509476222784 run_lib.py:146] step: 295500, eval_loss: 4.78683e-02
I0211 04:37:18.009839 22509476222784 run_lib.py:133] step: 295550, training_loss: 3.65160e-02
I0211 04:37:36.804378 22509476222784 run_lib.py:133] step: 295600, training_loss: 3.80694e-02
I0211 04:37:36.970609 22509476222784 run_lib.py:146] step: 295600, eval_loss: 4.01156e-02
I0211 04:37:55.388660 22509476222784 run_lib.py:133] step: 295650, training_loss: 4.14395e-02
I0211 04:38:13.749301 22509476222784 run_lib.py:133] step: 295700, training_loss: 4.94170e-02
I0211 04:38:13.912469 22509476222784 run_lib.py:146] step: 295700, eval_loss: 4.48974e-02
I0211 04:38:32.596657 22509476222784 run_lib.py:133] step: 295750, training_loss: 3.52823e-02
I0211 04:38:50.999986 22509476222784 run_lib.py:133] step: 295800, training_loss: 4.18263e-02
I0211 04:38:51.161567 22509476222784 run_lib.py:146] step: 295800, eval_loss: 4.29779e-02
I0211 04:39:09.686966 22509476222784 run_lib.py:133] step: 295850, training_loss: 3.37046e-02
I0211 04:39:28.214421 22509476222784 run_lib.py:133] step: 295900, training_loss: 4.65865e-02
I0211 04:39:28.381846 22509476222784 run_lib.py:146] step: 295900, eval_loss: 3.80140e-02
I0211 04:39:47.107718 22509476222784 run_lib.py:133] step: 295950, training_loss: 4.18777e-02
I0211 04:40:05.563964 22509476222784 run_lib.py:133] step: 296000, training_loss: 4.16213e-02
I0211 04:40:05.729847 22509476222784 run_lib.py:146] step: 296000, eval_loss: 4.52603e-02
I0211 04:40:24.252496 22509476222784 run_lib.py:133] step: 296050, training_loss: 4.71586e-02
I0211 04:40:42.812168 22509476222784 run_lib.py:133] step: 296100, training_loss: 4.34685e-02
I0211 04:40:42.998653 22509476222784 run_lib.py:146] step: 296100, eval_loss: 4.45147e-02
I0211 04:41:01.574310 22509476222784 run_lib.py:133] step: 296150, training_loss: 5.45691e-02
I0211 04:41:20.097716 22509476222784 run_lib.py:133] step: 296200, training_loss: 4.88486e-02
I0211 04:41:20.280061 22509476222784 run_lib.py:146] step: 296200, eval_loss: 4.95127e-02
I0211 04:41:38.988024 22509476222784 run_lib.py:133] step: 296250, training_loss: 3.95950e-02
I0211 04:41:57.571280 22509476222784 run_lib.py:133] step: 296300, training_loss: 4.64238e-02
I0211 04:41:57.731637 22509476222784 run_lib.py:146] step: 296300, eval_loss: 4.49107e-02
I0211 04:42:16.264315 22509476222784 run_lib.py:133] step: 296350, training_loss: 3.45029e-02
I0211 04:42:34.807024 22509476222784 run_lib.py:133] step: 296400, training_loss: 4.56123e-02
I0211 04:42:34.976476 22509476222784 run_lib.py:146] step: 296400, eval_loss: 3.96569e-02
I0211 04:42:53.756807 22509476222784 run_lib.py:133] step: 296450, training_loss: 3.47740e-02
I0211 04:43:12.306404 22509476222784 run_lib.py:133] step: 296500, training_loss: 3.68107e-02
I0211 04:43:12.480843 22509476222784 run_lib.py:146] step: 296500, eval_loss: 3.71145e-02
I0211 04:43:31.116674 22509476222784 run_lib.py:133] step: 296550, training_loss: 5.84962e-02
I0211 04:43:49.644902 22509476222784 run_lib.py:133] step: 296600, training_loss: 3.35639e-02
I0211 04:43:49.808675 22509476222784 run_lib.py:146] step: 296600, eval_loss: 5.85363e-02
I0211 04:44:08.449039 22509476222784 run_lib.py:133] step: 296650, training_loss: 4.24576e-02
I0211 04:44:27.075166 22509476222784 run_lib.py:133] step: 296700, training_loss: 4.22890e-02
I0211 04:44:27.307422 22509476222784 run_lib.py:146] step: 296700, eval_loss: 4.16844e-02
I0211 04:44:46.039856 22509476222784 run_lib.py:133] step: 296750, training_loss: 3.49970e-02
I0211 04:45:04.578685 22509476222784 run_lib.py:133] step: 296800, training_loss: 4.43676e-02
I0211 04:45:04.759708 22509476222784 run_lib.py:146] step: 296800, eval_loss: 3.73471e-02
I0211 04:45:23.296622 22509476222784 run_lib.py:133] step: 296850, training_loss: 4.94855e-02
I0211 04:45:41.850579 22509476222784 run_lib.py:133] step: 296900, training_loss: 4.70201e-02
I0211 04:45:42.014826 22509476222784 run_lib.py:146] step: 296900, eval_loss: 5.91437e-02
I0211 04:46:00.555229 22509476222784 run_lib.py:133] step: 296950, training_loss: 4.61597e-02
I0211 04:46:19.159279 22509476222784 run_lib.py:133] step: 297000, training_loss: 3.98545e-02
I0211 04:46:19.327559 22509476222784 run_lib.py:146] step: 297000, eval_loss: 2.99259e-02
I0211 04:46:37.954462 22509476222784 run_lib.py:133] step: 297050, training_loss: 4.91525e-02
I0211 04:46:56.591950 22509476222784 run_lib.py:133] step: 297100, training_loss: 4.31922e-02
I0211 04:46:56.757616 22509476222784 run_lib.py:146] step: 297100, eval_loss: 4.40976e-02
I0211 04:47:15.271881 22509476222784 run_lib.py:133] step: 297150, training_loss: 5.09061e-02
I0211 04:47:33.814530 22509476222784 run_lib.py:133] step: 297200, training_loss: 4.51904e-02
I0211 04:47:33.982899 22509476222784 run_lib.py:146] step: 297200, eval_loss: 4.43348e-02
I0211 04:47:52.618439 22509476222784 run_lib.py:133] step: 297250, training_loss: 3.67862e-02
I0211 04:48:11.312025 22509476222784 run_lib.py:133] step: 297300, training_loss: 3.69206e-02
I0211 04:48:11.473725 22509476222784 run_lib.py:146] step: 297300, eval_loss: 4.26472e-02
I0211 04:48:30.021532 22509476222784 run_lib.py:133] step: 297350, training_loss: 4.28229e-02
I0211 04:48:48.539876 22509476222784 run_lib.py:133] step: 297400, training_loss: 4.07366e-02
I0211 04:48:48.704774 22509476222784 run_lib.py:146] step: 297400, eval_loss: 4.18108e-02
I0211 04:49:07.192902 22509476222784 run_lib.py:133] step: 297450, training_loss: 4.52729e-02
I0211 04:49:25.820856 22509476222784 run_lib.py:133] step: 297500, training_loss: 4.25974e-02
I0211 04:49:26.003049 22509476222784 run_lib.py:146] step: 297500, eval_loss: 3.41311e-02
I0211 04:49:44.532227 22509476222784 run_lib.py:133] step: 297550, training_loss: 5.48448e-02
I0211 04:50:03.171476 22509476222784 run_lib.py:133] step: 297600, training_loss: 4.99374e-02
I0211 04:50:03.337942 22509476222784 run_lib.py:146] step: 297600, eval_loss: 4.79166e-02
I0211 04:50:21.888866 22509476222784 run_lib.py:133] step: 297650, training_loss: 4.65393e-02
I0211 04:50:40.399293 22509476222784 run_lib.py:133] step: 297700, training_loss: 4.86658e-02
I0211 04:50:40.562730 22509476222784 run_lib.py:146] step: 297700, eval_loss: 3.67112e-02
I0211 04:50:59.189294 22509476222784 run_lib.py:133] step: 297750, training_loss: 3.86344e-02
I0211 04:51:17.787586 22509476222784 run_lib.py:133] step: 297800, training_loss: 4.69907e-02
I0211 04:51:17.951786 22509476222784 run_lib.py:146] step: 297800, eval_loss: 5.04732e-02
I0211 04:51:36.532246 22509476222784 run_lib.py:133] step: 297850, training_loss: 3.47665e-02
I0211 04:51:55.061814 22509476222784 run_lib.py:133] step: 297900, training_loss: 3.18541e-02
I0211 04:51:55.227889 22509476222784 run_lib.py:146] step: 297900, eval_loss: 4.18265e-02
I0211 04:52:13.823894 22509476222784 run_lib.py:133] step: 297950, training_loss: 4.38052e-02
I0211 04:52:32.294215 22509476222784 run_lib.py:133] step: 298000, training_loss: 4.36425e-02
I0211 04:52:32.458654 22509476222784 run_lib.py:146] step: 298000, eval_loss: 4.93170e-02
I0211 04:52:51.157301 22509476222784 run_lib.py:133] step: 298050, training_loss: 3.58273e-02
I0211 04:53:09.651044 22509476222784 run_lib.py:133] step: 298100, training_loss: 3.98500e-02
I0211 04:53:09.815712 22509476222784 run_lib.py:146] step: 298100, eval_loss: 3.85992e-02
I0211 04:53:28.501631 22509476222784 run_lib.py:133] step: 298150, training_loss: 3.65643e-02
I0211 04:53:47.053046 22509476222784 run_lib.py:133] step: 298200, training_loss: 5.07179e-02
I0211 04:53:47.215701 22509476222784 run_lib.py:146] step: 298200, eval_loss: 3.91323e-02
I0211 04:54:05.691642 22509476222784 run_lib.py:133] step: 298250, training_loss: 3.02026e-02
I0211 04:54:24.363539 22509476222784 run_lib.py:133] step: 298300, training_loss: 5.20810e-02
I0211 04:54:24.542853 22509476222784 run_lib.py:146] step: 298300, eval_loss: 4.48308e-02
I0211 04:54:43.034632 22509476222784 run_lib.py:133] step: 298350, training_loss: 4.88351e-02
I0211 04:55:01.695581 22509476222784 run_lib.py:133] step: 298400, training_loss: 3.54379e-02
I0211 04:55:01.860638 22509476222784 run_lib.py:146] step: 298400, eval_loss: 4.29940e-02
I0211 04:55:20.348744 22509476222784 run_lib.py:133] step: 298450, training_loss: 3.51333e-02
I0211 04:55:38.771748 22509476222784 run_lib.py:133] step: 298500, training_loss: 4.18294e-02
I0211 04:55:38.934523 22509476222784 run_lib.py:146] step: 298500, eval_loss: 3.60700e-02
I0211 04:55:57.586946 22509476222784 run_lib.py:133] step: 298550, training_loss: 3.94353e-02
I0211 04:56:16.192158 22509476222784 run_lib.py:133] step: 298600, training_loss: 4.18198e-02
I0211 04:56:16.355848 22509476222784 run_lib.py:146] step: 298600, eval_loss: 3.65935e-02
I0211 04:56:34.801115 22509476222784 run_lib.py:133] step: 298650, training_loss: 5.01373e-02
I0211 04:56:53.418852 22509476222784 run_lib.py:133] step: 298700, training_loss: 4.48366e-02
I0211 04:56:53.579692 22509476222784 run_lib.py:146] step: 298700, eval_loss: 5.15473e-02
I0211 04:57:12.090771 22509476222784 run_lib.py:133] step: 298750, training_loss: 4.34971e-02
I0211 04:57:30.607959 22509476222784 run_lib.py:133] step: 298800, training_loss: 3.79095e-02
I0211 04:57:30.777782 22509476222784 run_lib.py:146] step: 298800, eval_loss: 4.54095e-02
I0211 04:57:49.440656 22509476222784 run_lib.py:133] step: 298850, training_loss: 4.52207e-02
I0211 04:58:07.952511 22509476222784 run_lib.py:133] step: 298900, training_loss: 4.54004e-02
I0211 04:58:08.119546 22509476222784 run_lib.py:146] step: 298900, eval_loss: 4.91188e-02
I0211 04:58:26.580176 22509476222784 run_lib.py:133] step: 298950, training_loss: 4.27215e-02
I0211 04:58:45.042202 22509476222784 run_lib.py:133] step: 299000, training_loss: 3.44548e-02
I0211 04:58:45.205586 22509476222784 run_lib.py:146] step: 299000, eval_loss: 4.04235e-02
I0211 04:59:03.801412 22509476222784 run_lib.py:133] step: 299050, training_loss: 4.49158e-02
I0211 04:59:22.389071 22509476222784 run_lib.py:133] step: 299100, training_loss: 3.04119e-02
I0211 04:59:22.556906 22509476222784 run_lib.py:146] step: 299100, eval_loss: 5.36529e-02
I0211 04:59:41.136730 22509476222784 run_lib.py:133] step: 299150, training_loss: 4.35600e-02
I0211 04:59:59.593456 22509476222784 run_lib.py:133] step: 299200, training_loss: 4.49080e-02
I0211 04:59:59.753541 22509476222784 run_lib.py:146] step: 299200, eval_loss: 4.49253e-02
I0211 05:00:18.371340 22509476222784 run_lib.py:133] step: 299250, training_loss: 3.56599e-02
I0211 05:00:36.857947 22509476222784 run_lib.py:133] step: 299300, training_loss: 3.73378e-02
I0211 05:00:37.024869 22509476222784 run_lib.py:146] step: 299300, eval_loss: 3.19690e-02
I0211 05:00:55.676224 22509476222784 run_lib.py:133] step: 299350, training_loss: 4.71314e-02
I0211 05:01:14.225797 22509476222784 run_lib.py:133] step: 299400, training_loss: 4.49899e-02
I0211 05:01:14.390687 22509476222784 run_lib.py:146] step: 299400, eval_loss: 4.64337e-02
I0211 05:01:33.042839 22509476222784 run_lib.py:133] step: 299450, training_loss: 5.03075e-02
I0211 05:01:51.582129 22509476222784 run_lib.py:133] step: 299500, training_loss: 3.00588e-02
I0211 05:01:51.746377 22509476222784 run_lib.py:146] step: 299500, eval_loss: 3.25772e-02
I0211 05:02:10.291095 22509476222784 run_lib.py:133] step: 299550, training_loss: 4.38883e-02
I0211 05:02:28.823688 22509476222784 run_lib.py:133] step: 299600, training_loss: 4.02800e-02
I0211 05:02:28.995559 22509476222784 run_lib.py:146] step: 299600, eval_loss: 4.06847e-02
I0211 05:02:47.436817 22509476222784 run_lib.py:133] step: 299650, training_loss: 3.21164e-02
I0211 05:03:06.109035 22509476222784 run_lib.py:133] step: 299700, training_loss: 4.36504e-02
I0211 05:03:06.274929 22509476222784 run_lib.py:146] step: 299700, eval_loss: 3.63772e-02
I0211 05:03:24.840243 22509476222784 run_lib.py:133] step: 299750, training_loss: 4.42372e-02
I0211 05:03:43.296691 22509476222784 run_lib.py:133] step: 299800, training_loss: 5.03530e-02
I0211 05:03:43.461893 22509476222784 run_lib.py:146] step: 299800, eval_loss: 4.21634e-02
I0211 05:04:02.103602 22509476222784 run_lib.py:133] step: 299850, training_loss: 4.93272e-02
I0211 05:04:20.560190 22509476222784 run_lib.py:133] step: 299900, training_loss: 5.29971e-02
I0211 05:04:20.726583 22509476222784 run_lib.py:146] step: 299900, eval_loss: 3.65794e-02
I0211 05:04:39.304764 22509476222784 run_lib.py:133] step: 299950, training_loss: 3.75435e-02
I0211 05:04:57.888650 22509476222784 run_lib.py:133] step: 300000, training_loss: 5.49487e-02
I0211 05:04:58.624886 22509476222784 run_lib.py:146] step: 300000, eval_loss: 3.73527e-02
I0211 05:05:19.772135 22509476222784 run_lib.py:133] step: 300050, training_loss: 4.04517e-02
I0211 05:05:38.246745 22509476222784 run_lib.py:133] step: 300100, training_loss: 4.27252e-02
I0211 05:05:38.410268 22509476222784 run_lib.py:146] step: 300100, eval_loss: 4.37922e-02
I0211 05:05:57.072859 22509476222784 run_lib.py:133] step: 300150, training_loss: 5.23025e-02
I0211 05:06:15.591365 22509476222784 run_lib.py:133] step: 300200, training_loss: 4.13267e-02
I0211 05:06:15.761824 22509476222784 run_lib.py:146] step: 300200, eval_loss: 4.44553e-02
I0211 05:06:34.329156 22509476222784 run_lib.py:133] step: 300250, training_loss: 3.66504e-02
I0211 05:06:53.029964 22509476222784 run_lib.py:133] step: 300300, training_loss: 4.05953e-02
I0211 05:06:53.193747 22509476222784 run_lib.py:146] step: 300300, eval_loss: 4.31716e-02
I0211 05:07:11.656874 22509476222784 run_lib.py:133] step: 300350, training_loss: 5.27561e-02
I0211 05:07:30.308057 22509476222784 run_lib.py:133] step: 300400, training_loss: 3.36029e-02
I0211 05:07:30.483881 22509476222784 run_lib.py:146] step: 300400, eval_loss: 3.28448e-02
I0211 05:07:49.000877 22509476222784 run_lib.py:133] step: 300450, training_loss: 3.68893e-02
I0211 05:08:07.485573 22509476222784 run_lib.py:133] step: 300500, training_loss: 4.31773e-02
I0211 05:08:07.648701 22509476222784 run_lib.py:146] step: 300500, eval_loss: 4.07566e-02
I0211 05:08:26.186340 22509476222784 run_lib.py:133] step: 300550, training_loss: 6.35531e-02
I0211 05:08:44.695087 22509476222784 run_lib.py:133] step: 300600, training_loss: 4.79885e-02
I0211 05:08:44.886656 22509476222784 run_lib.py:146] step: 300600, eval_loss: 3.42622e-02
I0211 05:09:03.603182 22509476222784 run_lib.py:133] step: 300650, training_loss: 4.15894e-02
I0211 05:09:22.200302 22509476222784 run_lib.py:133] step: 300700, training_loss: 4.32015e-02
I0211 05:09:22.361725 22509476222784 run_lib.py:146] step: 300700, eval_loss: 4.20528e-02
I0211 05:09:40.897498 22509476222784 run_lib.py:133] step: 300750, training_loss: 4.23561e-02
I0211 05:09:59.415212 22509476222784 run_lib.py:133] step: 300800, training_loss: 3.79924e-02
I0211 05:09:59.586700 22509476222784 run_lib.py:146] step: 300800, eval_loss: 3.17227e-02
I0211 05:10:18.306189 22509476222784 run_lib.py:133] step: 300850, training_loss: 3.95096e-02
I0211 05:10:36.885551 22509476222784 run_lib.py:133] step: 300900, training_loss: 3.54926e-02
I0211 05:10:37.050947 22509476222784 run_lib.py:146] step: 300900, eval_loss: 3.82079e-02
I0211 05:10:55.558339 22509476222784 run_lib.py:133] step: 300950, training_loss: 3.93035e-02
I0211 05:11:14.066274 22509476222784 run_lib.py:133] step: 301000, training_loss: 3.45576e-02
I0211 05:11:14.246716 22509476222784 run_lib.py:146] step: 301000, eval_loss: 4.58582e-02
I0211 05:11:32.856544 22509476222784 run_lib.py:133] step: 301050, training_loss: 4.01331e-02
I0211 05:11:51.294665 22509476222784 run_lib.py:133] step: 301100, training_loss: 4.20519e-02
I0211 05:11:51.455478 22509476222784 run_lib.py:146] step: 301100, eval_loss: 3.90594e-02
I0211 05:12:10.231902 22509476222784 run_lib.py:133] step: 301150, training_loss: 3.77076e-02
I0211 05:12:28.769993 22509476222784 run_lib.py:133] step: 301200, training_loss: 3.25851e-02
I0211 05:12:28.931756 22509476222784 run_lib.py:146] step: 301200, eval_loss: 3.83383e-02
I0211 05:12:47.504076 22509476222784 run_lib.py:133] step: 301250, training_loss: 4.38274e-02
I0211 05:13:05.906374 22509476222784 run_lib.py:133] step: 301300, training_loss: 4.50433e-02
I0211 05:13:06.088759 22509476222784 run_lib.py:146] step: 301300, eval_loss: 4.30210e-02
I0211 05:13:24.643665 22509476222784 run_lib.py:133] step: 301350, training_loss: 5.07375e-02
I0211 05:13:43.319627 22509476222784 run_lib.py:133] step: 301400, training_loss: 4.16089e-02
I0211 05:13:43.485019 22509476222784 run_lib.py:146] step: 301400, eval_loss: 3.69280e-02
I0211 05:14:02.013865 22509476222784 run_lib.py:133] step: 301450, training_loss: 4.63870e-02
I0211 05:14:20.679427 22509476222784 run_lib.py:133] step: 301500, training_loss: 4.42538e-02
I0211 05:14:20.842273 22509476222784 run_lib.py:146] step: 301500, eval_loss: 4.87050e-02
I0211 05:14:39.240028 22509476222784 run_lib.py:133] step: 301550, training_loss: 4.32020e-02
I0211 05:14:57.736051 22509476222784 run_lib.py:133] step: 301600, training_loss: 5.46403e-02
I0211 05:14:57.897329 22509476222784 run_lib.py:146] step: 301600, eval_loss: 2.54329e-02
I0211 05:15:16.688502 22509476222784 run_lib.py:133] step: 301650, training_loss: 4.55771e-02
I0211 05:15:35.205855 22509476222784 run_lib.py:133] step: 301700, training_loss: 4.18095e-02
I0211 05:15:35.369664 22509476222784 run_lib.py:146] step: 301700, eval_loss: 4.55560e-02
I0211 05:15:53.778892 22509476222784 run_lib.py:133] step: 301750, training_loss: 3.74906e-02
I0211 05:16:12.245797 22509476222784 run_lib.py:133] step: 301800, training_loss: 4.08168e-02
I0211 05:16:12.441870 22509476222784 run_lib.py:146] step: 301800, eval_loss: 4.18433e-02
I0211 05:16:31.081122 22509476222784 run_lib.py:133] step: 301850, training_loss: 4.89533e-02
I0211 05:16:49.693956 22509476222784 run_lib.py:133] step: 301900, training_loss: 4.00862e-02
I0211 05:16:49.856654 22509476222784 run_lib.py:146] step: 301900, eval_loss: 3.82620e-02
I0211 05:17:08.520138 22509476222784 run_lib.py:133] step: 301950, training_loss: 4.18262e-02
I0211 05:17:26.984775 22509476222784 run_lib.py:133] step: 302000, training_loss: 3.53763e-02
I0211 05:17:27.147461 22509476222784 run_lib.py:146] step: 302000, eval_loss: 4.95566e-02
I0211 05:17:45.643989 22509476222784 run_lib.py:133] step: 302050, training_loss: 4.86458e-02
I0211 05:18:04.120481 22509476222784 run_lib.py:133] step: 302100, training_loss: 4.03583e-02
I0211 05:18:04.293693 22509476222784 run_lib.py:146] step: 302100, eval_loss: 4.52132e-02
I0211 05:18:23.033663 22509476222784 run_lib.py:133] step: 302150, training_loss: 3.67073e-02
I0211 05:18:41.692887 22509476222784 run_lib.py:133] step: 302200, training_loss: 5.03865e-02
I0211 05:18:41.865873 22509476222784 run_lib.py:146] step: 302200, eval_loss: 3.69525e-02
I0211 05:19:00.430695 22509476222784 run_lib.py:133] step: 302250, training_loss: 4.93655e-02
I0211 05:19:18.933535 22509476222784 run_lib.py:133] step: 302300, training_loss: 4.71182e-02
I0211 05:19:19.099928 22509476222784 run_lib.py:146] step: 302300, eval_loss: 4.97012e-02
I0211 05:19:37.699130 22509476222784 run_lib.py:133] step: 302350, training_loss: 3.50333e-02
I0211 05:19:56.215886 22509476222784 run_lib.py:133] step: 302400, training_loss: 4.72810e-02
I0211 05:19:56.387841 22509476222784 run_lib.py:146] step: 302400, eval_loss: 3.46498e-02
I0211 05:20:15.089425 22509476222784 run_lib.py:133] step: 302450, training_loss: 4.29072e-02
I0211 05:20:33.619978 22509476222784 run_lib.py:133] step: 302500, training_loss: 4.02275e-02
I0211 05:20:33.789395 22509476222784 run_lib.py:146] step: 302500, eval_loss: 4.25015e-02
I0211 05:20:52.459227 22509476222784 run_lib.py:133] step: 302550, training_loss: 4.20442e-02
I0211 05:21:10.954449 22509476222784 run_lib.py:133] step: 302600, training_loss: 3.98122e-02
I0211 05:21:11.115630 22509476222784 run_lib.py:146] step: 302600, eval_loss: 4.43660e-02
I0211 05:21:29.742425 22509476222784 run_lib.py:133] step: 302650, training_loss: 3.72769e-02
I0211 05:21:48.215780 22509476222784 run_lib.py:133] step: 302700, training_loss: 5.64879e-02
I0211 05:21:48.395629 22509476222784 run_lib.py:146] step: 302700, eval_loss: 3.55879e-02
I0211 05:22:06.903614 22509476222784 run_lib.py:133] step: 302750, training_loss: 4.96514e-02
I0211 05:22:25.598766 22509476222784 run_lib.py:133] step: 302800, training_loss: 4.45971e-02
I0211 05:22:25.771550 22509476222784 run_lib.py:146] step: 302800, eval_loss: 5.87785e-02
I0211 05:22:44.294267 22509476222784 run_lib.py:133] step: 302850, training_loss: 4.35362e-02
I0211 05:23:02.835546 22509476222784 run_lib.py:133] step: 302900, training_loss: 3.45181e-02
I0211 05:23:02.999792 22509476222784 run_lib.py:146] step: 302900, eval_loss: 5.17845e-02
I0211 05:23:21.609400 22509476222784 run_lib.py:133] step: 302950, training_loss: 3.58532e-02
I0211 05:23:40.321238 22509476222784 run_lib.py:133] step: 303000, training_loss: 4.87428e-02
I0211 05:23:40.501404 22509476222784 run_lib.py:146] step: 303000, eval_loss: 4.35672e-02
I0211 05:23:59.046362 22509476222784 run_lib.py:133] step: 303050, training_loss: 3.96476e-02
I0211 05:24:17.551408 22509476222784 run_lib.py:133] step: 303100, training_loss: 3.25334e-02
I0211 05:24:17.727559 22509476222784 run_lib.py:146] step: 303100, eval_loss: 4.57881e-02
I0211 05:24:36.216079 22509476222784 run_lib.py:133] step: 303150, training_loss: 4.23046e-02
I0211 05:24:54.904788 22509476222784 run_lib.py:133] step: 303200, training_loss: 3.49677e-02
I0211 05:24:55.073874 22509476222784 run_lib.py:146] step: 303200, eval_loss: 2.97526e-02
I0211 05:25:13.589958 22509476222784 run_lib.py:133] step: 303250, training_loss: 4.33234e-02
I0211 05:25:32.145917 22509476222784 run_lib.py:133] step: 303300, training_loss: 4.79150e-02
I0211 05:25:32.309806 22509476222784 run_lib.py:146] step: 303300, eval_loss: 3.99593e-02
I0211 05:25:50.813884 22509476222784 run_lib.py:133] step: 303350, training_loss: 4.35433e-02
I0211 05:26:09.520433 22509476222784 run_lib.py:133] step: 303400, training_loss: 5.10646e-02
I0211 05:26:09.684754 22509476222784 run_lib.py:146] step: 303400, eval_loss: 3.80228e-02
I0211 05:26:28.178549 22509476222784 run_lib.py:133] step: 303450, training_loss: 3.86902e-02
I0211 05:26:46.710845 22509476222784 run_lib.py:133] step: 303500, training_loss: 4.47067e-02
I0211 05:26:46.873013 22509476222784 run_lib.py:146] step: 303500, eval_loss: 4.42885e-02
I0211 05:27:05.453977 22509476222784 run_lib.py:133] step: 303550, training_loss: 4.18493e-02
I0211 05:27:23.958861 22509476222784 run_lib.py:133] step: 303600, training_loss: 3.83967e-02
I0211 05:27:24.124933 22509476222784 run_lib.py:146] step: 303600, eval_loss: 4.76666e-02
I0211 05:27:42.782543 22509476222784 run_lib.py:133] step: 303650, training_loss: 4.11066e-02
I0211 05:28:01.388303 22509476222784 run_lib.py:133] step: 303700, training_loss: 4.37447e-02
I0211 05:28:01.554292 22509476222784 run_lib.py:146] step: 303700, eval_loss: 3.97353e-02
I0211 05:28:20.064643 22509476222784 run_lib.py:133] step: 303750, training_loss: 4.98077e-02
I0211 05:28:38.533873 22509476222784 run_lib.py:133] step: 303800, training_loss: 4.30725e-02
I0211 05:28:38.707466 22509476222784 run_lib.py:146] step: 303800, eval_loss: 4.56314e-02
I0211 05:28:57.306387 22509476222784 run_lib.py:133] step: 303850, training_loss: 5.70875e-02
I0211 05:29:15.808922 22509476222784 run_lib.py:133] step: 303900, training_loss: 3.77765e-02
I0211 05:29:15.972873 22509476222784 run_lib.py:146] step: 303900, eval_loss: 3.52593e-02
I0211 05:29:34.646984 22509476222784 run_lib.py:133] step: 303950, training_loss: 4.06807e-02
I0211 05:29:53.142347 22509476222784 run_lib.py:133] step: 304000, training_loss: 4.20858e-02
I0211 05:29:53.303534 22509476222784 run_lib.py:146] step: 304000, eval_loss: 5.01270e-02
I0211 05:30:11.889172 22509476222784 run_lib.py:133] step: 304050, training_loss: 4.37234e-02
I0211 05:30:30.346894 22509476222784 run_lib.py:133] step: 304100, training_loss: 4.89532e-02
I0211 05:30:30.516866 22509476222784 run_lib.py:146] step: 304100, eval_loss: 4.62268e-02
I0211 05:30:48.953530 22509476222784 run_lib.py:133] step: 304150, training_loss: 4.89276e-02
I0211 05:31:07.557471 22509476222784 run_lib.py:133] step: 304200, training_loss: 5.24986e-02
I0211 05:31:07.722804 22509476222784 run_lib.py:146] step: 304200, eval_loss: 4.13252e-02
I0211 05:31:26.247106 22509476222784 run_lib.py:133] step: 304250, training_loss: 4.48140e-02
I0211 05:31:44.893881 22509476222784 run_lib.py:133] step: 304300, training_loss: 4.45963e-02
I0211 05:31:45.061661 22509476222784 run_lib.py:146] step: 304300, eval_loss: 4.67382e-02
I0211 05:32:03.596352 22509476222784 run_lib.py:133] step: 304350, training_loss: 3.54887e-02
I0211 05:32:22.150235 22509476222784 run_lib.py:133] step: 304400, training_loss: 4.98151e-02
I0211 05:32:22.314866 22509476222784 run_lib.py:146] step: 304400, eval_loss: 3.91807e-02
I0211 05:32:41.055539 22509476222784 run_lib.py:133] step: 304450, training_loss: 5.28849e-02
I0211 05:32:59.570545 22509476222784 run_lib.py:133] step: 304500, training_loss: 4.14282e-02
I0211 05:32:59.732696 22509476222784 run_lib.py:146] step: 304500, eval_loss: 6.09363e-02
I0211 05:33:18.192849 22509476222784 run_lib.py:133] step: 304550, training_loss: 3.05743e-02
I0211 05:33:36.800611 22509476222784 run_lib.py:133] step: 304600, training_loss: 4.40484e-02
I0211 05:33:36.995643 22509476222784 run_lib.py:146] step: 304600, eval_loss: 4.49162e-02
I0211 05:33:55.582957 22509476222784 run_lib.py:133] step: 304650, training_loss: 3.46518e-02
I0211 05:34:14.042654 22509476222784 run_lib.py:133] step: 304700, training_loss: 4.60597e-02
I0211 05:34:14.207736 22509476222784 run_lib.py:146] step: 304700, eval_loss: 3.67383e-02
I0211 05:34:32.778741 22509476222784 run_lib.py:133] step: 304750, training_loss: 4.43413e-02
I0211 05:34:51.190016 22509476222784 run_lib.py:133] step: 304800, training_loss: 4.09876e-02
I0211 05:34:51.354470 22509476222784 run_lib.py:146] step: 304800, eval_loss: 3.43612e-02
I0211 05:35:09.844530 22509476222784 run_lib.py:133] step: 304850, training_loss: 4.68526e-02
I0211 05:35:28.386214 22509476222784 run_lib.py:133] step: 304900, training_loss: 5.06868e-02
I0211 05:35:28.548555 22509476222784 run_lib.py:146] step: 304900, eval_loss: 6.41584e-02
I0211 05:35:47.279104 22509476222784 run_lib.py:133] step: 304950, training_loss: 4.24799e-02
I0211 05:36:05.931361 22509476222784 run_lib.py:133] step: 305000, training_loss: 3.67709e-02
I0211 05:36:06.093706 22509476222784 run_lib.py:146] step: 305000, eval_loss: 5.87547e-02
I0211 05:36:24.592321 22509476222784 run_lib.py:133] step: 305050, training_loss: 4.90422e-02
I0211 05:36:43.077821 22509476222784 run_lib.py:133] step: 305100, training_loss: 4.34722e-02
I0211 05:36:43.243975 22509476222784 run_lib.py:146] step: 305100, eval_loss: 4.45152e-02
I0211 05:37:01.873559 22509476222784 run_lib.py:133] step: 305150, training_loss: 5.36976e-02
I0211 05:37:20.392186 22509476222784 run_lib.py:133] step: 305200, training_loss: 4.26898e-02
I0211 05:37:20.555781 22509476222784 run_lib.py:146] step: 305200, eval_loss: 3.99059e-02
I0211 05:37:39.206089 22509476222784 run_lib.py:133] step: 305250, training_loss: 2.79881e-02
I0211 05:37:57.685359 22509476222784 run_lib.py:133] step: 305300, training_loss: 4.38110e-02
I0211 05:37:57.848491 22509476222784 run_lib.py:146] step: 305300, eval_loss: 3.75489e-02
I0211 05:38:16.486409 22509476222784 run_lib.py:133] step: 305350, training_loss: 3.80710e-02
I0211 05:38:34.982281 22509476222784 run_lib.py:133] step: 305400, training_loss: 5.20803e-02
I0211 05:38:35.142549 22509476222784 run_lib.py:146] step: 305400, eval_loss: 3.92612e-02
I0211 05:38:53.817275 22509476222784 run_lib.py:133] step: 305450, training_loss: 5.33981e-02
I0211 05:39:12.350192 22509476222784 run_lib.py:133] step: 305500, training_loss: 3.07927e-02
I0211 05:39:12.521750 22509476222784 run_lib.py:146] step: 305500, eval_loss: 3.77364e-02
I0211 05:39:31.021705 22509476222784 run_lib.py:133] step: 305550, training_loss: 4.86108e-02
I0211 05:39:49.706002 22509476222784 run_lib.py:133] step: 305600, training_loss: 3.32669e-02
I0211 05:39:49.872744 22509476222784 run_lib.py:146] step: 305600, eval_loss: 5.16448e-02
I0211 05:40:08.310309 22509476222784 run_lib.py:133] step: 305650, training_loss: 4.37780e-02
I0211 05:40:26.792404 22509476222784 run_lib.py:133] step: 305700, training_loss: 3.98429e-02
I0211 05:40:26.962516 22509476222784 run_lib.py:146] step: 305700, eval_loss: 5.42270e-02
I0211 05:40:45.595341 22509476222784 run_lib.py:133] step: 305750, training_loss: 4.56915e-02
I0211 05:41:04.110979 22509476222784 run_lib.py:133] step: 305800, training_loss: 4.79422e-02
I0211 05:41:04.274710 22509476222784 run_lib.py:146] step: 305800, eval_loss: 3.92369e-02
I0211 05:41:22.945638 22509476222784 run_lib.py:133] step: 305850, training_loss: 5.61622e-02
I0211 05:41:41.451649 22509476222784 run_lib.py:133] step: 305900, training_loss: 4.74430e-02
I0211 05:41:41.612581 22509476222784 run_lib.py:146] step: 305900, eval_loss: 5.12592e-02
I0211 05:42:00.073325 22509476222784 run_lib.py:133] step: 305950, training_loss: 4.30411e-02
I0211 05:42:18.742458 22509476222784 run_lib.py:133] step: 306000, training_loss: 3.85561e-02
I0211 05:42:18.922537 22509476222784 run_lib.py:146] step: 306000, eval_loss: 5.45964e-02
I0211 05:42:37.500225 22509476222784 run_lib.py:133] step: 306050, training_loss: 3.81785e-02
I0211 05:42:56.059904 22509476222784 run_lib.py:133] step: 306100, training_loss: 5.46621e-02
I0211 05:42:56.225651 22509476222784 run_lib.py:146] step: 306100, eval_loss: 5.01791e-02
I0211 05:43:14.699182 22509476222784 run_lib.py:133] step: 306150, training_loss: 4.75577e-02
I0211 05:43:33.397207 22509476222784 run_lib.py:133] step: 306200, training_loss: 3.58524e-02
I0211 05:43:33.581555 22509476222784 run_lib.py:146] step: 306200, eval_loss: 3.58582e-02
I0211 05:43:52.099323 22509476222784 run_lib.py:133] step: 306250, training_loss: 3.81290e-02
I0211 05:44:10.754279 22509476222784 run_lib.py:133] step: 306300, training_loss: 3.12830e-02
I0211 05:44:10.919934 22509476222784 run_lib.py:146] step: 306300, eval_loss: 6.07724e-02
I0211 05:44:29.486198 22509476222784 run_lib.py:133] step: 306350, training_loss: 5.08689e-02
I0211 05:44:47.955499 22509476222784 run_lib.py:133] step: 306400, training_loss: 3.83563e-02
I0211 05:44:48.117738 22509476222784 run_lib.py:146] step: 306400, eval_loss: 3.27686e-02
I0211 05:45:06.806384 22509476222784 run_lib.py:133] step: 306450, training_loss: 3.61508e-02
I0211 05:45:25.386675 22509476222784 run_lib.py:133] step: 306500, training_loss: 3.29496e-02
I0211 05:45:25.580855 22509476222784 run_lib.py:146] step: 306500, eval_loss: 3.90721e-02
I0211 05:45:44.099970 22509476222784 run_lib.py:133] step: 306550, training_loss: 5.57394e-02
I0211 05:46:02.672146 22509476222784 run_lib.py:133] step: 306600, training_loss: 5.50970e-02
I0211 05:46:02.837161 22509476222784 run_lib.py:146] step: 306600, eval_loss: 3.67460e-02
I0211 05:46:21.509143 22509476222784 run_lib.py:133] step: 306650, training_loss: 5.39522e-02
I0211 05:46:39.966626 22509476222784 run_lib.py:133] step: 306700, training_loss: 4.79321e-02
I0211 05:46:40.131763 22509476222784 run_lib.py:146] step: 306700, eval_loss: 4.17107e-02
I0211 05:46:58.724977 22509476222784 run_lib.py:133] step: 306750, training_loss: 4.21797e-02
I0211 05:47:17.209947 22509476222784 run_lib.py:133] step: 306800, training_loss: 3.41049e-02
I0211 05:47:17.403065 22509476222784 run_lib.py:146] step: 306800, eval_loss: 4.33597e-02
I0211 05:47:36.116688 22509476222784 run_lib.py:133] step: 306850, training_loss: 3.56462e-02
I0211 05:47:54.493620 22509476222784 run_lib.py:133] step: 306900, training_loss: 4.25564e-02
I0211 05:47:54.654778 22509476222784 run_lib.py:146] step: 306900, eval_loss: 4.00140e-02
I0211 05:48:13.034764 22509476222784 run_lib.py:133] step: 306950, training_loss: 4.25295e-02
I0211 05:48:31.722650 22509476222784 run_lib.py:133] step: 307000, training_loss: 4.27267e-02
I0211 05:48:31.888510 22509476222784 run_lib.py:146] step: 307000, eval_loss: 4.02036e-02
I0211 05:48:50.401959 22509476222784 run_lib.py:133] step: 307050, training_loss: 3.89755e-02
I0211 05:49:09.149907 22509476222784 run_lib.py:133] step: 307100, training_loss: 2.95064e-02
I0211 05:49:09.318023 22509476222784 run_lib.py:146] step: 307100, eval_loss: 3.77123e-02
I0211 05:49:27.826710 22509476222784 run_lib.py:133] step: 307150, training_loss: 4.75509e-02
I0211 05:49:46.296023 22509476222784 run_lib.py:133] step: 307200, training_loss: 3.77977e-02
I0211 05:49:46.459745 22509476222784 run_lib.py:146] step: 307200, eval_loss: 5.10020e-02
I0211 05:50:05.092913 22509476222784 run_lib.py:133] step: 307250, training_loss: 3.01422e-02
I0211 05:50:23.543303 22509476222784 run_lib.py:133] step: 307300, training_loss: 4.05722e-02
I0211 05:50:23.705991 22509476222784 run_lib.py:146] step: 307300, eval_loss: 3.78552e-02
I0211 05:50:42.311975 22509476222784 run_lib.py:133] step: 307350, training_loss: 3.15442e-02
I0211 05:51:01.034602 22509476222784 run_lib.py:133] step: 307400, training_loss: 3.62395e-02
I0211 05:51:01.198904 22509476222784 run_lib.py:146] step: 307400, eval_loss: 3.47576e-02
I0211 05:51:19.704045 22509476222784 run_lib.py:133] step: 307450, training_loss: 3.80826e-02
I0211 05:51:38.135542 22509476222784 run_lib.py:133] step: 307500, training_loss: 3.42070e-02
I0211 05:51:38.446722 22509476222784 run_lib.py:146] step: 307500, eval_loss: 4.78763e-02
I0211 05:51:56.936271 22509476222784 run_lib.py:133] step: 307550, training_loss: 3.89334e-02
I0211 05:52:15.476186 22509476222784 run_lib.py:133] step: 307600, training_loss: 4.14814e-02
I0211 05:52:15.648519 22509476222784 run_lib.py:146] step: 307600, eval_loss: 3.65148e-02
I0211 05:52:34.233767 22509476222784 run_lib.py:133] step: 307650, training_loss: 4.70647e-02
I0211 05:52:52.772001 22509476222784 run_lib.py:133] step: 307700, training_loss: 4.72936e-02
I0211 05:52:52.944921 22509476222784 run_lib.py:146] step: 307700, eval_loss: 3.42299e-02
I0211 05:53:11.658581 22509476222784 run_lib.py:133] step: 307750, training_loss: 3.96966e-02
I0211 05:53:30.213517 22509476222784 run_lib.py:133] step: 307800, training_loss: 3.99445e-02
I0211 05:53:30.380615 22509476222784 run_lib.py:146] step: 307800, eval_loss: 4.58796e-02
I0211 05:53:48.873211 22509476222784 run_lib.py:133] step: 307850, training_loss: 4.01532e-02
I0211 05:54:07.432547 22509476222784 run_lib.py:133] step: 307900, training_loss: 3.75360e-02
I0211 05:54:07.600622 22509476222784 run_lib.py:146] step: 307900, eval_loss: 4.57138e-02
I0211 05:54:26.199820 22509476222784 run_lib.py:133] step: 307950, training_loss: 3.55279e-02
I0211 05:54:44.897929 22509476222784 run_lib.py:133] step: 308000, training_loss: 4.65108e-02
I0211 05:54:45.092852 22509476222784 run_lib.py:146] step: 308000, eval_loss: 3.95384e-02
I0211 05:55:03.559324 22509476222784 run_lib.py:133] step: 308050, training_loss: 4.02393e-02
I0211 05:55:22.045148 22509476222784 run_lib.py:133] step: 308100, training_loss: 5.08015e-02
I0211 05:55:22.208674 22509476222784 run_lib.py:146] step: 308100, eval_loss: 5.14498e-02
I0211 05:55:40.739148 22509476222784 run_lib.py:133] step: 308150, training_loss: 3.53523e-02
I0211 05:55:59.273764 22509476222784 run_lib.py:133] step: 308200, training_loss: 4.22454e-02
I0211 05:55:59.440810 22509476222784 run_lib.py:146] step: 308200, eval_loss: 3.61281e-02
I0211 05:56:18.023638 22509476222784 run_lib.py:133] step: 308250, training_loss: 3.87156e-02
I0211 05:56:36.491593 22509476222784 run_lib.py:133] step: 308300, training_loss: 2.75252e-02
I0211 05:56:36.670856 22509476222784 run_lib.py:146] step: 308300, eval_loss: 3.41196e-02
I0211 05:56:55.347898 22509476222784 run_lib.py:133] step: 308350, training_loss: 5.05140e-02
I0211 05:57:13.884927 22509476222784 run_lib.py:133] step: 308400, training_loss: 3.78440e-02
I0211 05:57:14.055565 22509476222784 run_lib.py:146] step: 308400, eval_loss: 5.56607e-02
I0211 05:57:32.587989 22509476222784 run_lib.py:133] step: 308450, training_loss: 3.96067e-02
I0211 05:57:51.243389 22509476222784 run_lib.py:133] step: 308500, training_loss: 3.68116e-02
I0211 05:57:51.407941 22509476222784 run_lib.py:146] step: 308500, eval_loss: 4.79219e-02
I0211 05:58:09.913496 22509476222784 run_lib.py:133] step: 308550, training_loss: 4.29227e-02
I0211 05:58:28.558308 22509476222784 run_lib.py:133] step: 308600, training_loss: 4.42668e-02
I0211 05:58:28.723931 22509476222784 run_lib.py:146] step: 308600, eval_loss: 3.30293e-02
I0211 05:58:47.233958 22509476222784 run_lib.py:133] step: 308650, training_loss: 3.86959e-02
I0211 05:59:05.783058 22509476222784 run_lib.py:133] step: 308700, training_loss: 4.92982e-02
I0211 05:59:05.947008 22509476222784 run_lib.py:146] step: 308700, eval_loss: 4.51977e-02
I0211 05:59:24.465358 22509476222784 run_lib.py:133] step: 308750, training_loss: 4.34545e-02
I0211 05:59:43.149461 22509476222784 run_lib.py:133] step: 308800, training_loss: 3.99480e-02
I0211 05:59:43.312597 22509476222784 run_lib.py:146] step: 308800, eval_loss: 3.99236e-02
I0211 06:00:01.758520 22509476222784 run_lib.py:133] step: 308850, training_loss: 3.66563e-02
I0211 06:00:20.295683 22509476222784 run_lib.py:133] step: 308900, training_loss: 3.33839e-02
I0211 06:00:20.470605 22509476222784 run_lib.py:146] step: 308900, eval_loss: 4.24445e-02
I0211 06:00:39.101222 22509476222784 run_lib.py:133] step: 308950, training_loss: 4.49644e-02
I0211 06:00:57.629405 22509476222784 run_lib.py:133] step: 309000, training_loss: 3.72947e-02
I0211 06:00:57.792813 22509476222784 run_lib.py:146] step: 309000, eval_loss: 4.45699e-02
I0211 06:01:16.292207 22509476222784 run_lib.py:133] step: 309050, training_loss: 6.01915e-02
I0211 06:01:34.715455 22509476222784 run_lib.py:133] step: 309100, training_loss: 3.72026e-02
I0211 06:01:34.879761 22509476222784 run_lib.py:146] step: 309100, eval_loss: 3.17957e-02
I0211 06:01:53.366893 22509476222784 run_lib.py:133] step: 309150, training_loss: 3.41906e-02
I0211 06:02:11.732714 22509476222784 run_lib.py:133] step: 309200, training_loss: 5.61398e-02
I0211 06:02:11.892706 22509476222784 run_lib.py:146] step: 309200, eval_loss: 4.83871e-02
I0211 06:02:30.585329 22509476222784 run_lib.py:133] step: 309250, training_loss: 3.21346e-02
I0211 06:02:49.224290 22509476222784 run_lib.py:133] step: 309300, training_loss: 3.53369e-02
I0211 06:02:49.388858 22509476222784 run_lib.py:146] step: 309300, eval_loss: 3.93260e-02
I0211 06:03:07.925881 22509476222784 run_lib.py:133] step: 309350, training_loss: 4.20329e-02
I0211 06:03:26.395601 22509476222784 run_lib.py:133] step: 309400, training_loss: 4.40056e-02
I0211 06:03:26.591665 22509476222784 run_lib.py:146] step: 309400, eval_loss: 5.45803e-02
I0211 06:03:45.119388 22509476222784 run_lib.py:133] step: 309450, training_loss: 3.68169e-02
I0211 06:04:03.665623 22509476222784 run_lib.py:133] step: 309500, training_loss: 5.32258e-02
I0211 06:04:03.839517 22509476222784 run_lib.py:146] step: 309500, eval_loss: 4.53494e-02
I0211 06:04:22.500227 22509476222784 run_lib.py:133] step: 309550, training_loss: 4.19497e-02
I0211 06:04:41.024778 22509476222784 run_lib.py:133] step: 309600, training_loss: 5.41031e-02
I0211 06:04:41.194381 22509476222784 run_lib.py:146] step: 309600, eval_loss: 4.03249e-02
I0211 06:04:59.906768 22509476222784 run_lib.py:133] step: 309650, training_loss: 4.53281e-02
I0211 06:05:18.358892 22509476222784 run_lib.py:133] step: 309700, training_loss: 4.09305e-02
I0211 06:05:18.519510 22509476222784 run_lib.py:146] step: 309700, eval_loss: 3.83697e-02
I0211 06:05:37.162598 22509476222784 run_lib.py:133] step: 309750, training_loss: 3.99489e-02
I0211 06:05:55.717630 22509476222784 run_lib.py:133] step: 309800, training_loss: 4.17525e-02
I0211 06:05:55.893561 22509476222784 run_lib.py:146] step: 309800, eval_loss: 4.86061e-02
I0211 06:06:14.451260 22509476222784 run_lib.py:133] step: 309850, training_loss: 3.52024e-02
I0211 06:06:33.202908 22509476222784 run_lib.py:133] step: 309900, training_loss: 4.35101e-02
I0211 06:06:33.374621 22509476222784 run_lib.py:146] step: 309900, eval_loss: 4.78422e-02
I0211 06:06:51.848959 22509476222784 run_lib.py:133] step: 309950, training_loss: 4.43835e-02
I0211 06:07:10.338929 22509476222784 run_lib.py:133] step: 310000, training_loss: 4.78107e-02
I0211 06:07:11.082809 22509476222784 run_lib.py:146] step: 310000, eval_loss: 4.01030e-02
I0211 06:07:32.408795 22509476222784 run_lib.py:133] step: 310050, training_loss: 3.92530e-02
I0211 06:07:50.949161 22509476222784 run_lib.py:133] step: 310100, training_loss: 4.38408e-02
I0211 06:07:51.112406 22509476222784 run_lib.py:146] step: 310100, eval_loss: 4.40518e-02
I0211 06:08:09.563495 22509476222784 run_lib.py:133] step: 310150, training_loss: 3.88128e-02
I0211 06:08:28.217244 22509476222784 run_lib.py:133] step: 310200, training_loss: 4.19169e-02
I0211 06:08:28.379575 22509476222784 run_lib.py:146] step: 310200, eval_loss: 4.75638e-02
I0211 06:08:46.853523 22509476222784 run_lib.py:133] step: 310250, training_loss: 5.27735e-02
I0211 06:09:05.441362 22509476222784 run_lib.py:133] step: 310300, training_loss: 4.33988e-02
I0211 06:09:05.634375 22509476222784 run_lib.py:146] step: 310300, eval_loss: 3.72017e-02
I0211 06:09:24.194407 22509476222784 run_lib.py:133] step: 310350, training_loss: 3.72785e-02
I0211 06:09:42.753646 22509476222784 run_lib.py:133] step: 310400, training_loss: 3.84490e-02
I0211 06:09:42.919611 22509476222784 run_lib.py:146] step: 310400, eval_loss: 4.92639e-02
I0211 06:10:01.606176 22509476222784 run_lib.py:133] step: 310450, training_loss: 5.58578e-02
I0211 06:10:20.231410 22509476222784 run_lib.py:133] step: 310500, training_loss: 4.63046e-02
I0211 06:10:20.395736 22509476222784 run_lib.py:146] step: 310500, eval_loss: 3.95934e-02
I0211 06:10:38.908183 22509476222784 run_lib.py:133] step: 310550, training_loss: 4.99216e-02
I0211 06:10:57.472016 22509476222784 run_lib.py:133] step: 310600, training_loss: 4.50740e-02
I0211 06:10:57.636434 22509476222784 run_lib.py:146] step: 310600, eval_loss: 3.95911e-02
I0211 06:11:16.353046 22509476222784 run_lib.py:133] step: 310650, training_loss: 4.25412e-02
I0211 06:11:34.785154 22509476222784 run_lib.py:133] step: 310700, training_loss: 5.70988e-02
I0211 06:11:34.953733 22509476222784 run_lib.py:146] step: 310700, eval_loss: 5.25645e-02
I0211 06:11:53.547223 22509476222784 run_lib.py:133] step: 310750, training_loss: 4.54687e-02
I0211 06:12:12.046708 22509476222784 run_lib.py:133] step: 310800, training_loss: 3.75753e-02
I0211 06:12:12.210626 22509476222784 run_lib.py:146] step: 310800, eval_loss: 5.64513e-02
I0211 06:12:30.851946 22509476222784 run_lib.py:133] step: 310850, training_loss: 3.45355e-02
I0211 06:12:49.427781 22509476222784 run_lib.py:133] step: 310900, training_loss: 3.29958e-02
I0211 06:12:49.596759 22509476222784 run_lib.py:146] step: 310900, eval_loss: 4.60916e-02
I0211 06:13:08.111555 22509476222784 run_lib.py:133] step: 310950, training_loss: 3.65032e-02
I0211 06:13:26.810626 22509476222784 run_lib.py:133] step: 311000, training_loss: 3.62894e-02
I0211 06:13:26.973804 22509476222784 run_lib.py:146] step: 311000, eval_loss: 3.12765e-02
I0211 06:13:45.365254 22509476222784 run_lib.py:133] step: 311050, training_loss: 3.51561e-02
I0211 06:14:03.998856 22509476222784 run_lib.py:133] step: 311100, training_loss: 5.49181e-02
I0211 06:14:04.175716 22509476222784 run_lib.py:146] step: 311100, eval_loss: 4.97618e-02
I0211 06:14:22.732181 22509476222784 run_lib.py:133] step: 311150, training_loss: 3.58925e-02
I0211 06:14:41.146401 22509476222784 run_lib.py:133] step: 311200, training_loss: 4.01486e-02
I0211 06:14:41.320910 22509476222784 run_lib.py:146] step: 311200, eval_loss: 3.94392e-02
I0211 06:15:00.061225 22509476222784 run_lib.py:133] step: 311250, training_loss: 3.29815e-02
I0211 06:15:18.577733 22509476222784 run_lib.py:133] step: 311300, training_loss: 4.56570e-02
I0211 06:15:18.742840 22509476222784 run_lib.py:146] step: 311300, eval_loss: 3.95578e-02
I0211 06:15:37.242698 22509476222784 run_lib.py:133] step: 311350, training_loss: 4.37681e-02
I0211 06:15:55.715264 22509476222784 run_lib.py:133] step: 311400, training_loss: 5.20461e-02
I0211 06:15:55.889684 22509476222784 run_lib.py:146] step: 311400, eval_loss: 3.19392e-02
I0211 06:16:14.561812 22509476222784 run_lib.py:133] step: 311450, training_loss: 4.42546e-02
I0211 06:16:33.071049 22509476222784 run_lib.py:133] step: 311500, training_loss: 3.58143e-02
I0211 06:16:33.234250 22509476222784 run_lib.py:146] step: 311500, eval_loss: 3.80353e-02
I0211 06:16:51.763154 22509476222784 run_lib.py:133] step: 311550, training_loss: 5.07851e-02
I0211 06:17:10.238170 22509476222784 run_lib.py:133] step: 311600, training_loss: 6.00401e-02
I0211 06:17:10.399643 22509476222784 run_lib.py:146] step: 311600, eval_loss: 4.03896e-02
I0211 06:17:28.836551 22509476222784 run_lib.py:133] step: 311650, training_loss: 3.91536e-02
I0211 06:17:47.344094 22509476222784 run_lib.py:133] step: 311700, training_loss: 5.00178e-02
I0211 06:17:47.515821 22509476222784 run_lib.py:146] step: 311700, eval_loss: 4.18461e-02
I0211 06:18:06.233338 22509476222784 run_lib.py:133] step: 311750, training_loss: 5.00110e-02
I0211 06:18:24.830915 22509476222784 run_lib.py:133] step: 311800, training_loss: 3.55170e-02
I0211 06:18:25.005142 22509476222784 run_lib.py:146] step: 311800, eval_loss: 3.25291e-02
I0211 06:18:43.461681 22509476222784 run_lib.py:133] step: 311850, training_loss: 3.65841e-02
I0211 06:19:01.938167 22509476222784 run_lib.py:133] step: 311900, training_loss: 4.67168e-02
I0211 06:19:02.103665 22509476222784 run_lib.py:146] step: 311900, eval_loss: 4.23947e-02
I0211 06:19:20.761582 22509476222784 run_lib.py:133] step: 311950, training_loss: 5.15469e-02
I0211 06:19:39.370031 22509476222784 run_lib.py:133] step: 312000, training_loss: 4.38946e-02
I0211 06:19:39.533248 22509476222784 run_lib.py:146] step: 312000, eval_loss: 4.91030e-02
I0211 06:19:58.148229 22509476222784 run_lib.py:133] step: 312050, training_loss: 3.05237e-02
I0211 06:20:16.668712 22509476222784 run_lib.py:133] step: 312100, training_loss: 3.97978e-02
I0211 06:20:16.829724 22509476222784 run_lib.py:146] step: 312100, eval_loss: 4.21453e-02
I0211 06:20:35.526158 22509476222784 run_lib.py:133] step: 312150, training_loss: 5.29801e-02
I0211 06:20:54.069816 22509476222784 run_lib.py:133] step: 312200, training_loss: 4.72186e-02
I0211 06:20:54.235638 22509476222784 run_lib.py:146] step: 312200, eval_loss: 4.61781e-02
I0211 06:21:12.852717 22509476222784 run_lib.py:133] step: 312250, training_loss: 4.56260e-02
I0211 06:21:31.409556 22509476222784 run_lib.py:133] step: 312300, training_loss: 3.76644e-02
I0211 06:21:31.581608 22509476222784 run_lib.py:146] step: 312300, eval_loss: 3.72430e-02
I0211 06:21:50.065315 22509476222784 run_lib.py:133] step: 312350, training_loss: 4.31338e-02
I0211 06:22:08.684772 22509476222784 run_lib.py:133] step: 312400, training_loss: 3.79666e-02
I0211 06:22:08.865606 22509476222784 run_lib.py:146] step: 312400, eval_loss: 3.96767e-02
I0211 06:22:27.356713 22509476222784 run_lib.py:133] step: 312450, training_loss: 4.33537e-02
I0211 06:22:45.872191 22509476222784 run_lib.py:133] step: 312500, training_loss: 4.53348e-02
I0211 06:22:46.036829 22509476222784 run_lib.py:146] step: 312500, eval_loss: 3.38170e-02
I0211 06:23:04.747684 22509476222784 run_lib.py:133] step: 312550, training_loss: 3.64323e-02
I0211 06:23:23.448878 22509476222784 run_lib.py:133] step: 312600, training_loss: 3.10544e-02
I0211 06:23:23.610559 22509476222784 run_lib.py:146] step: 312600, eval_loss: 4.42169e-02
I0211 06:23:42.106420 22509476222784 run_lib.py:133] step: 312650, training_loss: 3.75864e-02
I0211 06:24:00.581881 22509476222784 run_lib.py:133] step: 312700, training_loss: 5.21622e-02
I0211 06:24:00.745629 22509476222784 run_lib.py:146] step: 312700, eval_loss: 4.30588e-02
I0211 06:24:19.229609 22509476222784 run_lib.py:133] step: 312750, training_loss: 3.10853e-02
I0211 06:24:37.875220 22509476222784 run_lib.py:133] step: 312800, training_loss: 2.76061e-02
I0211 06:24:38.056671 22509476222784 run_lib.py:146] step: 312800, eval_loss: 4.43217e-02
I0211 06:24:56.604129 22509476222784 run_lib.py:133] step: 312850, training_loss: 3.99022e-02
I0211 06:25:15.097406 22509476222784 run_lib.py:133] step: 312900, training_loss: 4.15228e-02
I0211 06:25:15.261908 22509476222784 run_lib.py:146] step: 312900, eval_loss: 3.82313e-02
I0211 06:25:33.755350 22509476222784 run_lib.py:133] step: 312950, training_loss: 3.98693e-02
I0211 06:25:52.367902 22509476222784 run_lib.py:133] step: 313000, training_loss: 4.46777e-02
I0211 06:25:52.530632 22509476222784 run_lib.py:146] step: 313000, eval_loss: 5.89249e-02
I0211 06:26:11.078354 22509476222784 run_lib.py:133] step: 313050, training_loss: 4.54653e-02
I0211 06:26:29.683887 22509476222784 run_lib.py:133] step: 313100, training_loss: 4.46241e-02
I0211 06:26:29.852825 22509476222784 run_lib.py:146] step: 313100, eval_loss: 3.59931e-02
I0211 06:26:48.379233 22509476222784 run_lib.py:133] step: 313150, training_loss: 3.69899e-02
I0211 06:27:06.916144 22509476222784 run_lib.py:133] step: 313200, training_loss: 3.61836e-02
I0211 06:27:07.080848 22509476222784 run_lib.py:146] step: 313200, eval_loss: 3.72969e-02
I0211 06:27:25.721269 22509476222784 run_lib.py:133] step: 313250, training_loss: 4.24411e-02
I0211 06:27:44.292864 22509476222784 run_lib.py:133] step: 313300, training_loss: 4.62548e-02
I0211 06:27:44.475711 22509476222784 run_lib.py:146] step: 313300, eval_loss: 3.79337e-02
I0211 06:28:03.031576 22509476222784 run_lib.py:133] step: 313350, training_loss: 4.41809e-02
I0211 06:28:21.549577 22509476222784 run_lib.py:133] step: 313400, training_loss: 4.69725e-02
I0211 06:28:21.714051 22509476222784 run_lib.py:146] step: 313400, eval_loss: 4.88575e-02
I0211 06:28:40.386403 22509476222784 run_lib.py:133] step: 313450, training_loss: 6.00797e-02
I0211 06:28:58.865083 22509476222784 run_lib.py:133] step: 313500, training_loss: 3.56768e-02
I0211 06:28:59.033757 22509476222784 run_lib.py:146] step: 313500, eval_loss: 4.08179e-02
I0211 06:29:17.681399 22509476222784 run_lib.py:133] step: 313550, training_loss: 3.17837e-02
I0211 06:29:36.234610 22509476222784 run_lib.py:133] step: 313600, training_loss: 3.83059e-02
I0211 06:29:36.409611 22509476222784 run_lib.py:146] step: 313600, eval_loss: 5.90374e-02
I0211 06:29:55.187433 22509476222784 run_lib.py:133] step: 313650, training_loss: 4.62548e-02
I0211 06:30:13.696894 22509476222784 run_lib.py:133] step: 313700, training_loss: 4.25002e-02
I0211 06:30:13.862883 22509476222784 run_lib.py:146] step: 313700, eval_loss: 3.57061e-02
I0211 06:30:32.341949 22509476222784 run_lib.py:133] step: 313750, training_loss: 4.41519e-02
I0211 06:30:50.938946 22509476222784 run_lib.py:133] step: 313800, training_loss: 4.83350e-02
I0211 06:30:51.103642 22509476222784 run_lib.py:146] step: 313800, eval_loss: 3.74443e-02
I0211 06:31:09.641561 22509476222784 run_lib.py:133] step: 313850, training_loss: 4.50130e-02
I0211 06:31:28.342263 22509476222784 run_lib.py:133] step: 313900, training_loss: 3.55595e-02
I0211 06:31:28.511464 22509476222784 run_lib.py:146] step: 313900, eval_loss: 4.73445e-02
I0211 06:31:47.058720 22509476222784 run_lib.py:133] step: 313950, training_loss: 4.96842e-02
I0211 06:32:05.606605 22509476222784 run_lib.py:133] step: 314000, training_loss: 5.93676e-02
I0211 06:32:05.766931 22509476222784 run_lib.py:146] step: 314000, eval_loss: 5.96465e-02
I0211 06:32:24.438772 22509476222784 run_lib.py:133] step: 314050, training_loss: 5.22039e-02
I0211 06:32:42.865759 22509476222784 run_lib.py:133] step: 314100, training_loss: 5.68602e-02
I0211 06:32:43.034691 22509476222784 run_lib.py:146] step: 314100, eval_loss: 3.04980e-02
I0211 06:33:01.575783 22509476222784 run_lib.py:133] step: 314150, training_loss: 4.30338e-02
I0211 06:33:20.363479 22509476222784 run_lib.py:133] step: 314200, training_loss: 4.29035e-02
I0211 06:33:20.530754 22509476222784 run_lib.py:146] step: 314200, eval_loss: 4.70966e-02
I0211 06:33:39.038033 22509476222784 run_lib.py:133] step: 314250, training_loss: 4.66359e-02
I0211 06:33:57.508022 22509476222784 run_lib.py:133] step: 314300, training_loss: 3.91240e-02
I0211 06:33:57.671605 22509476222784 run_lib.py:146] step: 314300, eval_loss: 4.14268e-02
I0211 06:34:16.275394 22509476222784 run_lib.py:133] step: 314350, training_loss: 4.92856e-02
I0211 06:34:34.817045 22509476222784 run_lib.py:133] step: 314400, training_loss: 5.01801e-02
I0211 06:34:34.982836 22509476222784 run_lib.py:146] step: 314400, eval_loss: 5.10078e-02
I0211 06:34:53.552402 22509476222784 run_lib.py:133] step: 314450, training_loss: 3.87126e-02
I0211 06:35:11.992897 22509476222784 run_lib.py:133] step: 314500, training_loss: 4.14889e-02
I0211 06:35:12.153639 22509476222784 run_lib.py:146] step: 314500, eval_loss: 4.23224e-02
I0211 06:35:30.849426 22509476222784 run_lib.py:133] step: 314550, training_loss: 4.76422e-02
I0211 06:35:49.418117 22509476222784 run_lib.py:133] step: 314600, training_loss: 4.13409e-02
I0211 06:35:49.580521 22509476222784 run_lib.py:146] step: 314600, eval_loss: 4.40114e-02
I0211 06:36:08.113253 22509476222784 run_lib.py:133] step: 314650, training_loss: 4.87113e-02
I0211 06:36:26.693676 22509476222784 run_lib.py:133] step: 314700, training_loss: 3.49902e-02
I0211 06:36:26.860563 22509476222784 run_lib.py:146] step: 314700, eval_loss: 5.25426e-02
I0211 06:36:45.509562 22509476222784 run_lib.py:133] step: 314750, training_loss: 5.65439e-02
I0211 06:37:04.035778 22509476222784 run_lib.py:133] step: 314800, training_loss: 4.80559e-02
I0211 06:37:04.200657 22509476222784 run_lib.py:146] step: 314800, eval_loss: 6.00044e-02
I0211 06:37:22.876036 22509476222784 run_lib.py:133] step: 314850, training_loss: 2.85317e-02
I0211 06:37:41.331066 22509476222784 run_lib.py:133] step: 314900, training_loss: 5.40903e-02
I0211 06:37:41.493605 22509476222784 run_lib.py:146] step: 314900, eval_loss: 4.42271e-02
I0211 06:38:00.132913 22509476222784 run_lib.py:133] step: 314950, training_loss: 3.57400e-02
I0211 06:38:18.679753 22509476222784 run_lib.py:133] step: 315000, training_loss: 4.20256e-02
I0211 06:38:18.997501 22509476222784 run_lib.py:146] step: 315000, eval_loss: 4.20658e-02
I0211 06:38:37.697124 22509476222784 run_lib.py:133] step: 315050, training_loss: 3.65079e-02
I0211 06:38:56.208919 22509476222784 run_lib.py:133] step: 315100, training_loss: 3.67966e-02
I0211 06:38:56.376091 22509476222784 run_lib.py:146] step: 315100, eval_loss: 4.54621e-02
I0211 06:39:14.861529 22509476222784 run_lib.py:133] step: 315150, training_loss: 5.43735e-02
I0211 06:39:33.524251 22509476222784 run_lib.py:133] step: 315200, training_loss: 4.13015e-02
I0211 06:39:33.719656 22509476222784 run_lib.py:146] step: 315200, eval_loss: 4.80845e-02
I0211 06:39:52.265179 22509476222784 run_lib.py:133] step: 315250, training_loss: 3.74642e-02
I0211 06:40:10.758567 22509476222784 run_lib.py:133] step: 315300, training_loss: 3.64295e-02
I0211 06:40:10.922892 22509476222784 run_lib.py:146] step: 315300, eval_loss: 5.25629e-02
I0211 06:40:29.652155 22509476222784 run_lib.py:133] step: 315350, training_loss: 4.10505e-02
I0211 06:40:48.147794 22509476222784 run_lib.py:133] step: 315400, training_loss: 4.51852e-02
I0211 06:40:48.310524 22509476222784 run_lib.py:146] step: 315400, eval_loss: 4.00321e-02
I0211 06:41:06.928169 22509476222784 run_lib.py:133] step: 315450, training_loss: 5.29511e-02
I0211 06:41:25.557658 22509476222784 run_lib.py:133] step: 315500, training_loss: 3.81437e-02
I0211 06:41:25.730840 22509476222784 run_lib.py:146] step: 315500, eval_loss: 3.85310e-02
I0211 06:41:44.260803 22509476222784 run_lib.py:133] step: 315550, training_loss: 3.33075e-02
I0211 06:42:02.909446 22509476222784 run_lib.py:133] step: 315600, training_loss: 4.68547e-02
I0211 06:42:03.083700 22509476222784 run_lib.py:146] step: 315600, eval_loss: 4.68652e-02
I0211 06:42:21.550098 22509476222784 run_lib.py:133] step: 315650, training_loss: 3.28984e-02
I0211 06:42:40.007257 22509476222784 run_lib.py:133] step: 315700, training_loss: 5.12163e-02
I0211 06:42:40.180590 22509476222784 run_lib.py:146] step: 315700, eval_loss: 5.01470e-02
I0211 06:42:58.695728 22509476222784 run_lib.py:133] step: 315750, training_loss: 3.86743e-02
I0211 06:43:17.430346 22509476222784 run_lib.py:133] step: 315800, training_loss: 3.67907e-02
I0211 06:43:17.596945 22509476222784 run_lib.py:146] step: 315800, eval_loss: 4.02776e-02
I0211 06:43:36.148110 22509476222784 run_lib.py:133] step: 315850, training_loss: 5.11081e-02
I0211 06:43:54.675646 22509476222784 run_lib.py:133] step: 315900, training_loss: 6.04284e-02
I0211 06:43:54.834581 22509476222784 run_lib.py:146] step: 315900, eval_loss: 3.21950e-02
I0211 06:44:13.254850 22509476222784 run_lib.py:133] step: 315950, training_loss: 4.06864e-02
I0211 06:44:31.670604 22509476222784 run_lib.py:133] step: 316000, training_loss: 4.58926e-02
I0211 06:44:31.833536 22509476222784 run_lib.py:146] step: 316000, eval_loss: 3.04206e-02
I0211 06:44:50.526742 22509476222784 run_lib.py:133] step: 316050, training_loss: 4.22020e-02
I0211 06:45:09.213787 22509476222784 run_lib.py:133] step: 316100, training_loss: 4.87596e-02
I0211 06:45:09.384748 22509476222784 run_lib.py:146] step: 316100, eval_loss: 4.01291e-02
I0211 06:45:27.932837 22509476222784 run_lib.py:133] step: 316150, training_loss: 4.34465e-02
I0211 06:45:46.493813 22509476222784 run_lib.py:133] step: 316200, training_loss: 3.72869e-02
I0211 06:45:46.676704 22509476222784 run_lib.py:146] step: 316200, eval_loss: 3.25289e-02
I0211 06:46:05.279707 22509476222784 run_lib.py:133] step: 316250, training_loss: 4.61252e-02
I0211 06:46:23.754362 22509476222784 run_lib.py:133] step: 316300, training_loss: 4.73049e-02
I0211 06:46:23.924911 22509476222784 run_lib.py:146] step: 316300, eval_loss: 5.19377e-02
I0211 06:46:42.609221 22509476222784 run_lib.py:133] step: 316350, training_loss: 3.13283e-02
I0211 06:47:01.196491 22509476222784 run_lib.py:133] step: 316400, training_loss: 3.09623e-02
I0211 06:47:01.357908 22509476222784 run_lib.py:146] step: 316400, eval_loss: 3.64393e-02
I0211 06:47:20.050032 22509476222784 run_lib.py:133] step: 316450, training_loss: 5.23811e-02
I0211 06:47:38.569858 22509476222784 run_lib.py:133] step: 316500, training_loss: 4.27586e-02
I0211 06:47:38.734699 22509476222784 run_lib.py:146] step: 316500, eval_loss: 4.52367e-02
I0211 06:47:57.125999 22509476222784 run_lib.py:133] step: 316550, training_loss: 4.63606e-02
I0211 06:48:15.804255 22509476222784 run_lib.py:133] step: 316600, training_loss: 4.32894e-02
I0211 06:48:15.982668 22509476222784 run_lib.py:146] step: 316600, eval_loss: 4.51330e-02
I0211 06:48:34.515814 22509476222784 run_lib.py:133] step: 316650, training_loss: 4.67531e-02
I0211 06:48:53.222665 22509476222784 run_lib.py:133] step: 316700, training_loss: 4.06504e-02
I0211 06:48:53.388975 22509476222784 run_lib.py:146] step: 316700, eval_loss: 3.44178e-02
I0211 06:49:11.907411 22509476222784 run_lib.py:133] step: 316750, training_loss: 4.60002e-02
I0211 06:49:30.359346 22509476222784 run_lib.py:133] step: 316800, training_loss: 5.41162e-02
I0211 06:49:30.522658 22509476222784 run_lib.py:146] step: 316800, eval_loss: 4.40334e-02
I0211 06:49:49.235547 22509476222784 run_lib.py:133] step: 316850, training_loss: 4.50162e-02
I0211 06:50:07.825908 22509476222784 run_lib.py:133] step: 316900, training_loss: 4.84043e-02
I0211 06:50:07.995187 22509476222784 run_lib.py:146] step: 316900, eval_loss: 3.53292e-02
I0211 06:50:26.576112 22509476222784 run_lib.py:133] step: 316950, training_loss: 5.10982e-02
I0211 06:50:45.168291 22509476222784 run_lib.py:133] step: 317000, training_loss: 4.25986e-02
I0211 06:50:45.332106 22509476222784 run_lib.py:146] step: 317000, eval_loss: 4.89423e-02
I0211 06:51:03.670184 22509476222784 run_lib.py:133] step: 317050, training_loss: 5.57725e-02
I0211 06:51:22.044070 22509476222784 run_lib.py:133] step: 317100, training_loss: 3.59060e-02
I0211 06:51:22.354734 22509476222784 run_lib.py:146] step: 317100, eval_loss: 4.20931e-02
I0211 06:51:40.901045 22509476222784 run_lib.py:133] step: 317150, training_loss: 4.54017e-02
I0211 06:51:59.457603 22509476222784 run_lib.py:133] step: 317200, training_loss: 3.94011e-02
I0211 06:51:59.622520 22509476222784 run_lib.py:146] step: 317200, eval_loss: 3.80385e-02
I0211 06:52:18.102300 22509476222784 run_lib.py:133] step: 317250, training_loss: 3.63133e-02
I0211 06:52:36.580663 22509476222784 run_lib.py:133] step: 317300, training_loss: 4.15944e-02
I0211 06:52:36.750643 22509476222784 run_lib.py:146] step: 317300, eval_loss: 4.22595e-02
I0211 06:52:55.433287 22509476222784 run_lib.py:133] step: 317350, training_loss: 3.73516e-02
I0211 06:53:14.049178 22509476222784 run_lib.py:133] step: 317400, training_loss: 4.04742e-02
I0211 06:53:14.212829 22509476222784 run_lib.py:146] step: 317400, eval_loss: 3.89228e-02
I0211 06:53:32.753103 22509476222784 run_lib.py:133] step: 317450, training_loss: 3.51333e-02
I0211 06:53:51.332288 22509476222784 run_lib.py:133] step: 317500, training_loss: 4.33538e-02
I0211 06:53:51.495120 22509476222784 run_lib.py:146] step: 317500, eval_loss: 3.72242e-02
I0211 06:54:10.141493 22509476222784 run_lib.py:133] step: 317550, training_loss: 4.11461e-02
I0211 06:54:28.663060 22509476222784 run_lib.py:133] step: 317600, training_loss: 4.37144e-02
I0211 06:54:28.827587 22509476222784 run_lib.py:146] step: 317600, eval_loss: 5.29996e-02
I0211 06:54:47.352390 22509476222784 run_lib.py:133] step: 317650, training_loss: 4.39324e-02
I0211 06:55:05.803995 22509476222784 run_lib.py:133] step: 317700, training_loss: 3.63981e-02
I0211 06:55:05.969312 22509476222784 run_lib.py:146] step: 317700, eval_loss: 5.57175e-02
I0211 06:55:24.701301 22509476222784 run_lib.py:133] step: 317750, training_loss: 3.81572e-02
I0211 06:55:43.214258 22509476222784 run_lib.py:133] step: 317800, training_loss: 4.05143e-02
I0211 06:55:43.377423 22509476222784 run_lib.py:146] step: 317800, eval_loss: 5.21413e-02
I0211 06:56:02.135282 22509476222784 run_lib.py:133] step: 317850, training_loss: 3.78698e-02
I0211 06:56:20.617593 22509476222784 run_lib.py:133] step: 317900, training_loss: 4.01669e-02
I0211 06:56:20.782713 22509476222784 run_lib.py:146] step: 317900, eval_loss: 3.59891e-02
I0211 06:56:39.416107 22509476222784 run_lib.py:133] step: 317950, training_loss: 3.77037e-02
I0211 06:56:57.861225 22509476222784 run_lib.py:133] step: 318000, training_loss: 4.65000e-02
I0211 06:56:58.037669 22509476222784 run_lib.py:146] step: 318000, eval_loss: 3.52965e-02
I0211 06:57:16.559576 22509476222784 run_lib.py:133] step: 318050, training_loss: 5.33040e-02
I0211 06:57:35.278321 22509476222784 run_lib.py:133] step: 318100, training_loss: 3.62568e-02
I0211 06:57:35.443001 22509476222784 run_lib.py:146] step: 318100, eval_loss: 4.63737e-02
I0211 06:57:53.951756 22509476222784 run_lib.py:133] step: 318150, training_loss: 3.38742e-02
I0211 06:58:12.572451 22509476222784 run_lib.py:133] step: 318200, training_loss: 3.22787e-02
I0211 06:58:12.736664 22509476222784 run_lib.py:146] step: 318200, eval_loss: 4.27619e-02
I0211 06:58:31.199469 22509476222784 run_lib.py:133] step: 318250, training_loss: 4.95420e-02
I0211 06:58:49.760663 22509476222784 run_lib.py:133] step: 318300, training_loss: 2.71707e-02
I0211 06:58:49.943140 22509476222784 run_lib.py:146] step: 318300, eval_loss: 4.36397e-02
I0211 06:59:08.489315 22509476222784 run_lib.py:133] step: 318350, training_loss: 3.03654e-02
I0211 06:59:27.092280 22509476222784 run_lib.py:133] step: 318400, training_loss: 4.49706e-02
I0211 06:59:27.257612 22509476222784 run_lib.py:146] step: 318400, eval_loss: 3.54466e-02
I0211 06:59:45.754202 22509476222784 run_lib.py:133] step: 318450, training_loss: 4.95567e-02
I0211 07:00:04.234329 22509476222784 run_lib.py:133] step: 318500, training_loss: 4.46457e-02
I0211 07:00:04.401825 22509476222784 run_lib.py:146] step: 318500, eval_loss: 4.74730e-02
I0211 07:00:23.097508 22509476222784 run_lib.py:133] step: 318550, training_loss: 3.45838e-02
I0211 07:00:41.616329 22509476222784 run_lib.py:133] step: 318600, training_loss: 3.17981e-02
I0211 07:00:41.779709 22509476222784 run_lib.py:146] step: 318600, eval_loss: 4.41967e-02
I0211 07:01:00.368313 22509476222784 run_lib.py:133] step: 318650, training_loss: 4.35490e-02
I0211 07:01:18.903720 22509476222784 run_lib.py:133] step: 318700, training_loss: 4.06918e-02
I0211 07:01:19.066555 22509476222784 run_lib.py:146] step: 318700, eval_loss: 4.44856e-02
I0211 07:01:37.594055 22509476222784 run_lib.py:133] step: 318750, training_loss: 6.26941e-02
I0211 07:01:56.076645 22509476222784 run_lib.py:133] step: 318800, training_loss: 4.64812e-02
I0211 07:01:56.249593 22509476222784 run_lib.py:146] step: 318800, eval_loss: 4.09485e-02
I0211 07:02:14.940630 22509476222784 run_lib.py:133] step: 318850, training_loss: 3.54827e-02
I0211 07:02:33.527819 22509476222784 run_lib.py:133] step: 318900, training_loss: 4.33628e-02
I0211 07:02:33.703673 22509476222784 run_lib.py:146] step: 318900, eval_loss: 4.56877e-02
I0211 07:02:52.222123 22509476222784 run_lib.py:133] step: 318950, training_loss: 4.95579e-02
I0211 07:03:10.749024 22509476222784 run_lib.py:133] step: 319000, training_loss: 4.33811e-02
I0211 07:03:10.913680 22509476222784 run_lib.py:146] step: 319000, eval_loss: 3.72180e-02
I0211 07:03:29.616403 22509476222784 run_lib.py:133] step: 319050, training_loss: 4.78811e-02
I0211 07:03:48.184889 22509476222784 run_lib.py:133] step: 319100, training_loss: 4.57342e-02
I0211 07:03:48.350725 22509476222784 run_lib.py:146] step: 319100, eval_loss: 4.06675e-02
I0211 07:04:06.972129 22509476222784 run_lib.py:133] step: 319150, training_loss: 5.55536e-02
I0211 07:04:25.439164 22509476222784 run_lib.py:133] step: 319200, training_loss: 4.14010e-02
I0211 07:04:25.601302 22509476222784 run_lib.py:146] step: 319200, eval_loss: 4.38459e-02
I0211 07:04:44.217715 22509476222784 run_lib.py:133] step: 319250, training_loss: 3.41933e-02
I0211 07:05:02.656629 22509476222784 run_lib.py:133] step: 319300, training_loss: 2.61687e-02
I0211 07:05:02.830780 22509476222784 run_lib.py:146] step: 319300, eval_loss: 4.33962e-02
I0211 07:05:21.424688 22509476222784 run_lib.py:133] step: 319350, training_loss: 3.96027e-02
I0211 07:05:39.949007 22509476222784 run_lib.py:133] step: 319400, training_loss: 3.72507e-02
I0211 07:05:40.113827 22509476222784 run_lib.py:146] step: 319400, eval_loss: 4.55007e-02
I0211 07:05:58.620340 22509476222784 run_lib.py:133] step: 319450, training_loss: 3.62935e-02
I0211 07:06:17.328754 22509476222784 run_lib.py:133] step: 319500, training_loss: 5.58183e-02
I0211 07:06:17.581532 22509476222784 run_lib.py:146] step: 319500, eval_loss: 5.02284e-02
I0211 07:06:36.086528 22509476222784 run_lib.py:133] step: 319550, training_loss: 5.15152e-02
I0211 07:06:54.647216 22509476222784 run_lib.py:133] step: 319600, training_loss: 3.53121e-02
I0211 07:06:54.815013 22509476222784 run_lib.py:146] step: 319600, eval_loss: 4.88083e-02
I0211 07:07:13.463989 22509476222784 run_lib.py:133] step: 319650, training_loss: 4.44375e-02
I0211 07:07:32.114336 22509476222784 run_lib.py:133] step: 319700, training_loss: 4.03259e-02
I0211 07:07:32.274756 22509476222784 run_lib.py:146] step: 319700, eval_loss: 3.51902e-02
I0211 07:07:50.759398 22509476222784 run_lib.py:133] step: 319750, training_loss: 3.52192e-02
I0211 07:08:09.192393 22509476222784 run_lib.py:133] step: 319800, training_loss: 4.01691e-02
I0211 07:08:09.355786 22509476222784 run_lib.py:146] step: 319800, eval_loss: 3.44559e-02
I0211 07:08:27.891071 22509476222784 run_lib.py:133] step: 319850, training_loss: 5.05326e-02
I0211 07:08:46.687612 22509476222784 run_lib.py:133] step: 319900, training_loss: 3.90704e-02
I0211 07:08:46.920769 22509476222784 run_lib.py:146] step: 319900, eval_loss: 5.74199e-02
I0211 07:09:05.448786 22509476222784 run_lib.py:133] step: 319950, training_loss: 5.50085e-02
I0211 07:09:23.963589 22509476222784 run_lib.py:133] step: 320000, training_loss: 4.79433e-02
I0211 07:09:24.703489 22509476222784 run_lib.py:146] step: 320000, eval_loss: 4.48441e-02
I0211 07:09:45.876016 22509476222784 run_lib.py:133] step: 320050, training_loss: 3.76267e-02
I0211 07:10:04.501082 22509476222784 run_lib.py:133] step: 320100, training_loss: 4.11030e-02
I0211 07:10:04.682221 22509476222784 run_lib.py:146] step: 320100, eval_loss: 3.98191e-02
I0211 07:10:23.268183 22509476222784 run_lib.py:133] step: 320150, training_loss: 5.01734e-02
I0211 07:10:41.836122 22509476222784 run_lib.py:133] step: 320200, training_loss: 5.02183e-02
I0211 07:10:42.008041 22509476222784 run_lib.py:146] step: 320200, eval_loss: 5.20311e-02
I0211 07:11:00.626910 22509476222784 run_lib.py:133] step: 320250, training_loss: 4.63779e-02
I0211 07:11:19.116197 22509476222784 run_lib.py:133] step: 320300, training_loss: 4.32197e-02
I0211 07:11:19.278763 22509476222784 run_lib.py:146] step: 320300, eval_loss: 4.48889e-02
I0211 07:11:37.714561 22509476222784 run_lib.py:133] step: 320350, training_loss: 4.36298e-02
I0211 07:11:56.161816 22509476222784 run_lib.py:133] step: 320400, training_loss: 4.64096e-02
I0211 07:11:56.341606 22509476222784 run_lib.py:146] step: 320400, eval_loss: 3.57951e-02
I0211 07:12:15.046466 22509476222784 run_lib.py:133] step: 320450, training_loss: 3.77566e-02
I0211 07:12:33.699515 22509476222784 run_lib.py:133] step: 320500, training_loss: 3.81934e-02
I0211 07:12:33.868936 22509476222784 run_lib.py:146] step: 320500, eval_loss: 2.89374e-02
I0211 07:12:52.399995 22509476222784 run_lib.py:133] step: 320550, training_loss: 5.29877e-02
I0211 07:13:10.823136 22509476222784 run_lib.py:133] step: 320600, training_loss: 4.56246e-02
I0211 07:13:10.995087 22509476222784 run_lib.py:146] step: 320600, eval_loss: 4.49858e-02
I0211 07:13:29.540286 22509476222784 run_lib.py:133] step: 320650, training_loss: 4.93264e-02
I0211 07:13:48.084637 22509476222784 run_lib.py:133] step: 320700, training_loss: 3.74200e-02
I0211 07:13:48.255754 22509476222784 run_lib.py:146] step: 320700, eval_loss: 4.46996e-02
I0211 07:14:06.960658 22509476222784 run_lib.py:133] step: 320750, training_loss: 2.91057e-02
I0211 07:14:25.408606 22509476222784 run_lib.py:133] step: 320800, training_loss: 3.70290e-02
I0211 07:14:25.576672 22509476222784 run_lib.py:146] step: 320800, eval_loss: 4.38101e-02
I0211 07:14:44.230012 22509476222784 run_lib.py:133] step: 320850, training_loss: 4.90769e-02
I0211 07:15:02.752577 22509476222784 run_lib.py:133] step: 320900, training_loss: 5.21216e-02
I0211 07:15:02.918892 22509476222784 run_lib.py:146] step: 320900, eval_loss: 5.61747e-02
I0211 07:15:21.533413 22509476222784 run_lib.py:133] step: 320950, training_loss: 4.10361e-02
I0211 07:15:40.085619 22509476222784 run_lib.py:133] step: 321000, training_loss: 5.01263e-02
I0211 07:15:40.249848 22509476222784 run_lib.py:146] step: 321000, eval_loss: 4.68515e-02
I0211 07:15:58.785636 22509476222784 run_lib.py:133] step: 321050, training_loss: 4.18571e-02
I0211 07:16:17.495568 22509476222784 run_lib.py:133] step: 321100, training_loss: 3.86592e-02
I0211 07:16:17.655598 22509476222784 run_lib.py:146] step: 321100, eval_loss: 4.68807e-02
I0211 07:16:36.137452 22509476222784 run_lib.py:133] step: 321150, training_loss: 3.99711e-02
I0211 07:16:54.636261 22509476222784 run_lib.py:133] step: 321200, training_loss: 3.69862e-02
I0211 07:16:54.795739 22509476222784 run_lib.py:146] step: 321200, eval_loss: 4.42343e-02
I0211 07:17:13.502525 22509476222784 run_lib.py:133] step: 321250, training_loss: 4.45674e-02
I0211 07:17:32.018441 22509476222784 run_lib.py:133] step: 321300, training_loss: 4.70607e-02
I0211 07:17:32.201845 22509476222784 run_lib.py:146] step: 321300, eval_loss: 4.79036e-02
I0211 07:17:50.948904 22509476222784 run_lib.py:133] step: 321350, training_loss: 3.71305e-02
I0211 07:18:09.483982 22509476222784 run_lib.py:133] step: 321400, training_loss: 4.60889e-02
I0211 07:18:09.649931 22509476222784 run_lib.py:146] step: 321400, eval_loss: 4.50963e-02
I0211 07:18:28.174501 22509476222784 run_lib.py:133] step: 321450, training_loss: 4.31020e-02
I0211 07:18:46.698949 22509476222784 run_lib.py:133] step: 321500, training_loss: 3.80956e-02
I0211 07:18:46.862633 22509476222784 run_lib.py:146] step: 321500, eval_loss: 4.53659e-02
I0211 07:19:05.355696 22509476222784 run_lib.py:133] step: 321550, training_loss: 4.00780e-02
I0211 07:19:23.940977 22509476222784 run_lib.py:133] step: 321600, training_loss: 4.64797e-02
I0211 07:19:24.105383 22509476222784 run_lib.py:146] step: 321600, eval_loss: 5.07383e-02
I0211 07:19:42.578475 22509476222784 run_lib.py:133] step: 321650, training_loss: 4.00844e-02
I0211 07:20:01.240196 22509476222784 run_lib.py:133] step: 321700, training_loss: 3.42345e-02
I0211 07:20:01.401599 22509476222784 run_lib.py:146] step: 321700, eval_loss: 3.85753e-02
I0211 07:20:19.804364 22509476222784 run_lib.py:133] step: 321750, training_loss: 4.90036e-02
I0211 07:20:38.311105 22509476222784 run_lib.py:133] step: 321800, training_loss: 4.25309e-02
I0211 07:20:38.492569 22509476222784 run_lib.py:146] step: 321800, eval_loss: 4.76188e-02
I0211 07:20:57.075024 22509476222784 run_lib.py:133] step: 321850, training_loss: 3.70708e-02
I0211 07:21:15.670121 22509476222784 run_lib.py:133] step: 321900, training_loss: 3.76667e-02
I0211 07:21:15.835587 22509476222784 run_lib.py:146] step: 321900, eval_loss: 5.68664e-02
I0211 07:21:34.509714 22509476222784 run_lib.py:133] step: 321950, training_loss: 4.60754e-02
I0211 07:21:53.105670 22509476222784 run_lib.py:133] step: 322000, training_loss: 4.34237e-02
I0211 07:21:53.268641 22509476222784 run_lib.py:146] step: 322000, eval_loss: 4.37205e-02
I0211 07:22:11.763659 22509476222784 run_lib.py:133] step: 322050, training_loss: 5.10035e-02
I0211 07:22:30.319884 22509476222784 run_lib.py:133] step: 322100, training_loss: 4.96076e-02
I0211 07:22:30.484020 22509476222784 run_lib.py:146] step: 322100, eval_loss: 3.65667e-02
I0211 07:22:49.231018 22509476222784 run_lib.py:133] step: 322150, training_loss: 4.94338e-02
I0211 07:23:07.740720 22509476222784 run_lib.py:133] step: 322200, training_loss: 4.65191e-02
I0211 07:23:07.902493 22509476222784 run_lib.py:146] step: 322200, eval_loss: 4.18850e-02
I0211 07:23:26.600804 22509476222784 run_lib.py:133] step: 322250, training_loss: 4.47596e-02
I0211 07:23:45.138979 22509476222784 run_lib.py:133] step: 322300, training_loss: 3.98902e-02
I0211 07:23:45.461738 22509476222784 run_lib.py:146] step: 322300, eval_loss: 4.49235e-02
I0211 07:24:04.027704 22509476222784 run_lib.py:133] step: 322350, training_loss: 4.30669e-02
I0211 07:24:22.497255 22509476222784 run_lib.py:133] step: 322400, training_loss: 3.83919e-02
I0211 07:24:22.675631 22509476222784 run_lib.py:146] step: 322400, eval_loss: 3.27156e-02
I0211 07:24:41.255906 22509476222784 run_lib.py:133] step: 322450, training_loss: 3.12605e-02
I0211 07:24:59.894863 22509476222784 run_lib.py:133] step: 322500, training_loss: 3.92579e-02
I0211 07:25:00.056280 22509476222784 run_lib.py:146] step: 322500, eval_loss: 3.29535e-02
I0211 07:25:18.419335 22509476222784 run_lib.py:133] step: 322550, training_loss: 3.57370e-02
I0211 07:25:37.004173 22509476222784 run_lib.py:133] step: 322600, training_loss: 5.32031e-02
I0211 07:25:37.169408 22509476222784 run_lib.py:146] step: 322600, eval_loss: 4.49675e-02
I0211 07:25:55.660326 22509476222784 run_lib.py:133] step: 322650, training_loss: 3.95968e-02
I0211 07:26:14.199772 22509476222784 run_lib.py:133] step: 322700, training_loss: 5.98840e-02
I0211 07:26:14.392677 22509476222784 run_lib.py:146] step: 322700, eval_loss: 3.74056e-02
I0211 07:26:33.091839 22509476222784 run_lib.py:133] step: 322750, training_loss: 4.25595e-02
I0211 07:26:51.564702 22509476222784 run_lib.py:133] step: 322800, training_loss: 4.96253e-02
I0211 07:26:51.729781 22509476222784 run_lib.py:146] step: 322800, eval_loss: 5.33610e-02
I0211 07:27:10.198735 22509476222784 run_lib.py:133] step: 322850, training_loss: 4.22943e-02
I0211 07:27:28.849733 22509476222784 run_lib.py:133] step: 322900, training_loss: 3.44718e-02
I0211 07:27:29.014649 22509476222784 run_lib.py:146] step: 322900, eval_loss: 4.06792e-02
I0211 07:27:47.488975 22509476222784 run_lib.py:133] step: 322950, training_loss: 4.46157e-02
I0211 07:28:06.039205 22509476222784 run_lib.py:133] step: 323000, training_loss: 4.11448e-02
I0211 07:28:06.399772 22509476222784 run_lib.py:146] step: 323000, eval_loss: 3.97958e-02
I0211 07:28:24.967827 22509476222784 run_lib.py:133] step: 323050, training_loss: 6.12541e-02
I0211 07:28:43.404193 22509476222784 run_lib.py:133] step: 323100, training_loss: 4.19700e-02
I0211 07:28:43.564705 22509476222784 run_lib.py:146] step: 323100, eval_loss: 3.06034e-02
I0211 07:29:02.102661 22509476222784 run_lib.py:133] step: 323150, training_loss: 3.89587e-02
I0211 07:29:20.684504 22509476222784 run_lib.py:133] step: 323200, training_loss: 4.07987e-02
I0211 07:29:20.855192 22509476222784 run_lib.py:146] step: 323200, eval_loss: 4.89227e-02
I0211 07:29:39.454005 22509476222784 run_lib.py:133] step: 323250, training_loss: 3.65718e-02
I0211 07:29:57.922477 22509476222784 run_lib.py:133] step: 323300, training_loss: 4.71150e-02
I0211 07:29:58.085510 22509476222784 run_lib.py:146] step: 323300, eval_loss: 4.59822e-02
I0211 07:30:16.519892 22509476222784 run_lib.py:133] step: 323350, training_loss: 4.21069e-02
I0211 07:30:35.013534 22509476222784 run_lib.py:133] step: 323400, training_loss: 5.03328e-02
I0211 07:30:35.179695 22509476222784 run_lib.py:146] step: 323400, eval_loss: 4.21634e-02
I0211 07:30:53.824031 22509476222784 run_lib.py:133] step: 323450, training_loss: 3.69251e-02
I0211 07:31:12.431958 22509476222784 run_lib.py:133] step: 323500, training_loss: 3.50140e-02
I0211 07:31:12.604883 22509476222784 run_lib.py:146] step: 323500, eval_loss: 4.29394e-02
I0211 07:31:31.145654 22509476222784 run_lib.py:133] step: 323550, training_loss: 4.75354e-02
I0211 07:31:49.643789 22509476222784 run_lib.py:133] step: 323600, training_loss: 4.72050e-02
I0211 07:31:49.804544 22509476222784 run_lib.py:146] step: 323600, eval_loss: 4.21733e-02
I0211 07:32:08.424075 22509476222784 run_lib.py:133] step: 323650, training_loss: 3.07152e-02
I0211 07:32:26.898666 22509476222784 run_lib.py:133] step: 323700, training_loss: 3.11854e-02
I0211 07:32:27.062890 22509476222784 run_lib.py:146] step: 323700, eval_loss: 5.62981e-02
I0211 07:32:45.746183 22509476222784 run_lib.py:133] step: 323750, training_loss: 3.44955e-02
I0211 07:33:04.337559 22509476222784 run_lib.py:133] step: 323800, training_loss: 4.18822e-02
I0211 07:33:04.502614 22509476222784 run_lib.py:146] step: 323800, eval_loss: 5.61690e-02
I0211 07:33:23.177025 22509476222784 run_lib.py:133] step: 323850, training_loss: 4.52455e-02
I0211 07:33:41.599272 22509476222784 run_lib.py:133] step: 323900, training_loss: 3.35383e-02
I0211 07:33:41.770457 22509476222784 run_lib.py:146] step: 323900, eval_loss: 3.95326e-02
I0211 07:34:00.289525 22509476222784 run_lib.py:133] step: 323950, training_loss: 4.53536e-02
I0211 07:34:19.027207 22509476222784 run_lib.py:133] step: 324000, training_loss: 5.69310e-02
I0211 07:34:19.190875 22509476222784 run_lib.py:146] step: 324000, eval_loss: 4.38115e-02
I0211 07:34:37.748541 22509476222784 run_lib.py:133] step: 324050, training_loss: 5.24559e-02
I0211 07:34:56.432559 22509476222784 run_lib.py:133] step: 324100, training_loss: 4.16548e-02
I0211 07:34:56.600558 22509476222784 run_lib.py:146] step: 324100, eval_loss: 4.20306e-02
I0211 07:35:15.078578 22509476222784 run_lib.py:133] step: 324150, training_loss: 4.18417e-02
I0211 07:35:33.598242 22509476222784 run_lib.py:133] step: 324200, training_loss: 4.80158e-02
I0211 07:35:33.787624 22509476222784 run_lib.py:146] step: 324200, eval_loss: 4.02177e-02
I0211 07:35:52.271522 22509476222784 run_lib.py:133] step: 324250, training_loss: 6.14407e-02
I0211 07:36:10.930914 22509476222784 run_lib.py:133] step: 324300, training_loss: 4.21874e-02
I0211 07:36:11.095731 22509476222784 run_lib.py:146] step: 324300, eval_loss: 2.79576e-02
I0211 07:36:29.601138 22509476222784 run_lib.py:133] step: 324350, training_loss: 4.83865e-02
I0211 07:36:48.114267 22509476222784 run_lib.py:133] step: 324400, training_loss: 4.52230e-02
I0211 07:36:48.278762 22509476222784 run_lib.py:146] step: 324400, eval_loss: 3.67710e-02
I0211 07:37:06.986626 22509476222784 run_lib.py:133] step: 324450, training_loss: 3.68011e-02
I0211 07:37:25.400177 22509476222784 run_lib.py:133] step: 324500, training_loss: 3.70739e-02
I0211 07:37:25.559510 22509476222784 run_lib.py:146] step: 324500, eval_loss: 3.49163e-02
I0211 07:37:44.125559 22509476222784 run_lib.py:133] step: 324550, training_loss: 4.19771e-02
I0211 07:38:02.620259 22509476222784 run_lib.py:133] step: 324600, training_loss: 4.35275e-02
I0211 07:38:02.792782 22509476222784 run_lib.py:146] step: 324600, eval_loss: 4.21962e-02
I0211 07:38:21.219408 22509476222784 run_lib.py:133] step: 324650, training_loss: 2.97525e-02
I0211 07:38:39.752244 22509476222784 run_lib.py:133] step: 324700, training_loss: 2.75627e-02
I0211 07:38:39.918937 22509476222784 run_lib.py:146] step: 324700, eval_loss: 4.96849e-02
I0211 07:38:58.599940 22509476222784 run_lib.py:133] step: 324750, training_loss: 5.23293e-02
I0211 07:39:17.189656 22509476222784 run_lib.py:133] step: 324800, training_loss: 4.00199e-02
I0211 07:39:17.361757 22509476222784 run_lib.py:146] step: 324800, eval_loss: 4.00353e-02
I0211 07:39:35.842669 22509476222784 run_lib.py:133] step: 324850, training_loss: 3.66254e-02
I0211 07:39:54.350071 22509476222784 run_lib.py:133] step: 324900, training_loss: 4.04023e-02
I0211 07:39:54.522955 22509476222784 run_lib.py:146] step: 324900, eval_loss: 4.92134e-02
I0211 07:40:13.271916 22509476222784 run_lib.py:133] step: 324950, training_loss: 4.47145e-02
I0211 07:40:31.818883 22509476222784 run_lib.py:133] step: 325000, training_loss: 6.20242e-02
I0211 07:40:31.979782 22509476222784 run_lib.py:146] step: 325000, eval_loss: 3.14911e-02
I0211 07:40:50.673470 22509476222784 run_lib.py:133] step: 325050, training_loss: 3.77367e-02
I0211 07:41:09.224110 22509476222784 run_lib.py:133] step: 325100, training_loss: 4.53782e-02
I0211 07:41:09.407946 22509476222784 run_lib.py:146] step: 325100, eval_loss: 4.03028e-02
I0211 07:41:28.131523 22509476222784 run_lib.py:133] step: 325150, training_loss: 4.47223e-02
I0211 07:41:46.689707 22509476222784 run_lib.py:133] step: 325200, training_loss: 4.11068e-02
I0211 07:41:46.855840 22509476222784 run_lib.py:146] step: 325200, eval_loss: 4.63232e-02
I0211 07:42:05.498414 22509476222784 run_lib.py:133] step: 325250, training_loss: 3.57055e-02
I0211 07:42:23.955162 22509476222784 run_lib.py:133] step: 325300, training_loss: 4.43976e-02
I0211 07:42:24.117657 22509476222784 run_lib.py:146] step: 325300, eval_loss: 4.24279e-02
I0211 07:42:42.657639 22509476222784 run_lib.py:133] step: 325350, training_loss: 4.96826e-02
I0211 07:43:01.375425 22509476222784 run_lib.py:133] step: 325400, training_loss: 4.40207e-02
I0211 07:43:01.539395 22509476222784 run_lib.py:146] step: 325400, eval_loss: 4.43076e-02
I0211 07:43:20.017433 22509476222784 run_lib.py:133] step: 325450, training_loss: 4.02057e-02
I0211 07:43:38.427163 22509476222784 run_lib.py:133] step: 325500, training_loss: 3.53050e-02
I0211 07:43:38.588280 22509476222784 run_lib.py:146] step: 325500, eval_loss: 3.53853e-02
I0211 07:43:57.244985 22509476222784 run_lib.py:133] step: 325550, training_loss: 5.01346e-02
I0211 07:44:15.838273 22509476222784 run_lib.py:133] step: 325600, training_loss: 4.98480e-02
I0211 07:44:16.003484 22509476222784 run_lib.py:146] step: 325600, eval_loss: 4.92104e-02
I0211 07:44:34.571082 22509476222784 run_lib.py:133] step: 325650, training_loss: 3.29780e-02
I0211 07:44:53.110069 22509476222784 run_lib.py:133] step: 325700, training_loss: 5.87360e-02
I0211 07:44:53.284586 22509476222784 run_lib.py:146] step: 325700, eval_loss: 5.03764e-02
I0211 07:45:11.773424 22509476222784 run_lib.py:133] step: 325750, training_loss: 4.14926e-02
I0211 07:45:30.431919 22509476222784 run_lib.py:133] step: 325800, training_loss: 3.70531e-02
I0211 07:45:30.596779 22509476222784 run_lib.py:146] step: 325800, eval_loss: 4.52856e-02
I0211 07:45:49.111796 22509476222784 run_lib.py:133] step: 325850, training_loss: 2.82946e-02
I0211 07:46:07.587889 22509476222784 run_lib.py:133] step: 325900, training_loss: 4.97561e-02
I0211 07:46:07.761229 22509476222784 run_lib.py:146] step: 325900, eval_loss: 4.02395e-02
I0211 07:46:26.368364 22509476222784 run_lib.py:133] step: 325950, training_loss: 2.81220e-02
I0211 07:46:44.977795 22509476222784 run_lib.py:133] step: 326000, training_loss: 4.05636e-02
I0211 07:46:45.140887 22509476222784 run_lib.py:146] step: 326000, eval_loss: 4.06529e-02
I0211 07:47:03.661370 22509476222784 run_lib.py:133] step: 326050, training_loss: 4.80975e-02
I0211 07:47:22.224917 22509476222784 run_lib.py:133] step: 326100, training_loss: 5.90000e-02
I0211 07:47:22.399724 22509476222784 run_lib.py:146] step: 326100, eval_loss: 2.71483e-02
I0211 07:47:40.917571 22509476222784 run_lib.py:133] step: 326150, training_loss: 4.52384e-02
I0211 07:47:59.525359 22509476222784 run_lib.py:133] step: 326200, training_loss: 3.42295e-02
I0211 07:47:59.691049 22509476222784 run_lib.py:146] step: 326200, eval_loss: 4.56439e-02
I0211 07:48:18.390598 22509476222784 run_lib.py:133] step: 326250, training_loss: 3.04646e-02
I0211 07:48:36.910106 22509476222784 run_lib.py:133] step: 326300, training_loss: 3.92760e-02
I0211 07:48:37.075570 22509476222784 run_lib.py:146] step: 326300, eval_loss: 4.08359e-02
I0211 07:48:55.565226 22509476222784 run_lib.py:133] step: 326350, training_loss: 4.73305e-02
I0211 07:49:14.072197 22509476222784 run_lib.py:133] step: 326400, training_loss: 3.58587e-02
I0211 07:49:14.237530 22509476222784 run_lib.py:146] step: 326400, eval_loss: 3.82927e-02
I0211 07:49:32.923570 22509476222784 run_lib.py:133] step: 326450, training_loss: 4.31957e-02
I0211 07:49:51.345825 22509476222784 run_lib.py:133] step: 326500, training_loss: 4.07905e-02
I0211 07:49:51.518445 22509476222784 run_lib.py:146] step: 326500, eval_loss: 4.39798e-02
I0211 07:50:10.200212 22509476222784 run_lib.py:133] step: 326550, training_loss: 3.32635e-02
I0211 07:50:28.709581 22509476222784 run_lib.py:133] step: 326600, training_loss: 5.22059e-02
I0211 07:50:28.878848 22509476222784 run_lib.py:146] step: 326600, eval_loss: 4.95343e-02
I0211 07:50:47.498368 22509476222784 run_lib.py:133] step: 326650, training_loss: 4.76648e-02
I0211 07:51:05.960961 22509476222784 run_lib.py:133] step: 326700, training_loss: 4.10314e-02
I0211 07:51:06.141654 22509476222784 run_lib.py:146] step: 326700, eval_loss: 5.04262e-02
I0211 07:51:24.655942 22509476222784 run_lib.py:133] step: 326750, training_loss: 4.73555e-02
I0211 07:51:43.384539 22509476222784 run_lib.py:133] step: 326800, training_loss: 3.42950e-02
I0211 07:51:43.565773 22509476222784 run_lib.py:146] step: 326800, eval_loss: 4.90762e-02
I0211 07:52:02.074040 22509476222784 run_lib.py:133] step: 326850, training_loss: 3.98663e-02
I0211 07:52:20.741405 22509476222784 run_lib.py:133] step: 326900, training_loss: 4.36214e-02
I0211 07:52:20.902652 22509476222784 run_lib.py:146] step: 326900, eval_loss: 4.66556e-02
I0211 07:52:39.417885 22509476222784 run_lib.py:133] step: 326950, training_loss: 6.16389e-02
I0211 07:52:57.918905 22509476222784 run_lib.py:133] step: 327000, training_loss: 2.99968e-02
I0211 07:52:58.092926 22509476222784 run_lib.py:146] step: 327000, eval_loss: 4.17245e-02
I0211 07:53:16.759149 22509476222784 run_lib.py:133] step: 327050, training_loss: 4.96465e-02
I0211 07:53:35.222338 22509476222784 run_lib.py:133] step: 327100, training_loss: 3.64676e-02
I0211 07:53:35.387246 22509476222784 run_lib.py:146] step: 327100, eval_loss: 5.26078e-02
I0211 07:53:53.896082 22509476222784 run_lib.py:133] step: 327150, training_loss: 5.11162e-02
I0211 07:54:12.402602 22509476222784 run_lib.py:133] step: 327200, training_loss: 4.52446e-02
I0211 07:54:12.565544 22509476222784 run_lib.py:146] step: 327200, eval_loss: 4.57396e-02
I0211 07:54:30.919222 22509476222784 run_lib.py:133] step: 327250, training_loss: 3.07250e-02
I0211 07:54:49.339260 22509476222784 run_lib.py:133] step: 327300, training_loss: 4.01405e-02
I0211 07:54:49.500348 22509476222784 run_lib.py:146] step: 327300, eval_loss: 3.60962e-02
I0211 07:55:08.054754 22509476222784 run_lib.py:133] step: 327350, training_loss: 3.92479e-02
I0211 07:55:26.499472 22509476222784 run_lib.py:133] step: 327400, training_loss: 4.60120e-02
I0211 07:55:26.665833 22509476222784 run_lib.py:146] step: 327400, eval_loss: 3.89238e-02
I0211 07:55:45.145628 22509476222784 run_lib.py:133] step: 327450, training_loss: 3.58224e-02
I0211 07:56:03.653201 22509476222784 run_lib.py:133] step: 327500, training_loss: 3.71559e-02
I0211 07:56:03.817931 22509476222784 run_lib.py:146] step: 327500, eval_loss: 3.61121e-02
I0211 07:56:22.450244 22509476222784 run_lib.py:133] step: 327550, training_loss: 4.38155e-02
I0211 07:56:40.996715 22509476222784 run_lib.py:133] step: 327600, training_loss: 4.79926e-02
I0211 07:56:41.160562 22509476222784 run_lib.py:146] step: 327600, eval_loss: 4.48144e-02
I0211 07:56:59.647893 22509476222784 run_lib.py:133] step: 327650, training_loss: 4.41223e-02
I0211 07:57:18.217408 22509476222784 run_lib.py:133] step: 327700, training_loss: 4.23520e-02
I0211 07:57:18.382912 22509476222784 run_lib.py:146] step: 327700, eval_loss: 4.77760e-02
I0211 07:57:37.086347 22509476222784 run_lib.py:133] step: 327750, training_loss: 4.53047e-02
I0211 07:57:55.603518 22509476222784 run_lib.py:133] step: 327800, training_loss: 3.54403e-02
I0211 07:57:55.769578 22509476222784 run_lib.py:146] step: 327800, eval_loss: 3.67161e-02
I0211 07:58:14.443512 22509476222784 run_lib.py:133] step: 327850, training_loss: 4.25454e-02
I0211 07:58:33.022856 22509476222784 run_lib.py:133] step: 327900, training_loss: 5.21311e-02
I0211 07:58:33.186899 22509476222784 run_lib.py:146] step: 327900, eval_loss: 3.26067e-02
I0211 07:58:51.901136 22509476222784 run_lib.py:133] step: 327950, training_loss: 3.77189e-02
I0211 07:59:10.439410 22509476222784 run_lib.py:133] step: 328000, training_loss: 5.49309e-02
I0211 07:59:10.614909 22509476222784 run_lib.py:146] step: 328000, eval_loss: 3.54096e-02
I0211 07:59:29.278669 22509476222784 run_lib.py:133] step: 328050, training_loss: 4.19326e-02
I0211 07:59:47.812958 22509476222784 run_lib.py:133] step: 328100, training_loss: 4.60859e-02
I0211 07:59:47.985145 22509476222784 run_lib.py:146] step: 328100, eval_loss: 4.12865e-02
I0211 08:00:06.512393 22509476222784 run_lib.py:133] step: 328150, training_loss: 5.14632e-02
I0211 08:00:25.188357 22509476222784 run_lib.py:133] step: 328200, training_loss: 4.11258e-02
I0211 08:00:25.354061 22509476222784 run_lib.py:146] step: 328200, eval_loss: 4.51928e-02
I0211 08:00:43.794045 22509476222784 run_lib.py:133] step: 328250, training_loss: 2.72226e-02
I0211 08:01:02.238144 22509476222784 run_lib.py:133] step: 328300, training_loss: 4.54032e-02
I0211 08:01:02.398655 22509476222784 run_lib.py:146] step: 328300, eval_loss: 4.58764e-02
I0211 08:01:20.990787 22509476222784 run_lib.py:133] step: 328350, training_loss: 3.81344e-02
I0211 08:01:39.486333 22509476222784 run_lib.py:133] step: 328400, training_loss: 3.85583e-02
I0211 08:01:39.713619 22509476222784 run_lib.py:146] step: 328400, eval_loss: 5.16208e-02
I0211 08:01:58.422444 22509476222784 run_lib.py:133] step: 328450, training_loss: 4.05651e-02
I0211 08:02:16.969301 22509476222784 run_lib.py:133] step: 328500, training_loss: 4.46287e-02
I0211 08:02:17.149697 22509476222784 run_lib.py:146] step: 328500, eval_loss: 3.96402e-02
I0211 08:02:35.566363 22509476222784 run_lib.py:133] step: 328550, training_loss: 3.84340e-02
I0211 08:02:54.259881 22509476222784 run_lib.py:133] step: 328600, training_loss: 4.00817e-02
I0211 08:02:54.435401 22509476222784 run_lib.py:146] step: 328600, eval_loss: 5.17214e-02
I0211 08:03:12.977750 22509476222784 run_lib.py:133] step: 328650, training_loss: 4.57329e-02
I0211 08:03:31.526611 22509476222784 run_lib.py:133] step: 328700, training_loss: 4.17750e-02
I0211 08:03:31.687298 22509476222784 run_lib.py:146] step: 328700, eval_loss: 4.27018e-02
I0211 08:03:50.190314 22509476222784 run_lib.py:133] step: 328750, training_loss: 3.65863e-02
I0211 08:04:08.857101 22509476222784 run_lib.py:133] step: 328800, training_loss: 4.90546e-02
I0211 08:04:09.020839 22509476222784 run_lib.py:146] step: 328800, eval_loss: 3.55011e-02
I0211 08:04:27.474740 22509476222784 run_lib.py:133] step: 328850, training_loss: 5.89024e-02
I0211 08:04:46.042165 22509476222784 run_lib.py:133] step: 328900, training_loss: 3.37706e-02
I0211 08:04:46.205798 22509476222784 run_lib.py:146] step: 328900, eval_loss: 3.89474e-02
I0211 08:05:04.767278 22509476222784 run_lib.py:133] step: 328950, training_loss: 4.42838e-02
I0211 08:05:23.332945 22509476222784 run_lib.py:133] step: 329000, training_loss: 3.46551e-02
I0211 08:05:23.499641 22509476222784 run_lib.py:146] step: 329000, eval_loss: 3.66684e-02
I0211 08:05:42.175216 22509476222784 run_lib.py:133] step: 329050, training_loss: 4.76350e-02
I0211 08:06:00.762208 22509476222784 run_lib.py:133] step: 329100, training_loss: 4.86682e-02
I0211 08:06:00.926657 22509476222784 run_lib.py:146] step: 329100, eval_loss: 5.87919e-02
I0211 08:06:19.436758 22509476222784 run_lib.py:133] step: 329150, training_loss: 4.35611e-02
I0211 08:06:37.960043 22509476222784 run_lib.py:133] step: 329200, training_loss: 6.12909e-02
I0211 08:06:38.124828 22509476222784 run_lib.py:146] step: 329200, eval_loss: 5.34610e-02
I0211 08:06:56.854906 22509476222784 run_lib.py:133] step: 329250, training_loss: 3.79333e-02
I0211 08:07:15.369719 22509476222784 run_lib.py:133] step: 329300, training_loss: 5.30579e-02
I0211 08:07:15.531468 22509476222784 run_lib.py:146] step: 329300, eval_loss: 3.92423e-02
I0211 08:07:34.130247 22509476222784 run_lib.py:133] step: 329350, training_loss: 4.64653e-02
I0211 08:07:52.629005 22509476222784 run_lib.py:133] step: 329400, training_loss: 3.77334e-02
I0211 08:07:52.798862 22509476222784 run_lib.py:146] step: 329400, eval_loss: 4.92630e-02
I0211 08:08:11.368899 22509476222784 run_lib.py:133] step: 329450, training_loss: 3.84832e-02
I0211 08:08:29.827807 22509476222784 run_lib.py:133] step: 329500, training_loss: 3.85681e-02
I0211 08:08:30.002637 22509476222784 run_lib.py:146] step: 329500, eval_loss: 5.65993e-02
I0211 08:08:48.525735 22509476222784 run_lib.py:133] step: 329550, training_loss: 4.51876e-02
I0211 08:09:07.246378 22509476222784 run_lib.py:133] step: 329600, training_loss: 5.64267e-02
I0211 08:09:07.414388 22509476222784 run_lib.py:146] step: 329600, eval_loss: 3.76670e-02
I0211 08:09:25.950431 22509476222784 run_lib.py:133] step: 329650, training_loss: 4.83312e-02
I0211 08:09:44.509128 22509476222784 run_lib.py:133] step: 329700, training_loss: 3.74972e-02
I0211 08:09:44.668251 22509476222784 run_lib.py:146] step: 329700, eval_loss: 4.42820e-02
I0211 08:10:03.070721 22509476222784 run_lib.py:133] step: 329750, training_loss: 4.89869e-02
I0211 08:10:21.581500 22509476222784 run_lib.py:133] step: 329800, training_loss: 5.35113e-02
I0211 08:10:21.747925 22509476222784 run_lib.py:146] step: 329800, eval_loss: 5.05803e-02
I0211 08:10:40.538527 22509476222784 run_lib.py:133] step: 329850, training_loss: 3.51906e-02
I0211 08:10:59.079807 22509476222784 run_lib.py:133] step: 329900, training_loss: 4.33254e-02
I0211 08:10:59.244899 22509476222784 run_lib.py:146] step: 329900, eval_loss: 4.48372e-02
I0211 08:11:17.724104 22509476222784 run_lib.py:133] step: 329950, training_loss: 3.49259e-02
I0211 08:11:36.367251 22509476222784 run_lib.py:133] step: 330000, training_loss: 5.94717e-02
I0211 08:11:37.093603 22509476222784 run_lib.py:146] step: 330000, eval_loss: 5.20389e-02
I0211 08:11:58.279572 22509476222784 run_lib.py:133] step: 330050, training_loss: 5.44865e-02
I0211 08:12:16.773901 22509476222784 run_lib.py:133] step: 330100, training_loss: 4.26620e-02
I0211 08:12:16.951744 22509476222784 run_lib.py:146] step: 330100, eval_loss: 3.95778e-02
I0211 08:12:35.512036 22509476222784 run_lib.py:133] step: 330150, training_loss: 3.17236e-02
I0211 08:12:53.977957 22509476222784 run_lib.py:133] step: 330200, training_loss: 3.07916e-02
I0211 08:12:54.141686 22509476222784 run_lib.py:146] step: 330200, eval_loss: 5.21849e-02
I0211 08:13:12.642319 22509476222784 run_lib.py:133] step: 330250, training_loss: 4.52288e-02
I0211 08:13:31.075055 22509476222784 run_lib.py:133] step: 330300, training_loss: 4.57404e-02
I0211 08:13:31.237811 22509476222784 run_lib.py:146] step: 330300, eval_loss: 3.70393e-02
I0211 08:13:49.885787 22509476222784 run_lib.py:133] step: 330350, training_loss: 3.85992e-02
I0211 08:14:08.402716 22509476222784 run_lib.py:133] step: 330400, training_loss: 4.92916e-02
I0211 08:14:08.575800 22509476222784 run_lib.py:146] step: 330400, eval_loss: 3.58805e-02
I0211 08:14:27.226098 22509476222784 run_lib.py:133] step: 330450, training_loss: 4.50656e-02
I0211 08:14:45.689144 22509476222784 run_lib.py:133] step: 330500, training_loss: 4.22591e-02
I0211 08:14:45.852687 22509476222784 run_lib.py:146] step: 330500, eval_loss: 3.81821e-02
I0211 08:15:04.331022 22509476222784 run_lib.py:133] step: 330550, training_loss: 4.06542e-02
I0211 08:15:22.764370 22509476222784 run_lib.py:133] step: 330600, training_loss: 3.49269e-02
I0211 08:15:22.937573 22509476222784 run_lib.py:146] step: 330600, eval_loss: 4.62310e-02
I0211 08:15:41.607351 22509476222784 run_lib.py:133] step: 330650, training_loss: 4.70707e-02
I0211 08:16:00.235922 22509476222784 run_lib.py:133] step: 330700, training_loss: 3.90854e-02
I0211 08:16:00.418737 22509476222784 run_lib.py:146] step: 330700, eval_loss: 5.22306e-02
I0211 08:16:18.907809 22509476222784 run_lib.py:133] step: 330750, training_loss: 4.31275e-02
I0211 08:16:37.352471 22509476222784 run_lib.py:133] step: 330800, training_loss: 4.05632e-02
I0211 08:16:37.514562 22509476222784 run_lib.py:146] step: 330800, eval_loss: 4.69563e-02
I0211 08:16:56.117380 22509476222784 run_lib.py:133] step: 330850, training_loss: 4.69712e-02
I0211 08:17:14.637374 22509476222784 run_lib.py:133] step: 330900, training_loss: 3.74815e-02
I0211 08:17:14.833660 22509476222784 run_lib.py:146] step: 330900, eval_loss: 3.90208e-02
I0211 08:17:33.525655 22509476222784 run_lib.py:133] step: 330950, training_loss: 5.90544e-02
I0211 08:17:52.067965 22509476222784 run_lib.py:133] step: 331000, training_loss: 3.54790e-02
I0211 08:17:52.236997 22509476222784 run_lib.py:146] step: 331000, eval_loss: 5.31043e-02
I0211 08:18:10.889633 22509476222784 run_lib.py:133] step: 331050, training_loss: 4.35090e-02
I0211 08:18:29.275905 22509476222784 run_lib.py:133] step: 331100, training_loss: 4.87044e-02
I0211 08:18:29.438755 22509476222784 run_lib.py:146] step: 331100, eval_loss: 3.60550e-02
I0211 08:18:48.063946 22509476222784 run_lib.py:133] step: 331150, training_loss: 4.65605e-02
I0211 08:19:06.576512 22509476222784 run_lib.py:133] step: 331200, training_loss: 4.79503e-02
I0211 08:19:06.740127 22509476222784 run_lib.py:146] step: 331200, eval_loss: 4.95562e-02
I0211 08:19:25.314085 22509476222784 run_lib.py:133] step: 331250, training_loss: 4.79156e-02
I0211 08:19:43.968500 22509476222784 run_lib.py:133] step: 331300, training_loss: 4.33972e-02
I0211 08:19:44.131668 22509476222784 run_lib.py:146] step: 331300, eval_loss: 4.40554e-02
I0211 08:20:02.630809 22509476222784 run_lib.py:133] step: 331350, training_loss: 3.46832e-02
I0211 08:20:21.136240 22509476222784 run_lib.py:133] step: 331400, training_loss: 4.95241e-02
I0211 08:20:21.300416 22509476222784 run_lib.py:146] step: 331400, eval_loss: 5.62718e-02
I0211 08:20:39.855744 22509476222784 run_lib.py:133] step: 331450, training_loss: 4.53378e-02
I0211 08:20:58.579378 22509476222784 run_lib.py:133] step: 331500, training_loss: 4.01025e-02
I0211 08:20:58.744906 22509476222784 run_lib.py:146] step: 331500, eval_loss: 4.47417e-02
I0211 08:21:17.239198 22509476222784 run_lib.py:133] step: 331550, training_loss: 4.00456e-02
I0211 08:21:35.748655 22509476222784 run_lib.py:133] step: 331600, training_loss: 5.04536e-02
I0211 08:21:35.913822 22509476222784 run_lib.py:146] step: 331600, eval_loss: 3.01311e-02
I0211 08:21:54.357060 22509476222784 run_lib.py:133] step: 331650, training_loss: 3.70869e-02
I0211 08:22:12.889351 22509476222784 run_lib.py:133] step: 331700, training_loss: 4.18074e-02
I0211 08:22:13.061669 22509476222784 run_lib.py:146] step: 331700, eval_loss: 4.44137e-02
I0211 08:22:31.609336 22509476222784 run_lib.py:133] step: 331750, training_loss: 3.01772e-02
I0211 08:22:50.124988 22509476222784 run_lib.py:133] step: 331800, training_loss: 3.77261e-02
I0211 08:22:50.294853 22509476222784 run_lib.py:146] step: 331800, eval_loss: 3.82448e-02
I0211 08:23:08.797409 22509476222784 run_lib.py:133] step: 331850, training_loss: 4.70339e-02
I0211 08:23:27.434406 22509476222784 run_lib.py:133] step: 331900, training_loss: 4.13699e-02
I0211 08:23:27.600928 22509476222784 run_lib.py:146] step: 331900, eval_loss: 4.75959e-02
I0211 08:23:46.114350 22509476222784 run_lib.py:133] step: 331950, training_loss: 4.92796e-02
I0211 08:24:04.715525 22509476222784 run_lib.py:133] step: 332000, training_loss: 4.89096e-02
I0211 08:24:04.885680 22509476222784 run_lib.py:146] step: 332000, eval_loss: 4.56135e-02
I0211 08:24:23.442568 22509476222784 run_lib.py:133] step: 332050, training_loss: 4.79908e-02
I0211 08:24:41.981419 22509476222784 run_lib.py:133] step: 332100, training_loss: 3.68079e-02
I0211 08:24:42.349796 22509476222784 run_lib.py:146] step: 332100, eval_loss: 3.53279e-02
I0211 08:25:01.087883 22509476222784 run_lib.py:133] step: 332150, training_loss: 4.02613e-02
I0211 08:25:19.680935 22509476222784 run_lib.py:133] step: 332200, training_loss: 4.98019e-02
I0211 08:25:19.845645 22509476222784 run_lib.py:146] step: 332200, eval_loss: 4.26237e-02
I0211 08:25:38.319114 22509476222784 run_lib.py:133] step: 332250, training_loss: 3.47711e-02
I0211 08:25:56.767391 22509476222784 run_lib.py:133] step: 332300, training_loss: 4.82232e-02
I0211 08:25:56.940873 22509476222784 run_lib.py:146] step: 332300, eval_loss: 4.32479e-02
I0211 08:26:15.618914 22509476222784 run_lib.py:133] step: 332350, training_loss: 3.44769e-02
I0211 08:26:34.187535 22509476222784 run_lib.py:133] step: 332400, training_loss: 4.60545e-02
I0211 08:26:34.354690 22509476222784 run_lib.py:146] step: 332400, eval_loss: 4.58735e-02
I0211 08:26:52.947231 22509476222784 run_lib.py:133] step: 332450, training_loss: 5.47544e-02
I0211 08:27:11.353923 22509476222784 run_lib.py:133] step: 332500, training_loss: 3.43657e-02
I0211 08:27:11.518580 22509476222784 run_lib.py:146] step: 332500, eval_loss: 4.26686e-02
I0211 08:27:30.167532 22509476222784 run_lib.py:133] step: 332550, training_loss: 4.83014e-02
I0211 08:27:48.697806 22509476222784 run_lib.py:133] step: 332600, training_loss: 4.05341e-02
I0211 08:27:48.861884 22509476222784 run_lib.py:146] step: 332600, eval_loss: 5.31950e-02
I0211 08:28:07.430139 22509476222784 run_lib.py:133] step: 332650, training_loss: 4.42597e-02
I0211 08:28:26.105591 22509476222784 run_lib.py:133] step: 332700, training_loss: 3.47190e-02
I0211 08:28:26.267665 22509476222784 run_lib.py:146] step: 332700, eval_loss: 3.83589e-02
I0211 08:28:44.768025 22509476222784 run_lib.py:133] step: 332750, training_loss: 5.54351e-02
I0211 08:29:03.478718 22509476222784 run_lib.py:133] step: 332800, training_loss: 4.39933e-02
I0211 08:29:03.658843 22509476222784 run_lib.py:146] step: 332800, eval_loss: 2.88723e-02
I0211 08:29:22.146888 22509476222784 run_lib.py:133] step: 332850, training_loss: 5.03599e-02
I0211 08:29:40.670270 22509476222784 run_lib.py:133] step: 332900, training_loss: 3.89288e-02
I0211 08:29:40.835944 22509476222784 run_lib.py:146] step: 332900, eval_loss: 4.51606e-02
I0211 08:29:59.488724 22509476222784 run_lib.py:133] step: 332950, training_loss: 4.19470e-02
I0211 08:30:18.039114 22509476222784 run_lib.py:133] step: 333000, training_loss: 5.57227e-02
I0211 08:30:18.204926 22509476222784 run_lib.py:146] step: 333000, eval_loss: 4.53412e-02
I0211 08:30:36.685150 22509476222784 run_lib.py:133] step: 333050, training_loss: 3.89716e-02
I0211 08:30:55.274006 22509476222784 run_lib.py:133] step: 333100, training_loss: 3.53146e-02
I0211 08:30:55.438493 22509476222784 run_lib.py:146] step: 333100, eval_loss: 2.89432e-02
I0211 08:31:13.981814 22509476222784 run_lib.py:133] step: 333150, training_loss: 4.39730e-02
I0211 08:31:32.530189 22509476222784 run_lib.py:133] step: 333200, training_loss: 4.90184e-02
I0211 08:31:32.693753 22509476222784 run_lib.py:146] step: 333200, eval_loss: 3.10372e-02
I0211 08:31:51.237288 22509476222784 run_lib.py:133] step: 333250, training_loss: 4.47583e-02
I0211 08:32:09.737663 22509476222784 run_lib.py:133] step: 333300, training_loss: 4.86069e-02
I0211 08:32:09.908097 22509476222784 run_lib.py:146] step: 333300, eval_loss: 4.53142e-02
I0211 08:32:28.357726 22509476222784 run_lib.py:133] step: 333350, training_loss: 4.08825e-02
I0211 08:32:46.822684 22509476222784 run_lib.py:133] step: 333400, training_loss: 4.51676e-02
I0211 08:32:46.996861 22509476222784 run_lib.py:146] step: 333400, eval_loss: 4.68246e-02
I0211 08:33:05.572820 22509476222784 run_lib.py:133] step: 333450, training_loss: 4.05949e-02
I0211 08:33:24.213384 22509476222784 run_lib.py:133] step: 333500, training_loss: 5.45025e-02
I0211 08:33:24.377696 22509476222784 run_lib.py:146] step: 333500, eval_loss: 4.44075e-02
I0211 08:33:42.849100 22509476222784 run_lib.py:133] step: 333550, training_loss: 3.94330e-02
I0211 08:34:01.349382 22509476222784 run_lib.py:133] step: 333600, training_loss: 4.27757e-02
I0211 08:34:01.510555 22509476222784 run_lib.py:146] step: 333600, eval_loss: 4.76769e-02
I0211 08:34:20.141621 22509476222784 run_lib.py:133] step: 333650, training_loss: 4.34482e-02
I0211 08:34:38.582360 22509476222784 run_lib.py:133] step: 333700, training_loss: 5.23965e-02
I0211 08:34:38.756733 22509476222784 run_lib.py:146] step: 333700, eval_loss: 3.00687e-02
I0211 08:34:57.428799 22509476222784 run_lib.py:133] step: 333750, training_loss: 4.62533e-02
I0211 08:35:15.948437 22509476222784 run_lib.py:133] step: 333800, training_loss: 3.34834e-02
I0211 08:35:16.120626 22509476222784 run_lib.py:146] step: 333800, eval_loss: 3.46543e-02
I0211 08:35:34.793804 22509476222784 run_lib.py:133] step: 333850, training_loss: 5.24474e-02
I0211 08:35:53.261220 22509476222784 run_lib.py:133] step: 333900, training_loss: 3.86048e-02
I0211 08:35:53.433656 22509476222784 run_lib.py:146] step: 333900, eval_loss: 5.70900e-02
I0211 08:36:12.057174 22509476222784 run_lib.py:133] step: 333950, training_loss: 2.79987e-02
I0211 08:36:30.516393 22509476222784 run_lib.py:133] step: 334000, training_loss: 5.47861e-02
I0211 08:36:30.680457 22509476222784 run_lib.py:146] step: 334000, eval_loss: 4.51583e-02
I0211 08:36:49.213603 22509476222784 run_lib.py:133] step: 334050, training_loss: 4.38325e-02
I0211 08:37:07.899681 22509476222784 run_lib.py:133] step: 334100, training_loss: 4.75890e-02
I0211 08:37:08.061727 22509476222784 run_lib.py:146] step: 334100, eval_loss: 5.05234e-02
I0211 08:37:26.542442 22509476222784 run_lib.py:133] step: 334150, training_loss: 4.41080e-02
I0211 08:37:45.028361 22509476222784 run_lib.py:133] step: 334200, training_loss: 3.69460e-02
I0211 08:37:45.193794 22509476222784 run_lib.py:146] step: 334200, eval_loss: 4.30567e-02
I0211 08:38:03.876024 22509476222784 run_lib.py:133] step: 334250, training_loss: 4.71452e-02
I0211 08:38:22.434144 22509476222784 run_lib.py:133] step: 334300, training_loss: 5.38711e-02
I0211 08:38:22.598823 22509476222784 run_lib.py:146] step: 334300, eval_loss: 4.66262e-02
I0211 08:38:41.297526 22509476222784 run_lib.py:133] step: 334350, training_loss: 4.50352e-02
I0211 08:38:59.777563 22509476222784 run_lib.py:133] step: 334400, training_loss: 4.88157e-02
I0211 08:38:59.943107 22509476222784 run_lib.py:146] step: 334400, eval_loss: 3.27252e-02
I0211 08:39:18.441247 22509476222784 run_lib.py:133] step: 334450, training_loss: 3.68533e-02
I0211 08:39:37.037857 22509476222784 run_lib.py:133] step: 334500, training_loss: 5.23734e-02
I0211 08:39:37.214859 22509476222784 run_lib.py:146] step: 334500, eval_loss: 4.27334e-02
I0211 08:39:55.793916 22509476222784 run_lib.py:133] step: 334550, training_loss: 3.95174e-02
I0211 08:40:14.295805 22509476222784 run_lib.py:133] step: 334600, training_loss: 3.69312e-02
I0211 08:40:14.458795 22509476222784 run_lib.py:146] step: 334600, eval_loss: 3.98024e-02
I0211 08:40:32.942153 22509476222784 run_lib.py:133] step: 334650, training_loss: 5.14924e-02
I0211 08:40:51.702097 22509476222784 run_lib.py:133] step: 334700, training_loss: 3.88688e-02
I0211 08:40:51.870875 22509476222784 run_lib.py:146] step: 334700, eval_loss: 3.76888e-02
I0211 08:41:10.348417 22509476222784 run_lib.py:133] step: 334750, training_loss: 2.47507e-02
I0211 08:41:28.840377 22509476222784 run_lib.py:133] step: 334800, training_loss: 4.53038e-02
I0211 08:41:29.012644 22509476222784 run_lib.py:146] step: 334800, eval_loss: 4.60736e-02
I0211 08:41:47.402822 22509476222784 run_lib.py:133] step: 334850, training_loss: 4.85606e-02
I0211 08:42:05.951439 22509476222784 run_lib.py:133] step: 334900, training_loss: 4.32465e-02
I0211 08:42:06.124444 22509476222784 run_lib.py:146] step: 334900, eval_loss: 5.53149e-02
I0211 08:42:24.794642 22509476222784 run_lib.py:133] step: 334950, training_loss: 5.20777e-02
I0211 08:42:43.381969 22509476222784 run_lib.py:133] step: 335000, training_loss: 4.17486e-02
I0211 08:42:43.549577 22509476222784 run_lib.py:146] step: 335000, eval_loss: 4.07901e-02
I0211 08:43:02.011174 22509476222784 run_lib.py:133] step: 335050, training_loss: 4.71031e-02
I0211 08:43:20.531227 22509476222784 run_lib.py:133] step: 335100, training_loss: 3.54407e-02
I0211 08:43:20.702884 22509476222784 run_lib.py:146] step: 335100, eval_loss: 4.76929e-02
I0211 08:43:39.403767 22509476222784 run_lib.py:133] step: 335150, training_loss: 5.79412e-02
I0211 08:43:57.784072 22509476222784 run_lib.py:133] step: 335200, training_loss: 4.84703e-02
I0211 08:43:57.947578 22509476222784 run_lib.py:146] step: 335200, eval_loss: 4.52555e-02
I0211 08:44:16.558339 22509476222784 run_lib.py:133] step: 335250, training_loss: 3.65970e-02
I0211 08:44:35.037636 22509476222784 run_lib.py:133] step: 335300, training_loss: 4.52046e-02
I0211 08:44:35.201526 22509476222784 run_lib.py:146] step: 335300, eval_loss: 3.15492e-02
I0211 08:44:53.860665 22509476222784 run_lib.py:133] step: 335350, training_loss: 4.48733e-02
I0211 08:45:12.423999 22509476222784 run_lib.py:133] step: 335400, training_loss: 4.25246e-02
I0211 08:45:12.589457 22509476222784 run_lib.py:146] step: 335400, eval_loss: 4.35044e-02
I0211 08:45:31.053696 22509476222784 run_lib.py:133] step: 335450, training_loss: 4.52430e-02
I0211 08:45:49.701401 22509476222784 run_lib.py:133] step: 335500, training_loss: 5.62181e-02
I0211 08:45:49.862643 22509476222784 run_lib.py:146] step: 335500, eval_loss: 4.43965e-02
I0211 08:46:08.400285 22509476222784 run_lib.py:133] step: 335550, training_loss: 4.38158e-02
I0211 08:46:26.998296 22509476222784 run_lib.py:133] step: 335600, training_loss: 3.83306e-02
I0211 08:46:27.163257 22509476222784 run_lib.py:146] step: 335600, eval_loss: 4.69564e-02
I0211 08:46:45.672443 22509476222784 run_lib.py:133] step: 335650, training_loss: 4.10941e-02
I0211 08:47:04.243036 22509476222784 run_lib.py:133] step: 335700, training_loss: 4.48378e-02
I0211 08:47:04.410915 22509476222784 run_lib.py:146] step: 335700, eval_loss: 4.67980e-02
I0211 08:47:23.110499 22509476222784 run_lib.py:133] step: 335750, training_loss: 5.77112e-02
I0211 08:47:41.644348 22509476222784 run_lib.py:133] step: 335800, training_loss: 5.53291e-02
I0211 08:47:41.807662 22509476222784 run_lib.py:146] step: 335800, eval_loss: 4.56743e-02
I0211 08:48:00.317587 22509476222784 run_lib.py:133] step: 335850, training_loss: 4.27359e-02
I0211 08:48:18.935410 22509476222784 run_lib.py:133] step: 335900, training_loss: 3.46215e-02
I0211 08:48:19.097609 22509476222784 run_lib.py:146] step: 335900, eval_loss: 3.96241e-02
I0211 08:48:37.493701 22509476222784 run_lib.py:133] step: 335950, training_loss: 4.36062e-02
I0211 08:48:56.045735 22509476222784 run_lib.py:133] step: 336000, training_loss: 5.26448e-02
I0211 08:48:56.386724 22509476222784 run_lib.py:146] step: 336000, eval_loss: 4.64626e-02
I0211 08:49:14.914383 22509476222784 run_lib.py:133] step: 336050, training_loss: 3.93062e-02
I0211 08:49:33.482130 22509476222784 run_lib.py:133] step: 336100, training_loss: 3.56918e-02
I0211 08:49:33.647797 22509476222784 run_lib.py:146] step: 336100, eval_loss: 4.34163e-02
I0211 08:49:52.095748 22509476222784 run_lib.py:133] step: 336150, training_loss: 4.50670e-02
I0211 08:50:10.580140 22509476222784 run_lib.py:133] step: 336200, training_loss: 3.28307e-02
I0211 08:50:10.752141 22509476222784 run_lib.py:146] step: 336200, eval_loss: 3.60046e-02
I0211 08:50:29.393849 22509476222784 run_lib.py:133] step: 336250, training_loss: 4.58235e-02
I0211 08:50:48.038924 22509476222784 run_lib.py:133] step: 336300, training_loss: 3.66851e-02
I0211 08:50:48.202507 22509476222784 run_lib.py:146] step: 336300, eval_loss: 3.26095e-02
I0211 08:51:06.673355 22509476222784 run_lib.py:133] step: 336350, training_loss: 4.57159e-02
I0211 08:51:25.170330 22509476222784 run_lib.py:133] step: 336400, training_loss: 4.30516e-02
I0211 08:51:25.332528 22509476222784 run_lib.py:146] step: 336400, eval_loss: 4.34190e-02
I0211 08:51:43.848227 22509476222784 run_lib.py:133] step: 336450, training_loss: 3.28338e-02
I0211 08:52:02.417535 22509476222784 run_lib.py:133] step: 336500, training_loss: 4.56312e-02
I0211 08:52:02.600867 22509476222784 run_lib.py:146] step: 336500, eval_loss: 5.48655e-02
I0211 08:52:21.161694 22509476222784 run_lib.py:133] step: 336550, training_loss: 4.40159e-02
I0211 08:52:39.687334 22509476222784 run_lib.py:133] step: 336600, training_loss: 5.70342e-02
I0211 08:52:39.853619 22509476222784 run_lib.py:146] step: 336600, eval_loss: 3.81579e-02
I0211 08:52:58.479324 22509476222784 run_lib.py:133] step: 336650, training_loss: 4.26006e-02
I0211 08:53:16.971382 22509476222784 run_lib.py:133] step: 336700, training_loss: 3.60733e-02
I0211 08:53:17.135675 22509476222784 run_lib.py:146] step: 336700, eval_loss: 3.67998e-02
I0211 08:53:35.790689 22509476222784 run_lib.py:133] step: 336750, training_loss: 3.51968e-02
I0211 08:53:54.358749 22509476222784 run_lib.py:133] step: 336800, training_loss: 4.24252e-02
I0211 08:53:54.523394 22509476222784 run_lib.py:146] step: 336800, eval_loss: 4.20799e-02
I0211 08:54:13.261677 22509476222784 run_lib.py:133] step: 336850, training_loss: 4.38808e-02
I0211 08:54:31.775699 22509476222784 run_lib.py:133] step: 336900, training_loss: 4.52328e-02
I0211 08:54:31.936734 22509476222784 run_lib.py:146] step: 336900, eval_loss: 3.50285e-02
I0211 08:54:50.426361 22509476222784 run_lib.py:133] step: 336950, training_loss: 3.75572e-02
I0211 08:55:09.055884 22509476222784 run_lib.py:133] step: 337000, training_loss: 4.62488e-02
I0211 08:55:09.220593 22509476222784 run_lib.py:146] step: 337000, eval_loss: 4.16221e-02
I0211 08:55:27.703569 22509476222784 run_lib.py:133] step: 337050, training_loss: 4.03531e-02
I0211 08:55:46.268636 22509476222784 run_lib.py:133] step: 337100, training_loss: 3.08449e-02
I0211 08:55:46.451445 22509476222784 run_lib.py:146] step: 337100, eval_loss: 3.34041e-02
I0211 08:56:04.870677 22509476222784 run_lib.py:133] step: 337150, training_loss: 3.67772e-02
I0211 08:56:23.353598 22509476222784 run_lib.py:133] step: 337200, training_loss: 4.24605e-02
I0211 08:56:23.523495 22509476222784 run_lib.py:146] step: 337200, eval_loss: 4.09454e-02
I0211 08:56:42.161780 22509476222784 run_lib.py:133] step: 337250, training_loss: 4.39868e-02
I0211 08:57:00.628489 22509476222784 run_lib.py:133] step: 337300, training_loss: 4.69650e-02
I0211 08:57:00.791515 22509476222784 run_lib.py:146] step: 337300, eval_loss: 4.62070e-02
I0211 08:57:19.336483 22509476222784 run_lib.py:133] step: 337350, training_loss: 5.63919e-02
I0211 08:57:37.822869 22509476222784 run_lib.py:133] step: 337400, training_loss: 4.32434e-02
I0211 08:57:37.982583 22509476222784 run_lib.py:146] step: 337400, eval_loss: 3.67405e-02
I0211 08:57:56.720148 22509476222784 run_lib.py:133] step: 337450, training_loss: 4.05067e-02
I0211 08:58:15.255377 22509476222784 run_lib.py:133] step: 337500, training_loss: 5.05271e-02
I0211 08:58:15.419778 22509476222784 run_lib.py:146] step: 337500, eval_loss: 4.51350e-02
I0211 08:58:33.965679 22509476222784 run_lib.py:133] step: 337550, training_loss: 4.02244e-02
I0211 08:58:52.447782 22509476222784 run_lib.py:133] step: 337600, training_loss: 4.96099e-02
I0211 08:58:52.627681 22509476222784 run_lib.py:146] step: 337600, eval_loss: 3.99243e-02
I0211 08:59:11.136138 22509476222784 run_lib.py:133] step: 337650, training_loss: 3.47661e-02
I0211 08:59:29.647415 22509476222784 run_lib.py:133] step: 337700, training_loss: 4.56599e-02
I0211 08:59:29.836869 22509476222784 run_lib.py:146] step: 337700, eval_loss: 5.13187e-02
I0211 08:59:48.557268 22509476222784 run_lib.py:133] step: 337750, training_loss: 4.38327e-02
I0211 09:00:07.101612 22509476222784 run_lib.py:133] step: 337800, training_loss: 3.38446e-02
I0211 09:00:07.271586 22509476222784 run_lib.py:146] step: 337800, eval_loss: 3.17300e-02
I0211 09:00:25.781924 22509476222784 run_lib.py:133] step: 337850, training_loss: 3.95161e-02
I0211 09:00:44.325952 22509476222784 run_lib.py:133] step: 337900, training_loss: 4.20554e-02
I0211 09:00:44.490444 22509476222784 run_lib.py:146] step: 337900, eval_loss: 6.48271e-02
I0211 09:01:03.272156 22509476222784 run_lib.py:133] step: 337950, training_loss: 5.45021e-02
I0211 09:01:21.775133 22509476222784 run_lib.py:133] step: 338000, training_loss: 3.95280e-02
I0211 09:01:21.940856 22509476222784 run_lib.py:146] step: 338000, eval_loss: 3.73703e-02
I0211 09:01:40.560913 22509476222784 run_lib.py:133] step: 338050, training_loss: 5.11743e-02
I0211 09:01:59.098608 22509476222784 run_lib.py:133] step: 338100, training_loss: 4.72294e-02
I0211 09:01:59.262557 22509476222784 run_lib.py:146] step: 338100, eval_loss: 3.68257e-02
I0211 09:02:17.916253 22509476222784 run_lib.py:133] step: 338150, training_loss: 3.96830e-02
I0211 09:02:36.495371 22509476222784 run_lib.py:133] step: 338200, training_loss: 4.40571e-02
I0211 09:02:36.662965 22509476222784 run_lib.py:146] step: 338200, eval_loss: 3.93820e-02
I0211 09:02:55.273400 22509476222784 run_lib.py:133] step: 338250, training_loss: 3.67713e-02
I0211 09:03:13.668838 22509476222784 run_lib.py:133] step: 338300, training_loss: 3.50209e-02
I0211 09:03:13.836559 22509476222784 run_lib.py:146] step: 338300, eval_loss: 2.95642e-02
I0211 09:03:32.307901 22509476222784 run_lib.py:133] step: 338350, training_loss: 5.14838e-02
I0211 09:03:50.996681 22509476222784 run_lib.py:133] step: 338400, training_loss: 3.53909e-02
I0211 09:03:51.162728 22509476222784 run_lib.py:146] step: 338400, eval_loss: 4.22878e-02
I0211 09:04:09.772349 22509476222784 run_lib.py:133] step: 338450, training_loss: 5.17345e-02
I0211 09:04:28.266277 22509476222784 run_lib.py:133] step: 338500, training_loss: 3.40903e-02
I0211 09:04:28.432601 22509476222784 run_lib.py:146] step: 338500, eval_loss: 4.94078e-02
I0211 09:04:47.017585 22509476222784 run_lib.py:133] step: 338550, training_loss: 4.42583e-02
I0211 09:05:05.581686 22509476222784 run_lib.py:133] step: 338600, training_loss: 4.33851e-02
I0211 09:05:05.745661 22509476222784 run_lib.py:146] step: 338600, eval_loss: 3.67011e-02
I0211 09:05:24.214802 22509476222784 run_lib.py:133] step: 338650, training_loss: 3.77664e-02
I0211 09:05:42.752290 22509476222784 run_lib.py:133] step: 338700, training_loss: 4.69492e-02
I0211 09:05:42.916163 22509476222784 run_lib.py:146] step: 338700, eval_loss: 3.96342e-02
I0211 09:06:01.445138 22509476222784 run_lib.py:133] step: 338750, training_loss: 4.36565e-02
I0211 09:06:20.126000 22509476222784 run_lib.py:133] step: 338800, training_loss: 3.06757e-02
I0211 09:06:20.281976 22509476222784 run_lib.py:146] step: 338800, eval_loss: 4.05749e-02
I0211 09:06:38.792642 22509476222784 run_lib.py:133] step: 338850, training_loss: 5.03227e-02
I0211 09:06:57.319683 22509476222784 run_lib.py:133] step: 338900, training_loss: 3.28421e-02
I0211 09:06:57.483586 22509476222784 run_lib.py:146] step: 338900, eval_loss: 4.87720e-02
I0211 09:07:15.964155 22509476222784 run_lib.py:133] step: 338950, training_loss: 3.29155e-02
I0211 09:07:34.647863 22509476222784 run_lib.py:133] step: 339000, training_loss: 4.03622e-02
I0211 09:07:34.829885 22509476222784 run_lib.py:146] step: 339000, eval_loss: 3.96316e-02
I0211 09:07:53.341748 22509476222784 run_lib.py:133] step: 339050, training_loss: 4.48253e-02
I0211 09:08:11.965462 22509476222784 run_lib.py:133] step: 339100, training_loss: 4.19028e-02
I0211 09:08:12.129891 22509476222784 run_lib.py:146] step: 339100, eval_loss: 4.44943e-02
I0211 09:08:30.615930 22509476222784 run_lib.py:133] step: 339150, training_loss: 5.35551e-02
I0211 09:08:49.095756 22509476222784 run_lib.py:133] step: 339200, training_loss: 4.71548e-02
I0211 09:08:49.275784 22509476222784 run_lib.py:146] step: 339200, eval_loss: 5.37525e-02
I0211 09:09:07.906231 22509476222784 run_lib.py:133] step: 339250, training_loss: 4.98223e-02
I0211 09:09:26.494281 22509476222784 run_lib.py:133] step: 339300, training_loss: 3.73127e-02
I0211 09:09:26.657120 22509476222784 run_lib.py:146] step: 339300, eval_loss: 4.70363e-02
I0211 09:09:45.119036 22509476222784 run_lib.py:133] step: 339350, training_loss: 4.50509e-02
I0211 09:10:03.588529 22509476222784 run_lib.py:133] step: 339400, training_loss: 4.12153e-02
I0211 09:10:03.780508 22509476222784 run_lib.py:146] step: 339400, eval_loss: 4.85159e-02
I0211 09:10:22.423377 22509476222784 run_lib.py:133] step: 339450, training_loss: 4.25003e-02
I0211 09:10:40.940677 22509476222784 run_lib.py:133] step: 339500, training_loss: 4.02652e-02
I0211 09:10:41.171644 22509476222784 run_lib.py:146] step: 339500, eval_loss: 5.42157e-02
I0211 09:10:59.853957 22509476222784 run_lib.py:133] step: 339550, training_loss: 4.93157e-02
I0211 09:11:18.377517 22509476222784 run_lib.py:133] step: 339600, training_loss: 4.45321e-02
I0211 09:11:18.542598 22509476222784 run_lib.py:146] step: 339600, eval_loss: 4.23810e-02
I0211 09:11:37.243670 22509476222784 run_lib.py:133] step: 339650, training_loss: 4.39229e-02
I0211 09:11:55.708113 22509476222784 run_lib.py:133] step: 339700, training_loss: 3.54901e-02
I0211 09:11:55.869610 22509476222784 run_lib.py:146] step: 339700, eval_loss: 3.93106e-02
I0211 09:12:14.255864 22509476222784 run_lib.py:133] step: 339750, training_loss: 5.27844e-02
I0211 09:12:32.810180 22509476222784 run_lib.py:133] step: 339800, training_loss: 4.43242e-02
I0211 09:12:32.971815 22509476222784 run_lib.py:146] step: 339800, eval_loss: 3.89427e-02
I0211 09:12:51.438429 22509476222784 run_lib.py:133] step: 339850, training_loss: 5.28387e-02
I0211 09:13:10.099404 22509476222784 run_lib.py:133] step: 339900, training_loss: 4.44341e-02
I0211 09:13:10.291558 22509476222784 run_lib.py:146] step: 339900, eval_loss: 5.30357e-02
I0211 09:13:28.803571 22509476222784 run_lib.py:133] step: 339950, training_loss: 4.23555e-02
I0211 09:13:47.255066 22509476222784 run_lib.py:133] step: 340000, training_loss: 4.99171e-02
I0211 09:13:48.544670 22509476222784 run_lib.py:146] step: 340000, eval_loss: 4.18433e-02
I0211 09:14:09.743510 22509476222784 run_lib.py:133] step: 340050, training_loss: 3.79519e-02
I0211 09:14:28.428667 22509476222784 run_lib.py:133] step: 340100, training_loss: 5.17806e-02
I0211 09:14:28.591748 22509476222784 run_lib.py:146] step: 340100, eval_loss: 3.55932e-02
I0211 09:14:47.010525 22509476222784 run_lib.py:133] step: 340150, training_loss: 4.38043e-02
I0211 09:15:05.658693 22509476222784 run_lib.py:133] step: 340200, training_loss: 4.61716e-02
I0211 09:15:05.829825 22509476222784 run_lib.py:146] step: 340200, eval_loss: 3.99131e-02
I0211 09:15:24.274071 22509476222784 run_lib.py:133] step: 340250, training_loss: 4.67573e-02
I0211 09:15:42.669191 22509476222784 run_lib.py:133] step: 340300, training_loss: 4.50868e-02
I0211 09:15:42.828707 22509476222784 run_lib.py:146] step: 340300, eval_loss: 3.94245e-02
I0211 09:16:01.487595 22509476222784 run_lib.py:133] step: 340350, training_loss: 3.81102e-02
I0211 09:16:20.056139 22509476222784 run_lib.py:133] step: 340400, training_loss: 4.74689e-02
I0211 09:16:20.367717 22509476222784 run_lib.py:146] step: 340400, eval_loss: 3.34718e-02
I0211 09:16:39.005280 22509476222784 run_lib.py:133] step: 340450, training_loss: 4.14925e-02
I0211 09:16:57.533145 22509476222784 run_lib.py:133] step: 340500, training_loss: 3.44185e-02
I0211 09:16:57.701823 22509476222784 run_lib.py:146] step: 340500, eval_loss: 4.24944e-02
I0211 09:17:16.186807 22509476222784 run_lib.py:133] step: 340550, training_loss: 3.15994e-02
I0211 09:17:34.964202 22509476222784 run_lib.py:133] step: 340600, training_loss: 5.24242e-02
I0211 09:17:35.126865 22509476222784 run_lib.py:146] step: 340600, eval_loss: 3.86016e-02
I0211 09:17:53.631010 22509476222784 run_lib.py:133] step: 340650, training_loss: 3.29261e-02
I0211 09:18:12.129909 22509476222784 run_lib.py:133] step: 340700, training_loss: 3.92362e-02
I0211 09:18:12.301605 22509476222784 run_lib.py:146] step: 340700, eval_loss: 4.80690e-02
I0211 09:18:30.791076 22509476222784 run_lib.py:133] step: 340750, training_loss: 4.08400e-02
I0211 09:18:49.388606 22509476222784 run_lib.py:133] step: 340800, training_loss: 4.39877e-02
I0211 09:18:49.547573 22509476222784 run_lib.py:146] step: 340800, eval_loss: 4.69822e-02
I0211 09:19:08.026202 22509476222784 run_lib.py:133] step: 340850, training_loss: 3.68197e-02
I0211 09:19:26.607235 22509476222784 run_lib.py:133] step: 340900, training_loss: 4.55993e-02
I0211 09:19:26.784649 22509476222784 run_lib.py:146] step: 340900, eval_loss: 3.51824e-02
I0211 09:19:45.250306 22509476222784 run_lib.py:133] step: 340950, training_loss: 4.80418e-02
I0211 09:20:03.815244 22509476222784 run_lib.py:133] step: 341000, training_loss: 2.75250e-02
I0211 09:20:04.070867 22509476222784 run_lib.py:146] step: 341000, eval_loss: 5.11709e-02
I0211 09:20:22.787464 22509476222784 run_lib.py:133] step: 341050, training_loss: 4.89238e-02
I0211 09:20:41.355262 22509476222784 run_lib.py:133] step: 341100, training_loss: 5.15517e-02
I0211 09:20:41.519621 22509476222784 run_lib.py:146] step: 341100, eval_loss: 4.57251e-02
I0211 09:21:00.011275 22509476222784 run_lib.py:133] step: 341150, training_loss: 4.56564e-02
I0211 09:21:18.621849 22509476222784 run_lib.py:133] step: 341200, training_loss: 3.57431e-02
I0211 09:21:18.815866 22509476222784 run_lib.py:146] step: 341200, eval_loss: 3.56777e-02
I0211 09:21:37.527080 22509476222784 run_lib.py:133] step: 341250, training_loss: 3.75166e-02
I0211 09:21:56.029947 22509476222784 run_lib.py:133] step: 341300, training_loss: 4.14975e-02
I0211 09:21:56.194488 22509476222784 run_lib.py:146] step: 341300, eval_loss: 3.79863e-02
I0211 09:22:14.711179 22509476222784 run_lib.py:133] step: 341350, training_loss: 5.31167e-02
I0211 09:22:33.226349 22509476222784 run_lib.py:133] step: 341400, training_loss: 3.46660e-02
I0211 09:22:33.393844 22509476222784 run_lib.py:146] step: 341400, eval_loss: 4.20538e-02
I0211 09:22:51.949623 22509476222784 run_lib.py:133] step: 341450, training_loss: 5.32158e-02
I0211 09:23:10.448996 22509476222784 run_lib.py:133] step: 341500, training_loss: 4.27966e-02
I0211 09:23:10.612621 22509476222784 run_lib.py:146] step: 341500, eval_loss: 4.21314e-02
I0211 09:23:29.067653 22509476222784 run_lib.py:133] step: 341550, training_loss: 3.43838e-02
I0211 09:23:47.754549 22509476222784 run_lib.py:133] step: 341600, training_loss: 3.13923e-02
I0211 09:23:47.919864 22509476222784 run_lib.py:146] step: 341600, eval_loss: 4.44339e-02
I0211 09:24:06.442804 22509476222784 run_lib.py:133] step: 341650, training_loss: 3.93350e-02
I0211 09:24:25.049095 22509476222784 run_lib.py:133] step: 341700, training_loss: 5.32395e-02
I0211 09:24:25.250598 22509476222784 run_lib.py:146] step: 341700, eval_loss: 4.14479e-02
I0211 09:24:43.806364 22509476222784 run_lib.py:133] step: 341750, training_loss: 4.83108e-02
I0211 09:25:02.305512 22509476222784 run_lib.py:133] step: 341800, training_loss: 3.92346e-02
I0211 09:25:02.469921 22509476222784 run_lib.py:146] step: 341800, eval_loss: 5.44601e-02
I0211 09:25:21.160593 22509476222784 run_lib.py:133] step: 341850, training_loss: 4.28425e-02
I0211 09:25:39.672024 22509476222784 run_lib.py:133] step: 341900, training_loss: 4.24959e-02
I0211 09:25:39.838899 22509476222784 run_lib.py:146] step: 341900, eval_loss: 5.89666e-02
I0211 09:25:58.337687 22509476222784 run_lib.py:133] step: 341950, training_loss: 3.64153e-02
I0211 09:26:16.994368 22509476222784 run_lib.py:133] step: 342000, training_loss: 4.38676e-02
I0211 09:26:17.195566 22509476222784 run_lib.py:146] step: 342000, eval_loss: 4.46722e-02
I0211 09:26:35.744123 22509476222784 run_lib.py:133] step: 342050, training_loss: 3.63714e-02
I0211 09:26:54.186696 22509476222784 run_lib.py:133] step: 342100, training_loss: 4.25804e-02
I0211 09:26:54.351527 22509476222784 run_lib.py:146] step: 342100, eval_loss: 3.36727e-02
I0211 09:27:12.996466 22509476222784 run_lib.py:133] step: 342150, training_loss: 3.84116e-02
I0211 09:27:31.451449 22509476222784 run_lib.py:133] step: 342200, training_loss: 4.60547e-02
I0211 09:27:31.608427 22509476222784 run_lib.py:146] step: 342200, eval_loss: 4.17731e-02
I0211 09:27:50.064597 22509476222784 run_lib.py:133] step: 342250, training_loss: 5.20153e-02
I0211 09:28:08.535028 22509476222784 run_lib.py:133] step: 342300, training_loss: 5.66385e-02
I0211 09:28:08.709941 22509476222784 run_lib.py:146] step: 342300, eval_loss: 4.40647e-02
I0211 09:28:27.469251 22509476222784 run_lib.py:133] step: 342350, training_loss: 4.78899e-02
I0211 09:28:46.084655 22509476222784 run_lib.py:133] step: 342400, training_loss: 4.61432e-02
I0211 09:28:46.250730 22509476222784 run_lib.py:146] step: 342400, eval_loss: 4.66732e-02
I0211 09:29:04.655263 22509476222784 run_lib.py:133] step: 342450, training_loss: 4.62659e-02
I0211 09:29:23.052597 22509476222784 run_lib.py:133] step: 342500, training_loss: 4.23489e-02
I0211 09:29:23.224587 22509476222784 run_lib.py:146] step: 342500, eval_loss: 4.79784e-02
I0211 09:29:41.861346 22509476222784 run_lib.py:133] step: 342550, training_loss: 5.36424e-02
I0211 09:30:00.375939 22509476222784 run_lib.py:133] step: 342600, training_loss: 2.71212e-02
I0211 09:30:00.557893 22509476222784 run_lib.py:146] step: 342600, eval_loss: 4.01492e-02
I0211 09:30:19.284667 22509476222784 run_lib.py:133] step: 342650, training_loss: 4.43339e-02
I0211 09:30:37.737384 22509476222784 run_lib.py:133] step: 342700, training_loss: 5.66610e-02
I0211 09:30:37.898760 22509476222784 run_lib.py:146] step: 342700, eval_loss: 4.61441e-02
I0211 09:30:56.505450 22509476222784 run_lib.py:133] step: 342750, training_loss: 3.91188e-02
I0211 09:31:14.894706 22509476222784 run_lib.py:133] step: 342800, training_loss: 5.52541e-02
I0211 09:31:15.064610 22509476222784 run_lib.py:146] step: 342800, eval_loss: 4.87918e-02
I0211 09:31:33.756081 22509476222784 run_lib.py:133] step: 342850, training_loss: 4.08572e-02
I0211 09:31:52.305984 22509476222784 run_lib.py:133] step: 342900, training_loss: 3.00402e-02
I0211 09:31:52.479843 22509476222784 run_lib.py:146] step: 342900, eval_loss: 3.96937e-02
I0211 09:32:11.022975 22509476222784 run_lib.py:133] step: 342950, training_loss: 4.81680e-02
I0211 09:32:29.700944 22509476222784 run_lib.py:133] step: 343000, training_loss: 4.30814e-02
I0211 09:32:29.865717 22509476222784 run_lib.py:146] step: 343000, eval_loss: 5.02246e-02
I0211 09:32:48.352710 22509476222784 run_lib.py:133] step: 343050, training_loss: 5.11675e-02
I0211 09:33:06.879968 22509476222784 run_lib.py:133] step: 343100, training_loss: 3.35112e-02
I0211 09:33:07.048925 22509476222784 run_lib.py:146] step: 343100, eval_loss: 2.71800e-02
I0211 09:33:25.765028 22509476222784 run_lib.py:133] step: 343150, training_loss: 5.16630e-02
I0211 09:33:44.320516 22509476222784 run_lib.py:133] step: 343200, training_loss: 5.10500e-02
I0211 09:33:44.482529 22509476222784 run_lib.py:146] step: 343200, eval_loss: 3.65820e-02
I0211 09:34:03.143678 22509476222784 run_lib.py:133] step: 343250, training_loss: 5.50518e-02
I0211 09:34:21.732887 22509476222784 run_lib.py:133] step: 343300, training_loss: 5.26422e-02
I0211 09:34:21.918522 22509476222784 run_lib.py:146] step: 343300, eval_loss: 4.69374e-02
I0211 09:34:40.530138 22509476222784 run_lib.py:133] step: 343350, training_loss: 3.56896e-02
I0211 09:34:59.225735 22509476222784 run_lib.py:133] step: 343400, training_loss: 3.73847e-02
I0211 09:34:59.393818 22509476222784 run_lib.py:146] step: 343400, eval_loss: 3.68828e-02
I0211 09:35:17.825362 22509476222784 run_lib.py:133] step: 343450, training_loss: 3.83602e-02
I0211 09:35:36.306915 22509476222784 run_lib.py:133] step: 343500, training_loss: 4.84490e-02
I0211 09:35:36.475798 22509476222784 run_lib.py:146] step: 343500, eval_loss: 4.58781e-02
I0211 09:35:54.961348 22509476222784 run_lib.py:133] step: 343550, training_loss: 4.06448e-02
I0211 09:36:13.624384 22509476222784 run_lib.py:133] step: 343600, training_loss: 3.98145e-02
I0211 09:36:13.833562 22509476222784 run_lib.py:146] step: 343600, eval_loss: 4.15483e-02
I0211 09:36:32.373866 22509476222784 run_lib.py:133] step: 343650, training_loss: 4.77478e-02
I0211 09:36:50.895077 22509476222784 run_lib.py:133] step: 343700, training_loss: 3.19388e-02
I0211 09:36:51.058665 22509476222784 run_lib.py:146] step: 343700, eval_loss: 4.45375e-02
I0211 09:37:09.538803 22509476222784 run_lib.py:133] step: 343750, training_loss: 5.29307e-02
I0211 09:37:28.029027 22509476222784 run_lib.py:133] step: 343800, training_loss: 3.49028e-02
I0211 09:37:28.193706 22509476222784 run_lib.py:146] step: 343800, eval_loss: 4.20175e-02
I0211 09:37:46.883757 22509476222784 run_lib.py:133] step: 343850, training_loss: 3.92636e-02
I0211 09:38:05.562946 22509476222784 run_lib.py:133] step: 343900, training_loss: 4.58465e-02
I0211 09:38:05.728885 22509476222784 run_lib.py:146] step: 343900, eval_loss: 3.31278e-02
I0211 09:38:24.233326 22509476222784 run_lib.py:133] step: 343950, training_loss: 4.23746e-02
I0211 09:38:42.709346 22509476222784 run_lib.py:133] step: 344000, training_loss: 4.48008e-02
I0211 09:38:42.872794 22509476222784 run_lib.py:146] step: 344000, eval_loss: 4.57545e-02
I0211 09:39:01.536695 22509476222784 run_lib.py:133] step: 344050, training_loss: 3.01948e-02
I0211 09:39:20.004700 22509476222784 run_lib.py:133] step: 344100, training_loss: 5.03116e-02
I0211 09:39:20.165924 22509476222784 run_lib.py:146] step: 344100, eval_loss: 4.08302e-02
I0211 09:39:38.883111 22509476222784 run_lib.py:133] step: 344150, training_loss: 5.19355e-02
I0211 09:39:57.410644 22509476222784 run_lib.py:133] step: 344200, training_loss: 4.92583e-02
I0211 09:39:57.574786 22509476222784 run_lib.py:146] step: 344200, eval_loss: 4.40220e-02
I0211 09:40:16.278067 22509476222784 run_lib.py:133] step: 344250, training_loss: 4.49355e-02
I0211 09:40:34.821398 22509476222784 run_lib.py:133] step: 344300, training_loss: 4.04401e-02
I0211 09:40:34.995894 22509476222784 run_lib.py:146] step: 344300, eval_loss: 4.21900e-02
I0211 09:40:53.402372 22509476222784 run_lib.py:133] step: 344350, training_loss: 4.37556e-02
I0211 09:41:12.076598 22509476222784 run_lib.py:133] step: 344400, training_loss: 4.16767e-02
I0211 09:41:12.271613 22509476222784 run_lib.py:146] step: 344400, eval_loss: 2.62756e-02
I0211 09:41:30.842690 22509476222784 run_lib.py:133] step: 344450, training_loss: 5.57679e-02
I0211 09:41:49.569923 22509476222784 run_lib.py:133] step: 344500, training_loss: 4.79558e-02
I0211 09:41:49.732786 22509476222784 run_lib.py:146] step: 344500, eval_loss: 5.42700e-02
I0211 09:42:08.238623 22509476222784 run_lib.py:133] step: 344550, training_loss: 4.46814e-02
I0211 09:42:26.760189 22509476222784 run_lib.py:133] step: 344600, training_loss: 5.35145e-02
I0211 09:42:26.918594 22509476222784 run_lib.py:146] step: 344600, eval_loss: 4.06095e-02
I0211 09:42:45.563144 22509476222784 run_lib.py:133] step: 344650, training_loss: 3.69024e-02
I0211 09:43:04.104538 22509476222784 run_lib.py:133] step: 344700, training_loss: 4.73087e-02
I0211 09:43:04.276353 22509476222784 run_lib.py:146] step: 344700, eval_loss: 4.35784e-02
I0211 09:43:22.763706 22509476222784 run_lib.py:133] step: 344750, training_loss: 2.93072e-02
I0211 09:43:41.481941 22509476222784 run_lib.py:133] step: 344800, training_loss: 3.70486e-02
I0211 09:43:41.663884 22509476222784 run_lib.py:146] step: 344800, eval_loss: 4.02307e-02
I0211 09:44:00.156501 22509476222784 run_lib.py:133] step: 344850, training_loss: 3.98153e-02
I0211 09:44:18.674359 22509476222784 run_lib.py:133] step: 344900, training_loss: 5.41578e-02
I0211 09:44:18.982356 22509476222784 run_lib.py:146] step: 344900, eval_loss: 4.37289e-02
I0211 09:44:37.496424 22509476222784 run_lib.py:133] step: 344950, training_loss: 3.68922e-02
I0211 09:44:56.083332 22509476222784 run_lib.py:133] step: 345000, training_loss: 3.80428e-02
I0211 09:44:56.246815 22509476222784 run_lib.py:146] step: 345000, eval_loss: 4.28733e-02
I0211 09:45:14.746455 22509476222784 run_lib.py:133] step: 345050, training_loss: 4.15523e-02
I0211 09:45:33.232609 22509476222784 run_lib.py:133] step: 345100, training_loss: 3.93936e-02
I0211 09:45:33.394620 22509476222784 run_lib.py:146] step: 345100, eval_loss: 3.78614e-02
I0211 09:45:51.991759 22509476222784 run_lib.py:133] step: 345150, training_loss: 3.80848e-02
I0211 09:46:10.468523 22509476222784 run_lib.py:133] step: 345200, training_loss: 3.70474e-02
I0211 09:46:10.640276 22509476222784 run_lib.py:146] step: 345200, eval_loss: 5.03900e-02
I0211 09:46:29.119951 22509476222784 run_lib.py:133] step: 345250, training_loss: 3.82625e-02
I0211 09:46:47.715053 22509476222784 run_lib.py:133] step: 345300, training_loss: 4.22669e-02
I0211 09:46:47.879848 22509476222784 run_lib.py:146] step: 345300, eval_loss: 5.06136e-02
I0211 09:47:06.510758 22509476222784 run_lib.py:133] step: 345350, training_loss: 3.95052e-02
I0211 09:47:25.020211 22509476222784 run_lib.py:133] step: 345400, training_loss: 4.37024e-02
I0211 09:47:25.189634 22509476222784 run_lib.py:146] step: 345400, eval_loss: 5.24966e-02
I0211 09:47:43.680726 22509476222784 run_lib.py:133] step: 345450, training_loss: 3.69972e-02
I0211 09:48:02.268316 22509476222784 run_lib.py:133] step: 345500, training_loss: 4.90666e-02
I0211 09:48:02.432061 22509476222784 run_lib.py:146] step: 345500, eval_loss: 3.24633e-02
I0211 09:48:21.153692 22509476222784 run_lib.py:133] step: 345550, training_loss: 4.49757e-02
I0211 09:48:39.659587 22509476222784 run_lib.py:133] step: 345600, training_loss: 4.73314e-02
I0211 09:48:39.841654 22509476222784 run_lib.py:146] step: 345600, eval_loss: 3.49742e-02
I0211 09:48:58.520214 22509476222784 run_lib.py:133] step: 345650, training_loss: 5.18047e-02
I0211 09:49:17.051209 22509476222784 run_lib.py:133] step: 345700, training_loss: 4.14085e-02
I0211 09:49:17.230731 22509476222784 run_lib.py:146] step: 345700, eval_loss: 4.56935e-02
I0211 09:49:35.887238 22509476222784 run_lib.py:133] step: 345750, training_loss: 3.69196e-02
I0211 09:49:54.415283 22509476222784 run_lib.py:133] step: 345800, training_loss: 3.97454e-02
I0211 09:49:54.589623 22509476222784 run_lib.py:146] step: 345800, eval_loss: 2.81106e-02
I0211 09:50:13.108070 22509476222784 run_lib.py:133] step: 345850, training_loss: 3.53149e-02
I0211 09:50:31.869296 22509476222784 run_lib.py:133] step: 345900, training_loss: 3.84299e-02
I0211 09:50:32.054914 22509476222784 run_lib.py:146] step: 345900, eval_loss: 3.52472e-02
I0211 09:50:50.609879 22509476222784 run_lib.py:133] step: 345950, training_loss: 4.73250e-02
I0211 09:51:09.239911 22509476222784 run_lib.py:133] step: 346000, training_loss: 5.00850e-02
I0211 09:51:09.403685 22509476222784 run_lib.py:146] step: 346000, eval_loss: 3.98244e-02
I0211 09:51:27.932388 22509476222784 run_lib.py:133] step: 346050, training_loss: 4.95444e-02
I0211 09:51:46.498912 22509476222784 run_lib.py:133] step: 346100, training_loss: 4.45091e-02
I0211 09:51:46.673869 22509476222784 run_lib.py:146] step: 346100, eval_loss: 5.04192e-02
I0211 09:52:05.214613 22509476222784 run_lib.py:133] step: 346150, training_loss: 3.80727e-02
I0211 09:52:23.964603 22509476222784 run_lib.py:133] step: 346200, training_loss: 3.97933e-02
I0211 09:52:24.151886 22509476222784 run_lib.py:146] step: 346200, eval_loss: 4.20168e-02
I0211 09:52:42.643045 22509476222784 run_lib.py:133] step: 346250, training_loss: 4.57834e-02
I0211 09:53:01.061660 22509476222784 run_lib.py:133] step: 346300, training_loss: 3.65265e-02
I0211 09:53:01.243578 22509476222784 run_lib.py:146] step: 346300, eval_loss: 4.30309e-02
I0211 09:53:19.847792 22509476222784 run_lib.py:133] step: 346350, training_loss: 3.27699e-02
I0211 09:53:38.434157 22509476222784 run_lib.py:133] step: 346400, training_loss: 4.35336e-02
I0211 09:53:38.597856 22509476222784 run_lib.py:146] step: 346400, eval_loss: 4.27012e-02
I0211 09:53:57.266918 22509476222784 run_lib.py:133] step: 346450, training_loss: 4.87602e-02
I0211 09:54:15.792935 22509476222784 run_lib.py:133] step: 346500, training_loss: 5.93845e-02
I0211 09:54:15.956184 22509476222784 run_lib.py:146] step: 346500, eval_loss: 3.38910e-02
I0211 09:54:34.436484 22509476222784 run_lib.py:133] step: 346550, training_loss: 4.34003e-02
I0211 09:54:52.902067 22509476222784 run_lib.py:133] step: 346600, training_loss: 4.72648e-02
I0211 09:54:53.076593 22509476222784 run_lib.py:146] step: 346600, eval_loss: 4.54540e-02
I0211 09:55:11.817429 22509476222784 run_lib.py:133] step: 346650, training_loss: 4.62351e-02
I0211 09:55:30.427211 22509476222784 run_lib.py:133] step: 346700, training_loss: 4.52695e-02
I0211 09:55:30.593670 22509476222784 run_lib.py:146] step: 346700, eval_loss: 3.49682e-02
I0211 09:55:49.038050 22509476222784 run_lib.py:133] step: 346750, training_loss: 4.61708e-02
I0211 09:56:07.493184 22509476222784 run_lib.py:133] step: 346800, training_loss: 3.49209e-02
I0211 09:56:07.655749 22509476222784 run_lib.py:146] step: 346800, eval_loss: 4.26921e-02
I0211 09:56:26.287624 22509476222784 run_lib.py:133] step: 346850, training_loss: 4.76252e-02
I0211 09:56:44.717442 22509476222784 run_lib.py:133] step: 346900, training_loss: 3.85854e-02
I0211 09:56:44.879855 22509476222784 run_lib.py:146] step: 346900, eval_loss: 5.77667e-02
I0211 09:57:03.593978 22509476222784 run_lib.py:133] step: 346950, training_loss: 3.24166e-02
I0211 09:57:22.089518 22509476222784 run_lib.py:133] step: 347000, training_loss: 3.75451e-02
I0211 09:57:22.251684 22509476222784 run_lib.py:146] step: 347000, eval_loss: 3.84616e-02
I0211 09:57:40.876767 22509476222784 run_lib.py:133] step: 347050, training_loss: 4.11987e-02
I0211 09:57:59.376948 22509476222784 run_lib.py:133] step: 347100, training_loss: 4.93836e-02
I0211 09:57:59.543840 22509476222784 run_lib.py:146] step: 347100, eval_loss: 4.64911e-02
I0211 09:58:18.193927 22509476222784 run_lib.py:133] step: 347150, training_loss: 4.38439e-02
I0211 09:58:36.730869 22509476222784 run_lib.py:133] step: 347200, training_loss: 4.20868e-02
I0211 09:58:36.904873 22509476222784 run_lib.py:146] step: 347200, eval_loss: 5.17768e-02
I0211 09:58:55.437790 22509476222784 run_lib.py:133] step: 347250, training_loss: 3.86768e-02
I0211 09:59:14.072958 22509476222784 run_lib.py:133] step: 347300, training_loss: 3.62469e-02
I0211 09:59:14.241438 22509476222784 run_lib.py:146] step: 347300, eval_loss: 4.63786e-02
I0211 09:59:32.713600 22509476222784 run_lib.py:133] step: 347350, training_loss: 4.20455e-02
I0211 09:59:51.248103 22509476222784 run_lib.py:133] step: 347400, training_loss: 3.39086e-02
I0211 09:59:51.405269 22509476222784 run_lib.py:146] step: 347400, eval_loss: 4.32182e-02
I0211 10:00:10.111295 22509476222784 run_lib.py:133] step: 347450, training_loss: 3.78277e-02
I0211 10:00:28.811083 22509476222784 run_lib.py:133] step: 347500, training_loss: 4.73559e-02
I0211 10:00:28.980774 22509476222784 run_lib.py:146] step: 347500, eval_loss: 3.72870e-02
I0211 10:00:47.498844 22509476222784 run_lib.py:133] step: 347550, training_loss: 3.48203e-02
I0211 10:01:05.968183 22509476222784 run_lib.py:133] step: 347600, training_loss: 4.12993e-02
I0211 10:01:06.141806 22509476222784 run_lib.py:146] step: 347600, eval_loss: 3.85281e-02
I0211 10:01:24.640531 22509476222784 run_lib.py:133] step: 347650, training_loss: 4.56250e-02
I0211 10:01:43.257601 22509476222784 run_lib.py:133] step: 347700, training_loss: 4.23132e-02
I0211 10:01:43.430631 22509476222784 run_lib.py:146] step: 347700, eval_loss: 3.48914e-02
I0211 10:02:01.953110 22509476222784 run_lib.py:133] step: 347750, training_loss: 4.56928e-02
I0211 10:02:20.497691 22509476222784 run_lib.py:133] step: 347800, training_loss: 6.00671e-02
I0211 10:02:20.661396 22509476222784 run_lib.py:146] step: 347800, eval_loss: 4.01293e-02
I0211 10:02:39.225923 22509476222784 run_lib.py:133] step: 347850, training_loss: 4.57643e-02
I0211 10:02:57.982000 22509476222784 run_lib.py:133] step: 347900, training_loss: 5.84291e-02
I0211 10:02:58.141057 22509476222784 run_lib.py:146] step: 347900, eval_loss: 5.77439e-02
I0211 10:03:16.677332 22509476222784 run_lib.py:133] step: 347950, training_loss: 4.57267e-02
I0211 10:03:35.293450 22509476222784 run_lib.py:133] step: 348000, training_loss: 3.92373e-02
I0211 10:03:35.496966 22509476222784 run_lib.py:146] step: 348000, eval_loss: 3.89557e-02
I0211 10:03:54.097336 22509476222784 run_lib.py:133] step: 348050, training_loss: 3.96061e-02
I0211 10:04:12.615090 22509476222784 run_lib.py:133] step: 348100, training_loss: 4.22151e-02
I0211 10:04:12.786864 22509476222784 run_lib.py:146] step: 348100, eval_loss: 3.42903e-02
I0211 10:04:31.505551 22509476222784 run_lib.py:133] step: 348150, training_loss: 4.95787e-02
I0211 10:04:50.126937 22509476222784 run_lib.py:133] step: 348200, training_loss: 3.68640e-02
I0211 10:04:50.291837 22509476222784 run_lib.py:146] step: 348200, eval_loss: 3.15030e-02
I0211 10:05:08.832754 22509476222784 run_lib.py:133] step: 348250, training_loss: 4.97629e-02
I0211 10:05:27.426830 22509476222784 run_lib.py:133] step: 348300, training_loss: 3.75131e-02
I0211 10:05:27.594857 22509476222784 run_lib.py:146] step: 348300, eval_loss: 4.00748e-02
I0211 10:05:46.370695 22509476222784 run_lib.py:133] step: 348350, training_loss: 3.81411e-02
I0211 10:06:04.959858 22509476222784 run_lib.py:133] step: 348400, training_loss: 3.35391e-02
I0211 10:06:05.122694 22509476222784 run_lib.py:146] step: 348400, eval_loss: 4.36904e-02
I0211 10:06:23.817080 22509476222784 run_lib.py:133] step: 348450, training_loss: 3.45196e-02
I0211 10:06:42.343271 22509476222784 run_lib.py:133] step: 348500, training_loss: 3.20961e-02
I0211 10:06:42.519613 22509476222784 run_lib.py:146] step: 348500, eval_loss: 4.82335e-02
I0211 10:07:01.269297 22509476222784 run_lib.py:133] step: 348550, training_loss: 4.77504e-02
I0211 10:07:19.867840 22509476222784 run_lib.py:133] step: 348600, training_loss: 4.71981e-02
I0211 10:07:20.032849 22509476222784 run_lib.py:146] step: 348600, eval_loss: 4.92768e-02
I0211 10:07:38.556826 22509476222784 run_lib.py:133] step: 348650, training_loss: 4.60505e-02
I0211 10:07:57.288264 22509476222784 run_lib.py:133] step: 348700, training_loss: 3.66170e-02
I0211 10:07:57.456490 22509476222784 run_lib.py:146] step: 348700, eval_loss: 3.67330e-02
I0211 10:08:15.977722 22509476222784 run_lib.py:133] step: 348750, training_loss: 3.93895e-02
I0211 10:08:34.687905 22509476222784 run_lib.py:133] step: 348800, training_loss: 4.27134e-02
I0211 10:08:34.879956 22509476222784 run_lib.py:146] step: 348800, eval_loss: 4.21467e-02
I0211 10:08:53.468233 22509476222784 run_lib.py:133] step: 348850, training_loss: 4.52932e-02
I0211 10:09:12.017713 22509476222784 run_lib.py:133] step: 348900, training_loss: 4.23989e-02
I0211 10:09:12.213740 22509476222784 run_lib.py:146] step: 348900, eval_loss: 4.53644e-02
I0211 10:09:30.942138 22509476222784 run_lib.py:133] step: 348950, training_loss: 4.09088e-02
I0211 10:09:49.488593 22509476222784 run_lib.py:133] step: 349000, training_loss: 3.35143e-02
I0211 10:09:49.654880 22509476222784 run_lib.py:146] step: 349000, eval_loss: 3.55802e-02
I0211 10:10:08.216495 22509476222784 run_lib.py:133] step: 349050, training_loss: 3.14530e-02
I0211 10:10:26.917587 22509476222784 run_lib.py:133] step: 349100, training_loss: 4.32327e-02
I0211 10:10:27.081792 22509476222784 run_lib.py:146] step: 349100, eval_loss: 4.81597e-02
I0211 10:10:45.584079 22509476222784 run_lib.py:133] step: 349150, training_loss: 3.12281e-02
I0211 10:11:04.070219 22509476222784 run_lib.py:133] step: 349200, training_loss: 3.94017e-02
I0211 10:11:04.237779 22509476222784 run_lib.py:146] step: 349200, eval_loss: 4.54435e-02
I0211 10:11:22.941935 22509476222784 run_lib.py:133] step: 349250, training_loss: 4.07587e-02
I0211 10:11:41.460901 22509476222784 run_lib.py:133] step: 349300, training_loss: 3.99166e-02
I0211 10:11:41.656759 22509476222784 run_lib.py:146] step: 349300, eval_loss: 4.92986e-02
I0211 10:12:00.214439 22509476222784 run_lib.py:133] step: 349350, training_loss: 4.91483e-02
I0211 10:12:18.835294 22509476222784 run_lib.py:133] step: 349400, training_loss: 5.12860e-02
I0211 10:12:19.010824 22509476222784 run_lib.py:146] step: 349400, eval_loss: 6.04875e-02
I0211 10:12:37.746058 22509476222784 run_lib.py:133] step: 349450, training_loss: 4.35298e-02
I0211 10:12:56.389426 22509476222784 run_lib.py:133] step: 349500, training_loss: 4.17581e-02
I0211 10:12:56.582839 22509476222784 run_lib.py:146] step: 349500, eval_loss: 3.77810e-02
I0211 10:13:15.130197 22509476222784 run_lib.py:133] step: 349550, training_loss: 4.88009e-02
I0211 10:13:33.675226 22509476222784 run_lib.py:133] step: 349600, training_loss: 4.95804e-02
I0211 10:13:33.856750 22509476222784 run_lib.py:146] step: 349600, eval_loss: 3.26714e-02
I0211 10:13:52.572522 22509476222784 run_lib.py:133] step: 349650, training_loss: 4.18199e-02
I0211 10:14:11.185275 22509476222784 run_lib.py:133] step: 349700, training_loss: 3.71487e-02
I0211 10:14:11.379592 22509476222784 run_lib.py:146] step: 349700, eval_loss: 4.58252e-02
I0211 10:14:30.134816 22509476222784 run_lib.py:133] step: 349750, training_loss: 3.60691e-02
I0211 10:14:48.642602 22509476222784 run_lib.py:133] step: 349800, training_loss: 3.79494e-02
I0211 10:14:48.800332 22509476222784 run_lib.py:146] step: 349800, eval_loss: 3.97718e-02
I0211 10:15:07.445370 22509476222784 run_lib.py:133] step: 349850, training_loss: 4.28902e-02
I0211 10:15:26.009840 22509476222784 run_lib.py:133] step: 349900, training_loss: 3.72099e-02
I0211 10:15:26.184913 22509476222784 run_lib.py:146] step: 349900, eval_loss: 3.97803e-02
I0211 10:15:44.946594 22509476222784 run_lib.py:133] step: 349950, training_loss: 2.21009e-02
I0211 10:16:03.510106 22509476222784 run_lib.py:133] step: 350000, training_loss: 5.14502e-02
I0211 10:16:04.335833 22509476222784 run_lib.py:146] step: 350000, eval_loss: 4.19598e-02
I0211 10:16:25.484250 22509476222784 run_lib.py:133] step: 350050, training_loss: 3.22799e-02
I0211 10:16:44.214618 22509476222784 run_lib.py:133] step: 350100, training_loss: 5.84916e-02
I0211 10:16:44.382775 22509476222784 run_lib.py:146] step: 350100, eval_loss: 4.70158e-02
I0211 10:17:02.896240 22509476222784 run_lib.py:133] step: 350150, training_loss: 4.94940e-02
I0211 10:17:21.609160 22509476222784 run_lib.py:133] step: 350200, training_loss: 3.50366e-02
I0211 10:17:21.780311 22509476222784 run_lib.py:146] step: 350200, eval_loss: 3.56936e-02
I0211 10:17:40.305874 22509476222784 run_lib.py:133] step: 350250, training_loss: 3.53652e-02
I0211 10:17:58.823111 22509476222784 run_lib.py:133] step: 350300, training_loss: 3.56032e-02
I0211 10:17:58.982578 22509476222784 run_lib.py:146] step: 350300, eval_loss: 3.77091e-02
I0211 10:18:17.699128 22509476222784 run_lib.py:133] step: 350350, training_loss: 3.80903e-02
I0211 10:18:36.306056 22509476222784 run_lib.py:133] step: 350400, training_loss: 5.22874e-02
I0211 10:18:36.467593 22509476222784 run_lib.py:146] step: 350400, eval_loss: 3.87962e-02
I0211 10:18:55.051765 22509476222784 run_lib.py:133] step: 350450, training_loss: 5.84206e-02
I0211 10:19:13.585327 22509476222784 run_lib.py:133] step: 350500, training_loss: 3.49215e-02
I0211 10:19:13.753687 22509476222784 run_lib.py:146] step: 350500, eval_loss: 4.31075e-02
I0211 10:19:32.472479 22509476222784 run_lib.py:133] step: 350550, training_loss: 4.23714e-02
I0211 10:19:51.013123 22509476222784 run_lib.py:133] step: 350600, training_loss: 4.49890e-02
I0211 10:19:51.182528 22509476222784 run_lib.py:146] step: 350600, eval_loss: 3.84217e-02
I0211 10:20:09.896029 22509476222784 run_lib.py:133] step: 350650, training_loss: 3.94439e-02
I0211 10:20:28.404446 22509476222784 run_lib.py:133] step: 350700, training_loss: 4.38700e-02
I0211 10:20:28.586664 22509476222784 run_lib.py:146] step: 350700, eval_loss: 4.18031e-02
I0211 10:20:47.415654 22509476222784 run_lib.py:133] step: 350750, training_loss: 3.49118e-02
I0211 10:21:06.026880 22509476222784 run_lib.py:133] step: 350800, training_loss: 4.46908e-02
I0211 10:21:06.186387 22509476222784 run_lib.py:146] step: 350800, eval_loss: 3.63851e-02
I0211 10:21:24.685047 22509476222784 run_lib.py:133] step: 350850, training_loss: 5.34728e-02
I0211 10:21:43.356079 22509476222784 run_lib.py:133] step: 350900, training_loss: 3.55208e-02
I0211 10:21:43.527629 22509476222784 run_lib.py:146] step: 350900, eval_loss: 5.39189e-02
I0211 10:22:02.066122 22509476222784 run_lib.py:133] step: 350950, training_loss: 4.66386e-02
I0211 10:22:20.760079 22509476222784 run_lib.py:133] step: 351000, training_loss: 4.63970e-02
I0211 10:22:20.940721 22509476222784 run_lib.py:146] step: 351000, eval_loss: 3.38179e-02
I0211 10:22:39.499025 22509476222784 run_lib.py:133] step: 351050, training_loss: 3.30161e-02
I0211 10:22:58.012171 22509476222784 run_lib.py:133] step: 351100, training_loss: 4.33415e-02
I0211 10:22:58.177916 22509476222784 run_lib.py:146] step: 351100, eval_loss: 3.84033e-02
I0211 10:23:16.901173 22509476222784 run_lib.py:133] step: 351150, training_loss: 4.46296e-02
I0211 10:23:35.331322 22509476222784 run_lib.py:133] step: 351200, training_loss: 3.73853e-02
I0211 10:23:35.498772 22509476222784 run_lib.py:146] step: 351200, eval_loss: 4.08528e-02
I0211 10:23:53.995976 22509476222784 run_lib.py:133] step: 351250, training_loss: 4.74888e-02
I0211 10:24:12.683170 22509476222784 run_lib.py:133] step: 351300, training_loss: 3.65487e-02
I0211 10:24:12.846001 22509476222784 run_lib.py:146] step: 351300, eval_loss: 3.51311e-02
I0211 10:24:31.452945 22509476222784 run_lib.py:133] step: 351350, training_loss: 3.61245e-02
I0211 10:24:49.968746 22509476222784 run_lib.py:133] step: 351400, training_loss: 5.20172e-02
I0211 10:24:50.133607 22509476222784 run_lib.py:146] step: 351400, eval_loss: 3.73454e-02
I0211 10:25:08.749187 22509476222784 run_lib.py:133] step: 351450, training_loss: 2.80741e-02
I0211 10:25:27.305605 22509476222784 run_lib.py:133] step: 351500, training_loss: 4.70760e-02
I0211 10:25:27.472039 22509476222784 run_lib.py:146] step: 351500, eval_loss: 3.84766e-02
I0211 10:25:46.011073 22509476222784 run_lib.py:133] step: 351550, training_loss: 3.41436e-02
I0211 10:26:04.597461 22509476222784 run_lib.py:133] step: 351600, training_loss: 4.68646e-02
I0211 10:26:04.766981 22509476222784 run_lib.py:146] step: 351600, eval_loss: 3.74173e-02
I0211 10:26:23.526823 22509476222784 run_lib.py:133] step: 351650, training_loss: 3.43225e-02
I0211 10:26:42.129545 22509476222784 run_lib.py:133] step: 351700, training_loss: 4.85012e-02
I0211 10:26:42.291689 22509476222784 run_lib.py:146] step: 351700, eval_loss: 3.51550e-02
I0211 10:27:00.807544 22509476222784 run_lib.py:133] step: 351750, training_loss: 4.46616e-02
I0211 10:27:19.326658 22509476222784 run_lib.py:133] step: 351800, training_loss: 4.58258e-02
I0211 10:27:19.488646 22509476222784 run_lib.py:146] step: 351800, eval_loss: 4.94749e-02
I0211 10:27:38.050487 22509476222784 run_lib.py:133] step: 351850, training_loss: 4.84313e-02
I0211 10:27:56.558538 22509476222784 run_lib.py:133] step: 351900, training_loss: 5.08669e-02
I0211 10:27:56.740703 22509476222784 run_lib.py:146] step: 351900, eval_loss: 5.04054e-02
I0211 10:28:15.498339 22509476222784 run_lib.py:133] step: 351950, training_loss: 3.34551e-02
I0211 10:28:34.041236 22509476222784 run_lib.py:133] step: 352000, training_loss: 3.21173e-02
I0211 10:28:34.202391 22509476222784 run_lib.py:146] step: 352000, eval_loss: 5.03495e-02
I0211 10:28:52.868163 22509476222784 run_lib.py:133] step: 352050, training_loss: 5.37328e-02
I0211 10:29:11.399757 22509476222784 run_lib.py:133] step: 352100, training_loss: 3.75608e-02
I0211 10:29:11.563710 22509476222784 run_lib.py:146] step: 352100, eval_loss: 5.79275e-02
I0211 10:29:30.263316 22509476222784 run_lib.py:133] step: 352150, training_loss: 3.35783e-02
I0211 10:29:48.906702 22509476222784 run_lib.py:133] step: 352200, training_loss: 5.19209e-02
I0211 10:29:49.086828 22509476222784 run_lib.py:146] step: 352200, eval_loss: 4.76491e-02
I0211 10:30:07.699193 22509476222784 run_lib.py:133] step: 352250, training_loss: 4.73439e-02
I0211 10:30:26.405352 22509476222784 run_lib.py:133] step: 352300, training_loss: 3.06715e-02
I0211 10:30:26.568620 22509476222784 run_lib.py:146] step: 352300, eval_loss: 3.38506e-02
I0211 10:30:45.052526 22509476222784 run_lib.py:133] step: 352350, training_loss: 3.58022e-02
I0211 10:31:03.559279 22509476222784 run_lib.py:133] step: 352400, training_loss: 4.99499e-02
I0211 10:31:03.740633 22509476222784 run_lib.py:146] step: 352400, eval_loss: 3.71092e-02
I0211 10:31:22.535330 22509476222784 run_lib.py:133] step: 352450, training_loss: 3.95109e-02
I0211 10:31:41.318081 22509476222784 run_lib.py:133] step: 352500, training_loss: 4.24523e-02
I0211 10:31:41.488923 22509476222784 run_lib.py:146] step: 352500, eval_loss: 4.75731e-02
I0211 10:32:00.223351 22509476222784 run_lib.py:133] step: 352550, training_loss: 4.69639e-02
I0211 10:32:18.743179 22509476222784 run_lib.py:133] step: 352600, training_loss: 4.40848e-02
I0211 10:32:18.907791 22509476222784 run_lib.py:146] step: 352600, eval_loss: 3.53064e-02
I0211 10:32:37.458954 22509476222784 run_lib.py:133] step: 352650, training_loss: 3.44838e-02
I0211 10:32:56.190407 22509476222784 run_lib.py:133] step: 352700, training_loss: 4.12498e-02
I0211 10:32:56.360099 22509476222784 run_lib.py:146] step: 352700, eval_loss: 3.85249e-02
I0211 10:33:14.954126 22509476222784 run_lib.py:133] step: 352750, training_loss: 5.05761e-02
I0211 10:33:33.477929 22509476222784 run_lib.py:133] step: 352800, training_loss: 4.75562e-02
I0211 10:33:33.645782 22509476222784 run_lib.py:146] step: 352800, eval_loss: 4.42891e-02
I0211 10:33:52.140204 22509476222784 run_lib.py:133] step: 352850, training_loss: 4.61086e-02
I0211 10:34:10.806205 22509476222784 run_lib.py:133] step: 352900, training_loss: 4.83250e-02
I0211 10:34:10.971822 22509476222784 run_lib.py:146] step: 352900, eval_loss: 4.98429e-02
I0211 10:34:29.448402 22509476222784 run_lib.py:133] step: 352950, training_loss: 4.23052e-02
I0211 10:34:48.099335 22509476222784 run_lib.py:133] step: 353000, training_loss: 3.93862e-02
I0211 10:34:48.272819 22509476222784 run_lib.py:146] step: 353000, eval_loss: 3.42399e-02
I0211 10:35:06.837201 22509476222784 run_lib.py:133] step: 353050, training_loss: 3.93484e-02
I0211 10:35:25.372114 22509476222784 run_lib.py:133] step: 353100, training_loss: 3.92223e-02
I0211 10:35:25.536963 22509476222784 run_lib.py:146] step: 353100, eval_loss: 3.10351e-02
I0211 10:35:44.261622 22509476222784 run_lib.py:133] step: 353150, training_loss: 3.77699e-02
I0211 10:36:02.816220 22509476222784 run_lib.py:133] step: 353200, training_loss: 3.30190e-02
I0211 10:36:02.977764 22509476222784 run_lib.py:146] step: 353200, eval_loss: 3.53949e-02
I0211 10:36:21.530920 22509476222784 run_lib.py:133] step: 353250, training_loss: 4.91599e-02
I0211 10:36:40.084720 22509476222784 run_lib.py:133] step: 353300, training_loss: 5.06018e-02
I0211 10:36:40.256848 22509476222784 run_lib.py:146] step: 353300, eval_loss: 4.34521e-02
I0211 10:36:58.966866 22509476222784 run_lib.py:133] step: 353350, training_loss: 3.24536e-02
I0211 10:37:17.528844 22509476222784 run_lib.py:133] step: 353400, training_loss: 4.15119e-02
I0211 10:37:17.694881 22509476222784 run_lib.py:146] step: 353400, eval_loss: 4.98719e-02
I0211 10:37:36.371860 22509476222784 run_lib.py:133] step: 353450, training_loss: 3.41975e-02
I0211 10:37:54.892409 22509476222784 run_lib.py:133] step: 353500, training_loss: 4.75591e-02
I0211 10:37:55.057686 22509476222784 run_lib.py:146] step: 353500, eval_loss: 3.08943e-02
I0211 10:38:13.748360 22509476222784 run_lib.py:133] step: 353550, training_loss: 4.29154e-02
I0211 10:38:32.382466 22509476222784 run_lib.py:133] step: 353600, training_loss: 3.43758e-02
I0211 10:38:32.548897 22509476222784 run_lib.py:146] step: 353600, eval_loss: 4.63193e-02
I0211 10:38:51.088433 22509476222784 run_lib.py:133] step: 353650, training_loss: 5.12727e-02
I0211 10:39:09.801363 22509476222784 run_lib.py:133] step: 353700, training_loss: 4.02524e-02
I0211 10:39:09.968710 22509476222784 run_lib.py:146] step: 353700, eval_loss: 2.94470e-02
I0211 10:39:28.509234 22509476222784 run_lib.py:133] step: 353750, training_loss: 3.02998e-02
I0211 10:39:47.191960 22509476222784 run_lib.py:133] step: 353800, training_loss: 4.20491e-02
I0211 10:39:47.398248 22509476222784 run_lib.py:146] step: 353800, eval_loss: 4.99338e-02
I0211 10:40:06.010512 22509476222784 run_lib.py:133] step: 353850, training_loss: 4.66999e-02
I0211 10:40:24.541988 22509476222784 run_lib.py:133] step: 353900, training_loss: 4.24470e-02
I0211 10:40:24.711260 22509476222784 run_lib.py:146] step: 353900, eval_loss: 3.83295e-02
I0211 10:40:43.375002 22509476222784 run_lib.py:133] step: 353950, training_loss: 3.42853e-02
I0211 10:41:01.907028 22509476222784 run_lib.py:133] step: 354000, training_loss: 4.18544e-02
I0211 10:41:02.091461 22509476222784 run_lib.py:146] step: 354000, eval_loss: 3.61989e-02
I0211 10:41:20.635373 22509476222784 run_lib.py:133] step: 354050, training_loss: 6.88961e-02
I0211 10:41:39.361980 22509476222784 run_lib.py:133] step: 354100, training_loss: 4.08817e-02
I0211 10:41:39.525174 22509476222784 run_lib.py:146] step: 354100, eval_loss: 4.40656e-02
I0211 10:41:58.138861 22509476222784 run_lib.py:133] step: 354150, training_loss: 4.49362e-02
I0211 10:42:16.669348 22509476222784 run_lib.py:133] step: 354200, training_loss: 4.94195e-02
I0211 10:42:17.019501 22509476222784 run_lib.py:146] step: 354200, eval_loss: 3.65959e-02
I0211 10:42:35.498908 22509476222784 run_lib.py:133] step: 354250, training_loss: 4.67277e-02
I0211 10:42:54.018323 22509476222784 run_lib.py:133] step: 354300, training_loss: 4.45830e-02
I0211 10:42:54.184913 22509476222784 run_lib.py:146] step: 354300, eval_loss: 3.72748e-02
I0211 10:43:12.743424 22509476222784 run_lib.py:133] step: 354350, training_loss: 5.08148e-02
I0211 10:43:31.392676 22509476222784 run_lib.py:133] step: 354400, training_loss: 3.62543e-02
I0211 10:43:31.557794 22509476222784 run_lib.py:146] step: 354400, eval_loss: 3.85804e-02
I0211 10:43:50.291963 22509476222784 run_lib.py:133] step: 354450, training_loss: 4.10772e-02
I0211 10:44:08.861924 22509476222784 run_lib.py:133] step: 354500, training_loss: 2.98373e-02
I0211 10:44:09.027435 22509476222784 run_lib.py:146] step: 354500, eval_loss: 4.68318e-02
I0211 10:44:27.526531 22509476222784 run_lib.py:133] step: 354550, training_loss: 4.89421e-02
I0211 10:44:46.015282 22509476222784 run_lib.py:133] step: 354600, training_loss: 5.39328e-02
I0211 10:44:46.179493 22509476222784 run_lib.py:146] step: 354600, eval_loss: 4.08510e-02
I0211 10:45:04.930058 22509476222784 run_lib.py:133] step: 354650, training_loss: 4.97209e-02
I0211 10:45:23.552726 22509476222784 run_lib.py:133] step: 354700, training_loss: 4.55363e-02
I0211 10:45:23.717639 22509476222784 run_lib.py:146] step: 354700, eval_loss: 4.48721e-02
I0211 10:45:42.239096 22509476222784 run_lib.py:133] step: 354750, training_loss: 5.44510e-02
I0211 10:46:00.789998 22509476222784 run_lib.py:133] step: 354800, training_loss: 3.74744e-02
I0211 10:46:00.966804 22509476222784 run_lib.py:146] step: 354800, eval_loss: 4.88001e-02
I0211 10:46:19.639224 22509476222784 run_lib.py:133] step: 354850, training_loss: 4.61662e-02
I0211 10:46:38.224427 22509476222784 run_lib.py:133] step: 354900, training_loss: 5.47529e-02
I0211 10:46:38.395604 22509476222784 run_lib.py:146] step: 354900, eval_loss: 5.85299e-02
I0211 10:46:57.075279 22509476222784 run_lib.py:133] step: 354950, training_loss: 5.22592e-02
I0211 10:47:15.613579 22509476222784 run_lib.py:133] step: 355000, training_loss: 3.71241e-02
I0211 10:47:15.776579 22509476222784 run_lib.py:146] step: 355000, eval_loss: 4.54672e-02
I0211 10:47:34.530360 22509476222784 run_lib.py:133] step: 355050, training_loss: 3.33852e-02
I0211 10:47:53.082265 22509476222784 run_lib.py:133] step: 355100, training_loss: 3.75485e-02
I0211 10:47:53.270718 22509476222784 run_lib.py:146] step: 355100, eval_loss: 3.99669e-02
I0211 10:48:11.816565 22509476222784 run_lib.py:133] step: 355150, training_loss: 4.56456e-02
I0211 10:48:30.496688 22509476222784 run_lib.py:133] step: 355200, training_loss: 4.05942e-02
I0211 10:48:30.672904 22509476222784 run_lib.py:146] step: 355200, eval_loss: 4.89660e-02
I0211 10:48:49.233576 22509476222784 run_lib.py:133] step: 355250, training_loss: 3.76417e-02
I0211 10:49:07.940167 22509476222784 run_lib.py:133] step: 355300, training_loss: 4.29039e-02
I0211 10:49:08.106626 22509476222784 run_lib.py:146] step: 355300, eval_loss: 3.94228e-02
I0211 10:49:26.670125 22509476222784 run_lib.py:133] step: 355350, training_loss: 4.39720e-02
I0211 10:49:45.185392 22509476222784 run_lib.py:133] step: 355400, training_loss: 4.27675e-02
I0211 10:49:45.359727 22509476222784 run_lib.py:146] step: 355400, eval_loss: 4.90286e-02
I0211 10:50:03.900750 22509476222784 run_lib.py:133] step: 355450, training_loss: 5.67995e-02
I0211 10:50:22.702330 22509476222784 run_lib.py:133] step: 355500, training_loss: 3.28580e-02
I0211 10:50:22.865975 22509476222784 run_lib.py:146] step: 355500, eval_loss: 4.13021e-02
I0211 10:50:41.474387 22509476222784 run_lib.py:133] step: 355550, training_loss: 4.04324e-02
I0211 10:51:00.088726 22509476222784 run_lib.py:133] step: 355600, training_loss: 3.72788e-02
I0211 10:51:00.270324 22509476222784 run_lib.py:146] step: 355600, eval_loss: 3.65832e-02
I0211 10:51:18.967880 22509476222784 run_lib.py:133] step: 355650, training_loss: 5.15816e-02
I0211 10:51:37.483177 22509476222784 run_lib.py:133] step: 355700, training_loss: 3.96725e-02
I0211 10:51:37.663651 22509476222784 run_lib.py:146] step: 355700, eval_loss: 3.91605e-02
I0211 10:51:56.325635 22509476222784 run_lib.py:133] step: 355750, training_loss: 3.12293e-02
I0211 10:52:14.870581 22509476222784 run_lib.py:133] step: 355800, training_loss: 4.67048e-02
I0211 10:52:15.070880 22509476222784 run_lib.py:146] step: 355800, eval_loss: 4.41310e-02
I0211 10:52:33.620637 22509476222784 run_lib.py:133] step: 355850, training_loss: 4.29142e-02
I0211 10:52:52.135317 22509476222784 run_lib.py:133] step: 355900, training_loss: 6.00593e-02
I0211 10:52:52.300783 22509476222784 run_lib.py:146] step: 355900, eval_loss: 4.36956e-02
I0211 10:53:11.004821 22509476222784 run_lib.py:133] step: 355950, training_loss: 4.22301e-02
I0211 10:53:29.592460 22509476222784 run_lib.py:133] step: 356000, training_loss: 5.27575e-02
I0211 10:53:29.757034 22509476222784 run_lib.py:146] step: 356000, eval_loss: 3.51722e-02
I0211 10:53:48.379344 22509476222784 run_lib.py:133] step: 356050, training_loss: 3.80826e-02
I0211 10:54:06.886716 22509476222784 run_lib.py:133] step: 356100, training_loss: 3.70265e-02
I0211 10:54:07.056712 22509476222784 run_lib.py:146] step: 356100, eval_loss: 3.98455e-02
I0211 10:54:25.733530 22509476222784 run_lib.py:133] step: 356150, training_loss: 4.22313e-02
I0211 10:54:44.241870 22509476222784 run_lib.py:133] step: 356200, training_loss: 4.54261e-02
I0211 10:54:44.407934 22509476222784 run_lib.py:146] step: 356200, eval_loss: 3.88981e-02
I0211 10:55:03.077018 22509476222784 run_lib.py:133] step: 356250, training_loss: 3.64166e-02
I0211 10:55:21.678267 22509476222784 run_lib.py:133] step: 356300, training_loss: 3.04541e-02
I0211 10:55:21.858936 22509476222784 run_lib.py:146] step: 356300, eval_loss: 5.01079e-02
I0211 10:55:40.563284 22509476222784 run_lib.py:133] step: 356350, training_loss: 4.94337e-02
I0211 10:55:59.099343 22509476222784 run_lib.py:133] step: 356400, training_loss: 3.89761e-02
I0211 10:55:59.262707 22509476222784 run_lib.py:146] step: 356400, eval_loss: 4.84744e-02
I0211 10:56:17.917285 22509476222784 run_lib.py:133] step: 356450, training_loss: 4.55017e-02
I0211 10:56:36.447367 22509476222784 run_lib.py:133] step: 356500, training_loss: 5.22911e-02
I0211 10:56:36.609680 22509476222784 run_lib.py:146] step: 356500, eval_loss: 4.88006e-02
I0211 10:56:55.195125 22509476222784 run_lib.py:133] step: 356550, training_loss: 4.93471e-02
I0211 10:57:13.976242 22509476222784 run_lib.py:133] step: 356600, training_loss: 4.04693e-02
I0211 10:57:14.163868 22509476222784 run_lib.py:146] step: 356600, eval_loss: 5.29007e-02
I0211 10:57:32.740518 22509476222784 run_lib.py:133] step: 356650, training_loss: 3.74402e-02
I0211 10:57:51.340313 22509476222784 run_lib.py:133] step: 356700, training_loss: 4.46963e-02
I0211 10:57:51.505944 22509476222784 run_lib.py:146] step: 356700, eval_loss: 4.01562e-02
I0211 10:58:10.187739 22509476222784 run_lib.py:133] step: 356750, training_loss: 5.49584e-02
I0211 10:58:28.857940 22509476222784 run_lib.py:133] step: 356800, training_loss: 3.48348e-02
I0211 10:58:29.063707 22509476222784 run_lib.py:146] step: 356800, eval_loss: 4.74123e-02
I0211 10:58:47.601998 22509476222784 run_lib.py:133] step: 356850, training_loss: 3.42513e-02
I0211 10:59:06.167423 22509476222784 run_lib.py:133] step: 356900, training_loss: 5.08129e-02
I0211 10:59:06.332037 22509476222784 run_lib.py:146] step: 356900, eval_loss: 3.41903e-02
I0211 10:59:24.919258 22509476222784 run_lib.py:133] step: 356950, training_loss: 4.21049e-02
I0211 10:59:43.630569 22509476222784 run_lib.py:133] step: 357000, training_loss: 4.74555e-02
I0211 10:59:43.788165 22509476222784 run_lib.py:146] step: 357000, eval_loss: 4.57667e-02
I0211 11:00:02.227347 22509476222784 run_lib.py:133] step: 357050, training_loss: 3.17923e-02
I0211 11:00:20.718459 22509476222784 run_lib.py:133] step: 357100, training_loss: 4.49592e-02
I0211 11:00:20.888272 22509476222784 run_lib.py:146] step: 357100, eval_loss: 3.41832e-02
I0211 11:00:39.480900 22509476222784 run_lib.py:133] step: 357150, training_loss: 4.13608e-02
I0211 11:00:58.253960 22509476222784 run_lib.py:133] step: 357200, training_loss: 3.73003e-02
I0211 11:00:58.448783 22509476222784 run_lib.py:146] step: 357200, eval_loss: 4.28400e-02
I0211 11:01:16.973977 22509476222784 run_lib.py:133] step: 357250, training_loss: 3.89444e-02
I0211 11:01:35.536014 22509476222784 run_lib.py:133] step: 357300, training_loss: 4.83430e-02
I0211 11:01:35.699712 22509476222784 run_lib.py:146] step: 357300, eval_loss: 5.04100e-02
I0211 11:01:54.227293 22509476222784 run_lib.py:133] step: 357350, training_loss: 3.43178e-02
I0211 11:02:12.996517 22509476222784 run_lib.py:133] step: 357400, training_loss: 4.16707e-02
I0211 11:02:13.160846 22509476222784 run_lib.py:146] step: 357400, eval_loss: 3.94474e-02
I0211 11:02:31.902388 22509476222784 run_lib.py:133] step: 357450, training_loss: 4.01454e-02
I0211 11:02:50.467756 22509476222784 run_lib.py:133] step: 357500, training_loss: 5.90899e-02
I0211 11:02:50.629705 22509476222784 run_lib.py:146] step: 357500, eval_loss: 3.71521e-02
I0211 11:03:09.160733 22509476222784 run_lib.py:133] step: 357550, training_loss: 3.66103e-02
I0211 11:03:27.707449 22509476222784 run_lib.py:133] step: 357600, training_loss: 3.03911e-02
I0211 11:03:27.875006 22509476222784 run_lib.py:146] step: 357600, eval_loss: 3.73445e-02
I0211 11:03:46.544199 22509476222784 run_lib.py:133] step: 357650, training_loss: 5.19807e-02
I0211 11:04:05.107948 22509476222784 run_lib.py:133] step: 357700, training_loss: 3.78060e-02
I0211 11:04:05.272782 22509476222784 run_lib.py:146] step: 357700, eval_loss: 3.09528e-02
I0211 11:04:23.993399 22509476222784 run_lib.py:133] step: 357750, training_loss: 3.45509e-02
I0211 11:04:42.506207 22509476222784 run_lib.py:133] step: 357800, training_loss: 3.59358e-02
I0211 11:04:42.677910 22509476222784 run_lib.py:146] step: 357800, eval_loss: 4.20537e-02
I0211 11:05:01.295142 22509476222784 run_lib.py:133] step: 357850, training_loss: 4.33304e-02
I0211 11:05:19.813428 22509476222784 run_lib.py:133] step: 357900, training_loss: 2.98517e-02
I0211 11:05:19.975827 22509476222784 run_lib.py:146] step: 357900, eval_loss: 3.99741e-02
I0211 11:05:38.472901 22509476222784 run_lib.py:133] step: 357950, training_loss: 5.67384e-02
I0211 11:05:57.232924 22509476222784 run_lib.py:133] step: 358000, training_loss: 5.20569e-02
I0211 11:05:57.437891 22509476222784 run_lib.py:146] step: 358000, eval_loss: 4.09891e-02
I0211 11:06:15.979813 22509476222784 run_lib.py:133] step: 358050, training_loss: 5.20123e-02
I0211 11:06:34.699591 22509476222784 run_lib.py:133] step: 358100, training_loss: 4.26064e-02
I0211 11:06:34.866028 22509476222784 run_lib.py:146] step: 358100, eval_loss: 5.22545e-02
I0211 11:06:53.383550 22509476222784 run_lib.py:133] step: 358150, training_loss: 5.13164e-02
I0211 11:07:11.905197 22509476222784 run_lib.py:133] step: 358200, training_loss: 4.77016e-02
I0211 11:07:12.076737 22509476222784 run_lib.py:146] step: 358200, eval_loss: 5.48679e-02
I0211 11:07:30.809019 22509476222784 run_lib.py:133] step: 358250, training_loss: 3.10235e-02
I0211 11:07:49.416983 22509476222784 run_lib.py:133] step: 358300, training_loss: 4.88980e-02
I0211 11:07:49.584827 22509476222784 run_lib.py:146] step: 358300, eval_loss: 4.80280e-02
I0211 11:08:08.162776 22509476222784 run_lib.py:133] step: 358350, training_loss: 3.77970e-02
I0211 11:08:26.949871 22509476222784 run_lib.py:133] step: 358400, training_loss: 4.23961e-02
I0211 11:08:27.110657 22509476222784 run_lib.py:146] step: 358400, eval_loss: 3.91227e-02
I0211 11:08:45.637338 22509476222784 run_lib.py:133] step: 358450, training_loss: 3.35865e-02
I0211 11:09:04.216660 22509476222784 run_lib.py:133] step: 358500, training_loss: 3.12423e-02
I0211 11:09:04.463862 22509476222784 run_lib.py:146] step: 358500, eval_loss: 3.57215e-02
I0211 11:09:23.139531 22509476222784 run_lib.py:133] step: 358550, training_loss: 4.20685e-02
I0211 11:09:41.726492 22509476222784 run_lib.py:133] step: 358600, training_loss: 3.71528e-02
I0211 11:09:41.892706 22509476222784 run_lib.py:146] step: 358600, eval_loss: 4.88328e-02
I0211 11:10:00.379014 22509476222784 run_lib.py:133] step: 358650, training_loss: 3.32362e-02
I0211 11:10:18.920183 22509476222784 run_lib.py:133] step: 358700, training_loss: 4.78086e-02
I0211 11:10:19.089733 22509476222784 run_lib.py:146] step: 358700, eval_loss: 4.97826e-02
I0211 11:10:37.834547 22509476222784 run_lib.py:133] step: 358750, training_loss: 4.10571e-02
I0211 11:10:56.414554 22509476222784 run_lib.py:133] step: 358800, training_loss: 3.18427e-02
I0211 11:10:56.597922 22509476222784 run_lib.py:146] step: 358800, eval_loss: 4.75269e-02
I0211 11:11:15.234907 22509476222784 run_lib.py:133] step: 358850, training_loss: 5.13396e-02
I0211 11:11:33.783842 22509476222784 run_lib.py:133] step: 358900, training_loss: 4.98374e-02
I0211 11:11:33.944788 22509476222784 run_lib.py:146] step: 358900, eval_loss: 4.35379e-02
I0211 11:11:52.644267 22509476222784 run_lib.py:133] step: 358950, training_loss: 4.89055e-02
I0211 11:12:11.160081 22509476222784 run_lib.py:133] step: 359000, training_loss: 3.91126e-02
I0211 11:12:11.361923 22509476222784 run_lib.py:146] step: 359000, eval_loss: 5.41125e-02
I0211 11:12:30.005315 22509476222784 run_lib.py:133] step: 359050, training_loss: 4.28457e-02
I0211 11:12:48.519618 22509476222784 run_lib.py:133] step: 359100, training_loss: 4.70923e-02
I0211 11:12:48.696685 22509476222784 run_lib.py:146] step: 359100, eval_loss: 5.11436e-02
I0211 11:13:07.476164 22509476222784 run_lib.py:133] step: 359150, training_loss: 4.80784e-02
I0211 11:13:26.053138 22509476222784 run_lib.py:133] step: 359200, training_loss: 4.90436e-02
I0211 11:13:26.216929 22509476222784 run_lib.py:146] step: 359200, eval_loss: 4.79233e-02
I0211 11:13:44.912662 22509476222784 run_lib.py:133] step: 359250, training_loss: 3.77670e-02
I0211 11:14:03.460135 22509476222784 run_lib.py:133] step: 359300, training_loss: 4.30314e-02
I0211 11:14:03.622684 22509476222784 run_lib.py:146] step: 359300, eval_loss: 4.94844e-02
I0211 11:14:22.110843 22509476222784 run_lib.py:133] step: 359350, training_loss: 3.83414e-02
I0211 11:14:40.819634 22509476222784 run_lib.py:133] step: 359400, training_loss: 3.97539e-02
I0211 11:14:40.995864 22509476222784 run_lib.py:146] step: 359400, eval_loss: 5.23739e-02
I0211 11:14:59.532893 22509476222784 run_lib.py:133] step: 359450, training_loss: 4.52991e-02
I0211 11:15:18.093975 22509476222784 run_lib.py:133] step: 359500, training_loss: 4.61524e-02
I0211 11:15:18.260937 22509476222784 run_lib.py:146] step: 359500, eval_loss: 3.95919e-02
I0211 11:15:37.068539 22509476222784 run_lib.py:133] step: 359550, training_loss: 3.82190e-02
I0211 11:15:55.647570 22509476222784 run_lib.py:133] step: 359600, training_loss: 4.72247e-02
I0211 11:15:55.812644 22509476222784 run_lib.py:146] step: 359600, eval_loss: 4.89788e-02
I0211 11:16:14.497205 22509476222784 run_lib.py:133] step: 359650, training_loss: 2.99585e-02
I0211 11:16:33.118884 22509476222784 run_lib.py:133] step: 359700, training_loss: 4.17346e-02
I0211 11:16:33.282363 22509476222784 run_lib.py:146] step: 359700, eval_loss: 3.77119e-02
I0211 11:16:51.841289 22509476222784 run_lib.py:133] step: 359750, training_loss: 5.19170e-02
I0211 11:17:10.572641 22509476222784 run_lib.py:133] step: 359800, training_loss: 4.00477e-02
I0211 11:17:10.739467 22509476222784 run_lib.py:146] step: 359800, eval_loss: 4.71138e-02
I0211 11:17:29.241982 22509476222784 run_lib.py:133] step: 359850, training_loss: 4.80352e-02
I0211 11:17:47.762728 22509476222784 run_lib.py:133] step: 359900, training_loss: 3.66157e-02
I0211 11:17:47.926616 22509476222784 run_lib.py:146] step: 359900, eval_loss: 4.81068e-02
I0211 11:18:06.487452 22509476222784 run_lib.py:133] step: 359950, training_loss: 4.11817e-02
I0211 11:18:25.230001 22509476222784 run_lib.py:133] step: 360000, training_loss: 5.62638e-02
I0211 11:18:26.214560 22509476222784 run_lib.py:146] step: 360000, eval_loss: 3.97049e-02
I0211 11:18:47.641637 22509476222784 run_lib.py:133] step: 360050, training_loss: 5.93218e-02
I0211 11:19:06.297142 22509476222784 run_lib.py:133] step: 360100, training_loss: 3.83929e-02
I0211 11:19:06.461748 22509476222784 run_lib.py:146] step: 360100, eval_loss: 4.82690e-02
I0211 11:19:24.946239 22509476222784 run_lib.py:133] step: 360150, training_loss: 4.72903e-02
I0211 11:19:43.469411 22509476222784 run_lib.py:133] step: 360200, training_loss: 4.08128e-02
I0211 11:19:43.641640 22509476222784 run_lib.py:146] step: 360200, eval_loss: 4.79682e-02
I0211 11:20:02.186155 22509476222784 run_lib.py:133] step: 360250, training_loss: 5.08263e-02
I0211 11:20:20.925631 22509476222784 run_lib.py:133] step: 360300, training_loss: 4.61080e-02
I0211 11:20:21.090005 22509476222784 run_lib.py:146] step: 360300, eval_loss: 3.91098e-02
I0211 11:20:39.713012 22509476222784 run_lib.py:133] step: 360350, training_loss: 4.17919e-02
I0211 11:20:58.263279 22509476222784 run_lib.py:133] step: 360400, training_loss: 4.55594e-02
I0211 11:20:58.474668 22509476222784 run_lib.py:146] step: 360400, eval_loss: 3.46964e-02
I0211 11:21:17.018077 22509476222784 run_lib.py:133] step: 360450, training_loss: 4.48112e-02
I0211 11:21:35.575848 22509476222784 run_lib.py:133] step: 360500, training_loss: 5.26097e-02
I0211 11:21:35.752707 22509476222784 run_lib.py:146] step: 360500, eval_loss: 2.88070e-02
I0211 11:21:54.482480 22509476222784 run_lib.py:133] step: 360550, training_loss: 4.23771e-02
I0211 11:22:13.157669 22509476222784 run_lib.py:133] step: 360600, training_loss: 4.21919e-02
I0211 11:22:13.321642 22509476222784 run_lib.py:146] step: 360600, eval_loss: 3.77632e-02
I0211 11:22:31.884477 22509476222784 run_lib.py:133] step: 360650, training_loss: 3.77005e-02
I0211 11:22:50.435504 22509476222784 run_lib.py:133] step: 360700, training_loss: 4.64808e-02
I0211 11:22:50.599406 22509476222784 run_lib.py:146] step: 360700, eval_loss: 3.61205e-02
I0211 11:23:09.285800 22509476222784 run_lib.py:133] step: 360750, training_loss: 4.65839e-02
I0211 11:23:27.848229 22509476222784 run_lib.py:133] step: 360800, training_loss: 3.44346e-02
I0211 11:23:28.011908 22509476222784 run_lib.py:146] step: 360800, eval_loss: 3.81621e-02
I0211 11:23:46.793305 22509476222784 run_lib.py:133] step: 360850, training_loss: 4.02695e-02
I0211 11:24:05.328658 22509476222784 run_lib.py:133] step: 360900, training_loss: 3.83105e-02
I0211 11:24:05.491659 22509476222784 run_lib.py:146] step: 360900, eval_loss: 4.00334e-02
I0211 11:24:24.152027 22509476222784 run_lib.py:133] step: 360950, training_loss: 4.87877e-02
I0211 11:24:42.730669 22509476222784 run_lib.py:133] step: 361000, training_loss: 5.66524e-02
I0211 11:24:42.916877 22509476222784 run_lib.py:146] step: 361000, eval_loss: 3.44352e-02
I0211 11:25:01.468131 22509476222784 run_lib.py:133] step: 361050, training_loss: 5.32267e-02
I0211 11:25:20.256577 22509476222784 run_lib.py:133] step: 361100, training_loss: 4.24112e-02
I0211 11:25:20.468861 22509476222784 run_lib.py:146] step: 361100, eval_loss: 3.86238e-02
I0211 11:25:38.944965 22509476222784 run_lib.py:133] step: 361150, training_loss: 4.92718e-02
I0211 11:25:57.633076 22509476222784 run_lib.py:133] step: 361200, training_loss: 4.86139e-02
I0211 11:25:57.820801 22509476222784 run_lib.py:146] step: 361200, eval_loss: 4.72079e-02
I0211 11:26:16.386963 22509476222784 run_lib.py:133] step: 361250, training_loss: 3.41594e-02
I0211 11:26:34.906430 22509476222784 run_lib.py:133] step: 361300, training_loss: 5.72598e-02
I0211 11:26:35.067650 22509476222784 run_lib.py:146] step: 361300, eval_loss: 4.53922e-02
I0211 11:26:53.788068 22509476222784 run_lib.py:133] step: 361350, training_loss: 4.96636e-02
I0211 11:27:12.376958 22509476222784 run_lib.py:133] step: 361400, training_loss: 6.70849e-02
I0211 11:27:12.558981 22509476222784 run_lib.py:146] step: 361400, eval_loss: 3.80162e-02
I0211 11:27:31.111631 22509476222784 run_lib.py:133] step: 361450, training_loss: 4.46344e-02
I0211 11:27:49.855064 22509476222784 run_lib.py:133] step: 361500, training_loss: 4.58936e-02
I0211 11:27:50.022005 22509476222784 run_lib.py:146] step: 361500, eval_loss: 4.49703e-02
I0211 11:28:08.553649 22509476222784 run_lib.py:133] step: 361550, training_loss: 4.56967e-02
I0211 11:28:27.075004 22509476222784 run_lib.py:133] step: 361600, training_loss: 2.84917e-02
I0211 11:28:27.402709 22509476222784 run_lib.py:146] step: 361600, eval_loss: 5.71804e-02
I0211 11:28:45.940008 22509476222784 run_lib.py:133] step: 361650, training_loss: 4.93182e-02
I0211 11:29:04.519915 22509476222784 run_lib.py:133] step: 361700, training_loss: 3.98632e-02
I0211 11:29:04.684479 22509476222784 run_lib.py:146] step: 361700, eval_loss: 4.96604e-02
I0211 11:29:23.214776 22509476222784 run_lib.py:133] step: 361750, training_loss: 5.29931e-02
I0211 11:29:41.748183 22509476222784 run_lib.py:133] step: 361800, training_loss: 5.33275e-02
I0211 11:29:41.909727 22509476222784 run_lib.py:146] step: 361800, eval_loss: 4.51900e-02
I0211 11:30:00.607789 22509476222784 run_lib.py:133] step: 361850, training_loss: 4.39322e-02
I0211 11:30:19.253768 22509476222784 run_lib.py:133] step: 361900, training_loss: 4.18908e-02
I0211 11:30:19.428191 22509476222784 run_lib.py:146] step: 361900, eval_loss: 4.21108e-02
I0211 11:30:37.986125 22509476222784 run_lib.py:133] step: 361950, training_loss: 5.32730e-02
I0211 11:30:56.537794 22509476222784 run_lib.py:133] step: 362000, training_loss: 3.93449e-02
I0211 11:30:56.718606 22509476222784 run_lib.py:146] step: 362000, eval_loss: 3.23033e-02
I0211 11:31:15.380891 22509476222784 run_lib.py:133] step: 362050, training_loss: 3.00283e-02
I0211 11:31:33.961903 22509476222784 run_lib.py:133] step: 362100, training_loss: 3.98041e-02
I0211 11:31:34.126577 22509476222784 run_lib.py:146] step: 362100, eval_loss: 3.56459e-02
I0211 11:31:52.629599 22509476222784 run_lib.py:133] step: 362150, training_loss: 5.15037e-02
I0211 11:32:11.213404 22509476222784 run_lib.py:133] step: 362200, training_loss: 4.22331e-02
I0211 11:32:11.377707 22509476222784 run_lib.py:146] step: 362200, eval_loss: 5.60156e-02
I0211 11:32:30.085828 22509476222784 run_lib.py:133] step: 362250, training_loss: 3.17134e-02
I0211 11:32:48.566858 22509476222784 run_lib.py:133] step: 362300, training_loss: 4.09986e-02
I0211 11:32:48.728790 22509476222784 run_lib.py:146] step: 362300, eval_loss: 4.36108e-02
I0211 11:33:07.354187 22509476222784 run_lib.py:133] step: 362350, training_loss: 3.73861e-02
I0211 11:33:25.853771 22509476222784 run_lib.py:133] step: 362400, training_loss: 4.26731e-02
I0211 11:33:26.020699 22509476222784 run_lib.py:146] step: 362400, eval_loss: 3.62123e-02
I0211 11:33:44.705117 22509476222784 run_lib.py:133] step: 362450, training_loss: 4.52379e-02
I0211 11:34:03.270647 22509476222784 run_lib.py:133] step: 362500, training_loss: 5.37271e-02
I0211 11:34:03.453693 22509476222784 run_lib.py:146] step: 362500, eval_loss: 6.19228e-02
I0211 11:34:21.960194 22509476222784 run_lib.py:133] step: 362550, training_loss: 4.55545e-02
I0211 11:34:40.764708 22509476222784 run_lib.py:133] step: 362600, training_loss: 3.55396e-02
I0211 11:34:40.946770 22509476222784 run_lib.py:146] step: 362600, eval_loss: 3.38884e-02
I0211 11:34:59.536541 22509476222784 run_lib.py:133] step: 362650, training_loss: 5.44812e-02
I0211 11:35:18.217734 22509476222784 run_lib.py:133] step: 362700, training_loss: 4.30792e-02
I0211 11:35:18.380870 22509476222784 run_lib.py:146] step: 362700, eval_loss: 4.24218e-02
I0211 11:35:36.940421 22509476222784 run_lib.py:133] step: 362750, training_loss: 4.36016e-02
I0211 11:35:55.457904 22509476222784 run_lib.py:133] step: 362800, training_loss: 4.34203e-02
I0211 11:35:55.620802 22509476222784 run_lib.py:146] step: 362800, eval_loss: 4.01483e-02
I0211 11:36:14.166393 22509476222784 run_lib.py:133] step: 362850, training_loss: 5.12473e-02
I0211 11:36:32.919643 22509476222784 run_lib.py:133] step: 362900, training_loss: 4.20440e-02
I0211 11:36:33.096854 22509476222784 run_lib.py:146] step: 362900, eval_loss: 5.59737e-02
I0211 11:36:51.618538 22509476222784 run_lib.py:133] step: 362950, training_loss: 3.63844e-02
I0211 11:37:10.162361 22509476222784 run_lib.py:133] step: 363000, training_loss: 5.14149e-02
I0211 11:37:10.345309 22509476222784 run_lib.py:146] step: 363000, eval_loss: 4.47161e-02
I0211 11:37:29.100131 22509476222784 run_lib.py:133] step: 363050, training_loss: 3.88599e-02
I0211 11:37:47.662501 22509476222784 run_lib.py:133] step: 363100, training_loss: 5.31990e-02
I0211 11:37:47.826914 22509476222784 run_lib.py:146] step: 363100, eval_loss: 4.12118e-02
I0211 11:38:06.390601 22509476222784 run_lib.py:133] step: 363150, training_loss: 4.34132e-02
I0211 11:38:24.826539 22509476222784 run_lib.py:133] step: 363200, training_loss: 4.25192e-02
I0211 11:38:24.982530 22509476222784 run_lib.py:146] step: 363200, eval_loss: 4.48160e-02
I0211 11:38:43.380359 22509476222784 run_lib.py:133] step: 363250, training_loss: 4.68849e-02
I0211 11:39:01.933786 22509476222784 run_lib.py:133] step: 363300, training_loss: 4.47796e-02
I0211 11:39:02.115904 22509476222784 run_lib.py:146] step: 363300, eval_loss: 4.14191e-02
I0211 11:39:20.841822 22509476222784 run_lib.py:133] step: 363350, training_loss: 5.90474e-02
I0211 11:39:39.459393 22509476222784 run_lib.py:133] step: 363400, training_loss: 3.66331e-02
I0211 11:39:39.624812 22509476222784 run_lib.py:146] step: 363400, eval_loss: 4.26550e-02
I0211 11:39:58.165135 22509476222784 run_lib.py:133] step: 363450, training_loss: 5.70189e-02
I0211 11:40:16.680966 22509476222784 run_lib.py:133] step: 363500, training_loss: 3.93687e-02
I0211 11:40:16.841933 22509476222784 run_lib.py:146] step: 363500, eval_loss: 4.28452e-02
I0211 11:40:35.538634 22509476222784 run_lib.py:133] step: 363550, training_loss: 4.80944e-02
I0211 11:40:54.131505 22509476222784 run_lib.py:133] step: 363600, training_loss: 4.00019e-02
I0211 11:40:54.322849 22509476222784 run_lib.py:146] step: 363600, eval_loss: 4.40661e-02
I0211 11:41:13.055214 22509476222784 run_lib.py:133] step: 363650, training_loss: 3.67678e-02
I0211 11:41:31.535898 22509476222784 run_lib.py:133] step: 363700, training_loss: 3.81548e-02
I0211 11:41:31.697616 22509476222784 run_lib.py:146] step: 363700, eval_loss: 4.30314e-02
I0211 11:41:50.365793 22509476222784 run_lib.py:133] step: 363750, training_loss: 4.15666e-02
I0211 11:42:08.909187 22509476222784 run_lib.py:133] step: 363800, training_loss: 3.43627e-02
I0211 11:42:09.120718 22509476222784 run_lib.py:146] step: 363800, eval_loss: 5.07646e-02
I0211 11:42:27.957044 22509476222784 run_lib.py:133] step: 363850, training_loss: 4.79277e-02
I0211 11:42:46.546623 22509476222784 run_lib.py:133] step: 363900, training_loss: 4.26000e-02
I0211 11:42:46.711746 22509476222784 run_lib.py:146] step: 363900, eval_loss: 3.95003e-02
I0211 11:43:05.276580 22509476222784 run_lib.py:133] step: 363950, training_loss: 4.57764e-02
I0211 11:43:23.972771 22509476222784 run_lib.py:133] step: 364000, training_loss: 5.39536e-02
I0211 11:43:24.152679 22509476222784 run_lib.py:146] step: 364000, eval_loss: 6.01620e-02
I0211 11:43:42.706624 22509476222784 run_lib.py:133] step: 364050, training_loss: 3.42924e-02
I0211 11:44:01.308050 22509476222784 run_lib.py:133] step: 364100, training_loss: 5.13980e-02
I0211 11:44:01.472809 22509476222784 run_lib.py:146] step: 364100, eval_loss: 3.78039e-02
I0211 11:44:20.186765 22509476222784 run_lib.py:133] step: 364150, training_loss: 4.51600e-02
I0211 11:44:38.898255 22509476222784 run_lib.py:133] step: 364200, training_loss: 5.95781e-02
I0211 11:44:39.058471 22509476222784 run_lib.py:146] step: 364200, eval_loss: 3.12795e-02
I0211 11:44:57.508099 22509476222784 run_lib.py:133] step: 364250, training_loss: 4.06721e-02
I0211 11:45:15.928148 22509476222784 run_lib.py:133] step: 364300, training_loss: 4.03628e-02
I0211 11:45:16.094001 22509476222784 run_lib.py:146] step: 364300, eval_loss: 4.07133e-02
I0211 11:45:34.638970 22509476222784 run_lib.py:133] step: 364350, training_loss: 3.13658e-02
I0211 11:45:53.394171 22509476222784 run_lib.py:133] step: 364400, training_loss: 4.98857e-02
I0211 11:45:53.561798 22509476222784 run_lib.py:146] step: 364400, eval_loss: 3.36653e-02
I0211 11:46:12.161616 22509476222784 run_lib.py:133] step: 364450, training_loss: 3.91575e-02
I0211 11:46:30.714907 22509476222784 run_lib.py:133] step: 364500, training_loss: 3.94809e-02
I0211 11:46:30.883767 22509476222784 run_lib.py:146] step: 364500, eval_loss: 5.01624e-02
I0211 11:46:49.417207 22509476222784 run_lib.py:133] step: 364550, training_loss: 4.22481e-02
I0211 11:47:08.171496 22509476222784 run_lib.py:133] step: 364600, training_loss: 4.28606e-02
I0211 11:47:08.334510 22509476222784 run_lib.py:146] step: 364600, eval_loss: 4.04373e-02
I0211 11:47:26.966912 22509476222784 run_lib.py:133] step: 364650, training_loss: 4.00472e-02
I0211 11:47:45.653558 22509476222784 run_lib.py:133] step: 364700, training_loss: 2.90333e-02
I0211 11:47:45.822981 22509476222784 run_lib.py:146] step: 364700, eval_loss: 5.90586e-02
I0211 11:48:04.344634 22509476222784 run_lib.py:133] step: 364750, training_loss: 3.85200e-02
I0211 11:48:22.879871 22509476222784 run_lib.py:133] step: 364800, training_loss: 3.35982e-02
I0211 11:48:23.045938 22509476222784 run_lib.py:146] step: 364800, eval_loss: 3.69610e-02
I0211 11:48:41.736335 22509476222784 run_lib.py:133] step: 364850, training_loss: 4.18678e-02
I0211 11:49:00.399680 22509476222784 run_lib.py:133] step: 364900, training_loss: 3.31706e-02
I0211 11:49:00.575555 22509476222784 run_lib.py:146] step: 364900, eval_loss: 4.82071e-02
I0211 11:49:19.100553 22509476222784 run_lib.py:133] step: 364950, training_loss: 4.10658e-02
I0211 11:49:37.601816 22509476222784 run_lib.py:133] step: 365000, training_loss: 4.00317e-02
I0211 11:49:37.765817 22509476222784 run_lib.py:146] step: 365000, eval_loss: 3.37294e-02
I0211 11:49:56.493009 22509476222784 run_lib.py:133] step: 365050, training_loss: 5.02317e-02
I0211 11:50:14.955240 22509476222784 run_lib.py:133] step: 365100, training_loss: 3.73259e-02
I0211 11:50:15.115735 22509476222784 run_lib.py:146] step: 365100, eval_loss: 6.04928e-02
I0211 11:50:33.804794 22509476222784 run_lib.py:133] step: 365150, training_loss: 4.91652e-02
I0211 11:50:52.401053 22509476222784 run_lib.py:133] step: 365200, training_loss: 4.15938e-02
I0211 11:50:52.595792 22509476222784 run_lib.py:146] step: 365200, eval_loss: 4.36416e-02
I0211 11:51:11.363373 22509476222784 run_lib.py:133] step: 365250, training_loss: 3.61109e-02
I0211 11:51:29.837193 22509476222784 run_lib.py:133] step: 365300, training_loss: 4.31916e-02
I0211 11:51:30.001516 22509476222784 run_lib.py:146] step: 365300, eval_loss: 4.13665e-02
I0211 11:51:48.451036 22509476222784 run_lib.py:133] step: 365350, training_loss: 3.80013e-02
I0211 11:52:07.100653 22509476222784 run_lib.py:133] step: 365400, training_loss: 4.61469e-02
I0211 11:52:07.264697 22509476222784 run_lib.py:146] step: 365400, eval_loss: 4.44179e-02
I0211 11:52:25.796280 22509476222784 run_lib.py:133] step: 365450, training_loss: 3.63497e-02
I0211 11:52:44.524633 22509476222784 run_lib.py:133] step: 365500, training_loss: 2.83683e-02
I0211 11:52:44.688404 22509476222784 run_lib.py:146] step: 365500, eval_loss: 4.25088e-02
I0211 11:53:03.248570 22509476222784 run_lib.py:133] step: 365550, training_loss: 5.13507e-02
I0211 11:53:21.776663 22509476222784 run_lib.py:133] step: 365600, training_loss: 4.41051e-02
I0211 11:53:21.939903 22509476222784 run_lib.py:146] step: 365600, eval_loss: 4.00610e-02
I0211 11:53:40.697847 22509476222784 run_lib.py:133] step: 365650, training_loss: 4.75354e-02
I0211 11:53:59.279117 22509476222784 run_lib.py:133] step: 365700, training_loss: 3.78914e-02
I0211 11:53:59.450931 22509476222784 run_lib.py:146] step: 365700, eval_loss: 3.99139e-02
I0211 11:54:18.053498 22509476222784 run_lib.py:133] step: 365750, training_loss: 4.28907e-02
I0211 11:54:36.831099 22509476222784 run_lib.py:133] step: 365800, training_loss: 4.06572e-02
I0211 11:54:36.998889 22509476222784 run_lib.py:146] step: 365800, eval_loss: 4.66271e-02
I0211 11:54:55.513071 22509476222784 run_lib.py:133] step: 365850, training_loss: 3.60018e-02
I0211 11:55:14.108850 22509476222784 run_lib.py:133] step: 365900, training_loss: 4.84747e-02
I0211 11:55:14.277682 22509476222784 run_lib.py:146] step: 365900, eval_loss: 4.79517e-02
I0211 11:55:32.857030 22509476222784 run_lib.py:133] step: 365950, training_loss: 4.37022e-02
I0211 11:55:51.467641 22509476222784 run_lib.py:133] step: 366000, training_loss: 4.54997e-02
I0211 11:55:51.633893 22509476222784 run_lib.py:146] step: 366000, eval_loss: 4.07351e-02
I0211 11:56:10.219979 22509476222784 run_lib.py:133] step: 366050, training_loss: 4.57389e-02
I0211 11:56:28.764403 22509476222784 run_lib.py:133] step: 366100, training_loss: 5.16043e-02
I0211 11:56:28.930638 22509476222784 run_lib.py:146] step: 366100, eval_loss: 5.26834e-02
I0211 11:56:47.678199 22509476222784 run_lib.py:133] step: 366150, training_loss: 4.86145e-02
I0211 11:57:06.320989 22509476222784 run_lib.py:133] step: 366200, training_loss: 4.90787e-02
I0211 11:57:06.492807 22509476222784 run_lib.py:146] step: 366200, eval_loss: 4.73357e-02
I0211 11:57:25.079422 22509476222784 run_lib.py:133] step: 366250, training_loss: 4.20732e-02
I0211 11:57:43.639668 22509476222784 run_lib.py:133] step: 366300, training_loss: 3.93407e-02
I0211 11:57:43.807612 22509476222784 run_lib.py:146] step: 366300, eval_loss: 4.64252e-02
I0211 11:58:02.454973 22509476222784 run_lib.py:133] step: 366350, training_loss: 4.01086e-02
I0211 11:58:21.017317 22509476222784 run_lib.py:133] step: 366400, training_loss: 4.08726e-02
I0211 11:58:21.183438 22509476222784 run_lib.py:146] step: 366400, eval_loss: 3.61279e-02
I0211 11:58:39.848353 22509476222784 run_lib.py:133] step: 366450, training_loss: 3.84861e-02
I0211 11:58:58.418434 22509476222784 run_lib.py:133] step: 366500, training_loss: 4.08915e-02
I0211 11:58:58.600373 22509476222784 run_lib.py:146] step: 366500, eval_loss: 4.14180e-02
I0211 11:59:17.394719 22509476222784 run_lib.py:133] step: 366550, training_loss: 4.48155e-02
I0211 11:59:35.933493 22509476222784 run_lib.py:133] step: 366600, training_loss: 3.13624e-02
I0211 11:59:36.106218 22509476222784 run_lib.py:146] step: 366600, eval_loss: 4.30749e-02
I0211 11:59:54.806583 22509476222784 run_lib.py:133] step: 366650, training_loss: 4.20403e-02
I0211 12:00:13.366047 22509476222784 run_lib.py:133] step: 366700, training_loss: 3.31840e-02
I0211 12:00:13.532925 22509476222784 run_lib.py:146] step: 366700, eval_loss: 3.41930e-02
I0211 12:00:32.049589 22509476222784 run_lib.py:133] step: 366750, training_loss: 3.96587e-02
I0211 12:00:50.825095 22509476222784 run_lib.py:133] step: 366800, training_loss: 3.82192e-02
I0211 12:00:51.015022 22509476222784 run_lib.py:146] step: 366800, eval_loss: 4.43823e-02
I0211 12:01:09.539257 22509476222784 run_lib.py:133] step: 366850, training_loss: 4.82646e-02
I0211 12:01:28.074794 22509476222784 run_lib.py:133] step: 366900, training_loss: 3.72751e-02
I0211 12:01:28.276842 22509476222784 run_lib.py:146] step: 366900, eval_loss: 4.97573e-02
I0211 12:01:47.009525 22509476222784 run_lib.py:133] step: 366950, training_loss: 5.35673e-02
I0211 12:02:05.596240 22509476222784 run_lib.py:133] step: 367000, training_loss: 3.57570e-02
I0211 12:02:05.759601 22509476222784 run_lib.py:146] step: 367000, eval_loss: 4.01932e-02
I0211 12:02:24.434403 22509476222784 run_lib.py:133] step: 367050, training_loss: 4.69889e-02
I0211 12:02:42.988408 22509476222784 run_lib.py:133] step: 367100, training_loss: 3.08080e-02
I0211 12:02:43.165954 22509476222784 run_lib.py:146] step: 367100, eval_loss: 3.06339e-02
I0211 12:03:01.738286 22509476222784 run_lib.py:133] step: 367150, training_loss: 4.58911e-02
I0211 12:03:20.476794 22509476222784 run_lib.py:133] step: 367200, training_loss: 3.83041e-02
I0211 12:03:20.643666 22509476222784 run_lib.py:146] step: 367200, eval_loss: 3.28632e-02
I0211 12:03:39.156978 22509476222784 run_lib.py:133] step: 367250, training_loss: 3.27438e-02
I0211 12:03:57.682018 22509476222784 run_lib.py:133] step: 367300, training_loss: 4.62913e-02
I0211 12:03:57.849509 22509476222784 run_lib.py:146] step: 367300, eval_loss: 4.32266e-02
I0211 12:04:16.335901 22509476222784 run_lib.py:133] step: 367350, training_loss: 4.39723e-02
I0211 12:04:35.028396 22509476222784 run_lib.py:133] step: 367400, training_loss: 3.91137e-02
I0211 12:04:35.193912 22509476222784 run_lib.py:146] step: 367400, eval_loss: 4.63881e-02
I0211 12:04:53.829221 22509476222784 run_lib.py:133] step: 367450, training_loss: 3.66481e-02
I0211 12:05:12.504423 22509476222784 run_lib.py:133] step: 367500, training_loss: 4.68267e-02
I0211 12:05:12.689705 22509476222784 run_lib.py:146] step: 367500, eval_loss: 4.16079e-02
I0211 12:05:31.218891 22509476222784 run_lib.py:133] step: 367550, training_loss: 3.25219e-02
I0211 12:05:49.796772 22509476222784 run_lib.py:133] step: 367600, training_loss: 4.32380e-02
I0211 12:05:49.995683 22509476222784 run_lib.py:146] step: 367600, eval_loss: 4.11885e-02
I0211 12:06:08.679842 22509476222784 run_lib.py:133] step: 367650, training_loss: 5.72717e-02
I0211 12:06:27.401875 22509476222784 run_lib.py:133] step: 367700, training_loss: 4.79253e-02
I0211 12:06:27.587826 22509476222784 run_lib.py:146] step: 367700, eval_loss: 4.71397e-02
I0211 12:06:46.121412 22509476222784 run_lib.py:133] step: 367750, training_loss: 3.41323e-02
I0211 12:07:04.645750 22509476222784 run_lib.py:133] step: 367800, training_loss: 4.04882e-02
I0211 12:07:04.809796 22509476222784 run_lib.py:146] step: 367800, eval_loss: 4.98648e-02
I0211 12:07:23.497507 22509476222784 run_lib.py:133] step: 367850, training_loss: 4.21579e-02
I0211 12:07:42.058359 22509476222784 run_lib.py:133] step: 367900, training_loss: 5.18538e-02
I0211 12:07:42.222821 22509476222784 run_lib.py:146] step: 367900, eval_loss: 5.03757e-02
I0211 12:08:01.006658 22509476222784 run_lib.py:133] step: 367950, training_loss: 5.20592e-02
I0211 12:08:19.587805 22509476222784 run_lib.py:133] step: 368000, training_loss: 3.97164e-02
I0211 12:08:19.750660 22509476222784 run_lib.py:146] step: 368000, eval_loss: 4.89027e-02
I0211 12:08:38.466231 22509476222784 run_lib.py:133] step: 368050, training_loss: 5.14254e-02
I0211 12:08:57.075271 22509476222784 run_lib.py:133] step: 368100, training_loss: 4.59359e-02
I0211 12:08:57.267980 22509476222784 run_lib.py:146] step: 368100, eval_loss: 5.21624e-02
I0211 12:09:15.851245 22509476222784 run_lib.py:133] step: 368150, training_loss: 5.97196e-02
I0211 12:09:34.572813 22509476222784 run_lib.py:133] step: 368200, training_loss: 3.19976e-02
I0211 12:09:34.739865 22509476222784 run_lib.py:146] step: 368200, eval_loss: 4.58806e-02
I0211 12:09:53.277431 22509476222784 run_lib.py:133] step: 368250, training_loss: 4.74617e-02
I0211 12:10:11.974652 22509476222784 run_lib.py:133] step: 368300, training_loss: 4.27747e-02
I0211 12:10:12.139807 22509476222784 run_lib.py:146] step: 368300, eval_loss: 4.94755e-02
I0211 12:10:30.628643 22509476222784 run_lib.py:133] step: 368350, training_loss: 4.38364e-02
I0211 12:10:49.056131 22509476222784 run_lib.py:133] step: 368400, training_loss: 4.14456e-02
I0211 12:10:49.230471 22509476222784 run_lib.py:146] step: 368400, eval_loss: 3.87688e-02
I0211 12:11:07.849350 22509476222784 run_lib.py:133] step: 368450, training_loss: 4.17907e-02
I0211 12:11:26.405521 22509476222784 run_lib.py:133] step: 368500, training_loss: 3.67687e-02
I0211 12:11:26.576000 22509476222784 run_lib.py:146] step: 368500, eval_loss: 4.38886e-02
I0211 12:11:45.110141 22509476222784 run_lib.py:133] step: 368550, training_loss: 3.51626e-02
I0211 12:12:03.877532 22509476222784 run_lib.py:133] step: 368600, training_loss: 4.65533e-02
I0211 12:12:04.080898 22509476222784 run_lib.py:146] step: 368600, eval_loss: 5.69446e-02
I0211 12:12:22.599355 22509476222784 run_lib.py:133] step: 368650, training_loss: 5.46134e-02
I0211 12:12:41.152288 22509476222784 run_lib.py:133] step: 368700, training_loss: 5.08609e-02
I0211 12:12:41.471567 22509476222784 run_lib.py:146] step: 368700, eval_loss: 4.14581e-02
I0211 12:13:00.004279 22509476222784 run_lib.py:133] step: 368750, training_loss: 4.41589e-02
I0211 12:13:18.590940 22509476222784 run_lib.py:133] step: 368800, training_loss: 4.95226e-02
I0211 12:13:18.784878 22509476222784 run_lib.py:146] step: 368800, eval_loss: 4.16938e-02
I0211 12:13:37.334428 22509476222784 run_lib.py:133] step: 368850, training_loss: 5.14675e-02
I0211 12:13:55.827170 22509476222784 run_lib.py:133] step: 368900, training_loss: 4.09765e-02
I0211 12:13:55.995779 22509476222784 run_lib.py:146] step: 368900, eval_loss: 2.75761e-02
I0211 12:14:14.719157 22509476222784 run_lib.py:133] step: 368950, training_loss: 3.61839e-02
I0211 12:14:33.321360 22509476222784 run_lib.py:133] step: 369000, training_loss: 3.64918e-02
I0211 12:14:33.487613 22509476222784 run_lib.py:146] step: 369000, eval_loss: 4.08292e-02
I0211 12:14:52.079261 22509476222784 run_lib.py:133] step: 369050, training_loss: 2.96186e-02
I0211 12:15:10.714006 22509476222784 run_lib.py:133] step: 369100, training_loss: 4.05791e-02
I0211 12:15:10.881648 22509476222784 run_lib.py:146] step: 369100, eval_loss: 4.34581e-02
I0211 12:15:29.566550 22509476222784 run_lib.py:133] step: 369150, training_loss: 3.47340e-02
I0211 12:15:48.179717 22509476222784 run_lib.py:133] step: 369200, training_loss: 4.79921e-02
I0211 12:15:48.385587 22509476222784 run_lib.py:146] step: 369200, eval_loss: 4.27891e-02
I0211 12:16:06.935442 22509476222784 run_lib.py:133] step: 369250, training_loss: 4.18505e-02
I0211 12:16:25.468085 22509476222784 run_lib.py:133] step: 369300, training_loss: 4.84763e-02
I0211 12:16:25.633952 22509476222784 run_lib.py:146] step: 369300, eval_loss: 5.53557e-02
I0211 12:16:44.383014 22509476222784 run_lib.py:133] step: 369350, training_loss: 4.36005e-02
I0211 12:17:02.898497 22509476222784 run_lib.py:133] step: 369400, training_loss: 3.06193e-02
I0211 12:17:03.059625 22509476222784 run_lib.py:146] step: 369400, eval_loss: 4.57294e-02
I0211 12:17:21.751893 22509476222784 run_lib.py:133] step: 369450, training_loss: 3.72633e-02
I0211 12:17:40.288140 22509476222784 run_lib.py:133] step: 369500, training_loss: 3.96169e-02
I0211 12:17:40.453435 22509476222784 run_lib.py:146] step: 369500, eval_loss: 3.42223e-02
I0211 12:17:59.165775 22509476222784 run_lib.py:133] step: 369550, training_loss: 3.55409e-02
I0211 12:18:17.731543 22509476222784 run_lib.py:133] step: 369600, training_loss: 5.72176e-02
I0211 12:18:17.913756 22509476222784 run_lib.py:146] step: 369600, eval_loss: 3.41399e-02
I0211 12:18:36.469284 22509476222784 run_lib.py:133] step: 369650, training_loss: 3.98711e-02
I0211 12:18:55.216302 22509476222784 run_lib.py:133] step: 369700, training_loss: 4.58921e-02
I0211 12:18:55.381873 22509476222784 run_lib.py:146] step: 369700, eval_loss: 3.47788e-02
I0211 12:19:13.903416 22509476222784 run_lib.py:133] step: 369750, training_loss: 4.49319e-02
I0211 12:19:32.569503 22509476222784 run_lib.py:133] step: 369800, training_loss: 4.70297e-02
I0211 12:19:32.732618 22509476222784 run_lib.py:146] step: 369800, eval_loss: 3.31549e-02
I0211 12:19:51.223799 22509476222784 run_lib.py:133] step: 369850, training_loss: 5.75343e-02
I0211 12:20:09.834121 22509476222784 run_lib.py:133] step: 369900, training_loss: 3.80624e-02
I0211 12:20:10.011852 22509476222784 run_lib.py:146] step: 369900, eval_loss: 4.77162e-02
I0211 12:20:28.540392 22509476222784 run_lib.py:133] step: 369950, training_loss: 5.26490e-02
I0211 12:20:47.266131 22509476222784 run_lib.py:133] step: 370000, training_loss: 3.63651e-02
I0211 12:20:48.008382 22509476222784 run_lib.py:146] step: 370000, eval_loss: 4.38446e-02
I0211 12:21:09.326906 22509476222784 run_lib.py:133] step: 370050, training_loss: 3.83064e-02
I0211 12:21:27.924437 22509476222784 run_lib.py:133] step: 370100, training_loss: 3.38548e-02
I0211 12:21:28.092679 22509476222784 run_lib.py:146] step: 370100, eval_loss: 4.36959e-02
I0211 12:21:46.618284 22509476222784 run_lib.py:133] step: 370150, training_loss: 3.60272e-02
I0211 12:22:05.202091 22509476222784 run_lib.py:133] step: 370200, training_loss: 4.09148e-02
I0211 12:22:05.418909 22509476222784 run_lib.py:146] step: 370200, eval_loss: 5.26994e-02
I0211 12:22:24.144513 22509476222784 run_lib.py:133] step: 370250, training_loss: 3.48894e-02
I0211 12:22:42.632603 22509476222784 run_lib.py:133] step: 370300, training_loss: 4.33663e-02
I0211 12:22:42.796647 22509476222784 run_lib.py:146] step: 370300, eval_loss: 4.05749e-02
I0211 12:23:01.447495 22509476222784 run_lib.py:133] step: 370350, training_loss: 5.03896e-02
I0211 12:23:19.971257 22509476222784 run_lib.py:133] step: 370400, training_loss: 3.52182e-02
I0211 12:23:20.287708 22509476222784 run_lib.py:146] step: 370400, eval_loss: 4.64928e-02
I0211 12:23:39.082215 22509476222784 run_lib.py:133] step: 370450, training_loss: 4.64463e-02
I0211 12:23:57.557941 22509476222784 run_lib.py:133] step: 370500, training_loss: 2.97700e-02
I0211 12:23:57.722691 22509476222784 run_lib.py:146] step: 370500, eval_loss: 4.29378e-02
I0211 12:24:16.320544 22509476222784 run_lib.py:133] step: 370550, training_loss: 3.36289e-02
I0211 12:24:34.783950 22509476222784 run_lib.py:133] step: 370600, training_loss: 3.15472e-02
I0211 12:24:34.945888 22509476222784 run_lib.py:146] step: 370600, eval_loss: 4.45723e-02
I0211 12:24:53.423575 22509476222784 run_lib.py:133] step: 370650, training_loss: 5.17592e-02
I0211 12:25:12.225783 22509476222784 run_lib.py:133] step: 370700, training_loss: 4.00764e-02
I0211 12:25:12.428898 22509476222784 run_lib.py:146] step: 370700, eval_loss: 5.03292e-02
I0211 12:25:30.978310 22509476222784 run_lib.py:133] step: 370750, training_loss: 3.83499e-02
I0211 12:25:49.478101 22509476222784 run_lib.py:133] step: 370800, training_loss: 4.58885e-02
I0211 12:25:49.642515 22509476222784 run_lib.py:146] step: 370800, eval_loss: 4.80569e-02
I0211 12:26:08.348228 22509476222784 run_lib.py:133] step: 370850, training_loss: 4.08202e-02
I0211 12:26:27.024286 22509476222784 run_lib.py:133] step: 370900, training_loss: 4.53612e-02
I0211 12:26:27.181000 22509476222784 run_lib.py:146] step: 370900, eval_loss: 4.09593e-02
I0211 12:26:45.705738 22509476222784 run_lib.py:133] step: 370950, training_loss: 5.78219e-02
I0211 12:27:04.230878 22509476222784 run_lib.py:133] step: 371000, training_loss: 4.49969e-02
I0211 12:27:04.404667 22509476222784 run_lib.py:146] step: 371000, eval_loss: 4.78086e-02
I0211 12:27:22.961035 22509476222784 run_lib.py:133] step: 371050, training_loss: 4.06955e-02
I0211 12:27:41.640398 22509476222784 run_lib.py:133] step: 371100, training_loss: 4.77187e-02
I0211 12:27:41.806921 22509476222784 run_lib.py:146] step: 371100, eval_loss: 3.96291e-02
I0211 12:28:00.326517 22509476222784 run_lib.py:133] step: 371150, training_loss: 4.62371e-02
I0211 12:28:18.855429 22509476222784 run_lib.py:133] step: 371200, training_loss: 3.81751e-02
I0211 12:28:19.030852 22509476222784 run_lib.py:146] step: 371200, eval_loss: 4.34270e-02
I0211 12:28:37.629750 22509476222784 run_lib.py:133] step: 371250, training_loss: 3.66164e-02
I0211 12:28:56.363271 22509476222784 run_lib.py:133] step: 371300, training_loss: 3.96528e-02
I0211 12:28:56.527887 22509476222784 run_lib.py:146] step: 371300, eval_loss: 4.16018e-02
I0211 12:29:15.123903 22509476222784 run_lib.py:133] step: 371350, training_loss: 4.57428e-02
I0211 12:29:33.685028 22509476222784 run_lib.py:133] step: 371400, training_loss: 3.57508e-02
I0211 12:29:33.845595 22509476222784 run_lib.py:146] step: 371400, eval_loss: 5.14154e-02
I0211 12:29:52.350619 22509476222784 run_lib.py:133] step: 371450, training_loss: 6.04250e-02
I0211 12:30:10.900429 22509476222784 run_lib.py:133] step: 371500, training_loss: 5.08790e-02
I0211 12:30:11.080582 22509476222784 run_lib.py:146] step: 371500, eval_loss: 3.70834e-02
I0211 12:30:29.859990 22509476222784 run_lib.py:133] step: 371550, training_loss: 5.92058e-02
I0211 12:30:48.563920 22509476222784 run_lib.py:133] step: 371600, training_loss: 4.21629e-02
I0211 12:30:48.727890 22509476222784 run_lib.py:146] step: 371600, eval_loss: 5.33815e-02
I0211 12:31:07.260564 22509476222784 run_lib.py:133] step: 371650, training_loss: 4.34415e-02
I0211 12:31:25.756040 22509476222784 run_lib.py:133] step: 371700, training_loss: 4.70640e-02
I0211 12:31:25.919342 22509476222784 run_lib.py:146] step: 371700, eval_loss: 5.00923e-02
I0211 12:31:44.563776 22509476222784 run_lib.py:133] step: 371750, training_loss: 4.72200e-02
I0211 12:32:03.119528 22509476222784 run_lib.py:133] step: 371800, training_loss: 3.95269e-02
I0211 12:32:03.283134 22509476222784 run_lib.py:146] step: 371800, eval_loss: 4.46775e-02
I0211 12:32:22.020762 22509476222784 run_lib.py:133] step: 371850, training_loss: 3.44413e-02
I0211 12:32:40.530847 22509476222784 run_lib.py:133] step: 371900, training_loss: 3.28762e-02
I0211 12:32:40.756482 22509476222784 run_lib.py:146] step: 371900, eval_loss: 3.98240e-02
I0211 12:32:59.392562 22509476222784 run_lib.py:133] step: 371950, training_loss: 4.56894e-02
I0211 12:33:17.929572 22509476222784 run_lib.py:133] step: 372000, training_loss: 4.16126e-02
I0211 12:33:18.103887 22509476222784 run_lib.py:146] step: 372000, eval_loss: 4.48963e-02
I0211 12:33:36.671375 22509476222784 run_lib.py:133] step: 372050, training_loss: 3.84504e-02
I0211 12:33:55.447283 22509476222784 run_lib.py:133] step: 372100, training_loss: 3.92511e-02
I0211 12:33:55.617882 22509476222784 run_lib.py:146] step: 372100, eval_loss: 3.79424e-02
I0211 12:34:14.050849 22509476222784 run_lib.py:133] step: 372150, training_loss: 3.29259e-02
I0211 12:34:32.688074 22509476222784 run_lib.py:133] step: 372200, training_loss: 3.26852e-02
I0211 12:34:32.883649 22509476222784 run_lib.py:146] step: 372200, eval_loss: 4.07243e-02
I0211 12:34:51.393343 22509476222784 run_lib.py:133] step: 372250, training_loss: 4.93733e-02
I0211 12:35:09.898491 22509476222784 run_lib.py:133] step: 372300, training_loss: 4.51624e-02
I0211 12:35:10.065794 22509476222784 run_lib.py:146] step: 372300, eval_loss: 3.73613e-02
I0211 12:35:28.839627 22509476222784 run_lib.py:133] step: 372350, training_loss: 5.36524e-02
I0211 12:35:47.368549 22509476222784 run_lib.py:133] step: 372400, training_loss: 3.69605e-02
I0211 12:35:47.531505 22509476222784 run_lib.py:146] step: 372400, eval_loss: 3.93379e-02
I0211 12:36:06.052789 22509476222784 run_lib.py:133] step: 372450, training_loss: 5.31200e-02
I0211 12:36:24.688458 22509476222784 run_lib.py:133] step: 372500, training_loss: 4.18698e-02
I0211 12:36:24.901439 22509476222784 run_lib.py:146] step: 372500, eval_loss: 3.10649e-02
I0211 12:36:43.402968 22509476222784 run_lib.py:133] step: 372550, training_loss: 3.30795e-02
I0211 12:37:01.938504 22509476222784 run_lib.py:133] step: 372600, training_loss: 3.87403e-02
I0211 12:37:02.107390 22509476222784 run_lib.py:146] step: 372600, eval_loss: 4.56627e-02
I0211 12:37:20.706465 22509476222784 run_lib.py:133] step: 372650, training_loss: 4.37808e-02
I0211 12:37:39.216069 22509476222784 run_lib.py:133] step: 372700, training_loss: 5.27041e-02
I0211 12:37:39.378688 22509476222784 run_lib.py:146] step: 372700, eval_loss: 5.18913e-02
I0211 12:37:57.887132 22509476222784 run_lib.py:133] step: 372750, training_loss: 4.95305e-02
I0211 12:38:16.316909 22509476222784 run_lib.py:133] step: 372800, training_loss: 5.49634e-02
I0211 12:38:16.498705 22509476222784 run_lib.py:146] step: 372800, eval_loss: 4.27053e-02
I0211 12:38:35.220153 22509476222784 run_lib.py:133] step: 372850, training_loss: 2.66079e-02
I0211 12:38:53.843699 22509476222784 run_lib.py:133] step: 372900, training_loss: 4.15627e-02
I0211 12:38:54.019668 22509476222784 run_lib.py:146] step: 372900, eval_loss: 2.81279e-02
I0211 12:39:12.561150 22509476222784 run_lib.py:133] step: 372950, training_loss: 4.52516e-02
I0211 12:39:31.188033 22509476222784 run_lib.py:133] step: 373000, training_loss: 6.16517e-02
I0211 12:39:31.357621 22509476222784 run_lib.py:146] step: 373000, eval_loss: 3.88457e-02
I0211 12:39:50.046806 22509476222784 run_lib.py:133] step: 373050, training_loss: 4.23797e-02
I0211 12:40:08.593966 22509476222784 run_lib.py:133] step: 373100, training_loss: 3.82717e-02
I0211 12:40:08.757519 22509476222784 run_lib.py:146] step: 373100, eval_loss: 4.52546e-02
I0211 12:40:27.390065 22509476222784 run_lib.py:133] step: 373150, training_loss: 3.47445e-02
I0211 12:40:45.896566 22509476222784 run_lib.py:133] step: 373200, training_loss: 5.11111e-02
I0211 12:40:46.059870 22509476222784 run_lib.py:146] step: 373200, eval_loss: 4.89871e-02
I0211 12:41:04.803193 22509476222784 run_lib.py:133] step: 373250, training_loss: 5.19380e-02
I0211 12:41:23.346022 22509476222784 run_lib.py:133] step: 373300, training_loss: 5.68538e-02
I0211 12:41:23.507644 22509476222784 run_lib.py:146] step: 373300, eval_loss: 4.47889e-02
I0211 12:41:42.145955 22509476222784 run_lib.py:133] step: 373350, training_loss: 4.74463e-02
I0211 12:42:00.693548 22509476222784 run_lib.py:133] step: 373400, training_loss: 4.11146e-02
I0211 12:42:00.859885 22509476222784 run_lib.py:146] step: 373400, eval_loss: 3.09863e-02
I0211 12:42:19.331143 22509476222784 run_lib.py:133] step: 373450, training_loss: 3.97353e-02
I0211 12:42:38.028335 22509476222784 run_lib.py:133] step: 373500, training_loss: 4.54593e-02
I0211 12:42:38.202729 22509476222784 run_lib.py:146] step: 373500, eval_loss: 4.17174e-02
I0211 12:42:56.733195 22509476222784 run_lib.py:133] step: 373550, training_loss: 3.13373e-02
I0211 12:43:15.241404 22509476222784 run_lib.py:133] step: 373600, training_loss: 4.58978e-02
I0211 12:43:15.407836 22509476222784 run_lib.py:146] step: 373600, eval_loss: 4.24462e-02
I0211 12:43:34.117912 22509476222784 run_lib.py:133] step: 373650, training_loss: 4.10909e-02
I0211 12:43:52.629989 22509476222784 run_lib.py:133] step: 373700, training_loss: 4.57790e-02
I0211 12:43:52.796528 22509476222784 run_lib.py:146] step: 373700, eval_loss: 4.81391e-02
I0211 12:44:11.488025 22509476222784 run_lib.py:133] step: 373750, training_loss: 4.58739e-02
I0211 12:44:30.133974 22509476222784 run_lib.py:133] step: 373800, training_loss: 4.23805e-02
I0211 12:44:30.302707 22509476222784 run_lib.py:146] step: 373800, eval_loss: 3.74471e-02
I0211 12:44:48.817383 22509476222784 run_lib.py:133] step: 373850, training_loss: 3.10853e-02
I0211 12:45:07.588541 22509476222784 run_lib.py:133] step: 373900, training_loss: 4.62606e-02
I0211 12:45:07.754969 22509476222784 run_lib.py:146] step: 373900, eval_loss: 4.56854e-02
I0211 12:45:26.275772 22509476222784 run_lib.py:133] step: 373950, training_loss: 4.51337e-02
I0211 12:45:44.834932 22509476222784 run_lib.py:133] step: 374000, training_loss: 4.52617e-02
I0211 12:45:45.000690 22509476222784 run_lib.py:146] step: 374000, eval_loss: 4.10601e-02
I0211 12:46:03.514993 22509476222784 run_lib.py:133] step: 374050, training_loss: 3.94177e-02
I0211 12:46:22.258410 22509476222784 run_lib.py:133] step: 374100, training_loss: 3.92837e-02
I0211 12:46:22.422456 22509476222784 run_lib.py:146] step: 374100, eval_loss: 3.64621e-02
I0211 12:46:41.016582 22509476222784 run_lib.py:133] step: 374150, training_loss: 5.17684e-02
I0211 12:46:59.642413 22509476222784 run_lib.py:133] step: 374200, training_loss: 4.08854e-02
I0211 12:46:59.806593 22509476222784 run_lib.py:146] step: 374200, eval_loss: 3.52375e-02
I0211 12:47:18.298330 22509476222784 run_lib.py:133] step: 374250, training_loss: 3.48271e-02
I0211 12:47:36.841108 22509476222784 run_lib.py:133] step: 374300, training_loss: 3.35080e-02
I0211 12:47:37.036263 22509476222784 run_lib.py:146] step: 374300, eval_loss: 5.70152e-02
I0211 12:47:55.822802 22509476222784 run_lib.py:133] step: 374350, training_loss: 4.04857e-02
I0211 12:48:14.489703 22509476222784 run_lib.py:133] step: 374400, training_loss: 4.47152e-02
I0211 12:48:14.655893 22509476222784 run_lib.py:146] step: 374400, eval_loss: 3.92017e-02
I0211 12:48:33.105246 22509476222784 run_lib.py:133] step: 374450, training_loss: 3.66023e-02
I0211 12:48:51.638242 22509476222784 run_lib.py:133] step: 374500, training_loss: 3.93776e-02
I0211 12:48:51.832684 22509476222784 run_lib.py:146] step: 374500, eval_loss: 5.06979e-02
I0211 12:49:10.470741 22509476222784 run_lib.py:133] step: 374550, training_loss: 4.41283e-02
I0211 12:49:29.068300 22509476222784 run_lib.py:133] step: 374600, training_loss: 4.83053e-02
I0211 12:49:29.231409 22509476222784 run_lib.py:146] step: 374600, eval_loss: 5.08339e-02
I0211 12:49:47.949683 22509476222784 run_lib.py:133] step: 374650, training_loss: 4.08130e-02
I0211 12:50:06.502558 22509476222784 run_lib.py:133] step: 374700, training_loss: 4.00885e-02
I0211 12:50:06.667806 22509476222784 run_lib.py:146] step: 374700, eval_loss: 3.67201e-02
I0211 12:50:25.380909 22509476222784 run_lib.py:133] step: 374750, training_loss: 4.69575e-02
I0211 12:50:43.952224 22509476222784 run_lib.py:133] step: 374800, training_loss: 4.34842e-02
I0211 12:50:44.153590 22509476222784 run_lib.py:146] step: 374800, eval_loss: 2.81911e-02
I0211 12:51:02.717243 22509476222784 run_lib.py:133] step: 374850, training_loss: 4.41894e-02
I0211 12:51:21.361185 22509476222784 run_lib.py:133] step: 374900, training_loss: 3.17148e-02
I0211 12:51:21.536751 22509476222784 run_lib.py:146] step: 374900, eval_loss: 4.08399e-02
I0211 12:51:40.048323 22509476222784 run_lib.py:133] step: 374950, training_loss: 4.51782e-02
I0211 12:51:58.761960 22509476222784 run_lib.py:133] step: 375000, training_loss: 5.34649e-02
I0211 12:51:58.922974 22509476222784 run_lib.py:146] step: 375000, eval_loss: 4.24153e-02
I0211 12:52:17.393106 22509476222784 run_lib.py:133] step: 375050, training_loss: 3.80160e-02
I0211 12:52:35.914634 22509476222784 run_lib.py:133] step: 375100, training_loss: 3.12278e-02
I0211 12:52:36.211862 22509476222784 run_lib.py:146] step: 375100, eval_loss: 4.93148e-02
I0211 12:52:54.969489 22509476222784 run_lib.py:133] step: 375150, training_loss: 3.87957e-02
I0211 12:53:13.513424 22509476222784 run_lib.py:133] step: 375200, training_loss: 4.45543e-02
I0211 12:53:13.675878 22509476222784 run_lib.py:146] step: 375200, eval_loss: 5.54873e-02
I0211 12:53:32.169426 22509476222784 run_lib.py:133] step: 375250, training_loss: 6.02909e-02
I0211 12:53:50.857735 22509476222784 run_lib.py:133] step: 375300, training_loss: 3.98492e-02
I0211 12:53:51.064878 22509476222784 run_lib.py:146] step: 375300, eval_loss: 3.11656e-02
I0211 12:54:09.545759 22509476222784 run_lib.py:133] step: 375350, training_loss: 4.88921e-02
I0211 12:54:28.074036 22509476222784 run_lib.py:133] step: 375400, training_loss: 3.63325e-02
I0211 12:54:28.394614 22509476222784 run_lib.py:146] step: 375400, eval_loss: 3.59678e-02
I0211 12:54:46.919261 22509476222784 run_lib.py:133] step: 375450, training_loss: 4.91766e-02
I0211 12:55:05.466773 22509476222784 run_lib.py:133] step: 375500, training_loss: 4.67689e-02
I0211 12:55:05.631796 22509476222784 run_lib.py:146] step: 375500, eval_loss: 3.78495e-02
I0211 12:55:24.161759 22509476222784 run_lib.py:133] step: 375550, training_loss: 5.08008e-02
I0211 12:55:42.656151 22509476222784 run_lib.py:133] step: 375600, training_loss: 5.10797e-02
I0211 12:55:42.816332 22509476222784 run_lib.py:146] step: 375600, eval_loss: 4.67100e-02
I0211 12:56:01.472630 22509476222784 run_lib.py:133] step: 375650, training_loss: 5.06879e-02
I0211 12:56:20.129220 22509476222784 run_lib.py:133] step: 375700, training_loss: 4.52328e-02
I0211 12:56:20.300431 22509476222784 run_lib.py:146] step: 375700, eval_loss: 3.80586e-02
I0211 12:56:38.843043 22509476222784 run_lib.py:133] step: 375750, training_loss: 5.34414e-02
I0211 12:56:57.408375 22509476222784 run_lib.py:133] step: 375800, training_loss: 4.57302e-02
I0211 12:56:57.609939 22509476222784 run_lib.py:146] step: 375800, eval_loss: 4.57281e-02
I0211 12:57:16.298194 22509476222784 run_lib.py:133] step: 375850, training_loss: 4.88658e-02
I0211 12:57:34.850981 22509476222784 run_lib.py:133] step: 375900, training_loss: 4.20000e-02
I0211 12:57:35.020585 22509476222784 run_lib.py:146] step: 375900, eval_loss: 3.99788e-02
I0211 12:57:53.615342 22509476222784 run_lib.py:133] step: 375950, training_loss: 4.69758e-02
I0211 12:58:12.151821 22509476222784 run_lib.py:133] step: 376000, training_loss: 4.76276e-02
I0211 12:58:12.315916 22509476222784 run_lib.py:146] step: 376000, eval_loss: 4.04976e-02
I0211 12:58:31.019089 22509476222784 run_lib.py:133] step: 376050, training_loss: 4.53692e-02
I0211 12:58:49.533650 22509476222784 run_lib.py:133] step: 376100, training_loss: 4.38538e-02
I0211 12:58:49.698607 22509476222784 run_lib.py:146] step: 376100, eval_loss: 4.50248e-02
I0211 12:59:08.379278 22509476222784 run_lib.py:133] step: 376150, training_loss: 4.27512e-02
I0211 12:59:26.897144 22509476222784 run_lib.py:133] step: 376200, training_loss: 4.58569e-02
I0211 12:59:27.110884 22509476222784 run_lib.py:146] step: 376200, eval_loss: 5.39009e-02
I0211 12:59:45.776687 22509476222784 run_lib.py:133] step: 376250, training_loss: 5.00602e-02
I0211 13:00:04.263748 22509476222784 run_lib.py:133] step: 376300, training_loss: 3.59741e-02
I0211 13:00:04.425663 22509476222784 run_lib.py:146] step: 376300, eval_loss: 3.71711e-02
I0211 13:00:22.989071 22509476222784 run_lib.py:133] step: 376350, training_loss: 3.72787e-02
I0211 13:00:41.680683 22509476222784 run_lib.py:133] step: 376400, training_loss: 3.08406e-02
I0211 13:00:41.844657 22509476222784 run_lib.py:146] step: 376400, eval_loss: 4.06760e-02
I0211 13:01:00.352056 22509476222784 run_lib.py:133] step: 376450, training_loss: 5.37951e-02
I0211 13:01:19.143326 22509476222784 run_lib.py:133] step: 376500, training_loss: 3.67576e-02
I0211 13:01:19.332933 22509476222784 run_lib.py:146] step: 376500, eval_loss: 4.42675e-02
I0211 13:01:37.914314 22509476222784 run_lib.py:133] step: 376550, training_loss: 4.35506e-02
I0211 13:01:56.417261 22509476222784 run_lib.py:133] step: 376600, training_loss: 3.65267e-02
I0211 13:01:56.580710 22509476222784 run_lib.py:146] step: 376600, eval_loss: 3.67186e-02
I0211 13:02:15.093494 22509476222784 run_lib.py:133] step: 376650, training_loss: 4.96626e-02
I0211 13:02:33.794763 22509476222784 run_lib.py:133] step: 376700, training_loss: 3.87070e-02
I0211 13:02:33.963739 22509476222784 run_lib.py:146] step: 376700, eval_loss: 3.84640e-02
I0211 13:02:52.513675 22509476222784 run_lib.py:133] step: 376750, training_loss: 3.81366e-02
I0211 13:03:11.060343 22509476222784 run_lib.py:133] step: 376800, training_loss: 4.12714e-02
I0211 13:03:11.225599 22509476222784 run_lib.py:146] step: 376800, eval_loss: 4.12524e-02
I0211 13:03:29.917759 22509476222784 run_lib.py:133] step: 376850, training_loss: 5.10977e-02
I0211 13:03:48.444645 22509476222784 run_lib.py:133] step: 376900, training_loss: 3.89803e-02
I0211 13:03:48.643666 22509476222784 run_lib.py:146] step: 376900, eval_loss: 4.81504e-02
I0211 13:04:07.215414 22509476222784 run_lib.py:133] step: 376950, training_loss: 5.35139e-02
I0211 13:04:25.827538 22509476222784 run_lib.py:133] step: 377000, training_loss: 4.03430e-02
I0211 13:04:26.020208 22509476222784 run_lib.py:146] step: 377000, eval_loss: 3.09674e-02
I0211 13:04:44.596271 22509476222784 run_lib.py:133] step: 377050, training_loss: 3.36547e-02
I0211 13:05:03.109434 22509476222784 run_lib.py:133] step: 377100, training_loss: 3.32472e-02
I0211 13:05:03.271660 22509476222784 run_lib.py:146] step: 377100, eval_loss: 3.26214e-02
I0211 13:05:21.892764 22509476222784 run_lib.py:133] step: 377150, training_loss: 4.40771e-02
I0211 13:05:40.488286 22509476222784 run_lib.py:133] step: 377200, training_loss: 4.52645e-02
I0211 13:05:40.677892 22509476222784 run_lib.py:146] step: 377200, eval_loss: 3.79745e-02
I0211 13:05:59.195242 22509476222784 run_lib.py:133] step: 377250, training_loss: 5.10295e-02
I0211 13:06:17.741635 22509476222784 run_lib.py:133] step: 377300, training_loss: 3.59210e-02
I0211 13:06:17.906810 22509476222784 run_lib.py:146] step: 377300, eval_loss: 4.44074e-02
I0211 13:06:36.611743 22509476222784 run_lib.py:133] step: 377350, training_loss: 3.91521e-02
I0211 13:06:55.116429 22509476222784 run_lib.py:133] step: 377400, training_loss: 4.25161e-02
I0211 13:06:55.280733 22509476222784 run_lib.py:146] step: 377400, eval_loss: 4.06907e-02
I0211 13:07:13.907926 22509476222784 run_lib.py:133] step: 377450, training_loss: 4.59694e-02
I0211 13:07:32.362445 22509476222784 run_lib.py:133] step: 377500, training_loss: 4.13228e-02
I0211 13:07:32.521613 22509476222784 run_lib.py:146] step: 377500, eval_loss: 3.96986e-02
I0211 13:07:51.227959 22509476222784 run_lib.py:133] step: 377550, training_loss: 4.98618e-02
I0211 13:08:09.753842 22509476222784 run_lib.py:133] step: 377600, training_loss: 4.04839e-02
I0211 13:08:09.926104 22509476222784 run_lib.py:146] step: 377600, eval_loss: 4.51288e-02
I0211 13:08:28.619238 22509476222784 run_lib.py:133] step: 377650, training_loss: 4.49523e-02
I0211 13:08:47.171949 22509476222784 run_lib.py:133] step: 377700, training_loss: 4.76090e-02
I0211 13:08:47.338013 22509476222784 run_lib.py:146] step: 377700, eval_loss: 4.36540e-02
I0211 13:09:05.882074 22509476222784 run_lib.py:133] step: 377750, training_loss: 3.70631e-02
I0211 13:09:24.536769 22509476222784 run_lib.py:133] step: 377800, training_loss: 4.58744e-02
I0211 13:09:24.707843 22509476222784 run_lib.py:146] step: 377800, eval_loss: 3.05273e-02
I0211 13:09:43.215423 22509476222784 run_lib.py:133] step: 377850, training_loss: 4.23530e-02
I0211 13:10:01.817920 22509476222784 run_lib.py:133] step: 377900, training_loss: 3.83592e-02
I0211 13:10:01.980368 22509476222784 run_lib.py:146] step: 377900, eval_loss: 3.16776e-02
I0211 13:10:20.540234 22509476222784 run_lib.py:133] step: 377950, training_loss: 2.89971e-02
I0211 13:10:39.179970 22509476222784 run_lib.py:133] step: 378000, training_loss: 4.49326e-02
I0211 13:10:39.378570 22509476222784 run_lib.py:146] step: 378000, eval_loss: 5.09282e-02
I0211 13:10:57.926366 22509476222784 run_lib.py:133] step: 378050, training_loss: 4.88429e-02
I0211 13:11:16.467424 22509476222784 run_lib.py:133] step: 378100, training_loss: 3.09488e-02
I0211 13:11:16.664864 22509476222784 run_lib.py:146] step: 378100, eval_loss: 4.17266e-02
I0211 13:11:35.272790 22509476222784 run_lib.py:133] step: 378150, training_loss: 4.57131e-02
I0211 13:11:54.057294 22509476222784 run_lib.py:133] step: 378200, training_loss: 3.17198e-02
I0211 13:11:54.221614 22509476222784 run_lib.py:146] step: 378200, eval_loss: 3.93195e-02
I0211 13:12:12.690974 22509476222784 run_lib.py:133] step: 378250, training_loss: 4.60844e-02
I0211 13:12:31.187596 22509476222784 run_lib.py:133] step: 378300, training_loss: 3.72289e-02
I0211 13:12:31.352658 22509476222784 run_lib.py:146] step: 378300, eval_loss: 4.02064e-02
I0211 13:12:49.887131 22509476222784 run_lib.py:133] step: 378350, training_loss: 4.28183e-02
I0211 13:13:08.652982 22509476222784 run_lib.py:133] step: 378400, training_loss: 3.58405e-02
I0211 13:13:08.816896 22509476222784 run_lib.py:146] step: 378400, eval_loss: 4.56114e-02
I0211 13:13:27.403872 22509476222784 run_lib.py:133] step: 378450, training_loss: 5.32050e-02
I0211 13:13:46.131110 22509476222784 run_lib.py:133] step: 378500, training_loss: 4.63948e-02
I0211 13:13:46.292600 22509476222784 run_lib.py:146] step: 378500, eval_loss: 3.67412e-02
I0211 13:14:04.833187 22509476222784 run_lib.py:133] step: 378550, training_loss: 5.10196e-02
I0211 13:14:23.359255 22509476222784 run_lib.py:133] step: 378600, training_loss: 4.16634e-02
I0211 13:14:23.529752 22509476222784 run_lib.py:146] step: 378600, eval_loss: 4.53476e-02
I0211 13:14:42.187814 22509476222784 run_lib.py:133] step: 378650, training_loss: 3.46922e-02
I0211 13:15:00.860867 22509476222784 run_lib.py:133] step: 378700, training_loss: 3.11520e-02
I0211 13:15:01.071733 22509476222784 run_lib.py:146] step: 378700, eval_loss: 4.35727e-02
I0211 13:15:19.595797 22509476222784 run_lib.py:133] step: 378750, training_loss: 4.32396e-02
I0211 13:15:38.166618 22509476222784 run_lib.py:133] step: 378800, training_loss: 3.95538e-02
I0211 13:15:38.330473 22509476222784 run_lib.py:146] step: 378800, eval_loss: 5.06965e-02
I0211 13:15:57.042110 22509476222784 run_lib.py:133] step: 378850, training_loss: 4.55754e-02
I0211 13:16:15.513928 22509476222784 run_lib.py:133] step: 378900, training_loss: 3.76346e-02
I0211 13:16:15.684311 22509476222784 run_lib.py:146] step: 378900, eval_loss: 4.09205e-02
I0211 13:16:34.274974 22509476222784 run_lib.py:133] step: 378950, training_loss: 4.41698e-02
I0211 13:16:52.801201 22509476222784 run_lib.py:133] step: 379000, training_loss: 3.62562e-02
I0211 13:16:52.995877 22509476222784 run_lib.py:146] step: 379000, eval_loss: 4.01232e-02
I0211 13:17:11.751817 22509476222784 run_lib.py:133] step: 379050, training_loss: 5.03842e-02
I0211 13:17:30.296837 22509476222784 run_lib.py:133] step: 379100, training_loss: 4.35320e-02
I0211 13:17:30.462761 22509476222784 run_lib.py:146] step: 379100, eval_loss: 3.46759e-02
I0211 13:17:48.955662 22509476222784 run_lib.py:133] step: 379150, training_loss: 4.80518e-02
I0211 13:18:07.542515 22509476222784 run_lib.py:133] step: 379200, training_loss: 5.03968e-02
I0211 13:18:07.708775 22509476222784 run_lib.py:146] step: 379200, eval_loss: 3.75469e-02
I0211 13:18:26.262418 22509476222784 run_lib.py:133] step: 379250, training_loss: 5.03501e-02
I0211 13:18:45.032319 22509476222784 run_lib.py:133] step: 379300, training_loss: 5.17466e-02
I0211 13:18:45.197475 22509476222784 run_lib.py:146] step: 379300, eval_loss: 4.70566e-02
I0211 13:19:03.697971 22509476222784 run_lib.py:133] step: 379350, training_loss: 4.40556e-02
I0211 13:19:22.239370 22509476222784 run_lib.py:133] step: 379400, training_loss: 4.44299e-02
I0211 13:19:22.417448 22509476222784 run_lib.py:146] step: 379400, eval_loss: 4.29779e-02
I0211 13:19:41.046869 22509476222784 run_lib.py:133] step: 379450, training_loss: 4.15775e-02
I0211 13:19:59.588076 22509476222784 run_lib.py:133] step: 379500, training_loss: 4.12269e-02
I0211 13:19:59.774902 22509476222784 run_lib.py:146] step: 379500, eval_loss: 4.02815e-02
I0211 13:20:18.362193 22509476222784 run_lib.py:133] step: 379550, training_loss: 4.73374e-02
I0211 13:20:37.159389 22509476222784 run_lib.py:133] step: 379600, training_loss: 4.25257e-02
I0211 13:20:37.326447 22509476222784 run_lib.py:146] step: 379600, eval_loss: 2.89812e-02
I0211 13:20:55.851884 22509476222784 run_lib.py:133] step: 379650, training_loss: 4.07431e-02
I0211 13:21:14.331483 22509476222784 run_lib.py:133] step: 379700, training_loss: 3.98198e-02
I0211 13:21:14.495631 22509476222784 run_lib.py:146] step: 379700, eval_loss: 3.95391e-02
I0211 13:21:33.044294 22509476222784 run_lib.py:133] step: 379750, training_loss: 3.68941e-02
I0211 13:21:51.581049 22509476222784 run_lib.py:133] step: 379800, training_loss: 4.74182e-02
I0211 13:21:51.744782 22509476222784 run_lib.py:146] step: 379800, eval_loss: 4.62715e-02
I0211 13:22:10.277575 22509476222784 run_lib.py:133] step: 379850, training_loss: 3.31542e-02
I0211 13:22:28.740087 22509476222784 run_lib.py:133] step: 379900, training_loss: 4.48660e-02
I0211 13:22:28.902706 22509476222784 run_lib.py:146] step: 379900, eval_loss: 4.35464e-02
I0211 13:22:47.593478 22509476222784 run_lib.py:133] step: 379950, training_loss: 3.17088e-02
I0211 13:23:06.165653 22509476222784 run_lib.py:133] step: 380000, training_loss: 3.73203e-02
I0211 13:23:07.118541 22509476222784 run_lib.py:146] step: 380000, eval_loss: 3.55916e-02
I0211 13:23:28.381323 22509476222784 run_lib.py:133] step: 380050, training_loss: 3.12577e-02
I0211 13:23:46.885515 22509476222784 run_lib.py:133] step: 380100, training_loss: 4.47693e-02
I0211 13:23:47.052644 22509476222784 run_lib.py:146] step: 380100, eval_loss: 3.12256e-02
I0211 13:24:05.502923 22509476222784 run_lib.py:133] step: 380150, training_loss: 4.65258e-02
I0211 13:24:24.190042 22509476222784 run_lib.py:133] step: 380200, training_loss: 4.60965e-02
I0211 13:24:24.357641 22509476222784 run_lib.py:146] step: 380200, eval_loss: 5.08850e-02
I0211 13:24:42.933572 22509476222784 run_lib.py:133] step: 380250, training_loss: 4.44258e-02
I0211 13:25:01.597994 22509476222784 run_lib.py:133] step: 380300, training_loss: 4.64439e-02
I0211 13:25:01.762913 22509476222784 run_lib.py:146] step: 380300, eval_loss: 4.04571e-02
I0211 13:25:20.321939 22509476222784 run_lib.py:133] step: 380350, training_loss: 4.33825e-02
I0211 13:25:38.850126 22509476222784 run_lib.py:133] step: 380400, training_loss: 4.23362e-02
I0211 13:25:39.010449 22509476222784 run_lib.py:146] step: 380400, eval_loss: 3.05023e-02
I0211 13:25:57.741657 22509476222784 run_lib.py:133] step: 380450, training_loss: 3.29143e-02
I0211 13:26:16.376809 22509476222784 run_lib.py:133] step: 380500, training_loss: 3.71030e-02
I0211 13:26:16.572718 22509476222784 run_lib.py:146] step: 380500, eval_loss: 5.06750e-02
I0211 13:26:35.113168 22509476222784 run_lib.py:133] step: 380550, training_loss: 3.82735e-02
I0211 13:26:53.692936 22509476222784 run_lib.py:133] step: 380600, training_loss: 4.26602e-02
I0211 13:26:53.864660 22509476222784 run_lib.py:146] step: 380600, eval_loss: 3.81314e-02
I0211 13:27:12.541378 22509476222784 run_lib.py:133] step: 380650, training_loss: 3.43913e-02
I0211 13:27:31.081647 22509476222784 run_lib.py:133] step: 380700, training_loss: 3.88602e-02
I0211 13:27:31.286593 22509476222784 run_lib.py:146] step: 380700, eval_loss: 3.29421e-02
I0211 13:27:49.957860 22509476222784 run_lib.py:133] step: 380750, training_loss: 4.50493e-02
I0211 13:28:08.464341 22509476222784 run_lib.py:133] step: 380800, training_loss: 4.11681e-02
I0211 13:28:08.629791 22509476222784 run_lib.py:146] step: 380800, eval_loss: 5.28610e-02
I0211 13:28:27.351140 22509476222784 run_lib.py:133] step: 380850, training_loss: 4.08797e-02
I0211 13:28:45.890364 22509476222784 run_lib.py:133] step: 380900, training_loss: 3.99352e-02
I0211 13:28:46.054011 22509476222784 run_lib.py:146] step: 380900, eval_loss: 4.02432e-02
I0211 13:29:04.595191 22509476222784 run_lib.py:133] step: 380950, training_loss: 3.27475e-02
I0211 13:29:23.260005 22509476222784 run_lib.py:133] step: 381000, training_loss: 5.20051e-02
I0211 13:29:23.423759 22509476222784 run_lib.py:146] step: 381000, eval_loss: 4.76565e-02
I0211 13:29:41.914022 22509476222784 run_lib.py:133] step: 381050, training_loss: 3.88110e-02
I0211 13:30:00.613578 22509476222784 run_lib.py:133] step: 381100, training_loss: 4.62387e-02
I0211 13:30:00.830688 22509476222784 run_lib.py:146] step: 381100, eval_loss: 3.72912e-02
I0211 13:30:19.372211 22509476222784 run_lib.py:133] step: 381150, training_loss: 4.33990e-02
I0211 13:30:37.914108 22509476222784 run_lib.py:133] step: 381200, training_loss: 3.88601e-02
I0211 13:30:38.078906 22509476222784 run_lib.py:146] step: 381200, eval_loss: 3.93370e-02
I0211 13:30:56.822209 22509476222784 run_lib.py:133] step: 381250, training_loss: 4.73104e-02
I0211 13:31:15.316985 22509476222784 run_lib.py:133] step: 381300, training_loss: 4.32336e-02
I0211 13:31:15.479584 22509476222784 run_lib.py:146] step: 381300, eval_loss: 4.30173e-02
I0211 13:31:34.040837 22509476222784 run_lib.py:133] step: 381350, training_loss: 5.10969e-02
I0211 13:31:52.690241 22509476222784 run_lib.py:133] step: 381400, training_loss: 5.48063e-02
I0211 13:31:52.859965 22509476222784 run_lib.py:146] step: 381400, eval_loss: 3.54902e-02
I0211 13:32:11.458698 22509476222784 run_lib.py:133] step: 381450, training_loss: 5.17937e-02
I0211 13:32:30.017844 22509476222784 run_lib.py:133] step: 381500, training_loss: 4.87866e-02
I0211 13:32:30.179581 22509476222784 run_lib.py:146] step: 381500, eval_loss: 4.45008e-02
I0211 13:32:48.832785 22509476222784 run_lib.py:133] step: 381550, training_loss: 4.03269e-02
I0211 13:33:07.381621 22509476222784 run_lib.py:133] step: 381600, training_loss: 3.40645e-02
I0211 13:33:07.550761 22509476222784 run_lib.py:146] step: 381600, eval_loss: 5.24736e-02
I0211 13:33:26.134545 22509476222784 run_lib.py:133] step: 381650, training_loss: 3.43392e-02
I0211 13:33:44.712862 22509476222784 run_lib.py:133] step: 381700, training_loss: 4.55227e-02
I0211 13:33:44.877789 22509476222784 run_lib.py:146] step: 381700, eval_loss: 4.03870e-02
I0211 13:34:03.630537 22509476222784 run_lib.py:133] step: 381750, training_loss: 3.48563e-02
I0211 13:34:22.223842 22509476222784 run_lib.py:133] step: 381800, training_loss: 3.77898e-02
I0211 13:34:22.390259 22509476222784 run_lib.py:146] step: 381800, eval_loss: 4.90813e-02
I0211 13:34:40.873802 22509476222784 run_lib.py:133] step: 381850, training_loss: 4.66019e-02
I0211 13:34:59.372908 22509476222784 run_lib.py:133] step: 381900, training_loss: 5.13649e-02
I0211 13:34:59.534063 22509476222784 run_lib.py:146] step: 381900, eval_loss: 5.08248e-02
I0211 13:35:18.238896 22509476222784 run_lib.py:133] step: 381950, training_loss: 4.13299e-02
I0211 13:35:36.816468 22509476222784 run_lib.py:133] step: 382000, training_loss: 3.07241e-02
I0211 13:35:36.982422 22509476222784 run_lib.py:146] step: 382000, eval_loss: 3.84168e-02
I0211 13:35:55.664068 22509476222784 run_lib.py:133] step: 382050, training_loss: 4.21765e-02
I0211 13:36:14.110764 22509476222784 run_lib.py:133] step: 382100, training_loss: 3.97092e-02
I0211 13:36:14.274687 22509476222784 run_lib.py:146] step: 382100, eval_loss: 3.45967e-02
I0211 13:36:32.918247 22509476222784 run_lib.py:133] step: 382150, training_loss: 3.78384e-02
I0211 13:36:51.438392 22509476222784 run_lib.py:133] step: 382200, training_loss: 4.48665e-02
I0211 13:36:51.611874 22509476222784 run_lib.py:146] step: 382200, eval_loss: 3.44423e-02
I0211 13:37:10.359357 22509476222784 run_lib.py:133] step: 382250, training_loss: 2.84346e-02
I0211 13:37:28.943729 22509476222784 run_lib.py:133] step: 382300, training_loss: 4.17075e-02
I0211 13:37:29.103013 22509476222784 run_lib.py:146] step: 382300, eval_loss: 4.84838e-02
I0211 13:37:47.607519 22509476222784 run_lib.py:133] step: 382350, training_loss: 5.58324e-02
I0211 13:38:06.230498 22509476222784 run_lib.py:133] step: 382400, training_loss: 4.43861e-02
I0211 13:38:06.393621 22509476222784 run_lib.py:146] step: 382400, eval_loss: 5.18856e-02
I0211 13:38:24.887803 22509476222784 run_lib.py:133] step: 382450, training_loss: 3.57530e-02
I0211 13:38:43.381762 22509476222784 run_lib.py:133] step: 382500, training_loss: 6.54868e-02
I0211 13:38:43.565612 22509476222784 run_lib.py:146] step: 382500, eval_loss: 4.57148e-02
I0211 13:39:02.274906 22509476222784 run_lib.py:133] step: 382550, training_loss: 5.10116e-02
I0211 13:39:20.823423 22509476222784 run_lib.py:133] step: 382600, training_loss: 3.82974e-02
I0211 13:39:20.995219 22509476222784 run_lib.py:146] step: 382600, eval_loss: 4.62060e-02
I0211 13:39:39.671575 22509476222784 run_lib.py:133] step: 382650, training_loss: 4.66593e-02
I0211 13:39:58.174193 22509476222784 run_lib.py:133] step: 382700, training_loss: 3.02760e-02
I0211 13:39:58.394584 22509476222784 run_lib.py:146] step: 382700, eval_loss: 4.39903e-02
I0211 13:40:16.884825 22509476222784 run_lib.py:133] step: 382750, training_loss: 4.53979e-02
I0211 13:40:35.607744 22509476222784 run_lib.py:133] step: 382800, training_loss: 4.27285e-02
I0211 13:40:35.774756 22509476222784 run_lib.py:146] step: 382800, eval_loss: 4.08317e-02
I0211 13:40:54.381911 22509476222784 run_lib.py:133] step: 382850, training_loss: 4.51363e-02
I0211 13:41:12.829542 22509476222784 run_lib.py:133] step: 382900, training_loss: 3.93427e-02
I0211 13:41:12.995555 22509476222784 run_lib.py:146] step: 382900, eval_loss: 4.73977e-02
I0211 13:41:31.449231 22509476222784 run_lib.py:133] step: 382950, training_loss: 4.00792e-02
I0211 13:41:50.156617 22509476222784 run_lib.py:133] step: 383000, training_loss: 4.00612e-02
I0211 13:41:50.325885 22509476222784 run_lib.py:146] step: 383000, eval_loss: 4.34237e-02
I0211 13:42:08.756303 22509476222784 run_lib.py:133] step: 383050, training_loss: 5.25891e-02
I0211 13:42:27.300424 22509476222784 run_lib.py:133] step: 383100, training_loss: 4.88796e-02
I0211 13:42:27.471660 22509476222784 run_lib.py:146] step: 383100, eval_loss: 4.10709e-02
I0211 13:42:45.946652 22509476222784 run_lib.py:133] step: 383150, training_loss: 4.47333e-02
I0211 13:43:04.487716 22509476222784 run_lib.py:133] step: 383200, training_loss: 4.00844e-02
I0211 13:43:04.656644 22509476222784 run_lib.py:146] step: 383200, eval_loss: 3.23985e-02
I0211 13:43:23.323245 22509476222784 run_lib.py:133] step: 383250, training_loss: 4.03934e-02
I0211 13:43:41.940545 22509476222784 run_lib.py:133] step: 383300, training_loss: 3.31097e-02
I0211 13:43:42.103882 22509476222784 run_lib.py:146] step: 383300, eval_loss: 4.83456e-02
I0211 13:44:00.717423 22509476222784 run_lib.py:133] step: 383350, training_loss: 3.61134e-02
I0211 13:44:19.239527 22509476222784 run_lib.py:133] step: 383400, training_loss: 4.72876e-02
I0211 13:44:19.412573 22509476222784 run_lib.py:146] step: 383400, eval_loss: 4.33328e-02
I0211 13:44:38.085613 22509476222784 run_lib.py:133] step: 383450, training_loss: 4.09514e-02
I0211 13:44:56.584142 22509476222784 run_lib.py:133] step: 383500, training_loss: 4.22495e-02
I0211 13:44:56.752530 22509476222784 run_lib.py:146] step: 383500, eval_loss: 3.59423e-02
I0211 13:45:15.407326 22509476222784 run_lib.py:133] step: 383550, training_loss: 5.17780e-02
I0211 13:45:33.996193 22509476222784 run_lib.py:133] step: 383600, training_loss: 4.60276e-02
I0211 13:45:34.161360 22509476222784 run_lib.py:146] step: 383600, eval_loss: 3.60161e-02
I0211 13:45:52.840523 22509476222784 run_lib.py:133] step: 383650, training_loss: 4.33166e-02
I0211 13:46:11.331523 22509476222784 run_lib.py:133] step: 383700, training_loss: 4.05795e-02
I0211 13:46:11.494640 22509476222784 run_lib.py:146] step: 383700, eval_loss: 4.10244e-02
I0211 13:46:29.960458 22509476222784 run_lib.py:133] step: 383750, training_loss: 3.65157e-02
I0211 13:46:48.609364 22509476222784 run_lib.py:133] step: 383800, training_loss: 3.92517e-02
I0211 13:46:48.770612 22509476222784 run_lib.py:146] step: 383800, eval_loss: 3.31554e-02
I0211 13:47:07.294589 22509476222784 run_lib.py:133] step: 383850, training_loss: 5.69860e-02
I0211 13:47:25.910988 22509476222784 run_lib.py:133] step: 383900, training_loss: 5.03158e-02
I0211 13:47:26.086606 22509476222784 run_lib.py:146] step: 383900, eval_loss: 4.84204e-02
I0211 13:47:44.568070 22509476222784 run_lib.py:133] step: 383950, training_loss: 4.43575e-02
I0211 13:48:03.036136 22509476222784 run_lib.py:133] step: 384000, training_loss: 3.78684e-02
I0211 13:48:03.200676 22509476222784 run_lib.py:146] step: 384000, eval_loss: 4.69993e-02
I0211 13:48:21.840888 22509476222784 run_lib.py:133] step: 384050, training_loss: 5.01457e-02
I0211 13:48:40.325257 22509476222784 run_lib.py:133] step: 384100, training_loss: 2.84924e-02
I0211 13:48:40.494185 22509476222784 run_lib.py:146] step: 384100, eval_loss: 4.05627e-02
I0211 13:48:59.019437 22509476222784 run_lib.py:133] step: 384150, training_loss: 5.35434e-02
I0211 13:49:17.713268 22509476222784 run_lib.py:133] step: 384200, training_loss: 4.50664e-02
I0211 13:49:17.884403 22509476222784 run_lib.py:146] step: 384200, eval_loss: 4.66816e-02
I0211 13:49:36.398066 22509476222784 run_lib.py:133] step: 384250, training_loss: 4.09613e-02
I0211 13:49:54.966398 22509476222784 run_lib.py:133] step: 384300, training_loss: 4.85477e-02
I0211 13:49:55.334671 22509476222784 run_lib.py:146] step: 384300, eval_loss: 4.22635e-02
I0211 13:50:13.816592 22509476222784 run_lib.py:133] step: 384350, training_loss: 4.82033e-02
I0211 13:50:32.369980 22509476222784 run_lib.py:133] step: 384400, training_loss: 4.06480e-02
I0211 13:50:32.549626 22509476222784 run_lib.py:146] step: 384400, eval_loss: 3.70525e-02
I0211 13:50:51.091718 22509476222784 run_lib.py:133] step: 384450, training_loss: 4.51454e-02
I0211 13:51:09.617496 22509476222784 run_lib.py:133] step: 384500, training_loss: 4.98423e-02
I0211 13:51:09.786755 22509476222784 run_lib.py:146] step: 384500, eval_loss: 4.57227e-02
I0211 13:51:28.533150 22509476222784 run_lib.py:133] step: 384550, training_loss: 4.96186e-02
I0211 13:51:47.105456 22509476222784 run_lib.py:133] step: 384600, training_loss: 4.45352e-02
I0211 13:51:47.307726 22509476222784 run_lib.py:146] step: 384600, eval_loss: 4.33907e-02
I0211 13:52:05.829072 22509476222784 run_lib.py:133] step: 384650, training_loss: 2.75141e-02
I0211 13:52:24.415867 22509476222784 run_lib.py:133] step: 384700, training_loss: 4.08670e-02
I0211 13:52:24.578776 22509476222784 run_lib.py:146] step: 384700, eval_loss: 3.96375e-02
I0211 13:52:43.305179 22509476222784 run_lib.py:133] step: 384750, training_loss: 3.52887e-02
I0211 13:53:01.934797 22509476222784 run_lib.py:133] step: 384800, training_loss: 4.09365e-02
I0211 13:53:02.099627 22509476222784 run_lib.py:146] step: 384800, eval_loss: 4.75151e-02
I0211 13:53:20.596982 22509476222784 run_lib.py:133] step: 384850, training_loss: 5.73202e-02
I0211 13:53:39.088330 22509476222784 run_lib.py:133] step: 384900, training_loss: 3.71177e-02
I0211 13:53:39.268581 22509476222784 run_lib.py:146] step: 384900, eval_loss: 3.59970e-02
I0211 13:53:57.900840 22509476222784 run_lib.py:133] step: 384950, training_loss: 3.98683e-02
I0211 13:54:16.427329 22509476222784 run_lib.py:133] step: 385000, training_loss: 4.11907e-02
I0211 13:54:16.596846 22509476222784 run_lib.py:146] step: 385000, eval_loss: 4.77903e-02
I0211 13:54:35.310373 22509476222784 run_lib.py:133] step: 385050, training_loss: 4.85298e-02
I0211 13:54:53.845267 22509476222784 run_lib.py:133] step: 385100, training_loss: 4.43629e-02
I0211 13:54:54.008480 22509476222784 run_lib.py:146] step: 385100, eval_loss: 4.25171e-02
I0211 13:55:12.661723 22509476222784 run_lib.py:133] step: 385150, training_loss: 4.36727e-02
I0211 13:55:31.193065 22509476222784 run_lib.py:133] step: 385200, training_loss: 4.50331e-02
I0211 13:55:31.364889 22509476222784 run_lib.py:146] step: 385200, eval_loss: 4.33243e-02
I0211 13:55:49.970352 22509476222784 run_lib.py:133] step: 385250, training_loss: 4.84985e-02
I0211 13:56:08.686308 22509476222784 run_lib.py:133] step: 385300, training_loss: 3.18343e-02
I0211 13:56:08.850683 22509476222784 run_lib.py:146] step: 385300, eval_loss: 4.65013e-02
I0211 13:56:27.378011 22509476222784 run_lib.py:133] step: 385350, training_loss: 4.47943e-02
I0211 13:56:46.028797 22509476222784 run_lib.py:133] step: 385400, training_loss: 4.81769e-02
I0211 13:56:46.193858 22509476222784 run_lib.py:146] step: 385400, eval_loss: 4.77053e-02
I0211 13:57:04.760033 22509476222784 run_lib.py:133] step: 385450, training_loss: 4.63212e-02
I0211 13:57:23.304462 22509476222784 run_lib.py:133] step: 385500, training_loss: 4.49739e-02
I0211 13:57:23.469377 22509476222784 run_lib.py:146] step: 385500, eval_loss: 3.44030e-02
I0211 13:57:42.107026 22509476222784 run_lib.py:133] step: 385550, training_loss: 4.37388e-02
I0211 13:58:00.617068 22509476222784 run_lib.py:133] step: 385600, training_loss: 3.74378e-02
I0211 13:58:00.784560 22509476222784 run_lib.py:146] step: 385600, eval_loss: 4.64307e-02
I0211 13:58:19.267367 22509476222784 run_lib.py:133] step: 385650, training_loss: 4.77962e-02
I0211 13:58:37.786978 22509476222784 run_lib.py:133] step: 385700, training_loss: 3.79320e-02
I0211 13:58:37.948971 22509476222784 run_lib.py:146] step: 385700, eval_loss: 4.21561e-02
I0211 13:58:56.649208 22509476222784 run_lib.py:133] step: 385750, training_loss: 4.94052e-02
I0211 13:59:15.179717 22509476222784 run_lib.py:133] step: 385800, training_loss: 2.95455e-02
I0211 13:59:15.346650 22509476222784 run_lib.py:146] step: 385800, eval_loss: 5.29820e-02
I0211 13:59:33.944014 22509476222784 run_lib.py:133] step: 385850, training_loss: 4.67924e-02
I0211 13:59:52.485344 22509476222784 run_lib.py:133] step: 385900, training_loss: 5.06535e-02
I0211 13:59:52.664560 22509476222784 run_lib.py:146] step: 385900, eval_loss: 4.57065e-02
I0211 14:00:11.187403 22509476222784 run_lib.py:133] step: 385950, training_loss: 4.00174e-02
I0211 14:00:29.697340 22509476222784 run_lib.py:133] step: 386000, training_loss: 4.93919e-02
I0211 14:00:29.870743 22509476222784 run_lib.py:146] step: 386000, eval_loss: 3.87261e-02
I0211 14:00:48.540618 22509476222784 run_lib.py:133] step: 386050, training_loss: 4.51547e-02
I0211 14:01:07.130108 22509476222784 run_lib.py:133] step: 386100, training_loss: 5.05341e-02
I0211 14:01:07.290928 22509476222784 run_lib.py:146] step: 386100, eval_loss: 4.26221e-02
I0211 14:01:25.758823 22509476222784 run_lib.py:133] step: 386150, training_loss: 4.22964e-02
I0211 14:01:44.201025 22509476222784 run_lib.py:133] step: 386200, training_loss: 3.78255e-02
I0211 14:01:44.363584 22509476222784 run_lib.py:146] step: 386200, eval_loss: 4.95080e-02
I0211 14:02:02.977400 22509476222784 run_lib.py:133] step: 386250, training_loss: 4.08088e-02
I0211 14:02:21.555264 22509476222784 run_lib.py:133] step: 386300, training_loss: 3.58345e-02
I0211 14:02:21.742638 22509476222784 run_lib.py:146] step: 386300, eval_loss: 4.51749e-02
I0211 14:02:40.419990 22509476222784 run_lib.py:133] step: 386350, training_loss: 3.13384e-02
I0211 14:02:59.006755 22509476222784 run_lib.py:133] step: 386400, training_loss: 4.22172e-02
I0211 14:02:59.174871 22509476222784 run_lib.py:146] step: 386400, eval_loss: 4.75125e-02
I0211 14:03:17.841564 22509476222784 run_lib.py:133] step: 386450, training_loss: 3.64180e-02
I0211 14:03:36.334329 22509476222784 run_lib.py:133] step: 386500, training_loss: 4.24410e-02
I0211 14:03:36.501347 22509476222784 run_lib.py:146] step: 386500, eval_loss: 4.56143e-02
I0211 14:03:55.159829 22509476222784 run_lib.py:133] step: 386550, training_loss: 3.25498e-02
I0211 14:04:13.703227 22509476222784 run_lib.py:133] step: 386600, training_loss: 5.00531e-02
I0211 14:04:13.871978 22509476222784 run_lib.py:146] step: 386600, eval_loss: 4.20699e-02
I0211 14:04:32.418074 22509476222784 run_lib.py:133] step: 386650, training_loss: 4.24944e-02
I0211 14:04:51.111124 22509476222784 run_lib.py:133] step: 386700, training_loss: 4.07260e-02
I0211 14:04:51.275576 22509476222784 run_lib.py:146] step: 386700, eval_loss: 3.21945e-02
I0211 14:05:09.735810 22509476222784 run_lib.py:133] step: 386750, training_loss: 4.04545e-02
I0211 14:05:28.257843 22509476222784 run_lib.py:133] step: 386800, training_loss: 2.16889e-02
I0211 14:05:28.438534 22509476222784 run_lib.py:146] step: 386800, eval_loss: 4.28014e-02
I0211 14:05:47.113735 22509476222784 run_lib.py:133] step: 386850, training_loss: 3.59210e-02
I0211 14:06:05.865519 22509476222784 run_lib.py:133] step: 386900, training_loss: 4.55371e-02
I0211 14:06:06.030819 22509476222784 run_lib.py:146] step: 386900, eval_loss: 4.87569e-02
I0211 14:06:24.560791 22509476222784 run_lib.py:133] step: 386950, training_loss: 3.95473e-02
I0211 14:06:43.077651 22509476222784 run_lib.py:133] step: 387000, training_loss: 3.45537e-02
I0211 14:06:43.237222 22509476222784 run_lib.py:146] step: 387000, eval_loss: 4.54943e-02
I0211 14:07:01.739812 22509476222784 run_lib.py:133] step: 387050, training_loss: 3.99278e-02
I0211 14:07:20.483930 22509476222784 run_lib.py:133] step: 387100, training_loss: 4.74663e-02
I0211 14:07:20.649849 22509476222784 run_lib.py:146] step: 387100, eval_loss: 4.58723e-02
I0211 14:07:39.166292 22509476222784 run_lib.py:133] step: 387150, training_loss: 4.78404e-02
I0211 14:07:57.642515 22509476222784 run_lib.py:133] step: 387200, training_loss: 5.08126e-02
I0211 14:07:57.808798 22509476222784 run_lib.py:146] step: 387200, eval_loss: 4.23508e-02
I0211 14:08:16.271839 22509476222784 run_lib.py:133] step: 387250, training_loss: 4.47443e-02
I0211 14:08:34.923211 22509476222784 run_lib.py:133] step: 387300, training_loss: 3.97079e-02
I0211 14:08:35.096758 22509476222784 run_lib.py:146] step: 387300, eval_loss: 4.28791e-02
I0211 14:08:53.599932 22509476222784 run_lib.py:133] step: 387350, training_loss: 3.18392e-02
I0211 14:09:12.293331 22509476222784 run_lib.py:133] step: 387400, training_loss: 4.01703e-02
I0211 14:09:12.459166 22509476222784 run_lib.py:146] step: 387400, eval_loss: 4.14833e-02
I0211 14:09:30.971408 22509476222784 run_lib.py:133] step: 387450, training_loss: 4.30677e-02
I0211 14:09:49.492990 22509476222784 run_lib.py:133] step: 387500, training_loss: 5.37801e-02
I0211 14:09:49.672655 22509476222784 run_lib.py:146] step: 387500, eval_loss: 4.66378e-02
I0211 14:10:08.379629 22509476222784 run_lib.py:133] step: 387550, training_loss: 5.25161e-02
I0211 14:10:26.943006 22509476222784 run_lib.py:133] step: 387600, training_loss: 4.01243e-02
I0211 14:10:27.105623 22509476222784 run_lib.py:146] step: 387600, eval_loss: 4.80115e-02
I0211 14:10:45.609369 22509476222784 run_lib.py:133] step: 387650, training_loss: 5.02905e-02
I0211 14:11:04.189409 22509476222784 run_lib.py:133] step: 387700, training_loss: 4.53778e-02
I0211 14:11:04.361586 22509476222784 run_lib.py:146] step: 387700, eval_loss: 3.92612e-02
I0211 14:11:23.054399 22509476222784 run_lib.py:133] step: 387750, training_loss: 3.77057e-02
I0211 14:11:41.554878 22509476222784 run_lib.py:133] step: 387800, training_loss: 4.04597e-02
I0211 14:11:41.719609 22509476222784 run_lib.py:146] step: 387800, eval_loss: 4.21462e-02
I0211 14:12:00.391069 22509476222784 run_lib.py:133] step: 387850, training_loss: 3.23984e-02
I0211 14:12:18.883235 22509476222784 run_lib.py:133] step: 387900, training_loss: 3.10105e-02
I0211 14:12:19.047801 22509476222784 run_lib.py:146] step: 387900, eval_loss: 3.92977e-02
I0211 14:12:37.729907 22509476222784 run_lib.py:133] step: 387950, training_loss: 3.26588e-02
I0211 14:12:56.309920 22509476222784 run_lib.py:133] step: 388000, training_loss: 3.14339e-02
I0211 14:12:56.469429 22509476222784 run_lib.py:146] step: 388000, eval_loss: 3.86295e-02
I0211 14:13:15.072819 22509476222784 run_lib.py:133] step: 388050, training_loss: 3.59713e-02
I0211 14:13:33.827356 22509476222784 run_lib.py:133] step: 388100, training_loss: 5.25905e-02
I0211 14:13:33.995548 22509476222784 run_lib.py:146] step: 388100, eval_loss: 3.65700e-02
I0211 14:13:52.515527 22509476222784 run_lib.py:133] step: 388150, training_loss: 4.08299e-02
I0211 14:14:11.111337 22509476222784 run_lib.py:133] step: 388200, training_loss: 5.36847e-02
I0211 14:14:11.288436 22509476222784 run_lib.py:146] step: 388200, eval_loss: 3.64260e-02
I0211 14:14:29.833158 22509476222784 run_lib.py:133] step: 388250, training_loss: 4.73951e-02
I0211 14:14:48.367451 22509476222784 run_lib.py:133] step: 388300, training_loss: 3.64542e-02
I0211 14:14:48.532000 22509476222784 run_lib.py:146] step: 388300, eval_loss: 4.73184e-02
I0211 14:15:07.165394 22509476222784 run_lib.py:133] step: 388350, training_loss: 4.41218e-02
I0211 14:15:25.596115 22509476222784 run_lib.py:133] step: 388400, training_loss: 3.74884e-02
I0211 14:15:25.758572 22509476222784 run_lib.py:146] step: 388400, eval_loss: 4.32642e-02
I0211 14:15:44.271214 22509476222784 run_lib.py:133] step: 388450, training_loss: 2.79983e-02
I0211 14:16:02.985596 22509476222784 run_lib.py:133] step: 388500, training_loss: 4.43926e-02
I0211 14:16:03.150924 22509476222784 run_lib.py:146] step: 388500, eval_loss: 5.10312e-02
I0211 14:16:21.708759 22509476222784 run_lib.py:133] step: 388550, training_loss: 4.66784e-02
I0211 14:16:40.214511 22509476222784 run_lib.py:133] step: 388600, training_loss: 4.19364e-02
I0211 14:16:40.386917 22509476222784 run_lib.py:146] step: 388600, eval_loss: 3.94097e-02
I0211 14:16:59.036744 22509476222784 run_lib.py:133] step: 388650, training_loss: 4.37932e-02
I0211 14:17:17.547444 22509476222784 run_lib.py:133] step: 388700, training_loss: 3.97139e-02
I0211 14:17:17.713806 22509476222784 run_lib.py:146] step: 388700, eval_loss: 3.93765e-02
I0211 14:17:36.284514 22509476222784 run_lib.py:133] step: 388750, training_loss: 4.76831e-02
I0211 14:17:54.826322 22509476222784 run_lib.py:133] step: 388800, training_loss: 4.74137e-02
I0211 14:17:54.995858 22509476222784 run_lib.py:146] step: 388800, eval_loss: 5.97836e-02
I0211 14:18:13.701611 22509476222784 run_lib.py:133] step: 388850, training_loss: 5.61364e-02
I0211 14:18:32.274019 22509476222784 run_lib.py:133] step: 388900, training_loss: 5.51662e-02
I0211 14:18:32.437638 22509476222784 run_lib.py:146] step: 388900, eval_loss: 4.25416e-02
I0211 14:18:50.962687 22509476222784 run_lib.py:133] step: 388950, training_loss: 4.64091e-02
I0211 14:19:09.535142 22509476222784 run_lib.py:133] step: 389000, training_loss: 3.98319e-02
I0211 14:19:09.730873 22509476222784 run_lib.py:146] step: 389000, eval_loss: 5.07884e-02
I0211 14:19:28.502072 22509476222784 run_lib.py:133] step: 389050, training_loss: 5.51052e-02
I0211 14:19:47.105515 22509476222784 run_lib.py:133] step: 389100, training_loss: 4.73308e-02
I0211 14:19:47.305140 22509476222784 run_lib.py:146] step: 389100, eval_loss: 4.25529e-02
I0211 14:20:06.009110 22509476222784 run_lib.py:133] step: 389150, training_loss: 4.28585e-02
I0211 14:20:24.505513 22509476222784 run_lib.py:133] step: 389200, training_loss: 4.91558e-02
I0211 14:20:24.669337 22509476222784 run_lib.py:146] step: 389200, eval_loss: 5.16473e-02
I0211 14:20:43.326890 22509476222784 run_lib.py:133] step: 389250, training_loss: 4.38346e-02
I0211 14:21:01.914488 22509476222784 run_lib.py:133] step: 389300, training_loss: 4.51341e-02
I0211 14:21:02.079245 22509476222784 run_lib.py:146] step: 389300, eval_loss: 4.53782e-02
I0211 14:21:20.781186 22509476222784 run_lib.py:133] step: 389350, training_loss: 3.84966e-02
I0211 14:21:39.293707 22509476222784 run_lib.py:133] step: 389400, training_loss: 4.17241e-02
I0211 14:21:39.455434 22509476222784 run_lib.py:146] step: 389400, eval_loss: 5.35314e-02
I0211 14:21:58.018762 22509476222784 run_lib.py:133] step: 389450, training_loss: 4.13748e-02
I0211 14:22:16.698765 22509476222784 run_lib.py:133] step: 389500, training_loss: 3.23697e-02
I0211 14:22:16.860634 22509476222784 run_lib.py:146] step: 389500, eval_loss: 4.35875e-02
I0211 14:22:35.393784 22509476222784 run_lib.py:133] step: 389550, training_loss: 3.60714e-02
I0211 14:22:53.911312 22509476222784 run_lib.py:133] step: 389600, training_loss: 3.91291e-02
I0211 14:22:54.091705 22509476222784 run_lib.py:146] step: 389600, eval_loss: 4.93380e-02
I0211 14:23:12.824852 22509476222784 run_lib.py:133] step: 389650, training_loss: 4.49300e-02
I0211 14:23:31.345397 22509476222784 run_lib.py:133] step: 389700, training_loss: 4.99598e-02
I0211 14:23:31.509835 22509476222784 run_lib.py:146] step: 389700, eval_loss: 4.24046e-02
I0211 14:23:50.220435 22509476222784 run_lib.py:133] step: 389750, training_loss: 4.00653e-02
I0211 14:24:08.644176 22509476222784 run_lib.py:133] step: 389800, training_loss: 4.34353e-02
I0211 14:24:08.808747 22509476222784 run_lib.py:146] step: 389800, eval_loss: 4.21925e-02
I0211 14:24:27.305421 22509476222784 run_lib.py:133] step: 389850, training_loss: 3.21338e-02
I0211 14:24:46.029064 22509476222784 run_lib.py:133] step: 389900, training_loss: 5.32242e-02
I0211 14:24:46.193822 22509476222784 run_lib.py:146] step: 389900, eval_loss: 4.48050e-02
I0211 14:25:04.726712 22509476222784 run_lib.py:133] step: 389950, training_loss: 4.36925e-02
I0211 14:25:23.219575 22509476222784 run_lib.py:133] step: 390000, training_loss: 4.18199e-02
I0211 14:25:24.172564 22509476222784 run_lib.py:146] step: 390000, eval_loss: 4.60343e-02
I0211 14:25:45.583598 22509476222784 run_lib.py:133] step: 390050, training_loss: 3.98104e-02
I0211 14:26:04.125964 22509476222784 run_lib.py:133] step: 390100, training_loss: 3.90291e-02
I0211 14:26:04.291949 22509476222784 run_lib.py:146] step: 390100, eval_loss: 5.06807e-02
I0211 14:26:23.004260 22509476222784 run_lib.py:133] step: 390150, training_loss: 5.05967e-02
I0211 14:26:41.605111 22509476222784 run_lib.py:133] step: 390200, training_loss: 3.48675e-02
I0211 14:26:41.770674 22509476222784 run_lib.py:146] step: 390200, eval_loss: 4.49499e-02
I0211 14:27:00.355627 22509476222784 run_lib.py:133] step: 390250, training_loss: 5.38431e-02
I0211 14:27:18.869045 22509476222784 run_lib.py:133] step: 390300, training_loss: 4.93580e-02
I0211 14:27:19.043614 22509476222784 run_lib.py:146] step: 390300, eval_loss: 4.64405e-02
I0211 14:27:37.578742 22509476222784 run_lib.py:133] step: 390350, training_loss: 5.23667e-02
I0211 14:27:56.131057 22509476222784 run_lib.py:133] step: 390400, training_loss: 4.17256e-02
I0211 14:27:56.304703 22509476222784 run_lib.py:146] step: 390400, eval_loss: 3.76461e-02
I0211 14:28:15.006738 22509476222784 run_lib.py:133] step: 390450, training_loss: 4.34792e-02
I0211 14:28:33.731383 22509476222784 run_lib.py:133] step: 390500, training_loss: 4.95644e-02
I0211 14:28:33.937224 22509476222784 run_lib.py:146] step: 390500, eval_loss: 5.06768e-02
I0211 14:28:52.523960 22509476222784 run_lib.py:133] step: 390550, training_loss: 4.89073e-02
I0211 14:29:11.076240 22509476222784 run_lib.py:133] step: 390600, training_loss: 4.73636e-02
I0211 14:29:11.243014 22509476222784 run_lib.py:146] step: 390600, eval_loss: 3.69745e-02
I0211 14:29:29.883980 22509476222784 run_lib.py:133] step: 390650, training_loss: 3.71011e-02
I0211 14:29:48.456134 22509476222784 run_lib.py:133] step: 390700, training_loss: 5.81342e-02
I0211 14:29:48.632688 22509476222784 run_lib.py:146] step: 390700, eval_loss: 3.70770e-02
I0211 14:30:07.371427 22509476222784 run_lib.py:133] step: 390750, training_loss: 3.79663e-02
I0211 14:30:25.940603 22509476222784 run_lib.py:133] step: 390800, training_loss: 4.40264e-02
I0211 14:30:26.105527 22509476222784 run_lib.py:146] step: 390800, eval_loss: 4.16613e-02
I0211 14:30:44.822811 22509476222784 run_lib.py:133] step: 390850, training_loss: 3.15310e-02
I0211 14:31:03.301306 22509476222784 run_lib.py:133] step: 390900, training_loss: 4.23213e-02
I0211 14:31:03.463456 22509476222784 run_lib.py:146] step: 390900, eval_loss: 4.61827e-02
I0211 14:31:22.072602 22509476222784 run_lib.py:133] step: 390950, training_loss: 3.90720e-02
I0211 14:31:40.607106 22509476222784 run_lib.py:133] step: 391000, training_loss: 3.79397e-02
I0211 14:31:40.802792 22509476222784 run_lib.py:146] step: 391000, eval_loss: 4.62902e-02
I0211 14:31:59.367493 22509476222784 run_lib.py:133] step: 391050, training_loss: 5.55069e-02
I0211 14:32:18.133034 22509476222784 run_lib.py:133] step: 391100, training_loss: 4.37503e-02
I0211 14:32:18.332676 22509476222784 run_lib.py:146] step: 391100, eval_loss: 4.92011e-02
I0211 14:32:36.843204 22509476222784 run_lib.py:133] step: 391150, training_loss: 3.77704e-02
I0211 14:32:55.368209 22509476222784 run_lib.py:133] step: 391200, training_loss: 4.86950e-02
I0211 14:32:55.531619 22509476222784 run_lib.py:146] step: 391200, eval_loss: 3.66306e-02
I0211 14:33:14.246539 22509476222784 run_lib.py:133] step: 391250, training_loss: 4.75773e-02
I0211 14:33:33.049938 22509476222784 run_lib.py:133] step: 391300, training_loss: 3.97877e-02
I0211 14:33:33.214425 22509476222784 run_lib.py:146] step: 391300, eval_loss: 4.48105e-02
I0211 14:33:51.750845 22509476222784 run_lib.py:133] step: 391350, training_loss: 4.72200e-02
I0211 14:34:10.298849 22509476222784 run_lib.py:133] step: 391400, training_loss: 3.49549e-02
I0211 14:34:10.465379 22509476222784 run_lib.py:146] step: 391400, eval_loss: 5.51603e-02
I0211 14:34:28.939865 22509476222784 run_lib.py:133] step: 391450, training_loss: 4.35941e-02
I0211 14:34:47.606170 22509476222784 run_lib.py:133] step: 391500, training_loss: 4.31997e-02
I0211 14:34:47.774919 22509476222784 run_lib.py:146] step: 391500, eval_loss: 4.05414e-02
I0211 14:35:06.332246 22509476222784 run_lib.py:133] step: 391550, training_loss: 3.63887e-02
I0211 14:35:24.796871 22509476222784 run_lib.py:133] step: 391600, training_loss: 4.44644e-02
I0211 14:35:24.968582 22509476222784 run_lib.py:146] step: 391600, eval_loss: 5.21916e-02
I0211 14:35:43.374054 22509476222784 run_lib.py:133] step: 391650, training_loss: 3.93557e-02
I0211 14:36:02.050201 22509476222784 run_lib.py:133] step: 391700, training_loss: 5.51444e-02
I0211 14:36:02.213600 22509476222784 run_lib.py:146] step: 391700, eval_loss: 4.47145e-02
I0211 14:36:20.675025 22509476222784 run_lib.py:133] step: 391750, training_loss: 4.45835e-02
I0211 14:36:39.282565 22509476222784 run_lib.py:133] step: 391800, training_loss: 5.59728e-02
I0211 14:36:39.446707 22509476222784 run_lib.py:146] step: 391800, eval_loss: 4.16654e-02
I0211 14:36:58.027858 22509476222784 run_lib.py:133] step: 391850, training_loss: 3.59926e-02
I0211 14:37:16.569090 22509476222784 run_lib.py:133] step: 391900, training_loss: 4.00096e-02
I0211 14:37:16.729732 22509476222784 run_lib.py:146] step: 391900, eval_loss: 4.02328e-02
I0211 14:37:35.463680 22509476222784 run_lib.py:133] step: 391950, training_loss: 3.91307e-02
I0211 14:37:54.029117 22509476222784 run_lib.py:133] step: 392000, training_loss: 4.69745e-02
I0211 14:37:54.192789 22509476222784 run_lib.py:146] step: 392000, eval_loss: 3.73127e-02
I0211 14:38:12.691617 22509476222784 run_lib.py:133] step: 392050, training_loss: 3.82428e-02
I0211 14:38:31.286707 22509476222784 run_lib.py:133] step: 392100, training_loss: 4.46986e-02
I0211 14:38:31.453715 22509476222784 run_lib.py:146] step: 392100, eval_loss: 4.47232e-02
I0211 14:38:50.186945 22509476222784 run_lib.py:133] step: 392150, training_loss: 4.16916e-02
I0211 14:39:08.736675 22509476222784 run_lib.py:133] step: 392200, training_loss: 4.75074e-02
I0211 14:39:08.901617 22509476222784 run_lib.py:146] step: 392200, eval_loss: 4.49428e-02
I0211 14:39:27.593981 22509476222784 run_lib.py:133] step: 392250, training_loss: 2.88297e-02
I0211 14:39:46.140778 22509476222784 run_lib.py:133] step: 392300, training_loss: 3.76962e-02
I0211 14:39:46.323844 22509476222784 run_lib.py:146] step: 392300, eval_loss: 5.00093e-02
I0211 14:40:05.041016 22509476222784 run_lib.py:133] step: 392350, training_loss: 3.83466e-02
I0211 14:40:23.590546 22509476222784 run_lib.py:133] step: 392400, training_loss: 5.17374e-02
I0211 14:40:23.758989 22509476222784 run_lib.py:146] step: 392400, eval_loss: 4.82022e-02
I0211 14:40:42.285317 22509476222784 run_lib.py:133] step: 392450, training_loss: 5.10188e-02
I0211 14:41:01.054314 22509476222784 run_lib.py:133] step: 392500, training_loss: 4.76286e-02
I0211 14:41:01.220832 22509476222784 run_lib.py:146] step: 392500, eval_loss: 3.51151e-02
I0211 14:41:19.762477 22509476222784 run_lib.py:133] step: 392550, training_loss: 4.75752e-02
I0211 14:41:38.478544 22509476222784 run_lib.py:133] step: 392600, training_loss: 4.14838e-02
I0211 14:41:38.641712 22509476222784 run_lib.py:146] step: 392600, eval_loss: 4.79113e-02
I0211 14:41:57.176525 22509476222784 run_lib.py:133] step: 392650, training_loss: 3.72230e-02
I0211 14:42:15.766304 22509476222784 run_lib.py:133] step: 392700, training_loss: 3.46391e-02
I0211 14:42:15.932212 22509476222784 run_lib.py:146] step: 392700, eval_loss: 4.33939e-02
I0211 14:42:34.626976 22509476222784 run_lib.py:133] step: 392750, training_loss: 3.87857e-02
I0211 14:42:53.131914 22509476222784 run_lib.py:133] step: 392800, training_loss: 4.71178e-02
I0211 14:42:53.293638 22509476222784 run_lib.py:146] step: 392800, eval_loss: 4.45815e-02
I0211 14:43:11.831444 22509476222784 run_lib.py:133] step: 392850, training_loss: 4.81617e-02
I0211 14:43:30.531843 22509476222784 run_lib.py:133] step: 392900, training_loss: 3.80265e-02
I0211 14:43:30.700973 22509476222784 run_lib.py:146] step: 392900, eval_loss: 3.77714e-02
I0211 14:43:49.332862 22509476222784 run_lib.py:133] step: 392950, training_loss: 3.85777e-02
I0211 14:44:07.865169 22509476222784 run_lib.py:133] step: 393000, training_loss: 4.46779e-02
I0211 14:44:08.029606 22509476222784 run_lib.py:146] step: 393000, eval_loss: 4.05741e-02
I0211 14:44:26.637960 22509476222784 run_lib.py:133] step: 393050, training_loss: 4.48578e-02
I0211 14:44:45.186737 22509476222784 run_lib.py:133] step: 393100, training_loss: 3.85857e-02
I0211 14:44:45.350608 22509476222784 run_lib.py:146] step: 393100, eval_loss: 5.50548e-02
I0211 14:45:03.914163 22509476222784 run_lib.py:133] step: 393150, training_loss: 3.45085e-02
I0211 14:45:22.494271 22509476222784 run_lib.py:133] step: 393200, training_loss: 5.26192e-02
I0211 14:45:22.658958 22509476222784 run_lib.py:146] step: 393200, eval_loss: 5.44306e-02
I0211 14:45:41.432887 22509476222784 run_lib.py:133] step: 393250, training_loss: 3.77446e-02
I0211 14:46:00.065380 22509476222784 run_lib.py:133] step: 393300, training_loss: 4.88009e-02
I0211 14:46:00.226718 22509476222784 run_lib.py:146] step: 393300, eval_loss: 4.73404e-02
I0211 14:46:18.810414 22509476222784 run_lib.py:133] step: 393350, training_loss: 4.25710e-02
I0211 14:46:37.330639 22509476222784 run_lib.py:133] step: 393400, training_loss: 3.76771e-02
I0211 14:46:37.494668 22509476222784 run_lib.py:146] step: 393400, eval_loss: 3.38891e-02
I0211 14:46:56.214107 22509476222784 run_lib.py:133] step: 393450, training_loss: 3.22826e-02
I0211 14:47:14.829791 22509476222784 run_lib.py:133] step: 393500, training_loss: 4.00745e-02
I0211 14:47:14.996734 22509476222784 run_lib.py:146] step: 393500, eval_loss: 4.17316e-02
I0211 14:47:33.695318 22509476222784 run_lib.py:133] step: 393550, training_loss: 4.27299e-02
I0211 14:47:52.225266 22509476222784 run_lib.py:133] step: 393600, training_loss: 4.00522e-02
I0211 14:47:52.423581 22509476222784 run_lib.py:146] step: 393600, eval_loss: 3.67641e-02
I0211 14:48:11.051636 22509476222784 run_lib.py:133] step: 393650, training_loss: 5.34167e-02
I0211 14:48:29.527903 22509476222784 run_lib.py:133] step: 393700, training_loss: 3.24528e-02
I0211 14:48:29.690680 22509476222784 run_lib.py:146] step: 393700, eval_loss: 4.91572e-02
I0211 14:48:48.431341 22509476222784 run_lib.py:133] step: 393750, training_loss: 3.21735e-02
I0211 14:49:07.010854 22509476222784 run_lib.py:133] step: 393800, training_loss: 4.46169e-02
I0211 14:49:07.175961 22509476222784 run_lib.py:146] step: 393800, eval_loss: 3.63083e-02
I0211 14:49:25.712395 22509476222784 run_lib.py:133] step: 393850, training_loss: 4.16075e-02
I0211 14:49:44.428309 22509476222784 run_lib.py:133] step: 393900, training_loss: 4.21682e-02
I0211 14:49:44.589981 22509476222784 run_lib.py:146] step: 393900, eval_loss: 4.75272e-02
I0211 14:50:03.106206 22509476222784 run_lib.py:133] step: 393950, training_loss: 4.03736e-02
I0211 14:50:21.590267 22509476222784 run_lib.py:133] step: 394000, training_loss: 3.95955e-02
I0211 14:50:21.769469 22509476222784 run_lib.py:146] step: 394000, eval_loss: 4.50623e-02
I0211 14:50:40.454315 22509476222784 run_lib.py:133] step: 394050, training_loss: 4.90880e-02
I0211 14:50:58.975382 22509476222784 run_lib.py:133] step: 394100, training_loss: 4.58444e-02
I0211 14:50:59.139814 22509476222784 run_lib.py:146] step: 394100, eval_loss: 3.39402e-02
I0211 14:51:17.857996 22509476222784 run_lib.py:133] step: 394150, training_loss: 4.45902e-02
I0211 14:51:36.340973 22509476222784 run_lib.py:133] step: 394200, training_loss: 5.34803e-02
I0211 14:51:36.540468 22509476222784 run_lib.py:146] step: 394200, eval_loss: 3.40278e-02
I0211 14:51:55.056010 22509476222784 run_lib.py:133] step: 394250, training_loss: 3.84967e-02
I0211 14:52:13.763703 22509476222784 run_lib.py:133] step: 394300, training_loss: 6.13255e-02
I0211 14:52:13.928846 22509476222784 run_lib.py:146] step: 394300, eval_loss: 4.98235e-02
I0211 14:52:32.471946 22509476222784 run_lib.py:133] step: 394350, training_loss: 5.24602e-02
I0211 14:52:51.030635 22509476222784 run_lib.py:133] step: 394400, training_loss: 5.07834e-02
I0211 14:52:51.196484 22509476222784 run_lib.py:146] step: 394400, eval_loss: 4.94145e-02
I0211 14:53:09.706934 22509476222784 run_lib.py:133] step: 394450, training_loss: 3.91672e-02
I0211 14:53:28.399726 22509476222784 run_lib.py:133] step: 394500, training_loss: 4.04801e-02
I0211 14:53:28.563698 22509476222784 run_lib.py:146] step: 394500, eval_loss: 4.00277e-02
I0211 14:53:47.100345 22509476222784 run_lib.py:133] step: 394550, training_loss: 4.22207e-02
I0211 14:54:05.687890 22509476222784 run_lib.py:133] step: 394600, training_loss: 4.37975e-02
I0211 14:54:05.853061 22509476222784 run_lib.py:146] step: 394600, eval_loss: 4.91895e-02
I0211 14:54:24.361352 22509476222784 run_lib.py:133] step: 394650, training_loss: 5.38756e-02
I0211 14:54:42.889471 22509476222784 run_lib.py:133] step: 394700, training_loss: 4.43924e-02
I0211 14:54:43.051384 22509476222784 run_lib.py:146] step: 394700, eval_loss: 4.48714e-02
I0211 14:55:01.751467 22509476222784 run_lib.py:133] step: 394750, training_loss: 4.27856e-02
I0211 14:55:20.363470 22509476222784 run_lib.py:133] step: 394800, training_loss: 3.70196e-02
I0211 14:55:20.533798 22509476222784 run_lib.py:146] step: 394800, eval_loss: 3.28135e-02
I0211 14:55:39.076234 22509476222784 run_lib.py:133] step: 394850, training_loss: 4.71149e-02
I0211 14:55:57.554539 22509476222784 run_lib.py:133] step: 394900, training_loss: 5.17918e-02
I0211 14:55:57.744611 22509476222784 run_lib.py:146] step: 394900, eval_loss: 3.83227e-02
I0211 14:56:16.411637 22509476222784 run_lib.py:133] step: 394950, training_loss: 5.01057e-02
I0211 14:56:34.890639 22509476222784 run_lib.py:133] step: 395000, training_loss: 3.23058e-02
I0211 14:56:35.057705 22509476222784 run_lib.py:146] step: 395000, eval_loss: 3.95114e-02
I0211 14:56:53.665484 22509476222784 run_lib.py:133] step: 395050, training_loss: 4.22000e-02
I0211 14:57:12.167166 22509476222784 run_lib.py:133] step: 395100, training_loss: 3.96130e-02
I0211 14:57:12.337017 22509476222784 run_lib.py:146] step: 395100, eval_loss: 3.94795e-02
I0211 14:57:31.078865 22509476222784 run_lib.py:133] step: 395150, training_loss: 5.24568e-02
I0211 14:57:49.585890 22509476222784 run_lib.py:133] step: 395200, training_loss: 5.23359e-02
I0211 14:57:49.746833 22509476222784 run_lib.py:146] step: 395200, eval_loss: 3.36342e-02
I0211 14:58:08.222817 22509476222784 run_lib.py:133] step: 395250, training_loss: 3.84473e-02
I0211 14:58:26.905302 22509476222784 run_lib.py:133] step: 395300, training_loss: 4.27941e-02
I0211 14:58:27.069640 22509476222784 run_lib.py:146] step: 395300, eval_loss: 3.73426e-02
I0211 14:58:45.478533 22509476222784 run_lib.py:133] step: 395350, training_loss: 5.17838e-02
I0211 14:59:04.153731 22509476222784 run_lib.py:133] step: 395400, training_loss: 3.96688e-02
I0211 14:59:04.334697 22509476222784 run_lib.py:146] step: 395400, eval_loss: 5.04053e-02
I0211 14:59:22.867114 22509476222784 run_lib.py:133] step: 395450, training_loss: 5.53630e-02
I0211 14:59:41.363293 22509476222784 run_lib.py:133] step: 395500, training_loss: 4.29588e-02
I0211 14:59:41.527587 22509476222784 run_lib.py:146] step: 395500, eval_loss: 3.16188e-02
I0211 15:00:00.222658 22509476222784 run_lib.py:133] step: 395550, training_loss: 3.76120e-02
I0211 15:00:18.764231 22509476222784 run_lib.py:133] step: 395600, training_loss: 3.51458e-02
I0211 15:00:18.926688 22509476222784 run_lib.py:146] step: 395600, eval_loss: 3.46490e-02
I0211 15:00:37.463529 22509476222784 run_lib.py:133] step: 395650, training_loss: 5.19041e-02
I0211 15:00:56.189757 22509476222784 run_lib.py:133] step: 395700, training_loss: 4.17919e-02
I0211 15:00:56.356790 22509476222784 run_lib.py:146] step: 395700, eval_loss: 3.50480e-02
I0211 15:01:14.989002 22509476222784 run_lib.py:133] step: 395750, training_loss: 5.26756e-02
I0211 15:01:33.560533 22509476222784 run_lib.py:133] step: 395800, training_loss: 4.39312e-02
I0211 15:01:33.913591 22509476222784 run_lib.py:146] step: 395800, eval_loss: 4.16760e-02
I0211 15:01:52.437543 22509476222784 run_lib.py:133] step: 395850, training_loss: 4.52459e-02
I0211 15:02:10.929199 22509476222784 run_lib.py:133] step: 395900, training_loss: 5.47844e-02
I0211 15:02:11.103824 22509476222784 run_lib.py:146] step: 395900, eval_loss: 4.05741e-02
I0211 15:02:29.630395 22509476222784 run_lib.py:133] step: 395950, training_loss: 4.81093e-02
I0211 15:02:48.187036 22509476222784 run_lib.py:133] step: 396000, training_loss: 5.45483e-02
I0211 15:02:48.352012 22509476222784 run_lib.py:146] step: 396000, eval_loss: 4.41678e-02
I0211 15:03:07.143671 22509476222784 run_lib.py:133] step: 396050, training_loss: 5.17663e-02
I0211 15:03:25.831434 22509476222784 run_lib.py:133] step: 396100, training_loss: 4.09566e-02
I0211 15:03:25.995659 22509476222784 run_lib.py:146] step: 396100, eval_loss: 4.20222e-02
I0211 15:03:44.491005 22509476222784 run_lib.py:133] step: 396150, training_loss: 3.33112e-02
I0211 15:04:03.060960 22509476222784 run_lib.py:133] step: 396200, training_loss: 4.26217e-02
I0211 15:04:03.227993 22509476222784 run_lib.py:146] step: 396200, eval_loss: 3.86588e-02
I0211 15:04:22.012543 22509476222784 run_lib.py:133] step: 396250, training_loss: 5.61694e-02
I0211 15:04:40.670359 22509476222784 run_lib.py:133] step: 396300, training_loss: 4.42105e-02
I0211 15:04:40.836748 22509476222784 run_lib.py:146] step: 396300, eval_loss: 2.98929e-02
I0211 15:04:59.325286 22509476222784 run_lib.py:133] step: 396350, training_loss: 3.89463e-02
I0211 15:05:17.857824 22509476222784 run_lib.py:133] step: 396400, training_loss: 5.45850e-02
I0211 15:05:18.068546 22509476222784 run_lib.py:146] step: 396400, eval_loss: 4.94681e-02
I0211 15:05:36.756759 22509476222784 run_lib.py:133] step: 396450, training_loss: 4.04344e-02
I0211 15:05:55.354983 22509476222784 run_lib.py:133] step: 396500, training_loss: 4.92619e-02
I0211 15:05:55.545422 22509476222784 run_lib.py:146] step: 396500, eval_loss: 3.85286e-02
I0211 15:06:14.334910 22509476222784 run_lib.py:133] step: 396550, training_loss: 3.59727e-02
I0211 15:06:32.863605 22509476222784 run_lib.py:133] step: 396600, training_loss: 4.34410e-02
I0211 15:06:33.025781 22509476222784 run_lib.py:146] step: 396600, eval_loss: 5.71406e-02
I0211 15:06:51.672957 22509476222784 run_lib.py:133] step: 396650, training_loss: 5.28164e-02
I0211 15:07:10.219808 22509476222784 run_lib.py:133] step: 396700, training_loss: 4.28654e-02
I0211 15:07:10.381686 22509476222784 run_lib.py:146] step: 396700, eval_loss: 4.77781e-02
I0211 15:07:28.859466 22509476222784 run_lib.py:133] step: 396750, training_loss: 5.22883e-02
I0211 15:07:47.535559 22509476222784 run_lib.py:133] step: 396800, training_loss: 4.73764e-02
I0211 15:07:47.709485 22509476222784 run_lib.py:146] step: 396800, eval_loss: 3.80001e-02
I0211 15:08:06.191857 22509476222784 run_lib.py:133] step: 396850, training_loss: 3.86458e-02
I0211 15:08:24.876173 22509476222784 run_lib.py:133] step: 396900, training_loss: 5.23698e-02
I0211 15:08:25.040707 22509476222784 run_lib.py:146] step: 396900, eval_loss: 4.14749e-02
I0211 15:08:43.533739 22509476222784 run_lib.py:133] step: 396950, training_loss: 3.81395e-02
I0211 15:09:02.024587 22509476222784 run_lib.py:133] step: 397000, training_loss: 3.30001e-02
I0211 15:09:02.188693 22509476222784 run_lib.py:146] step: 397000, eval_loss: 4.25655e-02
I0211 15:09:20.705861 22509476222784 run_lib.py:133] step: 397050, training_loss: 4.55440e-02
I0211 15:09:39.271077 22509476222784 run_lib.py:133] step: 397100, training_loss: 4.49499e-02
I0211 15:09:39.435827 22509476222784 run_lib.py:146] step: 397100, eval_loss: 3.23814e-02
I0211 15:09:57.947996 22509476222784 run_lib.py:133] step: 397150, training_loss: 3.62430e-02
I0211 15:10:16.438276 22509476222784 run_lib.py:133] step: 397200, training_loss: 3.95009e-02
I0211 15:10:16.602542 22509476222784 run_lib.py:146] step: 397200, eval_loss: 4.31265e-02
I0211 15:10:35.187118 22509476222784 run_lib.py:133] step: 397250, training_loss: 4.65093e-02
I0211 15:10:53.618994 22509476222784 run_lib.py:133] step: 397300, training_loss: 4.04509e-02
I0211 15:10:53.797650 22509476222784 run_lib.py:146] step: 397300, eval_loss: 3.62262e-02
I0211 15:11:12.438265 22509476222784 run_lib.py:133] step: 397350, training_loss: 4.06859e-02
I0211 15:11:30.935857 22509476222784 run_lib.py:133] step: 397400, training_loss: 4.70528e-02
I0211 15:11:31.099778 22509476222784 run_lib.py:146] step: 397400, eval_loss: 4.93739e-02
I0211 15:11:49.625638 22509476222784 run_lib.py:133] step: 397450, training_loss: 3.41931e-02
I0211 15:12:08.102441 22509476222784 run_lib.py:133] step: 397500, training_loss: 4.96637e-02
I0211 15:12:08.267140 22509476222784 run_lib.py:146] step: 397500, eval_loss: 3.74895e-02
I0211 15:12:26.846082 22509476222784 run_lib.py:133] step: 397550, training_loss: 4.28477e-02
I0211 15:12:45.462164 22509476222784 run_lib.py:133] step: 397600, training_loss: 4.86001e-02
I0211 15:12:45.626882 22509476222784 run_lib.py:146] step: 397600, eval_loss: 4.36312e-02
I0211 15:13:04.149999 22509476222784 run_lib.py:133] step: 397650, training_loss: 3.82059e-02
I0211 15:13:22.600671 22509476222784 run_lib.py:133] step: 397700, training_loss: 3.69650e-02
I0211 15:13:22.764971 22509476222784 run_lib.py:146] step: 397700, eval_loss: 3.49911e-02
I0211 15:13:41.422984 22509476222784 run_lib.py:133] step: 397750, training_loss: 3.97121e-02
I0211 15:13:59.928285 22509476222784 run_lib.py:133] step: 397800, training_loss: 4.94270e-02
I0211 15:14:00.092902 22509476222784 run_lib.py:146] step: 397800, eval_loss: 3.95729e-02
I0211 15:14:18.784631 22509476222784 run_lib.py:133] step: 397850, training_loss: 4.25506e-02
I0211 15:14:37.358516 22509476222784 run_lib.py:133] step: 397900, training_loss: 3.86411e-02
I0211 15:14:37.523095 22509476222784 run_lib.py:146] step: 397900, eval_loss: 4.83101e-02
I0211 15:14:56.200081 22509476222784 run_lib.py:133] step: 397950, training_loss: 2.60399e-02
I0211 15:15:14.705784 22509476222784 run_lib.py:133] step: 398000, training_loss: 4.38631e-02
I0211 15:15:14.875717 22509476222784 run_lib.py:146] step: 398000, eval_loss: 3.34611e-02
I0211 15:15:33.520339 22509476222784 run_lib.py:133] step: 398050, training_loss: 3.83363e-02
I0211 15:15:52.031704 22509476222784 run_lib.py:133] step: 398100, training_loss: 4.33780e-02
I0211 15:15:52.231904 22509476222784 run_lib.py:146] step: 398100, eval_loss: 4.54239e-02
I0211 15:16:10.787315 22509476222784 run_lib.py:133] step: 398150, training_loss: 3.78734e-02
I0211 15:16:29.469746 22509476222784 run_lib.py:133] step: 398200, training_loss: 4.32876e-02
I0211 15:16:29.634258 22509476222784 run_lib.py:146] step: 398200, eval_loss: 2.98675e-02
I0211 15:16:48.072643 22509476222784 run_lib.py:133] step: 398250, training_loss: 4.08714e-02
I0211 15:17:06.472192 22509476222784 run_lib.py:133] step: 398300, training_loss: 4.90297e-02
I0211 15:17:06.635720 22509476222784 run_lib.py:146] step: 398300, eval_loss: 5.19933e-02
I0211 15:17:25.334645 22509476222784 run_lib.py:133] step: 398350, training_loss: 3.62474e-02
I0211 15:17:44.000441 22509476222784 run_lib.py:133] step: 398400, training_loss: 4.15507e-02
I0211 15:17:44.170669 22509476222784 run_lib.py:146] step: 398400, eval_loss: 4.70143e-02
I0211 15:18:02.694259 22509476222784 run_lib.py:133] step: 398450, training_loss: 3.77876e-02
I0211 15:18:21.223707 22509476222784 run_lib.py:133] step: 398500, training_loss: 3.98430e-02
I0211 15:18:21.383883 22509476222784 run_lib.py:146] step: 398500, eval_loss: 3.69065e-02
I0211 15:18:39.979966 22509476222784 run_lib.py:133] step: 398550, training_loss: 3.67059e-02
I0211 15:18:58.677079 22509476222784 run_lib.py:133] step: 398600, training_loss: 4.20100e-02
I0211 15:18:58.842022 22509476222784 run_lib.py:146] step: 398600, eval_loss: 4.42020e-02
I0211 15:19:17.363507 22509476222784 run_lib.py:133] step: 398650, training_loss: 4.56008e-02
I0211 15:19:35.901132 22509476222784 run_lib.py:133] step: 398700, training_loss: 5.09518e-02
I0211 15:19:36.082559 22509476222784 run_lib.py:146] step: 398700, eval_loss: 5.00014e-02
I0211 15:19:54.630503 22509476222784 run_lib.py:133] step: 398750, training_loss: 3.42268e-02
I0211 15:20:13.382811 22509476222784 run_lib.py:133] step: 398800, training_loss: 3.83302e-02
I0211 15:20:13.547992 22509476222784 run_lib.py:146] step: 398800, eval_loss: 3.92467e-02
I0211 15:20:32.081518 22509476222784 run_lib.py:133] step: 398850, training_loss: 4.46411e-02
I0211 15:20:50.566126 22509476222784 run_lib.py:133] step: 398900, training_loss: 3.84872e-02
I0211 15:20:50.729678 22509476222784 run_lib.py:146] step: 398900, eval_loss: 5.49991e-02
I0211 15:21:09.216238 22509476222784 run_lib.py:133] step: 398950, training_loss: 5.68327e-02
I0211 15:21:27.755270 22509476222784 run_lib.py:133] step: 399000, training_loss: 3.84061e-02
I0211 15:21:27.918913 22509476222784 run_lib.py:146] step: 399000, eval_loss: 4.93319e-02
I0211 15:21:46.642427 22509476222784 run_lib.py:133] step: 399050, training_loss: 5.18470e-02
I0211 15:22:05.188507 22509476222784 run_lib.py:133] step: 399100, training_loss: 4.73410e-02
I0211 15:22:05.353733 22509476222784 run_lib.py:146] step: 399100, eval_loss: 3.66191e-02
I0211 15:22:23.893656 22509476222784 run_lib.py:133] step: 399150, training_loss: 4.07469e-02
I0211 15:22:42.394512 22509476222784 run_lib.py:133] step: 399200, training_loss: 3.68069e-02
I0211 15:22:42.561975 22509476222784 run_lib.py:146] step: 399200, eval_loss: 4.44069e-02
I0211 15:23:01.164030 22509476222784 run_lib.py:133] step: 399250, training_loss: 3.27104e-02
I0211 15:23:19.664801 22509476222784 run_lib.py:133] step: 399300, training_loss: 3.98078e-02
I0211 15:23:19.829898 22509476222784 run_lib.py:146] step: 399300, eval_loss: 4.11138e-02
I0211 15:23:38.504975 22509476222784 run_lib.py:133] step: 399350, training_loss: 4.78212e-02
I0211 15:23:56.935578 22509476222784 run_lib.py:133] step: 399400, training_loss: 4.21154e-02
I0211 15:23:57.097525 22509476222784 run_lib.py:146] step: 399400, eval_loss: 4.00850e-02
I0211 15:24:15.729667 22509476222784 run_lib.py:133] step: 399450, training_loss: 4.77592e-02
I0211 15:24:34.213540 22509476222784 run_lib.py:133] step: 399500, training_loss: 3.81641e-02
I0211 15:24:34.372776 22509476222784 run_lib.py:146] step: 399500, eval_loss: 4.93350e-02
I0211 15:24:52.947352 22509476222784 run_lib.py:133] step: 399550, training_loss: 3.87489e-02
I0211 15:25:11.666545 22509476222784 run_lib.py:133] step: 399600, training_loss: 5.00928e-02
I0211 15:25:11.831667 22509476222784 run_lib.py:146] step: 399600, eval_loss: 3.33387e-02
I0211 15:25:30.326741 22509476222784 run_lib.py:133] step: 399650, training_loss: 5.26453e-02
I0211 15:25:48.968765 22509476222784 run_lib.py:133] step: 399700, training_loss: 4.62565e-02
I0211 15:25:49.136087 22509476222784 run_lib.py:146] step: 399700, eval_loss: 3.32607e-02
I0211 15:26:07.660399 22509476222784 run_lib.py:133] step: 399750, training_loss: 3.77318e-02
I0211 15:26:26.162864 22509476222784 run_lib.py:133] step: 399800, training_loss: 4.72283e-02
I0211 15:26:26.326619 22509476222784 run_lib.py:146] step: 399800, eval_loss: 3.51244e-02
I0211 15:26:44.914149 22509476222784 run_lib.py:133] step: 399850, training_loss: 3.77875e-02
I0211 15:27:03.436076 22509476222784 run_lib.py:133] step: 399900, training_loss: 3.42464e-02
I0211 15:27:03.599793 22509476222784 run_lib.py:146] step: 399900, eval_loss: 3.48918e-02
I0211 15:27:22.147511 22509476222784 run_lib.py:133] step: 399950, training_loss: 3.84275e-02
I0211 15:27:40.831694 22509476222784 run_lib.py:133] step: 400000, training_loss: 5.19539e-02
I0211 15:27:41.879536 22509476222784 run_lib.py:146] step: 400000, eval_loss: 3.51478e-02
I0211 15:28:03.007606 22509476222784 run_lib.py:133] step: 400050, training_loss: 4.03792e-02
I0211 15:28:21.498298 22509476222784 run_lib.py:133] step: 400100, training_loss: 3.07854e-02
I0211 15:28:21.669763 22509476222784 run_lib.py:146] step: 400100, eval_loss: 4.15546e-02
I0211 15:28:40.174286 22509476222784 run_lib.py:133] step: 400150, training_loss: 4.65776e-02
I0211 15:28:58.893717 22509476222784 run_lib.py:133] step: 400200, training_loss: 3.05484e-02
I0211 15:28:59.106579 22509476222784 run_lib.py:146] step: 400200, eval_loss: 3.75975e-02
I0211 15:29:17.589242 22509476222784 run_lib.py:133] step: 400250, training_loss: 3.55051e-02
I0211 15:29:36.095473 22509476222784 run_lib.py:133] step: 400300, training_loss: 5.00086e-02
I0211 15:29:36.259659 22509476222784 run_lib.py:146] step: 400300, eval_loss: 2.59211e-02
I0211 15:29:54.893709 22509476222784 run_lib.py:133] step: 400350, training_loss: 3.76007e-02
I0211 15:30:13.452120 22509476222784 run_lib.py:133] step: 400400, training_loss: 3.62214e-02
I0211 15:30:13.616293 22509476222784 run_lib.py:146] step: 400400, eval_loss: 3.78746e-02
I0211 15:30:32.186608 22509476222784 run_lib.py:133] step: 400450, training_loss: 4.65870e-02
I0211 15:30:50.617276 22509476222784 run_lib.py:133] step: 400500, training_loss: 4.05301e-02
I0211 15:30:50.782448 22509476222784 run_lib.py:146] step: 400500, eval_loss: 5.51631e-02
I0211 15:31:09.279809 22509476222784 run_lib.py:133] step: 400550, training_loss: 4.68467e-02
I0211 15:31:27.771618 22509476222784 run_lib.py:133] step: 400600, training_loss: 3.68017e-02
I0211 15:31:27.945739 22509476222784 run_lib.py:146] step: 400600, eval_loss: 4.60575e-02
I0211 15:31:46.639622 22509476222784 run_lib.py:133] step: 400650, training_loss: 4.44434e-02
I0211 15:32:05.240057 22509476222784 run_lib.py:133] step: 400700, training_loss: 3.96161e-02
I0211 15:32:05.415553 22509476222784 run_lib.py:146] step: 400700, eval_loss: 4.68926e-02
I0211 15:32:23.897701 22509476222784 run_lib.py:133] step: 400750, training_loss: 3.68930e-02
I0211 15:32:42.379952 22509476222784 run_lib.py:133] step: 400800, training_loss: 4.25215e-02
I0211 15:32:42.586520 22509476222784 run_lib.py:146] step: 400800, eval_loss: 4.55128e-02
I0211 15:33:01.263601 22509476222784 run_lib.py:133] step: 400850, training_loss: 3.68862e-02
I0211 15:33:19.745279 22509476222784 run_lib.py:133] step: 400900, training_loss: 3.31061e-02
I0211 15:33:19.907577 22509476222784 run_lib.py:146] step: 400900, eval_loss: 3.98048e-02
I0211 15:33:38.587300 22509476222784 run_lib.py:133] step: 400950, training_loss: 4.92774e-02
I0211 15:33:57.087117 22509476222784 run_lib.py:133] step: 401000, training_loss: 4.54756e-02
I0211 15:33:57.251754 22509476222784 run_lib.py:146] step: 401000, eval_loss: 4.60071e-02
I0211 15:34:15.831152 22509476222784 run_lib.py:133] step: 401050, training_loss: 3.51463e-02
I0211 15:34:34.212592 22509476222784 run_lib.py:133] step: 401100, training_loss: 4.01427e-02
I0211 15:34:34.377965 22509476222784 run_lib.py:146] step: 401100, eval_loss: 3.58928e-02
I0211 15:34:52.906635 22509476222784 run_lib.py:133] step: 401150, training_loss: 5.35129e-02
I0211 15:35:11.364684 22509476222784 run_lib.py:133] step: 401200, training_loss: 5.58814e-02
I0211 15:35:11.545736 22509476222784 run_lib.py:146] step: 401200, eval_loss: 3.38755e-02
I0211 15:35:30.119602 22509476222784 run_lib.py:133] step: 401250, training_loss: 3.47480e-02
I0211 15:35:48.818633 22509476222784 run_lib.py:133] step: 401300, training_loss: 4.94884e-02
I0211 15:35:48.983331 22509476222784 run_lib.py:146] step: 401300, eval_loss: 4.56466e-02
I0211 15:36:07.433410 22509476222784 run_lib.py:133] step: 401350, training_loss: 4.35428e-02
I0211 15:36:25.902157 22509476222784 run_lib.py:133] step: 401400, training_loss: 3.83600e-02
I0211 15:36:26.073600 22509476222784 run_lib.py:146] step: 401400, eval_loss: 4.90254e-02
I0211 15:36:44.703964 22509476222784 run_lib.py:133] step: 401450, training_loss: 4.81627e-02
I0211 15:37:03.187107 22509476222784 run_lib.py:133] step: 401500, training_loss: 4.06409e-02
I0211 15:37:03.352856 22509476222784 run_lib.py:146] step: 401500, eval_loss: 3.63013e-02
I0211 15:37:22.049844 22509476222784 run_lib.py:133] step: 401550, training_loss: 3.10348e-02
I0211 15:37:40.553570 22509476222784 run_lib.py:133] step: 401600, training_loss: 3.63975e-02
I0211 15:37:40.719751 22509476222784 run_lib.py:146] step: 401600, eval_loss: 4.07054e-02
I0211 15:37:59.127155 22509476222784 run_lib.py:133] step: 401650, training_loss: 4.19647e-02
I0211 15:38:17.792632 22509476222784 run_lib.py:133] step: 401700, training_loss: 3.04600e-02
I0211 15:38:17.982575 22509476222784 run_lib.py:146] step: 401700, eval_loss: 4.04412e-02
I0211 15:38:36.480486 22509476222784 run_lib.py:133] step: 401750, training_loss: 4.21172e-02
I0211 15:38:54.978554 22509476222784 run_lib.py:133] step: 401800, training_loss: 2.85210e-02
I0211 15:38:55.143172 22509476222784 run_lib.py:146] step: 401800, eval_loss: 4.15508e-02
I0211 15:39:13.650746 22509476222784 run_lib.py:133] step: 401850, training_loss: 4.27859e-02
I0211 15:39:32.299435 22509476222784 run_lib.py:133] step: 401900, training_loss: 4.63407e-02
I0211 15:39:32.459654 22509476222784 run_lib.py:146] step: 401900, eval_loss: 3.72472e-02
I0211 15:39:50.955204 22509476222784 run_lib.py:133] step: 401950, training_loss: 6.84097e-02
I0211 15:40:09.525009 22509476222784 run_lib.py:133] step: 402000, training_loss: 4.19596e-02
I0211 15:40:09.726742 22509476222784 run_lib.py:146] step: 402000, eval_loss: 3.31200e-02
I0211 15:40:28.259320 22509476222784 run_lib.py:133] step: 402050, training_loss: 3.63684e-02
I0211 15:40:46.815406 22509476222784 run_lib.py:133] step: 402100, training_loss: 5.04897e-02
I0211 15:40:46.978986 22509476222784 run_lib.py:146] step: 402100, eval_loss: 4.66318e-02
I0211 15:41:05.669729 22509476222784 run_lib.py:133] step: 402150, training_loss: 3.25408e-02
I0211 15:41:24.213214 22509476222784 run_lib.py:133] step: 402200, training_loss: 4.00026e-02
I0211 15:41:24.376559 22509476222784 run_lib.py:146] step: 402200, eval_loss: 4.73943e-02
I0211 15:41:42.812650 22509476222784 run_lib.py:133] step: 402250, training_loss: 4.25278e-02
I0211 15:42:01.317905 22509476222784 run_lib.py:133] step: 402300, training_loss: 5.23198e-02
I0211 15:42:01.485308 22509476222784 run_lib.py:146] step: 402300, eval_loss: 3.38202e-02
I0211 15:42:20.184915 22509476222784 run_lib.py:133] step: 402350, training_loss: 3.76863e-02
I0211 15:42:38.674366 22509476222784 run_lib.py:133] step: 402400, training_loss: 2.96824e-02
I0211 15:42:38.836913 22509476222784 run_lib.py:146] step: 402400, eval_loss: 5.22909e-02
I0211 15:42:57.529398 22509476222784 run_lib.py:133] step: 402450, training_loss: 5.46191e-02
I0211 15:43:16.000208 22509476222784 run_lib.py:133] step: 402500, training_loss: 2.85447e-02
I0211 15:43:16.162586 22509476222784 run_lib.py:146] step: 402500, eval_loss: 5.35062e-02
I0211 15:43:34.742761 22509476222784 run_lib.py:133] step: 402550, training_loss: 4.52269e-02
I0211 15:43:53.268244 22509476222784 run_lib.py:133] step: 402600, training_loss: 4.06742e-02
I0211 15:43:53.481687 22509476222784 run_lib.py:146] step: 402600, eval_loss: 4.64971e-02
I0211 15:44:11.947175 22509476222784 run_lib.py:133] step: 402650, training_loss: 4.36697e-02
I0211 15:44:30.590674 22509476222784 run_lib.py:133] step: 402700, training_loss: 4.11063e-02
I0211 15:44:30.755947 22509476222784 run_lib.py:146] step: 402700, eval_loss: 4.41871e-02
I0211 15:44:49.274389 22509476222784 run_lib.py:133] step: 402750, training_loss: 3.54578e-02
I0211 15:45:07.782980 22509476222784 run_lib.py:133] step: 402800, training_loss: 4.67471e-02
I0211 15:45:07.944448 22509476222784 run_lib.py:146] step: 402800, eval_loss: 4.09108e-02
I0211 15:45:26.391205 22509476222784 run_lib.py:133] step: 402850, training_loss: 4.34175e-02
I0211 15:45:44.952730 22509476222784 run_lib.py:133] step: 402900, training_loss: 4.43127e-02
I0211 15:45:45.126839 22509476222784 run_lib.py:146] step: 402900, eval_loss: 3.79265e-02
I0211 15:46:03.902686 22509476222784 run_lib.py:133] step: 402950, training_loss: 4.70115e-02
I0211 15:46:22.331275 22509476222784 run_lib.py:133] step: 403000, training_loss: 4.38340e-02
I0211 15:46:22.496718 22509476222784 run_lib.py:146] step: 403000, eval_loss: 3.94958e-02
I0211 15:46:40.980278 22509476222784 run_lib.py:133] step: 403050, training_loss: 3.86089e-02
I0211 15:46:59.651035 22509476222784 run_lib.py:133] step: 403100, training_loss: 4.18199e-02
I0211 15:46:59.814783 22509476222784 run_lib.py:146] step: 403100, eval_loss: 4.15315e-02
I0211 15:47:18.331683 22509476222784 run_lib.py:133] step: 403150, training_loss: 4.35554e-02
I0211 15:47:36.872090 22509476222784 run_lib.py:133] step: 403200, training_loss: 3.65211e-02
I0211 15:47:37.226377 22509476222784 run_lib.py:146] step: 403200, eval_loss: 4.30719e-02
I0211 15:47:55.746912 22509476222784 run_lib.py:133] step: 403250, training_loss: 4.23124e-02
I0211 15:48:14.255589 22509476222784 run_lib.py:133] step: 403300, training_loss: 3.34734e-02
I0211 15:48:14.456382 22509476222784 run_lib.py:146] step: 403300, eval_loss: 4.31906e-02
I0211 15:48:32.915632 22509476222784 run_lib.py:133] step: 403350, training_loss: 4.26600e-02
I0211 15:48:51.416536 22509476222784 run_lib.py:133] step: 403400, training_loss: 4.25560e-02
I0211 15:48:51.579785 22509476222784 run_lib.py:146] step: 403400, eval_loss: 4.15735e-02
I0211 15:49:10.250915 22509476222784 run_lib.py:133] step: 403450, training_loss: 3.65265e-02
I0211 15:49:28.854207 22509476222784 run_lib.py:133] step: 403500, training_loss: 4.16690e-02
I0211 15:49:29.028685 22509476222784 run_lib.py:146] step: 403500, eval_loss: 4.95232e-02
I0211 15:49:47.513305 22509476222784 run_lib.py:133] step: 403550, training_loss: 3.69814e-02
I0211 15:50:06.010640 22509476222784 run_lib.py:133] step: 403600, training_loss: 4.07953e-02
I0211 15:50:06.226608 22509476222784 run_lib.py:146] step: 403600, eval_loss: 4.97668e-02
I0211 15:50:24.937041 22509476222784 run_lib.py:133] step: 403650, training_loss: 4.00129e-02
I0211 15:50:43.510518 22509476222784 run_lib.py:133] step: 403700, training_loss: 4.43628e-02
I0211 15:50:43.700312 22509476222784 run_lib.py:146] step: 403700, eval_loss: 3.19556e-02
I0211 15:51:02.187298 22509476222784 run_lib.py:133] step: 403750, training_loss: 4.08723e-02
I0211 15:51:20.724065 22509476222784 run_lib.py:133] step: 403800, training_loss: 3.17102e-02
I0211 15:51:20.887446 22509476222784 run_lib.py:146] step: 403800, eval_loss: 3.88624e-02
I0211 15:51:39.572026 22509476222784 run_lib.py:133] step: 403850, training_loss: 4.68336e-02
I0211 15:51:58.024279 22509476222784 run_lib.py:133] step: 403900, training_loss: 3.76555e-02
I0211 15:51:58.191437 22509476222784 run_lib.py:146] step: 403900, eval_loss: 3.29965e-02
I0211 15:52:16.746458 22509476222784 run_lib.py:133] step: 403950, training_loss: 3.60416e-02
I0211 15:52:35.260767 22509476222784 run_lib.py:133] step: 404000, training_loss: 3.87608e-02
I0211 15:52:35.440647 22509476222784 run_lib.py:146] step: 404000, eval_loss: 4.42752e-02
I0211 15:52:54.188033 22509476222784 run_lib.py:133] step: 404050, training_loss: 4.76039e-02
I0211 15:53:12.720890 22509476222784 run_lib.py:133] step: 404100, training_loss: 4.48968e-02
I0211 15:53:12.883835 22509476222784 run_lib.py:146] step: 404100, eval_loss: 3.30850e-02
I0211 15:53:31.321532 22509476222784 run_lib.py:133] step: 404150, training_loss: 3.62908e-02
I0211 15:53:49.898251 22509476222784 run_lib.py:133] step: 404200, training_loss: 4.43987e-02
I0211 15:53:50.062654 22509476222784 run_lib.py:146] step: 404200, eval_loss: 2.88953e-02
I0211 15:54:08.530272 22509476222784 run_lib.py:133] step: 404250, training_loss: 3.47975e-02
I0211 15:54:27.099262 22509476222784 run_lib.py:133] step: 404300, training_loss: 3.87886e-02
I0211 15:54:27.263257 22509476222784 run_lib.py:146] step: 404300, eval_loss: 3.14400e-02
I0211 15:54:45.825229 22509476222784 run_lib.py:133] step: 404350, training_loss: 4.31619e-02
I0211 15:55:04.299621 22509476222784 run_lib.py:133] step: 404400, training_loss: 3.75559e-02
I0211 15:55:04.463717 22509476222784 run_lib.py:146] step: 404400, eval_loss: 4.08603e-02
I0211 15:55:22.982752 22509476222784 run_lib.py:133] step: 404450, training_loss: 4.27513e-02
I0211 15:55:41.624446 22509476222784 run_lib.py:133] step: 404500, training_loss: 4.95744e-02
I0211 15:55:41.791121 22509476222784 run_lib.py:146] step: 404500, eval_loss: 3.82498e-02
I0211 15:56:00.267151 22509476222784 run_lib.py:133] step: 404550, training_loss: 3.71193e-02
I0211 15:56:18.786121 22509476222784 run_lib.py:133] step: 404600, training_loss: 4.82306e-02
I0211 15:56:18.946400 22509476222784 run_lib.py:146] step: 404600, eval_loss: 5.17326e-02
I0211 15:56:37.675450 22509476222784 run_lib.py:133] step: 404650, training_loss: 4.13649e-02
I0211 15:56:56.191245 22509476222784 run_lib.py:133] step: 404700, training_loss: 3.60228e-02
I0211 15:56:56.354560 22509476222784 run_lib.py:146] step: 404700, eval_loss: 4.38344e-02
I0211 15:57:14.899627 22509476222784 run_lib.py:133] step: 404750, training_loss: 4.40180e-02
I0211 15:57:33.394032 22509476222784 run_lib.py:133] step: 404800, training_loss: 4.03065e-02
I0211 15:57:33.553688 22509476222784 run_lib.py:146] step: 404800, eval_loss: 4.58952e-02
I0211 15:57:52.105174 22509476222784 run_lib.py:133] step: 404850, training_loss: 3.31080e-02
I0211 15:58:10.622559 22509476222784 run_lib.py:133] step: 404900, training_loss: 3.62196e-02
I0211 15:58:10.790741 22509476222784 run_lib.py:146] step: 404900, eval_loss: 4.02915e-02
I0211 15:58:29.456944 22509476222784 run_lib.py:133] step: 404950, training_loss: 3.74168e-02
I0211 15:58:48.030386 22509476222784 run_lib.py:133] step: 405000, training_loss: 4.94983e-02
I0211 15:58:48.208645 22509476222784 run_lib.py:146] step: 405000, eval_loss: 4.25617e-02
I0211 15:59:06.718973 22509476222784 run_lib.py:133] step: 405050, training_loss: 4.07268e-02
I0211 15:59:25.254112 22509476222784 run_lib.py:133] step: 405100, training_loss: 3.27971e-02
I0211 15:59:25.437683 22509476222784 run_lib.py:146] step: 405100, eval_loss: 5.09090e-02
I0211 15:59:44.105927 22509476222784 run_lib.py:133] step: 405150, training_loss: 4.62916e-02
I0211 16:00:02.718447 22509476222784 run_lib.py:133] step: 405200, training_loss: 4.95549e-02
I0211 16:00:02.882365 22509476222784 run_lib.py:146] step: 405200, eval_loss: 5.80966e-02
I0211 16:00:21.627729 22509476222784 run_lib.py:133] step: 405250, training_loss: 4.00374e-02
I0211 16:00:40.147975 22509476222784 run_lib.py:133] step: 405300, training_loss: 3.83525e-02
I0211 16:00:40.312640 22509476222784 run_lib.py:146] step: 405300, eval_loss: 4.04239e-02
I0211 16:00:58.914262 22509476222784 run_lib.py:133] step: 405350, training_loss: 4.78251e-02
I0211 16:01:17.357495 22509476222784 run_lib.py:133] step: 405400, training_loss: 3.63503e-02
I0211 16:01:17.523755 22509476222784 run_lib.py:146] step: 405400, eval_loss: 3.68585e-02
I0211 16:01:36.230537 22509476222784 run_lib.py:133] step: 405450, training_loss: 4.10233e-02
I0211 16:01:54.830367 22509476222784 run_lib.py:133] step: 405500, training_loss: 4.42127e-02
I0211 16:01:54.996307 22509476222784 run_lib.py:146] step: 405500, eval_loss: 3.73124e-02
I0211 16:02:13.449511 22509476222784 run_lib.py:133] step: 405550, training_loss: 3.53148e-02
I0211 16:02:32.129990 22509476222784 run_lib.py:133] step: 405600, training_loss: 4.33994e-02
I0211 16:02:32.298773 22509476222784 run_lib.py:146] step: 405600, eval_loss: 5.12068e-02
I0211 16:02:50.787715 22509476222784 run_lib.py:133] step: 405650, training_loss: 3.84696e-02
I0211 16:03:09.270522 22509476222784 run_lib.py:133] step: 405700, training_loss: 5.20833e-02
I0211 16:03:09.432650 22509476222784 run_lib.py:146] step: 405700, eval_loss: 4.24981e-02
I0211 16:03:28.116741 22509476222784 run_lib.py:133] step: 405750, training_loss: 4.97647e-02
I0211 16:03:46.839162 22509476222784 run_lib.py:133] step: 405800, training_loss: 3.78512e-02
I0211 16:03:47.002701 22509476222784 run_lib.py:146] step: 405800, eval_loss: 4.13069e-02
I0211 16:04:05.477843 22509476222784 run_lib.py:133] step: 405850, training_loss: 4.03696e-02
I0211 16:04:23.993362 22509476222784 run_lib.py:133] step: 405900, training_loss: 4.21996e-02
I0211 16:04:24.162939 22509476222784 run_lib.py:146] step: 405900, eval_loss: 3.49078e-02
I0211 16:04:42.690452 22509476222784 run_lib.py:133] step: 405950, training_loss: 5.22063e-02
I0211 16:05:01.419798 22509476222784 run_lib.py:133] step: 406000, training_loss: 3.98238e-02
I0211 16:05:01.586721 22509476222784 run_lib.py:146] step: 406000, eval_loss: 4.17347e-02
I0211 16:05:20.128069 22509476222784 run_lib.py:133] step: 406050, training_loss: 4.02844e-02
I0211 16:05:38.624044 22509476222784 run_lib.py:133] step: 406100, training_loss: 2.68462e-02
I0211 16:05:38.788733 22509476222784 run_lib.py:146] step: 406100, eval_loss: 4.17128e-02
I0211 16:05:57.288515 22509476222784 run_lib.py:133] step: 406150, training_loss: 3.81216e-02
I0211 16:06:16.013823 22509476222784 run_lib.py:133] step: 406200, training_loss: 4.38334e-02
I0211 16:06:16.174652 22509476222784 run_lib.py:146] step: 406200, eval_loss: 4.23760e-02
I0211 16:06:34.693123 22509476222784 run_lib.py:133] step: 406250, training_loss: 4.11684e-02
I0211 16:06:53.284075 22509476222784 run_lib.py:133] step: 406300, training_loss: 4.66522e-02
I0211 16:06:53.458403 22509476222784 run_lib.py:146] step: 406300, eval_loss: 4.20252e-02
I0211 16:07:12.037501 22509476222784 run_lib.py:133] step: 406350, training_loss: 4.68202e-02
I0211 16:07:30.572752 22509476222784 run_lib.py:133] step: 406400, training_loss: 4.10018e-02
I0211 16:07:30.739900 22509476222784 run_lib.py:146] step: 406400, eval_loss: 4.13422e-02
I0211 16:07:49.441884 22509476222784 run_lib.py:133] step: 406450, training_loss: 5.31468e-02
I0211 16:08:08.053867 22509476222784 run_lib.py:133] step: 406500, training_loss: 4.10961e-02
I0211 16:08:08.220634 22509476222784 run_lib.py:146] step: 406500, eval_loss: 3.76796e-02
I0211 16:08:26.782337 22509476222784 run_lib.py:133] step: 406550, training_loss: 4.01084e-02
I0211 16:08:45.431137 22509476222784 run_lib.py:133] step: 406600, training_loss: 2.97003e-02
I0211 16:08:45.643876 22509476222784 run_lib.py:146] step: 406600, eval_loss: 3.36754e-02
I0211 16:09:04.402782 22509476222784 run_lib.py:133] step: 406650, training_loss: 3.71965e-02
I0211 16:09:22.973492 22509476222784 run_lib.py:133] step: 406700, training_loss: 5.02228e-02
I0211 16:09:23.216627 22509476222784 run_lib.py:146] step: 406700, eval_loss: 4.42568e-02
I0211 16:09:41.830608 22509476222784 run_lib.py:133] step: 406750, training_loss: 4.42009e-02
I0211 16:10:00.393909 22509476222784 run_lib.py:133] step: 406800, training_loss: 4.68107e-02
I0211 16:10:00.560495 22509476222784 run_lib.py:146] step: 406800, eval_loss: 3.99432e-02
I0211 16:10:19.291253 22509476222784 run_lib.py:133] step: 406850, training_loss: 4.44259e-02
I0211 16:10:37.935038 22509476222784 run_lib.py:133] step: 406900, training_loss: 3.90230e-02
I0211 16:10:38.099875 22509476222784 run_lib.py:146] step: 406900, eval_loss: 4.07580e-02
I0211 16:10:56.611096 22509476222784 run_lib.py:133] step: 406950, training_loss: 4.79447e-02
I0211 16:11:15.366406 22509476222784 run_lib.py:133] step: 407000, training_loss: 4.67154e-02
I0211 16:11:15.532005 22509476222784 run_lib.py:146] step: 407000, eval_loss: 4.35496e-02
I0211 16:11:34.081758 22509476222784 run_lib.py:133] step: 407050, training_loss: 3.69855e-02
I0211 16:11:52.787328 22509476222784 run_lib.py:133] step: 407100, training_loss: 3.65533e-02
I0211 16:11:52.951032 22509476222784 run_lib.py:146] step: 407100, eval_loss: 4.42772e-02
I0211 16:12:11.555377 22509476222784 run_lib.py:133] step: 407150, training_loss: 4.93478e-02
I0211 16:12:30.034779 22509476222784 run_lib.py:133] step: 407200, training_loss: 4.07461e-02
I0211 16:12:30.196521 22509476222784 run_lib.py:146] step: 407200, eval_loss: 5.27021e-02
I0211 16:12:48.847534 22509476222784 run_lib.py:133] step: 407250, training_loss: 3.82715e-02
I0211 16:13:07.334372 22509476222784 run_lib.py:133] step: 407300, training_loss: 5.11019e-02
I0211 16:13:07.501905 22509476222784 run_lib.py:146] step: 407300, eval_loss: 3.81091e-02
I0211 16:13:26.015840 22509476222784 run_lib.py:133] step: 407350, training_loss: 4.12137e-02
I0211 16:13:44.650608 22509476222784 run_lib.py:133] step: 407400, training_loss: 4.50207e-02
I0211 16:13:44.818362 22509476222784 run_lib.py:146] step: 407400, eval_loss: 4.92097e-02
I0211 16:14:03.280536 22509476222784 run_lib.py:133] step: 407450, training_loss: 2.92918e-02
I0211 16:14:21.727420 22509476222784 run_lib.py:133] step: 407500, training_loss: 4.37929e-02
I0211 16:14:21.899308 22509476222784 run_lib.py:146] step: 407500, eval_loss: 3.70458e-02
I0211 16:14:40.546114 22509476222784 run_lib.py:133] step: 407550, training_loss: 4.75309e-02
I0211 16:14:59.049020 22509476222784 run_lib.py:133] step: 407600, training_loss: 4.07552e-02
I0211 16:14:59.216687 22509476222784 run_lib.py:146] step: 407600, eval_loss: 4.05865e-02
I0211 16:15:17.726185 22509476222784 run_lib.py:133] step: 407650, training_loss: 3.52272e-02
I0211 16:15:36.295147 22509476222784 run_lib.py:133] step: 407700, training_loss: 5.27162e-02
I0211 16:15:36.470818 22509476222784 run_lib.py:146] step: 407700, eval_loss: 4.48569e-02
I0211 16:15:55.240760 22509476222784 run_lib.py:133] step: 407750, training_loss: 5.78286e-02
I0211 16:16:13.954777 22509476222784 run_lib.py:133] step: 407800, training_loss: 4.57277e-02
I0211 16:16:14.120800 22509476222784 run_lib.py:146] step: 407800, eval_loss: 4.50994e-02
I0211 16:16:32.636859 22509476222784 run_lib.py:133] step: 407850, training_loss: 3.87575e-02
I0211 16:16:51.151905 22509476222784 run_lib.py:133] step: 407900, training_loss: 3.57129e-02
I0211 16:16:51.318594 22509476222784 run_lib.py:146] step: 407900, eval_loss: 4.64990e-02
I0211 16:17:09.940093 22509476222784 run_lib.py:133] step: 407950, training_loss: 3.89401e-02
I0211 16:17:28.521561 22509476222784 run_lib.py:133] step: 408000, training_loss: 4.58875e-02
I0211 16:17:28.686861 22509476222784 run_lib.py:146] step: 408000, eval_loss: 4.00524e-02
I0211 16:17:47.477054 22509476222784 run_lib.py:133] step: 408050, training_loss: 3.95477e-02
I0211 16:18:06.069108 22509476222784 run_lib.py:133] step: 408100, training_loss: 4.51676e-02
I0211 16:18:06.230710 22509476222784 run_lib.py:146] step: 408100, eval_loss: 4.42082e-02
I0211 16:18:24.887447 22509476222784 run_lib.py:133] step: 408150, training_loss: 4.63649e-02
I0211 16:18:43.453321 22509476222784 run_lib.py:133] step: 408200, training_loss: 3.04843e-02
I0211 16:18:43.635606 22509476222784 run_lib.py:146] step: 408200, eval_loss: 4.44129e-02
I0211 16:19:02.372857 22509476222784 run_lib.py:133] step: 408250, training_loss: 5.12808e-02
I0211 16:19:20.978073 22509476222784 run_lib.py:133] step: 408300, training_loss: 4.64425e-02
I0211 16:19:21.144603 22509476222784 run_lib.py:146] step: 408300, eval_loss: 4.03858e-02
I0211 16:19:39.700983 22509476222784 run_lib.py:133] step: 408350, training_loss: 4.99534e-02
I0211 16:19:58.320621 22509476222784 run_lib.py:133] step: 408400, training_loss: 4.20530e-02
I0211 16:19:58.488812 22509476222784 run_lib.py:146] step: 408400, eval_loss: 6.00631e-02
I0211 16:20:16.989554 22509476222784 run_lib.py:133] step: 408450, training_loss: 2.99697e-02
I0211 16:20:35.639400 22509476222784 run_lib.py:133] step: 408500, training_loss: 3.55767e-02
I0211 16:20:35.806927 22509476222784 run_lib.py:146] step: 408500, eval_loss: 5.60386e-02
I0211 16:20:54.529418 22509476222784 run_lib.py:133] step: 408550, training_loss: 4.02069e-02
I0211 16:21:13.085259 22509476222784 run_lib.py:133] step: 408600, training_loss: 3.87782e-02
I0211 16:21:13.265720 22509476222784 run_lib.py:146] step: 408600, eval_loss: 3.82615e-02
I0211 16:21:31.925985 22509476222784 run_lib.py:133] step: 408650, training_loss: 5.39485e-02
I0211 16:21:50.480302 22509476222784 run_lib.py:133] step: 408700, training_loss: 3.87935e-02
I0211 16:21:50.660640 22509476222784 run_lib.py:146] step: 408700, eval_loss: 4.00280e-02
I0211 16:22:09.266779 22509476222784 run_lib.py:133] step: 408750, training_loss: 3.63029e-02
I0211 16:22:28.013174 22509476222784 run_lib.py:133] step: 408800, training_loss: 4.28254e-02
I0211 16:22:28.203995 22509476222784 run_lib.py:146] step: 408800, eval_loss: 4.24512e-02
I0211 16:22:46.728626 22509476222784 run_lib.py:133] step: 408850, training_loss: 3.93227e-02
I0211 16:23:05.175487 22509476222784 run_lib.py:133] step: 408900, training_loss: 4.06993e-02
I0211 16:23:05.339442 22509476222784 run_lib.py:146] step: 408900, eval_loss: 4.76843e-02
I0211 16:23:23.866515 22509476222784 run_lib.py:133] step: 408950, training_loss: 4.17217e-02
I0211 16:23:42.615726 22509476222784 run_lib.py:133] step: 409000, training_loss: 5.80214e-02
I0211 16:23:42.801504 22509476222784 run_lib.py:146] step: 409000, eval_loss: 4.53012e-02
I0211 16:24:01.395689 22509476222784 run_lib.py:133] step: 409050, training_loss: 3.75027e-02
I0211 16:24:20.045622 22509476222784 run_lib.py:133] step: 409100, training_loss: 3.88095e-02
I0211 16:24:20.209688 22509476222784 run_lib.py:146] step: 409100, eval_loss: 4.61741e-02
I0211 16:24:38.715119 22509476222784 run_lib.py:133] step: 409150, training_loss: 3.24319e-02
I0211 16:24:57.266529 22509476222784 run_lib.py:133] step: 409200, training_loss: 4.87671e-02
I0211 16:24:57.462881 22509476222784 run_lib.py:146] step: 409200, eval_loss: 4.30472e-02
I0211 16:25:16.116820 22509476222784 run_lib.py:133] step: 409250, training_loss: 4.39543e-02
I0211 16:25:34.862200 22509476222784 run_lib.py:133] step: 409300, training_loss: 4.18874e-02
I0211 16:25:35.027846 22509476222784 run_lib.py:146] step: 409300, eval_loss: 3.75898e-02
I0211 16:25:53.556062 22509476222784 run_lib.py:133] step: 409350, training_loss: 4.55565e-02
I0211 16:26:12.055912 22509476222784 run_lib.py:133] step: 409400, training_loss: 3.75673e-02
I0211 16:26:12.289782 22509476222784 run_lib.py:146] step: 409400, eval_loss: 4.21560e-02
I0211 16:26:30.970815 22509476222784 run_lib.py:133] step: 409450, training_loss: 3.67541e-02
I0211 16:26:49.503471 22509476222784 run_lib.py:133] step: 409500, training_loss: 3.64689e-02
I0211 16:26:49.722999 22509476222784 run_lib.py:146] step: 409500, eval_loss: 4.20939e-02
I0211 16:27:08.521262 22509476222784 run_lib.py:133] step: 409550, training_loss: 4.36879e-02
I0211 16:27:26.990703 22509476222784 run_lib.py:133] step: 409600, training_loss: 4.57079e-02
I0211 16:27:27.155738 22509476222784 run_lib.py:146] step: 409600, eval_loss: 5.34368e-02
I0211 16:27:45.937567 22509476222784 run_lib.py:133] step: 409650, training_loss: 4.23166e-02
I0211 16:28:04.462117 22509476222784 run_lib.py:133] step: 409700, training_loss: 4.57209e-02
I0211 16:28:04.626860 22509476222784 run_lib.py:146] step: 409700, eval_loss: 5.26630e-02
I0211 16:28:23.134417 22509476222784 run_lib.py:133] step: 409750, training_loss: 4.74835e-02
I0211 16:28:41.817005 22509476222784 run_lib.py:133] step: 409800, training_loss: 3.59469e-02
I0211 16:28:42.043704 22509476222784 run_lib.py:146] step: 409800, eval_loss: 5.35549e-02
I0211 16:29:00.561256 22509476222784 run_lib.py:133] step: 409850, training_loss: 5.21564e-02
I0211 16:29:19.255958 22509476222784 run_lib.py:133] step: 409900, training_loss: 4.49525e-02
I0211 16:29:19.417748 22509476222784 run_lib.py:146] step: 409900, eval_loss: 4.29522e-02
I0211 16:29:37.957591 22509476222784 run_lib.py:133] step: 409950, training_loss: 2.97832e-02
I0211 16:29:56.486783 22509476222784 run_lib.py:133] step: 410000, training_loss: 3.79774e-02
I0211 16:29:57.338574 22509476222784 run_lib.py:146] step: 410000, eval_loss: 4.27398e-02
I0211 16:30:18.737880 22509476222784 run_lib.py:133] step: 410050, training_loss: 3.19400e-02
I0211 16:30:37.284171 22509476222784 run_lib.py:133] step: 410100, training_loss: 3.50252e-02
I0211 16:30:37.451758 22509476222784 run_lib.py:146] step: 410100, eval_loss: 4.71999e-02
I0211 16:30:56.206266 22509476222784 run_lib.py:133] step: 410150, training_loss: 5.21111e-02
I0211 16:31:14.754354 22509476222784 run_lib.py:133] step: 410200, training_loss: 5.18020e-02
I0211 16:31:14.955848 22509476222784 run_lib.py:146] step: 410200, eval_loss: 3.41026e-02
I0211 16:31:33.434471 22509476222784 run_lib.py:133] step: 410250, training_loss: 4.23798e-02
I0211 16:31:52.090823 22509476222784 run_lib.py:133] step: 410300, training_loss: 3.87441e-02
I0211 16:31:52.254721 22509476222784 run_lib.py:146] step: 410300, eval_loss: 3.39650e-02
I0211 16:32:10.774227 22509476222784 run_lib.py:133] step: 410350, training_loss: 4.28808e-02
I0211 16:32:29.548210 22509476222784 run_lib.py:133] step: 410400, training_loss: 4.05436e-02
I0211 16:32:29.732570 22509476222784 run_lib.py:146] step: 410400, eval_loss: 4.60323e-02
I0211 16:32:48.276178 22509476222784 run_lib.py:133] step: 410450, training_loss: 3.99583e-02
I0211 16:33:06.790472 22509476222784 run_lib.py:133] step: 410500, training_loss: 4.27501e-02
I0211 16:33:06.982104 22509476222784 run_lib.py:146] step: 410500, eval_loss: 4.01964e-02
I0211 16:33:25.515966 22509476222784 run_lib.py:133] step: 410550, training_loss: 4.04310e-02
I0211 16:33:44.136898 22509476222784 run_lib.py:133] step: 410600, training_loss: 4.37476e-02
I0211 16:33:44.339777 22509476222784 run_lib.py:146] step: 410600, eval_loss: 4.22049e-02
I0211 16:34:02.811510 22509476222784 run_lib.py:133] step: 410650, training_loss: 3.87094e-02
I0211 16:34:21.372101 22509476222784 run_lib.py:133] step: 410700, training_loss: 4.44927e-02
I0211 16:34:21.538615 22509476222784 run_lib.py:146] step: 410700, eval_loss: 4.34331e-02
I0211 16:34:40.219149 22509476222784 run_lib.py:133] step: 410750, training_loss: 3.19962e-02
I0211 16:34:58.709105 22509476222784 run_lib.py:133] step: 410800, training_loss: 4.69647e-02
I0211 16:34:58.895689 22509476222784 run_lib.py:146] step: 410800, eval_loss: 4.62255e-02
I0211 16:35:17.493011 22509476222784 run_lib.py:133] step: 410850, training_loss: 3.93209e-02
I0211 16:35:35.974425 22509476222784 run_lib.py:133] step: 410900, training_loss: 3.80775e-02
I0211 16:35:36.138900 22509476222784 run_lib.py:146] step: 410900, eval_loss: 5.30848e-02
I0211 16:35:54.699544 22509476222784 run_lib.py:133] step: 410950, training_loss: 5.37201e-02
I0211 16:36:13.213978 22509476222784 run_lib.py:133] step: 411000, training_loss: 4.84072e-02
I0211 16:36:13.379668 22509476222784 run_lib.py:146] step: 411000, eval_loss: 3.98320e-02
I0211 16:36:32.075680 22509476222784 run_lib.py:133] step: 411050, training_loss: 3.04282e-02
I0211 16:36:50.663280 22509476222784 run_lib.py:133] step: 411100, training_loss: 3.17195e-02
I0211 16:36:50.839676 22509476222784 run_lib.py:146] step: 411100, eval_loss: 3.78151e-02
I0211 16:37:09.282335 22509476222784 run_lib.py:133] step: 411150, training_loss: 4.08329e-02
I0211 16:37:27.784040 22509476222784 run_lib.py:133] step: 411200, training_loss: 5.00392e-02
I0211 16:37:27.980876 22509476222784 run_lib.py:146] step: 411200, eval_loss: 3.17850e-02
I0211 16:37:46.746015 22509476222784 run_lib.py:133] step: 411250, training_loss: 4.39244e-02
I0211 16:38:05.331780 22509476222784 run_lib.py:133] step: 411300, training_loss: 4.47103e-02
I0211 16:38:05.534891 22509476222784 run_lib.py:146] step: 411300, eval_loss: 4.31838e-02
I0211 16:38:24.156259 22509476222784 run_lib.py:133] step: 411350, training_loss: 5.40401e-02
I0211 16:38:42.608351 22509476222784 run_lib.py:133] step: 411400, training_loss: 4.50685e-02
I0211 16:38:42.790528 22509476222784 run_lib.py:146] step: 411400, eval_loss: 3.39327e-02
I0211 16:39:01.343749 22509476222784 run_lib.py:133] step: 411450, training_loss: 4.72921e-02
I0211 16:39:19.868140 22509476222784 run_lib.py:133] step: 411500, training_loss: 3.41576e-02
I0211 16:39:20.047766 22509476222784 run_lib.py:146] step: 411500, eval_loss: 3.96625e-02
I0211 16:39:38.799228 22509476222784 run_lib.py:133] step: 411550, training_loss: 5.03206e-02
I0211 16:39:57.359297 22509476222784 run_lib.py:133] step: 411600, training_loss: 4.07415e-02
I0211 16:39:57.527807 22509476222784 run_lib.py:146] step: 411600, eval_loss: 4.60382e-02
I0211 16:40:16.070477 22509476222784 run_lib.py:133] step: 411650, training_loss: 4.38552e-02
I0211 16:40:34.785482 22509476222784 run_lib.py:133] step: 411700, training_loss: 3.85713e-02
I0211 16:40:34.951924 22509476222784 run_lib.py:146] step: 411700, eval_loss: 3.60420e-02
I0211 16:40:53.565997 22509476222784 run_lib.py:133] step: 411750, training_loss: 4.12495e-02
I0211 16:41:12.123914 22509476222784 run_lib.py:133] step: 411800, training_loss: 5.33737e-02
I0211 16:41:12.288057 22509476222784 run_lib.py:146] step: 411800, eval_loss: 3.39466e-02
I0211 16:41:30.961390 22509476222784 run_lib.py:133] step: 411850, training_loss: 4.56833e-02
I0211 16:41:49.473197 22509476222784 run_lib.py:133] step: 411900, training_loss: 3.70421e-02
I0211 16:41:49.674694 22509476222784 run_lib.py:146] step: 411900, eval_loss: 4.00436e-02
I0211 16:42:08.307468 22509476222784 run_lib.py:133] step: 411950, training_loss: 5.14118e-02
I0211 16:42:26.793179 22509476222784 run_lib.py:133] step: 412000, training_loss: 4.32592e-02
I0211 16:42:27.005903 22509476222784 run_lib.py:146] step: 412000, eval_loss: 4.50900e-02
I0211 16:42:45.566146 22509476222784 run_lib.py:133] step: 412050, training_loss: 4.19467e-02
I0211 16:43:04.272583 22509476222784 run_lib.py:133] step: 412100, training_loss: 3.72322e-02
I0211 16:43:04.467598 22509476222784 run_lib.py:146] step: 412100, eval_loss: 4.67195e-02
I0211 16:43:22.922320 22509476222784 run_lib.py:133] step: 412150, training_loss: 4.59679e-02
I0211 16:43:41.374168 22509476222784 run_lib.py:133] step: 412200, training_loss: 4.80178e-02
I0211 16:43:41.617600 22509476222784 run_lib.py:146] step: 412200, eval_loss: 4.97158e-02
I0211 16:44:00.151990 22509476222784 run_lib.py:133] step: 412250, training_loss: 4.12020e-02
I0211 16:44:18.813722 22509476222784 run_lib.py:133] step: 412300, training_loss: 4.36170e-02
I0211 16:44:18.977911 22509476222784 run_lib.py:146] step: 412300, eval_loss: 3.79109e-02
I0211 16:44:37.513167 22509476222784 run_lib.py:133] step: 412350, training_loss: 3.30861e-02
I0211 16:44:56.069375 22509476222784 run_lib.py:133] step: 412400, training_loss: 3.50910e-02
I0211 16:44:56.234280 22509476222784 run_lib.py:146] step: 412400, eval_loss: 4.43509e-02
I0211 16:45:14.624696 22509476222784 run_lib.py:133] step: 412450, training_loss: 3.71718e-02
I0211 16:45:33.098116 22509476222784 run_lib.py:133] step: 412500, training_loss: 4.73792e-02
I0211 16:45:33.263054 22509476222784 run_lib.py:146] step: 412500, eval_loss: 3.83399e-02
I0211 16:45:51.970729 22509476222784 run_lib.py:133] step: 412550, training_loss: 3.47569e-02
I0211 16:46:10.652440 22509476222784 run_lib.py:133] step: 412600, training_loss: 4.90633e-02
I0211 16:46:10.856743 22509476222784 run_lib.py:146] step: 412600, eval_loss: 3.84792e-02
I0211 16:46:29.297343 22509476222784 run_lib.py:133] step: 412650, training_loss: 4.43940e-02
I0211 16:46:47.854591 22509476222784 run_lib.py:133] step: 412700, training_loss: 3.46533e-02
I0211 16:46:48.055638 22509476222784 run_lib.py:146] step: 412700, eval_loss: 3.93050e-02
I0211 16:47:06.736963 22509476222784 run_lib.py:133] step: 412750, training_loss: 3.49285e-02
I0211 16:47:25.274454 22509476222784 run_lib.py:133] step: 412800, training_loss: 3.40092e-02
I0211 16:47:25.440837 22509476222784 run_lib.py:146] step: 412800, eval_loss: 4.23422e-02
I0211 16:47:44.161320 22509476222784 run_lib.py:133] step: 412850, training_loss: 5.53825e-02
I0211 16:48:02.675690 22509476222784 run_lib.py:133] step: 412900, training_loss: 4.31383e-02
I0211 16:48:02.846525 22509476222784 run_lib.py:146] step: 412900, eval_loss: 5.22453e-02
I0211 16:48:21.593214 22509476222784 run_lib.py:133] step: 412950, training_loss: 4.53135e-02
I0211 16:48:40.124173 22509476222784 run_lib.py:133] step: 413000, training_loss: 3.65277e-02
I0211 16:48:40.322623 22509476222784 run_lib.py:146] step: 413000, eval_loss: 3.07292e-02
I0211 16:48:58.872928 22509476222784 run_lib.py:133] step: 413050, training_loss: 3.10977e-02
I0211 16:49:17.513810 22509476222784 run_lib.py:133] step: 413100, training_loss: 5.03815e-02
I0211 16:49:17.696634 22509476222784 run_lib.py:146] step: 413100, eval_loss: 3.53207e-02
I0211 16:49:36.240207 22509476222784 run_lib.py:133] step: 413150, training_loss: 4.42137e-02
I0211 16:49:54.956151 22509476222784 run_lib.py:133] step: 413200, training_loss: 3.80026e-02
I0211 16:49:55.119754 22509476222784 run_lib.py:146] step: 413200, eval_loss: 4.49759e-02
I0211 16:50:13.629982 22509476222784 run_lib.py:133] step: 413250, training_loss: 3.89995e-02
I0211 16:50:32.103750 22509476222784 run_lib.py:133] step: 413300, training_loss: 3.97123e-02
I0211 16:50:32.267667 22509476222784 run_lib.py:146] step: 413300, eval_loss: 4.29788e-02
I0211 16:50:50.861974 22509476222784 run_lib.py:133] step: 413350, training_loss: 4.20716e-02
I0211 16:51:09.408587 22509476222784 run_lib.py:133] step: 413400, training_loss: 3.96946e-02
I0211 16:51:09.573798 22509476222784 run_lib.py:146] step: 413400, eval_loss: 4.60232e-02
I0211 16:51:28.214648 22509476222784 run_lib.py:133] step: 413450, training_loss: 4.54948e-02
I0211 16:51:46.958541 22509476222784 run_lib.py:133] step: 413500, training_loss: 2.90617e-02
I0211 16:51:47.124779 22509476222784 run_lib.py:146] step: 413500, eval_loss: 4.22129e-02
I0211 16:52:05.644297 22509476222784 run_lib.py:133] step: 413550, training_loss: 4.95512e-02
I0211 16:52:24.209380 22509476222784 run_lib.py:133] step: 413600, training_loss: 3.32081e-02
I0211 16:52:24.526012 22509476222784 run_lib.py:146] step: 413600, eval_loss: 4.59331e-02
I0211 16:52:43.104119 22509476222784 run_lib.py:133] step: 413650, training_loss: 3.32047e-02
I0211 16:53:01.718104 22509476222784 run_lib.py:133] step: 413700, training_loss: 4.67784e-02
I0211 16:53:01.886237 22509476222784 run_lib.py:146] step: 413700, eval_loss: 4.81816e-02
I0211 16:53:20.416898 22509476222784 run_lib.py:133] step: 413750, training_loss: 3.03342e-02
I0211 16:53:38.937672 22509476222784 run_lib.py:133] step: 413800, training_loss: 3.53169e-02
I0211 16:53:39.100669 22509476222784 run_lib.py:146] step: 413800, eval_loss: 3.68700e-02
I0211 16:53:57.756690 22509476222784 run_lib.py:133] step: 413850, training_loss: 3.86687e-02
I0211 16:54:16.366050 22509476222784 run_lib.py:133] step: 413900, training_loss: 5.76992e-02
I0211 16:54:16.554881 22509476222784 run_lib.py:146] step: 413900, eval_loss: 5.44491e-02
I0211 16:54:35.064418 22509476222784 run_lib.py:133] step: 413950, training_loss: 4.58245e-02
I0211 16:54:53.650170 22509476222784 run_lib.py:133] step: 414000, training_loss: 4.33227e-02
I0211 16:54:53.832239 22509476222784 run_lib.py:146] step: 414000, eval_loss: 4.27550e-02
I0211 16:55:12.616309 22509476222784 run_lib.py:133] step: 414050, training_loss: 4.24201e-02
I0211 16:55:31.377590 22509476222784 run_lib.py:133] step: 414100, training_loss: 3.86572e-02
I0211 16:55:31.541764 22509476222784 run_lib.py:146] step: 414100, eval_loss: 4.54096e-02
I0211 16:55:50.054343 22509476222784 run_lib.py:133] step: 414150, training_loss: 4.25882e-02
I0211 16:56:08.568239 22509476222784 run_lib.py:133] step: 414200, training_loss: 4.50928e-02
I0211 16:56:08.733736 22509476222784 run_lib.py:146] step: 414200, eval_loss: 5.93594e-02
I0211 16:56:27.408026 22509476222784 run_lib.py:133] step: 414250, training_loss: 3.89707e-02
I0211 16:56:45.979848 22509476222784 run_lib.py:133] step: 414300, training_loss: 3.51547e-02
I0211 16:56:46.161821 22509476222784 run_lib.py:146] step: 414300, eval_loss: 2.87407e-02
I0211 16:57:04.948925 22509476222784 run_lib.py:133] step: 414350, training_loss: 3.84870e-02
I0211 16:57:23.479838 22509476222784 run_lib.py:133] step: 414400, training_loss: 3.49911e-02
I0211 16:57:23.644607 22509476222784 run_lib.py:146] step: 414400, eval_loss: 4.80466e-02
I0211 16:57:42.297104 22509476222784 run_lib.py:133] step: 414450, training_loss: 4.68668e-02
I0211 16:58:00.846041 22509476222784 run_lib.py:133] step: 414500, training_loss: 5.00519e-02
I0211 16:58:01.033809 22509476222784 run_lib.py:146] step: 414500, eval_loss: 5.44891e-02
I0211 16:58:19.577875 22509476222784 run_lib.py:133] step: 414550, training_loss: 4.82220e-02
I0211 16:58:38.398472 22509476222784 run_lib.py:133] step: 414600, training_loss: 3.66909e-02
I0211 16:58:38.562781 22509476222784 run_lib.py:146] step: 414600, eval_loss: 5.58103e-02
I0211 16:58:57.062150 22509476222784 run_lib.py:133] step: 414650, training_loss: 4.29248e-02
I0211 16:59:15.691686 22509476222784 run_lib.py:133] step: 414700, training_loss: 4.76505e-02
I0211 16:59:15.855686 22509476222784 run_lib.py:146] step: 414700, eval_loss: 3.89057e-02
I0211 16:59:34.384097 22509476222784 run_lib.py:133] step: 414750, training_loss: 3.16081e-02
I0211 16:59:52.859240 22509476222784 run_lib.py:133] step: 414800, training_loss: 4.03527e-02
I0211 16:59:53.030209 22509476222784 run_lib.py:146] step: 414800, eval_loss: 3.41396e-02
I0211 17:00:11.649031 22509476222784 run_lib.py:133] step: 414850, training_loss: 4.04969e-02
I0211 17:00:30.380714 22509476222784 run_lib.py:133] step: 414900, training_loss: 4.40828e-02
I0211 17:00:30.563566 22509476222784 run_lib.py:146] step: 414900, eval_loss: 4.17513e-02
I0211 17:00:49.102627 22509476222784 run_lib.py:133] step: 414950, training_loss: 4.59517e-02
I0211 17:01:07.636636 22509476222784 run_lib.py:133] step: 415000, training_loss: 4.44078e-02
I0211 17:01:07.806923 22509476222784 run_lib.py:146] step: 415000, eval_loss: 3.76513e-02
I0211 17:01:26.524432 22509476222784 run_lib.py:133] step: 415050, training_loss: 4.90149e-02
I0211 17:01:45.142091 22509476222784 run_lib.py:133] step: 415100, training_loss: 4.00614e-02
I0211 17:01:45.306930 22509476222784 run_lib.py:146] step: 415100, eval_loss: 4.80676e-02
I0211 17:02:03.829725 22509476222784 run_lib.py:133] step: 415150, training_loss: 4.23205e-02
I0211 17:02:22.353867 22509476222784 run_lib.py:133] step: 415200, training_loss: 3.29726e-02
I0211 17:02:22.523674 22509476222784 run_lib.py:146] step: 415200, eval_loss: 4.45838e-02
I0211 17:02:41.032080 22509476222784 run_lib.py:133] step: 415250, training_loss: 4.54697e-02
I0211 17:02:59.560267 22509476222784 run_lib.py:133] step: 415300, training_loss: 4.98798e-02
I0211 17:02:59.725731 22509476222784 run_lib.py:146] step: 415300, eval_loss: 4.61220e-02
I0211 17:03:18.415502 22509476222784 run_lib.py:133] step: 415350, training_loss: 2.67529e-02
I0211 17:03:37.062880 22509476222784 run_lib.py:133] step: 415400, training_loss: 5.11994e-02
I0211 17:03:37.274698 22509476222784 run_lib.py:146] step: 415400, eval_loss: 5.17196e-02
I0211 17:03:55.782729 22509476222784 run_lib.py:133] step: 415450, training_loss: 4.85194e-02
I0211 17:04:14.345306 22509476222784 run_lib.py:133] step: 415500, training_loss: 4.34648e-02
I0211 17:04:14.542961 22509476222784 run_lib.py:146] step: 415500, eval_loss: 3.88543e-02
I0211 17:04:33.301943 22509476222784 run_lib.py:133] step: 415550, training_loss: 4.23372e-02
I0211 17:04:51.841046 22509476222784 run_lib.py:133] step: 415600, training_loss: 5.84957e-02
I0211 17:04:52.003729 22509476222784 run_lib.py:146] step: 415600, eval_loss: 2.42727e-02
I0211 17:05:10.577708 22509476222784 run_lib.py:133] step: 415650, training_loss: 4.17725e-02
I0211 17:05:29.123434 22509476222784 run_lib.py:133] step: 415700, training_loss: 3.84237e-02
I0211 17:05:29.314381 22509476222784 run_lib.py:146] step: 415700, eval_loss: 4.75484e-02
I0211 17:05:48.084100 22509476222784 run_lib.py:133] step: 415750, training_loss: 5.07582e-02
I0211 17:06:06.561073 22509476222784 run_lib.py:133] step: 415800, training_loss: 4.92179e-02
I0211 17:06:06.723597 22509476222784 run_lib.py:146] step: 415800, eval_loss: 3.94289e-02
I0211 17:06:25.402999 22509476222784 run_lib.py:133] step: 415850, training_loss: 3.74161e-02
I0211 17:06:43.956683 22509476222784 run_lib.py:133] step: 415900, training_loss: 4.42575e-02
I0211 17:06:44.121773 22509476222784 run_lib.py:146] step: 415900, eval_loss: 4.81404e-02
I0211 17:07:02.612312 22509476222784 run_lib.py:133] step: 415950, training_loss: 5.09454e-02
I0211 17:07:21.278434 22509476222784 run_lib.py:133] step: 416000, training_loss: 5.72904e-02
I0211 17:07:21.443920 22509476222784 run_lib.py:146] step: 416000, eval_loss: 5.23216e-02
I0211 17:07:39.960064 22509476222784 run_lib.py:133] step: 416050, training_loss: 4.29030e-02
I0211 17:07:58.450716 22509476222784 run_lib.py:133] step: 416100, training_loss: 4.90701e-02
I0211 17:07:58.615484 22509476222784 run_lib.py:146] step: 416100, eval_loss: 3.90739e-02
I0211 17:08:17.339600 22509476222784 run_lib.py:133] step: 416150, training_loss: 3.90876e-02
I0211 17:08:36.026200 22509476222784 run_lib.py:133] step: 416200, training_loss: 4.36943e-02
I0211 17:08:36.218500 22509476222784 run_lib.py:146] step: 416200, eval_loss: 4.45525e-02
I0211 17:08:54.791064 22509476222784 run_lib.py:133] step: 416250, training_loss: 3.53948e-02
I0211 17:09:13.411074 22509476222784 run_lib.py:133] step: 416300, training_loss: 4.53213e-02
I0211 17:09:13.584083 22509476222784 run_lib.py:146] step: 416300, eval_loss: 3.36032e-02
I0211 17:09:32.158857 22509476222784 run_lib.py:133] step: 416350, training_loss: 4.28832e-02
I0211 17:09:50.882496 22509476222784 run_lib.py:133] step: 416400, training_loss: 4.07696e-02
I0211 17:09:51.094868 22509476222784 run_lib.py:146] step: 416400, eval_loss: 4.10388e-02
I0211 17:10:09.585937 22509476222784 run_lib.py:133] step: 416450, training_loss: 5.02245e-02
I0211 17:10:28.155311 22509476222784 run_lib.py:133] step: 416500, training_loss: 3.63736e-02
I0211 17:10:28.321619 22509476222784 run_lib.py:146] step: 416500, eval_loss: 4.34528e-02
I0211 17:10:46.854349 22509476222784 run_lib.py:133] step: 416550, training_loss: 4.36171e-02
I0211 17:11:05.604432 22509476222784 run_lib.py:133] step: 416600, training_loss: 4.25002e-02
I0211 17:11:05.769798 22509476222784 run_lib.py:146] step: 416600, eval_loss: 5.95133e-02
I0211 17:11:24.320300 22509476222784 run_lib.py:133] step: 416650, training_loss: 4.50505e-02
I0211 17:11:42.843658 22509476222784 run_lib.py:133] step: 416700, training_loss: 5.65369e-02
I0211 17:11:43.003645 22509476222784 run_lib.py:146] step: 416700, eval_loss: 4.80563e-02
I0211 17:12:01.495522 22509476222784 run_lib.py:133] step: 416750, training_loss: 4.00427e-02
I0211 17:12:19.998073 22509476222784 run_lib.py:133] step: 416800, training_loss: 3.62888e-02
I0211 17:12:20.170789 22509476222784 run_lib.py:146] step: 416800, eval_loss: 3.67003e-02
I0211 17:12:38.841163 22509476222784 run_lib.py:133] step: 416850, training_loss: 4.24886e-02
I0211 17:12:57.411602 22509476222784 run_lib.py:133] step: 416900, training_loss: 4.02391e-02
I0211 17:12:57.577502 22509476222784 run_lib.py:146] step: 416900, eval_loss: 3.50771e-02
I0211 17:13:16.049685 22509476222784 run_lib.py:133] step: 416950, training_loss: 3.59321e-02
I0211 17:13:34.547384 22509476222784 run_lib.py:133] step: 417000, training_loss: 3.85648e-02
I0211 17:13:34.743493 22509476222784 run_lib.py:146] step: 417000, eval_loss: 4.11158e-02
I0211 17:13:53.376370 22509476222784 run_lib.py:133] step: 417050, training_loss: 5.52031e-02
I0211 17:14:11.915619 22509476222784 run_lib.py:133] step: 417100, training_loss: 3.73060e-02
I0211 17:14:12.078880 22509476222784 run_lib.py:146] step: 417100, eval_loss: 4.15890e-02
I0211 17:14:30.822971 22509476222784 run_lib.py:133] step: 417150, training_loss: 4.23840e-02
I0211 17:14:49.328874 22509476222784 run_lib.py:133] step: 417200, training_loss: 4.76181e-02
I0211 17:14:49.490586 22509476222784 run_lib.py:146] step: 417200, eval_loss: 4.16344e-02
I0211 17:15:08.164463 22509476222784 run_lib.py:133] step: 417250, training_loss: 4.10919e-02
I0211 17:15:26.672524 22509476222784 run_lib.py:133] step: 417300, training_loss: 4.89206e-02
I0211 17:15:26.837878 22509476222784 run_lib.py:146] step: 417300, eval_loss: 4.28921e-02
I0211 17:15:45.330727 22509476222784 run_lib.py:133] step: 417350, training_loss: 3.69553e-02
I0211 17:16:04.080601 22509476222784 run_lib.py:133] step: 417400, training_loss: 5.18375e-02
I0211 17:16:04.246685 22509476222784 run_lib.py:146] step: 417400, eval_loss: 5.27871e-02
I0211 17:16:22.678719 22509476222784 run_lib.py:133] step: 417450, training_loss: 4.87941e-02
I0211 17:16:41.351807 22509476222784 run_lib.py:133] step: 417500, training_loss: 5.09720e-02
I0211 17:16:41.565785 22509476222784 run_lib.py:146] step: 417500, eval_loss: 5.06799e-02
I0211 17:17:00.071877 22509476222784 run_lib.py:133] step: 417550, training_loss: 3.64028e-02
I0211 17:17:18.569716 22509476222784 run_lib.py:133] step: 417600, training_loss: 4.59268e-02
I0211 17:17:18.737454 22509476222784 run_lib.py:146] step: 417600, eval_loss: 5.50245e-02
I0211 17:17:37.450777 22509476222784 run_lib.py:133] step: 417650, training_loss: 4.22933e-02
I0211 17:17:56.030205 22509476222784 run_lib.py:133] step: 417700, training_loss: 3.98691e-02
I0211 17:17:56.211031 22509476222784 run_lib.py:146] step: 417700, eval_loss: 4.20715e-02
I0211 17:18:14.726409 22509476222784 run_lib.py:133] step: 417750, training_loss: 4.55082e-02
I0211 17:18:33.387537 22509476222784 run_lib.py:133] step: 417800, training_loss: 5.16547e-02
I0211 17:18:33.554223 22509476222784 run_lib.py:146] step: 417800, eval_loss: 5.82644e-02
I0211 17:18:51.993774 22509476222784 run_lib.py:133] step: 417850, training_loss: 5.54851e-02
I0211 17:19:10.453679 22509476222784 run_lib.py:133] step: 417900, training_loss: 4.91199e-02
I0211 17:19:10.626487 22509476222784 run_lib.py:146] step: 417900, eval_loss: 4.11421e-02
I0211 17:19:29.263994 22509476222784 run_lib.py:133] step: 417950, training_loss: 4.67606e-02
I0211 17:19:47.771458 22509476222784 run_lib.py:133] step: 418000, training_loss: 4.78127e-02
I0211 17:19:47.934938 22509476222784 run_lib.py:146] step: 418000, eval_loss: 3.76172e-02
I0211 17:20:06.484050 22509476222784 run_lib.py:133] step: 418050, training_loss: 4.45331e-02
I0211 17:20:25.080884 22509476222784 run_lib.py:133] step: 418100, training_loss: 4.62153e-02
I0211 17:20:25.241751 22509476222784 run_lib.py:146] step: 418100, eval_loss: 4.26799e-02
I0211 17:20:43.972205 22509476222784 run_lib.py:133] step: 418150, training_loss: 6.07857e-02
I0211 17:21:02.584310 22509476222784 run_lib.py:133] step: 418200, training_loss: 3.73906e-02
I0211 17:21:02.759935 22509476222784 run_lib.py:146] step: 418200, eval_loss: 4.55123e-02
I0211 17:21:21.362264 22509476222784 run_lib.py:133] step: 418250, training_loss: 5.17643e-02
I0211 17:21:39.936345 22509476222784 run_lib.py:133] step: 418300, training_loss: 4.62232e-02
I0211 17:21:40.101880 22509476222784 run_lib.py:146] step: 418300, eval_loss: 4.22506e-02
I0211 17:21:58.838506 22509476222784 run_lib.py:133] step: 418350, training_loss: 3.97382e-02
I0211 17:22:17.370069 22509476222784 run_lib.py:133] step: 418400, training_loss: 4.88420e-02
I0211 17:22:17.534513 22509476222784 run_lib.py:146] step: 418400, eval_loss: 4.65426e-02
I0211 17:22:36.214416 22509476222784 run_lib.py:133] step: 418450, training_loss: 3.37799e-02
I0211 17:22:54.783035 22509476222784 run_lib.py:133] step: 418500, training_loss: 5.04834e-02
I0211 17:22:54.977864 22509476222784 run_lib.py:146] step: 418500, eval_loss: 3.75361e-02
I0211 17:23:13.742697 22509476222784 run_lib.py:133] step: 418550, training_loss: 4.59229e-02
I0211 17:23:32.236608 22509476222784 run_lib.py:133] step: 418600, training_loss: 3.67733e-02
I0211 17:23:32.398694 22509476222784 run_lib.py:146] step: 418600, eval_loss: 4.55624e-02
I0211 17:23:51.047706 22509476222784 run_lib.py:133] step: 418650, training_loss: 3.60346e-02
I0211 17:24:09.556088 22509476222784 run_lib.py:133] step: 418700, training_loss: 4.44345e-02
I0211 17:24:09.766474 22509476222784 run_lib.py:146] step: 418700, eval_loss: 3.20874e-02
I0211 17:24:28.342294 22509476222784 run_lib.py:133] step: 418750, training_loss: 4.58483e-02
I0211 17:24:47.015882 22509476222784 run_lib.py:133] step: 418800, training_loss: 3.51986e-02
I0211 17:24:47.182850 22509476222784 run_lib.py:146] step: 418800, eval_loss: 4.32781e-02
I0211 17:25:05.714062 22509476222784 run_lib.py:133] step: 418850, training_loss: 4.83008e-02
I0211 17:25:24.220354 22509476222784 run_lib.py:133] step: 418900, training_loss: 3.26165e-02
I0211 17:25:24.413719 22509476222784 run_lib.py:146] step: 418900, eval_loss: 5.18339e-02
I0211 17:25:43.175805 22509476222784 run_lib.py:133] step: 418950, training_loss: 4.60707e-02
I0211 17:26:01.699794 22509476222784 run_lib.py:133] step: 419000, training_loss: 4.31209e-02
I0211 17:26:01.889898 22509476222784 run_lib.py:146] step: 419000, eval_loss: 5.31924e-02
I0211 17:26:20.660468 22509476222784 run_lib.py:133] step: 419050, training_loss: 4.82571e-02
I0211 17:26:39.242385 22509476222784 run_lib.py:133] step: 419100, training_loss: 4.09231e-02
I0211 17:26:39.425933 22509476222784 run_lib.py:146] step: 419100, eval_loss: 3.73130e-02
I0211 17:26:57.974621 22509476222784 run_lib.py:133] step: 419150, training_loss: 4.27594e-02
I0211 17:27:16.713948 22509476222784 run_lib.py:133] step: 419200, training_loss: 4.22328e-02
I0211 17:27:16.880796 22509476222784 run_lib.py:146] step: 419200, eval_loss: 3.13335e-02
I0211 17:27:35.406337 22509476222784 run_lib.py:133] step: 419250, training_loss: 4.40166e-02
I0211 17:27:53.985492 22509476222784 run_lib.py:133] step: 419300, training_loss: 4.40682e-02
I0211 17:27:54.157912 22509476222784 run_lib.py:146] step: 419300, eval_loss: 4.34125e-02
I0211 17:28:12.657686 22509476222784 run_lib.py:133] step: 419350, training_loss: 2.84286e-02
I0211 17:28:31.404704 22509476222784 run_lib.py:133] step: 419400, training_loss: 4.66803e-02
I0211 17:28:31.610982 22509476222784 run_lib.py:146] step: 419400, eval_loss: 4.36218e-02
I0211 17:28:50.158266 22509476222784 run_lib.py:133] step: 419450, training_loss: 5.29712e-02
I0211 17:29:08.775590 22509476222784 run_lib.py:133] step: 419500, training_loss: 3.85220e-02
I0211 17:29:08.936561 22509476222784 run_lib.py:146] step: 419500, eval_loss: 3.88428e-02
I0211 17:29:27.404639 22509476222784 run_lib.py:133] step: 419550, training_loss: 4.30402e-02
I0211 17:29:45.983180 22509476222784 run_lib.py:133] step: 419600, training_loss: 4.33046e-02
I0211 17:29:46.163879 22509476222784 run_lib.py:146] step: 419600, eval_loss: 4.59128e-02
I0211 17:30:04.944437 22509476222784 run_lib.py:133] step: 419650, training_loss: 4.92894e-02
I0211 17:30:23.659125 22509476222784 run_lib.py:133] step: 419700, training_loss: 4.65655e-02
I0211 17:30:23.823545 22509476222784 run_lib.py:146] step: 419700, eval_loss: 4.06625e-02
I0211 17:30:42.341619 22509476222784 run_lib.py:133] step: 419750, training_loss: 3.84655e-02
I0211 17:31:00.813152 22509476222784 run_lib.py:133] step: 419800, training_loss: 3.52925e-02
I0211 17:31:00.977648 22509476222784 run_lib.py:146] step: 419800, eval_loss: 6.43849e-02
I0211 17:31:19.682315 22509476222784 run_lib.py:133] step: 419850, training_loss: 4.04337e-02
I0211 17:31:38.274958 22509476222784 run_lib.py:133] step: 419900, training_loss: 3.75790e-02
I0211 17:31:38.439337 22509476222784 run_lib.py:146] step: 419900, eval_loss: 4.23489e-02
I0211 17:31:57.214563 22509476222784 run_lib.py:133] step: 419950, training_loss: 3.44387e-02
I0211 17:32:15.730567 22509476222784 run_lib.py:133] step: 420000, training_loss: 4.48661e-02
I0211 17:32:16.470761 22509476222784 run_lib.py:146] step: 420000, eval_loss: 4.45685e-02
I0211 17:32:37.772204 22509476222784 run_lib.py:133] step: 420050, training_loss: 3.91462e-02
I0211 17:32:56.322253 22509476222784 run_lib.py:133] step: 420100, training_loss: 3.82819e-02
I0211 17:32:56.485931 22509476222784 run_lib.py:146] step: 420100, eval_loss: 3.01098e-02
I0211 17:33:15.115621 22509476222784 run_lib.py:133] step: 420150, training_loss: 4.21805e-02
I0211 17:33:33.663379 22509476222784 run_lib.py:133] step: 420200, training_loss: 4.17897e-02
I0211 17:33:33.827898 22509476222784 run_lib.py:146] step: 420200, eval_loss: 4.73593e-02
I0211 17:33:52.368674 22509476222784 run_lib.py:133] step: 420250, training_loss: 3.78794e-02
I0211 17:34:10.927872 22509476222784 run_lib.py:133] step: 420300, training_loss: 4.92051e-02
I0211 17:34:11.093983 22509476222784 run_lib.py:146] step: 420300, eval_loss: 3.58756e-02
I0211 17:34:29.820673 22509476222784 run_lib.py:133] step: 420350, training_loss: 3.47951e-02
I0211 17:34:48.400807 22509476222784 run_lib.py:133] step: 420400, training_loss: 4.73585e-02
I0211 17:34:48.563636 22509476222784 run_lib.py:146] step: 420400, eval_loss: 4.50854e-02
I0211 17:35:07.059075 22509476222784 run_lib.py:133] step: 420450, training_loss: 5.95218e-02
I0211 17:35:25.638661 22509476222784 run_lib.py:133] step: 420500, training_loss: 3.49604e-02
I0211 17:35:25.831736 22509476222784 run_lib.py:146] step: 420500, eval_loss: 5.75277e-02
I0211 17:35:44.561325 22509476222784 run_lib.py:133] step: 420550, training_loss: 4.26339e-02
I0211 17:36:03.102455 22509476222784 run_lib.py:133] step: 420600, training_loss: 5.11921e-02
I0211 17:36:03.294537 22509476222784 run_lib.py:146] step: 420600, eval_loss: 3.46345e-02
I0211 17:36:22.000156 22509476222784 run_lib.py:133] step: 420650, training_loss: 4.66756e-02
I0211 17:36:40.573242 22509476222784 run_lib.py:133] step: 420700, training_loss: 3.70140e-02
I0211 17:36:40.753706 22509476222784 run_lib.py:146] step: 420700, eval_loss: 3.81749e-02
I0211 17:36:59.542446 22509476222784 run_lib.py:133] step: 420750, training_loss: 4.53478e-02
I0211 17:37:18.138910 22509476222784 run_lib.py:133] step: 420800, training_loss: 5.20534e-02
I0211 17:37:18.304936 22509476222784 run_lib.py:146] step: 420800, eval_loss: 3.62892e-02
I0211 17:37:36.866918 22509476222784 run_lib.py:133] step: 420850, training_loss: 5.15024e-02
I0211 17:37:55.500905 22509476222784 run_lib.py:133] step: 420900, training_loss: 3.66865e-02
I0211 17:37:55.668596 22509476222784 run_lib.py:146] step: 420900, eval_loss: 5.49537e-02
I0211 17:38:14.188801 22509476222784 run_lib.py:133] step: 420950, training_loss: 3.83403e-02
I0211 17:38:32.907355 22509476222784 run_lib.py:133] step: 421000, training_loss: 3.65580e-02
I0211 17:38:33.072144 22509476222784 run_lib.py:146] step: 421000, eval_loss: 3.05846e-02
I0211 17:38:51.614152 22509476222784 run_lib.py:133] step: 421050, training_loss: 4.20749e-02
I0211 17:39:10.115429 22509476222784 run_lib.py:133] step: 421100, training_loss: 3.10517e-02
I0211 17:39:10.287765 22509476222784 run_lib.py:146] step: 421100, eval_loss: 3.93137e-02
I0211 17:39:28.995065 22509476222784 run_lib.py:133] step: 421150, training_loss: 4.17757e-02
I0211 17:39:47.560495 22509476222784 run_lib.py:133] step: 421200, training_loss: 4.09887e-02
I0211 17:39:47.772063 22509476222784 run_lib.py:146] step: 421200, eval_loss: 4.82336e-02
I0211 17:40:06.369969 22509476222784 run_lib.py:133] step: 421250, training_loss: 5.12957e-02
I0211 17:40:25.090513 22509476222784 run_lib.py:133] step: 421300, training_loss: 3.49537e-02
I0211 17:40:25.255789 22509476222784 run_lib.py:146] step: 421300, eval_loss: 4.50823e-02
I0211 17:40:43.783278 22509476222784 run_lib.py:133] step: 421350, training_loss: 4.91805e-02
I0211 17:41:02.423434 22509476222784 run_lib.py:133] step: 421400, training_loss: 3.97729e-02
I0211 17:41:02.762504 22509476222784 run_lib.py:146] step: 421400, eval_loss: 4.34816e-02
I0211 17:41:21.285883 22509476222784 run_lib.py:133] step: 421450, training_loss: 4.89546e-02
I0211 17:41:39.813745 22509476222784 run_lib.py:133] step: 421500, training_loss: 4.72937e-02
I0211 17:41:40.006636 22509476222784 run_lib.py:146] step: 421500, eval_loss: 2.96714e-02
I0211 17:41:58.624847 22509476222784 run_lib.py:133] step: 421550, training_loss: 3.80954e-02
I0211 17:42:17.213983 22509476222784 run_lib.py:133] step: 421600, training_loss: 3.95313e-02
I0211 17:42:17.385846 22509476222784 run_lib.py:146] step: 421600, eval_loss: 4.44953e-02
I0211 17:42:36.149152 22509476222784 run_lib.py:133] step: 421650, training_loss: 4.53664e-02
I0211 17:42:54.725970 22509476222784 run_lib.py:133] step: 421700, training_loss: 5.26862e-02
I0211 17:42:54.892818 22509476222784 run_lib.py:146] step: 421700, eval_loss: 3.98422e-02
I0211 17:43:13.384315 22509476222784 run_lib.py:133] step: 421750, training_loss: 6.01598e-02
I0211 17:43:31.795001 22509476222784 run_lib.py:133] step: 421800, training_loss: 3.83979e-02
I0211 17:43:31.968560 22509476222784 run_lib.py:146] step: 421800, eval_loss: 4.65848e-02
I0211 17:43:50.664127 22509476222784 run_lib.py:133] step: 421850, training_loss: 3.63026e-02
I0211 17:44:09.343715 22509476222784 run_lib.py:133] step: 421900, training_loss: 4.85388e-02
I0211 17:44:09.506916 22509476222784 run_lib.py:146] step: 421900, eval_loss: 3.98135e-02
I0211 17:44:28.093347 22509476222784 run_lib.py:133] step: 421950, training_loss: 3.61254e-02
I0211 17:44:46.652391 22509476222784 run_lib.py:133] step: 422000, training_loss: 4.83612e-02
I0211 17:44:46.820685 22509476222784 run_lib.py:146] step: 422000, eval_loss: 4.27946e-02
I0211 17:45:05.544356 22509476222784 run_lib.py:133] step: 422050, training_loss: 4.88713e-02
I0211 17:45:24.142083 22509476222784 run_lib.py:133] step: 422100, training_loss: 4.46247e-02
I0211 17:45:24.316668 22509476222784 run_lib.py:146] step: 422100, eval_loss: 3.25866e-02
I0211 17:45:43.048303 22509476222784 run_lib.py:133] step: 422150, training_loss: 2.91921e-02
I0211 17:46:01.620956 22509476222784 run_lib.py:133] step: 422200, training_loss: 4.04543e-02
I0211 17:46:01.785815 22509476222784 run_lib.py:146] step: 422200, eval_loss: 6.35383e-02
I0211 17:46:20.493679 22509476222784 run_lib.py:133] step: 422250, training_loss: 4.08824e-02
I0211 17:46:39.006446 22509476222784 run_lib.py:133] step: 422300, training_loss: 3.10786e-02
I0211 17:46:39.175411 22509476222784 run_lib.py:146] step: 422300, eval_loss: 3.61028e-02
I0211 17:46:57.745093 22509476222784 run_lib.py:133] step: 422350, training_loss: 4.62803e-02
I0211 17:47:16.544643 22509476222784 run_lib.py:133] step: 422400, training_loss: 3.68336e-02
I0211 17:47:16.708759 22509476222784 run_lib.py:146] step: 422400, eval_loss: 2.86485e-02
I0211 17:47:35.315055 22509476222784 run_lib.py:133] step: 422450, training_loss: 3.60537e-02
I0211 17:47:53.976107 22509476222784 run_lib.py:133] step: 422500, training_loss: 4.74186e-02
I0211 17:47:54.138727 22509476222784 run_lib.py:146] step: 422500, eval_loss: 3.45599e-02
I0211 17:48:12.655577 22509476222784 run_lib.py:133] step: 422550, training_loss: 4.75419e-02
I0211 17:48:31.243637 22509476222784 run_lib.py:133] step: 422600, training_loss: 4.38964e-02
I0211 17:48:31.410625 22509476222784 run_lib.py:146] step: 422600, eval_loss: 4.64869e-02
I0211 17:48:49.944547 22509476222784 run_lib.py:133] step: 422650, training_loss: 3.99928e-02
I0211 17:49:08.698667 22509476222784 run_lib.py:133] step: 422700, training_loss: 4.67964e-02
I0211 17:49:08.865821 22509476222784 run_lib.py:146] step: 422700, eval_loss: 4.47205e-02
I0211 17:49:27.296210 22509476222784 run_lib.py:133] step: 422750, training_loss: 4.41035e-02
I0211 17:49:45.714807 22509476222784 run_lib.py:133] step: 422800, training_loss: 4.44726e-02
I0211 17:49:45.880800 22509476222784 run_lib.py:146] step: 422800, eval_loss: 4.40008e-02
I0211 17:50:04.566296 22509476222784 run_lib.py:133] step: 422850, training_loss: 3.45977e-02
I0211 17:50:23.089507 22509476222784 run_lib.py:133] step: 422900, training_loss: 4.51267e-02
I0211 17:50:23.290835 22509476222784 run_lib.py:146] step: 422900, eval_loss: 4.51727e-02
I0211 17:50:41.912697 22509476222784 run_lib.py:133] step: 422950, training_loss: 5.66905e-02
I0211 17:51:00.482047 22509476222784 run_lib.py:133] step: 423000, training_loss: 4.57966e-02
I0211 17:51:00.646924 22509476222784 run_lib.py:146] step: 423000, eval_loss: 5.17014e-02
I0211 17:51:19.188779 22509476222784 run_lib.py:133] step: 423050, training_loss: 4.50925e-02
I0211 17:51:37.755308 22509476222784 run_lib.py:133] step: 423100, training_loss: 2.87232e-02
I0211 17:51:37.922003 22509476222784 run_lib.py:146] step: 423100, eval_loss: 3.99922e-02
I0211 17:51:56.674917 22509476222784 run_lib.py:133] step: 423150, training_loss: 4.10950e-02
I0211 17:52:15.316541 22509476222784 run_lib.py:133] step: 423200, training_loss: 2.91367e-02
I0211 17:52:15.493649 22509476222784 run_lib.py:146] step: 423200, eval_loss: 5.53544e-02
I0211 17:52:34.040756 22509476222784 run_lib.py:133] step: 423250, training_loss: 3.64733e-02
I0211 17:52:52.587952 22509476222784 run_lib.py:133] step: 423300, training_loss: 5.36440e-02
I0211 17:52:52.751492 22509476222784 run_lib.py:146] step: 423300, eval_loss: 3.70852e-02
I0211 17:53:11.506776 22509476222784 run_lib.py:133] step: 423350, training_loss: 5.00930e-02
I0211 17:53:30.047457 22509476222784 run_lib.py:133] step: 423400, training_loss: 4.72876e-02
I0211 17:53:30.241731 22509476222784 run_lib.py:146] step: 423400, eval_loss: 4.12189e-02
I0211 17:53:48.915431 22509476222784 run_lib.py:133] step: 423450, training_loss: 3.82354e-02
I0211 17:54:07.453794 22509476222784 run_lib.py:133] step: 423500, training_loss: 4.34903e-02
I0211 17:54:07.635172 22509476222784 run_lib.py:146] step: 423500, eval_loss: 4.92372e-02
I0211 17:54:26.325847 22509476222784 run_lib.py:133] step: 423550, training_loss: 4.01355e-02
I0211 17:54:44.819904 22509476222784 run_lib.py:133] step: 423600, training_loss: 4.67580e-02
I0211 17:54:44.982432 22509476222784 run_lib.py:146] step: 423600, eval_loss: 4.37376e-02
I0211 17:55:03.617803 22509476222784 run_lib.py:133] step: 423650, training_loss: 5.20543e-02
I0211 17:55:22.080401 22509476222784 run_lib.py:133] step: 423700, training_loss: 4.08463e-02
I0211 17:55:22.244623 22509476222784 run_lib.py:146] step: 423700, eval_loss: 4.55938e-02
I0211 17:55:40.750729 22509476222784 run_lib.py:133] step: 423750, training_loss: 3.02904e-02
I0211 17:55:59.390750 22509476222784 run_lib.py:133] step: 423800, training_loss: 4.93185e-02
I0211 17:55:59.553544 22509476222784 run_lib.py:146] step: 423800, eval_loss: 4.65887e-02
I0211 17:56:18.078825 22509476222784 run_lib.py:133] step: 423850, training_loss: 4.70894e-02
I0211 17:56:36.662819 22509476222784 run_lib.py:133] step: 423900, training_loss: 3.13842e-02
I0211 17:56:36.829852 22509476222784 run_lib.py:146] step: 423900, eval_loss: 3.78181e-02
I0211 17:56:55.509335 22509476222784 run_lib.py:133] step: 423950, training_loss: 4.13432e-02
I0211 17:57:14.233999 22509476222784 run_lib.py:133] step: 424000, training_loss: 5.13438e-02
I0211 17:57:14.399828 22509476222784 run_lib.py:146] step: 424000, eval_loss: 3.66800e-02
I0211 17:57:32.959397 22509476222784 run_lib.py:133] step: 424050, training_loss: 4.29315e-02
I0211 17:57:51.588937 22509476222784 run_lib.py:133] step: 424100, training_loss: 4.46469e-02
I0211 17:57:51.754746 22509476222784 run_lib.py:146] step: 424100, eval_loss: 3.05364e-02
I0211 17:58:10.301666 22509476222784 run_lib.py:133] step: 424150, training_loss: 3.74622e-02
I0211 17:58:29.054237 22509476222784 run_lib.py:133] step: 424200, training_loss: 4.67309e-02
I0211 17:58:29.216350 22509476222784 run_lib.py:146] step: 424200, eval_loss: 5.73525e-02
I0211 17:58:47.641311 22509476222784 run_lib.py:133] step: 424250, training_loss: 4.87065e-02
I0211 17:59:06.116405 22509476222784 run_lib.py:133] step: 424300, training_loss: 5.25165e-02
I0211 17:59:06.278633 22509476222784 run_lib.py:146] step: 424300, eval_loss: 5.06997e-02
I0211 17:59:24.782464 22509476222784 run_lib.py:133] step: 424350, training_loss: 4.43275e-02
I0211 17:59:43.450189 22509476222784 run_lib.py:133] step: 424400, training_loss: 3.59034e-02
I0211 17:59:43.638827 22509476222784 run_lib.py:146] step: 424400, eval_loss: 3.21930e-02
I0211 18:00:02.188073 22509476222784 run_lib.py:133] step: 424450, training_loss: 4.67143e-02
I0211 18:00:20.833190 22509476222784 run_lib.py:133] step: 424500, training_loss: 3.84622e-02
I0211 18:00:21.008879 22509476222784 run_lib.py:146] step: 424500, eval_loss: 4.63092e-02
I0211 18:00:39.467908 22509476222784 run_lib.py:133] step: 424550, training_loss: 5.03156e-02
I0211 18:00:57.987334 22509476222784 run_lib.py:133] step: 424600, training_loss: 4.14427e-02
I0211 18:00:58.150912 22509476222784 run_lib.py:146] step: 424600, eval_loss: 3.85565e-02
I0211 18:01:16.836546 22509476222784 run_lib.py:133] step: 424650, training_loss: 4.50681e-02
I0211 18:01:35.452912 22509476222784 run_lib.py:133] step: 424700, training_loss: 3.44930e-02
I0211 18:01:35.617961 22509476222784 run_lib.py:146] step: 424700, eval_loss: 3.73823e-02
I0211 18:01:54.131337 22509476222784 run_lib.py:133] step: 424750, training_loss: 4.58116e-02
I0211 18:02:12.594069 22509476222784 run_lib.py:133] step: 424800, training_loss: 3.40890e-02
I0211 18:02:12.762342 22509476222784 run_lib.py:146] step: 424800, eval_loss: 5.28856e-02
I0211 18:02:31.383997 22509476222784 run_lib.py:133] step: 424850, training_loss: 3.94737e-02
I0211 18:02:49.908960 22509476222784 run_lib.py:133] step: 424900, training_loss: 3.33419e-02
I0211 18:02:50.094514 22509476222784 run_lib.py:146] step: 424900, eval_loss: 4.78016e-02
I0211 18:03:08.816552 22509476222784 run_lib.py:133] step: 424950, training_loss: 4.41900e-02
I0211 18:03:27.433627 22509476222784 run_lib.py:133] step: 425000, training_loss: 5.27619e-02
I0211 18:03:27.626600 22509476222784 run_lib.py:146] step: 425000, eval_loss: 3.59130e-02
I0211 18:03:46.320178 22509476222784 run_lib.py:133] step: 425050, training_loss: 4.04029e-02
I0211 18:04:04.810329 22509476222784 run_lib.py:133] step: 425100, training_loss: 4.79012e-02
I0211 18:04:04.974653 22509476222784 run_lib.py:146] step: 425100, eval_loss: 4.03461e-02
I0211 18:04:23.473616 22509476222784 run_lib.py:133] step: 425150, training_loss: 4.51227e-02
I0211 18:04:42.235838 22509476222784 run_lib.py:133] step: 425200, training_loss: 5.07999e-02
I0211 18:04:42.399948 22509476222784 run_lib.py:146] step: 425200, eval_loss: 4.58456e-02
I0211 18:05:00.904541 22509476222784 run_lib.py:133] step: 425250, training_loss: 5.31401e-02
I0211 18:05:19.533539 22509476222784 run_lib.py:133] step: 425300, training_loss: 4.12135e-02
I0211 18:05:19.693738 22509476222784 run_lib.py:146] step: 425300, eval_loss: 4.19245e-02
I0211 18:05:38.225648 22509476222784 run_lib.py:133] step: 425350, training_loss: 4.52497e-02
I0211 18:05:56.725529 22509476222784 run_lib.py:133] step: 425400, training_loss: 3.47149e-02
I0211 18:05:56.891734 22509476222784 run_lib.py:146] step: 425400, eval_loss: 3.54946e-02
I0211 18:06:15.540755 22509476222784 run_lib.py:133] step: 425450, training_loss: 4.68499e-02
I0211 18:06:34.114131 22509476222784 run_lib.py:133] step: 425500, training_loss: 3.72017e-02
I0211 18:06:34.281666 22509476222784 run_lib.py:146] step: 425500, eval_loss: 4.58011e-02
I0211 18:06:52.827004 22509476222784 run_lib.py:133] step: 425550, training_loss: 5.17361e-02
I0211 18:07:11.490932 22509476222784 run_lib.py:133] step: 425600, training_loss: 2.52567e-02
I0211 18:07:11.656759 22509476222784 run_lib.py:146] step: 425600, eval_loss: 3.44703e-02
I0211 18:07:30.156273 22509476222784 run_lib.py:133] step: 425650, training_loss: 3.77772e-02
I0211 18:07:48.555411 22509476222784 run_lib.py:133] step: 425700, training_loss: 3.11173e-02
I0211 18:07:48.716704 22509476222784 run_lib.py:146] step: 425700, eval_loss: 3.86733e-02
I0211 18:08:07.388524 22509476222784 run_lib.py:133] step: 425750, training_loss: 3.68270e-02
I0211 18:08:25.928861 22509476222784 run_lib.py:133] step: 425800, training_loss: 3.53761e-02
I0211 18:08:26.116979 22509476222784 run_lib.py:146] step: 425800, eval_loss: 4.19412e-02
I0211 18:08:44.673249 22509476222784 run_lib.py:133] step: 425850, training_loss: 4.05067e-02
I0211 18:09:03.140306 22509476222784 run_lib.py:133] step: 425900, training_loss: 3.49646e-02
I0211 18:09:03.308418 22509476222784 run_lib.py:146] step: 425900, eval_loss: 3.70244e-02
I0211 18:09:21.983526 22509476222784 run_lib.py:133] step: 425950, training_loss: 5.34770e-02
I0211 18:09:40.594653 22509476222784 run_lib.py:133] step: 426000, training_loss: 4.23834e-02
I0211 18:09:40.768833 22509476222784 run_lib.py:146] step: 426000, eval_loss: 4.04262e-02
I0211 18:09:59.314766 22509476222784 run_lib.py:133] step: 426050, training_loss: 4.81171e-02
I0211 18:10:17.878823 22509476222784 run_lib.py:133] step: 426100, training_loss: 4.01912e-02
I0211 18:10:18.041999 22509476222784 run_lib.py:146] step: 426100, eval_loss: 4.45216e-02
I0211 18:10:36.772142 22509476222784 run_lib.py:133] step: 426150, training_loss: 3.73010e-02
I0211 18:10:55.236454 22509476222784 run_lib.py:133] step: 426200, training_loss: 4.48287e-02
I0211 18:10:55.398754 22509476222784 run_lib.py:146] step: 426200, eval_loss: 3.49391e-02
I0211 18:11:14.013969 22509476222784 run_lib.py:133] step: 426250, training_loss: 4.27091e-02
I0211 18:11:32.447092 22509476222784 run_lib.py:133] step: 426300, training_loss: 5.00577e-02
I0211 18:11:32.610811 22509476222784 run_lib.py:146] step: 426300, eval_loss: 3.23651e-02
I0211 18:11:51.295691 22509476222784 run_lib.py:133] step: 426350, training_loss: 4.04132e-02
I0211 18:12:09.732987 22509476222784 run_lib.py:133] step: 426400, training_loss: 4.82619e-02
I0211 18:12:09.898669 22509476222784 run_lib.py:146] step: 426400, eval_loss: 3.17050e-02
I0211 18:12:28.537793 22509476222784 run_lib.py:133] step: 426450, training_loss: 2.72352e-02
I0211 18:12:47.058545 22509476222784 run_lib.py:133] step: 426500, training_loss: 4.66044e-02
I0211 18:12:47.222658 22509476222784 run_lib.py:146] step: 426500, eval_loss: 3.55214e-02
I0211 18:13:05.708947 22509476222784 run_lib.py:133] step: 426550, training_loss: 4.94611e-02
I0211 18:13:24.409367 22509476222784 run_lib.py:133] step: 426600, training_loss: 6.30096e-02
I0211 18:13:24.575089 22509476222784 run_lib.py:146] step: 426600, eval_loss: 2.60560e-02
I0211 18:13:43.086576 22509476222784 run_lib.py:133] step: 426650, training_loss: 3.88677e-02
I0211 18:14:01.556393 22509476222784 run_lib.py:133] step: 426700, training_loss: 4.99384e-02
I0211 18:14:01.717575 22509476222784 run_lib.py:146] step: 426700, eval_loss: 4.61691e-02
I0211 18:14:20.411354 22509476222784 run_lib.py:133] step: 426750, training_loss: 3.79586e-02
I0211 18:14:38.884395 22509476222784 run_lib.py:133] step: 426800, training_loss: 3.06858e-02
I0211 18:14:39.049796 22509476222784 run_lib.py:146] step: 426800, eval_loss: 4.59174e-02
I0211 18:14:57.762318 22509476222784 run_lib.py:133] step: 426850, training_loss: 3.44277e-02
I0211 18:15:16.301578 22509476222784 run_lib.py:133] step: 426900, training_loss: 4.01306e-02
I0211 18:15:16.468663 22509476222784 run_lib.py:146] step: 426900, eval_loss: 2.94388e-02
I0211 18:15:34.924887 22509476222784 run_lib.py:133] step: 426950, training_loss: 4.25858e-02
I0211 18:15:53.534301 22509476222784 run_lib.py:133] step: 427000, training_loss: 3.84283e-02
I0211 18:15:53.698771 22509476222784 run_lib.py:146] step: 427000, eval_loss: 3.81271e-02
I0211 18:16:12.223812 22509476222784 run_lib.py:133] step: 427050, training_loss: 4.88740e-02
I0211 18:16:30.783954 22509476222784 run_lib.py:133] step: 427100, training_loss: 3.66718e-02
I0211 18:16:30.947878 22509476222784 run_lib.py:146] step: 427100, eval_loss: 4.46177e-02
I0211 18:16:49.490823 22509476222784 run_lib.py:133] step: 427150, training_loss: 4.36739e-02
I0211 18:17:08.157566 22509476222784 run_lib.py:133] step: 427200, training_loss: 5.18196e-02
I0211 18:17:08.318685 22509476222784 run_lib.py:146] step: 427200, eval_loss: 3.80605e-02
I0211 18:17:26.849272 22509476222784 run_lib.py:133] step: 427250, training_loss: 4.84421e-02
I0211 18:17:45.391775 22509476222784 run_lib.py:133] step: 427300, training_loss: 4.17432e-02
I0211 18:17:45.554473 22509476222784 run_lib.py:146] step: 427300, eval_loss: 3.19433e-02
I0211 18:18:04.078307 22509476222784 run_lib.py:133] step: 427350, training_loss: 4.31598e-02
I0211 18:18:22.670756 22509476222784 run_lib.py:133] step: 427400, training_loss: 3.42617e-02
I0211 18:18:22.852623 22509476222784 run_lib.py:146] step: 427400, eval_loss: 4.38178e-02
I0211 18:18:41.558976 22509476222784 run_lib.py:133] step: 427450, training_loss: 5.17771e-02
I0211 18:19:00.255344 22509476222784 run_lib.py:133] step: 427500, training_loss: 4.32283e-02
I0211 18:19:00.424947 22509476222784 run_lib.py:146] step: 427500, eval_loss: 3.06915e-02
I0211 18:19:18.948388 22509476222784 run_lib.py:133] step: 427550, training_loss: 5.13556e-02
I0211 18:19:37.449891 22509476222784 run_lib.py:133] step: 427600, training_loss: 3.37564e-02
I0211 18:19:37.612672 22509476222784 run_lib.py:146] step: 427600, eval_loss: 3.18625e-02
I0211 18:19:56.200628 22509476222784 run_lib.py:133] step: 427650, training_loss: 4.50578e-02
I0211 18:20:14.714540 22509476222784 run_lib.py:133] step: 427700, training_loss: 3.25602e-02
I0211 18:20:14.882937 22509476222784 run_lib.py:146] step: 427700, eval_loss: 5.22646e-02
I0211 18:20:33.597354 22509476222784 run_lib.py:133] step: 427750, training_loss: 3.68789e-02
I0211 18:20:52.134686 22509476222784 run_lib.py:133] step: 427800, training_loss: 3.61896e-02
I0211 18:20:52.301719 22509476222784 run_lib.py:146] step: 427800, eval_loss: 4.24149e-02
I0211 18:21:10.962313 22509476222784 run_lib.py:133] step: 427850, training_loss: 4.20466e-02
I0211 18:21:29.457309 22509476222784 run_lib.py:133] step: 427900, training_loss: 4.43189e-02
I0211 18:21:29.623982 22509476222784 run_lib.py:146] step: 427900, eval_loss: 4.41057e-02
I0211 18:21:48.111231 22509476222784 run_lib.py:133] step: 427950, training_loss: 5.71112e-02
I0211 18:22:06.821023 22509476222784 run_lib.py:133] step: 428000, training_loss: 4.04924e-02
I0211 18:22:06.993382 22509476222784 run_lib.py:146] step: 428000, eval_loss: 4.70217e-02
I0211 18:22:25.500823 22509476222784 run_lib.py:133] step: 428050, training_loss: 4.39551e-02
I0211 18:22:44.199239 22509476222784 run_lib.py:133] step: 428100, training_loss: 3.80739e-02
I0211 18:22:44.384357 22509476222784 run_lib.py:146] step: 428100, eval_loss: 5.03613e-02
I0211 18:23:02.887648 22509476222784 run_lib.py:133] step: 428150, training_loss: 4.07072e-02
I0211 18:23:21.383203 22509476222784 run_lib.py:133] step: 428200, training_loss: 3.62347e-02
I0211 18:23:21.545674 22509476222784 run_lib.py:146] step: 428200, eval_loss: 3.80554e-02
I0211 18:23:40.197670 22509476222784 run_lib.py:133] step: 428250, training_loss: 2.71656e-02
I0211 18:23:58.784029 22509476222784 run_lib.py:133] step: 428300, training_loss: 4.67395e-02
I0211 18:23:58.982613 22509476222784 run_lib.py:146] step: 428300, eval_loss: 4.13013e-02
I0211 18:24:17.444252 22509476222784 run_lib.py:133] step: 428350, training_loss: 4.34671e-02
I0211 18:24:36.122272 22509476222784 run_lib.py:133] step: 428400, training_loss: 4.03479e-02
I0211 18:24:36.286611 22509476222784 run_lib.py:146] step: 428400, eval_loss: 5.46457e-02
I0211 18:24:54.832294 22509476222784 run_lib.py:133] step: 428450, training_loss: 3.61042e-02
I0211 18:25:13.315336 22509476222784 run_lib.py:133] step: 428500, training_loss: 3.64061e-02
I0211 18:25:13.630357 22509476222784 run_lib.py:146] step: 428500, eval_loss: 3.40948e-02
I0211 18:25:32.140138 22509476222784 run_lib.py:133] step: 428550, training_loss: 5.58708e-02
I0211 18:25:50.676037 22509476222784 run_lib.py:133] step: 428600, training_loss: 3.96516e-02
I0211 18:25:50.836359 22509476222784 run_lib.py:146] step: 428600, eval_loss: 5.11260e-02
I0211 18:26:09.371232 22509476222784 run_lib.py:133] step: 428650, training_loss: 3.18506e-02
I0211 18:26:27.915688 22509476222784 run_lib.py:133] step: 428700, training_loss: 2.89703e-02
I0211 18:26:28.087885 22509476222784 run_lib.py:146] step: 428700, eval_loss: 5.43928e-02
I0211 18:26:46.749127 22509476222784 run_lib.py:133] step: 428750, training_loss: 4.49158e-02
I0211 18:27:05.324236 22509476222784 run_lib.py:133] step: 428800, training_loss: 4.33845e-02
I0211 18:27:05.516611 22509476222784 run_lib.py:146] step: 428800, eval_loss: 4.67183e-02
I0211 18:27:24.057456 22509476222784 run_lib.py:133] step: 428850, training_loss: 4.94389e-02
I0211 18:27:42.667141 22509476222784 run_lib.py:133] step: 428900, training_loss: 4.58634e-02
I0211 18:27:42.831966 22509476222784 run_lib.py:146] step: 428900, eval_loss: 5.54150e-02
I0211 18:28:01.550777 22509476222784 run_lib.py:133] step: 428950, training_loss: 4.71086e-02
I0211 18:28:20.077012 22509476222784 run_lib.py:133] step: 429000, training_loss: 4.12014e-02
I0211 18:28:20.240665 22509476222784 run_lib.py:146] step: 429000, eval_loss: 4.25629e-02
I0211 18:28:38.715905 22509476222784 run_lib.py:133] step: 429050, training_loss: 2.94897e-02
I0211 18:28:57.219549 22509476222784 run_lib.py:133] step: 429100, training_loss: 2.97074e-02
I0211 18:28:57.389542 22509476222784 run_lib.py:146] step: 429100, eval_loss: 4.23305e-02
I0211 18:29:16.002981 22509476222784 run_lib.py:133] step: 429150, training_loss: 2.78957e-02
I0211 18:29:34.515225 22509476222784 run_lib.py:133] step: 429200, training_loss: 4.09110e-02
I0211 18:29:34.692685 22509476222784 run_lib.py:146] step: 429200, eval_loss: 3.61417e-02
I0211 18:29:53.303984 22509476222784 run_lib.py:133] step: 429250, training_loss: 4.52118e-02
I0211 18:30:11.801494 22509476222784 run_lib.py:133] step: 429300, training_loss: 4.79001e-02
I0211 18:30:11.971906 22509476222784 run_lib.py:146] step: 429300, eval_loss: 3.52250e-02
I0211 18:30:30.654121 22509476222784 run_lib.py:133] step: 429350, training_loss: 4.15434e-02
I0211 18:30:49.066393 22509476222784 run_lib.py:133] step: 429400, training_loss: 4.38970e-02
I0211 18:30:49.229680 22509476222784 run_lib.py:146] step: 429400, eval_loss: 4.73563e-02
I0211 18:31:07.746226 22509476222784 run_lib.py:133] step: 429450, training_loss: 3.56655e-02
I0211 18:31:26.391659 22509476222784 run_lib.py:133] step: 429500, training_loss: 3.72996e-02
I0211 18:31:26.555721 22509476222784 run_lib.py:146] step: 429500, eval_loss: 4.68441e-02
I0211 18:31:45.019145 22509476222784 run_lib.py:133] step: 429550, training_loss: 4.61459e-02
I0211 18:32:03.525758 22509476222784 run_lib.py:133] step: 429600, training_loss: 5.00988e-02
I0211 18:32:03.687735 22509476222784 run_lib.py:146] step: 429600, eval_loss: 5.02411e-02
I0211 18:32:22.233448 22509476222784 run_lib.py:133] step: 429650, training_loss: 4.44352e-02
I0211 18:32:40.704377 22509476222784 run_lib.py:133] step: 429700, training_loss: 4.77719e-02
I0211 18:32:40.870723 22509476222784 run_lib.py:146] step: 429700, eval_loss: 4.73523e-02
I0211 18:32:59.386484 22509476222784 run_lib.py:133] step: 429750, training_loss: 5.04424e-02
I0211 18:33:18.113440 22509476222784 run_lib.py:133] step: 429800, training_loss: 4.56869e-02
I0211 18:33:18.276714 22509476222784 run_lib.py:146] step: 429800, eval_loss: 4.13013e-02
I0211 18:33:36.746404 22509476222784 run_lib.py:133] step: 429850, training_loss: 5.76864e-02
I0211 18:33:55.278577 22509476222784 run_lib.py:133] step: 429900, training_loss: 5.01194e-02
I0211 18:33:55.525809 22509476222784 run_lib.py:146] step: 429900, eval_loss: 4.56605e-02
I0211 18:34:14.255798 22509476222784 run_lib.py:133] step: 429950, training_loss: 4.62930e-02
I0211 18:34:32.820796 22509476222784 run_lib.py:133] step: 430000, training_loss: 3.30683e-02
I0211 18:34:33.618980 22509476222784 run_lib.py:146] step: 430000, eval_loss: 4.59304e-02
I0211 18:34:55.021431 22509476222784 run_lib.py:133] step: 430050, training_loss: 3.82101e-02
I0211 18:35:13.425120 22509476222784 run_lib.py:133] step: 430100, training_loss: 3.90598e-02
I0211 18:35:13.580769 22509476222784 run_lib.py:146] step: 430100, eval_loss: 3.47570e-02
I0211 18:35:32.041610 22509476222784 run_lib.py:133] step: 430150, training_loss: 2.45985e-02
I0211 18:35:50.800005 22509476222784 run_lib.py:133] step: 430200, training_loss: 3.95670e-02
I0211 18:35:50.995882 22509476222784 run_lib.py:146] step: 430200, eval_loss: 5.48909e-02
I0211 18:36:09.537664 22509476222784 run_lib.py:133] step: 430250, training_loss: 4.03562e-02
I0211 18:36:28.054374 22509476222784 run_lib.py:133] step: 430300, training_loss: 3.95330e-02
I0211 18:36:28.399689 22509476222784 run_lib.py:146] step: 430300, eval_loss: 3.42255e-02
I0211 18:36:46.882410 22509476222784 run_lib.py:133] step: 430350, training_loss: 5.26475e-02
I0211 18:37:05.339136 22509476222784 run_lib.py:133] step: 430400, training_loss: 3.51537e-02
I0211 18:37:05.509404 22509476222784 run_lib.py:146] step: 430400, eval_loss: 3.72942e-02
I0211 18:37:24.025456 22509476222784 run_lib.py:133] step: 430450, training_loss: 5.09771e-02
I0211 18:37:42.510454 22509476222784 run_lib.py:133] step: 430500, training_loss: 4.19249e-02
I0211 18:37:42.686902 22509476222784 run_lib.py:146] step: 430500, eval_loss: 3.77358e-02
I0211 18:38:01.353201 22509476222784 run_lib.py:133] step: 430550, training_loss: 5.45976e-02
I0211 18:38:19.814769 22509476222784 run_lib.py:133] step: 430600, training_loss: 3.62278e-02
I0211 18:38:19.975584 22509476222784 run_lib.py:146] step: 430600, eval_loss: 4.86359e-02
I0211 18:38:38.378723 22509476222784 run_lib.py:133] step: 430650, training_loss: 3.38805e-02
I0211 18:38:56.808043 22509476222784 run_lib.py:133] step: 430700, training_loss: 3.59149e-02
I0211 18:38:56.977083 22509476222784 run_lib.py:146] step: 430700, eval_loss: 4.29661e-02
I0211 18:39:15.689450 22509476222784 run_lib.py:133] step: 430750, training_loss: 5.01700e-02
I0211 18:39:34.304186 22509476222784 run_lib.py:133] step: 430800, training_loss: 6.35225e-02
I0211 18:39:34.468657 22509476222784 run_lib.py:146] step: 430800, eval_loss: 4.03904e-02
I0211 18:39:52.987103 22509476222784 run_lib.py:133] step: 430850, training_loss: 4.20593e-02
I0211 18:40:11.538545 22509476222784 run_lib.py:133] step: 430900, training_loss: 4.26173e-02
I0211 18:40:11.701688 22509476222784 run_lib.py:146] step: 430900, eval_loss: 4.39073e-02
I0211 18:40:30.366173 22509476222784 run_lib.py:133] step: 430950, training_loss: 4.62765e-02
I0211 18:40:48.959163 22509476222784 run_lib.py:133] step: 431000, training_loss: 4.02003e-02
I0211 18:40:49.124056 22509476222784 run_lib.py:146] step: 431000, eval_loss: 4.07836e-02
I0211 18:41:07.893981 22509476222784 run_lib.py:133] step: 431050, training_loss: 5.20808e-02
I0211 18:41:26.377886 22509476222784 run_lib.py:133] step: 431100, training_loss: 5.14180e-02
I0211 18:41:26.540709 22509476222784 run_lib.py:146] step: 431100, eval_loss: 4.53930e-02
I0211 18:41:45.172349 22509476222784 run_lib.py:133] step: 431150, training_loss: 4.18634e-02
I0211 18:42:03.707333 22509476222784 run_lib.py:133] step: 431200, training_loss: 4.52466e-02
I0211 18:42:03.873879 22509476222784 run_lib.py:146] step: 431200, eval_loss: 4.41213e-02
I0211 18:42:22.378652 22509476222784 run_lib.py:133] step: 431250, training_loss: 4.36636e-02
I0211 18:42:41.122753 22509476222784 run_lib.py:133] step: 431300, training_loss: 4.81191e-02
I0211 18:42:41.316081 22509476222784 run_lib.py:146] step: 431300, eval_loss: 4.07399e-02
I0211 18:42:59.848541 22509476222784 run_lib.py:133] step: 431350, training_loss: 3.80918e-02
I0211 18:43:18.535984 22509476222784 run_lib.py:133] step: 431400, training_loss: 2.79278e-02
I0211 18:43:18.720940 22509476222784 run_lib.py:146] step: 431400, eval_loss: 4.68766e-02
I0211 18:43:37.269232 22509476222784 run_lib.py:133] step: 431450, training_loss: 5.16527e-02
I0211 18:43:55.786611 22509476222784 run_lib.py:133] step: 431500, training_loss: 3.79791e-02
I0211 18:43:55.982495 22509476222784 run_lib.py:146] step: 431500, eval_loss: 5.01460e-02
I0211 18:44:14.497886 22509476222784 run_lib.py:133] step: 431550, training_loss: 4.30893e-02
I0211 18:44:33.214878 22509476222784 run_lib.py:133] step: 431600, training_loss: 5.31910e-02
I0211 18:44:33.381925 22509476222784 run_lib.py:146] step: 431600, eval_loss: 5.12115e-02
I0211 18:44:51.807492 22509476222784 run_lib.py:133] step: 431650, training_loss: 3.71059e-02
I0211 18:45:10.337645 22509476222784 run_lib.py:133] step: 431700, training_loss: 5.16267e-02
I0211 18:45:10.501204 22509476222784 run_lib.py:146] step: 431700, eval_loss: 4.28819e-02
I0211 18:45:29.200465 22509476222784 run_lib.py:133] step: 431750, training_loss: 4.85400e-02
I0211 18:45:47.742245 22509476222784 run_lib.py:133] step: 431800, training_loss: 3.39567e-02
I0211 18:45:47.907615 22509476222784 run_lib.py:146] step: 431800, eval_loss: 4.57957e-02
I0211 18:46:06.439322 22509476222784 run_lib.py:133] step: 431850, training_loss: 5.31677e-02
I0211 18:46:25.014817 22509476222784 run_lib.py:133] step: 431900, training_loss: 4.86118e-02
I0211 18:46:25.200888 22509476222784 run_lib.py:146] step: 431900, eval_loss: 3.86062e-02
I0211 18:46:43.768449 22509476222784 run_lib.py:133] step: 431950, training_loss: 3.47643e-02
I0211 18:47:02.300086 22509476222784 run_lib.py:133] step: 432000, training_loss: 3.89980e-02
I0211 18:47:02.483635 22509476222784 run_lib.py:146] step: 432000, eval_loss: 3.89598e-02
I0211 18:47:21.120487 22509476222784 run_lib.py:133] step: 432050, training_loss: 2.84579e-02
I0211 18:47:39.685804 22509476222784 run_lib.py:133] step: 432100, training_loss: 5.07227e-02
I0211 18:47:39.867745 22509476222784 run_lib.py:146] step: 432100, eval_loss: 5.72864e-02
I0211 18:47:58.455686 22509476222784 run_lib.py:133] step: 432150, training_loss: 4.66627e-02
I0211 18:48:16.975039 22509476222784 run_lib.py:133] step: 432200, training_loss: 5.50578e-02
I0211 18:48:17.140057 22509476222784 run_lib.py:146] step: 432200, eval_loss: 4.84331e-02
I0211 18:48:35.846022 22509476222784 run_lib.py:133] step: 432250, training_loss: 3.12573e-02
I0211 18:48:54.377551 22509476222784 run_lib.py:133] step: 432300, training_loss: 4.64029e-02
I0211 18:48:54.544707 22509476222784 run_lib.py:146] step: 432300, eval_loss: 4.15531e-02
I0211 18:49:13.187245 22509476222784 run_lib.py:133] step: 432350, training_loss: 3.65904e-02
I0211 18:49:31.753102 22509476222784 run_lib.py:133] step: 432400, training_loss: 4.60085e-02
I0211 18:49:31.920725 22509476222784 run_lib.py:146] step: 432400, eval_loss: 4.87916e-02
I0211 18:49:50.640795 22509476222784 run_lib.py:133] step: 432450, training_loss: 3.87049e-02
I0211 18:50:09.187370 22509476222784 run_lib.py:133] step: 432500, training_loss: 3.78504e-02
I0211 18:50:09.349656 22509476222784 run_lib.py:146] step: 432500, eval_loss: 4.12597e-02
I0211 18:50:27.974558 22509476222784 run_lib.py:133] step: 432550, training_loss: 3.88505e-02
I0211 18:50:46.405447 22509476222784 run_lib.py:133] step: 432600, training_loss: 4.17481e-02
I0211 18:50:46.568810 22509476222784 run_lib.py:146] step: 432600, eval_loss: 3.45684e-02
I0211 18:51:04.995643 22509476222784 run_lib.py:133] step: 432650, training_loss: 4.66312e-02
I0211 18:51:23.712062 22509476222784 run_lib.py:133] step: 432700, training_loss: 5.00623e-02
I0211 18:51:23.878728 22509476222784 run_lib.py:146] step: 432700, eval_loss: 5.39855e-02
I0211 18:51:42.416827 22509476222784 run_lib.py:133] step: 432750, training_loss: 4.20283e-02
I0211 18:52:00.906924 22509476222784 run_lib.py:133] step: 432800, training_loss: 3.46905e-02
I0211 18:52:01.070701 22509476222784 run_lib.py:146] step: 432800, eval_loss: 3.47194e-02
I0211 18:52:19.739614 22509476222784 run_lib.py:133] step: 432850, training_loss: 5.21332e-02
I0211 18:52:38.346784 22509476222784 run_lib.py:133] step: 432900, training_loss: 4.80134e-02
I0211 18:52:38.515632 22509476222784 run_lib.py:146] step: 432900, eval_loss: 4.66970e-02
I0211 18:52:57.037474 22509476222784 run_lib.py:133] step: 432950, training_loss: 4.60747e-02
I0211 18:53:15.494480 22509476222784 run_lib.py:133] step: 433000, training_loss: 4.05719e-02
I0211 18:53:15.658648 22509476222784 run_lib.py:146] step: 433000, eval_loss: 4.44164e-02
I0211 18:53:34.188854 22509476222784 run_lib.py:133] step: 433050, training_loss: 3.44963e-02
I0211 18:53:52.833881 22509476222784 run_lib.py:133] step: 433100, training_loss: 3.77618e-02
I0211 18:53:52.999732 22509476222784 run_lib.py:146] step: 433100, eval_loss: 4.52561e-02
I0211 18:54:11.475460 22509476222784 run_lib.py:133] step: 433150, training_loss: 3.90800e-02
I0211 18:54:29.948665 22509476222784 run_lib.py:133] step: 433200, training_loss: 5.47052e-02
I0211 18:54:30.127587 22509476222784 run_lib.py:146] step: 433200, eval_loss: 3.89909e-02
I0211 18:54:48.656102 22509476222784 run_lib.py:133] step: 433250, training_loss: 3.74392e-02
I0211 18:55:07.447567 22509476222784 run_lib.py:133] step: 433300, training_loss: 6.10153e-02
I0211 18:55:07.622319 22509476222784 run_lib.py:146] step: 433300, eval_loss: 4.00205e-02
I0211 18:55:26.148086 22509476222784 run_lib.py:133] step: 433350, training_loss: 4.06368e-02
I0211 18:55:44.668058 22509476222784 run_lib.py:133] step: 433400, training_loss: 4.26413e-02
I0211 18:55:44.828536 22509476222784 run_lib.py:146] step: 433400, eval_loss: 5.22927e-02
I0211 18:56:03.195565 22509476222784 run_lib.py:133] step: 433450, training_loss: 2.99978e-02
I0211 18:56:21.552488 22509476222784 run_lib.py:133] step: 433500, training_loss: 3.92733e-02
I0211 18:56:21.719823 22509476222784 run_lib.py:146] step: 433500, eval_loss: 4.66467e-02
I0211 18:56:40.273372 22509476222784 run_lib.py:133] step: 433550, training_loss: 4.26659e-02
I0211 18:56:58.968816 22509476222784 run_lib.py:133] step: 433600, training_loss: 4.12360e-02
I0211 18:56:59.133686 22509476222784 run_lib.py:146] step: 433600, eval_loss: 3.81588e-02
I0211 18:57:17.606423 22509476222784 run_lib.py:133] step: 433650, training_loss: 4.36102e-02
I0211 18:57:36.062677 22509476222784 run_lib.py:133] step: 433700, training_loss: 4.05220e-02
I0211 18:57:36.242744 22509476222784 run_lib.py:146] step: 433700, eval_loss: 3.45484e-02
I0211 18:57:54.880367 22509476222784 run_lib.py:133] step: 433750, training_loss: 3.94099e-02
I0211 18:58:13.426127 22509476222784 run_lib.py:133] step: 433800, training_loss: 3.85050e-02
I0211 18:58:13.591906 22509476222784 run_lib.py:146] step: 433800, eval_loss: 4.29933e-02
I0211 18:58:32.309077 22509476222784 run_lib.py:133] step: 433850, training_loss: 4.12431e-02
I0211 18:58:50.693276 22509476222784 run_lib.py:133] step: 433900, training_loss: 4.74273e-02
I0211 18:58:50.853051 22509476222784 run_lib.py:146] step: 433900, eval_loss: 5.21357e-02
I0211 18:59:09.508780 22509476222784 run_lib.py:133] step: 433950, training_loss: 4.89186e-02
I0211 18:59:27.979857 22509476222784 run_lib.py:133] step: 434000, training_loss: 4.35528e-02
I0211 18:59:28.143743 22509476222784 run_lib.py:146] step: 434000, eval_loss: 4.41962e-02
I0211 18:59:46.628106 22509476222784 run_lib.py:133] step: 434050, training_loss: 5.28031e-02
I0211 19:00:05.363567 22509476222784 run_lib.py:133] step: 434100, training_loss: 4.48845e-02
I0211 19:00:05.530766 22509476222784 run_lib.py:146] step: 434100, eval_loss: 4.45883e-02
I0211 19:00:24.033382 22509476222784 run_lib.py:133] step: 434150, training_loss: 4.25513e-02
I0211 19:00:42.672865 22509476222784 run_lib.py:133] step: 434200, training_loss: 3.79883e-02
I0211 19:00:42.837742 22509476222784 run_lib.py:146] step: 434200, eval_loss: 4.34487e-02
I0211 19:01:01.374013 22509476222784 run_lib.py:133] step: 434250, training_loss: 3.22223e-02
I0211 19:01:19.853201 22509476222784 run_lib.py:133] step: 434300, training_loss: 4.45003e-02
I0211 19:01:20.016080 22509476222784 run_lib.py:146] step: 434300, eval_loss: 3.79113e-02
I0211 19:01:38.743392 22509476222784 run_lib.py:133] step: 434350, training_loss: 4.04749e-02
I0211 19:01:57.252866 22509476222784 run_lib.py:133] step: 434400, training_loss: 4.62947e-02
I0211 19:01:57.421765 22509476222784 run_lib.py:146] step: 434400, eval_loss: 4.15576e-02
I0211 19:02:15.953490 22509476222784 run_lib.py:133] step: 434450, training_loss: 3.97348e-02
I0211 19:02:34.591140 22509476222784 run_lib.py:133] step: 434500, training_loss: 5.02645e-02
I0211 19:02:34.754218 22509476222784 run_lib.py:146] step: 434500, eval_loss: 4.09310e-02
I0211 19:02:53.186731 22509476222784 run_lib.py:133] step: 434550, training_loss: 3.93569e-02
I0211 19:03:11.739396 22509476222784 run_lib.py:133] step: 434600, training_loss: 4.35395e-02
I0211 19:03:11.904610 22509476222784 run_lib.py:146] step: 434600, eval_loss: 4.81727e-02
I0211 19:03:30.442107 22509476222784 run_lib.py:133] step: 434650, training_loss: 3.96999e-02
I0211 19:03:48.913267 22509476222784 run_lib.py:133] step: 434700, training_loss: 3.96585e-02
I0211 19:03:49.086378 22509476222784 run_lib.py:146] step: 434700, eval_loss: 3.47450e-02
I0211 19:04:07.564912 22509476222784 run_lib.py:133] step: 434750, training_loss: 5.33951e-02
I0211 19:04:26.071690 22509476222784 run_lib.py:133] step: 434800, training_loss: 4.20435e-02
I0211 19:04:26.262616 22509476222784 run_lib.py:146] step: 434800, eval_loss: 4.19064e-02
I0211 19:04:44.920595 22509476222784 run_lib.py:133] step: 434850, training_loss: 4.58475e-02
I0211 19:05:03.571203 22509476222784 run_lib.py:133] step: 434900, training_loss: 3.84081e-02
I0211 19:05:03.735585 22509476222784 run_lib.py:146] step: 434900, eval_loss: 4.39783e-02
I0211 19:05:22.278555 22509476222784 run_lib.py:133] step: 434950, training_loss: 3.18260e-02
I0211 19:05:40.709492 22509476222784 run_lib.py:133] step: 435000, training_loss: 3.90891e-02
I0211 19:05:40.871855 22509476222784 run_lib.py:146] step: 435000, eval_loss: 5.11180e-02
I0211 19:05:59.486811 22509476222784 run_lib.py:133] step: 435050, training_loss: 3.65437e-02
I0211 19:06:17.998005 22509476222784 run_lib.py:133] step: 435100, training_loss: 4.36597e-02
I0211 19:06:18.161079 22509476222784 run_lib.py:146] step: 435100, eval_loss: 3.84684e-02
I0211 19:06:36.874146 22509476222784 run_lib.py:133] step: 435150, training_loss: 3.99326e-02
I0211 19:06:55.331968 22509476222784 run_lib.py:133] step: 435200, training_loss: 3.90211e-02
I0211 19:06:55.495958 22509476222784 run_lib.py:146] step: 435200, eval_loss: 4.08726e-02
I0211 19:07:14.110316 22509476222784 run_lib.py:133] step: 435250, training_loss: 5.27299e-02
I0211 19:07:32.513649 22509476222784 run_lib.py:133] step: 435300, training_loss: 4.63062e-02
I0211 19:07:32.699519 22509476222784 run_lib.py:146] step: 435300, eval_loss: 4.52255e-02
I0211 19:07:51.325038 22509476222784 run_lib.py:133] step: 435350, training_loss: 4.18342e-02
I0211 19:08:09.858160 22509476222784 run_lib.py:133] step: 435400, training_loss: 4.64356e-02
I0211 19:08:10.039664 22509476222784 run_lib.py:146] step: 435400, eval_loss: 4.77771e-02
I0211 19:08:28.571507 22509476222784 run_lib.py:133] step: 435450, training_loss: 3.64512e-02
I0211 19:08:47.279849 22509476222784 run_lib.py:133] step: 435500, training_loss: 3.73733e-02
I0211 19:08:47.448630 22509476222784 run_lib.py:146] step: 435500, eval_loss: 4.86220e-02
I0211 19:09:05.962334 22509476222784 run_lib.py:133] step: 435550, training_loss: 3.70542e-02
I0211 19:09:24.482660 22509476222784 run_lib.py:133] step: 435600, training_loss: 4.90488e-02
I0211 19:09:24.648627 22509476222784 run_lib.py:146] step: 435600, eval_loss: 4.16720e-02
I0211 19:09:43.313639 22509476222784 run_lib.py:133] step: 435650, training_loss: 5.00866e-02
I0211 19:10:01.916098 22509476222784 run_lib.py:133] step: 435700, training_loss: 5.07469e-02
I0211 19:10:02.088740 22509476222784 run_lib.py:146] step: 435700, eval_loss: 3.80600e-02
I0211 19:10:20.706753 22509476222784 run_lib.py:133] step: 435750, training_loss: 3.51068e-02
I0211 19:10:39.125065 22509476222784 run_lib.py:133] step: 435800, training_loss: 5.04548e-02
I0211 19:10:39.287452 22509476222784 run_lib.py:146] step: 435800, eval_loss: 4.18246e-02
I0211 19:10:57.801884 22509476222784 run_lib.py:133] step: 435850, training_loss: 4.53514e-02
I0211 19:11:16.493500 22509476222784 run_lib.py:133] step: 435900, training_loss: 5.00912e-02
I0211 19:11:16.659630 22509476222784 run_lib.py:146] step: 435900, eval_loss: 5.31544e-02
I0211 19:11:35.159391 22509476222784 run_lib.py:133] step: 435950, training_loss: 3.96749e-02
I0211 19:11:53.737564 22509476222784 run_lib.py:133] step: 436000, training_loss: 5.30846e-02
I0211 19:11:53.912684 22509476222784 run_lib.py:146] step: 436000, eval_loss: 5.20754e-02
I0211 19:12:12.472104 22509476222784 run_lib.py:133] step: 436050, training_loss: 5.13224e-02
I0211 19:12:31.229507 22509476222784 run_lib.py:133] step: 436100, training_loss: 4.11364e-02
I0211 19:12:31.394574 22509476222784 run_lib.py:146] step: 436100, eval_loss: 3.95263e-02
I0211 19:12:49.910143 22509476222784 run_lib.py:133] step: 436150, training_loss: 3.96027e-02
I0211 19:13:08.480096 22509476222784 run_lib.py:133] step: 436200, training_loss: 4.16564e-02
I0211 19:13:08.641609 22509476222784 run_lib.py:146] step: 436200, eval_loss: 3.10780e-02
I0211 19:13:27.098883 22509476222784 run_lib.py:133] step: 436250, training_loss: 4.07763e-02
I0211 19:13:45.706774 22509476222784 run_lib.py:133] step: 436300, training_loss: 2.96623e-02
I0211 19:13:45.871574 22509476222784 run_lib.py:146] step: 436300, eval_loss: 3.28407e-02
I0211 19:14:04.588101 22509476222784 run_lib.py:133] step: 436350, training_loss: 4.58968e-02
I0211 19:14:23.165202 22509476222784 run_lib.py:133] step: 436400, training_loss: 4.75300e-02
I0211 19:14:23.333067 22509476222784 run_lib.py:146] step: 436400, eval_loss: 3.64262e-02
I0211 19:14:41.789205 22509476222784 run_lib.py:133] step: 436450, training_loss: 5.44684e-02
I0211 19:15:00.279659 22509476222784 run_lib.py:133] step: 436500, training_loss: 4.25687e-02
I0211 19:15:00.444689 22509476222784 run_lib.py:146] step: 436500, eval_loss: 5.40232e-02
I0211 19:15:19.137989 22509476222784 run_lib.py:133] step: 436550, training_loss: 4.32550e-02
I0211 19:15:37.677584 22509476222784 run_lib.py:133] step: 436600, training_loss: 4.07366e-02
I0211 19:15:37.842037 22509476222784 run_lib.py:146] step: 436600, eval_loss: 5.03833e-02
I0211 19:15:56.601637 22509476222784 run_lib.py:133] step: 436650, training_loss: 3.86357e-02
I0211 19:16:15.120247 22509476222784 run_lib.py:133] step: 436700, training_loss: 3.50948e-02
I0211 19:16:15.284578 22509476222784 run_lib.py:146] step: 436700, eval_loss: 3.06471e-02
I0211 19:16:33.873467 22509476222784 run_lib.py:133] step: 436750, training_loss: 4.75693e-02
I0211 19:16:52.270990 22509476222784 run_lib.py:133] step: 436800, training_loss: 4.19393e-02
I0211 19:16:52.438025 22509476222784 run_lib.py:146] step: 436800, eval_loss: 4.21210e-02
I0211 19:17:10.994154 22509476222784 run_lib.py:133] step: 436850, training_loss: 4.37030e-02
I0211 19:17:29.709263 22509476222784 run_lib.py:133] step: 436900, training_loss: 4.74785e-02
I0211 19:17:29.901621 22509476222784 run_lib.py:146] step: 436900, eval_loss: 4.58223e-02
I0211 19:17:48.391829 22509476222784 run_lib.py:133] step: 436950, training_loss: 3.92008e-02
I0211 19:18:07.019510 22509476222784 run_lib.py:133] step: 437000, training_loss: 4.02529e-02
I0211 19:18:07.192563 22509476222784 run_lib.py:146] step: 437000, eval_loss: 4.65112e-02
I0211 19:18:25.716469 22509476222784 run_lib.py:133] step: 437050, training_loss: 4.44140e-02
I0211 19:18:44.301465 22509476222784 run_lib.py:133] step: 437100, training_loss: 4.63822e-02
I0211 19:18:44.465989 22509476222784 run_lib.py:146] step: 437100, eval_loss: 4.60867e-02
I0211 19:19:03.199328 22509476222784 run_lib.py:133] step: 437150, training_loss: 4.06019e-02
I0211 19:19:21.677825 22509476222784 run_lib.py:133] step: 437200, training_loss: 3.17919e-02
I0211 19:19:21.840451 22509476222784 run_lib.py:146] step: 437200, eval_loss: 2.54110e-02
I0211 19:19:40.275331 22509476222784 run_lib.py:133] step: 437250, training_loss: 4.14185e-02
I0211 19:19:58.944747 22509476222784 run_lib.py:133] step: 437300, training_loss: 4.32232e-02
I0211 19:19:59.107634 22509476222784 run_lib.py:146] step: 437300, eval_loss: 4.67664e-02
I0211 19:20:17.639350 22509476222784 run_lib.py:133] step: 437350, training_loss: 3.55682e-02
I0211 19:20:36.116786 22509476222784 run_lib.py:133] step: 437400, training_loss: 3.68989e-02
I0211 19:20:36.456646 22509476222784 run_lib.py:146] step: 437400, eval_loss: 3.88951e-02
I0211 19:20:55.004011 22509476222784 run_lib.py:133] step: 437450, training_loss: 4.50667e-02
I0211 19:21:13.562932 22509476222784 run_lib.py:133] step: 437500, training_loss: 4.34409e-02
I0211 19:21:13.728054 22509476222784 run_lib.py:146] step: 437500, eval_loss: 3.96802e-02
I0211 19:21:32.236249 22509476222784 run_lib.py:133] step: 437550, training_loss: 3.44953e-02
I0211 19:21:50.736413 22509476222784 run_lib.py:133] step: 437600, training_loss: 3.96060e-02
I0211 19:21:50.917563 22509476222784 run_lib.py:146] step: 437600, eval_loss: 5.02796e-02
I0211 19:22:09.581600 22509476222784 run_lib.py:133] step: 437650, training_loss: 4.60621e-02
I0211 19:22:28.220866 22509476222784 run_lib.py:133] step: 437700, training_loss: 4.62406e-02
I0211 19:22:28.387801 22509476222784 run_lib.py:146] step: 437700, eval_loss: 4.33333e-02
I0211 19:22:46.883137 22509476222784 run_lib.py:133] step: 437750, training_loss: 4.21006e-02
I0211 19:23:05.416491 22509476222784 run_lib.py:133] step: 437800, training_loss: 4.50117e-02
I0211 19:23:05.580704 22509476222784 run_lib.py:146] step: 437800, eval_loss: 5.38544e-02
I0211 19:23:24.231477 22509476222784 run_lib.py:133] step: 437850, training_loss: 5.07464e-02
I0211 19:23:42.824855 22509476222784 run_lib.py:133] step: 437900, training_loss: 4.45975e-02
I0211 19:23:42.995652 22509476222784 run_lib.py:146] step: 437900, eval_loss: 3.96725e-02
I0211 19:24:01.536606 22509476222784 run_lib.py:133] step: 437950, training_loss: 3.72655e-02
I0211 19:24:20.113010 22509476222784 run_lib.py:133] step: 438000, training_loss: 4.17767e-02
I0211 19:24:20.277946 22509476222784 run_lib.py:146] step: 438000, eval_loss: 4.11583e-02
I0211 19:24:39.013264 22509476222784 run_lib.py:133] step: 438050, training_loss: 4.02014e-02
I0211 19:24:57.488008 22509476222784 run_lib.py:133] step: 438100, training_loss: 3.62626e-02
I0211 19:24:57.649653 22509476222784 run_lib.py:146] step: 438100, eval_loss: 5.63274e-02
I0211 19:25:16.301124 22509476222784 run_lib.py:133] step: 438150, training_loss: 4.54640e-02
I0211 19:25:34.744165 22509476222784 run_lib.py:133] step: 438200, training_loss: 3.91676e-02
I0211 19:25:34.909889 22509476222784 run_lib.py:146] step: 438200, eval_loss: 4.25956e-02
I0211 19:25:53.665414 22509476222784 run_lib.py:133] step: 438250, training_loss: 4.05200e-02
I0211 19:26:12.135396 22509476222784 run_lib.py:133] step: 438300, training_loss: 3.70010e-02
I0211 19:26:12.301674 22509476222784 run_lib.py:146] step: 438300, eval_loss: 3.98465e-02
I0211 19:26:30.768939 22509476222784 run_lib.py:133] step: 438350, training_loss: 4.34246e-02
I0211 19:26:49.386075 22509476222784 run_lib.py:133] step: 438400, training_loss: 3.63985e-02
I0211 19:26:49.550188 22509476222784 run_lib.py:146] step: 438400, eval_loss: 4.50007e-02
I0211 19:27:08.065911 22509476222784 run_lib.py:133] step: 438450, training_loss: 3.56983e-02
I0211 19:27:26.666820 22509476222784 run_lib.py:133] step: 438500, training_loss: 4.62245e-02
I0211 19:27:26.844101 22509476222784 run_lib.py:146] step: 438500, eval_loss: 3.90112e-02
I0211 19:27:45.314507 22509476222784 run_lib.py:133] step: 438550, training_loss: 3.87415e-02
I0211 19:28:03.807541 22509476222784 run_lib.py:133] step: 438600, training_loss: 3.78068e-02
I0211 19:28:03.969619 22509476222784 run_lib.py:146] step: 438600, eval_loss: 4.03184e-02
I0211 19:28:22.412047 22509476222784 run_lib.py:133] step: 438650, training_loss: 4.44658e-02
I0211 19:28:41.103220 22509476222784 run_lib.py:133] step: 438700, training_loss: 5.04459e-02
I0211 19:28:41.265704 22509476222784 run_lib.py:146] step: 438700, eval_loss: 3.29320e-02
I0211 19:28:59.751586 22509476222784 run_lib.py:133] step: 438750, training_loss: 3.00115e-02
I0211 19:29:18.283988 22509476222784 run_lib.py:133] step: 438800, training_loss: 5.16795e-02
I0211 19:29:18.461625 22509476222784 run_lib.py:146] step: 438800, eval_loss: 4.13497e-02
I0211 19:29:37.118657 22509476222784 run_lib.py:133] step: 438850, training_loss: 3.67105e-02
I0211 19:29:55.581448 22509476222784 run_lib.py:133] step: 438900, training_loss: 3.55967e-02
I0211 19:29:55.745633 22509476222784 run_lib.py:146] step: 438900, eval_loss: 5.27849e-02
I0211 19:30:14.306018 22509476222784 run_lib.py:133] step: 438950, training_loss: 4.66247e-02
I0211 19:30:32.762434 22509476222784 run_lib.py:133] step: 439000, training_loss: 3.62596e-02
I0211 19:30:32.983057 22509476222784 run_lib.py:146] step: 439000, eval_loss: 6.59560e-02
I0211 19:30:51.514676 22509476222784 run_lib.py:133] step: 439050, training_loss: 4.37320e-02
I0211 19:31:09.960958 22509476222784 run_lib.py:133] step: 439100, training_loss: 3.78994e-02
I0211 19:31:10.124861 22509476222784 run_lib.py:146] step: 439100, eval_loss: 4.28608e-02
I0211 19:31:28.737434 22509476222784 run_lib.py:133] step: 439150, training_loss: 4.94056e-02
I0211 19:31:47.265744 22509476222784 run_lib.py:133] step: 439200, training_loss: 4.87989e-02
I0211 19:31:47.428664 22509476222784 run_lib.py:146] step: 439200, eval_loss: 4.32593e-02
I0211 19:32:05.897357 22509476222784 run_lib.py:133] step: 439250, training_loss: 5.14553e-02
I0211 19:32:24.347106 22509476222784 run_lib.py:133] step: 439300, training_loss: 5.29191e-02
I0211 19:32:24.527605 22509476222784 run_lib.py:146] step: 439300, eval_loss: 3.95762e-02
I0211 19:32:43.207156 22509476222784 run_lib.py:133] step: 439350, training_loss: 5.49407e-02
I0211 19:33:01.757557 22509476222784 run_lib.py:133] step: 439400, training_loss: 3.59911e-02
I0211 19:33:01.923031 22509476222784 run_lib.py:146] step: 439400, eval_loss: 4.48562e-02
I0211 19:33:20.628781 22509476222784 run_lib.py:133] step: 439450, training_loss: 4.81731e-02
I0211 19:33:39.103166 22509476222784 run_lib.py:133] step: 439500, training_loss: 5.24154e-02
I0211 19:33:39.266381 22509476222784 run_lib.py:146] step: 439500, eval_loss: 4.64019e-02
I0211 19:33:57.933646 22509476222784 run_lib.py:133] step: 439550, training_loss: 5.60060e-02
I0211 19:34:16.410519 22509476222784 run_lib.py:133] step: 439600, training_loss: 3.86713e-02
I0211 19:34:16.570710 22509476222784 run_lib.py:146] step: 439600, eval_loss: 5.56570e-02
I0211 19:34:35.331301 22509476222784 run_lib.py:133] step: 439650, training_loss: 4.45494e-02
I0211 19:34:53.825546 22509476222784 run_lib.py:133] step: 439700, training_loss: 5.20021e-02
I0211 19:34:53.995658 22509476222784 run_lib.py:146] step: 439700, eval_loss: 5.34725e-02
I0211 19:35:12.461115 22509476222784 run_lib.py:133] step: 439750, training_loss: 5.70716e-02
I0211 19:35:31.047564 22509476222784 run_lib.py:133] step: 439800, training_loss: 5.75680e-02
I0211 19:35:31.218809 22509476222784 run_lib.py:146] step: 439800, eval_loss: 3.43599e-02
I0211 19:35:49.705494 22509476222784 run_lib.py:133] step: 439850, training_loss: 4.13027e-02
I0211 19:36:08.374453 22509476222784 run_lib.py:133] step: 439900, training_loss: 3.74905e-02
I0211 19:36:08.547785 22509476222784 run_lib.py:146] step: 439900, eval_loss: 4.81523e-02
I0211 19:36:27.272419 22509476222784 run_lib.py:133] step: 439950, training_loss: 3.83462e-02
I0211 19:36:45.970568 22509476222784 run_lib.py:133] step: 440000, training_loss: 5.86229e-02
I0211 19:36:46.697594 22509476222784 run_lib.py:146] step: 440000, eval_loss: 4.73087e-02
I0211 19:37:07.935889 22509476222784 run_lib.py:133] step: 440050, training_loss: 4.31179e-02
I0211 19:37:26.564940 22509476222784 run_lib.py:133] step: 440100, training_loss: 4.29370e-02
I0211 19:37:26.734653 22509476222784 run_lib.py:146] step: 440100, eval_loss: 4.14458e-02
I0211 19:37:45.294237 22509476222784 run_lib.py:133] step: 440150, training_loss: 5.11709e-02
I0211 19:38:03.879634 22509476222784 run_lib.py:133] step: 440200, training_loss: 4.29961e-02
I0211 19:38:04.044900 22509476222784 run_lib.py:146] step: 440200, eval_loss: 3.01038e-02
I0211 19:38:22.699909 22509476222784 run_lib.py:133] step: 440250, training_loss: 4.09725e-02
I0211 19:38:41.232806 22509476222784 run_lib.py:133] step: 440300, training_loss: 4.01254e-02
I0211 19:38:41.404105 22509476222784 run_lib.py:146] step: 440300, eval_loss: 5.55233e-02
I0211 19:38:59.841593 22509476222784 run_lib.py:133] step: 440350, training_loss: 3.89557e-02
I0211 19:39:18.397879 22509476222784 run_lib.py:133] step: 440400, training_loss: 4.71747e-02
I0211 19:39:18.581468 22509476222784 run_lib.py:146] step: 440400, eval_loss: 5.58599e-02
I0211 19:39:37.256079 22509476222784 run_lib.py:133] step: 440450, training_loss: 3.65362e-02
I0211 19:39:55.774468 22509476222784 run_lib.py:133] step: 440500, training_loss: 4.67210e-02
I0211 19:39:55.943374 22509476222784 run_lib.py:146] step: 440500, eval_loss: 3.63107e-02
I0211 19:40:14.623951 22509476222784 run_lib.py:133] step: 440550, training_loss: 4.52308e-02
I0211 19:40:33.058623 22509476222784 run_lib.py:133] step: 440600, training_loss: 4.85809e-02
I0211 19:40:33.224418 22509476222784 run_lib.py:146] step: 440600, eval_loss: 4.29734e-02
I0211 19:40:51.862349 22509476222784 run_lib.py:133] step: 440650, training_loss: 3.85515e-02
I0211 19:41:10.422289 22509476222784 run_lib.py:133] step: 440700, training_loss: 3.49818e-02
I0211 19:41:10.636891 22509476222784 run_lib.py:146] step: 440700, eval_loss: 3.85773e-02
I0211 19:41:29.143727 22509476222784 run_lib.py:133] step: 440750, training_loss: 5.62949e-02
I0211 19:41:47.796670 22509476222784 run_lib.py:133] step: 440800, training_loss: 3.44262e-02
I0211 19:41:47.968744 22509476222784 run_lib.py:146] step: 440800, eval_loss: 4.49218e-02
I0211 19:42:06.409433 22509476222784 run_lib.py:133] step: 440850, training_loss: 5.42076e-02
I0211 19:42:25.056652 22509476222784 run_lib.py:133] step: 440900, training_loss: 5.56288e-02
I0211 19:42:25.216259 22509476222784 run_lib.py:146] step: 440900, eval_loss: 4.96416e-02
I0211 19:42:43.677626 22509476222784 run_lib.py:133] step: 440950, training_loss: 4.81142e-02
I0211 19:43:02.244189 22509476222784 run_lib.py:133] step: 441000, training_loss: 4.29672e-02
I0211 19:43:02.408749 22509476222784 run_lib.py:146] step: 441000, eval_loss: 5.06736e-02
I0211 19:43:21.114101 22509476222784 run_lib.py:133] step: 441050, training_loss: 4.87001e-02
I0211 19:43:39.592696 22509476222784 run_lib.py:133] step: 441100, training_loss: 3.62389e-02
I0211 19:43:39.757896 22509476222784 run_lib.py:146] step: 441100, eval_loss: 4.94357e-02
I0211 19:43:58.229554 22509476222784 run_lib.py:133] step: 441150, training_loss: 3.82453e-02
I0211 19:44:16.888683 22509476222784 run_lib.py:133] step: 441200, training_loss: 3.21327e-02
I0211 19:44:17.069941 22509476222784 run_lib.py:146] step: 441200, eval_loss: 3.26729e-02
I0211 19:44:35.616302 22509476222784 run_lib.py:133] step: 441250, training_loss: 3.33355e-02
I0211 19:44:54.163934 22509476222784 run_lib.py:133] step: 441300, training_loss: 4.33521e-02
I0211 19:44:54.329682 22509476222784 run_lib.py:146] step: 441300, eval_loss: 4.89419e-02
I0211 19:45:12.904950 22509476222784 run_lib.py:133] step: 441350, training_loss: 4.65470e-02
I0211 19:45:31.449155 22509476222784 run_lib.py:133] step: 441400, training_loss: 4.21628e-02
I0211 19:45:31.614692 22509476222784 run_lib.py:146] step: 441400, eval_loss: 4.28032e-02
I0211 19:45:50.109212 22509476222784 run_lib.py:133] step: 441450, training_loss: 4.19940e-02
I0211 19:46:08.654747 22509476222784 run_lib.py:133] step: 441500, training_loss: 3.97226e-02
I0211 19:46:08.819828 22509476222784 run_lib.py:146] step: 441500, eval_loss: 4.65299e-02
I0211 19:46:27.404100 22509476222784 run_lib.py:133] step: 441550, training_loss: 4.23119e-02
I0211 19:46:45.876128 22509476222784 run_lib.py:133] step: 441600, training_loss: 3.52577e-02
I0211 19:46:46.045658 22509476222784 run_lib.py:146] step: 441600, eval_loss: 3.40139e-02
I0211 19:47:04.537349 22509476222784 run_lib.py:133] step: 441650, training_loss: 3.97936e-02
I0211 19:47:23.044473 22509476222784 run_lib.py:133] step: 441700, training_loss: 4.34931e-02
I0211 19:47:23.208040 22509476222784 run_lib.py:146] step: 441700, eval_loss: 4.92452e-02
I0211 19:47:41.822010 22509476222784 run_lib.py:133] step: 441750, training_loss: 3.92075e-02
I0211 19:48:00.334589 22509476222784 run_lib.py:133] step: 441800, training_loss: 4.14605e-02
I0211 19:48:00.503519 22509476222784 run_lib.py:146] step: 441800, eval_loss: 3.13891e-02
I0211 19:48:19.159058 22509476222784 run_lib.py:133] step: 441850, training_loss: 5.32729e-02
I0211 19:48:37.688615 22509476222784 run_lib.py:133] step: 441900, training_loss: 3.94549e-02
I0211 19:48:37.852800 22509476222784 run_lib.py:146] step: 441900, eval_loss: 4.28198e-02
I0211 19:48:56.533227 22509476222784 run_lib.py:133] step: 441950, training_loss: 4.51940e-02
I0211 19:49:15.040877 22509476222784 run_lib.py:133] step: 442000, training_loss: 2.93720e-02
I0211 19:49:15.223589 22509476222784 run_lib.py:146] step: 442000, eval_loss: 3.87890e-02
I0211 19:49:33.858011 22509476222784 run_lib.py:133] step: 442050, training_loss: 3.94481e-02
I0211 19:49:52.398255 22509476222784 run_lib.py:133] step: 442100, training_loss: 3.04725e-02
I0211 19:49:52.576904 22509476222784 run_lib.py:146] step: 442100, eval_loss: 3.76574e-02
I0211 19:50:11.094079 22509476222784 run_lib.py:133] step: 442150, training_loss: 5.24617e-02
I0211 19:50:29.777675 22509476222784 run_lib.py:133] step: 442200, training_loss: 3.98759e-02
I0211 19:50:29.942855 22509476222784 run_lib.py:146] step: 442200, eval_loss: 3.31156e-02
I0211 19:50:48.445470 22509476222784 run_lib.py:133] step: 442250, training_loss: 3.18396e-02
I0211 19:51:06.953346 22509476222784 run_lib.py:133] step: 442300, training_loss: 4.89068e-02
I0211 19:51:07.158547 22509476222784 run_lib.py:146] step: 442300, eval_loss: 3.74128e-02
I0211 19:51:25.817035 22509476222784 run_lib.py:133] step: 442350, training_loss: 5.40025e-02
I0211 19:51:44.351457 22509476222784 run_lib.py:133] step: 442400, training_loss: 3.86172e-02
I0211 19:51:44.516900 22509476222784 run_lib.py:146] step: 442400, eval_loss: 4.04534e-02
I0211 19:52:03.186708 22509476222784 run_lib.py:133] step: 442450, training_loss: 4.11506e-02
I0211 19:52:21.660379 22509476222784 run_lib.py:133] step: 442500, training_loss: 4.02498e-02
I0211 19:52:21.819545 22509476222784 run_lib.py:146] step: 442500, eval_loss: 5.37622e-02
I0211 19:52:40.240767 22509476222784 run_lib.py:133] step: 442550, training_loss: 4.39135e-02
I0211 19:52:58.844909 22509476222784 run_lib.py:133] step: 442600, training_loss: 3.67892e-02
I0211 19:52:59.100823 22509476222784 run_lib.py:146] step: 442600, eval_loss: 4.59023e-02
I0211 19:53:17.601517 22509476222784 run_lib.py:133] step: 442650, training_loss: 3.73257e-02
I0211 19:53:36.151856 22509476222784 run_lib.py:133] step: 442700, training_loss: 3.66561e-02
I0211 19:53:36.318653 22509476222784 run_lib.py:146] step: 442700, eval_loss: 4.70475e-02
I0211 19:53:54.805890 22509476222784 run_lib.py:133] step: 442750, training_loss: 5.46854e-02
I0211 19:54:13.464004 22509476222784 run_lib.py:133] step: 442800, training_loss: 4.20160e-02
I0211 19:54:13.627688 22509476222784 run_lib.py:146] step: 442800, eval_loss: 3.74862e-02
I0211 19:54:32.113531 22509476222784 run_lib.py:133] step: 442850, training_loss: 3.21001e-02
I0211 19:54:50.712180 22509476222784 run_lib.py:133] step: 442900, training_loss: 3.91714e-02
I0211 19:54:50.875716 22509476222784 run_lib.py:146] step: 442900, eval_loss: 4.66927e-02
I0211 19:55:09.439340 22509476222784 run_lib.py:133] step: 442950, training_loss: 4.73806e-02
I0211 19:55:27.883535 22509476222784 run_lib.py:133] step: 443000, training_loss: 4.05527e-02
I0211 19:55:28.043594 22509476222784 run_lib.py:146] step: 443000, eval_loss: 4.10561e-02
I0211 19:55:46.749482 22509476222784 run_lib.py:133] step: 443050, training_loss: 4.54781e-02
I0211 19:56:05.351464 22509476222784 run_lib.py:133] step: 443100, training_loss: 4.12574e-02
I0211 19:56:05.515383 22509476222784 run_lib.py:146] step: 443100, eval_loss: 4.73546e-02
I0211 19:56:24.003461 22509476222784 run_lib.py:133] step: 443150, training_loss: 3.51989e-02
I0211 19:56:42.558704 22509476222784 run_lib.py:133] step: 443200, training_loss: 3.58170e-02
I0211 19:56:42.729005 22509476222784 run_lib.py:146] step: 443200, eval_loss: 3.28431e-02
I0211 19:57:01.401707 22509476222784 run_lib.py:133] step: 443250, training_loss: 4.07718e-02
I0211 19:57:19.909592 22509476222784 run_lib.py:133] step: 443300, training_loss: 4.35352e-02
I0211 19:57:20.079721 22509476222784 run_lib.py:146] step: 443300, eval_loss: 5.09465e-02
I0211 19:57:38.726745 22509476222784 run_lib.py:133] step: 443350, training_loss: 3.79868e-02
I0211 19:57:57.212591 22509476222784 run_lib.py:133] step: 443400, training_loss: 4.00016e-02
I0211 19:57:57.390638 22509476222784 run_lib.py:146] step: 443400, eval_loss: 4.86068e-02
I0211 19:58:16.026500 22509476222784 run_lib.py:133] step: 443450, training_loss: 4.29169e-02
I0211 19:58:34.447422 22509476222784 run_lib.py:133] step: 443500, training_loss: 3.20119e-02
I0211 19:58:34.609732 22509476222784 run_lib.py:146] step: 443500, eval_loss: 5.00933e-02
I0211 19:58:53.094894 22509476222784 run_lib.py:133] step: 443550, training_loss: 4.67918e-02
I0211 19:59:11.861296 22509476222784 run_lib.py:133] step: 443600, training_loss: 5.06842e-02
I0211 19:59:12.026944 22509476222784 run_lib.py:146] step: 443600, eval_loss: 3.61140e-02
I0211 19:59:30.481020 22509476222784 run_lib.py:133] step: 443650, training_loss: 5.03497e-02
I0211 19:59:49.092448 22509476222784 run_lib.py:133] step: 443700, training_loss: 3.92461e-02
I0211 19:59:49.258687 22509476222784 run_lib.py:146] step: 443700, eval_loss: 4.29437e-02
I0211 20:00:07.692287 22509476222784 run_lib.py:133] step: 443750, training_loss: 2.55792e-02
I0211 20:00:26.217032 22509476222784 run_lib.py:133] step: 443800, training_loss: 4.06824e-02
I0211 20:00:26.400060 22509476222784 run_lib.py:146] step: 443800, eval_loss: 4.65591e-02
I0211 20:00:45.082804 22509476222784 run_lib.py:133] step: 443850, training_loss: 5.05247e-02
I0211 20:01:03.564008 22509476222784 run_lib.py:133] step: 443900, training_loss: 4.24462e-02
I0211 20:01:03.725684 22509476222784 run_lib.py:146] step: 443900, eval_loss: 5.46438e-02
I0211 20:01:22.198172 22509476222784 run_lib.py:133] step: 443950, training_loss: 3.64038e-02
I0211 20:01:40.797472 22509476222784 run_lib.py:133] step: 444000, training_loss: 3.82313e-02
I0211 20:01:40.987841 22509476222784 run_lib.py:146] step: 444000, eval_loss: 4.86722e-02
I0211 20:01:59.535813 22509476222784 run_lib.py:133] step: 444050, training_loss: 4.85188e-02
I0211 20:02:18.109313 22509476222784 run_lib.py:133] step: 444100, training_loss: 3.98275e-02
I0211 20:02:18.460502 22509476222784 run_lib.py:146] step: 444100, eval_loss: 4.80086e-02
I0211 20:02:36.931384 22509476222784 run_lib.py:133] step: 444150, training_loss: 3.80389e-02
I0211 20:02:55.415024 22509476222784 run_lib.py:133] step: 444200, training_loss: 5.05117e-02
I0211 20:02:55.579519 22509476222784 run_lib.py:146] step: 444200, eval_loss: 4.63785e-02
I0211 20:03:14.062765 22509476222784 run_lib.py:133] step: 444250, training_loss: 4.27324e-02
I0211 20:03:32.667579 22509476222784 run_lib.py:133] step: 444300, training_loss: 4.50188e-02
I0211 20:03:32.864577 22509476222784 run_lib.py:146] step: 444300, eval_loss: 3.59244e-02
I0211 20:03:51.591148 22509476222784 run_lib.py:133] step: 444350, training_loss: 4.86123e-02
I0211 20:04:10.197179 22509476222784 run_lib.py:133] step: 444400, training_loss: 3.29959e-02
I0211 20:04:10.357474 22509476222784 run_lib.py:146] step: 444400, eval_loss: 3.76524e-02
I0211 20:04:28.856513 22509476222784 run_lib.py:133] step: 444450, training_loss: 4.40751e-02
I0211 20:04:47.361699 22509476222784 run_lib.py:133] step: 444500, training_loss: 4.61451e-02
I0211 20:04:47.523466 22509476222784 run_lib.py:146] step: 444500, eval_loss: 4.85270e-02
I0211 20:05:06.008331 22509476222784 run_lib.py:133] step: 444550, training_loss: 4.40573e-02
I0211 20:05:24.589964 22509476222784 run_lib.py:133] step: 444600, training_loss: 3.92358e-02
I0211 20:05:24.809639 22509476222784 run_lib.py:146] step: 444600, eval_loss: 4.39839e-02
I0211 20:05:43.352401 22509476222784 run_lib.py:133] step: 444650, training_loss: 2.92680e-02
I0211 20:06:01.868556 22509476222784 run_lib.py:133] step: 444700, training_loss: 3.93503e-02
I0211 20:06:02.031792 22509476222784 run_lib.py:146] step: 444700, eval_loss: 5.69369e-02
I0211 20:06:20.701770 22509476222784 run_lib.py:133] step: 444750, training_loss: 4.35941e-02
I0211 20:06:39.156934 22509476222784 run_lib.py:133] step: 444800, training_loss: 3.64458e-02
I0211 20:06:39.319618 22509476222784 run_lib.py:146] step: 444800, eval_loss: 3.36816e-02
I0211 20:06:57.956043 22509476222784 run_lib.py:133] step: 444850, training_loss: 4.34572e-02
I0211 20:07:16.503762 22509476222784 run_lib.py:133] step: 444900, training_loss: 4.21752e-02
I0211 20:07:16.683882 22509476222784 run_lib.py:146] step: 444900, eval_loss: 3.94699e-02
I0211 20:07:35.386017 22509476222784 run_lib.py:133] step: 444950, training_loss: 3.89164e-02
I0211 20:07:53.899023 22509476222784 run_lib.py:133] step: 445000, training_loss: 3.60765e-02
I0211 20:07:54.077960 22509476222784 run_lib.py:146] step: 445000, eval_loss: 4.97557e-02
I0211 20:08:12.556476 22509476222784 run_lib.py:133] step: 445050, training_loss: 4.04764e-02
I0211 20:08:31.234545 22509476222784 run_lib.py:133] step: 445100, training_loss: 4.55033e-02
I0211 20:08:31.402630 22509476222784 run_lib.py:146] step: 445100, eval_loss: 3.99937e-02
I0211 20:08:49.915752 22509476222784 run_lib.py:133] step: 445150, training_loss: 3.16920e-02
I0211 20:09:08.679765 22509476222784 run_lib.py:133] step: 445200, training_loss: 3.93929e-02
I0211 20:09:08.845120 22509476222784 run_lib.py:146] step: 445200, eval_loss: 3.93100e-02
I0211 20:09:27.296166 22509476222784 run_lib.py:133] step: 445250, training_loss: 3.61893e-02
I0211 20:09:45.814134 22509476222784 run_lib.py:133] step: 445300, training_loss: 3.29219e-02
I0211 20:09:45.977665 22509476222784 run_lib.py:146] step: 445300, eval_loss: 5.56087e-02
I0211 20:10:04.579950 22509476222784 run_lib.py:133] step: 445350, training_loss: 4.98513e-02
I0211 20:10:23.058937 22509476222784 run_lib.py:133] step: 445400, training_loss: 3.43152e-02
I0211 20:10:23.223937 22509476222784 run_lib.py:146] step: 445400, eval_loss: 4.87843e-02
I0211 20:10:41.796752 22509476222784 run_lib.py:133] step: 445450, training_loss: 4.42296e-02
I0211 20:11:00.323491 22509476222784 run_lib.py:133] step: 445500, training_loss: 3.65356e-02
I0211 20:11:00.489567 22509476222784 run_lib.py:146] step: 445500, eval_loss: 3.98853e-02
I0211 20:11:19.114078 22509476222784 run_lib.py:133] step: 445550, training_loss: 4.41278e-02
I0211 20:11:37.501991 22509476222784 run_lib.py:133] step: 445600, training_loss: 4.69707e-02
I0211 20:11:37.665601 22509476222784 run_lib.py:146] step: 445600, eval_loss: 4.51242e-02
I0211 20:11:56.249635 22509476222784 run_lib.py:133] step: 445650, training_loss: 2.82797e-02
I0211 20:12:14.839123 22509476222784 run_lib.py:133] step: 445700, training_loss: 2.99033e-02
I0211 20:12:15.003270 22509476222784 run_lib.py:146] step: 445700, eval_loss: 3.90279e-02
I0211 20:12:33.517734 22509476222784 run_lib.py:133] step: 445750, training_loss: 3.82967e-02
I0211 20:12:52.010498 22509476222784 run_lib.py:133] step: 445800, training_loss: 4.48425e-02
I0211 20:12:52.174298 22509476222784 run_lib.py:146] step: 445800, eval_loss: 3.45549e-02
I0211 20:13:10.856888 22509476222784 run_lib.py:133] step: 445850, training_loss: 5.08318e-02
I0211 20:13:29.502095 22509476222784 run_lib.py:133] step: 445900, training_loss: 3.06489e-02
I0211 20:13:29.667913 22509476222784 run_lib.py:146] step: 445900, eval_loss: 3.87116e-02
I0211 20:13:48.252910 22509476222784 run_lib.py:133] step: 445950, training_loss: 5.45128e-02
I0211 20:14:06.781799 22509476222784 run_lib.py:133] step: 446000, training_loss: 4.98139e-02
I0211 20:14:06.948665 22509476222784 run_lib.py:146] step: 446000, eval_loss: 3.84346e-02
I0211 20:14:25.631624 22509476222784 run_lib.py:133] step: 446050, training_loss: 3.89627e-02
I0211 20:14:44.131638 22509476222784 run_lib.py:133] step: 446100, training_loss: 6.34994e-02
I0211 20:14:44.304625 22509476222784 run_lib.py:146] step: 446100, eval_loss: 5.16343e-02
I0211 20:15:02.909605 22509476222784 run_lib.py:133] step: 446150, training_loss: 3.49928e-02
I0211 20:15:21.453411 22509476222784 run_lib.py:133] step: 446200, training_loss: 3.75083e-02
I0211 20:15:21.617835 22509476222784 run_lib.py:146] step: 446200, eval_loss: 4.15823e-02
I0211 20:15:40.411158 22509476222784 run_lib.py:133] step: 446250, training_loss: 4.05606e-02
I0211 20:15:58.889650 22509476222784 run_lib.py:133] step: 446300, training_loss: 3.62828e-02
I0211 20:15:59.100702 22509476222784 run_lib.py:146] step: 446300, eval_loss: 3.34003e-02
I0211 20:16:17.732816 22509476222784 run_lib.py:133] step: 446350, training_loss: 3.79631e-02
I0211 20:16:36.241296 22509476222784 run_lib.py:133] step: 446400, training_loss: 3.46829e-02
I0211 20:16:36.406617 22509476222784 run_lib.py:146] step: 446400, eval_loss: 4.40212e-02
I0211 20:16:54.913208 22509476222784 run_lib.py:133] step: 446450, training_loss: 5.12374e-02
I0211 20:17:13.596034 22509476222784 run_lib.py:133] step: 446500, training_loss: 3.56253e-02
I0211 20:17:13.773545 22509476222784 run_lib.py:146] step: 446500, eval_loss: 4.71065e-02
I0211 20:17:32.187598 22509476222784 run_lib.py:133] step: 446550, training_loss: 4.67111e-02
I0211 20:17:50.733863 22509476222784 run_lib.py:133] step: 446600, training_loss: 3.88689e-02
I0211 20:17:50.899867 22509476222784 run_lib.py:146] step: 446600, eval_loss: 4.76978e-02
I0211 20:18:09.625364 22509476222784 run_lib.py:133] step: 446650, training_loss: 4.79551e-02
I0211 20:18:28.310277 22509476222784 run_lib.py:133] step: 446700, training_loss: 3.89832e-02
I0211 20:18:28.472652 22509476222784 run_lib.py:146] step: 446700, eval_loss: 5.03919e-02
I0211 20:18:47.019157 22509476222784 run_lib.py:133] step: 446750, training_loss: 4.48640e-02
I0211 20:19:05.530001 22509476222784 run_lib.py:133] step: 446800, training_loss: 4.86987e-02
I0211 20:19:05.698867 22509476222784 run_lib.py:146] step: 446800, eval_loss: 5.34051e-02
I0211 20:19:24.281517 22509476222784 run_lib.py:133] step: 446850, training_loss: 4.99763e-02
I0211 20:19:43.011717 22509476222784 run_lib.py:133] step: 446900, training_loss: 5.55943e-02
I0211 20:19:43.176954 22509476222784 run_lib.py:146] step: 446900, eval_loss: 4.84426e-02
I0211 20:20:01.643466 22509476222784 run_lib.py:133] step: 446950, training_loss: 4.79877e-02
I0211 20:20:20.210093 22509476222784 run_lib.py:133] step: 447000, training_loss: 5.15548e-02
I0211 20:20:20.375749 22509476222784 run_lib.py:146] step: 447000, eval_loss: 4.46856e-02
I0211 20:20:38.916100 22509476222784 run_lib.py:133] step: 447050, training_loss: 5.32748e-02
I0211 20:20:57.614849 22509476222784 run_lib.py:133] step: 447100, training_loss: 3.77260e-02
I0211 20:20:57.779960 22509476222784 run_lib.py:146] step: 447100, eval_loss: 4.75697e-02
I0211 20:21:16.289005 22509476222784 run_lib.py:133] step: 447150, training_loss: 5.51296e-02
I0211 20:21:34.841392 22509476222784 run_lib.py:133] step: 447200, training_loss: 4.09847e-02
I0211 20:21:35.004659 22509476222784 run_lib.py:146] step: 447200, eval_loss: 4.16923e-02
I0211 20:21:53.519241 22509476222784 run_lib.py:133] step: 447250, training_loss: 4.61104e-02
I0211 20:22:12.050995 22509476222784 run_lib.py:133] step: 447300, training_loss: 3.92009e-02
I0211 20:22:12.239658 22509476222784 run_lib.py:146] step: 447300, eval_loss: 4.98532e-02
I0211 20:22:30.955826 22509476222784 run_lib.py:133] step: 447350, training_loss: 3.99597e-02
I0211 20:22:49.564155 22509476222784 run_lib.py:133] step: 447400, training_loss: 5.32802e-02
I0211 20:22:49.728478 22509476222784 run_lib.py:146] step: 447400, eval_loss: 4.00270e-02
I0211 20:23:08.124751 22509476222784 run_lib.py:133] step: 447450, training_loss: 4.40937e-02
I0211 20:23:26.541883 22509476222784 run_lib.py:133] step: 447500, training_loss: 3.69489e-02
I0211 20:23:26.706676 22509476222784 run_lib.py:146] step: 447500, eval_loss: 4.40907e-02
I0211 20:23:45.301134 22509476222784 run_lib.py:133] step: 447550, training_loss: 5.50423e-02
I0211 20:24:03.848343 22509476222784 run_lib.py:133] step: 447600, training_loss: 3.36227e-02
I0211 20:24:04.024439 22509476222784 run_lib.py:146] step: 447600, eval_loss: 4.31493e-02
I0211 20:24:22.752839 22509476222784 run_lib.py:133] step: 447650, training_loss: 4.39057e-02
I0211 20:24:41.249006 22509476222784 run_lib.py:133] step: 447700, training_loss: 5.22027e-02
I0211 20:24:41.408604 22509476222784 run_lib.py:146] step: 447700, eval_loss: 3.70521e-02
I0211 20:25:00.012328 22509476222784 run_lib.py:133] step: 447750, training_loss: 5.04421e-02
I0211 20:25:18.510004 22509476222784 run_lib.py:133] step: 447800, training_loss: 4.63274e-02
I0211 20:25:18.720704 22509476222784 run_lib.py:146] step: 447800, eval_loss: 3.48581e-02
I0211 20:25:37.263602 22509476222784 run_lib.py:133] step: 447850, training_loss: 4.68195e-02
I0211 20:25:56.008260 22509476222784 run_lib.py:133] step: 447900, training_loss: 3.68404e-02
I0211 20:25:56.172745 22509476222784 run_lib.py:146] step: 447900, eval_loss: 5.23844e-02
I0211 20:26:14.682602 22509476222784 run_lib.py:133] step: 447950, training_loss: 4.99866e-02
I0211 20:26:33.259775 22509476222784 run_lib.py:133] step: 448000, training_loss: 4.69019e-02
I0211 20:26:33.423641 22509476222784 run_lib.py:146] step: 448000, eval_loss: 4.32353e-02
I0211 20:26:51.858704 22509476222784 run_lib.py:133] step: 448050, training_loss: 4.86391e-02
I0211 20:27:10.289941 22509476222784 run_lib.py:133] step: 448100, training_loss: 5.55028e-02
I0211 20:27:10.453356 22509476222784 run_lib.py:146] step: 448100, eval_loss: 5.15226e-02
I0211 20:27:29.111371 22509476222784 run_lib.py:133] step: 448150, training_loss: 3.63550e-02
I0211 20:27:47.719173 22509476222784 run_lib.py:133] step: 448200, training_loss: 4.90414e-02
I0211 20:27:47.883713 22509476222784 run_lib.py:146] step: 448200, eval_loss: 4.26690e-02
I0211 20:28:06.396983 22509476222784 run_lib.py:133] step: 448250, training_loss: 5.00854e-02
I0211 20:28:25.086465 22509476222784 run_lib.py:133] step: 448300, training_loss: 3.65644e-02
I0211 20:28:25.258111 22509476222784 run_lib.py:146] step: 448300, eval_loss: 4.50170e-02
I0211 20:28:43.720601 22509476222784 run_lib.py:133] step: 448350, training_loss: 3.40052e-02
I0211 20:29:02.116126 22509476222784 run_lib.py:133] step: 448400, training_loss: 3.79723e-02
I0211 20:29:02.294679 22509476222784 run_lib.py:146] step: 448400, eval_loss: 3.94863e-02
I0211 20:29:20.852013 22509476222784 run_lib.py:133] step: 448450, training_loss: 5.67711e-02
I0211 20:29:39.369957 22509476222784 run_lib.py:133] step: 448500, training_loss: 5.28593e-02
I0211 20:29:39.533789 22509476222784 run_lib.py:146] step: 448500, eval_loss: 4.18300e-02
I0211 20:29:58.062893 22509476222784 run_lib.py:133] step: 448550, training_loss: 3.22871e-02
I0211 20:30:16.509393 22509476222784 run_lib.py:133] step: 448600, training_loss: 5.17683e-02
I0211 20:30:16.672530 22509476222784 run_lib.py:146] step: 448600, eval_loss: 3.75261e-02
I0211 20:30:35.325018 22509476222784 run_lib.py:133] step: 448650, training_loss: 4.17406e-02
I0211 20:30:53.903945 22509476222784 run_lib.py:133] step: 448700, training_loss: 3.47440e-02
I0211 20:30:54.066782 22509476222784 run_lib.py:146] step: 448700, eval_loss: 4.23263e-02
I0211 20:31:12.637571 22509476222784 run_lib.py:133] step: 448750, training_loss: 5.10068e-02
I0211 20:31:31.121116 22509476222784 run_lib.py:133] step: 448800, training_loss: 4.16767e-02
I0211 20:31:31.287623 22509476222784 run_lib.py:146] step: 448800, eval_loss: 4.39366e-02
I0211 20:31:49.923388 22509476222784 run_lib.py:133] step: 448850, training_loss: 4.85893e-02
I0211 20:32:08.445453 22509476222784 run_lib.py:133] step: 448900, training_loss: 3.73034e-02
I0211 20:32:08.645501 22509476222784 run_lib.py:146] step: 448900, eval_loss: 4.48235e-02
I0211 20:32:27.309168 22509476222784 run_lib.py:133] step: 448950, training_loss: 3.67130e-02
I0211 20:32:45.871956 22509476222784 run_lib.py:133] step: 449000, training_loss: 4.97740e-02
I0211 20:32:46.036058 22509476222784 run_lib.py:146] step: 449000, eval_loss: 4.41354e-02
I0211 20:33:04.775839 22509476222784 run_lib.py:133] step: 449050, training_loss: 3.90228e-02
I0211 20:33:23.311013 22509476222784 run_lib.py:133] step: 449100, training_loss: 4.03100e-02
I0211 20:33:23.474946 22509476222784 run_lib.py:146] step: 449100, eval_loss: 4.50495e-02
I0211 20:33:42.055059 22509476222784 run_lib.py:133] step: 449150, training_loss: 5.81882e-02
I0211 20:34:00.506700 22509476222784 run_lib.py:133] step: 449200, training_loss: 3.54461e-02
I0211 20:34:00.668691 22509476222784 run_lib.py:146] step: 449200, eval_loss: 3.95202e-02
I0211 20:34:19.081349 22509476222784 run_lib.py:133] step: 449250, training_loss: 5.09537e-02
I0211 20:34:37.770948 22509476222784 run_lib.py:133] step: 449300, training_loss: 4.02010e-02
I0211 20:34:37.968676 22509476222784 run_lib.py:146] step: 449300, eval_loss: 3.15930e-02
I0211 20:34:56.470202 22509476222784 run_lib.py:133] step: 449350, training_loss: 4.31874e-02
I0211 20:35:14.972694 22509476222784 run_lib.py:133] step: 449400, training_loss: 4.00088e-02
I0211 20:35:15.156589 22509476222784 run_lib.py:146] step: 449400, eval_loss: 5.09830e-02
I0211 20:35:33.873991 22509476222784 run_lib.py:133] step: 449450, training_loss: 3.97348e-02
I0211 20:35:52.389955 22509476222784 run_lib.py:133] step: 449500, training_loss: 4.13449e-02
I0211 20:35:52.559726 22509476222784 run_lib.py:146] step: 449500, eval_loss: 4.05252e-02
I0211 20:36:11.246554 22509476222784 run_lib.py:133] step: 449550, training_loss: 4.29038e-02
I0211 20:36:29.725102 22509476222784 run_lib.py:133] step: 449600, training_loss: 5.77324e-02
I0211 20:36:29.884290 22509476222784 run_lib.py:146] step: 449600, eval_loss: 3.53809e-02
I0211 20:36:48.299127 22509476222784 run_lib.py:133] step: 449650, training_loss: 3.80615e-02
I0211 20:37:07.001614 22509476222784 run_lib.py:133] step: 449700, training_loss: 3.57505e-02
I0211 20:37:07.165680 22509476222784 run_lib.py:146] step: 449700, eval_loss: 4.48141e-02
I0211 20:37:25.677061 22509476222784 run_lib.py:133] step: 449750, training_loss: 4.04345e-02
I0211 20:37:44.151918 22509476222784 run_lib.py:133] step: 449800, training_loss: 3.36485e-02
I0211 20:37:44.332548 22509476222784 run_lib.py:146] step: 449800, eval_loss: 3.72586e-02
I0211 20:38:02.888142 22509476222784 run_lib.py:133] step: 449850, training_loss: 4.53914e-02
I0211 20:38:21.567317 22509476222784 run_lib.py:133] step: 449900, training_loss: 4.16763e-02
I0211 20:38:21.731727 22509476222784 run_lib.py:146] step: 449900, eval_loss: 4.10242e-02
I0211 20:38:40.247910 22509476222784 run_lib.py:133] step: 449950, training_loss: 4.76110e-02
I0211 20:38:58.796355 22509476222784 run_lib.py:133] step: 450000, training_loss: 3.13057e-02
I0211 20:38:59.567290 22509476222784 run_lib.py:146] step: 450000, eval_loss: 4.57657e-02
I0211 20:39:20.852056 22509476222784 run_lib.py:133] step: 450050, training_loss: 3.41099e-02
I0211 20:39:39.459838 22509476222784 run_lib.py:133] step: 450100, training_loss: 3.54787e-02
I0211 20:39:39.622898 22509476222784 run_lib.py:146] step: 450100, eval_loss: 4.17014e-02
I0211 20:39:58.334932 22509476222784 run_lib.py:133] step: 450150, training_loss: 4.39938e-02
I0211 20:40:16.834746 22509476222784 run_lib.py:133] step: 450200, training_loss: 4.86529e-02
I0211 20:40:16.996604 22509476222784 run_lib.py:146] step: 450200, eval_loss: 4.78849e-02
I0211 20:40:35.489188 22509476222784 run_lib.py:133] step: 450250, training_loss: 3.92793e-02
I0211 20:40:53.839693 22509476222784 run_lib.py:133] step: 450300, training_loss: 3.10843e-02
I0211 20:40:54.015638 22509476222784 run_lib.py:146] step: 450300, eval_loss: 4.38566e-02
I0211 20:41:12.583388 22509476222784 run_lib.py:133] step: 450350, training_loss: 5.27109e-02
I0211 20:41:31.160337 22509476222784 run_lib.py:133] step: 450400, training_loss: 4.92751e-02
I0211 20:41:31.324727 22509476222784 run_lib.py:146] step: 450400, eval_loss: 4.28789e-02
I0211 20:41:49.991782 22509476222784 run_lib.py:133] step: 450450, training_loss: 4.06215e-02
I0211 20:42:08.551287 22509476222784 run_lib.py:133] step: 450500, training_loss: 4.05095e-02
I0211 20:42:08.714751 22509476222784 run_lib.py:146] step: 450500, eval_loss: 4.34783e-02
I0211 20:42:27.237277 22509476222784 run_lib.py:133] step: 450550, training_loss: 3.70763e-02
I0211 20:42:45.792595 22509476222784 run_lib.py:133] step: 450600, training_loss: 3.76859e-02
I0211 20:42:45.953403 22509476222784 run_lib.py:146] step: 450600, eval_loss: 3.57878e-02
I0211 20:43:04.635650 22509476222784 run_lib.py:133] step: 450650, training_loss: 4.14078e-02
I0211 20:43:23.126329 22509476222784 run_lib.py:133] step: 450700, training_loss: 4.12076e-02
I0211 20:43:23.287631 22509476222784 run_lib.py:146] step: 450700, eval_loss: 4.56312e-02
I0211 20:43:41.946336 22509476222784 run_lib.py:133] step: 450750, training_loss: 4.95746e-02
I0211 20:44:00.487836 22509476222784 run_lib.py:133] step: 450800, training_loss: 4.52765e-02
I0211 20:44:00.654753 22509476222784 run_lib.py:146] step: 450800, eval_loss: 4.64847e-02
I0211 20:44:19.300443 22509476222784 run_lib.py:133] step: 450850, training_loss: 4.71558e-02
I0211 20:44:37.879628 22509476222784 run_lib.py:133] step: 450900, training_loss: 4.20583e-02
I0211 20:44:38.061670 22509476222784 run_lib.py:146] step: 450900, eval_loss: 2.99047e-02
I0211 20:44:56.604006 22509476222784 run_lib.py:133] step: 450950, training_loss: 4.16428e-02
I0211 20:45:15.312850 22509476222784 run_lib.py:133] step: 451000, training_loss: 4.68699e-02
I0211 20:45:15.477754 22509476222784 run_lib.py:146] step: 451000, eval_loss: 4.90440e-02
I0211 20:45:34.008851 22509476222784 run_lib.py:133] step: 451050, training_loss: 4.51098e-02
I0211 20:45:52.720611 22509476222784 run_lib.py:133] step: 451100, training_loss: 3.85972e-02
I0211 20:45:52.883672 22509476222784 run_lib.py:146] step: 451100, eval_loss: 3.26735e-02
I0211 20:46:11.411839 22509476222784 run_lib.py:133] step: 451150, training_loss: 4.60256e-02
I0211 20:46:29.981325 22509476222784 run_lib.py:133] step: 451200, training_loss: 4.81715e-02
I0211 20:46:30.156912 22509476222784 run_lib.py:146] step: 451200, eval_loss: 3.28203e-02
I0211 20:46:48.887232 22509476222784 run_lib.py:133] step: 451250, training_loss: 3.67640e-02
I0211 20:47:07.445441 22509476222784 run_lib.py:133] step: 451300, training_loss: 3.74768e-02
I0211 20:47:07.611067 22509476222784 run_lib.py:146] step: 451300, eval_loss: 4.07451e-02
I0211 20:47:26.116205 22509476222784 run_lib.py:133] step: 451350, training_loss: 4.10325e-02
I0211 20:47:44.791827 22509476222784 run_lib.py:133] step: 451400, training_loss: 4.76692e-02
I0211 20:47:44.982493 22509476222784 run_lib.py:146] step: 451400, eval_loss: 4.51295e-02
I0211 20:48:03.464198 22509476222784 run_lib.py:133] step: 451450, training_loss: 4.00473e-02
I0211 20:48:21.959366 22509476222784 run_lib.py:133] step: 451500, training_loss: 4.26032e-02
I0211 20:48:22.312865 22509476222784 run_lib.py:146] step: 451500, eval_loss: 5.37937e-02
I0211 20:48:40.868788 22509476222784 run_lib.py:133] step: 451550, training_loss: 4.75198e-02
I0211 20:48:59.358239 22509476222784 run_lib.py:133] step: 451600, training_loss: 3.66958e-02
I0211 20:48:59.518699 22509476222784 run_lib.py:146] step: 451600, eval_loss: 3.31223e-02
I0211 20:49:18.009277 22509476222784 run_lib.py:133] step: 451650, training_loss: 3.74346e-02
I0211 20:49:36.447951 22509476222784 run_lib.py:133] step: 451700, training_loss: 4.60739e-02
I0211 20:49:36.615808 22509476222784 run_lib.py:146] step: 451700, eval_loss: 5.55468e-02
I0211 20:49:55.372033 22509476222784 run_lib.py:133] step: 451750, training_loss: 3.35805e-02
I0211 20:50:14.060034 22509476222784 run_lib.py:133] step: 451800, training_loss: 5.54252e-02
I0211 20:50:14.225551 22509476222784 run_lib.py:146] step: 451800, eval_loss: 5.16129e-02
I0211 20:50:32.702874 22509476222784 run_lib.py:133] step: 451850, training_loss: 4.78337e-02
I0211 20:50:51.222341 22509476222784 run_lib.py:133] step: 451900, training_loss: 4.14251e-02
I0211 20:50:51.383663 22509476222784 run_lib.py:146] step: 451900, eval_loss: 5.01421e-02
I0211 20:51:10.033211 22509476222784 run_lib.py:133] step: 451950, training_loss: 4.03506e-02
I0211 20:51:28.583014 22509476222784 run_lib.py:133] step: 452000, training_loss: 4.64212e-02
I0211 20:51:28.748046 22509476222784 run_lib.py:146] step: 452000, eval_loss: 7.15265e-02
I0211 20:51:47.259080 22509476222784 run_lib.py:133] step: 452050, training_loss: 4.37877e-02
I0211 20:52:05.739059 22509476222784 run_lib.py:133] step: 452100, training_loss: 5.18145e-02
I0211 20:52:05.913663 22509476222784 run_lib.py:146] step: 452100, eval_loss: 4.30766e-02
I0211 20:52:24.629078 22509476222784 run_lib.py:133] step: 452150, training_loss: 4.78104e-02
I0211 20:52:43.130270 22509476222784 run_lib.py:133] step: 452200, training_loss: 5.01370e-02
I0211 20:52:43.294772 22509476222784 run_lib.py:146] step: 452200, eval_loss: 3.43418e-02
I0211 20:53:01.949704 22509476222784 run_lib.py:133] step: 452250, training_loss: 4.18446e-02
I0211 20:53:20.555284 22509476222784 run_lib.py:133] step: 452300, training_loss: 4.00394e-02
I0211 20:53:20.719678 22509476222784 run_lib.py:146] step: 452300, eval_loss: 4.24094e-02
I0211 20:53:39.438753 22509476222784 run_lib.py:133] step: 452350, training_loss: 3.52429e-02
I0211 20:53:57.896264 22509476222784 run_lib.py:133] step: 452400, training_loss: 3.50361e-02
I0211 20:53:58.059319 22509476222784 run_lib.py:146] step: 452400, eval_loss: 3.43866e-02
I0211 20:54:16.484556 22509476222784 run_lib.py:133] step: 452450, training_loss: 3.97747e-02
I0211 20:54:35.131819 22509476222784 run_lib.py:133] step: 452500, training_loss: 3.19798e-02
I0211 20:54:35.324400 22509476222784 run_lib.py:146] step: 452500, eval_loss: 4.52674e-02
I0211 20:54:53.887957 22509476222784 run_lib.py:133] step: 452550, training_loss: 4.38584e-02
I0211 20:55:12.611706 22509476222784 run_lib.py:133] step: 452600, training_loss: 4.78707e-02
I0211 20:55:12.778774 22509476222784 run_lib.py:146] step: 452600, eval_loss: 4.53344e-02
I0211 20:55:31.302108 22509476222784 run_lib.py:133] step: 452650, training_loss: 4.83930e-02
I0211 20:55:49.794804 22509476222784 run_lib.py:133] step: 452700, training_loss: 4.43079e-02
I0211 20:55:49.969893 22509476222784 run_lib.py:146] step: 452700, eval_loss: 3.61851e-02
I0211 20:56:08.423199 22509476222784 run_lib.py:133] step: 452750, training_loss: 3.25164e-02
I0211 20:56:27.010687 22509476222784 run_lib.py:133] step: 452800, training_loss: 3.57396e-02
I0211 20:56:27.185575 22509476222784 run_lib.py:146] step: 452800, eval_loss: 4.31560e-02
I0211 20:56:45.710651 22509476222784 run_lib.py:133] step: 452850, training_loss: 4.19987e-02
I0211 20:57:04.266577 22509476222784 run_lib.py:133] step: 452900, training_loss: 5.39200e-02
I0211 20:57:04.430526 22509476222784 run_lib.py:146] step: 452900, eval_loss: 5.63593e-02
I0211 20:57:23.115917 22509476222784 run_lib.py:133] step: 452950, training_loss: 4.63110e-02
I0211 20:57:41.604402 22509476222784 run_lib.py:133] step: 453000, training_loss: 2.97154e-02
I0211 20:57:41.764338 22509476222784 run_lib.py:146] step: 453000, eval_loss: 4.80651e-02
I0211 20:58:00.328222 22509476222784 run_lib.py:133] step: 453050, training_loss: 3.90823e-02
I0211 20:58:18.805410 22509476222784 run_lib.py:133] step: 453100, training_loss: 3.95439e-02
I0211 20:58:18.979784 22509476222784 run_lib.py:146] step: 453100, eval_loss: 4.43014e-02
I0211 20:58:37.453013 22509476222784 run_lib.py:133] step: 453150, training_loss: 4.37642e-02
I0211 20:58:55.892131 22509476222784 run_lib.py:133] step: 453200, training_loss: 3.77819e-02
I0211 20:58:56.055628 22509476222784 run_lib.py:146] step: 453200, eval_loss: 3.13660e-02
I0211 20:59:14.712237 22509476222784 run_lib.py:133] step: 453250, training_loss: 3.89060e-02
I0211 20:59:33.285037 22509476222784 run_lib.py:133] step: 453300, training_loss: 3.43900e-02
I0211 20:59:33.449610 22509476222784 run_lib.py:146] step: 453300, eval_loss: 4.10878e-02
I0211 20:59:51.887422 22509476222784 run_lib.py:133] step: 453350, training_loss: 4.34015e-02
I0211 21:00:10.365364 22509476222784 run_lib.py:133] step: 453400, training_loss: 4.10742e-02
I0211 21:00:10.537510 22509476222784 run_lib.py:146] step: 453400, eval_loss: 3.26785e-02
I0211 21:00:29.213624 22509476222784 run_lib.py:133] step: 453450, training_loss: 4.38462e-02
I0211 21:00:47.646347 22509476222784 run_lib.py:133] step: 453500, training_loss: 4.54021e-02
I0211 21:00:47.806546 22509476222784 run_lib.py:146] step: 453500, eval_loss: 4.32033e-02
I0211 21:01:06.503074 22509476222784 run_lib.py:133] step: 453550, training_loss: 4.67369e-02
I0211 21:01:25.043716 22509476222784 run_lib.py:133] step: 453600, training_loss: 4.18205e-02
I0211 21:01:25.205955 22509476222784 run_lib.py:146] step: 453600, eval_loss: 4.95525e-02
I0211 21:01:43.796551 22509476222784 run_lib.py:133] step: 453650, training_loss: 3.61587e-02
I0211 21:02:02.346373 22509476222784 run_lib.py:133] step: 453700, training_loss: 3.68323e-02
I0211 21:02:02.521675 22509476222784 run_lib.py:146] step: 453700, eval_loss: 4.50128e-02
I0211 21:02:21.204265 22509476222784 run_lib.py:133] step: 453750, training_loss: 5.27961e-02
I0211 21:02:39.729890 22509476222784 run_lib.py:133] step: 453800, training_loss: 4.74000e-02
I0211 21:02:39.922913 22509476222784 run_lib.py:146] step: 453800, eval_loss: 5.61266e-02
I0211 21:02:58.423826 22509476222784 run_lib.py:133] step: 453850, training_loss: 4.14346e-02
I0211 21:03:17.061686 22509476222784 run_lib.py:133] step: 453900, training_loss: 4.53771e-02
I0211 21:03:17.224491 22509476222784 run_lib.py:146] step: 453900, eval_loss: 3.79379e-02
I0211 21:03:35.720821 22509476222784 run_lib.py:133] step: 453950, training_loss: 4.63910e-02
I0211 21:03:54.267430 22509476222784 run_lib.py:133] step: 454000, training_loss: 5.06566e-02
I0211 21:03:54.434959 22509476222784 run_lib.py:146] step: 454000, eval_loss: 5.03657e-02
I0211 21:04:13.188623 22509476222784 run_lib.py:133] step: 454050, training_loss: 5.21964e-02
I0211 21:04:31.847518 22509476222784 run_lib.py:133] step: 454100, training_loss: 4.22685e-02
I0211 21:04:32.013535 22509476222784 run_lib.py:146] step: 454100, eval_loss: 3.56162e-02
I0211 21:04:50.475626 22509476222784 run_lib.py:133] step: 454150, training_loss: 5.03360e-02
I0211 21:05:08.937639 22509476222784 run_lib.py:133] step: 454200, training_loss: 4.95193e-02
I0211 21:05:09.103678 22509476222784 run_lib.py:146] step: 454200, eval_loss: 5.82000e-02
I0211 21:05:27.598348 22509476222784 run_lib.py:133] step: 454250, training_loss: 3.69908e-02
I0211 21:05:46.338199 22509476222784 run_lib.py:133] step: 454300, training_loss: 4.98759e-02
I0211 21:05:46.520069 22509476222784 run_lib.py:146] step: 454300, eval_loss: 4.65794e-02
I0211 21:06:05.046870 22509476222784 run_lib.py:133] step: 454350, training_loss: 3.57620e-02
I0211 21:06:23.480477 22509476222784 run_lib.py:133] step: 454400, training_loss: 4.21389e-02
I0211 21:06:23.640221 22509476222784 run_lib.py:146] step: 454400, eval_loss: 4.15414e-02
I0211 21:06:42.039715 22509476222784 run_lib.py:133] step: 454450, training_loss: 3.96501e-02
I0211 21:07:00.647321 22509476222784 run_lib.py:133] step: 454500, training_loss: 3.38384e-02
I0211 21:07:00.816801 22509476222784 run_lib.py:146] step: 454500, eval_loss: 4.79765e-02
I0211 21:07:19.379401 22509476222784 run_lib.py:133] step: 454550, training_loss: 4.28312e-02
I0211 21:07:37.976846 22509476222784 run_lib.py:133] step: 454600, training_loss: 5.10175e-02
I0211 21:07:38.143664 22509476222784 run_lib.py:146] step: 454600, eval_loss: 5.03137e-02
I0211 21:07:56.618909 22509476222784 run_lib.py:133] step: 454650, training_loss: 3.89343e-02
I0211 21:08:15.100128 22509476222784 run_lib.py:133] step: 454700, training_loss: 3.96277e-02
I0211 21:08:15.263689 22509476222784 run_lib.py:146] step: 454700, eval_loss: 3.63469e-02
I0211 21:08:33.893466 22509476222784 run_lib.py:133] step: 454750, training_loss: 4.48185e-02
I0211 21:08:52.472728 22509476222784 run_lib.py:133] step: 454800, training_loss: 3.60447e-02
I0211 21:08:52.683148 22509476222784 run_lib.py:146] step: 454800, eval_loss: 4.55855e-02
I0211 21:09:11.261011 22509476222784 run_lib.py:133] step: 454850, training_loss: 4.03061e-02
I0211 21:09:29.753615 22509476222784 run_lib.py:133] step: 454900, training_loss: 4.34950e-02
I0211 21:09:29.949745 22509476222784 run_lib.py:146] step: 454900, eval_loss: 4.70641e-02
I0211 21:09:48.625886 22509476222784 run_lib.py:133] step: 454950, training_loss: 4.77847e-02
I0211 21:10:07.090635 22509476222784 run_lib.py:133] step: 455000, training_loss: 4.40374e-02
I0211 21:10:07.307494 22509476222784 run_lib.py:146] step: 455000, eval_loss: 4.09016e-02
I0211 21:10:25.899376 22509476222784 run_lib.py:133] step: 455050, training_loss: 3.95016e-02
I0211 21:10:44.417434 22509476222784 run_lib.py:133] step: 455100, training_loss: 3.77679e-02
I0211 21:10:44.599650 22509476222784 run_lib.py:146] step: 455100, eval_loss: 5.08871e-02
I0211 21:11:03.324926 22509476222784 run_lib.py:133] step: 455150, training_loss: 5.09309e-02
I0211 21:11:21.864241 22509476222784 run_lib.py:133] step: 455200, training_loss: 3.76776e-02
I0211 21:11:22.028818 22509476222784 run_lib.py:146] step: 455200, eval_loss: 4.14176e-02
I0211 21:11:40.527995 22509476222784 run_lib.py:133] step: 455250, training_loss: 4.96427e-02
I0211 21:11:59.127596 22509476222784 run_lib.py:133] step: 455300, training_loss: 4.98378e-02
I0211 21:11:59.307742 22509476222784 run_lib.py:146] step: 455300, eval_loss: 4.41847e-02
I0211 21:12:17.778929 22509476222784 run_lib.py:133] step: 455350, training_loss: 4.62482e-02
I0211 21:12:36.300534 22509476222784 run_lib.py:133] step: 455400, training_loss: 5.40604e-02
I0211 21:12:36.463803 22509476222784 run_lib.py:146] step: 455400, eval_loss: 4.20202e-02
I0211 21:12:54.975347 22509476222784 run_lib.py:133] step: 455450, training_loss: 3.75602e-02
I0211 21:13:13.470578 22509476222784 run_lib.py:133] step: 455500, training_loss: 3.62926e-02
I0211 21:13:13.634432 22509476222784 run_lib.py:146] step: 455500, eval_loss: 4.19967e-02
I0211 21:13:32.279885 22509476222784 run_lib.py:133] step: 455550, training_loss: 4.12984e-02
I0211 21:13:50.760146 22509476222784 run_lib.py:133] step: 455600, training_loss: 4.99771e-02
I0211 21:13:50.926759 22509476222784 run_lib.py:146] step: 455600, eval_loss: 3.54853e-02
I0211 21:14:09.415760 22509476222784 run_lib.py:133] step: 455650, training_loss: 4.15202e-02
I0211 21:14:28.101476 22509476222784 run_lib.py:133] step: 455700, training_loss: 4.37837e-02
I0211 21:14:28.283936 22509476222784 run_lib.py:146] step: 455700, eval_loss: 4.26792e-02
I0211 21:14:46.815385 22509476222784 run_lib.py:133] step: 455750, training_loss: 3.39067e-02
I0211 21:15:05.290391 22509476222784 run_lib.py:133] step: 455800, training_loss: 3.40603e-02
I0211 21:15:05.463624 22509476222784 run_lib.py:146] step: 455800, eval_loss: 4.16641e-02
I0211 21:15:24.117089 22509476222784 run_lib.py:133] step: 455850, training_loss: 6.14844e-02
I0211 21:15:42.609923 22509476222784 run_lib.py:133] step: 455900, training_loss: 4.52459e-02
I0211 21:15:42.770551 22509476222784 run_lib.py:146] step: 455900, eval_loss: 4.57194e-02
I0211 21:16:01.244133 22509476222784 run_lib.py:133] step: 455950, training_loss: 3.12456e-02
I0211 21:16:19.775008 22509476222784 run_lib.py:133] step: 456000, training_loss: 5.21955e-02
I0211 21:16:19.968485 22509476222784 run_lib.py:146] step: 456000, eval_loss: 4.80552e-02
I0211 21:16:38.616375 22509476222784 run_lib.py:133] step: 456050, training_loss: 3.84585e-02
I0211 21:16:57.219670 22509476222784 run_lib.py:133] step: 456100, training_loss: 3.97442e-02
I0211 21:16:57.420828 22509476222784 run_lib.py:146] step: 456100, eval_loss: 4.30488e-02
I0211 21:17:15.948776 22509476222784 run_lib.py:133] step: 456150, training_loss: 4.31985e-02
I0211 21:17:34.399851 22509476222784 run_lib.py:133] step: 456200, training_loss: 4.71181e-02
I0211 21:17:34.565889 22509476222784 run_lib.py:146] step: 456200, eval_loss: 4.37410e-02
I0211 21:17:53.186791 22509476222784 run_lib.py:133] step: 456250, training_loss: 3.30100e-02
I0211 21:18:11.750939 22509476222784 run_lib.py:133] step: 456300, training_loss: 5.56809e-02
I0211 21:18:11.919769 22509476222784 run_lib.py:146] step: 456300, eval_loss: 5.32006e-02
I0211 21:18:30.545919 22509476222784 run_lib.py:133] step: 456350, training_loss: 4.60878e-02
I0211 21:18:48.977255 22509476222784 run_lib.py:133] step: 456400, training_loss: 4.61873e-02
I0211 21:18:49.139763 22509476222784 run_lib.py:146] step: 456400, eval_loss: 4.59070e-02
I0211 21:19:07.776767 22509476222784 run_lib.py:133] step: 456450, training_loss: 4.21394e-02
I0211 21:19:26.260899 22509476222784 run_lib.py:133] step: 456500, training_loss: 4.27213e-02
I0211 21:19:26.441590 22509476222784 run_lib.py:146] step: 456500, eval_loss: 3.93530e-02
I0211 21:19:45.152400 22509476222784 run_lib.py:133] step: 456550, training_loss: 3.85052e-02
I0211 21:20:03.718633 22509476222784 run_lib.py:133] step: 456600, training_loss: 4.46366e-02
I0211 21:20:03.884768 22509476222784 run_lib.py:146] step: 456600, eval_loss: 3.51029e-02
I0211 21:20:22.402932 22509476222784 run_lib.py:133] step: 456650, training_loss: 2.94258e-02
I0211 21:20:41.007085 22509476222784 run_lib.py:133] step: 456700, training_loss: 5.57877e-02
I0211 21:20:41.173318 22509476222784 run_lib.py:146] step: 456700, eval_loss: 3.85820e-02
I0211 21:20:59.671345 22509476222784 run_lib.py:133] step: 456750, training_loss: 4.60910e-02
I0211 21:21:18.228244 22509476222784 run_lib.py:133] step: 456800, training_loss: 5.17007e-02
I0211 21:21:18.447888 22509476222784 run_lib.py:146] step: 456800, eval_loss: 4.69358e-02
I0211 21:21:37.184560 22509476222784 run_lib.py:133] step: 456850, training_loss: 4.52980e-02
I0211 21:21:55.700119 22509476222784 run_lib.py:133] step: 456900, training_loss: 5.62033e-02
I0211 21:21:55.870756 22509476222784 run_lib.py:146] step: 456900, eval_loss: 4.26129e-02
I0211 21:22:14.539152 22509476222784 run_lib.py:133] step: 456950, training_loss: 3.77200e-02
I0211 21:22:32.982595 22509476222784 run_lib.py:133] step: 457000, training_loss: 4.34487e-02
I0211 21:22:33.146929 22509476222784 run_lib.py:146] step: 457000, eval_loss: 2.97771e-02
I0211 21:22:51.634449 22509476222784 run_lib.py:133] step: 457050, training_loss: 5.13938e-02
I0211 21:23:10.343979 22509476222784 run_lib.py:133] step: 457100, training_loss: 3.10928e-02
I0211 21:23:10.531799 22509476222784 run_lib.py:146] step: 457100, eval_loss: 3.12493e-02
I0211 21:23:29.040590 22509476222784 run_lib.py:133] step: 457150, training_loss: 3.45849e-02
I0211 21:23:47.525248 22509476222784 run_lib.py:133] step: 457200, training_loss: 3.88326e-02
I0211 21:23:47.708440 22509476222784 run_lib.py:146] step: 457200, eval_loss: 4.77902e-02
I0211 21:24:06.155280 22509476222784 run_lib.py:133] step: 457250, training_loss: 4.75282e-02
I0211 21:24:24.789391 22509476222784 run_lib.py:133] step: 457300, training_loss: 4.90493e-02
I0211 21:24:24.950430 22509476222784 run_lib.py:146] step: 457300, eval_loss: 3.73196e-02
I0211 21:24:43.438759 22509476222784 run_lib.py:133] step: 457350, training_loss: 4.24839e-02
I0211 21:25:01.969346 22509476222784 run_lib.py:133] step: 457400, training_loss: 3.97356e-02
I0211 21:25:02.141560 22509476222784 run_lib.py:146] step: 457400, eval_loss: 4.69436e-02
I0211 21:25:20.648716 22509476222784 run_lib.py:133] step: 457450, training_loss: 3.48667e-02
I0211 21:25:39.162067 22509476222784 run_lib.py:133] step: 457500, training_loss: 5.01869e-02
I0211 21:25:39.327966 22509476222784 run_lib.py:146] step: 457500, eval_loss: 3.25205e-02
I0211 21:25:58.030088 22509476222784 run_lib.py:133] step: 457550, training_loss: 3.20990e-02
I0211 21:26:16.528031 22509476222784 run_lib.py:133] step: 457600, training_loss: 2.87113e-02
I0211 21:26:16.705590 22509476222784 run_lib.py:146] step: 457600, eval_loss: 4.42121e-02
I0211 21:26:35.065634 22509476222784 run_lib.py:133] step: 457650, training_loss: 3.96666e-02
I0211 21:26:53.640695 22509476222784 run_lib.py:133] step: 457700, training_loss: 4.84132e-02
I0211 21:26:53.812670 22509476222784 run_lib.py:146] step: 457700, eval_loss: 3.06671e-02
I0211 21:27:12.513812 22509476222784 run_lib.py:133] step: 457750, training_loss: 4.58174e-02
I0211 21:27:31.042491 22509476222784 run_lib.py:133] step: 457800, training_loss: 4.62395e-02
I0211 21:27:31.231638 22509476222784 run_lib.py:146] step: 457800, eval_loss: 4.06035e-02
I0211 21:27:49.829007 22509476222784 run_lib.py:133] step: 457850, training_loss: 4.68460e-02
I0211 21:28:08.328478 22509476222784 run_lib.py:133] step: 457900, training_loss: 4.17204e-02
I0211 21:28:08.535545 22509476222784 run_lib.py:146] step: 457900, eval_loss: 5.04112e-02
I0211 21:28:27.264569 22509476222784 run_lib.py:133] step: 457950, training_loss: 3.74917e-02
I0211 21:28:45.789907 22509476222784 run_lib.py:133] step: 458000, training_loss: 4.21277e-02
I0211 21:28:45.953813 22509476222784 run_lib.py:146] step: 458000, eval_loss: 4.27832e-02
I0211 21:29:04.463689 22509476222784 run_lib.py:133] step: 458050, training_loss: 4.27236e-02
I0211 21:29:23.086299 22509476222784 run_lib.py:133] step: 458100, training_loss: 3.84599e-02
I0211 21:29:23.250410 22509476222784 run_lib.py:146] step: 458100, eval_loss: 4.11398e-02
I0211 21:29:41.764683 22509476222784 run_lib.py:133] step: 458150, training_loss: 3.79753e-02
I0211 21:30:00.445214 22509476222784 run_lib.py:133] step: 458200, training_loss: 3.64108e-02
I0211 21:30:00.608449 22509476222784 run_lib.py:146] step: 458200, eval_loss: 3.59892e-02
I0211 21:30:19.143263 22509476222784 run_lib.py:133] step: 458250, training_loss: 5.37479e-02
I0211 21:30:37.587758 22509476222784 run_lib.py:133] step: 458300, training_loss: 5.17897e-02
I0211 21:30:37.749491 22509476222784 run_lib.py:146] step: 458300, eval_loss: 4.21404e-02
I0211 21:30:56.430287 22509476222784 run_lib.py:133] step: 458350, training_loss: 4.89056e-02
I0211 21:31:15.000269 22509476222784 run_lib.py:133] step: 458400, training_loss: 4.67289e-02
I0211 21:31:15.164876 22509476222784 run_lib.py:146] step: 458400, eval_loss: 3.86936e-02
I0211 21:31:33.654961 22509476222784 run_lib.py:133] step: 458450, training_loss: 5.30716e-02
I0211 21:31:52.368317 22509476222784 run_lib.py:133] step: 458500, training_loss: 4.86618e-02
I0211 21:31:52.534925 22509476222784 run_lib.py:146] step: 458500, eval_loss: 3.28102e-02
I0211 21:32:11.044025 22509476222784 run_lib.py:133] step: 458550, training_loss: 5.80608e-02
I0211 21:32:29.552384 22509476222784 run_lib.py:133] step: 458600, training_loss: 4.43681e-02
I0211 21:32:29.902497 22509476222784 run_lib.py:146] step: 458600, eval_loss: 4.20401e-02
I0211 21:32:48.385918 22509476222784 run_lib.py:133] step: 458650, training_loss: 5.45481e-02
I0211 21:33:06.801062 22509476222784 run_lib.py:133] step: 458700, training_loss: 4.99445e-02
I0211 21:33:06.968827 22509476222784 run_lib.py:146] step: 458700, eval_loss: 3.62287e-02
I0211 21:33:25.575426 22509476222784 run_lib.py:133] step: 458750, training_loss: 5.31756e-02
I0211 21:33:44.062984 22509476222784 run_lib.py:133] step: 458800, training_loss: 4.48700e-02
I0211 21:33:44.254645 22509476222784 run_lib.py:146] step: 458800, eval_loss: 3.80513e-02
I0211 21:34:02.912866 22509476222784 run_lib.py:133] step: 458850, training_loss: 3.87218e-02
I0211 21:34:21.478328 22509476222784 run_lib.py:133] step: 458900, training_loss: 4.93975e-02
I0211 21:34:21.643897 22509476222784 run_lib.py:146] step: 458900, eval_loss: 3.31777e-02
I0211 21:34:40.130040 22509476222784 run_lib.py:133] step: 458950, training_loss: 4.61027e-02
I0211 21:34:58.687058 22509476222784 run_lib.py:133] step: 459000, training_loss: 5.08129e-02
I0211 21:34:58.901894 22509476222784 run_lib.py:146] step: 459000, eval_loss: 3.13969e-02
I0211 21:35:17.585133 22509476222784 run_lib.py:133] step: 459050, training_loss: 4.48322e-02
I0211 21:35:36.150215 22509476222784 run_lib.py:133] step: 459100, training_loss: 5.32904e-02
I0211 21:35:36.312618 22509476222784 run_lib.py:146] step: 459100, eval_loss: 5.02563e-02
I0211 21:35:54.836589 22509476222784 run_lib.py:133] step: 459150, training_loss: 4.31148e-02
I0211 21:36:13.391298 22509476222784 run_lib.py:133] step: 459200, training_loss: 4.98477e-02
I0211 21:36:13.571902 22509476222784 run_lib.py:146] step: 459200, eval_loss: 4.48020e-02
I0211 21:36:32.308631 22509476222784 run_lib.py:133] step: 459250, training_loss: 5.26974e-02
I0211 21:36:50.761275 22509476222784 run_lib.py:133] step: 459300, training_loss: 4.09193e-02
I0211 21:36:50.933493 22509476222784 run_lib.py:146] step: 459300, eval_loss: 3.98655e-02
I0211 21:37:09.541391 22509476222784 run_lib.py:133] step: 459350, training_loss: 3.80892e-02
I0211 21:37:28.044226 22509476222784 run_lib.py:133] step: 459400, training_loss: 4.35146e-02
I0211 21:37:28.208004 22509476222784 run_lib.py:146] step: 459400, eval_loss: 4.12702e-02
I0211 21:37:46.804042 22509476222784 run_lib.py:133] step: 459450, training_loss: 4.24377e-02
I0211 21:38:05.293219 22509476222784 run_lib.py:133] step: 459500, training_loss: 4.33239e-02
I0211 21:38:05.464566 22509476222784 run_lib.py:146] step: 459500, eval_loss: 5.54507e-02
I0211 21:38:24.011136 22509476222784 run_lib.py:133] step: 459550, training_loss: 2.82866e-02
I0211 21:38:42.690140 22509476222784 run_lib.py:133] step: 459600, training_loss: 5.13424e-02
I0211 21:38:42.854957 22509476222784 run_lib.py:146] step: 459600, eval_loss: 5.04173e-02
I0211 21:39:01.365593 22509476222784 run_lib.py:133] step: 459650, training_loss: 3.97822e-02
I0211 21:39:19.949763 22509476222784 run_lib.py:133] step: 459700, training_loss: 3.92436e-02
I0211 21:39:20.109514 22509476222784 run_lib.py:146] step: 459700, eval_loss: 4.65329e-02
I0211 21:39:38.584140 22509476222784 run_lib.py:133] step: 459750, training_loss: 4.48986e-02
I0211 21:39:57.142483 22509476222784 run_lib.py:133] step: 459800, training_loss: 3.86269e-02
I0211 21:39:57.325680 22509476222784 run_lib.py:146] step: 459800, eval_loss: 4.00577e-02
I0211 21:40:16.021489 22509476222784 run_lib.py:133] step: 459850, training_loss: 4.06431e-02
I0211 21:40:34.528212 22509476222784 run_lib.py:133] step: 459900, training_loss: 4.37884e-02
I0211 21:40:34.691843 22509476222784 run_lib.py:146] step: 459900, eval_loss: 3.37827e-02
I0211 21:40:53.214669 22509476222784 run_lib.py:133] step: 459950, training_loss: 4.25240e-02
I0211 21:41:11.773474 22509476222784 run_lib.py:133] step: 460000, training_loss: 4.75135e-02
I0211 21:41:12.506716 22509476222784 run_lib.py:146] step: 460000, eval_loss: 4.67320e-02
I0211 21:41:33.881372 22509476222784 run_lib.py:133] step: 460050, training_loss: 4.09318e-02
I0211 21:41:52.550618 22509476222784 run_lib.py:133] step: 460100, training_loss: 4.64146e-02
I0211 21:41:52.713722 22509476222784 run_lib.py:146] step: 460100, eval_loss: 3.94057e-02
I0211 21:42:11.110242 22509476222784 run_lib.py:133] step: 460150, training_loss: 4.74545e-02
I0211 21:42:29.567302 22509476222784 run_lib.py:133] step: 460200, training_loss: 2.77007e-02
I0211 21:42:29.771990 22509476222784 run_lib.py:146] step: 460200, eval_loss: 4.13257e-02
I0211 21:42:48.438271 22509476222784 run_lib.py:133] step: 460250, training_loss: 4.64985e-02
I0211 21:43:06.937681 22509476222784 run_lib.py:133] step: 460300, training_loss: 4.65941e-02
I0211 21:43:07.101568 22509476222784 run_lib.py:146] step: 460300, eval_loss: 3.70919e-02
I0211 21:43:25.572992 22509476222784 run_lib.py:133] step: 460350, training_loss: 4.38674e-02
I0211 21:43:44.230773 22509476222784 run_lib.py:133] step: 460400, training_loss: 4.39788e-02
I0211 21:43:44.467678 22509476222784 run_lib.py:146] step: 460400, eval_loss: 3.56081e-02
I0211 21:44:03.218360 22509476222784 run_lib.py:133] step: 460450, training_loss: 3.94631e-02
I0211 21:44:21.747920 22509476222784 run_lib.py:133] step: 460500, training_loss: 4.95430e-02
I0211 21:44:21.910905 22509476222784 run_lib.py:146] step: 460500, eval_loss: 4.38577e-02
I0211 21:44:40.459490 22509476222784 run_lib.py:133] step: 460550, training_loss: 4.18946e-02
I0211 21:44:58.925852 22509476222784 run_lib.py:133] step: 460600, training_loss: 3.93386e-02
I0211 21:44:59.131365 22509476222784 run_lib.py:146] step: 460600, eval_loss: 4.50371e-02
I0211 21:45:17.646096 22509476222784 run_lib.py:133] step: 460650, training_loss: 5.14330e-02
I0211 21:45:36.188019 22509476222784 run_lib.py:133] step: 460700, training_loss: 3.51676e-02
I0211 21:45:36.354788 22509476222784 run_lib.py:146] step: 460700, eval_loss: 4.21541e-02
I0211 21:45:55.082394 22509476222784 run_lib.py:133] step: 460750, training_loss: 3.52860e-02
I0211 21:46:13.594791 22509476222784 run_lib.py:133] step: 460800, training_loss: 4.68696e-02
I0211 21:46:13.769883 22509476222784 run_lib.py:146] step: 460800, eval_loss: 3.78874e-02
I0211 21:46:32.227164 22509476222784 run_lib.py:133] step: 460850, training_loss: 4.73641e-02
I0211 21:46:50.847195 22509476222784 run_lib.py:133] step: 460900, training_loss: 3.42196e-02
I0211 21:46:51.027553 22509476222784 run_lib.py:146] step: 460900, eval_loss: 4.66351e-02
I0211 21:47:09.691533 22509476222784 run_lib.py:133] step: 460950, training_loss: 4.86972e-02
I0211 21:47:28.161079 22509476222784 run_lib.py:133] step: 461000, training_loss: 4.15429e-02
I0211 21:47:28.326971 22509476222784 run_lib.py:146] step: 461000, eval_loss: 4.72439e-02
I0211 21:47:46.912824 22509476222784 run_lib.py:133] step: 461050, training_loss: 3.69291e-02
I0211 21:48:05.388334 22509476222784 run_lib.py:133] step: 461100, training_loss: 5.37810e-02
I0211 21:48:05.550574 22509476222784 run_lib.py:146] step: 461100, eval_loss: 4.51439e-02
I0211 21:48:24.221515 22509476222784 run_lib.py:133] step: 461150, training_loss: 3.53658e-02
I0211 21:48:42.750518 22509476222784 run_lib.py:133] step: 461200, training_loss: 3.87991e-02
I0211 21:48:42.930754 22509476222784 run_lib.py:146] step: 461200, eval_loss: 4.37187e-02
I0211 21:49:01.559859 22509476222784 run_lib.py:133] step: 461250, training_loss: 4.41961e-02
I0211 21:49:20.066862 22509476222784 run_lib.py:133] step: 461300, training_loss: 3.63539e-02
I0211 21:49:20.266760 22509476222784 run_lib.py:146] step: 461300, eval_loss: 4.64066e-02
I0211 21:49:38.730627 22509476222784 run_lib.py:133] step: 461350, training_loss: 3.80293e-02
I0211 21:49:57.375984 22509476222784 run_lib.py:133] step: 461400, training_loss: 4.13393e-02
I0211 21:49:57.550602 22509476222784 run_lib.py:146] step: 461400, eval_loss: 3.90670e-02
I0211 21:50:16.045191 22509476222784 run_lib.py:133] step: 461450, training_loss: 3.74481e-02
I0211 21:50:34.530616 22509476222784 run_lib.py:133] step: 461500, training_loss: 3.89395e-02
I0211 21:50:34.694764 22509476222784 run_lib.py:146] step: 461500, eval_loss: 4.56593e-02
I0211 21:50:53.413924 22509476222784 run_lib.py:133] step: 461550, training_loss: 2.57196e-02
I0211 21:51:11.893022 22509476222784 run_lib.py:133] step: 461600, training_loss: 4.37801e-02
I0211 21:51:12.054306 22509476222784 run_lib.py:146] step: 461600, eval_loss: 3.39054e-02
I0211 21:51:30.687252 22509476222784 run_lib.py:133] step: 461650, training_loss: 3.31159e-02
I0211 21:51:49.168750 22509476222784 run_lib.py:133] step: 461700, training_loss: 3.36679e-02
I0211 21:51:49.338908 22509476222784 run_lib.py:146] step: 461700, eval_loss: 4.15691e-02
I0211 21:52:07.820525 22509476222784 run_lib.py:133] step: 461750, training_loss: 3.61530e-02
I0211 21:52:26.489351 22509476222784 run_lib.py:133] step: 461800, training_loss: 4.31503e-02
I0211 21:52:26.654903 22509476222784 run_lib.py:146] step: 461800, eval_loss: 5.51914e-02
I0211 21:52:45.184583 22509476222784 run_lib.py:133] step: 461850, training_loss: 5.55992e-02
I0211 21:53:03.691311 22509476222784 run_lib.py:133] step: 461900, training_loss: 5.12505e-02
I0211 21:53:03.862852 22509476222784 run_lib.py:146] step: 461900, eval_loss: 4.86325e-02
I0211 21:53:22.361775 22509476222784 run_lib.py:133] step: 461950, training_loss: 4.74401e-02
I0211 21:53:41.082345 22509476222784 run_lib.py:133] step: 462000, training_loss: 4.17593e-02
I0211 21:53:41.275860 22509476222784 run_lib.py:146] step: 462000, eval_loss: 4.72031e-02
I0211 21:53:59.817514 22509476222784 run_lib.py:133] step: 462050, training_loss: 4.26278e-02
I0211 21:54:18.416800 22509476222784 run_lib.py:133] step: 462100, training_loss: 4.04945e-02
I0211 21:54:18.601666 22509476222784 run_lib.py:146] step: 462100, eval_loss: 3.67584e-02
I0211 21:54:37.108233 22509476222784 run_lib.py:133] step: 462150, training_loss: 4.51696e-02
I0211 21:54:55.558107 22509476222784 run_lib.py:133] step: 462200, training_loss: 3.58784e-02
I0211 21:54:55.729815 22509476222784 run_lib.py:146] step: 462200, eval_loss: 5.24269e-02
I0211 21:55:14.375016 22509476222784 run_lib.py:133] step: 462250, training_loss: 3.78230e-02
I0211 21:55:33.038587 22509476222784 run_lib.py:133] step: 462300, training_loss: 4.97480e-02
I0211 21:55:33.202513 22509476222784 run_lib.py:146] step: 462300, eval_loss: 4.60726e-02
I0211 21:55:51.632383 22509476222784 run_lib.py:133] step: 462350, training_loss: 3.97986e-02
I0211 21:56:10.144903 22509476222784 run_lib.py:133] step: 462400, training_loss: 3.81672e-02
I0211 21:56:10.321480 22509476222784 run_lib.py:146] step: 462400, eval_loss: 4.15024e-02
I0211 21:56:28.959507 22509476222784 run_lib.py:133] step: 462450, training_loss: 4.50655e-02
I0211 21:56:47.488015 22509476222784 run_lib.py:133] step: 462500, training_loss: 4.09926e-02
I0211 21:56:47.662899 22509476222784 run_lib.py:146] step: 462500, eval_loss: 3.23740e-02
I0211 21:57:06.348426 22509476222784 run_lib.py:133] step: 462550, training_loss: 4.68755e-02
I0211 21:57:24.894068 22509476222784 run_lib.py:133] step: 462600, training_loss: 4.04850e-02
I0211 21:57:25.060866 22509476222784 run_lib.py:146] step: 462600, eval_loss: 4.45597e-02
I0211 21:57:43.768988 22509476222784 run_lib.py:133] step: 462650, training_loss: 3.66219e-02
I0211 21:58:02.319945 22509476222784 run_lib.py:133] step: 462700, training_loss: 4.20938e-02
I0211 21:58:02.486103 22509476222784 run_lib.py:146] step: 462700, eval_loss: 3.67704e-02
I0211 21:58:20.952002 22509476222784 run_lib.py:133] step: 462750, training_loss: 4.36815e-02
I0211 21:58:39.664558 22509476222784 run_lib.py:133] step: 462800, training_loss: 3.74023e-02
I0211 21:58:39.834571 22509476222784 run_lib.py:146] step: 462800, eval_loss: 3.24074e-02
I0211 21:58:58.434941 22509476222784 run_lib.py:133] step: 462850, training_loss: 4.66903e-02
I0211 21:59:17.136879 22509476222784 run_lib.py:133] step: 462900, training_loss: 5.44328e-02
I0211 21:59:17.308877 22509476222784 run_lib.py:146] step: 462900, eval_loss: 4.97263e-02
I0211 21:59:35.820647 22509476222784 run_lib.py:133] step: 462950, training_loss: 4.63411e-02
I0211 21:59:54.315427 22509476222784 run_lib.py:133] step: 463000, training_loss: 4.40887e-02
I0211 21:59:54.475442 22509476222784 run_lib.py:146] step: 463000, eval_loss: 4.30654e-02
I0211 22:00:13.100207 22509476222784 run_lib.py:133] step: 463050, training_loss: 3.53975e-02
I0211 22:00:31.626969 22509476222784 run_lib.py:133] step: 463100, training_loss: 4.28534e-02
I0211 22:00:31.792876 22509476222784 run_lib.py:146] step: 463100, eval_loss: 4.55858e-02
I0211 22:00:50.320429 22509476222784 run_lib.py:133] step: 463150, training_loss: 4.04443e-02
I0211 22:01:09.058816 22509476222784 run_lib.py:133] step: 463200, training_loss: 3.98952e-02
I0211 22:01:09.233078 22509476222784 run_lib.py:146] step: 463200, eval_loss: 5.13232e-02
I0211 22:01:27.744102 22509476222784 run_lib.py:133] step: 463250, training_loss: 4.12568e-02
I0211 22:01:46.161891 22509476222784 run_lib.py:133] step: 463300, training_loss: 4.43764e-02
I0211 22:01:46.461491 22509476222784 run_lib.py:146] step: 463300, eval_loss: 6.06332e-02
I0211 22:02:04.897549 22509476222784 run_lib.py:133] step: 463350, training_loss: 4.94424e-02
I0211 22:02:23.449653 22509476222784 run_lib.py:133] step: 463400, training_loss: 3.92809e-02
I0211 22:02:23.617007 22509476222784 run_lib.py:146] step: 463400, eval_loss: 3.70177e-02
I0211 22:02:42.136675 22509476222784 run_lib.py:133] step: 463450, training_loss: 4.05616e-02
I0211 22:03:00.602471 22509476222784 run_lib.py:133] step: 463500, training_loss: 4.74357e-02
I0211 22:03:00.765536 22509476222784 run_lib.py:146] step: 463500, eval_loss: 3.66769e-02
I0211 22:03:19.435860 22509476222784 run_lib.py:133] step: 463550, training_loss: 4.16566e-02
I0211 22:03:38.009762 22509476222784 run_lib.py:133] step: 463600, training_loss: 4.04018e-02
I0211 22:03:38.179681 22509476222784 run_lib.py:146] step: 463600, eval_loss: 3.98926e-02
I0211 22:03:56.745542 22509476222784 run_lib.py:133] step: 463650, training_loss: 5.31921e-02
I0211 22:04:15.218744 22509476222784 run_lib.py:133] step: 463700, training_loss: 4.58751e-02
I0211 22:04:15.383660 22509476222784 run_lib.py:146] step: 463700, eval_loss: 6.77605e-02
I0211 22:04:33.971887 22509476222784 run_lib.py:133] step: 463750, training_loss: 4.46584e-02
I0211 22:04:52.519481 22509476222784 run_lib.py:133] step: 463800, training_loss: 3.90452e-02
I0211 22:04:52.683602 22509476222784 run_lib.py:146] step: 463800, eval_loss: 4.52439e-02
I0211 22:05:11.213905 22509476222784 run_lib.py:133] step: 463850, training_loss: 4.52880e-02
I0211 22:05:29.742690 22509476222784 run_lib.py:133] step: 463900, training_loss: 3.17509e-02
I0211 22:05:29.904021 22509476222784 run_lib.py:146] step: 463900, eval_loss: 4.00510e-02
I0211 22:05:48.637303 22509476222784 run_lib.py:133] step: 463950, training_loss: 3.76004e-02
I0211 22:06:07.083976 22509476222784 run_lib.py:133] step: 464000, training_loss: 4.17126e-02
I0211 22:06:07.252578 22509476222784 run_lib.py:146] step: 464000, eval_loss: 6.36572e-02
I0211 22:06:25.906192 22509476222784 run_lib.py:133] step: 464050, training_loss: 5.17071e-02
I0211 22:06:44.393329 22509476222784 run_lib.py:133] step: 464100, training_loss: 5.07612e-02
I0211 22:06:44.557624 22509476222784 run_lib.py:146] step: 464100, eval_loss: 4.71028e-02
I0211 22:07:03.221540 22509476222784 run_lib.py:133] step: 464150, training_loss: 4.65173e-02
I0211 22:07:21.757691 22509476222784 run_lib.py:133] step: 464200, training_loss: 5.61611e-02
I0211 22:07:21.955636 22509476222784 run_lib.py:146] step: 464200, eval_loss: 3.80216e-02
I0211 22:07:40.477237 22509476222784 run_lib.py:133] step: 464250, training_loss: 3.24185e-02
I0211 22:07:59.115909 22509476222784 run_lib.py:133] step: 464300, training_loss: 3.38218e-02
I0211 22:07:59.280889 22509476222784 run_lib.py:146] step: 464300, eval_loss: 3.10302e-02
I0211 22:08:17.794656 22509476222784 run_lib.py:133] step: 464350, training_loss: 4.36693e-02
I0211 22:08:36.293307 22509476222784 run_lib.py:133] step: 464400, training_loss: 5.22730e-02
I0211 22:08:36.455536 22509476222784 run_lib.py:146] step: 464400, eval_loss: 4.27497e-02
I0211 22:08:54.832879 22509476222784 run_lib.py:133] step: 464450, training_loss: 4.19090e-02
I0211 22:09:13.330722 22509476222784 run_lib.py:133] step: 464500, training_loss: 4.13367e-02
I0211 22:09:13.499736 22509476222784 run_lib.py:146] step: 464500, eval_loss: 4.90052e-02
I0211 22:09:32.219097 22509476222784 run_lib.py:133] step: 464550, training_loss: 5.17614e-02
I0211 22:09:50.747225 22509476222784 run_lib.py:133] step: 464600, training_loss: 5.37823e-02
I0211 22:09:51.157897 22509476222784 run_lib.py:146] step: 464600, eval_loss: 3.62655e-02
I0211 22:10:09.630477 22509476222784 run_lib.py:133] step: 464650, training_loss: 3.75778e-02
I0211 22:10:28.128843 22509476222784 run_lib.py:133] step: 464700, training_loss: 3.64551e-02
I0211 22:10:28.308607 22509476222784 run_lib.py:146] step: 464700, eval_loss: 4.57387e-02
I0211 22:10:47.007069 22509476222784 run_lib.py:133] step: 464750, training_loss: 4.93106e-02
I0211 22:11:05.558485 22509476222784 run_lib.py:133] step: 464800, training_loss: 4.32734e-02
I0211 22:11:05.725424 22509476222784 run_lib.py:146] step: 464800, eval_loss: 4.47632e-02
I0211 22:11:24.348789 22509476222784 run_lib.py:133] step: 464850, training_loss: 5.05200e-02
I0211 22:11:42.844538 22509476222784 run_lib.py:133] step: 464900, training_loss: 4.13059e-02
I0211 22:11:43.009404 22509476222784 run_lib.py:146] step: 464900, eval_loss: 3.68794e-02
I0211 22:12:01.521823 22509476222784 run_lib.py:133] step: 464950, training_loss: 5.10157e-02
I0211 22:12:20.125941 22509476222784 run_lib.py:133] step: 465000, training_loss: 3.91862e-02
I0211 22:12:20.294853 22509476222784 run_lib.py:146] step: 465000, eval_loss: 4.72859e-02
I0211 22:12:38.965548 22509476222784 run_lib.py:133] step: 465050, training_loss: 4.93900e-02
I0211 22:12:57.511972 22509476222784 run_lib.py:133] step: 465100, training_loss: 4.84653e-02
I0211 22:12:57.678911 22509476222784 run_lib.py:146] step: 465100, eval_loss: 4.37557e-02
I0211 22:13:16.120571 22509476222784 run_lib.py:133] step: 465150, training_loss: 3.36748e-02
I0211 22:13:34.568355 22509476222784 run_lib.py:133] step: 465200, training_loss: 4.96838e-02
I0211 22:13:34.732896 22509476222784 run_lib.py:146] step: 465200, eval_loss: 5.60715e-02
I0211 22:13:53.357881 22509476222784 run_lib.py:133] step: 465250, training_loss: 4.17846e-02
I0211 22:14:11.849587 22509476222784 run_lib.py:133] step: 465300, training_loss: 4.28407e-02
I0211 22:14:12.015382 22509476222784 run_lib.py:146] step: 465300, eval_loss: 3.72010e-02
I0211 22:14:30.695085 22509476222784 run_lib.py:133] step: 465350, training_loss: 4.10485e-02
I0211 22:14:49.161760 22509476222784 run_lib.py:133] step: 465400, training_loss: 3.80279e-02
I0211 22:14:49.320213 22509476222784 run_lib.py:146] step: 465400, eval_loss: 3.01693e-02
I0211 22:15:07.937113 22509476222784 run_lib.py:133] step: 465450, training_loss: 3.37713e-02
I0211 22:15:26.417317 22509476222784 run_lib.py:133] step: 465500, training_loss: 5.09429e-02
I0211 22:15:26.590870 22509476222784 run_lib.py:146] step: 465500, eval_loss: 3.83585e-02
I0211 22:15:45.307217 22509476222784 run_lib.py:133] step: 465550, training_loss: 3.67050e-02
I0211 22:16:03.892712 22509476222784 run_lib.py:133] step: 465600, training_loss: 4.27111e-02
I0211 22:16:04.060807 22509476222784 run_lib.py:146] step: 465600, eval_loss: 4.54548e-02
I0211 22:16:22.563052 22509476222784 run_lib.py:133] step: 465650, training_loss: 3.84122e-02
I0211 22:16:41.192211 22509476222784 run_lib.py:133] step: 465700, training_loss: 4.98268e-02
I0211 22:16:41.356635 22509476222784 run_lib.py:146] step: 465700, eval_loss: 4.05844e-02
I0211 22:16:59.858469 22509476222784 run_lib.py:133] step: 465750, training_loss: 2.92816e-02
I0211 22:17:18.445206 22509476222784 run_lib.py:133] step: 465800, training_loss: 4.19599e-02
I0211 22:17:18.632896 22509476222784 run_lib.py:146] step: 465800, eval_loss: 5.82124e-02
I0211 22:17:37.337355 22509476222784 run_lib.py:133] step: 465850, training_loss: 4.86448e-02
I0211 22:17:56.020046 22509476222784 run_lib.py:133] step: 465900, training_loss: 3.64672e-02
I0211 22:17:56.180650 22509476222784 run_lib.py:146] step: 465900, eval_loss: 4.44055e-02
I0211 22:18:14.671160 22509476222784 run_lib.py:133] step: 465950, training_loss: 3.88920e-02
I0211 22:18:33.201124 22509476222784 run_lib.py:133] step: 466000, training_loss: 3.85490e-02
I0211 22:18:33.364846 22509476222784 run_lib.py:146] step: 466000, eval_loss: 4.71134e-02
I0211 22:18:51.903903 22509476222784 run_lib.py:133] step: 466050, training_loss: 4.11083e-02
I0211 22:19:10.641152 22509476222784 run_lib.py:133] step: 466100, training_loss: 5.18721e-02
I0211 22:19:10.814138 22509476222784 run_lib.py:146] step: 466100, eval_loss: 4.36118e-02
I0211 22:19:29.290828 22509476222784 run_lib.py:133] step: 466150, training_loss: 4.40769e-02
I0211 22:19:47.745560 22509476222784 run_lib.py:133] step: 466200, training_loss: 4.13313e-02
I0211 22:19:47.909686 22509476222784 run_lib.py:146] step: 466200, eval_loss: 5.48160e-02
I0211 22:20:06.386788 22509476222784 run_lib.py:133] step: 466250, training_loss: 3.81585e-02
I0211 22:20:25.111985 22509476222784 run_lib.py:133] step: 466300, training_loss: 5.35048e-02
I0211 22:20:25.273940 22509476222784 run_lib.py:146] step: 466300, eval_loss: 2.53043e-02
I0211 22:20:43.843178 22509476222784 run_lib.py:133] step: 466350, training_loss: 3.82872e-02
I0211 22:21:02.453855 22509476222784 run_lib.py:133] step: 466400, training_loss: 3.65797e-02
I0211 22:21:02.615695 22509476222784 run_lib.py:146] step: 466400, eval_loss: 3.48400e-02
I0211 22:21:21.109496 22509476222784 run_lib.py:133] step: 466450, training_loss: 4.08119e-02
I0211 22:21:39.606459 22509476222784 run_lib.py:133] step: 466500, training_loss: 4.84334e-02
I0211 22:21:39.771878 22509476222784 run_lib.py:146] step: 466500, eval_loss: 3.88879e-02
I0211 22:21:58.321504 22509476222784 run_lib.py:133] step: 466550, training_loss: 3.93223e-02
I0211 22:22:16.849712 22509476222784 run_lib.py:133] step: 466600, training_loss: 4.12598e-02
I0211 22:22:17.031627 22509476222784 run_lib.py:146] step: 466600, eval_loss: 6.13667e-02
I0211 22:22:35.548443 22509476222784 run_lib.py:133] step: 466650, training_loss: 5.00261e-02
I0211 22:22:54.108995 22509476222784 run_lib.py:133] step: 466700, training_loss: 4.83491e-02
I0211 22:22:54.271886 22509476222784 run_lib.py:146] step: 466700, eval_loss: 3.45813e-02
I0211 22:23:13.003949 22509476222784 run_lib.py:133] step: 466750, training_loss: 4.97847e-02
I0211 22:23:31.480436 22509476222784 run_lib.py:133] step: 466800, training_loss: 4.41637e-02
I0211 22:23:31.699710 22509476222784 run_lib.py:146] step: 466800, eval_loss: 3.65673e-02
I0211 22:23:50.350143 22509476222784 run_lib.py:133] step: 466850, training_loss: 4.76478e-02
I0211 22:24:08.858390 22509476222784 run_lib.py:133] step: 466900, training_loss: 4.47244e-02
I0211 22:24:09.028008 22509476222784 run_lib.py:146] step: 466900, eval_loss: 4.96101e-02
I0211 22:24:27.770622 22509476222784 run_lib.py:133] step: 466950, training_loss: 4.87419e-02
I0211 22:24:46.337331 22509476222784 run_lib.py:133] step: 467000, training_loss: 3.61589e-02
I0211 22:24:46.502577 22509476222784 run_lib.py:146] step: 467000, eval_loss: 4.04051e-02
I0211 22:25:05.000234 22509476222784 run_lib.py:133] step: 467050, training_loss: 3.74015e-02
I0211 22:25:23.628592 22509476222784 run_lib.py:133] step: 467100, training_loss: 3.87084e-02
I0211 22:25:23.808675 22509476222784 run_lib.py:146] step: 467100, eval_loss: 3.42728e-02
I0211 22:25:42.370440 22509476222784 run_lib.py:133] step: 467150, training_loss: 4.70021e-02
I0211 22:26:01.188599 22509476222784 run_lib.py:133] step: 467200, training_loss: 5.10947e-02
I0211 22:26:01.363008 22509476222784 run_lib.py:146] step: 467200, eval_loss: 4.40454e-02
I0211 22:26:19.880757 22509476222784 run_lib.py:133] step: 467250, training_loss: 4.25394e-02
I0211 22:26:38.349940 22509476222784 run_lib.py:133] step: 467300, training_loss: 4.55863e-02
I0211 22:26:38.509624 22509476222784 run_lib.py:146] step: 467300, eval_loss: 3.47755e-02
I0211 22:26:57.035359 22509476222784 run_lib.py:133] step: 467350, training_loss: 3.37932e-02
I0211 22:27:15.404747 22509476222784 run_lib.py:133] step: 467400, training_loss: 4.02332e-02
I0211 22:27:15.569677 22509476222784 run_lib.py:146] step: 467400, eval_loss: 4.67350e-02
I0211 22:27:34.061112 22509476222784 run_lib.py:133] step: 467450, training_loss: 5.13682e-02
I0211 22:27:52.721784 22509476222784 run_lib.py:133] step: 467500, training_loss: 3.80621e-02
I0211 22:27:52.886622 22509476222784 run_lib.py:146] step: 467500, eval_loss: 2.20331e-02
I0211 22:28:11.400346 22509476222784 run_lib.py:133] step: 467550, training_loss: 4.37509e-02
I0211 22:28:29.921482 22509476222784 run_lib.py:133] step: 467600, training_loss: 4.83650e-02
I0211 22:28:30.086505 22509476222784 run_lib.py:146] step: 467600, eval_loss: 3.71721e-02
I0211 22:28:48.599386 22509476222784 run_lib.py:133] step: 467650, training_loss: 4.32540e-02
I0211 22:29:07.042658 22509476222784 run_lib.py:133] step: 467700, training_loss: 3.77426e-02
I0211 22:29:07.220722 22509476222784 run_lib.py:146] step: 467700, eval_loss: 4.42707e-02
I0211 22:29:25.776276 22509476222784 run_lib.py:133] step: 467750, training_loss: 3.00357e-02
I0211 22:29:44.321995 22509476222784 run_lib.py:133] step: 467800, training_loss: 4.02248e-02
I0211 22:29:44.485868 22509476222784 run_lib.py:146] step: 467800, eval_loss: 5.75569e-02
I0211 22:30:03.198420 22509476222784 run_lib.py:133] step: 467850, training_loss: 4.05666e-02
I0211 22:30:21.709576 22509476222784 run_lib.py:133] step: 467900, training_loss: 3.21649e-02
I0211 22:30:21.874406 22509476222784 run_lib.py:146] step: 467900, eval_loss: 3.07165e-02
I0211 22:30:40.338783 22509476222784 run_lib.py:133] step: 467950, training_loss: 4.90997e-02
I0211 22:30:58.841236 22509476222784 run_lib.py:133] step: 468000, training_loss: 5.29865e-02
I0211 22:30:59.020657 22509476222784 run_lib.py:146] step: 468000, eval_loss: 3.59034e-02
I0211 22:31:17.704354 22509476222784 run_lib.py:133] step: 468050, training_loss: 4.86256e-02
I0211 22:31:36.244866 22509476222784 run_lib.py:133] step: 468100, training_loss: 4.48553e-02
I0211 22:31:36.410732 22509476222784 run_lib.py:146] step: 468100, eval_loss: 4.18764e-02
I0211 22:31:55.091287 22509476222784 run_lib.py:133] step: 468150, training_loss: 3.68470e-02
I0211 22:32:13.548898 22509476222784 run_lib.py:133] step: 468200, training_loss: 5.16847e-02
I0211 22:32:13.710637 22509476222784 run_lib.py:146] step: 468200, eval_loss: 3.21817e-02
I0211 22:32:32.352838 22509476222784 run_lib.py:133] step: 468250, training_loss: 4.66890e-02
I0211 22:32:50.876312 22509476222784 run_lib.py:133] step: 468300, training_loss: 5.66346e-02
I0211 22:32:51.040892 22509476222784 run_lib.py:146] step: 468300, eval_loss: 3.90126e-02
I0211 22:33:09.739799 22509476222784 run_lib.py:133] step: 468350, training_loss: 4.07346e-02
I0211 22:33:28.234971 22509476222784 run_lib.py:133] step: 468400, training_loss: 4.73544e-02
I0211 22:33:28.404096 22509476222784 run_lib.py:146] step: 468400, eval_loss: 4.90064e-02
I0211 22:33:46.874303 22509476222784 run_lib.py:133] step: 468450, training_loss: 6.02489e-02
I0211 22:34:05.457561 22509476222784 run_lib.py:133] step: 468500, training_loss: 3.91522e-02
I0211 22:34:05.624719 22509476222784 run_lib.py:146] step: 468500, eval_loss: 4.29903e-02
I0211 22:34:24.144888 22509476222784 run_lib.py:133] step: 468550, training_loss: 4.96855e-02
I0211 22:34:42.685918 22509476222784 run_lib.py:133] step: 468600, training_loss: 3.15233e-02
I0211 22:34:42.866270 22509476222784 run_lib.py:146] step: 468600, eval_loss: 3.52103e-02
I0211 22:35:01.543748 22509476222784 run_lib.py:133] step: 468650, training_loss: 3.24971e-02
I0211 22:35:20.034672 22509476222784 run_lib.py:133] step: 468700, training_loss: 3.78560e-02
I0211 22:35:20.191220 22509476222784 run_lib.py:146] step: 468700, eval_loss: 3.57222e-02
I0211 22:35:38.838282 22509476222784 run_lib.py:133] step: 468750, training_loss: 4.45836e-02
I0211 22:35:57.363923 22509476222784 run_lib.py:133] step: 468800, training_loss: 3.89873e-02
I0211 22:35:57.560889 22509476222784 run_lib.py:146] step: 468800, eval_loss: 3.94375e-02
I0211 22:36:16.119312 22509476222784 run_lib.py:133] step: 468850, training_loss: 5.23740e-02
I0211 22:36:34.856152 22509476222784 run_lib.py:133] step: 468900, training_loss: 3.96178e-02
I0211 22:36:35.022590 22509476222784 run_lib.py:146] step: 468900, eval_loss: 4.34412e-02
I0211 22:36:53.482093 22509476222784 run_lib.py:133] step: 468950, training_loss: 3.71726e-02
I0211 22:37:11.963418 22509476222784 run_lib.py:133] step: 469000, training_loss: 3.81702e-02
I0211 22:37:12.127821 22509476222784 run_lib.py:146] step: 469000, eval_loss: 4.76482e-02
I0211 22:37:30.597609 22509476222784 run_lib.py:133] step: 469050, training_loss: 4.15745e-02
I0211 22:37:49.195884 22509476222784 run_lib.py:133] step: 469100, training_loss: 3.53893e-02
I0211 22:37:49.360096 22509476222784 run_lib.py:146] step: 469100, eval_loss: 3.34362e-02
I0211 22:38:07.881085 22509476222784 run_lib.py:133] step: 469150, training_loss: 3.78483e-02
I0211 22:38:26.509540 22509476222784 run_lib.py:133] step: 469200, training_loss: 4.50201e-02
I0211 22:38:26.675949 22509476222784 run_lib.py:146] step: 469200, eval_loss: 4.18998e-02
I0211 22:38:45.193237 22509476222784 run_lib.py:133] step: 469250, training_loss: 3.78678e-02
I0211 22:39:03.735868 22509476222784 run_lib.py:133] step: 469300, training_loss: 3.54199e-02
I0211 22:39:03.947556 22509476222784 run_lib.py:146] step: 469300, eval_loss: 4.13396e-02
I0211 22:39:22.589967 22509476222784 run_lib.py:133] step: 469350, training_loss: 5.15421e-02
I0211 22:39:41.140245 22509476222784 run_lib.py:133] step: 469400, training_loss: 3.96164e-02
I0211 22:39:41.316599 22509476222784 run_lib.py:146] step: 469400, eval_loss: 4.29406e-02
I0211 22:39:59.856152 22509476222784 run_lib.py:133] step: 469450, training_loss: 3.53427e-02
I0211 22:40:18.458594 22509476222784 run_lib.py:133] step: 469500, training_loss: 4.47589e-02
I0211 22:40:18.623671 22509476222784 run_lib.py:146] step: 469500, eval_loss: 4.12873e-02
I0211 22:40:37.302327 22509476222784 run_lib.py:133] step: 469550, training_loss: 4.02711e-02
I0211 22:40:55.749662 22509476222784 run_lib.py:133] step: 469600, training_loss: 5.15410e-02
I0211 22:40:55.913551 22509476222784 run_lib.py:146] step: 469600, eval_loss: 4.49990e-02
I0211 22:41:14.495766 22509476222784 run_lib.py:133] step: 469650, training_loss: 5.86471e-02
I0211 22:41:32.971867 22509476222784 run_lib.py:133] step: 469700, training_loss: 3.94448e-02
I0211 22:41:33.132856 22509476222784 run_lib.py:146] step: 469700, eval_loss: 4.16290e-02
I0211 22:41:51.864215 22509476222784 run_lib.py:133] step: 469750, training_loss: 3.80461e-02
I0211 22:42:10.341126 22509476222784 run_lib.py:133] step: 469800, training_loss: 4.09142e-02
I0211 22:42:10.503693 22509476222784 run_lib.py:146] step: 469800, eval_loss: 4.54172e-02
I0211 22:42:28.957850 22509476222784 run_lib.py:133] step: 469850, training_loss: 3.15186e-02
I0211 22:42:47.640552 22509476222784 run_lib.py:133] step: 469900, training_loss: 4.23495e-02
I0211 22:42:47.804785 22509476222784 run_lib.py:146] step: 469900, eval_loss: 4.59162e-02
I0211 22:43:06.263558 22509476222784 run_lib.py:133] step: 469950, training_loss: 3.56361e-02
I0211 22:43:24.958729 22509476222784 run_lib.py:133] step: 470000, training_loss: 5.04918e-02
I0211 22:43:25.728327 22509476222784 run_lib.py:146] step: 470000, eval_loss: 4.63454e-02
I0211 22:43:47.036184 22509476222784 run_lib.py:133] step: 470050, training_loss: 3.59392e-02
I0211 22:44:05.570101 22509476222784 run_lib.py:133] step: 470100, training_loss: 4.66004e-02
I0211 22:44:05.743277 22509476222784 run_lib.py:146] step: 470100, eval_loss: 3.52617e-02
I0211 22:44:24.233372 22509476222784 run_lib.py:133] step: 470150, training_loss: 4.51664e-02
I0211 22:44:42.696501 22509476222784 run_lib.py:133] step: 470200, training_loss: 4.83938e-02
I0211 22:44:42.856565 22509476222784 run_lib.py:146] step: 470200, eval_loss: 4.06313e-02
I0211 22:45:01.358770 22509476222784 run_lib.py:133] step: 470250, training_loss: 3.79183e-02
I0211 22:45:19.959574 22509476222784 run_lib.py:133] step: 470300, training_loss: 4.12212e-02
I0211 22:45:20.140608 22509476222784 run_lib.py:146] step: 470300, eval_loss: 4.04493e-02
I0211 22:45:38.647027 22509476222784 run_lib.py:133] step: 470350, training_loss: 4.25561e-02
I0211 22:45:57.205945 22509476222784 run_lib.py:133] step: 470400, training_loss: 4.19350e-02
I0211 22:45:57.422900 22509476222784 run_lib.py:146] step: 470400, eval_loss: 3.75332e-02
I0211 22:46:16.012313 22509476222784 run_lib.py:133] step: 470450, training_loss: 4.04011e-02
I0211 22:46:34.468006 22509476222784 run_lib.py:133] step: 470500, training_loss: 4.02449e-02
I0211 22:46:34.630476 22509476222784 run_lib.py:146] step: 470500, eval_loss: 4.79658e-02
I0211 22:46:53.276658 22509476222784 run_lib.py:133] step: 470550, training_loss: 4.22985e-02
I0211 22:47:11.822604 22509476222784 run_lib.py:133] step: 470600, training_loss: 4.77086e-02
I0211 22:47:11.995410 22509476222784 run_lib.py:146] step: 470600, eval_loss: 4.13572e-02
I0211 22:47:30.700723 22509476222784 run_lib.py:133] step: 470650, training_loss: 4.42901e-02
I0211 22:47:49.193670 22509476222784 run_lib.py:133] step: 470700, training_loss: 4.83130e-02
I0211 22:47:49.353610 22509476222784 run_lib.py:146] step: 470700, eval_loss: 5.36572e-02
I0211 22:48:08.046519 22509476222784 run_lib.py:133] step: 470750, training_loss: 5.08042e-02
I0211 22:48:26.641471 22509476222784 run_lib.py:133] step: 470800, training_loss: 4.57019e-02
I0211 22:48:26.814227 22509476222784 run_lib.py:146] step: 470800, eval_loss: 4.26852e-02
I0211 22:48:45.407908 22509476222784 run_lib.py:133] step: 470850, training_loss: 4.39115e-02
I0211 22:49:04.076613 22509476222784 run_lib.py:133] step: 470900, training_loss: 4.76841e-02
I0211 22:49:04.242766 22509476222784 run_lib.py:146] step: 470900, eval_loss: 5.89099e-02
I0211 22:49:22.682921 22509476222784 run_lib.py:133] step: 470950, training_loss: 4.54349e-02
I0211 22:49:41.197425 22509476222784 run_lib.py:133] step: 471000, training_loss: 4.56191e-02
I0211 22:49:41.361564 22509476222784 run_lib.py:146] step: 471000, eval_loss: 4.38751e-02
I0211 22:50:00.006433 22509476222784 run_lib.py:133] step: 471050, training_loss: 5.25307e-02
I0211 22:50:18.713203 22509476222784 run_lib.py:133] step: 471100, training_loss: 4.80140e-02
I0211 22:50:18.877707 22509476222784 run_lib.py:146] step: 471100, eval_loss: 3.78676e-02
I0211 22:50:37.484009 22509476222784 run_lib.py:133] step: 471150, training_loss: 4.64006e-02
I0211 22:50:55.972059 22509476222784 run_lib.py:133] step: 471200, training_loss: 5.38960e-02
I0211 22:50:56.134620 22509476222784 run_lib.py:146] step: 471200, eval_loss: 5.30575e-02
I0211 22:51:14.649676 22509476222784 run_lib.py:133] step: 471250, training_loss: 5.17504e-02
I0211 22:51:33.309429 22509476222784 run_lib.py:133] step: 471300, training_loss: 4.47190e-02
I0211 22:51:33.473871 22509476222784 run_lib.py:146] step: 471300, eval_loss: 5.94935e-02
I0211 22:51:52.005915 22509476222784 run_lib.py:133] step: 471350, training_loss: 4.68089e-02
I0211 22:52:10.570472 22509476222784 run_lib.py:133] step: 471400, training_loss: 2.90726e-02
I0211 22:52:10.731487 22509476222784 run_lib.py:146] step: 471400, eval_loss: 3.23833e-02
I0211 22:52:29.260144 22509476222784 run_lib.py:133] step: 471450, training_loss: 3.67425e-02
I0211 22:52:47.958505 22509476222784 run_lib.py:133] step: 471500, training_loss: 4.72857e-02
I0211 22:52:48.122306 22509476222784 run_lib.py:146] step: 471500, eval_loss: 4.72491e-02
I0211 22:53:06.615294 22509476222784 run_lib.py:133] step: 471550, training_loss: 4.78473e-02
I0211 22:53:25.149900 22509476222784 run_lib.py:133] step: 471600, training_loss: 3.66062e-02
I0211 22:53:25.313907 22509476222784 run_lib.py:146] step: 471600, eval_loss: 4.21514e-02
I0211 22:53:43.835859 22509476222784 run_lib.py:133] step: 471650, training_loss: 4.09457e-02
I0211 22:54:02.317262 22509476222784 run_lib.py:133] step: 471700, training_loss: 4.13174e-02
I0211 22:54:02.483800 22509476222784 run_lib.py:146] step: 471700, eval_loss: 4.15966e-02
I0211 22:54:21.145515 22509476222784 run_lib.py:133] step: 471750, training_loss: 5.27099e-02
I0211 22:54:39.700341 22509476222784 run_lib.py:133] step: 471800, training_loss: 3.29135e-02
I0211 22:54:39.866877 22509476222784 run_lib.py:146] step: 471800, eval_loss: 2.76333e-02
I0211 22:54:58.388172 22509476222784 run_lib.py:133] step: 471850, training_loss: 5.03160e-02
I0211 22:55:16.945215 22509476222784 run_lib.py:133] step: 471900, training_loss: 3.83224e-02
I0211 22:55:17.115877 22509476222784 run_lib.py:146] step: 471900, eval_loss: 4.39247e-02
I0211 22:55:35.776555 22509476222784 run_lib.py:133] step: 471950, training_loss: 3.86061e-02
I0211 22:55:54.234301 22509476222784 run_lib.py:133] step: 472000, training_loss: 4.19840e-02
I0211 22:55:54.398829 22509476222784 run_lib.py:146] step: 472000, eval_loss: 2.42536e-02
I0211 22:56:13.116051 22509476222784 run_lib.py:133] step: 472050, training_loss: 4.63029e-02
I0211 22:56:31.597971 22509476222784 run_lib.py:133] step: 472100, training_loss: 5.12048e-02
I0211 22:56:31.761664 22509476222784 run_lib.py:146] step: 472100, eval_loss: 3.54562e-02
I0211 22:56:50.410695 22509476222784 run_lib.py:133] step: 472150, training_loss: 3.31161e-02
I0211 22:57:08.943646 22509476222784 run_lib.py:133] step: 472200, training_loss: 4.37459e-02
I0211 22:57:09.116751 22509476222784 run_lib.py:146] step: 472200, eval_loss: 4.33112e-02
I0211 22:57:27.661308 22509476222784 run_lib.py:133] step: 472250, training_loss: 4.14809e-02
I0211 22:57:46.370760 22509476222784 run_lib.py:133] step: 472300, training_loss: 3.20007e-02
I0211 22:57:46.538177 22509476222784 run_lib.py:146] step: 472300, eval_loss: 4.98043e-02
I0211 22:58:05.068522 22509476222784 run_lib.py:133] step: 472350, training_loss: 6.07566e-02
I0211 22:58:23.769851 22509476222784 run_lib.py:133] step: 472400, training_loss: 2.95246e-02
I0211 22:58:23.941693 22509476222784 run_lib.py:146] step: 472400, eval_loss: 4.18544e-02
I0211 22:58:42.467333 22509476222784 run_lib.py:133] step: 472450, training_loss: 4.17808e-02
I0211 22:59:01.004004 22509476222784 run_lib.py:133] step: 472500, training_loss: 4.79976e-02
I0211 22:59:01.168862 22509476222784 run_lib.py:146] step: 472500, eval_loss: 5.50831e-02
I0211 22:59:19.912774 22509476222784 run_lib.py:133] step: 472550, training_loss: 3.51106e-02
I0211 22:59:38.388775 22509476222784 run_lib.py:133] step: 472600, training_loss: 5.33532e-02
I0211 22:59:38.551716 22509476222784 run_lib.py:146] step: 472600, eval_loss: 4.54341e-02
I0211 22:59:57.082463 22509476222784 run_lib.py:133] step: 472650, training_loss: 4.01277e-02
I0211 23:00:15.732572 22509476222784 run_lib.py:133] step: 472700, training_loss: 3.45137e-02
I0211 23:00:15.897933 22509476222784 run_lib.py:146] step: 472700, eval_loss: 5.17726e-02
I0211 23:00:34.511448 22509476222784 run_lib.py:133] step: 472750, training_loss: 5.03887e-02
I0211 23:00:53.090253 22509476222784 run_lib.py:133] step: 472800, training_loss: 4.44650e-02
I0211 23:00:53.255723 22509476222784 run_lib.py:146] step: 472800, eval_loss: 4.08920e-02
I0211 23:01:11.864490 22509476222784 run_lib.py:133] step: 472850, training_loss: 3.72128e-02
I0211 23:01:30.355736 22509476222784 run_lib.py:133] step: 472900, training_loss: 3.07026e-02
I0211 23:01:30.519807 22509476222784 run_lib.py:146] step: 472900, eval_loss: 3.53095e-02
I0211 23:01:49.009408 22509476222784 run_lib.py:133] step: 472950, training_loss: 3.42254e-02
I0211 23:02:07.598913 22509476222784 run_lib.py:133] step: 473000, training_loss: 4.53849e-02
I0211 23:02:07.782888 22509476222784 run_lib.py:146] step: 473000, eval_loss: 3.68581e-02
I0211 23:02:26.505113 22509476222784 run_lib.py:133] step: 473050, training_loss: 4.57001e-02
I0211 23:02:45.117070 22509476222784 run_lib.py:133] step: 473100, training_loss: 3.58895e-02
I0211 23:02:45.278604 22509476222784 run_lib.py:146] step: 473100, eval_loss: 3.02491e-02
I0211 23:03:03.735423 22509476222784 run_lib.py:133] step: 473150, training_loss: 4.93834e-02
I0211 23:03:22.227716 22509476222784 run_lib.py:133] step: 473200, training_loss: 4.19991e-02
I0211 23:03:22.449796 22509476222784 run_lib.py:146] step: 473200, eval_loss: 4.00888e-02
I0211 23:03:41.135668 22509476222784 run_lib.py:133] step: 473250, training_loss: 3.18172e-02
I0211 23:03:59.709043 22509476222784 run_lib.py:133] step: 473300, training_loss: 3.87103e-02
I0211 23:03:59.874662 22509476222784 run_lib.py:146] step: 473300, eval_loss: 4.53063e-02
I0211 23:04:18.525839 22509476222784 run_lib.py:133] step: 473350, training_loss: 3.55788e-02
I0211 23:04:36.984707 22509476222784 run_lib.py:133] step: 473400, training_loss: 4.99664e-02
I0211 23:04:37.149847 22509476222784 run_lib.py:146] step: 473400, eval_loss: 3.35404e-02
I0211 23:04:55.773564 22509476222784 run_lib.py:133] step: 473450, training_loss: 3.06610e-02
I0211 23:05:14.217304 22509476222784 run_lib.py:133] step: 473500, training_loss: 4.08646e-02
I0211 23:05:14.378490 22509476222784 run_lib.py:146] step: 473500, eval_loss: 3.95163e-02
I0211 23:05:33.077003 22509476222784 run_lib.py:133] step: 473550, training_loss: 4.81030e-02
I0211 23:05:51.683954 22509476222784 run_lib.py:133] step: 473600, training_loss: 4.47434e-02
I0211 23:05:51.851827 22509476222784 run_lib.py:146] step: 473600, eval_loss: 4.98449e-02
I0211 23:06:10.385026 22509476222784 run_lib.py:133] step: 473650, training_loss: 4.44740e-02
I0211 23:06:29.107981 22509476222784 run_lib.py:133] step: 473700, training_loss: 3.99327e-02
I0211 23:06:29.273872 22509476222784 run_lib.py:146] step: 473700, eval_loss: 4.32012e-02
I0211 23:06:47.779538 22509476222784 run_lib.py:133] step: 473750, training_loss: 4.52850e-02
I0211 23:07:06.236090 22509476222784 run_lib.py:133] step: 473800, training_loss: 4.07940e-02
I0211 23:07:06.408676 22509476222784 run_lib.py:146] step: 473800, eval_loss: 5.41507e-02
I0211 23:07:25.135877 22509476222784 run_lib.py:133] step: 473850, training_loss: 3.55502e-02
I0211 23:07:43.648232 22509476222784 run_lib.py:133] step: 473900, training_loss: 4.12347e-02
I0211 23:07:43.812025 22509476222784 run_lib.py:146] step: 473900, eval_loss: 3.59694e-02
I0211 23:08:02.577656 22509476222784 run_lib.py:133] step: 473950, training_loss: 3.50926e-02
I0211 23:08:21.139539 22509476222784 run_lib.py:133] step: 474000, training_loss: 6.47339e-02
I0211 23:08:21.301414 22509476222784 run_lib.py:146] step: 474000, eval_loss: 5.32596e-02
I0211 23:08:39.827681 22509476222784 run_lib.py:133] step: 474050, training_loss: 5.24725e-02
I0211 23:08:58.515011 22509476222784 run_lib.py:133] step: 474100, training_loss: 4.91314e-02
I0211 23:08:58.685943 22509476222784 run_lib.py:146] step: 474100, eval_loss: 4.47121e-02
I0211 23:09:17.267092 22509476222784 run_lib.py:133] step: 474150, training_loss: 4.46615e-02
I0211 23:09:35.825310 22509476222784 run_lib.py:133] step: 474200, training_loss: 4.17849e-02
I0211 23:09:35.995824 22509476222784 run_lib.py:146] step: 474200, eval_loss: 3.86249e-02
I0211 23:09:54.443819 22509476222784 run_lib.py:133] step: 474250, training_loss: 3.44832e-02
I0211 23:10:13.106962 22509476222784 run_lib.py:133] step: 474300, training_loss: 3.86649e-02
I0211 23:10:13.271716 22509476222784 run_lib.py:146] step: 474300, eval_loss: 3.87138e-02
I0211 23:10:31.780604 22509476222784 run_lib.py:133] step: 474350, training_loss: 4.08226e-02
I0211 23:10:50.430474 22509476222784 run_lib.py:133] step: 474400, training_loss: 4.15822e-02
I0211 23:10:50.595736 22509476222784 run_lib.py:146] step: 474400, eval_loss: 4.07079e-02
I0211 23:11:09.151181 22509476222784 run_lib.py:133] step: 474450, training_loss: 4.00873e-02
I0211 23:11:27.787736 22509476222784 run_lib.py:133] step: 474500, training_loss: 4.68943e-02
I0211 23:11:27.969254 22509476222784 run_lib.py:146] step: 474500, eval_loss: 3.58050e-02
I0211 23:11:46.685677 22509476222784 run_lib.py:133] step: 474550, training_loss: 4.33455e-02
I0211 23:12:05.283836 22509476222784 run_lib.py:133] step: 474600, training_loss: 4.67018e-02
I0211 23:12:05.456067 22509476222784 run_lib.py:146] step: 474600, eval_loss: 3.40277e-02
I0211 23:12:24.052917 22509476222784 run_lib.py:133] step: 474650, training_loss: 3.27969e-02
I0211 23:12:42.684331 22509476222784 run_lib.py:133] step: 474700, training_loss: 4.99756e-02
I0211 23:12:42.850664 22509476222784 run_lib.py:146] step: 474700, eval_loss: 4.02623e-02
I0211 23:13:01.520970 22509476222784 run_lib.py:133] step: 474750, training_loss: 3.36071e-02
I0211 23:13:20.028745 22509476222784 run_lib.py:133] step: 474800, training_loss: 5.54143e-02
I0211 23:13:20.192536 22509476222784 run_lib.py:146] step: 474800, eval_loss: 4.60892e-02
I0211 23:13:38.838040 22509476222784 run_lib.py:133] step: 474850, training_loss: 4.08609e-02
I0211 23:13:57.342116 22509476222784 run_lib.py:133] step: 474900, training_loss: 4.71473e-02
I0211 23:13:57.506579 22509476222784 run_lib.py:146] step: 474900, eval_loss: 3.24279e-02
I0211 23:14:16.233169 22509476222784 run_lib.py:133] step: 474950, training_loss: 4.58643e-02
I0211 23:14:34.711230 22509476222784 run_lib.py:133] step: 475000, training_loss: 3.58010e-02
I0211 23:14:34.872654 22509476222784 run_lib.py:146] step: 475000, eval_loss: 4.38111e-02
I0211 23:14:53.385466 22509476222784 run_lib.py:133] step: 475050, training_loss: 3.75894e-02
I0211 23:15:12.018004 22509476222784 run_lib.py:133] step: 475100, training_loss: 4.40338e-02
I0211 23:15:12.184828 22509476222784 run_lib.py:146] step: 475100, eval_loss: 5.05940e-02
I0211 23:15:30.629243 22509476222784 run_lib.py:133] step: 475150, training_loss: 4.47682e-02
I0211 23:15:49.227025 22509476222784 run_lib.py:133] step: 475200, training_loss: 5.22500e-02
I0211 23:15:49.399577 22509476222784 run_lib.py:146] step: 475200, eval_loss: 4.86783e-02
I0211 23:16:07.901127 22509476222784 run_lib.py:133] step: 475250, training_loss: 4.85155e-02
I0211 23:16:26.384018 22509476222784 run_lib.py:133] step: 475300, training_loss: 3.95138e-02
I0211 23:16:26.548917 22509476222784 run_lib.py:146] step: 475300, eval_loss: 4.31329e-02
I0211 23:16:45.248307 22509476222784 run_lib.py:133] step: 475350, training_loss: 5.05667e-02
I0211 23:17:03.709767 22509476222784 run_lib.py:133] step: 475400, training_loss: 4.71938e-02
I0211 23:17:03.872684 22509476222784 run_lib.py:146] step: 475400, eval_loss: 4.92292e-02
I0211 23:17:22.331165 22509476222784 run_lib.py:133] step: 475450, training_loss: 4.51646e-02
I0211 23:17:40.986151 22509476222784 run_lib.py:133] step: 475500, training_loss: 3.57918e-02
I0211 23:17:41.152786 22509476222784 run_lib.py:146] step: 475500, eval_loss: 5.08050e-02
I0211 23:17:59.697948 22509476222784 run_lib.py:133] step: 475550, training_loss: 3.89215e-02
I0211 23:18:18.143784 22509476222784 run_lib.py:133] step: 475600, training_loss: 4.68977e-02
I0211 23:18:18.506694 22509476222784 run_lib.py:146] step: 475600, eval_loss: 3.56486e-02
I0211 23:18:37.040300 22509476222784 run_lib.py:133] step: 475650, training_loss: 3.53111e-02
I0211 23:18:55.542254 22509476222784 run_lib.py:133] step: 475700, training_loss: 4.11739e-02
I0211 23:18:55.708728 22509476222784 run_lib.py:146] step: 475700, eval_loss: 3.47625e-02
I0211 23:19:14.252269 22509476222784 run_lib.py:133] step: 475750, training_loss: 5.22074e-02
I0211 23:19:32.778160 22509476222784 run_lib.py:133] step: 475800, training_loss: 4.45808e-02
I0211 23:19:32.943951 22509476222784 run_lib.py:146] step: 475800, eval_loss: 3.88710e-02
I0211 23:19:51.664615 22509476222784 run_lib.py:133] step: 475850, training_loss: 4.79751e-02
I0211 23:20:10.147733 22509476222784 run_lib.py:133] step: 475900, training_loss: 4.68134e-02
I0211 23:20:10.311074 22509476222784 run_lib.py:146] step: 475900, eval_loss: 5.96072e-02
I0211 23:20:28.827165 22509476222784 run_lib.py:133] step: 475950, training_loss: 4.92661e-02
I0211 23:20:47.332394 22509476222784 run_lib.py:133] step: 476000, training_loss: 4.24343e-02
I0211 23:20:47.506756 22509476222784 run_lib.py:146] step: 476000, eval_loss: 3.75658e-02
I0211 23:21:06.171201 22509476222784 run_lib.py:133] step: 476050, training_loss: 4.31771e-02
I0211 23:21:24.811498 22509476222784 run_lib.py:133] step: 476100, training_loss: 3.70258e-02
I0211 23:21:24.977776 22509476222784 run_lib.py:146] step: 476100, eval_loss: 4.19190e-02
I0211 23:21:43.488200 22509476222784 run_lib.py:133] step: 476150, training_loss: 5.09995e-02
I0211 23:22:01.969497 22509476222784 run_lib.py:133] step: 476200, training_loss: 4.86349e-02
I0211 23:22:02.132710 22509476222784 run_lib.py:146] step: 476200, eval_loss: 4.29345e-02
I0211 23:22:20.753531 22509476222784 run_lib.py:133] step: 476250, training_loss: 4.00075e-02
I0211 23:22:39.297276 22509476222784 run_lib.py:133] step: 476300, training_loss: 5.13503e-02
I0211 23:22:39.460883 22509476222784 run_lib.py:146] step: 476300, eval_loss: 4.91212e-02
I0211 23:22:58.201731 22509476222784 run_lib.py:133] step: 476350, training_loss: 4.35499e-02
I0211 23:23:16.687631 22509476222784 run_lib.py:133] step: 476400, training_loss: 3.58763e-02
I0211 23:23:16.857676 22509476222784 run_lib.py:146] step: 476400, eval_loss: 4.23300e-02
I0211 23:23:35.462517 22509476222784 run_lib.py:133] step: 476450, training_loss: 4.01769e-02
I0211 23:23:53.915226 22509476222784 run_lib.py:133] step: 476500, training_loss: 3.26170e-02
I0211 23:23:54.079686 22509476222784 run_lib.py:146] step: 476500, eval_loss: 4.48412e-02
I0211 23:24:12.632899 22509476222784 run_lib.py:133] step: 476550, training_loss: 4.47499e-02
I0211 23:24:31.318852 22509476222784 run_lib.py:133] step: 476600, training_loss: 4.61597e-02
I0211 23:24:31.484744 22509476222784 run_lib.py:146] step: 476600, eval_loss: 3.84949e-02
I0211 23:24:49.971512 22509476222784 run_lib.py:133] step: 476650, training_loss: 3.93715e-02
I0211 23:25:08.622009 22509476222784 run_lib.py:133] step: 476700, training_loss: 4.92527e-02
I0211 23:25:08.786663 22509476222784 run_lib.py:146] step: 476700, eval_loss: 4.76849e-02
I0211 23:25:27.345790 22509476222784 run_lib.py:133] step: 476750, training_loss: 6.73473e-02
I0211 23:25:45.860361 22509476222784 run_lib.py:133] step: 476800, training_loss: 2.93450e-02
I0211 23:25:46.022604 22509476222784 run_lib.py:146] step: 476800, eval_loss: 4.04718e-02
I0211 23:26:04.535633 22509476222784 run_lib.py:133] step: 476850, training_loss: 4.80697e-02
I0211 23:26:23.232472 22509476222784 run_lib.py:133] step: 476900, training_loss: 4.08262e-02
I0211 23:26:23.398809 22509476222784 run_lib.py:146] step: 476900, eval_loss: 4.17508e-02
I0211 23:26:41.939009 22509476222784 run_lib.py:133] step: 476950, training_loss: 4.39028e-02
I0211 23:27:00.460188 22509476222784 run_lib.py:133] step: 477000, training_loss: 4.28702e-02
I0211 23:27:00.626873 22509476222784 run_lib.py:146] step: 477000, eval_loss: 3.89878e-02
I0211 23:27:19.305927 22509476222784 run_lib.py:133] step: 477050, training_loss: 4.68061e-02
I0211 23:27:37.818890 22509476222784 run_lib.py:133] step: 477100, training_loss: 3.81105e-02
I0211 23:27:37.996925 22509476222784 run_lib.py:146] step: 477100, eval_loss: 3.59666e-02
I0211 23:27:56.650991 22509476222784 run_lib.py:133] step: 477150, training_loss: 5.38667e-02
I0211 23:28:15.189905 22509476222784 run_lib.py:133] step: 477200, training_loss: 3.65075e-02
I0211 23:28:15.353543 22509476222784 run_lib.py:146] step: 477200, eval_loss: 4.72055e-02
I0211 23:28:33.883906 22509476222784 run_lib.py:133] step: 477250, training_loss: 5.27248e-02
I0211 23:28:52.373257 22509476222784 run_lib.py:133] step: 477300, training_loss: 3.86887e-02
I0211 23:28:52.541687 22509476222784 run_lib.py:146] step: 477300, eval_loss: 4.13923e-02
I0211 23:29:11.235628 22509476222784 run_lib.py:133] step: 477350, training_loss: 4.62095e-02
I0211 23:29:29.881330 22509476222784 run_lib.py:133] step: 477400, training_loss: 3.70002e-02
I0211 23:29:30.067817 22509476222784 run_lib.py:146] step: 477400, eval_loss: 4.55794e-02
I0211 23:29:48.597939 22509476222784 run_lib.py:133] step: 477450, training_loss: 4.15147e-02
I0211 23:30:07.136306 22509476222784 run_lib.py:133] step: 477500, training_loss: 4.48096e-02
I0211 23:30:07.307913 22509476222784 run_lib.py:146] step: 477500, eval_loss: 4.16403e-02
I0211 23:30:25.958286 22509476222784 run_lib.py:133] step: 477550, training_loss: 4.03178e-02
I0211 23:30:44.438539 22509476222784 run_lib.py:133] step: 477600, training_loss: 3.45241e-02
I0211 23:30:44.608563 22509476222784 run_lib.py:146] step: 477600, eval_loss: 4.07916e-02
I0211 23:31:03.287247 22509476222784 run_lib.py:133] step: 477650, training_loss: 5.05950e-02
I0211 23:31:21.838697 22509476222784 run_lib.py:133] step: 477700, training_loss: 3.63225e-02
I0211 23:31:22.004462 22509476222784 run_lib.py:146] step: 477700, eval_loss: 5.33483e-02
I0211 23:31:40.689894 22509476222784 run_lib.py:133] step: 477750, training_loss: 3.22554e-02
I0211 23:31:59.165650 22509476222784 run_lib.py:133] step: 477800, training_loss: 3.88311e-02
I0211 23:31:59.327344 22509476222784 run_lib.py:146] step: 477800, eval_loss: 5.47626e-02
I0211 23:32:17.960021 22509476222784 run_lib.py:133] step: 477850, training_loss: 4.77248e-02
I0211 23:32:36.446274 22509476222784 run_lib.py:133] step: 477900, training_loss: 4.34954e-02
I0211 23:32:36.626521 22509476222784 run_lib.py:146] step: 477900, eval_loss: 3.74681e-02
I0211 23:32:55.219449 22509476222784 run_lib.py:133] step: 477950, training_loss: 4.59592e-02
I0211 23:33:13.914994 22509476222784 run_lib.py:133] step: 478000, training_loss: 3.89840e-02
I0211 23:33:14.078599 22509476222784 run_lib.py:146] step: 478000, eval_loss: 4.97697e-02
I0211 23:33:32.532519 22509476222784 run_lib.py:133] step: 478050, training_loss: 2.74029e-02
I0211 23:33:50.974414 22509476222784 run_lib.py:133] step: 478100, training_loss: 5.18658e-02
I0211 23:33:51.138594 22509476222784 run_lib.py:146] step: 478100, eval_loss: 3.74198e-02
I0211 23:34:09.796435 22509476222784 run_lib.py:133] step: 478150, training_loss: 4.74871e-02
I0211 23:34:28.430299 22509476222784 run_lib.py:133] step: 478200, training_loss: 4.74331e-02
I0211 23:34:28.593723 22509476222784 run_lib.py:146] step: 478200, eval_loss: 4.64877e-02
I0211 23:34:47.088226 22509476222784 run_lib.py:133] step: 478250, training_loss: 5.61806e-02
I0211 23:35:05.567116 22509476222784 run_lib.py:133] step: 478300, training_loss: 4.63983e-02
I0211 23:35:05.727623 22509476222784 run_lib.py:146] step: 478300, eval_loss: 3.49518e-02
I0211 23:35:24.211790 22509476222784 run_lib.py:133] step: 478350, training_loss: 4.78295e-02
I0211 23:35:42.893755 22509476222784 run_lib.py:133] step: 478400, training_loss: 4.94227e-02
I0211 23:35:43.057536 22509476222784 run_lib.py:146] step: 478400, eval_loss: 5.93816e-02
I0211 23:36:01.492346 22509476222784 run_lib.py:133] step: 478450, training_loss: 3.62843e-02
I0211 23:36:20.012485 22509476222784 run_lib.py:133] step: 478500, training_loss: 4.77961e-02
I0211 23:36:20.192641 22509476222784 run_lib.py:146] step: 478500, eval_loss: 4.45874e-02
I0211 23:36:38.673837 22509476222784 run_lib.py:133] step: 478550, training_loss: 3.88867e-02
I0211 23:36:57.393307 22509476222784 run_lib.py:133] step: 478600, training_loss: 4.50803e-02
I0211 23:36:57.557730 22509476222784 run_lib.py:146] step: 478600, eval_loss: 4.33726e-02
I0211 23:37:16.040792 22509476222784 run_lib.py:133] step: 478650, training_loss: 3.46847e-02
I0211 23:37:34.607717 22509476222784 run_lib.py:133] step: 478700, training_loss: 3.95495e-02
I0211 23:37:34.770583 22509476222784 run_lib.py:146] step: 478700, eval_loss: 5.30764e-02
I0211 23:37:53.270854 22509476222784 run_lib.py:133] step: 478750, training_loss: 4.36987e-02
I0211 23:38:11.816455 22509476222784 run_lib.py:133] step: 478800, training_loss: 5.08672e-02
I0211 23:38:11.982829 22509476222784 run_lib.py:146] step: 478800, eval_loss: 4.51006e-02
I0211 23:38:30.679118 22509476222784 run_lib.py:133] step: 478850, training_loss: 3.29459e-02
I0211 23:38:49.281683 22509476222784 run_lib.py:133] step: 478900, training_loss: 4.54839e-02
I0211 23:38:49.473109 22509476222784 run_lib.py:146] step: 478900, eval_loss: 5.66797e-02
I0211 23:39:07.906760 22509476222784 run_lib.py:133] step: 478950, training_loss: 4.08574e-02
I0211 23:39:26.342589 22509476222784 run_lib.py:133] step: 479000, training_loss: 4.69837e-02
I0211 23:39:26.505650 22509476222784 run_lib.py:146] step: 479000, eval_loss: 5.15901e-02
I0211 23:39:45.093518 22509476222784 run_lib.py:133] step: 479050, training_loss: 3.24065e-02
I0211 23:40:03.705567 22509476222784 run_lib.py:133] step: 479100, training_loss: 4.93423e-02
I0211 23:40:03.870960 22509476222784 run_lib.py:146] step: 479100, eval_loss: 3.92400e-02
I0211 23:40:22.543201 22509476222784 run_lib.py:133] step: 479150, training_loss: 3.27846e-02
I0211 23:40:41.004012 22509476222784 run_lib.py:133] step: 479200, training_loss: 4.51036e-02
I0211 23:40:41.165379 22509476222784 run_lib.py:146] step: 479200, eval_loss: 4.05297e-02
I0211 23:40:59.715141 22509476222784 run_lib.py:133] step: 479250, training_loss: 4.07666e-02
I0211 23:41:18.170776 22509476222784 run_lib.py:133] step: 479300, training_loss: 4.52791e-02
I0211 23:41:18.339871 22509476222784 run_lib.py:146] step: 479300, eval_loss: 4.31271e-02
I0211 23:41:36.857776 22509476222784 run_lib.py:133] step: 479350, training_loss: 4.29008e-02
I0211 23:41:55.555009 22509476222784 run_lib.py:133] step: 479400, training_loss: 3.95536e-02
I0211 23:41:55.720598 22509476222784 run_lib.py:146] step: 479400, eval_loss: 3.78841e-02
I0211 23:42:14.165034 22509476222784 run_lib.py:133] step: 479450, training_loss: 3.59222e-02
I0211 23:42:32.790742 22509476222784 run_lib.py:133] step: 479500, training_loss: 4.26444e-02
I0211 23:42:32.954528 22509476222784 run_lib.py:146] step: 479500, eval_loss: 4.36365e-02
I0211 23:42:51.436749 22509476222784 run_lib.py:133] step: 479550, training_loss: 4.60042e-02
I0211 23:43:10.010258 22509476222784 run_lib.py:133] step: 479600, training_loss: 3.47083e-02
I0211 23:43:10.174025 22509476222784 run_lib.py:146] step: 479600, eval_loss: 4.75277e-02
I0211 23:43:28.924415 22509476222784 run_lib.py:133] step: 479650, training_loss: 2.80931e-02
I0211 23:43:47.397977 22509476222784 run_lib.py:133] step: 479700, training_loss: 3.58344e-02
I0211 23:43:47.557707 22509476222784 run_lib.py:146] step: 479700, eval_loss: 5.26388e-02
I0211 23:44:06.046442 22509476222784 run_lib.py:133] step: 479750, training_loss: 4.40204e-02
I0211 23:44:24.684018 22509476222784 run_lib.py:133] step: 479800, training_loss: 3.67213e-02
I0211 23:44:24.847570 22509476222784 run_lib.py:146] step: 479800, eval_loss: 5.97762e-02
I0211 23:44:43.299183 22509476222784 run_lib.py:133] step: 479850, training_loss: 4.26386e-02
I0211 23:45:01.839737 22509476222784 run_lib.py:133] step: 479900, training_loss: 4.03256e-02
I0211 23:45:02.012734 22509476222784 run_lib.py:146] step: 479900, eval_loss: 3.75662e-02
I0211 23:45:20.841261 22509476222784 run_lib.py:133] step: 479950, training_loss: 4.43917e-02
I0211 23:45:39.351792 22509476222784 run_lib.py:133] step: 480000, training_loss: 4.48591e-02
I0211 23:45:40.097793 22509476222784 run_lib.py:146] step: 480000, eval_loss: 4.30143e-02
I0211 23:46:01.508188 22509476222784 run_lib.py:133] step: 480050, training_loss: 3.68661e-02
I0211 23:46:20.004949 22509476222784 run_lib.py:133] step: 480100, training_loss: 4.14312e-02
I0211 23:46:20.172652 22509476222784 run_lib.py:146] step: 480100, eval_loss: 4.89335e-02
I0211 23:46:38.766091 22509476222784 run_lib.py:133] step: 480150, training_loss: 4.14436e-02
I0211 23:46:57.347494 22509476222784 run_lib.py:133] step: 480200, training_loss: 3.29056e-02
I0211 23:46:57.512753 22509476222784 run_lib.py:146] step: 480200, eval_loss: 4.72783e-02
I0211 23:47:16.187328 22509476222784 run_lib.py:133] step: 480250, training_loss: 4.46810e-02
I0211 23:47:34.645946 22509476222784 run_lib.py:133] step: 480300, training_loss: 3.78869e-02
I0211 23:47:34.806406 22509476222784 run_lib.py:146] step: 480300, eval_loss: 4.39535e-02
I0211 23:47:53.185717 22509476222784 run_lib.py:133] step: 480350, training_loss: 5.21049e-02
I0211 23:48:11.616506 22509476222784 run_lib.py:133] step: 480400, training_loss: 4.75787e-02
I0211 23:48:11.782877 22509476222784 run_lib.py:146] step: 480400, eval_loss: 5.05064e-02
I0211 23:48:30.436990 22509476222784 run_lib.py:133] step: 480450, training_loss: 5.77176e-02
I0211 23:48:49.111186 22509476222784 run_lib.py:133] step: 480500, training_loss: 2.83377e-02
I0211 23:48:49.275848 22509476222784 run_lib.py:146] step: 480500, eval_loss: 4.80129e-02
I0211 23:49:07.734076 22509476222784 run_lib.py:133] step: 480550, training_loss: 4.08020e-02
I0211 23:49:26.196966 22509476222784 run_lib.py:133] step: 480600, training_loss: 4.18520e-02
I0211 23:49:26.362977 22509476222784 run_lib.py:146] step: 480600, eval_loss: 3.71757e-02
I0211 23:49:45.092722 22509476222784 run_lib.py:133] step: 480650, training_loss: 3.73966e-02
I0211 23:50:03.628164 22509476222784 run_lib.py:133] step: 480700, training_loss: 3.58150e-02
I0211 23:50:03.792952 22509476222784 run_lib.py:146] step: 480700, eval_loss: 5.17184e-02
I0211 23:50:22.541432 22509476222784 run_lib.py:133] step: 480750, training_loss: 5.58592e-02
I0211 23:50:41.017176 22509476222784 run_lib.py:133] step: 480800, training_loss: 4.11613e-02
I0211 23:50:41.181901 22509476222784 run_lib.py:146] step: 480800, eval_loss: 4.29087e-02
I0211 23:50:59.855407 22509476222784 run_lib.py:133] step: 480850, training_loss: 3.56476e-02
I0211 23:51:18.346971 22509476222784 run_lib.py:133] step: 480900, training_loss: 4.04870e-02
I0211 23:51:18.512900 22509476222784 run_lib.py:146] step: 480900, eval_loss: 4.31363e-02
I0211 23:51:37.142611 22509476222784 run_lib.py:133] step: 480950, training_loss: 4.72304e-02
I0211 23:51:55.579835 22509476222784 run_lib.py:133] step: 481000, training_loss: 5.05843e-02
I0211 23:51:55.752507 22509476222784 run_lib.py:146] step: 481000, eval_loss: 3.51968e-02
I0211 23:52:14.229291 22509476222784 run_lib.py:133] step: 481050, training_loss: 4.23748e-02
I0211 23:52:32.905949 22509476222784 run_lib.py:133] step: 481100, training_loss: 3.90394e-02
I0211 23:52:33.135787 22509476222784 run_lib.py:146] step: 481100, eval_loss: 4.24683e-02
I0211 23:52:51.679535 22509476222784 run_lib.py:133] step: 481150, training_loss: 4.82294e-02
I0211 23:53:10.156323 22509476222784 run_lib.py:133] step: 481200, training_loss: 4.66533e-02
I0211 23:53:10.316400 22509476222784 run_lib.py:146] step: 481200, eval_loss: 4.41763e-02
I0211 23:53:28.998058 22509476222784 run_lib.py:133] step: 481250, training_loss: 4.86304e-02
I0211 23:53:47.528815 22509476222784 run_lib.py:133] step: 481300, training_loss: 4.45918e-02
I0211 23:53:47.712571 22509476222784 run_lib.py:146] step: 481300, eval_loss: 3.78150e-02
I0211 23:54:06.381806 22509476222784 run_lib.py:133] step: 481350, training_loss: 3.55541e-02
I0211 23:54:24.798728 22509476222784 run_lib.py:133] step: 481400, training_loss: 4.08303e-02
I0211 23:54:24.968825 22509476222784 run_lib.py:146] step: 481400, eval_loss: 4.08070e-02
I0211 23:54:43.375992 22509476222784 run_lib.py:133] step: 481450, training_loss: 4.03602e-02
I0211 23:55:02.050003 22509476222784 run_lib.py:133] step: 481500, training_loss: 3.87927e-02
I0211 23:55:02.242622 22509476222784 run_lib.py:146] step: 481500, eval_loss: 4.95793e-02
I0211 23:55:20.761450 22509476222784 run_lib.py:133] step: 481550, training_loss: 3.37668e-02
I0211 23:55:39.347345 22509476222784 run_lib.py:133] step: 481600, training_loss: 4.70671e-02
I0211 23:55:39.510417 22509476222784 run_lib.py:146] step: 481600, eval_loss: 5.82078e-02
I0211 23:55:58.008608 22509476222784 run_lib.py:133] step: 481650, training_loss: 4.03596e-02
I0211 23:56:16.700581 22509476222784 run_lib.py:133] step: 481700, training_loss: 3.76078e-02
I0211 23:56:16.862667 22509476222784 run_lib.py:146] step: 481700, eval_loss: 4.55179e-02
I0211 23:56:35.299468 22509476222784 run_lib.py:133] step: 481750, training_loss: 5.54648e-02
I0211 23:56:53.874572 22509476222784 run_lib.py:133] step: 481800, training_loss: 6.04833e-02
I0211 23:56:54.049611 22509476222784 run_lib.py:146] step: 481800, eval_loss: 3.93385e-02
I0211 23:57:12.602697 22509476222784 run_lib.py:133] step: 481850, training_loss: 4.73514e-02
I0211 23:57:31.123654 22509476222784 run_lib.py:133] step: 481900, training_loss: 4.72099e-02
I0211 23:57:31.289751 22509476222784 run_lib.py:146] step: 481900, eval_loss: 3.21421e-02
I0211 23:57:49.973746 22509476222784 run_lib.py:133] step: 481950, training_loss: 4.28986e-02
I0211 23:58:08.597171 22509476222784 run_lib.py:133] step: 482000, training_loss: 5.12090e-02
I0211 23:58:08.759007 22509476222784 run_lib.py:146] step: 482000, eval_loss: 4.88409e-02
I0211 23:58:27.261343 22509476222784 run_lib.py:133] step: 482050, training_loss: 4.25099e-02
I0211 23:58:45.907708 22509476222784 run_lib.py:133] step: 482100, training_loss: 3.37452e-02
I0211 23:58:46.070790 22509476222784 run_lib.py:146] step: 482100, eval_loss: 3.59200e-02
I0211 23:59:04.806404 22509476222784 run_lib.py:133] step: 482150, training_loss: 4.86250e-02
I0211 23:59:23.290785 22509476222784 run_lib.py:133] step: 482200, training_loss: 3.75459e-02
I0211 23:59:23.452671 22509476222784 run_lib.py:146] step: 482200, eval_loss: 4.51958e-02
I0211 23:59:42.008774 22509476222784 run_lib.py:133] step: 482250, training_loss: 5.00014e-02
I0212 00:00:00.479218 22509476222784 run_lib.py:133] step: 482300, training_loss: 3.72014e-02
I0212 00:00:00.646040 22509476222784 run_lib.py:146] step: 482300, eval_loss: 3.49190e-02
I0212 00:00:19.299413 22509476222784 run_lib.py:133] step: 482350, training_loss: 5.03418e-02
I0212 00:00:37.803205 22509476222784 run_lib.py:133] step: 482400, training_loss: 4.52956e-02
I0212 00:00:37.968672 22509476222784 run_lib.py:146] step: 482400, eval_loss: 3.57890e-02
I0212 00:00:56.422959 22509476222784 run_lib.py:133] step: 482450, training_loss: 4.01706e-02
I0212 00:01:15.118869 22509476222784 run_lib.py:133] step: 482500, training_loss: 4.06428e-02
I0212 00:01:15.282965 22509476222784 run_lib.py:146] step: 482500, eval_loss: 4.04267e-02
I0212 00:01:33.792580 22509476222784 run_lib.py:133] step: 482550, training_loss: 3.44665e-02
I0212 00:01:52.429554 22509476222784 run_lib.py:133] step: 482600, training_loss: 4.29545e-02
I0212 00:01:52.590412 22509476222784 run_lib.py:146] step: 482600, eval_loss: 4.18332e-02
I0212 00:02:11.070940 22509476222784 run_lib.py:133] step: 482650, training_loss: 3.32964e-02
I0212 00:02:29.525179 22509476222784 run_lib.py:133] step: 482700, training_loss: 3.28714e-02
I0212 00:02:29.700696 22509476222784 run_lib.py:146] step: 482700, eval_loss: 3.66908e-02
I0212 00:02:48.401247 22509476222784 run_lib.py:133] step: 482750, training_loss: 4.51507e-02
I0212 00:03:06.960472 22509476222784 run_lib.py:133] step: 482800, training_loss: 5.04246e-02
I0212 00:03:07.125375 22509476222784 run_lib.py:146] step: 482800, eval_loss: 4.42689e-02
I0212 00:03:25.625961 22509476222784 run_lib.py:133] step: 482850, training_loss: 4.61342e-02
I0212 00:03:44.261111 22509476222784 run_lib.py:133] step: 482900, training_loss: 4.32750e-02
I0212 00:03:44.431712 22509476222784 run_lib.py:146] step: 482900, eval_loss: 4.45584e-02
I0212 00:04:02.999823 22509476222784 run_lib.py:133] step: 482950, training_loss: 4.71922e-02
I0212 00:04:21.530906 22509476222784 run_lib.py:133] step: 483000, training_loss: 3.16894e-02
I0212 00:04:21.881200 22509476222784 run_lib.py:146] step: 483000, eval_loss: 3.95243e-02
I0212 00:04:40.362727 22509476222784 run_lib.py:133] step: 483050, training_loss: 3.42187e-02
I0212 00:04:58.836746 22509476222784 run_lib.py:133] step: 483100, training_loss: 3.13667e-02
I0212 00:04:59.004696 22509476222784 run_lib.py:146] step: 483100, eval_loss: 3.02770e-02
I0212 00:05:17.434568 22509476222784 run_lib.py:133] step: 483150, training_loss: 4.18654e-02
I0212 00:05:35.954491 22509476222784 run_lib.py:133] step: 483200, training_loss: 4.16650e-02
I0212 00:05:36.139590 22509476222784 run_lib.py:146] step: 483200, eval_loss: 3.22017e-02
I0212 00:05:54.871224 22509476222784 run_lib.py:133] step: 483250, training_loss: 3.62650e-02
I0212 00:06:13.485651 22509476222784 run_lib.py:133] step: 483300, training_loss: 3.94869e-02
I0212 00:06:13.667653 22509476222784 run_lib.py:146] step: 483300, eval_loss: 3.05011e-02
I0212 00:06:32.152603 22509476222784 run_lib.py:133] step: 483350, training_loss: 5.09631e-02
I0212 00:06:50.636910 22509476222784 run_lib.py:133] step: 483400, training_loss: 3.98381e-02
I0212 00:06:50.802699 22509476222784 run_lib.py:146] step: 483400, eval_loss: 3.83497e-02
I0212 00:07:09.456168 22509476222784 run_lib.py:133] step: 483450, training_loss: 4.45944e-02
I0212 00:07:28.081521 22509476222784 run_lib.py:133] step: 483500, training_loss: 3.77198e-02
I0212 00:07:28.244712 22509476222784 run_lib.py:146] step: 483500, eval_loss: 5.02668e-02
I0212 00:07:46.674428 22509476222784 run_lib.py:133] step: 483550, training_loss: 4.15586e-02
I0212 00:08:05.104951 22509476222784 run_lib.py:133] step: 483600, training_loss: 4.48931e-02
I0212 00:08:05.267774 22509476222784 run_lib.py:146] step: 483600, eval_loss: 4.03134e-02
I0212 00:08:23.896259 22509476222784 run_lib.py:133] step: 483650, training_loss: 4.16557e-02
I0212 00:08:42.361721 22509476222784 run_lib.py:133] step: 483700, training_loss: 4.22650e-02
I0212 00:08:42.525972 22509476222784 run_lib.py:146] step: 483700, eval_loss: 3.98725e-02
I0212 00:09:01.200773 22509476222784 run_lib.py:133] step: 483750, training_loss: 5.63301e-02
I0212 00:09:19.782185 22509476222784 run_lib.py:133] step: 483800, training_loss: 4.90879e-02
I0212 00:09:19.946689 22509476222784 run_lib.py:146] step: 483800, eval_loss: 4.52650e-02
I0212 00:09:38.627459 22509476222784 run_lib.py:133] step: 483850, training_loss: 3.42568e-02
I0212 00:09:57.078145 22509476222784 run_lib.py:133] step: 483900, training_loss: 5.44940e-02
I0212 00:09:57.241353 22509476222784 run_lib.py:146] step: 483900, eval_loss: 3.15090e-02
I0212 00:10:15.749187 22509476222784 run_lib.py:133] step: 483950, training_loss: 5.69663e-02
I0212 00:10:34.361644 22509476222784 run_lib.py:133] step: 484000, training_loss: 3.06441e-02
I0212 00:10:34.528722 22509476222784 run_lib.py:146] step: 484000, eval_loss: 4.94229e-02
I0212 00:10:53.080039 22509476222784 run_lib.py:133] step: 484050, training_loss: 2.95529e-02
I0212 00:11:11.631332 22509476222784 run_lib.py:133] step: 484100, training_loss: 5.29299e-02
I0212 00:11:11.791759 22509476222784 run_lib.py:146] step: 484100, eval_loss: 5.03412e-02
I0212 00:11:30.237755 22509476222784 run_lib.py:133] step: 484150, training_loss: 4.72647e-02
I0212 00:11:48.690699 22509476222784 run_lib.py:133] step: 484200, training_loss: 4.55581e-02
I0212 00:11:48.856055 22509476222784 run_lib.py:146] step: 484200, eval_loss: 5.00335e-02
I0212 00:12:07.298132 22509476222784 run_lib.py:133] step: 484250, training_loss: 3.98116e-02
I0212 00:12:25.878520 22509476222784 run_lib.py:133] step: 484300, training_loss: 4.60705e-02
I0212 00:12:26.048561 22509476222784 run_lib.py:146] step: 484300, eval_loss: 3.86397e-02
I0212 00:12:44.540168 22509476222784 run_lib.py:133] step: 484350, training_loss: 4.50106e-02
I0212 00:13:03.054985 22509476222784 run_lib.py:133] step: 484400, training_loss: 3.53890e-02
I0212 00:13:03.220008 22509476222784 run_lib.py:146] step: 484400, eval_loss: 3.75564e-02
I0212 00:13:21.924461 22509476222784 run_lib.py:133] step: 484450, training_loss: 4.51766e-02
I0212 00:13:40.406171 22509476222784 run_lib.py:133] step: 484500, training_loss: 3.81291e-02
I0212 00:13:40.565435 22509476222784 run_lib.py:146] step: 484500, eval_loss: 3.88061e-02
I0212 00:13:59.152258 22509476222784 run_lib.py:133] step: 484550, training_loss: 4.10924e-02
I0212 00:14:17.686159 22509476222784 run_lib.py:133] step: 484600, training_loss: 4.54786e-02
I0212 00:14:17.857852 22509476222784 run_lib.py:146] step: 484600, eval_loss: 3.83140e-02
I0212 00:14:36.416648 22509476222784 run_lib.py:133] step: 484650, training_loss: 4.82168e-02
I0212 00:14:54.953895 22509476222784 run_lib.py:133] step: 484700, training_loss: 3.69300e-02
I0212 00:14:55.128896 22509476222784 run_lib.py:146] step: 484700, eval_loss: 4.22442e-02
I0212 00:15:13.750559 22509476222784 run_lib.py:133] step: 484750, training_loss: 4.07282e-02
I0212 00:15:32.295843 22509476222784 run_lib.py:133] step: 484800, training_loss: 4.48253e-02
I0212 00:15:32.470715 22509476222784 run_lib.py:146] step: 484800, eval_loss: 4.51179e-02
I0212 00:15:50.895399 22509476222784 run_lib.py:133] step: 484850, training_loss: 5.59871e-02
I0212 00:16:09.345724 22509476222784 run_lib.py:133] step: 484900, training_loss: 3.99748e-02
I0212 00:16:09.509871 22509476222784 run_lib.py:146] step: 484900, eval_loss: 4.05520e-02
I0212 00:16:28.262146 22509476222784 run_lib.py:133] step: 484950, training_loss: 4.59528e-02
I0212 00:16:46.704978 22509476222784 run_lib.py:133] step: 485000, training_loss: 4.21243e-02
I0212 00:16:46.866626 22509476222784 run_lib.py:146] step: 485000, eval_loss: 5.37343e-02
I0212 00:17:05.494561 22509476222784 run_lib.py:133] step: 485050, training_loss: 5.50978e-02
I0212 00:17:24.024619 22509476222784 run_lib.py:133] step: 485100, training_loss: 5.37511e-02
I0212 00:17:24.195950 22509476222784 run_lib.py:146] step: 485100, eval_loss: 2.69607e-02
I0212 00:17:42.931218 22509476222784 run_lib.py:133] step: 485150, training_loss: 4.46320e-02
I0212 00:18:01.462187 22509476222784 run_lib.py:133] step: 485200, training_loss: 4.22240e-02
I0212 00:18:01.628713 22509476222784 run_lib.py:146] step: 485200, eval_loss: 4.45809e-02
I0212 00:18:20.281647 22509476222784 run_lib.py:133] step: 485250, training_loss: 3.37646e-02
I0212 00:18:38.773967 22509476222784 run_lib.py:133] step: 485300, training_loss: 4.98838e-02
I0212 00:18:38.938603 22509476222784 run_lib.py:146] step: 485300, eval_loss: 5.60015e-02
I0212 00:18:57.431106 22509476222784 run_lib.py:133] step: 485350, training_loss: 3.43742e-02
I0212 00:19:16.092396 22509476222784 run_lib.py:133] step: 485400, training_loss: 5.58131e-02
I0212 00:19:16.254671 22509476222784 run_lib.py:146] step: 485400, eval_loss: 4.53861e-02
I0212 00:19:34.789631 22509476222784 run_lib.py:133] step: 485450, training_loss: 4.91145e-02
I0212 00:19:53.269991 22509476222784 run_lib.py:133] step: 485500, training_loss: 3.68298e-02
I0212 00:19:53.430602 22509476222784 run_lib.py:146] step: 485500, eval_loss: 4.23174e-02
I0212 00:20:12.096374 22509476222784 run_lib.py:133] step: 485550, training_loss: 3.91041e-02
I0212 00:20:30.719669 22509476222784 run_lib.py:133] step: 485600, training_loss: 5.49103e-02
I0212 00:20:30.884825 22509476222784 run_lib.py:146] step: 485600, eval_loss: 3.79191e-02
I0212 00:20:49.354918 22509476222784 run_lib.py:133] step: 485650, training_loss: 4.10730e-02
I0212 00:21:07.910990 22509476222784 run_lib.py:133] step: 485700, training_loss: 4.79791e-02
I0212 00:21:08.090646 22509476222784 run_lib.py:146] step: 485700, eval_loss: 3.93551e-02
I0212 00:21:26.481459 22509476222784 run_lib.py:133] step: 485750, training_loss: 3.97708e-02
I0212 00:21:45.072861 22509476222784 run_lib.py:133] step: 485800, training_loss: 5.67548e-02
I0212 00:21:45.236835 22509476222784 run_lib.py:146] step: 485800, eval_loss: 3.85291e-02
I0212 00:22:03.766182 22509476222784 run_lib.py:133] step: 485850, training_loss: 4.71886e-02
I0212 00:22:22.232750 22509476222784 run_lib.py:133] step: 485900, training_loss: 4.57676e-02
I0212 00:22:22.395668 22509476222784 run_lib.py:146] step: 485900, eval_loss: 3.91416e-02
I0212 00:22:40.895118 22509476222784 run_lib.py:133] step: 485950, training_loss: 3.50318e-02
I0212 00:22:59.498888 22509476222784 run_lib.py:133] step: 486000, training_loss: 4.59333e-02
I0212 00:22:59.670900 22509476222784 run_lib.py:146] step: 486000, eval_loss: 3.30753e-02
I0212 00:23:18.158150 22509476222784 run_lib.py:133] step: 486050, training_loss: 5.46174e-02
I0212 00:23:36.663403 22509476222784 run_lib.py:133] step: 486100, training_loss: 3.61997e-02
I0212 00:23:36.827796 22509476222784 run_lib.py:146] step: 486100, eval_loss: 5.38167e-02
I0212 00:23:55.254507 22509476222784 run_lib.py:133] step: 486150, training_loss: 3.45426e-02
I0212 00:24:13.746716 22509476222784 run_lib.py:133] step: 486200, training_loss: 3.79488e-02
I0212 00:24:13.910875 22509476222784 run_lib.py:146] step: 486200, eval_loss: 4.54270e-02
I0212 00:24:32.535590 22509476222784 run_lib.py:133] step: 486250, training_loss: 3.70118e-02
I0212 00:24:51.239322 22509476222784 run_lib.py:133] step: 486300, training_loss: 4.27301e-02
I0212 00:24:51.431900 22509476222784 run_lib.py:146] step: 486300, eval_loss: 4.40095e-02
I0212 00:25:09.912427 22509476222784 run_lib.py:133] step: 486350, training_loss: 4.31086e-02
I0212 00:25:28.365694 22509476222784 run_lib.py:133] step: 486400, training_loss: 4.97927e-02
I0212 00:25:28.526408 22509476222784 run_lib.py:146] step: 486400, eval_loss: 3.84179e-02
I0212 00:25:47.174870 22509476222784 run_lib.py:133] step: 486450, training_loss: 3.68792e-02
I0212 00:26:05.697132 22509476222784 run_lib.py:133] step: 486500, training_loss: 4.60951e-02
I0212 00:26:05.859621 22509476222784 run_lib.py:146] step: 486500, eval_loss: 4.23479e-02
I0212 00:26:24.539548 22509476222784 run_lib.py:133] step: 486550, training_loss: 4.72588e-02
I0212 00:26:43.129262 22509476222784 run_lib.py:133] step: 486600, training_loss: 4.86773e-02
I0212 00:26:43.293629 22509476222784 run_lib.py:146] step: 486600, eval_loss: 4.47966e-02
I0212 00:27:01.937883 22509476222784 run_lib.py:133] step: 486650, training_loss: 4.92860e-02
I0212 00:27:20.438385 22509476222784 run_lib.py:133] step: 486700, training_loss: 5.55816e-02
I0212 00:27:20.601553 22509476222784 run_lib.py:146] step: 486700, eval_loss: 4.66620e-02
I0212 00:27:39.065641 22509476222784 run_lib.py:133] step: 486750, training_loss: 4.26953e-02
I0212 00:27:57.681252 22509476222784 run_lib.py:133] step: 486800, training_loss: 3.49486e-02
I0212 00:27:57.843012 22509476222784 run_lib.py:146] step: 486800, eval_loss: 4.81217e-02
I0212 00:28:16.347010 22509476222784 run_lib.py:133] step: 486850, training_loss: 5.22569e-02
I0212 00:28:35.111115 22509476222784 run_lib.py:133] step: 486900, training_loss: 4.36131e-02
I0212 00:28:35.273900 22509476222784 run_lib.py:146] step: 486900, eval_loss: 3.81981e-02
I0212 00:28:53.813753 22509476222784 run_lib.py:133] step: 486950, training_loss: 4.30934e-02
I0212 00:29:12.294827 22509476222784 run_lib.py:133] step: 487000, training_loss: 4.99598e-02
I0212 00:29:12.464505 22509476222784 run_lib.py:146] step: 487000, eval_loss: 3.30031e-02
I0212 00:29:31.069253 22509476222784 run_lib.py:133] step: 487050, training_loss: 4.71861e-02
I0212 00:29:49.574265 22509476222784 run_lib.py:133] step: 487100, training_loss: 4.75542e-02
I0212 00:29:49.750519 22509476222784 run_lib.py:146] step: 487100, eval_loss: 5.21232e-02
I0212 00:30:08.239626 22509476222784 run_lib.py:133] step: 487150, training_loss: 3.37650e-02
I0212 00:30:26.951730 22509476222784 run_lib.py:133] step: 487200, training_loss: 3.84666e-02
I0212 00:30:27.172701 22509476222784 run_lib.py:146] step: 487200, eval_loss: 3.35830e-02
I0212 00:30:45.612248 22509476222784 run_lib.py:133] step: 487250, training_loss: 4.68283e-02
I0212 00:31:04.027487 22509476222784 run_lib.py:133] step: 487300, training_loss: 5.55695e-02
I0212 00:31:04.190571 22509476222784 run_lib.py:146] step: 487300, eval_loss: 5.13761e-02
I0212 00:31:22.810402 22509476222784 run_lib.py:133] step: 487350, training_loss: 5.47403e-02
I0212 00:31:41.313328 22509476222784 run_lib.py:133] step: 487400, training_loss: 4.73195e-02
I0212 00:31:41.480862 22509476222784 run_lib.py:146] step: 487400, eval_loss: 4.25889e-02
I0212 00:32:00.038707 22509476222784 run_lib.py:133] step: 487450, training_loss: 4.57918e-02
I0212 00:32:18.559895 22509476222784 run_lib.py:133] step: 487500, training_loss: 4.64651e-02
I0212 00:32:18.726655 22509476222784 run_lib.py:146] step: 487500, eval_loss: 4.38133e-02
I0212 00:32:37.392203 22509476222784 run_lib.py:133] step: 487550, training_loss: 4.06502e-02
I0212 00:32:55.935686 22509476222784 run_lib.py:133] step: 487600, training_loss: 3.80354e-02
I0212 00:32:56.099933 22509476222784 run_lib.py:146] step: 487600, eval_loss: 5.05947e-02
I0212 00:33:14.611033 22509476222784 run_lib.py:133] step: 487650, training_loss: 5.45904e-02
I0212 00:33:33.223948 22509476222784 run_lib.py:133] step: 487700, training_loss: 4.11560e-02
I0212 00:33:33.388131 22509476222784 run_lib.py:146] step: 487700, eval_loss: 4.22607e-02
I0212 00:33:52.121410 22509476222784 run_lib.py:133] step: 487750, training_loss: 5.80896e-02
I0212 00:34:10.634353 22509476222784 run_lib.py:133] step: 487800, training_loss: 3.97037e-02
I0212 00:34:10.794309 22509476222784 run_lib.py:146] step: 487800, eval_loss: 4.43037e-02
I0212 00:34:29.442558 22509476222784 run_lib.py:133] step: 487850, training_loss: 4.78678e-02
I0212 00:34:47.897367 22509476222784 run_lib.py:133] step: 487900, training_loss: 3.30775e-02
I0212 00:34:48.085510 22509476222784 run_lib.py:146] step: 487900, eval_loss: 3.68289e-02
I0212 00:35:06.758274 22509476222784 run_lib.py:133] step: 487950, training_loss: 4.16879e-02
I0212 00:35:25.295981 22509476222784 run_lib.py:133] step: 488000, training_loss: 3.85608e-02
I0212 00:35:25.461622 22509476222784 run_lib.py:146] step: 488000, eval_loss: 4.60638e-02
I0212 00:35:44.157133 22509476222784 run_lib.py:133] step: 488050, training_loss: 4.87745e-02
I0212 00:36:02.629250 22509476222784 run_lib.py:133] step: 488100, training_loss: 5.17587e-02
I0212 00:36:02.793499 22509476222784 run_lib.py:146] step: 488100, eval_loss: 3.74505e-02
I0212 00:36:21.244758 22509476222784 run_lib.py:133] step: 488150, training_loss: 5.84447e-02
I0212 00:36:39.830203 22509476222784 run_lib.py:133] step: 488200, training_loss: 3.67983e-02
I0212 00:36:39.995609 22509476222784 run_lib.py:146] step: 488200, eval_loss: 5.08514e-02
I0212 00:36:58.536739 22509476222784 run_lib.py:133] step: 488250, training_loss: 3.18791e-02
I0212 00:37:16.998412 22509476222784 run_lib.py:133] step: 488300, training_loss: 4.51020e-02
I0212 00:37:17.159860 22509476222784 run_lib.py:146] step: 488300, eval_loss: 3.71980e-02
I0212 00:37:35.772428 22509476222784 run_lib.py:133] step: 488350, training_loss: 4.01855e-02
I0212 00:37:54.264716 22509476222784 run_lib.py:133] step: 488400, training_loss: 3.69665e-02
I0212 00:37:54.428685 22509476222784 run_lib.py:146] step: 488400, eval_loss: 4.35366e-02
I0212 00:38:13.027346 22509476222784 run_lib.py:133] step: 488450, training_loss: 4.93430e-02
I0212 00:38:31.491801 22509476222784 run_lib.py:133] step: 488500, training_loss: 4.45085e-02
I0212 00:38:31.672698 22509476222784 run_lib.py:146] step: 488500, eval_loss: 3.00014e-02
I0212 00:38:50.214240 22509476222784 run_lib.py:133] step: 488550, training_loss: 5.17537e-02
I0212 00:39:08.936802 22509476222784 run_lib.py:133] step: 488600, training_loss: 4.57010e-02
I0212 00:39:09.100994 22509476222784 run_lib.py:146] step: 488600, eval_loss: 3.82795e-02
I0212 00:39:27.607730 22509476222784 run_lib.py:133] step: 488650, training_loss: 4.52269e-02
I0212 00:39:46.078666 22509476222784 run_lib.py:133] step: 488700, training_loss: 3.32845e-02
I0212 00:39:46.241810 22509476222784 run_lib.py:146] step: 488700, eval_loss: 4.18757e-02
I0212 00:40:04.755462 22509476222784 run_lib.py:133] step: 488750, training_loss: 3.79544e-02
I0212 00:40:23.414314 22509476222784 run_lib.py:133] step: 488800, training_loss: 3.53602e-02
I0212 00:40:23.577792 22509476222784 run_lib.py:146] step: 488800, eval_loss: 4.11883e-02
I0212 00:40:42.136939 22509476222784 run_lib.py:133] step: 488850, training_loss: 3.73748e-02
I0212 00:41:00.703602 22509476222784 run_lib.py:133] step: 488900, training_loss: 3.78722e-02
I0212 00:41:00.868607 22509476222784 run_lib.py:146] step: 488900, eval_loss: 3.14488e-02
I0212 00:41:19.314147 22509476222784 run_lib.py:133] step: 488950, training_loss: 4.81078e-02
I0212 00:41:37.778543 22509476222784 run_lib.py:133] step: 489000, training_loss: 4.76110e-02
I0212 00:41:37.944054 22509476222784 run_lib.py:146] step: 489000, eval_loss: 5.24864e-02
I0212 00:41:56.608092 22509476222784 run_lib.py:133] step: 489050, training_loss: 3.93973e-02
I0212 00:42:15.288423 22509476222784 run_lib.py:133] step: 489100, training_loss: 4.64023e-02
I0212 00:42:15.452776 22509476222784 run_lib.py:146] step: 489100, eval_loss: 5.27519e-02
I0212 00:42:33.843592 22509476222784 run_lib.py:133] step: 489150, training_loss: 5.05994e-02
I0212 00:42:52.192307 22509476222784 run_lib.py:133] step: 489200, training_loss: 3.77367e-02
I0212 00:42:52.375471 22509476222784 run_lib.py:146] step: 489200, eval_loss: 4.30907e-02
I0212 00:43:10.878741 22509476222784 run_lib.py:133] step: 489250, training_loss: 4.51266e-02
I0212 00:43:29.331416 22509476222784 run_lib.py:133] step: 489300, training_loss: 4.58897e-02
I0212 00:43:29.493679 22509476222784 run_lib.py:146] step: 489300, eval_loss: 3.47194e-02
I0212 00:43:48.116909 22509476222784 run_lib.py:133] step: 489350, training_loss: 4.37430e-02
I0212 00:44:06.650532 22509476222784 run_lib.py:133] step: 489400, training_loss: 3.90423e-02
I0212 00:44:06.831008 22509476222784 run_lib.py:146] step: 489400, eval_loss: 3.90635e-02
I0212 00:44:25.547581 22509476222784 run_lib.py:133] step: 489450, training_loss: 4.46967e-02
I0212 00:44:44.058451 22509476222784 run_lib.py:133] step: 489500, training_loss: 4.95709e-02
I0212 00:44:44.227510 22509476222784 run_lib.py:146] step: 489500, eval_loss: 4.62103e-02
I0212 00:45:02.652892 22509476222784 run_lib.py:133] step: 489550, training_loss: 3.87621e-02
I0212 00:45:21.347052 22509476222784 run_lib.py:133] step: 489600, training_loss: 4.48182e-02
I0212 00:45:21.515905 22509476222784 run_lib.py:146] step: 489600, eval_loss: 4.22447e-02
I0212 00:45:40.049251 22509476222784 run_lib.py:133] step: 489650, training_loss: 4.99418e-02
I0212 00:45:58.765031 22509476222784 run_lib.py:133] step: 489700, training_loss: 4.16183e-02
I0212 00:45:58.932436 22509476222784 run_lib.py:146] step: 489700, eval_loss: 3.84130e-02
I0212 00:46:17.444213 22509476222784 run_lib.py:133] step: 489750, training_loss: 5.01537e-02
I0212 00:46:35.989169 22509476222784 run_lib.py:133] step: 489800, training_loss: 5.20816e-02
I0212 00:46:36.150659 22509476222784 run_lib.py:146] step: 489800, eval_loss: 3.81907e-02
I0212 00:46:54.811590 22509476222784 run_lib.py:133] step: 489850, training_loss: 4.27391e-02
I0212 00:47:13.328548 22509476222784 run_lib.py:133] step: 489900, training_loss: 4.82538e-02
I0212 00:47:13.497650 22509476222784 run_lib.py:146] step: 489900, eval_loss: 4.36412e-02
I0212 00:47:32.038713 22509476222784 run_lib.py:133] step: 489950, training_loss: 3.37885e-02
I0212 00:47:50.759162 22509476222784 run_lib.py:133] step: 490000, training_loss: 4.43176e-02
I0212 00:47:51.654786 22509476222784 run_lib.py:146] step: 490000, eval_loss: 5.50150e-02
I0212 00:48:12.802100 22509476222784 run_lib.py:133] step: 490050, training_loss: 3.83287e-02
I0212 00:48:31.259381 22509476222784 run_lib.py:133] step: 490100, training_loss: 4.29278e-02
I0212 00:48:31.424621 22509476222784 run_lib.py:146] step: 490100, eval_loss: 5.31243e-02
I0212 00:48:50.013323 22509476222784 run_lib.py:133] step: 490150, training_loss: 3.45779e-02
I0212 00:49:08.564142 22509476222784 run_lib.py:133] step: 490200, training_loss: 5.24284e-02
I0212 00:49:08.728781 22509476222784 run_lib.py:146] step: 490200, eval_loss: 6.34290e-02
I0212 00:49:27.253721 22509476222784 run_lib.py:133] step: 490250, training_loss: 3.72359e-02
I0212 00:49:45.783525 22509476222784 run_lib.py:133] step: 490300, training_loss: 4.08485e-02
I0212 00:49:45.945680 22509476222784 run_lib.py:146] step: 490300, eval_loss: 3.72897e-02
I0212 00:50:04.627578 22509476222784 run_lib.py:133] step: 490350, training_loss: 4.74726e-02
I0212 00:50:23.115868 22509476222784 run_lib.py:133] step: 490400, training_loss: 4.20193e-02
I0212 00:50:23.281772 22509476222784 run_lib.py:146] step: 490400, eval_loss: 4.67570e-02
I0212 00:50:41.817853 22509476222784 run_lib.py:133] step: 490450, training_loss: 4.08529e-02
I0212 00:51:00.308922 22509476222784 run_lib.py:133] step: 490500, training_loss: 4.28645e-02
I0212 00:51:00.486999 22509476222784 run_lib.py:146] step: 490500, eval_loss: 3.84045e-02
I0212 00:51:19.035272 22509476222784 run_lib.py:133] step: 490550, training_loss: 4.01023e-02
I0212 00:51:37.576128 22509476222784 run_lib.py:133] step: 490600, training_loss: 4.64332e-02
I0212 00:51:37.740900 22509476222784 run_lib.py:146] step: 490600, eval_loss: 3.96779e-02
I0212 00:51:56.434890 22509476222784 run_lib.py:133] step: 490650, training_loss: 4.29028e-02
I0212 00:52:15.036795 22509476222784 run_lib.py:133] step: 490700, training_loss: 3.72181e-02
I0212 00:52:15.206006 22509476222784 run_lib.py:146] step: 490700, eval_loss: 4.46378e-02
I0212 00:52:33.782455 22509476222784 run_lib.py:133] step: 490750, training_loss: 3.73954e-02
I0212 00:52:52.350114 22509476222784 run_lib.py:133] step: 490800, training_loss: 4.06041e-02
I0212 00:52:52.511875 22509476222784 run_lib.py:146] step: 490800, eval_loss: 3.64604e-02
I0212 00:53:11.172088 22509476222784 run_lib.py:133] step: 490850, training_loss: 3.84008e-02
I0212 00:53:29.699126 22509476222784 run_lib.py:133] step: 490900, training_loss: 3.96806e-02
I0212 00:53:29.864789 22509476222784 run_lib.py:146] step: 490900, eval_loss: 5.05882e-02
I0212 00:53:48.496344 22509476222784 run_lib.py:133] step: 490950, training_loss: 3.88168e-02
I0212 00:54:07.019768 22509476222784 run_lib.py:133] step: 491000, training_loss: 4.57995e-02
I0212 00:54:07.191485 22509476222784 run_lib.py:146] step: 491000, eval_loss: 4.39287e-02
I0212 00:54:25.895453 22509476222784 run_lib.py:133] step: 491050, training_loss: 3.45351e-02
I0212 00:54:44.406059 22509476222784 run_lib.py:133] step: 491100, training_loss: 3.70783e-02
I0212 00:54:44.581940 22509476222784 run_lib.py:146] step: 491100, eval_loss: 4.50870e-02
I0212 00:55:03.246350 22509476222784 run_lib.py:133] step: 491150, training_loss: 4.45472e-02
I0212 00:55:21.732971 22509476222784 run_lib.py:133] step: 491200, training_loss: 5.07170e-02
I0212 00:55:21.898391 22509476222784 run_lib.py:146] step: 491200, eval_loss: 4.22544e-02
I0212 00:55:40.354979 22509476222784 run_lib.py:133] step: 491250, training_loss: 4.78384e-02
I0212 00:55:59.018825 22509476222784 run_lib.py:133] step: 491300, training_loss: 3.49730e-02
I0212 00:55:59.188825 22509476222784 run_lib.py:146] step: 491300, eval_loss: 4.20504e-02
I0212 00:56:17.707320 22509476222784 run_lib.py:133] step: 491350, training_loss: 5.19898e-02
I0212 00:56:36.173603 22509476222784 run_lib.py:133] step: 491400, training_loss: 4.59947e-02
I0212 00:56:36.337689 22509476222784 run_lib.py:146] step: 491400, eval_loss: 3.22398e-02
I0212 00:56:54.897365 22509476222784 run_lib.py:133] step: 491450, training_loss: 4.94009e-02
I0212 00:57:13.515675 22509476222784 run_lib.py:133] step: 491500, training_loss: 3.85095e-02
I0212 00:57:13.679769 22509476222784 run_lib.py:146] step: 491500, eval_loss: 3.19560e-02
I0212 00:57:32.200699 22509476222784 run_lib.py:133] step: 491550, training_loss: 3.95875e-02
I0212 00:57:50.745297 22509476222784 run_lib.py:133] step: 491600, training_loss: 3.71394e-02
I0212 00:57:50.907984 22509476222784 run_lib.py:146] step: 491600, eval_loss: 3.37238e-02
I0212 00:58:09.314904 22509476222784 run_lib.py:133] step: 491650, training_loss: 3.43962e-02
I0212 00:58:27.967744 22509476222784 run_lib.py:133] step: 491700, training_loss: 3.48715e-02
I0212 00:58:28.128768 22509476222784 run_lib.py:146] step: 491700, eval_loss: 3.42337e-02
I0212 00:58:46.661734 22509476222784 run_lib.py:133] step: 491750, training_loss: 4.11457e-02
I0212 00:59:05.130758 22509476222784 run_lib.py:133] step: 491800, training_loss: 2.75176e-02
I0212 00:59:05.313893 22509476222784 run_lib.py:146] step: 491800, eval_loss: 2.88230e-02
I0212 00:59:23.834099 22509476222784 run_lib.py:133] step: 491850, training_loss: 4.93137e-02
I0212 00:59:42.590052 22509476222784 run_lib.py:133] step: 491900, training_loss: 3.81788e-02
I0212 00:59:42.763665 22509476222784 run_lib.py:146] step: 491900, eval_loss: 4.40787e-02
I0212 01:00:01.256025 22509476222784 run_lib.py:133] step: 491950, training_loss: 3.45571e-02
I0212 01:00:19.749928 22509476222784 run_lib.py:133] step: 492000, training_loss: 3.49886e-02
I0212 01:00:19.912581 22509476222784 run_lib.py:146] step: 492000, eval_loss: 3.69840e-02
I0212 01:00:38.288590 22509476222784 run_lib.py:133] step: 492050, training_loss: 4.85455e-02
I0212 01:00:56.775072 22509476222784 run_lib.py:133] step: 492100, training_loss: 3.29367e-02
I0212 01:00:56.938944 22509476222784 run_lib.py:146] step: 492100, eval_loss: 3.48603e-02
I0212 01:01:15.672440 22509476222784 run_lib.py:133] step: 492150, training_loss: 4.41302e-02
I0212 01:01:34.280042 22509476222784 run_lib.py:133] step: 492200, training_loss: 3.52501e-02
I0212 01:01:34.441667 22509476222784 run_lib.py:146] step: 492200, eval_loss: 3.89240e-02
I0212 01:01:52.947214 22509476222784 run_lib.py:133] step: 492250, training_loss: 2.50602e-02
I0212 01:02:11.394487 22509476222784 run_lib.py:133] step: 492300, training_loss: 5.08085e-02
I0212 01:02:11.558521 22509476222784 run_lib.py:146] step: 492300, eval_loss: 4.58886e-02
I0212 01:02:30.129223 22509476222784 run_lib.py:133] step: 492350, training_loss: 2.88027e-02
I0212 01:02:48.563437 22509476222784 run_lib.py:133] step: 492400, training_loss: 4.56227e-02
I0212 01:02:48.728597 22509476222784 run_lib.py:146] step: 492400, eval_loss: 3.95124e-02
I0212 01:03:07.382212 22509476222784 run_lib.py:133] step: 492450, training_loss: 3.46924e-02
I0212 01:03:25.899134 22509476222784 run_lib.py:133] step: 492500, training_loss: 3.72824e-02
I0212 01:03:26.063634 22509476222784 run_lib.py:146] step: 492500, eval_loss: 5.27494e-02
I0212 01:03:44.659768 22509476222784 run_lib.py:133] step: 492550, training_loss: 3.36605e-02
I0212 01:04:03.147713 22509476222784 run_lib.py:133] step: 492600, training_loss: 4.09975e-02
I0212 01:04:03.311920 22509476222784 run_lib.py:146] step: 492600, eval_loss: 4.66448e-02
I0212 01:04:21.908726 22509476222784 run_lib.py:133] step: 492650, training_loss: 3.93520e-02
I0212 01:04:40.671598 22509476222784 run_lib.py:133] step: 492700, training_loss: 5.28451e-02
I0212 01:04:40.832598 22509476222784 run_lib.py:146] step: 492700, eval_loss: 3.48179e-02
I0212 01:04:59.264793 22509476222784 run_lib.py:133] step: 492750, training_loss: 3.06267e-02
I0212 01:05:17.925742 22509476222784 run_lib.py:133] step: 492800, training_loss: 3.54931e-02
I0212 01:05:18.091871 22509476222784 run_lib.py:146] step: 492800, eval_loss: 4.74874e-02
I0212 01:05:36.506386 22509476222784 run_lib.py:133] step: 492850, training_loss: 4.42398e-02
I0212 01:05:55.003181 22509476222784 run_lib.py:133] step: 492900, training_loss: 3.85550e-02
I0212 01:05:55.184673 22509476222784 run_lib.py:146] step: 492900, eval_loss: 4.61856e-02
I0212 01:06:13.876842 22509476222784 run_lib.py:133] step: 492950, training_loss: 4.15462e-02
I0212 01:06:32.380559 22509476222784 run_lib.py:133] step: 493000, training_loss: 4.11876e-02
I0212 01:06:32.545947 22509476222784 run_lib.py:146] step: 493000, eval_loss: 4.55023e-02
I0212 01:06:51.026240 22509476222784 run_lib.py:133] step: 493050, training_loss: 3.72718e-02
I0212 01:07:09.617231 22509476222784 run_lib.py:133] step: 493100, training_loss: 4.13573e-02
I0212 01:07:09.776579 22509476222784 run_lib.py:146] step: 493100, eval_loss: 4.26899e-02
I0212 01:07:28.264275 22509476222784 run_lib.py:133] step: 493150, training_loss: 5.22487e-02
I0212 01:07:46.748250 22509476222784 run_lib.py:133] step: 493200, training_loss: 5.36839e-02
I0212 01:07:46.922866 22509476222784 run_lib.py:146] step: 493200, eval_loss: 3.63762e-02
I0212 01:08:05.548300 22509476222784 run_lib.py:133] step: 493250, training_loss: 4.42201e-02
I0212 01:08:24.049155 22509476222784 run_lib.py:133] step: 493300, training_loss: 4.01784e-02
I0212 01:08:24.218037 22509476222784 run_lib.py:146] step: 493300, eval_loss: 3.85517e-02
I0212 01:08:42.672953 22509476222784 run_lib.py:133] step: 493350, training_loss: 4.27070e-02
I0212 01:09:01.140189 22509476222784 run_lib.py:133] step: 493400, training_loss: 4.12218e-02
I0212 01:09:01.303638 22509476222784 run_lib.py:146] step: 493400, eval_loss: 5.13125e-02
I0212 01:09:20.019001 22509476222784 run_lib.py:133] step: 493450, training_loss: 3.94133e-02
I0212 01:09:38.681146 22509476222784 run_lib.py:133] step: 493500, training_loss: 4.29835e-02
I0212 01:09:38.844870 22509476222784 run_lib.py:146] step: 493500, eval_loss: 3.31496e-02
I0212 01:09:57.311377 22509476222784 run_lib.py:133] step: 493550, training_loss: 4.27067e-02
I0212 01:10:15.681237 22509476222784 run_lib.py:133] step: 493600, training_loss: 2.98246e-02
I0212 01:10:15.841748 22509476222784 run_lib.py:146] step: 493600, eval_loss: 4.00260e-02
I0212 01:10:34.486870 22509476222784 run_lib.py:133] step: 493650, training_loss: 3.21931e-02
I0212 01:10:52.967734 22509476222784 run_lib.py:133] step: 493700, training_loss: 4.48698e-02
I0212 01:10:53.142895 22509476222784 run_lib.py:146] step: 493700, eval_loss: 5.12762e-02
I0212 01:11:11.851210 22509476222784 run_lib.py:133] step: 493750, training_loss: 5.75741e-02
I0212 01:11:30.392048 22509476222784 run_lib.py:133] step: 493800, training_loss: 4.10728e-02
I0212 01:11:30.558617 22509476222784 run_lib.py:146] step: 493800, eval_loss: 3.31292e-02
I0212 01:11:49.219014 22509476222784 run_lib.py:133] step: 493850, training_loss: 4.47700e-02
I0212 01:12:07.655949 22509476222784 run_lib.py:133] step: 493900, training_loss: 4.57357e-02
I0212 01:12:07.825280 22509476222784 run_lib.py:146] step: 493900, eval_loss: 5.08373e-02
I0212 01:12:26.475556 22509476222784 run_lib.py:133] step: 493950, training_loss: 3.70440e-02
I0212 01:12:45.026370 22509476222784 run_lib.py:133] step: 494000, training_loss: 2.95468e-02
I0212 01:12:45.190970 22509476222784 run_lib.py:146] step: 494000, eval_loss: 3.78694e-02
I0212 01:13:03.751849 22509476222784 run_lib.py:133] step: 494050, training_loss: 4.37563e-02
I0212 01:13:22.457620 22509476222784 run_lib.py:133] step: 494100, training_loss: 5.24360e-02
I0212 01:13:22.618604 22509476222784 run_lib.py:146] step: 494100, eval_loss: 5.19254e-02
I0212 01:13:41.118024 22509476222784 run_lib.py:133] step: 494150, training_loss: 4.66366e-02
I0212 01:13:59.622386 22509476222784 run_lib.py:133] step: 494200, training_loss: 3.45262e-02
I0212 01:13:59.792765 22509476222784 run_lib.py:146] step: 494200, eval_loss: 6.05045e-02
I0212 01:14:18.362978 22509476222784 run_lib.py:133] step: 494250, training_loss: 4.53813e-02
I0212 01:14:36.935989 22509476222784 run_lib.py:133] step: 494300, training_loss: 3.75695e-02
I0212 01:14:37.147623 22509476222784 run_lib.py:146] step: 494300, eval_loss: 5.07773e-02
I0212 01:14:55.831015 22509476222784 run_lib.py:133] step: 494350, training_loss: 5.55943e-02
I0212 01:15:14.336709 22509476222784 run_lib.py:133] step: 494400, training_loss: 4.41617e-02
I0212 01:15:14.507107 22509476222784 run_lib.py:146] step: 494400, eval_loss: 4.63310e-02
I0212 01:15:33.058777 22509476222784 run_lib.py:133] step: 494450, training_loss: 5.25486e-02
I0212 01:15:51.807144 22509476222784 run_lib.py:133] step: 494500, training_loss: 5.36813e-02
I0212 01:15:51.969743 22509476222784 run_lib.py:146] step: 494500, eval_loss: 4.06300e-02
I0212 01:16:10.445976 22509476222784 run_lib.py:133] step: 494550, training_loss: 3.63104e-02
I0212 01:16:29.000255 22509476222784 run_lib.py:133] step: 494600, training_loss: 4.08824e-02
I0212 01:16:29.165943 22509476222784 run_lib.py:146] step: 494600, eval_loss: 3.74837e-02
I0212 01:16:47.673972 22509476222784 run_lib.py:133] step: 494650, training_loss: 4.10952e-02
I0212 01:17:06.362905 22509476222784 run_lib.py:133] step: 494700, training_loss: 4.00256e-02
I0212 01:17:06.527846 22509476222784 run_lib.py:146] step: 494700, eval_loss: 3.43602e-02
I0212 01:17:25.018203 22509476222784 run_lib.py:133] step: 494750, training_loss: 4.95484e-02
I0212 01:17:43.600289 22509476222784 run_lib.py:133] step: 494800, training_loss: 5.25803e-02
I0212 01:17:43.765306 22509476222784 run_lib.py:146] step: 494800, eval_loss: 5.09947e-02
I0212 01:18:02.187219 22509476222784 run_lib.py:133] step: 494850, training_loss: 3.38889e-02
I0212 01:18:20.786587 22509476222784 run_lib.py:133] step: 494900, training_loss: 5.31546e-02
I0212 01:18:20.951048 22509476222784 run_lib.py:146] step: 494900, eval_loss: 5.21766e-02
I0212 01:18:39.640717 22509476222784 run_lib.py:133] step: 494950, training_loss: 4.97524e-02
I0212 01:18:58.271596 22509476222784 run_lib.py:133] step: 495000, training_loss: 4.87793e-02
I0212 01:18:58.431287 22509476222784 run_lib.py:146] step: 495000, eval_loss: 4.74125e-02
I0212 01:19:16.952757 22509476222784 run_lib.py:133] step: 495050, training_loss: 4.53639e-02
I0212 01:19:35.502681 22509476222784 run_lib.py:133] step: 495100, training_loss: 5.12717e-02
I0212 01:19:35.680886 22509476222784 run_lib.py:146] step: 495100, eval_loss: 5.28370e-02
I0212 01:19:54.403260 22509476222784 run_lib.py:133] step: 495150, training_loss: 3.78759e-02
I0212 01:20:12.955704 22509476222784 run_lib.py:133] step: 495200, training_loss: 4.16132e-02
I0212 01:20:13.121526 22509476222784 run_lib.py:146] step: 495200, eval_loss: 4.34605e-02
I0212 01:20:31.731737 22509476222784 run_lib.py:133] step: 495250, training_loss: 4.03822e-02
I0212 01:20:50.174177 22509476222784 run_lib.py:133] step: 495300, training_loss: 4.58699e-02
I0212 01:20:50.337475 22509476222784 run_lib.py:146] step: 495300, eval_loss: 4.23899e-02
I0212 01:21:08.984909 22509476222784 run_lib.py:133] step: 495350, training_loss: 4.01350e-02
I0212 01:21:27.507213 22509476222784 run_lib.py:133] step: 495400, training_loss: 4.12709e-02
I0212 01:21:27.672981 22509476222784 run_lib.py:146] step: 495400, eval_loss: 4.59537e-02
I0212 01:21:46.215100 22509476222784 run_lib.py:133] step: 495450, training_loss: 3.46660e-02
I0212 01:22:04.912780 22509476222784 run_lib.py:133] step: 495500, training_loss: 4.11271e-02
I0212 01:22:05.135705 22509476222784 run_lib.py:146] step: 495500, eval_loss: 4.13336e-02
I0212 01:22:23.619035 22509476222784 run_lib.py:133] step: 495550, training_loss: 3.26650e-02
I0212 01:22:42.201218 22509476222784 run_lib.py:133] step: 495600, training_loss: 3.61494e-02
I0212 01:22:42.363626 22509476222784 run_lib.py:146] step: 495600, eval_loss: 3.77204e-02
I0212 01:23:00.768091 22509476222784 run_lib.py:133] step: 495650, training_loss: 5.10058e-02
I0212 01:23:19.337353 22509476222784 run_lib.py:133] step: 495700, training_loss: 4.48137e-02
I0212 01:23:19.507657 22509476222784 run_lib.py:146] step: 495700, eval_loss: 6.24358e-02
I0212 01:23:38.179636 22509476222784 run_lib.py:133] step: 495750, training_loss: 3.72409e-02
I0212 01:23:56.719537 22509476222784 run_lib.py:133] step: 495800, training_loss: 3.52316e-02
I0212 01:23:56.883693 22509476222784 run_lib.py:146] step: 495800, eval_loss: 4.03855e-02
I0212 01:24:15.339393 22509476222784 run_lib.py:133] step: 495850, training_loss: 3.53175e-02
I0212 01:24:34.010617 22509476222784 run_lib.py:133] step: 495900, training_loss: 5.03954e-02
I0212 01:24:34.177829 22509476222784 run_lib.py:146] step: 495900, eval_loss: 3.38640e-02
I0212 01:24:52.746054 22509476222784 run_lib.py:133] step: 495950, training_loss: 4.63998e-02
I0212 01:25:11.243795 22509476222784 run_lib.py:133] step: 496000, training_loss: 4.11951e-02
I0212 01:25:11.592816 22509476222784 run_lib.py:146] step: 496000, eval_loss: 5.20908e-02
I0212 01:25:30.108852 22509476222784 run_lib.py:133] step: 496050, training_loss: 3.12119e-02
I0212 01:25:48.605698 22509476222784 run_lib.py:133] step: 496100, training_loss: 4.58730e-02
I0212 01:25:48.769784 22509476222784 run_lib.py:146] step: 496100, eval_loss: 3.74807e-02
I0212 01:26:07.227163 22509476222784 run_lib.py:133] step: 496150, training_loss: 5.13857e-02
I0212 01:26:25.755125 22509476222784 run_lib.py:133] step: 496200, training_loss: 2.78570e-02
I0212 01:26:25.924567 22509476222784 run_lib.py:146] step: 496200, eval_loss: 4.93823e-02
I0212 01:26:44.578189 22509476222784 run_lib.py:133] step: 496250, training_loss: 4.62393e-02
I0212 01:27:03.152101 22509476222784 run_lib.py:133] step: 496300, training_loss: 4.13143e-02
I0212 01:27:03.315324 22509476222784 run_lib.py:146] step: 496300, eval_loss: 4.11799e-02
I0212 01:27:21.763126 22509476222784 run_lib.py:133] step: 496350, training_loss: 3.74787e-02
I0212 01:27:40.268367 22509476222784 run_lib.py:133] step: 496400, training_loss: 4.52086e-02
I0212 01:27:40.430619 22509476222784 run_lib.py:146] step: 496400, eval_loss: 3.36619e-02
I0212 01:27:59.093232 22509476222784 run_lib.py:133] step: 496450, training_loss: 4.11922e-02
I0212 01:28:17.747014 22509476222784 run_lib.py:133] step: 496500, training_loss: 4.27848e-02
I0212 01:28:17.919869 22509476222784 run_lib.py:146] step: 496500, eval_loss: 3.03993e-02
I0212 01:28:36.463333 22509476222784 run_lib.py:133] step: 496550, training_loss: 3.85302e-02
I0212 01:28:55.043716 22509476222784 run_lib.py:133] step: 496600, training_loss: 4.24142e-02
I0212 01:28:55.219789 22509476222784 run_lib.py:146] step: 496600, eval_loss: 5.16242e-02
I0212 01:29:13.844553 22509476222784 run_lib.py:133] step: 496650, training_loss: 4.55249e-02
I0212 01:29:32.258580 22509476222784 run_lib.py:133] step: 496700, training_loss: 3.50152e-02
I0212 01:29:32.423620 22509476222784 run_lib.py:146] step: 496700, eval_loss: 4.35381e-02
I0212 01:29:51.095826 22509476222784 run_lib.py:133] step: 496750, training_loss: 4.75792e-02
I0212 01:30:09.630281 22509476222784 run_lib.py:133] step: 496800, training_loss: 4.50675e-02
I0212 01:30:09.799170 22509476222784 run_lib.py:146] step: 496800, eval_loss: 4.46127e-02
I0212 01:30:28.542946 22509476222784 run_lib.py:133] step: 496850, training_loss: 4.03958e-02
I0212 01:30:47.033142 22509476222784 run_lib.py:133] step: 496900, training_loss: 5.62458e-02
I0212 01:30:47.193630 22509476222784 run_lib.py:146] step: 496900, eval_loss: 3.91283e-02
I0212 01:31:05.653690 22509476222784 run_lib.py:133] step: 496950, training_loss: 4.06517e-02
I0212 01:31:24.180571 22509476222784 run_lib.py:133] step: 497000, training_loss: 5.12553e-02
I0212 01:31:24.359748 22509476222784 run_lib.py:146] step: 497000, eval_loss: 3.76342e-02
I0212 01:31:42.763700 22509476222784 run_lib.py:133] step: 497050, training_loss: 4.53405e-02
I0212 01:32:01.428331 22509476222784 run_lib.py:133] step: 497100, training_loss: 4.00227e-02
I0212 01:32:01.626587 22509476222784 run_lib.py:146] step: 497100, eval_loss: 3.84193e-02
I0212 01:32:20.119314 22509476222784 run_lib.py:133] step: 497150, training_loss: 3.44160e-02
I0212 01:32:38.569619 22509476222784 run_lib.py:133] step: 497200, training_loss: 3.09842e-02
I0212 01:32:38.733635 22509476222784 run_lib.py:146] step: 497200, eval_loss: 4.79743e-02
I0212 01:32:57.356178 22509476222784 run_lib.py:133] step: 497250, training_loss: 3.81439e-02
I0212 01:33:15.925537 22509476222784 run_lib.py:133] step: 497300, training_loss: 3.54732e-02
I0212 01:33:16.088415 22509476222784 run_lib.py:146] step: 497300, eval_loss: 5.16588e-02
I0212 01:33:34.639206 22509476222784 run_lib.py:133] step: 497350, training_loss: 2.73307e-02
I0212 01:33:53.128691 22509476222784 run_lib.py:133] step: 497400, training_loss: 4.34321e-02
I0212 01:33:53.290647 22509476222784 run_lib.py:146] step: 497400, eval_loss: 4.36654e-02
I0212 01:34:11.970893 22509476222784 run_lib.py:133] step: 497450, training_loss: 4.17044e-02
I0212 01:34:30.568946 22509476222784 run_lib.py:133] step: 497500, training_loss: 4.66458e-02
I0212 01:34:30.734810 22509476222784 run_lib.py:146] step: 497500, eval_loss: 5.00881e-02
I0212 01:34:49.324981 22509476222784 run_lib.py:133] step: 497550, training_loss: 3.89701e-02
I0212 01:35:07.893564 22509476222784 run_lib.py:133] step: 497600, training_loss: 4.41290e-02
I0212 01:35:08.059674 22509476222784 run_lib.py:146] step: 497600, eval_loss: 4.65056e-02
I0212 01:35:26.576898 22509476222784 run_lib.py:133] step: 497650, training_loss: 4.19158e-02
I0212 01:35:44.956353 22509476222784 run_lib.py:133] step: 497700, training_loss: 4.71522e-02
I0212 01:35:45.118507 22509476222784 run_lib.py:146] step: 497700, eval_loss: 3.73541e-02
I0212 01:36:03.747258 22509476222784 run_lib.py:133] step: 497750, training_loss: 5.28167e-02
I0212 01:36:22.378569 22509476222784 run_lib.py:133] step: 497800, training_loss: 4.82479e-02
I0212 01:36:22.542736 22509476222784 run_lib.py:146] step: 497800, eval_loss: 4.27482e-02
I0212 01:36:41.086032 22509476222784 run_lib.py:133] step: 497850, training_loss: 4.41796e-02
I0212 01:36:59.576391 22509476222784 run_lib.py:133] step: 497900, training_loss: 5.42981e-02
I0212 01:36:59.738391 22509476222784 run_lib.py:146] step: 497900, eval_loss: 5.46753e-02
I0212 01:37:18.308518 22509476222784 run_lib.py:133] step: 497950, training_loss: 4.06049e-02
I0212 01:37:36.712589 22509476222784 run_lib.py:133] step: 498000, training_loss: 4.49449e-02
I0212 01:37:36.882508 22509476222784 run_lib.py:146] step: 498000, eval_loss: 4.43118e-02
I0212 01:37:55.543920 22509476222784 run_lib.py:133] step: 498050, training_loss: 3.87791e-02
I0212 01:38:14.132623 22509476222784 run_lib.py:133] step: 498100, training_loss: 3.27758e-02
I0212 01:38:14.297651 22509476222784 run_lib.py:146] step: 498100, eval_loss: 3.33057e-02
I0212 01:38:32.981891 22509476222784 run_lib.py:133] step: 498150, training_loss: 4.87767e-02
I0212 01:38:51.527655 22509476222784 run_lib.py:133] step: 498200, training_loss: 3.31456e-02
I0212 01:38:51.691775 22509476222784 run_lib.py:146] step: 498200, eval_loss: 3.84713e-02
I0212 01:39:10.240809 22509476222784 run_lib.py:133] step: 498250, training_loss: 4.03396e-02
I0212 01:39:28.740540 22509476222784 run_lib.py:133] step: 498300, training_loss: 4.38175e-02
I0212 01:39:28.946851 22509476222784 run_lib.py:146] step: 498300, eval_loss: 4.51437e-02
I0212 01:39:47.527508 22509476222784 run_lib.py:133] step: 498350, training_loss: 5.83718e-02
I0212 01:40:06.197546 22509476222784 run_lib.py:133] step: 498400, training_loss: 3.61732e-02
I0212 01:40:06.358605 22509476222784 run_lib.py:146] step: 498400, eval_loss: 4.40056e-02
I0212 01:40:24.747501 22509476222784 run_lib.py:133] step: 498450, training_loss: 3.31879e-02
I0212 01:40:43.242914 22509476222784 run_lib.py:133] step: 498500, training_loss: 4.14183e-02
I0212 01:40:43.423885 22509476222784 run_lib.py:146] step: 498500, eval_loss: 4.33708e-02
I0212 01:41:02.050433 22509476222784 run_lib.py:133] step: 498550, training_loss: 4.22382e-02
I0212 01:41:20.593470 22509476222784 run_lib.py:133] step: 498600, training_loss: 5.46304e-02
I0212 01:41:20.763566 22509476222784 run_lib.py:146] step: 498600, eval_loss: 3.64412e-02
I0212 01:41:39.238304 22509476222784 run_lib.py:133] step: 498650, training_loss: 4.74877e-02
I0212 01:41:57.740571 22509476222784 run_lib.py:133] step: 498700, training_loss: 3.38293e-02
I0212 01:41:57.905027 22509476222784 run_lib.py:146] step: 498700, eval_loss: 3.99611e-02
I0212 01:42:16.421704 22509476222784 run_lib.py:133] step: 498750, training_loss: 5.55817e-02
I0212 01:42:35.123136 22509476222784 run_lib.py:133] step: 498800, training_loss: 4.63957e-02
I0212 01:42:35.283383 22509476222784 run_lib.py:146] step: 498800, eval_loss: 4.12738e-02
I0212 01:42:53.761800 22509476222784 run_lib.py:133] step: 498850, training_loss: 4.97767e-02
I0212 01:43:12.188131 22509476222784 run_lib.py:133] step: 498900, training_loss: 4.76282e-02
I0212 01:43:12.358660 22509476222784 run_lib.py:146] step: 498900, eval_loss: 5.32639e-02
I0212 01:43:30.877776 22509476222784 run_lib.py:133] step: 498950, training_loss: 3.31397e-02
I0212 01:43:49.616780 22509476222784 run_lib.py:133] step: 499000, training_loss: 4.65545e-02
I0212 01:43:49.790712 22509476222784 run_lib.py:146] step: 499000, eval_loss: 4.47006e-02
I0212 01:44:08.271386 22509476222784 run_lib.py:133] step: 499050, training_loss: 5.11562e-02
I0212 01:44:26.879505 22509476222784 run_lib.py:133] step: 499100, training_loss: 4.43958e-02
I0212 01:44:27.042637 22509476222784 run_lib.py:146] step: 499100, eval_loss: 4.21499e-02
I0212 01:44:45.528464 22509476222784 run_lib.py:133] step: 499150, training_loss: 4.64957e-02
I0212 01:45:04.081066 22509476222784 run_lib.py:133] step: 499200, training_loss: 3.25404e-02
I0212 01:45:04.263787 22509476222784 run_lib.py:146] step: 499200, eval_loss: 3.99933e-02
I0212 01:45:22.952018 22509476222784 run_lib.py:133] step: 499250, training_loss: 5.17114e-02
I0212 01:45:41.447585 22509476222784 run_lib.py:133] step: 499300, training_loss: 5.14788e-02
I0212 01:45:41.607663 22509476222784 run_lib.py:146] step: 499300, eval_loss: 4.62591e-02
I0212 01:46:00.081156 22509476222784 run_lib.py:133] step: 499350, training_loss: 3.99042e-02
I0212 01:46:18.603723 22509476222784 run_lib.py:133] step: 499400, training_loss: 3.84674e-02
I0212 01:46:18.768785 22509476222784 run_lib.py:146] step: 499400, eval_loss: 3.97585e-02
I0212 01:46:37.473278 22509476222784 run_lib.py:133] step: 499450, training_loss: 4.11518e-02
I0212 01:46:55.992311 22509476222784 run_lib.py:133] step: 499500, training_loss: 3.73020e-02
I0212 01:46:56.155884 22509476222784 run_lib.py:146] step: 499500, eval_loss: 2.97848e-02
I0212 01:47:14.850028 22509476222784 run_lib.py:133] step: 499550, training_loss: 4.59437e-02
I0212 01:47:33.371292 22509476222784 run_lib.py:133] step: 499600, training_loss: 4.91652e-02
I0212 01:47:33.535741 22509476222784 run_lib.py:146] step: 499600, eval_loss: 4.10077e-02
I0212 01:47:52.189103 22509476222784 run_lib.py:133] step: 499650, training_loss: 4.98810e-02
I0212 01:48:10.680405 22509476222784 run_lib.py:133] step: 499700, training_loss: 4.06889e-02
I0212 01:48:10.850795 22509476222784 run_lib.py:146] step: 499700, eval_loss: 3.61888e-02
I0212 01:48:29.410066 22509476222784 run_lib.py:133] step: 499750, training_loss: 5.04032e-02
I0212 01:48:48.121953 22509476222784 run_lib.py:133] step: 499800, training_loss: 3.72702e-02
I0212 01:48:48.283698 22509476222784 run_lib.py:146] step: 499800, eval_loss: 3.57139e-02
I0212 01:49:06.769950 22509476222784 run_lib.py:133] step: 499850, training_loss: 6.26825e-02
I0212 01:49:25.408875 22509476222784 run_lib.py:133] step: 499900, training_loss: 3.75528e-02
I0212 01:49:25.606150 22509476222784 run_lib.py:146] step: 499900, eval_loss: 3.68710e-02
I0212 01:49:44.105081 22509476222784 run_lib.py:133] step: 499950, training_loss: 4.75230e-02
I0212 01:50:02.733330 22509476222784 run_lib.py:133] step: 500000, training_loss: 4.04083e-02
I0212 01:50:03.506565 22509476222784 run_lib.py:146] step: 500000, eval_loss: 4.50219e-02
I0212 01:50:24.734352 22509476222784 run_lib.py:133] step: 500050, training_loss: 4.74392e-02
I0212 01:50:43.452631 22509476222784 run_lib.py:133] step: 500100, training_loss: 4.12963e-02
I0212 01:50:43.624647 22509476222784 run_lib.py:146] step: 500100, eval_loss: 4.83927e-02
I0212 01:51:02.087283 22509476222784 run_lib.py:133] step: 500150, training_loss: 4.27218e-02
I0212 01:51:20.746950 22509476222784 run_lib.py:133] step: 500200, training_loss: 4.54011e-02
I0212 01:51:20.910680 22509476222784 run_lib.py:146] step: 500200, eval_loss: 4.47789e-02
I0212 01:51:39.435052 22509476222784 run_lib.py:133] step: 500250, training_loss: 4.89177e-02
I0212 01:51:57.921234 22509476222784 run_lib.py:133] step: 500300, training_loss: 3.59392e-02
I0212 01:51:58.083849 22509476222784 run_lib.py:146] step: 500300, eval_loss: 3.93882e-02
I0212 01:52:16.845403 22509476222784 run_lib.py:133] step: 500350, training_loss: 4.12024e-02
I0212 01:52:35.359638 22509476222784 run_lib.py:133] step: 500400, training_loss: 4.95018e-02
I0212 01:52:35.522675 22509476222784 run_lib.py:146] step: 500400, eval_loss: 4.26277e-02
I0212 01:52:54.149563 22509476222784 run_lib.py:133] step: 500450, training_loss: 4.67777e-02
I0212 01:53:12.710070 22509476222784 run_lib.py:133] step: 500500, training_loss: 3.65743e-02
I0212 01:53:12.890722 22509476222784 run_lib.py:146] step: 500500, eval_loss: 4.11765e-02
I0212 01:53:31.501492 22509476222784 run_lib.py:133] step: 500550, training_loss: 4.32632e-02
I0212 01:53:50.164781 22509476222784 run_lib.py:133] step: 500600, training_loss: 3.99259e-02
I0212 01:53:50.329871 22509476222784 run_lib.py:146] step: 500600, eval_loss: 3.82571e-02
I0212 01:54:08.856178 22509476222784 run_lib.py:133] step: 500650, training_loss: 3.89641e-02
I0212 01:54:27.328512 22509476222784 run_lib.py:133] step: 500700, training_loss: 2.80471e-02
I0212 01:54:27.491711 22509476222784 run_lib.py:146] step: 500700, eval_loss: 5.20613e-02
I0212 01:54:45.997159 22509476222784 run_lib.py:133] step: 500750, training_loss: 5.37739e-02
I0212 01:55:04.672916 22509476222784 run_lib.py:133] step: 500800, training_loss: 5.27197e-02
I0212 01:55:04.863035 22509476222784 run_lib.py:146] step: 500800, eval_loss: 4.90718e-02
I0212 01:55:23.460196 22509476222784 run_lib.py:133] step: 500850, training_loss: 3.98352e-02
I0212 01:55:42.069730 22509476222784 run_lib.py:133] step: 500900, training_loss: 3.51279e-02
I0212 01:55:42.256584 22509476222784 run_lib.py:146] step: 500900, eval_loss: 4.04115e-02
I0212 01:56:00.764127 22509476222784 run_lib.py:133] step: 500950, training_loss: 5.18889e-02
I0212 01:56:19.242870 22509476222784 run_lib.py:133] step: 501000, training_loss: 3.36356e-02
I0212 01:56:19.426845 22509476222784 run_lib.py:146] step: 501000, eval_loss: 5.21369e-02
I0212 01:56:38.106206 22509476222784 run_lib.py:133] step: 501050, training_loss: 4.00199e-02
I0212 01:56:56.752656 22509476222784 run_lib.py:133] step: 501100, training_loss: 4.17183e-02
I0212 01:56:56.918961 22509476222784 run_lib.py:146] step: 501100, eval_loss: 3.71709e-02
I0212 01:57:15.362915 22509476222784 run_lib.py:133] step: 501150, training_loss: 4.55591e-02
I0212 01:57:33.823012 22509476222784 run_lib.py:133] step: 501200, training_loss: 3.23521e-02
I0212 01:57:33.992515 22509476222784 run_lib.py:146] step: 501200, eval_loss: 3.83854e-02
I0212 01:57:52.656993 22509476222784 run_lib.py:133] step: 501250, training_loss: 4.33523e-02
I0212 01:58:11.217771 22509476222784 run_lib.py:133] step: 501300, training_loss: 4.77092e-02
I0212 01:58:11.379785 22509476222784 run_lib.py:146] step: 501300, eval_loss: 3.92221e-02
I0212 01:58:30.120095 22509476222784 run_lib.py:133] step: 501350, training_loss: 3.91048e-02
I0212 01:58:48.623648 22509476222784 run_lib.py:133] step: 501400, training_loss: 4.60711e-02
I0212 01:58:48.794129 22509476222784 run_lib.py:146] step: 501400, eval_loss: 5.02245e-02
I0212 01:59:07.496193 22509476222784 run_lib.py:133] step: 501450, training_loss: 3.89378e-02
I0212 01:59:26.020852 22509476222784 run_lib.py:133] step: 501500, training_loss: 3.66688e-02
I0212 01:59:26.184723 22509476222784 run_lib.py:146] step: 501500, eval_loss: 5.16424e-02
I0212 01:59:44.693799 22509476222784 run_lib.py:133] step: 501550, training_loss: 3.87369e-02
I0212 02:00:03.457712 22509476222784 run_lib.py:133] step: 501600, training_loss: 3.74866e-02
I0212 02:00:03.651576 22509476222784 run_lib.py:146] step: 501600, eval_loss: 4.17333e-02
I0212 02:00:22.184960 22509476222784 run_lib.py:133] step: 501650, training_loss: 3.72143e-02
I0212 02:00:40.860411 22509476222784 run_lib.py:133] step: 501700, training_loss: 2.75633e-02
I0212 02:00:41.022390 22509476222784 run_lib.py:146] step: 501700, eval_loss: 3.79399e-02
I0212 02:00:59.561409 22509476222784 run_lib.py:133] step: 501750, training_loss: 4.16702e-02
I0212 02:01:18.146140 22509476222784 run_lib.py:133] step: 501800, training_loss: 4.04360e-02
I0212 02:01:18.311731 22509476222784 run_lib.py:146] step: 501800, eval_loss: 5.24033e-02
I0212 02:01:36.972790 22509476222784 run_lib.py:133] step: 501850, training_loss: 3.96706e-02
I0212 02:01:55.528945 22509476222784 run_lib.py:133] step: 501900, training_loss: 4.36437e-02
I0212 02:01:55.698350 22509476222784 run_lib.py:146] step: 501900, eval_loss: 4.97667e-02
I0212 02:02:14.215028 22509476222784 run_lib.py:133] step: 501950, training_loss: 5.04889e-02
I0212 02:02:32.866324 22509476222784 run_lib.py:133] step: 502000, training_loss: 4.49859e-02
I0212 02:02:33.029443 22509476222784 run_lib.py:146] step: 502000, eval_loss: 3.81578e-02
I0212 02:02:51.444578 22509476222784 run_lib.py:133] step: 502050, training_loss: 3.94683e-02
I0212 02:03:09.949290 22509476222784 run_lib.py:133] step: 502100, training_loss: 3.66381e-02
I0212 02:03:10.119460 22509476222784 run_lib.py:146] step: 502100, eval_loss: 3.81798e-02
I0212 02:03:28.745278 22509476222784 run_lib.py:133] step: 502150, training_loss: 5.19693e-02
I0212 02:03:47.244096 22509476222784 run_lib.py:133] step: 502200, training_loss: 2.49311e-02
I0212 02:03:47.404402 22509476222784 run_lib.py:146] step: 502200, eval_loss: 4.27013e-02
I0212 02:04:05.945502 22509476222784 run_lib.py:133] step: 502250, training_loss: 4.08301e-02
I0212 02:04:24.475941 22509476222784 run_lib.py:133] step: 502300, training_loss: 4.46335e-02
I0212 02:04:24.654521 22509476222784 run_lib.py:146] step: 502300, eval_loss: 3.94081e-02
I0212 02:04:43.317157 22509476222784 run_lib.py:133] step: 502350, training_loss: 4.01169e-02
I0212 02:05:01.935097 22509476222784 run_lib.py:133] step: 502400, training_loss: 4.77979e-02
I0212 02:05:02.116611 22509476222784 run_lib.py:146] step: 502400, eval_loss: 4.63040e-02
I0212 02:05:20.631951 22509476222784 run_lib.py:133] step: 502450, training_loss: 4.87069e-02
I0212 02:05:39.188331 22509476222784 run_lib.py:133] step: 502500, training_loss: 4.57891e-02
I0212 02:05:39.409638 22509476222784 run_lib.py:146] step: 502500, eval_loss: 4.36297e-02
I0212 02:05:58.049853 22509476222784 run_lib.py:133] step: 502550, training_loss: 4.77836e-02
I0212 02:06:16.514289 22509476222784 run_lib.py:133] step: 502600, training_loss: 4.78843e-02
I0212 02:06:16.712588 22509476222784 run_lib.py:146] step: 502600, eval_loss: 4.68948e-02
I0212 02:06:35.269941 22509476222784 run_lib.py:133] step: 502650, training_loss: 3.85150e-02
I0212 02:06:53.848558 22509476222784 run_lib.py:133] step: 502700, training_loss: 3.29631e-02
I0212 02:06:54.011829 22509476222784 run_lib.py:146] step: 502700, eval_loss: 3.20624e-02
I0212 02:07:12.714862 22509476222784 run_lib.py:133] step: 502750, training_loss: 3.74434e-02
I0212 02:07:31.226003 22509476222784 run_lib.py:133] step: 502800, training_loss: 4.28639e-02
I0212 02:07:31.390680 22509476222784 run_lib.py:146] step: 502800, eval_loss: 5.04553e-02
I0212 02:07:49.994948 22509476222784 run_lib.py:133] step: 502850, training_loss: 3.95685e-02
I0212 02:08:08.529396 22509476222784 run_lib.py:133] step: 502900, training_loss: 3.82561e-02
I0212 02:08:08.708620 22509476222784 run_lib.py:146] step: 502900, eval_loss: 3.11443e-02
I0212 02:08:27.214379 22509476222784 run_lib.py:133] step: 502950, training_loss: 4.93466e-02
I0212 02:08:45.889986 22509476222784 run_lib.py:133] step: 503000, training_loss: 2.75724e-02
I0212 02:08:46.050555 22509476222784 run_lib.py:146] step: 503000, eval_loss: 5.23144e-02
I0212 02:09:04.560124 22509476222784 run_lib.py:133] step: 503050, training_loss: 4.48221e-02
I0212 02:09:22.972693 22509476222784 run_lib.py:133] step: 503100, training_loss: 4.11647e-02
I0212 02:09:23.134620 22509476222784 run_lib.py:146] step: 503100, eval_loss: 3.84182e-02
I0212 02:09:41.643512 22509476222784 run_lib.py:133] step: 503150, training_loss: 3.51996e-02
I0212 02:10:00.174046 22509476222784 run_lib.py:133] step: 503200, training_loss: 3.91790e-02
I0212 02:10:00.338755 22509476222784 run_lib.py:146] step: 503200, eval_loss: 5.53255e-02
I0212 02:10:19.097465 22509476222784 run_lib.py:133] step: 503250, training_loss: 3.43270e-02
I0212 02:10:37.609636 22509476222784 run_lib.py:133] step: 503300, training_loss: 5.01134e-02
I0212 02:10:37.775807 22509476222784 run_lib.py:146] step: 503300, eval_loss: 4.72111e-02
I0212 02:10:56.263457 22509476222784 run_lib.py:133] step: 503350, training_loss: 5.20216e-02
I0212 02:11:14.854045 22509476222784 run_lib.py:133] step: 503400, training_loss: 4.74195e-02
I0212 02:11:15.018647 22509476222784 run_lib.py:146] step: 503400, eval_loss: 4.34689e-02
I0212 02:11:33.563123 22509476222784 run_lib.py:133] step: 503450, training_loss: 4.91833e-02
I0212 02:11:52.214819 22509476222784 run_lib.py:133] step: 503500, training_loss: 4.83912e-02
I0212 02:11:52.378856 22509476222784 run_lib.py:146] step: 503500, eval_loss: 5.27440e-02
I0212 02:12:10.886102 22509476222784 run_lib.py:133] step: 503550, training_loss: 5.02918e-02
I0212 02:12:29.566474 22509476222784 run_lib.py:133] step: 503600, training_loss: 3.47180e-02
I0212 02:12:29.731526 22509476222784 run_lib.py:146] step: 503600, eval_loss: 4.81873e-02
I0212 02:12:48.236093 22509476222784 run_lib.py:133] step: 503650, training_loss: 4.30124e-02
I0212 02:13:06.823086 22509476222784 run_lib.py:133] step: 503700, training_loss: 5.12441e-02
I0212 02:13:06.995792 22509476222784 run_lib.py:146] step: 503700, eval_loss: 5.73611e-02
I0212 02:13:25.536826 22509476222784 run_lib.py:133] step: 503750, training_loss: 4.17802e-02
I0212 02:13:44.041496 22509476222784 run_lib.py:133] step: 503800, training_loss: 5.28115e-02
I0212 02:13:44.207795 22509476222784 run_lib.py:146] step: 503800, eval_loss: 3.52172e-02
I0212 02:14:02.844394 22509476222784 run_lib.py:133] step: 503850, training_loss: 4.65422e-02
I0212 02:14:21.341771 22509476222784 run_lib.py:133] step: 503900, training_loss: 3.43484e-02
I0212 02:14:21.505770 22509476222784 run_lib.py:146] step: 503900, eval_loss: 3.87136e-02
I0212 02:14:40.056512 22509476222784 run_lib.py:133] step: 503950, training_loss: 3.78290e-02
I0212 02:14:58.584909 22509476222784 run_lib.py:133] step: 504000, training_loss: 4.73224e-02
I0212 02:14:58.749142 22509476222784 run_lib.py:146] step: 504000, eval_loss: 5.39346e-02
I0212 02:15:17.408369 22509476222784 run_lib.py:133] step: 504050, training_loss: 4.04281e-02
I0212 02:15:35.929091 22509476222784 run_lib.py:133] step: 504100, training_loss: 3.66002e-02
I0212 02:15:36.116817 22509476222784 run_lib.py:146] step: 504100, eval_loss: 4.45509e-02
I0212 02:15:54.745675 22509476222784 run_lib.py:133] step: 504150, training_loss: 3.92172e-02
I0212 02:16:13.195015 22509476222784 run_lib.py:133] step: 504200, training_loss: 5.09552e-02
I0212 02:16:13.357501 22509476222784 run_lib.py:146] step: 504200, eval_loss: 4.74437e-02
I0212 02:16:32.016360 22509476222784 run_lib.py:133] step: 504250, training_loss: 4.73005e-02
I0212 02:16:50.608740 22509476222784 run_lib.py:133] step: 504300, training_loss: 3.89568e-02
I0212 02:16:50.820650 22509476222784 run_lib.py:146] step: 504300, eval_loss: 4.07494e-02
I0212 02:17:09.341176 22509476222784 run_lib.py:133] step: 504350, training_loss: 4.28851e-02
I0212 02:17:28.053494 22509476222784 run_lib.py:133] step: 504400, training_loss: 4.73038e-02
I0212 02:17:28.228575 22509476222784 run_lib.py:146] step: 504400, eval_loss: 4.27959e-02
I0212 02:17:46.765467 22509476222784 run_lib.py:133] step: 504450, training_loss: 4.56378e-02
I0212 02:18:05.442435 22509476222784 run_lib.py:133] step: 504500, training_loss: 4.16565e-02
I0212 02:18:05.609878 22509476222784 run_lib.py:146] step: 504500, eval_loss: 4.15168e-02
I0212 02:18:24.201648 22509476222784 run_lib.py:133] step: 504550, training_loss: 4.64913e-02
I0212 02:18:42.731497 22509476222784 run_lib.py:133] step: 504600, training_loss: 4.10868e-02
I0212 02:18:42.892901 22509476222784 run_lib.py:146] step: 504600, eval_loss: 4.59446e-02
I0212 02:19:01.649802 22509476222784 run_lib.py:133] step: 504650, training_loss: 3.20502e-02
I0212 02:19:20.131747 22509476222784 run_lib.py:133] step: 504700, training_loss: 4.26426e-02
I0212 02:19:20.296456 22509476222784 run_lib.py:146] step: 504700, eval_loss: 4.38999e-02
I0212 02:19:38.780829 22509476222784 run_lib.py:133] step: 504750, training_loss: 4.84033e-02
I0212 02:19:57.413593 22509476222784 run_lib.py:133] step: 504800, training_loss: 4.87733e-02
I0212 02:19:57.591607 22509476222784 run_lib.py:146] step: 504800, eval_loss: 3.00454e-02
I0212 02:20:16.152288 22509476222784 run_lib.py:133] step: 504850, training_loss: 5.19586e-02
I0212 02:20:34.644018 22509476222784 run_lib.py:133] step: 504900, training_loss: 4.26911e-02
I0212 02:20:35.022914 22509476222784 run_lib.py:146] step: 504900, eval_loss: 3.89337e-02
I0212 02:20:53.432776 22509476222784 run_lib.py:133] step: 504950, training_loss: 4.52827e-02
I0212 02:21:11.926739 22509476222784 run_lib.py:133] step: 505000, training_loss: 2.97568e-02
I0212 02:21:12.119722 22509476222784 run_lib.py:146] step: 505000, eval_loss: 3.81505e-02
I0212 02:21:30.651087 22509476222784 run_lib.py:133] step: 505050, training_loss: 4.79728e-02
I0212 02:21:49.217191 22509476222784 run_lib.py:133] step: 505100, training_loss: 3.73988e-02
I0212 02:21:49.382924 22509476222784 run_lib.py:146] step: 505100, eval_loss: 3.42185e-02
I0212 02:22:08.120630 22509476222784 run_lib.py:133] step: 505150, training_loss: 4.02565e-02
I0212 02:22:26.709790 22509476222784 run_lib.py:133] step: 505200, training_loss: 4.48320e-02
I0212 02:22:26.880834 22509476222784 run_lib.py:146] step: 505200, eval_loss: 3.40223e-02
I0212 02:22:45.428472 22509476222784 run_lib.py:133] step: 505250, training_loss: 3.99895e-02
I0212 02:23:03.903951 22509476222784 run_lib.py:133] step: 505300, training_loss: 3.65585e-02
I0212 02:23:04.084699 22509476222784 run_lib.py:146] step: 505300, eval_loss: 4.49255e-02
I0212 02:23:22.757267 22509476222784 run_lib.py:133] step: 505350, training_loss: 4.93042e-02
I0212 02:23:41.417020 22509476222784 run_lib.py:133] step: 505400, training_loss: 4.51470e-02
I0212 02:23:41.592188 22509476222784 run_lib.py:146] step: 505400, eval_loss: 4.08603e-02
I0212 02:24:00.129920 22509476222784 run_lib.py:133] step: 505450, training_loss: 5.24696e-02
I0212 02:24:18.534956 22509476222784 run_lib.py:133] step: 505500, training_loss: 4.69916e-02
I0212 02:24:18.696783 22509476222784 run_lib.py:146] step: 505500, eval_loss: 4.51436e-02
I0212 02:24:37.320695 22509476222784 run_lib.py:133] step: 505550, training_loss: 4.43305e-02
I0212 02:24:55.847288 22509476222784 run_lib.py:133] step: 505600, training_loss: 4.11902e-02
I0212 02:24:56.016990 22509476222784 run_lib.py:146] step: 505600, eval_loss: 3.77400e-02
I0212 02:25:14.734434 22509476222784 run_lib.py:133] step: 505650, training_loss: 4.26483e-02
I0212 02:25:33.266550 22509476222784 run_lib.py:133] step: 505700, training_loss: 3.86194e-02
I0212 02:25:33.432640 22509476222784 run_lib.py:146] step: 505700, eval_loss: 4.04283e-02
I0212 02:25:52.032766 22509476222784 run_lib.py:133] step: 505750, training_loss: 3.97965e-02
I0212 02:26:10.538028 22509476222784 run_lib.py:133] step: 505800, training_loss: 3.90429e-02
I0212 02:26:10.727605 22509476222784 run_lib.py:146] step: 505800, eval_loss: 5.29232e-02
I0212 02:26:29.257428 22509476222784 run_lib.py:133] step: 505850, training_loss: 3.94630e-02
I0212 02:26:47.848333 22509476222784 run_lib.py:133] step: 505900, training_loss: 4.68058e-02
I0212 02:26:48.011712 22509476222784 run_lib.py:146] step: 505900, eval_loss: 3.12572e-02
I0212 02:27:06.524132 22509476222784 run_lib.py:133] step: 505950, training_loss: 5.37917e-02
I0212 02:27:25.194789 22509476222784 run_lib.py:133] step: 506000, training_loss: 4.70760e-02
I0212 02:27:25.355642 22509476222784 run_lib.py:146] step: 506000, eval_loss: 3.45895e-02
I0212 02:27:43.880700 22509476222784 run_lib.py:133] step: 506050, training_loss: 4.80766e-02
I0212 02:28:02.351314 22509476222784 run_lib.py:133] step: 506100, training_loss: 3.37001e-02
I0212 02:28:02.516892 22509476222784 run_lib.py:146] step: 506100, eval_loss: 4.93918e-02
I0212 02:28:20.959146 22509476222784 run_lib.py:133] step: 506150, training_loss: 4.95211e-02
I0212 02:28:39.621811 22509476222784 run_lib.py:133] step: 506200, training_loss: 4.23900e-02
I0212 02:28:39.786633 22509476222784 run_lib.py:146] step: 506200, eval_loss: 4.38652e-02
I0212 02:28:58.277079 22509476222784 run_lib.py:133] step: 506250, training_loss: 3.21376e-02
I0212 02:29:16.775551 22509476222784 run_lib.py:133] step: 506300, training_loss: 4.03443e-02
I0212 02:29:16.944533 22509476222784 run_lib.py:146] step: 506300, eval_loss: 3.07752e-02
I0212 02:29:35.593097 22509476222784 run_lib.py:133] step: 506350, training_loss: 4.69530e-02
I0212 02:29:54.129462 22509476222784 run_lib.py:133] step: 506400, training_loss: 3.84705e-02
I0212 02:29:54.301655 22509476222784 run_lib.py:146] step: 506400, eval_loss: 3.60459e-02
I0212 02:30:12.985608 22509476222784 run_lib.py:133] step: 506450, training_loss: 4.06057e-02
I0212 02:30:31.515631 22509476222784 run_lib.py:133] step: 506500, training_loss: 4.69983e-02
I0212 02:30:31.676633 22509476222784 run_lib.py:146] step: 506500, eval_loss: 4.51749e-02
I0212 02:30:50.183403 22509476222784 run_lib.py:133] step: 506550, training_loss: 3.80156e-02
I0212 02:31:08.638486 22509476222784 run_lib.py:133] step: 506600, training_loss: 4.78304e-02
I0212 02:31:08.802839 22509476222784 run_lib.py:146] step: 506600, eval_loss: 3.36414e-02
I0212 02:31:27.489856 22509476222784 run_lib.py:133] step: 506650, training_loss: 3.07660e-02
I0212 02:31:46.173557 22509476222784 run_lib.py:133] step: 506700, training_loss: 4.41733e-02
I0212 02:31:46.339586 22509476222784 run_lib.py:146] step: 506700, eval_loss: 4.06123e-02
I0212 02:32:04.857883 22509476222784 run_lib.py:133] step: 506750, training_loss: 4.26035e-02
I0212 02:32:23.333761 22509476222784 run_lib.py:133] step: 506800, training_loss: 5.91915e-02
I0212 02:32:23.497707 22509476222784 run_lib.py:146] step: 506800, eval_loss: 3.58806e-02
I0212 02:32:42.190079 22509476222784 run_lib.py:133] step: 506850, training_loss: 4.86799e-02
I0212 02:33:00.690558 22509476222784 run_lib.py:133] step: 506900, training_loss: 3.79050e-02
I0212 02:33:00.874545 22509476222784 run_lib.py:146] step: 506900, eval_loss: 3.76763e-02
I0212 02:33:19.441920 22509476222784 run_lib.py:133] step: 506950, training_loss: 5.14009e-02
I0212 02:33:37.981544 22509476222784 run_lib.py:133] step: 507000, training_loss: 3.53033e-02
I0212 02:33:38.155606 22509476222784 run_lib.py:146] step: 507000, eval_loss: 3.98449e-02
I0212 02:33:56.873107 22509476222784 run_lib.py:133] step: 507050, training_loss: 5.04622e-02
I0212 02:34:15.462569 22509476222784 run_lib.py:133] step: 507100, training_loss: 3.58258e-02
I0212 02:34:15.628821 22509476222784 run_lib.py:146] step: 507100, eval_loss: 4.45886e-02
I0212 02:34:34.276859 22509476222784 run_lib.py:133] step: 507150, training_loss: 3.73550e-02
I0212 02:34:52.828671 22509476222784 run_lib.py:133] step: 507200, training_loss: 4.49881e-02
I0212 02:34:52.995668 22509476222784 run_lib.py:146] step: 507200, eval_loss: 4.00910e-02
I0212 02:35:11.465887 22509476222784 run_lib.py:133] step: 507250, training_loss: 4.29615e-02
I0212 02:35:30.136163 22509476222784 run_lib.py:133] step: 507300, training_loss: 4.50882e-02
I0212 02:35:30.300507 22509476222784 run_lib.py:146] step: 507300, eval_loss: 4.00421e-02
I0212 02:35:48.832250 22509476222784 run_lib.py:133] step: 507350, training_loss: 4.58745e-02
I0212 02:36:07.294287 22509476222784 run_lib.py:133] step: 507400, training_loss: 4.21570e-02
I0212 02:36:07.453712 22509476222784 run_lib.py:146] step: 507400, eval_loss: 3.55418e-02
I0212 02:36:26.160531 22509476222784 run_lib.py:133] step: 507450, training_loss: 4.68227e-02
I0212 02:36:44.853956 22509476222784 run_lib.py:133] step: 507500, training_loss: 3.67762e-02
I0212 02:36:45.029853 22509476222784 run_lib.py:146] step: 507500, eval_loss: 4.01623e-02
I0212 02:37:03.556267 22509476222784 run_lib.py:133] step: 507550, training_loss: 5.81563e-02
I0212 02:37:22.102361 22509476222784 run_lib.py:133] step: 507600, training_loss: 4.20781e-02
I0212 02:37:22.266666 22509476222784 run_lib.py:146] step: 507600, eval_loss: 3.91041e-02
I0212 02:37:40.731752 22509476222784 run_lib.py:133] step: 507650, training_loss: 3.26656e-02
I0212 02:37:59.420667 22509476222784 run_lib.py:133] step: 507700, training_loss: 3.79644e-02
I0212 02:37:59.585804 22509476222784 run_lib.py:146] step: 507700, eval_loss: 3.50637e-02
I0212 02:38:18.076738 22509476222784 run_lib.py:133] step: 507750, training_loss: 4.42382e-02
I0212 02:38:36.610726 22509476222784 run_lib.py:133] step: 507800, training_loss: 3.62629e-02
I0212 02:38:36.779916 22509476222784 run_lib.py:146] step: 507800, eval_loss: 3.90205e-02
I0212 02:38:55.329715 22509476222784 run_lib.py:133] step: 507850, training_loss: 3.14922e-02
I0212 02:39:13.920695 22509476222784 run_lib.py:133] step: 507900, training_loss: 2.76601e-02
I0212 02:39:14.079496 22509476222784 run_lib.py:146] step: 507900, eval_loss: 4.00519e-02
I0212 02:39:32.585174 22509476222784 run_lib.py:133] step: 507950, training_loss: 3.88947e-02
I0212 02:39:51.136052 22509476222784 run_lib.py:133] step: 508000, training_loss: 4.21042e-02
I0212 02:39:51.307575 22509476222784 run_lib.py:146] step: 508000, eval_loss: 4.36327e-02
I0212 02:40:09.777458 22509476222784 run_lib.py:133] step: 508050, training_loss: 4.96907e-02
I0212 02:40:28.293854 22509476222784 run_lib.py:133] step: 508100, training_loss: 4.15386e-02
I0212 02:40:28.459560 22509476222784 run_lib.py:146] step: 508100, eval_loss: 2.41974e-02
I0212 02:40:47.161084 22509476222784 run_lib.py:133] step: 508150, training_loss: 4.63680e-02
I0212 02:41:05.640418 22509476222784 run_lib.py:133] step: 508200, training_loss: 5.95490e-02
I0212 02:41:05.804962 22509476222784 run_lib.py:146] step: 508200, eval_loss: 4.30253e-02
I0212 02:41:24.266962 22509476222784 run_lib.py:133] step: 508250, training_loss: 3.65257e-02
I0212 02:41:42.760135 22509476222784 run_lib.py:133] step: 508300, training_loss: 3.57128e-02
I0212 02:41:42.951791 22509476222784 run_lib.py:146] step: 508300, eval_loss: 4.04462e-02
I0212 02:42:01.670634 22509476222784 run_lib.py:133] step: 508350, training_loss: 3.61867e-02
I0212 02:42:20.120674 22509476222784 run_lib.py:133] step: 508400, training_loss: 4.63487e-02
I0212 02:42:20.282962 22509476222784 run_lib.py:146] step: 508400, eval_loss: 4.41595e-02
I0212 02:42:38.980973 22509476222784 run_lib.py:133] step: 508450, training_loss: 4.51758e-02
I0212 02:42:57.562981 22509476222784 run_lib.py:133] step: 508500, training_loss: 5.55894e-02
I0212 02:42:57.726911 22509476222784 run_lib.py:146] step: 508500, eval_loss: 4.76405e-02
I0212 02:43:16.329905 22509476222784 run_lib.py:133] step: 508550, training_loss: 4.06745e-02
I0212 02:43:34.863273 22509476222784 run_lib.py:133] step: 508600, training_loss: 4.64827e-02
I0212 02:43:35.048620 22509476222784 run_lib.py:146] step: 508600, eval_loss: 4.24846e-02
I0212 02:43:53.576512 22509476222784 run_lib.py:133] step: 508650, training_loss: 4.01599e-02
I0212 02:44:12.398473 22509476222784 run_lib.py:133] step: 508700, training_loss: 4.80048e-02
I0212 02:44:12.563418 22509476222784 run_lib.py:146] step: 508700, eval_loss: 3.50503e-02
I0212 02:44:31.138682 22509476222784 run_lib.py:133] step: 508750, training_loss: 6.15000e-02
I0212 02:44:49.793192 22509476222784 run_lib.py:133] step: 508800, training_loss: 4.63471e-02
I0212 02:44:49.955694 22509476222784 run_lib.py:146] step: 508800, eval_loss: 5.12031e-02
I0212 02:45:08.444278 22509476222784 run_lib.py:133] step: 508850, training_loss: 4.20385e-02
I0212 02:45:26.931627 22509476222784 run_lib.py:133] step: 508900, training_loss: 4.46393e-02
I0212 02:45:27.095844 22509476222784 run_lib.py:146] step: 508900, eval_loss: 3.77384e-02
I0212 02:45:45.874593 22509476222784 run_lib.py:133] step: 508950, training_loss: 4.49577e-02
I0212 02:46:04.436845 22509476222784 run_lib.py:133] step: 509000, training_loss: 4.40977e-02
I0212 02:46:04.608845 22509476222784 run_lib.py:146] step: 509000, eval_loss: 3.84925e-02
I0212 02:46:23.083382 22509476222784 run_lib.py:133] step: 509050, training_loss: 4.25305e-02
I0212 02:46:41.734020 22509476222784 run_lib.py:133] step: 509100, training_loss: 4.05894e-02
I0212 02:46:41.918709 22509476222784 run_lib.py:146] step: 509100, eval_loss: 4.82536e-02
I0212 02:47:00.470137 22509476222784 run_lib.py:133] step: 509150, training_loss: 3.78740e-02
I0212 02:47:19.034632 22509476222784 run_lib.py:133] step: 509200, training_loss: 4.36230e-02
I0212 02:47:19.223106 22509476222784 run_lib.py:146] step: 509200, eval_loss: 3.48797e-02
I0212 02:47:37.894671 22509476222784 run_lib.py:133] step: 509250, training_loss: 5.63624e-02
I0212 02:47:56.413099 22509476222784 run_lib.py:133] step: 509300, training_loss: 3.27957e-02
I0212 02:47:56.576954 22509476222784 run_lib.py:146] step: 509300, eval_loss: 4.79290e-02
I0212 02:48:15.072250 22509476222784 run_lib.py:133] step: 509350, training_loss: 4.28572e-02
I0212 02:48:33.530179 22509476222784 run_lib.py:133] step: 509400, training_loss: 3.53336e-02
I0212 02:48:33.703947 22509476222784 run_lib.py:146] step: 509400, eval_loss: 4.28835e-02
I0212 02:48:52.396615 22509476222784 run_lib.py:133] step: 509450, training_loss: 5.45929e-02
I0212 02:49:11.143592 22509476222784 run_lib.py:133] step: 509500, training_loss: 3.79555e-02
I0212 02:49:11.308555 22509476222784 run_lib.py:146] step: 509500, eval_loss: 4.74475e-02
I0212 02:49:29.799954 22509476222784 run_lib.py:133] step: 509550, training_loss: 3.06069e-02
I0212 02:49:48.274502 22509476222784 run_lib.py:133] step: 509600, training_loss: 3.82770e-02
I0212 02:49:48.438668 22509476222784 run_lib.py:146] step: 509600, eval_loss: 4.25355e-02
I0212 02:50:07.066358 22509476222784 run_lib.py:133] step: 509650, training_loss: 3.12855e-02
I0212 02:50:25.530850 22509476222784 run_lib.py:133] step: 509700, training_loss: 4.55822e-02
I0212 02:50:25.700882 22509476222784 run_lib.py:146] step: 509700, eval_loss: 4.45706e-02
I0212 02:50:44.442559 22509476222784 run_lib.py:133] step: 509750, training_loss: 4.01193e-02
I0212 02:51:02.958982 22509476222784 run_lib.py:133] step: 509800, training_loss: 3.42970e-02
I0212 02:51:03.124647 22509476222784 run_lib.py:146] step: 509800, eval_loss: 4.81857e-02
I0212 02:51:21.814420 22509476222784 run_lib.py:133] step: 509850, training_loss: 3.47716e-02
I0212 02:51:40.270035 22509476222784 run_lib.py:133] step: 509900, training_loss: 4.03163e-02
I0212 02:51:40.435696 22509476222784 run_lib.py:146] step: 509900, eval_loss: 3.54702e-02
I0212 02:51:59.047165 22509476222784 run_lib.py:133] step: 509950, training_loss: 3.63279e-02
I0212 02:52:17.526570 22509476222784 run_lib.py:133] step: 510000, training_loss: 4.68254e-02
I0212 02:52:18.292598 22509476222784 run_lib.py:146] step: 510000, eval_loss: 4.26761e-02
I0212 02:52:39.481742 22509476222784 run_lib.py:133] step: 510050, training_loss: 4.34553e-02
I0212 02:52:58.221076 22509476222784 run_lib.py:133] step: 510100, training_loss: 4.28320e-02
I0212 02:52:58.416620 22509476222784 run_lib.py:146] step: 510100, eval_loss: 4.42637e-02
I0212 02:53:16.916543 22509476222784 run_lib.py:133] step: 510150, training_loss: 4.01639e-02
I0212 02:53:35.543112 22509476222784 run_lib.py:133] step: 510200, training_loss: 3.31799e-02
I0212 02:53:35.752773 22509476222784 run_lib.py:146] step: 510200, eval_loss: 5.80625e-02
I0212 02:53:54.235259 22509476222784 run_lib.py:133] step: 510250, training_loss: 3.61930e-02
I0212 02:54:12.882973 22509476222784 run_lib.py:133] step: 510300, training_loss: 4.53273e-02
I0212 02:54:13.051863 22509476222784 run_lib.py:146] step: 510300, eval_loss: 3.64854e-02
I0212 02:54:31.784766 22509476222784 run_lib.py:133] step: 510350, training_loss: 3.49381e-02
I0212 02:54:50.339089 22509476222784 run_lib.py:133] step: 510400, training_loss: 3.77449e-02
I0212 02:54:50.502801 22509476222784 run_lib.py:146] step: 510400, eval_loss: 5.02656e-02
I0212 02:55:08.991503 22509476222784 run_lib.py:133] step: 510450, training_loss: 5.51722e-02
I0212 02:55:27.469803 22509476222784 run_lib.py:133] step: 510500, training_loss: 3.30539e-02
I0212 02:55:27.634838 22509476222784 run_lib.py:146] step: 510500, eval_loss: 3.66510e-02
I0212 02:55:46.305877 22509476222784 run_lib.py:133] step: 510550, training_loss: 3.93569e-02
I0212 02:56:04.783178 22509476222784 run_lib.py:133] step: 510600, training_loss: 4.63864e-02
I0212 02:56:04.946819 22509476222784 run_lib.py:146] step: 510600, eval_loss: 3.67950e-02
I0212 02:56:23.533120 22509476222784 run_lib.py:133] step: 510650, training_loss: 4.37536e-02
I0212 02:56:42.027666 22509476222784 run_lib.py:133] step: 510700, training_loss: 2.99956e-02
I0212 02:56:42.191851 22509476222784 run_lib.py:146] step: 510700, eval_loss: 5.10925e-02
I0212 02:57:00.821060 22509476222784 run_lib.py:133] step: 510750, training_loss: 3.60601e-02
I0212 02:57:19.293961 22509476222784 run_lib.py:133] step: 510800, training_loss: 4.37986e-02
I0212 02:57:19.454354 22509476222784 run_lib.py:146] step: 510800, eval_loss: 3.78920e-02
I0212 02:57:38.007156 22509476222784 run_lib.py:133] step: 510850, training_loss: 4.52024e-02
I0212 02:57:56.751183 22509476222784 run_lib.py:133] step: 510900, training_loss: 3.82243e-02
I0212 02:57:56.915940 22509476222784 run_lib.py:146] step: 510900, eval_loss: 3.95693e-02
I0212 02:58:15.382663 22509476222784 run_lib.py:133] step: 510950, training_loss: 4.04833e-02
I0212 02:58:33.983267 22509476222784 run_lib.py:133] step: 511000, training_loss: 3.48002e-02
I0212 02:58:34.199774 22509476222784 run_lib.py:146] step: 511000, eval_loss: 3.66946e-02
I0212 02:58:52.663806 22509476222784 run_lib.py:133] step: 511050, training_loss: 4.09272e-02
I0212 02:59:11.169804 22509476222784 run_lib.py:133] step: 511100, training_loss: 5.24083e-02
I0212 02:59:11.345649 22509476222784 run_lib.py:146] step: 511100, eval_loss: 4.92386e-02
I0212 02:59:30.047899 22509476222784 run_lib.py:133] step: 511150, training_loss: 3.62516e-02
I0212 02:59:48.566571 22509476222784 run_lib.py:133] step: 511200, training_loss: 4.51848e-02
I0212 02:59:48.742476 22509476222784 run_lib.py:146] step: 511200, eval_loss: 4.30180e-02
I0212 03:00:07.255241 22509476222784 run_lib.py:133] step: 511250, training_loss: 4.37787e-02
I0212 03:00:25.950689 22509476222784 run_lib.py:133] step: 511300, training_loss: 3.75901e-02
I0212 03:00:26.144524 22509476222784 run_lib.py:146] step: 511300, eval_loss: 4.01811e-02
I0212 03:00:44.545759 22509476222784 run_lib.py:133] step: 511350, training_loss: 2.97542e-02
I0212 03:01:03.033401 22509476222784 run_lib.py:133] step: 511400, training_loss: 4.49462e-02
I0212 03:01:03.212852 22509476222784 run_lib.py:146] step: 511400, eval_loss: 4.91289e-02
I0212 03:01:21.861816 22509476222784 run_lib.py:133] step: 511450, training_loss: 3.80824e-02
I0212 03:01:40.432808 22509476222784 run_lib.py:133] step: 511500, training_loss: 3.23424e-02
I0212 03:01:40.598470 22509476222784 run_lib.py:146] step: 511500, eval_loss: 3.77151e-02
I0212 03:01:59.032632 22509476222784 run_lib.py:133] step: 511550, training_loss: 3.69215e-02
I0212 03:02:17.514403 22509476222784 run_lib.py:133] step: 511600, training_loss: 3.69139e-02
I0212 03:02:17.721670 22509476222784 run_lib.py:146] step: 511600, eval_loss: 3.47528e-02
I0212 03:02:36.372406 22509476222784 run_lib.py:133] step: 511650, training_loss: 4.02146e-02
I0212 03:02:55.037557 22509476222784 run_lib.py:133] step: 511700, training_loss: 4.53868e-02
I0212 03:02:55.201935 22509476222784 run_lib.py:146] step: 511700, eval_loss: 3.44041e-02
I0212 03:03:13.750376 22509476222784 run_lib.py:133] step: 511750, training_loss: 4.81001e-02
I0212 03:03:32.265319 22509476222784 run_lib.py:133] step: 511800, training_loss: 5.24280e-02
I0212 03:03:32.466003 22509476222784 run_lib.py:146] step: 511800, eval_loss: 3.80458e-02
I0212 03:03:51.144081 22509476222784 run_lib.py:133] step: 511850, training_loss: 4.17089e-02
I0212 03:04:09.656918 22509476222784 run_lib.py:133] step: 511900, training_loss: 3.84117e-02
I0212 03:04:09.882372 22509476222784 run_lib.py:146] step: 511900, eval_loss: 2.60904e-02
I0212 03:04:28.497459 22509476222784 run_lib.py:133] step: 511950, training_loss: 4.86742e-02
I0212 03:04:47.091582 22509476222784 run_lib.py:133] step: 512000, training_loss: 3.84345e-02
I0212 03:04:47.255594 22509476222784 run_lib.py:146] step: 512000, eval_loss: 4.39470e-02
I0212 03:05:05.949201 22509476222784 run_lib.py:133] step: 512050, training_loss: 4.00504e-02
I0212 03:05:24.474757 22509476222784 run_lib.py:133] step: 512100, training_loss: 4.71494e-02
I0212 03:05:24.639739 22509476222784 run_lib.py:146] step: 512100, eval_loss: 4.96378e-02
I0212 03:05:43.313536 22509476222784 run_lib.py:133] step: 512150, training_loss: 4.04815e-02
I0212 03:06:01.810475 22509476222784 run_lib.py:133] step: 512200, training_loss: 4.85229e-02
I0212 03:06:01.970272 22509476222784 run_lib.py:146] step: 512200, eval_loss: 4.70781e-02
I0212 03:06:20.506987 22509476222784 run_lib.py:133] step: 512250, training_loss: 5.24743e-02
I0212 03:06:39.262696 22509476222784 run_lib.py:133] step: 512300, training_loss: 4.59472e-02
I0212 03:06:39.449800 22509476222784 run_lib.py:146] step: 512300, eval_loss: 4.13644e-02
I0212 03:06:57.957416 22509476222784 run_lib.py:133] step: 512350, training_loss: 3.93165e-02
I0212 03:07:16.458303 22509476222784 run_lib.py:133] step: 512400, training_loss: 3.78952e-02
I0212 03:07:16.627688 22509476222784 run_lib.py:146] step: 512400, eval_loss: 3.91476e-02
I0212 03:07:35.140487 22509476222784 run_lib.py:133] step: 512450, training_loss: 3.80169e-02
I0212 03:07:53.520159 22509476222784 run_lib.py:133] step: 512500, training_loss: 3.23938e-02
I0212 03:07:53.695544 22509476222784 run_lib.py:146] step: 512500, eval_loss: 4.93257e-02
I0212 03:08:12.265249 22509476222784 run_lib.py:133] step: 512550, training_loss: 4.84941e-02
I0212 03:08:30.783341 22509476222784 run_lib.py:133] step: 512600, training_loss: 4.60650e-02
I0212 03:08:30.968901 22509476222784 run_lib.py:146] step: 512600, eval_loss: 3.70022e-02
I0212 03:08:49.525379 22509476222784 run_lib.py:133] step: 512650, training_loss: 4.46687e-02
I0212 03:09:08.172668 22509476222784 run_lib.py:133] step: 512700, training_loss: 4.44268e-02
I0212 03:09:08.331602 22509476222784 run_lib.py:146] step: 512700, eval_loss: 3.88523e-02
I0212 03:09:26.806601 22509476222784 run_lib.py:133] step: 512750, training_loss: 4.56774e-02
I0212 03:09:45.385908 22509476222784 run_lib.py:133] step: 512800, training_loss: 4.82694e-02
I0212 03:09:45.559990 22509476222784 run_lib.py:146] step: 512800, eval_loss: 4.45394e-02
I0212 03:10:04.099683 22509476222784 run_lib.py:133] step: 512850, training_loss: 3.49672e-02
I0212 03:10:22.831529 22509476222784 run_lib.py:133] step: 512900, training_loss: 3.42989e-02
I0212 03:10:23.013557 22509476222784 run_lib.py:146] step: 512900, eval_loss: 4.91916e-02
I0212 03:10:41.528206 22509476222784 run_lib.py:133] step: 512950, training_loss: 5.13253e-02
I0212 03:11:00.063440 22509476222784 run_lib.py:133] step: 513000, training_loss: 4.81169e-02
I0212 03:11:00.225771 22509476222784 run_lib.py:146] step: 513000, eval_loss: 4.58175e-02
I0212 03:11:18.731475 22509476222784 run_lib.py:133] step: 513050, training_loss: 4.84526e-02
I0212 03:11:37.322769 22509476222784 run_lib.py:133] step: 513100, training_loss: 3.69094e-02
I0212 03:11:37.517906 22509476222784 run_lib.py:146] step: 513100, eval_loss: 4.63767e-02
I0212 03:11:56.278872 22509476222784 run_lib.py:133] step: 513150, training_loss: 3.67581e-02
I0212 03:12:14.867259 22509476222784 run_lib.py:133] step: 513200, training_loss: 4.77251e-02
I0212 03:12:15.028704 22509476222784 run_lib.py:146] step: 513200, eval_loss: 4.24029e-02
I0212 03:12:33.450136 22509476222784 run_lib.py:133] step: 513250, training_loss: 3.83659e-02
I0212 03:12:51.974423 22509476222784 run_lib.py:133] step: 513300, training_loss: 5.30388e-02
I0212 03:12:52.196932 22509476222784 run_lib.py:146] step: 513300, eval_loss: 3.49642e-02
I0212 03:13:10.943397 22509476222784 run_lib.py:133] step: 513350, training_loss: 5.24211e-02
I0212 03:13:29.480680 22509476222784 run_lib.py:133] step: 513400, training_loss: 3.90542e-02
I0212 03:13:29.675878 22509476222784 run_lib.py:146] step: 513400, eval_loss: 4.20912e-02
I0212 03:13:48.309955 22509476222784 run_lib.py:133] step: 513450, training_loss: 2.56762e-02
I0212 03:14:06.846222 22509476222784 run_lib.py:133] step: 513500, training_loss: 4.81165e-02
I0212 03:14:07.008524 22509476222784 run_lib.py:146] step: 513500, eval_loss: 4.23039e-02
I0212 03:14:25.595585 22509476222784 run_lib.py:133] step: 513550, training_loss: 4.48574e-02
I0212 03:14:44.134096 22509476222784 run_lib.py:133] step: 513600, training_loss: 3.73819e-02
I0212 03:14:44.296810 22509476222784 run_lib.py:146] step: 513600, eval_loss: 3.96531e-02
I0212 03:15:02.840380 22509476222784 run_lib.py:133] step: 513650, training_loss: 3.46689e-02
I0212 03:15:21.559649 22509476222784 run_lib.py:133] step: 513700, training_loss: 4.53776e-02
I0212 03:15:21.721726 22509476222784 run_lib.py:146] step: 513700, eval_loss: 3.37015e-02
I0212 03:15:40.189210 22509476222784 run_lib.py:133] step: 513750, training_loss: 4.85122e-02
I0212 03:15:58.843476 22509476222784 run_lib.py:133] step: 513800, training_loss: 4.54570e-02
I0212 03:15:59.208810 22509476222784 run_lib.py:146] step: 513800, eval_loss: 5.08153e-02
I0212 03:16:17.782805 22509476222784 run_lib.py:133] step: 513850, training_loss: 3.86215e-02
I0212 03:16:36.306045 22509476222784 run_lib.py:133] step: 513900, training_loss: 4.74062e-02
I0212 03:16:36.494654 22509476222784 run_lib.py:146] step: 513900, eval_loss: 2.89789e-02
I0212 03:16:55.203595 22509476222784 run_lib.py:133] step: 513950, training_loss: 4.64783e-02
I0212 03:17:13.679639 22509476222784 run_lib.py:133] step: 514000, training_loss: 4.20172e-02
I0212 03:17:13.843468 22509476222784 run_lib.py:146] step: 514000, eval_loss: 3.65378e-02
I0212 03:17:32.332351 22509476222784 run_lib.py:133] step: 514050, training_loss: 4.76164e-02
I0212 03:17:51.034473 22509476222784 run_lib.py:133] step: 514100, training_loss: 3.73392e-02
I0212 03:17:51.223398 22509476222784 run_lib.py:146] step: 514100, eval_loss: 4.25219e-02
I0212 03:18:09.784856 22509476222784 run_lib.py:133] step: 514150, training_loss: 4.51209e-02
I0212 03:18:28.264870 22509476222784 run_lib.py:133] step: 514200, training_loss: 4.04073e-02
I0212 03:18:28.616568 22509476222784 run_lib.py:146] step: 514200, eval_loss: 5.19691e-02
I0212 03:18:47.157721 22509476222784 run_lib.py:133] step: 514250, training_loss: 3.97401e-02
I0212 03:19:05.665423 22509476222784 run_lib.py:133] step: 514300, training_loss: 3.80748e-02
I0212 03:19:05.830774 22509476222784 run_lib.py:146] step: 514300, eval_loss: 4.57067e-02
I0212 03:19:24.260153 22509476222784 run_lib.py:133] step: 514350, training_loss: 3.59456e-02
I0212 03:19:42.756946 22509476222784 run_lib.py:133] step: 514400, training_loss: 4.10171e-02
I0212 03:19:42.921883 22509476222784 run_lib.py:146] step: 514400, eval_loss: 4.20404e-02
I0212 03:20:01.638741 22509476222784 run_lib.py:133] step: 514450, training_loss: 3.79651e-02
I0212 03:20:20.231571 22509476222784 run_lib.py:133] step: 514500, training_loss: 3.82167e-02
I0212 03:20:20.396473 22509476222784 run_lib.py:146] step: 514500, eval_loss: 4.36450e-02
I0212 03:20:38.871907 22509476222784 run_lib.py:133] step: 514550, training_loss: 4.72930e-02
I0212 03:20:57.398763 22509476222784 run_lib.py:133] step: 514600, training_loss: 4.38587e-02
I0212 03:20:57.580480 22509476222784 run_lib.py:146] step: 514600, eval_loss: 4.00275e-02
I0212 03:21:16.235039 22509476222784 run_lib.py:133] step: 514650, training_loss: 4.47132e-02
I0212 03:21:34.879255 22509476222784 run_lib.py:133] step: 514700, training_loss: 4.63907e-02
I0212 03:21:35.052583 22509476222784 run_lib.py:146] step: 514700, eval_loss: 4.07128e-02
I0212 03:21:53.555537 22509476222784 run_lib.py:133] step: 514750, training_loss: 4.70877e-02
I0212 03:22:12.038427 22509476222784 run_lib.py:133] step: 514800, training_loss: 4.83111e-02
I0212 03:22:12.228888 22509476222784 run_lib.py:146] step: 514800, eval_loss: 3.82093e-02
I0212 03:22:30.879490 22509476222784 run_lib.py:133] step: 514850, training_loss: 4.37960e-02
I0212 03:22:49.350574 22509476222784 run_lib.py:133] step: 514900, training_loss: 4.81463e-02
I0212 03:22:49.519173 22509476222784 run_lib.py:146] step: 514900, eval_loss: 4.41072e-02
I0212 03:23:08.220309 22509476222784 run_lib.py:133] step: 514950, training_loss: 5.85144e-02
I0212 03:23:26.770458 22509476222784 run_lib.py:133] step: 515000, training_loss: 3.48945e-02
I0212 03:23:26.946515 22509476222784 run_lib.py:146] step: 515000, eval_loss: 4.82957e-02
I0212 03:23:45.615060 22509476222784 run_lib.py:133] step: 515050, training_loss: 3.84154e-02
I0212 03:24:04.126417 22509476222784 run_lib.py:133] step: 515100, training_loss: 5.19392e-02
I0212 03:24:04.287243 22509476222784 run_lib.py:146] step: 515100, eval_loss: 4.77454e-02
I0212 03:24:22.789753 22509476222784 run_lib.py:133] step: 515150, training_loss: 3.06486e-02
I0212 03:24:41.506666 22509476222784 run_lib.py:133] step: 515200, training_loss: 4.20005e-02
I0212 03:24:41.681876 22509476222784 run_lib.py:146] step: 515200, eval_loss: 6.04521e-02
I0212 03:25:00.197307 22509476222784 run_lib.py:133] step: 515250, training_loss: 4.30629e-02
I0212 03:25:18.870401 22509476222784 run_lib.py:133] step: 515300, training_loss: 3.53317e-02
I0212 03:25:19.039804 22509476222784 run_lib.py:146] step: 515300, eval_loss: 4.06944e-02
I0212 03:25:37.565345 22509476222784 run_lib.py:133] step: 515350, training_loss: 5.49789e-02
I0212 03:25:56.114177 22509476222784 run_lib.py:133] step: 515400, training_loss: 4.29379e-02
I0212 03:25:56.277621 22509476222784 run_lib.py:146] step: 515400, eval_loss: 4.05829e-02
I0212 03:26:14.910426 22509476222784 run_lib.py:133] step: 515450, training_loss: 4.33824e-02
I0212 03:26:33.464984 22509476222784 run_lib.py:133] step: 515500, training_loss: 3.54433e-02
I0212 03:26:33.630861 22509476222784 run_lib.py:146] step: 515500, eval_loss: 5.75073e-02
I0212 03:26:52.160596 22509476222784 run_lib.py:133] step: 515550, training_loss: 4.97181e-02
I0212 03:27:10.615005 22509476222784 run_lib.py:133] step: 515600, training_loss: 4.19070e-02
I0212 03:27:10.774672 22509476222784 run_lib.py:146] step: 515600, eval_loss: 3.88557e-02
I0212 03:27:29.457747 22509476222784 run_lib.py:133] step: 515650, training_loss: 3.67866e-02
I0212 03:27:47.928091 22509476222784 run_lib.py:133] step: 515700, training_loss: 3.33615e-02
I0212 03:27:48.093761 22509476222784 run_lib.py:146] step: 515700, eval_loss: 4.94484e-02
I0212 03:28:06.804346 22509476222784 run_lib.py:133] step: 515750, training_loss: 4.13759e-02
I0212 03:28:25.431114 22509476222784 run_lib.py:133] step: 515800, training_loss: 4.03663e-02
I0212 03:28:25.600814 22509476222784 run_lib.py:146] step: 515800, eval_loss: 5.38107e-02
I0212 03:28:44.082401 22509476222784 run_lib.py:133] step: 515850, training_loss: 4.76263e-02
I0212 03:29:02.575660 22509476222784 run_lib.py:133] step: 515900, training_loss: 3.64841e-02
I0212 03:29:02.740824 22509476222784 run_lib.py:146] step: 515900, eval_loss: 5.32982e-02
I0212 03:29:21.429623 22509476222784 run_lib.py:133] step: 515950, training_loss: 4.58798e-02
I0212 03:29:40.088644 22509476222784 run_lib.py:133] step: 516000, training_loss: 4.25461e-02
I0212 03:29:40.251859 22509476222784 run_lib.py:146] step: 516000, eval_loss: 3.57266e-02
I0212 03:29:58.798623 22509476222784 run_lib.py:133] step: 516050, training_loss: 4.31840e-02
I0212 03:30:17.241231 22509476222784 run_lib.py:133] step: 516100, training_loss: 3.59827e-02
I0212 03:30:17.403504 22509476222784 run_lib.py:146] step: 516100, eval_loss: 3.28240e-02
I0212 03:30:36.059758 22509476222784 run_lib.py:133] step: 516150, training_loss: 4.99916e-02
I0212 03:30:54.582905 22509476222784 run_lib.py:133] step: 516200, training_loss: 4.58995e-02
I0212 03:30:54.771008 22509476222784 run_lib.py:146] step: 516200, eval_loss: 3.84645e-02
I0212 03:31:13.449733 22509476222784 run_lib.py:133] step: 516250, training_loss: 3.50730e-02
I0212 03:31:31.932508 22509476222784 run_lib.py:133] step: 516300, training_loss: 3.63318e-02
I0212 03:31:32.096891 22509476222784 run_lib.py:146] step: 516300, eval_loss: 4.14548e-02
I0212 03:31:50.796884 22509476222784 run_lib.py:133] step: 516350, training_loss: 3.13046e-02
I0212 03:32:09.292091 22509476222784 run_lib.py:133] step: 516400, training_loss: 4.94357e-02
I0212 03:32:09.456830 22509476222784 run_lib.py:146] step: 516400, eval_loss: 4.12064e-02
I0212 03:32:28.094921 22509476222784 run_lib.py:133] step: 516450, training_loss: 3.92396e-02
I0212 03:32:46.696678 22509476222784 run_lib.py:133] step: 516500, training_loss: 4.29722e-02
I0212 03:32:46.861905 22509476222784 run_lib.py:146] step: 516500, eval_loss: 4.42451e-02
I0212 03:33:05.481797 22509476222784 run_lib.py:133] step: 516550, training_loss: 3.43607e-02
I0212 03:33:24.269191 22509476222784 run_lib.py:133] step: 516600, training_loss: 4.51493e-02
I0212 03:33:24.432661 22509476222784 run_lib.py:146] step: 516600, eval_loss: 4.99922e-02
I0212 03:33:42.956184 22509476222784 run_lib.py:133] step: 516650, training_loss: 3.45848e-02
I0212 03:34:01.391357 22509476222784 run_lib.py:133] step: 516700, training_loss: 3.78738e-02
I0212 03:34:01.556839 22509476222784 run_lib.py:146] step: 516700, eval_loss: 4.07999e-02
I0212 03:34:20.230819 22509476222784 run_lib.py:133] step: 516750, training_loss: 4.10217e-02
I0212 03:34:38.906491 22509476222784 run_lib.py:133] step: 516800, training_loss: 4.72811e-02
I0212 03:34:39.079597 22509476222784 run_lib.py:146] step: 516800, eval_loss: 3.99463e-02
I0212 03:34:57.618268 22509476222784 run_lib.py:133] step: 516850, training_loss: 3.88128e-02
I0212 03:35:16.126881 22509476222784 run_lib.py:133] step: 516900, training_loss: 3.63479e-02
I0212 03:35:16.290763 22509476222784 run_lib.py:146] step: 516900, eval_loss: 5.32606e-02
I0212 03:35:34.821827 22509476222784 run_lib.py:133] step: 516950, training_loss: 3.61145e-02
I0212 03:35:53.521962 22509476222784 run_lib.py:133] step: 517000, training_loss: 4.62611e-02
I0212 03:35:53.684615 22509476222784 run_lib.py:146] step: 517000, eval_loss: 3.50363e-02
I0212 03:36:12.136735 22509476222784 run_lib.py:133] step: 517050, training_loss: 5.28277e-02
I0212 03:36:30.609468 22509476222784 run_lib.py:133] step: 517100, training_loss: 5.10397e-02
I0212 03:36:30.783293 22509476222784 run_lib.py:146] step: 517100, eval_loss: 4.20395e-02
I0212 03:36:49.314781 22509476222784 run_lib.py:133] step: 517150, training_loss: 3.38215e-02
I0212 03:37:08.025270 22509476222784 run_lib.py:133] step: 517200, training_loss: 3.85199e-02
I0212 03:37:08.205982 22509476222784 run_lib.py:146] step: 517200, eval_loss: 4.70254e-02
I0212 03:37:26.739270 22509476222784 run_lib.py:133] step: 517250, training_loss: 4.32111e-02
I0212 03:37:45.348898 22509476222784 run_lib.py:133] step: 517300, training_loss: 3.90729e-02
I0212 03:37:45.515712 22509476222784 run_lib.py:146] step: 517300, eval_loss: 4.78666e-02
I0212 03:38:04.093954 22509476222784 run_lib.py:133] step: 517350, training_loss: 3.71954e-02
I0212 03:38:22.669777 22509476222784 run_lib.py:133] step: 517400, training_loss: 4.65245e-02
I0212 03:38:22.832920 22509476222784 run_lib.py:146] step: 517400, eval_loss: 4.26404e-02
I0212 03:38:41.513343 22509476222784 run_lib.py:133] step: 517450, training_loss: 4.90933e-02
I0212 03:39:00.093454 22509476222784 run_lib.py:133] step: 517500, training_loss: 4.42911e-02
I0212 03:39:00.273800 22509476222784 run_lib.py:146] step: 517500, eval_loss: 3.61526e-02
I0212 03:39:18.801697 22509476222784 run_lib.py:133] step: 517550, training_loss: 2.39409e-02
I0212 03:39:37.280788 22509476222784 run_lib.py:133] step: 517600, training_loss: 4.58118e-02
I0212 03:39:37.448884 22509476222784 run_lib.py:146] step: 517600, eval_loss: 3.87614e-02
I0212 03:39:56.139382 22509476222784 run_lib.py:133] step: 517650, training_loss: 4.30761e-02
I0212 03:40:14.690129 22509476222784 run_lib.py:133] step: 517700, training_loss: 4.44004e-02
I0212 03:40:14.854883 22509476222784 run_lib.py:146] step: 517700, eval_loss: 4.40005e-02
I0212 03:40:33.496768 22509476222784 run_lib.py:133] step: 517750, training_loss: 3.91512e-02
I0212 03:40:51.856628 22509476222784 run_lib.py:133] step: 517800, training_loss: 3.29307e-02
I0212 03:40:52.019724 22509476222784 run_lib.py:146] step: 517800, eval_loss: 4.64862e-02
I0212 03:41:10.604806 22509476222784 run_lib.py:133] step: 517850, training_loss: 4.57064e-02
I0212 03:41:29.078646 22509476222784 run_lib.py:133] step: 517900, training_loss: 4.22106e-02
I0212 03:41:29.241016 22509476222784 run_lib.py:146] step: 517900, eval_loss: 3.98334e-02
I0212 03:41:47.834686 22509476222784 run_lib.py:133] step: 517950, training_loss: 4.98307e-02
I0212 03:42:06.543190 22509476222784 run_lib.py:133] step: 518000, training_loss: 3.65753e-02
I0212 03:42:06.706572 22509476222784 run_lib.py:146] step: 518000, eval_loss: 3.80134e-02
I0212 03:42:25.186467 22509476222784 run_lib.py:133] step: 518050, training_loss: 3.61447e-02
I0212 03:42:43.860648 22509476222784 run_lib.py:133] step: 518100, training_loss: 4.21536e-02
I0212 03:42:44.034643 22509476222784 run_lib.py:146] step: 518100, eval_loss: 3.75989e-02
I0212 03:43:02.565553 22509476222784 run_lib.py:133] step: 518150, training_loss: 4.67835e-02
I0212 03:43:21.162844 22509476222784 run_lib.py:133] step: 518200, training_loss: 4.46090e-02
I0212 03:43:21.352771 22509476222784 run_lib.py:146] step: 518200, eval_loss: 4.50124e-02
I0212 03:43:40.071626 22509476222784 run_lib.py:133] step: 518250, training_loss: 3.71557e-02
I0212 03:43:58.561608 22509476222784 run_lib.py:133] step: 518300, training_loss: 5.31882e-02
I0212 03:43:58.726703 22509476222784 run_lib.py:146] step: 518300, eval_loss: 4.27719e-02
I0212 03:44:17.257525 22509476222784 run_lib.py:133] step: 518350, training_loss: 3.04949e-02
I0212 03:44:35.875243 22509476222784 run_lib.py:133] step: 518400, training_loss: 4.18848e-02
I0212 03:44:36.036872 22509476222784 run_lib.py:146] step: 518400, eval_loss: 4.05310e-02
I0212 03:44:54.620451 22509476222784 run_lib.py:133] step: 518450, training_loss: 3.78754e-02
I0212 03:45:13.217822 22509476222784 run_lib.py:133] step: 518500, training_loss: 4.03486e-02
I0212 03:45:13.381759 22509476222784 run_lib.py:146] step: 518500, eval_loss: 4.06406e-02
I0212 03:45:32.044124 22509476222784 run_lib.py:133] step: 518550, training_loss: 3.88673e-02
I0212 03:45:50.590962 22509476222784 run_lib.py:133] step: 518600, training_loss: 4.90393e-02
I0212 03:45:50.755775 22509476222784 run_lib.py:146] step: 518600, eval_loss: 3.61930e-02
I0212 03:46:09.151854 22509476222784 run_lib.py:133] step: 518650, training_loss: 4.01480e-02
I0212 03:46:27.679934 22509476222784 run_lib.py:133] step: 518700, training_loss: 4.66928e-02
I0212 03:46:27.873619 22509476222784 run_lib.py:146] step: 518700, eval_loss: 5.45782e-02
I0212 03:46:46.572711 22509476222784 run_lib.py:133] step: 518750, training_loss: 3.97385e-02
I0212 03:47:05.269852 22509476222784 run_lib.py:133] step: 518800, training_loss: 3.69855e-02
I0212 03:47:05.475622 22509476222784 run_lib.py:146] step: 518800, eval_loss: 4.85681e-02
I0212 03:47:24.012482 22509476222784 run_lib.py:133] step: 518850, training_loss: 4.47711e-02
I0212 03:47:42.499050 22509476222784 run_lib.py:133] step: 518900, training_loss: 5.56708e-02
I0212 03:47:42.692612 22509476222784 run_lib.py:146] step: 518900, eval_loss: 4.07329e-02
I0212 03:48:01.370432 22509476222784 run_lib.py:133] step: 518950, training_loss: 3.33556e-02
I0212 03:48:19.873548 22509476222784 run_lib.py:133] step: 519000, training_loss: 4.47563e-02
I0212 03:48:20.047478 22509476222784 run_lib.py:146] step: 519000, eval_loss: 3.29601e-02
I0212 03:48:38.746575 22509476222784 run_lib.py:133] step: 519050, training_loss: 4.50494e-02
I0212 03:48:57.275193 22509476222784 run_lib.py:133] step: 519100, training_loss: 3.91569e-02
I0212 03:48:57.440709 22509476222784 run_lib.py:146] step: 519100, eval_loss: 4.63072e-02
I0212 03:49:16.131879 22509476222784 run_lib.py:133] step: 519150, training_loss: 4.53755e-02
I0212 03:49:34.623989 22509476222784 run_lib.py:133] step: 519200, training_loss: 5.45049e-02
I0212 03:49:34.790766 22509476222784 run_lib.py:146] step: 519200, eval_loss: 3.88180e-02
I0212 03:49:53.449742 22509476222784 run_lib.py:133] step: 519250, training_loss: 3.33778e-02
I0212 03:50:12.112662 22509476222784 run_lib.py:133] step: 519300, training_loss: 4.14153e-02
I0212 03:50:12.275940 22509476222784 run_lib.py:146] step: 519300, eval_loss: 3.53493e-02
I0212 03:50:30.782078 22509476222784 run_lib.py:133] step: 519350, training_loss: 4.46721e-02
I0212 03:50:49.459858 22509476222784 run_lib.py:133] step: 519400, training_loss: 5.25950e-02
I0212 03:50:49.628608 22509476222784 run_lib.py:146] step: 519400, eval_loss: 4.53212e-02
I0212 03:51:08.109463 22509476222784 run_lib.py:133] step: 519450, training_loss: 4.18085e-02
I0212 03:51:26.616038 22509476222784 run_lib.py:133] step: 519500, training_loss: 4.84078e-02
I0212 03:51:26.784772 22509476222784 run_lib.py:146] step: 519500, eval_loss: 4.23337e-02
I0212 03:51:45.564843 22509476222784 run_lib.py:133] step: 519550, training_loss: 4.52647e-02
I0212 03:52:04.175328 22509476222784 run_lib.py:133] step: 519600, training_loss: 4.45995e-02
I0212 03:52:04.355852 22509476222784 run_lib.py:146] step: 519600, eval_loss: 4.62927e-02
I0212 03:52:23.041218 22509476222784 run_lib.py:133] step: 519650, training_loss: 5.02283e-02
I0212 03:52:41.496946 22509476222784 run_lib.py:133] step: 519700, training_loss: 4.47754e-02
I0212 03:52:41.661538 22509476222784 run_lib.py:146] step: 519700, eval_loss: 5.25374e-02
I0212 03:53:00.217700 22509476222784 run_lib.py:133] step: 519750, training_loss: 4.14611e-02
I0212 03:53:18.895107 22509476222784 run_lib.py:133] step: 519800, training_loss: 3.56034e-02
I0212 03:53:19.075435 22509476222784 run_lib.py:146] step: 519800, eval_loss: 5.07990e-02
I0212 03:53:37.648700 22509476222784 run_lib.py:133] step: 519850, training_loss: 3.76267e-02
I0212 03:53:56.170431 22509476222784 run_lib.py:133] step: 519900, training_loss: 4.57892e-02
I0212 03:53:56.334645 22509476222784 run_lib.py:146] step: 519900, eval_loss: 3.18460e-02
I0212 03:54:14.816163 22509476222784 run_lib.py:133] step: 519950, training_loss: 4.61266e-02
I0212 03:54:33.523937 22509476222784 run_lib.py:133] step: 520000, training_loss: 3.42015e-02
I0212 03:54:34.261688 22509476222784 run_lib.py:146] step: 520000, eval_loss: 5.47842e-02
I0212 03:54:55.452624 22509476222784 run_lib.py:133] step: 520050, training_loss: 4.17689e-02
I0212 03:55:14.249546 22509476222784 run_lib.py:133] step: 520100, training_loss: 3.99772e-02
I0212 03:55:14.435741 22509476222784 run_lib.py:146] step: 520100, eval_loss: 2.99158e-02
I0212 03:55:32.912253 22509476222784 run_lib.py:133] step: 520150, training_loss: 4.00719e-02
I0212 03:55:51.400749 22509476222784 run_lib.py:133] step: 520200, training_loss: 5.95927e-02
I0212 03:55:51.564724 22509476222784 run_lib.py:146] step: 520200, eval_loss: 4.51872e-02
I0212 03:56:10.021055 22509476222784 run_lib.py:133] step: 520250, training_loss: 4.34930e-02
I0212 03:56:28.676808 22509476222784 run_lib.py:133] step: 520300, training_loss: 4.02373e-02
I0212 03:56:28.862795 22509476222784 run_lib.py:146] step: 520300, eval_loss: 4.15155e-02
I0212 03:56:47.445983 22509476222784 run_lib.py:133] step: 520350, training_loss: 5.75947e-02
I0212 03:57:05.991498 22509476222784 run_lib.py:133] step: 520400, training_loss: 4.12170e-02
I0212 03:57:06.151911 22509476222784 run_lib.py:146] step: 520400, eval_loss: 4.15022e-02
I0212 03:57:24.683573 22509476222784 run_lib.py:133] step: 520450, training_loss: 4.31383e-02
I0212 03:57:43.158735 22509476222784 run_lib.py:133] step: 520500, training_loss: 4.33174e-02
I0212 03:57:43.322812 22509476222784 run_lib.py:146] step: 520500, eval_loss: 4.10895e-02
I0212 03:58:01.942049 22509476222784 run_lib.py:133] step: 520550, training_loss: 4.15092e-02
I0212 03:58:20.536805 22509476222784 run_lib.py:133] step: 520600, training_loss: 5.35637e-02
I0212 03:58:20.710542 22509476222784 run_lib.py:146] step: 520600, eval_loss: 5.27834e-02
I0212 03:58:39.214963 22509476222784 run_lib.py:133] step: 520650, training_loss: 5.00920e-02
I0212 03:58:57.680605 22509476222784 run_lib.py:133] step: 520700, training_loss: 4.13700e-02
I0212 03:58:57.844347 22509476222784 run_lib.py:146] step: 520700, eval_loss: 4.38700e-02
I0212 03:59:16.535650 22509476222784 run_lib.py:133] step: 520750, training_loss: 3.65331e-02
I0212 03:59:35.033336 22509476222784 run_lib.py:133] step: 520800, training_loss: 4.48714e-02
I0212 03:59:35.223604 22509476222784 run_lib.py:146] step: 520800, eval_loss: 4.09144e-02
I0212 03:59:53.881380 22509476222784 run_lib.py:133] step: 520850, training_loss: 4.06533e-02
I0212 04:00:12.408061 22509476222784 run_lib.py:133] step: 520900, training_loss: 4.16631e-02
I0212 04:00:12.573843 22509476222784 run_lib.py:146] step: 520900, eval_loss: 4.07251e-02
I0212 04:00:31.273243 22509476222784 run_lib.py:133] step: 520950, training_loss: 4.46861e-02
I0212 04:00:49.784006 22509476222784 run_lib.py:133] step: 521000, training_loss: 4.08768e-02
I0212 04:00:49.950866 22509476222784 run_lib.py:146] step: 521000, eval_loss: 3.49233e-02
I0212 04:01:08.429544 22509476222784 run_lib.py:133] step: 521050, training_loss: 4.89520e-02
I0212 04:01:27.080027 22509476222784 run_lib.py:133] step: 521100, training_loss: 4.68374e-02
I0212 04:01:27.286627 22509476222784 run_lib.py:146] step: 521100, eval_loss: 4.88785e-02
I0212 04:01:45.859213 22509476222784 run_lib.py:133] step: 521150, training_loss: 3.19547e-02
I0212 04:02:04.555443 22509476222784 run_lib.py:133] step: 521200, training_loss: 3.30716e-02
I0212 04:02:04.718957 22509476222784 run_lib.py:146] step: 521200, eval_loss: 4.04296e-02
I0212 04:02:23.268210 22509476222784 run_lib.py:133] step: 521250, training_loss: 4.31189e-02
I0212 04:02:41.782895 22509476222784 run_lib.py:133] step: 521300, training_loss: 5.64334e-02
I0212 04:02:41.941617 22509476222784 run_lib.py:146] step: 521300, eval_loss: 3.47351e-02
I0212 04:03:00.555613 22509476222784 run_lib.py:133] step: 521350, training_loss: 3.97272e-02
I0212 04:03:19.108407 22509476222784 run_lib.py:133] step: 521400, training_loss: 4.71371e-02
I0212 04:03:19.290857 22509476222784 run_lib.py:146] step: 521400, eval_loss: 4.48860e-02
I0212 04:03:37.862915 22509476222784 run_lib.py:133] step: 521450, training_loss: 4.26991e-02
I0212 04:03:56.590824 22509476222784 run_lib.py:133] step: 521500, training_loss: 4.04189e-02
I0212 04:03:56.772816 22509476222784 run_lib.py:146] step: 521500, eval_loss: 4.91745e-02
I0212 04:04:15.256887 22509476222784 run_lib.py:133] step: 521550, training_loss: 2.91028e-02
I0212 04:04:33.782212 22509476222784 run_lib.py:133] step: 521600, training_loss: 4.50749e-02
I0212 04:04:34.092594 22509476222784 run_lib.py:146] step: 521600, eval_loss: 4.47988e-02
I0212 04:04:52.606917 22509476222784 run_lib.py:133] step: 521650, training_loss: 3.37759e-02
I0212 04:05:11.161764 22509476222784 run_lib.py:133] step: 521700, training_loss: 3.80193e-02
I0212 04:05:11.372446 22509476222784 run_lib.py:146] step: 521700, eval_loss: 4.06634e-02
I0212 04:05:29.910600 22509476222784 run_lib.py:133] step: 521750, training_loss: 4.41103e-02
I0212 04:05:48.395224 22509476222784 run_lib.py:133] step: 521800, training_loss: 4.08076e-02
I0212 04:05:48.555744 22509476222784 run_lib.py:146] step: 521800, eval_loss: 3.69029e-02
I0212 04:06:07.295226 22509476222784 run_lib.py:133] step: 521850, training_loss: 4.47065e-02
I0212 04:06:25.903394 22509476222784 run_lib.py:133] step: 521900, training_loss: 4.11920e-02
I0212 04:06:26.082704 22509476222784 run_lib.py:146] step: 521900, eval_loss: 5.26995e-02
I0212 04:06:44.591454 22509476222784 run_lib.py:133] step: 521950, training_loss: 4.41335e-02
I0212 04:07:03.087320 22509476222784 run_lib.py:133] step: 522000, training_loss: 4.93789e-02
I0212 04:07:03.265703 22509476222784 run_lib.py:146] step: 522000, eval_loss: 4.82448e-02
I0212 04:07:21.924050 22509476222784 run_lib.py:133] step: 522050, training_loss: 3.50612e-02
I0212 04:07:40.491603 22509476222784 run_lib.py:133] step: 522100, training_loss: 4.16645e-02
I0212 04:07:40.673584 22509476222784 run_lib.py:146] step: 522100, eval_loss: 3.10022e-02
I0212 04:07:59.146388 22509476222784 run_lib.py:133] step: 522150, training_loss: 4.22432e-02
I0212 04:08:17.669510 22509476222784 run_lib.py:133] step: 522200, training_loss: 4.11649e-02
I0212 04:08:17.852772 22509476222784 run_lib.py:146] step: 522200, eval_loss: 4.49728e-02
I0212 04:08:36.557423 22509476222784 run_lib.py:133] step: 522250, training_loss: 5.32096e-02
I0212 04:08:55.058673 22509476222784 run_lib.py:133] step: 522300, training_loss: 4.37550e-02
I0212 04:08:55.241129 22509476222784 run_lib.py:146] step: 522300, eval_loss: 5.71699e-02
I0212 04:09:13.780379 22509476222784 run_lib.py:133] step: 522350, training_loss: 3.43932e-02
I0212 04:09:32.213540 22509476222784 run_lib.py:133] step: 522400, training_loss: 3.99998e-02
I0212 04:09:32.379158 22509476222784 run_lib.py:146] step: 522400, eval_loss: 4.16838e-02
I0212 04:09:50.998716 22509476222784 run_lib.py:133] step: 522450, training_loss: 4.44381e-02
I0212 04:10:09.562417 22509476222784 run_lib.py:133] step: 522500, training_loss: 4.29420e-02
I0212 04:10:09.744823 22509476222784 run_lib.py:146] step: 522500, eval_loss: 4.34839e-02
I0212 04:10:28.256904 22509476222784 run_lib.py:133] step: 522550, training_loss: 3.88396e-02
I0212 04:10:47.007105 22509476222784 run_lib.py:133] step: 522600, training_loss: 4.93411e-02
I0212 04:10:47.187031 22509476222784 run_lib.py:146] step: 522600, eval_loss: 3.37057e-02
I0212 04:11:05.729682 22509476222784 run_lib.py:133] step: 522650, training_loss: 5.26888e-02
I0212 04:11:24.380795 22509476222784 run_lib.py:133] step: 522700, training_loss: 4.03731e-02
I0212 04:11:24.554642 22509476222784 run_lib.py:146] step: 522700, eval_loss: 5.33706e-02
I0212 04:11:43.073714 22509476222784 run_lib.py:133] step: 522750, training_loss: 4.44304e-02
I0212 04:12:01.593106 22509476222784 run_lib.py:133] step: 522800, training_loss: 3.55104e-02
I0212 04:12:01.758073 22509476222784 run_lib.py:146] step: 522800, eval_loss: 5.19238e-02
I0212 04:12:20.356022 22509476222784 run_lib.py:133] step: 522850, training_loss: 4.54891e-02
I0212 04:12:39.077572 22509476222784 run_lib.py:133] step: 522900, training_loss: 4.91733e-02
I0212 04:12:39.242781 22509476222784 run_lib.py:146] step: 522900, eval_loss: 3.99981e-02
I0212 04:12:57.699706 22509476222784 run_lib.py:133] step: 522950, training_loss: 3.65967e-02
I0212 04:13:16.154099 22509476222784 run_lib.py:133] step: 523000, training_loss: 4.39794e-02
I0212 04:13:16.318573 22509476222784 run_lib.py:146] step: 523000, eval_loss: 3.85487e-02
I0212 04:13:34.952334 22509476222784 run_lib.py:133] step: 523050, training_loss: 4.26594e-02
I0212 04:13:53.509801 22509476222784 run_lib.py:133] step: 523100, training_loss: 3.52493e-02
I0212 04:13:53.688331 22509476222784 run_lib.py:146] step: 523100, eval_loss: 3.82194e-02
I0212 04:14:12.308626 22509476222784 run_lib.py:133] step: 523150, training_loss: 4.27535e-02
I0212 04:14:30.812211 22509476222784 run_lib.py:133] step: 523200, training_loss: 4.09450e-02
I0212 04:14:30.971362 22509476222784 run_lib.py:146] step: 523200, eval_loss: 4.52350e-02
I0212 04:14:49.412844 22509476222784 run_lib.py:133] step: 523250, training_loss: 4.71592e-02
I0212 04:15:07.904690 22509476222784 run_lib.py:133] step: 523300, training_loss: 4.47254e-02
I0212 04:15:08.087664 22509476222784 run_lib.py:146] step: 523300, eval_loss: 3.20827e-02
I0212 04:15:26.693709 22509476222784 run_lib.py:133] step: 523350, training_loss: 4.54821e-02
I0212 04:15:45.329116 22509476222784 run_lib.py:133] step: 523400, training_loss: 2.77605e-02
I0212 04:15:45.505548 22509476222784 run_lib.py:146] step: 523400, eval_loss: 4.45342e-02
I0212 04:16:04.017127 22509476222784 run_lib.py:133] step: 523450, training_loss: 4.68891e-02
I0212 04:16:22.502429 22509476222784 run_lib.py:133] step: 523500, training_loss: 3.23096e-02
I0212 04:16:22.758748 22509476222784 run_lib.py:146] step: 523500, eval_loss: 4.14444e-02
I0212 04:16:41.423250 22509476222784 run_lib.py:133] step: 523550, training_loss: 4.52856e-02
I0212 04:16:59.893530 22509476222784 run_lib.py:133] step: 523600, training_loss: 3.89140e-02
I0212 04:17:00.055488 22509476222784 run_lib.py:146] step: 523600, eval_loss: 3.89674e-02
I0212 04:17:18.666254 22509476222784 run_lib.py:133] step: 523650, training_loss: 4.89474e-02
I0212 04:17:37.185676 22509476222784 run_lib.py:133] step: 523700, training_loss: 3.80131e-02
I0212 04:17:37.349598 22509476222784 run_lib.py:146] step: 523700, eval_loss: 5.06102e-02
I0212 04:17:56.043759 22509476222784 run_lib.py:133] step: 523750, training_loss: 5.03447e-02
I0212 04:18:14.531316 22509476222784 run_lib.py:133] step: 523800, training_loss: 4.69406e-02
I0212 04:18:14.695543 22509476222784 run_lib.py:146] step: 523800, eval_loss: 3.59986e-02
I0212 04:18:33.328953 22509476222784 run_lib.py:133] step: 523850, training_loss: 4.40595e-02
I0212 04:18:51.798453 22509476222784 run_lib.py:133] step: 523900, training_loss: 3.77162e-02
I0212 04:18:52.001715 22509476222784 run_lib.py:146] step: 523900, eval_loss: 4.17544e-02
I0212 04:19:10.536911 22509476222784 run_lib.py:133] step: 523950, training_loss: 6.18065e-02
I0212 04:19:29.254387 22509476222784 run_lib.py:133] step: 524000, training_loss: 4.20448e-02
I0212 04:19:29.446610 22509476222784 run_lib.py:146] step: 524000, eval_loss: 4.59038e-02
I0212 04:19:47.965817 22509476222784 run_lib.py:133] step: 524050, training_loss: 6.05462e-02
I0212 04:20:06.431829 22509476222784 run_lib.py:133] step: 524100, training_loss: 4.34398e-02
I0212 04:20:06.601526 22509476222784 run_lib.py:146] step: 524100, eval_loss: 3.73293e-02
I0212 04:20:25.139237 22509476222784 run_lib.py:133] step: 524150, training_loss: 4.24486e-02
I0212 04:20:43.789304 22509476222784 run_lib.py:133] step: 524200, training_loss: 3.44207e-02
I0212 04:20:44.018107 22509476222784 run_lib.py:146] step: 524200, eval_loss: 4.72032e-02
I0212 04:21:02.604530 22509476222784 run_lib.py:133] step: 524250, training_loss: 3.66166e-02
I0212 04:21:21.106684 22509476222784 run_lib.py:133] step: 524300, training_loss: 4.48638e-02
I0212 04:21:21.300920 22509476222784 run_lib.py:146] step: 524300, eval_loss: 4.76842e-02
I0212 04:21:39.757984 22509476222784 run_lib.py:133] step: 524350, training_loss: 4.17078e-02
I0212 04:21:58.460918 22509476222784 run_lib.py:133] step: 524400, training_loss: 5.48487e-02
I0212 04:21:58.624886 22509476222784 run_lib.py:146] step: 524400, eval_loss: 4.71024e-02
I0212 04:22:17.147886 22509476222784 run_lib.py:133] step: 524450, training_loss: 3.56120e-02
I0212 04:22:35.739874 22509476222784 run_lib.py:133] step: 524500, training_loss: 4.41394e-02
I0212 04:22:35.918074 22509476222784 run_lib.py:146] step: 524500, eval_loss: 3.40372e-02
I0212 04:22:54.463194 22509476222784 run_lib.py:133] step: 524550, training_loss: 4.78636e-02
I0212 04:23:13.070808 22509476222784 run_lib.py:133] step: 524600, training_loss: 4.74875e-02
I0212 04:23:13.232340 22509476222784 run_lib.py:146] step: 524600, eval_loss: 4.01309e-02
I0212 04:23:31.776442 22509476222784 run_lib.py:133] step: 524650, training_loss: 4.66639e-02
I0212 04:23:50.336714 22509476222784 run_lib.py:133] step: 524700, training_loss: 4.17989e-02
I0212 04:23:50.497772 22509476222784 run_lib.py:146] step: 524700, eval_loss: 4.45129e-02
I0212 04:24:09.042927 22509476222784 run_lib.py:133] step: 524750, training_loss: 3.36115e-02
I0212 04:24:27.556600 22509476222784 run_lib.py:133] step: 524800, training_loss: 3.93436e-02
I0212 04:24:27.755605 22509476222784 run_lib.py:146] step: 524800, eval_loss: 4.10800e-02
I0212 04:24:46.461156 22509476222784 run_lib.py:133] step: 524850, training_loss: 3.84155e-02
I0212 04:25:04.996220 22509476222784 run_lib.py:133] step: 524900, training_loss: 4.83130e-02
I0212 04:25:05.164526 22509476222784 run_lib.py:146] step: 524900, eval_loss: 3.44735e-02
I0212 04:25:23.619302 22509476222784 run_lib.py:133] step: 524950, training_loss: 5.70715e-02
I0212 04:25:42.094127 22509476222784 run_lib.py:133] step: 525000, training_loss: 3.17714e-02
I0212 04:25:42.261915 22509476222784 run_lib.py:146] step: 525000, eval_loss: 4.91581e-02
I0212 04:26:00.964198 22509476222784 run_lib.py:133] step: 525050, training_loss: 4.19928e-02
I0212 04:26:19.439055 22509476222784 run_lib.py:133] step: 525100, training_loss: 4.52627e-02
I0212 04:26:19.609033 22509476222784 run_lib.py:146] step: 525100, eval_loss: 3.98824e-02
I0212 04:26:38.263849 22509476222784 run_lib.py:133] step: 525150, training_loss: 3.84415e-02
I0212 04:26:56.739644 22509476222784 run_lib.py:133] step: 525200, training_loss: 3.82061e-02
I0212 04:26:56.902684 22509476222784 run_lib.py:146] step: 525200, eval_loss: 3.12086e-02
I0212 04:27:15.559374 22509476222784 run_lib.py:133] step: 525250, training_loss: 4.66008e-02
I0212 04:27:34.105221 22509476222784 run_lib.py:133] step: 525300, training_loss: 3.93065e-02
I0212 04:27:34.284672 22509476222784 run_lib.py:146] step: 525300, eval_loss: 3.74438e-02
I0212 04:27:52.821478 22509476222784 run_lib.py:133] step: 525350, training_loss: 4.33351e-02
I0212 04:28:11.495687 22509476222784 run_lib.py:133] step: 525400, training_loss: 4.18340e-02
I0212 04:28:11.707665 22509476222784 run_lib.py:146] step: 525400, eval_loss: 4.32141e-02
I0212 04:28:30.275638 22509476222784 run_lib.py:133] step: 525450, training_loss: 4.36588e-02
I0212 04:28:48.908568 22509476222784 run_lib.py:133] step: 525500, training_loss: 4.66294e-02
I0212 04:28:49.071268 22509476222784 run_lib.py:146] step: 525500, eval_loss: 3.76929e-02
I0212 04:29:07.556337 22509476222784 run_lib.py:133] step: 525550, training_loss: 4.43429e-02
I0212 04:29:26.392317 22509476222784 run_lib.py:133] step: 525600, training_loss: 4.35693e-02
I0212 04:29:26.558883 22509476222784 run_lib.py:146] step: 525600, eval_loss: 4.15216e-02
I0212 04:29:45.277780 22509476222784 run_lib.py:133] step: 525650, training_loss: 4.37667e-02
I0212 04:30:03.775566 22509476222784 run_lib.py:133] step: 525700, training_loss: 3.93063e-02
I0212 04:30:03.947674 22509476222784 run_lib.py:146] step: 525700, eval_loss: 5.29477e-02
I0212 04:30:22.421084 22509476222784 run_lib.py:133] step: 525750, training_loss: 3.61107e-02
I0212 04:30:41.041764 22509476222784 run_lib.py:133] step: 525800, training_loss: 3.76761e-02
I0212 04:30:41.207916 22509476222784 run_lib.py:146] step: 525800, eval_loss: 4.81574e-02
I0212 04:30:59.694827 22509476222784 run_lib.py:133] step: 525850, training_loss: 5.14123e-02
I0212 04:31:18.215088 22509476222784 run_lib.py:133] step: 525900, training_loss: 4.85145e-02
I0212 04:31:18.379838 22509476222784 run_lib.py:146] step: 525900, eval_loss: 4.12982e-02
I0212 04:31:37.006017 22509476222784 run_lib.py:133] step: 525950, training_loss: 4.69964e-02
I0212 04:31:55.529892 22509476222784 run_lib.py:133] step: 526000, training_loss: 3.59169e-02
I0212 04:31:55.693693 22509476222784 run_lib.py:146] step: 526000, eval_loss: 3.70881e-02
I0212 04:32:14.200964 22509476222784 run_lib.py:133] step: 526050, training_loss: 4.42824e-02
I0212 04:32:32.639826 22509476222784 run_lib.py:133] step: 526100, training_loss: 4.18292e-02
I0212 04:32:32.799566 22509476222784 run_lib.py:146] step: 526100, eval_loss: 3.13721e-02
I0212 04:32:51.398422 22509476222784 run_lib.py:133] step: 526150, training_loss: 4.13555e-02
I0212 04:33:10.030032 22509476222784 run_lib.py:133] step: 526200, training_loss: 3.47431e-02
I0212 04:33:10.241961 22509476222784 run_lib.py:146] step: 526200, eval_loss: 3.25217e-02
I0212 04:33:28.801149 22509476222784 run_lib.py:133] step: 526250, training_loss: 4.54071e-02
I0212 04:33:47.343544 22509476222784 run_lib.py:133] step: 526300, training_loss: 3.56126e-02
I0212 04:33:47.507931 22509476222784 run_lib.py:146] step: 526300, eval_loss: 3.94787e-02
I0212 04:34:06.218757 22509476222784 run_lib.py:133] step: 526350, training_loss: 3.53342e-02
I0212 04:34:24.664569 22509476222784 run_lib.py:133] step: 526400, training_loss: 4.87059e-02
I0212 04:34:24.824382 22509476222784 run_lib.py:146] step: 526400, eval_loss: 4.58932e-02
I0212 04:34:43.525645 22509476222784 run_lib.py:133] step: 526450, training_loss: 4.46739e-02
I0212 04:35:02.080550 22509476222784 run_lib.py:133] step: 526500, training_loss: 3.43637e-02
I0212 04:35:02.243607 22509476222784 run_lib.py:146] step: 526500, eval_loss: 3.47127e-02
I0212 04:35:20.856800 22509476222784 run_lib.py:133] step: 526550, training_loss: 3.33355e-02
I0212 04:35:39.386665 22509476222784 run_lib.py:133] step: 526600, training_loss: 3.16737e-02
I0212 04:35:39.553689 22509476222784 run_lib.py:146] step: 526600, eval_loss: 4.05081e-02
I0212 04:35:58.072639 22509476222784 run_lib.py:133] step: 526650, training_loss: 3.09160e-02
I0212 04:36:16.558511 22509476222784 run_lib.py:133] step: 526700, training_loss: 3.68239e-02
I0212 04:36:16.739690 22509476222784 run_lib.py:146] step: 526700, eval_loss: 4.34278e-02
I0212 04:36:35.281598 22509476222784 run_lib.py:133] step: 526750, training_loss: 5.37687e-02
I0212 04:36:53.894478 22509476222784 run_lib.py:133] step: 526800, training_loss: 5.31126e-02
I0212 04:36:54.057912 22509476222784 run_lib.py:146] step: 526800, eval_loss: 3.81451e-02
I0212 04:37:12.481226 22509476222784 run_lib.py:133] step: 526850, training_loss: 4.05036e-02
I0212 04:37:30.940965 22509476222784 run_lib.py:133] step: 526900, training_loss: 4.56165e-02
I0212 04:37:31.104445 22509476222784 run_lib.py:146] step: 526900, eval_loss: 4.06928e-02
I0212 04:37:49.698326 22509476222784 run_lib.py:133] step: 526950, training_loss: 4.53535e-02
I0212 04:38:08.239302 22509476222784 run_lib.py:133] step: 527000, training_loss: 4.06451e-02
I0212 04:38:08.408416 22509476222784 run_lib.py:146] step: 527000, eval_loss: 4.35967e-02
I0212 04:38:27.081348 22509476222784 run_lib.py:133] step: 527050, training_loss: 3.83109e-02
I0212 04:38:45.598308 22509476222784 run_lib.py:133] step: 527100, training_loss: 4.00812e-02
I0212 04:38:45.770196 22509476222784 run_lib.py:146] step: 527100, eval_loss: 5.39802e-02
I0212 04:39:04.259757 22509476222784 run_lib.py:133] step: 527150, training_loss: 4.48389e-02
I0212 04:39:22.904984 22509476222784 run_lib.py:133] step: 527200, training_loss: 6.32260e-02
I0212 04:39:23.069779 22509476222784 run_lib.py:146] step: 527200, eval_loss: 3.62810e-02
I0212 04:39:41.451556 22509476222784 run_lib.py:133] step: 527250, training_loss: 4.17631e-02
I0212 04:39:59.931296 22509476222784 run_lib.py:133] step: 527300, training_loss: 4.24500e-02
I0212 04:40:00.093671 22509476222784 run_lib.py:146] step: 527300, eval_loss: 5.34607e-02
I0212 04:40:18.461889 22509476222784 run_lib.py:133] step: 527350, training_loss: 3.65302e-02
I0212 04:40:37.082997 22509476222784 run_lib.py:133] step: 527400, training_loss: 4.12192e-02
I0212 04:40:37.244235 22509476222784 run_lib.py:146] step: 527400, eval_loss: 4.48985e-02
I0212 04:40:55.688396 22509476222784 run_lib.py:133] step: 527450, training_loss: 4.06377e-02
I0212 04:41:14.308649 22509476222784 run_lib.py:133] step: 527500, training_loss: 4.62013e-02
I0212 04:41:14.520879 22509476222784 run_lib.py:146] step: 527500, eval_loss: 3.63661e-02
I0212 04:41:33.095925 22509476222784 run_lib.py:133] step: 527550, training_loss: 3.42116e-02
I0212 04:41:51.626162 22509476222784 run_lib.py:133] step: 527600, training_loss: 4.26589e-02
I0212 04:41:51.797569 22509476222784 run_lib.py:146] step: 527600, eval_loss: 4.03035e-02
I0212 04:42:10.481330 22509476222784 run_lib.py:133] step: 527650, training_loss: 4.13438e-02
I0212 04:42:28.967437 22509476222784 run_lib.py:133] step: 527700, training_loss: 3.28911e-02
I0212 04:42:29.134010 22509476222784 run_lib.py:146] step: 527700, eval_loss: 4.05820e-02
I0212 04:42:47.699088 22509476222784 run_lib.py:133] step: 527750, training_loss: 3.77200e-02
I0212 04:43:06.336559 22509476222784 run_lib.py:133] step: 527800, training_loss: 3.69433e-02
I0212 04:43:06.500828 22509476222784 run_lib.py:146] step: 527800, eval_loss: 3.85688e-02
I0212 04:43:25.187369 22509476222784 run_lib.py:133] step: 527850, training_loss: 4.45692e-02
I0212 04:43:43.711541 22509476222784 run_lib.py:133] step: 527900, training_loss: 2.99215e-02
I0212 04:43:43.881511 22509476222784 run_lib.py:146] step: 527900, eval_loss: 3.95661e-02
I0212 04:44:02.525682 22509476222784 run_lib.py:133] step: 527950, training_loss: 3.93956e-02
I0212 04:44:21.030390 22509476222784 run_lib.py:133] step: 528000, training_loss: 4.33383e-02
I0212 04:44:21.191739 22509476222784 run_lib.py:146] step: 528000, eval_loss: 4.90733e-02
I0212 04:44:39.919566 22509476222784 run_lib.py:133] step: 528050, training_loss: 3.14374e-02
I0212 04:44:58.585652 22509476222784 run_lib.py:133] step: 528100, training_loss: 4.69027e-02
I0212 04:44:58.752616 22509476222784 run_lib.py:146] step: 528100, eval_loss: 3.66423e-02
I0212 04:45:17.265154 22509476222784 run_lib.py:133] step: 528150, training_loss: 4.40176e-02
I0212 04:45:35.960476 22509476222784 run_lib.py:133] step: 528200, training_loss: 4.33563e-02
I0212 04:45:36.125567 22509476222784 run_lib.py:146] step: 528200, eval_loss: 4.71578e-02
I0212 04:45:54.635066 22509476222784 run_lib.py:133] step: 528250, training_loss: 4.87624e-02
I0212 04:46:13.285495 22509476222784 run_lib.py:133] step: 528300, training_loss: 4.11893e-02
I0212 04:46:13.451737 22509476222784 run_lib.py:146] step: 528300, eval_loss: 3.69206e-02
I0212 04:46:31.925546 22509476222784 run_lib.py:133] step: 528350, training_loss: 4.80459e-02
I0212 04:46:50.422207 22509476222784 run_lib.py:133] step: 528400, training_loss: 4.46404e-02
I0212 04:46:50.585013 22509476222784 run_lib.py:146] step: 528400, eval_loss: 4.24833e-02
I0212 04:47:09.291885 22509476222784 run_lib.py:133] step: 528450, training_loss: 3.78473e-02
I0212 04:47:27.812356 22509476222784 run_lib.py:133] step: 528500, training_loss: 4.15860e-02
I0212 04:47:27.975694 22509476222784 run_lib.py:146] step: 528500, eval_loss: 3.92691e-02
I0212 04:47:46.411668 22509476222784 run_lib.py:133] step: 528550, training_loss: 3.80584e-02
I0212 04:48:05.050007 22509476222784 run_lib.py:133] step: 528600, training_loss: 4.21506e-02
I0212 04:48:05.217821 22509476222784 run_lib.py:146] step: 528600, eval_loss: 5.31523e-02
I0212 04:48:23.752186 22509476222784 run_lib.py:133] step: 528650, training_loss: 3.90339e-02
I0212 04:48:42.310455 22509476222784 run_lib.py:133] step: 528700, training_loss: 4.95031e-02
I0212 04:48:42.698804 22509476222784 run_lib.py:146] step: 528700, eval_loss: 3.69082e-02
I0212 04:49:01.170672 22509476222784 run_lib.py:133] step: 528750, training_loss: 5.20052e-02
I0212 04:49:19.628852 22509476222784 run_lib.py:133] step: 528800, training_loss: 5.66573e-02
I0212 04:49:19.797686 22509476222784 run_lib.py:146] step: 528800, eval_loss: 4.38360e-02
I0212 04:49:38.282157 22509476222784 run_lib.py:133] step: 528850, training_loss: 3.50917e-02
I0212 04:49:56.813396 22509476222784 run_lib.py:133] step: 528900, training_loss: 3.99887e-02
I0212 04:49:56.975881 22509476222784 run_lib.py:146] step: 528900, eval_loss: 3.86358e-02
I0212 04:50:15.652340 22509476222784 run_lib.py:133] step: 528950, training_loss: 4.50245e-02
I0212 04:50:34.260250 22509476222784 run_lib.py:133] step: 529000, training_loss: 6.23997e-02
I0212 04:50:34.433533 22509476222784 run_lib.py:146] step: 529000, eval_loss: 4.99251e-02
I0212 04:50:52.919384 22509476222784 run_lib.py:133] step: 529050, training_loss: 3.29072e-02
I0212 04:51:11.351228 22509476222784 run_lib.py:133] step: 529100, training_loss: 4.43691e-02
I0212 04:51:11.525778 22509476222784 run_lib.py:146] step: 529100, eval_loss: 4.20665e-02
I0212 04:51:30.162617 22509476222784 run_lib.py:133] step: 529150, training_loss: 4.28021e-02
I0212 04:51:48.728605 22509476222784 run_lib.py:133] step: 529200, training_loss: 4.77559e-02
I0212 04:51:48.907644 22509476222784 run_lib.py:146] step: 529200, eval_loss: 4.15805e-02
I0212 04:52:07.401922 22509476222784 run_lib.py:133] step: 529250, training_loss: 4.07241e-02
I0212 04:52:25.923602 22509476222784 run_lib.py:133] step: 529300, training_loss: 3.51929e-02
I0212 04:52:26.085558 22509476222784 run_lib.py:146] step: 529300, eval_loss: 4.18046e-02
I0212 04:52:44.694354 22509476222784 run_lib.py:133] step: 529350, training_loss: 4.64808e-02
I0212 04:53:03.232138 22509476222784 run_lib.py:133] step: 529400, training_loss: 3.49615e-02
I0212 04:53:03.412679 22509476222784 run_lib.py:146] step: 529400, eval_loss: 4.64241e-02
I0212 04:53:22.078769 22509476222784 run_lib.py:133] step: 529450, training_loss: 3.71503e-02
I0212 04:53:40.598287 22509476222784 run_lib.py:133] step: 529500, training_loss: 5.81153e-02
I0212 04:53:40.768769 22509476222784 run_lib.py:146] step: 529500, eval_loss: 3.62864e-02
I0212 04:53:59.472536 22509476222784 run_lib.py:133] step: 529550, training_loss: 4.99892e-02
I0212 04:54:18.049943 22509476222784 run_lib.py:133] step: 529600, training_loss: 3.89493e-02
I0212 04:54:18.223724 22509476222784 run_lib.py:146] step: 529600, eval_loss: 3.35340e-02
I0212 04:54:36.771781 22509476222784 run_lib.py:133] step: 529650, training_loss: 4.33953e-02
I0212 04:54:55.450928 22509476222784 run_lib.py:133] step: 529700, training_loss: 3.20868e-02
I0212 04:54:55.614778 22509476222784 run_lib.py:146] step: 529700, eval_loss: 4.25230e-02
I0212 04:55:14.133659 22509476222784 run_lib.py:133] step: 529750, training_loss: 4.57440e-02
I0212 04:55:32.787476 22509476222784 run_lib.py:133] step: 529800, training_loss: 4.77378e-02
I0212 04:55:32.955883 22509476222784 run_lib.py:146] step: 529800, eval_loss: 3.62099e-02
I0212 04:55:51.517642 22509476222784 run_lib.py:133] step: 529850, training_loss: 3.12063e-02
I0212 04:56:09.987581 22509476222784 run_lib.py:133] step: 529900, training_loss: 4.69541e-02
I0212 04:56:10.147490 22509476222784 run_lib.py:146] step: 529900, eval_loss: 4.40854e-02
I0212 04:56:28.645204 22509476222784 run_lib.py:133] step: 529950, training_loss: 4.57012e-02
I0212 04:56:47.280650 22509476222784 run_lib.py:133] step: 530000, training_loss: 5.01336e-02
I0212 04:56:48.090816 22509476222784 run_lib.py:146] step: 530000, eval_loss: 3.90719e-02
I0212 04:57:09.474132 22509476222784 run_lib.py:133] step: 530050, training_loss: 3.59301e-02
I0212 04:57:28.129395 22509476222784 run_lib.py:133] step: 530100, training_loss: 4.68641e-02
I0212 04:57:28.295797 22509476222784 run_lib.py:146] step: 530100, eval_loss: 4.03687e-02
I0212 04:57:46.750881 22509476222784 run_lib.py:133] step: 530150, training_loss: 3.07080e-02
I0212 04:58:05.278538 22509476222784 run_lib.py:133] step: 530200, training_loss: 4.44837e-02
I0212 04:58:05.531619 22509476222784 run_lib.py:146] step: 530200, eval_loss: 5.09502e-02
I0212 04:58:24.194312 22509476222784 run_lib.py:133] step: 530250, training_loss: 3.85398e-02
I0212 04:58:42.646649 22509476222784 run_lib.py:133] step: 530300, training_loss: 2.79865e-02
I0212 04:58:42.826420 22509476222784 run_lib.py:146] step: 530300, eval_loss: 5.99687e-02
I0212 04:59:01.395947 22509476222784 run_lib.py:133] step: 530350, training_loss: 3.76010e-02
I0212 04:59:19.798816 22509476222784 run_lib.py:133] step: 530400, training_loss: 3.14924e-02
I0212 04:59:19.966549 22509476222784 run_lib.py:146] step: 530400, eval_loss: 3.61123e-02
I0212 04:59:38.636556 22509476222784 run_lib.py:133] step: 530450, training_loss: 4.84595e-02
I0212 04:59:57.194189 22509476222784 run_lib.py:133] step: 530500, training_loss: 5.69375e-02
I0212 04:59:57.361527 22509476222784 run_lib.py:146] step: 530500, eval_loss: 4.30588e-02
I0212 05:00:15.971648 22509476222784 run_lib.py:133] step: 530550, training_loss: 4.25962e-02
I0212 05:00:34.476085 22509476222784 run_lib.py:133] step: 530600, training_loss: 5.06873e-02
I0212 05:00:34.655648 22509476222784 run_lib.py:146] step: 530600, eval_loss: 4.70287e-02
I0212 05:00:53.182659 22509476222784 run_lib.py:133] step: 530650, training_loss: 4.87894e-02
I0212 05:01:11.842068 22509476222784 run_lib.py:133] step: 530700, training_loss: 4.51096e-02
I0212 05:01:12.011646 22509476222784 run_lib.py:146] step: 530700, eval_loss: 3.52237e-02
I0212 05:01:30.530745 22509476222784 run_lib.py:133] step: 530750, training_loss: 5.01429e-02
I0212 05:01:48.980974 22509476222784 run_lib.py:133] step: 530800, training_loss: 4.68311e-02
I0212 05:01:49.143439 22509476222784 run_lib.py:146] step: 530800, eval_loss: 4.32955e-02
I0212 05:02:07.731256 22509476222784 run_lib.py:133] step: 530850, training_loss: 4.72012e-02
I0212 05:02:26.451363 22509476222784 run_lib.py:133] step: 530900, training_loss: 4.05138e-02
I0212 05:02:26.622851 22509476222784 run_lib.py:146] step: 530900, eval_loss: 6.01196e-02
I0212 05:02:45.174482 22509476222784 run_lib.py:133] step: 530950, training_loss: 4.60706e-02
I0212 05:03:03.684372 22509476222784 run_lib.py:133] step: 531000, training_loss: 4.48353e-02
I0212 05:03:03.895811 22509476222784 run_lib.py:146] step: 531000, eval_loss: 3.45877e-02
I0212 05:03:22.377947 22509476222784 run_lib.py:133] step: 531050, training_loss: 4.03520e-02
I0212 05:03:41.018709 22509476222784 run_lib.py:133] step: 531100, training_loss: 3.18497e-02
I0212 05:03:41.199649 22509476222784 run_lib.py:146] step: 531100, eval_loss: 4.81936e-02
I0212 05:03:59.743742 22509476222784 run_lib.py:133] step: 531150, training_loss: 4.98468e-02
I0212 05:04:18.293598 22509476222784 run_lib.py:133] step: 531200, training_loss: 4.32764e-02
I0212 05:04:18.458880 22509476222784 run_lib.py:146] step: 531200, eval_loss: 5.11943e-02
I0212 05:04:36.969979 22509476222784 run_lib.py:133] step: 531250, training_loss: 3.87600e-02
I0212 05:04:55.645472 22509476222784 run_lib.py:133] step: 531300, training_loss: 3.79958e-02
I0212 05:04:55.808827 22509476222784 run_lib.py:146] step: 531300, eval_loss: 3.36376e-02
I0212 05:05:14.259153 22509476222784 run_lib.py:133] step: 531350, training_loss: 5.18826e-02
I0212 05:05:32.849889 22509476222784 run_lib.py:133] step: 531400, training_loss: 3.52370e-02
I0212 05:05:33.015885 22509476222784 run_lib.py:146] step: 531400, eval_loss: 3.47749e-02
I0212 05:05:51.574879 22509476222784 run_lib.py:133] step: 531450, training_loss: 4.64179e-02
I0212 05:06:10.095966 22509476222784 run_lib.py:133] step: 531500, training_loss: 4.50623e-02
I0212 05:06:10.268747 22509476222784 run_lib.py:146] step: 531500, eval_loss: 4.00226e-02
I0212 05:06:28.939522 22509476222784 run_lib.py:133] step: 531550, training_loss: 5.50308e-02
I0212 05:06:47.581842 22509476222784 run_lib.py:133] step: 531600, training_loss: 6.15512e-02
I0212 05:06:47.744728 22509476222784 run_lib.py:146] step: 531600, eval_loss: 5.58920e-02
I0212 05:07:06.259216 22509476222784 run_lib.py:133] step: 531650, training_loss: 5.32076e-02
I0212 05:07:24.797716 22509476222784 run_lib.py:133] step: 531700, training_loss: 4.79767e-02
I0212 05:07:24.968504 22509476222784 run_lib.py:146] step: 531700, eval_loss: 5.29397e-02
I0212 05:07:43.694366 22509476222784 run_lib.py:133] step: 531750, training_loss: 4.22872e-02
I0212 05:08:02.195598 22509476222784 run_lib.py:133] step: 531800, training_loss: 3.54798e-02
I0212 05:08:02.364512 22509476222784 run_lib.py:146] step: 531800, eval_loss: 3.07698e-02
I0212 05:08:21.008349 22509476222784 run_lib.py:133] step: 531850, training_loss: 3.66924e-02
I0212 05:08:39.500285 22509476222784 run_lib.py:133] step: 531900, training_loss: 5.07402e-02
I0212 05:08:39.664955 22509476222784 run_lib.py:146] step: 531900, eval_loss: 4.80049e-02
I0212 05:08:58.328335 22509476222784 run_lib.py:133] step: 531950, training_loss: 4.79787e-02
I0212 05:09:16.880686 22509476222784 run_lib.py:133] step: 532000, training_loss: 5.09601e-02
I0212 05:09:17.047690 22509476222784 run_lib.py:146] step: 532000, eval_loss: 4.48484e-02
I0212 05:09:35.558955 22509476222784 run_lib.py:133] step: 532050, training_loss: 3.61050e-02
I0212 05:09:54.299714 22509476222784 run_lib.py:133] step: 532100, training_loss: 5.10862e-02
I0212 05:09:54.463608 22509476222784 run_lib.py:146] step: 532100, eval_loss: 3.94802e-02
I0212 05:10:12.971209 22509476222784 run_lib.py:133] step: 532150, training_loss: 4.60192e-02
I0212 05:10:31.627533 22509476222784 run_lib.py:133] step: 532200, training_loss: 3.78501e-02
I0212 05:10:31.790460 22509476222784 run_lib.py:146] step: 532200, eval_loss: 4.06486e-02
I0212 05:10:50.258306 22509476222784 run_lib.py:133] step: 532250, training_loss: 5.28849e-02
I0212 05:11:08.775991 22509476222784 run_lib.py:133] step: 532300, training_loss: 4.95155e-02
I0212 05:11:08.936651 22509476222784 run_lib.py:146] step: 532300, eval_loss: 2.66753e-02
I0212 05:11:27.668306 22509476222784 run_lib.py:133] step: 532350, training_loss: 4.10575e-02
I0212 05:11:46.202590 22509476222784 run_lib.py:133] step: 532400, training_loss: 4.85217e-02
I0212 05:11:46.374687 22509476222784 run_lib.py:146] step: 532400, eval_loss: 4.23905e-02
I0212 05:12:04.811750 22509476222784 run_lib.py:133] step: 532450, training_loss: 3.52020e-02
I0212 05:12:23.462038 22509476222784 run_lib.py:133] step: 532500, training_loss: 4.54218e-02
I0212 05:12:23.641630 22509476222784 run_lib.py:146] step: 532500, eval_loss: 3.32050e-02
I0212 05:12:42.173078 22509476222784 run_lib.py:133] step: 532550, training_loss: 3.07264e-02
I0212 05:13:00.688318 22509476222784 run_lib.py:133] step: 532600, training_loss: 3.70253e-02
I0212 05:13:00.852916 22509476222784 run_lib.py:146] step: 532600, eval_loss: 3.78601e-02
I0212 05:13:19.381981 22509476222784 run_lib.py:133] step: 532650, training_loss: 3.60632e-02
I0212 05:13:37.727133 22509476222784 run_lib.py:133] step: 532700, training_loss: 5.17519e-02
I0212 05:13:37.888470 22509476222784 run_lib.py:146] step: 532700, eval_loss: 5.41979e-02
I0212 05:13:56.393927 22509476222784 run_lib.py:133] step: 532750, training_loss: 3.70295e-02
I0212 05:14:14.909382 22509476222784 run_lib.py:133] step: 532800, training_loss: 3.73799e-02
I0212 05:14:15.073754 22509476222784 run_lib.py:146] step: 532800, eval_loss: 5.68568e-02
I0212 05:14:33.830068 22509476222784 run_lib.py:133] step: 532850, training_loss: 3.78871e-02
I0212 05:14:52.447319 22509476222784 run_lib.py:133] step: 532900, training_loss: 4.24575e-02
I0212 05:14:52.635909 22509476222784 run_lib.py:146] step: 532900, eval_loss: 5.93964e-02
I0212 05:15:11.102034 22509476222784 run_lib.py:133] step: 532950, training_loss: 4.00784e-02
I0212 05:15:29.601281 22509476222784 run_lib.py:133] step: 533000, training_loss: 3.70712e-02
I0212 05:15:29.780612 22509476222784 run_lib.py:146] step: 533000, eval_loss: 5.03166e-02
I0212 05:15:48.473480 22509476222784 run_lib.py:133] step: 533050, training_loss: 4.38300e-02
I0212 05:16:07.051595 22509476222784 run_lib.py:133] step: 533100, training_loss: 3.22798e-02
I0212 05:16:07.215320 22509476222784 run_lib.py:146] step: 533100, eval_loss: 4.46830e-02
I0212 05:16:25.909083 22509476222784 run_lib.py:133] step: 533150, training_loss: 4.66153e-02
I0212 05:16:44.435592 22509476222784 run_lib.py:133] step: 533200, training_loss: 4.51980e-02
I0212 05:16:44.606689 22509476222784 run_lib.py:146] step: 533200, eval_loss: 3.56260e-02
I0212 05:17:03.233679 22509476222784 run_lib.py:133] step: 533250, training_loss: 3.49714e-02
I0212 05:17:21.697521 22509476222784 run_lib.py:133] step: 533300, training_loss: 4.63556e-02
I0212 05:17:21.861917 22509476222784 run_lib.py:146] step: 533300, eval_loss: 3.91139e-02
I0212 05:17:40.664602 22509476222784 run_lib.py:133] step: 533350, training_loss: 5.14154e-02
I0212 05:17:59.226757 22509476222784 run_lib.py:133] step: 533400, training_loss: 4.59684e-02
I0212 05:17:59.409709 22509476222784 run_lib.py:146] step: 533400, eval_loss: 5.08785e-02
I0212 05:18:17.877130 22509476222784 run_lib.py:133] step: 533450, training_loss: 4.07760e-02
I0212 05:18:36.429928 22509476222784 run_lib.py:133] step: 533500, training_loss: 4.85894e-02
I0212 05:18:36.594691 22509476222784 run_lib.py:146] step: 533500, eval_loss: 3.52798e-02
I0212 05:18:55.061822 22509476222784 run_lib.py:133] step: 533550, training_loss: 3.81712e-02
I0212 05:19:13.648936 22509476222784 run_lib.py:133] step: 533600, training_loss: 5.15767e-02
I0212 05:19:13.854380 22509476222784 run_lib.py:146] step: 533600, eval_loss: 2.82347e-02
I0212 05:19:32.524476 22509476222784 run_lib.py:133] step: 533650, training_loss: 5.09079e-02
I0212 05:19:50.951227 22509476222784 run_lib.py:133] step: 533700, training_loss: 5.00182e-02
I0212 05:19:51.111625 22509476222784 run_lib.py:146] step: 533700, eval_loss: 4.07174e-02
I0212 05:20:09.866556 22509476222784 run_lib.py:133] step: 533750, training_loss: 3.61405e-02
I0212 05:20:28.396824 22509476222784 run_lib.py:133] step: 533800, training_loss: 3.28348e-02
I0212 05:20:28.559636 22509476222784 run_lib.py:146] step: 533800, eval_loss: 3.96538e-02
I0212 05:20:46.999914 22509476222784 run_lib.py:133] step: 533850, training_loss: 3.97265e-02
I0212 05:21:05.671092 22509476222784 run_lib.py:133] step: 533900, training_loss: 2.91452e-02
I0212 05:21:05.843679 22509476222784 run_lib.py:146] step: 533900, eval_loss: 4.09037e-02
I0212 05:21:24.342401 22509476222784 run_lib.py:133] step: 533950, training_loss: 3.29996e-02
I0212 05:21:42.827527 22509476222784 run_lib.py:133] step: 534000, training_loss: 3.72235e-02
I0212 05:21:42.993979 22509476222784 run_lib.py:146] step: 534000, eval_loss: 3.74205e-02
I0212 05:22:01.490592 22509476222784 run_lib.py:133] step: 534050, training_loss: 4.51302e-02
I0212 05:22:20.161723 22509476222784 run_lib.py:133] step: 534100, training_loss: 5.17453e-02
I0212 05:22:20.331593 22509476222784 run_lib.py:146] step: 534100, eval_loss: 4.54156e-02
I0212 05:22:38.898803 22509476222784 run_lib.py:133] step: 534150, training_loss: 3.91883e-02
I0212 05:22:57.539312 22509476222784 run_lib.py:133] step: 534200, training_loss: 3.33124e-02
I0212 05:22:57.702716 22509476222784 run_lib.py:146] step: 534200, eval_loss: 4.79378e-02
I0212 05:23:16.195377 22509476222784 run_lib.py:133] step: 534250, training_loss: 3.30851e-02
I0212 05:23:34.661800 22509476222784 run_lib.py:133] step: 534300, training_loss: 5.00399e-02
I0212 05:23:34.825630 22509476222784 run_lib.py:146] step: 534300, eval_loss: 2.84351e-02
I0212 05:23:53.390827 22509476222784 run_lib.py:133] step: 534350, training_loss: 3.56314e-02
I0212 05:24:11.982858 22509476222784 run_lib.py:133] step: 534400, training_loss: 4.22612e-02
I0212 05:24:12.197740 22509476222784 run_lib.py:146] step: 534400, eval_loss: 4.72580e-02
I0212 05:24:30.654186 22509476222784 run_lib.py:133] step: 534450, training_loss: 3.53206e-02
I0212 05:24:49.072337 22509476222784 run_lib.py:133] step: 534500, training_loss: 3.59797e-02
I0212 05:24:49.235747 22509476222784 run_lib.py:146] step: 534500, eval_loss: 3.65550e-02
I0212 05:25:07.969385 22509476222784 run_lib.py:133] step: 534550, training_loss: 3.78573e-02
I0212 05:25:26.491296 22509476222784 run_lib.py:133] step: 534600, training_loss: 3.71899e-02
I0212 05:25:26.654543 22509476222784 run_lib.py:146] step: 534600, eval_loss: 4.19275e-02
I0212 05:25:45.265568 22509476222784 run_lib.py:133] step: 534650, training_loss: 4.61315e-02
I0212 05:26:03.719169 22509476222784 run_lib.py:133] step: 534700, training_loss: 4.14559e-02
I0212 05:26:03.881788 22509476222784 run_lib.py:146] step: 534700, eval_loss: 4.83629e-02
I0212 05:26:22.550950 22509476222784 run_lib.py:133] step: 534750, training_loss: 4.21253e-02
I0212 05:26:41.064212 22509476222784 run_lib.py:133] step: 534800, training_loss: 2.96261e-02
I0212 05:26:41.276610 22509476222784 run_lib.py:146] step: 534800, eval_loss: 4.02029e-02
I0212 05:26:59.799414 22509476222784 run_lib.py:133] step: 534850, training_loss: 5.08836e-02
I0212 05:27:18.468977 22509476222784 run_lib.py:133] step: 534900, training_loss: 5.60228e-02
I0212 05:27:18.659815 22509476222784 run_lib.py:146] step: 534900, eval_loss: 4.53813e-02
I0212 05:27:37.187952 22509476222784 run_lib.py:133] step: 534950, training_loss: 5.22184e-02
I0212 05:27:55.840373 22509476222784 run_lib.py:133] step: 535000, training_loss: 3.45790e-02
I0212 05:27:56.002603 22509476222784 run_lib.py:146] step: 535000, eval_loss: 5.94098e-02
I0212 05:28:14.408915 22509476222784 run_lib.py:133] step: 535050, training_loss: 4.00313e-02
I0212 05:28:32.801654 22509476222784 run_lib.py:133] step: 535100, training_loss: 4.23795e-02
I0212 05:28:32.968561 22509476222784 run_lib.py:146] step: 535100, eval_loss: 4.27008e-02
I0212 05:28:51.663561 22509476222784 run_lib.py:133] step: 535150, training_loss: 4.62570e-02
I0212 05:29:10.188728 22509476222784 run_lib.py:133] step: 535200, training_loss: 4.34012e-02
I0212 05:29:10.375873 22509476222784 run_lib.py:146] step: 535200, eval_loss: 5.98970e-02
I0212 05:29:28.985640 22509476222784 run_lib.py:133] step: 535250, training_loss: 3.89278e-02
I0212 05:29:47.714428 22509476222784 run_lib.py:133] step: 535300, training_loss: 3.94685e-02
I0212 05:29:47.905645 22509476222784 run_lib.py:146] step: 535300, eval_loss: 3.92114e-02
I0212 05:30:06.428392 22509476222784 run_lib.py:133] step: 535350, training_loss: 3.72363e-02
I0212 05:30:24.893771 22509476222784 run_lib.py:133] step: 535400, training_loss: 3.29715e-02
I0212 05:30:25.206629 22509476222784 run_lib.py:146] step: 535400, eval_loss: 4.36558e-02
I0212 05:30:43.672691 22509476222784 run_lib.py:133] step: 535450, training_loss: 4.82967e-02
I0212 05:31:02.230012 22509476222784 run_lib.py:133] step: 535500, training_loss: 4.54616e-02
I0212 05:31:02.395482 22509476222784 run_lib.py:146] step: 535500, eval_loss: 4.15339e-02
I0212 05:31:20.932233 22509476222784 run_lib.py:133] step: 535550, training_loss: 4.24942e-02
I0212 05:31:39.374396 22509476222784 run_lib.py:133] step: 535600, training_loss: 4.38706e-02
I0212 05:31:39.534385 22509476222784 run_lib.py:146] step: 535600, eval_loss: 3.63443e-02
I0212 05:31:58.213544 22509476222784 run_lib.py:133] step: 535650, training_loss: 4.67619e-02
I0212 05:32:16.770357 22509476222784 run_lib.py:133] step: 535700, training_loss: 3.46555e-02
I0212 05:32:16.937603 22509476222784 run_lib.py:146] step: 535700, eval_loss: 5.18284e-02
I0212 05:32:35.444810 22509476222784 run_lib.py:133] step: 535750, training_loss: 3.82341e-02
I0212 05:32:54.009067 22509476222784 run_lib.py:133] step: 535800, training_loss: 4.51163e-02
I0212 05:32:54.178622 22509476222784 run_lib.py:146] step: 535800, eval_loss: 3.87444e-02
I0212 05:33:12.847337 22509476222784 run_lib.py:133] step: 535850, training_loss: 4.74671e-02
I0212 05:33:31.439308 22509476222784 run_lib.py:133] step: 535900, training_loss: 4.53135e-02
I0212 05:33:31.601432 22509476222784 run_lib.py:146] step: 535900, eval_loss: 3.33224e-02
I0212 05:33:50.084962 22509476222784 run_lib.py:133] step: 535950, training_loss: 2.95619e-02
I0212 05:34:08.579266 22509476222784 run_lib.py:133] step: 536000, training_loss: 5.56301e-02
I0212 05:34:08.743403 22509476222784 run_lib.py:146] step: 536000, eval_loss: 5.80831e-02
I0212 05:34:27.341197 22509476222784 run_lib.py:133] step: 536050, training_loss: 3.80275e-02
I0212 05:34:45.900530 22509476222784 run_lib.py:133] step: 536100, training_loss: 5.77875e-02
I0212 05:34:46.062829 22509476222784 run_lib.py:146] step: 536100, eval_loss: 3.74428e-02
I0212 05:35:04.777925 22509476222784 run_lib.py:133] step: 536150, training_loss: 4.35764e-02
I0212 05:35:23.261090 22509476222784 run_lib.py:133] step: 536200, training_loss: 4.24275e-02
I0212 05:35:23.425778 22509476222784 run_lib.py:146] step: 536200, eval_loss: 3.78599e-02
I0212 05:35:42.014068 22509476222784 run_lib.py:133] step: 536250, training_loss: 3.71362e-02
I0212 05:36:00.566182 22509476222784 run_lib.py:133] step: 536300, training_loss: 3.28001e-02
I0212 05:36:00.754712 22509476222784 run_lib.py:146] step: 536300, eval_loss: 4.72202e-02
I0212 05:36:19.273134 22509476222784 run_lib.py:133] step: 536350, training_loss: 4.49546e-02
I0212 05:36:38.020436 22509476222784 run_lib.py:133] step: 536400, training_loss: 4.29235e-02
I0212 05:36:38.191492 22509476222784 run_lib.py:146] step: 536400, eval_loss: 5.16298e-02
I0212 05:36:56.642855 22509476222784 run_lib.py:133] step: 536450, training_loss: 4.12447e-02
I0212 05:37:15.269112 22509476222784 run_lib.py:133] step: 536500, training_loss: 5.35197e-02
I0212 05:37:15.437639 22509476222784 run_lib.py:146] step: 536500, eval_loss: 4.68547e-02
I0212 05:37:33.943195 22509476222784 run_lib.py:133] step: 536550, training_loss: 4.82350e-02
I0212 05:37:52.458472 22509476222784 run_lib.py:133] step: 536600, training_loss: 4.51108e-02
I0212 05:37:52.623897 22509476222784 run_lib.py:146] step: 536600, eval_loss: 4.56611e-02
I0212 05:38:11.357668 22509476222784 run_lib.py:133] step: 536650, training_loss: 4.19871e-02
I0212 05:38:29.755970 22509476222784 run_lib.py:133] step: 536700, training_loss: 4.59327e-02
I0212 05:38:29.920875 22509476222784 run_lib.py:146] step: 536700, eval_loss: 3.70563e-02
I0212 05:38:48.268367 22509476222784 run_lib.py:133] step: 536750, training_loss: 5.38911e-02
I0212 05:39:06.772174 22509476222784 run_lib.py:133] step: 536800, training_loss: 4.68896e-02
I0212 05:39:07.016721 22509476222784 run_lib.py:146] step: 536800, eval_loss: 4.65478e-02
I0212 05:39:25.683697 22509476222784 run_lib.py:133] step: 536850, training_loss: 4.44237e-02
I0212 05:39:44.235088 22509476222784 run_lib.py:133] step: 536900, training_loss: 4.49919e-02
I0212 05:39:44.406925 22509476222784 run_lib.py:146] step: 536900, eval_loss: 3.78830e-02
I0212 05:40:03.024259 22509476222784 run_lib.py:133] step: 536950, training_loss: 4.46074e-02
I0212 05:40:21.462362 22509476222784 run_lib.py:133] step: 537000, training_loss: 3.11060e-02
I0212 05:40:21.624686 22509476222784 run_lib.py:146] step: 537000, eval_loss: 3.32181e-02
I0212 05:40:40.100677 22509476222784 run_lib.py:133] step: 537050, training_loss: 5.33656e-02
I0212 05:40:58.646698 22509476222784 run_lib.py:133] step: 537100, training_loss: 3.83114e-02
I0212 05:40:58.811904 22509476222784 run_lib.py:146] step: 537100, eval_loss: 3.90367e-02
I0212 05:41:17.540115 22509476222784 run_lib.py:133] step: 537150, training_loss: 4.25716e-02
I0212 05:41:36.187325 22509476222784 run_lib.py:133] step: 537200, training_loss: 4.72463e-02
I0212 05:41:36.352593 22509476222784 run_lib.py:146] step: 537200, eval_loss: 4.02198e-02
I0212 05:41:54.860179 22509476222784 run_lib.py:133] step: 537250, training_loss: 5.01653e-02
I0212 05:42:13.374084 22509476222784 run_lib.py:133] step: 537300, training_loss: 3.76819e-02
I0212 05:42:13.553620 22509476222784 run_lib.py:146] step: 537300, eval_loss: 3.52584e-02
I0212 05:42:32.201152 22509476222784 run_lib.py:133] step: 537350, training_loss: 3.90650e-02
I0212 05:42:50.752869 22509476222784 run_lib.py:133] step: 537400, training_loss: 3.96431e-02
I0212 05:42:50.918362 22509476222784 run_lib.py:146] step: 537400, eval_loss: 4.07325e-02
I0212 05:43:09.622120 22509476222784 run_lib.py:133] step: 537450, training_loss: 3.97658e-02
I0212 05:43:28.098750 22509476222784 run_lib.py:133] step: 537500, training_loss: 4.04305e-02
I0212 05:43:28.287615 22509476222784 run_lib.py:146] step: 537500, eval_loss: 4.06423e-02
I0212 05:43:46.984222 22509476222784 run_lib.py:133] step: 537550, training_loss: 4.40506e-02
I0212 05:44:05.499881 22509476222784 run_lib.py:133] step: 537600, training_loss: 5.38633e-02
I0212 05:44:05.678688 22509476222784 run_lib.py:146] step: 537600, eval_loss: 3.38673e-02
I0212 05:44:24.256886 22509476222784 run_lib.py:133] step: 537650, training_loss: 4.45789e-02
I0212 05:44:42.762856 22509476222784 run_lib.py:133] step: 537700, training_loss: 4.20105e-02
I0212 05:44:42.936423 22509476222784 run_lib.py:146] step: 537700, eval_loss: 3.95603e-02
I0212 05:45:01.423085 22509476222784 run_lib.py:133] step: 537750, training_loss: 3.66390e-02
I0212 05:45:20.200615 22509476222784 run_lib.py:133] step: 537800, training_loss: 4.04913e-02
I0212 05:45:20.365776 22509476222784 run_lib.py:146] step: 537800, eval_loss: 4.20662e-02
I0212 05:45:38.880786 22509476222784 run_lib.py:133] step: 537850, training_loss: 4.48664e-02
I0212 05:45:57.308861 22509476222784 run_lib.py:133] step: 537900, training_loss: 5.25189e-02
I0212 05:45:57.472325 22509476222784 run_lib.py:146] step: 537900, eval_loss: 3.65508e-02
I0212 05:46:16.079338 22509476222784 run_lib.py:133] step: 537950, training_loss: 4.08963e-02
I0212 05:46:34.704802 22509476222784 run_lib.py:133] step: 538000, training_loss: 4.22255e-02
I0212 05:46:34.869858 22509476222784 run_lib.py:146] step: 538000, eval_loss: 4.09310e-02
I0212 05:46:53.452260 22509476222784 run_lib.py:133] step: 538050, training_loss: 4.74634e-02
I0212 05:47:11.953450 22509476222784 run_lib.py:133] step: 538100, training_loss: 4.02087e-02
I0212 05:47:12.117630 22509476222784 run_lib.py:146] step: 538100, eval_loss: 3.27179e-02
I0212 05:47:30.595052 22509476222784 run_lib.py:133] step: 538150, training_loss: 5.16225e-02
I0212 05:47:49.260583 22509476222784 run_lib.py:133] step: 538200, training_loss: 4.12555e-02
I0212 05:47:49.425913 22509476222784 run_lib.py:146] step: 538200, eval_loss: 3.35191e-02
I0212 05:48:07.949420 22509476222784 run_lib.py:133] step: 538250, training_loss: 4.54534e-02
I0212 05:48:26.547952 22509476222784 run_lib.py:133] step: 538300, training_loss: 3.91271e-02
I0212 05:48:26.712871 22509476222784 run_lib.py:146] step: 538300, eval_loss: 4.07729e-02
I0212 05:48:45.230781 22509476222784 run_lib.py:133] step: 538350, training_loss: 3.92811e-02
I0212 05:49:03.858623 22509476222784 run_lib.py:133] step: 538400, training_loss: 3.62691e-02
I0212 05:49:04.020524 22509476222784 run_lib.py:146] step: 538400, eval_loss: 4.05441e-02
I0212 05:49:22.448727 22509476222784 run_lib.py:133] step: 538450, training_loss: 3.56600e-02
I0212 05:49:41.013247 22509476222784 run_lib.py:133] step: 538500, training_loss: 3.13910e-02
I0212 05:49:41.174862 22509476222784 run_lib.py:146] step: 538500, eval_loss: 3.94448e-02
I0212 05:49:59.723927 22509476222784 run_lib.py:133] step: 538550, training_loss: 3.92530e-02
I0212 05:50:18.145794 22509476222784 run_lib.py:133] step: 538600, training_loss: 5.48220e-02
I0212 05:50:18.311743 22509476222784 run_lib.py:146] step: 538600, eval_loss: 4.14242e-02
I0212 05:50:37.006485 22509476222784 run_lib.py:133] step: 538650, training_loss: 4.55627e-02
I0212 05:50:55.584175 22509476222784 run_lib.py:133] step: 538700, training_loss: 3.62268e-02
I0212 05:50:55.751978 22509476222784 run_lib.py:146] step: 538700, eval_loss: 3.52487e-02
I0212 05:51:14.255207 22509476222784 run_lib.py:133] step: 538750, training_loss: 3.83677e-02
I0212 05:51:32.813093 22509476222784 run_lib.py:133] step: 538800, training_loss: 4.55607e-02
I0212 05:51:32.977573 22509476222784 run_lib.py:146] step: 538800, eval_loss: 4.19070e-02
I0212 05:51:51.662633 22509476222784 run_lib.py:133] step: 538850, training_loss: 3.86506e-02
I0212 05:52:10.124374 22509476222784 run_lib.py:133] step: 538900, training_loss: 4.59393e-02
I0212 05:52:10.300363 22509476222784 run_lib.py:146] step: 538900, eval_loss: 4.51826e-02
I0212 05:52:28.944808 22509476222784 run_lib.py:133] step: 538950, training_loss: 3.82655e-02
I0212 05:52:47.448557 22509476222784 run_lib.py:133] step: 539000, training_loss: 3.32476e-02
I0212 05:52:47.616593 22509476222784 run_lib.py:146] step: 539000, eval_loss: 4.40350e-02
I0212 05:53:06.233389 22509476222784 run_lib.py:133] step: 539050, training_loss: 3.55890e-02
I0212 05:53:24.774906 22509476222784 run_lib.py:133] step: 539100, training_loss: 3.71836e-02
I0212 05:53:24.956184 22509476222784 run_lib.py:146] step: 539100, eval_loss: 3.80137e-02
I0212 05:53:43.469349 22509476222784 run_lib.py:133] step: 539150, training_loss: 5.34526e-02
I0212 05:54:02.082014 22509476222784 run_lib.py:133] step: 539200, training_loss: 3.23823e-02
I0212 05:54:02.244812 22509476222784 run_lib.py:146] step: 539200, eval_loss: 3.82107e-02
I0212 05:54:20.696491 22509476222784 run_lib.py:133] step: 539250, training_loss: 4.57699e-02
I0212 05:54:39.334067 22509476222784 run_lib.py:133] step: 539300, training_loss: 4.92003e-02
I0212 05:54:39.536376 22509476222784 run_lib.py:146] step: 539300, eval_loss: 3.25300e-02
I0212 05:54:58.028172 22509476222784 run_lib.py:133] step: 539350, training_loss: 4.41893e-02
I0212 05:55:16.585062 22509476222784 run_lib.py:133] step: 539400, training_loss: 5.37129e-02
I0212 05:55:16.772533 22509476222784 run_lib.py:146] step: 539400, eval_loss: 4.75563e-02
I0212 05:55:35.439762 22509476222784 run_lib.py:133] step: 539450, training_loss: 4.77060e-02
I0212 05:55:53.881695 22509476222784 run_lib.py:133] step: 539500, training_loss: 4.71508e-02
I0212 05:55:54.046624 22509476222784 run_lib.py:146] step: 539500, eval_loss: 5.01303e-02
I0212 05:56:12.456928 22509476222784 run_lib.py:133] step: 539550, training_loss: 3.74614e-02
I0212 05:56:31.096903 22509476222784 run_lib.py:133] step: 539600, training_loss: 4.52112e-02
I0212 05:56:31.261880 22509476222784 run_lib.py:146] step: 539600, eval_loss: 4.19489e-02
I0212 05:56:49.773310 22509476222784 run_lib.py:133] step: 539650, training_loss: 4.95804e-02
I0212 05:57:08.252615 22509476222784 run_lib.py:133] step: 539700, training_loss: 4.21435e-02
I0212 05:57:08.416824 22509476222784 run_lib.py:146] step: 539700, eval_loss: 4.79231e-02
I0212 05:57:26.956352 22509476222784 run_lib.py:133] step: 539750, training_loss: 4.38619e-02
I0212 05:57:45.382892 22509476222784 run_lib.py:133] step: 539800, training_loss: 4.11754e-02
I0212 05:57:45.544235 22509476222784 run_lib.py:146] step: 539800, eval_loss: 4.39670e-02
I0212 05:58:03.961086 22509476222784 run_lib.py:133] step: 539850, training_loss: 2.89183e-02
I0212 05:58:22.395756 22509476222784 run_lib.py:133] step: 539900, training_loss: 3.65447e-02
I0212 05:58:22.556801 22509476222784 run_lib.py:146] step: 539900, eval_loss: 5.25555e-02
I0212 05:58:41.180372 22509476222784 run_lib.py:133] step: 539950, training_loss: 3.18826e-02
I0212 05:58:59.814540 22509476222784 run_lib.py:133] step: 540000, training_loss: 4.23930e-02
I0212 05:59:00.552501 22509476222784 run_lib.py:146] step: 540000, eval_loss: 4.45909e-02
I0212 05:59:21.684465 22509476222784 run_lib.py:133] step: 540050, training_loss: 3.64759e-02
I0212 05:59:40.198611 22509476222784 run_lib.py:133] step: 540100, training_loss: 3.90229e-02
I0212 05:59:40.379904 22509476222784 run_lib.py:146] step: 540100, eval_loss: 4.63346e-02
I0212 05:59:58.868766 22509476222784 run_lib.py:133] step: 540150, training_loss: 4.02788e-02
I0212 06:00:17.602324 22509476222784 run_lib.py:133] step: 540200, training_loss: 4.50758e-02
I0212 06:00:17.782009 22509476222784 run_lib.py:146] step: 540200, eval_loss: 3.76781e-02
I0212 06:00:36.325751 22509476222784 run_lib.py:133] step: 540250, training_loss: 5.32596e-02
I0212 06:00:54.930616 22509476222784 run_lib.py:133] step: 540300, training_loss: 4.18987e-02
I0212 06:00:55.094391 22509476222784 run_lib.py:146] step: 540300, eval_loss: 4.63644e-02
I0212 06:01:13.599184 22509476222784 run_lib.py:133] step: 540350, training_loss: 5.72792e-02
I0212 06:01:32.090393 22509476222784 run_lib.py:133] step: 540400, training_loss: 4.00296e-02
I0212 06:01:32.252489 22509476222784 run_lib.py:146] step: 540400, eval_loss: 5.34334e-02
I0212 06:01:50.897620 22509476222784 run_lib.py:133] step: 540450, training_loss: 5.00784e-02
I0212 06:02:09.558272 22509476222784 run_lib.py:133] step: 540500, training_loss: 3.68224e-02
I0212 06:02:09.765899 22509476222784 run_lib.py:146] step: 540500, eval_loss: 3.23672e-02
I0212 06:02:28.229674 22509476222784 run_lib.py:133] step: 540550, training_loss: 3.73140e-02
I0212 06:02:46.734828 22509476222784 run_lib.py:133] step: 540600, training_loss: 5.25559e-02
I0212 06:02:46.901916 22509476222784 run_lib.py:146] step: 540600, eval_loss: 4.36455e-02
I0212 06:03:05.538911 22509476222784 run_lib.py:133] step: 540650, training_loss: 4.41814e-02
I0212 06:03:23.905224 22509476222784 run_lib.py:133] step: 540700, training_loss: 4.74520e-02
I0212 06:03:24.068460 22509476222784 run_lib.py:146] step: 540700, eval_loss: 5.23590e-02
I0212 06:03:42.582767 22509476222784 run_lib.py:133] step: 540750, training_loss: 4.61877e-02
I0212 06:04:01.117925 22509476222784 run_lib.py:133] step: 540800, training_loss: 4.65270e-02
I0212 06:04:01.289130 22509476222784 run_lib.py:146] step: 540800, eval_loss: 3.90981e-02
I0212 06:04:19.999027 22509476222784 run_lib.py:133] step: 540850, training_loss: 4.47025e-02
I0212 06:04:38.466845 22509476222784 run_lib.py:133] step: 540900, training_loss: 4.76920e-02
I0212 06:04:38.629599 22509476222784 run_lib.py:146] step: 540900, eval_loss: 3.86529e-02
I0212 06:04:57.080770 22509476222784 run_lib.py:133] step: 540950, training_loss: 3.83535e-02
I0212 06:05:15.695374 22509476222784 run_lib.py:133] step: 541000, training_loss: 4.70894e-02
I0212 06:05:15.874758 22509476222784 run_lib.py:146] step: 541000, eval_loss: 3.94002e-02
I0212 06:05:34.380651 22509476222784 run_lib.py:133] step: 541050, training_loss: 3.76023e-02
I0212 06:05:53.106241 22509476222784 run_lib.py:133] step: 541100, training_loss: 4.12540e-02
I0212 06:05:53.268738 22509476222784 run_lib.py:146] step: 541100, eval_loss: 4.12083e-02
I0212 06:06:11.720378 22509476222784 run_lib.py:133] step: 541150, training_loss: 3.65252e-02
I0212 06:06:30.221375 22509476222784 run_lib.py:133] step: 541200, training_loss: 5.07642e-02
I0212 06:06:30.385715 22509476222784 run_lib.py:146] step: 541200, eval_loss: 4.33885e-02
I0212 06:06:49.018480 22509476222784 run_lib.py:133] step: 541250, training_loss: 4.35691e-02
I0212 06:07:07.559862 22509476222784 run_lib.py:133] step: 541300, training_loss: 5.07907e-02
I0212 06:07:07.722954 22509476222784 run_lib.py:146] step: 541300, eval_loss: 3.32394e-02
I0212 06:07:26.243773 22509476222784 run_lib.py:133] step: 541350, training_loss: 3.56166e-02
I0212 06:07:44.938314 22509476222784 run_lib.py:133] step: 541400, training_loss: 4.13807e-02
I0212 06:07:45.153789 22509476222784 run_lib.py:146] step: 541400, eval_loss: 4.60054e-02
I0212 06:08:03.660234 22509476222784 run_lib.py:133] step: 541450, training_loss: 5.06215e-02
I0212 06:08:22.083070 22509476222784 run_lib.py:133] step: 541500, training_loss: 3.90470e-02
I0212 06:08:22.245321 22509476222784 run_lib.py:146] step: 541500, eval_loss: 4.83147e-02
I0212 06:08:40.771183 22509476222784 run_lib.py:133] step: 541550, training_loss: 3.24592e-02
I0212 06:08:59.278004 22509476222784 run_lib.py:133] step: 541600, training_loss: 4.21066e-02
I0212 06:08:59.460503 22509476222784 run_lib.py:146] step: 541600, eval_loss: 3.42471e-02
I0212 06:09:17.986800 22509476222784 run_lib.py:133] step: 541650, training_loss: 4.44103e-02
I0212 06:09:36.462586 22509476222784 run_lib.py:133] step: 541700, training_loss: 5.14965e-02
I0212 06:09:36.626876 22509476222784 run_lib.py:146] step: 541700, eval_loss: 5.76221e-02
I0212 06:09:55.352195 22509476222784 run_lib.py:133] step: 541750, training_loss: 4.12179e-02
I0212 06:10:13.920319 22509476222784 run_lib.py:133] step: 541800, training_loss: 4.46393e-02
I0212 06:10:14.082637 22509476222784 run_lib.py:146] step: 541800, eval_loss: 3.85811e-02
I0212 06:10:32.498314 22509476222784 run_lib.py:133] step: 541850, training_loss: 4.60424e-02
I0212 06:10:51.023438 22509476222784 run_lib.py:133] step: 541900, training_loss: 4.48610e-02
I0212 06:10:51.201764 22509476222784 run_lib.py:146] step: 541900, eval_loss: 3.71995e-02
I0212 06:11:09.969614 22509476222784 run_lib.py:133] step: 541950, training_loss: 4.07003e-02
I0212 06:11:28.483367 22509476222784 run_lib.py:133] step: 542000, training_loss: 5.15146e-02
I0212 06:11:28.658959 22509476222784 run_lib.py:146] step: 542000, eval_loss: 3.75584e-02
I0212 06:11:47.269504 22509476222784 run_lib.py:133] step: 542050, training_loss: 4.01606e-02
I0212 06:12:05.706521 22509476222784 run_lib.py:133] step: 542100, training_loss: 4.32026e-02
I0212 06:12:05.870784 22509476222784 run_lib.py:146] step: 542100, eval_loss: 4.57872e-02
I0212 06:12:24.566647 22509476222784 run_lib.py:133] step: 542150, training_loss: 3.82682e-02
I0212 06:12:43.121893 22509476222784 run_lib.py:133] step: 542200, training_loss: 2.54631e-02
I0212 06:12:43.286979 22509476222784 run_lib.py:146] step: 542200, eval_loss: 5.32026e-02
I0212 06:13:02.004663 22509476222784 run_lib.py:133] step: 542250, training_loss: 4.28463e-02
I0212 06:13:20.501969 22509476222784 run_lib.py:133] step: 542300, training_loss: 4.32763e-02
I0212 06:13:20.663652 22509476222784 run_lib.py:146] step: 542300, eval_loss: 4.93739e-02
I0212 06:13:39.202991 22509476222784 run_lib.py:133] step: 542350, training_loss: 3.86202e-02
I0212 06:13:57.882112 22509476222784 run_lib.py:133] step: 542400, training_loss: 5.36371e-02
I0212 06:13:58.051733 22509476222784 run_lib.py:146] step: 542400, eval_loss: 4.19482e-02
I0212 06:14:16.570805 22509476222784 run_lib.py:133] step: 542450, training_loss: 5.13784e-02
I0212 06:14:35.088120 22509476222784 run_lib.py:133] step: 542500, training_loss: 4.19045e-02
I0212 06:14:35.267675 22509476222784 run_lib.py:146] step: 542500, eval_loss: 3.94472e-02
I0212 06:14:53.940094 22509476222784 run_lib.py:133] step: 542550, training_loss: 4.84992e-02
I0212 06:15:12.367300 22509476222784 run_lib.py:133] step: 542600, training_loss: 3.67399e-02
I0212 06:15:12.535424 22509476222784 run_lib.py:146] step: 542600, eval_loss: 3.17459e-02
I0212 06:15:31.166684 22509476222784 run_lib.py:133] step: 542650, training_loss: 3.29097e-02
I0212 06:15:49.725895 22509476222784 run_lib.py:133] step: 542700, training_loss: 4.40308e-02
I0212 06:15:49.889768 22509476222784 run_lib.py:146] step: 542700, eval_loss: 3.99253e-02
I0212 06:16:08.336079 22509476222784 run_lib.py:133] step: 542750, training_loss: 5.10614e-02
I0212 06:16:26.906981 22509476222784 run_lib.py:133] step: 542800, training_loss: 3.89079e-02
I0212 06:16:27.068562 22509476222784 run_lib.py:146] step: 542800, eval_loss: 3.94200e-02
I0212 06:16:45.525004 22509476222784 run_lib.py:133] step: 542850, training_loss: 3.91690e-02
I0212 06:17:04.033221 22509476222784 run_lib.py:133] step: 542900, training_loss: 4.32658e-02
I0212 06:17:04.215226 22509476222784 run_lib.py:146] step: 542900, eval_loss: 4.11733e-02
I0212 06:17:22.846525 22509476222784 run_lib.py:133] step: 542950, training_loss: 3.45839e-02
I0212 06:17:41.602049 22509476222784 run_lib.py:133] step: 543000, training_loss: 4.75881e-02
I0212 06:17:41.777545 22509476222784 run_lib.py:146] step: 543000, eval_loss: 4.81900e-02
I0212 06:18:00.268560 22509476222784 run_lib.py:133] step: 543050, training_loss: 4.83500e-02
I0212 06:18:18.875105 22509476222784 run_lib.py:133] step: 543100, training_loss: 3.75884e-02
I0212 06:18:19.040597 22509476222784 run_lib.py:146] step: 543100, eval_loss: 4.28128e-02
I0212 06:18:37.582767 22509476222784 run_lib.py:133] step: 543150, training_loss: 4.15445e-02
I0212 06:18:56.150674 22509476222784 run_lib.py:133] step: 543200, training_loss: 4.07390e-02
I0212 06:18:56.319733 22509476222784 run_lib.py:146] step: 543200, eval_loss: 4.68318e-02
I0212 06:19:15.100261 22509476222784 run_lib.py:133] step: 543250, training_loss: 3.88130e-02
I0212 06:19:33.700655 22509476222784 run_lib.py:133] step: 543300, training_loss: 4.45399e-02
I0212 06:19:33.868558 22509476222784 run_lib.py:146] step: 543300, eval_loss: 4.30684e-02
I0212 06:19:52.383296 22509476222784 run_lib.py:133] step: 543350, training_loss: 4.06622e-02
I0212 06:20:10.871709 22509476222784 run_lib.py:133] step: 543400, training_loss: 3.50764e-02
I0212 06:20:11.047759 22509476222784 run_lib.py:146] step: 543400, eval_loss: 4.22928e-02
I0212 06:20:29.684303 22509476222784 run_lib.py:133] step: 543450, training_loss: 3.25701e-02
I0212 06:20:48.257877 22509476222784 run_lib.py:133] step: 543500, training_loss: 4.07968e-02
I0212 06:20:48.435598 22509476222784 run_lib.py:146] step: 543500, eval_loss: 3.87190e-02
I0212 06:21:07.165710 22509476222784 run_lib.py:133] step: 543550, training_loss: 4.81220e-02
I0212 06:21:25.557246 22509476222784 run_lib.py:133] step: 543600, training_loss: 4.64266e-02
I0212 06:21:25.723762 22509476222784 run_lib.py:146] step: 543600, eval_loss: 4.53122e-02
I0212 06:21:44.294176 22509476222784 run_lib.py:133] step: 543650, training_loss: 2.99818e-02
I0212 06:22:02.795823 22509476222784 run_lib.py:133] step: 543700, training_loss: 3.74849e-02
I0212 06:22:02.956240 22509476222784 run_lib.py:146] step: 543700, eval_loss: 4.41147e-02
I0212 06:22:21.492645 22509476222784 run_lib.py:133] step: 543750, training_loss: 4.86152e-02
I0212 06:22:40.174411 22509476222784 run_lib.py:133] step: 543800, training_loss: 4.38331e-02
I0212 06:22:40.359914 22509476222784 run_lib.py:146] step: 543800, eval_loss: 3.63628e-02
I0212 06:22:58.873075 22509476222784 run_lib.py:133] step: 543850, training_loss: 4.27588e-02
I0212 06:23:17.601449 22509476222784 run_lib.py:133] step: 543900, training_loss: 5.25514e-02
I0212 06:23:17.767920 22509476222784 run_lib.py:146] step: 543900, eval_loss: 4.26065e-02
I0212 06:23:36.237031 22509476222784 run_lib.py:133] step: 543950, training_loss: 3.74657e-02
I0212 06:23:54.726361 22509476222784 run_lib.py:133] step: 544000, training_loss: 6.19215e-02
I0212 06:23:54.905630 22509476222784 run_lib.py:146] step: 544000, eval_loss: 4.05109e-02
I0212 06:24:13.640859 22509476222784 run_lib.py:133] step: 544050, training_loss: 4.76413e-02
I0212 06:24:32.182128 22509476222784 run_lib.py:133] step: 544100, training_loss: 4.16660e-02
I0212 06:24:32.345503 22509476222784 run_lib.py:146] step: 544100, eval_loss: 3.67718e-02
I0212 06:24:50.860194 22509476222784 run_lib.py:133] step: 544150, training_loss: 3.57857e-02
I0212 06:25:09.510894 22509476222784 run_lib.py:133] step: 544200, training_loss: 4.42662e-02
I0212 06:25:09.676331 22509476222784 run_lib.py:146] step: 544200, eval_loss: 5.14479e-02
I0212 06:25:28.201666 22509476222784 run_lib.py:133] step: 544250, training_loss: 3.87107e-02
I0212 06:25:46.741124 22509476222784 run_lib.py:133] step: 544300, training_loss: 4.19873e-02
I0212 06:25:47.062839 22509476222784 run_lib.py:146] step: 544300, eval_loss: 3.88962e-02
I0212 06:26:05.589497 22509476222784 run_lib.py:133] step: 544350, training_loss: 4.82317e-02
I0212 06:26:24.079578 22509476222784 run_lib.py:133] step: 544400, training_loss: 4.10161e-02
I0212 06:26:24.245723 22509476222784 run_lib.py:146] step: 544400, eval_loss: 4.97750e-02
I0212 06:26:42.708002 22509476222784 run_lib.py:133] step: 544450, training_loss: 4.21735e-02
I0212 06:27:01.200783 22509476222784 run_lib.py:133] step: 544500, training_loss: 4.16579e-02
I0212 06:27:01.365633 22509476222784 run_lib.py:146] step: 544500, eval_loss: 4.01647e-02
I0212 06:27:19.978054 22509476222784 run_lib.py:133] step: 544550, training_loss: 3.91435e-02
I0212 06:27:38.569937 22509476222784 run_lib.py:133] step: 544600, training_loss: 3.30709e-02
I0212 06:27:38.733808 22509476222784 run_lib.py:146] step: 544600, eval_loss: 3.55826e-02
I0212 06:27:57.281671 22509476222784 run_lib.py:133] step: 544650, training_loss: 4.42859e-02
I0212 06:28:15.705116 22509476222784 run_lib.py:133] step: 544700, training_loss: 3.81085e-02
I0212 06:28:15.868550 22509476222784 run_lib.py:146] step: 544700, eval_loss: 4.24322e-02
I0212 06:28:34.455974 22509476222784 run_lib.py:133] step: 544750, training_loss: 5.72371e-02
I0212 06:28:53.032016 22509476222784 run_lib.py:133] step: 544800, training_loss: 3.22215e-02
I0212 06:28:53.314954 22509476222784 run_lib.py:146] step: 544800, eval_loss: 3.60306e-02
I0212 06:29:11.814485 22509476222784 run_lib.py:133] step: 544850, training_loss: 3.43087e-02
I0212 06:29:30.372255 22509476222784 run_lib.py:133] step: 544900, training_loss: 4.59892e-02
I0212 06:29:30.550664 22509476222784 run_lib.py:146] step: 544900, eval_loss: 3.38632e-02
I0212 06:29:49.233231 22509476222784 run_lib.py:133] step: 544950, training_loss: 4.08711e-02
I0212 06:30:07.698249 22509476222784 run_lib.py:133] step: 545000, training_loss: 4.38034e-02
I0212 06:30:07.864010 22509476222784 run_lib.py:146] step: 545000, eval_loss: 3.57485e-02
I0212 06:30:26.494928 22509476222784 run_lib.py:133] step: 545050, training_loss: 5.21269e-02
I0212 06:30:44.985829 22509476222784 run_lib.py:133] step: 545100, training_loss: 5.27323e-02
I0212 06:30:45.148760 22509476222784 run_lib.py:146] step: 545100, eval_loss: 2.95664e-02
I0212 06:31:03.785517 22509476222784 run_lib.py:133] step: 545150, training_loss: 3.62949e-02
I0212 06:31:22.300822 22509476222784 run_lib.py:133] step: 545200, training_loss: 4.84642e-02
I0212 06:31:22.494111 22509476222784 run_lib.py:146] step: 545200, eval_loss: 3.63371e-02
I0212 06:31:41.051953 22509476222784 run_lib.py:133] step: 545250, training_loss: 4.19899e-02
I0212 06:31:59.792369 22509476222784 run_lib.py:133] step: 545300, training_loss: 3.68807e-02
I0212 06:31:59.971969 22509476222784 run_lib.py:146] step: 545300, eval_loss: 4.11623e-02
I0212 06:32:18.423981 22509476222784 run_lib.py:133] step: 545350, training_loss: 4.56530e-02
I0212 06:32:37.064971 22509476222784 run_lib.py:133] step: 545400, training_loss: 2.32907e-02
I0212 06:32:37.230854 22509476222784 run_lib.py:146] step: 545400, eval_loss: 4.15653e-02
I0212 06:32:55.798020 22509476222784 run_lib.py:133] step: 545450, training_loss: 3.40605e-02
I0212 06:33:14.389134 22509476222784 run_lib.py:133] step: 545500, training_loss: 5.06094e-02
I0212 06:33:14.551367 22509476222784 run_lib.py:146] step: 545500, eval_loss: 4.98721e-02
I0212 06:33:33.174430 22509476222784 run_lib.py:133] step: 545550, training_loss: 4.65282e-02
I0212 06:33:51.654133 22509476222784 run_lib.py:133] step: 545600, training_loss: 4.44542e-02
I0212 06:33:51.834619 22509476222784 run_lib.py:146] step: 545600, eval_loss: 5.44295e-02
I0212 06:34:10.320296 22509476222784 run_lib.py:133] step: 545650, training_loss: 3.50152e-02
I0212 06:34:28.876588 22509476222784 run_lib.py:133] step: 545700, training_loss: 4.04905e-02
I0212 06:34:29.042825 22509476222784 run_lib.py:146] step: 545700, eval_loss: 5.01553e-02
I0212 06:34:47.640132 22509476222784 run_lib.py:133] step: 545750, training_loss: 5.00596e-02
I0212 06:35:06.026041 22509476222784 run_lib.py:133] step: 545800, training_loss: 3.44513e-02
I0212 06:35:06.188464 22509476222784 run_lib.py:146] step: 545800, eval_loss: 3.64192e-02
I0212 06:35:24.636954 22509476222784 run_lib.py:133] step: 545850, training_loss: 3.56691e-02
I0212 06:35:43.130758 22509476222784 run_lib.py:133] step: 545900, training_loss: 4.29230e-02
I0212 06:35:43.308003 22509476222784 run_lib.py:146] step: 545900, eval_loss: 4.82029e-02
I0212 06:36:01.842309 22509476222784 run_lib.py:133] step: 545950, training_loss: 4.45132e-02
I0212 06:36:20.407687 22509476222784 run_lib.py:133] step: 546000, training_loss: 4.67977e-02
I0212 06:36:20.596460 22509476222784 run_lib.py:146] step: 546000, eval_loss: 4.32472e-02
I0212 06:36:39.290630 22509476222784 run_lib.py:133] step: 546050, training_loss: 4.18596e-02
I0212 06:36:57.929321 22509476222784 run_lib.py:133] step: 546100, training_loss: 3.17258e-02
I0212 06:36:58.110923 22509476222784 run_lib.py:146] step: 546100, eval_loss: 5.55389e-02
I0212 06:37:16.636433 22509476222784 run_lib.py:133] step: 546150, training_loss: 4.58542e-02
I0212 06:37:35.193230 22509476222784 run_lib.py:133] step: 546200, training_loss: 3.96825e-02
I0212 06:37:35.356660 22509476222784 run_lib.py:146] step: 546200, eval_loss: 3.84758e-02
I0212 06:37:54.064855 22509476222784 run_lib.py:133] step: 546250, training_loss: 4.97528e-02
I0212 06:38:12.709881 22509476222784 run_lib.py:133] step: 546300, training_loss: 4.27690e-02
I0212 06:38:12.879673 22509476222784 run_lib.py:146] step: 546300, eval_loss: 4.35580e-02
I0212 06:38:31.594358 22509476222784 run_lib.py:133] step: 546350, training_loss: 4.34258e-02
I0212 06:38:50.132385 22509476222784 run_lib.py:133] step: 546400, training_loss: 4.06287e-02
I0212 06:38:50.322869 22509476222784 run_lib.py:146] step: 546400, eval_loss: 3.04799e-02
I0212 06:39:09.014734 22509476222784 run_lib.py:133] step: 546450, training_loss: 5.83005e-02
I0212 06:39:27.510098 22509476222784 run_lib.py:133] step: 546500, training_loss: 4.89292e-02
I0212 06:39:27.676438 22509476222784 run_lib.py:146] step: 546500, eval_loss: 3.74888e-02
I0212 06:39:46.245828 22509476222784 run_lib.py:133] step: 546550, training_loss: 3.67747e-02
I0212 06:40:04.684688 22509476222784 run_lib.py:133] step: 546600, training_loss: 4.19642e-02
I0212 06:40:04.850953 22509476222784 run_lib.py:146] step: 546600, eval_loss: 4.42472e-02
I0212 06:40:23.391131 22509476222784 run_lib.py:133] step: 546650, training_loss: 3.50914e-02
I0212 06:40:42.108829 22509476222784 run_lib.py:133] step: 546700, training_loss: 4.44602e-02
I0212 06:40:42.272539 22509476222784 run_lib.py:146] step: 546700, eval_loss: 5.19433e-02
I0212 06:41:00.748924 22509476222784 run_lib.py:133] step: 546750, training_loss: 3.23643e-02
I0212 06:41:19.231801 22509476222784 run_lib.py:133] step: 546800, training_loss: 4.95430e-02
I0212 06:41:19.419920 22509476222784 run_lib.py:146] step: 546800, eval_loss: 4.55143e-02
I0212 06:41:38.162762 22509476222784 run_lib.py:133] step: 546850, training_loss: 4.59437e-02
I0212 06:41:56.876409 22509476222784 run_lib.py:133] step: 546900, training_loss: 4.43280e-02
I0212 06:41:57.067627 22509476222784 run_lib.py:146] step: 546900, eval_loss: 4.42912e-02
I0212 06:42:15.536357 22509476222784 run_lib.py:133] step: 546950, training_loss: 3.56164e-02
I0212 06:42:33.962172 22509476222784 run_lib.py:133] step: 547000, training_loss: 3.99105e-02
I0212 06:42:34.124544 22509476222784 run_lib.py:146] step: 547000, eval_loss: 5.55148e-02
I0212 06:42:52.621281 22509476222784 run_lib.py:133] step: 547050, training_loss: 3.17488e-02
I0212 06:43:11.281034 22509476222784 run_lib.py:133] step: 547100, training_loss: 5.45741e-02
I0212 06:43:11.445781 22509476222784 run_lib.py:146] step: 547100, eval_loss: 3.88362e-02
I0212 06:43:29.974900 22509476222784 run_lib.py:133] step: 547150, training_loss: 4.01542e-02
I0212 06:43:48.462355 22509476222784 run_lib.py:133] step: 547200, training_loss: 3.56110e-02
I0212 06:43:48.628834 22509476222784 run_lib.py:146] step: 547200, eval_loss: 5.07902e-02
I0212 06:44:07.132041 22509476222784 run_lib.py:133] step: 547250, training_loss: 5.87236e-02
I0212 06:44:25.844758 22509476222784 run_lib.py:133] step: 547300, training_loss: 4.45505e-02
I0212 06:44:26.046026 22509476222784 run_lib.py:146] step: 547300, eval_loss: 3.65605e-02
I0212 06:44:44.539467 22509476222784 run_lib.py:133] step: 547350, training_loss: 4.53586e-02
I0212 06:45:03.116566 22509476222784 run_lib.py:133] step: 547400, training_loss: 4.65291e-02
I0212 06:45:03.284723 22509476222784 run_lib.py:146] step: 547400, eval_loss: 5.05888e-02
I0212 06:45:21.745505 22509476222784 run_lib.py:133] step: 547450, training_loss: 3.68325e-02
I0212 06:45:40.261738 22509476222784 run_lib.py:133] step: 547500, training_loss: 6.04366e-02
I0212 06:45:40.460699 22509476222784 run_lib.py:146] step: 547500, eval_loss: 4.78160e-02
I0212 06:45:59.153813 22509476222784 run_lib.py:133] step: 547550, training_loss: 4.52865e-02
I0212 06:46:17.658988 22509476222784 run_lib.py:133] step: 547600, training_loss: 4.35421e-02
I0212 06:46:17.822589 22509476222784 run_lib.py:146] step: 547600, eval_loss: 4.35811e-02
I0212 06:46:36.280072 22509476222784 run_lib.py:133] step: 547650, training_loss: 5.56597e-02
I0212 06:46:54.853137 22509476222784 run_lib.py:133] step: 547700, training_loss: 3.72346e-02
I0212 06:46:55.034335 22509476222784 run_lib.py:146] step: 547700, eval_loss: 5.11955e-02
I0212 06:47:13.736243 22509476222784 run_lib.py:133] step: 547750, training_loss: 4.59029e-02
I0212 06:47:32.164762 22509476222784 run_lib.py:133] step: 547800, training_loss: 4.25563e-02
I0212 06:47:32.328750 22509476222784 run_lib.py:146] step: 547800, eval_loss: 4.88579e-02
I0212 06:47:51.007744 22509476222784 run_lib.py:133] step: 547850, training_loss: 3.53744e-02
I0212 06:48:09.394805 22509476222784 run_lib.py:133] step: 547900, training_loss: 4.04027e-02
I0212 06:48:09.556587 22509476222784 run_lib.py:146] step: 547900, eval_loss: 3.25834e-02
I0212 06:48:28.125746 22509476222784 run_lib.py:133] step: 547950, training_loss: 5.10148e-02
I0212 06:48:46.643763 22509476222784 run_lib.py:133] step: 548000, training_loss: 3.79991e-02
I0212 06:48:46.813375 22509476222784 run_lib.py:146] step: 548000, eval_loss: 3.59190e-02
I0212 06:49:05.330368 22509476222784 run_lib.py:133] step: 548050, training_loss: 3.41978e-02
I0212 06:49:24.002841 22509476222784 run_lib.py:133] step: 548100, training_loss: 3.05956e-02
I0212 06:49:24.166777 22509476222784 run_lib.py:146] step: 548100, eval_loss: 4.74233e-02
I0212 06:49:42.642009 22509476222784 run_lib.py:133] step: 548150, training_loss: 3.76192e-02
I0212 06:50:01.280850 22509476222784 run_lib.py:133] step: 548200, training_loss: 3.61687e-02
I0212 06:50:01.456612 22509476222784 run_lib.py:146] step: 548200, eval_loss: 4.71860e-02
I0212 06:50:19.998613 22509476222784 run_lib.py:133] step: 548250, training_loss: 3.14369e-02
I0212 06:50:38.593858 22509476222784 run_lib.py:133] step: 548300, training_loss: 5.24304e-02
I0212 06:50:38.763741 22509476222784 run_lib.py:146] step: 548300, eval_loss: 5.74763e-02
I0212 06:50:57.420480 22509476222784 run_lib.py:133] step: 548350, training_loss: 4.60231e-02
I0212 06:51:15.842226 22509476222784 run_lib.py:133] step: 548400, training_loss: 4.51839e-02
I0212 06:51:16.004549 22509476222784 run_lib.py:146] step: 548400, eval_loss: 5.12849e-02
I0212 06:51:34.495409 22509476222784 run_lib.py:133] step: 548450, training_loss: 4.65910e-02
I0212 06:51:53.147953 22509476222784 run_lib.py:133] step: 548500, training_loss: 3.94098e-02
I0212 06:51:53.330720 22509476222784 run_lib.py:146] step: 548500, eval_loss: 4.59627e-02
I0212 06:52:11.920686 22509476222784 run_lib.py:133] step: 548550, training_loss: 4.71901e-02
I0212 06:52:30.427222 22509476222784 run_lib.py:133] step: 548600, training_loss: 4.21807e-02
I0212 06:52:30.592726 22509476222784 run_lib.py:146] step: 548600, eval_loss: 3.50348e-02
I0212 06:52:49.192221 22509476222784 run_lib.py:133] step: 548650, training_loss: 4.93038e-02
I0212 06:53:07.668200 22509476222784 run_lib.py:133] step: 548700, training_loss: 4.08481e-02
I0212 06:53:07.834902 22509476222784 run_lib.py:146] step: 548700, eval_loss: 3.40724e-02
I0212 06:53:26.262228 22509476222784 run_lib.py:133] step: 548750, training_loss: 3.79241e-02
I0212 06:53:44.794564 22509476222784 run_lib.py:133] step: 548800, training_loss: 5.59892e-02
I0212 06:53:44.968719 22509476222784 run_lib.py:146] step: 548800, eval_loss: 5.45991e-02
I0212 06:54:03.686633 22509476222784 run_lib.py:133] step: 548850, training_loss: 3.96123e-02
I0212 06:54:22.248535 22509476222784 run_lib.py:133] step: 548900, training_loss: 3.50253e-02
I0212 06:54:22.411365 22509476222784 run_lib.py:146] step: 548900, eval_loss: 3.67147e-02
I0212 06:54:40.925841 22509476222784 run_lib.py:133] step: 548950, training_loss: 4.10067e-02
I0212 06:54:59.434510 22509476222784 run_lib.py:133] step: 549000, training_loss: 5.39089e-02
I0212 06:54:59.630820 22509476222784 run_lib.py:146] step: 549000, eval_loss: 3.67924e-02
I0212 06:55:18.310488 22509476222784 run_lib.py:133] step: 549050, training_loss: 4.45755e-02
I0212 06:55:36.702295 22509476222784 run_lib.py:133] step: 549100, training_loss: 5.27628e-02
I0212 06:55:36.868397 22509476222784 run_lib.py:146] step: 549100, eval_loss: 4.00691e-02
I0212 06:55:55.444888 22509476222784 run_lib.py:133] step: 549150, training_loss: 5.59591e-02
I0212 06:56:13.946483 22509476222784 run_lib.py:133] step: 549200, training_loss: 4.69852e-02
I0212 06:56:14.118953 22509476222784 run_lib.py:146] step: 549200, eval_loss: 3.36358e-02
I0212 06:56:32.753932 22509476222784 run_lib.py:133] step: 549250, training_loss: 3.42957e-02
I0212 06:56:51.332604 22509476222784 run_lib.py:133] step: 549300, training_loss: 3.82140e-02
I0212 06:56:51.505782 22509476222784 run_lib.py:146] step: 549300, eval_loss: 4.76512e-02
I0212 06:57:10.228145 22509476222784 run_lib.py:133] step: 549350, training_loss: 4.46957e-02
I0212 06:57:28.807058 22509476222784 run_lib.py:133] step: 549400, training_loss: 4.91994e-02
I0212 06:57:28.983135 22509476222784 run_lib.py:146] step: 549400, eval_loss: 5.94642e-02
I0212 06:57:47.461944 22509476222784 run_lib.py:133] step: 549450, training_loss: 5.29398e-02
I0212 06:58:06.090852 22509476222784 run_lib.py:133] step: 549500, training_loss: 5.01630e-02
I0212 06:58:06.252710 22509476222784 run_lib.py:146] step: 549500, eval_loss: 4.97388e-02
I0212 06:58:24.707121 22509476222784 run_lib.py:133] step: 549550, training_loss: 4.38180e-02
I0212 06:58:43.238798 22509476222784 run_lib.py:133] step: 549600, training_loss: 3.53409e-02
I0212 06:58:43.479403 22509476222784 run_lib.py:146] step: 549600, eval_loss: 3.71142e-02
I0212 06:59:02.142470 22509476222784 run_lib.py:133] step: 549650, training_loss: 3.95576e-02
I0212 06:59:20.689885 22509476222784 run_lib.py:133] step: 549700, training_loss: 4.89737e-02
I0212 06:59:20.851176 22509476222784 run_lib.py:146] step: 549700, eval_loss: 3.83199e-02
I0212 06:59:39.468618 22509476222784 run_lib.py:133] step: 549750, training_loss: 3.29517e-02
I0212 06:59:57.981155 22509476222784 run_lib.py:133] step: 549800, training_loss: 3.93822e-02
I0212 06:59:58.146662 22509476222784 run_lib.py:146] step: 549800, eval_loss: 2.55536e-02
I0212 07:00:16.531099 22509476222784 run_lib.py:133] step: 549850, training_loss: 3.80536e-02
I0212 07:00:35.214252 22509476222784 run_lib.py:133] step: 549900, training_loss: 4.56262e-02
I0212 07:00:35.392790 22509476222784 run_lib.py:146] step: 549900, eval_loss: 5.26795e-02
I0212 07:00:53.970425 22509476222784 run_lib.py:133] step: 549950, training_loss: 3.99882e-02
I0212 07:01:12.400585 22509476222784 run_lib.py:133] step: 550000, training_loss: 4.28221e-02
I0212 07:01:13.119504 22509476222784 run_lib.py:146] step: 550000, eval_loss: 4.76468e-02
I0212 07:01:34.188495 22509476222784 run_lib.py:133] step: 550050, training_loss: 3.02258e-02
I0212 07:01:52.661100 22509476222784 run_lib.py:133] step: 550100, training_loss: 4.71449e-02
I0212 07:01:52.839845 22509476222784 run_lib.py:146] step: 550100, eval_loss: 5.31286e-02
I0212 07:02:11.577205 22509476222784 run_lib.py:133] step: 550150, training_loss: 4.61136e-02
I0212 07:02:30.176260 22509476222784 run_lib.py:133] step: 550200, training_loss: 3.33702e-02
I0212 07:02:30.352802 22509476222784 run_lib.py:146] step: 550200, eval_loss: 2.83631e-02
I0212 07:02:48.935448 22509476222784 run_lib.py:133] step: 550250, training_loss: 5.06504e-02
I0212 07:03:07.418791 22509476222784 run_lib.py:133] step: 550300, training_loss: 3.86751e-02
I0212 07:03:07.582848 22509476222784 run_lib.py:146] step: 550300, eval_loss: 3.97986e-02
I0212 07:03:26.088298 22509476222784 run_lib.py:133] step: 550350, training_loss: 4.91078e-02
I0212 07:03:44.540625 22509476222784 run_lib.py:133] step: 550400, training_loss: 4.09322e-02
I0212 07:03:44.704687 22509476222784 run_lib.py:146] step: 550400, eval_loss: 3.74303e-02
I0212 07:04:03.322526 22509476222784 run_lib.py:133] step: 550450, training_loss: 2.91598e-02
I0212 07:04:21.953437 22509476222784 run_lib.py:133] step: 550500, training_loss: 4.39869e-02
I0212 07:04:22.122646 22509476222784 run_lib.py:146] step: 550500, eval_loss: 3.40801e-02
I0212 07:04:40.593463 22509476222784 run_lib.py:133] step: 550550, training_loss: 4.75789e-02
I0212 07:04:58.935505 22509476222784 run_lib.py:133] step: 550600, training_loss: 3.71719e-02
I0212 07:04:59.102868 22509476222784 run_lib.py:146] step: 550600, eval_loss: 3.72149e-02
I0212 07:05:17.746920 22509476222784 run_lib.py:133] step: 550650, training_loss: 3.84595e-02
I0212 07:05:36.305585 22509476222784 run_lib.py:133] step: 550700, training_loss: 4.32179e-02
I0212 07:05:36.486417 22509476222784 run_lib.py:146] step: 550700, eval_loss: 4.61085e-02
I0212 07:05:55.215542 22509476222784 run_lib.py:133] step: 550750, training_loss: 3.91281e-02
I0212 07:06:13.676099 22509476222784 run_lib.py:133] step: 550800, training_loss: 3.51298e-02
I0212 07:06:13.838328 22509476222784 run_lib.py:146] step: 550800, eval_loss: 2.89162e-02
I0212 07:06:32.526248 22509476222784 run_lib.py:133] step: 550850, training_loss: 4.19717e-02
I0212 07:06:50.971652 22509476222784 run_lib.py:133] step: 550900, training_loss: 5.12802e-02
I0212 07:06:51.133624 22509476222784 run_lib.py:146] step: 550900, eval_loss: 4.19776e-02
I0212 07:07:09.791040 22509476222784 run_lib.py:133] step: 550950, training_loss: 4.90853e-02
I0212 07:07:28.231992 22509476222784 run_lib.py:133] step: 551000, training_loss: 4.47064e-02
I0212 07:07:28.401873 22509476222784 run_lib.py:146] step: 551000, eval_loss: 5.27449e-02
I0212 07:07:46.932980 22509476222784 run_lib.py:133] step: 551050, training_loss: 4.02576e-02
I0212 07:08:05.612562 22509476222784 run_lib.py:133] step: 551100, training_loss: 4.22587e-02
I0212 07:08:05.793945 22509476222784 run_lib.py:146] step: 551100, eval_loss: 3.35974e-02
I0212 07:08:24.261137 22509476222784 run_lib.py:133] step: 551150, training_loss: 4.69561e-02
I0212 07:08:42.678335 22509476222784 run_lib.py:133] step: 551200, training_loss: 3.38792e-02
I0212 07:08:42.849496 22509476222784 run_lib.py:146] step: 551200, eval_loss: 3.83499e-02
I0212 07:09:01.493334 22509476222784 run_lib.py:133] step: 551250, training_loss: 3.72992e-02
I0212 07:09:20.231824 22509476222784 run_lib.py:133] step: 551300, training_loss: 4.76618e-02
I0212 07:09:20.396330 22509476222784 run_lib.py:146] step: 551300, eval_loss: 4.17883e-02
I0212 07:09:38.912128 22509476222784 run_lib.py:133] step: 551350, training_loss: 4.41827e-02
I0212 07:09:57.414310 22509476222784 run_lib.py:133] step: 551400, training_loss: 4.98626e-02
I0212 07:09:57.574438 22509476222784 run_lib.py:146] step: 551400, eval_loss: 4.03294e-02
I0212 07:10:16.083486 22509476222784 run_lib.py:133] step: 551450, training_loss: 4.27214e-02
I0212 07:10:34.591620 22509476222784 run_lib.py:133] step: 551500, training_loss: 3.47041e-02
I0212 07:10:34.767859 22509476222784 run_lib.py:146] step: 551500, eval_loss: 4.59359e-02
I0212 07:10:53.278930 22509476222784 run_lib.py:133] step: 551550, training_loss: 3.71792e-02
I0212 07:11:11.787493 22509476222784 run_lib.py:133] step: 551600, training_loss: 4.74460e-02
I0212 07:11:11.952603 22509476222784 run_lib.py:146] step: 551600, eval_loss: 3.27445e-02
I0212 07:11:30.422018 22509476222784 run_lib.py:133] step: 551650, training_loss: 4.02352e-02
I0212 07:11:49.143255 22509476222784 run_lib.py:133] step: 551700, training_loss: 3.80151e-02
I0212 07:11:49.307788 22509476222784 run_lib.py:146] step: 551700, eval_loss: 5.61286e-02
I0212 07:12:07.776183 22509476222784 run_lib.py:133] step: 551750, training_loss: 4.99643e-02
I0212 07:12:26.433394 22509476222784 run_lib.py:133] step: 551800, training_loss: 3.64175e-02
I0212 07:12:26.597595 22509476222784 run_lib.py:146] step: 551800, eval_loss: 4.11341e-02
I0212 07:12:45.167156 22509476222784 run_lib.py:133] step: 551850, training_loss: 3.89005e-02
I0212 07:13:03.565801 22509476222784 run_lib.py:133] step: 551900, training_loss: 3.44348e-02
I0212 07:13:03.727677 22509476222784 run_lib.py:146] step: 551900, eval_loss: 3.78945e-02
I0212 07:13:22.354886 22509476222784 run_lib.py:133] step: 551950, training_loss: 4.50747e-02
I0212 07:13:40.944577 22509476222784 run_lib.py:133] step: 552000, training_loss: 4.40341e-02
I0212 07:13:41.108882 22509476222784 run_lib.py:146] step: 552000, eval_loss: 3.85208e-02
I0212 07:13:59.587083 22509476222784 run_lib.py:133] step: 552050, training_loss: 3.75979e-02
I0212 07:14:18.040720 22509476222784 run_lib.py:133] step: 552100, training_loss: 4.09615e-02
I0212 07:14:18.207659 22509476222784 run_lib.py:146] step: 552100, eval_loss: 3.70760e-02
I0212 07:14:36.936748 22509476222784 run_lib.py:133] step: 552150, training_loss: 4.75540e-02
I0212 07:14:55.460466 22509476222784 run_lib.py:133] step: 552200, training_loss: 4.08212e-02
I0212 07:14:55.624807 22509476222784 run_lib.py:146] step: 552200, eval_loss: 3.69028e-02
I0212 07:15:14.281081 22509476222784 run_lib.py:133] step: 552250, training_loss: 6.15886e-02
I0212 07:15:32.796916 22509476222784 run_lib.py:133] step: 552300, training_loss: 5.40676e-02
I0212 07:15:32.956413 22509476222784 run_lib.py:146] step: 552300, eval_loss: 4.69296e-02
I0212 07:15:51.706609 22509476222784 run_lib.py:133] step: 552350, training_loss: 3.60090e-02
I0212 07:16:10.243561 22509476222784 run_lib.py:133] step: 552400, training_loss: 2.80370e-02
I0212 07:16:10.405607 22509476222784 run_lib.py:146] step: 552400, eval_loss: 4.08465e-02
I0212 07:16:28.951357 22509476222784 run_lib.py:133] step: 552450, training_loss: 2.76018e-02
I0212 07:16:47.645062 22509476222784 run_lib.py:133] step: 552500, training_loss: 4.69066e-02
I0212 07:16:47.812928 22509476222784 run_lib.py:146] step: 552500, eval_loss: 3.73809e-02
I0212 07:17:06.317453 22509476222784 run_lib.py:133] step: 552550, training_loss: 4.16971e-02
I0212 07:17:24.955199 22509476222784 run_lib.py:133] step: 552600, training_loss: 3.75091e-02
I0212 07:17:25.139701 22509476222784 run_lib.py:146] step: 552600, eval_loss: 3.55746e-02
I0212 07:17:43.675083 22509476222784 run_lib.py:133] step: 552650, training_loss: 5.27833e-02
I0212 07:18:02.240105 22509476222784 run_lib.py:133] step: 552700, training_loss: 3.67922e-02
I0212 07:18:02.403866 22509476222784 run_lib.py:146] step: 552700, eval_loss: 3.53354e-02
I0212 07:18:21.104941 22509476222784 run_lib.py:133] step: 552750, training_loss: 4.38908e-02
I0212 07:18:39.607246 22509476222784 run_lib.py:133] step: 552800, training_loss: 3.15349e-02
I0212 07:18:39.771621 22509476222784 run_lib.py:146] step: 552800, eval_loss: 4.26204e-02
I0212 07:18:58.309602 22509476222784 run_lib.py:133] step: 552850, training_loss: 4.66622e-02
I0212 07:19:16.970954 22509476222784 run_lib.py:133] step: 552900, training_loss: 4.92900e-02
I0212 07:19:17.145827 22509476222784 run_lib.py:146] step: 552900, eval_loss: 4.31533e-02
I0212 07:19:35.616166 22509476222784 run_lib.py:133] step: 552950, training_loss: 2.78391e-02
I0212 07:19:54.077304 22509476222784 run_lib.py:133] step: 553000, training_loss: 5.32798e-02
I0212 07:19:54.243615 22509476222784 run_lib.py:146] step: 553000, eval_loss: 4.42517e-02
I0212 07:20:12.857448 22509476222784 run_lib.py:133] step: 553050, training_loss: 3.67850e-02
I0212 07:20:31.347700 22509476222784 run_lib.py:133] step: 553100, training_loss: 4.23508e-02
I0212 07:20:31.511816 22509476222784 run_lib.py:146] step: 553100, eval_loss: 3.43050e-02
I0212 07:20:50.012535 22509476222784 run_lib.py:133] step: 553150, training_loss: 4.36581e-02
I0212 07:21:08.597872 22509476222784 run_lib.py:133] step: 553200, training_loss: 4.49185e-02
I0212 07:21:08.766885 22509476222784 run_lib.py:146] step: 553200, eval_loss: 4.73705e-02
I0212 07:21:27.403466 22509476222784 run_lib.py:133] step: 553250, training_loss: 4.68266e-02
I0212 07:21:45.988265 22509476222784 run_lib.py:133] step: 553300, training_loss: 3.33650e-02
I0212 07:21:46.196719 22509476222784 run_lib.py:146] step: 553300, eval_loss: 4.51200e-02
I0212 07:22:04.691959 22509476222784 run_lib.py:133] step: 553350, training_loss: 4.66963e-02
I0212 07:22:23.187157 22509476222784 run_lib.py:133] step: 553400, training_loss: 4.20583e-02
I0212 07:22:23.370709 22509476222784 run_lib.py:146] step: 553400, eval_loss: 4.72112e-02
I0212 07:22:42.051213 22509476222784 run_lib.py:133] step: 553450, training_loss: 3.67776e-02
I0212 07:23:00.596686 22509476222784 run_lib.py:133] step: 553500, training_loss: 2.92386e-02
I0212 07:23:00.766651 22509476222784 run_lib.py:146] step: 553500, eval_loss: 3.50485e-02
I0212 07:23:19.399466 22509476222784 run_lib.py:133] step: 553550, training_loss: 6.03265e-02
I0212 07:23:37.905181 22509476222784 run_lib.py:133] step: 553600, training_loss: 3.26110e-02
I0212 07:23:38.084654 22509476222784 run_lib.py:146] step: 553600, eval_loss: 3.20381e-02
I0212 07:23:56.712530 22509476222784 run_lib.py:133] step: 553650, training_loss: 5.06743e-02
I0212 07:24:15.217823 22509476222784 run_lib.py:133] step: 553700, training_loss: 4.15008e-02
I0212 07:24:15.389671 22509476222784 run_lib.py:146] step: 553700, eval_loss: 5.33427e-02
I0212 07:24:34.088317 22509476222784 run_lib.py:133] step: 553750, training_loss: 3.93408e-02
I0212 07:24:52.581936 22509476222784 run_lib.py:133] step: 553800, training_loss: 4.66908e-02
I0212 07:24:52.742619 22509476222784 run_lib.py:146] step: 553800, eval_loss: 6.07936e-02
I0212 07:25:11.232636 22509476222784 run_lib.py:133] step: 553850, training_loss: 4.54099e-02
I0212 07:25:29.927006 22509476222784 run_lib.py:133] step: 553900, training_loss: 4.50275e-02
I0212 07:25:30.090505 22509476222784 run_lib.py:146] step: 553900, eval_loss: 4.49942e-02
I0212 07:25:48.470686 22509476222784 run_lib.py:133] step: 553950, training_loss: 4.01485e-02
I0212 07:26:06.972797 22509476222784 run_lib.py:133] step: 554000, training_loss: 4.77035e-02
I0212 07:26:07.153642 22509476222784 run_lib.py:146] step: 554000, eval_loss: 4.56961e-02
I0212 07:26:25.858321 22509476222784 run_lib.py:133] step: 554050, training_loss: 3.84373e-02
I0212 07:26:44.387079 22509476222784 run_lib.py:133] step: 554100, training_loss: 2.79583e-02
I0212 07:26:44.552898 22509476222784 run_lib.py:146] step: 554100, eval_loss: 4.02492e-02
I0212 07:27:03.232646 22509476222784 run_lib.py:133] step: 554150, training_loss: 3.32846e-02
I0212 07:27:21.687275 22509476222784 run_lib.py:133] step: 554200, training_loss: 4.62237e-02
I0212 07:27:21.849708 22509476222784 run_lib.py:146] step: 554200, eval_loss: 5.68516e-02
I0212 07:27:40.326014 22509476222784 run_lib.py:133] step: 554250, training_loss: 2.94120e-02
I0212 07:27:59.046847 22509476222784 run_lib.py:133] step: 554300, training_loss: 4.45224e-02
I0212 07:27:59.220843 22509476222784 run_lib.py:146] step: 554300, eval_loss: 4.74563e-02
I0212 07:28:17.642350 22509476222784 run_lib.py:133] step: 554350, training_loss: 4.03677e-02
I0212 07:28:36.116575 22509476222784 run_lib.py:133] step: 554400, training_loss: 3.76186e-02
I0212 07:28:36.281743 22509476222784 run_lib.py:146] step: 554400, eval_loss: 4.57308e-02
I0212 07:28:54.773611 22509476222784 run_lib.py:133] step: 554450, training_loss: 5.08195e-02
I0212 07:29:13.434660 22509476222784 run_lib.py:133] step: 554500, training_loss: 4.24804e-02
I0212 07:29:13.597637 22509476222784 run_lib.py:146] step: 554500, eval_loss: 3.40872e-02
I0212 07:29:32.132446 22509476222784 run_lib.py:133] step: 554550, training_loss: 4.19780e-02
I0212 07:29:50.763157 22509476222784 run_lib.py:133] step: 554600, training_loss: 4.12942e-02
I0212 07:29:50.929353 22509476222784 run_lib.py:146] step: 554600, eval_loss: 4.03374e-02
I0212 07:30:09.436486 22509476222784 run_lib.py:133] step: 554650, training_loss: 4.37903e-02
I0212 07:30:27.816046 22509476222784 run_lib.py:133] step: 554700, training_loss: 4.56992e-02
I0212 07:30:27.977609 22509476222784 run_lib.py:146] step: 554700, eval_loss: 5.51795e-02
I0212 07:30:46.662472 22509476222784 run_lib.py:133] step: 554750, training_loss: 4.02637e-02
I0212 07:31:05.276164 22509476222784 run_lib.py:133] step: 554800, training_loss: 3.70750e-02
I0212 07:31:05.462234 22509476222784 run_lib.py:146] step: 554800, eval_loss: 3.15322e-02
I0212 07:31:24.073309 22509476222784 run_lib.py:133] step: 554850, training_loss: 3.41712e-02
I0212 07:31:42.544764 22509476222784 run_lib.py:133] step: 554900, training_loss: 3.36143e-02
I0212 07:31:42.736650 22509476222784 run_lib.py:146] step: 554900, eval_loss: 3.97644e-02
I0212 07:32:01.422829 22509476222784 run_lib.py:133] step: 554950, training_loss: 4.69046e-02
I0212 07:32:19.824328 22509476222784 run_lib.py:133] step: 555000, training_loss: 5.28562e-02
I0212 07:32:19.985910 22509476222784 run_lib.py:146] step: 555000, eval_loss: 4.06636e-02
I0212 07:32:38.636753 22509476222784 run_lib.py:133] step: 555050, training_loss: 4.13346e-02
I0212 07:32:57.092664 22509476222784 run_lib.py:133] step: 555100, training_loss: 4.69069e-02
I0212 07:32:57.255784 22509476222784 run_lib.py:146] step: 555100, eval_loss: 3.81691e-02
I0212 07:33:15.931837 22509476222784 run_lib.py:133] step: 555150, training_loss: 5.49116e-02
I0212 07:33:34.417241 22509476222784 run_lib.py:133] step: 555200, training_loss: 4.39159e-02
I0212 07:33:34.628801 22509476222784 run_lib.py:146] step: 555200, eval_loss: 4.34420e-02
I0212 07:33:53.139678 22509476222784 run_lib.py:133] step: 555250, training_loss: 5.29975e-02
I0212 07:34:11.732948 22509476222784 run_lib.py:133] step: 555300, training_loss: 4.15717e-02
I0212 07:34:11.900005 22509476222784 run_lib.py:146] step: 555300, eval_loss: 4.52972e-02
I0212 07:34:30.464082 22509476222784 run_lib.py:133] step: 555350, training_loss: 3.75992e-02
I0212 07:34:49.046937 22509476222784 run_lib.py:133] step: 555400, training_loss: 5.48263e-02
I0212 07:34:49.211544 22509476222784 run_lib.py:146] step: 555400, eval_loss: 5.33993e-02
I0212 07:35:07.745393 22509476222784 run_lib.py:133] step: 555450, training_loss: 4.24580e-02
I0212 07:35:26.278948 22509476222784 run_lib.py:133] step: 555500, training_loss: 3.52384e-02
I0212 07:35:26.458551 22509476222784 run_lib.py:146] step: 555500, eval_loss: 4.57716e-02
I0212 07:35:45.118366 22509476222784 run_lib.py:133] step: 555550, training_loss: 5.16361e-02
I0212 07:36:03.609583 22509476222784 run_lib.py:133] step: 555600, training_loss: 3.40033e-02
I0212 07:36:03.776794 22509476222784 run_lib.py:146] step: 555600, eval_loss: 4.35241e-02
I0212 07:36:22.323526 22509476222784 run_lib.py:133] step: 555650, training_loss: 3.95813e-02
I0212 07:36:40.951641 22509476222784 run_lib.py:133] step: 555700, training_loss: 5.58529e-02
I0212 07:36:41.111667 22509476222784 run_lib.py:146] step: 555700, eval_loss: 4.81348e-02
I0212 07:36:59.475525 22509476222784 run_lib.py:133] step: 555750, training_loss: 3.47581e-02
I0212 07:37:17.911805 22509476222784 run_lib.py:133] step: 555800, training_loss: 4.85213e-02
I0212 07:37:18.224889 22509476222784 run_lib.py:146] step: 555800, eval_loss: 4.38958e-02
I0212 07:37:36.712789 22509476222784 run_lib.py:133] step: 555850, training_loss: 5.90336e-02
I0212 07:37:55.170735 22509476222784 run_lib.py:133] step: 555900, training_loss: 5.50798e-02
I0212 07:37:55.334508 22509476222784 run_lib.py:146] step: 555900, eval_loss: 4.98397e-02
I0212 07:38:13.833741 22509476222784 run_lib.py:133] step: 555950, training_loss: 3.58732e-02
I0212 07:38:32.365793 22509476222784 run_lib.py:133] step: 556000, training_loss: 3.71869e-02
I0212 07:38:32.529872 22509476222784 run_lib.py:146] step: 556000, eval_loss: 4.15201e-02
I0212 07:38:51.216642 22509476222784 run_lib.py:133] step: 556050, training_loss: 3.69079e-02
I0212 07:39:09.781554 22509476222784 run_lib.py:133] step: 556100, training_loss: 4.44785e-02
I0212 07:39:09.968696 22509476222784 run_lib.py:146] step: 556100, eval_loss: 5.04121e-02
I0212 07:39:28.498394 22509476222784 run_lib.py:133] step: 556150, training_loss: 4.25353e-02
I0212 07:39:47.023966 22509476222784 run_lib.py:133] step: 556200, training_loss: 4.75773e-02
I0212 07:39:47.187926 22509476222784 run_lib.py:146] step: 556200, eval_loss: 4.81144e-02
I0212 07:40:05.889382 22509476222784 run_lib.py:133] step: 556250, training_loss: 4.07561e-02
I0212 07:40:24.393156 22509476222784 run_lib.py:133] step: 556300, training_loss: 3.68440e-02
I0212 07:40:24.558922 22509476222784 run_lib.py:146] step: 556300, eval_loss: 4.08385e-02
I0212 07:40:43.104209 22509476222784 run_lib.py:133] step: 556350, training_loss: 3.70082e-02
I0212 07:41:01.615353 22509476222784 run_lib.py:133] step: 556400, training_loss: 3.25705e-02
I0212 07:41:01.790655 22509476222784 run_lib.py:146] step: 556400, eval_loss: 4.29201e-02
I0212 07:41:20.491630 22509476222784 run_lib.py:133] step: 556450, training_loss: 4.13918e-02
I0212 07:41:39.002112 22509476222784 run_lib.py:133] step: 556500, training_loss: 4.11575e-02
I0212 07:41:39.199427 22509476222784 run_lib.py:146] step: 556500, eval_loss: 3.98495e-02
I0212 07:41:57.912148 22509476222784 run_lib.py:133] step: 556550, training_loss: 4.26173e-02
I0212 07:42:16.436350 22509476222784 run_lib.py:133] step: 556600, training_loss: 4.79517e-02
I0212 07:42:16.593639 22509476222784 run_lib.py:146] step: 556600, eval_loss: 5.10759e-02
I0212 07:42:35.202189 22509476222784 run_lib.py:133] step: 556650, training_loss: 4.36846e-02
I0212 07:42:53.758456 22509476222784 run_lib.py:133] step: 556700, training_loss: 4.42263e-02
I0212 07:42:53.937781 22509476222784 run_lib.py:146] step: 556700, eval_loss: 4.08669e-02
I0212 07:43:12.485708 22509476222784 run_lib.py:133] step: 556750, training_loss: 4.91459e-02
I0212 07:43:31.245443 22509476222784 run_lib.py:133] step: 556800, training_loss: 5.09182e-02
I0212 07:43:31.417633 22509476222784 run_lib.py:146] step: 556800, eval_loss: 3.49261e-02
I0212 07:43:49.819600 22509476222784 run_lib.py:133] step: 556850, training_loss: 4.40462e-02
I0212 07:44:08.433361 22509476222784 run_lib.py:133] step: 556900, training_loss: 4.06528e-02
I0212 07:44:08.597142 22509476222784 run_lib.py:146] step: 556900, eval_loss: 4.32418e-02
I0212 07:44:27.067216 22509476222784 run_lib.py:133] step: 556950, training_loss: 5.70982e-02
I0212 07:44:45.640725 22509476222784 run_lib.py:133] step: 557000, training_loss: 3.86545e-02
I0212 07:44:45.805969 22509476222784 run_lib.py:146] step: 557000, eval_loss: 5.13911e-02
I0212 07:45:04.331355 22509476222784 run_lib.py:133] step: 557050, training_loss: 4.07353e-02
I0212 07:45:23.059341 22509476222784 run_lib.py:133] step: 557100, training_loss: 3.15460e-02
I0212 07:45:23.251597 22509476222784 run_lib.py:146] step: 557100, eval_loss: 4.10860e-02
I0212 07:45:41.695590 22509476222784 run_lib.py:133] step: 557150, training_loss: 4.30746e-02
I0212 07:46:00.174963 22509476222784 run_lib.py:133] step: 557200, training_loss: 4.14695e-02
I0212 07:46:00.345675 22509476222784 run_lib.py:146] step: 557200, eval_loss: 4.03844e-02
I0212 07:46:19.029299 22509476222784 run_lib.py:133] step: 557250, training_loss: 4.29890e-02
I0212 07:46:37.615087 22509476222784 run_lib.py:133] step: 557300, training_loss: 4.57259e-02
I0212 07:46:37.794619 22509476222784 run_lib.py:146] step: 557300, eval_loss: 2.78028e-02
I0212 07:46:56.397461 22509476222784 run_lib.py:133] step: 557350, training_loss: 3.54582e-02
I0212 07:47:14.950143 22509476222784 run_lib.py:133] step: 557400, training_loss: 4.84592e-02
I0212 07:47:15.113864 22509476222784 run_lib.py:146] step: 557400, eval_loss: 5.59220e-02
I0212 07:47:33.626188 22509476222784 run_lib.py:133] step: 557450, training_loss: 3.81266e-02
I0212 07:47:52.145889 22509476222784 run_lib.py:133] step: 557500, training_loss: 4.19289e-02
I0212 07:47:52.340858 22509476222784 run_lib.py:146] step: 557500, eval_loss: 4.93035e-02
I0212 07:48:11.030195 22509476222784 run_lib.py:133] step: 557550, training_loss: 4.19531e-02
I0212 07:48:29.676717 22509476222784 run_lib.py:133] step: 557600, training_loss: 5.10289e-02
I0212 07:48:29.836220 22509476222784 run_lib.py:146] step: 557600, eval_loss: 4.87215e-02
I0212 07:48:48.333598 22509476222784 run_lib.py:133] step: 557650, training_loss: 3.80573e-02
I0212 07:49:06.834474 22509476222784 run_lib.py:133] step: 557700, training_loss: 5.36400e-02
I0212 07:49:06.998892 22509476222784 run_lib.py:146] step: 557700, eval_loss: 3.99860e-02
I0212 07:49:25.612296 22509476222784 run_lib.py:133] step: 557750, training_loss: 4.91614e-02
I0212 07:49:44.184991 22509476222784 run_lib.py:133] step: 557800, training_loss: 4.48449e-02
I0212 07:49:44.366759 22509476222784 run_lib.py:146] step: 557800, eval_loss: 4.79406e-02
I0212 07:50:03.087680 22509476222784 run_lib.py:133] step: 557850, training_loss: 4.33863e-02
I0212 07:50:21.640367 22509476222784 run_lib.py:133] step: 557900, training_loss: 3.74678e-02
I0212 07:50:21.800767 22509476222784 run_lib.py:146] step: 557900, eval_loss: 3.27448e-02
I0212 07:50:40.532530 22509476222784 run_lib.py:133] step: 557950, training_loss: 3.88772e-02
I0212 07:50:59.037923 22509476222784 run_lib.py:133] step: 558000, training_loss: 5.00557e-02
I0212 07:50:59.200624 22509476222784 run_lib.py:146] step: 558000, eval_loss: 3.26109e-02
I0212 07:51:17.763021 22509476222784 run_lib.py:133] step: 558050, training_loss: 4.82814e-02
I0212 07:51:36.307722 22509476222784 run_lib.py:133] step: 558100, training_loss: 4.00837e-02
I0212 07:51:36.497887 22509476222784 run_lib.py:146] step: 558100, eval_loss: 3.71308e-02
I0212 07:51:55.052818 22509476222784 run_lib.py:133] step: 558150, training_loss: 4.09714e-02
I0212 07:52:13.643942 22509476222784 run_lib.py:133] step: 558200, training_loss: 4.15501e-02
I0212 07:52:13.811334 22509476222784 run_lib.py:146] step: 558200, eval_loss: 4.02135e-02
I0212 07:52:32.260044 22509476222784 run_lib.py:133] step: 558250, training_loss: 4.43906e-02
I0212 07:52:50.739142 22509476222784 run_lib.py:133] step: 558300, training_loss: 4.15574e-02
I0212 07:52:50.902630 22509476222784 run_lib.py:146] step: 558300, eval_loss: 3.49799e-02
I0212 07:53:09.602983 22509476222784 run_lib.py:133] step: 558350, training_loss: 4.14225e-02
I0212 07:53:28.374635 22509476222784 run_lib.py:133] step: 558400, training_loss: 3.74892e-02
I0212 07:53:28.538975 22509476222784 run_lib.py:146] step: 558400, eval_loss: 5.31413e-02
I0212 07:53:47.012592 22509476222784 run_lib.py:133] step: 558450, training_loss: 3.78770e-02
I0212 07:54:05.513592 22509476222784 run_lib.py:133] step: 558500, training_loss: 5.14064e-02
I0212 07:54:05.672534 22509476222784 run_lib.py:146] step: 558500, eval_loss: 4.71732e-02
I0212 07:54:24.126944 22509476222784 run_lib.py:133] step: 558550, training_loss: 5.64153e-02
I0212 07:54:42.808407 22509476222784 run_lib.py:133] step: 558600, training_loss: 4.23918e-02
I0212 07:54:42.977806 22509476222784 run_lib.py:146] step: 558600, eval_loss: 3.27005e-02
I0212 07:55:01.560020 22509476222784 run_lib.py:133] step: 558650, training_loss: 4.00766e-02
I0212 07:55:20.109571 22509476222784 run_lib.py:133] step: 558700, training_loss: 3.77964e-02
I0212 07:55:20.273593 22509476222784 run_lib.py:146] step: 558700, eval_loss: 4.29989e-02
I0212 07:55:38.790619 22509476222784 run_lib.py:133] step: 558750, training_loss: 5.63103e-02
I0212 07:55:57.459916 22509476222784 run_lib.py:133] step: 558800, training_loss: 4.42303e-02
I0212 07:55:57.624579 22509476222784 run_lib.py:146] step: 558800, eval_loss: 4.11344e-02
I0212 07:56:16.135721 22509476222784 run_lib.py:133] step: 558850, training_loss: 3.96492e-02
I0212 07:56:34.827665 22509476222784 run_lib.py:133] step: 558900, training_loss: 4.72877e-02
I0212 07:56:35.009955 22509476222784 run_lib.py:146] step: 558900, eval_loss: 4.13942e-02
I0212 07:56:53.601954 22509476222784 run_lib.py:133] step: 558950, training_loss: 4.14672e-02
I0212 07:57:12.069370 22509476222784 run_lib.py:133] step: 559000, training_loss: 4.62630e-02
I0212 07:57:12.229645 22509476222784 run_lib.py:146] step: 559000, eval_loss: 5.00661e-02
I0212 07:57:30.815208 22509476222784 run_lib.py:133] step: 559050, training_loss: 5.68429e-02
I0212 07:57:49.435765 22509476222784 run_lib.py:133] step: 559100, training_loss: 4.12879e-02
I0212 07:57:49.606682 22509476222784 run_lib.py:146] step: 559100, eval_loss: 4.53931e-02
I0212 07:58:08.142227 22509476222784 run_lib.py:133] step: 559150, training_loss: 4.77060e-02
I0212 07:58:26.650204 22509476222784 run_lib.py:133] step: 559200, training_loss: 4.56297e-02
I0212 07:58:26.832684 22509476222784 run_lib.py:146] step: 559200, eval_loss: 3.63943e-02
I0212 07:58:45.515928 22509476222784 run_lib.py:133] step: 559250, training_loss: 4.91540e-02
I0212 07:59:04.001745 22509476222784 run_lib.py:133] step: 559300, training_loss: 4.83267e-02
I0212 07:59:04.165683 22509476222784 run_lib.py:146] step: 559300, eval_loss: 3.05991e-02
I0212 07:59:22.822571 22509476222784 run_lib.py:133] step: 559350, training_loss: 4.93918e-02
I0212 07:59:41.382697 22509476222784 run_lib.py:133] step: 559400, training_loss: 4.91857e-02
I0212 07:59:41.546817 22509476222784 run_lib.py:146] step: 559400, eval_loss: 3.96891e-02
I0212 08:00:00.307434 22509476222784 run_lib.py:133] step: 559450, training_loss: 5.07556e-02
I0212 08:00:18.786688 22509476222784 run_lib.py:133] step: 559500, training_loss: 4.59478e-02
I0212 08:00:18.968655 22509476222784 run_lib.py:146] step: 559500, eval_loss: 5.47047e-02
I0212 08:00:37.437057 22509476222784 run_lib.py:133] step: 559550, training_loss: 5.15860e-02
I0212 08:00:56.097479 22509476222784 run_lib.py:133] step: 559600, training_loss: 4.58416e-02
I0212 08:00:56.268838 22509476222784 run_lib.py:146] step: 559600, eval_loss: 3.68533e-02
I0212 08:01:14.776077 22509476222784 run_lib.py:133] step: 559650, training_loss: 3.87013e-02
I0212 08:01:33.543808 22509476222784 run_lib.py:133] step: 559700, training_loss: 4.92949e-02
I0212 08:01:33.710773 22509476222784 run_lib.py:146] step: 559700, eval_loss: 3.39530e-02
I0212 08:01:52.223107 22509476222784 run_lib.py:133] step: 559750, training_loss: 4.14616e-02
I0212 08:02:10.710022 22509476222784 run_lib.py:133] step: 559800, training_loss: 2.90167e-02
I0212 08:02:10.875784 22509476222784 run_lib.py:146] step: 559800, eval_loss: 5.00049e-02
I0212 08:02:29.491011 22509476222784 run_lib.py:133] step: 559850, training_loss: 4.23748e-02
I0212 08:02:47.964896 22509476222784 run_lib.py:133] step: 559900, training_loss: 4.54506e-02
I0212 08:02:48.149812 22509476222784 run_lib.py:146] step: 559900, eval_loss: 3.35888e-02
I0212 08:03:06.742661 22509476222784 run_lib.py:133] step: 559950, training_loss: 4.88875e-02
I0212 08:03:25.475947 22509476222784 run_lib.py:133] step: 560000, training_loss: 3.96822e-02
I0212 08:03:26.240844 22509476222784 run_lib.py:146] step: 560000, eval_loss: 4.76349e-02
I0212 08:03:47.418471 22509476222784 run_lib.py:133] step: 560050, training_loss: 3.35029e-02
I0212 08:04:05.864768 22509476222784 run_lib.py:133] step: 560100, training_loss: 4.31133e-02
I0212 08:04:06.027559 22509476222784 run_lib.py:146] step: 560100, eval_loss: 4.01616e-02
I0212 08:04:24.431211 22509476222784 run_lib.py:133] step: 560150, training_loss: 4.37792e-02
I0212 08:04:43.095818 22509476222784 run_lib.py:133] step: 560200, training_loss: 4.90182e-02
I0212 08:04:43.289741 22509476222784 run_lib.py:146] step: 560200, eval_loss: 4.04469e-02
I0212 08:05:01.873730 22509476222784 run_lib.py:133] step: 560250, training_loss: 4.90681e-02
I0212 08:05:20.366208 22509476222784 run_lib.py:133] step: 560300, training_loss: 5.06648e-02
I0212 08:05:20.531946 22509476222784 run_lib.py:146] step: 560300, eval_loss: 2.78772e-02
I0212 08:05:39.173578 22509476222784 run_lib.py:133] step: 560350, training_loss: 2.88336e-02
I0212 08:05:57.655905 22509476222784 run_lib.py:133] step: 560400, training_loss: 3.34411e-02
I0212 08:05:57.828387 22509476222784 run_lib.py:146] step: 560400, eval_loss: 4.44928e-02
I0212 08:06:16.367848 22509476222784 run_lib.py:133] step: 560450, training_loss: 3.46153e-02
I0212 08:06:34.915706 22509476222784 run_lib.py:133] step: 560500, training_loss: 4.32726e-02
I0212 08:06:35.086414 22509476222784 run_lib.py:146] step: 560500, eval_loss: 3.90721e-02
I0212 08:06:53.645362 22509476222784 run_lib.py:133] step: 560550, training_loss: 3.40463e-02
I0212 08:07:12.149865 22509476222784 run_lib.py:133] step: 560600, training_loss: 5.15618e-02
I0212 08:07:12.341570 22509476222784 run_lib.py:146] step: 560600, eval_loss: 4.34812e-02
I0212 08:07:31.001089 22509476222784 run_lib.py:133] step: 560650, training_loss: 4.52225e-02
I0212 08:07:49.557271 22509476222784 run_lib.py:133] step: 560700, training_loss: 4.57268e-02
I0212 08:07:49.723893 22509476222784 run_lib.py:146] step: 560700, eval_loss: 2.93974e-02
I0212 08:08:08.233147 22509476222784 run_lib.py:133] step: 560750, training_loss: 4.45727e-02
I0212 08:08:26.851273 22509476222784 run_lib.py:133] step: 560800, training_loss: 4.75110e-02
I0212 08:08:27.015992 22509476222784 run_lib.py:146] step: 560800, eval_loss: 4.67656e-02
I0212 08:08:45.731968 22509476222784 run_lib.py:133] step: 560850, training_loss: 5.81858e-02
I0212 08:09:04.137957 22509476222784 run_lib.py:133] step: 560900, training_loss: 4.21404e-02
I0212 08:09:04.300506 22509476222784 run_lib.py:146] step: 560900, eval_loss: 3.30224e-02
I0212 08:09:22.933983 22509476222784 run_lib.py:133] step: 560950, training_loss: 5.38371e-02
I0212 08:09:41.454534 22509476222784 run_lib.py:133] step: 561000, training_loss: 4.86657e-02
I0212 08:09:41.619888 22509476222784 run_lib.py:146] step: 561000, eval_loss: 5.13220e-02
I0212 08:10:00.276105 22509476222784 run_lib.py:133] step: 561050, training_loss: 4.75602e-02
I0212 08:10:18.808632 22509476222784 run_lib.py:133] step: 561100, training_loss: 4.94424e-02
I0212 08:10:18.974543 22509476222784 run_lib.py:146] step: 561100, eval_loss: 3.62846e-02
I0212 08:10:37.571620 22509476222784 run_lib.py:133] step: 561150, training_loss: 3.64515e-02
I0212 08:10:56.091743 22509476222784 run_lib.py:133] step: 561200, training_loss: 4.27086e-02
I0212 08:10:56.266911 22509476222784 run_lib.py:146] step: 561200, eval_loss: 3.39205e-02
I0212 08:11:14.777967 22509476222784 run_lib.py:133] step: 561250, training_loss: 3.29519e-02
I0212 08:11:33.463775 22509476222784 run_lib.py:133] step: 561300, training_loss: 4.25422e-02
I0212 08:11:33.633306 22509476222784 run_lib.py:146] step: 561300, eval_loss: 5.17328e-02
I0212 08:11:52.179724 22509476222784 run_lib.py:133] step: 561350, training_loss: 5.09027e-02
I0212 08:12:10.764919 22509476222784 run_lib.py:133] step: 561400, training_loss: 4.08707e-02
I0212 08:12:10.968893 22509476222784 run_lib.py:146] step: 561400, eval_loss: 4.73002e-02
I0212 08:12:29.649248 22509476222784 run_lib.py:133] step: 561450, training_loss: 3.53478e-02
I0212 08:12:48.204449 22509476222784 run_lib.py:133] step: 561500, training_loss: 3.78520e-02
I0212 08:12:48.366659 22509476222784 run_lib.py:146] step: 561500, eval_loss: 5.26881e-02
I0212 08:13:07.018585 22509476222784 run_lib.py:133] step: 561550, training_loss: 4.03107e-02
I0212 08:13:25.474046 22509476222784 run_lib.py:133] step: 561600, training_loss: 3.00400e-02
I0212 08:13:25.655568 22509476222784 run_lib.py:146] step: 561600, eval_loss: 4.23847e-02
I0212 08:13:44.163665 22509476222784 run_lib.py:133] step: 561650, training_loss: 3.38844e-02
I0212 08:14:02.882087 22509476222784 run_lib.py:133] step: 561700, training_loss: 4.29624e-02
I0212 08:14:03.086587 22509476222784 run_lib.py:146] step: 561700, eval_loss: 4.14569e-02
I0212 08:14:21.624008 22509476222784 run_lib.py:133] step: 561750, training_loss: 4.82900e-02
I0212 08:14:40.084593 22509476222784 run_lib.py:133] step: 561800, training_loss: 4.23942e-02
I0212 08:14:40.254050 22509476222784 run_lib.py:146] step: 561800, eval_loss: 3.73064e-02
I0212 08:14:58.792295 22509476222784 run_lib.py:133] step: 561850, training_loss: 3.92436e-02
I0212 08:15:17.572322 22509476222784 run_lib.py:133] step: 561900, training_loss: 3.37120e-02
I0212 08:15:17.746924 22509476222784 run_lib.py:146] step: 561900, eval_loss: 5.00619e-02
I0212 08:15:36.277550 22509476222784 run_lib.py:133] step: 561950, training_loss: 4.73642e-02
I0212 08:15:54.872943 22509476222784 run_lib.py:133] step: 562000, training_loss: 5.17273e-02
I0212 08:15:55.039698 22509476222784 run_lib.py:146] step: 562000, eval_loss: 4.04060e-02
I0212 08:16:13.497891 22509476222784 run_lib.py:133] step: 562050, training_loss: 4.95383e-02
I0212 08:16:32.009174 22509476222784 run_lib.py:133] step: 562100, training_loss: 5.07775e-02
I0212 08:16:32.200919 22509476222784 run_lib.py:146] step: 562100, eval_loss: 3.53803e-02
I0212 08:16:50.875265 22509476222784 run_lib.py:133] step: 562150, training_loss: 4.03105e-02
I0212 08:17:09.527516 22509476222784 run_lib.py:133] step: 562200, training_loss: 4.50910e-02
I0212 08:17:09.701079 22509476222784 run_lib.py:146] step: 562200, eval_loss: 5.30245e-02
I0212 08:17:28.163689 22509476222784 run_lib.py:133] step: 562250, training_loss: 4.12808e-02
I0212 08:17:46.679751 22509476222784 run_lib.py:133] step: 562300, training_loss: 3.97493e-02
I0212 08:17:46.849763 22509476222784 run_lib.py:146] step: 562300, eval_loss: 3.37779e-02
I0212 08:18:05.509870 22509476222784 run_lib.py:133] step: 562350, training_loss: 4.35623e-02
I0212 08:18:23.984786 22509476222784 run_lib.py:133] step: 562400, training_loss: 4.21705e-02
I0212 08:18:24.148919 22509476222784 run_lib.py:146] step: 562400, eval_loss: 4.37089e-02
I0212 08:18:42.872795 22509476222784 run_lib.py:133] step: 562450, training_loss: 6.02310e-02
I0212 08:19:01.401142 22509476222784 run_lib.py:133] step: 562500, training_loss: 4.86946e-02
I0212 08:19:01.564720 22509476222784 run_lib.py:146] step: 562500, eval_loss: 4.13675e-02
I0212 08:19:20.187017 22509476222784 run_lib.py:133] step: 562550, training_loss: 4.82577e-02
I0212 08:19:38.751821 22509476222784 run_lib.py:133] step: 562600, training_loss: 3.90448e-02
I0212 08:19:38.932803 22509476222784 run_lib.py:146] step: 562600, eval_loss: 3.72456e-02
I0212 08:19:57.507737 22509476222784 run_lib.py:133] step: 562650, training_loss: 3.89927e-02
I0212 08:20:16.293283 22509476222784 run_lib.py:133] step: 562700, training_loss: 4.58696e-02
I0212 08:20:16.602869 22509476222784 run_lib.py:146] step: 562700, eval_loss: 4.64659e-02
I0212 08:20:35.060325 22509476222784 run_lib.py:133] step: 562750, training_loss: 4.18073e-02
I0212 08:20:53.680274 22509476222784 run_lib.py:133] step: 562800, training_loss: 4.02469e-02
I0212 08:20:53.863665 22509476222784 run_lib.py:146] step: 562800, eval_loss: 4.49897e-02
I0212 08:21:12.388366 22509476222784 run_lib.py:133] step: 562850, training_loss: 4.25528e-02
I0212 08:21:30.944419 22509476222784 run_lib.py:133] step: 562900, training_loss: 4.56944e-02
I0212 08:21:31.108955 22509476222784 run_lib.py:146] step: 562900, eval_loss: 4.13270e-02
I0212 08:21:49.708703 22509476222784 run_lib.py:133] step: 562950, training_loss: 4.31674e-02
I0212 08:22:08.201195 22509476222784 run_lib.py:133] step: 563000, training_loss: 3.13962e-02
I0212 08:22:08.380034 22509476222784 run_lib.py:146] step: 563000, eval_loss: 4.20897e-02
I0212 08:22:26.855138 22509476222784 run_lib.py:133] step: 563050, training_loss: 4.16286e-02
I0212 08:22:45.445102 22509476222784 run_lib.py:133] step: 563100, training_loss: 4.81716e-02
I0212 08:22:45.608965 22509476222784 run_lib.py:146] step: 563100, eval_loss: 4.08898e-02
I0212 08:23:04.189321 22509476222784 run_lib.py:133] step: 563150, training_loss: 3.52914e-02
I0212 08:23:22.661698 22509476222784 run_lib.py:133] step: 563200, training_loss: 4.35500e-02
I0212 08:23:23.010392 22509476222784 run_lib.py:146] step: 563200, eval_loss: 4.30371e-02
I0212 08:23:41.547391 22509476222784 run_lib.py:133] step: 563250, training_loss: 4.04865e-02
I0212 08:24:00.029989 22509476222784 run_lib.py:133] step: 563300, training_loss: 4.10563e-02
I0212 08:24:00.191554 22509476222784 run_lib.py:146] step: 563300, eval_loss: 3.97884e-02
I0212 08:24:18.666997 22509476222784 run_lib.py:133] step: 563350, training_loss: 3.70929e-02
I0212 08:24:37.136069 22509476222784 run_lib.py:133] step: 563400, training_loss: 3.02804e-02
I0212 08:24:37.304841 22509476222784 run_lib.py:146] step: 563400, eval_loss: 3.46072e-02
I0212 08:24:56.028907 22509476222784 run_lib.py:133] step: 563450, training_loss: 3.92370e-02
I0212 08:25:14.618617 22509476222784 run_lib.py:133] step: 563500, training_loss: 4.40265e-02
I0212 08:25:14.784737 22509476222784 run_lib.py:146] step: 563500, eval_loss: 4.62765e-02
I0212 08:25:33.230120 22509476222784 run_lib.py:133] step: 563550, training_loss: 5.09081e-02
I0212 08:25:51.698187 22509476222784 run_lib.py:133] step: 563600, training_loss: 4.44399e-02
I0212 08:25:51.861582 22509476222784 run_lib.py:146] step: 563600, eval_loss: 3.61903e-02
I0212 08:26:10.519311 22509476222784 run_lib.py:133] step: 563650, training_loss: 3.96514e-02
I0212 08:26:29.151944 22509476222784 run_lib.py:133] step: 563700, training_loss: 4.23809e-02
I0212 08:26:29.316439 22509476222784 run_lib.py:146] step: 563700, eval_loss: 4.01406e-02
I0212 08:26:47.838575 22509476222784 run_lib.py:133] step: 563750, training_loss: 4.34914e-02
I0212 08:27:06.259054 22509476222784 run_lib.py:133] step: 563800, training_loss: 3.57400e-02
I0212 08:27:06.419420 22509476222784 run_lib.py:146] step: 563800, eval_loss: 4.47354e-02
I0212 08:27:25.123552 22509476222784 run_lib.py:133] step: 563850, training_loss: 3.99115e-02
I0212 08:27:43.650148 22509476222784 run_lib.py:133] step: 563900, training_loss: 4.64097e-02
I0212 08:27:43.812644 22509476222784 run_lib.py:146] step: 563900, eval_loss: 3.52963e-02
I0212 08:28:02.391625 22509476222784 run_lib.py:133] step: 563950, training_loss: 5.07933e-02
I0212 08:28:20.991847 22509476222784 run_lib.py:133] step: 564000, training_loss: 3.87504e-02
I0212 08:28:21.157761 22509476222784 run_lib.py:146] step: 564000, eval_loss: 3.54240e-02
I0212 08:28:39.898975 22509476222784 run_lib.py:133] step: 564050, training_loss: 3.96432e-02
I0212 08:28:58.418037 22509476222784 run_lib.py:133] step: 564100, training_loss: 5.21479e-02
I0212 08:28:58.582687 22509476222784 run_lib.py:146] step: 564100, eval_loss: 4.58569e-02
I0212 08:29:17.068073 22509476222784 run_lib.py:133] step: 564150, training_loss: 4.28073e-02
I0212 08:29:35.699706 22509476222784 run_lib.py:133] step: 564200, training_loss: 3.43270e-02
I0212 08:29:35.867933 22509476222784 run_lib.py:146] step: 564200, eval_loss: 3.51362e-02
I0212 08:29:54.429463 22509476222784 run_lib.py:133] step: 564250, training_loss: 4.93789e-02
I0212 08:30:13.131733 22509476222784 run_lib.py:133] step: 564300, training_loss: 3.65836e-02
I0212 08:30:13.293817 22509476222784 run_lib.py:146] step: 564300, eval_loss: 4.87094e-02
I0212 08:30:31.872864 22509476222784 run_lib.py:133] step: 564350, training_loss: 4.87499e-02
I0212 08:30:50.387610 22509476222784 run_lib.py:133] step: 564400, training_loss: 3.73242e-02
I0212 08:30:50.570660 22509476222784 run_lib.py:146] step: 564400, eval_loss: 4.73095e-02
I0212 08:31:09.067411 22509476222784 run_lib.py:133] step: 564450, training_loss: 4.65116e-02
I0212 08:31:27.701642 22509476222784 run_lib.py:133] step: 564500, training_loss: 3.92576e-02
I0212 08:31:27.879598 22509476222784 run_lib.py:146] step: 564500, eval_loss: 3.34402e-02
I0212 08:31:46.373649 22509476222784 run_lib.py:133] step: 564550, training_loss: 3.49770e-02
I0212 08:32:04.902531 22509476222784 run_lib.py:133] step: 564600, training_loss: 4.77357e-02
I0212 08:32:05.067950 22509476222784 run_lib.py:146] step: 564600, eval_loss: 4.03318e-02
I0212 08:32:23.779127 22509476222784 run_lib.py:133] step: 564650, training_loss: 2.81463e-02
I0212 08:32:42.283990 22509476222784 run_lib.py:133] step: 564700, training_loss: 4.87712e-02
I0212 08:32:42.445562 22509476222784 run_lib.py:146] step: 564700, eval_loss: 4.36333e-02
I0212 08:33:00.988495 22509476222784 run_lib.py:133] step: 564750, training_loss: 4.26242e-02
I0212 08:33:19.487520 22509476222784 run_lib.py:133] step: 564800, training_loss: 4.04452e-02
I0212 08:33:19.653012 22509476222784 run_lib.py:146] step: 564800, eval_loss: 3.27540e-02
I0212 08:33:38.188440 22509476222784 run_lib.py:133] step: 564850, training_loss: 5.38803e-02
I0212 08:33:56.670772 22509476222784 run_lib.py:133] step: 564900, training_loss: 5.08312e-02
I0212 08:33:56.834743 22509476222784 run_lib.py:146] step: 564900, eval_loss: 3.25064e-02
I0212 08:34:15.437361 22509476222784 run_lib.py:133] step: 564950, training_loss: 4.17800e-02
I0212 08:34:34.054069 22509476222784 run_lib.py:133] step: 565000, training_loss: 6.09281e-02
I0212 08:34:34.236616 22509476222784 run_lib.py:146] step: 565000, eval_loss: 4.49889e-02
I0212 08:34:52.765759 22509476222784 run_lib.py:133] step: 565050, training_loss: 3.34157e-02
I0212 08:35:11.334272 22509476222784 run_lib.py:133] step: 565100, training_loss: 4.09436e-02
I0212 08:35:11.500190 22509476222784 run_lib.py:146] step: 565100, eval_loss: 4.84849e-02
I0212 08:35:30.170500 22509476222784 run_lib.py:133] step: 565150, training_loss: 4.16517e-02
I0212 08:35:48.618536 22509476222784 run_lib.py:133] step: 565200, training_loss: 3.76742e-02
I0212 08:35:48.781488 22509476222784 run_lib.py:146] step: 565200, eval_loss: 4.59597e-02
I0212 08:36:07.437682 22509476222784 run_lib.py:133] step: 565250, training_loss: 4.51552e-02
I0212 08:36:25.963620 22509476222784 run_lib.py:133] step: 565300, training_loss: 4.83653e-02
I0212 08:36:26.132751 22509476222784 run_lib.py:146] step: 565300, eval_loss: 4.76672e-02
I0212 08:36:44.832795 22509476222784 run_lib.py:133] step: 565350, training_loss: 4.50758e-02
I0212 08:37:03.390907 22509476222784 run_lib.py:133] step: 565400, training_loss: 4.80004e-02
I0212 08:37:03.555729 22509476222784 run_lib.py:146] step: 565400, eval_loss: 4.27764e-02
I0212 08:37:22.241780 22509476222784 run_lib.py:133] step: 565450, training_loss: 4.30298e-02
I0212 08:37:40.743809 22509476222784 run_lib.py:133] step: 565500, training_loss: 6.37200e-02
I0212 08:37:40.906580 22509476222784 run_lib.py:146] step: 565500, eval_loss: 5.02497e-02
I0212 08:37:59.327205 22509476222784 run_lib.py:133] step: 565550, training_loss: 3.99294e-02
I0212 08:38:18.044468 22509476222784 run_lib.py:133] step: 565600, training_loss: 3.53794e-02
I0212 08:38:18.208068 22509476222784 run_lib.py:146] step: 565600, eval_loss: 5.19044e-02
I0212 08:38:36.743967 22509476222784 run_lib.py:133] step: 565650, training_loss: 6.43138e-02
I0212 08:38:55.214813 22509476222784 run_lib.py:133] step: 565700, training_loss: 4.16022e-02
I0212 08:38:55.375828 22509476222784 run_lib.py:146] step: 565700, eval_loss: 4.96617e-02
I0212 08:39:14.092030 22509476222784 run_lib.py:133] step: 565750, training_loss: 3.85360e-02
I0212 08:39:32.718232 22509476222784 run_lib.py:133] step: 565800, training_loss: 4.30514e-02
I0212 08:39:32.881674 22509476222784 run_lib.py:146] step: 565800, eval_loss: 3.70682e-02
I0212 08:39:51.413479 22509476222784 run_lib.py:133] step: 565850, training_loss: 4.58665e-02
I0212 08:40:09.880949 22509476222784 run_lib.py:133] step: 565900, training_loss: 4.00137e-02
I0212 08:40:10.046603 22509476222784 run_lib.py:146] step: 565900, eval_loss: 4.92226e-02
I0212 08:40:28.529144 22509476222784 run_lib.py:133] step: 565950, training_loss: 3.91074e-02
I0212 08:40:47.213188 22509476222784 run_lib.py:133] step: 566000, training_loss: 5.16730e-02
I0212 08:40:47.401645 22509476222784 run_lib.py:146] step: 566000, eval_loss: 3.82356e-02
I0212 08:41:05.873078 22509476222784 run_lib.py:133] step: 566050, training_loss: 3.81907e-02
I0212 08:41:24.368577 22509476222784 run_lib.py:133] step: 566100, training_loss: 4.27067e-02
I0212 08:41:24.539874 22509476222784 run_lib.py:146] step: 566100, eval_loss: 2.50870e-02
I0212 08:41:43.083682 22509476222784 run_lib.py:133] step: 566150, training_loss: 3.45741e-02
I0212 08:42:01.827512 22509476222784 run_lib.py:133] step: 566200, training_loss: 5.12574e-02
I0212 08:42:01.995872 22509476222784 run_lib.py:146] step: 566200, eval_loss: 3.61460e-02
I0212 08:42:20.523914 22509476222784 run_lib.py:133] step: 566250, training_loss: 6.97438e-02
I0212 08:42:39.120093 22509476222784 run_lib.py:133] step: 566300, training_loss: 4.80041e-02
I0212 08:42:39.284647 22509476222784 run_lib.py:146] step: 566300, eval_loss: 5.19650e-02
I0212 08:42:57.755869 22509476222784 run_lib.py:133] step: 566350, training_loss: 3.80726e-02
I0212 08:43:16.242369 22509476222784 run_lib.py:133] step: 566400, training_loss: 4.54833e-02
I0212 08:43:16.444680 22509476222784 run_lib.py:146] step: 566400, eval_loss: 3.38504e-02
I0212 08:43:35.158747 22509476222784 run_lib.py:133] step: 566450, training_loss: 4.29659e-02
I0212 08:43:53.781513 22509476222784 run_lib.py:133] step: 566500, training_loss: 4.51665e-02
I0212 08:43:53.945912 22509476222784 run_lib.py:146] step: 566500, eval_loss: 3.57547e-02
I0212 08:44:12.499603 22509476222784 run_lib.py:133] step: 566550, training_loss: 4.28249e-02
I0212 08:44:30.998774 22509476222784 run_lib.py:133] step: 566600, training_loss: 3.87544e-02
I0212 08:44:31.169734 22509476222784 run_lib.py:146] step: 566600, eval_loss: 3.67761e-02
I0212 08:44:49.812471 22509476222784 run_lib.py:133] step: 566650, training_loss: 4.21845e-02
I0212 08:45:08.366756 22509476222784 run_lib.py:133] step: 566700, training_loss: 4.02952e-02
I0212 08:45:08.532829 22509476222784 run_lib.py:146] step: 566700, eval_loss: 3.99567e-02
I0212 08:45:27.241266 22509476222784 run_lib.py:133] step: 566750, training_loss: 5.24370e-02
I0212 08:45:45.773964 22509476222784 run_lib.py:133] step: 566800, training_loss: 5.05756e-02
I0212 08:45:45.938813 22509476222784 run_lib.py:146] step: 566800, eval_loss: 4.24780e-02
I0212 08:46:04.504324 22509476222784 run_lib.py:133] step: 566850, training_loss: 4.88586e-02
I0212 08:46:22.922829 22509476222784 run_lib.py:133] step: 566900, training_loss: 3.56599e-02
I0212 08:46:23.088692 22509476222784 run_lib.py:146] step: 566900, eval_loss: 4.30923e-02
I0212 08:46:41.677031 22509476222784 run_lib.py:133] step: 566950, training_loss: 5.27894e-02
I0212 08:47:00.379140 22509476222784 run_lib.py:133] step: 567000, training_loss: 5.16277e-02
I0212 08:47:00.545044 22509476222784 run_lib.py:146] step: 567000, eval_loss: 4.20362e-02
I0212 08:47:19.077743 22509476222784 run_lib.py:133] step: 567050, training_loss: 4.17046e-02
I0212 08:47:37.708045 22509476222784 run_lib.py:133] step: 567100, training_loss: 4.52712e-02
I0212 08:47:37.868673 22509476222784 run_lib.py:146] step: 567100, eval_loss: 4.22788e-02
I0212 08:47:56.368580 22509476222784 run_lib.py:133] step: 567150, training_loss: 4.37153e-02
I0212 08:48:14.927715 22509476222784 run_lib.py:133] step: 567200, training_loss: 5.59859e-02
I0212 08:48:15.096946 22509476222784 run_lib.py:146] step: 567200, eval_loss: 4.07644e-02
I0212 08:48:33.877434 22509476222784 run_lib.py:133] step: 567250, training_loss: 3.36635e-02
I0212 08:48:52.405446 22509476222784 run_lib.py:133] step: 567300, training_loss: 5.83530e-02
I0212 08:48:52.584998 22509476222784 run_lib.py:146] step: 567300, eval_loss: 4.82879e-02
I0212 08:49:11.088920 22509476222784 run_lib.py:133] step: 567350, training_loss: 4.54110e-02
I0212 08:49:29.610637 22509476222784 run_lib.py:133] step: 567400, training_loss: 4.71516e-02
I0212 08:49:29.772408 22509476222784 run_lib.py:146] step: 567400, eval_loss: 4.59627e-02
I0212 08:49:48.268731 22509476222784 run_lib.py:133] step: 567450, training_loss: 3.61498e-02
I0212 08:50:06.845490 22509476222784 run_lib.py:133] step: 567500, training_loss: 4.11957e-02
I0212 08:50:07.009854 22509476222784 run_lib.py:146] step: 567500, eval_loss: 4.10340e-02
I0212 08:50:25.649599 22509476222784 run_lib.py:133] step: 567550, training_loss: 4.97748e-02
I0212 08:50:44.172235 22509476222784 run_lib.py:133] step: 567600, training_loss: 3.91657e-02
I0212 08:50:44.338624 22509476222784 run_lib.py:146] step: 567600, eval_loss: 3.75114e-02
I0212 08:51:02.856451 22509476222784 run_lib.py:133] step: 567650, training_loss: 4.48550e-02
I0212 08:51:21.409263 22509476222784 run_lib.py:133] step: 567700, training_loss: 4.78563e-02
I0212 08:51:21.582969 22509476222784 run_lib.py:146] step: 567700, eval_loss: 4.53729e-02
I0212 08:51:40.296052 22509476222784 run_lib.py:133] step: 567750, training_loss: 4.00611e-02
I0212 08:51:58.833844 22509476222784 run_lib.py:133] step: 567800, training_loss: 4.73487e-02
I0212 08:51:58.997510 22509476222784 run_lib.py:146] step: 567800, eval_loss: 4.04518e-02
I0212 08:52:17.493285 22509476222784 run_lib.py:133] step: 567850, training_loss: 3.91536e-02
I0212 08:52:36.010603 22509476222784 run_lib.py:133] step: 567900, training_loss: 3.82366e-02
I0212 08:52:36.174659 22509476222784 run_lib.py:146] step: 567900, eval_loss: 6.27092e-02
I0212 08:52:54.736163 22509476222784 run_lib.py:133] step: 567950, training_loss: 4.14933e-02
I0212 08:53:13.290601 22509476222784 run_lib.py:133] step: 568000, training_loss: 4.29528e-02
I0212 08:53:13.454432 22509476222784 run_lib.py:146] step: 568000, eval_loss: 4.30433e-02
I0212 08:53:32.162433 22509476222784 run_lib.py:133] step: 568050, training_loss: 4.12049e-02
I0212 08:53:50.660920 22509476222784 run_lib.py:133] step: 568100, training_loss: 4.36358e-02
I0212 08:53:50.844601 22509476222784 run_lib.py:146] step: 568100, eval_loss: 3.39763e-02
I0212 08:54:09.501847 22509476222784 run_lib.py:133] step: 568150, training_loss: 5.77357e-02
I0212 08:54:27.955969 22509476222784 run_lib.py:133] step: 568200, training_loss: 3.66843e-02
I0212 08:54:28.125415 22509476222784 run_lib.py:146] step: 568200, eval_loss: 4.95672e-02
I0212 08:54:46.693582 22509476222784 run_lib.py:133] step: 568250, training_loss: 3.92141e-02
I0212 08:55:05.200667 22509476222784 run_lib.py:133] step: 568300, training_loss: 4.85341e-02
I0212 08:55:05.366670 22509476222784 run_lib.py:146] step: 568300, eval_loss: 5.80158e-02
I0212 08:55:23.869473 22509476222784 run_lib.py:133] step: 568350, training_loss: 3.28506e-02
I0212 08:55:42.528891 22509476222784 run_lib.py:133] step: 568400, training_loss: 4.67794e-02
I0212 08:55:42.737835 22509476222784 run_lib.py:146] step: 568400, eval_loss: 3.64117e-02
I0212 08:56:01.260715 22509476222784 run_lib.py:133] step: 568450, training_loss: 4.19350e-02
I0212 08:56:19.832398 22509476222784 run_lib.py:133] step: 568500, training_loss: 4.58764e-02
I0212 08:56:19.998880 22509476222784 run_lib.py:146] step: 568500, eval_loss: 3.41126e-02
I0212 08:56:38.763686 22509476222784 run_lib.py:133] step: 568550, training_loss: 3.44084e-02
I0212 08:56:57.195927 22509476222784 run_lib.py:133] step: 568600, training_loss: 3.43430e-02
I0212 08:56:57.364640 22509476222784 run_lib.py:146] step: 568600, eval_loss: 5.04284e-02
I0212 08:57:15.973171 22509476222784 run_lib.py:133] step: 568650, training_loss: 4.37097e-02
I0212 08:57:34.405209 22509476222784 run_lib.py:133] step: 568700, training_loss: 3.87534e-02
I0212 08:57:34.570899 22509476222784 run_lib.py:146] step: 568700, eval_loss: 4.42190e-02
I0212 08:57:53.103734 22509476222784 run_lib.py:133] step: 568750, training_loss: 4.63956e-02
I0212 08:58:11.837183 22509476222784 run_lib.py:133] step: 568800, training_loss: 4.04568e-02
I0212 08:58:12.050303 22509476222784 run_lib.py:146] step: 568800, eval_loss: 3.78293e-02
I0212 08:58:30.506575 22509476222784 run_lib.py:133] step: 568850, training_loss: 3.65165e-02
I0212 08:58:48.966906 22509476222784 run_lib.py:133] step: 568900, training_loss: 5.38577e-02
I0212 08:58:49.130285 22509476222784 run_lib.py:146] step: 568900, eval_loss: 4.66812e-02
I0212 08:59:07.596647 22509476222784 run_lib.py:133] step: 568950, training_loss: 4.43059e-02
I0212 08:59:26.174001 22509476222784 run_lib.py:133] step: 569000, training_loss: 4.65606e-02
I0212 08:59:26.336359 22509476222784 run_lib.py:146] step: 569000, eval_loss: 4.49410e-02
I0212 08:59:44.800068 22509476222784 run_lib.py:133] step: 569050, training_loss: 3.50063e-02
I0212 09:00:03.389031 22509476222784 run_lib.py:133] step: 569100, training_loss: 4.25312e-02
I0212 09:00:03.552685 22509476222784 run_lib.py:146] step: 569100, eval_loss: 3.75880e-02
I0212 09:00:21.981727 22509476222784 run_lib.py:133] step: 569150, training_loss: 4.80763e-02
I0212 09:00:40.517421 22509476222784 run_lib.py:133] step: 569200, training_loss: 3.29150e-02
I0212 09:00:40.717778 22509476222784 run_lib.py:146] step: 569200, eval_loss: 3.52979e-02
I0212 09:00:59.357847 22509476222784 run_lib.py:133] step: 569250, training_loss: 4.98900e-02
I0212 09:01:18.022871 22509476222784 run_lib.py:133] step: 569300, training_loss: 4.48319e-02
I0212 09:01:18.188802 22509476222784 run_lib.py:146] step: 569300, eval_loss: 3.33866e-02
I0212 09:01:36.649803 22509476222784 run_lib.py:133] step: 569350, training_loss: 5.06518e-02
I0212 09:01:55.101447 22509476222784 run_lib.py:133] step: 569400, training_loss: 4.73357e-02
I0212 09:01:55.265592 22509476222784 run_lib.py:146] step: 569400, eval_loss: 3.98165e-02
I0212 09:02:13.862555 22509476222784 run_lib.py:133] step: 569450, training_loss: 4.26008e-02
I0212 09:02:32.365791 22509476222784 run_lib.py:133] step: 569500, training_loss: 4.95320e-02
I0212 09:02:32.525727 22509476222784 run_lib.py:146] step: 569500, eval_loss: 3.84401e-02
I0212 09:02:51.149760 22509476222784 run_lib.py:133] step: 569550, training_loss: 4.87348e-02
I0212 09:03:09.633095 22509476222784 run_lib.py:133] step: 569600, training_loss: 3.93832e-02
I0212 09:03:09.806721 22509476222784 run_lib.py:146] step: 569600, eval_loss: 4.60625e-02
I0212 09:03:28.481823 22509476222784 run_lib.py:133] step: 569650, training_loss: 3.50062e-02
I0212 09:03:47.000409 22509476222784 run_lib.py:133] step: 569700, training_loss: 2.82712e-02
I0212 09:03:47.165788 22509476222784 run_lib.py:146] step: 569700, eval_loss: 3.97682e-02
I0212 09:04:05.609020 22509476222784 run_lib.py:133] step: 569750, training_loss: 5.21554e-02
I0212 09:04:24.219670 22509476222784 run_lib.py:133] step: 569800, training_loss: 2.79843e-02
I0212 09:04:24.382616 22509476222784 run_lib.py:146] step: 569800, eval_loss: 3.58232e-02
I0212 09:04:42.879257 22509476222784 run_lib.py:133] step: 569850, training_loss: 4.31847e-02
I0212 09:05:01.553378 22509476222784 run_lib.py:133] step: 569900, training_loss: 4.77800e-02
I0212 09:05:01.724865 22509476222784 run_lib.py:146] step: 569900, eval_loss: 3.31229e-02
I0212 09:05:20.198537 22509476222784 run_lib.py:133] step: 569950, training_loss: 4.26992e-02
I0212 09:05:38.645584 22509476222784 run_lib.py:133] step: 570000, training_loss: 4.04304e-02
I0212 09:05:40.569515 22509476222784 run_lib.py:146] step: 570000, eval_loss: 3.86723e-02
I0212 09:06:03.082287 22509476222784 run_lib.py:133] step: 570050, training_loss: 3.07551e-02
I0212 09:06:21.588687 22509476222784 run_lib.py:133] step: 570100, training_loss: 4.82114e-02
I0212 09:06:21.752684 22509476222784 run_lib.py:146] step: 570100, eval_loss: 3.91038e-02
I0212 09:06:40.446807 22509476222784 run_lib.py:133] step: 570150, training_loss: 4.88646e-02
I0212 09:06:58.946388 22509476222784 run_lib.py:133] step: 570200, training_loss: 4.48877e-02
I0212 09:06:59.111784 22509476222784 run_lib.py:146] step: 570200, eval_loss: 4.17774e-02
I0212 09:07:17.569157 22509476222784 run_lib.py:133] step: 570250, training_loss: 4.40012e-02
I0212 09:07:36.198604 22509476222784 run_lib.py:133] step: 570300, training_loss: 4.89091e-02
I0212 09:07:36.362795 22509476222784 run_lib.py:146] step: 570300, eval_loss: 4.12072e-02
I0212 09:07:54.876792 22509476222784 run_lib.py:133] step: 570350, training_loss: 5.13775e-02
I0212 09:08:13.492529 22509476222784 run_lib.py:133] step: 570400, training_loss: 3.91904e-02
I0212 09:08:13.657213 22509476222784 run_lib.py:146] step: 570400, eval_loss: 4.68137e-02
I0212 09:08:32.027409 22509476222784 run_lib.py:133] step: 570450, training_loss: 4.49320e-02
I0212 09:08:50.414232 22509476222784 run_lib.py:133] step: 570500, training_loss: 4.10090e-02
I0212 09:08:50.572386 22509476222784 run_lib.py:146] step: 570500, eval_loss: 4.86233e-02
I0212 09:09:08.888340 22509476222784 run_lib.py:133] step: 570550, training_loss: 4.11901e-02
I0212 09:09:27.427453 22509476222784 run_lib.py:133] step: 570600, training_loss: 3.61300e-02
I0212 09:09:27.600712 22509476222784 run_lib.py:146] step: 570600, eval_loss: 3.32994e-02
I0212 09:09:46.108829 22509476222784 run_lib.py:133] step: 570650, training_loss: 3.50688e-02
I0212 09:10:04.583032 22509476222784 run_lib.py:133] step: 570700, training_loss: 4.25106e-02
I0212 09:10:04.747650 22509476222784 run_lib.py:146] step: 570700, eval_loss: 3.79032e-02
I0212 09:10:23.417362 22509476222784 run_lib.py:133] step: 570750, training_loss: 2.64530e-02
I0212 09:10:41.910912 22509476222784 run_lib.py:133] step: 570800, training_loss: 3.80183e-02
I0212 09:10:42.075663 22509476222784 run_lib.py:146] step: 570800, eval_loss: 3.42088e-02
I0212 09:11:00.605238 22509476222784 run_lib.py:133] step: 570850, training_loss: 4.36897e-02
I0212 09:11:19.090887 22509476222784 run_lib.py:133] step: 570900, training_loss: 3.52434e-02
I0212 09:11:19.254839 22509476222784 run_lib.py:146] step: 570900, eval_loss: 3.78744e-02
I0212 09:11:37.810779 22509476222784 run_lib.py:133] step: 570950, training_loss: 2.59243e-02
I0212 09:11:56.323189 22509476222784 run_lib.py:133] step: 571000, training_loss: 3.70882e-02
I0212 09:11:56.483552 22509476222784 run_lib.py:146] step: 571000, eval_loss: 3.56770e-02
I0212 09:12:15.112313 22509476222784 run_lib.py:133] step: 571050, training_loss: 4.94008e-02
I0212 09:12:33.670126 22509476222784 run_lib.py:133] step: 571100, training_loss: 4.35727e-02
I0212 09:12:33.834520 22509476222784 run_lib.py:146] step: 571100, eval_loss: 4.10056e-02
I0212 09:12:52.326842 22509476222784 run_lib.py:133] step: 571150, training_loss: 4.18979e-02
I0212 09:13:10.878571 22509476222784 run_lib.py:133] step: 571200, training_loss: 4.13669e-02
I0212 09:13:11.056703 22509476222784 run_lib.py:146] step: 571200, eval_loss: 3.87229e-02
I0212 09:13:29.727956 22509476222784 run_lib.py:133] step: 571250, training_loss: 4.31673e-02
I0212 09:13:48.197378 22509476222784 run_lib.py:133] step: 571300, training_loss: 4.09526e-02
I0212 09:13:48.368753 22509476222784 run_lib.py:146] step: 571300, eval_loss: 3.83323e-02
I0212 09:14:06.974702 22509476222784 run_lib.py:133] step: 571350, training_loss: 4.92549e-02
I0212 09:14:25.461988 22509476222784 run_lib.py:133] step: 571400, training_loss: 4.50599e-02
I0212 09:14:25.631334 22509476222784 run_lib.py:146] step: 571400, eval_loss: 4.24719e-02
I0212 09:14:44.305598 22509476222784 run_lib.py:133] step: 571450, training_loss: 3.00990e-02
I0212 09:15:02.714804 22509476222784 run_lib.py:133] step: 571500, training_loss: 4.36404e-02
I0212 09:15:02.874721 22509476222784 run_lib.py:146] step: 571500, eval_loss: 5.68946e-02
I0212 09:15:21.497009 22509476222784 run_lib.py:133] step: 571550, training_loss: 4.60636e-02
I0212 09:15:39.956859 22509476222784 run_lib.py:133] step: 571600, training_loss: 4.59966e-02
I0212 09:15:40.120855 22509476222784 run_lib.py:146] step: 571600, eval_loss: 4.89915e-02
I0212 09:15:58.559580 22509476222784 run_lib.py:133] step: 571650, training_loss: 3.43847e-02
I0212 09:16:17.169047 22509476222784 run_lib.py:133] step: 571700, training_loss: 5.49360e-02
I0212 09:16:17.370631 22509476222784 run_lib.py:146] step: 571700, eval_loss: 3.03952e-02
I0212 09:16:35.869364 22509476222784 run_lib.py:133] step: 571750, training_loss: 4.22654e-02
I0212 09:16:54.391356 22509476222784 run_lib.py:133] step: 571800, training_loss: 3.12681e-02
I0212 09:16:54.560877 22509476222784 run_lib.py:146] step: 571800, eval_loss: 4.63496e-02
I0212 09:17:13.282140 22509476222784 run_lib.py:133] step: 571850, training_loss: 4.14848e-02
I0212 09:17:31.758060 22509476222784 run_lib.py:133] step: 571900, training_loss: 3.79229e-02
I0212 09:17:31.920643 22509476222784 run_lib.py:146] step: 571900, eval_loss: 4.63405e-02
I0212 09:17:50.513279 22509476222784 run_lib.py:133] step: 571950, training_loss: 4.83007e-02
I0212 09:18:09.017055 22509476222784 run_lib.py:133] step: 572000, training_loss: 5.17581e-02
I0212 09:18:09.187098 22509476222784 run_lib.py:146] step: 572000, eval_loss: 3.74076e-02
I0212 09:18:27.714846 22509476222784 run_lib.py:133] step: 572050, training_loss: 4.47517e-02
I0212 09:18:46.283798 22509476222784 run_lib.py:133] step: 572100, training_loss: 5.01546e-02
I0212 09:18:46.449640 22509476222784 run_lib.py:146] step: 572100, eval_loss: 5.30954e-02
I0212 09:19:04.939826 22509476222784 run_lib.py:133] step: 572150, training_loss: 4.64208e-02
I0212 09:19:23.383285 22509476222784 run_lib.py:133] step: 572200, training_loss: 4.44840e-02
I0212 09:19:23.546780 22509476222784 run_lib.py:146] step: 572200, eval_loss: 3.88544e-02
I0212 09:19:42.044968 22509476222784 run_lib.py:133] step: 572250, training_loss: 4.06298e-02
I0212 09:20:00.758152 22509476222784 run_lib.py:133] step: 572300, training_loss: 3.62237e-02
I0212 09:20:00.922408 22509476222784 run_lib.py:146] step: 572300, eval_loss: 5.68346e-02
I0212 09:20:19.431796 22509476222784 run_lib.py:133] step: 572350, training_loss: 3.69168e-02
I0212 09:20:37.997570 22509476222784 run_lib.py:133] step: 572400, training_loss: 3.64496e-02
I0212 09:20:38.182417 22509476222784 run_lib.py:146] step: 572400, eval_loss: 3.83568e-02
I0212 09:20:56.674697 22509476222784 run_lib.py:133] step: 572450, training_loss: 4.98010e-02
I0212 09:21:15.171026 22509476222784 run_lib.py:133] step: 572500, training_loss: 4.72117e-02
I0212 09:21:15.343799 22509476222784 run_lib.py:146] step: 572500, eval_loss: 4.29253e-02
I0212 09:21:34.016443 22509476222784 run_lib.py:133] step: 572550, training_loss: 4.69658e-02
I0212 09:21:52.643430 22509476222784 run_lib.py:133] step: 572600, training_loss: 4.43840e-02
I0212 09:21:52.810558 22509476222784 run_lib.py:146] step: 572600, eval_loss: 3.43826e-02
I0212 09:22:11.216982 22509476222784 run_lib.py:133] step: 572650, training_loss: 4.42094e-02
I0212 09:22:29.673255 22509476222784 run_lib.py:133] step: 572700, training_loss: 3.14165e-02
I0212 09:22:29.837730 22509476222784 run_lib.py:146] step: 572700, eval_loss: 3.51093e-02
I0212 09:22:48.465585 22509476222784 run_lib.py:133] step: 572750, training_loss: 3.77952e-02
I0212 09:23:07.014798 22509476222784 run_lib.py:133] step: 572800, training_loss: 4.11084e-02
I0212 09:23:07.179811 22509476222784 run_lib.py:146] step: 572800, eval_loss: 3.55895e-02
I0212 09:23:25.874114 22509476222784 run_lib.py:133] step: 572850, training_loss: 3.95651e-02
I0212 09:23:44.346198 22509476222784 run_lib.py:133] step: 572900, training_loss: 4.05815e-02
I0212 09:23:44.505621 22509476222784 run_lib.py:146] step: 572900, eval_loss: 5.49548e-02
I0212 09:24:03.146127 22509476222784 run_lib.py:133] step: 572950, training_loss: 3.56252e-02
I0212 09:24:21.662882 22509476222784 run_lib.py:133] step: 573000, training_loss: 4.32139e-02
I0212 09:24:21.834935 22509476222784 run_lib.py:146] step: 573000, eval_loss: 4.76168e-02
I0212 09:24:40.376533 22509476222784 run_lib.py:133] step: 573050, training_loss: 4.48381e-02
I0212 09:24:59.055505 22509476222784 run_lib.py:133] step: 573100, training_loss: 3.68261e-02
I0212 09:24:59.220606 22509476222784 run_lib.py:146] step: 573100, eval_loss: 5.06142e-02
I0212 09:25:17.702122 22509476222784 run_lib.py:133] step: 573150, training_loss: 4.52117e-02
I0212 09:25:36.350448 22509476222784 run_lib.py:133] step: 573200, training_loss: 3.40532e-02
I0212 09:25:36.546528 22509476222784 run_lib.py:146] step: 573200, eval_loss: 3.92689e-02
I0212 09:25:55.010283 22509476222784 run_lib.py:133] step: 573250, training_loss: 4.13332e-02
I0212 09:26:13.491608 22509476222784 run_lib.py:133] step: 573300, training_loss: 5.56907e-02
I0212 09:26:13.655074 22509476222784 run_lib.py:146] step: 573300, eval_loss: 3.98937e-02
I0212 09:26:32.341673 22509476222784 run_lib.py:133] step: 573350, training_loss: 3.71726e-02
I0212 09:26:50.843813 22509476222784 run_lib.py:133] step: 573400, training_loss: 4.74664e-02
I0212 09:26:51.004624 22509476222784 run_lib.py:146] step: 573400, eval_loss: 4.01666e-02
I0212 09:27:09.421033 22509476222784 run_lib.py:133] step: 573450, training_loss: 6.35489e-02
I0212 09:27:28.015420 22509476222784 run_lib.py:133] step: 573500, training_loss: 3.54613e-02
I0212 09:27:28.182084 22509476222784 run_lib.py:146] step: 573500, eval_loss: 3.57523e-02
I0212 09:27:46.665281 22509476222784 run_lib.py:133] step: 573550, training_loss: 4.14142e-02
I0212 09:28:05.187158 22509476222784 run_lib.py:133] step: 573600, training_loss: 5.07815e-02
I0212 09:28:05.505594 22509476222784 run_lib.py:146] step: 573600, eval_loss: 3.87663e-02
I0212 09:28:23.966217 22509476222784 run_lib.py:133] step: 573650, training_loss: 4.39942e-02
I0212 09:28:42.445042 22509476222784 run_lib.py:133] step: 573700, training_loss: 3.77873e-02
I0212 09:28:42.607931 22509476222784 run_lib.py:146] step: 573700, eval_loss: 4.15512e-02
I0212 09:29:01.071679 22509476222784 run_lib.py:133] step: 573750, training_loss: 4.12192e-02
I0212 09:29:19.543401 22509476222784 run_lib.py:133] step: 573800, training_loss: 5.04566e-02
I0212 09:29:19.704475 22509476222784 run_lib.py:146] step: 573800, eval_loss: 4.13596e-02
I0212 09:29:38.390559 22509476222784 run_lib.py:133] step: 573850, training_loss: 3.21108e-02
I0212 09:29:56.986272 22509476222784 run_lib.py:133] step: 573900, training_loss: 5.33284e-02
I0212 09:29:57.158789 22509476222784 run_lib.py:146] step: 573900, eval_loss: 4.84520e-02
I0212 09:30:15.630964 22509476222784 run_lib.py:133] step: 573950, training_loss: 4.23025e-02
I0212 09:30:34.170608 22509476222784 run_lib.py:133] step: 574000, training_loss: 3.83160e-02
I0212 09:30:34.369778 22509476222784 run_lib.py:146] step: 574000, eval_loss: 3.89636e-02
I0212 09:30:52.953689 22509476222784 run_lib.py:133] step: 574050, training_loss: 5.30366e-02
I0212 09:31:11.492518 22509476222784 run_lib.py:133] step: 574100, training_loss: 5.08925e-02
I0212 09:31:11.658497 22509476222784 run_lib.py:146] step: 574100, eval_loss: 2.63328e-02
I0212 09:31:30.147730 22509476222784 run_lib.py:133] step: 574150, training_loss: 4.72267e-02
I0212 09:31:48.691792 22509476222784 run_lib.py:133] step: 574200, training_loss: 4.96578e-02
I0212 09:31:48.856908 22509476222784 run_lib.py:146] step: 574200, eval_loss: 5.88274e-02
I0212 09:32:07.512757 22509476222784 run_lib.py:133] step: 574250, training_loss: 3.66958e-02
I0212 09:32:25.928869 22509476222784 run_lib.py:133] step: 574300, training_loss: 3.74983e-02
I0212 09:32:26.089709 22509476222784 run_lib.py:146] step: 574300, eval_loss: 3.29377e-02
I0212 09:32:44.664514 22509476222784 run_lib.py:133] step: 574350, training_loss: 4.55898e-02
I0212 09:33:03.151079 22509476222784 run_lib.py:133] step: 574400, training_loss: 4.86317e-02
I0212 09:33:03.318765 22509476222784 run_lib.py:146] step: 574400, eval_loss: 5.37699e-02
I0212 09:33:21.988480 22509476222784 run_lib.py:133] step: 574450, training_loss: 4.24490e-02
I0212 09:33:40.554663 22509476222784 run_lib.py:133] step: 574500, training_loss: 4.77586e-02
I0212 09:33:40.718390 22509476222784 run_lib.py:146] step: 574500, eval_loss: 4.60514e-02
I0212 09:33:59.161732 22509476222784 run_lib.py:133] step: 574550, training_loss: 4.57538e-02
I0212 09:34:17.766582 22509476222784 run_lib.py:133] step: 574600, training_loss: 5.27089e-02
I0212 09:34:17.932734 22509476222784 run_lib.py:146] step: 574600, eval_loss: 4.35529e-02
I0212 09:34:36.442870 22509476222784 run_lib.py:133] step: 574650, training_loss: 4.16919e-02
I0212 09:34:55.115237 22509476222784 run_lib.py:133] step: 574700, training_loss: 4.65636e-02
I0212 09:34:55.292909 22509476222784 run_lib.py:146] step: 574700, eval_loss: 4.53125e-02
I0212 09:35:13.808981 22509476222784 run_lib.py:133] step: 574750, training_loss: 3.88731e-02
I0212 09:35:32.290005 22509476222784 run_lib.py:133] step: 574800, training_loss: 4.26148e-02
I0212 09:35:32.451581 22509476222784 run_lib.py:146] step: 574800, eval_loss: 3.76986e-02
I0212 09:35:51.041843 22509476222784 run_lib.py:133] step: 574850, training_loss: 3.97123e-02
I0212 09:36:09.457462 22509476222784 run_lib.py:133] step: 574900, training_loss: 3.99577e-02
I0212 09:36:09.621519 22509476222784 run_lib.py:146] step: 574900, eval_loss: 4.11186e-02
I0212 09:36:28.116212 22509476222784 run_lib.py:133] step: 574950, training_loss: 4.99623e-02
I0212 09:36:46.660032 22509476222784 run_lib.py:133] step: 575000, training_loss: 5.03107e-02
I0212 09:36:46.824716 22509476222784 run_lib.py:146] step: 575000, eval_loss: 3.94608e-02
I0212 09:37:05.417026 22509476222784 run_lib.py:133] step: 575050, training_loss: 3.55177e-02
I0212 09:37:23.911858 22509476222784 run_lib.py:133] step: 575100, training_loss: 4.88744e-02
I0212 09:37:24.075594 22509476222784 run_lib.py:146] step: 575100, eval_loss: 4.24928e-02
I0212 09:37:42.602014 22509476222784 run_lib.py:133] step: 575150, training_loss: 4.57639e-02
I0212 09:38:01.064964 22509476222784 run_lib.py:133] step: 575200, training_loss: 3.73383e-02
I0212 09:38:01.231825 22509476222784 run_lib.py:146] step: 575200, eval_loss: 3.85569e-02
I0212 09:38:19.757401 22509476222784 run_lib.py:133] step: 575250, training_loss: 4.01816e-02
I0212 09:38:38.267185 22509476222784 run_lib.py:133] step: 575300, training_loss: 4.85053e-02
I0212 09:38:38.428959 22509476222784 run_lib.py:146] step: 575300, eval_loss: 3.46061e-02
I0212 09:38:57.175668 22509476222784 run_lib.py:133] step: 575350, training_loss: 4.77685e-02
I0212 09:39:15.643414 22509476222784 run_lib.py:133] step: 575400, training_loss: 3.85827e-02
I0212 09:39:15.807823 22509476222784 run_lib.py:146] step: 575400, eval_loss: 4.94898e-02
I0212 09:39:34.275612 22509476222784 run_lib.py:133] step: 575450, training_loss: 3.27373e-02
I0212 09:39:52.746352 22509476222784 run_lib.py:133] step: 575500, training_loss: 5.51014e-02
I0212 09:39:52.919556 22509476222784 run_lib.py:146] step: 575500, eval_loss: 3.89492e-02
I0212 09:40:11.612249 22509476222784 run_lib.py:133] step: 575550, training_loss: 5.44812e-02
I0212 09:40:30.112516 22509476222784 run_lib.py:133] step: 575600, training_loss: 4.38980e-02
I0212 09:40:30.332296 22509476222784 run_lib.py:146] step: 575600, eval_loss: 4.07996e-02
I0212 09:40:49.004085 22509476222784 run_lib.py:133] step: 575650, training_loss: 3.41887e-02
I0212 09:41:07.425975 22509476222784 run_lib.py:133] step: 575700, training_loss: 5.59675e-02
I0212 09:41:07.587308 22509476222784 run_lib.py:146] step: 575700, eval_loss: 4.28116e-02
I0212 09:41:26.241658 22509476222784 run_lib.py:133] step: 575750, training_loss: 4.22817e-02
I0212 09:41:44.768018 22509476222784 run_lib.py:133] step: 575800, training_loss: 5.15515e-02
I0212 09:41:44.932850 22509476222784 run_lib.py:146] step: 575800, eval_loss: 4.23102e-02
I0212 09:42:03.640486 22509476222784 run_lib.py:133] step: 575850, training_loss: 3.96075e-02
I0212 09:42:22.174697 22509476222784 run_lib.py:133] step: 575900, training_loss: 3.65319e-02
I0212 09:42:22.339749 22509476222784 run_lib.py:146] step: 575900, eval_loss: 5.23087e-02
I0212 09:42:40.824979 22509476222784 run_lib.py:133] step: 575950, training_loss: 4.18787e-02
I0212 09:42:59.377813 22509476222784 run_lib.py:133] step: 576000, training_loss: 4.45098e-02
I0212 09:42:59.540575 22509476222784 run_lib.py:146] step: 576000, eval_loss: 4.57404e-02
I0212 09:43:18.009189 22509476222784 run_lib.py:133] step: 576050, training_loss: 3.45153e-02
I0212 09:43:36.575794 22509476222784 run_lib.py:133] step: 576100, training_loss: 4.11089e-02
I0212 09:43:36.741579 22509476222784 run_lib.py:146] step: 576100, eval_loss: 4.09002e-02
I0212 09:43:55.536710 22509476222784 run_lib.py:133] step: 576150, training_loss: 4.08938e-02
I0212 09:44:14.156755 22509476222784 run_lib.py:133] step: 576200, training_loss: 4.72863e-02
I0212 09:44:14.320531 22509476222784 run_lib.py:146] step: 576200, eval_loss: 4.57751e-02
I0212 09:44:32.761389 22509476222784 run_lib.py:133] step: 576250, training_loss: 3.75314e-02
I0212 09:44:51.212838 22509476222784 run_lib.py:133] step: 576300, training_loss: 3.88722e-02
I0212 09:44:51.386842 22509476222784 run_lib.py:146] step: 576300, eval_loss: 4.88051e-02
I0212 09:45:09.932667 22509476222784 run_lib.py:133] step: 576350, training_loss: 4.16011e-02
I0212 09:45:28.634652 22509476222784 run_lib.py:133] step: 576400, training_loss: 4.10644e-02
I0212 09:45:28.800661 22509476222784 run_lib.py:146] step: 576400, eval_loss: 4.37080e-02
I0212 09:45:47.285860 22509476222784 run_lib.py:133] step: 576450, training_loss: 3.86892e-02
I0212 09:46:05.742946 22509476222784 run_lib.py:133] step: 576500, training_loss: 4.23413e-02
I0212 09:46:05.905474 22509476222784 run_lib.py:146] step: 576500, eval_loss: 4.99080e-02
I0212 09:46:24.403527 22509476222784 run_lib.py:133] step: 576550, training_loss: 3.29183e-02
I0212 09:46:43.046362 22509476222784 run_lib.py:133] step: 576600, training_loss: 3.97884e-02
I0212 09:46:43.212857 22509476222784 run_lib.py:146] step: 576600, eval_loss: 4.75822e-02
I0212 09:47:01.745883 22509476222784 run_lib.py:133] step: 576650, training_loss: 4.73875e-02
I0212 09:47:20.369341 22509476222784 run_lib.py:133] step: 576700, training_loss: 5.10111e-02
I0212 09:47:20.529570 22509476222784 run_lib.py:146] step: 576700, eval_loss: 4.50268e-02
I0212 09:47:39.003990 22509476222784 run_lib.py:133] step: 576750, training_loss: 4.83959e-02
I0212 09:47:57.460086 22509476222784 run_lib.py:133] step: 576800, training_loss: 4.20222e-02
I0212 09:47:57.623697 22509476222784 run_lib.py:146] step: 576800, eval_loss: 3.30309e-02
I0212 09:48:16.266032 22509476222784 run_lib.py:133] step: 576850, training_loss: 4.35345e-02
I0212 09:48:34.914499 22509476222784 run_lib.py:133] step: 576900, training_loss: 4.05621e-02
I0212 09:48:35.080553 22509476222784 run_lib.py:146] step: 576900, eval_loss: 4.28816e-02
I0212 09:48:53.571628 22509476222784 run_lib.py:133] step: 576950, training_loss: 5.19897e-02
I0212 09:49:12.065153 22509476222784 run_lib.py:133] step: 577000, training_loss: 5.31316e-02
I0212 09:49:12.230017 22509476222784 run_lib.py:146] step: 577000, eval_loss: 3.29782e-02
I0212 09:49:30.910898 22509476222784 run_lib.py:133] step: 577050, training_loss: 4.35441e-02
I0212 09:49:49.367723 22509476222784 run_lib.py:133] step: 577100, training_loss: 4.41781e-02
I0212 09:49:49.531657 22509476222784 run_lib.py:146] step: 577100, eval_loss: 4.75889e-02
I0212 09:50:08.196567 22509476222784 run_lib.py:133] step: 577150, training_loss: 4.25781e-02
I0212 09:50:26.730900 22509476222784 run_lib.py:133] step: 577200, training_loss: 2.99363e-02
I0212 09:50:26.894012 22509476222784 run_lib.py:146] step: 577200, eval_loss: 3.56894e-02
I0212 09:50:45.494435 22509476222784 run_lib.py:133] step: 577250, training_loss: 4.75824e-02
I0212 09:51:03.921501 22509476222784 run_lib.py:133] step: 577300, training_loss: 3.32144e-02
I0212 09:51:04.086656 22509476222784 run_lib.py:146] step: 577300, eval_loss: 5.19915e-02
I0212 09:51:22.553459 22509476222784 run_lib.py:133] step: 577350, training_loss: 3.97391e-02
I0212 09:51:41.196225 22509476222784 run_lib.py:133] step: 577400, training_loss: 4.69775e-02
I0212 09:51:41.374647 22509476222784 run_lib.py:146] step: 577400, eval_loss: 3.11558e-02
I0212 09:51:59.880163 22509476222784 run_lib.py:133] step: 577450, training_loss: 5.70200e-02
I0212 09:52:18.573117 22509476222784 run_lib.py:133] step: 577500, training_loss: 4.35179e-02
I0212 09:52:18.738010 22509476222784 run_lib.py:146] step: 577500, eval_loss: 5.08284e-02
I0212 09:52:37.239956 22509476222784 run_lib.py:133] step: 577550, training_loss: 3.14220e-02
I0212 09:52:55.705366 22509476222784 run_lib.py:133] step: 577600, training_loss: 5.32447e-02
I0212 09:52:55.880748 22509476222784 run_lib.py:146] step: 577600, eval_loss: 4.21504e-02
I0212 09:53:14.500174 22509476222784 run_lib.py:133] step: 577650, training_loss: 3.63305e-02
I0212 09:53:33.061995 22509476222784 run_lib.py:133] step: 577700, training_loss: 5.21542e-02
I0212 09:53:33.233778 22509476222784 run_lib.py:146] step: 577700, eval_loss: 4.44601e-02
I0212 09:53:51.747207 22509476222784 run_lib.py:133] step: 577750, training_loss: 3.99032e-02
I0212 09:54:10.503150 22509476222784 run_lib.py:133] step: 577800, training_loss: 4.10482e-02
I0212 09:54:10.669951 22509476222784 run_lib.py:146] step: 577800, eval_loss: 4.13217e-02
I0212 09:54:29.108586 22509476222784 run_lib.py:133] step: 577850, training_loss: 3.71635e-02
I0212 09:54:47.566403 22509476222784 run_lib.py:133] step: 577900, training_loss: 4.16477e-02
I0212 09:54:47.728551 22509476222784 run_lib.py:146] step: 577900, eval_loss: 3.24424e-02
I0212 09:55:06.263989 22509476222784 run_lib.py:133] step: 577950, training_loss: 5.14205e-02
I0212 09:55:24.841444 22509476222784 run_lib.py:133] step: 578000, training_loss: 2.94107e-02
I0212 09:55:25.004903 22509476222784 run_lib.py:146] step: 578000, eval_loss: 4.14014e-02
I0212 09:55:43.539501 22509476222784 run_lib.py:133] step: 578050, training_loss: 4.22785e-02
I0212 09:56:02.110708 22509476222784 run_lib.py:133] step: 578100, training_loss: 4.43954e-02
I0212 09:56:02.272792 22509476222784 run_lib.py:146] step: 578100, eval_loss: 4.53425e-02
I0212 09:56:20.974766 22509476222784 run_lib.py:133] step: 578150, training_loss: 3.64266e-02
I0212 09:56:39.564193 22509476222784 run_lib.py:133] step: 578200, training_loss: 3.42633e-02
I0212 09:56:39.737842 22509476222784 run_lib.py:146] step: 578200, eval_loss: 4.26679e-02
I0212 09:56:58.280403 22509476222784 run_lib.py:133] step: 578250, training_loss: 4.10810e-02
I0212 09:57:16.797865 22509476222784 run_lib.py:133] step: 578300, training_loss: 4.12127e-02
I0212 09:57:16.969834 22509476222784 run_lib.py:146] step: 578300, eval_loss: 3.71167e-02
I0212 09:57:35.665243 22509476222784 run_lib.py:133] step: 578350, training_loss: 4.50812e-02
I0212 09:57:54.162251 22509476222784 run_lib.py:133] step: 578400, training_loss: 5.22992e-02
I0212 09:57:54.326673 22509476222784 run_lib.py:146] step: 578400, eval_loss: 4.55786e-02
I0212 09:58:12.987567 22509476222784 run_lib.py:133] step: 578450, training_loss: 2.52917e-02
I0212 09:58:31.528352 22509476222784 run_lib.py:133] step: 578500, training_loss: 4.76264e-02
I0212 09:58:31.691855 22509476222784 run_lib.py:146] step: 578500, eval_loss: 3.70551e-02
I0212 09:58:50.405545 22509476222784 run_lib.py:133] step: 578550, training_loss: 3.07351e-02
I0212 09:59:08.918244 22509476222784 run_lib.py:133] step: 578600, training_loss: 4.41084e-02
I0212 09:59:09.088626 22509476222784 run_lib.py:146] step: 578600, eval_loss: 4.64639e-02
I0212 09:59:27.756634 22509476222784 run_lib.py:133] step: 578650, training_loss: 4.88439e-02
I0212 09:59:46.279949 22509476222784 run_lib.py:133] step: 578700, training_loss: 4.25168e-02
I0212 09:59:46.455491 22509476222784 run_lib.py:146] step: 578700, eval_loss: 5.43925e-02
I0212 10:00:05.101029 22509476222784 run_lib.py:133] step: 578750, training_loss: 4.57002e-02
I0212 10:00:23.859186 22509476222784 run_lib.py:133] step: 578800, training_loss: 3.76146e-02
I0212 10:00:24.024719 22509476222784 run_lib.py:146] step: 578800, eval_loss: 3.89211e-02
I0212 10:00:42.539977 22509476222784 run_lib.py:133] step: 578850, training_loss: 4.81106e-02
I0212 10:01:01.052383 22509476222784 run_lib.py:133] step: 578900, training_loss: 4.42330e-02
I0212 10:01:01.216712 22509476222784 run_lib.py:146] step: 578900, eval_loss: 4.82530e-02
I0212 10:01:19.953597 22509476222784 run_lib.py:133] step: 578950, training_loss: 5.03779e-02
I0212 10:01:38.516465 22509476222784 run_lib.py:133] step: 579000, training_loss: 3.79916e-02
I0212 10:01:38.681040 22509476222784 run_lib.py:146] step: 579000, eval_loss: 5.38345e-02
I0212 10:01:57.425990 22509476222784 run_lib.py:133] step: 579050, training_loss: 3.90519e-02
I0212 10:02:15.994648 22509476222784 run_lib.py:133] step: 579100, training_loss: 5.37286e-02
I0212 10:02:16.168748 22509476222784 run_lib.py:146] step: 579100, eval_loss: 4.90337e-02
I0212 10:02:34.724871 22509476222784 run_lib.py:133] step: 579150, training_loss: 4.44030e-02
I0212 10:02:53.428818 22509476222784 run_lib.py:133] step: 579200, training_loss: 3.43205e-02
I0212 10:02:53.596978 22509476222784 run_lib.py:146] step: 579200, eval_loss: 5.06039e-02
I0212 10:03:12.163557 22509476222784 run_lib.py:133] step: 579250, training_loss: 3.28731e-02
I0212 10:03:30.757639 22509476222784 run_lib.py:133] step: 579300, training_loss: 4.49408e-02
I0212 10:03:30.922901 22509476222784 run_lib.py:146] step: 579300, eval_loss: 3.20782e-02
I0212 10:03:49.382069 22509476222784 run_lib.py:133] step: 579350, training_loss: 4.71555e-02
I0212 10:04:08.076733 22509476222784 run_lib.py:133] step: 579400, training_loss: 4.22146e-02
I0212 10:04:08.241774 22509476222784 run_lib.py:146] step: 579400, eval_loss: 5.28548e-02
I0212 10:04:26.796147 22509476222784 run_lib.py:133] step: 579450, training_loss: 4.11824e-02
I0212 10:04:45.395739 22509476222784 run_lib.py:133] step: 579500, training_loss: 5.16251e-02
I0212 10:04:45.556672 22509476222784 run_lib.py:146] step: 579500, eval_loss: 3.91571e-02
I0212 10:05:04.145256 22509476222784 run_lib.py:133] step: 579550, training_loss: 4.40304e-02
I0212 10:05:22.739671 22509476222784 run_lib.py:133] step: 579600, training_loss: 4.25443e-02
I0212 10:05:22.903824 22509476222784 run_lib.py:146] step: 579600, eval_loss: 4.18104e-02
I0212 10:05:41.641882 22509476222784 run_lib.py:133] step: 579650, training_loss: 3.58035e-02
I0212 10:06:00.282767 22509476222784 run_lib.py:133] step: 579700, training_loss: 3.63737e-02
I0212 10:06:00.448935 22509476222784 run_lib.py:146] step: 579700, eval_loss: 3.76132e-02
I0212 10:06:18.934245 22509476222784 run_lib.py:133] step: 579750, training_loss: 3.51753e-02
I0212 10:06:37.500211 22509476222784 run_lib.py:133] step: 579800, training_loss: 4.27272e-02
I0212 10:06:37.675732 22509476222784 run_lib.py:146] step: 579800, eval_loss: 4.65670e-02
I0212 10:06:56.448657 22509476222784 run_lib.py:133] step: 579850, training_loss: 5.24452e-02
I0212 10:07:15.003816 22509476222784 run_lib.py:133] step: 579900, training_loss: 3.83495e-02
I0212 10:07:15.175610 22509476222784 run_lib.py:146] step: 579900, eval_loss: 5.76407e-02
I0212 10:07:33.900416 22509476222784 run_lib.py:133] step: 579950, training_loss: 4.09199e-02
I0212 10:07:52.392988 22509476222784 run_lib.py:133] step: 580000, training_loss: 3.49946e-02
I0212 10:07:53.129597 22509476222784 run_lib.py:146] step: 580000, eval_loss: 4.56546e-02
I0212 10:08:14.733363 22509476222784 run_lib.py:133] step: 580050, training_loss: 4.09516e-02
I0212 10:08:33.329778 22509476222784 run_lib.py:133] step: 580100, training_loss: 3.88377e-02
I0212 10:08:33.493688 22509476222784 run_lib.py:146] step: 580100, eval_loss: 4.76508e-02
I0212 10:08:52.256732 22509476222784 run_lib.py:133] step: 580150, training_loss: 3.65846e-02
I0212 10:09:10.793765 22509476222784 run_lib.py:133] step: 580200, training_loss: 3.93891e-02
I0212 10:09:10.957413 22509476222784 run_lib.py:146] step: 580200, eval_loss: 4.34878e-02
I0212 10:09:29.491348 22509476222784 run_lib.py:133] step: 580250, training_loss: 3.95608e-02
I0212 10:09:48.070926 22509476222784 run_lib.py:133] step: 580300, training_loss: 2.92153e-02
I0212 10:09:48.239005 22509476222784 run_lib.py:146] step: 580300, eval_loss: 4.92226e-02
I0212 10:10:06.997309 22509476222784 run_lib.py:133] step: 580350, training_loss: 3.52087e-02
I0212 10:10:25.694899 22509476222784 run_lib.py:133] step: 580400, training_loss: 4.59165e-02
I0212 10:10:25.864054 22509476222784 run_lib.py:146] step: 580400, eval_loss: 4.85248e-02
I0212 10:10:44.461207 22509476222784 run_lib.py:133] step: 580450, training_loss: 5.41603e-02
I0212 10:11:03.020175 22509476222784 run_lib.py:133] step: 580500, training_loss: 4.45641e-02
I0212 10:11:03.183655 22509476222784 run_lib.py:146] step: 580500, eval_loss: 4.18389e-02
I0212 10:11:21.878027 22509476222784 run_lib.py:133] step: 580550, training_loss: 4.22355e-02
I0212 10:11:40.470251 22509476222784 run_lib.py:133] step: 580600, training_loss: 3.68148e-02
I0212 10:11:40.650801 22509476222784 run_lib.py:146] step: 580600, eval_loss: 4.39334e-02
I0212 10:11:59.456585 22509476222784 run_lib.py:133] step: 580650, training_loss: 5.26110e-02
I0212 10:12:18.020018 22509476222784 run_lib.py:133] step: 580700, training_loss: 4.27414e-02
I0212 10:12:18.194828 22509476222784 run_lib.py:146] step: 580700, eval_loss: 6.40414e-02
I0212 10:12:36.901505 22509476222784 run_lib.py:133] step: 580750, training_loss: 3.97557e-02
I0212 10:12:55.406799 22509476222784 run_lib.py:133] step: 580800, training_loss: 4.16037e-02
I0212 10:12:55.570655 22509476222784 run_lib.py:146] step: 580800, eval_loss: 4.39239e-02
I0212 10:13:14.137030 22509476222784 run_lib.py:133] step: 580850, training_loss: 3.94048e-02
I0212 10:13:32.939015 22509476222784 run_lib.py:133] step: 580900, training_loss: 4.37211e-02
I0212 10:13:33.103579 22509476222784 run_lib.py:146] step: 580900, eval_loss: 3.48867e-02
I0212 10:13:51.688257 22509476222784 run_lib.py:133] step: 580950, training_loss: 3.65283e-02
I0212 10:14:10.426791 22509476222784 run_lib.py:133] step: 581000, training_loss: 4.37987e-02
I0212 10:14:10.587361 22509476222784 run_lib.py:146] step: 581000, eval_loss: 5.37757e-02
I0212 10:14:29.164320 22509476222784 run_lib.py:133] step: 581050, training_loss: 5.29879e-02
I0212 10:14:47.735931 22509476222784 run_lib.py:133] step: 581100, training_loss: 3.87427e-02
I0212 10:14:47.913454 22509476222784 run_lib.py:146] step: 581100, eval_loss: 4.44856e-02
I0212 10:15:06.728247 22509476222784 run_lib.py:133] step: 581150, training_loss: 4.51343e-02
I0212 10:15:25.334947 22509476222784 run_lib.py:133] step: 581200, training_loss: 4.18446e-02
I0212 10:15:25.504650 22509476222784 run_lib.py:146] step: 581200, eval_loss: 4.98616e-02
I0212 10:15:44.095420 22509476222784 run_lib.py:133] step: 581250, training_loss: 2.86395e-02
I0212 10:16:02.769400 22509476222784 run_lib.py:133] step: 581300, training_loss: 3.54946e-02
I0212 10:16:02.933859 22509476222784 run_lib.py:146] step: 581300, eval_loss: 3.41928e-02
I0212 10:16:21.430747 22509476222784 run_lib.py:133] step: 581350, training_loss: 5.07912e-02
I0212 10:16:39.995766 22509476222784 run_lib.py:133] step: 581400, training_loss: 3.70415e-02
I0212 10:16:40.347691 22509476222784 run_lib.py:146] step: 581400, eval_loss: 4.13348e-02
I0212 10:16:58.886792 22509476222784 run_lib.py:133] step: 581450, training_loss: 3.90555e-02
I0212 10:17:17.387403 22509476222784 run_lib.py:133] step: 581500, training_loss: 3.70833e-02
I0212 10:17:17.548815 22509476222784 run_lib.py:146] step: 581500, eval_loss: 4.58189e-02
I0212 10:17:36.016952 22509476222784 run_lib.py:133] step: 581550, training_loss: 3.41725e-02
I0212 10:17:54.585148 22509476222784 run_lib.py:133] step: 581600, training_loss: 5.14126e-02
I0212 10:17:54.760977 22509476222784 run_lib.py:146] step: 581600, eval_loss: 3.73850e-02
I0212 10:18:13.439422 22509476222784 run_lib.py:133] step: 581650, training_loss: 3.81497e-02
I0212 10:18:32.122760 22509476222784 run_lib.py:133] step: 581700, training_loss: 4.06643e-02
I0212 10:18:32.292795 22509476222784 run_lib.py:146] step: 581700, eval_loss: 5.10430e-02
I0212 10:18:50.838811 22509476222784 run_lib.py:133] step: 581750, training_loss: 3.25698e-02
I0212 10:19:09.388871 22509476222784 run_lib.py:133] step: 581800, training_loss: 5.00208e-02
I0212 10:19:09.552692 22509476222784 run_lib.py:146] step: 581800, eval_loss: 3.34010e-02
I0212 10:19:28.215677 22509476222784 run_lib.py:133] step: 581850, training_loss: 5.20790e-02
I0212 10:19:46.861788 22509476222784 run_lib.py:133] step: 581900, training_loss: 4.61405e-02
I0212 10:19:47.034774 22509476222784 run_lib.py:146] step: 581900, eval_loss: 4.84748e-02
I0212 10:20:05.605844 22509476222784 run_lib.py:133] step: 581950, training_loss: 4.64285e-02
I0212 10:20:24.117938 22509476222784 run_lib.py:133] step: 582000, training_loss: 3.67246e-02
I0212 10:20:24.287659 22509476222784 run_lib.py:146] step: 582000, eval_loss: 5.53974e-02
I0212 10:20:43.124128 22509476222784 run_lib.py:133] step: 582050, training_loss: 4.46126e-02
I0212 10:21:01.653791 22509476222784 run_lib.py:133] step: 582100, training_loss: 4.86189e-02
I0212 10:21:01.831914 22509476222784 run_lib.py:146] step: 582100, eval_loss: 4.31661e-02
I0212 10:21:20.541632 22509476222784 run_lib.py:133] step: 582150, training_loss: 3.61498e-02
I0212 10:21:39.151131 22509476222784 run_lib.py:133] step: 582200, training_loss: 3.94867e-02
I0212 10:21:39.315692 22509476222784 run_lib.py:146] step: 582200, eval_loss: 3.61351e-02
I0212 10:21:58.013613 22509476222784 run_lib.py:133] step: 582250, training_loss: 5.06889e-02
I0212 10:22:16.562283 22509476222784 run_lib.py:133] step: 582300, training_loss: 3.18546e-02
I0212 10:22:16.726542 22509476222784 run_lib.py:146] step: 582300, eval_loss: 3.38536e-02
I0212 10:22:35.220153 22509476222784 run_lib.py:133] step: 582350, training_loss: 3.00378e-02
I0212 10:22:53.933289 22509476222784 run_lib.py:133] step: 582400, training_loss: 5.00748e-02
I0212 10:22:54.094637 22509476222784 run_lib.py:146] step: 582400, eval_loss: 5.59730e-02
I0212 10:23:12.791158 22509476222784 run_lib.py:133] step: 582450, training_loss: 3.50445e-02
I0212 10:23:31.527183 22509476222784 run_lib.py:133] step: 582500, training_loss: 4.88460e-02
I0212 10:23:31.695605 22509476222784 run_lib.py:146] step: 582500, eval_loss: 3.73969e-02
I0212 10:23:50.221926 22509476222784 run_lib.py:133] step: 582550, training_loss: 4.29764e-02
I0212 10:24:08.712958 22509476222784 run_lib.py:133] step: 582600, training_loss: 3.80730e-02
I0212 10:24:08.879862 22509476222784 run_lib.py:146] step: 582600, eval_loss: 4.60709e-02
I0212 10:24:27.456521 22509476222784 run_lib.py:133] step: 582650, training_loss: 4.02200e-02
I0212 10:24:46.234956 22509476222784 run_lib.py:133] step: 582700, training_loss: 4.77881e-02
I0212 10:24:46.400053 22509476222784 run_lib.py:146] step: 582700, eval_loss: 4.36261e-02
I0212 10:25:04.969692 22509476222784 run_lib.py:133] step: 582750, training_loss: 4.45096e-02
I0212 10:25:23.530827 22509476222784 run_lib.py:133] step: 582800, training_loss: 4.62485e-02
I0212 10:25:23.785913 22509476222784 run_lib.py:146] step: 582800, eval_loss: 4.07257e-02
I0212 10:25:42.533302 22509476222784 run_lib.py:133] step: 582850, training_loss: 4.44623e-02
I0212 10:26:01.092489 22509476222784 run_lib.py:133] step: 582900, training_loss: 3.90217e-02
I0212 10:26:01.254080 22509476222784 run_lib.py:146] step: 582900, eval_loss: 4.27488e-02
I0212 10:26:19.896673 22509476222784 run_lib.py:133] step: 582950, training_loss: 3.42307e-02
I0212 10:26:38.490408 22509476222784 run_lib.py:133] step: 583000, training_loss: 5.21324e-02
I0212 10:26:38.656958 22509476222784 run_lib.py:146] step: 583000, eval_loss: 3.73251e-02
I0212 10:26:57.191362 22509476222784 run_lib.py:133] step: 583050, training_loss: 4.01392e-02
I0212 10:27:15.798329 22509476222784 run_lib.py:133] step: 583100, training_loss: 3.45309e-02
I0212 10:27:15.968819 22509476222784 run_lib.py:146] step: 583100, eval_loss: 3.77130e-02
I0212 10:27:34.700877 22509476222784 run_lib.py:133] step: 583150, training_loss: 4.74482e-02
I0212 10:27:53.344438 22509476222784 run_lib.py:133] step: 583200, training_loss: 4.13933e-02
I0212 10:27:53.518705 22509476222784 run_lib.py:146] step: 583200, eval_loss: 4.74070e-02
I0212 10:28:12.132113 22509476222784 run_lib.py:133] step: 583250, training_loss: 4.10122e-02
I0212 10:28:30.746014 22509476222784 run_lib.py:133] step: 583300, training_loss: 3.53759e-02
I0212 10:28:30.910770 22509476222784 run_lib.py:146] step: 583300, eval_loss: 4.69408e-02
I0212 10:28:49.659670 22509476222784 run_lib.py:133] step: 583350, training_loss: 2.26700e-02
I0212 10:29:08.214011 22509476222784 run_lib.py:133] step: 583400, training_loss: 5.42765e-02
I0212 10:29:08.375741 22509476222784 run_lib.py:146] step: 583400, eval_loss: 4.92986e-02
I0212 10:29:27.071417 22509476222784 run_lib.py:133] step: 583450, training_loss: 3.36052e-02
I0212 10:29:45.607336 22509476222784 run_lib.py:133] step: 583500, training_loss: 4.60161e-02
I0212 10:29:45.788877 22509476222784 run_lib.py:146] step: 583500, eval_loss: 3.95441e-02
I0212 10:30:04.607632 22509476222784 run_lib.py:133] step: 583550, training_loss: 4.30266e-02
I0212 10:30:23.214130 22509476222784 run_lib.py:133] step: 583600, training_loss: 3.82974e-02
I0212 10:30:23.380643 22509476222784 run_lib.py:146] step: 583600, eval_loss: 5.22212e-02
I0212 10:30:42.060469 22509476222784 run_lib.py:133] step: 583650, training_loss: 4.20688e-02
I0212 10:31:00.559265 22509476222784 run_lib.py:133] step: 583700, training_loss: 4.32713e-02
I0212 10:31:00.723703 22509476222784 run_lib.py:146] step: 583700, eval_loss: 4.99591e-02
I0212 10:31:19.250700 22509476222784 run_lib.py:133] step: 583750, training_loss: 5.23370e-02
I0212 10:31:37.954893 22509476222784 run_lib.py:133] step: 583800, training_loss: 4.15020e-02
I0212 10:31:38.119538 22509476222784 run_lib.py:146] step: 583800, eval_loss: 4.55424e-02
I0212 10:31:56.756877 22509476222784 run_lib.py:133] step: 583850, training_loss: 4.57914e-02
I0212 10:32:15.252345 22509476222784 run_lib.py:133] step: 583900, training_loss: 5.32639e-02
I0212 10:32:15.444694 22509476222784 run_lib.py:146] step: 583900, eval_loss: 3.73038e-02
I0212 10:32:34.125910 22509476222784 run_lib.py:133] step: 583950, training_loss: 4.70355e-02
I0212 10:32:52.754632 22509476222784 run_lib.py:133] step: 584000, training_loss: 4.69746e-02
I0212 10:32:52.919888 22509476222784 run_lib.py:146] step: 584000, eval_loss: 4.10924e-02
I0212 10:33:11.354486 22509476222784 run_lib.py:133] step: 584050, training_loss: 3.94951e-02
I0212 10:33:29.775885 22509476222784 run_lib.py:133] step: 584100, training_loss: 3.11483e-02
I0212 10:33:29.938657 22509476222784 run_lib.py:146] step: 584100, eval_loss: 5.03953e-02
I0212 10:33:48.321813 22509476222784 run_lib.py:133] step: 584150, training_loss: 3.52608e-02
I0212 10:34:06.904310 22509476222784 run_lib.py:133] step: 584200, training_loss: 3.41820e-02
I0212 10:34:07.072993 22509476222784 run_lib.py:146] step: 584200, eval_loss: 4.88254e-02
I0212 10:34:25.595131 22509476222784 run_lib.py:133] step: 584250, training_loss: 4.64170e-02
I0212 10:34:44.149807 22509476222784 run_lib.py:133] step: 584300, training_loss: 3.57343e-02
I0212 10:34:44.326862 22509476222784 run_lib.py:146] step: 584300, eval_loss: 4.74199e-02
I0212 10:35:02.843186 22509476222784 run_lib.py:133] step: 584350, training_loss: 4.90232e-02
I0212 10:35:21.517243 22509476222784 run_lib.py:133] step: 584400, training_loss: 3.45345e-02
I0212 10:35:21.678545 22509476222784 run_lib.py:146] step: 584400, eval_loss: 4.12831e-02
I0212 10:35:40.150458 22509476222784 run_lib.py:133] step: 584450, training_loss: 4.12735e-02
I0212 10:35:58.748421 22509476222784 run_lib.py:133] step: 584500, training_loss: 3.49533e-02
I0212 10:35:58.915910 22509476222784 run_lib.py:146] step: 584500, eval_loss: 5.01635e-02
I0212 10:36:17.494274 22509476222784 run_lib.py:133] step: 584550, training_loss: 4.42857e-02
I0212 10:36:36.069694 22509476222784 run_lib.py:133] step: 584600, training_loss: 4.62477e-02
I0212 10:36:36.234823 22509476222784 run_lib.py:146] step: 584600, eval_loss: 4.44682e-02
I0212 10:36:54.994364 22509476222784 run_lib.py:133] step: 584650, training_loss: 3.27869e-02
I0212 10:37:13.582347 22509476222784 run_lib.py:133] step: 584700, training_loss: 4.65680e-02
I0212 10:37:13.747453 22509476222784 run_lib.py:146] step: 584700, eval_loss: 4.32109e-02
I0212 10:37:32.301524 22509476222784 run_lib.py:133] step: 584750, training_loss: 3.09671e-02
I0212 10:37:50.831886 22509476222784 run_lib.py:133] step: 584800, training_loss: 4.60453e-02
I0212 10:37:50.995507 22509476222784 run_lib.py:146] step: 584800, eval_loss: 2.94398e-02
I0212 10:38:09.677695 22509476222784 run_lib.py:133] step: 584850, training_loss: 3.37651e-02
I0212 10:38:28.297472 22509476222784 run_lib.py:133] step: 584900, training_loss: 3.98588e-02
I0212 10:38:28.468866 22509476222784 run_lib.py:146] step: 584900, eval_loss: 4.60621e-02
I0212 10:38:47.222721 22509476222784 run_lib.py:133] step: 584950, training_loss: 4.57316e-02
I0212 10:39:05.782034 22509476222784 run_lib.py:133] step: 585000, training_loss: 3.62104e-02
I0212 10:39:05.948990 22509476222784 run_lib.py:146] step: 585000, eval_loss: 3.21345e-02
I0212 10:39:24.670165 22509476222784 run_lib.py:133] step: 585050, training_loss: 5.04986e-02
I0212 10:39:43.264784 22509476222784 run_lib.py:133] step: 585100, training_loss: 4.36779e-02
I0212 10:39:43.461642 22509476222784 run_lib.py:146] step: 585100, eval_loss: 3.71561e-02
I0212 10:40:02.083605 22509476222784 run_lib.py:133] step: 585150, training_loss: 3.90781e-02
I0212 10:40:20.781161 22509476222784 run_lib.py:133] step: 585200, training_loss: 3.72428e-02
I0212 10:40:20.945804 22509476222784 run_lib.py:146] step: 585200, eval_loss: 5.18943e-02
I0212 10:40:39.454295 22509476222784 run_lib.py:133] step: 585250, training_loss: 3.71850e-02
I0212 10:40:58.100028 22509476222784 run_lib.py:133] step: 585300, training_loss: 4.71503e-02
I0212 10:40:58.260776 22509476222784 run_lib.py:146] step: 585300, eval_loss: 4.25671e-02
I0212 10:41:16.799680 22509476222784 run_lib.py:133] step: 585350, training_loss: 3.62751e-02
I0212 10:41:35.338281 22509476222784 run_lib.py:133] step: 585400, training_loss: 4.38241e-02
I0212 10:41:35.513827 22509476222784 run_lib.py:146] step: 585400, eval_loss: 3.98552e-02
I0212 10:41:54.261319 22509476222784 run_lib.py:133] step: 585450, training_loss: 3.83048e-02
I0212 10:42:12.831033 22509476222784 run_lib.py:133] step: 585500, training_loss: 4.42274e-02
I0212 10:42:12.996807 22509476222784 run_lib.py:146] step: 585500, eval_loss: 4.10400e-02
I0212 10:42:31.498598 22509476222784 run_lib.py:133] step: 585550, training_loss: 4.84693e-02
I0212 10:42:50.148025 22509476222784 run_lib.py:133] step: 585600, training_loss: 5.97135e-02
I0212 10:42:50.317598 22509476222784 run_lib.py:146] step: 585600, eval_loss: 4.21645e-02
I0212 10:43:08.848938 22509476222784 run_lib.py:133] step: 585650, training_loss: 3.83489e-02
I0212 10:43:27.471775 22509476222784 run_lib.py:133] step: 585700, training_loss: 3.69925e-02
I0212 10:43:27.636023 22509476222784 run_lib.py:146] step: 585700, eval_loss: 4.48614e-02
I0212 10:43:46.295228 22509476222784 run_lib.py:133] step: 585750, training_loss: 4.73017e-02
I0212 10:44:04.810696 22509476222784 run_lib.py:133] step: 585800, training_loss: 3.05593e-02
I0212 10:44:04.973814 22509476222784 run_lib.py:146] step: 585800, eval_loss: 4.69987e-02
I0212 10:44:23.486634 22509476222784 run_lib.py:133] step: 585850, training_loss: 3.99180e-02
I0212 10:44:41.975552 22509476222784 run_lib.py:133] step: 585900, training_loss: 2.94341e-02
I0212 10:44:42.146323 22509476222784 run_lib.py:146] step: 585900, eval_loss: 3.17043e-02
I0212 10:45:00.873575 22509476222784 run_lib.py:133] step: 585950, training_loss: 4.34061e-02
I0212 10:45:19.597517 22509476222784 run_lib.py:133] step: 586000, training_loss: 5.48169e-02
I0212 10:45:19.761690 22509476222784 run_lib.py:146] step: 586000, eval_loss: 3.77922e-02
I0212 10:45:38.303444 22509476222784 run_lib.py:133] step: 586050, training_loss: 5.05027e-02
I0212 10:45:56.831419 22509476222784 run_lib.py:133] step: 586100, training_loss: 4.81550e-02
I0212 10:45:56.995801 22509476222784 run_lib.py:146] step: 586100, eval_loss: 4.56154e-02
I0212 10:46:15.610297 22509476222784 run_lib.py:133] step: 586150, training_loss: 4.05295e-02
I0212 10:46:34.104665 22509476222784 run_lib.py:133] step: 586200, training_loss: 4.41215e-02
I0212 10:46:34.269021 22509476222784 run_lib.py:146] step: 586200, eval_loss: 4.78563e-02
I0212 10:46:53.031192 22509476222784 run_lib.py:133] step: 586250, training_loss: 5.14526e-02
I0212 10:47:11.582544 22509476222784 run_lib.py:133] step: 586300, training_loss: 4.84691e-02
I0212 10:47:11.743721 22509476222784 run_lib.py:146] step: 586300, eval_loss: 4.21525e-02
I0212 10:47:30.455155 22509476222784 run_lib.py:133] step: 586350, training_loss: 4.55957e-02
I0212 10:47:48.947340 22509476222784 run_lib.py:133] step: 586400, training_loss: 4.61705e-02
I0212 10:47:49.113860 22509476222784 run_lib.py:146] step: 586400, eval_loss: 4.85439e-02
I0212 10:48:07.860594 22509476222784 run_lib.py:133] step: 586450, training_loss: 3.25784e-02
I0212 10:48:26.474040 22509476222784 run_lib.py:133] step: 586500, training_loss: 5.08693e-02
I0212 10:48:26.672932 22509476222784 run_lib.py:146] step: 586500, eval_loss: 4.57073e-02
I0212 10:48:45.221703 22509476222784 run_lib.py:133] step: 586550, training_loss: 5.32558e-02
I0212 10:49:03.954961 22509476222784 run_lib.py:133] step: 586600, training_loss: 4.23798e-02
I0212 10:49:04.119832 22509476222784 run_lib.py:146] step: 586600, eval_loss: 3.50107e-02
I0212 10:49:22.667249 22509476222784 run_lib.py:133] step: 586650, training_loss: 3.45988e-02
I0212 10:49:41.220529 22509476222784 run_lib.py:133] step: 586700, training_loss: 5.01460e-02
I0212 10:49:41.401706 22509476222784 run_lib.py:146] step: 586700, eval_loss: 3.97459e-02
I0212 10:50:00.174183 22509476222784 run_lib.py:133] step: 586750, training_loss: 4.42917e-02
I0212 10:50:18.800285 22509476222784 run_lib.py:133] step: 586800, training_loss: 4.20340e-02
I0212 10:50:18.971911 22509476222784 run_lib.py:146] step: 586800, eval_loss: 4.36395e-02
I0212 10:50:37.773168 22509476222784 run_lib.py:133] step: 586850, training_loss: 3.25795e-02
I0212 10:50:56.401444 22509476222784 run_lib.py:133] step: 586900, training_loss: 4.78346e-02
I0212 10:50:56.568972 22509476222784 run_lib.py:146] step: 586900, eval_loss: 3.73124e-02
I0212 10:51:15.132816 22509476222784 run_lib.py:133] step: 586950, training_loss: 4.15535e-02
I0212 10:51:33.869074 22509476222784 run_lib.py:133] step: 587000, training_loss: 4.36942e-02
I0212 10:51:34.045802 22509476222784 run_lib.py:146] step: 587000, eval_loss: 3.72821e-02
I0212 10:51:52.600598 22509476222784 run_lib.py:133] step: 587050, training_loss: 3.97438e-02
I0212 10:52:11.218091 22509476222784 run_lib.py:133] step: 587100, training_loss: 4.74831e-02
I0212 10:52:11.382469 22509476222784 run_lib.py:146] step: 587100, eval_loss: 4.56374e-02
I0212 10:52:29.972571 22509476222784 run_lib.py:133] step: 587150, training_loss: 3.78818e-02
I0212 10:52:48.768561 22509476222784 run_lib.py:133] step: 587200, training_loss: 4.29706e-02
I0212 10:52:48.931204 22509476222784 run_lib.py:146] step: 587200, eval_loss: 3.58372e-02
I0212 10:53:07.479603 22509476222784 run_lib.py:133] step: 587250, training_loss: 5.01571e-02
I0212 10:53:26.131818 22509476222784 run_lib.py:133] step: 587300, training_loss: 4.43433e-02
I0212 10:53:26.307985 22509476222784 run_lib.py:146] step: 587300, eval_loss: 3.78407e-02
I0212 10:53:44.908512 22509476222784 run_lib.py:133] step: 587350, training_loss: 3.71371e-02
I0212 10:54:03.490729 22509476222784 run_lib.py:133] step: 587400, training_loss: 5.48517e-02
I0212 10:54:03.655719 22509476222784 run_lib.py:146] step: 587400, eval_loss: 3.32978e-02
I0212 10:54:22.392760 22509476222784 run_lib.py:133] step: 587450, training_loss: 3.44434e-02
I0212 10:54:40.994160 22509476222784 run_lib.py:133] step: 587500, training_loss: 3.68022e-02
I0212 10:54:41.158790 22509476222784 run_lib.py:146] step: 587500, eval_loss: 3.74487e-02
I0212 10:54:59.683881 22509476222784 run_lib.py:133] step: 587550, training_loss: 5.36543e-02
I0212 10:55:18.280911 22509476222784 run_lib.py:133] step: 587600, training_loss: 4.68497e-02
I0212 10:55:18.445038 22509476222784 run_lib.py:146] step: 587600, eval_loss: 3.39983e-02
I0212 10:55:37.274150 22509476222784 run_lib.py:133] step: 587650, training_loss: 4.30418e-02
I0212 10:55:55.896754 22509476222784 run_lib.py:133] step: 587700, training_loss: 3.62427e-02
I0212 10:55:56.065838 22509476222784 run_lib.py:146] step: 587700, eval_loss: 4.75873e-02
I0212 10:56:14.767246 22509476222784 run_lib.py:133] step: 587750, training_loss: 5.24507e-02
I0212 10:56:33.346193 22509476222784 run_lib.py:133] step: 587800, training_loss: 4.03856e-02
I0212 10:56:33.526755 22509476222784 run_lib.py:146] step: 587800, eval_loss: 5.07597e-02
I0212 10:56:52.313309 22509476222784 run_lib.py:133] step: 587850, training_loss: 3.71504e-02
I0212 10:57:10.842806 22509476222784 run_lib.py:133] step: 587900, training_loss: 4.64079e-02
I0212 10:57:11.007772 22509476222784 run_lib.py:146] step: 587900, eval_loss: 4.49348e-02
I0212 10:57:29.464504 22509476222784 run_lib.py:133] step: 587950, training_loss: 4.53314e-02
I0212 10:57:48.131799 22509476222784 run_lib.py:133] step: 588000, training_loss: 5.21538e-02
I0212 10:57:48.296491 22509476222784 run_lib.py:146] step: 588000, eval_loss: 4.80811e-02
I0212 10:58:06.847995 22509476222784 run_lib.py:133] step: 588050, training_loss: 5.26759e-02
I0212 10:58:25.641572 22509476222784 run_lib.py:133] step: 588100, training_loss: 4.10812e-02
I0212 10:58:25.840148 22509476222784 run_lib.py:146] step: 588100, eval_loss: 3.96259e-02
I0212 10:58:44.429650 22509476222784 run_lib.py:133] step: 588150, training_loss: 4.51123e-02
I0212 10:59:03.012166 22509476222784 run_lib.py:133] step: 588200, training_loss: 4.11780e-02
I0212 10:59:03.181559 22509476222784 run_lib.py:146] step: 588200, eval_loss: 5.33904e-02
I0212 10:59:21.921779 22509476222784 run_lib.py:133] step: 588250, training_loss: 4.84446e-02
I0212 10:59:40.559174 22509476222784 run_lib.py:133] step: 588300, training_loss: 4.43720e-02
I0212 10:59:40.745899 22509476222784 run_lib.py:146] step: 588300, eval_loss: 6.63973e-02
I0212 10:59:59.291975 22509476222784 run_lib.py:133] step: 588350, training_loss: 3.17046e-02
I0212 11:00:18.016583 22509476222784 run_lib.py:133] step: 588400, training_loss: 4.36822e-02
I0212 11:00:18.181809 22509476222784 run_lib.py:146] step: 588400, eval_loss: 4.97330e-02
I0212 11:00:36.690409 22509476222784 run_lib.py:133] step: 588450, training_loss: 4.65944e-02
I0212 11:00:55.213935 22509476222784 run_lib.py:133] step: 588500, training_loss: 4.67318e-02
I0212 11:00:55.584367 22509476222784 run_lib.py:146] step: 588500, eval_loss: 4.83207e-02
I0212 11:01:14.128068 22509476222784 run_lib.py:133] step: 588550, training_loss: 3.94769e-02
I0212 11:01:32.670483 22509476222784 run_lib.py:133] step: 588600, training_loss: 5.20948e-02
I0212 11:01:32.833474 22509476222784 run_lib.py:146] step: 588600, eval_loss: 3.39086e-02
I0212 11:01:51.415060 22509476222784 run_lib.py:133] step: 588650, training_loss: 4.04264e-02
I0212 11:02:09.890429 22509476222784 run_lib.py:133] step: 588700, training_loss: 3.85168e-02
I0212 11:02:10.052339 22509476222784 run_lib.py:146] step: 588700, eval_loss: 4.28710e-02
I0212 11:02:28.776069 22509476222784 run_lib.py:133] step: 588750, training_loss: 2.91770e-02
I0212 11:02:47.435233 22509476222784 run_lib.py:133] step: 588800, training_loss: 3.68124e-02
I0212 11:02:47.604930 22509476222784 run_lib.py:146] step: 588800, eval_loss: 4.40550e-02
I0212 11:03:06.162223 22509476222784 run_lib.py:133] step: 588850, training_loss: 4.31268e-02
I0212 11:03:24.763906 22509476222784 run_lib.py:133] step: 588900, training_loss: 3.86851e-02
I0212 11:03:24.929031 22509476222784 run_lib.py:146] step: 588900, eval_loss: 4.09184e-02
I0212 11:03:43.633062 22509476222784 run_lib.py:133] step: 588950, training_loss: 4.51729e-02
I0212 11:04:02.246090 22509476222784 run_lib.py:133] step: 589000, training_loss: 5.36232e-02
I0212 11:04:02.410613 22509476222784 run_lib.py:146] step: 589000, eval_loss: 4.92096e-02
I0212 11:04:20.949036 22509476222784 run_lib.py:133] step: 589050, training_loss: 3.65451e-02
I0212 11:04:39.551194 22509476222784 run_lib.py:133] step: 589100, training_loss: 4.05102e-02
I0212 11:04:39.716970 22509476222784 run_lib.py:146] step: 589100, eval_loss: 4.25928e-02
I0212 11:04:58.524546 22509476222784 run_lib.py:133] step: 589150, training_loss: 3.88060e-02
I0212 11:05:17.077548 22509476222784 run_lib.py:133] step: 589200, training_loss: 4.38168e-02
I0212 11:05:17.241565 22509476222784 run_lib.py:146] step: 589200, eval_loss: 5.01022e-02
I0212 11:05:35.879703 22509476222784 run_lib.py:133] step: 589250, training_loss: 4.98692e-02
I0212 11:05:54.337984 22509476222784 run_lib.py:133] step: 589300, training_loss: 4.31593e-02
I0212 11:05:54.502781 22509476222784 run_lib.py:146] step: 589300, eval_loss: 5.44759e-02
I0212 11:06:13.195717 22509476222784 run_lib.py:133] step: 589350, training_loss: 4.73729e-02
I0212 11:06:31.691079 22509476222784 run_lib.py:133] step: 589400, training_loss: 3.41274e-02
I0212 11:06:31.885673 22509476222784 run_lib.py:146] step: 589400, eval_loss: 4.32280e-02
I0212 11:06:50.323795 22509476222784 run_lib.py:133] step: 589450, training_loss: 3.98819e-02
I0212 11:07:09.001533 22509476222784 run_lib.py:133] step: 589500, training_loss: 3.32775e-02
I0212 11:07:09.199565 22509476222784 run_lib.py:146] step: 589500, eval_loss: 4.47844e-02
I0212 11:07:27.662019 22509476222784 run_lib.py:133] step: 589550, training_loss: 5.55890e-02
I0212 11:07:46.347802 22509476222784 run_lib.py:133] step: 589600, training_loss: 4.29950e-02
I0212 11:07:46.515769 22509476222784 run_lib.py:146] step: 589600, eval_loss: 4.20253e-02
I0212 11:08:05.142497 22509476222784 run_lib.py:133] step: 589650, training_loss: 4.04803e-02
I0212 11:08:23.755838 22509476222784 run_lib.py:133] step: 589700, training_loss: 4.46689e-02
I0212 11:08:23.922749 22509476222784 run_lib.py:146] step: 589700, eval_loss: 3.73493e-02
I0212 11:08:42.383008 22509476222784 run_lib.py:133] step: 589750, training_loss: 3.48788e-02
I0212 11:09:01.085556 22509476222784 run_lib.py:133] step: 589800, training_loss: 4.43017e-02
I0212 11:09:01.278630 22509476222784 run_lib.py:146] step: 589800, eval_loss: 3.23239e-02
I0212 11:09:19.718677 22509476222784 run_lib.py:133] step: 589850, training_loss: 5.97680e-02
I0212 11:09:38.329612 22509476222784 run_lib.py:133] step: 589900, training_loss: 5.36333e-02
I0212 11:09:38.515384 22509476222784 run_lib.py:146] step: 589900, eval_loss: 3.80478e-02
I0212 11:09:57.260913 22509476222784 run_lib.py:133] step: 589950, training_loss: 4.78190e-02
I0212 11:10:15.776145 22509476222784 run_lib.py:133] step: 590000, training_loss: 3.48531e-02
I0212 11:10:16.496302 22509476222784 run_lib.py:146] step: 590000, eval_loss: 6.05219e-02
I0212 11:10:37.729246 22509476222784 run_lib.py:133] step: 590050, training_loss: 4.18692e-02
I0212 11:10:56.173333 22509476222784 run_lib.py:133] step: 590100, training_loss: 3.91948e-02
I0212 11:10:56.333579 22509476222784 run_lib.py:146] step: 590100, eval_loss: 4.75445e-02
I0212 11:11:14.890383 22509476222784 run_lib.py:133] step: 590150, training_loss: 2.90085e-02
I0212 11:11:33.599133 22509476222784 run_lib.py:133] step: 590200, training_loss: 5.23146e-02
I0212 11:11:33.830763 22509476222784 run_lib.py:146] step: 590200, eval_loss: 4.52273e-02
I0212 11:11:52.364145 22509476222784 run_lib.py:133] step: 590250, training_loss: 4.28424e-02
I0212 11:12:10.823304 22509476222784 run_lib.py:133] step: 590300, training_loss: 4.44699e-02
I0212 11:12:11.156855 22509476222784 run_lib.py:146] step: 590300, eval_loss: 4.10462e-02
I0212 11:12:29.697072 22509476222784 run_lib.py:133] step: 590350, training_loss: 4.33374e-02
I0212 11:12:48.306799 22509476222784 run_lib.py:133] step: 590400, training_loss: 4.45098e-02
I0212 11:12:48.471889 22509476222784 run_lib.py:146] step: 590400, eval_loss: 4.98465e-02
I0212 11:13:06.924124 22509476222784 run_lib.py:133] step: 590450, training_loss: 4.85485e-02
I0212 11:13:25.409036 22509476222784 run_lib.py:133] step: 590500, training_loss: 3.95685e-02
I0212 11:13:25.604598 22509476222784 run_lib.py:146] step: 590500, eval_loss: 3.65846e-02
I0212 11:13:44.318135 22509476222784 run_lib.py:133] step: 590550, training_loss: 3.86988e-02
I0212 11:14:02.912397 22509476222784 run_lib.py:133] step: 590600, training_loss: 4.79835e-02
I0212 11:14:03.094736 22509476222784 run_lib.py:146] step: 590600, eval_loss: 3.60004e-02
I0212 11:14:21.626247 22509476222784 run_lib.py:133] step: 590650, training_loss: 3.36705e-02
I0212 11:14:40.168360 22509476222784 run_lib.py:133] step: 590700, training_loss: 4.69217e-02
I0212 11:14:40.367412 22509476222784 run_lib.py:146] step: 590700, eval_loss: 4.27419e-02
I0212 11:14:59.065512 22509476222784 run_lib.py:133] step: 590750, training_loss: 3.24112e-02
I0212 11:15:17.667257 22509476222784 run_lib.py:133] step: 590800, training_loss: 4.47508e-02
I0212 11:15:17.864073 22509476222784 run_lib.py:146] step: 590800, eval_loss: 3.25086e-02
I0212 11:15:36.359986 22509476222784 run_lib.py:133] step: 590850, training_loss: 6.14275e-02
I0212 11:15:54.845373 22509476222784 run_lib.py:133] step: 590900, training_loss: 3.62613e-02
I0212 11:15:55.011861 22509476222784 run_lib.py:146] step: 590900, eval_loss: 3.83539e-02
I0212 11:16:13.663029 22509476222784 run_lib.py:133] step: 590950, training_loss: 4.25315e-02
I0212 11:16:32.197392 22509476222784 run_lib.py:133] step: 591000, training_loss: 3.81607e-02
I0212 11:16:32.360919 22509476222784 run_lib.py:146] step: 591000, eval_loss: 4.11207e-02
I0212 11:16:51.034025 22509476222784 run_lib.py:133] step: 591050, training_loss: 3.81929e-02
I0212 11:17:09.584688 22509476222784 run_lib.py:133] step: 591100, training_loss: 3.54278e-02
I0212 11:17:09.744272 22509476222784 run_lib.py:146] step: 591100, eval_loss: 3.43471e-02
I0212 11:17:28.240872 22509476222784 run_lib.py:133] step: 591150, training_loss: 3.06441e-02
I0212 11:17:46.636779 22509476222784 run_lib.py:133] step: 591200, training_loss: 2.80149e-02
I0212 11:17:46.818742 22509476222784 run_lib.py:146] step: 591200, eval_loss: 3.50438e-02
I0212 11:18:05.354490 22509476222784 run_lib.py:133] step: 591250, training_loss: 5.01423e-02
I0212 11:18:24.103095 22509476222784 run_lib.py:133] step: 591300, training_loss: 4.30348e-02
I0212 11:18:24.270996 22509476222784 run_lib.py:146] step: 591300, eval_loss: 5.33219e-02
I0212 11:18:42.789248 22509476222784 run_lib.py:133] step: 591350, training_loss: 3.74684e-02
I0212 11:19:01.410125 22509476222784 run_lib.py:133] step: 591400, training_loss: 3.96685e-02
I0212 11:19:01.572660 22509476222784 run_lib.py:146] step: 591400, eval_loss: 4.70977e-02
I0212 11:19:20.033236 22509476222784 run_lib.py:133] step: 591450, training_loss: 4.20907e-02
I0212 11:19:38.516412 22509476222784 run_lib.py:133] step: 591500, training_loss: 5.02149e-02
I0212 11:19:38.686979 22509476222784 run_lib.py:146] step: 591500, eval_loss: 5.43360e-02
I0212 11:19:57.264676 22509476222784 run_lib.py:133] step: 591550, training_loss: 4.58319e-02
I0212 11:20:16.005083 22509476222784 run_lib.py:133] step: 591600, training_loss: 4.02111e-02
I0212 11:20:16.207741 22509476222784 run_lib.py:146] step: 591600, eval_loss: 5.13748e-02
I0212 11:20:34.670710 22509476222784 run_lib.py:133] step: 591650, training_loss: 3.83651e-02
I0212 11:20:53.147534 22509476222784 run_lib.py:133] step: 591700, training_loss: 3.56977e-02
I0212 11:20:53.314916 22509476222784 run_lib.py:146] step: 591700, eval_loss: 4.68833e-02
I0212 11:21:12.018174 22509476222784 run_lib.py:133] step: 591750, training_loss: 4.33428e-02
I0212 11:21:30.607493 22509476222784 run_lib.py:133] step: 591800, training_loss: 3.64187e-02
I0212 11:21:30.769793 22509476222784 run_lib.py:146] step: 591800, eval_loss: 4.59744e-02
I0212 11:21:49.340554 22509476222784 run_lib.py:133] step: 591850, training_loss: 4.32346e-02
I0212 11:22:07.782036 22509476222784 run_lib.py:133] step: 591900, training_loss: 5.10977e-02
I0212 11:22:07.944525 22509476222784 run_lib.py:146] step: 591900, eval_loss: 4.31006e-02
I0212 11:22:26.445578 22509476222784 run_lib.py:133] step: 591950, training_loss: 3.08065e-02
I0212 11:22:44.946674 22509476222784 run_lib.py:133] step: 592000, training_loss: 4.13063e-02
I0212 11:22:45.109841 22509476222784 run_lib.py:146] step: 592000, eval_loss: 5.73417e-02
I0212 11:23:03.758737 22509476222784 run_lib.py:133] step: 592050, training_loss: 3.44090e-02
I0212 11:23:22.383308 22509476222784 run_lib.py:133] step: 592100, training_loss: 4.03394e-02
I0212 11:23:22.584929 22509476222784 run_lib.py:146] step: 592100, eval_loss: 3.68980e-02
I0212 11:23:41.086628 22509476222784 run_lib.py:133] step: 592150, training_loss: 3.61810e-02
I0212 11:23:59.596009 22509476222784 run_lib.py:133] step: 592200, training_loss: 4.34787e-02
I0212 11:23:59.761068 22509476222784 run_lib.py:146] step: 592200, eval_loss: 3.80340e-02
I0212 11:24:18.346698 22509476222784 run_lib.py:133] step: 592250, training_loss: 3.61788e-02
I0212 11:24:36.938070 22509476222784 run_lib.py:133] step: 592300, training_loss: 4.79197e-02
I0212 11:24:37.103750 22509476222784 run_lib.py:146] step: 592300, eval_loss: 4.56532e-02
I0212 11:24:55.730664 22509476222784 run_lib.py:133] step: 592350, training_loss: 4.54359e-02
I0212 11:25:14.149044 22509476222784 run_lib.py:133] step: 592400, training_loss: 5.67155e-02
I0212 11:25:14.310407 22509476222784 run_lib.py:146] step: 592400, eval_loss: 4.98649e-02
I0212 11:25:32.886107 22509476222784 run_lib.py:133] step: 592450, training_loss: 5.35325e-02
I0212 11:25:51.422538 22509476222784 run_lib.py:133] step: 592500, training_loss: 3.17923e-02
I0212 11:25:51.586835 22509476222784 run_lib.py:146] step: 592500, eval_loss: 4.64629e-02
I0212 11:26:10.345482 22509476222784 run_lib.py:133] step: 592550, training_loss: 5.43110e-02
I0212 11:26:28.837651 22509476222784 run_lib.py:133] step: 592600, training_loss: 4.46754e-02
I0212 11:26:29.002658 22509476222784 run_lib.py:146] step: 592600, eval_loss: 4.35257e-02
I0212 11:26:47.486650 22509476222784 run_lib.py:133] step: 592650, training_loss: 4.98925e-02
I0212 11:27:06.113130 22509476222784 run_lib.py:133] step: 592700, training_loss: 3.63076e-02
I0212 11:27:06.316887 22509476222784 run_lib.py:146] step: 592700, eval_loss: 4.67470e-02
I0212 11:27:24.881817 22509476222784 run_lib.py:133] step: 592750, training_loss: 4.89314e-02
I0212 11:27:43.468060 22509476222784 run_lib.py:133] step: 592800, training_loss: 4.48829e-02
I0212 11:27:43.654026 22509476222784 run_lib.py:146] step: 592800, eval_loss: 3.50120e-02
I0212 11:28:02.346184 22509476222784 run_lib.py:133] step: 592850, training_loss: 3.00220e-02
I0212 11:28:20.988660 22509476222784 run_lib.py:133] step: 592900, training_loss: 3.68385e-02
I0212 11:28:21.152674 22509476222784 run_lib.py:146] step: 592900, eval_loss: 4.30534e-02
I0212 11:28:39.617443 22509476222784 run_lib.py:133] step: 592950, training_loss: 3.71130e-02
I0212 11:28:58.089004 22509476222784 run_lib.py:133] step: 593000, training_loss: 5.69195e-02
I0212 11:28:58.253810 22509476222784 run_lib.py:146] step: 593000, eval_loss: 4.12221e-02
I0212 11:29:16.873955 22509476222784 run_lib.py:133] step: 593050, training_loss: 4.64905e-02
I0212 11:29:35.653945 22509476222784 run_lib.py:133] step: 593100, training_loss: 4.08672e-02
I0212 11:29:35.821662 22509476222784 run_lib.py:146] step: 593100, eval_loss: 3.85105e-02
I0212 11:29:54.328323 22509476222784 run_lib.py:133] step: 593150, training_loss: 5.25316e-02
I0212 11:30:12.804434 22509476222784 run_lib.py:133] step: 593200, training_loss: 3.60732e-02
I0212 11:30:12.993761 22509476222784 run_lib.py:146] step: 593200, eval_loss: 4.10387e-02
I0212 11:30:31.542222 22509476222784 run_lib.py:133] step: 593250, training_loss: 3.84327e-02
I0212 11:30:50.228332 22509476222784 run_lib.py:133] step: 593300, training_loss: 4.64275e-02
I0212 11:30:50.417556 22509476222784 run_lib.py:146] step: 593300, eval_loss: 4.67996e-02
I0212 11:31:08.895604 22509476222784 run_lib.py:133] step: 593350, training_loss: 4.19166e-02
I0212 11:31:27.431296 22509476222784 run_lib.py:133] step: 593400, training_loss: 3.61602e-02
I0212 11:31:27.593520 22509476222784 run_lib.py:146] step: 593400, eval_loss: 4.77292e-02
I0212 11:31:46.040629 22509476222784 run_lib.py:133] step: 593450, training_loss: 3.29148e-02
I0212 11:32:04.556710 22509476222784 run_lib.py:133] step: 593500, training_loss: 4.63813e-02
I0212 11:32:04.810614 22509476222784 run_lib.py:146] step: 593500, eval_loss: 3.25618e-02
I0212 11:32:23.442121 22509476222784 run_lib.py:133] step: 593550, training_loss: 4.38508e-02
I0212 11:32:41.919440 22509476222784 run_lib.py:133] step: 593600, training_loss: 4.21544e-02
I0212 11:32:42.097585 22509476222784 run_lib.py:146] step: 593600, eval_loss: 3.70859e-02
I0212 11:33:00.508180 22509476222784 run_lib.py:133] step: 593650, training_loss: 4.09962e-02
I0212 11:33:19.059190 22509476222784 run_lib.py:133] step: 593700, training_loss: 3.99373e-02
I0212 11:33:19.235008 22509476222784 run_lib.py:146] step: 593700, eval_loss: 5.08371e-02
I0212 11:33:37.896037 22509476222784 run_lib.py:133] step: 593750, training_loss: 4.03607e-02
I0212 11:33:56.251581 22509476222784 run_lib.py:133] step: 593800, training_loss: 4.97865e-02
I0212 11:33:56.440536 22509476222784 run_lib.py:146] step: 593800, eval_loss: 3.81059e-02
I0212 11:34:15.099659 22509476222784 run_lib.py:133] step: 593850, training_loss: 5.25313e-02
I0212 11:34:33.606253 22509476222784 run_lib.py:133] step: 593900, training_loss: 4.30686e-02
I0212 11:34:33.768770 22509476222784 run_lib.py:146] step: 593900, eval_loss: 5.20944e-02
I0212 11:34:52.498870 22509476222784 run_lib.py:133] step: 593950, training_loss: 3.45652e-02
I0212 11:35:11.013657 22509476222784 run_lib.py:133] step: 594000, training_loss: 4.81904e-02
I0212 11:35:11.242577 22509476222784 run_lib.py:146] step: 594000, eval_loss: 3.28360e-02
I0212 11:35:29.680899 22509476222784 run_lib.py:133] step: 594050, training_loss: 3.23470e-02
I0212 11:35:48.272751 22509476222784 run_lib.py:133] step: 594100, training_loss: 3.45953e-02
I0212 11:35:48.439207 22509476222784 run_lib.py:146] step: 594100, eval_loss: 4.06469e-02
I0212 11:36:06.987990 22509476222784 run_lib.py:133] step: 594150, training_loss: 4.67034e-02
I0212 11:36:25.775060 22509476222784 run_lib.py:133] step: 594200, training_loss: 4.05529e-02
I0212 11:36:25.939860 22509476222784 run_lib.py:146] step: 594200, eval_loss: 5.36710e-02
I0212 11:36:44.493192 22509476222784 run_lib.py:133] step: 594250, training_loss: 4.12654e-02
I0212 11:37:03.026813 22509476222784 run_lib.py:133] step: 594300, training_loss: 4.15468e-02
I0212 11:37:03.191785 22509476222784 run_lib.py:146] step: 594300, eval_loss: 5.60591e-02
I0212 11:37:21.874314 22509476222784 run_lib.py:133] step: 594350, training_loss: 4.83444e-02
I0212 11:37:40.492133 22509476222784 run_lib.py:133] step: 594400, training_loss: 3.97959e-02
I0212 11:37:40.665708 22509476222784 run_lib.py:146] step: 594400, eval_loss: 3.88529e-02
I0212 11:37:59.254609 22509476222784 run_lib.py:133] step: 594450, training_loss: 4.37270e-02
I0212 11:38:17.964110 22509476222784 run_lib.py:133] step: 594500, training_loss: 2.71616e-02
I0212 11:38:18.162647 22509476222784 run_lib.py:146] step: 594500, eval_loss: 2.78001e-02
I0212 11:38:36.697227 22509476222784 run_lib.py:133] step: 594550, training_loss: 3.49375e-02
I0212 11:38:55.186975 22509476222784 run_lib.py:133] step: 594600, training_loss: 4.03455e-02
I0212 11:38:55.356993 22509476222784 run_lib.py:146] step: 594600, eval_loss: 4.20211e-02
I0212 11:39:13.964906 22509476222784 run_lib.py:133] step: 594650, training_loss: 4.15132e-02
I0212 11:39:32.607836 22509476222784 run_lib.py:133] step: 594700, training_loss: 4.26248e-02
I0212 11:39:32.771374 22509476222784 run_lib.py:146] step: 594700, eval_loss: 4.91701e-02
I0212 11:39:51.321894 22509476222784 run_lib.py:133] step: 594750, training_loss: 4.98492e-02
I0212 11:40:09.791905 22509476222784 run_lib.py:133] step: 594800, training_loss: 5.82964e-02
I0212 11:40:09.955790 22509476222784 run_lib.py:146] step: 594800, eval_loss: 4.16402e-02
I0212 11:40:28.663095 22509476222784 run_lib.py:133] step: 594850, training_loss: 5.64199e-02
I0212 11:40:47.295703 22509476222784 run_lib.py:133] step: 594900, training_loss: 5.06433e-02
I0212 11:40:47.478618 22509476222784 run_lib.py:146] step: 594900, eval_loss: 4.33251e-02
I0212 11:41:06.083838 22509476222784 run_lib.py:133] step: 594950, training_loss: 4.32081e-02
I0212 11:41:24.620219 22509476222784 run_lib.py:133] step: 595000, training_loss: 3.77844e-02
I0212 11:41:24.786619 22509476222784 run_lib.py:146] step: 595000, eval_loss: 4.67698e-02
I0212 11:41:43.511715 22509476222784 run_lib.py:133] step: 595050, training_loss: 4.20570e-02
I0212 11:42:02.075251 22509476222784 run_lib.py:133] step: 595100, training_loss: 3.69805e-02
I0212 11:42:02.239711 22509476222784 run_lib.py:146] step: 595100, eval_loss: 4.00051e-02
I0212 11:42:20.910179 22509476222784 run_lib.py:133] step: 595150, training_loss: 3.98683e-02
I0212 11:42:39.458322 22509476222784 run_lib.py:133] step: 595200, training_loss: 4.52891e-02
I0212 11:42:39.622790 22509476222784 run_lib.py:146] step: 595200, eval_loss: 3.11348e-02
I0212 11:42:58.350698 22509476222784 run_lib.py:133] step: 595250, training_loss: 4.54499e-02
I0212 11:43:16.955632 22509476222784 run_lib.py:133] step: 595300, training_loss: 4.93607e-02
I0212 11:43:17.137999 22509476222784 run_lib.py:146] step: 595300, eval_loss: 3.60714e-02
I0212 11:43:35.896877 22509476222784 run_lib.py:133] step: 595350, training_loss: 3.34152e-02
I0212 11:43:54.456044 22509476222784 run_lib.py:133] step: 595400, training_loss: 4.03014e-02
I0212 11:43:54.649133 22509476222784 run_lib.py:146] step: 595400, eval_loss: 4.19784e-02
I0212 11:44:13.138484 22509476222784 run_lib.py:133] step: 595450, training_loss: 4.22543e-02
I0212 11:44:31.878853 22509476222784 run_lib.py:133] step: 595500, training_loss: 4.58744e-02
I0212 11:44:32.080674 22509476222784 run_lib.py:146] step: 595500, eval_loss: 3.63489e-02
I0212 11:44:50.631743 22509476222784 run_lib.py:133] step: 595550, training_loss: 3.40057e-02
I0212 11:45:09.198125 22509476222784 run_lib.py:133] step: 595600, training_loss: 3.50085e-02
I0212 11:45:09.362841 22509476222784 run_lib.py:146] step: 595600, eval_loss: 4.07419e-02
I0212 11:45:28.103222 22509476222784 run_lib.py:133] step: 595650, training_loss: 3.74829e-02
I0212 11:45:46.609331 22509476222784 run_lib.py:133] step: 595700, training_loss: 3.63648e-02
I0212 11:45:46.782784 22509476222784 run_lib.py:146] step: 595700, eval_loss: 4.85477e-02
I0212 11:46:05.494228 22509476222784 run_lib.py:133] step: 595750, training_loss: 4.31103e-02
I0212 11:46:24.133512 22509476222784 run_lib.py:133] step: 595800, training_loss: 3.87690e-02
I0212 11:46:24.305781 22509476222784 run_lib.py:146] step: 595800, eval_loss: 5.63157e-02
I0212 11:46:42.915340 22509476222784 run_lib.py:133] step: 595850, training_loss: 4.17122e-02
I0212 11:47:01.701455 22509476222784 run_lib.py:133] step: 595900, training_loss: 4.19676e-02
I0212 11:47:01.898625 22509476222784 run_lib.py:146] step: 595900, eval_loss: 3.68208e-02
I0212 11:47:20.371005 22509476222784 run_lib.py:133] step: 595950, training_loss: 4.56945e-02
I0212 11:47:38.950998 22509476222784 run_lib.py:133] step: 596000, training_loss: 3.95988e-02
I0212 11:47:39.138628 22509476222784 run_lib.py:146] step: 596000, eval_loss: 4.18886e-02
I0212 11:47:57.729170 22509476222784 run_lib.py:133] step: 596050, training_loss: 3.78234e-02
I0212 11:48:16.499153 22509476222784 run_lib.py:133] step: 596100, training_loss: 4.82026e-02
I0212 11:48:16.702703 22509476222784 run_lib.py:146] step: 596100, eval_loss: 4.32251e-02
I0212 11:48:35.174575 22509476222784 run_lib.py:133] step: 596150, training_loss: 3.34736e-02
I0212 11:48:53.759516 22509476222784 run_lib.py:133] step: 596200, training_loss: 4.51667e-02
I0212 11:48:53.970675 22509476222784 run_lib.py:146] step: 596200, eval_loss: 4.73092e-02
I0212 11:49:12.510950 22509476222784 run_lib.py:133] step: 596250, training_loss: 6.03646e-02
I0212 11:49:31.081626 22509476222784 run_lib.py:133] step: 596300, training_loss: 3.93062e-02
I0212 11:49:31.245909 22509476222784 run_lib.py:146] step: 596300, eval_loss: 4.45218e-02
I0212 11:49:50.029192 22509476222784 run_lib.py:133] step: 596350, training_loss: 3.98902e-02
I0212 11:50:08.642000 22509476222784 run_lib.py:133] step: 596400, training_loss: 4.72182e-02
I0212 11:50:08.810440 22509476222784 run_lib.py:146] step: 596400, eval_loss: 4.18648e-02
I0212 11:50:27.315195 22509476222784 run_lib.py:133] step: 596450, training_loss: 4.07529e-02
I0212 11:50:45.788695 22509476222784 run_lib.py:133] step: 596500, training_loss: 3.92490e-02
I0212 11:50:45.952838 22509476222784 run_lib.py:146] step: 596500, eval_loss: 2.86258e-02
I0212 11:51:04.670971 22509476222784 run_lib.py:133] step: 596550, training_loss: 4.17775e-02
I0212 11:51:23.279461 22509476222784 run_lib.py:133] step: 596600, training_loss: 3.96558e-02
I0212 11:51:23.446196 22509476222784 run_lib.py:146] step: 596600, eval_loss: 3.60561e-02
I0212 11:51:42.172705 22509476222784 run_lib.py:133] step: 596650, training_loss: 3.22880e-02
I0212 11:52:00.651014 22509476222784 run_lib.py:133] step: 596700, training_loss: 4.16238e-02
I0212 11:52:00.863790 22509476222784 run_lib.py:146] step: 596700, eval_loss: 4.88272e-02
I0212 11:52:19.525838 22509476222784 run_lib.py:133] step: 596750, training_loss: 4.67656e-02
I0212 11:52:38.037929 22509476222784 run_lib.py:133] step: 596800, training_loss: 3.45702e-02
I0212 11:52:38.225923 22509476222784 run_lib.py:146] step: 596800, eval_loss: 5.17234e-02
I0212 11:52:56.798034 22509476222784 run_lib.py:133] step: 596850, training_loss: 3.52863e-02
I0212 11:53:15.512388 22509476222784 run_lib.py:133] step: 596900, training_loss: 4.06434e-02
I0212 11:53:15.679634 22509476222784 run_lib.py:146] step: 596900, eval_loss: 4.09911e-02
I0212 11:53:34.237844 22509476222784 run_lib.py:133] step: 596950, training_loss: 4.99105e-02
I0212 11:53:52.957597 22509476222784 run_lib.py:133] step: 597000, training_loss: 3.94595e-02
I0212 11:53:53.122773 22509476222784 run_lib.py:146] step: 597000, eval_loss: 4.12372e-02
I0212 11:54:11.685387 22509476222784 run_lib.py:133] step: 597050, training_loss: 5.50352e-02
I0212 11:54:30.257507 22509476222784 run_lib.py:133] step: 597100, training_loss: 4.62997e-02
I0212 11:54:30.423491 22509476222784 run_lib.py:146] step: 597100, eval_loss: 4.42809e-02
I0212 11:54:49.192640 22509476222784 run_lib.py:133] step: 597150, training_loss: 5.65501e-02
I0212 11:55:07.790187 22509476222784 run_lib.py:133] step: 597200, training_loss: 4.17636e-02
I0212 11:55:07.950417 22509476222784 run_lib.py:146] step: 597200, eval_loss: 4.29512e-02
I0212 11:55:26.483552 22509476222784 run_lib.py:133] step: 597250, training_loss: 3.62934e-02
I0212 11:55:45.172538 22509476222784 run_lib.py:133] step: 597300, training_loss: 4.13684e-02
I0212 11:55:45.342731 22509476222784 run_lib.py:146] step: 597300, eval_loss: 3.90028e-02
I0212 11:56:03.877595 22509476222784 run_lib.py:133] step: 597350, training_loss: 3.83242e-02
I0212 11:56:22.503737 22509476222784 run_lib.py:133] step: 597400, training_loss: 4.21247e-02
I0212 11:56:22.859532 22509476222784 run_lib.py:146] step: 597400, eval_loss: 4.51773e-02
I0212 11:56:41.353517 22509476222784 run_lib.py:133] step: 597450, training_loss: 5.70088e-02
I0212 11:56:59.873502 22509476222784 run_lib.py:133] step: 597500, training_loss: 2.97767e-02
I0212 11:57:00.037776 22509476222784 run_lib.py:146] step: 597500, eval_loss: 4.62669e-02
I0212 11:57:18.556570 22509476222784 run_lib.py:133] step: 597550, training_loss: 5.52540e-02
I0212 11:57:37.128166 22509476222784 run_lib.py:133] step: 597600, training_loss: 4.76150e-02
I0212 11:57:37.294854 22509476222784 run_lib.py:146] step: 597600, eval_loss: 2.87603e-02
I0212 11:57:56.009223 22509476222784 run_lib.py:133] step: 597650, training_loss: 4.94515e-02
I0212 11:58:14.594343 22509476222784 run_lib.py:133] step: 597700, training_loss: 4.87229e-02
I0212 11:58:14.754841 22509476222784 run_lib.py:146] step: 597700, eval_loss: 4.25753e-02
I0212 11:58:33.253811 22509476222784 run_lib.py:133] step: 597750, training_loss: 3.85669e-02
I0212 11:58:51.815776 22509476222784 run_lib.py:133] step: 597800, training_loss: 4.08833e-02
I0212 11:58:51.979794 22509476222784 run_lib.py:146] step: 597800, eval_loss: 4.31350e-02
I0212 11:59:10.671722 22509476222784 run_lib.py:133] step: 597850, training_loss: 3.19351e-02
I0212 11:59:29.287154 22509476222784 run_lib.py:133] step: 597900, training_loss: 3.62543e-02
I0212 11:59:29.489609 22509476222784 run_lib.py:146] step: 597900, eval_loss: 3.97934e-02
I0212 11:59:48.043939 22509476222784 run_lib.py:133] step: 597950, training_loss: 4.05039e-02
I0212 12:00:06.624648 22509476222784 run_lib.py:133] step: 598000, training_loss: 4.02282e-02
I0212 12:00:06.799836 22509476222784 run_lib.py:146] step: 598000, eval_loss: 3.30682e-02
I0212 12:00:25.526079 22509476222784 run_lib.py:133] step: 598050, training_loss: 3.58343e-02
I0212 12:00:44.041995 22509476222784 run_lib.py:133] step: 598100, training_loss: 4.73598e-02
I0212 12:00:44.205471 22509476222784 run_lib.py:146] step: 598100, eval_loss: 3.96957e-02
I0212 12:01:02.880959 22509476222784 run_lib.py:133] step: 598150, training_loss: 4.82724e-02
I0212 12:01:21.456924 22509476222784 run_lib.py:133] step: 598200, training_loss: 3.52491e-02
I0212 12:01:21.620859 22509476222784 run_lib.py:146] step: 598200, eval_loss: 3.75960e-02
I0212 12:01:40.393321 22509476222784 run_lib.py:133] step: 598250, training_loss: 4.93081e-02
I0212 12:01:58.891331 22509476222784 run_lib.py:133] step: 598300, training_loss: 3.39579e-02
I0212 12:01:59.059737 22509476222784 run_lib.py:146] step: 598300, eval_loss: 4.72795e-02
I0212 12:02:17.556824 22509476222784 run_lib.py:133] step: 598350, training_loss: 4.11697e-02
I0212 12:02:36.220882 22509476222784 run_lib.py:133] step: 598400, training_loss: 3.59265e-02
I0212 12:02:36.400869 22509476222784 run_lib.py:146] step: 598400, eval_loss: 5.15804e-02
I0212 12:02:54.972167 22509476222784 run_lib.py:133] step: 598450, training_loss: 3.73201e-02
I0212 12:03:13.773268 22509476222784 run_lib.py:133] step: 598500, training_loss: 4.88098e-02
I0212 12:03:13.938129 22509476222784 run_lib.py:146] step: 598500, eval_loss: 4.52633e-02
I0212 12:03:32.432186 22509476222784 run_lib.py:133] step: 598550, training_loss: 3.68499e-02
I0212 12:03:50.983464 22509476222784 run_lib.py:133] step: 598600, training_loss: 4.52027e-02
I0212 12:03:51.171718 22509476222784 run_lib.py:146] step: 598600, eval_loss: 5.42608e-02
I0212 12:04:09.713545 22509476222784 run_lib.py:133] step: 598650, training_loss: 3.54229e-02
I0212 12:04:28.378314 22509476222784 run_lib.py:133] step: 598700, training_loss: 6.45741e-02
I0212 12:04:28.543807 22509476222784 run_lib.py:146] step: 598700, eval_loss: 3.64312e-02
I0212 12:04:47.141574 22509476222784 run_lib.py:133] step: 598750, training_loss: 3.34504e-02
I0212 12:05:05.724417 22509476222784 run_lib.py:133] step: 598800, training_loss: 4.72798e-02
I0212 12:05:05.933691 22509476222784 run_lib.py:146] step: 598800, eval_loss: 5.31667e-02
I0212 12:05:24.675625 22509476222784 run_lib.py:133] step: 598850, training_loss: 4.61981e-02
I0212 12:05:43.198380 22509476222784 run_lib.py:133] step: 598900, training_loss: 3.41716e-02
I0212 12:05:43.362792 22509476222784 run_lib.py:146] step: 598900, eval_loss: 4.62167e-02
I0212 12:06:01.956677 22509476222784 run_lib.py:133] step: 598950, training_loss: 3.45933e-02
I0212 12:06:20.655171 22509476222784 run_lib.py:133] step: 599000, training_loss: 3.45182e-02
I0212 12:06:20.821058 22509476222784 run_lib.py:146] step: 599000, eval_loss: 5.26349e-02
I0212 12:06:39.377265 22509476222784 run_lib.py:133] step: 599050, training_loss: 4.20225e-02
I0212 12:06:57.927090 22509476222784 run_lib.py:133] step: 599100, training_loss: 4.09095e-02
I0212 12:06:58.087764 22509476222784 run_lib.py:146] step: 599100, eval_loss: 3.24369e-02
I0212 12:07:16.776060 22509476222784 run_lib.py:133] step: 599150, training_loss: 3.94269e-02
I0212 12:07:35.466284 22509476222784 run_lib.py:133] step: 599200, training_loss: 4.62171e-02
I0212 12:07:35.630801 22509476222784 run_lib.py:146] step: 599200, eval_loss: 3.14150e-02
I0212 12:07:54.217420 22509476222784 run_lib.py:133] step: 599250, training_loss: 5.51268e-02
I0212 12:08:12.806410 22509476222784 run_lib.py:133] step: 599300, training_loss: 2.81468e-02
I0212 12:08:12.970935 22509476222784 run_lib.py:146] step: 599300, eval_loss: 3.65466e-02
I0212 12:08:31.708814 22509476222784 run_lib.py:133] step: 599350, training_loss: 5.87846e-02
I0212 12:08:50.188457 22509476222784 run_lib.py:133] step: 599400, training_loss: 4.60660e-02
I0212 12:08:50.352524 22509476222784 run_lib.py:146] step: 599400, eval_loss: 4.01615e-02
I0212 12:09:08.959344 22509476222784 run_lib.py:133] step: 599450, training_loss: 4.74400e-02
I0212 12:09:27.510248 22509476222784 run_lib.py:133] step: 599500, training_loss: 4.68475e-02
I0212 12:09:27.703694 22509476222784 run_lib.py:146] step: 599500, eval_loss: 4.68512e-02
I0212 12:09:46.416272 22509476222784 run_lib.py:133] step: 599550, training_loss: 3.40696e-02
I0212 12:10:05.020045 22509476222784 run_lib.py:133] step: 599600, training_loss: 4.69795e-02
I0212 12:10:05.214788 22509476222784 run_lib.py:146] step: 599600, eval_loss: 4.83903e-02
I0212 12:10:23.870070 22509476222784 run_lib.py:133] step: 599650, training_loss: 4.32461e-02
I0212 12:10:42.418870 22509476222784 run_lib.py:133] step: 599700, training_loss: 4.66994e-02
I0212 12:10:42.600711 22509476222784 run_lib.py:146] step: 599700, eval_loss: 4.12331e-02
I0212 12:11:01.092585 22509476222784 run_lib.py:133] step: 599750, training_loss: 4.63328e-02
I0212 12:11:19.848140 22509476222784 run_lib.py:133] step: 599800, training_loss: 4.04419e-02
I0212 12:11:20.030623 22509476222784 run_lib.py:146] step: 599800, eval_loss: 4.46547e-02
I0212 12:11:38.569288 22509476222784 run_lib.py:133] step: 599850, training_loss: 4.79673e-02
I0212 12:11:57.100233 22509476222784 run_lib.py:133] step: 599900, training_loss: 4.19902e-02
I0212 12:11:57.272758 22509476222784 run_lib.py:146] step: 599900, eval_loss: 3.75574e-02
I0212 12:12:15.874690 22509476222784 run_lib.py:133] step: 599950, training_loss: 4.26197e-02
I0212 12:12:34.479163 22509476222784 run_lib.py:133] step: 600000, training_loss: 5.11874e-02
I0212 12:12:35.228578 22509476222784 run_lib.py:146] step: 600000, eval_loss: 4.37077e-02
I0212 12:12:56.384113 22509476222784 run_lib.py:133] step: 600050, training_loss: 3.95876e-02
I0212 12:13:15.001955 22509476222784 run_lib.py:133] step: 600100, training_loss: 2.69536e-02
I0212 12:13:15.210383 22509476222784 run_lib.py:146] step: 600100, eval_loss: 4.80704e-02
I0212 12:13:33.696459 22509476222784 run_lib.py:133] step: 600150, training_loss: 3.22419e-02
I0212 12:13:52.147409 22509476222784 run_lib.py:133] step: 600200, training_loss: 3.98653e-02
I0212 12:13:52.308527 22509476222784 run_lib.py:146] step: 600200, eval_loss: 4.91765e-02
I0212 12:14:10.958955 22509476222784 run_lib.py:133] step: 600250, training_loss: 3.68267e-02
I0212 12:14:29.467324 22509476222784 run_lib.py:133] step: 600300, training_loss: 3.32911e-02
I0212 12:14:29.643563 22509476222784 run_lib.py:146] step: 600300, eval_loss: 4.13699e-02
I0212 12:14:48.173172 22509476222784 run_lib.py:133] step: 600350, training_loss: 4.59609e-02
I0212 12:15:06.734046 22509476222784 run_lib.py:133] step: 600400, training_loss: 4.67700e-02
I0212 12:15:06.903552 22509476222784 run_lib.py:146] step: 600400, eval_loss: 3.11848e-02
I0212 12:15:25.544175 22509476222784 run_lib.py:133] step: 600450, training_loss: 3.72222e-02
I0212 12:15:44.007844 22509476222784 run_lib.py:133] step: 600500, training_loss: 4.41047e-02
I0212 12:15:44.171365 22509476222784 run_lib.py:146] step: 600500, eval_loss: 2.97364e-02
I0212 12:16:02.815820 22509476222784 run_lib.py:133] step: 600550, training_loss: 3.41478e-02
I0212 12:16:21.388428 22509476222784 run_lib.py:133] step: 600600, training_loss: 4.04684e-02
I0212 12:16:21.552448 22509476222784 run_lib.py:146] step: 600600, eval_loss: 4.85457e-02
I0212 12:16:40.334173 22509476222784 run_lib.py:133] step: 600650, training_loss: 4.22988e-02
I0212 12:16:58.872941 22509476222784 run_lib.py:133] step: 600700, training_loss: 3.02421e-02
I0212 12:16:59.058998 22509476222784 run_lib.py:146] step: 600700, eval_loss: 2.53641e-02
I0212 12:17:17.539317 22509476222784 run_lib.py:133] step: 600750, training_loss: 4.40081e-02
I0212 12:17:36.240942 22509476222784 run_lib.py:133] step: 600800, training_loss: 4.86948e-02
I0212 12:17:36.421383 22509476222784 run_lib.py:146] step: 600800, eval_loss: 4.42444e-02
I0212 12:17:55.000545 22509476222784 run_lib.py:133] step: 600850, training_loss: 3.87053e-02
I0212 12:18:13.801592 22509476222784 run_lib.py:133] step: 600900, training_loss: 3.86332e-02
I0212 12:18:13.965817 22509476222784 run_lib.py:146] step: 600900, eval_loss: 3.71766e-02
I0212 12:18:32.513438 22509476222784 run_lib.py:133] step: 600950, training_loss: 3.72360e-02
I0212 12:18:51.059460 22509476222784 run_lib.py:133] step: 601000, training_loss: 4.41868e-02
I0212 12:18:51.223683 22509476222784 run_lib.py:146] step: 601000, eval_loss: 4.21075e-02
I0212 12:19:09.939802 22509476222784 run_lib.py:133] step: 601050, training_loss: 3.64441e-02
I0212 12:19:28.499093 22509476222784 run_lib.py:133] step: 601100, training_loss: 3.65452e-02
I0212 12:19:28.662017 22509476222784 run_lib.py:146] step: 601100, eval_loss: 5.11493e-02
I0212 12:19:47.253025 22509476222784 run_lib.py:133] step: 601150, training_loss: 4.45827e-02
I0212 12:20:05.944196 22509476222784 run_lib.py:133] step: 601200, training_loss: 2.97060e-02
I0212 12:20:06.136749 22509476222784 run_lib.py:146] step: 601200, eval_loss: 4.06671e-02
I0212 12:20:24.670407 22509476222784 run_lib.py:133] step: 601250, training_loss: 3.23479e-02
I0212 12:20:43.193881 22509476222784 run_lib.py:133] step: 601300, training_loss: 4.08527e-02
I0212 12:20:43.372905 22509476222784 run_lib.py:146] step: 601300, eval_loss: 3.88788e-02
I0212 12:21:01.966844 22509476222784 run_lib.py:133] step: 601350, training_loss: 4.95196e-02
I0212 12:21:20.517552 22509476222784 run_lib.py:133] step: 601400, training_loss: 4.45760e-02
I0212 12:21:20.686685 22509476222784 run_lib.py:146] step: 601400, eval_loss: 3.40210e-02
I0212 12:21:39.237251 22509476222784 run_lib.py:133] step: 601450, training_loss: 5.08379e-02
I0212 12:21:57.770667 22509476222784 run_lib.py:133] step: 601500, training_loss: 5.03130e-02
I0212 12:21:57.933900 22509476222784 run_lib.py:146] step: 601500, eval_loss: 5.36015e-02
I0212 12:22:16.650632 22509476222784 run_lib.py:133] step: 601550, training_loss: 4.65162e-02
I0212 12:22:35.229947 22509476222784 run_lib.py:133] step: 601600, training_loss: 4.53425e-02
I0212 12:22:35.393788 22509476222784 run_lib.py:146] step: 601600, eval_loss: 4.45020e-02
I0212 12:22:53.956585 22509476222784 run_lib.py:133] step: 601650, training_loss: 4.96488e-02
I0212 12:23:12.452409 22509476222784 run_lib.py:133] step: 601700, training_loss: 4.52481e-02
I0212 12:23:12.632704 22509476222784 run_lib.py:146] step: 601700, eval_loss: 3.81655e-02
I0212 12:23:31.349344 22509476222784 run_lib.py:133] step: 601750, training_loss: 4.82698e-02
I0212 12:23:49.905828 22509476222784 run_lib.py:133] step: 601800, training_loss: 4.33858e-02
I0212 12:23:50.070930 22509476222784 run_lib.py:146] step: 601800, eval_loss: 3.67288e-02
I0212 12:24:08.754944 22509476222784 run_lib.py:133] step: 601850, training_loss: 3.01381e-02
I0212 12:24:27.328990 22509476222784 run_lib.py:133] step: 601900, training_loss: 4.42943e-02
I0212 12:24:27.494866 22509476222784 run_lib.py:146] step: 601900, eval_loss: 3.35108e-02
I0212 12:24:46.163741 22509476222784 run_lib.py:133] step: 601950, training_loss: 4.36167e-02
I0212 12:25:04.708376 22509476222784 run_lib.py:133] step: 602000, training_loss: 3.86006e-02
I0212 12:25:04.870417 22509476222784 run_lib.py:146] step: 602000, eval_loss: 3.87196e-02
I0212 12:25:23.618328 22509476222784 run_lib.py:133] step: 602050, training_loss: 3.32014e-02
I0212 12:25:42.188229 22509476222784 run_lib.py:133] step: 602100, training_loss: 4.38400e-02
I0212 12:25:42.351671 22509476222784 run_lib.py:146] step: 602100, eval_loss: 5.75172e-02
I0212 12:26:00.886915 22509476222784 run_lib.py:133] step: 602150, training_loss: 4.23931e-02
I0212 12:26:19.585111 22509476222784 run_lib.py:133] step: 602200, training_loss: 4.19911e-02
I0212 12:26:19.754878 22509476222784 run_lib.py:146] step: 602200, eval_loss: 4.05811e-02
I0212 12:26:38.424237 22509476222784 run_lib.py:133] step: 602250, training_loss: 5.46621e-02
I0212 12:26:57.067282 22509476222784 run_lib.py:133] step: 602300, training_loss: 3.67755e-02
I0212 12:26:57.234804 22509476222784 run_lib.py:146] step: 602300, eval_loss: 4.01999e-02
I0212 12:27:15.931039 22509476222784 run_lib.py:133] step: 602350, training_loss: 4.81643e-02
I0212 12:27:34.434846 22509476222784 run_lib.py:133] step: 602400, training_loss: 2.85565e-02
I0212 12:27:34.598987 22509476222784 run_lib.py:146] step: 602400, eval_loss: 4.46711e-02
I0212 12:27:53.295481 22509476222784 run_lib.py:133] step: 602450, training_loss: 4.44163e-02
I0212 12:28:11.911367 22509476222784 run_lib.py:133] step: 602500, training_loss: 5.61635e-02
I0212 12:28:12.076029 22509476222784 run_lib.py:146] step: 602500, eval_loss: 3.61165e-02
I0212 12:28:30.627204 22509476222784 run_lib.py:133] step: 602550, training_loss: 4.66541e-02
I0212 12:28:49.329181 22509476222784 run_lib.py:133] step: 602600, training_loss: 3.75249e-02
I0212 12:28:49.542627 22509476222784 run_lib.py:146] step: 602600, eval_loss: 3.98172e-02
I0212 12:29:08.038285 22509476222784 run_lib.py:133] step: 602650, training_loss: 5.22997e-02
I0212 12:29:26.592055 22509476222784 run_lib.py:133] step: 602700, training_loss: 4.40221e-02
I0212 12:29:26.758984 22509476222784 run_lib.py:146] step: 602700, eval_loss: 4.39275e-02
I0212 12:29:45.244580 22509476222784 run_lib.py:133] step: 602750, training_loss: 3.03808e-02
I0212 12:30:03.953085 22509476222784 run_lib.py:133] step: 602800, training_loss: 3.53066e-02
I0212 12:30:04.123987 22509476222784 run_lib.py:146] step: 602800, eval_loss: 5.26218e-02
I0212 12:30:22.698383 22509476222784 run_lib.py:133] step: 602850, training_loss: 3.83619e-02
I0212 12:30:41.389997 22509476222784 run_lib.py:133] step: 602900, training_loss: 3.59675e-02
I0212 12:30:41.558603 22509476222784 run_lib.py:146] step: 602900, eval_loss: 4.95903e-02
I0212 12:31:00.116087 22509476222784 run_lib.py:133] step: 602950, training_loss: 3.84949e-02
I0212 12:31:18.596902 22509476222784 run_lib.py:133] step: 603000, training_loss: 4.14653e-02
I0212 12:31:18.757651 22509476222784 run_lib.py:146] step: 603000, eval_loss: 3.79607e-02
I0212 12:31:37.514190 22509476222784 run_lib.py:133] step: 603050, training_loss: 3.59658e-02
I0212 12:31:56.187789 22509476222784 run_lib.py:133] step: 603100, training_loss: 4.95511e-02
I0212 12:31:56.355563 22509476222784 run_lib.py:146] step: 603100, eval_loss: 4.45414e-02
I0212 12:32:14.868126 22509476222784 run_lib.py:133] step: 603150, training_loss: 3.37226e-02
I0212 12:32:33.433077 22509476222784 run_lib.py:133] step: 603200, training_loss: 4.75604e-02
I0212 12:32:33.606765 22509476222784 run_lib.py:146] step: 603200, eval_loss: 3.84292e-02
I0212 12:32:52.233233 22509476222784 run_lib.py:133] step: 603250, training_loss: 4.12222e-02
I0212 12:33:10.846207 22509476222784 run_lib.py:133] step: 603300, training_loss: 4.26312e-02
I0212 12:33:11.010873 22509476222784 run_lib.py:146] step: 603300, eval_loss: 3.93347e-02
I0212 12:33:29.696923 22509476222784 run_lib.py:133] step: 603350, training_loss: 4.21073e-02
I0212 12:33:48.247739 22509476222784 run_lib.py:133] step: 603400, training_loss: 4.93840e-02
I0212 12:33:48.410642 22509476222784 run_lib.py:146] step: 603400, eval_loss: 4.29106e-02
I0212 12:34:07.106467 22509476222784 run_lib.py:133] step: 603450, training_loss: 3.74396e-02
I0212 12:34:25.689279 22509476222784 run_lib.py:133] step: 603500, training_loss: 4.53919e-02
I0212 12:34:25.850625 22509476222784 run_lib.py:146] step: 603500, eval_loss: 4.40233e-02
I0212 12:34:44.428229 22509476222784 run_lib.py:133] step: 603550, training_loss: 5.33187e-02
I0212 12:35:03.150186 22509476222784 run_lib.py:133] step: 603600, training_loss: 4.61926e-02
I0212 12:35:03.330321 22509476222784 run_lib.py:146] step: 603600, eval_loss: 4.65914e-02
I0212 12:35:21.877840 22509476222784 run_lib.py:133] step: 603650, training_loss: 4.21586e-02
I0212 12:35:40.596957 22509476222784 run_lib.py:133] step: 603700, training_loss: 4.19879e-02
I0212 12:35:40.761786 22509476222784 run_lib.py:146] step: 603700, eval_loss: 3.45433e-02
I0212 12:35:59.270294 22509476222784 run_lib.py:133] step: 603750, training_loss: 5.13702e-02
I0212 12:36:17.791171 22509476222784 run_lib.py:133] step: 603800, training_loss: 4.48616e-02
I0212 12:36:17.995785 22509476222784 run_lib.py:146] step: 603800, eval_loss: 4.16929e-02
I0212 12:36:36.758926 22509476222784 run_lib.py:133] step: 603850, training_loss: 3.49301e-02
I0212 12:36:55.346005 22509476222784 run_lib.py:133] step: 603900, training_loss: 4.24226e-02
I0212 12:36:55.526082 22509476222784 run_lib.py:146] step: 603900, eval_loss: 4.41975e-02
I0212 12:37:14.057929 22509476222784 run_lib.py:133] step: 603950, training_loss: 5.00754e-02
I0212 12:37:32.734716 22509476222784 run_lib.py:133] step: 604000, training_loss: 4.69635e-02
I0212 12:37:32.897611 22509476222784 run_lib.py:146] step: 604000, eval_loss: 3.72715e-02
I0212 12:37:51.413461 22509476222784 run_lib.py:133] step: 604050, training_loss: 3.51029e-02
I0212 12:38:10.061923 22509476222784 run_lib.py:133] step: 604100, training_loss: 4.20478e-02
I0212 12:38:10.427531 22509476222784 run_lib.py:146] step: 604100, eval_loss: 3.69088e-02
I0212 12:38:28.970628 22509476222784 run_lib.py:133] step: 604150, training_loss: 3.86533e-02
I0212 12:38:47.551573 22509476222784 run_lib.py:133] step: 604200, training_loss: 4.51982e-02
I0212 12:38:47.742652 22509476222784 run_lib.py:146] step: 604200, eval_loss: 4.35492e-02
I0212 12:39:06.285251 22509476222784 run_lib.py:133] step: 604250, training_loss: 4.67587e-02
I0212 12:39:24.816911 22509476222784 run_lib.py:133] step: 604300, training_loss: 3.59775e-02
I0212 12:39:25.007700 22509476222784 run_lib.py:146] step: 604300, eval_loss: 4.35427e-02
I0212 12:39:43.705198 22509476222784 run_lib.py:133] step: 604350, training_loss: 5.46043e-02
I0212 12:40:02.317491 22509476222784 run_lib.py:133] step: 604400, training_loss: 3.99625e-02
I0212 12:40:02.482054 22509476222784 run_lib.py:146] step: 604400, eval_loss: 4.85825e-02
I0212 12:40:21.090313 22509476222784 run_lib.py:133] step: 604450, training_loss: 3.98755e-02
I0212 12:40:39.543989 22509476222784 run_lib.py:133] step: 604500, training_loss: 3.79491e-02
I0212 12:40:39.707635 22509476222784 run_lib.py:146] step: 604500, eval_loss: 3.26042e-02
I0212 12:40:58.365708 22509476222784 run_lib.py:133] step: 604550, training_loss: 3.73954e-02
I0212 12:41:17.036882 22509476222784 run_lib.py:133] step: 604600, training_loss: 4.58061e-02
I0212 12:41:17.217657 22509476222784 run_lib.py:146] step: 604600, eval_loss: 3.71157e-02
I0212 12:41:35.795337 22509476222784 run_lib.py:133] step: 604650, training_loss: 5.24536e-02
I0212 12:41:54.362484 22509476222784 run_lib.py:133] step: 604700, training_loss: 4.23158e-02
I0212 12:41:54.574946 22509476222784 run_lib.py:146] step: 604700, eval_loss: 5.13863e-02
I0212 12:42:13.273557 22509476222784 run_lib.py:133] step: 604750, training_loss: 4.31417e-02
I0212 12:42:31.782995 22509476222784 run_lib.py:133] step: 604800, training_loss: 4.23000e-02
I0212 12:42:31.968706 22509476222784 run_lib.py:146] step: 604800, eval_loss: 3.56139e-02
I0212 12:42:50.619743 22509476222784 run_lib.py:133] step: 604850, training_loss: 4.26075e-02
I0212 12:43:09.108962 22509476222784 run_lib.py:133] step: 604900, training_loss: 5.74239e-02
I0212 12:43:09.273801 22509476222784 run_lib.py:146] step: 604900, eval_loss: 4.62074e-02
I0212 12:43:28.027984 22509476222784 run_lib.py:133] step: 604950, training_loss: 3.80713e-02
I0212 12:43:46.634773 22509476222784 run_lib.py:133] step: 605000, training_loss: 3.76683e-02
I0212 12:43:46.799880 22509476222784 run_lib.py:146] step: 605000, eval_loss: 3.62999e-02
I0212 12:44:05.324582 22509476222784 run_lib.py:133] step: 605050, training_loss: 3.40381e-02
I0212 12:44:24.072024 22509476222784 run_lib.py:133] step: 605100, training_loss: 4.18626e-02
I0212 12:44:24.241093 22509476222784 run_lib.py:146] step: 605100, eval_loss: 4.35760e-02
I0212 12:44:42.808795 22509476222784 run_lib.py:133] step: 605150, training_loss: 4.49410e-02
I0212 12:45:01.633411 22509476222784 run_lib.py:133] step: 605200, training_loss: 3.92604e-02
I0212 12:45:01.802100 22509476222784 run_lib.py:146] step: 605200, eval_loss: 4.23520e-02
I0212 12:45:20.429110 22509476222784 run_lib.py:133] step: 605250, training_loss: 4.77118e-02
I0212 12:45:39.001275 22509476222784 run_lib.py:133] step: 605300, training_loss: 3.96771e-02
I0212 12:45:39.164324 22509476222784 run_lib.py:146] step: 605300, eval_loss: 4.10481e-02
I0212 12:45:57.696556 22509476222784 run_lib.py:133] step: 605350, training_loss: 4.17773e-02
I0212 12:46:16.465992 22509476222784 run_lib.py:133] step: 605400, training_loss: 3.16101e-02
I0212 12:46:16.634871 22509476222784 run_lib.py:146] step: 605400, eval_loss: 3.18308e-02
I0212 12:46:35.230477 22509476222784 run_lib.py:133] step: 605450, training_loss: 5.16014e-02
I0212 12:46:53.836549 22509476222784 run_lib.py:133] step: 605500, training_loss: 4.03557e-02
I0212 12:46:54.003757 22509476222784 run_lib.py:146] step: 605500, eval_loss: 3.72000e-02
I0212 12:47:12.688690 22509476222784 run_lib.py:133] step: 605550, training_loss: 5.14537e-02
I0212 12:47:31.217720 22509476222784 run_lib.py:133] step: 605600, training_loss: 4.94191e-02
I0212 12:47:31.395669 22509476222784 run_lib.py:146] step: 605600, eval_loss: 5.22804e-02
I0212 12:47:50.091581 22509476222784 run_lib.py:133] step: 605650, training_loss: 3.28694e-02
I0212 12:48:08.682074 22509476222784 run_lib.py:133] step: 605700, training_loss: 4.71354e-02
I0212 12:48:08.846530 22509476222784 run_lib.py:146] step: 605700, eval_loss: 3.74844e-02
I0212 12:48:27.338232 22509476222784 run_lib.py:133] step: 605750, training_loss: 3.77585e-02
I0212 12:48:45.836149 22509476222784 run_lib.py:133] step: 605800, training_loss: 3.10409e-02
I0212 12:48:46.032364 22509476222784 run_lib.py:146] step: 605800, eval_loss: 4.88275e-02
I0212 12:49:04.777067 22509476222784 run_lib.py:133] step: 605850, training_loss: 3.97586e-02
I0212 12:49:23.383487 22509476222784 run_lib.py:133] step: 605900, training_loss: 4.34003e-02
I0212 12:49:23.552889 22509476222784 run_lib.py:146] step: 605900, eval_loss: 5.54813e-02
I0212 12:49:42.147961 22509476222784 run_lib.py:133] step: 605950, training_loss: 3.75400e-02
I0212 12:50:00.720383 22509476222784 run_lib.py:133] step: 606000, training_loss: 4.64398e-02
I0212 12:50:00.940608 22509476222784 run_lib.py:146] step: 606000, eval_loss: 3.68582e-02
I0212 12:50:19.701736 22509476222784 run_lib.py:133] step: 606050, training_loss: 3.21353e-02
I0212 12:50:38.244846 22509476222784 run_lib.py:133] step: 606100, training_loss: 3.56820e-02
I0212 12:50:38.408621 22509476222784 run_lib.py:146] step: 606100, eval_loss: 5.51752e-02
I0212 12:50:57.082932 22509476222784 run_lib.py:133] step: 606150, training_loss: 3.70920e-02
I0212 12:51:15.655802 22509476222784 run_lib.py:133] step: 606200, training_loss: 3.36517e-02
I0212 12:51:15.821786 22509476222784 run_lib.py:146] step: 606200, eval_loss: 4.10002e-02
I0212 12:51:34.618353 22509476222784 run_lib.py:133] step: 606250, training_loss: 3.90363e-02
I0212 12:51:53.105923 22509476222784 run_lib.py:133] step: 606300, training_loss: 4.17303e-02
I0212 12:51:53.266763 22509476222784 run_lib.py:146] step: 606300, eval_loss: 3.45641e-02
I0212 12:52:11.934987 22509476222784 run_lib.py:133] step: 606350, training_loss: 4.80916e-02
I0212 12:52:30.525440 22509476222784 run_lib.py:133] step: 606400, training_loss: 4.48247e-02
I0212 12:52:30.689789 22509476222784 run_lib.py:146] step: 606400, eval_loss: 3.52736e-02
I0212 12:52:49.259860 22509476222784 run_lib.py:133] step: 606450, training_loss: 4.58338e-02
I0212 12:53:08.036257 22509476222784 run_lib.py:133] step: 606500, training_loss: 4.14600e-02
I0212 12:53:08.202693 22509476222784 run_lib.py:146] step: 606500, eval_loss: 4.98299e-02
I0212 12:53:26.721491 22509476222784 run_lib.py:133] step: 606550, training_loss: 5.07283e-02
I0212 12:53:45.229121 22509476222784 run_lib.py:133] step: 606600, training_loss: 3.15667e-02
I0212 12:53:45.393714 22509476222784 run_lib.py:146] step: 606600, eval_loss: 4.94003e-02
I0212 12:54:04.111413 22509476222784 run_lib.py:133] step: 606650, training_loss: 4.07389e-02
I0212 12:54:22.684063 22509476222784 run_lib.py:133] step: 606700, training_loss: 3.64252e-02
I0212 12:54:22.853749 22509476222784 run_lib.py:146] step: 606700, eval_loss: 4.42700e-02
I0212 12:54:41.410659 22509476222784 run_lib.py:133] step: 606750, training_loss: 4.38895e-02
I0212 12:54:59.981304 22509476222784 run_lib.py:133] step: 606800, training_loss: 3.60555e-02
I0212 12:55:00.150719 22509476222784 run_lib.py:146] step: 606800, eval_loss: 3.63876e-02
I0212 12:55:18.706967 22509476222784 run_lib.py:133] step: 606850, training_loss: 3.83699e-02
I0212 12:55:37.459920 22509476222784 run_lib.py:133] step: 606900, training_loss: 4.07852e-02
I0212 12:55:37.629845 22509476222784 run_lib.py:146] step: 606900, eval_loss: 5.83409e-02
I0212 12:55:56.090295 22509476222784 run_lib.py:133] step: 606950, training_loss: 4.91010e-02
I0212 12:56:14.647230 22509476222784 run_lib.py:133] step: 607000, training_loss: 4.49288e-02
I0212 12:56:14.839956 22509476222784 run_lib.py:146] step: 607000, eval_loss: 4.51163e-02
I0212 12:56:33.364308 22509476222784 run_lib.py:133] step: 607050, training_loss: 4.65041e-02
I0212 12:56:52.113481 22509476222784 run_lib.py:133] step: 607100, training_loss: 3.48457e-02
I0212 12:56:52.282671 22509476222784 run_lib.py:146] step: 607100, eval_loss: 4.10247e-02
I0212 12:57:10.815768 22509476222784 run_lib.py:133] step: 607150, training_loss: 4.14300e-02
I0212 12:57:29.445204 22509476222784 run_lib.py:133] step: 607200, training_loss: 4.17075e-02
I0212 12:57:29.609617 22509476222784 run_lib.py:146] step: 607200, eval_loss: 3.81362e-02
I0212 12:57:48.175302 22509476222784 run_lib.py:133] step: 607250, training_loss: 4.59099e-02
I0212 12:58:06.773747 22509476222784 run_lib.py:133] step: 607300, training_loss: 4.29277e-02
I0212 12:58:06.943777 22509476222784 run_lib.py:146] step: 607300, eval_loss: 3.81201e-02
I0212 12:58:25.642905 22509476222784 run_lib.py:133] step: 607350, training_loss: 4.23109e-02
I0212 12:58:44.163164 22509476222784 run_lib.py:133] step: 607400, training_loss: 3.45711e-02
I0212 12:58:44.328912 22509476222784 run_lib.py:146] step: 607400, eval_loss: 4.60712e-02
I0212 12:59:02.756611 22509476222784 run_lib.py:133] step: 607450, training_loss: 5.07478e-02
I0212 12:59:21.213708 22509476222784 run_lib.py:133] step: 607500, training_loss: 5.19246e-02
I0212 12:59:21.383885 22509476222784 run_lib.py:146] step: 607500, eval_loss: 4.45819e-02
I0212 12:59:39.905421 22509476222784 run_lib.py:133] step: 607550, training_loss: 4.95213e-02
I0212 12:59:58.362121 22509476222784 run_lib.py:133] step: 607600, training_loss: 4.13375e-02
I0212 12:59:58.527039 22509476222784 run_lib.py:146] step: 607600, eval_loss: 4.35475e-02
I0212 13:00:17.212675 22509476222784 run_lib.py:133] step: 607650, training_loss: 3.57549e-02
I0212 13:00:35.696282 22509476222784 run_lib.py:133] step: 607700, training_loss: 3.41503e-02
I0212 13:00:35.880706 22509476222784 run_lib.py:146] step: 607700, eval_loss: 3.95723e-02
I0212 13:00:54.495728 22509476222784 run_lib.py:133] step: 607750, training_loss: 4.60213e-02
I0212 13:01:12.964376 22509476222784 run_lib.py:133] step: 607800, training_loss: 2.85580e-02
I0212 13:01:13.189907 22509476222784 run_lib.py:146] step: 607800, eval_loss: 3.09804e-02
I0212 13:01:31.759668 22509476222784 run_lib.py:133] step: 607850, training_loss: 5.74967e-02
I0212 13:01:50.503505 22509476222784 run_lib.py:133] step: 607900, training_loss: 4.33262e-02
I0212 13:01:50.677601 22509476222784 run_lib.py:146] step: 607900, eval_loss: 3.87969e-02
I0212 13:02:09.146220 22509476222784 run_lib.py:133] step: 607950, training_loss: 3.16971e-02
I0212 13:02:27.815716 22509476222784 run_lib.py:133] step: 608000, training_loss: 3.63957e-02
I0212 13:02:27.982601 22509476222784 run_lib.py:146] step: 608000, eval_loss: 4.83394e-02
I0212 13:02:46.471060 22509476222784 run_lib.py:133] step: 608050, training_loss: 4.33770e-02
I0212 13:03:05.019792 22509476222784 run_lib.py:133] step: 608100, training_loss: 4.44965e-02
I0212 13:03:05.186757 22509476222784 run_lib.py:146] step: 608100, eval_loss: 4.93554e-02
I0212 13:03:23.858422 22509476222784 run_lib.py:133] step: 608150, training_loss: 2.96489e-02
I0212 13:03:42.317933 22509476222784 run_lib.py:133] step: 608200, training_loss: 4.60403e-02
I0212 13:03:42.477588 22509476222784 run_lib.py:146] step: 608200, eval_loss: 3.05459e-02
I0212 13:04:00.931333 22509476222784 run_lib.py:133] step: 608250, training_loss: 4.75252e-02
I0212 13:04:19.586532 22509476222784 run_lib.py:133] step: 608300, training_loss: 5.46462e-02
I0212 13:04:19.793095 22509476222784 run_lib.py:146] step: 608300, eval_loss: 4.50056e-02
I0212 13:04:38.346904 22509476222784 run_lib.py:133] step: 608350, training_loss: 4.32579e-02
I0212 13:04:56.858960 22509476222784 run_lib.py:133] step: 608400, training_loss: 3.56223e-02
I0212 13:04:57.044852 22509476222784 run_lib.py:146] step: 608400, eval_loss: 4.37964e-02
I0212 13:05:15.664531 22509476222784 run_lib.py:133] step: 608450, training_loss: 4.52964e-02
I0212 13:05:34.097614 22509476222784 run_lib.py:133] step: 608500, training_loss: 4.75117e-02
I0212 13:05:34.261532 22509476222784 run_lib.py:146] step: 608500, eval_loss: 3.93364e-02
I0212 13:05:52.750490 22509476222784 run_lib.py:133] step: 608550, training_loss: 4.65664e-02
I0212 13:06:11.281199 22509476222784 run_lib.py:133] step: 608600, training_loss: 4.15229e-02
I0212 13:06:11.444299 22509476222784 run_lib.py:146] step: 608600, eval_loss: 4.19679e-02
I0212 13:06:30.100140 22509476222784 run_lib.py:133] step: 608650, training_loss: 3.87956e-02
I0212 13:06:48.641805 22509476222784 run_lib.py:133] step: 608700, training_loss: 4.01986e-02
I0212 13:06:48.803659 22509476222784 run_lib.py:146] step: 608700, eval_loss: 4.98922e-02
I0212 13:07:07.261168 22509476222784 run_lib.py:133] step: 608750, training_loss: 3.53348e-02
I0212 13:07:25.761372 22509476222784 run_lib.py:133] step: 608800, training_loss: 4.22512e-02
I0212 13:07:25.927754 22509476222784 run_lib.py:146] step: 608800, eval_loss: 2.40552e-02
I0212 13:07:44.585227 22509476222784 run_lib.py:133] step: 608850, training_loss: 3.34837e-02
I0212 13:08:03.149988 22509476222784 run_lib.py:133] step: 608900, training_loss: 4.65564e-02
I0212 13:08:03.345783 22509476222784 run_lib.py:146] step: 608900, eval_loss: 4.50956e-02
I0212 13:08:22.038859 22509476222784 run_lib.py:133] step: 608950, training_loss: 4.10482e-02
I0212 13:08:40.484001 22509476222784 run_lib.py:133] step: 609000, training_loss: 4.75284e-02
I0212 13:08:40.652678 22509476222784 run_lib.py:146] step: 609000, eval_loss: 4.20685e-02
I0212 13:08:59.277053 22509476222784 run_lib.py:133] step: 609050, training_loss: 3.89624e-02
I0212 13:09:17.796011 22509476222784 run_lib.py:133] step: 609100, training_loss: 4.03163e-02
I0212 13:09:17.956221 22509476222784 run_lib.py:146] step: 609100, eval_loss: 3.33355e-02
I0212 13:09:36.682910 22509476222784 run_lib.py:133] step: 609150, training_loss: 4.62857e-02
I0212 13:09:55.214511 22509476222784 run_lib.py:133] step: 609200, training_loss: 3.66578e-02
I0212 13:09:55.380977 22509476222784 run_lib.py:146] step: 609200, eval_loss: 4.02893e-02
I0212 13:10:13.946916 22509476222784 run_lib.py:133] step: 609250, training_loss: 4.04091e-02
I0212 13:10:32.708935 22509476222784 run_lib.py:133] step: 609300, training_loss: 3.49412e-02
I0212 13:10:32.874904 22509476222784 run_lib.py:146] step: 609300, eval_loss: 4.41754e-02
I0212 13:10:51.370828 22509476222784 run_lib.py:133] step: 609350, training_loss: 3.12534e-02
I0212 13:11:09.914844 22509476222784 run_lib.py:133] step: 609400, training_loss: 3.12016e-02
I0212 13:11:10.091855 22509476222784 run_lib.py:146] step: 609400, eval_loss: 4.05352e-02
I0212 13:11:28.820886 22509476222784 run_lib.py:133] step: 609450, training_loss: 4.04996e-02
I0212 13:11:47.328844 22509476222784 run_lib.py:133] step: 609500, training_loss: 4.24622e-02
I0212 13:11:47.492317 22509476222784 run_lib.py:146] step: 609500, eval_loss: 3.93291e-02
I0212 13:12:06.030236 22509476222784 run_lib.py:133] step: 609550, training_loss: 4.59204e-02
I0212 13:12:24.460204 22509476222784 run_lib.py:133] step: 609600, training_loss: 3.57711e-02
I0212 13:12:24.644284 22509476222784 run_lib.py:146] step: 609600, eval_loss: 4.13291e-02
I0212 13:12:43.130276 22509476222784 run_lib.py:133] step: 609650, training_loss: 4.43345e-02
I0212 13:13:01.832984 22509476222784 run_lib.py:133] step: 609700, training_loss: 3.34390e-02
I0212 13:13:02.027821 22509476222784 run_lib.py:146] step: 609700, eval_loss: 4.36981e-02
I0212 13:13:20.511908 22509476222784 run_lib.py:133] step: 609750, training_loss: 3.94059e-02
I0212 13:13:38.963992 22509476222784 run_lib.py:133] step: 609800, training_loss: 5.67662e-02
I0212 13:13:39.131053 22509476222784 run_lib.py:146] step: 609800, eval_loss: 3.80059e-02
I0212 13:13:57.630373 22509476222784 run_lib.py:133] step: 609850, training_loss: 5.34842e-02
I0212 13:14:16.321466 22509476222784 run_lib.py:133] step: 609900, training_loss: 5.92984e-02
I0212 13:14:16.541161 22509476222784 run_lib.py:146] step: 609900, eval_loss: 3.53462e-02
I0212 13:14:35.085935 22509476222784 run_lib.py:133] step: 609950, training_loss: 3.26942e-02
I0212 13:14:53.687677 22509476222784 run_lib.py:133] step: 610000, training_loss: 4.10866e-02
I0212 13:14:54.453989 22509476222784 run_lib.py:146] step: 610000, eval_loss: 3.77047e-02
I0212 13:15:15.625356 22509476222784 run_lib.py:133] step: 610050, training_loss: 3.38596e-02
I0212 13:15:34.174267 22509476222784 run_lib.py:133] step: 610100, training_loss: 3.39637e-02
I0212 13:15:34.361713 22509476222784 run_lib.py:146] step: 610100, eval_loss: 3.82427e-02
I0212 13:15:53.073306 22509476222784 run_lib.py:133] step: 610150, training_loss: 5.94382e-02
I0212 13:16:11.638856 22509476222784 run_lib.py:133] step: 610200, training_loss: 4.55523e-02
I0212 13:16:11.806862 22509476222784 run_lib.py:146] step: 610200, eval_loss: 4.66885e-02
I0212 13:16:30.483112 22509476222784 run_lib.py:133] step: 610250, training_loss: 3.55496e-02
I0212 13:16:49.124168 22509476222784 run_lib.py:133] step: 610300, training_loss: 4.37145e-02
I0212 13:16:49.291078 22509476222784 run_lib.py:146] step: 610300, eval_loss: 2.70798e-02
I0212 13:17:07.818203 22509476222784 run_lib.py:133] step: 610350, training_loss: 4.21514e-02
I0212 13:17:26.344463 22509476222784 run_lib.py:133] step: 610400, training_loss: 4.26763e-02
I0212 13:17:26.514111 22509476222784 run_lib.py:146] step: 610400, eval_loss: 5.18667e-02
I0212 13:17:45.217824 22509476222784 run_lib.py:133] step: 610450, training_loss: 4.14934e-02
I0212 13:18:03.926399 22509476222784 run_lib.py:133] step: 610500, training_loss: 4.12417e-02
I0212 13:18:04.090854 22509476222784 run_lib.py:146] step: 610500, eval_loss: 6.07313e-02
I0212 13:18:22.592037 22509476222784 run_lib.py:133] step: 610550, training_loss: 5.11131e-02
I0212 13:18:41.105638 22509476222784 run_lib.py:133] step: 610600, training_loss: 3.82095e-02
I0212 13:18:41.289490 22509476222784 run_lib.py:146] step: 610600, eval_loss: 3.71583e-02
I0212 13:18:59.892558 22509476222784 run_lib.py:133] step: 610650, training_loss: 4.34465e-02
I0212 13:19:18.451277 22509476222784 run_lib.py:133] step: 610700, training_loss: 3.97696e-02
I0212 13:19:18.620815 22509476222784 run_lib.py:146] step: 610700, eval_loss: 2.96024e-02
I0212 13:19:37.342182 22509476222784 run_lib.py:133] step: 610750, training_loss: 3.71121e-02
I0212 13:19:55.913116 22509476222784 run_lib.py:133] step: 610800, training_loss: 3.15344e-02
I0212 13:19:56.079725 22509476222784 run_lib.py:146] step: 610800, eval_loss: 3.10963e-02
I0212 13:20:14.817029 22509476222784 run_lib.py:133] step: 610850, training_loss: 4.44169e-02
I0212 13:20:33.426989 22509476222784 run_lib.py:133] step: 610900, training_loss: 4.50491e-02
I0212 13:20:33.591767 22509476222784 run_lib.py:146] step: 610900, eval_loss: 4.24165e-02
I0212 13:20:52.127986 22509476222784 run_lib.py:133] step: 610950, training_loss: 4.27791e-02
I0212 13:21:10.910479 22509476222784 run_lib.py:133] step: 611000, training_loss: 5.06863e-02
I0212 13:21:11.077269 22509476222784 run_lib.py:146] step: 611000, eval_loss: 4.63624e-02
I0212 13:21:29.615563 22509476222784 run_lib.py:133] step: 611050, training_loss: 4.89439e-02
I0212 13:21:48.328131 22509476222784 run_lib.py:133] step: 611100, training_loss: 3.90400e-02
I0212 13:21:48.487509 22509476222784 run_lib.py:146] step: 611100, eval_loss: 3.96627e-02
I0212 13:22:07.003488 22509476222784 run_lib.py:133] step: 611150, training_loss: 4.19795e-02
I0212 13:22:25.545169 22509476222784 run_lib.py:133] step: 611200, training_loss: 5.09819e-02
I0212 13:22:25.712750 22509476222784 run_lib.py:146] step: 611200, eval_loss: 4.45140e-02
I0212 13:22:44.449862 22509476222784 run_lib.py:133] step: 611250, training_loss: 3.61245e-02
I0212 13:23:03.073999 22509476222784 run_lib.py:133] step: 611300, training_loss: 4.35554e-02
I0212 13:23:03.239655 22509476222784 run_lib.py:146] step: 611300, eval_loss: 5.20449e-02
I0212 13:23:21.729111 22509476222784 run_lib.py:133] step: 611350, training_loss: 3.67254e-02
I0212 13:23:40.414948 22509476222784 run_lib.py:133] step: 611400, training_loss: 4.66534e-02
I0212 13:23:40.579629 22509476222784 run_lib.py:146] step: 611400, eval_loss: 4.48662e-02
I0212 13:23:59.100054 22509476222784 run_lib.py:133] step: 611450, training_loss: 3.74392e-02
I0212 13:24:17.618909 22509476222784 run_lib.py:133] step: 611500, training_loss: 3.65427e-02
I0212 13:24:17.975548 22509476222784 run_lib.py:146] step: 611500, eval_loss: 3.82418e-02
I0212 13:24:36.533284 22509476222784 run_lib.py:133] step: 611550, training_loss: 4.53375e-02
I0212 13:24:55.063078 22509476222784 run_lib.py:133] step: 611600, training_loss: 4.12080e-02
I0212 13:24:55.226743 22509476222784 run_lib.py:146] step: 611600, eval_loss: 3.86324e-02
I0212 13:25:13.769583 22509476222784 run_lib.py:133] step: 611650, training_loss: 5.38289e-02
I0212 13:25:32.302513 22509476222784 run_lib.py:133] step: 611700, training_loss: 4.41993e-02
I0212 13:25:32.467480 22509476222784 run_lib.py:146] step: 611700, eval_loss: 3.73325e-02
I0212 13:25:51.109645 22509476222784 run_lib.py:133] step: 611750, training_loss: 4.39043e-02
I0212 13:26:09.774626 22509476222784 run_lib.py:133] step: 611800, training_loss: 4.21774e-02
I0212 13:26:09.994628 22509476222784 run_lib.py:146] step: 611800, eval_loss: 4.29828e-02
I0212 13:26:28.586775 22509476222784 run_lib.py:133] step: 611850, training_loss: 3.64583e-02
I0212 13:26:47.149158 22509476222784 run_lib.py:133] step: 611900, training_loss: 3.23196e-02
I0212 13:26:47.313860 22509476222784 run_lib.py:146] step: 611900, eval_loss: 5.52372e-02
I0212 13:27:06.047792 22509476222784 run_lib.py:133] step: 611950, training_loss: 4.54816e-02
I0212 13:27:24.759319 22509476222784 run_lib.py:133] step: 612000, training_loss: 4.18453e-02
I0212 13:27:24.926021 22509476222784 run_lib.py:146] step: 612000, eval_loss: 3.05886e-02
I0212 13:27:43.553287 22509476222784 run_lib.py:133] step: 612050, training_loss: 4.34269e-02
I0212 13:28:02.188513 22509476222784 run_lib.py:133] step: 612100, training_loss: 4.30883e-02
I0212 13:28:02.350908 22509476222784 run_lib.py:146] step: 612100, eval_loss: 3.60416e-02
I0212 13:28:21.059360 22509476222784 run_lib.py:133] step: 612150, training_loss: 3.96093e-02
I0212 13:28:39.613202 22509476222784 run_lib.py:133] step: 612200, training_loss: 4.28257e-02
I0212 13:28:39.794980 22509476222784 run_lib.py:146] step: 612200, eval_loss: 4.41067e-02
I0212 13:28:58.413838 22509476222784 run_lib.py:133] step: 612250, training_loss: 4.71197e-02
I0212 13:29:16.991855 22509476222784 run_lib.py:133] step: 612300, training_loss: 4.27177e-02
I0212 13:29:17.188791 22509476222784 run_lib.py:146] step: 612300, eval_loss: 3.94970e-02
I0212 13:29:35.907724 22509476222784 run_lib.py:133] step: 612350, training_loss: 4.75889e-02
I0212 13:29:54.446150 22509476222784 run_lib.py:133] step: 612400, training_loss: 4.45304e-02
I0212 13:29:54.610193 22509476222784 run_lib.py:146] step: 612400, eval_loss: 3.97407e-02
I0212 13:30:13.175032 22509476222784 run_lib.py:133] step: 612450, training_loss: 5.48389e-02
I0212 13:30:31.891074 22509476222784 run_lib.py:133] step: 612500, training_loss: 4.96691e-02
I0212 13:30:32.052343 22509476222784 run_lib.py:146] step: 612500, eval_loss: 5.44263e-02
I0212 13:30:50.569790 22509476222784 run_lib.py:133] step: 612550, training_loss: 4.47449e-02
I0212 13:31:09.277428 22509476222784 run_lib.py:133] step: 612600, training_loss: 3.63852e-02
I0212 13:31:09.482846 22509476222784 run_lib.py:146] step: 612600, eval_loss: 5.72850e-02
I0212 13:31:28.047219 22509476222784 run_lib.py:133] step: 612650, training_loss: 4.05048e-02
I0212 13:31:46.622138 22509476222784 run_lib.py:133] step: 612700, training_loss: 4.98833e-02
I0212 13:31:46.788761 22509476222784 run_lib.py:146] step: 612700, eval_loss: 3.62675e-02
I0212 13:32:05.449461 22509476222784 run_lib.py:133] step: 612750, training_loss: 4.19491e-02
I0212 13:32:23.982851 22509476222784 run_lib.py:133] step: 612800, training_loss: 4.75743e-02
I0212 13:32:24.184689 22509476222784 run_lib.py:146] step: 612800, eval_loss: 4.69591e-02
I0212 13:32:42.747637 22509476222784 run_lib.py:133] step: 612850, training_loss: 3.39652e-02
I0212 13:33:01.281246 22509476222784 run_lib.py:133] step: 612900, training_loss: 3.76185e-02
I0212 13:33:01.449454 22509476222784 run_lib.py:146] step: 612900, eval_loss: 3.81558e-02
I0212 13:33:20.157653 22509476222784 run_lib.py:133] step: 612950, training_loss: 4.12228e-02
I0212 13:33:38.672988 22509476222784 run_lib.py:133] step: 613000, training_loss: 4.79644e-02
I0212 13:33:38.861434 22509476222784 run_lib.py:146] step: 613000, eval_loss: 3.65898e-02
I0212 13:33:57.487848 22509476222784 run_lib.py:133] step: 613050, training_loss: 3.94268e-02
I0212 13:34:16.094512 22509476222784 run_lib.py:133] step: 613100, training_loss: 4.60221e-02
I0212 13:34:16.269988 22509476222784 run_lib.py:146] step: 613100, eval_loss: 5.51508e-02
I0212 13:34:34.827208 22509476222784 run_lib.py:133] step: 613150, training_loss: 4.80644e-02
I0212 13:34:53.383063 22509476222784 run_lib.py:133] step: 613200, training_loss: 3.67679e-02
I0212 13:34:53.549968 22509476222784 run_lib.py:146] step: 613200, eval_loss: 5.20361e-02
I0212 13:35:12.239063 22509476222784 run_lib.py:133] step: 613250, training_loss: 5.13336e-02
I0212 13:35:30.798777 22509476222784 run_lib.py:133] step: 613300, training_loss: 4.59307e-02
I0212 13:35:30.968665 22509476222784 run_lib.py:146] step: 613300, eval_loss: 4.21364e-02
I0212 13:35:49.482669 22509476222784 run_lib.py:133] step: 613350, training_loss: 3.80346e-02
I0212 13:36:08.016374 22509476222784 run_lib.py:133] step: 613400, training_loss: 4.58908e-02
I0212 13:36:08.179848 22509476222784 run_lib.py:146] step: 613400, eval_loss: 4.73882e-02
I0212 13:36:26.876975 22509476222784 run_lib.py:133] step: 613450, training_loss: 3.71334e-02
I0212 13:36:45.319973 22509476222784 run_lib.py:133] step: 613500, training_loss: 4.46831e-02
I0212 13:36:45.479315 22509476222784 run_lib.py:146] step: 613500, eval_loss: 4.83467e-02
I0212 13:37:04.065016 22509476222784 run_lib.py:133] step: 613550, training_loss: 3.42977e-02
I0212 13:37:22.623156 22509476222784 run_lib.py:133] step: 613600, training_loss: 4.62548e-02
I0212 13:37:22.806621 22509476222784 run_lib.py:146] step: 613600, eval_loss: 5.25529e-02
I0212 13:37:41.490318 22509476222784 run_lib.py:133] step: 613650, training_loss: 5.33010e-02
I0212 13:37:59.992667 22509476222784 run_lib.py:133] step: 613700, training_loss: 3.70286e-02
I0212 13:38:00.158613 22509476222784 run_lib.py:146] step: 613700, eval_loss: 4.56444e-02
I0212 13:38:18.778495 22509476222784 run_lib.py:133] step: 613750, training_loss: 3.80901e-02
I0212 13:38:37.303005 22509476222784 run_lib.py:133] step: 613800, training_loss: 4.34960e-02
I0212 13:38:37.499657 22509476222784 run_lib.py:146] step: 613800, eval_loss: 4.30709e-02
I0212 13:38:56.025398 22509476222784 run_lib.py:133] step: 613850, training_loss: 4.90199e-02
I0212 13:39:14.717511 22509476222784 run_lib.py:133] step: 613900, training_loss: 3.59881e-02
I0212 13:39:14.879887 22509476222784 run_lib.py:146] step: 613900, eval_loss: 4.29363e-02
I0212 13:39:33.439617 22509476222784 run_lib.py:133] step: 613950, training_loss: 3.87842e-02
I0212 13:39:51.966579 22509476222784 run_lib.py:133] step: 614000, training_loss: 4.54453e-02
I0212 13:39:52.132869 22509476222784 run_lib.py:146] step: 614000, eval_loss: 3.08654e-02
I0212 13:40:10.796649 22509476222784 run_lib.py:133] step: 614050, training_loss: 4.96807e-02
I0212 13:40:29.402204 22509476222784 run_lib.py:133] step: 614100, training_loss: 4.78982e-02
I0212 13:40:29.569607 22509476222784 run_lib.py:146] step: 614100, eval_loss: 4.95097e-02
I0212 13:40:48.065893 22509476222784 run_lib.py:133] step: 614150, training_loss: 5.29274e-02
I0212 13:41:06.627180 22509476222784 run_lib.py:133] step: 614200, training_loss: 3.85406e-02
I0212 13:41:06.816762 22509476222784 run_lib.py:146] step: 614200, eval_loss: 5.00082e-02
I0212 13:41:25.254363 22509476222784 run_lib.py:133] step: 614250, training_loss: 4.13890e-02
I0212 13:41:43.830694 22509476222784 run_lib.py:133] step: 614300, training_loss: 3.71321e-02
I0212 13:41:43.995677 22509476222784 run_lib.py:146] step: 614300, eval_loss: 4.42023e-02
I0212 13:42:02.498749 22509476222784 run_lib.py:133] step: 614350, training_loss: 3.39946e-02
I0212 13:42:21.045847 22509476222784 run_lib.py:133] step: 614400, training_loss: 3.06353e-02
I0212 13:42:21.208081 22509476222784 run_lib.py:146] step: 614400, eval_loss: 4.36127e-02
I0212 13:42:39.755488 22509476222784 run_lib.py:133] step: 614450, training_loss: 3.92726e-02
I0212 13:42:58.387650 22509476222784 run_lib.py:133] step: 614500, training_loss: 3.53758e-02
I0212 13:42:58.548228 22509476222784 run_lib.py:146] step: 614500, eval_loss: 2.98376e-02
I0212 13:43:16.984218 22509476222784 run_lib.py:133] step: 614550, training_loss: 5.17701e-02
I0212 13:43:35.558802 22509476222784 run_lib.py:133] step: 614600, training_loss: 5.21159e-02
I0212 13:43:35.725715 22509476222784 run_lib.py:146] step: 614600, eval_loss: 4.95066e-02
I0212 13:43:54.230051 22509476222784 run_lib.py:133] step: 614650, training_loss: 4.40933e-02
I0212 13:44:12.817630 22509476222784 run_lib.py:133] step: 614700, training_loss: 4.44026e-02
I0212 13:44:12.981984 22509476222784 run_lib.py:146] step: 614700, eval_loss: 3.53426e-02
I0212 13:44:31.583110 22509476222784 run_lib.py:133] step: 614750, training_loss: 4.86284e-02
I0212 13:44:50.148796 22509476222784 run_lib.py:133] step: 614800, training_loss: 4.54607e-02
I0212 13:44:50.312742 22509476222784 run_lib.py:146] step: 614800, eval_loss: 4.15684e-02
I0212 13:45:08.844990 22509476222784 run_lib.py:133] step: 614850, training_loss: 3.64787e-02
I0212 13:45:27.375420 22509476222784 run_lib.py:133] step: 614900, training_loss: 2.93408e-02
I0212 13:45:27.587515 22509476222784 run_lib.py:146] step: 614900, eval_loss: 5.34076e-02
I0212 13:45:46.391190 22509476222784 run_lib.py:133] step: 614950, training_loss: 4.27005e-02
I0212 13:46:04.931631 22509476222784 run_lib.py:133] step: 615000, training_loss: 5.25881e-02
I0212 13:46:05.120596 22509476222784 run_lib.py:146] step: 615000, eval_loss: 3.61482e-02
I0212 13:46:23.763536 22509476222784 run_lib.py:133] step: 615050, training_loss: 3.76242e-02
I0212 13:46:42.259470 22509476222784 run_lib.py:133] step: 615100, training_loss: 4.31905e-02
I0212 13:46:42.465868 22509476222784 run_lib.py:146] step: 615100, eval_loss: 3.91998e-02
I0212 13:47:01.081793 22509476222784 run_lib.py:133] step: 615150, training_loss: 4.20587e-02
I0212 13:47:19.687081 22509476222784 run_lib.py:133] step: 615200, training_loss: 3.95406e-02
I0212 13:47:19.892042 22509476222784 run_lib.py:146] step: 615200, eval_loss: 5.54625e-02
I0212 13:47:38.380476 22509476222784 run_lib.py:133] step: 615250, training_loss: 5.12962e-02
I0212 13:47:57.022906 22509476222784 run_lib.py:133] step: 615300, training_loss: 5.08973e-02
I0212 13:47:57.210603 22509476222784 run_lib.py:146] step: 615300, eval_loss: 4.60783e-02
I0212 13:48:15.729789 22509476222784 run_lib.py:133] step: 615350, training_loss: 4.87481e-02
I0212 13:48:34.355909 22509476222784 run_lib.py:133] step: 615400, training_loss: 4.65698e-02
I0212 13:48:34.526705 22509476222784 run_lib.py:146] step: 615400, eval_loss: 4.82807e-02
I0212 13:48:53.027356 22509476222784 run_lib.py:133] step: 615450, training_loss: 5.36907e-02
I0212 13:49:11.557726 22509476222784 run_lib.py:133] step: 615500, training_loss: 5.23109e-02
I0212 13:49:11.744503 22509476222784 run_lib.py:146] step: 615500, eval_loss: 4.63397e-02
I0212 13:49:30.456824 22509476222784 run_lib.py:133] step: 615550, training_loss: 5.82260e-02
I0212 13:49:48.986497 22509476222784 run_lib.py:133] step: 615600, training_loss: 3.79769e-02
I0212 13:49:49.151707 22509476222784 run_lib.py:146] step: 615600, eval_loss: 5.54323e-02
I0212 13:50:07.622763 22509476222784 run_lib.py:133] step: 615650, training_loss: 4.28704e-02
I0212 13:50:26.256595 22509476222784 run_lib.py:133] step: 615700, training_loss: 4.28796e-02
I0212 13:50:26.446666 22509476222784 run_lib.py:146] step: 615700, eval_loss: 4.33213e-02
I0212 13:50:44.986438 22509476222784 run_lib.py:133] step: 615750, training_loss: 4.01044e-02
I0212 13:51:03.563109 22509476222784 run_lib.py:133] step: 615800, training_loss: 4.07439e-02
I0212 13:51:03.747852 22509476222784 run_lib.py:146] step: 615800, eval_loss: 4.07516e-02
I0212 13:51:22.395297 22509476222784 run_lib.py:133] step: 615850, training_loss: 5.25463e-02
I0212 13:51:40.881767 22509476222784 run_lib.py:133] step: 615900, training_loss: 3.04637e-02
I0212 13:51:41.063678 22509476222784 run_lib.py:146] step: 615900, eval_loss: 4.27457e-02
I0212 13:51:59.601814 22509476222784 run_lib.py:133] step: 615950, training_loss: 4.22892e-02
I0212 13:52:18.129449 22509476222784 run_lib.py:133] step: 616000, training_loss: 3.97385e-02
I0212 13:52:18.325623 22509476222784 run_lib.py:146] step: 616000, eval_loss: 3.87242e-02
I0212 13:52:37.022408 22509476222784 run_lib.py:133] step: 616050, training_loss: 3.24977e-02
I0212 13:52:55.559513 22509476222784 run_lib.py:133] step: 616100, training_loss: 3.66878e-02
I0212 13:52:55.724104 22509476222784 run_lib.py:146] step: 616100, eval_loss: 3.32689e-02
I0212 13:53:14.255881 22509476222784 run_lib.py:133] step: 616150, training_loss: 4.99867e-02
I0212 13:53:32.791938 22509476222784 run_lib.py:133] step: 616200, training_loss: 3.51857e-02
I0212 13:53:32.955862 22509476222784 run_lib.py:146] step: 616200, eval_loss: 4.88533e-02
I0212 13:53:51.589133 22509476222784 run_lib.py:133] step: 616250, training_loss: 3.21846e-02
I0212 13:54:10.174957 22509476222784 run_lib.py:133] step: 616300, training_loss: 5.44001e-02
I0212 13:54:10.337009 22509476222784 run_lib.py:146] step: 616300, eval_loss: 4.14677e-02
I0212 13:54:29.090790 22509476222784 run_lib.py:133] step: 616350, training_loss: 4.42015e-02
I0212 13:54:47.581640 22509476222784 run_lib.py:133] step: 616400, training_loss: 4.15110e-02
I0212 13:54:47.745606 22509476222784 run_lib.py:146] step: 616400, eval_loss: 4.45793e-02
I0212 13:55:06.323332 22509476222784 run_lib.py:133] step: 616450, training_loss: 3.98405e-02
I0212 13:55:24.816606 22509476222784 run_lib.py:133] step: 616500, training_loss: 3.73163e-02
I0212 13:55:24.999758 22509476222784 run_lib.py:146] step: 616500, eval_loss: 4.48939e-02
I0212 13:55:43.740440 22509476222784 run_lib.py:133] step: 616550, training_loss: 4.62432e-02
I0212 13:56:02.255352 22509476222784 run_lib.py:133] step: 616600, training_loss: 4.87546e-02
I0212 13:56:02.419847 22509476222784 run_lib.py:146] step: 616600, eval_loss: 4.29944e-02
I0212 13:56:20.923519 22509476222784 run_lib.py:133] step: 616650, training_loss: 3.89955e-02
I0212 13:56:39.627493 22509476222784 run_lib.py:133] step: 616700, training_loss: 5.39660e-02
I0212 13:56:39.799747 22509476222784 run_lib.py:146] step: 616700, eval_loss: 4.40228e-02
I0212 13:56:58.295893 22509476222784 run_lib.py:133] step: 616750, training_loss: 4.30296e-02
I0212 13:57:16.949939 22509476222784 run_lib.py:133] step: 616800, training_loss: 5.16447e-02
I0212 13:57:17.131652 22509476222784 run_lib.py:146] step: 616800, eval_loss: 4.19039e-02
I0212 13:57:35.921175 22509476222784 run_lib.py:133] step: 616850, training_loss: 3.61308e-02
I0212 13:57:54.475244 22509476222784 run_lib.py:133] step: 616900, training_loss: 3.44287e-02
I0212 13:57:54.641729 22509476222784 run_lib.py:146] step: 616900, eval_loss: 5.38141e-02
I0212 13:58:13.284229 22509476222784 run_lib.py:133] step: 616950, training_loss: 3.90165e-02
I0212 13:58:31.780722 22509476222784 run_lib.py:133] step: 617000, training_loss: 4.73235e-02
I0212 13:58:31.951922 22509476222784 run_lib.py:146] step: 617000, eval_loss: 5.82189e-02
I0212 13:58:50.473722 22509476222784 run_lib.py:133] step: 617050, training_loss: 5.05606e-02
I0212 13:59:09.098682 22509476222784 run_lib.py:133] step: 617100, training_loss: 4.03461e-02
I0212 13:59:09.261778 22509476222784 run_lib.py:146] step: 617100, eval_loss: 4.41370e-02
I0212 13:59:27.695066 22509476222784 run_lib.py:133] step: 617150, training_loss: 3.22629e-02
I0212 13:59:46.191376 22509476222784 run_lib.py:133] step: 617200, training_loss: 4.63826e-02
I0212 13:59:46.372621 22509476222784 run_lib.py:146] step: 617200, eval_loss: 4.98208e-02
I0212 14:00:04.863548 22509476222784 run_lib.py:133] step: 617250, training_loss: 3.60603e-02
I0212 14:00:23.527361 22509476222784 run_lib.py:133] step: 617300, training_loss: 3.32764e-02
I0212 14:00:23.728778 22509476222784 run_lib.py:146] step: 617300, eval_loss: 4.98867e-02
I0212 14:00:42.346434 22509476222784 run_lib.py:133] step: 617350, training_loss: 4.76346e-02
I0212 14:01:00.923542 22509476222784 run_lib.py:133] step: 617400, training_loss: 3.46512e-02
I0212 14:01:01.104571 22509476222784 run_lib.py:146] step: 617400, eval_loss: 4.34106e-02
I0212 14:01:19.586117 22509476222784 run_lib.py:133] step: 617450, training_loss: 4.16330e-02
I0212 14:01:38.155717 22509476222784 run_lib.py:133] step: 617500, training_loss: 4.38226e-02
I0212 14:01:38.358824 22509476222784 run_lib.py:146] step: 617500, eval_loss: 4.97285e-02
I0212 14:01:56.951036 22509476222784 run_lib.py:133] step: 617550, training_loss: 4.95822e-02
I0212 14:02:15.533515 22509476222784 run_lib.py:133] step: 617600, training_loss: 4.10134e-02
I0212 14:02:15.699352 22509476222784 run_lib.py:146] step: 617600, eval_loss: 3.76053e-02
I0212 14:02:34.250682 22509476222784 run_lib.py:133] step: 617650, training_loss: 3.49636e-02
I0212 14:02:52.797465 22509476222784 run_lib.py:133] step: 617700, training_loss: 5.16319e-02
I0212 14:02:52.964889 22509476222784 run_lib.py:146] step: 617700, eval_loss: 4.15973e-02
I0212 14:03:11.676339 22509476222784 run_lib.py:133] step: 617750, training_loss: 5.01501e-02
I0212 14:03:30.116423 22509476222784 run_lib.py:133] step: 617800, training_loss: 3.87184e-02
I0212 14:03:30.277997 22509476222784 run_lib.py:146] step: 617800, eval_loss: 3.59544e-02
I0212 14:03:48.908500 22509476222784 run_lib.py:133] step: 617850, training_loss: 4.18992e-02
I0212 14:04:07.472126 22509476222784 run_lib.py:133] step: 617900, training_loss: 4.17269e-02
I0212 14:04:07.667669 22509476222784 run_lib.py:146] step: 617900, eval_loss: 3.72295e-02
I0212 14:04:26.335266 22509476222784 run_lib.py:133] step: 617950, training_loss: 3.56791e-02
I0212 14:04:44.845231 22509476222784 run_lib.py:133] step: 618000, training_loss: 3.99826e-02
I0212 14:04:45.026749 22509476222784 run_lib.py:146] step: 618000, eval_loss: 4.16340e-02
I0212 14:05:03.525661 22509476222784 run_lib.py:133] step: 618050, training_loss: 4.68819e-02
I0212 14:05:22.072327 22509476222784 run_lib.py:133] step: 618100, training_loss: 3.97114e-02
I0212 14:05:22.239581 22509476222784 run_lib.py:146] step: 618100, eval_loss: 4.99032e-02
I0212 14:05:40.752373 22509476222784 run_lib.py:133] step: 618150, training_loss: 4.45932e-02
I0212 14:05:59.485591 22509476222784 run_lib.py:133] step: 618200, training_loss: 4.95061e-02
I0212 14:05:59.647450 22509476222784 run_lib.py:146] step: 618200, eval_loss: 4.30476e-02
I0212 14:06:18.201201 22509476222784 run_lib.py:133] step: 618250, training_loss: 4.54568e-02
I0212 14:06:36.712247 22509476222784 run_lib.py:133] step: 618300, training_loss: 5.04256e-02
I0212 14:06:36.874471 22509476222784 run_lib.py:146] step: 618300, eval_loss: 4.19622e-02
I0212 14:06:55.515169 22509476222784 run_lib.py:133] step: 618350, training_loss: 5.24954e-02
I0212 14:07:14.039881 22509476222784 run_lib.py:133] step: 618400, training_loss: 3.26765e-02
I0212 14:07:14.235371 22509476222784 run_lib.py:146] step: 618400, eval_loss: 4.34599e-02
I0212 14:07:32.792897 22509476222784 run_lib.py:133] step: 618450, training_loss: 4.23893e-02
I0212 14:07:51.481582 22509476222784 run_lib.py:133] step: 618500, training_loss: 6.20147e-02
I0212 14:07:51.645933 22509476222784 run_lib.py:146] step: 618500, eval_loss: 3.51020e-02
I0212 14:08:10.153713 22509476222784 run_lib.py:133] step: 618550, training_loss: 4.22968e-02
I0212 14:08:28.646065 22509476222784 run_lib.py:133] step: 618600, training_loss: 3.78065e-02
I0212 14:08:28.956053 22509476222784 run_lib.py:146] step: 618600, eval_loss: 4.32326e-02
I0212 14:08:47.443443 22509476222784 run_lib.py:133] step: 618650, training_loss: 4.41627e-02
I0212 14:09:06.004221 22509476222784 run_lib.py:133] step: 618700, training_loss: 3.44653e-02
I0212 14:09:06.202662 22509476222784 run_lib.py:146] step: 618700, eval_loss: 4.47400e-02
I0212 14:09:24.774068 22509476222784 run_lib.py:133] step: 618750, training_loss: 4.22009e-02
I0212 14:09:43.332701 22509476222784 run_lib.py:133] step: 618800, training_loss: 3.26490e-02
I0212 14:09:43.496738 22509476222784 run_lib.py:146] step: 618800, eval_loss: 3.46994e-02
I0212 14:10:02.163136 22509476222784 run_lib.py:133] step: 618850, training_loss: 4.19027e-02
I0212 14:10:20.668572 22509476222784 run_lib.py:133] step: 618900, training_loss: 3.08521e-02
I0212 14:10:20.850016 22509476222784 run_lib.py:146] step: 618900, eval_loss: 4.37312e-02
I0212 14:10:39.362800 22509476222784 run_lib.py:133] step: 618950, training_loss: 4.42969e-02
I0212 14:10:57.880900 22509476222784 run_lib.py:133] step: 619000, training_loss: 3.95485e-02
I0212 14:10:58.045950 22509476222784 run_lib.py:146] step: 619000, eval_loss: 4.45445e-02
I0212 14:11:16.689978 22509476222784 run_lib.py:133] step: 619050, training_loss: 5.11076e-02
I0212 14:11:35.250962 22509476222784 run_lib.py:133] step: 619100, training_loss: 5.04743e-02
I0212 14:11:35.444671 22509476222784 run_lib.py:146] step: 619100, eval_loss: 3.70406e-02
I0212 14:11:53.981113 22509476222784 run_lib.py:133] step: 619150, training_loss: 4.49365e-02
I0212 14:12:12.508190 22509476222784 run_lib.py:133] step: 619200, training_loss: 4.77405e-02
I0212 14:12:12.669790 22509476222784 run_lib.py:146] step: 619200, eval_loss: 4.08050e-02
I0212 14:12:31.391108 22509476222784 run_lib.py:133] step: 619250, training_loss: 3.97733e-02
I0212 14:12:49.951560 22509476222784 run_lib.py:133] step: 619300, training_loss: 3.99265e-02
I0212 14:12:50.149683 22509476222784 run_lib.py:146] step: 619300, eval_loss: 5.31213e-02
I0212 14:13:08.799437 22509476222784 run_lib.py:133] step: 619350, training_loss: 4.31306e-02
I0212 14:13:27.264906 22509476222784 run_lib.py:133] step: 619400, training_loss: 4.47181e-02
I0212 14:13:27.428882 22509476222784 run_lib.py:146] step: 619400, eval_loss: 5.36025e-02
I0212 14:13:46.031093 22509476222784 run_lib.py:133] step: 619450, training_loss: 3.50264e-02
I0212 14:14:04.588007 22509476222784 run_lib.py:133] step: 619500, training_loss: 3.08157e-02
I0212 14:14:04.753440 22509476222784 run_lib.py:146] step: 619500, eval_loss: 3.07399e-02
I0212 14:14:23.227405 22509476222784 run_lib.py:133] step: 619550, training_loss: 4.55693e-02
I0212 14:14:41.897705 22509476222784 run_lib.py:133] step: 619600, training_loss: 3.42456e-02
I0212 14:14:42.060704 22509476222784 run_lib.py:146] step: 619600, eval_loss: 4.30939e-02
I0212 14:15:00.541569 22509476222784 run_lib.py:133] step: 619650, training_loss: 5.29556e-02
I0212 14:15:19.190460 22509476222784 run_lib.py:133] step: 619700, training_loss: 3.41659e-02
I0212 14:15:19.350548 22509476222784 run_lib.py:146] step: 619700, eval_loss: 4.25581e-02
I0212 14:15:37.846911 22509476222784 run_lib.py:133] step: 619750, training_loss: 4.63883e-02
I0212 14:15:56.372300 22509476222784 run_lib.py:133] step: 619800, training_loss: 3.88297e-02
I0212 14:15:56.545614 22509476222784 run_lib.py:146] step: 619800, eval_loss: 4.12838e-02
I0212 14:16:15.039819 22509476222784 run_lib.py:133] step: 619850, training_loss: 3.68950e-02
I0212 14:16:33.762821 22509476222784 run_lib.py:133] step: 619900, training_loss: 4.29447e-02
I0212 14:16:33.956240 22509476222784 run_lib.py:146] step: 619900, eval_loss: 4.09333e-02
I0212 14:16:52.439133 22509476222784 run_lib.py:133] step: 619950, training_loss: 4.29920e-02
I0212 14:17:10.953464 22509476222784 run_lib.py:133] step: 620000, training_loss: 4.79736e-02
I0212 14:17:11.956396 22509476222784 run_lib.py:146] step: 620000, eval_loss: 4.31582e-02
I0212 14:17:33.172935 22509476222784 run_lib.py:133] step: 620050, training_loss: 3.24165e-02
I0212 14:17:51.637952 22509476222784 run_lib.py:133] step: 620100, training_loss: 5.67690e-02
I0212 14:17:51.799571 22509476222784 run_lib.py:146] step: 620100, eval_loss: 3.84985e-02
I0212 14:18:10.235480 22509476222784 run_lib.py:133] step: 620150, training_loss: 4.02942e-02
I0212 14:18:28.930776 22509476222784 run_lib.py:133] step: 620200, training_loss: 3.60437e-02
I0212 14:18:29.117239 22509476222784 run_lib.py:146] step: 620200, eval_loss: 3.42594e-02
I0212 14:18:47.621548 22509476222784 run_lib.py:133] step: 620250, training_loss: 4.15784e-02
I0212 14:19:06.122728 22509476222784 run_lib.py:133] step: 620300, training_loss: 3.66199e-02
I0212 14:19:06.295729 22509476222784 run_lib.py:146] step: 620300, eval_loss: 4.92802e-02
I0212 14:19:24.876384 22509476222784 run_lib.py:133] step: 620350, training_loss: 3.85825e-02
I0212 14:19:43.583219 22509476222784 run_lib.py:133] step: 620400, training_loss: 4.42980e-02
I0212 14:19:43.746681 22509476222784 run_lib.py:146] step: 620400, eval_loss: 3.27360e-02
I0212 14:20:02.237138 22509476222784 run_lib.py:133] step: 620450, training_loss: 4.68145e-02
I0212 14:20:20.823722 22509476222784 run_lib.py:133] step: 620500, training_loss: 3.43303e-02
I0212 14:20:20.990949 22509476222784 run_lib.py:146] step: 620500, eval_loss: 5.12814e-02
I0212 14:20:39.420571 22509476222784 run_lib.py:133] step: 620550, training_loss: 3.75159e-02
I0212 14:20:57.944176 22509476222784 run_lib.py:133] step: 620600, training_loss: 4.22239e-02
I0212 14:20:58.109085 22509476222784 run_lib.py:146] step: 620600, eval_loss: 4.17068e-02
I0212 14:21:16.857873 22509476222784 run_lib.py:133] step: 620650, training_loss: 4.32311e-02
I0212 14:21:35.513859 22509476222784 run_lib.py:133] step: 620700, training_loss: 4.71539e-02
I0212 14:21:35.810656 22509476222784 run_lib.py:146] step: 620700, eval_loss: 3.87805e-02
I0212 14:21:54.305795 22509476222784 run_lib.py:133] step: 620750, training_loss: 5.05550e-02
I0212 14:22:12.773635 22509476222784 run_lib.py:133] step: 620800, training_loss: 3.66739e-02
I0212 14:22:12.954935 22509476222784 run_lib.py:146] step: 620800, eval_loss: 4.97186e-02
I0212 14:22:31.687794 22509476222784 run_lib.py:133] step: 620850, training_loss: 2.59980e-02
I0212 14:22:50.271317 22509476222784 run_lib.py:133] step: 620900, training_loss: 3.85240e-02
I0212 14:22:50.436667 22509476222784 run_lib.py:146] step: 620900, eval_loss: 4.72664e-02
I0212 14:23:09.035684 22509476222784 run_lib.py:133] step: 620950, training_loss: 3.90377e-02
I0212 14:23:27.512903 22509476222784 run_lib.py:133] step: 621000, training_loss: 4.56817e-02
I0212 14:23:27.677934 22509476222784 run_lib.py:146] step: 621000, eval_loss: 4.81733e-02
I0212 14:23:46.220523 22509476222784 run_lib.py:133] step: 621050, training_loss: 5.20823e-02
I0212 14:24:04.750806 22509476222784 run_lib.py:133] step: 621100, training_loss: 4.66973e-02
I0212 14:24:04.914006 22509476222784 run_lib.py:146] step: 621100, eval_loss: 4.29624e-02
I0212 14:24:23.505644 22509476222784 run_lib.py:133] step: 621150, training_loss: 4.68045e-02
I0212 14:24:42.133750 22509476222784 run_lib.py:133] step: 621200, training_loss: 3.86189e-02
I0212 14:24:42.295599 22509476222784 run_lib.py:146] step: 621200, eval_loss: 3.42050e-02
I0212 14:25:00.678876 22509476222784 run_lib.py:133] step: 621250, training_loss: 3.13254e-02
I0212 14:25:19.152605 22509476222784 run_lib.py:133] step: 621300, training_loss: 4.21724e-02
I0212 14:25:19.317862 22509476222784 run_lib.py:146] step: 621300, eval_loss: 4.26150e-02
I0212 14:25:37.854494 22509476222784 run_lib.py:133] step: 621350, training_loss: 4.20075e-02
I0212 14:25:56.474988 22509476222784 run_lib.py:133] step: 621400, training_loss: 3.81331e-02
I0212 14:25:56.639995 22509476222784 run_lib.py:146] step: 621400, eval_loss: 4.35845e-02
I0212 14:26:15.323418 22509476222784 run_lib.py:133] step: 621450, training_loss: 4.79131e-02
I0212 14:26:33.742703 22509476222784 run_lib.py:133] step: 621500, training_loss: 3.51337e-02
I0212 14:26:33.905264 22509476222784 run_lib.py:146] step: 621500, eval_loss: 4.77690e-02
I0212 14:26:52.263267 22509476222784 run_lib.py:133] step: 621550, training_loss: 4.23423e-02
I0212 14:27:10.770027 22509476222784 run_lib.py:133] step: 621600, training_loss: 5.19038e-02
I0212 14:27:10.932291 22509476222784 run_lib.py:146] step: 621600, eval_loss: 3.53871e-02
I0212 14:27:29.561108 22509476222784 run_lib.py:133] step: 621650, training_loss: 4.38617e-02
I0212 14:27:48.084842 22509476222784 run_lib.py:133] step: 621700, training_loss: 4.71258e-02
I0212 14:27:48.258540 22509476222784 run_lib.py:146] step: 621700, eval_loss: 2.98270e-02
I0212 14:28:06.830017 22509476222784 run_lib.py:133] step: 621750, training_loss: 4.39284e-02
I0212 14:28:25.328050 22509476222784 run_lib.py:133] step: 621800, training_loss: 4.78955e-02
I0212 14:28:25.528825 22509476222784 run_lib.py:146] step: 621800, eval_loss: 4.11383e-02
I0212 14:28:43.982454 22509476222784 run_lib.py:133] step: 621850, training_loss: 4.37748e-02
I0212 14:29:02.558838 22509476222784 run_lib.py:133] step: 621900, training_loss: 4.23805e-02
I0212 14:29:02.722995 22509476222784 run_lib.py:146] step: 621900, eval_loss: 4.47370e-02
I0212 14:29:21.412200 22509476222784 run_lib.py:133] step: 621950, training_loss: 4.15244e-02
I0212 14:29:39.987534 22509476222784 run_lib.py:133] step: 622000, training_loss: 5.38142e-02
I0212 14:29:40.150422 22509476222784 run_lib.py:146] step: 622000, eval_loss: 3.37266e-02
I0212 14:29:58.621093 22509476222784 run_lib.py:133] step: 622050, training_loss: 4.70479e-02
I0212 14:30:17.127136 22509476222784 run_lib.py:133] step: 622100, training_loss: 4.14533e-02
I0212 14:30:17.287811 22509476222784 run_lib.py:146] step: 622100, eval_loss: 3.83325e-02
I0212 14:30:35.959285 22509476222784 run_lib.py:133] step: 622150, training_loss: 3.00098e-02
I0212 14:30:54.548175 22509476222784 run_lib.py:133] step: 622200, training_loss: 4.73316e-02
I0212 14:30:54.715427 22509476222784 run_lib.py:146] step: 622200, eval_loss: 3.72030e-02
I0212 14:31:13.432628 22509476222784 run_lib.py:133] step: 622250, training_loss: 5.90107e-02
I0212 14:31:31.957205 22509476222784 run_lib.py:133] step: 622300, training_loss: 3.36323e-02
I0212 14:31:32.123958 22509476222784 run_lib.py:146] step: 622300, eval_loss: 5.35453e-02
I0212 14:31:50.665215 22509476222784 run_lib.py:133] step: 622350, training_loss: 4.21238e-02
I0212 14:32:09.127215 22509476222784 run_lib.py:133] step: 622400, training_loss: 4.24923e-02
I0212 14:32:09.299772 22509476222784 run_lib.py:146] step: 622400, eval_loss: 3.82832e-02
I0212 14:32:28.008530 22509476222784 run_lib.py:133] step: 622450, training_loss: 5.65766e-02
I0212 14:32:46.569642 22509476222784 run_lib.py:133] step: 622500, training_loss: 6.49603e-02
I0212 14:32:46.731227 22509476222784 run_lib.py:146] step: 622500, eval_loss: 5.26976e-02
I0212 14:33:05.222449 22509476222784 run_lib.py:133] step: 622550, training_loss: 4.09108e-02
I0212 14:33:23.924568 22509476222784 run_lib.py:133] step: 622600, training_loss: 4.57162e-02
I0212 14:33:24.085665 22509476222784 run_lib.py:146] step: 622600, eval_loss: 4.32509e-02
I0212 14:33:42.583917 22509476222784 run_lib.py:133] step: 622650, training_loss: 4.69577e-02
I0212 14:34:01.088810 22509476222784 run_lib.py:133] step: 622700, training_loss: 4.06967e-02
I0212 14:34:01.299775 22509476222784 run_lib.py:146] step: 622700, eval_loss: 2.96405e-02
I0212 14:34:19.978278 22509476222784 run_lib.py:133] step: 622750, training_loss: 3.69658e-02
I0212 14:34:38.508061 22509476222784 run_lib.py:133] step: 622800, training_loss: 3.85116e-02
I0212 14:34:38.672701 22509476222784 run_lib.py:146] step: 622800, eval_loss: 3.26898e-02
I0212 14:34:57.344154 22509476222784 run_lib.py:133] step: 622850, training_loss: 5.36428e-02
I0212 14:35:15.838768 22509476222784 run_lib.py:133] step: 622900, training_loss: 3.46013e-02
I0212 14:35:16.003895 22509476222784 run_lib.py:146] step: 622900, eval_loss: 3.74154e-02
I0212 14:35:34.425980 22509476222784 run_lib.py:133] step: 622950, training_loss: 2.85048e-02
I0212 14:35:53.122392 22509476222784 run_lib.py:133] step: 623000, training_loss: 3.71262e-02
I0212 14:35:53.286445 22509476222784 run_lib.py:146] step: 623000, eval_loss: 4.68973e-02
I0212 14:36:11.867980 22509476222784 run_lib.py:133] step: 623050, training_loss: 4.24631e-02
I0212 14:36:30.354590 22509476222784 run_lib.py:133] step: 623100, training_loss: 4.09168e-02
I0212 14:36:30.535718 22509476222784 run_lib.py:146] step: 623100, eval_loss: 3.29700e-02
I0212 14:36:49.025808 22509476222784 run_lib.py:133] step: 623150, training_loss: 4.38483e-02
I0212 14:37:07.722348 22509476222784 run_lib.py:133] step: 623200, training_loss: 3.58105e-02
I0212 14:37:07.887971 22509476222784 run_lib.py:146] step: 623200, eval_loss: 3.78487e-02
I0212 14:37:26.435781 22509476222784 run_lib.py:133] step: 623250, training_loss: 3.65986e-02
I0212 14:37:45.014045 22509476222784 run_lib.py:133] step: 623300, training_loss: 3.15438e-02
I0212 14:37:45.177899 22509476222784 run_lib.py:146] step: 623300, eval_loss: 3.65687e-02
I0212 14:38:03.679965 22509476222784 run_lib.py:133] step: 623350, training_loss: 4.10035e-02
I0212 14:38:22.315128 22509476222784 run_lib.py:133] step: 623400, training_loss: 3.53120e-02
I0212 14:38:22.479879 22509476222784 run_lib.py:146] step: 623400, eval_loss: 4.11546e-02
I0212 14:38:41.166412 22509476222784 run_lib.py:133] step: 623450, training_loss: 3.95442e-02
I0212 14:38:59.835617 22509476222784 run_lib.py:133] step: 623500, training_loss: 3.68835e-02
I0212 14:38:59.998962 22509476222784 run_lib.py:146] step: 623500, eval_loss: 3.98053e-02
I0212 14:39:18.579275 22509476222784 run_lib.py:133] step: 623550, training_loss: 4.70569e-02
I0212 14:39:37.036895 22509476222784 run_lib.py:133] step: 623600, training_loss: 3.61718e-02
I0212 14:39:37.201639 22509476222784 run_lib.py:146] step: 623600, eval_loss: 3.98875e-02
I0212 14:39:55.827496 22509476222784 run_lib.py:133] step: 623650, training_loss: 4.12194e-02
I0212 14:40:14.268350 22509476222784 run_lib.py:133] step: 623700, training_loss: 3.64151e-02
I0212 14:40:14.434962 22509476222784 run_lib.py:146] step: 623700, eval_loss: 3.48627e-02
I0212 14:40:33.168398 22509476222784 run_lib.py:133] step: 623750, training_loss: 3.82039e-02
I0212 14:40:51.812975 22509476222784 run_lib.py:133] step: 623800, training_loss: 5.29452e-02
I0212 14:40:51.979085 22509476222784 run_lib.py:146] step: 623800, eval_loss: 4.06899e-02
I0212 14:41:10.703850 22509476222784 run_lib.py:133] step: 623850, training_loss: 3.61948e-02
I0212 14:41:29.216137 22509476222784 run_lib.py:133] step: 623900, training_loss: 4.40022e-02
I0212 14:41:29.378254 22509476222784 run_lib.py:146] step: 623900, eval_loss: 6.25267e-02
I0212 14:41:47.894912 22509476222784 run_lib.py:133] step: 623950, training_loss: 4.61138e-02
I0212 14:42:06.594080 22509476222784 run_lib.py:133] step: 624000, training_loss: 3.08117e-02
I0212 14:42:06.757115 22509476222784 run_lib.py:146] step: 624000, eval_loss: 3.64521e-02
I0212 14:42:25.410469 22509476222784 run_lib.py:133] step: 624050, training_loss: 4.57273e-02
I0212 14:42:44.201171 22509476222784 run_lib.py:133] step: 624100, training_loss: 4.77431e-02
I0212 14:42:44.367755 22509476222784 run_lib.py:146] step: 624100, eval_loss: 2.94401e-02
I0212 14:43:02.909294 22509476222784 run_lib.py:133] step: 624150, training_loss: 4.77043e-02
I0212 14:43:21.389538 22509476222784 run_lib.py:133] step: 624200, training_loss: 3.32163e-02
I0212 14:43:21.556084 22509476222784 run_lib.py:146] step: 624200, eval_loss: 4.09710e-02
I0212 14:43:40.192800 22509476222784 run_lib.py:133] step: 624250, training_loss: 4.17588e-02
I0212 14:43:58.757819 22509476222784 run_lib.py:133] step: 624300, training_loss: 3.77766e-02
I0212 14:43:58.928637 22509476222784 run_lib.py:146] step: 624300, eval_loss: 4.28415e-02
I0212 14:44:17.480949 22509476222784 run_lib.py:133] step: 624350, training_loss: 4.34547e-02
I0212 14:44:36.235949 22509476222784 run_lib.py:133] step: 624400, training_loss: 3.63007e-02
I0212 14:44:36.445736 22509476222784 run_lib.py:146] step: 624400, eval_loss: 5.10615e-02
I0212 14:44:55.021606 22509476222784 run_lib.py:133] step: 624450, training_loss: 4.68589e-02
I0212 14:45:13.579634 22509476222784 run_lib.py:133] step: 624500, training_loss: 3.35642e-02
I0212 14:45:13.940599 22509476222784 run_lib.py:146] step: 624500, eval_loss: 4.79159e-02
I0212 14:45:32.467774 22509476222784 run_lib.py:133] step: 624550, training_loss: 4.22132e-02
I0212 14:45:51.021305 22509476222784 run_lib.py:133] step: 624600, training_loss: 5.12070e-02
I0212 14:45:51.202680 22509476222784 run_lib.py:146] step: 624600, eval_loss: 4.20574e-02
I0212 14:46:09.704188 22509476222784 run_lib.py:133] step: 624650, training_loss: 3.42194e-02
I0212 14:46:28.271924 22509476222784 run_lib.py:133] step: 624700, training_loss: 3.97835e-02
I0212 14:46:28.475867 22509476222784 run_lib.py:146] step: 624700, eval_loss: 4.13176e-02
I0212 14:46:47.189697 22509476222784 run_lib.py:133] step: 624750, training_loss: 3.24937e-02
I0212 14:47:05.812670 22509476222784 run_lib.py:133] step: 624800, training_loss: 3.71267e-02
I0212 14:47:05.976428 22509476222784 run_lib.py:146] step: 624800, eval_loss: 3.57171e-02
I0212 14:47:24.471975 22509476222784 run_lib.py:133] step: 624850, training_loss: 4.14446e-02
I0212 14:47:42.988582 22509476222784 run_lib.py:133] step: 624900, training_loss: 4.00956e-02
I0212 14:47:43.152545 22509476222784 run_lib.py:146] step: 624900, eval_loss: 4.32353e-02
I0212 14:48:01.929482 22509476222784 run_lib.py:133] step: 624950, training_loss: 5.32853e-02
I0212 14:48:20.584856 22509476222784 run_lib.py:133] step: 625000, training_loss: 4.43083e-02
I0212 14:48:20.750685 22509476222784 run_lib.py:146] step: 625000, eval_loss: 4.45978e-02
I0212 14:48:39.308889 22509476222784 run_lib.py:133] step: 625050, training_loss: 5.66318e-02
I0212 14:48:57.866125 22509476222784 run_lib.py:133] step: 625100, training_loss: 3.99053e-02
I0212 14:48:58.048606 22509476222784 run_lib.py:146] step: 625100, eval_loss: 3.62698e-02
I0212 14:49:16.779307 22509476222784 run_lib.py:133] step: 625150, training_loss: 4.23624e-02
I0212 14:49:35.319709 22509476222784 run_lib.py:133] step: 625200, training_loss: 3.45162e-02
I0212 14:49:35.486001 22509476222784 run_lib.py:146] step: 625200, eval_loss: 3.43814e-02
I0212 14:49:54.113739 22509476222784 run_lib.py:133] step: 625250, training_loss: 2.54404e-02
I0212 14:50:12.625905 22509476222784 run_lib.py:133] step: 625300, training_loss: 3.81040e-02
I0212 14:50:12.829388 22509476222784 run_lib.py:146] step: 625300, eval_loss: 4.94728e-02
I0212 14:50:31.529978 22509476222784 run_lib.py:133] step: 625350, training_loss: 3.52092e-02
I0212 14:50:50.095082 22509476222784 run_lib.py:133] step: 625400, training_loss: 5.05608e-02
I0212 14:50:50.306380 22509476222784 run_lib.py:146] step: 625400, eval_loss: 5.04735e-02
I0212 14:51:08.840841 22509476222784 run_lib.py:133] step: 625450, training_loss: 3.30927e-02
I0212 14:51:27.539129 22509476222784 run_lib.py:133] step: 625500, training_loss: 4.32225e-02
I0212 14:51:27.771842 22509476222784 run_lib.py:146] step: 625500, eval_loss: 3.05811e-02
I0212 14:51:46.308880 22509476222784 run_lib.py:133] step: 625550, training_loss: 4.38590e-02
I0212 14:52:04.985167 22509476222784 run_lib.py:133] step: 625600, training_loss: 3.65056e-02
I0212 14:52:05.157904 22509476222784 run_lib.py:146] step: 625600, eval_loss: 4.86054e-02
I0212 14:52:23.677762 22509476222784 run_lib.py:133] step: 625650, training_loss: 4.51682e-02
I0212 14:52:42.278008 22509476222784 run_lib.py:133] step: 625700, training_loss: 3.74648e-02
I0212 14:52:42.443948 22509476222784 run_lib.py:146] step: 625700, eval_loss: 4.61449e-02
I0212 14:53:01.125036 22509476222784 run_lib.py:133] step: 625750, training_loss: 5.74080e-02
I0212 14:53:19.604902 22509476222784 run_lib.py:133] step: 625800, training_loss: 3.10667e-02
I0212 14:53:19.774791 22509476222784 run_lib.py:146] step: 625800, eval_loss: 4.52096e-02
I0212 14:53:38.333874 22509476222784 run_lib.py:133] step: 625850, training_loss: 4.22511e-02
I0212 14:53:56.887471 22509476222784 run_lib.py:133] step: 625900, training_loss: 4.19033e-02
I0212 14:53:57.106812 22509476222784 run_lib.py:146] step: 625900, eval_loss: 4.10739e-02
I0212 14:54:15.791076 22509476222784 run_lib.py:133] step: 625950, training_loss: 2.60932e-02
I0212 14:54:34.312122 22509476222784 run_lib.py:133] step: 626000, training_loss: 4.50013e-02
I0212 14:54:34.482910 22509476222784 run_lib.py:146] step: 626000, eval_loss: 4.78311e-02
I0212 14:54:53.146185 22509476222784 run_lib.py:133] step: 626050, training_loss: 3.65051e-02
I0212 14:55:11.693268 22509476222784 run_lib.py:133] step: 626100, training_loss: 3.61357e-02
I0212 14:55:11.858101 22509476222784 run_lib.py:146] step: 626100, eval_loss: 4.07942e-02
I0212 14:55:30.367421 22509476222784 run_lib.py:133] step: 626150, training_loss: 4.28948e-02
I0212 14:55:48.886975 22509476222784 run_lib.py:133] step: 626200, training_loss: 4.33298e-02
I0212 14:55:49.060791 22509476222784 run_lib.py:146] step: 626200, eval_loss: 4.63978e-02
I0212 14:56:07.755718 22509476222784 run_lib.py:133] step: 626250, training_loss: 4.29436e-02
I0212 14:56:26.404479 22509476222784 run_lib.py:133] step: 626300, training_loss: 5.12200e-02
I0212 14:56:26.568894 22509476222784 run_lib.py:146] step: 626300, eval_loss: 3.85830e-02
I0212 14:56:45.087227 22509476222784 run_lib.py:133] step: 626350, training_loss: 5.40944e-02
I0212 14:57:03.643601 22509476222784 run_lib.py:133] step: 626400, training_loss: 2.98407e-02
I0212 14:57:03.845774 22509476222784 run_lib.py:146] step: 626400, eval_loss: 4.55526e-02
I0212 14:57:22.526297 22509476222784 run_lib.py:133] step: 626450, training_loss: 4.06895e-02
I0212 14:57:41.046764 22509476222784 run_lib.py:133] step: 626500, training_loss: 3.72617e-02
I0212 14:57:41.247636 22509476222784 run_lib.py:146] step: 626500, eval_loss: 4.47472e-02
I0212 14:57:59.972679 22509476222784 run_lib.py:133] step: 626550, training_loss: 4.16467e-02
I0212 14:58:18.461798 22509476222784 run_lib.py:133] step: 626600, training_loss: 4.01828e-02
I0212 14:58:18.633958 22509476222784 run_lib.py:146] step: 626600, eval_loss: 3.87367e-02
I0212 14:58:37.285157 22509476222784 run_lib.py:133] step: 626650, training_loss: 3.76530e-02
I0212 14:58:55.784734 22509476222784 run_lib.py:133] step: 626700, training_loss: 4.25074e-02
I0212 14:58:55.979780 22509476222784 run_lib.py:146] step: 626700, eval_loss: 4.08338e-02
I0212 14:59:14.658483 22509476222784 run_lib.py:133] step: 626750, training_loss: 4.32854e-02
I0212 14:59:33.187441 22509476222784 run_lib.py:133] step: 626800, training_loss: 5.06341e-02
I0212 14:59:33.351476 22509476222784 run_lib.py:146] step: 626800, eval_loss: 4.00629e-02
I0212 14:59:51.920943 22509476222784 run_lib.py:133] step: 626850, training_loss: 4.52343e-02
I0212 15:00:10.609218 22509476222784 run_lib.py:133] step: 626900, training_loss: 4.24994e-02
I0212 15:00:10.815605 22509476222784 run_lib.py:146] step: 626900, eval_loss: 3.58070e-02
I0212 15:00:29.315607 22509476222784 run_lib.py:133] step: 626950, training_loss: 4.91040e-02
I0212 15:00:47.855563 22509476222784 run_lib.py:133] step: 627000, training_loss: 5.21484e-02
I0212 15:00:48.035788 22509476222784 run_lib.py:146] step: 627000, eval_loss: 3.57168e-02
I0212 15:01:06.707862 22509476222784 run_lib.py:133] step: 627050, training_loss: 4.47590e-02
I0212 15:01:25.341024 22509476222784 run_lib.py:133] step: 627100, training_loss: 4.05068e-02
I0212 15:01:25.505774 22509476222784 run_lib.py:146] step: 627100, eval_loss: 3.20891e-02
I0212 15:01:43.955034 22509476222784 run_lib.py:133] step: 627150, training_loss: 4.46729e-02
I0212 15:02:02.398606 22509476222784 run_lib.py:133] step: 627200, training_loss: 3.83686e-02
I0212 15:02:02.562567 22509476222784 run_lib.py:146] step: 627200, eval_loss: 5.29641e-02
I0212 15:02:20.991893 22509476222784 run_lib.py:133] step: 627250, training_loss: 3.51748e-02
I0212 15:02:39.687246 22509476222784 run_lib.py:133] step: 627300, training_loss: 3.58252e-02
I0212 15:02:39.858871 22509476222784 run_lib.py:146] step: 627300, eval_loss: 6.77302e-02
I0212 15:02:58.446764 22509476222784 run_lib.py:133] step: 627350, training_loss: 3.80549e-02
I0212 15:03:16.923748 22509476222784 run_lib.py:133] step: 627400, training_loss: 3.63036e-02
I0212 15:03:17.121615 22509476222784 run_lib.py:146] step: 627400, eval_loss: 5.02459e-02
I0212 15:03:35.568749 22509476222784 run_lib.py:133] step: 627450, training_loss: 4.72309e-02
I0212 15:03:54.259381 22509476222784 run_lib.py:133] step: 627500, training_loss: 3.74161e-02
I0212 15:03:54.451689 22509476222784 run_lib.py:146] step: 627500, eval_loss: 4.73339e-02
I0212 15:04:12.971951 22509476222784 run_lib.py:133] step: 627550, training_loss: 4.68898e-02
I0212 15:04:31.578643 22509476222784 run_lib.py:133] step: 627600, training_loss: 5.38471e-02
I0212 15:04:31.742762 22509476222784 run_lib.py:146] step: 627600, eval_loss: 4.24101e-02
I0212 15:04:50.211626 22509476222784 run_lib.py:133] step: 627650, training_loss: 3.96536e-02
I0212 15:05:08.711518 22509476222784 run_lib.py:133] step: 627700, training_loss: 3.91365e-02
I0212 15:05:08.956236 22509476222784 run_lib.py:146] step: 627700, eval_loss: 4.38662e-02
I0212 15:05:27.647356 22509476222784 run_lib.py:133] step: 627750, training_loss: 3.47684e-02
I0212 15:05:46.252945 22509476222784 run_lib.py:133] step: 627800, training_loss: 3.96882e-02
I0212 15:05:46.417869 22509476222784 run_lib.py:146] step: 627800, eval_loss: 4.04528e-02
I0212 15:06:05.037285 22509476222784 run_lib.py:133] step: 627850, training_loss: 3.71635e-02
I0212 15:06:23.557396 22509476222784 run_lib.py:133] step: 627900, training_loss: 3.54227e-02
I0212 15:06:23.722437 22509476222784 run_lib.py:146] step: 627900, eval_loss: 4.70636e-02
I0212 15:06:42.386654 22509476222784 run_lib.py:133] step: 627950, training_loss: 4.15750e-02
I0212 15:07:00.858764 22509476222784 run_lib.py:133] step: 628000, training_loss: 4.35296e-02
I0212 15:07:01.026055 22509476222784 run_lib.py:146] step: 628000, eval_loss: 5.17678e-02
I0212 15:07:19.655841 22509476222784 run_lib.py:133] step: 628050, training_loss: 4.23148e-02
I0212 15:07:38.270948 22509476222784 run_lib.py:133] step: 628100, training_loss: 4.07520e-02
I0212 15:07:38.434913 22509476222784 run_lib.py:146] step: 628100, eval_loss: 4.48808e-02
I0212 15:07:57.154237 22509476222784 run_lib.py:133] step: 628150, training_loss: 4.59102e-02
I0212 15:08:15.692267 22509476222784 run_lib.py:133] step: 628200, training_loss: 5.23894e-02
I0212 15:08:15.853203 22509476222784 run_lib.py:146] step: 628200, eval_loss: 4.32179e-02
I0212 15:08:34.254105 22509476222784 run_lib.py:133] step: 628250, training_loss: 5.39448e-02
I0212 15:08:52.897896 22509476222784 run_lib.py:133] step: 628300, training_loss: 3.77798e-02
I0212 15:08:53.068740 22509476222784 run_lib.py:146] step: 628300, eval_loss: 6.07025e-02
I0212 15:09:11.604935 22509476222784 run_lib.py:133] step: 628350, training_loss: 4.56819e-02
I0212 15:09:30.337795 22509476222784 run_lib.py:133] step: 628400, training_loss: 2.41398e-02
I0212 15:09:30.539562 22509476222784 run_lib.py:146] step: 628400, eval_loss: 4.32013e-02
I0212 15:09:49.086543 22509476222784 run_lib.py:133] step: 628450, training_loss: 2.48913e-02
I0212 15:10:07.591025 22509476222784 run_lib.py:133] step: 628500, training_loss: 4.11999e-02
I0212 15:10:07.753605 22509476222784 run_lib.py:146] step: 628500, eval_loss: 3.45564e-02
I0212 15:10:26.409495 22509476222784 run_lib.py:133] step: 628550, training_loss: 3.39211e-02
I0212 15:10:44.999054 22509476222784 run_lib.py:133] step: 628600, training_loss: 4.57045e-02
I0212 15:10:45.164930 22509476222784 run_lib.py:146] step: 628600, eval_loss: 4.78616e-02
I0212 15:11:03.766061 22509476222784 run_lib.py:133] step: 628650, training_loss: 3.51518e-02
I0212 15:11:22.534690 22509476222784 run_lib.py:133] step: 628700, training_loss: 3.57697e-02
I0212 15:11:22.732748 22509476222784 run_lib.py:146] step: 628700, eval_loss: 3.96126e-02
I0212 15:11:41.292651 22509476222784 run_lib.py:133] step: 628750, training_loss: 2.99857e-02
I0212 15:11:59.862784 22509476222784 run_lib.py:133] step: 628800, training_loss: 5.00441e-02
I0212 15:12:00.029970 22509476222784 run_lib.py:146] step: 628800, eval_loss: 4.19905e-02
I0212 15:12:18.655130 22509476222784 run_lib.py:133] step: 628850, training_loss: 4.12727e-02
I0212 15:12:37.338115 22509476222784 run_lib.py:133] step: 628900, training_loss: 4.57431e-02
I0212 15:12:37.514747 22509476222784 run_lib.py:146] step: 628900, eval_loss: 4.22259e-02
I0212 15:12:56.087524 22509476222784 run_lib.py:133] step: 628950, training_loss: 4.14101e-02
I0212 15:13:14.584254 22509476222784 run_lib.py:133] step: 629000, training_loss: 4.90131e-02
I0212 15:13:14.747683 22509476222784 run_lib.py:146] step: 629000, eval_loss: 5.13397e-02
I0212 15:13:33.466610 22509476222784 run_lib.py:133] step: 629050, training_loss: 5.69459e-02
I0212 15:13:52.078154 22509476222784 run_lib.py:133] step: 629100, training_loss: 4.41783e-02
I0212 15:13:52.242916 22509476222784 run_lib.py:146] step: 629100, eval_loss: 4.46529e-02
I0212 15:14:10.740746 22509476222784 run_lib.py:133] step: 629150, training_loss: 4.83487e-02
I0212 15:14:29.142114 22509476222784 run_lib.py:133] step: 629200, training_loss: 3.83018e-02
I0212 15:14:29.311679 22509476222784 run_lib.py:146] step: 629200, eval_loss: 3.36086e-02
I0212 15:14:48.030937 22509476222784 run_lib.py:133] step: 629250, training_loss: 4.02314e-02
I0212 15:15:06.535056 22509476222784 run_lib.py:133] step: 629300, training_loss: 4.06973e-02
I0212 15:15:06.699698 22509476222784 run_lib.py:146] step: 629300, eval_loss: 4.40165e-02
I0212 15:15:25.411480 22509476222784 run_lib.py:133] step: 629350, training_loss: 5.19227e-02
I0212 15:15:43.992925 22509476222784 run_lib.py:133] step: 629400, training_loss: 4.65149e-02
I0212 15:15:44.157570 22509476222784 run_lib.py:146] step: 629400, eval_loss: 4.15168e-02
I0212 15:16:02.915503 22509476222784 run_lib.py:133] step: 629450, training_loss: 4.53865e-02
I0212 15:16:21.493703 22509476222784 run_lib.py:133] step: 629500, training_loss: 3.98587e-02
I0212 15:16:21.657639 22509476222784 run_lib.py:146] step: 629500, eval_loss: 4.61455e-02
I0212 15:16:40.309015 22509476222784 run_lib.py:133] step: 629550, training_loss: 3.09965e-02
I0212 15:16:58.835923 22509476222784 run_lib.py:133] step: 629600, training_loss: 3.63616e-02
I0212 15:16:59.001715 22509476222784 run_lib.py:146] step: 629600, eval_loss: 3.82232e-02
I0212 15:17:17.645888 22509476222784 run_lib.py:133] step: 629650, training_loss: 5.59961e-02
I0212 15:17:36.324155 22509476222784 run_lib.py:133] step: 629700, training_loss: 4.33968e-02
I0212 15:17:36.487805 22509476222784 run_lib.py:146] step: 629700, eval_loss: 3.68028e-02
I0212 15:17:55.079151 22509476222784 run_lib.py:133] step: 629750, training_loss: 4.31879e-02
I0212 15:18:13.616929 22509476222784 run_lib.py:133] step: 629800, training_loss: 4.87826e-02
I0212 15:18:13.790962 22509476222784 run_lib.py:146] step: 629800, eval_loss: 3.27046e-02
I0212 15:18:32.491545 22509476222784 run_lib.py:133] step: 629850, training_loss: 4.52992e-02
I0212 15:18:51.014252 22509476222784 run_lib.py:133] step: 629900, training_loss: 5.73218e-02
I0212 15:18:51.195790 22509476222784 run_lib.py:146] step: 629900, eval_loss: 4.90652e-02
I0212 15:19:09.850099 22509476222784 run_lib.py:133] step: 629950, training_loss: 4.01271e-02
I0212 15:19:28.425680 22509476222784 run_lib.py:133] step: 630000, training_loss: 4.89083e-02
I0212 15:19:29.159919 22509476222784 run_lib.py:146] step: 630000, eval_loss: 3.51638e-02
I0212 15:19:50.398362 22509476222784 run_lib.py:133] step: 630050, training_loss: 4.52886e-02
I0212 15:20:09.022292 22509476222784 run_lib.py:133] step: 630100, training_loss: 4.52352e-02
I0212 15:20:09.186585 22509476222784 run_lib.py:146] step: 630100, eval_loss: 4.89519e-02
I0212 15:20:27.912829 22509476222784 run_lib.py:133] step: 630150, training_loss: 4.51609e-02
I0212 15:20:46.521114 22509476222784 run_lib.py:133] step: 630200, training_loss: 4.37059e-02
I0212 15:20:46.738486 22509476222784 run_lib.py:146] step: 630200, eval_loss: 3.94431e-02
I0212 15:21:05.359115 22509476222784 run_lib.py:133] step: 630250, training_loss: 3.56132e-02
I0212 15:21:24.067628 22509476222784 run_lib.py:133] step: 630300, training_loss: 4.43024e-02
I0212 15:21:24.248636 22509476222784 run_lib.py:146] step: 630300, eval_loss: 3.77097e-02
I0212 15:21:42.758756 22509476222784 run_lib.py:133] step: 630350, training_loss: 2.73947e-02
I0212 15:22:01.469215 22509476222784 run_lib.py:133] step: 630400, training_loss: 4.51214e-02
I0212 15:22:01.647542 22509476222784 run_lib.py:146] step: 630400, eval_loss: 3.56175e-02
I0212 15:22:20.213523 22509476222784 run_lib.py:133] step: 630450, training_loss: 3.62482e-02
I0212 15:22:38.749748 22509476222784 run_lib.py:133] step: 630500, training_loss: 4.13888e-02
I0212 15:22:38.912758 22509476222784 run_lib.py:146] step: 630500, eval_loss: 4.11201e-02
I0212 15:22:57.407128 22509476222784 run_lib.py:133] step: 630550, training_loss: 4.96444e-02
I0212 15:23:15.924882 22509476222784 run_lib.py:133] step: 630600, training_loss: 4.99781e-02
I0212 15:23:16.123682 22509476222784 run_lib.py:146] step: 630600, eval_loss: 4.52579e-02
I0212 15:23:34.869430 22509476222784 run_lib.py:133] step: 630650, training_loss: 3.40936e-02
I0212 15:23:53.521981 22509476222784 run_lib.py:133] step: 630700, training_loss: 4.35206e-02
I0212 15:23:53.710807 22509476222784 run_lib.py:146] step: 630700, eval_loss: 3.55354e-02
I0212 15:24:12.366561 22509476222784 run_lib.py:133] step: 630750, training_loss: 4.43667e-02
I0212 15:24:30.934545 22509476222784 run_lib.py:133] step: 630800, training_loss: 3.86685e-02
I0212 15:24:31.098690 22509476222784 run_lib.py:146] step: 630800, eval_loss: 5.23531e-02
I0212 15:24:49.819677 22509476222784 run_lib.py:133] step: 630850, training_loss: 3.64932e-02
I0212 15:25:08.458719 22509476222784 run_lib.py:133] step: 630900, training_loss: 4.76841e-02
I0212 15:25:08.628913 22509476222784 run_lib.py:146] step: 630900, eval_loss: 5.23643e-02
I0212 15:25:27.123619 22509476222784 run_lib.py:133] step: 630950, training_loss: 5.49712e-02
I0212 15:25:45.734549 22509476222784 run_lib.py:133] step: 631000, training_loss: 4.66982e-02
I0212 15:25:45.899960 22509476222784 run_lib.py:146] step: 631000, eval_loss: 6.06516e-02
I0212 15:26:04.639754 22509476222784 run_lib.py:133] step: 631050, training_loss: 4.20482e-02
I0212 15:26:23.181098 22509476222784 run_lib.py:133] step: 631100, training_loss: 3.69852e-02
I0212 15:26:23.345660 22509476222784 run_lib.py:146] step: 631100, eval_loss: 3.25287e-02
I0212 15:26:42.044140 22509476222784 run_lib.py:133] step: 631150, training_loss: 3.56595e-02
I0212 15:27:00.547039 22509476222784 run_lib.py:133] step: 631200, training_loss: 5.12948e-02
I0212 15:27:00.709739 22509476222784 run_lib.py:146] step: 631200, eval_loss: 4.21933e-02
I0212 15:27:19.479926 22509476222784 run_lib.py:133] step: 631250, training_loss: 4.36212e-02
I0212 15:27:38.044697 22509476222784 run_lib.py:133] step: 631300, training_loss: 4.19654e-02
I0212 15:27:38.209542 22509476222784 run_lib.py:146] step: 631300, eval_loss: 4.72482e-02
I0212 15:27:56.712331 22509476222784 run_lib.py:133] step: 631350, training_loss: 5.13325e-02
I0212 15:28:15.358819 22509476222784 run_lib.py:133] step: 631400, training_loss: 4.24671e-02
I0212 15:28:15.523905 22509476222784 run_lib.py:146] step: 631400, eval_loss: 4.09079e-02
I0212 15:28:34.062006 22509476222784 run_lib.py:133] step: 631450, training_loss: 3.99023e-02
I0212 15:28:52.769886 22509476222784 run_lib.py:133] step: 631500, training_loss: 2.83676e-02
I0212 15:28:52.933357 22509476222784 run_lib.py:146] step: 631500, eval_loss: 4.80848e-02
I0212 15:29:11.487275 22509476222784 run_lib.py:133] step: 631550, training_loss: 3.80682e-02
I0212 15:29:30.041165 22509476222784 run_lib.py:133] step: 631600, training_loss: 4.30479e-02
I0212 15:29:30.206656 22509476222784 run_lib.py:146] step: 631600, eval_loss: 4.69555e-02
I0212 15:29:48.752672 22509476222784 run_lib.py:133] step: 631650, training_loss: 4.03639e-02
I0212 15:30:07.511578 22509476222784 run_lib.py:133] step: 631700, training_loss: 4.99037e-02
I0212 15:30:07.673874 22509476222784 run_lib.py:146] step: 631700, eval_loss: 4.08915e-02
I0212 15:30:26.249980 22509476222784 run_lib.py:133] step: 631750, training_loss: 3.72296e-02
I0212 15:30:44.801531 22509476222784 run_lib.py:133] step: 631800, training_loss: 4.55541e-02
I0212 15:30:44.966678 22509476222784 run_lib.py:146] step: 631800, eval_loss: 3.68009e-02
I0212 15:31:03.664952 22509476222784 run_lib.py:133] step: 631850, training_loss: 4.21675e-02
I0212 15:31:22.248103 22509476222784 run_lib.py:133] step: 631900, training_loss: 3.91621e-02
I0212 15:31:22.430767 22509476222784 run_lib.py:146] step: 631900, eval_loss: 4.77623e-02
I0212 15:31:41.060178 22509476222784 run_lib.py:133] step: 631950, training_loss: 4.95765e-02
I0212 15:31:59.569570 22509476222784 run_lib.py:133] step: 632000, training_loss: 3.94668e-02
I0212 15:31:59.748909 22509476222784 run_lib.py:146] step: 632000, eval_loss: 3.19233e-02
I0212 15:32:18.304866 22509476222784 run_lib.py:133] step: 632050, training_loss: 5.29672e-02
I0212 15:32:36.876217 22509476222784 run_lib.py:133] step: 632100, training_loss: 3.97222e-02
I0212 15:32:37.043615 22509476222784 run_lib.py:146] step: 632100, eval_loss: 3.71061e-02
I0212 15:32:55.810534 22509476222784 run_lib.py:133] step: 632150, training_loss: 3.84483e-02
I0212 15:33:14.424566 22509476222784 run_lib.py:133] step: 632200, training_loss: 3.81876e-02
I0212 15:33:14.588700 22509476222784 run_lib.py:146] step: 632200, eval_loss: 5.26264e-02
I0212 15:33:33.129062 22509476222784 run_lib.py:133] step: 632250, training_loss: 4.27177e-02
I0212 15:33:51.697760 22509476222784 run_lib.py:133] step: 632300, training_loss: 4.10275e-02
I0212 15:33:51.879997 22509476222784 run_lib.py:146] step: 632300, eval_loss: 3.77069e-02
I0212 15:34:10.636273 22509476222784 run_lib.py:133] step: 632350, training_loss: 4.40450e-02
I0212 15:34:29.237861 22509476222784 run_lib.py:133] step: 632400, training_loss: 3.69697e-02
I0212 15:34:29.403084 22509476222784 run_lib.py:146] step: 632400, eval_loss: 5.25098e-02
I0212 15:34:48.089255 22509476222784 run_lib.py:133] step: 632450, training_loss: 5.21914e-02
I0212 15:35:06.589109 22509476222784 run_lib.py:133] step: 632500, training_loss: 3.70522e-02
I0212 15:35:06.756621 22509476222784 run_lib.py:146] step: 632500, eval_loss: 4.48642e-02
I0212 15:35:25.479967 22509476222784 run_lib.py:133] step: 632550, training_loss: 3.82805e-02
I0212 15:35:44.176405 22509476222784 run_lib.py:133] step: 632600, training_loss: 3.99256e-02
I0212 15:35:44.339930 22509476222784 run_lib.py:146] step: 632600, eval_loss: 3.61688e-02
I0212 15:36:03.129182 22509476222784 run_lib.py:133] step: 632650, training_loss: 5.18230e-02
I0212 15:36:21.728448 22509476222784 run_lib.py:133] step: 632700, training_loss: 4.20474e-02
I0212 15:36:21.893670 22509476222784 run_lib.py:146] step: 632700, eval_loss: 4.81658e-02
I0212 15:36:40.431221 22509476222784 run_lib.py:133] step: 632750, training_loss: 4.23366e-02
I0212 15:36:59.172173 22509476222784 run_lib.py:133] step: 632800, training_loss: 2.85488e-02
I0212 15:36:59.353775 22509476222784 run_lib.py:146] step: 632800, eval_loss: 3.99516e-02
I0212 15:37:17.984889 22509476222784 run_lib.py:133] step: 632850, training_loss: 4.73245e-02
I0212 15:37:36.633718 22509476222784 run_lib.py:133] step: 632900, training_loss: 5.02606e-02
I0212 15:37:36.807781 22509476222784 run_lib.py:146] step: 632900, eval_loss: 4.55681e-02
I0212 15:37:55.592502 22509476222784 run_lib.py:133] step: 632950, training_loss: 4.76269e-02
I0212 15:38:14.331167 22509476222784 run_lib.py:133] step: 633000, training_loss: 4.73215e-02
I0212 15:38:14.494437 22509476222784 run_lib.py:146] step: 633000, eval_loss: 5.32085e-02
I0212 15:38:33.013435 22509476222784 run_lib.py:133] step: 633050, training_loss: 3.48355e-02
I0212 15:38:51.557751 22509476222784 run_lib.py:133] step: 633100, training_loss: 3.36114e-02
I0212 15:38:51.724092 22509476222784 run_lib.py:146] step: 633100, eval_loss: 3.43070e-02
I0212 15:39:10.332148 22509476222784 run_lib.py:133] step: 633150, training_loss: 4.48775e-02
I0212 15:39:29.180352 22509476222784 run_lib.py:133] step: 633200, training_loss: 3.61310e-02
I0212 15:39:29.347938 22509476222784 run_lib.py:146] step: 633200, eval_loss: 3.67561e-02
I0212 15:39:47.851655 22509476222784 run_lib.py:133] step: 633250, training_loss: 3.82500e-02
I0212 15:40:06.348216 22509476222784 run_lib.py:133] step: 633300, training_loss: 3.73990e-02
I0212 15:40:06.524588 22509476222784 run_lib.py:146] step: 633300, eval_loss: 3.46343e-02
I0212 15:40:25.046534 22509476222784 run_lib.py:133] step: 633350, training_loss: 4.51971e-02
I0212 15:40:43.779648 22509476222784 run_lib.py:133] step: 633400, training_loss: 4.39136e-02
I0212 15:40:43.943967 22509476222784 run_lib.py:146] step: 633400, eval_loss: 3.85462e-02
I0212 15:41:02.422127 22509476222784 run_lib.py:133] step: 633450, training_loss: 3.77390e-02
I0212 15:41:20.957085 22509476222784 run_lib.py:133] step: 633500, training_loss: 3.74674e-02
I0212 15:41:21.120629 22509476222784 run_lib.py:146] step: 633500, eval_loss: 4.57236e-02
I0212 15:41:39.667129 22509476222784 run_lib.py:133] step: 633550, training_loss: 3.52298e-02
I0212 15:41:58.280345 22509476222784 run_lib.py:133] step: 633600, training_loss: 4.27305e-02
I0212 15:41:58.462098 22509476222784 run_lib.py:146] step: 633600, eval_loss: 5.07792e-02
I0212 15:42:17.246495 22509476222784 run_lib.py:133] step: 633650, training_loss: 4.63680e-02
I0212 15:42:35.925257 22509476222784 run_lib.py:133] step: 633700, training_loss: 4.79871e-02
I0212 15:42:36.092679 22509476222784 run_lib.py:146] step: 633700, eval_loss: 3.56524e-02
I0212 15:42:54.640413 22509476222784 run_lib.py:133] step: 633750, training_loss: 4.27420e-02
I0212 15:43:13.201978 22509476222784 run_lib.py:133] step: 633800, training_loss: 5.29652e-02
I0212 15:43:13.366634 22509476222784 run_lib.py:146] step: 633800, eval_loss: 3.08100e-02
I0212 15:43:32.056414 22509476222784 run_lib.py:133] step: 633850, training_loss: 3.78426e-02
I0212 15:43:50.615266 22509476222784 run_lib.py:133] step: 633900, training_loss: 5.62021e-02
I0212 15:43:50.788412 22509476222784 run_lib.py:146] step: 633900, eval_loss: 3.85487e-02
I0212 15:44:09.540196 22509476222784 run_lib.py:133] step: 633950, training_loss: 4.49996e-02
I0212 15:44:28.069551 22509476222784 run_lib.py:133] step: 634000, training_loss: 4.58833e-02
I0212 15:44:28.234432 22509476222784 run_lib.py:146] step: 634000, eval_loss: 4.94923e-02
I0212 15:44:46.952446 22509476222784 run_lib.py:133] step: 634050, training_loss: 3.72785e-02
I0212 15:45:05.459722 22509476222784 run_lib.py:133] step: 634100, training_loss: 2.72848e-02
I0212 15:45:05.622656 22509476222784 run_lib.py:146] step: 634100, eval_loss: 3.90354e-02
I0212 15:45:24.151063 22509476222784 run_lib.py:133] step: 634150, training_loss: 3.71618e-02
I0212 15:45:42.941534 22509476222784 run_lib.py:133] step: 634200, training_loss: 4.18590e-02
I0212 15:45:43.108776 22509476222784 run_lib.py:146] step: 634200, eval_loss: 3.72836e-02
I0212 15:46:01.636398 22509476222784 run_lib.py:133] step: 634250, training_loss: 4.50312e-02
I0212 15:46:20.368878 22509476222784 run_lib.py:133] step: 634300, training_loss: 4.07749e-02
I0212 15:46:20.564921 22509476222784 run_lib.py:146] step: 634300, eval_loss: 3.80251e-02
I0212 15:46:39.125487 22509476222784 run_lib.py:133] step: 634350, training_loss: 4.75344e-02
I0212 15:46:57.700236 22509476222784 run_lib.py:133] step: 634400, training_loss: 5.23060e-02
I0212 15:46:57.864804 22509476222784 run_lib.py:146] step: 634400, eval_loss: 3.29397e-02
I0212 15:47:16.680030 22509476222784 run_lib.py:133] step: 634450, training_loss: 4.65920e-02
I0212 15:47:35.269091 22509476222784 run_lib.py:133] step: 634500, training_loss: 4.06844e-02
I0212 15:47:35.430689 22509476222784 run_lib.py:146] step: 634500, eval_loss: 4.24076e-02
I0212 15:47:53.985635 22509476222784 run_lib.py:133] step: 634550, training_loss: 3.05821e-02
I0212 15:48:12.749403 22509476222784 run_lib.py:133] step: 634600, training_loss: 4.33633e-02
I0212 15:48:12.915709 22509476222784 run_lib.py:146] step: 634600, eval_loss: 3.84078e-02
I0212 15:48:31.469120 22509476222784 run_lib.py:133] step: 634650, training_loss: 4.01243e-02
I0212 15:48:50.041351 22509476222784 run_lib.py:133] step: 634700, training_loss: 3.10377e-02
I0212 15:48:50.218739 22509476222784 run_lib.py:146] step: 634700, eval_loss: 4.00431e-02
I0212 15:49:08.904951 22509476222784 run_lib.py:133] step: 634750, training_loss: 3.76372e-02
I0212 15:49:27.488051 22509476222784 run_lib.py:133] step: 634800, training_loss: 4.74827e-02
I0212 15:49:27.725797 22509476222784 run_lib.py:146] step: 634800, eval_loss: 4.02893e-02
I0212 15:49:46.305822 22509476222784 run_lib.py:133] step: 634850, training_loss: 3.42899e-02
I0212 15:50:04.835900 22509476222784 run_lib.py:133] step: 634900, training_loss: 3.98896e-02
I0212 15:50:04.999572 22509476222784 run_lib.py:146] step: 634900, eval_loss: 3.55632e-02
I0212 15:50:23.723354 22509476222784 run_lib.py:133] step: 634950, training_loss: 3.53531e-02
I0212 15:50:42.381742 22509476222784 run_lib.py:133] step: 635000, training_loss: 5.18772e-02
I0212 15:50:42.549999 22509476222784 run_lib.py:146] step: 635000, eval_loss: 5.17240e-02
I0212 15:51:01.117724 22509476222784 run_lib.py:133] step: 635050, training_loss: 3.62591e-02
I0212 15:51:19.695679 22509476222784 run_lib.py:133] step: 635100, training_loss: 4.66649e-02
I0212 15:51:19.884306 22509476222784 run_lib.py:146] step: 635100, eval_loss: 3.52390e-02
I0212 15:51:38.622933 22509476222784 run_lib.py:133] step: 635150, training_loss: 3.57228e-02
I0212 15:51:57.150686 22509476222784 run_lib.py:133] step: 635200, training_loss: 3.80710e-02
I0212 15:51:57.325946 22509476222784 run_lib.py:146] step: 635200, eval_loss: 4.74551e-02
I0212 15:52:16.105244 22509476222784 run_lib.py:133] step: 635250, training_loss: 4.11134e-02
I0212 15:52:34.713773 22509476222784 run_lib.py:133] step: 635300, training_loss: 4.32852e-02
I0212 15:52:34.905029 22509476222784 run_lib.py:146] step: 635300, eval_loss: 4.73017e-02
I0212 15:52:53.670879 22509476222784 run_lib.py:133] step: 635350, training_loss: 4.23007e-02
I0212 15:53:12.192586 22509476222784 run_lib.py:133] step: 635400, training_loss: 4.03213e-02
I0212 15:53:12.356704 22509476222784 run_lib.py:146] step: 635400, eval_loss: 3.86818e-02
I0212 15:53:31.061730 22509476222784 run_lib.py:133] step: 635450, training_loss: 4.17602e-02
I0212 15:53:49.658459 22509476222784 run_lib.py:133] step: 635500, training_loss: 4.70291e-02
I0212 15:53:49.827892 22509476222784 run_lib.py:146] step: 635500, eval_loss: 4.57797e-02
I0212 15:54:08.411679 22509476222784 run_lib.py:133] step: 635550, training_loss: 4.52981e-02
I0212 15:54:27.188715 22509476222784 run_lib.py:133] step: 635600, training_loss: 4.25576e-02
I0212 15:54:27.356966 22509476222784 run_lib.py:146] step: 635600, eval_loss: 5.10021e-02
I0212 15:54:45.966967 22509476222784 run_lib.py:133] step: 635650, training_loss: 3.98976e-02
I0212 15:55:04.611619 22509476222784 run_lib.py:133] step: 635700, training_loss: 4.27134e-02
I0212 15:55:04.785701 22509476222784 run_lib.py:146] step: 635700, eval_loss: 4.23250e-02
I0212 15:55:23.513410 22509476222784 run_lib.py:133] step: 635750, training_loss: 3.67090e-02
I0212 15:55:42.107881 22509476222784 run_lib.py:133] step: 635800, training_loss: 3.08222e-02
I0212 15:55:42.307876 22509476222784 run_lib.py:146] step: 635800, eval_loss: 3.50942e-02
I0212 15:56:01.118173 22509476222784 run_lib.py:133] step: 635850, training_loss: 3.85718e-02
I0212 15:56:19.708153 22509476222784 run_lib.py:133] step: 635900, training_loss: 3.98614e-02
I0212 15:56:19.868801 22509476222784 run_lib.py:146] step: 635900, eval_loss: 6.38271e-02
I0212 15:56:38.426384 22509476222784 run_lib.py:133] step: 635950, training_loss: 2.90544e-02
I0212 15:56:57.201379 22509476222784 run_lib.py:133] step: 636000, training_loss: 4.48537e-02
I0212 15:56:57.376542 22509476222784 run_lib.py:146] step: 636000, eval_loss: 3.64543e-02
I0212 15:57:15.967340 22509476222784 run_lib.py:133] step: 636050, training_loss: 4.91219e-02
I0212 15:57:34.632121 22509476222784 run_lib.py:133] step: 636100, training_loss: 3.47158e-02
I0212 15:57:34.815078 22509476222784 run_lib.py:146] step: 636100, eval_loss: 4.30566e-02
I0212 15:57:53.367014 22509476222784 run_lib.py:133] step: 636150, training_loss: 4.48463e-02
I0212 15:58:12.129075 22509476222784 run_lib.py:133] step: 636200, training_loss: 3.77872e-02
I0212 15:58:12.326702 22509476222784 run_lib.py:146] step: 636200, eval_loss: 3.94269e-02
I0212 15:58:30.872524 22509476222784 run_lib.py:133] step: 636250, training_loss: 4.61896e-02
I0212 15:58:49.515573 22509476222784 run_lib.py:133] step: 636300, training_loss: 3.69518e-02
I0212 15:58:49.679748 22509476222784 run_lib.py:146] step: 636300, eval_loss: 3.72283e-02
I0212 15:59:08.172278 22509476222784 run_lib.py:133] step: 636350, training_loss: 5.04556e-02
I0212 15:59:26.649904 22509476222784 run_lib.py:133] step: 636400, training_loss: 4.12949e-02
I0212 15:59:26.814821 22509476222784 run_lib.py:146] step: 636400, eval_loss: 4.37224e-02
I0212 15:59:45.460472 22509476222784 run_lib.py:133] step: 636450, training_loss: 2.98508e-02
I0212 16:00:04.071732 22509476222784 run_lib.py:133] step: 636500, training_loss: 5.21624e-02
I0212 16:00:04.247960 22509476222784 run_lib.py:146] step: 636500, eval_loss: 5.07769e-02
I0212 16:00:22.880363 22509476222784 run_lib.py:133] step: 636550, training_loss: 3.02393e-02
I0212 16:00:41.476458 22509476222784 run_lib.py:133] step: 636600, training_loss: 4.56018e-02
I0212 16:00:41.641623 22509476222784 run_lib.py:146] step: 636600, eval_loss: 3.62692e-02
I0212 16:01:00.377165 22509476222784 run_lib.py:133] step: 636650, training_loss: 4.27932e-02
I0212 16:01:18.945042 22509476222784 run_lib.py:133] step: 636700, training_loss: 4.44064e-02
I0212 16:01:19.217764 22509476222784 run_lib.py:146] step: 636700, eval_loss: 3.66310e-02
I0212 16:01:37.912227 22509476222784 run_lib.py:133] step: 636750, training_loss: 4.27553e-02
I0212 16:01:56.517007 22509476222784 run_lib.py:133] step: 636800, training_loss: 3.28418e-02
I0212 16:01:56.681955 22509476222784 run_lib.py:146] step: 636800, eval_loss: 3.66229e-02
I0212 16:02:15.500716 22509476222784 run_lib.py:133] step: 636850, training_loss: 5.42006e-02
I0212 16:02:34.147149 22509476222784 run_lib.py:133] step: 636900, training_loss: 4.43845e-02
I0212 16:02:34.330719 22509476222784 run_lib.py:146] step: 636900, eval_loss: 4.72693e-02
I0212 16:02:52.880084 22509476222784 run_lib.py:133] step: 636950, training_loss: 3.38663e-02
I0212 16:03:11.590725 22509476222784 run_lib.py:133] step: 637000, training_loss: 4.32657e-02
I0212 16:03:11.774867 22509476222784 run_lib.py:146] step: 637000, eval_loss: 3.34727e-02
I0212 16:03:30.392715 22509476222784 run_lib.py:133] step: 637050, training_loss: 4.14908e-02
I0212 16:03:49.268981 22509476222784 run_lib.py:133] step: 637100, training_loss: 5.06908e-02
I0212 16:03:49.434683 22509476222784 run_lib.py:146] step: 637100, eval_loss: 4.29065e-02
I0212 16:04:08.008877 22509476222784 run_lib.py:133] step: 637150, training_loss: 4.73067e-02
I0212 16:04:26.530168 22509476222784 run_lib.py:133] step: 637200, training_loss: 4.72115e-02
I0212 16:04:26.694523 22509476222784 run_lib.py:146] step: 637200, eval_loss: 4.35695e-02
I0212 16:04:45.378141 22509476222784 run_lib.py:133] step: 637250, training_loss: 4.05787e-02
I0212 16:05:03.966303 22509476222784 run_lib.py:133] step: 637300, training_loss: 3.24148e-02
I0212 16:05:04.168623 22509476222784 run_lib.py:146] step: 637300, eval_loss: 4.18618e-02
I0212 16:05:22.739972 22509476222784 run_lib.py:133] step: 637350, training_loss: 4.76763e-02
I0212 16:05:41.420699 22509476222784 run_lib.py:133] step: 637400, training_loss: 5.39913e-02
I0212 16:05:41.583703 22509476222784 run_lib.py:146] step: 637400, eval_loss: 4.13732e-02
I0212 16:06:00.080229 22509476222784 run_lib.py:133] step: 637450, training_loss: 4.38052e-02
I0212 16:06:18.637438 22509476222784 run_lib.py:133] step: 637500, training_loss: 3.91632e-02
I0212 16:06:18.983195 22509476222784 run_lib.py:146] step: 637500, eval_loss: 4.14800e-02
I0212 16:06:37.560547 22509476222784 run_lib.py:133] step: 637550, training_loss: 3.65189e-02
I0212 16:06:56.125062 22509476222784 run_lib.py:133] step: 637600, training_loss: 5.96562e-02
I0212 16:06:56.296775 22509476222784 run_lib.py:146] step: 637600, eval_loss: 4.61489e-02
I0212 16:07:14.783405 22509476222784 run_lib.py:133] step: 637650, training_loss: 4.56264e-02
I0212 16:07:33.288318 22509476222784 run_lib.py:133] step: 637700, training_loss: 3.13760e-02
I0212 16:07:33.479439 22509476222784 run_lib.py:146] step: 637700, eval_loss: 4.38822e-02
I0212 16:07:52.217000 22509476222784 run_lib.py:133] step: 637750, training_loss: 3.43113e-02
I0212 16:08:10.841591 22509476222784 run_lib.py:133] step: 637800, training_loss: 4.13458e-02
I0212 16:08:11.045477 22509476222784 run_lib.py:146] step: 637800, eval_loss: 4.00787e-02
I0212 16:08:29.687132 22509476222784 run_lib.py:133] step: 637850, training_loss: 4.96714e-02
I0212 16:08:48.170085 22509476222784 run_lib.py:133] step: 637900, training_loss: 4.03213e-02
I0212 16:08:48.339713 22509476222784 run_lib.py:146] step: 637900, eval_loss: 4.20217e-02
I0212 16:09:07.030852 22509476222784 run_lib.py:133] step: 637950, training_loss: 3.80206e-02
I0212 16:09:25.686580 22509476222784 run_lib.py:133] step: 638000, training_loss: 4.29964e-02
I0212 16:09:25.868800 22509476222784 run_lib.py:146] step: 638000, eval_loss: 4.06363e-02
I0212 16:09:44.438913 22509476222784 run_lib.py:133] step: 638050, training_loss: 3.79037e-02
I0212 16:10:03.048328 22509476222784 run_lib.py:133] step: 638100, training_loss: 3.17782e-02
I0212 16:10:03.221745 22509476222784 run_lib.py:146] step: 638100, eval_loss: 3.51707e-02
I0212 16:10:21.966444 22509476222784 run_lib.py:133] step: 638150, training_loss: 4.21275e-02
I0212 16:10:40.492559 22509476222784 run_lib.py:133] step: 638200, training_loss: 4.72866e-02
I0212 16:10:40.655664 22509476222784 run_lib.py:146] step: 638200, eval_loss: 4.41130e-02
I0212 16:10:59.327312 22509476222784 run_lib.py:133] step: 638250, training_loss: 4.03967e-02
I0212 16:11:17.805684 22509476222784 run_lib.py:133] step: 638300, training_loss: 3.90356e-02
I0212 16:11:17.968664 22509476222784 run_lib.py:146] step: 638300, eval_loss: 4.06905e-02
I0212 16:11:36.657353 22509476222784 run_lib.py:133] step: 638350, training_loss: 3.94372e-02
I0212 16:11:55.256707 22509476222784 run_lib.py:133] step: 638400, training_loss: 5.13457e-02
I0212 16:11:55.431934 22509476222784 run_lib.py:146] step: 638400, eval_loss: 4.33419e-02
I0212 16:12:14.022495 22509476222784 run_lib.py:133] step: 638450, training_loss: 3.51887e-02
I0212 16:12:32.733416 22509476222784 run_lib.py:133] step: 638500, training_loss: 3.13919e-02
I0212 16:12:32.896408 22509476222784 run_lib.py:146] step: 638500, eval_loss: 3.06488e-02
I0212 16:12:51.448524 22509476222784 run_lib.py:133] step: 638550, training_loss: 3.96201e-02
I0212 16:13:10.137984 22509476222784 run_lib.py:133] step: 638600, training_loss: 4.93161e-02
I0212 16:13:10.310691 22509476222784 run_lib.py:146] step: 638600, eval_loss: 5.52120e-02
I0212 16:13:28.869759 22509476222784 run_lib.py:133] step: 638650, training_loss: 4.00128e-02
I0212 16:13:47.475594 22509476222784 run_lib.py:133] step: 638700, training_loss: 4.50496e-02
I0212 16:13:47.660827 22509476222784 run_lib.py:146] step: 638700, eval_loss: 5.22992e-02
I0212 16:14:06.188048 22509476222784 run_lib.py:133] step: 638750, training_loss: 3.94406e-02
I0212 16:14:24.844395 22509476222784 run_lib.py:133] step: 638800, training_loss: 3.10251e-02
I0212 16:14:25.004741 22509476222784 run_lib.py:146] step: 638800, eval_loss: 4.63079e-02
I0212 16:14:43.497125 22509476222784 run_lib.py:133] step: 638850, training_loss: 5.04194e-02
I0212 16:15:02.069179 22509476222784 run_lib.py:133] step: 638900, training_loss: 4.69139e-02
I0212 16:15:02.272525 22509476222784 run_lib.py:146] step: 638900, eval_loss: 4.55378e-02
I0212 16:15:21.020760 22509476222784 run_lib.py:133] step: 638950, training_loss: 4.56002e-02
I0212 16:15:39.572777 22509476222784 run_lib.py:133] step: 639000, training_loss: 4.45812e-02
I0212 16:15:39.761881 22509476222784 run_lib.py:146] step: 639000, eval_loss: 3.09396e-02
I0212 16:15:58.355367 22509476222784 run_lib.py:133] step: 639050, training_loss: 4.43716e-02
I0212 16:16:16.858716 22509476222784 run_lib.py:133] step: 639100, training_loss: 4.74362e-02
I0212 16:16:17.027996 22509476222784 run_lib.py:146] step: 639100, eval_loss: 3.90967e-02
I0212 16:16:35.577597 22509476222784 run_lib.py:133] step: 639150, training_loss: 4.45998e-02
I0212 16:16:54.135972 22509476222784 run_lib.py:133] step: 639200, training_loss: 4.27763e-02
I0212 16:16:54.299517 22509476222784 run_lib.py:146] step: 639200, eval_loss: 4.52184e-02
I0212 16:17:13.061999 22509476222784 run_lib.py:133] step: 639250, training_loss: 5.01567e-02
I0212 16:17:31.651921 22509476222784 run_lib.py:133] step: 639300, training_loss: 3.69067e-02
I0212 16:17:31.840613 22509476222784 run_lib.py:146] step: 639300, eval_loss: 5.03237e-02
I0212 16:17:50.341955 22509476222784 run_lib.py:133] step: 639350, training_loss: 3.86627e-02
I0212 16:18:08.860163 22509476222784 run_lib.py:133] step: 639400, training_loss: 2.93741e-02
I0212 16:18:09.040498 22509476222784 run_lib.py:146] step: 639400, eval_loss: 4.42342e-02
I0212 16:18:27.838567 22509476222784 run_lib.py:133] step: 639450, training_loss: 4.35890e-02
I0212 16:18:46.327587 22509476222784 run_lib.py:133] step: 639500, training_loss: 4.62155e-02
I0212 16:18:46.505796 22509476222784 run_lib.py:146] step: 639500, eval_loss: 4.44337e-02
I0212 16:19:05.187429 22509476222784 run_lib.py:133] step: 639550, training_loss: 4.90519e-02
I0212 16:19:23.672098 22509476222784 run_lib.py:133] step: 639600, training_loss: 4.64450e-02
I0212 16:19:23.884800 22509476222784 run_lib.py:146] step: 639600, eval_loss: 5.02342e-02
I0212 16:19:42.547962 22509476222784 run_lib.py:133] step: 639650, training_loss: 3.98271e-02
I0212 16:20:01.099339 22509476222784 run_lib.py:133] step: 639700, training_loss: 3.25065e-02
I0212 16:20:01.265110 22509476222784 run_lib.py:146] step: 639700, eval_loss: 4.06636e-02
I0212 16:20:20.003404 22509476222784 run_lib.py:133] step: 639750, training_loss: 4.61167e-02
I0212 16:20:38.520422 22509476222784 run_lib.py:133] step: 639800, training_loss: 4.70576e-02
I0212 16:20:38.685834 22509476222784 run_lib.py:146] step: 639800, eval_loss: 4.59247e-02
I0212 16:20:57.186639 22509476222784 run_lib.py:133] step: 639850, training_loss: 3.70654e-02
I0212 16:21:15.811063 22509476222784 run_lib.py:133] step: 639900, training_loss: 4.00447e-02
I0212 16:21:15.995595 22509476222784 run_lib.py:146] step: 639900, eval_loss: 4.78833e-02
I0212 16:21:34.574366 22509476222784 run_lib.py:133] step: 639950, training_loss: 3.60402e-02
I0212 16:21:53.241008 22509476222784 run_lib.py:133] step: 640000, training_loss: 4.10800e-02
I0212 16:21:53.983070 22509476222784 run_lib.py:146] step: 640000, eval_loss: 3.86644e-02
I0212 16:22:15.378956 22509476222784 run_lib.py:133] step: 640050, training_loss: 3.92519e-02
I0212 16:22:33.926935 22509476222784 run_lib.py:133] step: 640100, training_loss: 4.39665e-02
I0212 16:22:34.091626 22509476222784 run_lib.py:146] step: 640100, eval_loss: 3.14894e-02
I0212 16:22:52.623112 22509476222784 run_lib.py:133] step: 640150, training_loss: 5.43674e-02
I0212 16:23:11.370800 22509476222784 run_lib.py:133] step: 640200, training_loss: 4.29626e-02
I0212 16:23:11.535904 22509476222784 run_lib.py:146] step: 640200, eval_loss: 4.46616e-02
I0212 16:23:30.100709 22509476222784 run_lib.py:133] step: 640250, training_loss: 3.17917e-02
I0212 16:23:48.760388 22509476222784 run_lib.py:133] step: 640300, training_loss: 3.63590e-02
I0212 16:23:48.933701 22509476222784 run_lib.py:146] step: 640300, eval_loss: 3.97574e-02
I0212 16:24:07.462304 22509476222784 run_lib.py:133] step: 640350, training_loss: 4.18335e-02
I0212 16:24:26.006658 22509476222784 run_lib.py:133] step: 640400, training_loss: 4.45290e-02
I0212 16:24:26.174084 22509476222784 run_lib.py:146] step: 640400, eval_loss: 3.49996e-02
I0212 16:24:44.858281 22509476222784 run_lib.py:133] step: 640450, training_loss: 4.91278e-02
I0212 16:25:03.428749 22509476222784 run_lib.py:133] step: 640500, training_loss: 5.15491e-02
I0212 16:25:03.604510 22509476222784 run_lib.py:146] step: 640500, eval_loss: 3.98940e-02
I0212 16:25:22.175456 22509476222784 run_lib.py:133] step: 640550, training_loss: 3.53796e-02
I0212 16:25:40.699363 22509476222784 run_lib.py:133] step: 640600, training_loss: 4.70225e-02
I0212 16:25:40.862955 22509476222784 run_lib.py:146] step: 640600, eval_loss: 4.05006e-02
I0212 16:25:59.608450 22509476222784 run_lib.py:133] step: 640650, training_loss: 4.07634e-02
I0212 16:26:18.161029 22509476222784 run_lib.py:133] step: 640700, training_loss: 4.25309e-02
I0212 16:26:18.322727 22509476222784 run_lib.py:146] step: 640700, eval_loss: 4.47949e-02
I0212 16:26:36.984779 22509476222784 run_lib.py:133] step: 640750, training_loss: 4.20929e-02
I0212 16:26:55.568286 22509476222784 run_lib.py:133] step: 640800, training_loss: 4.07191e-02
I0212 16:26:55.752820 22509476222784 run_lib.py:146] step: 640800, eval_loss: 5.12170e-02
I0212 16:27:14.534813 22509476222784 run_lib.py:133] step: 640850, training_loss: 4.11746e-02
I0212 16:27:33.093826 22509476222784 run_lib.py:133] step: 640900, training_loss: 5.08343e-02
I0212 16:27:33.290927 22509476222784 run_lib.py:146] step: 640900, eval_loss: 4.51046e-02
I0212 16:27:51.832165 22509476222784 run_lib.py:133] step: 640950, training_loss: 4.27932e-02
I0212 16:28:10.534991 22509476222784 run_lib.py:133] step: 641000, training_loss: 4.62478e-02
I0212 16:28:10.734730 22509476222784 run_lib.py:146] step: 641000, eval_loss: 4.86968e-02
I0212 16:28:29.293041 22509476222784 run_lib.py:133] step: 641050, training_loss: 4.88622e-02
I0212 16:28:48.044589 22509476222784 run_lib.py:133] step: 641100, training_loss: 3.78608e-02
I0212 16:28:48.209905 22509476222784 run_lib.py:146] step: 641100, eval_loss: 3.87507e-02
I0212 16:29:06.792788 22509476222784 run_lib.py:133] step: 641150, training_loss: 4.92998e-02
I0212 16:29:25.298501 22509476222784 run_lib.py:133] step: 641200, training_loss: 3.37603e-02
I0212 16:29:25.458642 22509476222784 run_lib.py:146] step: 641200, eval_loss: 5.15712e-02
I0212 16:29:43.901580 22509476222784 run_lib.py:133] step: 641250, training_loss: 4.74722e-02
I0212 16:30:02.546755 22509476222784 run_lib.py:133] step: 641300, training_loss: 4.62203e-02
I0212 16:30:02.723842 22509476222784 run_lib.py:146] step: 641300, eval_loss: 2.68348e-02
I0212 16:30:21.331422 22509476222784 run_lib.py:133] step: 641350, training_loss: 4.32152e-02
I0212 16:30:39.980694 22509476222784 run_lib.py:133] step: 641400, training_loss: 4.34496e-02
I0212 16:30:40.147545 22509476222784 run_lib.py:146] step: 641400, eval_loss: 4.88187e-02
I0212 16:30:58.847293 22509476222784 run_lib.py:133] step: 641450, training_loss: 2.86688e-02
I0212 16:31:17.418500 22509476222784 run_lib.py:133] step: 641500, training_loss: 4.74080e-02
I0212 16:31:17.586660 22509476222784 run_lib.py:146] step: 641500, eval_loss: 3.83203e-02
I0212 16:31:36.189983 22509476222784 run_lib.py:133] step: 641550, training_loss: 3.68576e-02
I0212 16:31:54.758852 22509476222784 run_lib.py:133] step: 641600, training_loss: 3.95037e-02
I0212 16:31:54.922472 22509476222784 run_lib.py:146] step: 641600, eval_loss: 4.69536e-02
I0212 16:32:13.454431 22509476222784 run_lib.py:133] step: 641650, training_loss: 4.27159e-02
I0212 16:32:31.971578 22509476222784 run_lib.py:133] step: 641700, training_loss: 4.03232e-02
I0212 16:32:32.134682 22509476222784 run_lib.py:146] step: 641700, eval_loss: 4.16380e-02
I0212 16:32:50.801419 22509476222784 run_lib.py:133] step: 641750, training_loss: 3.25628e-02
I0212 16:33:09.392247 22509476222784 run_lib.py:133] step: 641800, training_loss: 4.91393e-02
I0212 16:33:09.558798 22509476222784 run_lib.py:146] step: 641800, eval_loss: 5.15052e-02
I0212 16:33:28.159335 22509476222784 run_lib.py:133] step: 641850, training_loss: 4.11286e-02
I0212 16:33:46.795728 22509476222784 run_lib.py:133] step: 641900, training_loss: 4.34497e-02
I0212 16:33:46.969992 22509476222784 run_lib.py:146] step: 641900, eval_loss: 4.13907e-02
I0212 16:34:05.679705 22509476222784 run_lib.py:133] step: 641950, training_loss: 3.91394e-02
I0212 16:34:24.198311 22509476222784 run_lib.py:133] step: 642000, training_loss: 4.05165e-02
I0212 16:34:24.362724 22509476222784 run_lib.py:146] step: 642000, eval_loss: 4.66272e-02
I0212 16:34:43.004125 22509476222784 run_lib.py:133] step: 642050, training_loss: 3.27912e-02
I0212 16:35:01.608507 22509476222784 run_lib.py:133] step: 642100, training_loss: 4.19192e-02
I0212 16:35:01.801967 22509476222784 run_lib.py:146] step: 642100, eval_loss: 4.25733e-02
I0212 16:35:20.559781 22509476222784 run_lib.py:133] step: 642150, training_loss: 4.72458e-02
I0212 16:35:39.038704 22509476222784 run_lib.py:133] step: 642200, training_loss: 4.11110e-02
I0212 16:35:39.205642 22509476222784 run_lib.py:146] step: 642200, eval_loss: 4.71333e-02
I0212 16:35:57.915075 22509476222784 run_lib.py:133] step: 642250, training_loss: 3.85248e-02
I0212 16:36:16.474587 22509476222784 run_lib.py:133] step: 642300, training_loss: 4.12458e-02
I0212 16:36:16.638125 22509476222784 run_lib.py:146] step: 642300, eval_loss: 4.68646e-02
I0212 16:36:35.165333 22509476222784 run_lib.py:133] step: 642350, training_loss: 3.44804e-02
I0212 16:36:53.783906 22509476222784 run_lib.py:133] step: 642400, training_loss: 4.10768e-02
I0212 16:36:53.956441 22509476222784 run_lib.py:146] step: 642400, eval_loss: 4.83429e-02
I0212 16:37:12.483454 22509476222784 run_lib.py:133] step: 642450, training_loss: 3.49214e-02
I0212 16:37:31.007285 22509476222784 run_lib.py:133] step: 642500, training_loss: 4.08316e-02
I0212 16:37:31.178415 22509476222784 run_lib.py:146] step: 642500, eval_loss: 3.17979e-02
I0212 16:37:49.898106 22509476222784 run_lib.py:133] step: 642550, training_loss: 4.67787e-02
I0212 16:38:08.603325 22509476222784 run_lib.py:133] step: 642600, training_loss: 3.84822e-02
I0212 16:38:08.776587 22509476222784 run_lib.py:146] step: 642600, eval_loss: 3.47907e-02
I0212 16:38:27.251996 22509476222784 run_lib.py:133] step: 642650, training_loss: 4.49034e-02
I0212 16:38:45.788649 22509476222784 run_lib.py:133] step: 642700, training_loss: 3.88476e-02
I0212 16:38:45.960102 22509476222784 run_lib.py:146] step: 642700, eval_loss: 4.30181e-02
I0212 16:39:04.493345 22509476222784 run_lib.py:133] step: 642750, training_loss: 5.04500e-02
I0212 16:39:23.232944 22509476222784 run_lib.py:133] step: 642800, training_loss: 4.05444e-02
I0212 16:39:23.461839 22509476222784 run_lib.py:146] step: 642800, eval_loss: 3.71471e-02
I0212 16:39:41.936421 22509476222784 run_lib.py:133] step: 642850, training_loss: 4.83318e-02
I0212 16:40:00.432565 22509476222784 run_lib.py:133] step: 642900, training_loss: 4.23821e-02
I0212 16:40:00.605716 22509476222784 run_lib.py:146] step: 642900, eval_loss: 5.55059e-02
I0212 16:40:19.155190 22509476222784 run_lib.py:133] step: 642950, training_loss: 2.80920e-02
I0212 16:40:37.907366 22509476222784 run_lib.py:133] step: 643000, training_loss: 3.85671e-02
I0212 16:40:38.105852 22509476222784 run_lib.py:146] step: 643000, eval_loss: 4.45482e-02
I0212 16:40:56.651755 22509476222784 run_lib.py:133] step: 643050, training_loss: 3.15332e-02
I0212 16:41:15.187131 22509476222784 run_lib.py:133] step: 643100, training_loss: 3.99834e-02
I0212 16:41:15.348605 22509476222784 run_lib.py:146] step: 643100, eval_loss: 3.11313e-02
I0212 16:41:33.777332 22509476222784 run_lib.py:133] step: 643150, training_loss: 5.07287e-02
I0212 16:41:52.346530 22509476222784 run_lib.py:133] step: 643200, training_loss: 3.49355e-02
I0212 16:41:52.538885 22509476222784 run_lib.py:146] step: 643200, eval_loss: 3.44394e-02
I0212 16:42:11.311426 22509476222784 run_lib.py:133] step: 643250, training_loss: 3.28714e-02
I0212 16:42:29.993521 22509476222784 run_lib.py:133] step: 643300, training_loss: 3.42210e-02
I0212 16:42:30.181650 22509476222784 run_lib.py:146] step: 643300, eval_loss: 4.21944e-02
I0212 16:42:48.716250 22509476222784 run_lib.py:133] step: 643350, training_loss: 2.98325e-02
I0212 16:43:07.225469 22509476222784 run_lib.py:133] step: 643400, training_loss: 5.07586e-02
I0212 16:43:07.432654 22509476222784 run_lib.py:146] step: 643400, eval_loss: 4.67384e-02
I0212 16:43:26.100026 22509476222784 run_lib.py:133] step: 643450, training_loss: 4.57789e-02
I0212 16:43:44.689444 22509476222784 run_lib.py:133] step: 643500, training_loss: 3.15593e-02
I0212 16:43:44.876895 22509476222784 run_lib.py:146] step: 643500, eval_loss: 4.71429e-02
I0212 16:44:03.660188 22509476222784 run_lib.py:133] step: 643550, training_loss: 5.17999e-02
I0212 16:44:22.189648 22509476222784 run_lib.py:133] step: 643600, training_loss: 4.84183e-02
I0212 16:44:22.352672 22509476222784 run_lib.py:146] step: 643600, eval_loss: 4.33938e-02
I0212 16:44:41.099165 22509476222784 run_lib.py:133] step: 643650, training_loss: 4.18313e-02
I0212 16:44:59.626123 22509476222784 run_lib.py:133] step: 643700, training_loss: 4.66434e-02
I0212 16:44:59.823825 22509476222784 run_lib.py:146] step: 643700, eval_loss: 4.20966e-02
I0212 16:45:18.392993 22509476222784 run_lib.py:133] step: 643750, training_loss: 3.47085e-02
I0212 16:45:37.199441 22509476222784 run_lib.py:133] step: 643800, training_loss: 3.49432e-02
I0212 16:45:37.410685 22509476222784 run_lib.py:146] step: 643800, eval_loss: 4.34175e-02
I0212 16:45:55.956105 22509476222784 run_lib.py:133] step: 643850, training_loss: 3.88694e-02
I0212 16:46:14.672193 22509476222784 run_lib.py:133] step: 643900, training_loss: 3.97924e-02
I0212 16:46:14.867517 22509476222784 run_lib.py:146] step: 643900, eval_loss: 4.67412e-02
I0212 16:46:33.426522 22509476222784 run_lib.py:133] step: 643950, training_loss: 4.16590e-02
I0212 16:46:51.996417 22509476222784 run_lib.py:133] step: 644000, training_loss: 4.74243e-02
I0212 16:46:52.259771 22509476222784 run_lib.py:146] step: 644000, eval_loss: 4.34313e-02
I0212 16:47:11.073232 22509476222784 run_lib.py:133] step: 644050, training_loss: 4.06378e-02
I0212 16:47:29.677517 22509476222784 run_lib.py:133] step: 644100, training_loss: 3.88938e-02
I0212 16:47:29.852606 22509476222784 run_lib.py:146] step: 644100, eval_loss: 6.13389e-02
I0212 16:47:48.379124 22509476222784 run_lib.py:133] step: 644150, training_loss: 2.23814e-02
I0212 16:48:07.056285 22509476222784 run_lib.py:133] step: 644200, training_loss: 3.47172e-02
I0212 16:48:07.258960 22509476222784 run_lib.py:146] step: 644200, eval_loss: 3.86058e-02
I0212 16:48:25.859563 22509476222784 run_lib.py:133] step: 644250, training_loss: 3.30091e-02
I0212 16:48:44.502225 22509476222784 run_lib.py:133] step: 644300, training_loss: 5.47103e-02
I0212 16:48:44.667873 22509476222784 run_lib.py:146] step: 644300, eval_loss: 4.46443e-02
I0212 16:49:03.313755 22509476222784 run_lib.py:133] step: 644350, training_loss: 3.23941e-02
I0212 16:49:21.802862 22509476222784 run_lib.py:133] step: 644400, training_loss: 4.44813e-02
I0212 16:49:21.968914 22509476222784 run_lib.py:146] step: 644400, eval_loss: 3.40640e-02
I0212 16:49:40.519096 22509476222784 run_lib.py:133] step: 644450, training_loss: 4.43424e-02
I0212 16:49:59.087590 22509476222784 run_lib.py:133] step: 644500, training_loss: 4.30310e-02
I0212 16:49:59.250904 22509476222784 run_lib.py:146] step: 644500, eval_loss: 4.65263e-02
I0212 16:50:18.028106 22509476222784 run_lib.py:133] step: 644550, training_loss: 3.88343e-02
I0212 16:50:36.691724 22509476222784 run_lib.py:133] step: 644600, training_loss: 3.60587e-02
I0212 16:50:36.887211 22509476222784 run_lib.py:146] step: 644600, eval_loss: 4.25659e-02
I0212 16:50:55.401641 22509476222784 run_lib.py:133] step: 644650, training_loss: 4.05664e-02
I0212 16:51:13.952276 22509476222784 run_lib.py:133] step: 644700, training_loss: 3.59668e-02
I0212 16:51:14.118189 22509476222784 run_lib.py:146] step: 644700, eval_loss: 3.66817e-02
I0212 16:51:32.786737 22509476222784 run_lib.py:133] step: 644750, training_loss: 4.03743e-02
I0212 16:51:51.389625 22509476222784 run_lib.py:133] step: 644800, training_loss: 4.41341e-02
I0212 16:51:51.556980 22509476222784 run_lib.py:146] step: 644800, eval_loss: 5.29419e-02
I0212 16:52:10.296738 22509476222784 run_lib.py:133] step: 644850, training_loss: 4.33112e-02
I0212 16:52:28.874281 22509476222784 run_lib.py:133] step: 644900, training_loss: 5.60300e-02
I0212 16:52:29.038395 22509476222784 run_lib.py:146] step: 644900, eval_loss: 5.21690e-02
I0212 16:52:47.765369 22509476222784 run_lib.py:133] step: 644950, training_loss: 3.64987e-02
I0212 16:53:06.317981 22509476222784 run_lib.py:133] step: 645000, training_loss: 4.46519e-02
I0212 16:53:06.478608 22509476222784 run_lib.py:146] step: 645000, eval_loss: 3.68384e-02
I0212 16:53:25.163522 22509476222784 run_lib.py:133] step: 645050, training_loss: 3.70010e-02
I0212 16:53:43.797646 22509476222784 run_lib.py:133] step: 645100, training_loss: 4.53354e-02
I0212 16:53:43.972776 22509476222784 run_lib.py:146] step: 645100, eval_loss: 3.18253e-02
I0212 16:54:02.531714 22509476222784 run_lib.py:133] step: 645150, training_loss: 4.08952e-02
I0212 16:54:21.280242 22509476222784 run_lib.py:133] step: 645200, training_loss: 3.12666e-02
I0212 16:54:21.445847 22509476222784 run_lib.py:146] step: 645200, eval_loss: 4.76409e-02
I0212 16:54:39.974334 22509476222784 run_lib.py:133] step: 645250, training_loss: 4.73892e-02
I0212 16:54:58.535705 22509476222784 run_lib.py:133] step: 645300, training_loss: 3.66743e-02
I0212 16:54:58.701649 22509476222784 run_lib.py:146] step: 645300, eval_loss: 3.85364e-02
I0212 16:55:17.423743 22509476222784 run_lib.py:133] step: 645350, training_loss: 4.46147e-02
I0212 16:55:36.082925 22509476222784 run_lib.py:133] step: 645400, training_loss: 3.57287e-02
I0212 16:55:36.263799 22509476222784 run_lib.py:146] step: 645400, eval_loss: 3.37949e-02
I0212 16:55:55.060428 22509476222784 run_lib.py:133] step: 645450, training_loss: 4.12659e-02
I0212 16:56:13.595618 22509476222784 run_lib.py:133] step: 645500, training_loss: 4.24976e-02
I0212 16:56:13.757766 22509476222784 run_lib.py:146] step: 645500, eval_loss: 4.92443e-02
I0212 16:56:32.295683 22509476222784 run_lib.py:133] step: 645550, training_loss: 4.12851e-02
I0212 16:56:50.987699 22509476222784 run_lib.py:133] step: 645600, training_loss: 5.20205e-02
I0212 16:56:51.171629 22509476222784 run_lib.py:146] step: 645600, eval_loss: 4.70202e-02
I0212 16:57:09.708557 22509476222784 run_lib.py:133] step: 645650, training_loss: 4.91802e-02
I0212 16:57:28.270967 22509476222784 run_lib.py:133] step: 645700, training_loss: 4.27961e-02
I0212 16:57:28.463796 22509476222784 run_lib.py:146] step: 645700, eval_loss: 4.97683e-02
I0212 16:57:46.970045 22509476222784 run_lib.py:133] step: 645750, training_loss: 3.96634e-02
I0212 16:58:05.679118 22509476222784 run_lib.py:133] step: 645800, training_loss: 4.06776e-02
I0212 16:58:05.844917 22509476222784 run_lib.py:146] step: 645800, eval_loss: 3.81925e-02
I0212 16:58:24.389991 22509476222784 run_lib.py:133] step: 645850, training_loss: 4.08443e-02
I0212 16:58:43.084771 22509476222784 run_lib.py:133] step: 645900, training_loss: 4.24791e-02
I0212 16:58:43.285010 22509476222784 run_lib.py:146] step: 645900, eval_loss: 4.85582e-02
I0212 16:59:01.829979 22509476222784 run_lib.py:133] step: 645950, training_loss: 3.66912e-02
I0212 16:59:20.347278 22509476222784 run_lib.py:133] step: 646000, training_loss: 4.49189e-02
I0212 16:59:20.509655 22509476222784 run_lib.py:146] step: 646000, eval_loss: 4.51401e-02
I0212 16:59:39.198416 22509476222784 run_lib.py:133] step: 646050, training_loss: 5.81345e-02
I0212 16:59:57.839800 22509476222784 run_lib.py:133] step: 646100, training_loss: 3.71196e-02
I0212 16:59:58.019588 22509476222784 run_lib.py:146] step: 646100, eval_loss: 4.20868e-02
I0212 17:00:16.618777 22509476222784 run_lib.py:133] step: 646150, training_loss: 4.75035e-02
I0212 17:00:35.233116 22509476222784 run_lib.py:133] step: 646200, training_loss: 5.26759e-02
I0212 17:00:35.415989 22509476222784 run_lib.py:146] step: 646200, eval_loss: 4.03642e-02
I0212 17:00:54.169298 22509476222784 run_lib.py:133] step: 646250, training_loss: 3.97481e-02
I0212 17:01:12.713201 22509476222784 run_lib.py:133] step: 646300, training_loss: 3.94804e-02
I0212 17:01:12.877336 22509476222784 run_lib.py:146] step: 646300, eval_loss: 5.38061e-02
I0212 17:01:31.591577 22509476222784 run_lib.py:133] step: 646350, training_loss: 3.71226e-02
I0212 17:01:50.220664 22509476222784 run_lib.py:133] step: 646400, training_loss: 3.49401e-02
I0212 17:01:50.386405 22509476222784 run_lib.py:146] step: 646400, eval_loss: 3.71532e-02
I0212 17:02:09.214517 22509476222784 run_lib.py:133] step: 646450, training_loss: 5.31389e-02
I0212 17:02:27.740175 22509476222784 run_lib.py:133] step: 646500, training_loss: 3.26359e-02
I0212 17:02:27.904820 22509476222784 run_lib.py:146] step: 646500, eval_loss: 3.15218e-02
I0212 17:02:46.420778 22509476222784 run_lib.py:133] step: 646550, training_loss: 3.53397e-02
I0212 17:03:05.171229 22509476222784 run_lib.py:133] step: 646600, training_loss: 3.99076e-02
I0212 17:03:05.390779 22509476222784 run_lib.py:146] step: 646600, eval_loss: 4.93039e-02
I0212 17:03:24.024887 22509476222784 run_lib.py:133] step: 646650, training_loss: 4.50295e-02
I0212 17:03:42.797119 22509476222784 run_lib.py:133] step: 646700, training_loss: 4.15314e-02
I0212 17:03:42.969071 22509476222784 run_lib.py:146] step: 646700, eval_loss: 4.27507e-02
I0212 17:04:01.556993 22509476222784 run_lib.py:133] step: 646750, training_loss: 3.59085e-02
I0212 17:04:20.049919 22509476222784 run_lib.py:133] step: 646800, training_loss: 3.81370e-02
I0212 17:04:20.216658 22509476222784 run_lib.py:146] step: 646800, eval_loss: 4.44114e-02
I0212 17:04:38.934279 22509476222784 run_lib.py:133] step: 646850, training_loss: 4.53708e-02
I0212 17:04:57.518313 22509476222784 run_lib.py:133] step: 646900, training_loss: 5.08212e-02
I0212 17:04:57.692788 22509476222784 run_lib.py:146] step: 646900, eval_loss: 4.18397e-02
I0212 17:05:16.310697 22509476222784 run_lib.py:133] step: 646950, training_loss: 4.56178e-02
I0212 17:05:35.074541 22509476222784 run_lib.py:133] step: 647000, training_loss: 3.64828e-02
I0212 17:05:35.294603 22509476222784 run_lib.py:146] step: 647000, eval_loss: 4.62482e-02
I0212 17:05:53.802689 22509476222784 run_lib.py:133] step: 647050, training_loss: 4.41992e-02
I0212 17:06:12.294107 22509476222784 run_lib.py:133] step: 647100, training_loss: 4.05720e-02
I0212 17:06:12.647708 22509476222784 run_lib.py:146] step: 647100, eval_loss: 5.20062e-02
I0212 17:06:31.174661 22509476222784 run_lib.py:133] step: 647150, training_loss: 4.10515e-02
I0212 17:06:49.748162 22509476222784 run_lib.py:133] step: 647200, training_loss: 4.28077e-02
I0212 17:06:49.913821 22509476222784 run_lib.py:146] step: 647200, eval_loss: 4.55999e-02
I0212 17:07:08.457098 22509476222784 run_lib.py:133] step: 647250, training_loss: 5.50952e-02
I0212 17:07:27.030602 22509476222784 run_lib.py:133] step: 647300, training_loss: 3.57025e-02
I0212 17:07:27.194411 22509476222784 run_lib.py:146] step: 647300, eval_loss: 4.59487e-02
I0212 17:07:45.903225 22509476222784 run_lib.py:133] step: 647350, training_loss: 4.64892e-02
I0212 17:08:04.582317 22509476222784 run_lib.py:133] step: 647400, training_loss: 3.69904e-02
I0212 17:08:04.743679 22509476222784 run_lib.py:146] step: 647400, eval_loss: 3.42138e-02
I0212 17:08:23.317239 22509476222784 run_lib.py:133] step: 647450, training_loss: 5.21806e-02
I0212 17:08:41.811954 22509476222784 run_lib.py:133] step: 647500, training_loss: 3.54317e-02
I0212 17:08:41.978591 22509476222784 run_lib.py:146] step: 647500, eval_loss: 4.53230e-02
I0212 17:09:00.688987 22509476222784 run_lib.py:133] step: 647550, training_loss: 4.00179e-02
I0212 17:09:19.359745 22509476222784 run_lib.py:133] step: 647600, training_loss: 4.52027e-02
I0212 17:09:19.524319 22509476222784 run_lib.py:146] step: 647600, eval_loss: 3.93509e-02
I0212 17:09:38.094160 22509476222784 run_lib.py:133] step: 647650, training_loss: 3.90497e-02
I0212 17:09:56.785748 22509476222784 run_lib.py:133] step: 647700, training_loss: 4.40094e-02
I0212 17:09:56.951181 22509476222784 run_lib.py:146] step: 647700, eval_loss: 4.46777e-02
I0212 17:10:15.710234 22509476222784 run_lib.py:133] step: 647750, training_loss: 4.66839e-02
I0212 17:10:34.233341 22509476222784 run_lib.py:133] step: 647800, training_loss: 3.13716e-02
I0212 17:10:34.396615 22509476222784 run_lib.py:146] step: 647800, eval_loss: 3.98744e-02
I0212 17:10:53.102249 22509476222784 run_lib.py:133] step: 647850, training_loss: 4.15420e-02
I0212 17:11:11.644164 22509476222784 run_lib.py:133] step: 647900, training_loss: 5.43924e-02
I0212 17:11:11.851851 22509476222784 run_lib.py:146] step: 647900, eval_loss: 4.43148e-02
I0212 17:11:30.568716 22509476222784 run_lib.py:133] step: 647950, training_loss: 4.25102e-02
I0212 17:11:49.139482 22509476222784 run_lib.py:133] step: 648000, training_loss: 4.48742e-02
I0212 17:11:49.329418 22509476222784 run_lib.py:146] step: 648000, eval_loss: 4.59592e-02
I0212 17:12:07.899813 22509476222784 run_lib.py:133] step: 648050, training_loss: 4.29696e-02
I0212 17:12:26.600065 22509476222784 run_lib.py:133] step: 648100, training_loss: 4.30757e-02
I0212 17:12:26.767839 22509476222784 run_lib.py:146] step: 648100, eval_loss: 4.65559e-02
I0212 17:12:45.294893 22509476222784 run_lib.py:133] step: 648150, training_loss: 3.99175e-02
I0212 17:13:04.037347 22509476222784 run_lib.py:133] step: 648200, training_loss: 4.58005e-02
I0212 17:13:04.251993 22509476222784 run_lib.py:146] step: 648200, eval_loss: 3.76378e-02
I0212 17:13:22.851379 22509476222784 run_lib.py:133] step: 648250, training_loss: 3.59354e-02
I0212 17:13:41.425840 22509476222784 run_lib.py:133] step: 648300, training_loss: 3.37522e-02
I0212 17:13:41.586689 22509476222784 run_lib.py:146] step: 648300, eval_loss: 4.31213e-02
I0212 17:14:00.173399 22509476222784 run_lib.py:133] step: 648350, training_loss: 4.04377e-02
I0212 17:14:18.909074 22509476222784 run_lib.py:133] step: 648400, training_loss: 4.25738e-02
I0212 17:14:19.115630 22509476222784 run_lib.py:146] step: 648400, eval_loss: 3.94735e-02
I0212 17:14:37.627712 22509476222784 run_lib.py:133] step: 648450, training_loss: 3.49166e-02
I0212 17:14:56.172023 22509476222784 run_lib.py:133] step: 648500, training_loss: 3.62100e-02
I0212 17:14:56.351581 22509476222784 run_lib.py:146] step: 648500, eval_loss: 4.10331e-02
I0212 17:15:15.092073 22509476222784 run_lib.py:133] step: 648550, training_loss: 4.35733e-02
I0212 17:15:33.671290 22509476222784 run_lib.py:133] step: 648600, training_loss: 5.33013e-02
I0212 17:15:33.836931 22509476222784 run_lib.py:146] step: 648600, eval_loss: 4.50768e-02
I0212 17:15:52.495793 22509476222784 run_lib.py:133] step: 648650, training_loss: 4.80347e-02
I0212 17:16:11.009492 22509476222784 run_lib.py:133] step: 648700, training_loss: 4.26734e-02
I0212 17:16:11.219697 22509476222784 run_lib.py:146] step: 648700, eval_loss: 4.38654e-02
I0212 17:16:29.734118 22509476222784 run_lib.py:133] step: 648750, training_loss: 2.84832e-02
I0212 17:16:48.304311 22509476222784 run_lib.py:133] step: 648800, training_loss: 4.04067e-02
I0212 17:16:48.470868 22509476222784 run_lib.py:146] step: 648800, eval_loss: 3.59096e-02
I0212 17:17:07.226465 22509476222784 run_lib.py:133] step: 648850, training_loss: 4.64530e-02
I0212 17:17:25.839890 22509476222784 run_lib.py:133] step: 648900, training_loss: 4.79141e-02
I0212 17:17:26.005674 22509476222784 run_lib.py:146] step: 648900, eval_loss: 5.10457e-02
I0212 17:17:44.502210 22509476222784 run_lib.py:133] step: 648950, training_loss: 3.13323e-02
I0212 17:18:03.072811 22509476222784 run_lib.py:133] step: 649000, training_loss: 3.42395e-02
I0212 17:18:03.240267 22509476222784 run_lib.py:146] step: 649000, eval_loss: 5.52957e-02
I0212 17:18:21.971763 22509476222784 run_lib.py:133] step: 649050, training_loss: 3.44984e-02
I0212 17:18:40.557085 22509476222784 run_lib.py:133] step: 649100, training_loss: 4.59328e-02
I0212 17:18:40.805129 22509476222784 run_lib.py:146] step: 649100, eval_loss: 3.67331e-02
I0212 17:18:59.518901 22509476222784 run_lib.py:133] step: 649150, training_loss: 4.06060e-02
I0212 17:19:18.069246 22509476222784 run_lib.py:133] step: 649200, training_loss: 4.57921e-02
I0212 17:19:18.264664 22509476222784 run_lib.py:146] step: 649200, eval_loss: 3.61876e-02
I0212 17:19:36.897784 22509476222784 run_lib.py:133] step: 649250, training_loss: 3.71049e-02
I0212 17:19:55.456551 22509476222784 run_lib.py:133] step: 649300, training_loss: 4.00415e-02
I0212 17:19:55.622810 22509476222784 run_lib.py:146] step: 649300, eval_loss: 3.30003e-02
I0212 17:20:14.451235 22509476222784 run_lib.py:133] step: 649350, training_loss: 4.30936e-02
I0212 17:20:33.038886 22509476222784 run_lib.py:133] step: 649400, training_loss: 3.18915e-02
I0212 17:20:33.236660 22509476222784 run_lib.py:146] step: 649400, eval_loss: 4.18349e-02
I0212 17:20:51.788541 22509476222784 run_lib.py:133] step: 649450, training_loss: 4.84113e-02
I0212 17:21:10.497870 22509476222784 run_lib.py:133] step: 649500, training_loss: 4.93517e-02
I0212 17:21:10.713769 22509476222784 run_lib.py:146] step: 649500, eval_loss: 3.99980e-02
I0212 17:21:29.293935 22509476222784 run_lib.py:133] step: 649550, training_loss: 4.71509e-02
I0212 17:21:47.940171 22509476222784 run_lib.py:133] step: 649600, training_loss: 3.72238e-02
I0212 17:21:48.104454 22509476222784 run_lib.py:146] step: 649600, eval_loss: 4.17033e-02
I0212 17:22:06.868046 22509476222784 run_lib.py:133] step: 649650, training_loss: 3.70115e-02
I0212 17:22:25.600274 22509476222784 run_lib.py:133] step: 649700, training_loss: 4.88124e-02
I0212 17:22:25.764417 22509476222784 run_lib.py:146] step: 649700, eval_loss: 4.49355e-02
I0212 17:22:44.307433 22509476222784 run_lib.py:133] step: 649750, training_loss: 3.91569e-02
I0212 17:23:02.877517 22509476222784 run_lib.py:133] step: 649800, training_loss: 4.25742e-02
I0212 17:23:03.054725 22509476222784 run_lib.py:146] step: 649800, eval_loss: 4.79530e-02
I0212 17:23:21.623855 22509476222784 run_lib.py:133] step: 649850, training_loss: 4.86657e-02
I0212 17:23:40.399689 22509476222784 run_lib.py:133] step: 649900, training_loss: 4.39398e-02
I0212 17:23:40.567709 22509476222784 run_lib.py:146] step: 649900, eval_loss: 4.90593e-02
I0212 17:23:59.087752 22509476222784 run_lib.py:133] step: 649950, training_loss: 3.96330e-02
I0212 17:24:17.618856 22509476222784 run_lib.py:133] step: 650000, training_loss: 3.41650e-02
I0212 17:24:18.370379 22509476222784 run_lib.py:146] step: 650000, eval_loss: 4.57134e-02
I0212 17:24:39.608216 22509476222784 run_lib.py:133] step: 650050, training_loss: 4.51218e-02
I0212 17:24:58.298817 22509476222784 run_lib.py:133] step: 650100, training_loss: 3.80731e-02
I0212 17:24:58.472669 22509476222784 run_lib.py:146] step: 650100, eval_loss: 4.40353e-02
I0212 17:25:17.022433 22509476222784 run_lib.py:133] step: 650150, training_loss: 4.29805e-02
I0212 17:25:35.559322 22509476222784 run_lib.py:133] step: 650200, training_loss: 4.03169e-02
I0212 17:25:35.731780 22509476222784 run_lib.py:146] step: 650200, eval_loss: 3.31103e-02
I0212 17:25:54.390554 22509476222784 run_lib.py:133] step: 650250, training_loss: 5.23154e-02
I0212 17:26:12.936054 22509476222784 run_lib.py:133] step: 650300, training_loss: 2.40539e-02
I0212 17:26:13.097557 22509476222784 run_lib.py:146] step: 650300, eval_loss: 4.57849e-02
I0212 17:26:31.619467 22509476222784 run_lib.py:133] step: 650350, training_loss: 5.47384e-02
I0212 17:26:50.186688 22509476222784 run_lib.py:133] step: 650400, training_loss: 4.41392e-02
I0212 17:26:50.361902 22509476222784 run_lib.py:146] step: 650400, eval_loss: 5.59032e-02
I0212 17:27:09.087789 22509476222784 run_lib.py:133] step: 650450, training_loss: 3.57130e-02
I0212 17:27:27.730608 22509476222784 run_lib.py:133] step: 650500, training_loss: 3.95361e-02
I0212 17:27:27.896585 22509476222784 run_lib.py:146] step: 650500, eval_loss: 4.04507e-02
I0212 17:27:46.416980 22509476222784 run_lib.py:133] step: 650550, training_loss: 4.35388e-02
I0212 17:28:04.985514 22509476222784 run_lib.py:133] step: 650600, training_loss: 5.11912e-02
I0212 17:28:05.281599 22509476222784 run_lib.py:146] step: 650600, eval_loss: 4.66809e-02
I0212 17:28:23.920210 22509476222784 run_lib.py:133] step: 650650, training_loss: 4.12207e-02
I0212 17:28:42.453361 22509476222784 run_lib.py:133] step: 650700, training_loss: 4.83800e-02
I0212 17:28:42.618803 22509476222784 run_lib.py:146] step: 650700, eval_loss: 5.00225e-02
I0212 17:29:01.339948 22509476222784 run_lib.py:133] step: 650750, training_loss: 4.43685e-02
I0212 17:29:19.895342 22509476222784 run_lib.py:133] step: 650800, training_loss: 4.07442e-02
I0212 17:29:20.084657 22509476222784 run_lib.py:146] step: 650800, eval_loss: 4.61859e-02
I0212 17:29:38.770312 22509476222784 run_lib.py:133] step: 650850, training_loss: 4.12992e-02
I0212 17:29:57.299134 22509476222784 run_lib.py:133] step: 650900, training_loss: 5.41035e-02
I0212 17:29:57.509644 22509476222784 run_lib.py:146] step: 650900, eval_loss: 3.82500e-02
I0212 17:30:16.306151 22509476222784 run_lib.py:133] step: 650950, training_loss: 4.80466e-02
I0212 17:30:34.891057 22509476222784 run_lib.py:133] step: 651000, training_loss: 3.82667e-02
I0212 17:30:35.081805 22509476222784 run_lib.py:146] step: 651000, eval_loss: 4.11533e-02
I0212 17:30:53.605258 22509476222784 run_lib.py:133] step: 651050, training_loss: 3.62955e-02
I0212 17:31:12.213150 22509476222784 run_lib.py:133] step: 651100, training_loss: 4.34978e-02
I0212 17:31:12.380840 22509476222784 run_lib.py:146] step: 651100, eval_loss: 3.50217e-02
I0212 17:31:30.910952 22509476222784 run_lib.py:133] step: 651150, training_loss: 2.99991e-02
I0212 17:31:49.482131 22509476222784 run_lib.py:133] step: 651200, training_loss: 3.61255e-02
I0212 17:31:49.650330 22509476222784 run_lib.py:146] step: 651200, eval_loss: 5.88562e-02
I0212 17:32:08.405004 22509476222784 run_lib.py:133] step: 651250, training_loss: 5.23484e-02
I0212 17:32:26.968752 22509476222784 run_lib.py:133] step: 651300, training_loss: 4.10505e-02
I0212 17:32:27.131457 22509476222784 run_lib.py:146] step: 651300, eval_loss: 4.93036e-02
I0212 17:32:45.802140 22509476222784 run_lib.py:133] step: 651350, training_loss: 4.74045e-02
I0212 17:33:04.318283 22509476222784 run_lib.py:133] step: 651400, training_loss: 4.19371e-02
I0212 17:33:04.494737 22509476222784 run_lib.py:146] step: 651400, eval_loss: 4.10696e-02
I0212 17:33:23.051718 22509476222784 run_lib.py:133] step: 651450, training_loss: 5.13477e-02
I0212 17:33:41.779135 22509476222784 run_lib.py:133] step: 651500, training_loss: 4.21330e-02
I0212 17:33:41.944950 22509476222784 run_lib.py:146] step: 651500, eval_loss: 4.78225e-02
I0212 17:34:00.479441 22509476222784 run_lib.py:133] step: 651550, training_loss: 4.39917e-02
I0212 17:34:19.008944 22509476222784 run_lib.py:133] step: 651600, training_loss: 4.06325e-02
I0212 17:34:19.173775 22509476222784 run_lib.py:146] step: 651600, eval_loss: 4.69598e-02
I0212 17:34:37.680501 22509476222784 run_lib.py:133] step: 651650, training_loss: 4.09326e-02
I0212 17:34:56.395485 22509476222784 run_lib.py:133] step: 651700, training_loss: 4.10640e-02
I0212 17:34:56.582134 22509476222784 run_lib.py:146] step: 651700, eval_loss: 5.67841e-02
I0212 17:35:15.225792 22509476222784 run_lib.py:133] step: 651750, training_loss: 4.15631e-02
I0212 17:35:33.873559 22509476222784 run_lib.py:133] step: 651800, training_loss: 4.39096e-02
I0212 17:35:34.069663 22509476222784 run_lib.py:146] step: 651800, eval_loss: 3.58951e-02
I0212 17:35:52.606442 22509476222784 run_lib.py:133] step: 651850, training_loss: 3.77744e-02
I0212 17:36:11.099237 22509476222784 run_lib.py:133] step: 651900, training_loss: 2.59881e-02
I0212 17:36:11.266527 22509476222784 run_lib.py:146] step: 651900, eval_loss: 4.70927e-02
I0212 17:36:30.012102 22509476222784 run_lib.py:133] step: 651950, training_loss: 4.25201e-02
I0212 17:36:48.752286 22509476222784 run_lib.py:133] step: 652000, training_loss: 4.64834e-02
I0212 17:36:48.919859 22509476222784 run_lib.py:146] step: 652000, eval_loss: 4.68592e-02
I0212 17:37:07.451088 22509476222784 run_lib.py:133] step: 652050, training_loss: 3.82159e-02
I0212 17:37:25.967428 22509476222784 run_lib.py:133] step: 652100, training_loss: 3.66067e-02
I0212 17:37:26.131601 22509476222784 run_lib.py:146] step: 652100, eval_loss: 5.22002e-02
I0212 17:37:44.784616 22509476222784 run_lib.py:133] step: 652150, training_loss: 4.02328e-02
I0212 17:38:03.303793 22509476222784 run_lib.py:133] step: 652200, training_loss: 5.07663e-02
I0212 17:38:03.468776 22509476222784 run_lib.py:146] step: 652200, eval_loss: 4.70125e-02
I0212 17:38:22.288297 22509476222784 run_lib.py:133] step: 652250, training_loss: 3.97213e-02
I0212 17:38:40.853040 22509476222784 run_lib.py:133] step: 652300, training_loss: 3.51732e-02
I0212 17:38:41.016478 22509476222784 run_lib.py:146] step: 652300, eval_loss: 3.98394e-02
I0212 17:38:59.745577 22509476222784 run_lib.py:133] step: 652350, training_loss: 5.00971e-02
I0212 17:39:18.345188 22509476222784 run_lib.py:133] step: 652400, training_loss: 3.96968e-02
I0212 17:39:18.510843 22509476222784 run_lib.py:146] step: 652400, eval_loss: 4.10471e-02
I0212 17:39:37.048418 22509476222784 run_lib.py:133] step: 652450, training_loss: 5.02190e-02
I0212 17:39:55.840315 22509476222784 run_lib.py:133] step: 652500, training_loss: 3.38119e-02
I0212 17:39:56.035827 22509476222784 run_lib.py:146] step: 652500, eval_loss: 3.47463e-02
I0212 17:40:14.532471 22509476222784 run_lib.py:133] step: 652550, training_loss: 6.02391e-02
I0212 17:40:33.238461 22509476222784 run_lib.py:133] step: 652600, training_loss: 4.71488e-02
I0212 17:40:33.421659 22509476222784 run_lib.py:146] step: 652600, eval_loss: 3.90886e-02
I0212 17:40:51.942564 22509476222784 run_lib.py:133] step: 652650, training_loss: 4.37146e-02
I0212 17:41:10.468975 22509476222784 run_lib.py:133] step: 652700, training_loss: 4.36543e-02
I0212 17:41:10.654675 22509476222784 run_lib.py:146] step: 652700, eval_loss: 3.45172e-02
I0212 17:41:29.359388 22509476222784 run_lib.py:133] step: 652750, training_loss: 3.67748e-02
I0212 17:41:47.927940 22509476222784 run_lib.py:133] step: 652800, training_loss: 5.12257e-02
I0212 17:41:48.133665 22509476222784 run_lib.py:146] step: 652800, eval_loss: 4.08889e-02
I0212 17:42:06.637052 22509476222784 run_lib.py:133] step: 652850, training_loss: 3.01962e-02
I0212 17:42:25.366144 22509476222784 run_lib.py:133] step: 652900, training_loss: 3.65028e-02
I0212 17:42:25.561609 22509476222784 run_lib.py:146] step: 652900, eval_loss: 2.99776e-02
I0212 17:42:44.070656 22509476222784 run_lib.py:133] step: 652950, training_loss: 4.92676e-02
I0212 17:43:02.595945 22509476222784 run_lib.py:133] step: 653000, training_loss: 3.36167e-02
I0212 17:43:02.909709 22509476222784 run_lib.py:146] step: 653000, eval_loss: 3.84267e-02
I0212 17:43:21.476370 22509476222784 run_lib.py:133] step: 653050, training_loss: 4.46034e-02
I0212 17:43:40.049510 22509476222784 run_lib.py:133] step: 653100, training_loss: 3.98028e-02
I0212 17:43:40.211044 22509476222784 run_lib.py:146] step: 653100, eval_loss: 4.10681e-02
I0212 17:43:58.691236 22509476222784 run_lib.py:133] step: 653150, training_loss: 3.95074e-02
I0212 17:44:17.216956 22509476222784 run_lib.py:133] step: 653200, training_loss: 3.62857e-02
I0212 17:44:17.411654 22509476222784 run_lib.py:146] step: 653200, eval_loss: 5.25155e-02
I0212 17:44:36.077601 22509476222784 run_lib.py:133] step: 653250, training_loss: 4.55105e-02
I0212 17:44:54.765086 22509476222784 run_lib.py:133] step: 653300, training_loss: 3.87935e-02
I0212 17:44:54.944534 22509476222784 run_lib.py:146] step: 653300, eval_loss: 4.19209e-02
I0212 17:45:13.518047 22509476222784 run_lib.py:133] step: 653350, training_loss: 4.58143e-02
I0212 17:45:32.134974 22509476222784 run_lib.py:133] step: 653400, training_loss: 3.79128e-02
I0212 17:45:32.300877 22509476222784 run_lib.py:146] step: 653400, eval_loss: 4.73341e-02
I0212 17:45:51.045702 22509476222784 run_lib.py:133] step: 653450, training_loss: 3.77019e-02
I0212 17:46:09.673253 22509476222784 run_lib.py:133] step: 653500, training_loss: 3.60511e-02
I0212 17:46:09.848787 22509476222784 run_lib.py:146] step: 653500, eval_loss: 3.78363e-02
I0212 17:46:28.458606 22509476222784 run_lib.py:133] step: 653550, training_loss: 4.22486e-02
I0212 17:46:47.059438 22509476222784 run_lib.py:133] step: 653600, training_loss: 3.49265e-02
I0212 17:46:47.220917 22509476222784 run_lib.py:146] step: 653600, eval_loss: 4.21761e-02
I0212 17:47:06.004765 22509476222784 run_lib.py:133] step: 653650, training_loss: 5.64137e-02
I0212 17:47:24.546755 22509476222784 run_lib.py:133] step: 653700, training_loss: 4.54742e-02
I0212 17:47:24.711630 22509476222784 run_lib.py:146] step: 653700, eval_loss: 3.83502e-02
I0212 17:47:43.339341 22509476222784 run_lib.py:133] step: 653750, training_loss: 4.56788e-02
I0212 17:48:01.922107 22509476222784 run_lib.py:133] step: 653800, training_loss: 3.62458e-02
I0212 17:48:02.142734 22509476222784 run_lib.py:146] step: 653800, eval_loss: 3.61110e-02
I0212 17:48:20.889512 22509476222784 run_lib.py:133] step: 653850, training_loss: 5.33801e-02
I0212 17:48:39.494131 22509476222784 run_lib.py:133] step: 653900, training_loss: 2.99425e-02
I0212 17:48:39.657922 22509476222784 run_lib.py:146] step: 653900, eval_loss: 5.19310e-02
I0212 17:48:58.187131 22509476222784 run_lib.py:133] step: 653950, training_loss: 4.08667e-02
I0212 17:49:16.881261 22509476222784 run_lib.py:133] step: 654000, training_loss: 4.11274e-02
I0212 17:49:17.042474 22509476222784 run_lib.py:146] step: 654000, eval_loss: 2.95964e-02
I0212 17:49:35.527546 22509476222784 run_lib.py:133] step: 654050, training_loss: 3.93204e-02
I0212 17:49:54.250934 22509476222784 run_lib.py:133] step: 654100, training_loss: 3.02095e-02
I0212 17:49:54.449800 22509476222784 run_lib.py:146] step: 654100, eval_loss: 4.04600e-02
I0212 17:50:13.021137 22509476222784 run_lib.py:133] step: 654150, training_loss: 4.78061e-02
I0212 17:50:31.586405 22509476222784 run_lib.py:133] step: 654200, training_loss: 4.20721e-02
I0212 17:50:31.751999 22509476222784 run_lib.py:146] step: 654200, eval_loss: 3.99895e-02
I0212 17:50:50.483610 22509476222784 run_lib.py:133] step: 654250, training_loss: 4.49526e-02
I0212 17:51:09.033152 22509476222784 run_lib.py:133] step: 654300, training_loss: 4.31649e-02
I0212 17:51:09.214934 22509476222784 run_lib.py:146] step: 654300, eval_loss: 4.05240e-02
I0212 17:51:27.742090 22509476222784 run_lib.py:133] step: 654350, training_loss: 4.72189e-02
I0212 17:51:46.314139 22509476222784 run_lib.py:133] step: 654400, training_loss: 4.21627e-02
I0212 17:51:46.499107 22509476222784 run_lib.py:146] step: 654400, eval_loss: 4.21946e-02
I0212 17:52:05.241113 22509476222784 run_lib.py:133] step: 654450, training_loss: 3.22644e-02
I0212 17:52:23.746255 22509476222784 run_lib.py:133] step: 654500, training_loss: 3.41208e-02
I0212 17:52:23.910536 22509476222784 run_lib.py:146] step: 654500, eval_loss: 3.50674e-02
I0212 17:52:42.539653 22509476222784 run_lib.py:133] step: 654550, training_loss: 5.08500e-02
I0212 17:53:01.133984 22509476222784 run_lib.py:133] step: 654600, training_loss: 4.54816e-02
I0212 17:53:01.321895 22509476222784 run_lib.py:146] step: 654600, eval_loss: 4.72687e-02
I0212 17:53:19.917664 22509476222784 run_lib.py:133] step: 654650, training_loss: 3.89398e-02
I0212 17:53:38.441533 22509476222784 run_lib.py:133] step: 654700, training_loss: 4.22113e-02
I0212 17:53:38.607621 22509476222784 run_lib.py:146] step: 654700, eval_loss: 4.91047e-02
I0212 17:53:57.325517 22509476222784 run_lib.py:133] step: 654750, training_loss: 4.59340e-02
I0212 17:54:15.971851 22509476222784 run_lib.py:133] step: 654800, training_loss: 4.18919e-02
I0212 17:54:16.136651 22509476222784 run_lib.py:146] step: 654800, eval_loss: 4.06510e-02
I0212 17:54:34.691675 22509476222784 run_lib.py:133] step: 654850, training_loss: 4.32816e-02
I0212 17:54:53.251883 22509476222784 run_lib.py:133] step: 654900, training_loss: 5.29910e-02
I0212 17:54:53.416505 22509476222784 run_lib.py:146] step: 654900, eval_loss: 3.98627e-02
I0212 17:55:12.189055 22509476222784 run_lib.py:133] step: 654950, training_loss: 6.20818e-02
I0212 17:55:30.755574 22509476222784 run_lib.py:133] step: 655000, training_loss: 3.25745e-02
I0212 17:55:30.917521 22509476222784 run_lib.py:146] step: 655000, eval_loss: 4.66376e-02
I0212 17:55:49.580399 22509476222784 run_lib.py:133] step: 655050, training_loss: 4.51204e-02
I0212 17:56:08.112971 22509476222784 run_lib.py:133] step: 655100, training_loss: 4.75980e-02
I0212 17:56:08.329851 22509476222784 run_lib.py:146] step: 655100, eval_loss: 4.04281e-02
I0212 17:56:27.074302 22509476222784 run_lib.py:133] step: 655150, training_loss: 5.34397e-02
I0212 17:56:45.644792 22509476222784 run_lib.py:133] step: 655200, training_loss: 4.83525e-02
I0212 17:56:45.842838 22509476222784 run_lib.py:146] step: 655200, eval_loss: 4.37168e-02
I0212 17:57:04.544008 22509476222784 run_lib.py:133] step: 655250, training_loss: 4.11583e-02
I0212 17:57:23.095558 22509476222784 run_lib.py:133] step: 655300, training_loss: 5.15213e-02
I0212 17:57:23.260750 22509476222784 run_lib.py:146] step: 655300, eval_loss: 4.13056e-02
I0212 17:57:41.815267 22509476222784 run_lib.py:133] step: 655350, training_loss: 3.90965e-02
I0212 17:58:00.536582 22509476222784 run_lib.py:133] step: 655400, training_loss: 4.77332e-02
I0212 17:58:00.730470 22509476222784 run_lib.py:146] step: 655400, eval_loss: 4.71559e-02
I0212 17:58:19.351888 22509476222784 run_lib.py:133] step: 655450, training_loss: 5.60074e-02
I0212 17:58:37.898477 22509476222784 run_lib.py:133] step: 655500, training_loss: 4.32522e-02
I0212 17:58:38.058786 22509476222784 run_lib.py:146] step: 655500, eval_loss: 3.49121e-02
I0212 17:58:56.727561 22509476222784 run_lib.py:133] step: 655550, training_loss: 4.04630e-02
I0212 17:59:15.450340 22509476222784 run_lib.py:133] step: 655600, training_loss: 3.82641e-02
I0212 17:59:15.614625 22509476222784 run_lib.py:146] step: 655600, eval_loss: 4.40852e-02
I0212 17:59:34.104580 22509476222784 run_lib.py:133] step: 655650, training_loss: 4.60687e-02
I0212 17:59:52.722329 22509476222784 run_lib.py:133] step: 655700, training_loss: 4.66738e-02
I0212 17:59:52.933650 22509476222784 run_lib.py:146] step: 655700, eval_loss: 4.14485e-02
I0212 18:00:11.474367 22509476222784 run_lib.py:133] step: 655750, training_loss: 5.40823e-02
I0212 18:00:30.201634 22509476222784 run_lib.py:133] step: 655800, training_loss: 4.19802e-02
I0212 18:00:30.366675 22509476222784 run_lib.py:146] step: 655800, eval_loss: 6.21941e-02
I0212 18:00:48.910892 22509476222784 run_lib.py:133] step: 655850, training_loss: 3.63754e-02
I0212 18:01:07.435080 22509476222784 run_lib.py:133] step: 655900, training_loss: 5.02508e-02
I0212 18:01:07.646646 22509476222784 run_lib.py:146] step: 655900, eval_loss: 3.76906e-02
I0212 18:01:26.214816 22509476222784 run_lib.py:133] step: 655950, training_loss: 4.51650e-02
I0212 18:01:44.995551 22509476222784 run_lib.py:133] step: 656000, training_loss: 4.12346e-02
I0212 18:01:45.187902 22509476222784 run_lib.py:146] step: 656000, eval_loss: 4.48311e-02
I0212 18:02:03.731049 22509476222784 run_lib.py:133] step: 656050, training_loss: 4.79438e-02
I0212 18:02:22.342121 22509476222784 run_lib.py:133] step: 656100, training_loss: 3.40699e-02
I0212 18:02:22.507829 22509476222784 run_lib.py:146] step: 656100, eval_loss: 4.40840e-02
I0212 18:02:41.058071 22509476222784 run_lib.py:133] step: 656150, training_loss: 3.78086e-02
I0212 18:02:59.611697 22509476222784 run_lib.py:133] step: 656200, training_loss: 3.89666e-02
I0212 18:02:59.792789 22509476222784 run_lib.py:146] step: 656200, eval_loss: 4.11139e-02
I0212 18:03:18.559054 22509476222784 run_lib.py:133] step: 656250, training_loss: 4.24554e-02
I0212 18:03:37.237914 22509476222784 run_lib.py:133] step: 656300, training_loss: 4.00475e-02
I0212 18:03:37.402471 22509476222784 run_lib.py:146] step: 656300, eval_loss: 4.30440e-02
I0212 18:03:55.955314 22509476222784 run_lib.py:133] step: 656350, training_loss: 5.21811e-02
I0212 18:04:14.499795 22509476222784 run_lib.py:133] step: 656400, training_loss: 3.49751e-02
I0212 18:04:14.662868 22509476222784 run_lib.py:146] step: 656400, eval_loss: 4.23547e-02
I0212 18:04:33.326375 22509476222784 run_lib.py:133] step: 656450, training_loss: 4.30839e-02
I0212 18:04:51.906976 22509476222784 run_lib.py:133] step: 656500, training_loss: 3.03174e-02
I0212 18:04:52.072897 22509476222784 run_lib.py:146] step: 656500, eval_loss: 4.09537e-02
I0212 18:05:10.841053 22509476222784 run_lib.py:133] step: 656550, training_loss: 4.88631e-02
I0212 18:05:29.395636 22509476222784 run_lib.py:133] step: 656600, training_loss: 5.92321e-02
I0212 18:05:29.561715 22509476222784 run_lib.py:146] step: 656600, eval_loss: 4.41819e-02
I0212 18:05:48.263403 22509476222784 run_lib.py:133] step: 656650, training_loss: 3.72933e-02
I0212 18:06:06.761154 22509476222784 run_lib.py:133] step: 656700, training_loss: 3.38611e-02
I0212 18:06:06.926696 22509476222784 run_lib.py:146] step: 656700, eval_loss: 4.31628e-02
I0212 18:06:25.416677 22509476222784 run_lib.py:133] step: 656750, training_loss: 4.02614e-02
I0212 18:06:44.237024 22509476222784 run_lib.py:133] step: 656800, training_loss: 4.65263e-02
I0212 18:06:44.400887 22509476222784 run_lib.py:146] step: 656800, eval_loss: 4.64422e-02
I0212 18:07:03.000796 22509476222784 run_lib.py:133] step: 656850, training_loss: 3.70726e-02
I0212 18:07:21.689580 22509476222784 run_lib.py:133] step: 656900, training_loss: 4.26046e-02
I0212 18:07:21.850653 22509476222784 run_lib.py:146] step: 656900, eval_loss: 4.95794e-02
I0212 18:07:40.371838 22509476222784 run_lib.py:133] step: 656950, training_loss: 4.56135e-02
I0212 18:07:58.903712 22509476222784 run_lib.py:133] step: 657000, training_loss: 4.01799e-02
I0212 18:07:59.119838 22509476222784 run_lib.py:146] step: 657000, eval_loss: 4.26178e-02
I0212 18:08:17.853863 22509476222784 run_lib.py:133] step: 657050, training_loss: 4.77423e-02
I0212 18:08:36.463242 22509476222784 run_lib.py:133] step: 657100, training_loss: 4.09403e-02
I0212 18:08:36.648792 22509476222784 run_lib.py:146] step: 657100, eval_loss: 3.91725e-02
I0212 18:08:55.195324 22509476222784 run_lib.py:133] step: 657150, training_loss: 3.90125e-02
I0212 18:09:13.959768 22509476222784 run_lib.py:133] step: 657200, training_loss: 4.60507e-02
I0212 18:09:14.123587 22509476222784 run_lib.py:146] step: 657200, eval_loss: 4.81667e-02
I0212 18:09:32.686270 22509476222784 run_lib.py:133] step: 657250, training_loss: 4.49417e-02
I0212 18:09:51.330336 22509476222784 run_lib.py:133] step: 657300, training_loss: 4.48963e-02
I0212 18:09:51.503713 22509476222784 run_lib.py:146] step: 657300, eval_loss: 5.31884e-02
I0212 18:10:10.223553 22509476222784 run_lib.py:133] step: 657350, training_loss: 3.88235e-02
I0212 18:10:28.738371 22509476222784 run_lib.py:133] step: 657400, training_loss: 4.51332e-02
I0212 18:10:28.942561 22509476222784 run_lib.py:146] step: 657400, eval_loss: 4.35255e-02
I0212 18:10:47.479996 22509476222784 run_lib.py:133] step: 657450, training_loss: 3.58537e-02
I0212 18:11:06.016631 22509476222784 run_lib.py:133] step: 657500, training_loss: 4.67304e-02
I0212 18:11:06.197849 22509476222784 run_lib.py:146] step: 657500, eval_loss: 4.99547e-02
I0212 18:11:24.934923 22509476222784 run_lib.py:133] step: 657550, training_loss: 3.83676e-02
I0212 18:11:43.690864 22509476222784 run_lib.py:133] step: 657600, training_loss: 4.40584e-02
I0212 18:11:43.902455 22509476222784 run_lib.py:146] step: 657600, eval_loss: 4.36869e-02
I0212 18:12:02.464828 22509476222784 run_lib.py:133] step: 657650, training_loss: 4.14874e-02
I0212 18:12:20.962443 22509476222784 run_lib.py:133] step: 657700, training_loss: 3.69371e-02
I0212 18:12:21.127630 22509476222784 run_lib.py:146] step: 657700, eval_loss: 3.08274e-02
I0212 18:12:39.777233 22509476222784 run_lib.py:133] step: 657750, training_loss: 5.32622e-02
I0212 18:12:58.386681 22509476222784 run_lib.py:133] step: 657800, training_loss: 3.05662e-02
I0212 18:12:58.572700 22509476222784 run_lib.py:146] step: 657800, eval_loss: 3.95795e-02
I0212 18:13:17.377333 22509476222784 run_lib.py:133] step: 657850, training_loss: 4.54728e-02
I0212 18:13:35.912748 22509476222784 run_lib.py:133] step: 657900, training_loss: 5.38566e-02
I0212 18:13:36.074771 22509476222784 run_lib.py:146] step: 657900, eval_loss: 4.44905e-02
I0212 18:13:54.731624 22509476222784 run_lib.py:133] step: 657950, training_loss: 3.02884e-02
I0212 18:14:13.282076 22509476222784 run_lib.py:133] step: 658000, training_loss: 4.35642e-02
I0212 18:14:13.472975 22509476222784 run_lib.py:146] step: 658000, eval_loss: 5.02734e-02
I0212 18:14:32.182290 22509476222784 run_lib.py:133] step: 658050, training_loss: 5.03832e-02
I0212 18:14:50.754785 22509476222784 run_lib.py:133] step: 658100, training_loss: 3.84664e-02
I0212 18:14:50.924897 22509476222784 run_lib.py:146] step: 658100, eval_loss: 4.17358e-02
I0212 18:15:09.436985 22509476222784 run_lib.py:133] step: 658150, training_loss: 4.31642e-02
I0212 18:15:28.140760 22509476222784 run_lib.py:133] step: 658200, training_loss: 4.59246e-02
I0212 18:15:28.340935 22509476222784 run_lib.py:146] step: 658200, eval_loss: 4.31986e-02
I0212 18:15:46.842136 22509476222784 run_lib.py:133] step: 658250, training_loss: 3.17064e-02
I0212 18:16:05.433474 22509476222784 run_lib.py:133] step: 658300, training_loss: 4.70254e-02
I0212 18:16:05.624904 22509476222784 run_lib.py:146] step: 658300, eval_loss: 3.97630e-02
I0212 18:16:24.380483 22509476222784 run_lib.py:133] step: 658350, training_loss: 3.41841e-02
I0212 18:16:42.926658 22509476222784 run_lib.py:133] step: 658400, training_loss: 3.80855e-02
I0212 18:16:43.135651 22509476222784 run_lib.py:146] step: 658400, eval_loss: 5.43146e-02
I0212 18:17:01.838825 22509476222784 run_lib.py:133] step: 658450, training_loss: 4.89206e-02
I0212 18:17:20.366718 22509476222784 run_lib.py:133] step: 658500, training_loss: 3.71031e-02
I0212 18:17:20.533899 22509476222784 run_lib.py:146] step: 658500, eval_loss: 4.05784e-02
I0212 18:17:39.089533 22509476222784 run_lib.py:133] step: 658550, training_loss: 3.22934e-02
I0212 18:17:57.827688 22509476222784 run_lib.py:133] step: 658600, training_loss: 4.03198e-02
I0212 18:17:58.003729 22509476222784 run_lib.py:146] step: 658600, eval_loss: 4.23658e-02
I0212 18:18:16.568097 22509476222784 run_lib.py:133] step: 658650, training_loss: 4.07664e-02
I0212 18:18:35.135862 22509476222784 run_lib.py:133] step: 658700, training_loss: 3.03989e-02
I0212 18:18:35.336395 22509476222784 run_lib.py:146] step: 658700, eval_loss: 4.60724e-02
I0212 18:18:53.904868 22509476222784 run_lib.py:133] step: 658750, training_loss: 3.85940e-02
I0212 18:19:12.624886 22509476222784 run_lib.py:133] step: 658800, training_loss: 4.00961e-02
I0212 18:19:12.785592 22509476222784 run_lib.py:146] step: 658800, eval_loss: 4.36493e-02
I0212 18:19:31.347600 22509476222784 run_lib.py:133] step: 658850, training_loss: 4.28134e-02
I0212 18:19:50.009579 22509476222784 run_lib.py:133] step: 658900, training_loss: 5.64543e-02
I0212 18:19:50.184791 22509476222784 run_lib.py:146] step: 658900, eval_loss: 4.19897e-02
I0212 18:20:08.787577 22509476222784 run_lib.py:133] step: 658950, training_loss: 5.00915e-02
I0212 18:20:27.346400 22509476222784 run_lib.py:133] step: 659000, training_loss: 4.84621e-02
I0212 18:20:27.513970 22509476222784 run_lib.py:146] step: 659000, eval_loss: 4.24181e-02
I0212 18:20:46.227847 22509476222784 run_lib.py:133] step: 659050, training_loss: 3.54078e-02
I0212 18:21:04.892800 22509476222784 run_lib.py:133] step: 659100, training_loss: 4.66335e-02
I0212 18:21:05.065719 22509476222784 run_lib.py:146] step: 659100, eval_loss: 3.42118e-02
I0212 18:21:23.669247 22509476222784 run_lib.py:133] step: 659150, training_loss: 4.15646e-02
I0212 18:21:42.233860 22509476222784 run_lib.py:133] step: 659200, training_loss: 3.46340e-02
I0212 18:21:42.416136 22509476222784 run_lib.py:146] step: 659200, eval_loss: 4.31058e-02
I0212 18:22:01.142054 22509476222784 run_lib.py:133] step: 659250, training_loss: 5.58302e-02
I0212 18:22:19.686759 22509476222784 run_lib.py:133] step: 659300, training_loss: 4.64228e-02
I0212 18:22:19.847745 22509476222784 run_lib.py:146] step: 659300, eval_loss: 4.94399e-02
I0212 18:22:38.556298 22509476222784 run_lib.py:133] step: 659350, training_loss: 3.87513e-02
I0212 18:22:57.155489 22509476222784 run_lib.py:133] step: 659400, training_loss: 4.12204e-02
I0212 18:22:57.362978 22509476222784 run_lib.py:146] step: 659400, eval_loss: 4.98983e-02
I0212 18:23:16.095407 22509476222784 run_lib.py:133] step: 659450, training_loss: 4.46799e-02
I0212 18:23:34.613131 22509476222784 run_lib.py:133] step: 659500, training_loss: 3.47918e-02
I0212 18:23:34.778823 22509476222784 run_lib.py:146] step: 659500, eval_loss: 4.34202e-02
I0212 18:23:53.258859 22509476222784 run_lib.py:133] step: 659550, training_loss: 4.52239e-02
I0212 18:24:11.895435 22509476222784 run_lib.py:133] step: 659600, training_loss: 3.73638e-02
I0212 18:24:12.066718 22509476222784 run_lib.py:146] step: 659600, eval_loss: 3.13777e-02
I0212 18:24:30.605093 22509476222784 run_lib.py:133] step: 659650, training_loss: 2.91127e-02
I0212 18:24:49.382221 22509476222784 run_lib.py:133] step: 659700, training_loss: 5.34957e-02
I0212 18:24:49.593862 22509476222784 run_lib.py:146] step: 659700, eval_loss: 4.40551e-02
I0212 18:25:08.214576 22509476222784 run_lib.py:133] step: 659750, training_loss: 4.04354e-02
I0212 18:25:26.764856 22509476222784 run_lib.py:133] step: 659800, training_loss: 4.24312e-02
I0212 18:25:26.933167 22509476222784 run_lib.py:146] step: 659800, eval_loss: 4.16490e-02
I0212 18:25:45.657004 22509476222784 run_lib.py:133] step: 659850, training_loss: 3.69808e-02
I0212 18:26:04.241308 22509476222784 run_lib.py:133] step: 659900, training_loss: 4.31785e-02
I0212 18:26:04.447665 22509476222784 run_lib.py:146] step: 659900, eval_loss: 4.02349e-02
I0212 18:26:23.004999 22509476222784 run_lib.py:133] step: 659950, training_loss: 3.77682e-02
I0212 18:26:41.714701 22509476222784 run_lib.py:133] step: 660000, training_loss: 3.83823e-02
I0212 18:26:42.526679 22509476222784 run_lib.py:146] step: 660000, eval_loss: 4.73311e-02
I0212 18:27:03.738421 22509476222784 run_lib.py:133] step: 660050, training_loss: 4.86863e-02
I0212 18:27:22.270852 22509476222784 run_lib.py:133] step: 660100, training_loss: 4.70042e-02
I0212 18:27:22.451820 22509476222784 run_lib.py:146] step: 660100, eval_loss: 3.44662e-02
I0212 18:27:41.130861 22509476222784 run_lib.py:133] step: 660150, training_loss: 4.21667e-02
I0212 18:27:59.706243 22509476222784 run_lib.py:133] step: 660200, training_loss: 5.35216e-02
I0212 18:27:59.869995 22509476222784 run_lib.py:146] step: 660200, eval_loss: 4.11776e-02
I0212 18:28:18.374609 22509476222784 run_lib.py:133] step: 660250, training_loss: 4.72568e-02
I0212 18:28:36.859740 22509476222784 run_lib.py:133] step: 660300, training_loss: 4.00453e-02
I0212 18:28:37.021825 22509476222784 run_lib.py:146] step: 660300, eval_loss: 3.79141e-02
I0212 18:28:55.774380 22509476222784 run_lib.py:133] step: 660350, training_loss: 3.50267e-02
I0212 18:29:14.383031 22509476222784 run_lib.py:133] step: 660400, training_loss: 4.26580e-02
I0212 18:29:14.565124 22509476222784 run_lib.py:146] step: 660400, eval_loss: 4.00691e-02
I0212 18:29:33.199461 22509476222784 run_lib.py:133] step: 660450, training_loss: 3.46975e-02
I0212 18:29:51.777512 22509476222784 run_lib.py:133] step: 660500, training_loss: 3.88092e-02
I0212 18:29:51.968654 22509476222784 run_lib.py:146] step: 660500, eval_loss: 3.85758e-02
I0212 18:30:10.486193 22509476222784 run_lib.py:133] step: 660550, training_loss: 5.12239e-02
I0212 18:30:29.041059 22509476222784 run_lib.py:133] step: 660600, training_loss: 3.42030e-02
I0212 18:30:29.223610 22509476222784 run_lib.py:146] step: 660600, eval_loss: 3.88427e-02
I0212 18:30:47.941076 22509476222784 run_lib.py:133] step: 660650, training_loss: 4.64083e-02
I0212 18:31:06.625334 22509476222784 run_lib.py:133] step: 660700, training_loss: 3.28815e-02
I0212 18:31:06.824977 22509476222784 run_lib.py:146] step: 660700, eval_loss: 5.10488e-02
I0212 18:31:25.358751 22509476222784 run_lib.py:133] step: 660750, training_loss: 4.32447e-02
I0212 18:31:43.893612 22509476222784 run_lib.py:133] step: 660800, training_loss: 3.75056e-02
I0212 18:31:44.055872 22509476222784 run_lib.py:146] step: 660800, eval_loss: 4.17271e-02
I0212 18:32:02.751975 22509476222784 run_lib.py:133] step: 660850, training_loss: 3.04169e-02
I0212 18:32:21.235558 22509476222784 run_lib.py:133] step: 660900, training_loss: 4.15127e-02
I0212 18:32:21.399623 22509476222784 run_lib.py:146] step: 660900, eval_loss: 4.41584e-02
I0212 18:32:40.052382 22509476222784 run_lib.py:133] step: 660950, training_loss: 4.69766e-02
I0212 18:32:58.655809 22509476222784 run_lib.py:133] step: 661000, training_loss: 4.48624e-02
I0212 18:32:58.851720 22509476222784 run_lib.py:146] step: 661000, eval_loss: 5.33116e-02
I0212 18:33:17.572290 22509476222784 run_lib.py:133] step: 661050, training_loss: 4.86771e-02
I0212 18:33:36.167288 22509476222784 run_lib.py:133] step: 661100, training_loss: 3.80051e-02
I0212 18:33:36.331809 22509476222784 run_lib.py:146] step: 661100, eval_loss: 5.34893e-02
I0212 18:33:55.008891 22509476222784 run_lib.py:133] step: 661150, training_loss: 4.10497e-02
I0212 18:34:13.459475 22509476222784 run_lib.py:133] step: 661200, training_loss: 3.99132e-02
I0212 18:34:13.628281 22509476222784 run_lib.py:146] step: 661200, eval_loss: 4.34967e-02
I0212 18:34:32.294560 22509476222784 run_lib.py:133] step: 661250, training_loss: 4.09920e-02
I0212 18:34:51.118392 22509476222784 run_lib.py:133] step: 661300, training_loss: 4.24325e-02
I0212 18:34:51.279992 22509476222784 run_lib.py:146] step: 661300, eval_loss: 4.04937e-02
I0212 18:35:09.802094 22509476222784 run_lib.py:133] step: 661350, training_loss: 4.38684e-02
I0212 18:35:28.352356 22509476222784 run_lib.py:133] step: 661400, training_loss: 5.40256e-02
I0212 18:35:28.552897 22509476222784 run_lib.py:146] step: 661400, eval_loss: 3.32835e-02
I0212 18:35:47.223132 22509476222784 run_lib.py:133] step: 661450, training_loss: 4.16230e-02
I0212 18:36:06.052883 22509476222784 run_lib.py:133] step: 661500, training_loss: 4.39195e-02
I0212 18:36:06.250093 22509476222784 run_lib.py:146] step: 661500, eval_loss: 3.99306e-02
I0212 18:36:24.800010 22509476222784 run_lib.py:133] step: 661550, training_loss: 3.84921e-02
I0212 18:36:43.353486 22509476222784 run_lib.py:133] step: 661600, training_loss: 2.51409e-02
I0212 18:36:43.555445 22509476222784 run_lib.py:146] step: 661600, eval_loss: 3.67782e-02
I0212 18:37:02.087958 22509476222784 run_lib.py:133] step: 661650, training_loss: 3.80488e-02
I0212 18:37:20.807124 22509476222784 run_lib.py:133] step: 661700, training_loss: 3.38118e-02
I0212 18:37:20.968520 22509476222784 run_lib.py:146] step: 661700, eval_loss: 4.75729e-02
I0212 18:37:39.530782 22509476222784 run_lib.py:133] step: 661750, training_loss: 4.23587e-02
I0212 18:37:58.092508 22509476222784 run_lib.py:133] step: 661800, training_loss: 4.01977e-02
I0212 18:37:58.262852 22509476222784 run_lib.py:146] step: 661800, eval_loss: 3.38728e-02
I0212 18:38:16.814535 22509476222784 run_lib.py:133] step: 661850, training_loss: 3.54433e-02
I0212 18:38:35.600894 22509476222784 run_lib.py:133] step: 661900, training_loss: 4.33109e-02
I0212 18:38:35.791947 22509476222784 run_lib.py:146] step: 661900, eval_loss: 4.04199e-02
I0212 18:38:54.300882 22509476222784 run_lib.py:133] step: 661950, training_loss: 5.71041e-02
I0212 18:39:12.898182 22509476222784 run_lib.py:133] step: 662000, training_loss: 4.59557e-02
I0212 18:39:13.097641 22509476222784 run_lib.py:146] step: 662000, eval_loss: 4.76834e-02
I0212 18:39:31.643083 22509476222784 run_lib.py:133] step: 662050, training_loss: 3.26224e-02
I0212 18:39:50.195339 22509476222784 run_lib.py:133] step: 662100, training_loss: 4.04413e-02
I0212 18:39:50.360470 22509476222784 run_lib.py:146] step: 662100, eval_loss: 4.51103e-02
I0212 18:40:09.072639 22509476222784 run_lib.py:133] step: 662150, training_loss: 4.65597e-02
I0212 18:40:27.688615 22509476222784 run_lib.py:133] step: 662200, training_loss: 4.36401e-02
I0212 18:40:27.848407 22509476222784 run_lib.py:146] step: 662200, eval_loss: 5.27842e-02
I0212 18:40:46.408255 22509476222784 run_lib.py:133] step: 662250, training_loss: 4.64769e-02
I0212 18:41:04.957702 22509476222784 run_lib.py:133] step: 662300, training_loss: 5.34926e-02
I0212 18:41:05.133031 22509476222784 run_lib.py:146] step: 662300, eval_loss: 3.33839e-02
I0212 18:41:23.858617 22509476222784 run_lib.py:133] step: 662350, training_loss: 5.45742e-02
I0212 18:41:42.459948 22509476222784 run_lib.py:133] step: 662400, training_loss: 4.09339e-02
I0212 18:41:42.625860 22509476222784 run_lib.py:146] step: 662400, eval_loss: 3.87594e-02
I0212 18:42:01.306012 22509476222784 run_lib.py:133] step: 662450, training_loss: 4.66224e-02
I0212 18:42:19.874305 22509476222784 run_lib.py:133] step: 662500, training_loss: 2.81878e-02
I0212 18:42:20.118557 22509476222784 run_lib.py:146] step: 662500, eval_loss: 5.56257e-02
I0212 18:42:38.875906 22509476222784 run_lib.py:133] step: 662550, training_loss: 3.70274e-02
I0212 18:42:57.424943 22509476222784 run_lib.py:133] step: 662600, training_loss: 2.87361e-02
I0212 18:42:57.587330 22509476222784 run_lib.py:146] step: 662600, eval_loss: 4.27324e-02
I0212 18:43:16.171580 22509476222784 run_lib.py:133] step: 662650, training_loss: 5.07157e-02
I0212 18:43:34.913345 22509476222784 run_lib.py:133] step: 662700, training_loss: 5.34500e-02
I0212 18:43:35.096780 22509476222784 run_lib.py:146] step: 662700, eval_loss: 4.48987e-02
I0212 18:43:53.598380 22509476222784 run_lib.py:133] step: 662750, training_loss: 4.29521e-02
I0212 18:44:12.273267 22509476222784 run_lib.py:133] step: 662800, training_loss: 4.62339e-02
I0212 18:44:12.450823 22509476222784 run_lib.py:146] step: 662800, eval_loss: 3.28020e-02
I0212 18:44:31.009634 22509476222784 run_lib.py:133] step: 662850, training_loss: 3.68080e-02
I0212 18:44:49.562600 22509476222784 run_lib.py:133] step: 662900, training_loss: 3.86401e-02
I0212 18:44:49.762676 22509476222784 run_lib.py:146] step: 662900, eval_loss: 4.23946e-02
I0212 18:45:08.467016 22509476222784 run_lib.py:133] step: 662950, training_loss: 5.67988e-02
I0212 18:45:26.980103 22509476222784 run_lib.py:133] step: 663000, training_loss: 3.22644e-02
I0212 18:45:27.149696 22509476222784 run_lib.py:146] step: 663000, eval_loss: 4.68144e-02
I0212 18:45:45.689373 22509476222784 run_lib.py:133] step: 663050, training_loss: 3.09169e-02
I0212 18:46:04.418431 22509476222784 run_lib.py:133] step: 663100, training_loss: 3.78336e-02
I0212 18:46:04.581914 22509476222784 run_lib.py:146] step: 663100, eval_loss: 3.52586e-02
I0212 18:46:23.124939 22509476222784 run_lib.py:133] step: 663150, training_loss: 4.00434e-02
I0212 18:46:41.676178 22509476222784 run_lib.py:133] step: 663200, training_loss: 3.73482e-02
I0212 18:46:41.850634 22509476222784 run_lib.py:146] step: 663200, eval_loss: 4.30601e-02
I0212 18:47:00.534433 22509476222784 run_lib.py:133] step: 663250, training_loss: 3.80118e-02
I0212 18:47:19.103473 22509476222784 run_lib.py:133] step: 663300, training_loss: 5.57381e-02
I0212 18:47:19.286156 22509476222784 run_lib.py:146] step: 663300, eval_loss: 5.02042e-02
I0212 18:47:37.834880 22509476222784 run_lib.py:133] step: 663350, training_loss: 5.22215e-02
I0212 18:47:56.393754 22509476222784 run_lib.py:133] step: 663400, training_loss: 3.47626e-02
I0212 18:47:56.558852 22509476222784 run_lib.py:146] step: 663400, eval_loss: 4.48513e-02
I0212 18:48:15.297229 22509476222784 run_lib.py:133] step: 663450, training_loss: 3.71616e-02
I0212 18:48:33.922567 22509476222784 run_lib.py:133] step: 663500, training_loss: 4.76338e-02
I0212 18:48:34.085732 22509476222784 run_lib.py:146] step: 663500, eval_loss: 4.62964e-02
I0212 18:48:52.599890 22509476222784 run_lib.py:133] step: 663550, training_loss: 3.75974e-02
I0212 18:49:11.051044 22509476222784 run_lib.py:133] step: 663600, training_loss: 3.78241e-02
I0212 18:49:11.210348 22509476222784 run_lib.py:146] step: 663600, eval_loss: 5.62902e-02
I0212 18:49:29.900801 22509476222784 run_lib.py:133] step: 663650, training_loss: 3.71660e-02
I0212 18:49:48.463030 22509476222784 run_lib.py:133] step: 663700, training_loss: 3.23303e-02
I0212 18:49:48.638679 22509476222784 run_lib.py:146] step: 663700, eval_loss: 4.25310e-02
I0212 18:50:07.407488 22509476222784 run_lib.py:133] step: 663750, training_loss: 4.97661e-02
I0212 18:50:25.953828 22509476222784 run_lib.py:133] step: 663800, training_loss: 4.11031e-02
I0212 18:50:26.177943 22509476222784 run_lib.py:146] step: 663800, eval_loss: 5.02844e-02
I0212 18:50:44.864358 22509476222784 run_lib.py:133] step: 663850, training_loss: 3.37679e-02
I0212 18:51:03.429068 22509476222784 run_lib.py:133] step: 663900, training_loss: 3.21774e-02
I0212 18:51:03.597707 22509476222784 run_lib.py:146] step: 663900, eval_loss: 4.80480e-02
I0212 18:51:22.308652 22509476222784 run_lib.py:133] step: 663950, training_loss: 2.88942e-02
I0212 18:51:40.836713 22509476222784 run_lib.py:133] step: 664000, training_loss: 3.87875e-02
I0212 18:51:41.000816 22509476222784 run_lib.py:146] step: 664000, eval_loss: 3.79006e-02
I0212 18:51:59.565284 22509476222784 run_lib.py:133] step: 664050, training_loss: 4.64878e-02
I0212 18:52:18.269488 22509476222784 run_lib.py:133] step: 664100, training_loss: 3.06847e-02
I0212 18:52:18.429647 22509476222784 run_lib.py:146] step: 664100, eval_loss: 4.45362e-02
I0212 18:52:36.945866 22509476222784 run_lib.py:133] step: 664150, training_loss: 4.71818e-02
I0212 18:52:55.555269 22509476222784 run_lib.py:133] step: 664200, training_loss: 4.82814e-02
I0212 18:52:55.728854 22509476222784 run_lib.py:146] step: 664200, eval_loss: 4.05007e-02
I0212 18:53:14.409533 22509476222784 run_lib.py:133] step: 664250, training_loss: 3.98612e-02
I0212 18:53:33.000198 22509476222784 run_lib.py:133] step: 664300, training_loss: 4.86727e-02
I0212 18:53:33.168041 22509476222784 run_lib.py:146] step: 664300, eval_loss: 4.62614e-02
I0212 18:53:51.863437 22509476222784 run_lib.py:133] step: 664350, training_loss: 4.24512e-02
I0212 18:54:10.430762 22509476222784 run_lib.py:133] step: 664400, training_loss: 2.71681e-02
I0212 18:54:10.609733 22509476222784 run_lib.py:146] step: 664400, eval_loss: 5.09518e-02
I0212 18:54:29.194829 22509476222784 run_lib.py:133] step: 664450, training_loss: 3.89469e-02
I0212 18:54:47.896325 22509476222784 run_lib.py:133] step: 664500, training_loss: 3.50068e-02
I0212 18:54:48.059747 22509476222784 run_lib.py:146] step: 664500, eval_loss: 4.67785e-02
I0212 18:55:06.612745 22509476222784 run_lib.py:133] step: 664550, training_loss: 4.53970e-02
I0212 18:55:25.173685 22509476222784 run_lib.py:133] step: 664600, training_loss: 4.07981e-02
I0212 18:55:25.334621 22509476222784 run_lib.py:146] step: 664600, eval_loss: 4.08210e-02
I0212 18:55:43.852633 22509476222784 run_lib.py:133] step: 664650, training_loss: 3.76838e-02
I0212 18:56:02.531404 22509476222784 run_lib.py:133] step: 664700, training_loss: 4.26677e-02
I0212 18:56:02.706541 22509476222784 run_lib.py:146] step: 664700, eval_loss: 5.26344e-02
I0212 18:56:21.266757 22509476222784 run_lib.py:133] step: 664750, training_loss: 4.26590e-02
I0212 18:56:39.952897 22509476222784 run_lib.py:133] step: 664800, training_loss: 3.77940e-02
I0212 18:56:40.141778 22509476222784 run_lib.py:146] step: 664800, eval_loss: 4.52596e-02
I0212 18:56:58.666818 22509476222784 run_lib.py:133] step: 664850, training_loss: 4.84775e-02
I0212 18:57:17.148491 22509476222784 run_lib.py:133] step: 664900, training_loss: 3.75586e-02
I0212 18:57:17.313722 22509476222784 run_lib.py:146] step: 664900, eval_loss: 4.77570e-02
I0212 18:57:35.993951 22509476222784 run_lib.py:133] step: 664950, training_loss: 4.00158e-02
I0212 18:57:54.786624 22509476222784 run_lib.py:133] step: 665000, training_loss: 3.84842e-02
I0212 18:57:54.951972 22509476222784 run_lib.py:146] step: 665000, eval_loss: 4.03832e-02
I0212 18:58:13.505943 22509476222784 run_lib.py:133] step: 665050, training_loss: 5.72090e-02
I0212 18:58:32.043630 22509476222784 run_lib.py:133] step: 665100, training_loss: 4.07994e-02
I0212 18:58:32.206623 22509476222784 run_lib.py:146] step: 665100, eval_loss: 3.93185e-02
I0212 18:58:50.837706 22509476222784 run_lib.py:133] step: 665150, training_loss: 3.14254e-02
I0212 18:59:09.329741 22509476222784 run_lib.py:133] step: 665200, training_loss: 4.00032e-02
I0212 18:59:09.509738 22509476222784 run_lib.py:146] step: 665200, eval_loss: 3.11498e-02
I0212 18:59:28.219468 22509476222784 run_lib.py:133] step: 665250, training_loss: 4.48066e-02
I0212 18:59:46.801059 22509476222784 run_lib.py:133] step: 665300, training_loss: 5.10053e-02
I0212 18:59:46.969898 22509476222784 run_lib.py:146] step: 665300, eval_loss: 4.99681e-02
I0212 19:00:05.643523 22509476222784 run_lib.py:133] step: 665350, training_loss: 4.69844e-02
I0212 19:00:24.199557 22509476222784 run_lib.py:133] step: 665400, training_loss: 4.46080e-02
I0212 19:00:24.392453 22509476222784 run_lib.py:146] step: 665400, eval_loss: 4.04288e-02
I0212 19:00:42.944361 22509476222784 run_lib.py:133] step: 665450, training_loss: 4.18952e-02
I0212 19:01:01.672423 22509476222784 run_lib.py:133] step: 665500, training_loss: 4.07725e-02
I0212 19:01:01.840707 22509476222784 run_lib.py:146] step: 665500, eval_loss: 4.47017e-02
I0212 19:01:20.362454 22509476222784 run_lib.py:133] step: 665550, training_loss: 3.91192e-02
I0212 19:01:39.073350 22509476222784 run_lib.py:133] step: 665600, training_loss: 3.67694e-02
I0212 19:01:39.238003 22509476222784 run_lib.py:146] step: 665600, eval_loss: 3.00577e-02
I0212 19:01:57.738528 22509476222784 run_lib.py:133] step: 665650, training_loss: 4.26100e-02
I0212 19:02:16.306226 22509476222784 run_lib.py:133] step: 665700, training_loss: 3.61727e-02
I0212 19:02:16.475966 22509476222784 run_lib.py:146] step: 665700, eval_loss: 5.16929e-02
I0212 19:02:35.216747 22509476222784 run_lib.py:133] step: 665750, training_loss: 3.31086e-02
I0212 19:02:53.797182 22509476222784 run_lib.py:133] step: 665800, training_loss: 4.12946e-02
I0212 19:02:53.968904 22509476222784 run_lib.py:146] step: 665800, eval_loss: 5.13552e-02
I0212 19:03:12.509464 22509476222784 run_lib.py:133] step: 665850, training_loss: 3.76478e-02
I0212 19:03:31.228758 22509476222784 run_lib.py:133] step: 665900, training_loss: 3.78784e-02
I0212 19:03:31.409810 22509476222784 run_lib.py:146] step: 665900, eval_loss: 4.97661e-02
I0212 19:03:49.967724 22509476222784 run_lib.py:133] step: 665950, training_loss: 5.05432e-02
I0212 19:04:08.590729 22509476222784 run_lib.py:133] step: 666000, training_loss: 4.40032e-02
I0212 19:04:08.943834 22509476222784 run_lib.py:146] step: 666000, eval_loss: 3.94094e-02
I0212 19:04:27.562985 22509476222784 run_lib.py:133] step: 666050, training_loss: 4.37883e-02
I0212 19:04:46.077653 22509476222784 run_lib.py:133] step: 666100, training_loss: 3.29441e-02
I0212 19:04:46.241543 22509476222784 run_lib.py:146] step: 666100, eval_loss: 3.56613e-02
I0212 19:05:04.768465 22509476222784 run_lib.py:133] step: 666150, training_loss: 5.46941e-02
I0212 19:05:23.358578 22509476222784 run_lib.py:133] step: 666200, training_loss: 4.61023e-02
I0212 19:05:23.526016 22509476222784 run_lib.py:146] step: 666200, eval_loss: 4.02671e-02
I0212 19:05:42.310423 22509476222784 run_lib.py:133] step: 666250, training_loss: 3.83306e-02
I0212 19:06:01.108193 22509476222784 run_lib.py:133] step: 666300, training_loss: 4.40543e-02
I0212 19:06:01.272896 22509476222784 run_lib.py:146] step: 666300, eval_loss: 3.72436e-02
I0212 19:06:19.812140 22509476222784 run_lib.py:133] step: 666350, training_loss: 4.02719e-02
I0212 19:06:38.282894 22509476222784 run_lib.py:133] step: 666400, training_loss: 4.18070e-02
I0212 19:06:38.469420 22509476222784 run_lib.py:146] step: 666400, eval_loss: 3.57465e-02
I0212 19:06:57.151947 22509476222784 run_lib.py:133] step: 666450, training_loss: 4.45367e-02
I0212 19:07:15.786757 22509476222784 run_lib.py:133] step: 666500, training_loss: 4.21140e-02
I0212 19:07:15.951995 22509476222784 run_lib.py:146] step: 666500, eval_loss: 3.71645e-02
I0212 19:07:34.574792 22509476222784 run_lib.py:133] step: 666550, training_loss: 4.99688e-02
I0212 19:07:53.234561 22509476222784 run_lib.py:133] step: 666600, training_loss: 4.23374e-02
I0212 19:07:53.399724 22509476222784 run_lib.py:146] step: 666600, eval_loss: 4.17139e-02
I0212 19:08:12.089334 22509476222784 run_lib.py:133] step: 666650, training_loss: 2.77247e-02
I0212 19:08:30.632599 22509476222784 run_lib.py:133] step: 666700, training_loss: 3.30213e-02
I0212 19:08:30.798974 22509476222784 run_lib.py:146] step: 666700, eval_loss: 4.80037e-02
I0212 19:08:49.470480 22509476222784 run_lib.py:133] step: 666750, training_loss: 4.53228e-02
I0212 19:09:08.087396 22509476222784 run_lib.py:133] step: 666800, training_loss: 4.11399e-02
I0212 19:09:08.253355 22509476222784 run_lib.py:146] step: 666800, eval_loss: 4.33756e-02
I0212 19:09:26.987296 22509476222784 run_lib.py:133] step: 666850, training_loss: 4.67656e-02
I0212 19:09:45.517540 22509476222784 run_lib.py:133] step: 666900, training_loss: 2.88918e-02
I0212 19:09:45.715430 22509476222784 run_lib.py:146] step: 666900, eval_loss: 4.06436e-02
I0212 19:10:04.273796 22509476222784 run_lib.py:133] step: 666950, training_loss: 3.42080e-02
I0212 19:10:22.933070 22509476222784 run_lib.py:133] step: 667000, training_loss: 3.12816e-02
I0212 19:10:23.120933 22509476222784 run_lib.py:146] step: 667000, eval_loss: 4.81822e-02
I0212 19:10:41.714763 22509476222784 run_lib.py:133] step: 667050, training_loss: 4.75570e-02
I0212 19:11:00.453505 22509476222784 run_lib.py:133] step: 667100, training_loss: 4.33301e-02
I0212 19:11:00.639530 22509476222784 run_lib.py:146] step: 667100, eval_loss: 3.29288e-02
I0212 19:11:19.129111 22509476222784 run_lib.py:133] step: 667150, training_loss: 5.20585e-02
I0212 19:11:37.654369 22509476222784 run_lib.py:133] step: 667200, training_loss: 4.32466e-02
I0212 19:11:37.840711 22509476222784 run_lib.py:146] step: 667200, eval_loss: 4.54241e-02
I0212 19:11:56.514979 22509476222784 run_lib.py:133] step: 667250, training_loss: 3.36982e-02
I0212 19:12:15.085884 22509476222784 run_lib.py:133] step: 667300, training_loss: 4.65801e-02
I0212 19:12:15.276419 22509476222784 run_lib.py:146] step: 667300, eval_loss: 3.85411e-02
I0212 19:12:33.880799 22509476222784 run_lib.py:133] step: 667350, training_loss: 4.27655e-02
I0212 19:12:52.387764 22509476222784 run_lib.py:133] step: 667400, training_loss: 4.92252e-02
I0212 19:12:52.548332 22509476222784 run_lib.py:146] step: 667400, eval_loss: 3.53736e-02
I0212 19:13:11.285018 22509476222784 run_lib.py:133] step: 667450, training_loss: 4.60665e-02
I0212 19:13:29.818673 22509476222784 run_lib.py:133] step: 667500, training_loss: 4.27487e-02
I0212 19:13:29.982529 22509476222784 run_lib.py:146] step: 667500, eval_loss: 4.35755e-02
I0212 19:13:48.644400 22509476222784 run_lib.py:133] step: 667550, training_loss: 4.62880e-02
I0212 19:14:07.213523 22509476222784 run_lib.py:133] step: 667600, training_loss: 4.94400e-02
I0212 19:14:07.395674 22509476222784 run_lib.py:146] step: 667600, eval_loss: 3.99255e-02
I0212 19:14:25.978868 22509476222784 run_lib.py:133] step: 667650, training_loss: 3.58874e-02
I0212 19:14:44.575613 22509476222784 run_lib.py:133] step: 667700, training_loss: 4.63314e-02
I0212 19:14:44.739966 22509476222784 run_lib.py:146] step: 667700, eval_loss: 5.37089e-02
I0212 19:15:03.512597 22509476222784 run_lib.py:133] step: 667750, training_loss: 3.58099e-02
I0212 19:15:22.105778 22509476222784 run_lib.py:133] step: 667800, training_loss: 3.59955e-02
I0212 19:15:22.270730 22509476222784 run_lib.py:146] step: 667800, eval_loss: 3.77260e-02
I0212 19:15:40.804177 22509476222784 run_lib.py:133] step: 667850, training_loss: 3.66132e-02
I0212 19:15:59.355730 22509476222784 run_lib.py:133] step: 667900, training_loss: 4.85487e-02
I0212 19:15:59.520982 22509476222784 run_lib.py:146] step: 667900, eval_loss: 4.11764e-02
I0212 19:16:18.301698 22509476222784 run_lib.py:133] step: 667950, training_loss: 4.17181e-02
I0212 19:16:36.824382 22509476222784 run_lib.py:133] step: 668000, training_loss: 5.49843e-02
I0212 19:16:37.002621 22509476222784 run_lib.py:146] step: 668000, eval_loss: 4.32855e-02
I0212 19:16:55.653286 22509476222784 run_lib.py:133] step: 668050, training_loss: 3.94053e-02
I0212 19:17:14.228801 22509476222784 run_lib.py:133] step: 668100, training_loss: 3.88486e-02
I0212 19:17:14.405885 22509476222784 run_lib.py:146] step: 668100, eval_loss: 3.36050e-02
I0212 19:17:33.219878 22509476222784 run_lib.py:133] step: 668150, training_loss: 3.75109e-02
I0212 19:17:51.760215 22509476222784 run_lib.py:133] step: 668200, training_loss: 4.21934e-02
I0212 19:17:51.926033 22509476222784 run_lib.py:146] step: 668200, eval_loss: 5.79169e-02
I0212 19:18:10.661652 22509476222784 run_lib.py:133] step: 668250, training_loss: 3.95555e-02
I0212 19:18:29.187747 22509476222784 run_lib.py:133] step: 668300, training_loss: 4.55332e-02
I0212 19:18:29.351732 22509476222784 run_lib.py:146] step: 668300, eval_loss: 3.95015e-02
I0212 19:18:47.883680 22509476222784 run_lib.py:133] step: 668350, training_loss: 6.69729e-02
I0212 19:19:06.634259 22509476222784 run_lib.py:133] step: 668400, training_loss: 4.50517e-02
I0212 19:19:06.819922 22509476222784 run_lib.py:146] step: 668400, eval_loss: 4.12440e-02
I0212 19:19:25.426912 22509476222784 run_lib.py:133] step: 668450, training_loss: 4.04264e-02
I0212 19:19:43.939800 22509476222784 run_lib.py:133] step: 668500, training_loss: 4.33320e-02
I0212 19:19:44.104754 22509476222784 run_lib.py:146] step: 668500, eval_loss: 4.27221e-02
I0212 19:20:02.828348 22509476222784 run_lib.py:133] step: 668550, training_loss: 4.26615e-02
I0212 19:20:21.588723 22509476222784 run_lib.py:133] step: 668600, training_loss: 4.09455e-02
I0212 19:20:21.761796 22509476222784 run_lib.py:146] step: 668600, eval_loss: 4.13848e-02
I0212 19:20:40.366901 22509476222784 run_lib.py:133] step: 668650, training_loss: 4.16766e-02
I0212 19:20:58.926733 22509476222784 run_lib.py:133] step: 668700, training_loss: 4.11717e-02
I0212 19:20:59.090391 22509476222784 run_lib.py:146] step: 668700, eval_loss: 4.39636e-02
I0212 19:21:17.698765 22509476222784 run_lib.py:133] step: 668750, training_loss: 3.57089e-02
I0212 19:21:36.439235 22509476222784 run_lib.py:133] step: 668800, training_loss: 4.92399e-02
I0212 19:21:36.604643 22509476222784 run_lib.py:146] step: 668800, eval_loss: 3.94210e-02
I0212 19:21:55.123192 22509476222784 run_lib.py:133] step: 668850, training_loss: 3.75692e-02
I0212 19:22:13.658140 22509476222784 run_lib.py:133] step: 668900, training_loss: 4.07258e-02
I0212 19:22:13.823917 22509476222784 run_lib.py:146] step: 668900, eval_loss: 3.73584e-02
I0212 19:22:32.437108 22509476222784 run_lib.py:133] step: 668950, training_loss: 4.53939e-02
I0212 19:22:51.200989 22509476222784 run_lib.py:133] step: 669000, training_loss: 4.08913e-02
I0212 19:22:51.367704 22509476222784 run_lib.py:146] step: 669000, eval_loss: 5.14414e-02
I0212 19:23:09.931136 22509476222784 run_lib.py:133] step: 669050, training_loss: 3.04178e-02
I0212 19:23:28.562082 22509476222784 run_lib.py:133] step: 669100, training_loss: 4.04707e-02
I0212 19:23:28.725791 22509476222784 run_lib.py:146] step: 669100, eval_loss: 6.39148e-02
I0212 19:23:47.254048 22509476222784 run_lib.py:133] step: 669150, training_loss: 4.77927e-02
I0212 19:24:05.908866 22509476222784 run_lib.py:133] step: 669200, training_loss: 3.98358e-02
I0212 19:24:06.104249 22509476222784 run_lib.py:146] step: 669200, eval_loss: 5.34004e-02
I0212 19:24:24.841034 22509476222784 run_lib.py:133] step: 669250, training_loss: 4.62470e-02
I0212 19:24:43.483649 22509476222784 run_lib.py:133] step: 669300, training_loss: 5.04160e-02
I0212 19:24:43.670732 22509476222784 run_lib.py:146] step: 669300, eval_loss: 3.22784e-02
I0212 19:25:02.231529 22509476222784 run_lib.py:133] step: 669350, training_loss: 3.29146e-02
I0212 19:25:20.810943 22509476222784 run_lib.py:133] step: 669400, training_loss: 3.97295e-02
I0212 19:25:20.996924 22509476222784 run_lib.py:146] step: 669400, eval_loss: 4.57985e-02
I0212 19:25:39.773439 22509476222784 run_lib.py:133] step: 669450, training_loss: 3.40100e-02
I0212 19:25:58.443632 22509476222784 run_lib.py:133] step: 669500, training_loss: 2.55188e-02
I0212 19:25:58.640752 22509476222784 run_lib.py:146] step: 669500, eval_loss: 5.27589e-02
I0212 19:26:17.371989 22509476222784 run_lib.py:133] step: 669550, training_loss: 3.98137e-02
I0212 19:26:35.958055 22509476222784 run_lib.py:133] step: 669600, training_loss: 4.00360e-02
I0212 19:26:36.138400 22509476222784 run_lib.py:146] step: 669600, eval_loss: 4.34536e-02
I0212 19:26:54.873082 22509476222784 run_lib.py:133] step: 669650, training_loss: 3.59539e-02
I0212 19:27:13.485498 22509476222784 run_lib.py:133] step: 669700, training_loss: 4.77411e-02
I0212 19:27:13.649910 22509476222784 run_lib.py:146] step: 669700, eval_loss: 3.94905e-02
I0212 19:27:32.267330 22509476222784 run_lib.py:133] step: 669750, training_loss: 3.38601e-02
I0212 19:27:51.014017 22509476222784 run_lib.py:133] step: 669800, training_loss: 4.83053e-02
I0212 19:27:51.175423 22509476222784 run_lib.py:146] step: 669800, eval_loss: 3.81938e-02
I0212 19:28:09.760155 22509476222784 run_lib.py:133] step: 669850, training_loss: 4.56134e-02
I0212 19:28:28.499349 22509476222784 run_lib.py:133] step: 669900, training_loss: 3.66070e-02
I0212 19:28:28.669773 22509476222784 run_lib.py:146] step: 669900, eval_loss: 5.21162e-02
I0212 19:28:47.222423 22509476222784 run_lib.py:133] step: 669950, training_loss: 4.47746e-02
I0212 19:29:05.859714 22509476222784 run_lib.py:133] step: 670000, training_loss: 4.39853e-02
I0212 19:29:06.593536 22509476222784 run_lib.py:146] step: 670000, eval_loss: 5.39484e-02
I0212 19:29:27.769036 22509476222784 run_lib.py:133] step: 670050, training_loss: 3.45890e-02
I0212 19:29:46.542932 22509476222784 run_lib.py:133] step: 670100, training_loss: 4.01285e-02
I0212 19:29:46.709087 22509476222784 run_lib.py:146] step: 670100, eval_loss: 3.81561e-02
I0212 19:30:05.210927 22509476222784 run_lib.py:133] step: 670150, training_loss: 4.30932e-02
I0212 19:30:23.922597 22509476222784 run_lib.py:133] step: 670200, training_loss: 4.92163e-02
I0212 19:30:24.096820 22509476222784 run_lib.py:146] step: 670200, eval_loss: 5.45450e-02
I0212 19:30:42.659935 22509476222784 run_lib.py:133] step: 670250, training_loss: 4.86339e-02
I0212 19:31:01.221859 22509476222784 run_lib.py:133] step: 670300, training_loss: 3.46406e-02
I0212 19:31:01.386185 22509476222784 run_lib.py:146] step: 670300, eval_loss: 3.99104e-02
I0212 19:31:20.107583 22509476222784 run_lib.py:133] step: 670350, training_loss: 4.01648e-02
I0212 19:31:38.652163 22509476222784 run_lib.py:133] step: 670400, training_loss: 4.61989e-02
I0212 19:31:38.819705 22509476222784 run_lib.py:146] step: 670400, eval_loss: 3.69833e-02
I0212 19:31:57.541687 22509476222784 run_lib.py:133] step: 670450, training_loss: 3.44682e-02
I0212 19:32:16.121466 22509476222784 run_lib.py:133] step: 670500, training_loss: 3.53621e-02
I0212 19:32:16.303541 22509476222784 run_lib.py:146] step: 670500, eval_loss: 4.67774e-02
I0212 19:32:34.884907 22509476222784 run_lib.py:133] step: 670550, training_loss: 4.13072e-02
I0212 19:32:53.656695 22509476222784 run_lib.py:133] step: 670600, training_loss: 4.03172e-02
I0212 19:32:53.830641 22509476222784 run_lib.py:146] step: 670600, eval_loss: 3.40856e-02
I0212 19:33:12.334009 22509476222784 run_lib.py:133] step: 670650, training_loss: 4.38243e-02
I0212 19:33:30.838883 22509476222784 run_lib.py:133] step: 670700, training_loss: 4.04733e-02
I0212 19:33:31.007296 22509476222784 run_lib.py:146] step: 670700, eval_loss: 4.23923e-02
I0212 19:33:49.563863 22509476222784 run_lib.py:133] step: 670750, training_loss: 4.63991e-02
I0212 19:34:08.335223 22509476222784 run_lib.py:133] step: 670800, training_loss: 4.53434e-02
I0212 19:34:08.496393 22509476222784 run_lib.py:146] step: 670800, eval_loss: 4.30042e-02
I0212 19:34:27.015345 22509476222784 run_lib.py:133] step: 670850, training_loss: 5.53115e-02
I0212 19:34:45.591212 22509476222784 run_lib.py:133] step: 670900, training_loss: 4.03530e-02
I0212 19:34:45.777690 22509476222784 run_lib.py:146] step: 670900, eval_loss: 4.25419e-02
I0212 19:35:04.271733 22509476222784 run_lib.py:133] step: 670950, training_loss: 3.44253e-02
I0212 19:35:22.822254 22509476222784 run_lib.py:133] step: 671000, training_loss: 3.66393e-02
I0212 19:35:23.003814 22509476222784 run_lib.py:146] step: 671000, eval_loss: 4.59150e-02
I0212 19:35:41.743181 22509476222784 run_lib.py:133] step: 671050, training_loss: 5.17302e-02
I0212 19:36:00.422926 22509476222784 run_lib.py:133] step: 671100, training_loss: 4.40243e-02
I0212 19:36:00.589910 22509476222784 run_lib.py:146] step: 671100, eval_loss: 3.30638e-02
I0212 19:36:19.156012 22509476222784 run_lib.py:133] step: 671150, training_loss: 3.43261e-02
I0212 19:36:37.707781 22509476222784 run_lib.py:133] step: 671200, training_loss: 3.87142e-02
I0212 19:36:37.872504 22509476222784 run_lib.py:146] step: 671200, eval_loss: 4.65183e-02
I0212 19:36:56.570035 22509476222784 run_lib.py:133] step: 671250, training_loss: 3.53497e-02
I0212 19:37:15.130319 22509476222784 run_lib.py:133] step: 671300, training_loss: 4.53675e-02
I0212 19:37:15.293475 22509476222784 run_lib.py:146] step: 671300, eval_loss: 4.86966e-02
I0212 19:37:34.046167 22509476222784 run_lib.py:133] step: 671350, training_loss: 3.34065e-02
I0212 19:37:52.622755 22509476222784 run_lib.py:133] step: 671400, training_loss: 4.84018e-02
I0212 19:37:52.824655 22509476222784 run_lib.py:146] step: 671400, eval_loss: 4.16916e-02
I0212 19:38:11.454239 22509476222784 run_lib.py:133] step: 671450, training_loss: 6.10194e-02
I0212 19:38:30.044409 22509476222784 run_lib.py:133] step: 671500, training_loss: 3.72706e-02
I0212 19:38:30.242677 22509476222784 run_lib.py:146] step: 671500, eval_loss: 3.64230e-02
I0212 19:38:48.815501 22509476222784 run_lib.py:133] step: 671550, training_loss: 4.04749e-02
I0212 19:39:07.563215 22509476222784 run_lib.py:133] step: 671600, training_loss: 4.45669e-02
I0212 19:39:07.728848 22509476222784 run_lib.py:146] step: 671600, eval_loss: 2.94495e-02
I0212 19:39:26.299610 22509476222784 run_lib.py:133] step: 671650, training_loss: 4.53005e-02
I0212 19:39:44.972915 22509476222784 run_lib.py:133] step: 671700, training_loss: 4.85415e-02
I0212 19:39:45.136697 22509476222784 run_lib.py:146] step: 671700, eval_loss: 4.36878e-02
I0212 19:40:03.671493 22509476222784 run_lib.py:133] step: 671750, training_loss: 4.97888e-02
I0212 19:40:22.235823 22509476222784 run_lib.py:133] step: 671800, training_loss: 4.27931e-02
I0212 19:40:22.401818 22509476222784 run_lib.py:146] step: 671800, eval_loss: 4.48264e-02
I0212 19:40:41.187437 22509476222784 run_lib.py:133] step: 671850, training_loss: 4.75249e-02
I0212 19:40:59.705160 22509476222784 run_lib.py:133] step: 671900, training_loss: 4.24874e-02
I0212 19:40:59.915091 22509476222784 run_lib.py:146] step: 671900, eval_loss: 4.56821e-02
I0212 19:41:18.404600 22509476222784 run_lib.py:133] step: 671950, training_loss: 4.68238e-02
I0212 19:41:37.048142 22509476222784 run_lib.py:133] step: 672000, training_loss: 3.70177e-02
I0212 19:41:37.215094 22509476222784 run_lib.py:146] step: 672000, eval_loss: 3.28331e-02
I0212 19:41:55.791873 22509476222784 run_lib.py:133] step: 672050, training_loss: 3.89032e-02
I0212 19:42:14.322758 22509476222784 run_lib.py:133] step: 672100, training_loss: 4.05391e-02
I0212 19:42:14.487797 22509476222784 run_lib.py:146] step: 672100, eval_loss: 4.27884e-02
I0212 19:42:33.084527 22509476222784 run_lib.py:133] step: 672150, training_loss: 5.01098e-02
I0212 19:42:51.556747 22509476222784 run_lib.py:133] step: 672200, training_loss: 6.08681e-02
I0212 19:42:51.718297 22509476222784 run_lib.py:146] step: 672200, eval_loss: 3.82787e-02
I0212 19:43:10.261199 22509476222784 run_lib.py:133] step: 672250, training_loss: 4.26941e-02
I0212 19:43:28.896732 22509476222784 run_lib.py:133] step: 672300, training_loss: 4.11203e-02
I0212 19:43:29.071956 22509476222784 run_lib.py:146] step: 672300, eval_loss: 4.51197e-02
I0212 19:43:47.828486 22509476222784 run_lib.py:133] step: 672350, training_loss: 4.79494e-02
I0212 19:44:06.501571 22509476222784 run_lib.py:133] step: 672400, training_loss: 4.08027e-02
I0212 19:44:06.668636 22509476222784 run_lib.py:146] step: 672400, eval_loss: 3.24888e-02
I0212 19:44:25.198241 22509476222784 run_lib.py:133] step: 672450, training_loss: 4.35897e-02
I0212 19:44:43.686233 22509476222784 run_lib.py:133] step: 672500, training_loss: 4.88367e-02
I0212 19:44:43.849633 22509476222784 run_lib.py:146] step: 672500, eval_loss: 4.92953e-02
I0212 19:45:02.503006 22509476222784 run_lib.py:133] step: 672550, training_loss: 2.81029e-02
I0212 19:45:21.119128 22509476222784 run_lib.py:133] step: 672600, training_loss: 4.65876e-02
I0212 19:45:21.323280 22509476222784 run_lib.py:146] step: 672600, eval_loss: 4.48083e-02
I0212 19:45:40.132141 22509476222784 run_lib.py:133] step: 672650, training_loss: 4.75693e-02
I0212 19:45:58.691376 22509476222784 run_lib.py:133] step: 672700, training_loss: 4.42142e-02
I0212 19:45:58.886274 22509476222784 run_lib.py:146] step: 672700, eval_loss: 4.33789e-02
I0212 19:46:17.563216 22509476222784 run_lib.py:133] step: 672750, training_loss: 5.28301e-02
I0212 19:46:36.066537 22509476222784 run_lib.py:133] step: 672800, training_loss: 3.82535e-02
I0212 19:46:36.234878 22509476222784 run_lib.py:146] step: 672800, eval_loss: 4.56802e-02
I0212 19:46:54.971256 22509476222784 run_lib.py:133] step: 672850, training_loss: 4.89089e-02
I0212 19:47:13.568358 22509476222784 run_lib.py:133] step: 672900, training_loss: 3.89073e-02
I0212 19:47:13.733587 22509476222784 run_lib.py:146] step: 672900, eval_loss: 4.81495e-02
I0212 19:47:32.174772 22509476222784 run_lib.py:133] step: 672950, training_loss: 3.59670e-02
I0212 19:47:50.876332 22509476222784 run_lib.py:133] step: 673000, training_loss: 4.70612e-02
I0212 19:47:51.041593 22509476222784 run_lib.py:146] step: 673000, eval_loss: 4.54370e-02
I0212 19:48:09.587983 22509476222784 run_lib.py:133] step: 673050, training_loss: 3.41772e-02
I0212 19:48:28.168682 22509476222784 run_lib.py:133] step: 673100, training_loss: 3.81578e-02
I0212 19:48:28.335406 22509476222784 run_lib.py:146] step: 673100, eval_loss: 4.22815e-02
I0212 19:48:47.125589 22509476222784 run_lib.py:133] step: 673150, training_loss: 4.32865e-02
I0212 19:49:05.756347 22509476222784 run_lib.py:133] step: 673200, training_loss: 4.75948e-02
I0212 19:49:05.918965 22509476222784 run_lib.py:146] step: 673200, eval_loss: 4.08643e-02
I0212 19:49:24.658325 22509476222784 run_lib.py:133] step: 673250, training_loss: 4.08064e-02
I0212 19:49:43.189394 22509476222784 run_lib.py:133] step: 673300, training_loss: 3.15007e-02
I0212 19:49:43.352586 22509476222784 run_lib.py:146] step: 673300, eval_loss: 3.54687e-02
I0212 19:50:01.915946 22509476222784 run_lib.py:133] step: 673350, training_loss: 4.17198e-02
I0212 19:50:20.773419 22509476222784 run_lib.py:133] step: 673400, training_loss: 3.69724e-02
I0212 19:50:20.954669 22509476222784 run_lib.py:146] step: 673400, eval_loss: 4.99787e-02
I0212 19:50:39.458010 22509476222784 run_lib.py:133] step: 673450, training_loss: 3.78670e-02
I0212 19:50:57.967634 22509476222784 run_lib.py:133] step: 673500, training_loss: 4.51635e-02
I0212 19:50:58.174812 22509476222784 run_lib.py:146] step: 673500, eval_loss: 4.57474e-02
I0212 19:51:16.724427 22509476222784 run_lib.py:133] step: 673550, training_loss: 5.04761e-02
I0212 19:51:35.497654 22509476222784 run_lib.py:133] step: 673600, training_loss: 4.39896e-02
I0212 19:51:35.675799 22509476222784 run_lib.py:146] step: 673600, eval_loss: 5.01259e-02
I0212 19:51:54.254942 22509476222784 run_lib.py:133] step: 673650, training_loss: 4.55941e-02
I0212 19:52:12.908732 22509476222784 run_lib.py:133] step: 673700, training_loss: 4.45639e-02
I0212 19:52:13.106904 22509476222784 run_lib.py:146] step: 673700, eval_loss: 3.90521e-02
I0212 19:52:31.691887 22509476222784 run_lib.py:133] step: 673750, training_loss: 3.44412e-02
I0212 19:52:50.234238 22509476222784 run_lib.py:133] step: 673800, training_loss: 3.91055e-02
I0212 19:52:50.428016 22509476222784 run_lib.py:146] step: 673800, eval_loss: 3.92317e-02
I0212 19:53:09.162675 22509476222784 run_lib.py:133] step: 673850, training_loss: 4.35921e-02
I0212 19:53:27.814826 22509476222784 run_lib.py:133] step: 673900, training_loss: 3.85183e-02
I0212 19:53:28.028855 22509476222784 run_lib.py:146] step: 673900, eval_loss: 5.87328e-02
I0212 19:53:46.587911 22509476222784 run_lib.py:133] step: 673950, training_loss: 4.50804e-02
I0212 19:54:05.175296 22509476222784 run_lib.py:133] step: 674000, training_loss: 5.14618e-02
I0212 19:54:05.339512 22509476222784 run_lib.py:146] step: 674000, eval_loss: 3.75328e-02
I0212 19:54:24.115308 22509476222784 run_lib.py:133] step: 674050, training_loss: 3.96071e-02
I0212 19:54:42.667610 22509476222784 run_lib.py:133] step: 674100, training_loss: 4.18533e-02
I0212 19:54:42.830451 22509476222784 run_lib.py:146] step: 674100, eval_loss: 4.57849e-02
I0212 19:55:01.446063 22509476222784 run_lib.py:133] step: 674150, training_loss: 4.95424e-02
I0212 19:55:20.087186 22509476222784 run_lib.py:133] step: 674200, training_loss: 5.56633e-02
I0212 19:55:20.272017 22509476222784 run_lib.py:146] step: 674200, eval_loss: 3.72974e-02
I0212 19:55:39.039404 22509476222784 run_lib.py:133] step: 674250, training_loss: 4.06205e-02
I0212 19:55:57.610642 22509476222784 run_lib.py:133] step: 674300, training_loss: 4.11902e-02
I0212 19:55:57.774896 22509476222784 run_lib.py:146] step: 674300, eval_loss: 3.61423e-02
I0212 19:56:16.315513 22509476222784 run_lib.py:133] step: 674350, training_loss: 4.29421e-02
I0212 19:56:35.071492 22509476222784 run_lib.py:133] step: 674400, training_loss: 3.59012e-02
I0212 19:56:35.263760 22509476222784 run_lib.py:146] step: 674400, eval_loss: 5.03146e-02
I0212 19:56:53.807029 22509476222784 run_lib.py:133] step: 674450, training_loss: 5.15580e-02
I0212 19:57:12.619679 22509476222784 run_lib.py:133] step: 674500, training_loss: 3.92670e-02
I0212 19:57:12.784610 22509476222784 run_lib.py:146] step: 674500, eval_loss: 4.04500e-02
I0212 19:57:31.376259 22509476222784 run_lib.py:133] step: 674550, training_loss: 3.19051e-02
I0212 19:57:49.902486 22509476222784 run_lib.py:133] step: 674600, training_loss: 3.96507e-02
I0212 19:57:50.069455 22509476222784 run_lib.py:146] step: 674600, eval_loss: 4.91737e-02
I0212 19:58:08.742371 22509476222784 run_lib.py:133] step: 674650, training_loss: 5.39109e-02
I0212 19:58:27.291741 22509476222784 run_lib.py:133] step: 674700, training_loss: 4.48987e-02
I0212 19:58:27.471874 22509476222784 run_lib.py:146] step: 674700, eval_loss: 4.26306e-02
I0212 19:58:46.077136 22509476222784 run_lib.py:133] step: 674750, training_loss: 3.93461e-02
I0212 19:59:04.900978 22509476222784 run_lib.py:133] step: 674800, training_loss: 3.90729e-02
I0212 19:59:05.067858 22509476222784 run_lib.py:146] step: 674800, eval_loss: 3.52080e-02
I0212 19:59:23.570762 22509476222784 run_lib.py:133] step: 674850, training_loss: 3.48600e-02
I0212 19:59:42.097740 22509476222784 run_lib.py:133] step: 674900, training_loss: 4.57927e-02
I0212 19:59:42.430556 22509476222784 run_lib.py:146] step: 674900, eval_loss: 4.90578e-02
I0212 20:00:00.943316 22509476222784 run_lib.py:133] step: 674950, training_loss: 3.44575e-02
I0212 20:00:19.559591 22509476222784 run_lib.py:133] step: 675000, training_loss: 4.98596e-02
I0212 20:00:19.725418 22509476222784 run_lib.py:146] step: 675000, eval_loss: 4.65875e-02
I0212 20:00:38.264768 22509476222784 run_lib.py:133] step: 675050, training_loss: 6.36632e-02
I0212 20:00:56.750941 22509476222784 run_lib.py:133] step: 675100, training_loss: 4.08644e-02
I0212 20:00:56.911665 22509476222784 run_lib.py:146] step: 675100, eval_loss: 3.87971e-02
I0212 20:01:15.608873 22509476222784 run_lib.py:133] step: 675150, training_loss: 4.65588e-02
I0212 20:01:34.262777 22509476222784 run_lib.py:133] step: 675200, training_loss: 4.29653e-02
I0212 20:01:34.433972 22509476222784 run_lib.py:146] step: 675200, eval_loss: 4.12634e-02
I0212 20:01:53.006478 22509476222784 run_lib.py:133] step: 675250, training_loss: 4.33601e-02
I0212 20:02:11.620541 22509476222784 run_lib.py:133] step: 675300, training_loss: 4.59623e-02
I0212 20:02:11.812705 22509476222784 run_lib.py:146] step: 675300, eval_loss: 4.58575e-02
I0212 20:02:30.579822 22509476222784 run_lib.py:133] step: 675350, training_loss: 3.65394e-02
I0212 20:02:49.248999 22509476222784 run_lib.py:133] step: 675400, training_loss: 3.60538e-02
I0212 20:02:49.456593 22509476222784 run_lib.py:146] step: 675400, eval_loss: 3.71181e-02
I0212 20:03:07.986055 22509476222784 run_lib.py:133] step: 675450, training_loss: 3.59411e-02
I0212 20:03:26.584427 22509476222784 run_lib.py:133] step: 675500, training_loss: 4.26766e-02
I0212 20:03:26.752095 22509476222784 run_lib.py:146] step: 675500, eval_loss: 3.74743e-02
I0212 20:03:45.564845 22509476222784 run_lib.py:133] step: 675550, training_loss: 3.45057e-02
I0212 20:04:04.102997 22509476222784 run_lib.py:133] step: 675600, training_loss: 4.11417e-02
I0212 20:04:04.265579 22509476222784 run_lib.py:146] step: 675600, eval_loss: 4.08271e-02
I0212 20:04:22.888112 22509476222784 run_lib.py:133] step: 675650, training_loss: 4.34206e-02
I0212 20:04:41.382412 22509476222784 run_lib.py:133] step: 675700, training_loss: 2.92004e-02
I0212 20:04:41.552978 22509476222784 run_lib.py:146] step: 675700, eval_loss: 4.24669e-02
I0212 20:05:00.297075 22509476222784 run_lib.py:133] step: 675750, training_loss: 4.71545e-02
I0212 20:05:18.917594 22509476222784 run_lib.py:133] step: 675800, training_loss: 4.53844e-02
I0212 20:05:19.107049 22509476222784 run_lib.py:146] step: 675800, eval_loss: 4.23139e-02
I0212 20:05:37.649887 22509476222784 run_lib.py:133] step: 675850, training_loss: 3.46778e-02
I0212 20:05:56.340864 22509476222784 run_lib.py:133] step: 675900, training_loss: 4.40646e-02
I0212 20:05:56.505893 22509476222784 run_lib.py:146] step: 675900, eval_loss: 4.35049e-02
I0212 20:06:15.117392 22509476222784 run_lib.py:133] step: 675950, training_loss: 5.08482e-02
I0212 20:06:33.800316 22509476222784 run_lib.py:133] step: 676000, training_loss: 3.15980e-02
I0212 20:06:33.969291 22509476222784 run_lib.py:146] step: 676000, eval_loss: 4.41478e-02
I0212 20:06:52.599442 22509476222784 run_lib.py:133] step: 676050, training_loss: 2.65552e-02
I0212 20:07:11.162240 22509476222784 run_lib.py:133] step: 676100, training_loss: 3.33050e-02
I0212 20:07:11.354903 22509476222784 run_lib.py:146] step: 676100, eval_loss: 4.85615e-02
I0212 20:07:29.887990 22509476222784 run_lib.py:133] step: 676150, training_loss: 3.14905e-02
I0212 20:07:48.614689 22509476222784 run_lib.py:133] step: 676200, training_loss: 3.74774e-02
I0212 20:07:48.817634 22509476222784 run_lib.py:146] step: 676200, eval_loss: 4.27056e-02
I0212 20:08:07.321141 22509476222784 run_lib.py:133] step: 676250, training_loss: 3.70430e-02
I0212 20:08:25.921938 22509476222784 run_lib.py:133] step: 676300, training_loss: 3.96408e-02
I0212 20:08:26.137728 22509476222784 run_lib.py:146] step: 676300, eval_loss: 4.76938e-02
I0212 20:08:44.960335 22509476222784 run_lib.py:133] step: 676350, training_loss: 3.82637e-02
I0212 20:09:03.579978 22509476222784 run_lib.py:133] step: 676400, training_loss: 4.87875e-02
I0212 20:09:03.775027 22509476222784 run_lib.py:146] step: 676400, eval_loss: 4.39513e-02
I0212 20:09:22.435396 22509476222784 run_lib.py:133] step: 676450, training_loss: 5.61673e-02
I0212 20:09:40.978860 22509476222784 run_lib.py:133] step: 676500, training_loss: 4.57454e-02
I0212 20:09:41.139784 22509476222784 run_lib.py:146] step: 676500, eval_loss: 4.05302e-02
I0212 20:09:59.693158 22509476222784 run_lib.py:133] step: 676550, training_loss: 5.51339e-02
I0212 20:10:18.329338 22509476222784 run_lib.py:133] step: 676600, training_loss: 4.29102e-02
I0212 20:10:18.505900 22509476222784 run_lib.py:146] step: 676600, eval_loss: 3.85742e-02
I0212 20:10:37.197014 22509476222784 run_lib.py:133] step: 676650, training_loss: 3.95954e-02
I0212 20:10:55.777555 22509476222784 run_lib.py:133] step: 676700, training_loss: 2.81879e-02
I0212 20:10:55.942964 22509476222784 run_lib.py:146] step: 676700, eval_loss: 4.68777e-02
I0212 20:11:14.422073 22509476222784 run_lib.py:133] step: 676750, training_loss: 4.12432e-02
I0212 20:11:32.929989 22509476222784 run_lib.py:133] step: 676800, training_loss: 2.91637e-02
I0212 20:11:33.093667 22509476222784 run_lib.py:146] step: 676800, eval_loss: 5.36006e-02
I0212 20:11:51.804658 22509476222784 run_lib.py:133] step: 676850, training_loss: 4.60300e-02
I0212 20:12:10.423211 22509476222784 run_lib.py:133] step: 676900, training_loss: 5.11559e-02
I0212 20:12:10.586773 22509476222784 run_lib.py:146] step: 676900, eval_loss: 3.29733e-02
I0212 20:12:29.345512 22509476222784 run_lib.py:133] step: 676950, training_loss: 2.91922e-02
I0212 20:12:47.856446 22509476222784 run_lib.py:133] step: 677000, training_loss: 4.17217e-02
I0212 20:12:48.039550 22509476222784 run_lib.py:146] step: 677000, eval_loss: 4.09220e-02
I0212 20:13:06.735952 22509476222784 run_lib.py:133] step: 677050, training_loss: 4.13143e-02
I0212 20:13:25.264371 22509476222784 run_lib.py:133] step: 677100, training_loss: 3.80049e-02
I0212 20:13:25.471466 22509476222784 run_lib.py:146] step: 677100, eval_loss: 4.01187e-02
I0212 20:13:44.242953 22509476222784 run_lib.py:133] step: 677150, training_loss: 4.95598e-02
I0212 20:14:02.786779 22509476222784 run_lib.py:133] step: 677200, training_loss: 3.93453e-02
I0212 20:14:02.952657 22509476222784 run_lib.py:146] step: 677200, eval_loss: 3.99495e-02
I0212 20:14:21.468654 22509476222784 run_lib.py:133] step: 677250, training_loss: 4.89899e-02
I0212 20:14:40.165923 22509476222784 run_lib.py:133] step: 677300, training_loss: 3.28982e-02
I0212 20:14:40.351624 22509476222784 run_lib.py:146] step: 677300, eval_loss: 2.86444e-02
I0212 20:14:58.875586 22509476222784 run_lib.py:133] step: 677350, training_loss: 3.00773e-02
I0212 20:15:17.473302 22509476222784 run_lib.py:133] step: 677400, training_loss: 5.45399e-02
I0212 20:15:17.669888 22509476222784 run_lib.py:146] step: 677400, eval_loss: 5.00599e-02
I0212 20:15:36.482062 22509476222784 run_lib.py:133] step: 677450, training_loss: 4.52487e-02
I0212 20:15:55.163907 22509476222784 run_lib.py:133] step: 677500, training_loss: 3.54687e-02
I0212 20:15:55.325223 22509476222784 run_lib.py:146] step: 677500, eval_loss: 4.65246e-02
I0212 20:16:13.857702 22509476222784 run_lib.py:133] step: 677550, training_loss: 3.11347e-02
I0212 20:16:32.454150 22509476222784 run_lib.py:133] step: 677600, training_loss: 5.10406e-02
I0212 20:16:32.665042 22509476222784 run_lib.py:146] step: 677600, eval_loss: 5.12107e-02
I0212 20:16:51.261335 22509476222784 run_lib.py:133] step: 677650, training_loss: 5.18961e-02
I0212 20:17:10.066016 22509476222784 run_lib.py:133] step: 677700, training_loss: 4.12483e-02
I0212 20:17:10.419986 22509476222784 run_lib.py:146] step: 677700, eval_loss: 4.02605e-02
I0212 20:17:28.988687 22509476222784 run_lib.py:133] step: 677750, training_loss: 3.96971e-02
I0212 20:17:47.527693 22509476222784 run_lib.py:133] step: 677800, training_loss: 3.31702e-02
I0212 20:17:47.709933 22509476222784 run_lib.py:146] step: 677800, eval_loss: 4.04436e-02
I0212 20:18:06.241678 22509476222784 run_lib.py:133] step: 677850, training_loss: 4.68460e-02
I0212 20:18:24.923943 22509476222784 run_lib.py:133] step: 677900, training_loss: 4.97765e-02
I0212 20:18:25.087250 22509476222784 run_lib.py:146] step: 677900, eval_loss: 4.54319e-02
I0212 20:18:43.756797 22509476222784 run_lib.py:133] step: 677950, training_loss: 4.64741e-02
I0212 20:19:02.453705 22509476222784 run_lib.py:133] step: 678000, training_loss: 3.79400e-02
I0212 20:19:02.617640 22509476222784 run_lib.py:146] step: 678000, eval_loss: 4.30983e-02
I0212 20:19:21.129264 22509476222784 run_lib.py:133] step: 678050, training_loss: 5.11253e-02
I0212 20:19:39.715838 22509476222784 run_lib.py:133] step: 678100, training_loss: 5.03445e-02
I0212 20:19:39.887928 22509476222784 run_lib.py:146] step: 678100, eval_loss: 4.88108e-02
I0212 20:19:58.596998 22509476222784 run_lib.py:133] step: 678150, training_loss: 4.55706e-02
I0212 20:20:17.369017 22509476222784 run_lib.py:133] step: 678200, training_loss: 4.03446e-02
I0212 20:20:17.575008 22509476222784 run_lib.py:146] step: 678200, eval_loss: 4.98286e-02
I0212 20:20:36.198119 22509476222784 run_lib.py:133] step: 678250, training_loss: 4.69639e-02
I0212 20:20:54.791809 22509476222784 run_lib.py:133] step: 678300, training_loss: 4.96130e-02
I0212 20:20:54.956696 22509476222784 run_lib.py:146] step: 678300, eval_loss: 4.62279e-02
I0212 20:21:13.724093 22509476222784 run_lib.py:133] step: 678350, training_loss: 4.19392e-02
I0212 20:21:32.288514 22509476222784 run_lib.py:133] step: 678400, training_loss: 3.84745e-02
I0212 20:21:32.449995 22509476222784 run_lib.py:146] step: 678400, eval_loss: 3.98689e-02
I0212 20:21:51.176608 22509476222784 run_lib.py:133] step: 678450, training_loss: 3.18587e-02
I0212 20:22:09.844059 22509476222784 run_lib.py:133] step: 678500, training_loss: 3.66798e-02
I0212 20:22:10.019899 22509476222784 run_lib.py:146] step: 678500, eval_loss: 4.56903e-02
I0212 20:22:28.797662 22509476222784 run_lib.py:133] step: 678550, training_loss: 4.25925e-02
I0212 20:22:47.393810 22509476222784 run_lib.py:133] step: 678600, training_loss: 3.87414e-02
I0212 20:22:47.591957 22509476222784 run_lib.py:146] step: 678600, eval_loss: 4.50237e-02
I0212 20:23:06.175923 22509476222784 run_lib.py:133] step: 678650, training_loss: 3.46463e-02
I0212 20:23:24.888936 22509476222784 run_lib.py:133] step: 678700, training_loss: 4.97902e-02
I0212 20:23:25.058616 22509476222784 run_lib.py:146] step: 678700, eval_loss: 3.14592e-02
I0212 20:23:43.705941 22509476222784 run_lib.py:133] step: 678750, training_loss: 4.62430e-02
I0212 20:24:02.565185 22509476222784 run_lib.py:133] step: 678800, training_loss: 4.20335e-02
I0212 20:24:02.728748 22509476222784 run_lib.py:146] step: 678800, eval_loss: 4.73356e-02
I0212 20:24:21.336020 22509476222784 run_lib.py:133] step: 678850, training_loss: 4.33529e-02
I0212 20:24:39.913141 22509476222784 run_lib.py:133] step: 678900, training_loss: 4.63832e-02
I0212 20:24:40.075659 22509476222784 run_lib.py:146] step: 678900, eval_loss: 3.94251e-02
I0212 20:24:58.817739 22509476222784 run_lib.py:133] step: 678950, training_loss: 5.03615e-02
I0212 20:25:17.352786 22509476222784 run_lib.py:133] step: 679000, training_loss: 4.17477e-02
I0212 20:25:17.523670 22509476222784 run_lib.py:146] step: 679000, eval_loss: 5.33229e-02
I0212 20:25:36.061946 22509476222784 run_lib.py:133] step: 679050, training_loss: 4.28259e-02
I0212 20:25:54.825487 22509476222784 run_lib.py:133] step: 679100, training_loss: 4.68304e-02
I0212 20:25:55.021099 22509476222784 run_lib.py:146] step: 679100, eval_loss: 3.76952e-02
I0212 20:26:13.595481 22509476222784 run_lib.py:133] step: 679150, training_loss: 5.82071e-02
I0212 20:26:32.128154 22509476222784 run_lib.py:133] step: 679200, training_loss: 4.05208e-02
I0212 20:26:32.321817 22509476222784 run_lib.py:146] step: 679200, eval_loss: 2.91103e-02
I0212 20:26:51.001505 22509476222784 run_lib.py:133] step: 679250, training_loss: 4.51343e-02
I0212 20:27:09.601983 22509476222784 run_lib.py:133] step: 679300, training_loss: 4.19991e-02
I0212 20:27:09.800888 22509476222784 run_lib.py:146] step: 679300, eval_loss: 3.35153e-02
I0212 20:27:28.387337 22509476222784 run_lib.py:133] step: 679350, training_loss: 4.31162e-02
I0212 20:27:46.944498 22509476222784 run_lib.py:133] step: 679400, training_loss: 5.19569e-02
I0212 20:27:47.104724 22509476222784 run_lib.py:146] step: 679400, eval_loss: 3.14887e-02
I0212 20:28:05.887390 22509476222784 run_lib.py:133] step: 679450, training_loss: 3.47648e-02
I0212 20:28:24.591057 22509476222784 run_lib.py:133] step: 679500, training_loss: 3.80934e-02
I0212 20:28:24.764754 22509476222784 run_lib.py:146] step: 679500, eval_loss: 3.12168e-02
I0212 20:28:43.360793 22509476222784 run_lib.py:133] step: 679550, training_loss: 4.44029e-02
I0212 20:29:01.983753 22509476222784 run_lib.py:133] step: 679600, training_loss: 4.96270e-02
I0212 20:29:02.148800 22509476222784 run_lib.py:146] step: 679600, eval_loss: 3.84695e-02
I0212 20:29:20.855436 22509476222784 run_lib.py:133] step: 679650, training_loss: 4.18411e-02
I0212 20:29:39.422661 22509476222784 run_lib.py:133] step: 679700, training_loss: 3.96924e-02
I0212 20:29:39.590522 22509476222784 run_lib.py:146] step: 679700, eval_loss: 3.64662e-02
I0212 20:29:58.342739 22509476222784 run_lib.py:133] step: 679750, training_loss: 3.35887e-02
I0212 20:30:16.936489 22509476222784 run_lib.py:133] step: 679800, training_loss: 4.02759e-02
I0212 20:30:17.098564 22509476222784 run_lib.py:146] step: 679800, eval_loss: 3.05623e-02
I0212 20:30:35.864581 22509476222784 run_lib.py:133] step: 679850, training_loss: 3.39859e-02
I0212 20:30:54.404858 22509476222784 run_lib.py:133] step: 679900, training_loss: 4.26538e-02
I0212 20:30:54.568348 22509476222784 run_lib.py:146] step: 679900, eval_loss: 3.61002e-02
I0212 20:31:13.245735 22509476222784 run_lib.py:133] step: 679950, training_loss: 4.39714e-02
I0212 20:31:31.826885 22509476222784 run_lib.py:133] step: 680000, training_loss: 4.98965e-02
I0212 20:31:32.591782 22509476222784 run_lib.py:146] step: 680000, eval_loss: 4.54119e-02
I0212 20:31:53.867944 22509476222784 run_lib.py:133] step: 680050, training_loss: 3.49676e-02
I0212 20:32:12.664502 22509476222784 run_lib.py:133] step: 680100, training_loss: 3.31701e-02
I0212 20:32:12.876991 22509476222784 run_lib.py:146] step: 680100, eval_loss: 3.89498e-02
I0212 20:32:31.364146 22509476222784 run_lib.py:133] step: 680150, training_loss: 4.06621e-02
I0212 20:32:49.976730 22509476222784 run_lib.py:133] step: 680200, training_loss: 3.07866e-02
I0212 20:32:50.150736 22509476222784 run_lib.py:146] step: 680200, eval_loss: 4.25384e-02
I0212 20:33:08.739561 22509476222784 run_lib.py:133] step: 680250, training_loss: 4.66566e-02
I0212 20:33:27.325625 22509476222784 run_lib.py:133] step: 680300, training_loss: 4.17144e-02
I0212 20:33:27.488819 22509476222784 run_lib.py:146] step: 680300, eval_loss: 5.62288e-02
I0212 20:33:46.260527 22509476222784 run_lib.py:133] step: 680350, training_loss: 3.37124e-02
I0212 20:34:04.888209 22509476222784 run_lib.py:133] step: 680400, training_loss: 4.94777e-02
I0212 20:34:05.079708 22509476222784 run_lib.py:146] step: 680400, eval_loss: 3.59353e-02
I0212 20:34:23.646087 22509476222784 run_lib.py:133] step: 680450, training_loss: 2.93854e-02
I0212 20:34:42.208026 22509476222784 run_lib.py:133] step: 680500, training_loss: 4.52005e-02
I0212 20:34:42.418698 22509476222784 run_lib.py:146] step: 680500, eval_loss: 4.67484e-02
I0212 20:35:01.235541 22509476222784 run_lib.py:133] step: 680550, training_loss: 4.24542e-02
I0212 20:35:19.815498 22509476222784 run_lib.py:133] step: 680600, training_loss: 4.06075e-02
I0212 20:35:19.979850 22509476222784 run_lib.py:146] step: 680600, eval_loss: 3.58199e-02
I0212 20:35:38.708923 22509476222784 run_lib.py:133] step: 680650, training_loss: 4.28189e-02
I0212 20:35:57.225602 22509476222784 run_lib.py:133] step: 680700, training_loss: 4.09021e-02
I0212 20:35:57.388446 22509476222784 run_lib.py:146] step: 680700, eval_loss: 5.47042e-02
I0212 20:36:16.045979 22509476222784 run_lib.py:133] step: 680750, training_loss: 3.71278e-02
I0212 20:36:34.664115 22509476222784 run_lib.py:133] step: 680800, training_loss: 5.67813e-02
I0212 20:36:34.826803 22509476222784 run_lib.py:146] step: 680800, eval_loss: 4.22856e-02
I0212 20:36:53.401558 22509476222784 run_lib.py:133] step: 680850, training_loss: 4.28792e-02
I0212 20:37:12.112396 22509476222784 run_lib.py:133] step: 680900, training_loss: 4.01345e-02
I0212 20:37:12.273880 22509476222784 run_lib.py:146] step: 680900, eval_loss: 4.85001e-02
I0212 20:37:30.834870 22509476222784 run_lib.py:133] step: 680950, training_loss: 3.98043e-02
I0212 20:37:49.495185 22509476222784 run_lib.py:133] step: 681000, training_loss: 4.07947e-02
I0212 20:37:49.672824 22509476222784 run_lib.py:146] step: 681000, eval_loss: 4.93290e-02
I0212 20:38:08.281914 22509476222784 run_lib.py:133] step: 681050, training_loss: 4.39159e-02
I0212 20:38:26.893804 22509476222784 run_lib.py:133] step: 681100, training_loss: 4.89891e-02
I0212 20:38:27.063998 22509476222784 run_lib.py:146] step: 681100, eval_loss: 4.84634e-02
I0212 20:38:45.792698 22509476222784 run_lib.py:133] step: 681150, training_loss: 4.28851e-02
I0212 20:39:04.303583 22509476222784 run_lib.py:133] step: 681200, training_loss: 3.71505e-02
I0212 20:39:04.502845 22509476222784 run_lib.py:146] step: 681200, eval_loss: 4.67097e-02
I0212 20:39:23.075551 22509476222784 run_lib.py:133] step: 681250, training_loss: 4.28696e-02
I0212 20:39:41.840399 22509476222784 run_lib.py:133] step: 681300, training_loss: 2.82500e-02
I0212 20:39:42.029009 22509476222784 run_lib.py:146] step: 681300, eval_loss: 3.90032e-02
I0212 20:40:00.661076 22509476222784 run_lib.py:133] step: 681350, training_loss: 3.73973e-02
I0212 20:40:19.154913 22509476222784 run_lib.py:133] step: 681400, training_loss: 3.44477e-02
I0212 20:40:19.318794 22509476222784 run_lib.py:146] step: 681400, eval_loss: 4.14149e-02
I0212 20:40:37.942498 22509476222784 run_lib.py:133] step: 681450, training_loss: 4.10610e-02
I0212 20:40:56.489755 22509476222784 run_lib.py:133] step: 681500, training_loss: 5.01017e-02
I0212 20:40:56.719949 22509476222784 run_lib.py:146] step: 681500, eval_loss: 3.66065e-02
I0212 20:41:15.256492 22509476222784 run_lib.py:133] step: 681550, training_loss: 4.29049e-02
I0212 20:41:33.875124 22509476222784 run_lib.py:133] step: 681600, training_loss: 4.62625e-02
I0212 20:41:34.038868 22509476222784 run_lib.py:146] step: 681600, eval_loss: 4.91845e-02
I0212 20:41:52.720468 22509476222784 run_lib.py:133] step: 681650, training_loss: 3.25561e-02
I0212 20:42:11.500509 22509476222784 run_lib.py:133] step: 681700, training_loss: 4.65075e-02
I0212 20:42:11.664755 22509476222784 run_lib.py:146] step: 681700, eval_loss: 3.89511e-02
I0212 20:42:30.214627 22509476222784 run_lib.py:133] step: 681750, training_loss: 4.70618e-02
I0212 20:42:48.834103 22509476222784 run_lib.py:133] step: 681800, training_loss: 4.19572e-02
I0212 20:42:48.995675 22509476222784 run_lib.py:146] step: 681800, eval_loss: 4.44415e-02
I0212 20:43:07.769790 22509476222784 run_lib.py:133] step: 681850, training_loss: 4.13445e-02
I0212 20:43:26.413451 22509476222784 run_lib.py:133] step: 681900, training_loss: 3.22624e-02
I0212 20:43:26.582094 22509476222784 run_lib.py:146] step: 681900, eval_loss: 3.99069e-02
I0212 20:43:45.323965 22509476222784 run_lib.py:133] step: 681950, training_loss: 4.21373e-02
I0212 20:44:03.869651 22509476222784 run_lib.py:133] step: 682000, training_loss: 3.85465e-02
I0212 20:44:04.036941 22509476222784 run_lib.py:146] step: 682000, eval_loss: 4.41786e-02
I0212 20:44:22.752255 22509476222784 run_lib.py:133] step: 682050, training_loss: 4.61890e-02
I0212 20:44:41.333222 22509476222784 run_lib.py:133] step: 682100, training_loss: 4.16070e-02
I0212 20:44:41.508731 22509476222784 run_lib.py:146] step: 682100, eval_loss: 3.59681e-02
I0212 20:45:00.315961 22509476222784 run_lib.py:133] step: 682150, training_loss: 4.54184e-02
I0212 20:45:18.906308 22509476222784 run_lib.py:133] step: 682200, training_loss: 3.59627e-02
I0212 20:45:19.084554 22509476222784 run_lib.py:146] step: 682200, eval_loss: 4.90682e-02
I0212 20:45:37.647852 22509476222784 run_lib.py:133] step: 682250, training_loss: 5.40477e-02
I0212 20:45:56.381209 22509476222784 run_lib.py:133] step: 682300, training_loss: 4.11529e-02
I0212 20:45:56.576752 22509476222784 run_lib.py:146] step: 682300, eval_loss: 5.26605e-02
I0212 20:46:15.129631 22509476222784 run_lib.py:133] step: 682350, training_loss: 2.98604e-02
I0212 20:46:33.707137 22509476222784 run_lib.py:133] step: 682400, training_loss: 4.77696e-02
I0212 20:46:33.887694 22509476222784 run_lib.py:146] step: 682400, eval_loss: 4.17489e-02
I0212 20:46:52.661399 22509476222784 run_lib.py:133] step: 682450, training_loss: 5.02553e-02
I0212 20:47:11.240281 22509476222784 run_lib.py:133] step: 682500, training_loss: 5.95327e-02
I0212 20:47:11.426804 22509476222784 run_lib.py:146] step: 682500, eval_loss: 4.68335e-02
I0212 20:47:30.128129 22509476222784 run_lib.py:133] step: 682550, training_loss: 3.61444e-02
I0212 20:47:48.679729 22509476222784 run_lib.py:133] step: 682600, training_loss: 3.89325e-02
I0212 20:47:48.885818 22509476222784 run_lib.py:146] step: 682600, eval_loss: 4.74768e-02
I0212 20:48:07.428911 22509476222784 run_lib.py:133] step: 682650, training_loss: 5.52134e-02
I0212 20:48:26.195071 22509476222784 run_lib.py:133] step: 682700, training_loss: 4.04082e-02
I0212 20:48:26.359910 22509476222784 run_lib.py:146] step: 682700, eval_loss: 4.50557e-02
I0212 20:48:44.962063 22509476222784 run_lib.py:133] step: 682750, training_loss: 4.34460e-02
I0212 20:49:03.500184 22509476222784 run_lib.py:133] step: 682800, training_loss: 4.75556e-02
I0212 20:49:03.662779 22509476222784 run_lib.py:146] step: 682800, eval_loss: 3.47858e-02
I0212 20:49:22.194801 22509476222784 run_lib.py:133] step: 682850, training_loss: 5.33647e-02
I0212 20:49:40.948331 22509476222784 run_lib.py:133] step: 682900, training_loss: 5.14104e-02
I0212 20:49:41.127685 22509476222784 run_lib.py:146] step: 682900, eval_loss: 4.27417e-02
I0212 20:49:59.858278 22509476222784 run_lib.py:133] step: 682950, training_loss: 4.89511e-02
I0212 20:50:18.635038 22509476222784 run_lib.py:133] step: 683000, training_loss: 4.13386e-02
I0212 20:50:18.821107 22509476222784 run_lib.py:146] step: 683000, eval_loss: 4.39922e-02
I0212 20:50:37.343197 22509476222784 run_lib.py:133] step: 683050, training_loss: 5.94595e-02
I0212 20:50:55.876620 22509476222784 run_lib.py:133] step: 683100, training_loss: 3.96217e-02
I0212 20:50:56.039528 22509476222784 run_lib.py:146] step: 683100, eval_loss: 3.64603e-02
I0212 20:51:14.705840 22509476222784 run_lib.py:133] step: 683150, training_loss: 4.11646e-02
I0212 20:51:33.413256 22509476222784 run_lib.py:133] step: 683200, training_loss: 4.64241e-02
I0212 20:51:33.617425 22509476222784 run_lib.py:146] step: 683200, eval_loss: 4.53356e-02
I0212 20:51:52.235084 22509476222784 run_lib.py:133] step: 683250, training_loss: 4.79902e-02
I0212 20:52:10.781208 22509476222784 run_lib.py:133] step: 683300, training_loss: 4.32159e-02
I0212 20:52:10.966205 22509476222784 run_lib.py:146] step: 683300, eval_loss: 3.77415e-02
I0212 20:52:29.662332 22509476222784 run_lib.py:133] step: 683350, training_loss: 4.10858e-02
I0212 20:52:48.250489 22509476222784 run_lib.py:133] step: 683400, training_loss: 5.25910e-02
I0212 20:52:48.418024 22509476222784 run_lib.py:146] step: 683400, eval_loss: 4.43214e-02
I0212 20:53:07.128789 22509476222784 run_lib.py:133] step: 683450, training_loss: 4.41823e-02
I0212 20:53:25.777301 22509476222784 run_lib.py:133] step: 683500, training_loss: 4.86304e-02
I0212 20:53:25.943968 22509476222784 run_lib.py:146] step: 683500, eval_loss: 4.17464e-02
I0212 20:53:44.701880 22509476222784 run_lib.py:133] step: 683550, training_loss: 4.95275e-02
I0212 20:54:03.245231 22509476222784 run_lib.py:133] step: 683600, training_loss: 4.79918e-02
I0212 20:54:03.418433 22509476222784 run_lib.py:146] step: 683600, eval_loss: 3.60050e-02
I0212 20:54:21.956866 22509476222784 run_lib.py:133] step: 683650, training_loss: 3.89641e-02
I0212 20:54:40.658140 22509476222784 run_lib.py:133] step: 683700, training_loss: 4.56580e-02
I0212 20:54:40.830841 22509476222784 run_lib.py:146] step: 683700, eval_loss: 4.75469e-02
I0212 20:54:59.548008 22509476222784 run_lib.py:133] step: 683750, training_loss: 4.77651e-02
I0212 20:55:18.275385 22509476222784 run_lib.py:133] step: 683800, training_loss: 3.00314e-02
I0212 20:55:18.442041 22509476222784 run_lib.py:146] step: 683800, eval_loss: 2.74029e-02
I0212 20:55:36.963266 22509476222784 run_lib.py:133] step: 683850, training_loss: 2.84539e-02
I0212 20:55:55.529429 22509476222784 run_lib.py:133] step: 683900, training_loss: 3.92558e-02
I0212 20:55:55.695953 22509476222784 run_lib.py:146] step: 683900, eval_loss: 2.94407e-02
I0212 20:56:14.438796 22509476222784 run_lib.py:133] step: 683950, training_loss: 4.05080e-02
I0212 20:56:33.053486 22509476222784 run_lib.py:133] step: 684000, training_loss: 4.61894e-02
I0212 20:56:33.217946 22509476222784 run_lib.py:146] step: 684000, eval_loss: 3.96610e-02
I0212 20:56:51.795492 22509476222784 run_lib.py:133] step: 684050, training_loss: 3.25966e-02
I0212 20:57:10.551205 22509476222784 run_lib.py:133] step: 684100, training_loss: 4.77414e-02
I0212 20:57:10.732254 22509476222784 run_lib.py:146] step: 684100, eval_loss: 4.78765e-02
I0212 20:57:29.302998 22509476222784 run_lib.py:133] step: 684150, training_loss: 5.09353e-02
I0212 20:57:47.878206 22509476222784 run_lib.py:133] step: 684200, training_loss: 3.75012e-02
I0212 20:57:48.192706 22509476222784 run_lib.py:146] step: 684200, eval_loss: 3.01328e-02
I0212 20:58:06.812112 22509476222784 run_lib.py:133] step: 684250, training_loss: 3.41362e-02
I0212 20:58:25.416799 22509476222784 run_lib.py:133] step: 684300, training_loss: 5.63802e-02
I0212 20:58:25.637396 22509476222784 run_lib.py:146] step: 684300, eval_loss: 3.98014e-02
I0212 20:58:44.191487 22509476222784 run_lib.py:133] step: 684350, training_loss: 4.61950e-02
I0212 20:59:02.754656 22509476222784 run_lib.py:133] step: 684400, training_loss: 5.14163e-02
I0212 20:59:02.946821 22509476222784 run_lib.py:146] step: 684400, eval_loss: 4.42069e-02
I0212 20:59:21.709264 22509476222784 run_lib.py:133] step: 684450, training_loss: 3.80351e-02
I0212 20:59:40.359551 22509476222784 run_lib.py:133] step: 684500, training_loss: 4.73721e-02
I0212 20:59:40.525219 22509476222784 run_lib.py:146] step: 684500, eval_loss: 4.38344e-02
I0212 20:59:59.105433 22509476222784 run_lib.py:133] step: 684550, training_loss: 4.16195e-02
I0212 21:00:17.583803 22509476222784 run_lib.py:133] step: 684600, training_loss: 5.94433e-02
I0212 21:00:17.746428 22509476222784 run_lib.py:146] step: 684600, eval_loss: 2.98736e-02
I0212 21:00:36.429064 22509476222784 run_lib.py:133] step: 684650, training_loss: 3.33366e-02
I0212 21:00:54.960133 22509476222784 run_lib.py:133] step: 684700, training_loss: 4.84984e-02
I0212 21:00:55.120722 22509476222784 run_lib.py:146] step: 684700, eval_loss: 4.43289e-02
I0212 21:01:13.701681 22509476222784 run_lib.py:133] step: 684750, training_loss: 4.15964e-02
I0212 21:01:32.283605 22509476222784 run_lib.py:133] step: 684800, training_loss: 4.50136e-02
I0212 21:01:32.454773 22509476222784 run_lib.py:146] step: 684800, eval_loss: 3.65827e-02
I0212 21:01:51.168272 22509476222784 run_lib.py:133] step: 684850, training_loss: 3.59029e-02
I0212 21:02:09.676722 22509476222784 run_lib.py:133] step: 684900, training_loss: 3.43364e-02
I0212 21:02:09.849657 22509476222784 run_lib.py:146] step: 684900, eval_loss: 4.47208e-02
I0212 21:02:28.544737 22509476222784 run_lib.py:133] step: 684950, training_loss: 4.10801e-02
I0212 21:02:47.134649 22509476222784 run_lib.py:133] step: 685000, training_loss: 3.50599e-02
I0212 21:02:47.308215 22509476222784 run_lib.py:146] step: 685000, eval_loss: 4.41079e-02
I0212 21:03:06.050145 22509476222784 run_lib.py:133] step: 685050, training_loss: 4.87470e-02
I0212 21:03:24.621866 22509476222784 run_lib.py:133] step: 685100, training_loss: 4.65211e-02
I0212 21:03:24.809871 22509476222784 run_lib.py:146] step: 685100, eval_loss: 3.79257e-02
I0212 21:03:43.376196 22509476222784 run_lib.py:133] step: 685150, training_loss: 4.90478e-02
I0212 21:04:02.068839 22509476222784 run_lib.py:133] step: 685200, training_loss: 5.01612e-02
I0212 21:04:02.256724 22509476222784 run_lib.py:146] step: 685200, eval_loss: 3.39693e-02
I0212 21:04:20.833246 22509476222784 run_lib.py:133] step: 685250, training_loss: 4.39332e-02
I0212 21:04:39.647946 22509476222784 run_lib.py:133] step: 685300, training_loss: 3.67094e-02
I0212 21:04:39.859597 22509476222784 run_lib.py:146] step: 685300, eval_loss: 4.83109e-02
I0212 21:04:58.388168 22509476222784 run_lib.py:133] step: 685350, training_loss: 3.71426e-02
I0212 21:05:16.941177 22509476222784 run_lib.py:133] step: 685400, training_loss: 4.29839e-02
I0212 21:05:17.128696 22509476222784 run_lib.py:146] step: 685400, eval_loss: 4.61749e-02
I0212 21:05:35.647858 22509476222784 run_lib.py:133] step: 685450, training_loss: 4.63758e-02
I0212 21:05:54.406490 22509476222784 run_lib.py:133] step: 685500, training_loss: 5.38534e-02
I0212 21:05:54.588925 22509476222784 run_lib.py:146] step: 685500, eval_loss: 3.78468e-02
I0212 21:06:13.215382 22509476222784 run_lib.py:133] step: 685550, training_loss: 2.97790e-02
I0212 21:06:31.692010 22509476222784 run_lib.py:133] step: 685600, training_loss: 3.95439e-02
I0212 21:06:31.853595 22509476222784 run_lib.py:146] step: 685600, eval_loss: 6.04207e-02
I0212 21:06:50.582813 22509476222784 run_lib.py:133] step: 685650, training_loss: 4.43486e-02
I0212 21:07:09.158380 22509476222784 run_lib.py:133] step: 685700, training_loss: 4.73935e-02
I0212 21:07:09.323668 22509476222784 run_lib.py:146] step: 685700, eval_loss: 4.53729e-02
I0212 21:07:27.927710 22509476222784 run_lib.py:133] step: 685750, training_loss: 4.18893e-02
I0212 21:07:46.510566 22509476222784 run_lib.py:133] step: 685800, training_loss: 5.21505e-02
I0212 21:07:46.691691 22509476222784 run_lib.py:146] step: 685800, eval_loss: 4.77208e-02
I0212 21:08:05.258471 22509476222784 run_lib.py:133] step: 685850, training_loss: 5.19068e-02
I0212 21:08:23.794392 22509476222784 run_lib.py:133] step: 685900, training_loss: 3.29596e-02
I0212 21:08:23.956400 22509476222784 run_lib.py:146] step: 685900, eval_loss: 2.63491e-02
I0212 21:08:42.693075 22509476222784 run_lib.py:133] step: 685950, training_loss: 3.67380e-02
I0212 21:09:01.276651 22509476222784 run_lib.py:133] step: 686000, training_loss: 5.97045e-02
I0212 21:09:01.440751 22509476222784 run_lib.py:146] step: 686000, eval_loss: 4.18617e-02
I0212 21:09:19.968841 22509476222784 run_lib.py:133] step: 686050, training_loss: 3.62754e-02
I0212 21:09:38.483815 22509476222784 run_lib.py:133] step: 686100, training_loss: 4.00528e-02
I0212 21:09:38.650929 22509476222784 run_lib.py:146] step: 686100, eval_loss: 3.69983e-02
I0212 21:09:57.358049 22509476222784 run_lib.py:133] step: 686150, training_loss: 4.99771e-02
I0212 21:10:15.943539 22509476222784 run_lib.py:133] step: 686200, training_loss: 4.87195e-02
I0212 21:10:16.110992 22509476222784 run_lib.py:146] step: 686200, eval_loss: 5.16694e-02
I0212 21:10:34.680548 22509476222784 run_lib.py:133] step: 686250, training_loss: 3.81282e-02
I0212 21:10:53.269503 22509476222784 run_lib.py:133] step: 686300, training_loss: 3.76522e-02
I0212 21:10:53.438766 22509476222784 run_lib.py:146] step: 686300, eval_loss: 4.12652e-02
I0212 21:11:12.143931 22509476222784 run_lib.py:133] step: 686350, training_loss: 5.06038e-02
I0212 21:11:30.725388 22509476222784 run_lib.py:133] step: 686400, training_loss: 4.77157e-02
I0212 21:11:30.943506 22509476222784 run_lib.py:146] step: 686400, eval_loss: 3.23891e-02
I0212 21:11:49.671773 22509476222784 run_lib.py:133] step: 686450, training_loss: 3.56219e-02
I0212 21:12:08.214265 22509476222784 run_lib.py:133] step: 686500, training_loss: 4.21164e-02
I0212 21:12:08.376515 22509476222784 run_lib.py:146] step: 686500, eval_loss: 5.28262e-02
I0212 21:12:26.949558 22509476222784 run_lib.py:133] step: 686550, training_loss: 3.64603e-02
I0212 21:12:45.738717 22509476222784 run_lib.py:133] step: 686600, training_loss: 4.42697e-02
I0212 21:12:45.907047 22509476222784 run_lib.py:146] step: 686600, eval_loss: 3.49175e-02
I0212 21:13:04.518484 22509476222784 run_lib.py:133] step: 686650, training_loss: 4.86715e-02
I0212 21:13:23.171764 22509476222784 run_lib.py:133] step: 686700, training_loss: 4.53568e-02
I0212 21:13:23.347334 22509476222784 run_lib.py:146] step: 686700, eval_loss: 4.14581e-02
I0212 21:13:42.050489 22509476222784 run_lib.py:133] step: 686750, training_loss: 4.07272e-02
I0212 21:14:00.759797 22509476222784 run_lib.py:133] step: 686800, training_loss: 5.13282e-02
I0212 21:14:00.933723 22509476222784 run_lib.py:146] step: 686800, eval_loss: 4.77396e-02
I0212 21:14:19.492090 22509476222784 run_lib.py:133] step: 686850, training_loss: 5.11488e-02
I0212 21:14:38.106015 22509476222784 run_lib.py:133] step: 686900, training_loss: 3.33715e-02
I0212 21:14:38.289506 22509476222784 run_lib.py:146] step: 686900, eval_loss: 3.92361e-02
I0212 21:14:56.822887 22509476222784 run_lib.py:133] step: 686950, training_loss: 4.58579e-02
I0212 21:15:15.573544 22509476222784 run_lib.py:133] step: 687000, training_loss: 4.37083e-02
I0212 21:15:15.763947 22509476222784 run_lib.py:146] step: 687000, eval_loss: 4.44755e-02
I0212 21:15:34.295581 22509476222784 run_lib.py:133] step: 687050, training_loss: 4.25218e-02
I0212 21:15:52.842352 22509476222784 run_lib.py:133] step: 687100, training_loss: 4.41804e-02
I0212 21:15:53.033937 22509476222784 run_lib.py:146] step: 687100, eval_loss: 3.95755e-02
I0212 21:16:11.683168 22509476222784 run_lib.py:133] step: 687150, training_loss: 3.85972e-02
I0212 21:16:30.440449 22509476222784 run_lib.py:133] step: 687200, training_loss: 5.17958e-02
I0212 21:16:30.606729 22509476222784 run_lib.py:146] step: 687200, eval_loss: 5.17305e-02
I0212 21:16:49.146002 22509476222784 run_lib.py:133] step: 687250, training_loss: 3.82954e-02
I0212 21:17:07.810402 22509476222784 run_lib.py:133] step: 687300, training_loss: 5.14859e-02
I0212 21:17:07.974705 22509476222784 run_lib.py:146] step: 687300, eval_loss: 4.76503e-02
I0212 21:17:26.506121 22509476222784 run_lib.py:133] step: 687350, training_loss: 3.58972e-02
I0212 21:17:45.070075 22509476222784 run_lib.py:133] step: 687400, training_loss: 3.60256e-02
I0212 21:17:45.238844 22509476222784 run_lib.py:146] step: 687400, eval_loss: 4.91444e-02
I0212 21:18:04.029147 22509476222784 run_lib.py:133] step: 687450, training_loss: 4.44200e-02
I0212 21:18:22.710490 22509476222784 run_lib.py:133] step: 687500, training_loss: 5.64211e-02
I0212 21:18:22.901671 22509476222784 run_lib.py:146] step: 687500, eval_loss: 4.63061e-02
I0212 21:18:41.463439 22509476222784 run_lib.py:133] step: 687550, training_loss: 4.23932e-02
I0212 21:19:00.017523 22509476222784 run_lib.py:133] step: 687600, training_loss: 3.92629e-02
I0212 21:19:00.189794 22509476222784 run_lib.py:146] step: 687600, eval_loss: 3.94464e-02
I0212 21:19:18.895179 22509476222784 run_lib.py:133] step: 687650, training_loss: 3.69040e-02
I0212 21:19:37.545557 22509476222784 run_lib.py:133] step: 687700, training_loss: 2.89687e-02
I0212 21:19:37.709960 22509476222784 run_lib.py:146] step: 687700, eval_loss: 3.78048e-02
I0212 21:19:56.407325 22509476222784 run_lib.py:133] step: 687750, training_loss: 3.66085e-02
I0212 21:20:14.967520 22509476222784 run_lib.py:133] step: 687800, training_loss: 5.79621e-02
I0212 21:20:15.161773 22509476222784 run_lib.py:146] step: 687800, eval_loss: 4.71150e-02
I0212 21:20:33.901983 22509476222784 run_lib.py:133] step: 687850, training_loss: 4.00372e-02
I0212 21:20:52.512794 22509476222784 run_lib.py:133] step: 687900, training_loss: 3.50346e-02
I0212 21:20:52.712882 22509476222784 run_lib.py:146] step: 687900, eval_loss: 4.12123e-02
I0212 21:21:11.356217 22509476222784 run_lib.py:133] step: 687950, training_loss: 3.83367e-02
I0212 21:21:30.076672 22509476222784 run_lib.py:133] step: 688000, training_loss: 3.44982e-02
I0212 21:21:30.245455 22509476222784 run_lib.py:146] step: 688000, eval_loss: 4.80155e-02
I0212 21:21:48.813066 22509476222784 run_lib.py:133] step: 688050, training_loss: 4.52021e-02
I0212 21:22:07.545997 22509476222784 run_lib.py:133] step: 688100, training_loss: 5.47644e-02
I0212 21:22:07.731113 22509476222784 run_lib.py:146] step: 688100, eval_loss: 3.92195e-02
I0212 21:22:26.351624 22509476222784 run_lib.py:133] step: 688150, training_loss: 3.91370e-02
I0212 21:22:45.015042 22509476222784 run_lib.py:133] step: 688200, training_loss: 4.63291e-02
I0212 21:22:45.183961 22509476222784 run_lib.py:146] step: 688200, eval_loss: 4.35201e-02
I0212 21:23:03.965476 22509476222784 run_lib.py:133] step: 688250, training_loss: 4.68700e-02
I0212 21:23:22.538112 22509476222784 run_lib.py:133] step: 688300, training_loss: 4.46558e-02
I0212 21:23:22.702836 22509476222784 run_lib.py:146] step: 688300, eval_loss: 2.77286e-02
I0212 21:23:41.215910 22509476222784 run_lib.py:133] step: 688350, training_loss: 3.06279e-02
I0212 21:23:59.884559 22509476222784 run_lib.py:133] step: 688400, training_loss: 4.84825e-02
I0212 21:24:00.074006 22509476222784 run_lib.py:146] step: 688400, eval_loss: 3.75683e-02
I0212 21:24:18.646212 22509476222784 run_lib.py:133] step: 688450, training_loss: 3.61758e-02
I0212 21:24:37.223130 22509476222784 run_lib.py:133] step: 688500, training_loss: 4.53046e-02
I0212 21:24:37.412007 22509476222784 run_lib.py:146] step: 688500, eval_loss: 3.98141e-02
I0212 21:24:56.062893 22509476222784 run_lib.py:133] step: 688550, training_loss: 3.27844e-02
I0212 21:25:14.621122 22509476222784 run_lib.py:133] step: 688600, training_loss: 4.80485e-02
I0212 21:25:14.816995 22509476222784 run_lib.py:146] step: 688600, eval_loss: 4.11020e-02
I0212 21:25:33.315958 22509476222784 run_lib.py:133] step: 688650, training_loss: 4.30991e-02
I0212 21:25:51.864349 22509476222784 run_lib.py:133] step: 688700, training_loss: 3.79625e-02
I0212 21:25:52.077670 22509476222784 run_lib.py:146] step: 688700, eval_loss: 4.21779e-02
I0212 21:26:10.795047 22509476222784 run_lib.py:133] step: 688750, training_loss: 3.59148e-02
I0212 21:26:29.515004 22509476222784 run_lib.py:133] step: 688800, training_loss: 4.78751e-02
I0212 21:26:29.684954 22509476222784 run_lib.py:146] step: 688800, eval_loss: 3.97504e-02
I0212 21:26:48.319439 22509476222784 run_lib.py:133] step: 688850, training_loss: 5.09856e-02
I0212 21:27:06.844248 22509476222784 run_lib.py:133] step: 688900, training_loss: 4.22649e-02
I0212 21:27:07.005688 22509476222784 run_lib.py:146] step: 688900, eval_loss: 4.17368e-02
I0212 21:27:25.682227 22509476222784 run_lib.py:133] step: 688950, training_loss: 4.47682e-02
I0212 21:27:44.189229 22509476222784 run_lib.py:133] step: 689000, training_loss: 3.87299e-02
I0212 21:27:44.361940 22509476222784 run_lib.py:146] step: 689000, eval_loss: 3.80991e-02
I0212 21:28:03.078046 22509476222784 run_lib.py:133] step: 689050, training_loss: 4.76911e-02
I0212 21:28:21.636305 22509476222784 run_lib.py:133] step: 689100, training_loss: 4.95148e-02
I0212 21:28:21.826920 22509476222784 run_lib.py:146] step: 689100, eval_loss: 4.96599e-02
I0212 21:28:40.530928 22509476222784 run_lib.py:133] step: 689150, training_loss: 4.32087e-02
I0212 21:28:59.060473 22509476222784 run_lib.py:133] step: 689200, training_loss: 3.47163e-02
I0212 21:28:59.224936 22509476222784 run_lib.py:146] step: 689200, eval_loss: 5.07547e-02
I0212 21:29:17.895726 22509476222784 run_lib.py:133] step: 689250, training_loss: 4.60012e-02
I0212 21:29:36.515429 22509476222784 run_lib.py:133] step: 689300, training_loss: 4.37054e-02
I0212 21:29:36.687758 22509476222784 run_lib.py:146] step: 689300, eval_loss: 4.54758e-02
I0212 21:29:55.229864 22509476222784 run_lib.py:133] step: 689350, training_loss: 3.58298e-02
I0212 21:30:13.869734 22509476222784 run_lib.py:133] step: 689400, training_loss: 4.36632e-02
I0212 21:30:14.030602 22509476222784 run_lib.py:146] step: 689400, eval_loss: 4.98610e-02
I0212 21:30:32.556954 22509476222784 run_lib.py:133] step: 689450, training_loss: 3.42960e-02
I0212 21:30:51.105543 22509476222784 run_lib.py:133] step: 689500, training_loss: 3.96399e-02
I0212 21:30:51.269474 22509476222784 run_lib.py:146] step: 689500, eval_loss: 6.09624e-02
I0212 21:31:10.026656 22509476222784 run_lib.py:133] step: 689550, training_loss: 3.70049e-02
I0212 21:31:28.632144 22509476222784 run_lib.py:133] step: 689600, training_loss: 4.25858e-02
I0212 21:31:28.812736 22509476222784 run_lib.py:146] step: 689600, eval_loss: 4.42432e-02
I0212 21:31:47.541664 22509476222784 run_lib.py:133] step: 689650, training_loss: 4.20325e-02
I0212 21:32:06.076815 22509476222784 run_lib.py:133] step: 689700, training_loss: 4.72955e-02
I0212 21:32:06.246969 22509476222784 run_lib.py:146] step: 689700, eval_loss: 4.07222e-02
I0212 21:32:24.778270 22509476222784 run_lib.py:133] step: 689750, training_loss: 4.77344e-02
I0212 21:32:43.456084 22509476222784 run_lib.py:133] step: 689800, training_loss: 3.48091e-02
I0212 21:32:43.623921 22509476222784 run_lib.py:146] step: 689800, eval_loss: 4.25177e-02
I0212 21:33:02.259989 22509476222784 run_lib.py:133] step: 689850, training_loss: 4.63615e-02
I0212 21:33:20.816659 22509476222784 run_lib.py:133] step: 689900, training_loss: 4.97293e-02
I0212 21:33:20.978847 22509476222784 run_lib.py:146] step: 689900, eval_loss: 4.84479e-02
I0212 21:33:39.505401 22509476222784 run_lib.py:133] step: 689950, training_loss: 4.61064e-02
I0212 21:33:58.263984 22509476222784 run_lib.py:133] step: 690000, training_loss: 3.17219e-02
I0212 21:33:59.105792 22509476222784 run_lib.py:146] step: 690000, eval_loss: 3.41727e-02
I0212 21:34:20.465489 22509476222784 run_lib.py:133] step: 690050, training_loss: 3.66014e-02
I0212 21:34:39.212423 22509476222784 run_lib.py:133] step: 690100, training_loss: 4.79532e-02
I0212 21:34:39.413723 22509476222784 run_lib.py:146] step: 690100, eval_loss: 4.61476e-02
I0212 21:34:57.958687 22509476222784 run_lib.py:133] step: 690150, training_loss: 3.80604e-02
I0212 21:35:16.556290 22509476222784 run_lib.py:133] step: 690200, training_loss: 3.81435e-02
I0212 21:35:16.720967 22509476222784 run_lib.py:146] step: 690200, eval_loss: 4.25670e-02
I0212 21:35:35.277570 22509476222784 run_lib.py:133] step: 690250, training_loss: 3.78840e-02
I0212 21:35:54.030639 22509476222784 run_lib.py:133] step: 690300, training_loss: 4.36738e-02
I0212 21:35:54.212727 22509476222784 run_lib.py:146] step: 690300, eval_loss: 4.49784e-02
I0212 21:36:12.826269 22509476222784 run_lib.py:133] step: 690350, training_loss: 5.09769e-02
I0212 21:36:31.426090 22509476222784 run_lib.py:133] step: 690400, training_loss: 4.66533e-02
I0212 21:36:31.630670 22509476222784 run_lib.py:146] step: 690400, eval_loss: 4.54955e-02
I0212 21:36:50.192746 22509476222784 run_lib.py:133] step: 690450, training_loss: 3.29931e-02
I0212 21:37:08.724101 22509476222784 run_lib.py:133] step: 690500, training_loss: 4.15678e-02
I0212 21:37:08.950745 22509476222784 run_lib.py:146] step: 690500, eval_loss: 4.03252e-02
I0212 21:37:27.632163 22509476222784 run_lib.py:133] step: 690550, training_loss: 5.07032e-02
I0212 21:37:46.250281 22509476222784 run_lib.py:133] step: 690600, training_loss: 3.63515e-02
I0212 21:37:46.431630 22509476222784 run_lib.py:146] step: 690600, eval_loss: 5.08970e-02
I0212 21:38:05.006712 22509476222784 run_lib.py:133] step: 690650, training_loss: 4.49143e-02
I0212 21:38:23.582596 22509476222784 run_lib.py:133] step: 690700, training_loss: 5.33979e-02
I0212 21:38:23.744691 22509476222784 run_lib.py:146] step: 690700, eval_loss: 4.24516e-02
I0212 21:38:42.514771 22509476222784 run_lib.py:133] step: 690750, training_loss: 5.38154e-02
I0212 21:39:01.111467 22509476222784 run_lib.py:133] step: 690800, training_loss: 4.49383e-02
I0212 21:39:01.275712 22509476222784 run_lib.py:146] step: 690800, eval_loss: 4.23952e-02
I0212 21:39:19.980051 22509476222784 run_lib.py:133] step: 690850, training_loss: 4.70456e-02
I0212 21:39:38.596216 22509476222784 run_lib.py:133] step: 690900, training_loss: 2.89556e-02
I0212 21:39:38.786904 22509476222784 run_lib.py:146] step: 690900, eval_loss: 4.12232e-02
I0212 21:39:57.610011 22509476222784 run_lib.py:133] step: 690950, training_loss: 3.70337e-02
I0212 21:40:16.187350 22509476222784 run_lib.py:133] step: 691000, training_loss: 4.11728e-02
I0212 21:40:16.379800 22509476222784 run_lib.py:146] step: 691000, eval_loss: 4.14225e-02
I0212 21:40:34.910492 22509476222784 run_lib.py:133] step: 691050, training_loss: 3.54662e-02
I0212 21:40:53.639147 22509476222784 run_lib.py:133] step: 691100, training_loss: 3.53785e-02
I0212 21:40:53.843686 22509476222784 run_lib.py:146] step: 691100, eval_loss: 4.41197e-02
I0212 21:41:12.452384 22509476222784 run_lib.py:133] step: 691150, training_loss: 4.54866e-02
I0212 21:41:31.248305 22509476222784 run_lib.py:133] step: 691200, training_loss: 5.20610e-02
I0212 21:41:31.435918 22509476222784 run_lib.py:146] step: 691200, eval_loss: 3.67049e-02
I0212 21:41:50.022679 22509476222784 run_lib.py:133] step: 691250, training_loss: 4.77215e-02
I0212 21:42:08.507144 22509476222784 run_lib.py:133] step: 691300, training_loss: 4.83952e-02
I0212 21:42:08.670730 22509476222784 run_lib.py:146] step: 691300, eval_loss: 3.77050e-02
I0212 21:42:27.336683 22509476222784 run_lib.py:133] step: 691350, training_loss: 5.12772e-02
I0212 21:42:45.944848 22509476222784 run_lib.py:133] step: 691400, training_loss: 4.99106e-02
I0212 21:42:46.132984 22509476222784 run_lib.py:146] step: 691400, eval_loss: 3.84104e-02
I0212 21:43:04.667622 22509476222784 run_lib.py:133] step: 691450, training_loss: 4.16938e-02
I0212 21:43:23.341669 22509476222784 run_lib.py:133] step: 691500, training_loss: 3.99711e-02
I0212 21:43:23.509015 22509476222784 run_lib.py:146] step: 691500, eval_loss: 4.23922e-02
I0212 21:43:42.052124 22509476222784 run_lib.py:133] step: 691550, training_loss: 4.46973e-02
I0212 21:44:00.584593 22509476222784 run_lib.py:133] step: 691600, training_loss: 4.00005e-02
I0212 21:44:00.931609 22509476222784 run_lib.py:146] step: 691600, eval_loss: 4.18878e-02
I0212 21:44:19.522873 22509476222784 run_lib.py:133] step: 691650, training_loss: 4.33293e-02
I0212 21:44:38.121707 22509476222784 run_lib.py:133] step: 691700, training_loss: 3.41168e-02
I0212 21:44:38.286992 22509476222784 run_lib.py:146] step: 691700, eval_loss: 3.69248e-02
I0212 21:44:56.894642 22509476222784 run_lib.py:133] step: 691750, training_loss: 4.39617e-02
I0212 21:45:15.418504 22509476222784 run_lib.py:133] step: 691800, training_loss: 5.95295e-02
I0212 21:45:15.579880 22509476222784 run_lib.py:146] step: 691800, eval_loss: 3.43349e-02
I0212 21:45:34.341988 22509476222784 run_lib.py:133] step: 691850, training_loss: 5.62132e-02
I0212 21:45:52.981359 22509476222784 run_lib.py:133] step: 691900, training_loss: 4.66028e-02
I0212 21:45:53.174995 22509476222784 run_lib.py:146] step: 691900, eval_loss: 3.13507e-02
I0212 21:46:11.717493 22509476222784 run_lib.py:133] step: 691950, training_loss: 4.91420e-02
I0212 21:46:30.198312 22509476222784 run_lib.py:133] step: 692000, training_loss: 4.47763e-02
I0212 21:46:30.363915 22509476222784 run_lib.py:146] step: 692000, eval_loss: 4.93241e-02
I0212 21:46:49.081354 22509476222784 run_lib.py:133] step: 692050, training_loss: 3.71115e-02
I0212 21:47:07.765058 22509476222784 run_lib.py:133] step: 692100, training_loss: 3.32917e-02
I0212 21:47:07.929781 22509476222784 run_lib.py:146] step: 692100, eval_loss: 4.69956e-02
I0212 21:47:26.539873 22509476222784 run_lib.py:133] step: 692150, training_loss: 3.21751e-02
I0212 21:47:45.187528 22509476222784 run_lib.py:133] step: 692200, training_loss: 4.85687e-02
I0212 21:47:45.352970 22509476222784 run_lib.py:146] step: 692200, eval_loss: 4.42209e-02
I0212 21:48:04.120594 22509476222784 run_lib.py:133] step: 692250, training_loss: 4.09197e-02
I0212 21:48:22.656602 22509476222784 run_lib.py:133] step: 692300, training_loss: 5.45882e-02
I0212 21:48:22.818820 22509476222784 run_lib.py:146] step: 692300, eval_loss: 4.10421e-02
I0212 21:48:41.487219 22509476222784 run_lib.py:133] step: 692350, training_loss: 4.06291e-02
I0212 21:49:00.048691 22509476222784 run_lib.py:133] step: 692400, training_loss: 3.46284e-02
I0212 21:49:00.247426 22509476222784 run_lib.py:146] step: 692400, eval_loss: 3.95629e-02
I0212 21:49:18.932750 22509476222784 run_lib.py:133] step: 692450, training_loss: 4.84237e-02
I0212 21:49:37.558166 22509476222784 run_lib.py:133] step: 692500, training_loss: 3.39471e-02
I0212 21:49:37.734584 22509476222784 run_lib.py:146] step: 692500, eval_loss: 3.72380e-02
I0212 21:49:56.297331 22509476222784 run_lib.py:133] step: 692550, training_loss: 3.10471e-02
I0212 21:50:15.006483 22509476222784 run_lib.py:133] step: 692600, training_loss: 4.26506e-02
I0212 21:50:15.167988 22509476222784 run_lib.py:146] step: 692600, eval_loss: 4.45770e-02
I0212 21:50:33.724971 22509476222784 run_lib.py:133] step: 692650, training_loss: 5.16715e-02
I0212 21:50:52.457928 22509476222784 run_lib.py:133] step: 692700, training_loss: 4.39058e-02
I0212 21:50:52.623971 22509476222784 run_lib.py:146] step: 692700, eval_loss: 3.89676e-02
I0212 21:51:11.263843 22509476222784 run_lib.py:133] step: 692750, training_loss: 3.92007e-02
I0212 21:51:29.805330 22509476222784 run_lib.py:133] step: 692800, training_loss: 4.40240e-02
I0212 21:51:29.974598 22509476222784 run_lib.py:146] step: 692800, eval_loss: 4.97878e-02
I0212 21:51:48.505016 22509476222784 run_lib.py:133] step: 692850, training_loss: 4.61309e-02
I0212 21:52:07.227544 22509476222784 run_lib.py:133] step: 692900, training_loss: 4.58816e-02
I0212 21:52:07.410044 22509476222784 run_lib.py:146] step: 692900, eval_loss: 3.19932e-02
I0212 21:52:25.998950 22509476222784 run_lib.py:133] step: 692950, training_loss: 4.02577e-02
I0212 21:52:44.612502 22509476222784 run_lib.py:133] step: 693000, training_loss: 4.43722e-02
I0212 21:52:44.777713 22509476222784 run_lib.py:146] step: 693000, eval_loss: 4.14688e-02
I0212 21:53:03.501822 22509476222784 run_lib.py:133] step: 693050, training_loss: 4.35623e-02
I0212 21:53:22.029911 22509476222784 run_lib.py:133] step: 693100, training_loss: 3.89335e-02
I0212 21:53:22.206502 22509476222784 run_lib.py:146] step: 693100, eval_loss: 5.18775e-02
I0212 21:53:40.871027 22509476222784 run_lib.py:133] step: 693150, training_loss: 4.40070e-02
I0212 21:53:59.401589 22509476222784 run_lib.py:133] step: 693200, training_loss: 4.51868e-02
I0212 21:53:59.568817 22509476222784 run_lib.py:146] step: 693200, eval_loss: 5.35550e-02
I0212 21:54:18.157573 22509476222784 run_lib.py:133] step: 693250, training_loss: 3.19779e-02
I0212 21:54:36.695071 22509476222784 run_lib.py:133] step: 693300, training_loss: 4.17077e-02
I0212 21:54:36.859995 22509476222784 run_lib.py:146] step: 693300, eval_loss: 4.02074e-02
I0212 21:54:55.582198 22509476222784 run_lib.py:133] step: 693350, training_loss: 5.49962e-02
I0212 21:55:14.225467 22509476222784 run_lib.py:133] step: 693400, training_loss: 3.77455e-02
I0212 21:55:14.393979 22509476222784 run_lib.py:146] step: 693400, eval_loss: 3.55331e-02
I0212 21:55:32.887869 22509476222784 run_lib.py:133] step: 693450, training_loss: 4.23917e-02
I0212 21:55:51.393782 22509476222784 run_lib.py:133] step: 693500, training_loss: 3.98858e-02
I0212 21:55:51.574720 22509476222784 run_lib.py:146] step: 693500, eval_loss: 4.86018e-02
I0212 21:56:10.251310 22509476222784 run_lib.py:133] step: 693550, training_loss: 3.46410e-02
I0212 21:56:28.819471 22509476222784 run_lib.py:133] step: 693600, training_loss: 4.22654e-02
I0212 21:56:28.992005 22509476222784 run_lib.py:146] step: 693600, eval_loss: 3.07321e-02
I0212 21:56:47.738873 22509476222784 run_lib.py:133] step: 693650, training_loss: 3.39218e-02
I0212 21:57:06.301304 22509476222784 run_lib.py:133] step: 693700, training_loss: 5.30810e-02
I0212 21:57:06.461665 22509476222784 run_lib.py:146] step: 693700, eval_loss: 4.40187e-02
I0212 21:57:25.166433 22509476222784 run_lib.py:133] step: 693750, training_loss: 5.12811e-02
I0212 21:57:43.736222 22509476222784 run_lib.py:133] step: 693800, training_loss: 4.35364e-02
I0212 21:57:43.906732 22509476222784 run_lib.py:146] step: 693800, eval_loss: 4.81661e-02
I0212 21:58:02.632622 22509476222784 run_lib.py:133] step: 693850, training_loss: 3.44364e-02
I0212 21:58:21.241226 22509476222784 run_lib.py:133] step: 693900, training_loss: 3.78491e-02
I0212 21:58:21.460890 22509476222784 run_lib.py:146] step: 693900, eval_loss: 3.37542e-02
I0212 21:58:39.998748 22509476222784 run_lib.py:133] step: 693950, training_loss: 3.93318e-02
I0212 21:58:58.713422 22509476222784 run_lib.py:133] step: 694000, training_loss: 4.93127e-02
I0212 21:58:58.918696 22509476222784 run_lib.py:146] step: 694000, eval_loss: 4.02828e-02
I0212 21:59:17.511261 22509476222784 run_lib.py:133] step: 694050, training_loss: 4.52434e-02
I0212 21:59:36.131881 22509476222784 run_lib.py:133] step: 694100, training_loss: 3.88410e-02
I0212 21:59:36.326308 22509476222784 run_lib.py:146] step: 694100, eval_loss: 4.30166e-02
I0212 21:59:55.100850 22509476222784 run_lib.py:133] step: 694150, training_loss: 3.81158e-02
I0212 22:00:13.788378 22509476222784 run_lib.py:133] step: 694200, training_loss: 4.39904e-02
I0212 22:00:13.995171 22509476222784 run_lib.py:146] step: 694200, eval_loss: 3.86072e-02
I0212 22:00:32.555785 22509476222784 run_lib.py:133] step: 694250, training_loss: 4.68939e-02
I0212 22:00:51.088132 22509476222784 run_lib.py:133] step: 694300, training_loss: 5.35423e-02
I0212 22:00:51.261816 22509476222784 run_lib.py:146] step: 694300, eval_loss: 3.88556e-02
I0212 22:01:09.845083 22509476222784 run_lib.py:133] step: 694350, training_loss: 3.47436e-02
I0212 22:01:28.596007 22509476222784 run_lib.py:133] step: 694400, training_loss: 3.71515e-02
I0212 22:01:28.762649 22509476222784 run_lib.py:146] step: 694400, eval_loss: 4.53709e-02
I0212 22:01:47.295303 22509476222784 run_lib.py:133] step: 694450, training_loss: 5.02826e-02
I0212 22:02:05.779503 22509476222784 run_lib.py:133] step: 694500, training_loss: 3.82773e-02
I0212 22:02:05.943671 22509476222784 run_lib.py:146] step: 694500, eval_loss: 3.83750e-02
I0212 22:02:24.430548 22509476222784 run_lib.py:133] step: 694550, training_loss: 4.61209e-02
I0212 22:02:43.129292 22509476222784 run_lib.py:133] step: 694600, training_loss: 3.92408e-02
I0212 22:02:43.293996 22509476222784 run_lib.py:146] step: 694600, eval_loss: 3.59997e-02
I0212 22:03:01.957867 22509476222784 run_lib.py:133] step: 694650, training_loss: 4.29827e-02
I0212 22:03:20.605792 22509476222784 run_lib.py:133] step: 694700, training_loss: 3.89690e-02
I0212 22:03:20.767362 22509476222784 run_lib.py:146] step: 694700, eval_loss: 3.66118e-02
I0212 22:03:39.304792 22509476222784 run_lib.py:133] step: 694750, training_loss: 4.10977e-02
I0212 22:03:57.801929 22509476222784 run_lib.py:133] step: 694800, training_loss: 4.47582e-02
I0212 22:03:57.968861 22509476222784 run_lib.py:146] step: 694800, eval_loss: 3.57663e-02
I0212 22:04:16.682171 22509476222784 run_lib.py:133] step: 694850, training_loss: 4.48641e-02
I0212 22:04:35.445568 22509476222784 run_lib.py:133] step: 694900, training_loss: 4.39979e-02
I0212 22:04:35.610771 22509476222784 run_lib.py:146] step: 694900, eval_loss: 3.59637e-02
I0212 22:04:54.152822 22509476222784 run_lib.py:133] step: 694950, training_loss: 4.15680e-02
I0212 22:05:12.648153 22509476222784 run_lib.py:133] step: 695000, training_loss: 4.21885e-02
I0212 22:05:12.814112 22509476222784 run_lib.py:146] step: 695000, eval_loss: 4.80604e-02
I0212 22:05:31.492517 22509476222784 run_lib.py:133] step: 695050, training_loss: 3.93366e-02
I0212 22:05:50.070211 22509476222784 run_lib.py:133] step: 695100, training_loss: 3.59935e-02
I0212 22:05:50.234829 22509476222784 run_lib.py:146] step: 695100, eval_loss: 5.26781e-02
I0212 22:06:08.995829 22509476222784 run_lib.py:133] step: 695150, training_loss: 4.24653e-02
I0212 22:06:27.757923 22509476222784 run_lib.py:133] step: 695200, training_loss: 3.11482e-02
I0212 22:06:27.924969 22509476222784 run_lib.py:146] step: 695200, eval_loss: 4.25656e-02
I0212 22:06:46.634070 22509476222784 run_lib.py:133] step: 695250, training_loss: 5.32588e-02
I0212 22:07:05.238558 22509476222784 run_lib.py:133] step: 695300, training_loss: 4.65878e-02
I0212 22:07:05.404869 22509476222784 run_lib.py:146] step: 695300, eval_loss: 5.69013e-02
I0212 22:07:23.894867 22509476222784 run_lib.py:133] step: 695350, training_loss: 5.04523e-02
I0212 22:07:42.676736 22509476222784 run_lib.py:133] step: 695400, training_loss: 5.05035e-02
I0212 22:07:42.879861 22509476222784 run_lib.py:146] step: 695400, eval_loss: 4.73836e-02
I0212 22:08:01.436231 22509476222784 run_lib.py:133] step: 695450, training_loss: 3.81225e-02
I0212 22:08:20.153614 22509476222784 run_lib.py:133] step: 695500, training_loss: 4.01983e-02
I0212 22:08:20.317833 22509476222784 run_lib.py:146] step: 695500, eval_loss: 2.98470e-02
I0212 22:08:38.882893 22509476222784 run_lib.py:133] step: 695550, training_loss: 3.56277e-02
I0212 22:08:57.412894 22509476222784 run_lib.py:133] step: 695600, training_loss: 4.74623e-02
I0212 22:08:57.573305 22509476222784 run_lib.py:146] step: 695600, eval_loss: 3.75145e-02
I0212 22:09:16.308712 22509476222784 run_lib.py:133] step: 695650, training_loss: 5.23992e-02
I0212 22:09:34.863987 22509476222784 run_lib.py:133] step: 695700, training_loss: 3.51002e-02
I0212 22:09:35.030319 22509476222784 run_lib.py:146] step: 695700, eval_loss: 6.38099e-02
I0212 22:09:53.545846 22509476222784 run_lib.py:133] step: 695750, training_loss: 4.52356e-02
I0212 22:10:12.268911 22509476222784 run_lib.py:133] step: 695800, training_loss: 3.98048e-02
I0212 22:10:12.442671 22509476222784 run_lib.py:146] step: 695800, eval_loss: 4.12089e-02
I0212 22:10:30.974278 22509476222784 run_lib.py:133] step: 695850, training_loss: 2.90994e-02
I0212 22:10:49.570698 22509476222784 run_lib.py:133] step: 695900, training_loss: 3.69105e-02
I0212 22:10:49.756825 22509476222784 run_lib.py:146] step: 695900, eval_loss: 3.14327e-02
I0212 22:11:08.364065 22509476222784 run_lib.py:133] step: 695950, training_loss: 4.69374e-02
I0212 22:11:26.922385 22509476222784 run_lib.py:133] step: 696000, training_loss: 3.41385e-02
I0212 22:11:27.085774 22509476222784 run_lib.py:146] step: 696000, eval_loss: 3.85880e-02
I0212 22:11:45.652457 22509476222784 run_lib.py:133] step: 696050, training_loss: 4.82901e-02
I0212 22:12:04.192006 22509476222784 run_lib.py:133] step: 696100, training_loss: 3.75681e-02
I0212 22:12:04.354769 22509476222784 run_lib.py:146] step: 696100, eval_loss: 4.39334e-02
I0212 22:12:23.139238 22509476222784 run_lib.py:133] step: 696150, training_loss: 4.16560e-02
I0212 22:12:41.869228 22509476222784 run_lib.py:133] step: 696200, training_loss: 4.82216e-02
I0212 22:12:42.034951 22509476222784 run_lib.py:146] step: 696200, eval_loss: 4.05594e-02
I0212 22:13:00.616596 22509476222784 run_lib.py:133] step: 696250, training_loss: 3.42707e-02
I0212 22:13:19.104943 22509476222784 run_lib.py:133] step: 696300, training_loss: 4.69837e-02
I0212 22:13:19.270811 22509476222784 run_lib.py:146] step: 696300, eval_loss: 3.59263e-02
I0212 22:13:37.908940 22509476222784 run_lib.py:133] step: 696350, training_loss: 3.57707e-02
I0212 22:13:56.407810 22509476222784 run_lib.py:133] step: 696400, training_loss: 3.35886e-02
I0212 22:13:56.578669 22509476222784 run_lib.py:146] step: 696400, eval_loss: 5.24553e-02
I0212 22:14:15.351179 22509476222784 run_lib.py:133] step: 696450, training_loss: 3.93072e-02
I0212 22:14:33.928894 22509476222784 run_lib.py:133] step: 696500, training_loss: 3.72030e-02
I0212 22:14:34.096853 22509476222784 run_lib.py:146] step: 696500, eval_loss: 3.92463e-02
I0212 22:14:52.833550 22509476222784 run_lib.py:133] step: 696550, training_loss: 3.13359e-02
I0212 22:15:11.373600 22509476222784 run_lib.py:133] step: 696600, training_loss: 5.10201e-02
I0212 22:15:11.548793 22509476222784 run_lib.py:146] step: 696600, eval_loss: 3.77926e-02
I0212 22:15:30.224349 22509476222784 run_lib.py:133] step: 696650, training_loss: 4.50135e-02
I0212 22:15:48.839717 22509476222784 run_lib.py:133] step: 696700, training_loss: 3.87680e-02
I0212 22:15:49.020528 22509476222784 run_lib.py:146] step: 696700, eval_loss: 6.73896e-02
I0212 22:16:07.634239 22509476222784 run_lib.py:133] step: 696750, training_loss: 3.94292e-02
I0212 22:16:26.379716 22509476222784 run_lib.py:133] step: 696800, training_loss: 3.46596e-02
I0212 22:16:26.544988 22509476222784 run_lib.py:146] step: 696800, eval_loss: 4.02209e-02
I0212 22:16:45.144168 22509476222784 run_lib.py:133] step: 696850, training_loss: 5.76185e-02
I0212 22:17:03.681734 22509476222784 run_lib.py:133] step: 696900, training_loss: 5.68659e-02
I0212 22:17:03.872915 22509476222784 run_lib.py:146] step: 696900, eval_loss: 5.11254e-02
I0212 22:17:22.560162 22509476222784 run_lib.py:133] step: 696950, training_loss: 3.22892e-02
I0212 22:17:41.188486 22509476222784 run_lib.py:133] step: 697000, training_loss: 4.42454e-02
I0212 22:17:41.378663 22509476222784 run_lib.py:146] step: 697000, eval_loss: 4.77985e-02
I0212 22:18:00.189193 22509476222784 run_lib.py:133] step: 697050, training_loss: 3.58280e-02
I0212 22:18:18.740412 22509476222784 run_lib.py:133] step: 697100, training_loss: 4.03345e-02
I0212 22:18:18.902765 22509476222784 run_lib.py:146] step: 697100, eval_loss: 3.74954e-02
I0212 22:18:37.460364 22509476222784 run_lib.py:133] step: 697150, training_loss: 3.91486e-02
I0212 22:18:56.204421 22509476222784 run_lib.py:133] step: 697200, training_loss: 4.85731e-02
I0212 22:18:56.386398 22509476222784 run_lib.py:146] step: 697200, eval_loss: 4.81651e-02
I0212 22:19:14.941913 22509476222784 run_lib.py:133] step: 697250, training_loss: 5.20795e-02
I0212 22:19:33.441308 22509476222784 run_lib.py:133] step: 697300, training_loss: 4.10205e-02
I0212 22:19:33.605922 22509476222784 run_lib.py:146] step: 697300, eval_loss: 4.23064e-02
I0212 22:19:52.127796 22509476222784 run_lib.py:133] step: 697350, training_loss: 4.80891e-02
I0212 22:20:10.910056 22509476222784 run_lib.py:133] step: 697400, training_loss: 4.45941e-02
I0212 22:20:11.075985 22509476222784 run_lib.py:146] step: 697400, eval_loss: 4.96431e-02
I0212 22:20:29.636744 22509476222784 run_lib.py:133] step: 697450, training_loss: 3.73748e-02
I0212 22:20:48.407640 22509476222784 run_lib.py:133] step: 697500, training_loss: 4.43684e-02
I0212 22:20:48.577965 22509476222784 run_lib.py:146] step: 697500, eval_loss: 5.82842e-02
I0212 22:21:07.174731 22509476222784 run_lib.py:133] step: 697550, training_loss: 4.81855e-02
I0212 22:21:25.765680 22509476222784 run_lib.py:133] step: 697600, training_loss: 3.97398e-02
I0212 22:21:25.968705 22509476222784 run_lib.py:146] step: 697600, eval_loss: 4.43107e-02
I0212 22:21:44.671005 22509476222784 run_lib.py:133] step: 697650, training_loss: 4.42839e-02
I0212 22:22:03.272101 22509476222784 run_lib.py:133] step: 697700, training_loss: 3.71917e-02
I0212 22:22:03.438940 22509476222784 run_lib.py:146] step: 697700, eval_loss: 5.30497e-02
I0212 22:22:22.063840 22509476222784 run_lib.py:133] step: 697750, training_loss: 4.58366e-02
I0212 22:22:40.745461 22509476222784 run_lib.py:133] step: 697800, training_loss: 4.17632e-02
I0212 22:22:40.935846 22509476222784 run_lib.py:146] step: 697800, eval_loss: 3.93706e-02
I0212 22:22:59.636564 22509476222784 run_lib.py:133] step: 697850, training_loss: 4.01363e-02
I0212 22:23:18.186277 22509476222784 run_lib.py:133] step: 697900, training_loss: 3.71156e-02
I0212 22:23:18.354828 22509476222784 run_lib.py:146] step: 697900, eval_loss: 5.05123e-02
I0212 22:23:37.030901 22509476222784 run_lib.py:133] step: 697950, training_loss: 4.48461e-02
I0212 22:23:55.563256 22509476222784 run_lib.py:133] step: 698000, training_loss: 3.69929e-02
I0212 22:23:55.725047 22509476222784 run_lib.py:146] step: 698000, eval_loss: 4.14914e-02
I0212 22:24:14.493285 22509476222784 run_lib.py:133] step: 698050, training_loss: 5.28750e-02
I0212 22:24:33.080788 22509476222784 run_lib.py:133] step: 698100, training_loss: 4.40468e-02
I0212 22:24:33.246981 22509476222784 run_lib.py:146] step: 698100, eval_loss: 5.19975e-02
I0212 22:24:51.786298 22509476222784 run_lib.py:133] step: 698150, training_loss: 3.11037e-02
I0212 22:25:10.577014 22509476222784 run_lib.py:133] step: 698200, training_loss: 5.87689e-02
I0212 22:25:10.743978 22509476222784 run_lib.py:146] step: 698200, eval_loss: 4.66131e-02
I0212 22:25:29.274792 22509476222784 run_lib.py:133] step: 698250, training_loss: 5.07988e-02
I0212 22:25:47.935191 22509476222784 run_lib.py:133] step: 698300, training_loss: 3.54180e-02
I0212 22:25:48.118704 22509476222784 run_lib.py:146] step: 698300, eval_loss: 5.16086e-02
I0212 22:26:06.682729 22509476222784 run_lib.py:133] step: 698350, training_loss: 5.34947e-02
I0212 22:26:25.269048 22509476222784 run_lib.py:133] step: 698400, training_loss: 3.25973e-02
I0212 22:26:25.464948 22509476222784 run_lib.py:146] step: 698400, eval_loss: 3.19712e-02
I0212 22:26:44.187358 22509476222784 run_lib.py:133] step: 698450, training_loss: 3.78591e-02
I0212 22:27:02.681349 22509476222784 run_lib.py:133] step: 698500, training_loss: 3.51001e-02
I0212 22:27:02.843687 22509476222784 run_lib.py:146] step: 698500, eval_loss: 5.39715e-02
I0212 22:27:21.393829 22509476222784 run_lib.py:133] step: 698550, training_loss: 4.35770e-02
I0212 22:27:40.116498 22509476222784 run_lib.py:133] step: 698600, training_loss: 4.00137e-02
I0212 22:27:40.298797 22509476222784 run_lib.py:146] step: 698600, eval_loss: 4.76697e-02
I0212 22:27:58.844028 22509476222784 run_lib.py:133] step: 698650, training_loss: 3.64628e-02
I0212 22:28:17.420462 22509476222784 run_lib.py:133] step: 698700, training_loss: 3.91474e-02
I0212 22:28:17.776906 22509476222784 run_lib.py:146] step: 698700, eval_loss: 4.14454e-02
I0212 22:28:36.360680 22509476222784 run_lib.py:133] step: 698750, training_loss: 4.34284e-02
I0212 22:28:54.948405 22509476222784 run_lib.py:133] step: 698800, training_loss: 3.43033e-02
I0212 22:28:55.111540 22509476222784 run_lib.py:146] step: 698800, eval_loss: 4.52427e-02
I0212 22:29:13.607456 22509476222784 run_lib.py:133] step: 698850, training_loss: 3.70933e-02
I0212 22:29:32.172321 22509476222784 run_lib.py:133] step: 698900, training_loss: 3.59356e-02
I0212 22:29:32.339768 22509476222784 run_lib.py:146] step: 698900, eval_loss: 3.27070e-02
I0212 22:29:51.089664 22509476222784 run_lib.py:133] step: 698950, training_loss: 6.38529e-02
I0212 22:30:09.724397 22509476222784 run_lib.py:133] step: 699000, training_loss: 4.81505e-02
I0212 22:30:09.938843 22509476222784 run_lib.py:146] step: 699000, eval_loss: 5.34059e-02
I0212 22:30:28.452349 22509476222784 run_lib.py:133] step: 699050, training_loss: 4.95830e-02
I0212 22:30:47.011556 22509476222784 run_lib.py:133] step: 699100, training_loss: 5.86269e-02
I0212 22:30:47.192849 22509476222784 run_lib.py:146] step: 699100, eval_loss: 3.45649e-02
I0212 22:31:05.941426 22509476222784 run_lib.py:133] step: 699150, training_loss: 3.71152e-02
I0212 22:31:24.591545 22509476222784 run_lib.py:133] step: 699200, training_loss: 4.67228e-02
I0212 22:31:24.753911 22509476222784 run_lib.py:146] step: 699200, eval_loss: 2.96545e-02
I0212 22:31:43.271580 22509476222784 run_lib.py:133] step: 699250, training_loss: 4.19533e-02
I0212 22:32:01.775280 22509476222784 run_lib.py:133] step: 699300, training_loss: 3.97323e-02
I0212 22:32:01.939461 22509476222784 run_lib.py:146] step: 699300, eval_loss: 3.78400e-02
I0212 22:32:20.653368 22509476222784 run_lib.py:133] step: 699350, training_loss: 5.11704e-02
I0212 22:32:39.223584 22509476222784 run_lib.py:133] step: 699400, training_loss: 5.16289e-02
I0212 22:32:39.385477 22509476222784 run_lib.py:146] step: 699400, eval_loss: 3.50773e-02
I0212 22:32:58.087462 22509476222784 run_lib.py:133] step: 699450, training_loss: 4.40209e-02
I0212 22:33:16.634759 22509476222784 run_lib.py:133] step: 699500, training_loss: 4.05808e-02
I0212 22:33:16.818752 22509476222784 run_lib.py:146] step: 699500, eval_loss: 4.80679e-02
I0212 22:33:35.480287 22509476222784 run_lib.py:133] step: 699550, training_loss: 4.95392e-02
I0212 22:33:54.078340 22509476222784 run_lib.py:133] step: 699600, training_loss: 3.23589e-02
I0212 22:33:54.245954 22509476222784 run_lib.py:146] step: 699600, eval_loss: 3.96381e-02
I0212 22:34:12.783548 22509476222784 run_lib.py:133] step: 699650, training_loss: 4.26167e-02
I0212 22:34:31.569428 22509476222784 run_lib.py:133] step: 699700, training_loss: 3.11089e-02
I0212 22:34:31.733451 22509476222784 run_lib.py:146] step: 699700, eval_loss: 4.61966e-02
I0212 22:34:50.299654 22509476222784 run_lib.py:133] step: 699750, training_loss: 4.19196e-02
I0212 22:35:09.050630 22509476222784 run_lib.py:133] step: 699800, training_loss: 4.32017e-02
I0212 22:35:09.269821 22509476222784 run_lib.py:146] step: 699800, eval_loss: 4.16858e-02
I0212 22:35:27.833733 22509476222784 run_lib.py:133] step: 699850, training_loss: 4.67610e-02
I0212 22:35:46.392012 22509476222784 run_lib.py:133] step: 699900, training_loss: 3.90268e-02
I0212 22:35:46.568078 22509476222784 run_lib.py:146] step: 699900, eval_loss: 5.39559e-02
I0212 22:36:05.161758 22509476222784 run_lib.py:133] step: 699950, training_loss: 5.18305e-02
I0212 22:36:23.963254 22509476222784 run_lib.py:133] step: 700000, training_loss: 3.01007e-02
I0212 22:36:24.730806 22509476222784 run_lib.py:146] step: 700000, eval_loss: 3.80597e-02
I0212 22:36:46.142159 22509476222784 run_lib.py:133] step: 700050, training_loss: 3.32995e-02
I0212 22:37:04.821951 22509476222784 run_lib.py:133] step: 700100, training_loss: 5.00647e-02
I0212 22:37:05.002923 22509476222784 run_lib.py:146] step: 700100, eval_loss: 4.12800e-02
I0212 22:37:23.506740 22509476222784 run_lib.py:133] step: 700150, training_loss: 5.24371e-02
I0212 22:37:42.062374 22509476222784 run_lib.py:133] step: 700200, training_loss: 4.46058e-02
I0212 22:37:42.236759 22509476222784 run_lib.py:146] step: 700200, eval_loss: 4.84295e-02
I0212 22:38:00.976704 22509476222784 run_lib.py:133] step: 700250, training_loss: 3.47165e-02
I0212 22:38:19.548568 22509476222784 run_lib.py:133] step: 700300, training_loss: 4.02755e-02
I0212 22:38:19.713313 22509476222784 run_lib.py:146] step: 700300, eval_loss: 3.97099e-02
I0212 22:38:38.429978 22509476222784 run_lib.py:133] step: 700350, training_loss: 3.75040e-02
I0212 22:38:56.961406 22509476222784 run_lib.py:133] step: 700400, training_loss: 5.12686e-02
I0212 22:38:57.145812 22509476222784 run_lib.py:146] step: 700400, eval_loss: 3.82780e-02
I0212 22:39:15.847911 22509476222784 run_lib.py:133] step: 700450, training_loss: 3.76279e-02
I0212 22:39:34.396746 22509476222784 run_lib.py:133] step: 700500, training_loss: 3.03219e-02
I0212 22:39:34.569046 22509476222784 run_lib.py:146] step: 700500, eval_loss: 3.75288e-02
I0212 22:39:53.382112 22509476222784 run_lib.py:133] step: 700550, training_loss: 5.20677e-02
I0212 22:40:11.942376 22509476222784 run_lib.py:133] step: 700600, training_loss: 4.01785e-02
I0212 22:40:12.108969 22509476222784 run_lib.py:146] step: 700600, eval_loss: 4.54716e-02
I0212 22:40:30.588273 22509476222784 run_lib.py:133] step: 700650, training_loss: 5.08436e-02
I0212 22:40:49.222707 22509476222784 run_lib.py:133] step: 700700, training_loss: 4.16491e-02
I0212 22:40:49.382188 22509476222784 run_lib.py:146] step: 700700, eval_loss: 4.22630e-02
I0212 22:41:07.931669 22509476222784 run_lib.py:133] step: 700750, training_loss: 4.51774e-02
I0212 22:41:26.573251 22509476222784 run_lib.py:133] step: 700800, training_loss: 6.04636e-02
I0212 22:41:26.738902 22509476222784 run_lib.py:146] step: 700800, eval_loss: 3.59130e-02
I0212 22:41:45.491064 22509476222784 run_lib.py:133] step: 700850, training_loss: 3.37484e-02
I0212 22:42:04.160967 22509476222784 run_lib.py:133] step: 700900, training_loss: 3.91337e-02
I0212 22:42:04.327859 22509476222784 run_lib.py:146] step: 700900, eval_loss: 4.64130e-02
I0212 22:42:22.892406 22509476222784 run_lib.py:133] step: 700950, training_loss: 3.65537e-02
I0212 22:42:41.448420 22509476222784 run_lib.py:133] step: 701000, training_loss: 4.29678e-02
I0212 22:42:41.674330 22509476222784 run_lib.py:146] step: 701000, eval_loss: 4.01332e-02
I0212 22:43:00.285594 22509476222784 run_lib.py:133] step: 701050, training_loss: 3.78429e-02
I0212 22:43:18.990349 22509476222784 run_lib.py:133] step: 701100, training_loss: 3.83245e-02
I0212 22:43:19.155812 22509476222784 run_lib.py:146] step: 701100, eval_loss: 3.36025e-02
I0212 22:43:37.675602 22509476222784 run_lib.py:133] step: 701150, training_loss: 3.02524e-02
I0212 22:43:56.226394 22509476222784 run_lib.py:133] step: 701200, training_loss: 4.10377e-02
I0212 22:43:56.390691 22509476222784 run_lib.py:146] step: 701200, eval_loss: 4.13987e-02
I0212 22:44:14.958357 22509476222784 run_lib.py:133] step: 701250, training_loss: 3.42432e-02
I0212 22:44:33.780191 22509476222784 run_lib.py:133] step: 701300, training_loss: 3.80786e-02
I0212 22:44:33.944930 22509476222784 run_lib.py:146] step: 701300, eval_loss: 3.79869e-02
I0212 22:44:52.530665 22509476222784 run_lib.py:133] step: 701350, training_loss: 4.51938e-02
I0212 22:45:11.134922 22509476222784 run_lib.py:133] step: 701400, training_loss: 3.30493e-02
I0212 22:45:11.307672 22509476222784 run_lib.py:146] step: 701400, eval_loss: 4.07663e-02
I0212 22:45:29.843972 22509476222784 run_lib.py:133] step: 701450, training_loss: 5.93800e-02
I0212 22:45:48.414020 22509476222784 run_lib.py:133] step: 701500, training_loss: 3.53025e-02
I0212 22:45:48.619439 22509476222784 run_lib.py:146] step: 701500, eval_loss: 3.89774e-02
I0212 22:46:07.411200 22509476222784 run_lib.py:133] step: 701550, training_loss: 3.11847e-02
I0212 22:46:26.116020 22509476222784 run_lib.py:133] step: 701600, training_loss: 5.55123e-02
I0212 22:46:26.280679 22509476222784 run_lib.py:146] step: 701600, eval_loss: 5.31202e-02
I0212 22:46:44.849855 22509476222784 run_lib.py:133] step: 701650, training_loss: 4.24326e-02
I0212 22:47:03.421789 22509476222784 run_lib.py:133] step: 701700, training_loss: 5.08122e-02
I0212 22:47:03.588762 22509476222784 run_lib.py:146] step: 701700, eval_loss: 3.75149e-02
I0212 22:47:22.353683 22509476222784 run_lib.py:133] step: 701750, training_loss: 4.29758e-02
I0212 22:47:41.013680 22509476222784 run_lib.py:133] step: 701800, training_loss: 3.33579e-02
I0212 22:47:41.183527 22509476222784 run_lib.py:146] step: 701800, eval_loss: 3.47848e-02
I0212 22:48:00.034223 22509476222784 run_lib.py:133] step: 701850, training_loss: 3.14409e-02
I0212 22:48:18.609254 22509476222784 run_lib.py:133] step: 701900, training_loss: 3.78667e-02
I0212 22:48:18.769699 22509476222784 run_lib.py:146] step: 701900, eval_loss: 3.82274e-02
I0212 22:48:37.454245 22509476222784 run_lib.py:133] step: 701950, training_loss: 3.60982e-02
I0212 22:48:56.033943 22509476222784 run_lib.py:133] step: 702000, training_loss: 3.46387e-02
I0212 22:48:56.213708 22509476222784 run_lib.py:146] step: 702000, eval_loss: 3.96223e-02
I0212 22:49:14.846934 22509476222784 run_lib.py:133] step: 702050, training_loss: 5.17131e-02
I0212 22:49:33.661825 22509476222784 run_lib.py:133] step: 702100, training_loss: 3.70516e-02
I0212 22:49:33.827007 22509476222784 run_lib.py:146] step: 702100, eval_loss: 4.81154e-02
I0212 22:49:52.414378 22509476222784 run_lib.py:133] step: 702150, training_loss: 4.20236e-02
I0212 22:50:11.047122 22509476222784 run_lib.py:133] step: 702200, training_loss: 4.74005e-02
I0212 22:50:11.216846 22509476222784 run_lib.py:146] step: 702200, eval_loss: 4.92006e-02
I0212 22:50:29.765585 22509476222784 run_lib.py:133] step: 702250, training_loss: 3.66981e-02
I0212 22:50:48.330642 22509476222784 run_lib.py:133] step: 702300, training_loss: 4.92030e-02
I0212 22:50:48.496135 22509476222784 run_lib.py:146] step: 702300, eval_loss: 4.78029e-02
I0212 22:51:07.276181 22509476222784 run_lib.py:133] step: 702350, training_loss: 3.28855e-02
I0212 22:51:25.795919 22509476222784 run_lib.py:133] step: 702400, training_loss: 3.68806e-02
I0212 22:51:25.996704 22509476222784 run_lib.py:146] step: 702400, eval_loss: 4.53571e-02
I0212 22:51:44.533930 22509476222784 run_lib.py:133] step: 702450, training_loss: 3.29306e-02
I0212 22:52:03.220929 22509476222784 run_lib.py:133] step: 702500, training_loss: 6.31610e-02
I0212 22:52:03.387935 22509476222784 run_lib.py:146] step: 702500, eval_loss: 3.12008e-02
I0212 22:52:21.938846 22509476222784 run_lib.py:133] step: 702550, training_loss: 4.35224e-02
I0212 22:52:40.505996 22509476222784 run_lib.py:133] step: 702600, training_loss: 3.95838e-02
I0212 22:52:40.679699 22509476222784 run_lib.py:146] step: 702600, eval_loss: 4.53314e-02
I0212 22:52:59.330791 22509476222784 run_lib.py:133] step: 702650, training_loss: 4.89177e-02
I0212 22:53:17.840979 22509476222784 run_lib.py:133] step: 702700, training_loss: 3.11786e-02
I0212 22:53:18.005701 22509476222784 run_lib.py:146] step: 702700, eval_loss: 5.53810e-02
I0212 22:53:36.533723 22509476222784 run_lib.py:133] step: 702750, training_loss: 3.75671e-02
I0212 22:53:55.104127 22509476222784 run_lib.py:133] step: 702800, training_loss: 3.86271e-02
I0212 22:53:55.269922 22509476222784 run_lib.py:146] step: 702800, eval_loss: 6.22126e-02
I0212 22:54:14.039444 22509476222784 run_lib.py:133] step: 702850, training_loss: 4.37583e-02
I0212 22:54:32.793128 22509476222784 run_lib.py:133] step: 702900, training_loss: 4.72856e-02
I0212 22:54:32.956421 22509476222784 run_lib.py:146] step: 702900, eval_loss: 2.88489e-02
I0212 22:54:51.471872 22509476222784 run_lib.py:133] step: 702950, training_loss: 4.91063e-02
I0212 22:55:10.023691 22509476222784 run_lib.py:133] step: 703000, training_loss: 4.28424e-02
I0212 22:55:10.189019 22509476222784 run_lib.py:146] step: 703000, eval_loss: 5.29753e-02
I0212 22:55:28.851486 22509476222784 run_lib.py:133] step: 703050, training_loss: 3.46697e-02
I0212 22:55:47.426135 22509476222784 run_lib.py:133] step: 703100, training_loss: 4.16610e-02
I0212 22:55:47.591750 22509476222784 run_lib.py:146] step: 703100, eval_loss: 4.01393e-02
I0212 22:56:06.286915 22509476222784 run_lib.py:133] step: 703150, training_loss: 3.34741e-02
I0212 22:56:24.863804 22509476222784 run_lib.py:133] step: 703200, training_loss: 3.06265e-02
I0212 22:56:25.048938 22509476222784 run_lib.py:146] step: 703200, eval_loss: 4.91047e-02
I0212 22:56:43.802911 22509476222784 run_lib.py:133] step: 703250, training_loss: 5.13759e-02
I0212 22:57:02.319936 22509476222784 run_lib.py:133] step: 703300, training_loss: 3.04608e-02
I0212 22:57:02.483544 22509476222784 run_lib.py:146] step: 703300, eval_loss: 4.40232e-02
I0212 22:57:21.162350 22509476222784 run_lib.py:133] step: 703350, training_loss: 4.35626e-02
I0212 22:57:39.749306 22509476222784 run_lib.py:133] step: 703400, training_loss: 4.24182e-02
I0212 22:57:39.930618 22509476222784 run_lib.py:146] step: 703400, eval_loss: 4.71403e-02
I0212 22:57:58.546848 22509476222784 run_lib.py:133] step: 703450, training_loss: 3.56855e-02
I0212 22:58:17.367432 22509476222784 run_lib.py:133] step: 703500, training_loss: 5.38721e-02
I0212 22:58:17.530730 22509476222784 run_lib.py:146] step: 703500, eval_loss: 5.30530e-02
I0212 22:58:36.056073 22509476222784 run_lib.py:133] step: 703550, training_loss: 3.87662e-02
I0212 22:58:54.560302 22509476222784 run_lib.py:133] step: 703600, training_loss: 4.11172e-02
I0212 22:58:54.724861 22509476222784 run_lib.py:146] step: 703600, eval_loss: 5.42585e-02
I0212 22:59:13.421548 22509476222784 run_lib.py:133] step: 703650, training_loss: 4.65004e-02
I0212 22:59:32.086003 22509476222784 run_lib.py:133] step: 703700, training_loss: 5.17185e-02
I0212 22:59:32.259727 22509476222784 run_lib.py:146] step: 703700, eval_loss: 4.37073e-02
I0212 22:59:51.011043 22509476222784 run_lib.py:133] step: 703750, training_loss: 3.62190e-02
I0212 23:00:09.560819 22509476222784 run_lib.py:133] step: 703800, training_loss: 4.02972e-02
I0212 23:00:09.722726 22509476222784 run_lib.py:146] step: 703800, eval_loss: 3.74741e-02
I0212 23:00:28.267710 22509476222784 run_lib.py:133] step: 703850, training_loss: 5.00418e-02
I0212 23:00:47.007517 22509476222784 run_lib.py:133] step: 703900, training_loss: 4.84771e-02
I0212 23:00:47.211892 22509476222784 run_lib.py:146] step: 703900, eval_loss: 4.07410e-02
I0212 23:01:05.836967 22509476222784 run_lib.py:133] step: 703950, training_loss: 3.84603e-02
I0212 23:01:24.452633 22509476222784 run_lib.py:133] step: 704000, training_loss: 3.98961e-02
I0212 23:01:24.653038 22509476222784 run_lib.py:146] step: 704000, eval_loss: 3.88472e-02
I0212 23:01:43.234466 22509476222784 run_lib.py:133] step: 704050, training_loss: 4.71878e-02
I0212 23:02:01.969482 22509476222784 run_lib.py:133] step: 704100, training_loss: 4.21218e-02
I0212 23:02:02.134603 22509476222784 run_lib.py:146] step: 704100, eval_loss: 5.19866e-02
I0212 23:02:20.600476 22509476222784 run_lib.py:133] step: 704150, training_loss: 4.78829e-02
I0212 23:02:39.218100 22509476222784 run_lib.py:133] step: 704200, training_loss: 4.72561e-02
I0212 23:02:39.379365 22509476222784 run_lib.py:146] step: 704200, eval_loss: 3.81555e-02
I0212 23:02:57.958927 22509476222784 run_lib.py:133] step: 704250, training_loss: 4.35022e-02
I0212 23:03:16.466121 22509476222784 run_lib.py:133] step: 704300, training_loss: 2.81385e-02
I0212 23:03:16.631088 22509476222784 run_lib.py:146] step: 704300, eval_loss: 4.10790e-02
I0212 23:03:35.292758 22509476222784 run_lib.py:133] step: 704350, training_loss: 4.36274e-02
I0212 23:03:53.913361 22509476222784 run_lib.py:133] step: 704400, training_loss: 4.68927e-02
I0212 23:03:54.131887 22509476222784 run_lib.py:146] step: 704400, eval_loss: 3.84875e-02
I0212 23:04:12.748453 22509476222784 run_lib.py:133] step: 704450, training_loss: 5.15690e-02
I0212 23:04:31.368026 22509476222784 run_lib.py:133] step: 704500, training_loss: 4.48359e-02
I0212 23:04:31.564924 22509476222784 run_lib.py:146] step: 704500, eval_loss: 4.38840e-02
I0212 23:04:50.248447 22509476222784 run_lib.py:133] step: 704550, training_loss: 4.18024e-02
I0212 23:05:08.773815 22509476222784 run_lib.py:133] step: 704600, training_loss: 3.79545e-02
I0212 23:05:08.937666 22509476222784 run_lib.py:146] step: 704600, eval_loss: 3.57268e-02
I0212 23:05:27.655514 22509476222784 run_lib.py:133] step: 704650, training_loss: 4.27919e-02
I0212 23:05:46.251024 22509476222784 run_lib.py:133] step: 704700, training_loss: 4.82114e-02
I0212 23:05:46.413791 22509476222784 run_lib.py:146] step: 704700, eval_loss: 4.15174e-02
I0212 23:06:05.222919 22509476222784 run_lib.py:133] step: 704750, training_loss: 3.41852e-02
I0212 23:06:23.734005 22509476222784 run_lib.py:133] step: 704800, training_loss: 3.63205e-02
I0212 23:06:23.899816 22509476222784 run_lib.py:146] step: 704800, eval_loss: 4.29827e-02
I0212 23:06:42.437113 22509476222784 run_lib.py:133] step: 704850, training_loss: 4.27898e-02
I0212 23:07:01.160154 22509476222784 run_lib.py:133] step: 704900, training_loss: 4.82616e-02
I0212 23:07:01.326890 22509476222784 run_lib.py:146] step: 704900, eval_loss: 3.85676e-02
I0212 23:07:19.868234 22509476222784 run_lib.py:133] step: 704950, training_loss: 4.34592e-02
I0212 23:07:38.613414 22509476222784 run_lib.py:133] step: 705000, training_loss: 4.27286e-02
I0212 23:07:38.855033 22509476222784 run_lib.py:146] step: 705000, eval_loss: 4.19629e-02
I0212 23:07:57.425153 22509476222784 run_lib.py:133] step: 705050, training_loss: 5.17641e-02
I0212 23:08:15.932952 22509476222784 run_lib.py:133] step: 705100, training_loss: 3.04733e-02
I0212 23:08:16.096882 22509476222784 run_lib.py:146] step: 705100, eval_loss: 4.73180e-02
I0212 23:08:34.823628 22509476222784 run_lib.py:133] step: 705150, training_loss: 3.35183e-02
I0212 23:08:53.381723 22509476222784 run_lib.py:133] step: 705200, training_loss: 4.36791e-02
I0212 23:08:53.569838 22509476222784 run_lib.py:146] step: 705200, eval_loss: 4.55507e-02
I0212 23:09:12.131117 22509476222784 run_lib.py:133] step: 705250, training_loss: 4.28013e-02
I0212 23:09:30.849320 22509476222784 run_lib.py:133] step: 705300, training_loss: 5.83938e-02
I0212 23:09:31.026856 22509476222784 run_lib.py:146] step: 705300, eval_loss: 4.67601e-02
I0212 23:09:49.620275 22509476222784 run_lib.py:133] step: 705350, training_loss: 3.79900e-02
I0212 23:10:08.148702 22509476222784 run_lib.py:133] step: 705400, training_loss: 3.86409e-02
I0212 23:10:08.521107 22509476222784 run_lib.py:146] step: 705400, eval_loss: 4.31444e-02
I0212 23:10:27.097448 22509476222784 run_lib.py:133] step: 705450, training_loss: 3.17084e-02
I0212 23:10:45.660977 22509476222784 run_lib.py:133] step: 705500, training_loss: 4.48916e-02
I0212 23:10:45.834413 22509476222784 run_lib.py:146] step: 705500, eval_loss: 3.55221e-02
I0212 23:11:04.420406 22509476222784 run_lib.py:133] step: 705550, training_loss: 4.78230e-02
I0212 23:11:23.003123 22509476222784 run_lib.py:133] step: 705600, training_loss: 3.04170e-02
I0212 23:11:23.171220 22509476222784 run_lib.py:146] step: 705600, eval_loss: 3.37216e-02
I0212 23:11:41.926677 22509476222784 run_lib.py:133] step: 705650, training_loss: 4.43416e-02
I0212 23:12:00.620196 22509476222784 run_lib.py:133] step: 705700, training_loss: 4.83574e-02
I0212 23:12:00.782731 22509476222784 run_lib.py:146] step: 705700, eval_loss: 5.76167e-02
I0212 23:12:19.369984 22509476222784 run_lib.py:133] step: 705750, training_loss: 3.54325e-02
I0212 23:12:37.966687 22509476222784 run_lib.py:133] step: 705800, training_loss: 3.61786e-02
I0212 23:12:38.163344 22509476222784 run_lib.py:146] step: 705800, eval_loss: 5.43124e-02
I0212 23:12:56.954967 22509476222784 run_lib.py:133] step: 705850, training_loss: 3.80412e-02
I0212 23:13:15.558075 22509476222784 run_lib.py:133] step: 705900, training_loss: 4.46370e-02
I0212 23:13:15.723643 22509476222784 run_lib.py:146] step: 705900, eval_loss: 5.21131e-02
I0212 23:13:34.288099 22509476222784 run_lib.py:133] step: 705950, training_loss: 5.13316e-02
I0212 23:13:52.923430 22509476222784 run_lib.py:133] step: 706000, training_loss: 4.40880e-02
I0212 23:13:53.092499 22509476222784 run_lib.py:146] step: 706000, eval_loss: 4.09129e-02
I0212 23:14:11.870891 22509476222784 run_lib.py:133] step: 706050, training_loss: 4.83911e-02
I0212 23:14:30.416029 22509476222784 run_lib.py:133] step: 706100, training_loss: 4.04970e-02
I0212 23:14:30.641767 22509476222784 run_lib.py:146] step: 706100, eval_loss: 3.37040e-02
I0212 23:14:49.366088 22509476222784 run_lib.py:133] step: 706150, training_loss: 4.00209e-02
I0212 23:15:07.910668 22509476222784 run_lib.py:133] step: 706200, training_loss: 4.16034e-02
I0212 23:15:08.146611 22509476222784 run_lib.py:146] step: 706200, eval_loss: 4.05762e-02
I0212 23:15:26.875976 22509476222784 run_lib.py:133] step: 706250, training_loss: 3.83362e-02
I0212 23:15:45.465155 22509476222784 run_lib.py:133] step: 706300, training_loss: 5.26874e-02
I0212 23:15:45.667712 22509476222784 run_lib.py:146] step: 706300, eval_loss: 4.24045e-02
I0212 23:16:04.200283 22509476222784 run_lib.py:133] step: 706350, training_loss: 3.84859e-02
I0212 23:16:22.936026 22509476222784 run_lib.py:133] step: 706400, training_loss: 3.56690e-02
I0212 23:16:23.127930 22509476222784 run_lib.py:146] step: 706400, eval_loss: 3.62431e-02
I0212 23:16:41.688211 22509476222784 run_lib.py:133] step: 706450, training_loss: 2.96852e-02
I0212 23:17:00.348507 22509476222784 run_lib.py:133] step: 706500, training_loss: 4.72146e-02
I0212 23:17:00.515827 22509476222784 run_lib.py:146] step: 706500, eval_loss: 4.78783e-02
I0212 23:17:19.121534 22509476222784 run_lib.py:133] step: 706550, training_loss: 3.30249e-02
I0212 23:17:37.738859 22509476222784 run_lib.py:133] step: 706600, training_loss: 4.49840e-02
I0212 23:17:37.900595 22509476222784 run_lib.py:146] step: 706600, eval_loss: 4.25177e-02
I0212 23:17:56.438524 22509476222784 run_lib.py:133] step: 706650, training_loss: 4.44654e-02
I0212 23:18:15.187270 22509476222784 run_lib.py:133] step: 706700, training_loss: 3.51330e-02
I0212 23:18:15.354678 22509476222784 run_lib.py:146] step: 706700, eval_loss: 3.85811e-02
I0212 23:18:33.889710 22509476222784 run_lib.py:133] step: 706750, training_loss: 3.61923e-02
I0212 23:18:52.490827 22509476222784 run_lib.py:133] step: 706800, training_loss: 3.98220e-02
I0212 23:18:52.673746 22509476222784 run_lib.py:146] step: 706800, eval_loss: 3.73199e-02
I0212 23:19:11.370902 22509476222784 run_lib.py:133] step: 706850, training_loss: 3.30092e-02
I0212 23:19:29.982364 22509476222784 run_lib.py:133] step: 706900, training_loss: 4.06553e-02
I0212 23:19:30.179411 22509476222784 run_lib.py:146] step: 706900, eval_loss: 4.16064e-02
I0212 23:19:48.806810 22509476222784 run_lib.py:133] step: 706950, training_loss: 3.04116e-02
I0212 23:20:07.331635 22509476222784 run_lib.py:133] step: 707000, training_loss: 3.91641e-02
I0212 23:20:07.494864 22509476222784 run_lib.py:146] step: 707000, eval_loss: 3.70914e-02
I0212 23:20:26.075035 22509476222784 run_lib.py:133] step: 707050, training_loss: 5.10169e-02
I0212 23:20:44.612292 22509476222784 run_lib.py:133] step: 707100, training_loss: 3.21443e-02
I0212 23:20:44.778911 22509476222784 run_lib.py:146] step: 707100, eval_loss: 3.83561e-02
I0212 23:21:03.553011 22509476222784 run_lib.py:133] step: 707150, training_loss: 4.47666e-02
I0212 23:21:22.242562 22509476222784 run_lib.py:133] step: 707200, training_loss: 5.61192e-02
I0212 23:21:22.409082 22509476222784 run_lib.py:146] step: 707200, eval_loss: 3.63477e-02
I0212 23:21:40.912943 22509476222784 run_lib.py:133] step: 707250, training_loss: 3.92037e-02
I0212 23:21:59.448026 22509476222784 run_lib.py:133] step: 707300, training_loss: 4.05089e-02
I0212 23:21:59.643710 22509476222784 run_lib.py:146] step: 707300, eval_loss: 4.03212e-02
I0212 23:22:18.408205 22509476222784 run_lib.py:133] step: 707350, training_loss: 4.27699e-02
I0212 23:22:36.959695 22509476222784 run_lib.py:133] step: 707400, training_loss: 3.94578e-02
I0212 23:22:37.125017 22509476222784 run_lib.py:146] step: 707400, eval_loss: 4.14612e-02
I0212 23:22:55.803560 22509476222784 run_lib.py:133] step: 707450, training_loss: 4.05690e-02
I0212 23:23:14.314083 22509476222784 run_lib.py:133] step: 707500, training_loss: 3.66210e-02
I0212 23:23:14.505710 22509476222784 run_lib.py:146] step: 707500, eval_loss: 4.76613e-02
I0212 23:23:33.216068 22509476222784 run_lib.py:133] step: 707550, training_loss: 3.75624e-02
I0212 23:23:51.796174 22509476222784 run_lib.py:133] step: 707600, training_loss: 4.37503e-02
I0212 23:23:51.973905 22509476222784 run_lib.py:146] step: 707600, eval_loss: 3.69102e-02
I0212 23:24:10.710140 22509476222784 run_lib.py:133] step: 707650, training_loss: 4.58030e-02
I0212 23:24:29.256894 22509476222784 run_lib.py:133] step: 707700, training_loss: 4.59166e-02
I0212 23:24:29.422903 22509476222784 run_lib.py:146] step: 707700, eval_loss: 5.10080e-02
I0212 23:24:47.921462 22509476222784 run_lib.py:133] step: 707750, training_loss: 3.81584e-02
I0212 23:25:06.588307 22509476222784 run_lib.py:133] step: 707800, training_loss: 4.94582e-02
I0212 23:25:06.760670 22509476222784 run_lib.py:146] step: 707800, eval_loss: 4.34690e-02
I0212 23:25:25.380806 22509476222784 run_lib.py:133] step: 707850, training_loss: 4.50580e-02
I0212 23:25:43.992478 22509476222784 run_lib.py:133] step: 707900, training_loss: 4.30432e-02
I0212 23:25:44.158988 22509476222784 run_lib.py:146] step: 707900, eval_loss: 4.50933e-02
I0212 23:26:02.893252 22509476222784 run_lib.py:133] step: 707950, training_loss: 5.02304e-02
I0212 23:26:21.576677 22509476222784 run_lib.py:133] step: 708000, training_loss: 4.37695e-02
I0212 23:26:21.794474 22509476222784 run_lib.py:146] step: 708000, eval_loss: 5.51702e-02
I0212 23:26:40.325746 22509476222784 run_lib.py:133] step: 708050, training_loss: 3.74947e-02
I0212 23:26:58.848103 22509476222784 run_lib.py:133] step: 708100, training_loss: 4.54942e-02
I0212 23:26:59.060957 22509476222784 run_lib.py:146] step: 708100, eval_loss: 3.94385e-02
I0212 23:27:17.650273 22509476222784 run_lib.py:133] step: 708150, training_loss: 4.76240e-02
I0212 23:27:36.437284 22509476222784 run_lib.py:133] step: 708200, training_loss: 4.43310e-02
I0212 23:27:36.630689 22509476222784 run_lib.py:146] step: 708200, eval_loss: 3.27579e-02
I0212 23:27:55.162973 22509476222784 run_lib.py:133] step: 708250, training_loss: 5.36573e-02
I0212 23:28:13.720805 22509476222784 run_lib.py:133] step: 708300, training_loss: 5.06608e-02
I0212 23:28:13.906694 22509476222784 run_lib.py:146] step: 708300, eval_loss: 4.16816e-02
I0212 23:28:32.414800 22509476222784 run_lib.py:133] step: 708350, training_loss: 4.36557e-02
I0212 23:28:51.175034 22509476222784 run_lib.py:133] step: 708400, training_loss: 4.85481e-02
I0212 23:28:51.349299 22509476222784 run_lib.py:146] step: 708400, eval_loss: 3.27499e-02
I0212 23:29:09.911109 22509476222784 run_lib.py:133] step: 708450, training_loss: 4.03200e-02
I0212 23:29:28.539542 22509476222784 run_lib.py:133] step: 708500, training_loss: 3.19336e-02
I0212 23:29:28.701647 22509476222784 run_lib.py:146] step: 708500, eval_loss: 3.60142e-02
I0212 23:29:47.211192 22509476222784 run_lib.py:133] step: 708550, training_loss: 2.82483e-02
I0212 23:30:05.769646 22509476222784 run_lib.py:133] step: 708600, training_loss: 3.96823e-02
I0212 23:30:05.981840 22509476222784 run_lib.py:146] step: 708600, eval_loss: 4.07359e-02
I0212 23:30:24.757515 22509476222784 run_lib.py:133] step: 708650, training_loss: 4.54229e-02
I0212 23:30:43.479515 22509476222784 run_lib.py:133] step: 708700, training_loss: 3.36186e-02
I0212 23:30:43.644781 22509476222784 run_lib.py:146] step: 708700, eval_loss: 4.25315e-02
I0212 23:31:02.170644 22509476222784 run_lib.py:133] step: 708750, training_loss: 3.71568e-02
I0212 23:31:20.704885 22509476222784 run_lib.py:133] step: 708800, training_loss: 4.14613e-02
I0212 23:31:20.870813 22509476222784 run_lib.py:146] step: 708800, eval_loss: 4.53638e-02
I0212 23:31:39.504035 22509476222784 run_lib.py:133] step: 708850, training_loss: 4.92944e-02
I0212 23:31:58.019217 22509476222784 run_lib.py:133] step: 708900, training_loss: 4.51559e-02
I0212 23:31:58.184159 22509476222784 run_lib.py:146] step: 708900, eval_loss: 4.43518e-02
I0212 23:32:16.962906 22509476222784 run_lib.py:133] step: 708950, training_loss: 4.20634e-02
I0212 23:32:35.528031 22509476222784 run_lib.py:133] step: 709000, training_loss: 3.15564e-02
I0212 23:32:35.689743 22509476222784 run_lib.py:146] step: 709000, eval_loss: 3.83910e-02
I0212 23:32:54.397661 22509476222784 run_lib.py:133] step: 709050, training_loss: 3.56449e-02
I0212 23:33:12.967277 22509476222784 run_lib.py:133] step: 709100, training_loss: 3.56437e-02
I0212 23:33:13.134097 22509476222784 run_lib.py:146] step: 709100, eval_loss: 4.04840e-02
I0212 23:33:31.683974 22509476222784 run_lib.py:133] step: 709150, training_loss: 4.16832e-02
I0212 23:33:50.442538 22509476222784 run_lib.py:133] step: 709200, training_loss: 4.86612e-02
I0212 23:33:50.606639 22509476222784 run_lib.py:146] step: 709200, eval_loss: 3.78032e-02
I0212 23:34:09.166275 22509476222784 run_lib.py:133] step: 709250, training_loss: 4.58443e-02
I0212 23:34:27.965742 22509476222784 run_lib.py:133] step: 709300, training_loss: 3.67314e-02
I0212 23:34:28.129817 22509476222784 run_lib.py:146] step: 709300, eval_loss: 6.31291e-02
I0212 23:34:46.697595 22509476222784 run_lib.py:133] step: 709350, training_loss: 4.16155e-02
I0212 23:35:05.262864 22509476222784 run_lib.py:133] step: 709400, training_loss: 3.53300e-02
I0212 23:35:05.426187 22509476222784 run_lib.py:146] step: 709400, eval_loss: 5.29828e-02
I0212 23:35:24.199079 22509476222784 run_lib.py:133] step: 709450, training_loss: 4.17968e-02
I0212 23:35:42.792978 22509476222784 run_lib.py:133] step: 709500, training_loss: 4.02688e-02
I0212 23:35:42.956617 22509476222784 run_lib.py:146] step: 709500, eval_loss: 3.88901e-02
I0212 23:36:01.506120 22509476222784 run_lib.py:133] step: 709550, training_loss: 4.60346e-02
I0212 23:36:20.239647 22509476222784 run_lib.py:133] step: 709600, training_loss: 3.82580e-02
I0212 23:36:20.406933 22509476222784 run_lib.py:146] step: 709600, eval_loss: 3.53357e-02
I0212 23:36:38.924265 22509476222784 run_lib.py:133] step: 709650, training_loss: 4.83158e-02
I0212 23:36:57.476790 22509476222784 run_lib.py:133] step: 709700, training_loss: 4.33819e-02
I0212 23:36:57.650620 22509476222784 run_lib.py:146] step: 709700, eval_loss: 4.26297e-02
I0212 23:37:16.310410 22509476222784 run_lib.py:133] step: 709750, training_loss: 4.27700e-02
I0212 23:37:34.838120 22509476222784 run_lib.py:133] step: 709800, training_loss: 3.28464e-02
I0212 23:37:35.002899 22509476222784 run_lib.py:146] step: 709800, eval_loss: 3.14318e-02
I0212 23:37:53.577905 22509476222784 run_lib.py:133] step: 709850, training_loss: 4.56482e-02
I0212 23:38:12.117024 22509476222784 run_lib.py:133] step: 709900, training_loss: 3.30756e-02
I0212 23:38:12.277875 22509476222784 run_lib.py:146] step: 709900, eval_loss: 4.90319e-02
I0212 23:38:31.046491 22509476222784 run_lib.py:133] step: 709950, training_loss: 3.89813e-02
I0212 23:38:49.707890 22509476222784 run_lib.py:133] step: 710000, training_loss: 3.68417e-02
I0212 23:38:50.466880 22509476222784 run_lib.py:146] step: 710000, eval_loss: 4.57405e-02
I0212 23:39:11.695861 22509476222784 run_lib.py:133] step: 710050, training_loss: 4.33588e-02
I0212 23:39:30.265085 22509476222784 run_lib.py:133] step: 710100, training_loss: 4.43548e-02
I0212 23:39:30.474767 22509476222784 run_lib.py:146] step: 710100, eval_loss: 4.59759e-02
I0212 23:39:48.986011 22509476222784 run_lib.py:133] step: 710150, training_loss: 3.31621e-02
I0212 23:40:07.705212 22509476222784 run_lib.py:133] step: 710200, training_loss: 4.35831e-02
I0212 23:40:07.895849 22509476222784 run_lib.py:146] step: 710200, eval_loss: 3.80786e-02
I0212 23:40:26.428046 22509476222784 run_lib.py:133] step: 710250, training_loss: 5.70428e-02
I0212 23:40:45.141803 22509476222784 run_lib.py:133] step: 710300, training_loss: 4.09740e-02
I0212 23:40:45.353970 22509476222784 run_lib.py:146] step: 710300, eval_loss: 3.87184e-02
I0212 23:41:03.912150 22509476222784 run_lib.py:133] step: 710350, training_loss: 4.19253e-02
I0212 23:41:22.476514 22509476222784 run_lib.py:133] step: 710400, training_loss: 3.45681e-02
I0212 23:41:22.662518 22509476222784 run_lib.py:146] step: 710400, eval_loss: 4.03595e-02
I0212 23:41:41.432746 22509476222784 run_lib.py:133] step: 710450, training_loss: 3.61083e-02
I0212 23:42:00.145256 22509476222784 run_lib.py:133] step: 710500, training_loss: 3.77215e-02
I0212 23:42:00.327956 22509476222784 run_lib.py:146] step: 710500, eval_loss: 4.10020e-02
I0212 23:42:18.988755 22509476222784 run_lib.py:133] step: 710550, training_loss: 3.46359e-02
I0212 23:42:37.549318 22509476222784 run_lib.py:133] step: 710600, training_loss: 3.35751e-02
I0212 23:42:37.729129 22509476222784 run_lib.py:146] step: 710600, eval_loss: 4.63932e-02
I0212 23:42:56.469142 22509476222784 run_lib.py:133] step: 710650, training_loss: 4.93337e-02
I0212 23:43:15.012646 22509476222784 run_lib.py:133] step: 710700, training_loss: 4.18343e-02
I0212 23:43:15.185935 22509476222784 run_lib.py:146] step: 710700, eval_loss: 3.96922e-02
I0212 23:43:33.847368 22509476222784 run_lib.py:133] step: 710750, training_loss: 4.36759e-02
I0212 23:43:52.448879 22509476222784 run_lib.py:133] step: 710800, training_loss: 3.26884e-02
I0212 23:43:52.612498 22509476222784 run_lib.py:146] step: 710800, eval_loss: 4.28111e-02
I0212 23:44:11.356187 22509476222784 run_lib.py:133] step: 710850, training_loss: 5.15516e-02
I0212 23:44:29.901322 22509476222784 run_lib.py:133] step: 710900, training_loss: 4.13769e-02
I0212 23:44:30.064790 22509476222784 run_lib.py:146] step: 710900, eval_loss: 4.55517e-02
I0212 23:44:48.640698 22509476222784 run_lib.py:133] step: 710950, training_loss: 4.61271e-02
I0212 23:45:07.366021 22509476222784 run_lib.py:133] step: 711000, training_loss: 2.81856e-02
I0212 23:45:07.534451 22509476222784 run_lib.py:146] step: 711000, eval_loss: 3.51261e-02
I0212 23:45:26.173384 22509476222784 run_lib.py:133] step: 711050, training_loss: 4.17714e-02
I0212 23:45:45.056497 22509476222784 run_lib.py:133] step: 711100, training_loss: 3.17976e-02
I0212 23:45:45.222684 22509476222784 run_lib.py:146] step: 711100, eval_loss: 3.89265e-02
I0212 23:46:03.756667 22509476222784 run_lib.py:133] step: 711150, training_loss: 5.13445e-02
I0212 23:46:22.284714 22509476222784 run_lib.py:133] step: 711200, training_loss: 3.40751e-02
I0212 23:46:22.476737 22509476222784 run_lib.py:146] step: 711200, eval_loss: 3.77563e-02
I0212 23:46:41.186536 22509476222784 run_lib.py:133] step: 711250, training_loss: 3.71268e-02
I0212 23:46:59.774331 22509476222784 run_lib.py:133] step: 711300, training_loss: 4.54882e-02
I0212 23:46:59.947629 22509476222784 run_lib.py:146] step: 711300, eval_loss: 3.43409e-02
I0212 23:47:18.576522 22509476222784 run_lib.py:133] step: 711350, training_loss: 4.23412e-02
I0212 23:47:37.359542 22509476222784 run_lib.py:133] step: 711400, training_loss: 4.38817e-02
I0212 23:47:37.543522 22509476222784 run_lib.py:146] step: 711400, eval_loss: 3.20849e-02
I0212 23:47:56.071263 22509476222784 run_lib.py:133] step: 711450, training_loss: 3.71134e-02
I0212 23:48:14.603139 22509476222784 run_lib.py:133] step: 711500, training_loss: 3.81216e-02
I0212 23:48:14.767693 22509476222784 run_lib.py:146] step: 711500, eval_loss: 4.03496e-02
I0212 23:48:33.374207 22509476222784 run_lib.py:133] step: 711550, training_loss: 3.65836e-02
I0212 23:48:52.032480 22509476222784 run_lib.py:133] step: 711600, training_loss: 4.29395e-02
I0212 23:48:52.208766 22509476222784 run_lib.py:146] step: 711600, eval_loss: 5.13107e-02
I0212 23:49:10.806914 22509476222784 run_lib.py:133] step: 711650, training_loss: 3.18853e-02
I0212 23:49:29.306289 22509476222784 run_lib.py:133] step: 711700, training_loss: 3.44037e-02
I0212 23:49:29.481662 22509476222784 run_lib.py:146] step: 711700, eval_loss: 4.03293e-02
I0212 23:49:48.226328 22509476222784 run_lib.py:133] step: 711750, training_loss: 4.02060e-02
I0212 23:50:06.891638 22509476222784 run_lib.py:133] step: 711800, training_loss: 5.01688e-02
I0212 23:50:07.058667 22509476222784 run_lib.py:146] step: 711800, eval_loss: 4.84055e-02
I0212 23:50:25.670464 22509476222784 run_lib.py:133] step: 711850, training_loss: 4.42567e-02
I0212 23:50:44.246783 22509476222784 run_lib.py:133] step: 711900, training_loss: 3.77502e-02
I0212 23:50:44.410901 22509476222784 run_lib.py:146] step: 711900, eval_loss: 3.89348e-02
I0212 23:51:03.189435 22509476222784 run_lib.py:133] step: 711950, training_loss: 4.37092e-02
I0212 23:51:21.733633 22509476222784 run_lib.py:133] step: 712000, training_loss: 4.16477e-02
I0212 23:51:21.896573 22509476222784 run_lib.py:146] step: 712000, eval_loss: 3.86960e-02
I0212 23:51:40.543495 22509476222784 run_lib.py:133] step: 712050, training_loss: 3.68403e-02
I0212 23:51:59.138266 22509476222784 run_lib.py:133] step: 712100, training_loss: 4.10104e-02
I0212 23:51:59.323628 22509476222784 run_lib.py:146] step: 712100, eval_loss: 3.68358e-02
I0212 23:52:18.092060 22509476222784 run_lib.py:133] step: 712150, training_loss: 3.91678e-02
I0212 23:52:36.625349 22509476222784 run_lib.py:133] step: 712200, training_loss: 3.97937e-02
I0212 23:52:36.786908 22509476222784 run_lib.py:146] step: 712200, eval_loss: 3.56601e-02
I0212 23:52:55.477791 22509476222784 run_lib.py:133] step: 712250, training_loss: 5.22819e-02
I0212 23:53:14.029118 22509476222784 run_lib.py:133] step: 712300, training_loss: 5.35905e-02
I0212 23:53:14.195962 22509476222784 run_lib.py:146] step: 712300, eval_loss: 4.44939e-02
I0212 23:53:32.810004 22509476222784 run_lib.py:133] step: 712350, training_loss: 4.51670e-02
I0212 23:53:51.587229 22509476222784 run_lib.py:133] step: 712400, training_loss: 4.78891e-02
I0212 23:53:51.786039 22509476222784 run_lib.py:146] step: 712400, eval_loss: 4.24865e-02
I0212 23:54:10.328988 22509476222784 run_lib.py:133] step: 712450, training_loss: 3.33626e-02
I0212 23:54:28.866714 22509476222784 run_lib.py:133] step: 712500, training_loss: 3.78469e-02
I0212 23:54:29.029283 22509476222784 run_lib.py:146] step: 712500, eval_loss: 3.88039e-02
I0212 23:54:47.688633 22509476222784 run_lib.py:133] step: 712550, training_loss: 4.21737e-02
I0212 23:55:06.311242 22509476222784 run_lib.py:133] step: 712600, training_loss: 4.08943e-02
I0212 23:55:06.502977 22509476222784 run_lib.py:146] step: 712600, eval_loss: 4.94283e-02
I0212 23:55:25.234016 22509476222784 run_lib.py:133] step: 712650, training_loss: 4.75861e-02
I0212 23:55:43.754942 22509476222784 run_lib.py:133] step: 712700, training_loss: 3.76067e-02
I0212 23:55:43.920007 22509476222784 run_lib.py:146] step: 712700, eval_loss: 4.02769e-02
I0212 23:56:02.499238 22509476222784 run_lib.py:133] step: 712750, training_loss: 4.77658e-02
I0212 23:56:21.188188 22509476222784 run_lib.py:133] step: 712800, training_loss: 3.39097e-02
I0212 23:56:21.437661 22509476222784 run_lib.py:146] step: 712800, eval_loss: 3.48165e-02
I0212 23:56:40.087257 22509476222784 run_lib.py:133] step: 712850, training_loss: 5.09524e-02
I0212 23:56:58.645299 22509476222784 run_lib.py:133] step: 712900, training_loss: 4.30420e-02
I0212 23:56:58.812976 22509476222784 run_lib.py:146] step: 712900, eval_loss: 4.79466e-02
I0212 23:57:17.395940 22509476222784 run_lib.py:133] step: 712950, training_loss: 3.82486e-02
I0212 23:57:36.135603 22509476222784 run_lib.py:133] step: 713000, training_loss: 2.99167e-02
I0212 23:57:36.320919 22509476222784 run_lib.py:146] step: 713000, eval_loss: 3.92050e-02
I0212 23:57:54.928127 22509476222784 run_lib.py:133] step: 713050, training_loss: 4.63629e-02
I0212 23:58:13.586997 22509476222784 run_lib.py:133] step: 713100, training_loss: 4.55971e-02
I0212 23:58:13.777872 22509476222784 run_lib.py:146] step: 713100, eval_loss: 4.19667e-02
I0212 23:58:32.342176 22509476222784 run_lib.py:133] step: 713150, training_loss: 4.26462e-02
I0212 23:58:50.931439 22509476222784 run_lib.py:133] step: 713200, training_loss: 4.47122e-02
I0212 23:58:51.095926 22509476222784 run_lib.py:146] step: 713200, eval_loss: 4.11597e-02
I0212 23:59:09.853570 22509476222784 run_lib.py:133] step: 713250, training_loss: 4.24287e-02
I0212 23:59:28.484565 22509476222784 run_lib.py:133] step: 713300, training_loss: 3.38309e-02
I0212 23:59:28.645648 22509476222784 run_lib.py:146] step: 713300, eval_loss: 4.23584e-02
I0212 23:59:47.193301 22509476222784 run_lib.py:133] step: 713350, training_loss: 3.83216e-02
I0213 00:00:05.724001 22509476222784 run_lib.py:133] step: 713400, training_loss: 4.90894e-02
I0213 00:00:05.914894 22509476222784 run_lib.py:146] step: 713400, eval_loss: 3.85076e-02
I0213 00:00:24.735661 22509476222784 run_lib.py:133] step: 713450, training_loss: 5.02210e-02
I0213 00:00:43.324113 22509476222784 run_lib.py:133] step: 713500, training_loss: 3.74064e-02
I0213 00:00:43.490946 22509476222784 run_lib.py:146] step: 713500, eval_loss: 3.32147e-02
I0213 00:01:02.187343 22509476222784 run_lib.py:133] step: 713550, training_loss: 3.85577e-02
I0213 00:01:20.742894 22509476222784 run_lib.py:133] step: 713600, training_loss: 4.47437e-02
I0213 00:01:20.974852 22509476222784 run_lib.py:146] step: 713600, eval_loss: 4.56686e-02
I0213 00:01:39.726068 22509476222784 run_lib.py:133] step: 713650, training_loss: 4.28150e-02
I0213 00:01:58.399729 22509476222784 run_lib.py:133] step: 713700, training_loss: 5.48116e-02
I0213 00:01:58.561789 22509476222784 run_lib.py:146] step: 713700, eval_loss: 5.41181e-02
I0213 00:02:17.106316 22509476222784 run_lib.py:133] step: 713750, training_loss: 4.42773e-02
I0213 00:02:35.876170 22509476222784 run_lib.py:133] step: 713800, training_loss: 3.00855e-02
I0213 00:02:36.076548 22509476222784 run_lib.py:146] step: 713800, eval_loss: 3.42701e-02
I0213 00:02:54.590143 22509476222784 run_lib.py:133] step: 713850, training_loss: 4.93939e-02
I0213 00:03:13.306607 22509476222784 run_lib.py:133] step: 713900, training_loss: 4.33884e-02
I0213 00:03:13.507481 22509476222784 run_lib.py:146] step: 713900, eval_loss: 3.94329e-02
I0213 00:03:32.064269 22509476222784 run_lib.py:133] step: 713950, training_loss: 4.62508e-02
I0213 00:03:50.681547 22509476222784 run_lib.py:133] step: 714000, training_loss: 4.24222e-02
I0213 00:03:50.885896 22509476222784 run_lib.py:146] step: 714000, eval_loss: 3.35835e-02
I0213 00:04:09.597872 22509476222784 run_lib.py:133] step: 714050, training_loss: 4.75968e-02
I0213 00:04:28.131228 22509476222784 run_lib.py:133] step: 714100, training_loss: 4.14945e-02
I0213 00:04:28.295776 22509476222784 run_lib.py:146] step: 714100, eval_loss: 3.61099e-02
I0213 00:04:46.876112 22509476222784 run_lib.py:133] step: 714150, training_loss: 5.58409e-02
I0213 00:05:05.610448 22509476222784 run_lib.py:133] step: 714200, training_loss: 2.83686e-02
I0213 00:05:05.791899 22509476222784 run_lib.py:146] step: 714200, eval_loss: 4.14055e-02
I0213 00:05:24.365376 22509476222784 run_lib.py:133] step: 714250, training_loss: 3.23929e-02
I0213 00:05:42.883551 22509476222784 run_lib.py:133] step: 714300, training_loss: 3.88590e-02
I0213 00:05:43.234512 22509476222784 run_lib.py:146] step: 714300, eval_loss: 5.70533e-02
I0213 00:06:01.789559 22509476222784 run_lib.py:133] step: 714350, training_loss: 5.00166e-02
I0213 00:06:20.305028 22509476222784 run_lib.py:133] step: 714400, training_loss: 4.19550e-02
I0213 00:06:20.481673 22509476222784 run_lib.py:146] step: 714400, eval_loss: 4.51953e-02
I0213 00:06:39.110816 22509476222784 run_lib.py:133] step: 714450, training_loss: 5.43339e-02
I0213 00:06:57.775335 22509476222784 run_lib.py:133] step: 714500, training_loss: 5.08019e-02
I0213 00:06:57.948944 22509476222784 run_lib.py:146] step: 714500, eval_loss: 3.51561e-02
I0213 00:07:16.705614 22509476222784 run_lib.py:133] step: 714550, training_loss: 4.07321e-02
I0213 00:07:35.319150 22509476222784 run_lib.py:133] step: 714600, training_loss: 3.69950e-02
I0213 00:07:35.488913 22509476222784 run_lib.py:146] step: 714600, eval_loss: 3.49686e-02
I0213 00:07:54.040934 22509476222784 run_lib.py:133] step: 714650, training_loss: 3.76515e-02
I0213 00:08:12.609820 22509476222784 run_lib.py:133] step: 714700, training_loss: 4.65946e-02
I0213 00:08:12.781981 22509476222784 run_lib.py:146] step: 714700, eval_loss: 4.33034e-02
I0213 00:08:31.556363 22509476222784 run_lib.py:133] step: 714750, training_loss: 3.38641e-02
I0213 00:08:50.184839 22509476222784 run_lib.py:133] step: 714800, training_loss: 4.09255e-02
I0213 00:08:50.347563 22509476222784 run_lib.py:146] step: 714800, eval_loss: 4.61766e-02
I0213 00:09:08.850291 22509476222784 run_lib.py:133] step: 714850, training_loss: 2.99841e-02
I0213 00:09:27.424887 22509476222784 run_lib.py:133] step: 714900, training_loss: 3.65759e-02
I0213 00:09:27.590066 22509476222784 run_lib.py:146] step: 714900, eval_loss: 3.60326e-02
I0213 00:09:46.302441 22509476222784 run_lib.py:133] step: 714950, training_loss: 4.31182e-02
I0213 00:10:04.915355 22509476222784 run_lib.py:133] step: 715000, training_loss: 4.08663e-02
I0213 00:10:05.086971 22509476222784 run_lib.py:146] step: 715000, eval_loss: 3.58139e-02
I0213 00:10:23.820480 22509476222784 run_lib.py:133] step: 715050, training_loss: 4.55701e-02
I0213 00:10:42.391176 22509476222784 run_lib.py:133] step: 715100, training_loss: 4.13850e-02
I0213 00:10:42.554473 22509476222784 run_lib.py:146] step: 715100, eval_loss: 4.38135e-02
I0213 00:11:01.301362 22509476222784 run_lib.py:133] step: 715150, training_loss: 3.95037e-02
I0213 00:11:19.830929 22509476222784 run_lib.py:133] step: 715200, training_loss: 4.20494e-02
I0213 00:11:19.995557 22509476222784 run_lib.py:146] step: 715200, eval_loss: 4.56422e-02
I0213 00:11:38.546845 22509476222784 run_lib.py:133] step: 715250, training_loss: 3.86179e-02
I0213 00:11:57.291975 22509476222784 run_lib.py:133] step: 715300, training_loss: 4.94650e-02
I0213 00:11:57.467911 22509476222784 run_lib.py:146] step: 715300, eval_loss: 3.57852e-02
I0213 00:12:16.040105 22509476222784 run_lib.py:133] step: 715350, training_loss: 4.89179e-02
I0213 00:12:34.780103 22509476222784 run_lib.py:133] step: 715400, training_loss: 4.42653e-02
I0213 00:12:34.954680 22509476222784 run_lib.py:146] step: 715400, eval_loss: 4.24140e-02
I0213 00:12:53.496049 22509476222784 run_lib.py:133] step: 715450, training_loss: 4.68286e-02
I0213 00:13:12.034598 22509476222784 run_lib.py:133] step: 715500, training_loss: 4.03618e-02
I0213 00:13:12.207700 22509476222784 run_lib.py:146] step: 715500, eval_loss: 4.98522e-02
I0213 00:13:30.788290 22509476222784 run_lib.py:133] step: 715550, training_loss: 4.79313e-02
I0213 00:13:49.561315 22509476222784 run_lib.py:133] step: 715600, training_loss: 4.87318e-02
I0213 00:13:49.724972 22509476222784 run_lib.py:146] step: 715600, eval_loss: 2.53285e-02
I0213 00:14:08.295874 22509476222784 run_lib.py:133] step: 715650, training_loss: 4.84957e-02
I0213 00:14:26.878426 22509476222784 run_lib.py:133] step: 715700, training_loss: 4.48366e-02
I0213 00:14:27.039696 22509476222784 run_lib.py:146] step: 715700, eval_loss: 3.90868e-02
I0213 00:14:45.725783 22509476222784 run_lib.py:133] step: 715750, training_loss: 3.85728e-02
I0213 00:15:04.361348 22509476222784 run_lib.py:133] step: 715800, training_loss: 4.29168e-02
I0213 00:15:04.569664 22509476222784 run_lib.py:146] step: 715800, eval_loss: 4.07911e-02
I0213 00:15:23.297623 22509476222784 run_lib.py:133] step: 715850, training_loss: 4.63993e-02
I0213 00:15:41.893848 22509476222784 run_lib.py:133] step: 715900, training_loss: 3.91552e-02
I0213 00:15:42.061297 22509476222784 run_lib.py:146] step: 715900, eval_loss: 4.54774e-02
I0213 00:16:00.608467 22509476222784 run_lib.py:133] step: 715950, training_loss: 3.98099e-02
I0213 00:16:19.216897 22509476222784 run_lib.py:133] step: 716000, training_loss: 4.19392e-02
I0213 00:16:19.380792 22509476222784 run_lib.py:146] step: 716000, eval_loss: 3.63175e-02
I0213 00:16:38.041449 22509476222784 run_lib.py:133] step: 716050, training_loss: 4.50981e-02
I0213 00:16:56.823842 22509476222784 run_lib.py:133] step: 716100, training_loss: 4.96281e-02
I0213 00:16:57.009904 22509476222784 run_lib.py:146] step: 716100, eval_loss: 3.81562e-02
I0213 00:17:15.560766 22509476222784 run_lib.py:133] step: 716150, training_loss: 3.80987e-02
I0213 00:17:34.190715 22509476222784 run_lib.py:133] step: 716200, training_loss: 3.21004e-02
I0213 00:17:34.385737 22509476222784 run_lib.py:146] step: 716200, eval_loss: 3.84314e-02
I0213 00:17:53.038460 22509476222784 run_lib.py:133] step: 716250, training_loss: 3.24435e-02
I0213 00:18:11.556690 22509476222784 run_lib.py:133] step: 716300, training_loss: 4.26749e-02
I0213 00:18:11.721803 22509476222784 run_lib.py:146] step: 716300, eval_loss: 4.04482e-02
I0213 00:18:30.474889 22509476222784 run_lib.py:133] step: 716350, training_loss: 2.75318e-02
I0213 00:18:49.063820 22509476222784 run_lib.py:133] step: 716400, training_loss: 3.48841e-02
I0213 00:18:49.264902 22509476222784 run_lib.py:146] step: 716400, eval_loss: 3.84377e-02
I0213 00:19:07.934146 22509476222784 run_lib.py:133] step: 716450, training_loss: 3.29650e-02
I0213 00:19:26.468326 22509476222784 run_lib.py:133] step: 716500, training_loss: 5.54205e-02
I0213 00:19:26.634477 22509476222784 run_lib.py:146] step: 716500, eval_loss: 5.02452e-02
I0213 00:19:45.361087 22509476222784 run_lib.py:133] step: 716550, training_loss: 3.43884e-02
I0213 00:20:04.004489 22509476222784 run_lib.py:133] step: 716600, training_loss: 4.25133e-02
I0213 00:20:04.176650 22509476222784 run_lib.py:146] step: 716600, eval_loss: 5.77267e-02
I0213 00:20:22.838286 22509476222784 run_lib.py:133] step: 716650, training_loss: 5.96417e-02
I0213 00:20:41.607272 22509476222784 run_lib.py:133] step: 716700, training_loss: 4.42910e-02
I0213 00:20:41.775746 22509476222784 run_lib.py:146] step: 716700, eval_loss: 4.13806e-02
I0213 00:21:00.286945 22509476222784 run_lib.py:133] step: 716750, training_loss: 4.63163e-02
I0213 00:21:18.859925 22509476222784 run_lib.py:133] step: 716800, training_loss: 4.69321e-02
I0213 00:21:19.033875 22509476222784 run_lib.py:146] step: 716800, eval_loss: 3.85140e-02
I0213 00:21:37.716660 22509476222784 run_lib.py:133] step: 716850, training_loss: 4.94014e-02
I0213 00:21:56.535329 22509476222784 run_lib.py:133] step: 716900, training_loss: 4.97461e-02
I0213 00:21:56.705911 22509476222784 run_lib.py:146] step: 716900, eval_loss: 4.79795e-02
I0213 00:22:15.300305 22509476222784 run_lib.py:133] step: 716950, training_loss: 4.29599e-02
I0213 00:22:33.853402 22509476222784 run_lib.py:133] step: 717000, training_loss: 3.15471e-02
I0213 00:22:34.017611 22509476222784 run_lib.py:146] step: 717000, eval_loss: 3.66957e-02
I0213 00:22:52.592483 22509476222784 run_lib.py:133] step: 717050, training_loss: 5.06835e-02
I0213 00:23:11.288715 22509476222784 run_lib.py:133] step: 717100, training_loss: 6.51041e-02
I0213 00:23:11.451082 22509476222784 run_lib.py:146] step: 717100, eval_loss: 4.33146e-02
I0213 00:23:30.057762 22509476222784 run_lib.py:133] step: 717150, training_loss: 4.92303e-02
I0213 00:23:48.735544 22509476222784 run_lib.py:133] step: 717200, training_loss: 3.82465e-02
I0213 00:23:48.910025 22509476222784 run_lib.py:146] step: 717200, eval_loss: 3.71213e-02
I0213 00:24:07.497674 22509476222784 run_lib.py:133] step: 717250, training_loss: 4.01872e-02
I0213 00:24:26.278948 22509476222784 run_lib.py:133] step: 717300, training_loss: 3.88290e-02
I0213 00:24:26.471852 22509476222784 run_lib.py:146] step: 717300, eval_loss: 3.52652e-02
I0213 00:24:45.050805 22509476222784 run_lib.py:133] step: 717350, training_loss: 4.21363e-02
I0213 00:25:03.734522 22509476222784 run_lib.py:133] step: 717400, training_loss: 3.67788e-02
I0213 00:25:03.924810 22509476222784 run_lib.py:146] step: 717400, eval_loss: 4.84365e-02
I0213 00:25:22.500063 22509476222784 run_lib.py:133] step: 717450, training_loss: 5.90494e-02
I0213 00:25:41.043812 22509476222784 run_lib.py:133] step: 717500, training_loss: 3.98103e-02
I0213 00:25:41.249620 22509476222784 run_lib.py:146] step: 717500, eval_loss: 3.68424e-02
I0213 00:26:00.036333 22509476222784 run_lib.py:133] step: 717550, training_loss: 4.38819e-02
I0213 00:26:18.687387 22509476222784 run_lib.py:133] step: 717600, training_loss: 3.15545e-02
I0213 00:26:18.899797 22509476222784 run_lib.py:146] step: 717600, eval_loss: 4.37288e-02
I0213 00:26:37.462760 22509476222784 run_lib.py:133] step: 717650, training_loss: 3.35058e-02
I0213 00:26:56.074930 22509476222784 run_lib.py:133] step: 717700, training_loss: 4.99160e-02
I0213 00:26:56.276685 22509476222784 run_lib.py:146] step: 717700, eval_loss: 4.39297e-02
I0213 00:27:15.072518 22509476222784 run_lib.py:133] step: 717750, training_loss: 4.54076e-02
I0213 00:27:33.652865 22509476222784 run_lib.py:133] step: 717800, training_loss: 2.83916e-02
I0213 00:27:33.866863 22509476222784 run_lib.py:146] step: 717800, eval_loss: 5.35070e-02
I0213 00:27:52.567782 22509476222784 run_lib.py:133] step: 717850, training_loss: 4.80678e-02
I0213 00:28:11.079894 22509476222784 run_lib.py:133] step: 717900, training_loss: 4.46155e-02
I0213 00:28:11.246426 22509476222784 run_lib.py:146] step: 717900, eval_loss: 4.50551e-02
I0213 00:28:29.960923 22509476222784 run_lib.py:133] step: 717950, training_loss: 3.22693e-02
I0213 00:28:48.591707 22509476222784 run_lib.py:133] step: 718000, training_loss: 4.39936e-02
I0213 00:28:48.755867 22509476222784 run_lib.py:146] step: 718000, eval_loss: 4.77004e-02
I0213 00:29:07.358191 22509476222784 run_lib.py:133] step: 718050, training_loss: 4.22277e-02
I0213 00:29:26.109470 22509476222784 run_lib.py:133] step: 718100, training_loss: 4.58112e-02
I0213 00:29:26.312621 22509476222784 run_lib.py:146] step: 718100, eval_loss: 4.76475e-02
I0213 00:29:44.904722 22509476222784 run_lib.py:133] step: 718150, training_loss: 4.36185e-02
I0213 00:30:03.644124 22509476222784 run_lib.py:133] step: 718200, training_loss: 3.74963e-02
I0213 00:30:03.824641 22509476222784 run_lib.py:146] step: 718200, eval_loss: 4.12511e-02
I0213 00:30:22.378799 22509476222784 run_lib.py:133] step: 718250, training_loss: 3.74229e-02
I0213 00:30:40.962061 22509476222784 run_lib.py:133] step: 718300, training_loss: 3.67533e-02
I0213 00:30:41.127711 22509476222784 run_lib.py:146] step: 718300, eval_loss: 5.55258e-02
I0213 00:30:59.864489 22509476222784 run_lib.py:133] step: 718350, training_loss: 3.52250e-02
I0213 00:31:18.380671 22509476222784 run_lib.py:133] step: 718400, training_loss: 3.27068e-02
I0213 00:31:18.547845 22509476222784 run_lib.py:146] step: 718400, eval_loss: 5.49651e-02
I0213 00:31:37.082026 22509476222784 run_lib.py:133] step: 718450, training_loss: 4.37627e-02
I0213 00:31:55.882799 22509476222784 run_lib.py:133] step: 718500, training_loss: 3.50334e-02
I0213 00:31:56.092303 22509476222784 run_lib.py:146] step: 718500, eval_loss: 5.39682e-02
I0213 00:32:14.700444 22509476222784 run_lib.py:133] step: 718550, training_loss: 3.80156e-02
I0213 00:32:33.239241 22509476222784 run_lib.py:133] step: 718600, training_loss: 4.09828e-02
I0213 00:32:33.427739 22509476222784 run_lib.py:146] step: 718600, eval_loss: 3.40207e-02
I0213 00:32:52.036881 22509476222784 run_lib.py:133] step: 718650, training_loss: 4.29669e-02
I0213 00:33:10.561758 22509476222784 run_lib.py:133] step: 718700, training_loss: 3.60231e-02
I0213 00:33:10.772687 22509476222784 run_lib.py:146] step: 718700, eval_loss: 3.58000e-02
I0213 00:33:29.360723 22509476222784 run_lib.py:133] step: 718750, training_loss: 3.88844e-02
I0213 00:33:47.956477 22509476222784 run_lib.py:133] step: 718800, training_loss: 4.19693e-02
I0213 00:33:48.150968 22509476222784 run_lib.py:146] step: 718800, eval_loss: 4.13566e-02
I0213 00:34:06.919520 22509476222784 run_lib.py:133] step: 718850, training_loss: 4.32667e-02
I0213 00:34:25.544223 22509476222784 run_lib.py:133] step: 718900, training_loss: 3.16874e-02
I0213 00:34:25.725564 22509476222784 run_lib.py:146] step: 718900, eval_loss: 4.72979e-02
I0213 00:34:44.285604 22509476222784 run_lib.py:133] step: 718950, training_loss: 2.78760e-02
I0213 00:35:02.937365 22509476222784 run_lib.py:133] step: 719000, training_loss: 5.50941e-02
I0213 00:35:03.146826 22509476222784 run_lib.py:146] step: 719000, eval_loss: 3.71720e-02
I0213 00:35:21.964936 22509476222784 run_lib.py:133] step: 719050, training_loss: 3.81463e-02
I0213 00:35:40.517452 22509476222784 run_lib.py:133] step: 719100, training_loss: 2.83640e-02
I0213 00:35:40.680324 22509476222784 run_lib.py:146] step: 719100, eval_loss: 3.78043e-02
I0213 00:35:59.383040 22509476222784 run_lib.py:133] step: 719150, training_loss: 3.73300e-02
I0213 00:36:17.934999 22509476222784 run_lib.py:133] step: 719200, training_loss: 4.07262e-02
I0213 00:36:18.103945 22509476222784 run_lib.py:146] step: 719200, eval_loss: 5.23105e-02
I0213 00:36:36.796275 22509476222784 run_lib.py:133] step: 719250, training_loss: 4.09550e-02
I0213 00:36:55.362266 22509476222784 run_lib.py:133] step: 719300, training_loss: 6.48808e-02
I0213 00:36:55.527903 22509476222784 run_lib.py:146] step: 719300, eval_loss: 3.95430e-02
I0213 00:37:14.234316 22509476222784 run_lib.py:133] step: 719350, training_loss: 4.47938e-02
I0213 00:37:32.737880 22509476222784 run_lib.py:133] step: 719400, training_loss: 4.30261e-02
I0213 00:37:32.901721 22509476222784 run_lib.py:146] step: 719400, eval_loss: 4.77954e-02
I0213 00:37:51.449699 22509476222784 run_lib.py:133] step: 719450, training_loss: 4.69270e-02
I0213 00:38:10.205954 22509476222784 run_lib.py:133] step: 719500, training_loss: 3.65154e-02
I0213 00:38:10.370968 22509476222784 run_lib.py:146] step: 719500, eval_loss: 4.77897e-02
I0213 00:38:28.993757 22509476222784 run_lib.py:133] step: 719550, training_loss: 4.79799e-02
I0213 00:38:47.568457 22509476222784 run_lib.py:133] step: 719600, training_loss: 3.94123e-02
I0213 00:38:47.735812 22509476222784 run_lib.py:146] step: 719600, eval_loss: 3.65773e-02
I0213 00:39:06.449048 22509476222784 run_lib.py:133] step: 719650, training_loss: 4.37021e-02
I0213 00:39:24.963700 22509476222784 run_lib.py:133] step: 719700, training_loss: 2.88986e-02
I0213 00:39:25.128927 22509476222784 run_lib.py:146] step: 719700, eval_loss: 3.69672e-02
I0213 00:39:43.836496 22509476222784 run_lib.py:133] step: 719750, training_loss: 4.20444e-02
I0213 00:40:02.490826 22509476222784 run_lib.py:133] step: 719800, training_loss: 6.24857e-02
I0213 00:40:02.654769 22509476222784 run_lib.py:146] step: 719800, eval_loss: 2.50233e-02
I0213 00:40:21.238223 22509476222784 run_lib.py:133] step: 719850, training_loss: 3.90448e-02
I0213 00:40:40.048169 22509476222784 run_lib.py:133] step: 719900, training_loss: 4.54475e-02
I0213 00:40:40.210713 22509476222784 run_lib.py:146] step: 719900, eval_loss: 3.17062e-02
I0213 00:40:58.719945 22509476222784 run_lib.py:133] step: 719950, training_loss: 3.11224e-02
I0213 00:41:17.262006 22509476222784 run_lib.py:133] step: 720000, training_loss: 4.26844e-02
I0213 00:41:18.040592 22509476222784 run_lib.py:146] step: 720000, eval_loss: 3.62508e-02
I0213 00:41:39.306066 22509476222784 run_lib.py:133] step: 720050, training_loss: 3.81274e-02
I0213 00:41:57.935519 22509476222784 run_lib.py:133] step: 720100, training_loss: 5.27575e-02
I0213 00:41:58.129953 22509476222784 run_lib.py:146] step: 720100, eval_loss: 3.63420e-02
I0213 00:42:16.856538 22509476222784 run_lib.py:133] step: 720150, training_loss: 4.25552e-02
I0213 00:42:35.420661 22509476222784 run_lib.py:133] step: 720200, training_loss: 4.13779e-02
I0213 00:42:35.653916 22509476222784 run_lib.py:146] step: 720200, eval_loss: 3.45527e-02
I0213 00:42:54.253801 22509476222784 run_lib.py:133] step: 720250, training_loss: 4.20264e-02
I0213 00:43:12.790937 22509476222784 run_lib.py:133] step: 720300, training_loss: 5.57540e-02
I0213 00:43:12.968755 22509476222784 run_lib.py:146] step: 720300, eval_loss: 3.68504e-02
I0213 00:43:31.539602 22509476222784 run_lib.py:133] step: 720350, training_loss: 3.90416e-02
I0213 00:43:50.176749 22509476222784 run_lib.py:133] step: 720400, training_loss: 3.61424e-02
I0213 00:43:50.341921 22509476222784 run_lib.py:146] step: 720400, eval_loss: 3.98237e-02
I0213 00:44:09.064462 22509476222784 run_lib.py:133] step: 720450, training_loss: 3.29159e-02
I0213 00:44:27.724381 22509476222784 run_lib.py:133] step: 720500, training_loss: 4.15572e-02
I0213 00:44:27.904693 22509476222784 run_lib.py:146] step: 720500, eval_loss: 5.28405e-02
I0213 00:44:46.475986 22509476222784 run_lib.py:133] step: 720550, training_loss: 4.20790e-02
I0213 00:45:05.080854 22509476222784 run_lib.py:133] step: 720600, training_loss: 4.10799e-02
I0213 00:45:05.304421 22509476222784 run_lib.py:146] step: 720600, eval_loss: 4.22262e-02
I0213 00:45:24.064998 22509476222784 run_lib.py:133] step: 720650, training_loss: 3.05447e-02
I0213 00:45:42.708876 22509476222784 run_lib.py:133] step: 720700, training_loss: 4.16157e-02
I0213 00:45:42.899959 22509476222784 run_lib.py:146] step: 720700, eval_loss: 4.82212e-02
I0213 00:46:01.599379 22509476222784 run_lib.py:133] step: 720750, training_loss: 3.87602e-02
I0213 00:46:20.146632 22509476222784 run_lib.py:133] step: 720800, training_loss: 3.63162e-02
I0213 00:46:20.312675 22509476222784 run_lib.py:146] step: 720800, eval_loss: 4.11420e-02
I0213 00:46:39.036062 22509476222784 run_lib.py:133] step: 720850, training_loss: 6.32626e-02
I0213 00:46:57.635954 22509476222784 run_lib.py:133] step: 720900, training_loss: 5.42176e-02
I0213 00:46:57.800020 22509476222784 run_lib.py:146] step: 720900, eval_loss: 3.81799e-02
I0213 00:47:16.508324 22509476222784 run_lib.py:133] step: 720950, training_loss: 3.50575e-02
I0213 00:47:35.039187 22509476222784 run_lib.py:133] step: 721000, training_loss: 2.98207e-02
I0213 00:47:35.200077 22509476222784 run_lib.py:146] step: 721000, eval_loss: 3.26541e-02
I0213 00:47:53.698754 22509476222784 run_lib.py:133] step: 721050, training_loss: 5.65932e-02
I0213 00:48:12.368585 22509476222784 run_lib.py:133] step: 721100, training_loss: 4.42194e-02
I0213 00:48:12.549813 22509476222784 run_lib.py:146] step: 721100, eval_loss: 3.77549e-02
I0213 00:48:31.107154 22509476222784 run_lib.py:133] step: 721150, training_loss: 4.02568e-02
I0213 00:48:49.708225 22509476222784 run_lib.py:133] step: 721200, training_loss: 2.56997e-02
I0213 00:48:49.901839 22509476222784 run_lib.py:146] step: 721200, eval_loss: 3.72011e-02
I0213 00:49:08.660389 22509476222784 run_lib.py:133] step: 721250, training_loss: 4.34936e-02
I0213 00:49:27.341657 22509476222784 run_lib.py:133] step: 721300, training_loss: 5.18262e-02
I0213 00:49:27.508795 22509476222784 run_lib.py:146] step: 721300, eval_loss: 5.79990e-02
I0213 00:49:46.070824 22509476222784 run_lib.py:133] step: 721350, training_loss: 4.19658e-02
I0213 00:50:04.680203 22509476222784 run_lib.py:133] step: 721400, training_loss: 5.35379e-02
I0213 00:50:04.843508 22509476222784 run_lib.py:146] step: 721400, eval_loss: 5.86626e-02
I0213 00:50:23.447573 22509476222784 run_lib.py:133] step: 721450, training_loss: 3.44270e-02
I0213 00:50:42.194079 22509476222784 run_lib.py:133] step: 721500, training_loss: 5.34109e-02
I0213 00:50:42.355891 22509476222784 run_lib.py:146] step: 721500, eval_loss: 4.24637e-02
I0213 00:51:00.865126 22509476222784 run_lib.py:133] step: 721550, training_loss: 4.72360e-02
I0213 00:51:19.414855 22509476222784 run_lib.py:133] step: 721600, training_loss: 4.50618e-02
I0213 00:51:19.804573 22509476222784 run_lib.py:146] step: 721600, eval_loss: 4.84406e-02
I0213 00:51:38.428257 22509476222784 run_lib.py:133] step: 721650, training_loss: 2.96419e-02
I0213 00:51:57.182097 22509476222784 run_lib.py:133] step: 721700, training_loss: 2.88669e-02
I0213 00:51:57.346808 22509476222784 run_lib.py:146] step: 721700, eval_loss: 4.86641e-02
I0213 00:52:15.856319 22509476222784 run_lib.py:133] step: 721750, training_loss: 4.28539e-02
I0213 00:52:34.450723 22509476222784 run_lib.py:133] step: 721800, training_loss: 4.46965e-02
I0213 00:52:34.614051 22509476222784 run_lib.py:146] step: 721800, eval_loss: 5.12707e-02
I0213 00:52:53.106209 22509476222784 run_lib.py:133] step: 721850, training_loss: 4.24789e-02
I0213 00:53:11.706479 22509476222784 run_lib.py:133] step: 721900, training_loss: 4.79296e-02
I0213 00:53:11.869988 22509476222784 run_lib.py:146] step: 721900, eval_loss: 5.06941e-02
I0213 00:53:30.633870 22509476222784 run_lib.py:133] step: 721950, training_loss: 4.43498e-02
I0213 00:53:49.203852 22509476222784 run_lib.py:133] step: 722000, training_loss: 5.16326e-02
I0213 00:53:49.391948 22509476222784 run_lib.py:146] step: 722000, eval_loss: 3.41354e-02
I0213 00:54:07.993285 22509476222784 run_lib.py:133] step: 722050, training_loss: 3.34781e-02
I0213 00:54:26.594472 22509476222784 run_lib.py:133] step: 722100, training_loss: 4.21098e-02
I0213 00:54:26.763960 22509476222784 run_lib.py:146] step: 722100, eval_loss: 4.27125e-02
I0213 00:54:45.473001 22509476222784 run_lib.py:133] step: 722150, training_loss: 4.45205e-02
I0213 00:55:04.082943 22509476222784 run_lib.py:133] step: 722200, training_loss: 3.85122e-02
I0213 00:55:04.271930 22509476222784 run_lib.py:146] step: 722200, eval_loss: 5.62670e-02
I0213 00:55:23.030750 22509476222784 run_lib.py:133] step: 722250, training_loss: 2.92483e-02
I0213 00:55:41.549615 22509476222784 run_lib.py:133] step: 722300, training_loss: 3.24479e-02
I0213 00:55:41.730715 22509476222784 run_lib.py:146] step: 722300, eval_loss: 3.87060e-02
I0213 00:56:00.380478 22509476222784 run_lib.py:133] step: 722350, training_loss: 3.99684e-02
I0213 00:56:18.958595 22509476222784 run_lib.py:133] step: 722400, training_loss: 4.46124e-02
I0213 00:56:19.122909 22509476222784 run_lib.py:146] step: 722400, eval_loss: 3.98498e-02
I0213 00:56:37.784064 22509476222784 run_lib.py:133] step: 722450, training_loss: 3.87908e-02
I0213 00:56:56.565037 22509476222784 run_lib.py:133] step: 722500, training_loss: 3.74103e-02
I0213 00:56:56.729735 22509476222784 run_lib.py:146] step: 722500, eval_loss: 4.70106e-02
I0213 00:57:15.243158 22509476222784 run_lib.py:133] step: 722550, training_loss: 2.75570e-02
I0213 00:57:33.926644 22509476222784 run_lib.py:133] step: 722600, training_loss: 5.63424e-02
I0213 00:57:34.147900 22509476222784 run_lib.py:146] step: 722600, eval_loss: 4.91205e-02
I0213 00:57:52.680788 22509476222784 run_lib.py:133] step: 722650, training_loss: 5.13958e-02
I0213 00:58:11.294692 22509476222784 run_lib.py:133] step: 722700, training_loss: 4.97634e-02
I0213 00:58:11.500133 22509476222784 run_lib.py:146] step: 722700, eval_loss: 4.54153e-02
I0213 00:58:30.235806 22509476222784 run_lib.py:133] step: 722750, training_loss: 3.88719e-02
I0213 00:58:48.741719 22509476222784 run_lib.py:133] step: 722800, training_loss: 4.17695e-02
I0213 00:58:48.905645 22509476222784 run_lib.py:146] step: 722800, eval_loss: 4.52523e-02
I0213 00:59:07.434595 22509476222784 run_lib.py:133] step: 722850, training_loss: 4.63530e-02
I0213 00:59:26.120205 22509476222784 run_lib.py:133] step: 722900, training_loss: 4.01613e-02
I0213 00:59:26.321943 22509476222784 run_lib.py:146] step: 722900, eval_loss: 4.28939e-02
I0213 00:59:44.888695 22509476222784 run_lib.py:133] step: 722950, training_loss: 4.03864e-02
I0213 01:00:03.390331 22509476222784 run_lib.py:133] step: 723000, training_loss: 3.66794e-02
I0213 01:00:03.555539 22509476222784 run_lib.py:146] step: 723000, eval_loss: 3.34162e-02
I0213 01:00:22.220729 22509476222784 run_lib.py:133] step: 723050, training_loss: 3.04049e-02
I0213 01:00:40.800953 22509476222784 run_lib.py:133] step: 723100, training_loss: 3.99745e-02
I0213 01:00:40.996017 22509476222784 run_lib.py:146] step: 723100, eval_loss: 4.45400e-02
I0213 01:00:59.579623 22509476222784 run_lib.py:133] step: 723150, training_loss: 3.63270e-02
I0213 01:01:18.316918 22509476222784 run_lib.py:133] step: 723200, training_loss: 4.91259e-02
I0213 01:01:18.511530 22509476222784 run_lib.py:146] step: 723200, eval_loss: 3.40906e-02
I0213 01:01:37.228097 22509476222784 run_lib.py:133] step: 723250, training_loss: 3.64665e-02
I0213 01:01:55.820046 22509476222784 run_lib.py:133] step: 723300, training_loss: 5.00626e-02
I0213 01:01:56.027886 22509476222784 run_lib.py:146] step: 723300, eval_loss: 3.80594e-02
I0213 01:02:14.570173 22509476222784 run_lib.py:133] step: 723350, training_loss: 5.16007e-02
I0213 01:02:33.159183 22509476222784 run_lib.py:133] step: 723400, training_loss: 5.26230e-02
I0213 01:02:33.336489 22509476222784 run_lib.py:146] step: 723400, eval_loss: 4.19999e-02
I0213 01:02:52.108441 22509476222784 run_lib.py:133] step: 723450, training_loss: 3.88743e-02
I0213 01:03:10.662866 22509476222784 run_lib.py:133] step: 723500, training_loss: 3.41144e-02
I0213 01:03:10.828774 22509476222784 run_lib.py:146] step: 723500, eval_loss: 4.56274e-02
I0213 01:03:29.522579 22509476222784 run_lib.py:133] step: 723550, training_loss: 4.87696e-02
I0213 01:03:48.048131 22509476222784 run_lib.py:133] step: 723600, training_loss: 4.56308e-02
I0213 01:03:48.212615 22509476222784 run_lib.py:146] step: 723600, eval_loss: 4.08516e-02
I0213 01:04:06.911479 22509476222784 run_lib.py:133] step: 723650, training_loss: 4.28115e-02
I0213 01:04:25.539595 22509476222784 run_lib.py:133] step: 723700, training_loss: 3.82347e-02
I0213 01:04:25.704389 22509476222784 run_lib.py:146] step: 723700, eval_loss: 4.74385e-02
I0213 01:04:44.458189 22509476222784 run_lib.py:133] step: 723750, training_loss: 3.70558e-02
I0213 01:05:03.007432 22509476222784 run_lib.py:133] step: 723800, training_loss: 5.53173e-02
I0213 01:05:03.176455 22509476222784 run_lib.py:146] step: 723800, eval_loss: 5.03370e-02
I0213 01:05:21.720466 22509476222784 run_lib.py:133] step: 723850, training_loss: 4.19267e-02
I0213 01:05:40.429212 22509476222784 run_lib.py:133] step: 723900, training_loss: 4.56597e-02
I0213 01:05:40.595909 22509476222784 run_lib.py:146] step: 723900, eval_loss: 3.83458e-02
I0213 01:05:59.145305 22509476222784 run_lib.py:133] step: 723950, training_loss: 3.51842e-02
I0213 01:06:17.771451 22509476222784 run_lib.py:133] step: 724000, training_loss: 4.35206e-02
I0213 01:06:17.937612 22509476222784 run_lib.py:146] step: 724000, eval_loss: 3.88368e-02
I0213 01:06:36.699032 22509476222784 run_lib.py:133] step: 724050, training_loss: 4.08516e-02
I0213 01:06:55.291357 22509476222784 run_lib.py:133] step: 724100, training_loss: 3.92696e-02
I0213 01:06:55.455623 22509476222784 run_lib.py:146] step: 724100, eval_loss: 4.56113e-02
I0213 01:07:14.138303 22509476222784 run_lib.py:133] step: 724150, training_loss: 3.37887e-02
I0213 01:07:32.789377 22509476222784 run_lib.py:133] step: 724200, training_loss: 4.15292e-02
I0213 01:07:32.954030 22509476222784 run_lib.py:146] step: 724200, eval_loss: 4.13702e-02
I0213 01:07:51.540259 22509476222784 run_lib.py:133] step: 724250, training_loss: 4.42145e-02
I0213 01:08:10.298937 22509476222784 run_lib.py:133] step: 724300, training_loss: 4.28151e-02
I0213 01:08:10.472713 22509476222784 run_lib.py:146] step: 724300, eval_loss: 3.93045e-02
I0213 01:08:29.020861 22509476222784 run_lib.py:133] step: 724350, training_loss: 2.81219e-02
I0213 01:08:47.576965 22509476222784 run_lib.py:133] step: 724400, training_loss: 3.66330e-02
I0213 01:08:47.741690 22509476222784 run_lib.py:146] step: 724400, eval_loss: 3.87841e-02
I0213 01:09:06.288657 22509476222784 run_lib.py:133] step: 724450, training_loss: 4.91165e-02
I0213 01:09:25.087736 22509476222784 run_lib.py:133] step: 724500, training_loss: 3.11830e-02
I0213 01:09:25.278796 22509476222784 run_lib.py:146] step: 724500, eval_loss: 3.09196e-02
I0213 01:09:43.845480 22509476222784 run_lib.py:133] step: 724550, training_loss: 4.34109e-02
I0213 01:10:02.510848 22509476222784 run_lib.py:133] step: 724600, training_loss: 3.46222e-02
I0213 01:10:02.695636 22509476222784 run_lib.py:146] step: 724600, eval_loss: 5.91717e-02
I0213 01:10:21.240523 22509476222784 run_lib.py:133] step: 724650, training_loss: 5.03558e-02
I0213 01:10:39.865707 22509476222784 run_lib.py:133] step: 724700, training_loss: 2.81197e-02
I0213 01:10:40.069861 22509476222784 run_lib.py:146] step: 724700, eval_loss: 2.92118e-02
I0213 01:10:58.825283 22509476222784 run_lib.py:133] step: 724750, training_loss: 3.01206e-02
I0213 01:11:17.467710 22509476222784 run_lib.py:133] step: 724800, training_loss: 2.66105e-02
I0213 01:11:17.630788 22509476222784 run_lib.py:146] step: 724800, eval_loss: 3.49678e-02
I0213 01:11:36.188223 22509476222784 run_lib.py:133] step: 724850, training_loss: 4.73871e-02
I0213 01:11:54.750278 22509476222784 run_lib.py:133] step: 724900, training_loss: 3.65841e-02
I0213 01:11:54.918255 22509476222784 run_lib.py:146] step: 724900, eval_loss: 4.42599e-02
I0213 01:12:13.595669 22509476222784 run_lib.py:133] step: 724950, training_loss: 4.39980e-02
I0213 01:12:32.223152 22509476222784 run_lib.py:133] step: 725000, training_loss: 2.65971e-02
I0213 01:12:32.389003 22509476222784 run_lib.py:146] step: 725000, eval_loss: 3.91350e-02
I0213 01:12:51.172893 22509476222784 run_lib.py:133] step: 725050, training_loss: 4.49410e-02
I0213 01:13:09.738079 22509476222784 run_lib.py:133] step: 725100, training_loss: 3.72316e-02
I0213 01:13:09.908925 22509476222784 run_lib.py:146] step: 725100, eval_loss: 4.38136e-02
I0213 01:13:28.583397 22509476222784 run_lib.py:133] step: 725150, training_loss: 5.19959e-02
I0213 01:13:47.118550 22509476222784 run_lib.py:133] step: 725200, training_loss: 5.28138e-02
I0213 01:13:47.280675 22509476222784 run_lib.py:146] step: 725200, eval_loss: 4.32173e-02
I0213 01:14:05.855040 22509476222784 run_lib.py:133] step: 725250, training_loss: 4.90391e-02
I0213 01:14:24.599711 22509476222784 run_lib.py:133] step: 725300, training_loss: 3.21888e-02
I0213 01:14:24.799122 22509476222784 run_lib.py:146] step: 725300, eval_loss: 3.74181e-02
I0213 01:14:43.345719 22509476222784 run_lib.py:133] step: 725350, training_loss: 4.35921e-02
I0213 01:15:02.085012 22509476222784 run_lib.py:133] step: 725400, training_loss: 4.39312e-02
I0213 01:15:02.284855 22509476222784 run_lib.py:146] step: 725400, eval_loss: 4.32435e-02
I0213 01:15:20.824432 22509476222784 run_lib.py:133] step: 725450, training_loss: 5.08119e-02
I0213 01:15:39.437581 22509476222784 run_lib.py:133] step: 725500, training_loss: 4.11842e-02
I0213 01:15:39.617913 22509476222784 run_lib.py:146] step: 725500, eval_loss: 4.14682e-02
I0213 01:15:58.377120 22509476222784 run_lib.py:133] step: 725550, training_loss: 4.85045e-02
I0213 01:16:16.919580 22509476222784 run_lib.py:133] step: 725600, training_loss: 4.92556e-02
I0213 01:16:17.104957 22509476222784 run_lib.py:146] step: 725600, eval_loss: 4.24201e-02
I0213 01:16:35.678560 22509476222784 run_lib.py:133] step: 725650, training_loss: 4.24933e-02
I0213 01:16:54.384104 22509476222784 run_lib.py:133] step: 725700, training_loss: 2.80848e-02
I0213 01:16:54.544751 22509476222784 run_lib.py:146] step: 725700, eval_loss: 4.01729e-02
I0213 01:17:13.123703 22509476222784 run_lib.py:133] step: 725750, training_loss: 4.07674e-02
I0213 01:17:31.635666 22509476222784 run_lib.py:133] step: 725800, training_loss: 3.71946e-02
I0213 01:17:32.027752 22509476222784 run_lib.py:146] step: 725800, eval_loss: 4.33723e-02
I0213 01:17:50.595764 22509476222784 run_lib.py:133] step: 725850, training_loss: 4.42182e-02
I0213 01:18:09.102953 22509476222784 run_lib.py:133] step: 725900, training_loss: 4.36110e-02
I0213 01:18:09.314069 22509476222784 run_lib.py:146] step: 725900, eval_loss: 3.78358e-02
I0213 01:18:27.875231 22509476222784 run_lib.py:133] step: 725950, training_loss: 4.72614e-02
I0213 01:18:46.339029 22509476222784 run_lib.py:133] step: 726000, training_loss: 4.84722e-02
I0213 01:18:46.512736 22509476222784 run_lib.py:146] step: 726000, eval_loss: 4.51402e-02
I0213 01:19:05.226464 22509476222784 run_lib.py:133] step: 726050, training_loss: 4.12277e-02
I0213 01:19:23.953658 22509476222784 run_lib.py:133] step: 726100, training_loss: 4.28590e-02
I0213 01:19:24.122889 22509476222784 run_lib.py:146] step: 726100, eval_loss: 4.62344e-02
I0213 01:19:42.723016 22509476222784 run_lib.py:133] step: 726150, training_loss: 3.79079e-02
I0213 01:20:01.249771 22509476222784 run_lib.py:133] step: 726200, training_loss: 3.99668e-02
I0213 01:20:01.413641 22509476222784 run_lib.py:146] step: 726200, eval_loss: 4.53208e-02
I0213 01:20:20.138590 22509476222784 run_lib.py:133] step: 726250, training_loss: 3.27459e-02
I0213 01:20:38.828132 22509476222784 run_lib.py:133] step: 726300, training_loss: 3.29485e-02
I0213 01:20:38.997368 22509476222784 run_lib.py:146] step: 726300, eval_loss: 4.68373e-02
I0213 01:20:57.584958 22509476222784 run_lib.py:133] step: 726350, training_loss: 4.11861e-02
I0213 01:21:16.131573 22509476222784 run_lib.py:133] step: 726400, training_loss: 3.90946e-02
I0213 01:21:16.297809 22509476222784 run_lib.py:146] step: 726400, eval_loss: 5.21013e-02
I0213 01:21:35.001101 22509476222784 run_lib.py:133] step: 726450, training_loss: 4.79620e-02
I0213 01:21:53.518653 22509476222784 run_lib.py:133] step: 726500, training_loss: 4.86411e-02
I0213 01:21:53.690718 22509476222784 run_lib.py:146] step: 726500, eval_loss: 4.32382e-02
I0213 01:22:12.371843 22509476222784 run_lib.py:133] step: 726550, training_loss: 4.64638e-02
I0213 01:22:30.888110 22509476222784 run_lib.py:133] step: 726600, training_loss: 5.70873e-02
I0213 01:22:31.049651 22509476222784 run_lib.py:146] step: 726600, eval_loss: 4.31299e-02
I0213 01:22:49.775407 22509476222784 run_lib.py:133] step: 726650, training_loss: 3.07595e-02
I0213 01:23:08.312586 22509476222784 run_lib.py:133] step: 726700, training_loss: 3.34814e-02
I0213 01:23:08.477742 22509476222784 run_lib.py:146] step: 726700, eval_loss: 4.91148e-02
I0213 01:23:26.977257 22509476222784 run_lib.py:133] step: 726750, training_loss: 4.26733e-02
I0213 01:23:45.640848 22509476222784 run_lib.py:133] step: 726800, training_loss: 4.16078e-02
I0213 01:23:45.822934 22509476222784 run_lib.py:146] step: 726800, eval_loss: 4.39494e-02
I0213 01:24:04.465283 22509476222784 run_lib.py:133] step: 726850, training_loss: 4.52729e-02
I0213 01:24:23.256696 22509476222784 run_lib.py:133] step: 726900, training_loss: 4.42894e-02
I0213 01:24:23.446005 22509476222784 run_lib.py:146] step: 726900, eval_loss: 3.89450e-02
I0213 01:24:42.016587 22509476222784 run_lib.py:133] step: 726950, training_loss: 4.73108e-02
I0213 01:25:00.570460 22509476222784 run_lib.py:133] step: 727000, training_loss: 4.80837e-02
I0213 01:25:00.781795 22509476222784 run_lib.py:146] step: 727000, eval_loss: 3.99638e-02
I0213 01:25:19.352344 22509476222784 run_lib.py:133] step: 727050, training_loss: 4.82568e-02
I0213 01:25:38.089803 22509476222784 run_lib.py:133] step: 727100, training_loss: 4.68436e-02
I0213 01:25:38.253096 22509476222784 run_lib.py:146] step: 727100, eval_loss: 3.99815e-02
I0213 01:25:56.877320 22509476222784 run_lib.py:133] step: 727150, training_loss: 3.79073e-02
I0213 01:26:15.441817 22509476222784 run_lib.py:133] step: 727200, training_loss: 3.26363e-02
I0213 01:26:15.608723 22509476222784 run_lib.py:146] step: 727200, eval_loss: 4.66633e-02
I0213 01:26:34.335470 22509476222784 run_lib.py:133] step: 727250, training_loss: 4.13237e-02
I0213 01:26:52.886878 22509476222784 run_lib.py:133] step: 727300, training_loss: 3.60597e-02
I0213 01:26:53.056030 22509476222784 run_lib.py:146] step: 727300, eval_loss: 3.88449e-02
I0213 01:27:11.717580 22509476222784 run_lib.py:133] step: 727350, training_loss: 3.86088e-02
I0213 01:27:30.303614 22509476222784 run_lib.py:133] step: 727400, training_loss: 5.20670e-02
I0213 01:27:30.491753 22509476222784 run_lib.py:146] step: 727400, eval_loss: 4.49535e-02
I0213 01:27:49.046825 22509476222784 run_lib.py:133] step: 727450, training_loss: 4.79931e-02
I0213 01:28:07.560727 22509476222784 run_lib.py:133] step: 727500, training_loss: 3.91325e-02
I0213 01:28:07.752702 22509476222784 run_lib.py:146] step: 727500, eval_loss: 5.17480e-02
I0213 01:28:26.460820 22509476222784 run_lib.py:133] step: 727550, training_loss: 5.02853e-02
I0213 01:28:45.126902 22509476222784 run_lib.py:133] step: 727600, training_loss: 3.21215e-02
I0213 01:28:45.290966 22509476222784 run_lib.py:146] step: 727600, eval_loss: 4.65365e-02
I0213 01:29:03.898201 22509476222784 run_lib.py:133] step: 727650, training_loss: 4.20771e-02
I0213 01:29:22.436710 22509476222784 run_lib.py:133] step: 727700, training_loss: 2.99928e-02
I0213 01:29:22.600770 22509476222784 run_lib.py:146] step: 727700, eval_loss: 4.84599e-02
I0213 01:29:41.254966 22509476222784 run_lib.py:133] step: 727750, training_loss: 3.95705e-02
I0213 01:29:59.801872 22509476222784 run_lib.py:133] step: 727800, training_loss: 3.30978e-02
I0213 01:29:59.988757 22509476222784 run_lib.py:146] step: 727800, eval_loss: 3.70015e-02
I0213 01:30:18.684910 22509476222784 run_lib.py:133] step: 727850, training_loss: 3.38224e-02
I0213 01:30:37.316559 22509476222784 run_lib.py:133] step: 727900, training_loss: 3.16827e-02
I0213 01:30:37.491929 22509476222784 run_lib.py:146] step: 727900, eval_loss: 3.98908e-02
I0213 01:30:56.192874 22509476222784 run_lib.py:133] step: 727950, training_loss: 3.52055e-02
I0213 01:31:14.799377 22509476222784 run_lib.py:133] step: 728000, training_loss: 4.90935e-02
I0213 01:31:14.968533 22509476222784 run_lib.py:146] step: 728000, eval_loss: 5.46467e-02
I0213 01:31:33.626711 22509476222784 run_lib.py:133] step: 728050, training_loss: 5.58189e-02
I0213 01:31:52.216563 22509476222784 run_lib.py:133] step: 728100, training_loss: 4.43244e-02
I0213 01:31:52.388672 22509476222784 run_lib.py:146] step: 728100, eval_loss: 4.21326e-02
I0213 01:32:11.021736 22509476222784 run_lib.py:133] step: 728150, training_loss: 5.38719e-02
I0213 01:32:29.793281 22509476222784 run_lib.py:133] step: 728200, training_loss: 3.84239e-02
I0213 01:32:29.995777 22509476222784 run_lib.py:146] step: 728200, eval_loss: 4.42416e-02
I0213 01:32:48.557195 22509476222784 run_lib.py:133] step: 728250, training_loss: 4.94591e-02
I0213 01:33:07.127722 22509476222784 run_lib.py:133] step: 728300, training_loss: 4.00642e-02
I0213 01:33:07.331895 22509476222784 run_lib.py:146] step: 728300, eval_loss: 3.73814e-02
I0213 01:33:26.046277 22509476222784 run_lib.py:133] step: 728350, training_loss: 5.38863e-02
I0213 01:33:44.753559 22509476222784 run_lib.py:133] step: 728400, training_loss: 4.08175e-02
I0213 01:33:44.924499 22509476222784 run_lib.py:146] step: 728400, eval_loss: 4.03695e-02
I0213 01:34:03.482862 22509476222784 run_lib.py:133] step: 728450, training_loss: 4.35276e-02
I0213 01:34:22.145593 22509476222784 run_lib.py:133] step: 728500, training_loss: 3.45239e-02
I0213 01:34:22.308529 22509476222784 run_lib.py:146] step: 728500, eval_loss: 4.20141e-02
I0213 01:34:40.810215 22509476222784 run_lib.py:133] step: 728550, training_loss: 4.34939e-02
I0213 01:34:59.616745 22509476222784 run_lib.py:133] step: 728600, training_loss: 4.43134e-02
I0213 01:34:59.828764 22509476222784 run_lib.py:146] step: 728600, eval_loss: 4.21197e-02
I0213 01:35:18.386292 22509476222784 run_lib.py:133] step: 728650, training_loss: 4.92314e-02
I0213 01:35:36.991401 22509476222784 run_lib.py:133] step: 728700, training_loss: 4.63824e-02
I0213 01:35:37.171685 22509476222784 run_lib.py:146] step: 728700, eval_loss: 3.55032e-02
I0213 01:35:55.685392 22509476222784 run_lib.py:133] step: 728750, training_loss: 3.78204e-02
I0213 01:36:14.481736 22509476222784 run_lib.py:133] step: 728800, training_loss: 2.53772e-02
I0213 01:36:14.669940 22509476222784 run_lib.py:146] step: 728800, eval_loss: 4.31843e-02
I0213 01:36:33.233117 22509476222784 run_lib.py:133] step: 728850, training_loss: 4.67733e-02
I0213 01:36:51.801453 22509476222784 run_lib.py:133] step: 728900, training_loss: 4.51415e-02
I0213 01:36:51.968601 22509476222784 run_lib.py:146] step: 728900, eval_loss: 4.30059e-02
I0213 01:37:10.540709 22509476222784 run_lib.py:133] step: 728950, training_loss: 4.77162e-02
I0213 01:37:29.111898 22509476222784 run_lib.py:133] step: 729000, training_loss: 3.80193e-02
I0213 01:37:29.297443 22509476222784 run_lib.py:146] step: 729000, eval_loss: 4.78996e-02
I0213 01:37:48.055124 22509476222784 run_lib.py:133] step: 729050, training_loss: 3.48320e-02
I0213 01:38:06.704772 22509476222784 run_lib.py:133] step: 729100, training_loss: 4.20728e-02
I0213 01:38:06.899669 22509476222784 run_lib.py:146] step: 729100, eval_loss: 3.72404e-02
I0213 01:38:25.411189 22509476222784 run_lib.py:133] step: 729150, training_loss: 6.14598e-02
I0213 01:38:44.029271 22509476222784 run_lib.py:133] step: 729200, training_loss: 3.40281e-02
I0213 01:38:44.245702 22509476222784 run_lib.py:146] step: 729200, eval_loss: 4.91487e-02
I0213 01:39:03.046605 22509476222784 run_lib.py:133] step: 729250, training_loss: 4.87229e-02
I0213 01:39:21.616880 22509476222784 run_lib.py:133] step: 729300, training_loss: 3.80134e-02
I0213 01:39:21.823116 22509476222784 run_lib.py:146] step: 729300, eval_loss: 3.70247e-02
I0213 01:39:40.499960 22509476222784 run_lib.py:133] step: 729350, training_loss: 3.35385e-02
I0213 01:39:59.027437 22509476222784 run_lib.py:133] step: 729400, training_loss: 4.22151e-02
I0213 01:39:59.190531 22509476222784 run_lib.py:146] step: 729400, eval_loss: 4.93899e-02
I0213 01:40:17.918914 22509476222784 run_lib.py:133] step: 729450, training_loss: 3.75700e-02
I0213 01:40:36.499337 22509476222784 run_lib.py:133] step: 729500, training_loss: 4.78580e-02
I0213 01:40:36.666953 22509476222784 run_lib.py:146] step: 729500, eval_loss: 4.76238e-02
I0213 01:40:55.187005 22509476222784 run_lib.py:133] step: 729550, training_loss: 4.29002e-02
I0213 01:41:13.913269 22509476222784 run_lib.py:133] step: 729600, training_loss: 3.45700e-02
I0213 01:41:14.076725 22509476222784 run_lib.py:146] step: 729600, eval_loss: 3.87708e-02
I0213 01:41:32.621967 22509476222784 run_lib.py:133] step: 729650, training_loss: 4.43225e-02
I0213 01:41:51.271562 22509476222784 run_lib.py:133] step: 729700, training_loss: 5.50947e-02
I0213 01:41:51.451543 22509476222784 run_lib.py:146] step: 729700, eval_loss: 4.07253e-02
I0213 01:42:10.041446 22509476222784 run_lib.py:133] step: 729750, training_loss: 3.91012e-02
I0213 01:42:28.605537 22509476222784 run_lib.py:133] step: 729800, training_loss: 3.38201e-02
I0213 01:42:28.771900 22509476222784 run_lib.py:146] step: 729800, eval_loss: 5.25591e-02
I0213 01:42:47.527823 22509476222784 run_lib.py:133] step: 729850, training_loss: 5.93398e-02
I0213 01:43:06.090810 22509476222784 run_lib.py:133] step: 729900, training_loss: 4.47396e-02
I0213 01:43:06.277687 22509476222784 run_lib.py:146] step: 729900, eval_loss: 3.57294e-02
I0213 01:43:24.811430 22509476222784 run_lib.py:133] step: 729950, training_loss: 2.98374e-02
I0213 01:43:43.513767 22509476222784 run_lib.py:133] step: 730000, training_loss: 4.51871e-02
I0213 01:43:44.381816 22509476222784 run_lib.py:146] step: 730000, eval_loss: 4.01206e-02
I0213 01:44:05.857658 22509476222784 run_lib.py:133] step: 730050, training_loss: 3.88419e-02
I0213 01:44:24.403557 22509476222784 run_lib.py:133] step: 730100, training_loss: 3.99063e-02
I0213 01:44:24.571850 22509476222784 run_lib.py:146] step: 730100, eval_loss: 3.84466e-02
I0213 01:44:43.132055 22509476222784 run_lib.py:133] step: 730150, training_loss: 4.43820e-02
I0213 01:45:01.859235 22509476222784 run_lib.py:133] step: 730200, training_loss: 3.84149e-02
I0213 01:45:02.064832 22509476222784 run_lib.py:146] step: 730200, eval_loss: 4.01549e-02
I0213 01:45:20.639807 22509476222784 run_lib.py:133] step: 730250, training_loss: 4.08933e-02
I0213 01:45:39.257708 22509476222784 run_lib.py:133] step: 730300, training_loss: 5.05703e-02
I0213 01:45:39.430708 22509476222784 run_lib.py:146] step: 730300, eval_loss: 4.14441e-02
I0213 01:45:58.160737 22509476222784 run_lib.py:133] step: 730350, training_loss: 3.30100e-02
I0213 01:46:16.738999 22509476222784 run_lib.py:133] step: 730400, training_loss: 3.69260e-02
I0213 01:46:16.902816 22509476222784 run_lib.py:146] step: 730400, eval_loss: 4.16686e-02
I0213 01:46:35.500692 22509476222784 run_lib.py:133] step: 730450, training_loss: 3.81915e-02
I0213 01:46:54.016132 22509476222784 run_lib.py:133] step: 730500, training_loss: 3.51754e-02
I0213 01:46:54.178534 22509476222784 run_lib.py:146] step: 730500, eval_loss: 5.29784e-02
I0213 01:47:12.805420 22509476222784 run_lib.py:133] step: 730550, training_loss: 4.52657e-02
I0213 01:47:31.398230 22509476222784 run_lib.py:133] step: 730600, training_loss: 3.26995e-02
I0213 01:47:31.596339 22509476222784 run_lib.py:146] step: 730600, eval_loss: 2.53968e-02
I0213 01:47:50.336486 22509476222784 run_lib.py:133] step: 730650, training_loss: 5.15578e-02
I0213 01:48:08.953364 22509476222784 run_lib.py:133] step: 730700, training_loss: 3.26631e-02
I0213 01:48:09.118001 22509476222784 run_lib.py:146] step: 730700, eval_loss: 4.58931e-02
I0213 01:48:27.652246 22509476222784 run_lib.py:133] step: 730750, training_loss: 3.98918e-02
I0213 01:48:46.264199 22509476222784 run_lib.py:133] step: 730800, training_loss: 4.64036e-02
I0213 01:48:46.430000 22509476222784 run_lib.py:146] step: 730800, eval_loss: 4.52185e-02
I0213 01:49:05.236001 22509476222784 run_lib.py:133] step: 730850, training_loss: 3.36211e-02
I0213 01:49:23.818440 22509476222784 run_lib.py:133] step: 730900, training_loss: 4.07712e-02
I0213 01:49:23.982694 22509476222784 run_lib.py:146] step: 730900, eval_loss: 3.87876e-02
I0213 01:49:42.692003 22509476222784 run_lib.py:133] step: 730950, training_loss: 3.87650e-02
I0213 01:50:01.264393 22509476222784 run_lib.py:133] step: 731000, training_loss: 3.70729e-02
I0213 01:50:01.425734 22509476222784 run_lib.py:146] step: 731000, eval_loss: 5.59998e-02
I0213 01:50:20.154633 22509476222784 run_lib.py:133] step: 731050, training_loss: 3.73665e-02
I0213 01:50:38.738023 22509476222784 run_lib.py:133] step: 731100, training_loss: 3.29330e-02
I0213 01:50:38.920933 22509476222784 run_lib.py:146] step: 731100, eval_loss: 4.38635e-02
I0213 01:50:57.662533 22509476222784 run_lib.py:133] step: 731150, training_loss: 4.54528e-02
I0213 01:51:16.210045 22509476222784 run_lib.py:133] step: 731200, training_loss: 2.93596e-02
I0213 01:51:16.378030 22509476222784 run_lib.py:146] step: 731200, eval_loss: 4.58101e-02
I0213 01:51:34.915896 22509476222784 run_lib.py:133] step: 731250, training_loss: 5.57662e-02
I0213 01:51:53.705979 22509476222784 run_lib.py:133] step: 731300, training_loss: 3.83884e-02
I0213 01:51:53.870619 22509476222784 run_lib.py:146] step: 731300, eval_loss: 3.84692e-02
I0213 01:52:12.426956 22509476222784 run_lib.py:133] step: 731350, training_loss: 4.63261e-02
I0213 01:52:31.078322 22509476222784 run_lib.py:133] step: 731400, training_loss: 5.40143e-02
I0213 01:52:31.242899 22509476222784 run_lib.py:146] step: 731400, eval_loss: 4.79525e-02
I0213 01:52:50.042034 22509476222784 run_lib.py:133] step: 731450, training_loss: 3.92034e-02
I0213 01:53:08.656903 22509476222784 run_lib.py:133] step: 731500, training_loss: 5.52485e-02
I0213 01:53:08.818012 22509476222784 run_lib.py:146] step: 731500, eval_loss: 4.00353e-02
I0213 01:53:27.473453 22509476222784 run_lib.py:133] step: 731550, training_loss: 4.23487e-02
I0213 01:53:46.044260 22509476222784 run_lib.py:133] step: 731600, training_loss: 4.03000e-02
I0213 01:53:46.253684 22509476222784 run_lib.py:146] step: 731600, eval_loss: 3.61587e-02
I0213 01:54:04.746838 22509476222784 run_lib.py:133] step: 731650, training_loss: 4.89742e-02
I0213 01:54:23.444258 22509476222784 run_lib.py:133] step: 731700, training_loss: 6.11088e-02
I0213 01:54:23.612883 22509476222784 run_lib.py:146] step: 731700, eval_loss: 3.79802e-02
I0213 01:54:42.153554 22509476222784 run_lib.py:133] step: 731750, training_loss: 3.38015e-02
I0213 01:55:00.682928 22509476222784 run_lib.py:133] step: 731800, training_loss: 3.94797e-02
I0213 01:55:00.866872 22509476222784 run_lib.py:146] step: 731800, eval_loss: 4.15210e-02
I0213 01:55:19.405971 22509476222784 run_lib.py:133] step: 731850, training_loss: 3.00151e-02
I0213 01:55:38.226884 22509476222784 run_lib.py:133] step: 731900, training_loss: 4.04722e-02
I0213 01:55:38.418836 22509476222784 run_lib.py:146] step: 731900, eval_loss: 5.55037e-02
I0213 01:55:56.992077 22509476222784 run_lib.py:133] step: 731950, training_loss: 5.35864e-02
I0213 01:56:15.650983 22509476222784 run_lib.py:133] step: 732000, training_loss: 3.06443e-02
I0213 01:56:15.839757 22509476222784 run_lib.py:146] step: 732000, eval_loss: 5.17215e-02
I0213 01:56:34.366551 22509476222784 run_lib.py:133] step: 732050, training_loss: 4.60180e-02
I0213 01:56:52.874693 22509476222784 run_lib.py:133] step: 732100, training_loss: 4.19774e-02
I0213 01:56:53.042657 22509476222784 run_lib.py:146] step: 732100, eval_loss: 3.48272e-02
I0213 01:57:11.792768 22509476222784 run_lib.py:133] step: 732150, training_loss: 3.67223e-02
I0213 01:57:30.560076 22509476222784 run_lib.py:133] step: 732200, training_loss: 4.31716e-02
I0213 01:57:30.769907 22509476222784 run_lib.py:146] step: 732200, eval_loss: 5.11935e-02
I0213 01:57:49.285306 22509476222784 run_lib.py:133] step: 732250, training_loss: 4.68898e-02
I0213 01:58:07.805844 22509476222784 run_lib.py:133] step: 732300, training_loss: 3.49410e-02
I0213 01:58:07.997801 22509476222784 run_lib.py:146] step: 732300, eval_loss: 4.85779e-02
I0213 01:58:26.702351 22509476222784 run_lib.py:133] step: 732350, training_loss: 3.68319e-02
I0213 01:58:45.246844 22509476222784 run_lib.py:133] step: 732400, training_loss: 3.69714e-02
I0213 01:58:45.408622 22509476222784 run_lib.py:146] step: 732400, eval_loss: 3.74250e-02
I0213 01:59:04.175174 22509476222784 run_lib.py:133] step: 732450, training_loss: 4.86224e-02
I0213 01:59:22.745349 22509476222784 run_lib.py:133] step: 732500, training_loss: 3.15353e-02
I0213 01:59:22.910915 22509476222784 run_lib.py:146] step: 732500, eval_loss: 5.13701e-02
I0213 01:59:41.608815 22509476222784 run_lib.py:133] step: 732550, training_loss: 3.73064e-02
I0213 02:00:00.163529 22509476222784 run_lib.py:133] step: 732600, training_loss: 3.57863e-02
I0213 02:00:00.374945 22509476222784 run_lib.py:146] step: 732600, eval_loss: 4.40959e-02
I0213 02:00:19.000907 22509476222784 run_lib.py:133] step: 732650, training_loss: 5.03399e-02
I0213 02:00:37.789283 22509476222784 run_lib.py:133] step: 732700, training_loss: 4.83473e-02
I0213 02:00:37.951180 22509476222784 run_lib.py:146] step: 732700, eval_loss: 3.51439e-02
I0213 02:00:56.534872 22509476222784 run_lib.py:133] step: 732750, training_loss: 3.95713e-02
I0213 02:01:15.235427 22509476222784 run_lib.py:133] step: 732800, training_loss: 3.58869e-02
I0213 02:01:15.399532 22509476222784 run_lib.py:146] step: 732800, eval_loss: 3.57852e-02
I0213 02:01:33.940242 22509476222784 run_lib.py:133] step: 732850, training_loss: 3.95602e-02
I0213 02:01:52.429421 22509476222784 run_lib.py:133] step: 732900, training_loss: 4.29484e-02
I0213 02:01:52.596557 22509476222784 run_lib.py:146] step: 732900, eval_loss: 3.84322e-02
I0213 02:02:11.342136 22509476222784 run_lib.py:133] step: 732950, training_loss: 4.62584e-02
I0213 02:02:29.893826 22509476222784 run_lib.py:133] step: 733000, training_loss: 4.03690e-02
I0213 02:02:30.058892 22509476222784 run_lib.py:146] step: 733000, eval_loss: 5.69841e-02
I0213 02:02:48.577875 22509476222784 run_lib.py:133] step: 733050, training_loss: 5.50123e-02
I0213 02:03:07.336094 22509476222784 run_lib.py:133] step: 733100, training_loss: 5.12457e-02
I0213 02:03:07.534305 22509476222784 run_lib.py:146] step: 733100, eval_loss: 3.36980e-02
I0213 02:03:26.115364 22509476222784 run_lib.py:133] step: 733150, training_loss: 4.55649e-02
I0213 02:03:44.705556 22509476222784 run_lib.py:133] step: 733200, training_loss: 5.05373e-02
I0213 02:03:45.030693 22509476222784 run_lib.py:146] step: 733200, eval_loss: 4.00938e-02
I0213 02:04:03.619521 22509476222784 run_lib.py:133] step: 733250, training_loss: 3.32388e-02
I0213 02:04:22.220313 22509476222784 run_lib.py:133] step: 733300, training_loss: 4.39971e-02
I0213 02:04:22.382615 22509476222784 run_lib.py:146] step: 733300, eval_loss: 3.40692e-02
I0213 02:04:40.968304 22509476222784 run_lib.py:133] step: 733350, training_loss: 4.46944e-02
I0213 02:04:59.523071 22509476222784 run_lib.py:133] step: 733400, training_loss: 2.79876e-02
I0213 02:04:59.706840 22509476222784 run_lib.py:146] step: 733400, eval_loss: 4.13971e-02
I0213 02:05:18.410487 22509476222784 run_lib.py:133] step: 733450, training_loss: 3.77879e-02
I0213 02:05:37.089662 22509476222784 run_lib.py:133] step: 733500, training_loss: 4.33182e-02
I0213 02:05:37.312869 22509476222784 run_lib.py:146] step: 733500, eval_loss: 4.80888e-02
I0213 02:05:55.900662 22509476222784 run_lib.py:133] step: 733550, training_loss: 4.45211e-02
I0213 02:06:14.536320 22509476222784 run_lib.py:133] step: 733600, training_loss: 3.57619e-02
I0213 02:06:14.722940 22509476222784 run_lib.py:146] step: 733600, eval_loss: 4.77871e-02
I0213 02:06:33.503257 22509476222784 run_lib.py:133] step: 733650, training_loss: 4.67663e-02
I0213 02:06:52.091966 22509476222784 run_lib.py:133] step: 733700, training_loss: 3.88750e-02
I0213 02:06:52.256690 22509476222784 run_lib.py:146] step: 733700, eval_loss: 4.12113e-02
I0213 02:07:10.855266 22509476222784 run_lib.py:133] step: 733750, training_loss: 5.52638e-02
I0213 02:07:29.439983 22509476222784 run_lib.py:133] step: 733800, training_loss: 3.71116e-02
I0213 02:07:29.616478 22509476222784 run_lib.py:146] step: 733800, eval_loss: 3.04231e-02
I0213 02:07:48.342308 22509476222784 run_lib.py:133] step: 733850, training_loss: 3.82585e-02
I0213 02:08:06.864016 22509476222784 run_lib.py:133] step: 733900, training_loss: 4.85995e-02
I0213 02:08:07.060311 22509476222784 run_lib.py:146] step: 733900, eval_loss: 4.32242e-02
I0213 02:08:25.768038 22509476222784 run_lib.py:133] step: 733950, training_loss: 4.07403e-02
I0213 02:08:44.286867 22509476222784 run_lib.py:133] step: 734000, training_loss: 3.77157e-02
I0213 02:08:44.484973 22509476222784 run_lib.py:146] step: 734000, eval_loss: 4.22465e-02
I0213 02:09:03.252471 22509476222784 run_lib.py:133] step: 734050, training_loss: 4.72523e-02
I0213 02:09:21.847439 22509476222784 run_lib.py:133] step: 734100, training_loss: 4.55668e-02
I0213 02:09:22.036040 22509476222784 run_lib.py:146] step: 734100, eval_loss: 3.85501e-02
I0213 02:09:40.614177 22509476222784 run_lib.py:133] step: 734150, training_loss: 4.53510e-02
I0213 02:09:59.285932 22509476222784 run_lib.py:133] step: 734200, training_loss: 3.43267e-02
I0213 02:09:59.450898 22509476222784 run_lib.py:146] step: 734200, eval_loss: 3.34131e-02
I0213 02:10:17.979219 22509476222784 run_lib.py:133] step: 734250, training_loss: 3.63433e-02
I0213 02:10:36.728982 22509476222784 run_lib.py:133] step: 734300, training_loss: 3.77376e-02
I0213 02:10:36.892913 22509476222784 run_lib.py:146] step: 734300, eval_loss: 3.98598e-02
I0213 02:10:55.461359 22509476222784 run_lib.py:133] step: 734350, training_loss: 5.07142e-02
I0213 02:11:14.021626 22509476222784 run_lib.py:133] step: 734400, training_loss: 4.67386e-02
I0213 02:11:14.186685 22509476222784 run_lib.py:146] step: 734400, eval_loss: 4.18032e-02
I0213 02:11:32.660585 22509476222784 run_lib.py:133] step: 734450, training_loss: 4.11415e-02
I0213 02:11:51.321218 22509476222784 run_lib.py:133] step: 734500, training_loss: 4.12037e-02
I0213 02:11:51.505692 22509476222784 run_lib.py:146] step: 734500, eval_loss: 4.29171e-02
I0213 02:12:10.115185 22509476222784 run_lib.py:133] step: 734550, training_loss: 4.05698e-02
I0213 02:12:28.686152 22509476222784 run_lib.py:133] step: 734600, training_loss: 4.27964e-02
I0213 02:12:28.852849 22509476222784 run_lib.py:146] step: 734600, eval_loss: 4.42084e-02
I0213 02:12:47.615751 22509476222784 run_lib.py:133] step: 734650, training_loss: 3.82000e-02
I0213 02:13:06.174259 22509476222784 run_lib.py:133] step: 734700, training_loss: 4.53589e-02
I0213 02:13:06.338415 22509476222784 run_lib.py:146] step: 734700, eval_loss: 4.45064e-02
I0213 02:13:24.972350 22509476222784 run_lib.py:133] step: 734750, training_loss: 3.68507e-02
I0213 02:13:43.519062 22509476222784 run_lib.py:133] step: 734800, training_loss: 3.10251e-02
I0213 02:13:43.684896 22509476222784 run_lib.py:146] step: 734800, eval_loss: 4.58420e-02
I0213 02:14:02.310020 22509476222784 run_lib.py:133] step: 734850, training_loss: 3.82088e-02
I0213 02:14:20.874088 22509476222784 run_lib.py:133] step: 734900, training_loss: 4.08306e-02
I0213 02:14:21.063621 22509476222784 run_lib.py:146] step: 734900, eval_loss: 4.29626e-02
I0213 02:14:39.810333 22509476222784 run_lib.py:133] step: 734950, training_loss: 3.48339e-02
I0213 02:14:58.409938 22509476222784 run_lib.py:133] step: 735000, training_loss: 4.85799e-02
I0213 02:14:58.611449 22509476222784 run_lib.py:146] step: 735000, eval_loss: 3.64029e-02
I0213 02:15:17.217742 22509476222784 run_lib.py:133] step: 735050, training_loss: 5.28103e-02
I0213 02:15:35.828035 22509476222784 run_lib.py:133] step: 735100, training_loss: 3.67137e-02
I0213 02:15:35.995784 22509476222784 run_lib.py:146] step: 735100, eval_loss: 4.48001e-02
I0213 02:15:54.796511 22509476222784 run_lib.py:133] step: 735150, training_loss: 5.94736e-02
I0213 02:16:13.370657 22509476222784 run_lib.py:133] step: 735200, training_loss: 4.59490e-02
I0213 02:16:13.532860 22509476222784 run_lib.py:146] step: 735200, eval_loss: 5.80985e-02
I0213 02:16:32.244343 22509476222784 run_lib.py:133] step: 735250, training_loss: 4.63076e-02
I0213 02:16:50.867518 22509476222784 run_lib.py:133] step: 735300, training_loss: 4.05487e-02
I0213 02:16:51.039012 22509476222784 run_lib.py:146] step: 735300, eval_loss: 4.40245e-02
I0213 02:17:09.940223 22509476222784 run_lib.py:133] step: 735350, training_loss: 3.38932e-02
I0213 02:17:28.539829 22509476222784 run_lib.py:133] step: 735400, training_loss: 4.54026e-02
I0213 02:17:28.743716 22509476222784 run_lib.py:146] step: 735400, eval_loss: 4.36595e-02
I0213 02:17:47.466662 22509476222784 run_lib.py:133] step: 735450, training_loss: 3.57487e-02
I0213 02:18:06.019896 22509476222784 run_lib.py:133] step: 735500, training_loss: 3.98274e-02
I0213 02:18:06.220909 22509476222784 run_lib.py:146] step: 735500, eval_loss: 3.99481e-02
I0213 02:18:24.820488 22509476222784 run_lib.py:133] step: 735550, training_loss: 4.50799e-02
I0213 02:18:43.594481 22509476222784 run_lib.py:133] step: 735600, training_loss: 5.25496e-02
I0213 02:18:43.781582 22509476222784 run_lib.py:146] step: 735600, eval_loss: 5.23894e-02
I0213 02:19:02.359653 22509476222784 run_lib.py:133] step: 735650, training_loss: 4.26920e-02
I0213 02:19:20.901005 22509476222784 run_lib.py:133] step: 735700, training_loss: 4.21448e-02
I0213 02:19:21.089515 22509476222784 run_lib.py:146] step: 735700, eval_loss: 3.75201e-02
I0213 02:19:39.796347 22509476222784 run_lib.py:133] step: 735750, training_loss: 4.40814e-02
I0213 02:19:58.503317 22509476222784 run_lib.py:133] step: 735800, training_loss: 4.50266e-02
I0213 02:19:58.694931 22509476222784 run_lib.py:146] step: 735800, eval_loss: 2.94909e-02
I0213 02:20:17.269646 22509476222784 run_lib.py:133] step: 735850, training_loss: 3.71663e-02
I0213 02:20:35.857370 22509476222784 run_lib.py:133] step: 735900, training_loss: 3.54327e-02
I0213 02:20:36.023537 22509476222784 run_lib.py:146] step: 735900, eval_loss: 4.02584e-02
I0213 02:20:54.521045 22509476222784 run_lib.py:133] step: 735950, training_loss: 5.10615e-02
I0213 02:21:13.263305 22509476222784 run_lib.py:133] step: 736000, training_loss: 4.86006e-02
I0213 02:21:13.462368 22509476222784 run_lib.py:146] step: 736000, eval_loss: 4.16457e-02
I0213 02:21:32.034464 22509476222784 run_lib.py:133] step: 736050, training_loss: 3.83335e-02
I0213 02:21:50.591469 22509476222784 run_lib.py:133] step: 736100, training_loss: 4.02798e-02
I0213 02:21:50.801928 22509476222784 run_lib.py:146] step: 736100, eval_loss: 3.23618e-02
I0213 02:22:09.385786 22509476222784 run_lib.py:133] step: 736150, training_loss: 4.96628e-02
I0213 02:22:28.175517 22509476222784 run_lib.py:133] step: 736200, training_loss: 4.44132e-02
I0213 02:22:28.359401 22509476222784 run_lib.py:146] step: 736200, eval_loss: 4.23248e-02
I0213 02:22:46.920193 22509476222784 run_lib.py:133] step: 736250, training_loss: 3.91642e-02
I0213 02:23:05.523147 22509476222784 run_lib.py:133] step: 736300, training_loss: 3.26747e-02
I0213 02:23:05.691517 22509476222784 run_lib.py:146] step: 736300, eval_loss: 4.50650e-02
I0213 02:23:24.141204 22509476222784 run_lib.py:133] step: 736350, training_loss: 3.36394e-02
I0213 02:23:42.711798 22509476222784 run_lib.py:133] step: 736400, training_loss: 4.75153e-02
I0213 02:23:42.934604 22509476222784 run_lib.py:146] step: 736400, eval_loss: 4.93918e-02
I0213 02:24:01.664083 22509476222784 run_lib.py:133] step: 736450, training_loss: 3.86385e-02
I0213 02:24:20.324780 22509476222784 run_lib.py:133] step: 736500, training_loss: 5.04891e-02
I0213 02:24:20.488863 22509476222784 run_lib.py:146] step: 736500, eval_loss: 4.59533e-02
I0213 02:24:39.052361 22509476222784 run_lib.py:133] step: 736550, training_loss: 4.82913e-02
I0213 02:24:57.619649 22509476222784 run_lib.py:133] step: 736600, training_loss: 4.28442e-02
I0213 02:24:57.785717 22509476222784 run_lib.py:146] step: 736600, eval_loss: 4.90063e-02
I0213 02:25:16.518020 22509476222784 run_lib.py:133] step: 736650, training_loss: 4.39080e-02
I0213 02:25:35.169334 22509476222784 run_lib.py:133] step: 736700, training_loss: 3.79791e-02
I0213 02:25:35.332955 22509476222784 run_lib.py:146] step: 736700, eval_loss: 4.83923e-02
I0213 02:25:54.115892 22509476222784 run_lib.py:133] step: 736750, training_loss: 4.28265e-02
I0213 02:26:12.672768 22509476222784 run_lib.py:133] step: 736800, training_loss: 3.53760e-02
I0213 02:26:12.837725 22509476222784 run_lib.py:146] step: 736800, eval_loss: 4.47246e-02
I0213 02:26:31.527172 22509476222784 run_lib.py:133] step: 736850, training_loss: 2.62756e-02
I0213 02:26:50.161047 22509476222784 run_lib.py:133] step: 736900, training_loss: 3.40561e-02
I0213 02:26:50.361573 22509476222784 run_lib.py:146] step: 736900, eval_loss: 5.52100e-02
I0213 02:27:08.897920 22509476222784 run_lib.py:133] step: 736950, training_loss: 3.79782e-02
I0213 02:27:27.626104 22509476222784 run_lib.py:133] step: 737000, training_loss: 3.65491e-02
I0213 02:27:27.790701 22509476222784 run_lib.py:146] step: 737000, eval_loss: 4.00507e-02
I0213 02:27:46.309395 22509476222784 run_lib.py:133] step: 737050, training_loss: 5.77272e-02
I0213 02:28:05.009157 22509476222784 run_lib.py:133] step: 737100, training_loss: 3.55926e-02
I0213 02:28:05.173878 22509476222784 run_lib.py:146] step: 737100, eval_loss: 5.18946e-02
I0213 02:28:23.849326 22509476222784 run_lib.py:133] step: 737150, training_loss: 4.36159e-02
I0213 02:28:42.371126 22509476222784 run_lib.py:133] step: 737200, training_loss: 4.66201e-02
I0213 02:28:42.532791 22509476222784 run_lib.py:146] step: 737200, eval_loss: 3.96232e-02
I0213 02:29:01.301664 22509476222784 run_lib.py:133] step: 737250, training_loss: 3.60000e-02
I0213 02:29:19.847514 22509476222784 run_lib.py:133] step: 737300, training_loss: 4.63003e-02
I0213 02:29:20.027095 22509476222784 run_lib.py:146] step: 737300, eval_loss: 3.59829e-02
I0213 02:29:38.586750 22509476222784 run_lib.py:133] step: 737350, training_loss: 3.86515e-02
I0213 02:29:57.318374 22509476222784 run_lib.py:133] step: 737400, training_loss: 5.50630e-02
I0213 02:29:57.493979 22509476222784 run_lib.py:146] step: 737400, eval_loss: 4.24087e-02
I0213 02:30:16.052614 22509476222784 run_lib.py:133] step: 737450, training_loss: 3.59072e-02
I0213 02:30:34.610443 22509476222784 run_lib.py:133] step: 737500, training_loss: 4.15789e-02
I0213 02:30:34.804251 22509476222784 run_lib.py:146] step: 737500, eval_loss: 4.57513e-02
I0213 02:30:53.428151 22509476222784 run_lib.py:133] step: 737550, training_loss: 3.89654e-02
I0213 02:31:11.926100 22509476222784 run_lib.py:133] step: 737600, training_loss: 4.00249e-02
I0213 02:31:12.088573 22509476222784 run_lib.py:146] step: 737600, eval_loss: 2.93401e-02
I0213 02:31:30.612526 22509476222784 run_lib.py:133] step: 737650, training_loss: 3.54429e-02
I0213 02:31:49.194787 22509476222784 run_lib.py:133] step: 737700, training_loss: 3.10106e-02
I0213 02:31:49.367432 22509476222784 run_lib.py:146] step: 737700, eval_loss: 4.88389e-02
I0213 02:32:08.071051 22509476222784 run_lib.py:133] step: 737750, training_loss: 3.88226e-02
I0213 02:32:26.717689 22509476222784 run_lib.py:133] step: 737800, training_loss: 3.80607e-02
I0213 02:32:26.886147 22509476222784 run_lib.py:146] step: 737800, eval_loss: 4.78224e-02
I0213 02:32:45.396647 22509476222784 run_lib.py:133] step: 737850, training_loss: 4.53925e-02
I0213 02:33:03.923971 22509476222784 run_lib.py:133] step: 737900, training_loss: 4.38961e-02
I0213 02:33:04.103755 22509476222784 run_lib.py:146] step: 737900, eval_loss: 3.92204e-02
I0213 02:33:22.875865 22509476222784 run_lib.py:133] step: 737950, training_loss: 4.08189e-02
I0213 02:33:41.435939 22509476222784 run_lib.py:133] step: 738000, training_loss: 4.78746e-02
I0213 02:33:41.599844 22509476222784 run_lib.py:146] step: 738000, eval_loss: 3.88586e-02
I0213 02:34:00.362071 22509476222784 run_lib.py:133] step: 738050, training_loss: 3.67247e-02
I0213 02:34:18.888246 22509476222784 run_lib.py:133] step: 738100, training_loss: 4.63428e-02
I0213 02:34:19.055606 22509476222784 run_lib.py:146] step: 738100, eval_loss: 3.78588e-02
I0213 02:34:37.734451 22509476222784 run_lib.py:133] step: 738150, training_loss: 4.76875e-02
I0213 02:34:56.349663 22509476222784 run_lib.py:133] step: 738200, training_loss: 4.24746e-02
I0213 02:34:56.552999 22509476222784 run_lib.py:146] step: 738200, eval_loss: 4.55211e-02
I0213 02:35:15.300450 22509476222784 run_lib.py:133] step: 738250, training_loss: 3.26524e-02
I0213 02:35:33.866786 22509476222784 run_lib.py:133] step: 738300, training_loss: 3.89997e-02
I0213 02:35:34.032826 22509476222784 run_lib.py:146] step: 738300, eval_loss: 3.88440e-02
I0213 02:35:52.525357 22509476222784 run_lib.py:133] step: 738350, training_loss: 3.37269e-02
I0213 02:36:11.217433 22509476222784 run_lib.py:133] step: 738400, training_loss: 3.80215e-02
I0213 02:36:11.389656 22509476222784 run_lib.py:146] step: 738400, eval_loss: 4.24236e-02
I0213 02:36:29.991828 22509476222784 run_lib.py:133] step: 738450, training_loss: 4.60982e-02
I0213 02:36:48.528736 22509476222784 run_lib.py:133] step: 738500, training_loss: 3.63276e-02
I0213 02:36:48.691697 22509476222784 run_lib.py:146] step: 738500, eval_loss: 5.58666e-02
I0213 02:37:07.403218 22509476222784 run_lib.py:133] step: 738550, training_loss: 4.27991e-02
I0213 02:37:25.874323 22509476222784 run_lib.py:133] step: 738600, training_loss: 5.94895e-02
I0213 02:37:26.035753 22509476222784 run_lib.py:146] step: 738600, eval_loss: 4.77895e-02
I0213 02:37:44.698431 22509476222784 run_lib.py:133] step: 738650, training_loss: 4.70461e-02
I0213 02:38:03.248550 22509476222784 run_lib.py:133] step: 738700, training_loss: 4.72422e-02
I0213 02:38:03.421562 22509476222784 run_lib.py:146] step: 738700, eval_loss: 4.28275e-02
I0213 02:38:21.984025 22509476222784 run_lib.py:133] step: 738750, training_loss: 4.49098e-02
I0213 02:38:40.792084 22509476222784 run_lib.py:133] step: 738800, training_loss: 5.28157e-02
I0213 02:38:40.956567 22509476222784 run_lib.py:146] step: 738800, eval_loss: 5.56123e-02
I0213 02:38:59.510938 22509476222784 run_lib.py:133] step: 738850, training_loss: 4.94124e-02
I0213 02:39:18.054208 22509476222784 run_lib.py:133] step: 738900, training_loss: 3.44977e-02
I0213 02:39:18.227639 22509476222784 run_lib.py:146] step: 738900, eval_loss: 4.40955e-02
I0213 02:39:36.765415 22509476222784 run_lib.py:133] step: 738950, training_loss: 3.63036e-02
I0213 02:39:55.455765 22509476222784 run_lib.py:133] step: 739000, training_loss: 3.85066e-02
I0213 02:39:55.619899 22509476222784 run_lib.py:146] step: 739000, eval_loss: 4.64128e-02
I0213 02:40:14.134166 22509476222784 run_lib.py:133] step: 739050, training_loss: 4.30507e-02
I0213 02:40:32.716155 22509476222784 run_lib.py:133] step: 739100, training_loss: 5.01152e-02
I0213 02:40:32.899518 22509476222784 run_lib.py:146] step: 739100, eval_loss: 4.10648e-02
I0213 02:40:51.433600 22509476222784 run_lib.py:133] step: 739150, training_loss: 4.27606e-02
I0213 02:41:09.929492 22509476222784 run_lib.py:133] step: 739200, training_loss: 4.14311e-02
I0213 02:41:10.158794 22509476222784 run_lib.py:146] step: 739200, eval_loss: 4.80218e-02
I0213 02:41:28.923344 22509476222784 run_lib.py:133] step: 739250, training_loss: 6.50568e-02
I0213 02:41:47.602511 22509476222784 run_lib.py:133] step: 739300, training_loss: 2.68195e-02
I0213 02:41:47.766877 22509476222784 run_lib.py:146] step: 739300, eval_loss: 4.01796e-02
I0213 02:42:06.280746 22509476222784 run_lib.py:133] step: 739350, training_loss: 4.65800e-02
I0213 02:42:24.837754 22509476222784 run_lib.py:133] step: 739400, training_loss: 4.57134e-02
I0213 02:42:25.007887 22509476222784 run_lib.py:146] step: 739400, eval_loss: 4.04645e-02
I0213 02:42:43.680341 22509476222784 run_lib.py:133] step: 739450, training_loss: 2.88308e-02
I0213 02:43:02.236990 22509476222784 run_lib.py:133] step: 739500, training_loss: 2.87210e-02
I0213 02:43:02.446074 22509476222784 run_lib.py:146] step: 739500, eval_loss: 4.06375e-02
I0213 02:43:21.274786 22509476222784 run_lib.py:133] step: 739550, training_loss: 5.66766e-02
I0213 02:43:39.891325 22509476222784 run_lib.py:133] step: 739600, training_loss: 2.88874e-02
I0213 02:43:40.081900 22509476222784 run_lib.py:146] step: 739600, eval_loss: 3.90397e-02
I0213 02:43:58.835401 22509476222784 run_lib.py:133] step: 739650, training_loss: 4.07412e-02
I0213 02:44:17.384865 22509476222784 run_lib.py:133] step: 739700, training_loss: 5.03246e-02
I0213 02:44:17.560839 22509476222784 run_lib.py:146] step: 739700, eval_loss: 4.93884e-02
I0213 02:44:36.121122 22509476222784 run_lib.py:133] step: 739750, training_loss: 5.20581e-02
I0213 02:44:54.986935 22509476222784 run_lib.py:133] step: 739800, training_loss: 5.48644e-02
I0213 02:44:55.154901 22509476222784 run_lib.py:146] step: 739800, eval_loss: 5.22882e-02
I0213 02:45:13.688699 22509476222784 run_lib.py:133] step: 739850, training_loss: 4.50001e-02
I0213 02:45:32.349732 22509476222784 run_lib.py:133] step: 739900, training_loss: 4.96671e-02
I0213 02:45:32.513114 22509476222784 run_lib.py:146] step: 739900, eval_loss: 5.02454e-02
I0213 02:45:50.977980 22509476222784 run_lib.py:133] step: 739950, training_loss: 3.19305e-02
I0213 02:46:09.497100 22509476222784 run_lib.py:133] step: 740000, training_loss: 3.39239e-02
I0213 02:46:10.216595 22509476222784 run_lib.py:146] step: 740000, eval_loss: 4.91731e-02
I0213 02:46:31.573997 22509476222784 run_lib.py:133] step: 740050, training_loss: 3.81194e-02
I0213 02:46:50.175252 22509476222784 run_lib.py:133] step: 740100, training_loss: 3.81725e-02
I0213 02:46:50.344892 22509476222784 run_lib.py:146] step: 740100, eval_loss: 3.93703e-02
I0213 02:47:09.122618 22509476222784 run_lib.py:133] step: 740150, training_loss: 4.30157e-02
I0213 02:47:27.727880 22509476222784 run_lib.py:133] step: 740200, training_loss: 4.60033e-02
I0213 02:47:27.914096 22509476222784 run_lib.py:146] step: 740200, eval_loss: 4.01000e-02
I0213 02:47:46.434470 22509476222784 run_lib.py:133] step: 740250, training_loss: 4.39333e-02
I0213 02:48:05.148938 22509476222784 run_lib.py:133] step: 740300, training_loss: 6.08193e-02
I0213 02:48:05.348601 22509476222784 run_lib.py:146] step: 740300, eval_loss: 4.59541e-02
I0213 02:48:23.943765 22509476222784 run_lib.py:133] step: 740350, training_loss: 4.03246e-02
I0213 02:48:42.720647 22509476222784 run_lib.py:133] step: 740400, training_loss: 3.65879e-02
I0213 02:48:42.892983 22509476222784 run_lib.py:146] step: 740400, eval_loss: 2.88873e-02
I0213 02:49:01.405860 22509476222784 run_lib.py:133] step: 740450, training_loss: 3.65548e-02
I0213 02:49:19.909049 22509476222784 run_lib.py:133] step: 740500, training_loss: 4.51972e-02
I0213 02:49:20.074687 22509476222784 run_lib.py:146] step: 740500, eval_loss: 4.88199e-02
I0213 02:49:38.592339 22509476222784 run_lib.py:133] step: 740550, training_loss: 3.81823e-02
I0213 02:49:57.392204 22509476222784 run_lib.py:133] step: 740600, training_loss: 2.91853e-02
I0213 02:49:57.564926 22509476222784 run_lib.py:146] step: 740600, eval_loss: 3.50276e-02
I0213 02:50:16.144248 22509476222784 run_lib.py:133] step: 740650, training_loss: 4.46604e-02
I0213 02:50:34.700008 22509476222784 run_lib.py:133] step: 740700, training_loss: 4.18365e-02
I0213 02:50:34.894035 22509476222784 run_lib.py:146] step: 740700, eval_loss: 3.55109e-02
I0213 02:50:53.599133 22509476222784 run_lib.py:133] step: 740750, training_loss: 3.15172e-02
I0213 02:51:12.163681 22509476222784 run_lib.py:133] step: 740800, training_loss: 4.31823e-02
I0213 02:51:12.396714 22509476222784 run_lib.py:146] step: 740800, eval_loss: 4.54030e-02
I0213 02:51:31.004379 22509476222784 run_lib.py:133] step: 740850, training_loss: 4.53133e-02
I0213 02:51:49.618290 22509476222784 run_lib.py:133] step: 740900, training_loss: 3.77495e-02
I0213 02:51:49.813386 22509476222784 run_lib.py:146] step: 740900, eval_loss: 3.56617e-02
I0213 02:52:08.395289 22509476222784 run_lib.py:133] step: 740950, training_loss: 4.57905e-02
I0213 02:52:26.924055 22509476222784 run_lib.py:133] step: 741000, training_loss: 5.75427e-02
I0213 02:52:27.086540 22509476222784 run_lib.py:146] step: 741000, eval_loss: 4.42045e-02
I0213 02:52:45.819319 22509476222784 run_lib.py:133] step: 741050, training_loss: 3.02086e-02
I0213 02:53:04.493824 22509476222784 run_lib.py:133] step: 741100, training_loss: 4.98567e-02
I0213 02:53:04.664985 22509476222784 run_lib.py:146] step: 741100, eval_loss: 3.95567e-02
I0213 02:53:23.261916 22509476222784 run_lib.py:133] step: 741150, training_loss: 2.99697e-02
I0213 02:53:41.866348 22509476222784 run_lib.py:133] step: 741200, training_loss: 4.84075e-02
I0213 02:53:42.033784 22509476222784 run_lib.py:146] step: 741200, eval_loss: 3.19982e-02
I0213 02:54:00.745781 22509476222784 run_lib.py:133] step: 741250, training_loss: 4.05609e-02
I0213 02:54:19.259369 22509476222784 run_lib.py:133] step: 741300, training_loss: 3.85133e-02
I0213 02:54:19.457681 22509476222784 run_lib.py:146] step: 741300, eval_loss: 4.70653e-02
I0213 02:54:38.162729 22509476222784 run_lib.py:133] step: 741350, training_loss: 4.32049e-02
I0213 02:54:56.755461 22509476222784 run_lib.py:133] step: 741400, training_loss: 2.59568e-02
I0213 02:54:56.922663 22509476222784 run_lib.py:146] step: 741400, eval_loss: 4.82650e-02
I0213 02:55:15.700057 22509476222784 run_lib.py:133] step: 741450, training_loss: 4.05934e-02
I0213 02:55:34.258744 22509476222784 run_lib.py:133] step: 741500, training_loss: 2.81921e-02
I0213 02:55:34.420795 22509476222784 run_lib.py:146] step: 741500, eval_loss: 4.76007e-02
I0213 02:55:53.060871 22509476222784 run_lib.py:133] step: 741550, training_loss: 3.78563e-02
I0213 02:56:11.615005 22509476222784 run_lib.py:133] step: 741600, training_loss: 5.00748e-02
I0213 02:56:11.849045 22509476222784 run_lib.py:146] step: 741600, eval_loss: 4.05545e-02
I0213 02:56:30.447540 22509476222784 run_lib.py:133] step: 741650, training_loss: 3.70009e-02
I0213 02:56:49.190606 22509476222784 run_lib.py:133] step: 741700, training_loss: 4.39158e-02
I0213 02:56:49.357723 22509476222784 run_lib.py:146] step: 741700, eval_loss: 4.53460e-02
I0213 02:57:07.861410 22509476222784 run_lib.py:133] step: 741750, training_loss: 4.10161e-02
I0213 02:57:26.418375 22509476222784 run_lib.py:133] step: 741800, training_loss: 4.77980e-02
I0213 02:57:26.608694 22509476222784 run_lib.py:146] step: 741800, eval_loss: 4.43543e-02
I0213 02:57:45.325378 22509476222784 run_lib.py:133] step: 741850, training_loss: 3.90814e-02
I0213 02:58:03.927294 22509476222784 run_lib.py:133] step: 741900, training_loss: 4.20696e-02
I0213 02:58:04.091006 22509476222784 run_lib.py:146] step: 741900, eval_loss: 3.60879e-02
I0213 02:58:22.908586 22509476222784 run_lib.py:133] step: 741950, training_loss: 4.06915e-02
I0213 02:58:41.517597 22509476222784 run_lib.py:133] step: 742000, training_loss: 3.12955e-02
I0213 02:58:41.689712 22509476222784 run_lib.py:146] step: 742000, eval_loss: 3.70614e-02
I0213 02:59:00.270182 22509476222784 run_lib.py:133] step: 742050, training_loss: 4.80042e-02
I0213 02:59:19.044525 22509476222784 run_lib.py:133] step: 742100, training_loss: 4.51391e-02
I0213 02:59:19.219914 22509476222784 run_lib.py:146] step: 742100, eval_loss: 6.20408e-02
I0213 02:59:37.786964 22509476222784 run_lib.py:133] step: 742150, training_loss: 4.07276e-02
I0213 02:59:56.363051 22509476222784 run_lib.py:133] step: 742200, training_loss: 4.36783e-02
I0213 02:59:56.528596 22509476222784 run_lib.py:146] step: 742200, eval_loss: 4.69580e-02
I0213 03:00:15.072665 22509476222784 run_lib.py:133] step: 742250, training_loss: 3.20458e-02
I0213 03:00:33.818513 22509476222784 run_lib.py:133] step: 742300, training_loss: 4.08105e-02
I0213 03:00:33.982313 22509476222784 run_lib.py:146] step: 742300, eval_loss: 4.84430e-02
I0213 03:00:52.497055 22509476222784 run_lib.py:133] step: 742350, training_loss: 4.47492e-02
I0213 03:01:11.115461 22509476222784 run_lib.py:133] step: 742400, training_loss: 4.35068e-02
I0213 03:01:11.279678 22509476222784 run_lib.py:146] step: 742400, eval_loss: 4.56632e-02
I0213 03:01:29.876762 22509476222784 run_lib.py:133] step: 742450, training_loss: 3.49905e-02
I0213 03:01:48.477241 22509476222784 run_lib.py:133] step: 742500, training_loss: 5.58228e-02
I0213 03:01:48.670905 22509476222784 run_lib.py:146] step: 742500, eval_loss: 4.80851e-02
I0213 03:02:07.424342 22509476222784 run_lib.py:133] step: 742550, training_loss: 4.01330e-02
I0213 03:02:26.029001 22509476222784 run_lib.py:133] step: 742600, training_loss: 3.87693e-02
I0213 03:02:26.227189 22509476222784 run_lib.py:146] step: 742600, eval_loss: 4.16672e-02
I0213 03:02:44.842935 22509476222784 run_lib.py:133] step: 742650, training_loss: 4.53608e-02
I0213 03:03:03.446962 22509476222784 run_lib.py:133] step: 742700, training_loss: 3.15070e-02
I0213 03:03:03.618911 22509476222784 run_lib.py:146] step: 742700, eval_loss: 4.63603e-02
I0213 03:03:22.322016 22509476222784 run_lib.py:133] step: 742750, training_loss: 4.54567e-02
I0213 03:03:40.864384 22509476222784 run_lib.py:133] step: 742800, training_loss: 4.60328e-02
I0213 03:03:41.073940 22509476222784 run_lib.py:146] step: 742800, eval_loss: 5.15423e-02
I0213 03:03:59.763814 22509476222784 run_lib.py:133] step: 742850, training_loss: 4.16375e-02
I0213 03:04:18.294881 22509476222784 run_lib.py:133] step: 742900, training_loss: 3.23355e-02
I0213 03:04:18.460691 22509476222784 run_lib.py:146] step: 742900, eval_loss: 5.38435e-02
I0213 03:04:37.171065 22509476222784 run_lib.py:133] step: 742950, training_loss: 3.47417e-02
I0213 03:04:55.706455 22509476222784 run_lib.py:133] step: 743000, training_loss: 5.00758e-02
I0213 03:04:55.878853 22509476222784 run_lib.py:146] step: 743000, eval_loss: 3.61329e-02
I0213 03:05:14.438055 22509476222784 run_lib.py:133] step: 743050, training_loss: 3.51151e-02
I0213 03:05:33.201853 22509476222784 run_lib.py:133] step: 743100, training_loss: 4.81416e-02
I0213 03:05:33.405986 22509476222784 run_lib.py:146] step: 743100, eval_loss: 4.09677e-02
I0213 03:05:51.930935 22509476222784 run_lib.py:133] step: 743150, training_loss: 4.13723e-02
I0213 03:06:10.626013 22509476222784 run_lib.py:133] step: 743200, training_loss: 4.47430e-02
I0213 03:06:10.846772 22509476222784 run_lib.py:146] step: 743200, eval_loss: 4.12735e-02
I0213 03:06:29.399494 22509476222784 run_lib.py:133] step: 743250, training_loss: 4.24664e-02
I0213 03:06:47.975482 22509476222784 run_lib.py:133] step: 743300, training_loss: 4.92781e-02
I0213 03:06:48.174082 22509476222784 run_lib.py:146] step: 743300, eval_loss: 3.55361e-02
I0213 03:07:06.896677 22509476222784 run_lib.py:133] step: 743350, training_loss: 3.76658e-02
I0213 03:07:25.406020 22509476222784 run_lib.py:133] step: 743400, training_loss: 4.36679e-02
I0213 03:07:25.566098 22509476222784 run_lib.py:146] step: 743400, eval_loss: 2.83005e-02
I0213 03:07:44.078298 22509476222784 run_lib.py:133] step: 743450, training_loss: 5.88198e-02
I0213 03:08:02.759569 22509476222784 run_lib.py:133] step: 743500, training_loss: 3.03270e-02
I0213 03:08:02.934903 22509476222784 run_lib.py:146] step: 743500, eval_loss: 4.74326e-02
I0213 03:08:21.549971 22509476222784 run_lib.py:133] step: 743550, training_loss: 3.77794e-02
I0213 03:08:40.074510 22509476222784 run_lib.py:133] step: 743600, training_loss: 3.26173e-02
I0213 03:08:40.424599 22509476222784 run_lib.py:146] step: 743600, eval_loss: 5.67727e-02
I0213 03:08:58.899493 22509476222784 run_lib.py:133] step: 743650, training_loss: 3.77787e-02
I0213 03:09:17.348073 22509476222784 run_lib.py:133] step: 743700, training_loss: 3.58655e-02
I0213 03:09:17.512671 22509476222784 run_lib.py:146] step: 743700, eval_loss: 4.54113e-02
I0213 03:09:36.008937 22509476222784 run_lib.py:133] step: 743750, training_loss: 4.17247e-02
I0213 03:09:54.598678 22509476222784 run_lib.py:133] step: 743800, training_loss: 3.94680e-02
I0213 03:09:54.795848 22509476222784 run_lib.py:146] step: 743800, eval_loss: 3.46513e-02
I0213 03:10:13.530948 22509476222784 run_lib.py:133] step: 743850, training_loss: 4.13520e-02
I0213 03:10:32.214418 22509476222784 run_lib.py:133] step: 743900, training_loss: 3.82844e-02
I0213 03:10:32.413721 22509476222784 run_lib.py:146] step: 743900, eval_loss: 4.12759e-02
I0213 03:10:50.969688 22509476222784 run_lib.py:133] step: 743950, training_loss: 3.40913e-02
I0213 03:11:09.516249 22509476222784 run_lib.py:133] step: 744000, training_loss: 4.92532e-02
I0213 03:11:09.712606 22509476222784 run_lib.py:146] step: 744000, eval_loss: 3.19625e-02
I0213 03:11:28.447770 22509476222784 run_lib.py:133] step: 744050, training_loss: 4.41597e-02
I0213 03:11:47.207231 22509476222784 run_lib.py:133] step: 744100, training_loss: 3.98407e-02
I0213 03:11:47.387662 22509476222784 run_lib.py:146] step: 744100, eval_loss: 3.33183e-02
I0213 03:12:05.932357 22509476222784 run_lib.py:133] step: 744150, training_loss: 2.95245e-02
I0213 03:12:24.499548 22509476222784 run_lib.py:133] step: 744200, training_loss: 4.36485e-02
I0213 03:12:24.663958 22509476222784 run_lib.py:146] step: 744200, eval_loss: 3.36377e-02
I0213 03:12:43.347234 22509476222784 run_lib.py:133] step: 744250, training_loss: 4.04556e-02
I0213 03:13:02.011197 22509476222784 run_lib.py:133] step: 744300, training_loss: 4.99162e-02
I0213 03:13:02.174930 22509476222784 run_lib.py:146] step: 744300, eval_loss: 4.71117e-02
I0213 03:13:20.895602 22509476222784 run_lib.py:133] step: 744350, training_loss: 4.38902e-02
I0213 03:13:39.465212 22509476222784 run_lib.py:133] step: 744400, training_loss: 4.53099e-02
I0213 03:13:39.659783 22509476222784 run_lib.py:146] step: 744400, eval_loss: 3.83713e-02
I0213 03:13:58.408955 22509476222784 run_lib.py:133] step: 744450, training_loss: 5.64901e-02
I0213 03:14:16.957637 22509476222784 run_lib.py:133] step: 744500, training_loss: 3.75896e-02
I0213 03:14:17.139167 22509476222784 run_lib.py:146] step: 744500, eval_loss: 4.01688e-02
I0213 03:14:35.646111 22509476222784 run_lib.py:133] step: 744550, training_loss: 4.28689e-02
I0213 03:14:54.433817 22509476222784 run_lib.py:133] step: 744600, training_loss: 3.12557e-02
I0213 03:14:54.625167 22509476222784 run_lib.py:146] step: 744600, eval_loss: 3.53473e-02
I0213 03:15:13.221892 22509476222784 run_lib.py:133] step: 744650, training_loss: 4.00779e-02
I0213 03:15:31.982862 22509476222784 run_lib.py:133] step: 744700, training_loss: 5.40927e-02
I0213 03:15:32.151822 22509476222784 run_lib.py:146] step: 744700, eval_loss: 3.46623e-02
I0213 03:15:50.674546 22509476222784 run_lib.py:133] step: 744750, training_loss: 5.11120e-02
I0213 03:16:09.252632 22509476222784 run_lib.py:133] step: 744800, training_loss: 2.84791e-02
I0213 03:16:09.414511 22509476222784 run_lib.py:146] step: 744800, eval_loss: 3.26220e-02
I0213 03:16:28.187586 22509476222784 run_lib.py:133] step: 744850, training_loss: 4.75200e-02
I0213 03:16:46.766613 22509476222784 run_lib.py:133] step: 744900, training_loss: 3.76691e-02
I0213 03:16:46.932036 22509476222784 run_lib.py:146] step: 744900, eval_loss: 4.41793e-02
I0213 03:17:05.453237 22509476222784 run_lib.py:133] step: 744950, training_loss: 3.94189e-02
I0213 03:17:23.979086 22509476222784 run_lib.py:133] step: 745000, training_loss: 4.54447e-02
I0213 03:17:24.178080 22509476222784 run_lib.py:146] step: 745000, eval_loss: 3.77113e-02
I0213 03:17:42.923095 22509476222784 run_lib.py:133] step: 745050, training_loss: 3.27979e-02
I0213 03:18:01.519458 22509476222784 run_lib.py:133] step: 745100, training_loss: 3.80749e-02
I0213 03:18:01.695792 22509476222784 run_lib.py:146] step: 745100, eval_loss: 3.58803e-02
I0213 03:18:20.379219 22509476222784 run_lib.py:133] step: 745150, training_loss: 4.75186e-02
I0213 03:18:38.991336 22509476222784 run_lib.py:133] step: 745200, training_loss: 4.06720e-02
I0213 03:18:39.180923 22509476222784 run_lib.py:146] step: 745200, eval_loss: 3.88806e-02
I0213 03:18:57.772494 22509476222784 run_lib.py:133] step: 745250, training_loss: 4.30711e-02
I0213 03:19:16.258394 22509476222784 run_lib.py:133] step: 745300, training_loss: 4.10577e-02
I0213 03:19:16.419812 22509476222784 run_lib.py:146] step: 745300, eval_loss: 5.00560e-02
I0213 03:19:35.132591 22509476222784 run_lib.py:133] step: 745350, training_loss: 5.35697e-02
I0213 03:19:53.826043 22509476222784 run_lib.py:133] step: 745400, training_loss: 3.46169e-02
I0213 03:19:54.001991 22509476222784 run_lib.py:146] step: 745400, eval_loss: 3.69808e-02
I0213 03:20:12.589732 22509476222784 run_lib.py:133] step: 745450, training_loss: 3.80064e-02
I0213 03:20:31.160334 22509476222784 run_lib.py:133] step: 745500, training_loss: 3.32369e-02
I0213 03:20:31.325915 22509476222784 run_lib.py:146] step: 745500, eval_loss: 3.19468e-02
I0213 03:20:50.003376 22509476222784 run_lib.py:133] step: 745550, training_loss: 2.86246e-02
I0213 03:21:08.491465 22509476222784 run_lib.py:133] step: 745600, training_loss: 3.99381e-02
I0213 03:21:08.655853 22509476222784 run_lib.py:146] step: 745600, eval_loss: 4.15067e-02
I0213 03:21:27.370889 22509476222784 run_lib.py:133] step: 745650, training_loss: 4.26273e-02
I0213 03:21:45.996898 22509476222784 run_lib.py:133] step: 745700, training_loss: 3.43049e-02
I0213 03:21:46.163903 22509476222784 run_lib.py:146] step: 745700, eval_loss: 3.37891e-02
I0213 03:22:04.881994 22509476222784 run_lib.py:133] step: 745750, training_loss: 4.48204e-02
I0213 03:22:23.389950 22509476222784 run_lib.py:133] step: 745800, training_loss: 4.71032e-02
I0213 03:22:23.550905 22509476222784 run_lib.py:146] step: 745800, eval_loss: 4.21233e-02
I0213 03:22:42.258281 22509476222784 run_lib.py:133] step: 745850, training_loss: 3.47184e-02
I0213 03:23:00.808011 22509476222784 run_lib.py:133] step: 745900, training_loss: 4.16704e-02
I0213 03:23:00.992760 22509476222784 run_lib.py:146] step: 745900, eval_loss: 6.23079e-02
I0213 03:23:19.614983 22509476222784 run_lib.py:133] step: 745950, training_loss: 3.82216e-02
I0213 03:23:38.455937 22509476222784 run_lib.py:133] step: 746000, training_loss: 3.24417e-02
I0213 03:23:38.620773 22509476222784 run_lib.py:146] step: 746000, eval_loss: 5.44199e-02
I0213 03:23:57.191161 22509476222784 run_lib.py:133] step: 746050, training_loss: 4.47931e-02
I0213 03:24:15.788456 22509476222784 run_lib.py:133] step: 746100, training_loss: 4.31248e-02
I0213 03:24:15.968944 22509476222784 run_lib.py:146] step: 746100, eval_loss: 4.08270e-02
I0213 03:24:34.741627 22509476222784 run_lib.py:133] step: 746150, training_loss: 4.12598e-02
I0213 03:24:53.512965 22509476222784 run_lib.py:133] step: 746200, training_loss: 5.00124e-02
I0213 03:24:53.698729 22509476222784 run_lib.py:146] step: 746200, eval_loss: 4.02490e-02
I0213 03:25:12.346734 22509476222784 run_lib.py:133] step: 746250, training_loss: 3.18857e-02
I0213 03:25:30.897324 22509476222784 run_lib.py:133] step: 746300, training_loss: 3.30700e-02
I0213 03:25:31.059722 22509476222784 run_lib.py:146] step: 746300, eval_loss: 4.32964e-02
I0213 03:25:49.598949 22509476222784 run_lib.py:133] step: 746350, training_loss: 5.53216e-02
I0213 03:26:08.395482 22509476222784 run_lib.py:133] step: 746400, training_loss: 3.58039e-02
I0213 03:26:08.561930 22509476222784 run_lib.py:146] step: 746400, eval_loss: 3.67087e-02
I0213 03:26:27.162038 22509476222784 run_lib.py:133] step: 746450, training_loss: 3.71258e-02
I0213 03:26:45.825956 22509476222784 run_lib.py:133] step: 746500, training_loss: 3.14164e-02
I0213 03:26:45.996037 22509476222784 run_lib.py:146] step: 746500, eval_loss: 4.48821e-02
I0213 03:27:04.561611 22509476222784 run_lib.py:133] step: 746550, training_loss: 4.37187e-02
I0213 03:27:23.301196 22509476222784 run_lib.py:133] step: 746600, training_loss: 4.45947e-02
I0213 03:27:23.466894 22509476222784 run_lib.py:146] step: 746600, eval_loss: 3.83906e-02
I0213 03:27:42.073706 22509476222784 run_lib.py:133] step: 746650, training_loss: 3.63154e-02
I0213 03:28:00.741732 22509476222784 run_lib.py:133] step: 746700, training_loss: 3.72304e-02
I0213 03:28:00.908926 22509476222784 run_lib.py:146] step: 746700, eval_loss: 4.21072e-02
I0213 03:28:19.624538 22509476222784 run_lib.py:133] step: 746750, training_loss: 4.40504e-02
I0213 03:28:38.187248 22509476222784 run_lib.py:133] step: 746800, training_loss: 4.28839e-02
I0213 03:28:38.356853 22509476222784 run_lib.py:146] step: 746800, eval_loss: 4.79356e-02
I0213 03:28:57.112165 22509476222784 run_lib.py:133] step: 746850, training_loss: 5.21003e-02
I0213 03:29:15.779471 22509476222784 run_lib.py:133] step: 746900, training_loss: 3.80835e-02
I0213 03:29:15.953961 22509476222784 run_lib.py:146] step: 746900, eval_loss: 3.93570e-02
I0213 03:29:34.484514 22509476222784 run_lib.py:133] step: 746950, training_loss: 5.00872e-02
I0213 03:29:53.126306 22509476222784 run_lib.py:133] step: 747000, training_loss: 4.23501e-02
I0213 03:29:53.300134 22509476222784 run_lib.py:146] step: 747000, eval_loss: 4.65165e-02
I0213 03:30:12.052511 22509476222784 run_lib.py:133] step: 747050, training_loss: 4.56608e-02
I0213 03:30:30.613040 22509476222784 run_lib.py:133] step: 747100, training_loss: 4.67077e-02
I0213 03:30:30.777994 22509476222784 run_lib.py:146] step: 747100, eval_loss: 5.15410e-02
I0213 03:30:49.500494 22509476222784 run_lib.py:133] step: 747150, training_loss: 4.36187e-02
I0213 03:31:08.072322 22509476222784 run_lib.py:133] step: 747200, training_loss: 5.04769e-02
I0213 03:31:08.252918 22509476222784 run_lib.py:146] step: 747200, eval_loss: 5.17106e-02
I0213 03:31:27.140134 22509476222784 run_lib.py:133] step: 747250, training_loss: 5.13543e-02
I0213 03:31:45.677038 22509476222784 run_lib.py:133] step: 747300, training_loss: 4.60322e-02
I0213 03:31:45.842083 22509476222784 run_lib.py:146] step: 747300, eval_loss: 4.09405e-02
I0213 03:32:04.381116 22509476222784 run_lib.py:133] step: 747350, training_loss: 4.61534e-02
I0213 03:32:23.165014 22509476222784 run_lib.py:133] step: 747400, training_loss: 5.64184e-02
I0213 03:32:23.338896 22509476222784 run_lib.py:146] step: 747400, eval_loss: 3.89130e-02
I0213 03:32:41.886136 22509476222784 run_lib.py:133] step: 747450, training_loss: 4.94072e-02
I0213 03:33:00.549410 22509476222784 run_lib.py:133] step: 747500, training_loss: 4.02511e-02
I0213 03:33:00.717999 22509476222784 run_lib.py:146] step: 747500, eval_loss: 4.22678e-02
I0213 03:33:19.353936 22509476222784 run_lib.py:133] step: 747550, training_loss: 4.79458e-02
I0213 03:33:37.965354 22509476222784 run_lib.py:133] step: 747600, training_loss: 4.32158e-02
I0213 03:33:38.128735 22509476222784 run_lib.py:146] step: 747600, eval_loss: 4.88945e-02
I0213 03:33:56.876496 22509476222784 run_lib.py:133] step: 747650, training_loss: 3.63128e-02
I0213 03:34:15.496636 22509476222784 run_lib.py:133] step: 747700, training_loss: 4.36005e-02
I0213 03:34:15.658647 22509476222784 run_lib.py:146] step: 747700, eval_loss: 4.73423e-02
I0213 03:34:34.157911 22509476222784 run_lib.py:133] step: 747750, training_loss: 3.49591e-02
I0213 03:34:52.918719 22509476222784 run_lib.py:133] step: 747800, training_loss: 5.21819e-02
I0213 03:34:53.137578 22509476222784 run_lib.py:146] step: 747800, eval_loss: 5.06133e-02
I0213 03:35:11.762334 22509476222784 run_lib.py:133] step: 747850, training_loss: 4.33573e-02
I0213 03:35:30.320513 22509476222784 run_lib.py:133] step: 747900, training_loss: 4.02538e-02
I0213 03:35:30.484906 22509476222784 run_lib.py:146] step: 747900, eval_loss: 3.70777e-02
I0213 03:35:49.139845 22509476222784 run_lib.py:133] step: 747950, training_loss: 4.16325e-02
I0213 03:36:07.686670 22509476222784 run_lib.py:133] step: 748000, training_loss: 3.82114e-02
I0213 03:36:07.851572 22509476222784 run_lib.py:146] step: 748000, eval_loss: 3.72932e-02
I0213 03:36:26.437850 22509476222784 run_lib.py:133] step: 748050, training_loss: 3.28980e-02
I0213 03:36:45.000945 22509476222784 run_lib.py:133] step: 748100, training_loss: 3.83966e-02
I0213 03:36:45.164445 22509476222784 run_lib.py:146] step: 748100, eval_loss: 3.41926e-02
I0213 03:37:03.956910 22509476222784 run_lib.py:133] step: 748150, training_loss: 3.86694e-02
I0213 03:37:22.623764 22509476222784 run_lib.py:133] step: 748200, training_loss: 4.02103e-02
I0213 03:37:22.787696 22509476222784 run_lib.py:146] step: 748200, eval_loss: 5.02556e-02
I0213 03:37:41.313242 22509476222784 run_lib.py:133] step: 748250, training_loss: 3.56297e-02
I0213 03:37:59.895313 22509476222784 run_lib.py:133] step: 748300, training_loss: 3.69560e-02
I0213 03:38:00.077672 22509476222784 run_lib.py:146] step: 748300, eval_loss: 3.58614e-02
I0213 03:38:18.795859 22509476222784 run_lib.py:133] step: 748350, training_loss: 3.88568e-02
I0213 03:38:37.384994 22509476222784 run_lib.py:133] step: 748400, training_loss: 4.80660e-02
I0213 03:38:37.547442 22509476222784 run_lib.py:146] step: 748400, eval_loss: 5.76002e-02
I0213 03:38:56.265595 22509476222784 run_lib.py:133] step: 748450, training_loss: 4.96960e-02
I0213 03:39:14.787497 22509476222784 run_lib.py:133] step: 748500, training_loss: 4.23473e-02
I0213 03:39:14.968549 22509476222784 run_lib.py:146] step: 748500, eval_loss: 4.01804e-02
I0213 03:39:33.659949 22509476222784 run_lib.py:133] step: 748550, training_loss: 4.79232e-02
I0213 03:39:52.222507 22509476222784 run_lib.py:133] step: 748600, training_loss: 4.39034e-02
I0213 03:39:52.441550 22509476222784 run_lib.py:146] step: 748600, eval_loss: 4.18280e-02
I0213 03:40:11.214572 22509476222784 run_lib.py:133] step: 748650, training_loss: 4.69448e-02
I0213 03:40:29.737767 22509476222784 run_lib.py:133] step: 748700, training_loss: 4.62739e-02
I0213 03:40:29.919752 22509476222784 run_lib.py:146] step: 748700, eval_loss: 4.24791e-02
I0213 03:40:48.447219 22509476222784 run_lib.py:133] step: 748750, training_loss: 4.06840e-02
I0213 03:41:07.140081 22509476222784 run_lib.py:133] step: 748800, training_loss: 4.10256e-02
I0213 03:41:07.307955 22509476222784 run_lib.py:146] step: 748800, eval_loss: 4.71914e-02
I0213 03:41:25.872024 22509476222784 run_lib.py:133] step: 748850, training_loss: 4.42662e-02
I0213 03:41:44.528740 22509476222784 run_lib.py:133] step: 748900, training_loss: 3.88342e-02
I0213 03:41:44.697928 22509476222784 run_lib.py:146] step: 748900, eval_loss: 3.47738e-02
I0213 03:42:03.434864 22509476222784 run_lib.py:133] step: 748950, training_loss: 4.46494e-02
I0213 03:42:22.026478 22509476222784 run_lib.py:133] step: 749000, training_loss: 2.77181e-02
I0213 03:42:22.190790 22509476222784 run_lib.py:146] step: 749000, eval_loss: 4.80658e-02
I0213 03:42:40.875872 22509476222784 run_lib.py:133] step: 749050, training_loss: 4.41926e-02
I0213 03:42:59.424716 22509476222784 run_lib.py:133] step: 749100, training_loss: 4.49638e-02
I0213 03:42:59.609681 22509476222784 run_lib.py:146] step: 749100, eval_loss: 4.23621e-02
I0213 03:43:18.271657 22509476222784 run_lib.py:133] step: 749150, training_loss: 3.69814e-02
I0213 03:43:37.074268 22509476222784 run_lib.py:133] step: 749200, training_loss: 3.91348e-02
I0213 03:43:37.266974 22509476222784 run_lib.py:146] step: 749200, eval_loss: 3.55601e-02
I0213 03:43:55.839380 22509476222784 run_lib.py:133] step: 749250, training_loss: 5.94955e-02
I0213 03:44:14.371103 22509476222784 run_lib.py:133] step: 749300, training_loss: 4.41917e-02
I0213 03:44:14.540495 22509476222784 run_lib.py:146] step: 749300, eval_loss: 4.47548e-02
I0213 03:44:33.017802 22509476222784 run_lib.py:133] step: 749350, training_loss: 4.03649e-02
I0213 03:44:51.813584 22509476222784 run_lib.py:133] step: 749400, training_loss: 4.24846e-02
I0213 03:44:52.029485 22509476222784 run_lib.py:146] step: 749400, eval_loss: 5.56052e-02
I0213 03:45:10.591138 22509476222784 run_lib.py:133] step: 749450, training_loss: 5.21981e-02
I0213 03:45:29.230553 22509476222784 run_lib.py:133] step: 749500, training_loss: 6.44697e-02
I0213 03:45:29.393856 22509476222784 run_lib.py:146] step: 749500, eval_loss: 4.31452e-02
I0213 03:45:47.898027 22509476222784 run_lib.py:133] step: 749550, training_loss: 4.11718e-02
I0213 03:46:06.478755 22509476222784 run_lib.py:133] step: 749600, training_loss: 3.43261e-02
I0213 03:46:06.637677 22509476222784 run_lib.py:146] step: 749600, eval_loss: 2.80916e-02
I0213 03:46:25.315621 22509476222784 run_lib.py:133] step: 749650, training_loss: 4.34876e-02
I0213 03:46:43.964703 22509476222784 run_lib.py:133] step: 749700, training_loss: 4.13647e-02
I0213 03:46:44.140378 22509476222784 run_lib.py:146] step: 749700, eval_loss: 4.46662e-02
I0213 03:47:02.731548 22509476222784 run_lib.py:133] step: 749750, training_loss: 3.99928e-02
I0213 03:47:21.250462 22509476222784 run_lib.py:133] step: 749800, training_loss: 3.67469e-02
I0213 03:47:21.414838 22509476222784 run_lib.py:146] step: 749800, eval_loss: 3.12559e-02
I0213 03:47:40.069392 22509476222784 run_lib.py:133] step: 749850, training_loss: 3.36233e-02
I0213 03:47:58.617855 22509476222784 run_lib.py:133] step: 749900, training_loss: 4.12566e-02
I0213 03:47:58.815775 22509476222784 run_lib.py:146] step: 749900, eval_loss: 3.46338e-02
I0213 03:48:17.565423 22509476222784 run_lib.py:133] step: 749950, training_loss: 3.24156e-02
I0213 03:48:36.166993 22509476222784 run_lib.py:133] step: 750000, training_loss: 5.12657e-02
I0213 03:48:37.055334 22509476222784 run_lib.py:146] step: 750000, eval_loss: 4.11621e-02
I0213 03:48:58.512463 22509476222784 run_lib.py:133] step: 750050, training_loss: 4.64350e-02
I0213 03:49:17.010753 22509476222784 run_lib.py:133] step: 750100, training_loss: 4.12923e-02
I0213 03:49:17.171706 22509476222784 run_lib.py:146] step: 750100, eval_loss: 3.33181e-02
I0213 03:49:35.751379 22509476222784 run_lib.py:133] step: 750150, training_loss: 4.19628e-02
I0213 03:49:54.384592 22509476222784 run_lib.py:133] step: 750200, training_loss: 4.36167e-02
I0213 03:49:54.560186 22509476222784 run_lib.py:146] step: 750200, eval_loss: 3.37260e-02
I0213 03:50:13.126818 22509476222784 run_lib.py:133] step: 750250, training_loss: 3.77622e-02
I0213 03:50:31.688591 22509476222784 run_lib.py:133] step: 750300, training_loss: 5.28334e-02
I0213 03:50:31.853947 22509476222784 run_lib.py:146] step: 750300, eval_loss: 3.32028e-02
I0213 03:50:50.536513 22509476222784 run_lib.py:133] step: 750350, training_loss: 4.61816e-02
I0213 03:51:09.083468 22509476222784 run_lib.py:133] step: 750400, training_loss: 3.79016e-02
I0213 03:51:09.253580 22509476222784 run_lib.py:146] step: 750400, eval_loss: 3.89232e-02
I0213 03:51:27.884885 22509476222784 run_lib.py:133] step: 750450, training_loss: 3.01712e-02
I0213 03:51:46.510984 22509476222784 run_lib.py:133] step: 750500, training_loss: 3.93209e-02
I0213 03:51:46.677034 22509476222784 run_lib.py:146] step: 750500, eval_loss: 3.32674e-02
I0213 03:52:05.445763 22509476222784 run_lib.py:133] step: 750550, training_loss: 2.71714e-02
I0213 03:52:23.966043 22509476222784 run_lib.py:133] step: 750600, training_loss: 3.71743e-02
I0213 03:52:24.127614 22509476222784 run_lib.py:146] step: 750600, eval_loss: 5.11489e-02
I0213 03:52:42.806032 22509476222784 run_lib.py:133] step: 750650, training_loss: 4.70691e-02
I0213 03:53:01.341852 22509476222784 run_lib.py:133] step: 750700, training_loss: 4.35204e-02
I0213 03:53:01.516497 22509476222784 run_lib.py:146] step: 750700, eval_loss: 3.61749e-02
I0213 03:53:20.305378 22509476222784 run_lib.py:133] step: 750750, training_loss: 3.29310e-02
I0213 03:53:38.868196 22509476222784 run_lib.py:133] step: 750800, training_loss: 3.27686e-02
I0213 03:53:39.031901 22509476222784 run_lib.py:146] step: 750800, eval_loss: 3.32823e-02
I0213 03:53:57.557134 22509476222784 run_lib.py:133] step: 750850, training_loss: 4.47059e-02
I0213 03:54:16.267666 22509476222784 run_lib.py:133] step: 750900, training_loss: 5.07239e-02
I0213 03:54:16.432823 22509476222784 run_lib.py:146] step: 750900, eval_loss: 4.86011e-02
I0213 03:54:35.045034 22509476222784 run_lib.py:133] step: 750950, training_loss: 3.24109e-02
I0213 03:54:53.834644 22509476222784 run_lib.py:133] step: 751000, training_loss: 3.75794e-02
I0213 03:54:53.998844 22509476222784 run_lib.py:146] step: 751000, eval_loss: 5.10189e-02
I0213 03:55:12.584098 22509476222784 run_lib.py:133] step: 751050, training_loss: 5.41356e-02
I0213 03:55:31.190566 22509476222784 run_lib.py:133] step: 751100, training_loss: 3.35437e-02
I0213 03:55:31.352715 22509476222784 run_lib.py:146] step: 751100, eval_loss: 4.45494e-02
I0213 03:55:50.043644 22509476222784 run_lib.py:133] step: 751150, training_loss: 4.75534e-02
I0213 03:56:08.624771 22509476222784 run_lib.py:133] step: 751200, training_loss: 4.54872e-02
I0213 03:56:08.805634 22509476222784 run_lib.py:146] step: 751200, eval_loss: 5.85371e-02
I0213 03:56:27.420194 22509476222784 run_lib.py:133] step: 751250, training_loss: 4.67702e-02
I0213 03:56:46.237291 22509476222784 run_lib.py:133] step: 751300, training_loss: 3.97537e-02
I0213 03:56:46.418958 22509476222784 run_lib.py:146] step: 751300, eval_loss: 3.72245e-02
I0213 03:57:04.983247 22509476222784 run_lib.py:133] step: 751350, training_loss: 3.92751e-02
I0213 03:57:23.517044 22509476222784 run_lib.py:133] step: 751400, training_loss: 4.38871e-02
I0213 03:57:23.837038 22509476222784 run_lib.py:146] step: 751400, eval_loss: 3.45351e-02
I0213 03:57:42.401888 22509476222784 run_lib.py:133] step: 751450, training_loss: 4.52565e-02
I0213 03:58:01.020085 22509476222784 run_lib.py:133] step: 751500, training_loss: 4.48621e-02
I0213 03:58:01.187253 22509476222784 run_lib.py:146] step: 751500, eval_loss: 4.56718e-02
I0213 03:58:19.824681 22509476222784 run_lib.py:133] step: 751550, training_loss: 3.00922e-02
I0213 03:58:38.400693 22509476222784 run_lib.py:133] step: 751600, training_loss: 4.37846e-02
I0213 03:58:38.607740 22509476222784 run_lib.py:146] step: 751600, eval_loss: 3.13994e-02
I0213 03:58:57.335680 22509476222784 run_lib.py:133] step: 751650, training_loss: 3.99659e-02
I0213 03:59:15.992943 22509476222784 run_lib.py:133] step: 751700, training_loss: 5.03721e-02
I0213 03:59:16.160158 22509476222784 run_lib.py:146] step: 751700, eval_loss: 5.36452e-02
I0213 03:59:34.707441 22509476222784 run_lib.py:133] step: 751750, training_loss: 3.88790e-02
I0213 03:59:53.309363 22509476222784 run_lib.py:133] step: 751800, training_loss: 3.22871e-02
I0213 03:59:53.490987 22509476222784 run_lib.py:146] step: 751800, eval_loss: 3.62434e-02
I0213 04:00:12.253377 22509476222784 run_lib.py:133] step: 751850, training_loss: 4.62171e-02
I0213 04:00:30.862422 22509476222784 run_lib.py:133] step: 751900, training_loss: 4.84154e-02
I0213 04:00:31.027708 22509476222784 run_lib.py:146] step: 751900, eval_loss: 4.09255e-02
I0213 04:00:49.550406 22509476222784 run_lib.py:133] step: 751950, training_loss: 3.54887e-02
I0213 04:01:08.137157 22509476222784 run_lib.py:133] step: 752000, training_loss: 5.06929e-02
I0213 04:01:08.334049 22509476222784 run_lib.py:146] step: 752000, eval_loss: 4.79206e-02
I0213 04:01:27.132258 22509476222784 run_lib.py:133] step: 752050, training_loss: 5.06350e-02
I0213 04:01:45.673107 22509476222784 run_lib.py:133] step: 752100, training_loss: 3.85067e-02
I0213 04:01:45.839905 22509476222784 run_lib.py:146] step: 752100, eval_loss: 3.70219e-02
I0213 04:02:04.569921 22509476222784 run_lib.py:133] step: 752150, training_loss: 4.05708e-02
I0213 04:02:23.131459 22509476222784 run_lib.py:133] step: 752200, training_loss: 4.07920e-02
I0213 04:02:23.294964 22509476222784 run_lib.py:146] step: 752200, eval_loss: 4.60822e-02
I0213 04:02:41.928286 22509476222784 run_lib.py:133] step: 752250, training_loss: 4.12442e-02
I0213 04:03:00.479954 22509476222784 run_lib.py:133] step: 752300, training_loss: 3.14791e-02
I0213 04:03:00.695723 22509476222784 run_lib.py:146] step: 752300, eval_loss: 4.14676e-02
I0213 04:03:19.287579 22509476222784 run_lib.py:133] step: 752350, training_loss: 5.75374e-02
I0213 04:03:38.012900 22509476222784 run_lib.py:133] step: 752400, training_loss: 4.81984e-02
I0213 04:03:38.175451 22509476222784 run_lib.py:146] step: 752400, eval_loss: 4.59472e-02
I0213 04:03:56.677036 22509476222784 run_lib.py:133] step: 752450, training_loss: 3.26551e-02
I0213 04:04:15.376994 22509476222784 run_lib.py:133] step: 752500, training_loss: 4.52512e-02
I0213 04:04:15.552690 22509476222784 run_lib.py:146] step: 752500, eval_loss: 4.39940e-02
I0213 04:04:34.106322 22509476222784 run_lib.py:133] step: 752550, training_loss: 4.19630e-02
I0213 04:04:52.682920 22509476222784 run_lib.py:133] step: 752600, training_loss: 3.41174e-02
I0213 04:04:52.858602 22509476222784 run_lib.py:146] step: 752600, eval_loss: 4.06183e-02
I0213 04:05:11.390696 22509476222784 run_lib.py:133] step: 752650, training_loss: 4.51182e-02
I0213 04:05:30.125409 22509476222784 run_lib.py:133] step: 752700, training_loss: 3.71878e-02
I0213 04:05:30.289935 22509476222784 run_lib.py:146] step: 752700, eval_loss: 3.99159e-02
I0213 04:05:48.807486 22509476222784 run_lib.py:133] step: 752750, training_loss: 5.00254e-02
I0213 04:06:07.338586 22509476222784 run_lib.py:133] step: 752800, training_loss: 3.93275e-02
I0213 04:06:07.504036 22509476222784 run_lib.py:146] step: 752800, eval_loss: 4.44631e-02
I0213 04:06:26.290105 22509476222784 run_lib.py:133] step: 752850, training_loss: 4.18199e-02
I0213 04:06:44.968954 22509476222784 run_lib.py:133] step: 752900, training_loss: 3.48818e-02
I0213 04:06:45.134996 22509476222784 run_lib.py:146] step: 752900, eval_loss: 4.17143e-02
I0213 04:07:03.840693 22509476222784 run_lib.py:133] step: 752950, training_loss: 3.08471e-02
I0213 04:07:22.423850 22509476222784 run_lib.py:133] step: 753000, training_loss: 3.35539e-02
I0213 04:07:22.585724 22509476222784 run_lib.py:146] step: 753000, eval_loss: 3.76186e-02
I0213 04:07:41.111720 22509476222784 run_lib.py:133] step: 753050, training_loss: 4.49447e-02
I0213 04:07:59.699531 22509476222784 run_lib.py:133] step: 753100, training_loss: 4.37667e-02
I0213 04:07:59.880455 22509476222784 run_lib.py:146] step: 753100, eval_loss: 3.28211e-02
I0213 04:08:18.678309 22509476222784 run_lib.py:133] step: 753150, training_loss: 4.10538e-02
I0213 04:08:37.349486 22509476222784 run_lib.py:133] step: 753200, training_loss: 2.80921e-02
I0213 04:08:37.514829 22509476222784 run_lib.py:146] step: 753200, eval_loss: 3.40493e-02
I0213 04:08:56.078940 22509476222784 run_lib.py:133] step: 753250, training_loss: 4.32380e-02
I0213 04:09:14.561860 22509476222784 run_lib.py:133] step: 753300, training_loss: 4.67215e-02
I0213 04:09:14.724390 22509476222784 run_lib.py:146] step: 753300, eval_loss: 3.97653e-02
I0213 04:09:33.369256 22509476222784 run_lib.py:133] step: 753350, training_loss: 3.82093e-02
I0213 04:09:51.956411 22509476222784 run_lib.py:133] step: 753400, training_loss: 3.78676e-02
I0213 04:09:52.145691 22509476222784 run_lib.py:146] step: 753400, eval_loss: 4.65354e-02
I0213 04:10:10.911450 22509476222784 run_lib.py:133] step: 753450, training_loss: 4.10206e-02
I0213 04:10:29.454179 22509476222784 run_lib.py:133] step: 753500, training_loss: 3.26013e-02
I0213 04:10:29.616697 22509476222784 run_lib.py:146] step: 753500, eval_loss: 5.44135e-02
I0213 04:10:48.302343 22509476222784 run_lib.py:133] step: 753550, training_loss: 4.09850e-02
I0213 04:11:06.930308 22509476222784 run_lib.py:133] step: 753600, training_loss: 3.50615e-02
I0213 04:11:07.107786 22509476222784 run_lib.py:146] step: 753600, eval_loss: 3.96899e-02
I0213 04:11:25.862920 22509476222784 run_lib.py:133] step: 753650, training_loss: 4.73556e-02
I0213 04:11:44.491233 22509476222784 run_lib.py:133] step: 753700, training_loss: 3.33303e-02
I0213 04:11:44.664956 22509476222784 run_lib.py:146] step: 753700, eval_loss: 4.63141e-02
I0213 04:12:03.187766 22509476222784 run_lib.py:133] step: 753750, training_loss: 3.71222e-02
I0213 04:12:21.883637 22509476222784 run_lib.py:133] step: 753800, training_loss: 4.22885e-02
I0213 04:12:22.046399 22509476222784 run_lib.py:146] step: 753800, eval_loss: 3.96214e-02
I0213 04:12:40.573061 22509476222784 run_lib.py:133] step: 753850, training_loss: 4.41553e-02
I0213 04:12:59.235478 22509476222784 run_lib.py:133] step: 753900, training_loss: 4.57838e-02
I0213 04:12:59.401964 22509476222784 run_lib.py:146] step: 753900, eval_loss: 4.12221e-02
I0213 04:13:18.187522 22509476222784 run_lib.py:133] step: 753950, training_loss: 4.89397e-02
I0213 04:13:36.839463 22509476222784 run_lib.py:133] step: 754000, training_loss: 2.81797e-02
I0213 04:13:37.003443 22509476222784 run_lib.py:146] step: 754000, eval_loss: 5.53059e-02
I0213 04:13:55.485000 22509476222784 run_lib.py:133] step: 754050, training_loss: 4.11656e-02
I0213 04:14:14.052461 22509476222784 run_lib.py:133] step: 754100, training_loss: 4.32496e-02
I0213 04:14:14.247807 22509476222784 run_lib.py:146] step: 754100, eval_loss: 4.24012e-02
I0213 04:14:32.889420 22509476222784 run_lib.py:133] step: 754150, training_loss: 4.56427e-02
I0213 04:14:51.684661 22509476222784 run_lib.py:133] step: 754200, training_loss: 4.58549e-02
I0213 04:14:51.866848 22509476222784 run_lib.py:146] step: 754200, eval_loss: 3.85193e-02
I0213 04:15:10.430411 22509476222784 run_lib.py:133] step: 754250, training_loss: 3.92690e-02
I0213 04:15:28.934205 22509476222784 run_lib.py:133] step: 754300, training_loss: 3.19018e-02
I0213 04:15:29.097637 22509476222784 run_lib.py:146] step: 754300, eval_loss: 4.03494e-02
I0213 04:15:47.585423 22509476222784 run_lib.py:133] step: 754350, training_loss: 4.90934e-02
I0213 04:16:06.332659 22509476222784 run_lib.py:133] step: 754400, training_loss: 3.43975e-02
I0213 04:16:06.526950 22509476222784 run_lib.py:146] step: 754400, eval_loss: 3.79624e-02
I0213 04:16:25.143914 22509476222784 run_lib.py:133] step: 754450, training_loss: 3.83948e-02
I0213 04:16:43.824066 22509476222784 run_lib.py:133] step: 754500, training_loss: 4.40588e-02
I0213 04:16:43.995961 22509476222784 run_lib.py:146] step: 754500, eval_loss: 4.70504e-02
I0213 04:17:02.498271 22509476222784 run_lib.py:133] step: 754550, training_loss: 3.93907e-02
I0213 04:17:21.060086 22509476222784 run_lib.py:133] step: 754600, training_loss: 5.36000e-02
I0213 04:17:21.234067 22509476222784 run_lib.py:146] step: 754600, eval_loss: 4.11079e-02
I0213 04:17:39.947163 22509476222784 run_lib.py:133] step: 754650, training_loss: 4.25170e-02
I0213 04:17:58.571205 22509476222784 run_lib.py:133] step: 754700, training_loss: 4.03510e-02
I0213 04:17:58.733338 22509476222784 run_lib.py:146] step: 754700, eval_loss: 4.03889e-02
I0213 04:18:17.312046 22509476222784 run_lib.py:133] step: 754750, training_loss: 5.28667e-02
I0213 04:18:35.898756 22509476222784 run_lib.py:133] step: 754800, training_loss: 4.19874e-02
I0213 04:18:36.062816 22509476222784 run_lib.py:146] step: 754800, eval_loss: 5.00500e-02
I0213 04:18:54.728969 22509476222784 run_lib.py:133] step: 754850, training_loss: 3.41868e-02
I0213 04:19:13.305502 22509476222784 run_lib.py:133] step: 754900, training_loss: 3.71656e-02
I0213 04:19:13.474899 22509476222784 run_lib.py:146] step: 754900, eval_loss: 4.49874e-02
I0213 04:19:32.270568 22509476222784 run_lib.py:133] step: 754950, training_loss: 4.56201e-02
I0213 04:19:50.848966 22509476222784 run_lib.py:133] step: 755000, training_loss: 3.51508e-02
I0213 04:19:51.015738 22509476222784 run_lib.py:146] step: 755000, eval_loss: 4.24816e-02
I0213 04:20:09.754698 22509476222784 run_lib.py:133] step: 755050, training_loss: 3.35569e-02
I0213 04:20:28.308117 22509476222784 run_lib.py:133] step: 755100, training_loss: 3.25871e-02
I0213 04:20:28.509753 22509476222784 run_lib.py:146] step: 755100, eval_loss: 5.17385e-02
I0213 04:20:47.081395 22509476222784 run_lib.py:133] step: 755150, training_loss: 3.94899e-02
I0213 04:21:05.844224 22509476222784 run_lib.py:133] step: 755200, training_loss: 3.80696e-02
I0213 04:21:06.010663 22509476222784 run_lib.py:146] step: 755200, eval_loss: 5.45852e-02
I0213 04:21:24.645187 22509476222784 run_lib.py:133] step: 755250, training_loss: 3.04409e-02
I0213 04:21:43.376882 22509476222784 run_lib.py:133] step: 755300, training_loss: 4.83985e-02
I0213 04:21:43.537702 22509476222784 run_lib.py:146] step: 755300, eval_loss: 3.80808e-02
I0213 04:22:02.041583 22509476222784 run_lib.py:133] step: 755350, training_loss: 3.58246e-02
I0213 04:22:20.566144 22509476222784 run_lib.py:133] step: 755400, training_loss: 3.34010e-02
I0213 04:22:20.763959 22509476222784 run_lib.py:146] step: 755400, eval_loss: 5.08647e-02
I0213 04:22:39.447635 22509476222784 run_lib.py:133] step: 755450, training_loss: 4.08449e-02
I0213 04:22:58.047891 22509476222784 run_lib.py:133] step: 755500, training_loss: 3.88702e-02
I0213 04:22:58.237788 22509476222784 run_lib.py:146] step: 755500, eval_loss: 4.86193e-02
I0213 04:23:16.825008 22509476222784 run_lib.py:133] step: 755550, training_loss: 4.84856e-02
I0213 04:23:35.560449 22509476222784 run_lib.py:133] step: 755600, training_loss: 3.48147e-02
I0213 04:23:35.725407 22509476222784 run_lib.py:146] step: 755600, eval_loss: 4.30987e-02
I0213 04:23:54.281880 22509476222784 run_lib.py:133] step: 755650, training_loss: 3.87137e-02
I0213 04:24:12.790306 22509476222784 run_lib.py:133] step: 755700, training_loss: 4.19264e-02
I0213 04:24:12.959378 22509476222784 run_lib.py:146] step: 755700, eval_loss: 4.13199e-02
I0213 04:24:31.663002 22509476222784 run_lib.py:133] step: 755750, training_loss: 4.90846e-02
I0213 04:24:50.214382 22509476222784 run_lib.py:133] step: 755800, training_loss: 4.78190e-02
I0213 04:24:50.403899 22509476222784 run_lib.py:146] step: 755800, eval_loss: 2.99727e-02
I0213 04:25:08.968707 22509476222784 run_lib.py:133] step: 755850, training_loss: 2.89857e-02
I0213 04:25:27.532849 22509476222784 run_lib.py:133] step: 755900, training_loss: 4.32396e-02
I0213 04:25:27.718783 22509476222784 run_lib.py:146] step: 755900, eval_loss: 4.89050e-02
I0213 04:25:46.441132 22509476222784 run_lib.py:133] step: 755950, training_loss: 3.95484e-02
I0213 04:26:05.123515 22509476222784 run_lib.py:133] step: 756000, training_loss: 4.23683e-02
I0213 04:26:05.318645 22509476222784 run_lib.py:146] step: 756000, eval_loss: 3.87459e-02
I0213 04:26:23.870237 22509476222784 run_lib.py:133] step: 756050, training_loss: 3.97146e-02
I0213 04:26:42.418999 22509476222784 run_lib.py:133] step: 756100, training_loss: 4.12926e-02
I0213 04:26:42.583750 22509476222784 run_lib.py:146] step: 756100, eval_loss: 4.22942e-02
I0213 04:27:01.330090 22509476222784 run_lib.py:133] step: 756150, training_loss: 4.40274e-02
I0213 04:27:19.908055 22509476222784 run_lib.py:133] step: 756200, training_loss: 3.61767e-02
I0213 04:27:20.068865 22509476222784 run_lib.py:146] step: 756200, eval_loss: 5.96494e-02
I0213 04:27:38.739852 22509476222784 run_lib.py:133] step: 756250, training_loss: 4.37798e-02
I0213 04:27:57.342533 22509476222784 run_lib.py:133] step: 756300, training_loss: 4.32022e-02
I0213 04:27:57.512044 22509476222784 run_lib.py:146] step: 756300, eval_loss: 3.95522e-02
I0213 04:28:16.271361 22509476222784 run_lib.py:133] step: 756350, training_loss: 3.94138e-02
I0213 04:28:34.817479 22509476222784 run_lib.py:133] step: 756400, training_loss: 3.50853e-02
I0213 04:28:34.991771 22509476222784 run_lib.py:146] step: 756400, eval_loss: 5.05710e-02
I0213 04:28:53.655515 22509476222784 run_lib.py:133] step: 756450, training_loss: 3.85441e-02
I0213 04:29:12.196613 22509476222784 run_lib.py:133] step: 756500, training_loss: 3.96853e-02
I0213 04:29:12.375704 22509476222784 run_lib.py:146] step: 756500, eval_loss: 3.51661e-02
I0213 04:29:30.971076 22509476222784 run_lib.py:133] step: 756550, training_loss: 2.76292e-02
I0213 04:29:49.829097 22509476222784 run_lib.py:133] step: 756600, training_loss: 4.92025e-02
I0213 04:29:49.996031 22509476222784 run_lib.py:146] step: 756600, eval_loss: 6.48303e-02
I0213 04:30:08.508928 22509476222784 run_lib.py:133] step: 756650, training_loss: 4.13544e-02
I0213 04:30:27.017145 22509476222784 run_lib.py:133] step: 756700, training_loss: 5.86055e-02
I0213 04:30:27.179678 22509476222784 run_lib.py:146] step: 756700, eval_loss: 4.53557e-02
I0213 04:30:45.841215 22509476222784 run_lib.py:133] step: 756750, training_loss: 5.11851e-02
I0213 04:31:04.471394 22509476222784 run_lib.py:133] step: 756800, training_loss: 4.24972e-02
I0213 04:31:04.639670 22509476222784 run_lib.py:146] step: 756800, eval_loss: 4.87896e-02
I0213 04:31:23.384479 22509476222784 run_lib.py:133] step: 756850, training_loss: 4.26937e-02
I0213 04:31:41.950979 22509476222784 run_lib.py:133] step: 756900, training_loss: 4.34272e-02
I0213 04:31:42.118759 22509476222784 run_lib.py:146] step: 756900, eval_loss: 3.34057e-02
I0213 04:32:00.611733 22509476222784 run_lib.py:133] step: 756950, training_loss: 4.32377e-02
I0213 04:32:19.315391 22509476222784 run_lib.py:133] step: 757000, training_loss: 4.57210e-02
I0213 04:32:19.504656 22509476222784 run_lib.py:146] step: 757000, eval_loss: 4.27366e-02
I0213 04:32:38.033259 22509476222784 run_lib.py:133] step: 757050, training_loss: 4.54789e-02
I0213 04:32:56.665141 22509476222784 run_lib.py:133] step: 757100, training_loss: 4.58898e-02
I0213 04:32:56.857190 22509476222784 run_lib.py:146] step: 757100, eval_loss: 3.88740e-02
I0213 04:33:15.425202 22509476222784 run_lib.py:133] step: 757150, training_loss: 4.91227e-02
I0213 04:33:34.137889 22509476222784 run_lib.py:133] step: 757200, training_loss: 4.42698e-02
I0213 04:33:34.298408 22509476222784 run_lib.py:146] step: 757200, eval_loss: 4.41296e-02
I0213 04:33:52.818270 22509476222784 run_lib.py:133] step: 757250, training_loss: 4.23622e-02
I0213 04:34:11.460678 22509476222784 run_lib.py:133] step: 757300, training_loss: 3.75147e-02
I0213 04:34:11.632990 22509476222784 run_lib.py:146] step: 757300, eval_loss: 4.74822e-02
I0213 04:34:30.242655 22509476222784 run_lib.py:133] step: 757350, training_loss: 4.38107e-02
I0213 04:34:48.805569 22509476222784 run_lib.py:133] step: 757400, training_loss: 5.23408e-02
I0213 04:34:48.970644 22509476222784 run_lib.py:146] step: 757400, eval_loss: 4.62358e-02
I0213 04:35:07.684162 22509476222784 run_lib.py:133] step: 757450, training_loss: 3.03317e-02
I0213 04:35:26.330783 22509476222784 run_lib.py:133] step: 757500, training_loss: 4.47828e-02
I0213 04:35:26.498857 22509476222784 run_lib.py:146] step: 757500, eval_loss: 4.61556e-02
I0213 04:35:45.070857 22509476222784 run_lib.py:133] step: 757550, training_loss: 5.27168e-02
I0213 04:36:03.715472 22509476222784 run_lib.py:133] step: 757600, training_loss: 5.11814e-02
I0213 04:36:03.905018 22509476222784 run_lib.py:146] step: 757600, eval_loss: 4.26346e-02
I0213 04:36:22.638028 22509476222784 run_lib.py:133] step: 757650, training_loss: 3.23720e-02
I0213 04:36:41.189517 22509476222784 run_lib.py:133] step: 757700, training_loss: 4.31786e-02
I0213 04:36:41.376445 22509476222784 run_lib.py:146] step: 757700, eval_loss: 4.25923e-02
I0213 04:37:00.057112 22509476222784 run_lib.py:133] step: 757750, training_loss: 3.74060e-02
I0213 04:37:18.600494 22509476222784 run_lib.py:133] step: 757800, training_loss: 4.31690e-02
I0213 04:37:18.801821 22509476222784 run_lib.py:146] step: 757800, eval_loss: 4.05821e-02
I0213 04:37:37.502784 22509476222784 run_lib.py:133] step: 757850, training_loss: 4.63192e-02
I0213 04:37:56.122906 22509476222784 run_lib.py:133] step: 757900, training_loss: 5.46430e-02
I0213 04:37:56.314730 22509476222784 run_lib.py:146] step: 757900, eval_loss: 3.32702e-02
I0213 04:38:14.892908 22509476222784 run_lib.py:133] step: 757950, training_loss: 4.33515e-02
I0213 04:38:33.657474 22509476222784 run_lib.py:133] step: 758000, training_loss: 5.05385e-02
I0213 04:38:33.822605 22509476222784 run_lib.py:146] step: 758000, eval_loss: 4.64068e-02
I0213 04:38:52.377495 22509476222784 run_lib.py:133] step: 758050, training_loss: 4.51449e-02
I0213 04:39:11.115482 22509476222784 run_lib.py:133] step: 758100, training_loss: 4.54179e-02
I0213 04:39:11.279506 22509476222784 run_lib.py:146] step: 758100, eval_loss: 4.86391e-02
I0213 04:39:29.886327 22509476222784 run_lib.py:133] step: 758150, training_loss: 4.12155e-02
I0213 04:39:48.441599 22509476222784 run_lib.py:133] step: 758200, training_loss: 3.69631e-02
I0213 04:39:48.603611 22509476222784 run_lib.py:146] step: 758200, eval_loss: 4.00889e-02
I0213 04:40:07.322246 22509476222784 run_lib.py:133] step: 758250, training_loss: 5.05171e-02
I0213 04:40:25.892826 22509476222784 run_lib.py:133] step: 758300, training_loss: 4.38717e-02
I0213 04:40:26.058698 22509476222784 run_lib.py:146] step: 758300, eval_loss: 4.62657e-02
I0213 04:40:44.624201 22509476222784 run_lib.py:133] step: 758350, training_loss: 3.86355e-02
I0213 04:41:03.381342 22509476222784 run_lib.py:133] step: 758400, training_loss: 4.68172e-02
I0213 04:41:03.580672 22509476222784 run_lib.py:146] step: 758400, eval_loss: 4.17600e-02
I0213 04:41:22.114881 22509476222784 run_lib.py:133] step: 758450, training_loss: 3.35549e-02
I0213 04:41:40.631733 22509476222784 run_lib.py:133] step: 758500, training_loss: 3.16882e-02
I0213 04:41:40.991902 22509476222784 run_lib.py:146] step: 758500, eval_loss: 5.67766e-02
I0213 04:41:59.534840 22509476222784 run_lib.py:133] step: 758550, training_loss: 5.16988e-02
I0213 04:42:18.029074 22509476222784 run_lib.py:133] step: 758600, training_loss: 4.88044e-02
I0213 04:42:18.199197 22509476222784 run_lib.py:146] step: 758600, eval_loss: 4.10743e-02
I0213 04:42:36.813289 22509476222784 run_lib.py:133] step: 758650, training_loss: 3.76872e-02
I0213 04:42:55.340491 22509476222784 run_lib.py:133] step: 758700, training_loss: 4.05213e-02
I0213 04:42:55.506850 22509476222784 run_lib.py:146] step: 758700, eval_loss: 4.91562e-02
I0213 04:43:14.268623 22509476222784 run_lib.py:133] step: 758750, training_loss: 5.60800e-02
I0213 04:43:32.929133 22509476222784 run_lib.py:133] step: 758800, training_loss: 3.66583e-02
I0213 04:43:33.097367 22509476222784 run_lib.py:146] step: 758800, eval_loss: 5.30478e-02
I0213 04:43:51.635823 22509476222784 run_lib.py:133] step: 758850, training_loss: 3.71016e-02
I0213 04:44:10.189015 22509476222784 run_lib.py:133] step: 758900, training_loss: 4.45827e-02
I0213 04:44:10.363761 22509476222784 run_lib.py:146] step: 758900, eval_loss: 4.01562e-02
I0213 04:44:29.161274 22509476222784 run_lib.py:133] step: 758950, training_loss: 4.05334e-02
I0213 04:44:47.817145 22509476222784 run_lib.py:133] step: 759000, training_loss: 3.31052e-02
I0213 04:44:48.030207 22509476222784 run_lib.py:146] step: 759000, eval_loss: 5.13727e-02
I0213 04:45:06.613066 22509476222784 run_lib.py:133] step: 759050, training_loss: 4.60442e-02
I0213 04:45:25.090142 22509476222784 run_lib.py:133] step: 759100, training_loss: 4.24883e-02
I0213 04:45:25.250872 22509476222784 run_lib.py:146] step: 759100, eval_loss: 3.82728e-02
I0213 04:45:43.940035 22509476222784 run_lib.py:133] step: 759150, training_loss: 4.36907e-02
I0213 04:46:02.510528 22509476222784 run_lib.py:133] step: 759200, training_loss: 3.62772e-02
I0213 04:46:02.691950 22509476222784 run_lib.py:146] step: 759200, eval_loss: 4.71272e-02
I0213 04:46:21.454533 22509476222784 run_lib.py:133] step: 759250, training_loss: 3.38257e-02
I0213 04:46:40.072909 22509476222784 run_lib.py:133] step: 759300, training_loss: 4.88403e-02
I0213 04:46:40.236797 22509476222784 run_lib.py:146] step: 759300, eval_loss: 4.11810e-02
I0213 04:46:58.941725 22509476222784 run_lib.py:133] step: 759350, training_loss: 4.58786e-02
I0213 04:47:17.516811 22509476222784 run_lib.py:133] step: 759400, training_loss: 4.15178e-02
I0213 04:47:17.686665 22509476222784 run_lib.py:146] step: 759400, eval_loss: 3.51534e-02
I0213 04:47:36.282805 22509476222784 run_lib.py:133] step: 759450, training_loss: 3.79797e-02
I0213 04:47:55.104720 22509476222784 run_lib.py:133] step: 759500, training_loss: 4.30534e-02
I0213 04:47:55.268941 22509476222784 run_lib.py:146] step: 759500, eval_loss: 4.37088e-02
I0213 04:48:13.901454 22509476222784 run_lib.py:133] step: 759550, training_loss: 3.65427e-02
I0213 04:48:32.585175 22509476222784 run_lib.py:133] step: 759600, training_loss: 4.26062e-02
I0213 04:48:32.745693 22509476222784 run_lib.py:146] step: 759600, eval_loss: 4.63492e-02
I0213 04:48:51.270142 22509476222784 run_lib.py:133] step: 759650, training_loss: 3.20788e-02
I0213 04:49:09.822535 22509476222784 run_lib.py:133] step: 759700, training_loss: 3.90665e-02
I0213 04:49:10.003083 22509476222784 run_lib.py:146] step: 759700, eval_loss: 4.43732e-02
I0213 04:49:28.834615 22509476222784 run_lib.py:133] step: 759750, training_loss: 4.15435e-02
I0213 04:49:47.417432 22509476222784 run_lib.py:133] step: 759800, training_loss: 3.46308e-02
I0213 04:49:47.586628 22509476222784 run_lib.py:146] step: 759800, eval_loss: 5.76825e-02
I0213 04:50:06.138238 22509476222784 run_lib.py:133] step: 759850, training_loss: 4.48167e-02
I0213 04:50:24.661300 22509476222784 run_lib.py:133] step: 759900, training_loss: 3.96298e-02
I0213 04:50:24.825747 22509476222784 run_lib.py:146] step: 759900, eval_loss: 3.85796e-02
I0213 04:50:43.527127 22509476222784 run_lib.py:133] step: 759950, training_loss: 4.34832e-02
I0213 04:51:02.200282 22509476222784 run_lib.py:133] step: 760000, training_loss: 5.50305e-02
I0213 04:51:02.949829 22509476222784 run_lib.py:146] step: 760000, eval_loss: 5.32187e-02
I0213 04:51:24.458762 22509476222784 run_lib.py:133] step: 760050, training_loss: 4.52722e-02
I0213 04:51:43.055391 22509476222784 run_lib.py:133] step: 760100, training_loss: 3.56757e-02
I0213 04:51:43.250737 22509476222784 run_lib.py:146] step: 760100, eval_loss: 3.81179e-02
I0213 04:52:01.962717 22509476222784 run_lib.py:133] step: 760150, training_loss: 4.92099e-02
I0213 04:52:20.546950 22509476222784 run_lib.py:133] step: 760200, training_loss: 4.02778e-02
I0213 04:52:20.738899 22509476222784 run_lib.py:146] step: 760200, eval_loss: 4.74730e-02
I0213 04:52:39.329067 22509476222784 run_lib.py:133] step: 760250, training_loss: 4.45687e-02
I0213 04:52:58.076123 22509476222784 run_lib.py:133] step: 760300, training_loss: 5.29481e-02
I0213 04:52:58.253716 22509476222784 run_lib.py:146] step: 760300, eval_loss: 4.24057e-02
I0213 04:53:16.800789 22509476222784 run_lib.py:133] step: 760350, training_loss: 4.62955e-02
I0213 04:53:35.427214 22509476222784 run_lib.py:133] step: 760400, training_loss: 3.64281e-02
I0213 04:53:35.638749 22509476222784 run_lib.py:146] step: 760400, eval_loss: 4.39963e-02
I0213 04:53:54.219228 22509476222784 run_lib.py:133] step: 760450, training_loss: 4.42073e-02
I0213 04:54:12.967758 22509476222784 run_lib.py:133] step: 760500, training_loss: 3.83334e-02
I0213 04:54:13.133485 22509476222784 run_lib.py:146] step: 760500, eval_loss: 3.31593e-02
I0213 04:54:31.731989 22509476222784 run_lib.py:133] step: 760550, training_loss: 4.81842e-02
I0213 04:54:50.335232 22509476222784 run_lib.py:133] step: 760600, training_loss: 4.69815e-02
I0213 04:54:50.496433 22509476222784 run_lib.py:146] step: 760600, eval_loss: 4.58658e-02
I0213 04:55:09.035828 22509476222784 run_lib.py:133] step: 760650, training_loss: 5.22016e-02
I0213 04:55:27.655582 22509476222784 run_lib.py:133] step: 760700, training_loss: 3.96047e-02
I0213 04:55:27.820775 22509476222784 run_lib.py:146] step: 760700, eval_loss: 3.77412e-02
I0213 04:55:46.549376 22509476222784 run_lib.py:133] step: 760750, training_loss: 5.31883e-02
I0213 04:56:05.312641 22509476222784 run_lib.py:133] step: 760800, training_loss: 4.45941e-02
I0213 04:56:05.483675 22509476222784 run_lib.py:146] step: 760800, eval_loss: 3.63639e-02
I0213 04:56:24.028914 22509476222784 run_lib.py:133] step: 760850, training_loss: 4.31144e-02
I0213 04:56:42.596668 22509476222784 run_lib.py:133] step: 760900, training_loss: 4.47689e-02
I0213 04:56:42.762708 22509476222784 run_lib.py:146] step: 760900, eval_loss: 3.12264e-02
I0213 04:57:01.465183 22509476222784 run_lib.py:133] step: 760950, training_loss: 4.61631e-02
I0213 04:57:20.020667 22509476222784 run_lib.py:133] step: 761000, training_loss: 3.86548e-02
I0213 04:57:20.185453 22509476222784 run_lib.py:146] step: 761000, eval_loss: 4.33356e-02
I0213 04:57:38.984613 22509476222784 run_lib.py:133] step: 761050, training_loss: 4.63699e-02
I0213 04:57:57.699108 22509476222784 run_lib.py:133] step: 761100, training_loss: 4.91813e-02
I0213 04:57:57.867128 22509476222784 run_lib.py:146] step: 761100, eval_loss: 4.63072e-02
I0213 04:58:16.598695 22509476222784 run_lib.py:133] step: 761150, training_loss: 3.24045e-02
I0213 04:58:35.159716 22509476222784 run_lib.py:133] step: 761200, training_loss: 3.54690e-02
I0213 04:58:35.343784 22509476222784 run_lib.py:146] step: 761200, eval_loss: 4.77186e-02
I0213 04:58:53.925115 22509476222784 run_lib.py:133] step: 761250, training_loss: 4.36912e-02
I0213 04:59:12.671140 22509476222784 run_lib.py:133] step: 761300, training_loss: 4.18424e-02
I0213 04:59:12.871565 22509476222784 run_lib.py:146] step: 761300, eval_loss: 4.55495e-02
I0213 04:59:31.400469 22509476222784 run_lib.py:133] step: 761350, training_loss: 4.45166e-02
I0213 04:59:50.207520 22509476222784 run_lib.py:133] step: 761400, training_loss: 4.87423e-02
I0213 04:59:50.409305 22509476222784 run_lib.py:146] step: 761400, eval_loss: 4.49840e-02
I0213 05:00:08.970639 22509476222784 run_lib.py:133] step: 761450, training_loss: 2.94103e-02
I0213 05:00:27.530615 22509476222784 run_lib.py:133] step: 761500, training_loss: 2.82446e-02
I0213 05:00:27.707857 22509476222784 run_lib.py:146] step: 761500, eval_loss: 4.15129e-02
I0213 05:00:46.266741 22509476222784 run_lib.py:133] step: 761550, training_loss: 3.36500e-02
I0213 05:01:05.032335 22509476222784 run_lib.py:133] step: 761600, training_loss: 2.70549e-02
I0213 05:01:05.198682 22509476222784 run_lib.py:146] step: 761600, eval_loss: 3.52350e-02
I0213 05:01:23.798447 22509476222784 run_lib.py:133] step: 761650, training_loss: 3.97666e-02
I0213 05:01:42.364989 22509476222784 run_lib.py:133] step: 761700, training_loss: 3.68327e-02
I0213 05:01:42.531906 22509476222784 run_lib.py:146] step: 761700, eval_loss: 4.67866e-02
I0213 05:02:01.197996 22509476222784 run_lib.py:133] step: 761750, training_loss: 5.57288e-02
I0213 05:02:19.714804 22509476222784 run_lib.py:133] step: 761800, training_loss: 3.10464e-02
I0213 05:02:19.882710 22509476222784 run_lib.py:146] step: 761800, eval_loss: 3.87714e-02
I0213 05:02:38.544601 22509476222784 run_lib.py:133] step: 761850, training_loss: 4.69808e-02
I0213 05:02:57.137283 22509476222784 run_lib.py:133] step: 761900, training_loss: 4.00996e-02
I0213 05:02:57.301944 22509476222784 run_lib.py:146] step: 761900, eval_loss: 5.56063e-02
I0213 05:03:15.817415 22509476222784 run_lib.py:133] step: 761950, training_loss: 4.28903e-02
I0213 05:03:34.356805 22509476222784 run_lib.py:133] step: 762000, training_loss: 3.95285e-02
I0213 05:03:34.518620 22509476222784 run_lib.py:146] step: 762000, eval_loss: 4.06388e-02
I0213 05:03:53.237842 22509476222784 run_lib.py:133] step: 762050, training_loss: 6.22946e-02
I0213 05:04:11.896726 22509476222784 run_lib.py:133] step: 762100, training_loss: 5.02398e-02
I0213 05:04:12.097269 22509476222784 run_lib.py:146] step: 762100, eval_loss: 4.00303e-02
I0213 05:04:30.714189 22509476222784 run_lib.py:133] step: 762150, training_loss: 4.51378e-02
I0213 05:04:49.297028 22509476222784 run_lib.py:133] step: 762200, training_loss: 5.74773e-02
I0213 05:04:49.464800 22509476222784 run_lib.py:146] step: 762200, eval_loss: 4.48017e-02
I0213 05:05:08.219421 22509476222784 run_lib.py:133] step: 762250, training_loss: 4.60787e-02
I0213 05:05:26.805768 22509476222784 run_lib.py:133] step: 762300, training_loss: 3.58475e-02
I0213 05:05:26.970745 22509476222784 run_lib.py:146] step: 762300, eval_loss: 4.50270e-02
I0213 05:05:45.637352 22509476222784 run_lib.py:133] step: 762350, training_loss: 4.05671e-02
I0213 05:06:04.175480 22509476222784 run_lib.py:133] step: 762400, training_loss: 4.09793e-02
I0213 05:06:04.338183 22509476222784 run_lib.py:146] step: 762400, eval_loss: 4.38954e-02
I0213 05:06:23.137349 22509476222784 run_lib.py:133] step: 762450, training_loss: 3.62458e-02
I0213 05:06:41.737415 22509476222784 run_lib.py:133] step: 762500, training_loss: 4.06723e-02
I0213 05:06:41.929761 22509476222784 run_lib.py:146] step: 762500, eval_loss: 5.19353e-02
I0213 05:07:00.639916 22509476222784 run_lib.py:133] step: 762550, training_loss: 4.93666e-02
I0213 05:07:19.194426 22509476222784 run_lib.py:133] step: 762600, training_loss: 4.83836e-02
I0213 05:07:19.366711 22509476222784 run_lib.py:146] step: 762600, eval_loss: 3.57069e-02
I0213 05:07:37.974347 22509476222784 run_lib.py:133] step: 762650, training_loss: 3.18732e-02
I0213 05:07:56.873388 22509476222784 run_lib.py:133] step: 762700, training_loss: 4.32578e-02
I0213 05:07:57.042353 22509476222784 run_lib.py:146] step: 762700, eval_loss: 4.32723e-02
I0213 05:08:15.581874 22509476222784 run_lib.py:133] step: 762750, training_loss: 4.00189e-02
I0213 05:08:34.135086 22509476222784 run_lib.py:133] step: 762800, training_loss: 4.08661e-02
I0213 05:08:34.299961 22509476222784 run_lib.py:146] step: 762800, eval_loss: 4.73228e-02
I0213 05:08:53.053330 22509476222784 run_lib.py:133] step: 762850, training_loss: 4.71766e-02
I0213 05:09:11.709086 22509476222784 run_lib.py:133] step: 762900, training_loss: 4.85793e-02
I0213 05:09:11.900737 22509476222784 run_lib.py:146] step: 762900, eval_loss: 4.06343e-02
I0213 05:09:30.476613 22509476222784 run_lib.py:133] step: 762950, training_loss: 3.90457e-02
I0213 05:09:49.042171 22509476222784 run_lib.py:133] step: 763000, training_loss: 3.65124e-02
I0213 05:09:49.205975 22509476222784 run_lib.py:146] step: 763000, eval_loss: 4.03104e-02
I0213 05:10:07.838456 22509476222784 run_lib.py:133] step: 763050, training_loss: 5.36386e-02
I0213 05:10:26.557466 22509476222784 run_lib.py:133] step: 763100, training_loss: 3.44241e-02
I0213 05:10:26.723745 22509476222784 run_lib.py:146] step: 763100, eval_loss: 4.17785e-02
I0213 05:10:45.253811 22509476222784 run_lib.py:133] step: 763150, training_loss: 4.83845e-02
I0213 05:11:03.832018 22509476222784 run_lib.py:133] step: 763200, training_loss: 4.78715e-02
I0213 05:11:04.012742 22509476222784 run_lib.py:146] step: 763200, eval_loss: 3.97787e-02
I0213 05:11:22.638816 22509476222784 run_lib.py:133] step: 763250, training_loss: 4.66945e-02
I0213 05:11:41.382639 22509476222784 run_lib.py:133] step: 763300, training_loss: 5.02779e-02
I0213 05:11:41.547090 22509476222784 run_lib.py:146] step: 763300, eval_loss: 4.16637e-02
I0213 05:12:00.157212 22509476222784 run_lib.py:133] step: 763350, training_loss: 4.69844e-02
I0213 05:12:18.739491 22509476222784 run_lib.py:133] step: 763400, training_loss: 4.45512e-02
I0213 05:12:18.902821 22509476222784 run_lib.py:146] step: 763400, eval_loss: 2.78629e-02
I0213 05:12:37.458238 22509476222784 run_lib.py:133] step: 763450, training_loss: 5.00751e-02
I0213 05:12:56.047859 22509476222784 run_lib.py:133] step: 763500, training_loss: 3.73228e-02
I0213 05:12:56.216089 22509476222784 run_lib.py:146] step: 763500, eval_loss: 4.74708e-02
I0213 05:13:14.949931 22509476222784 run_lib.py:133] step: 763550, training_loss: 4.90440e-02
I0213 05:13:33.587119 22509476222784 run_lib.py:133] step: 763600, training_loss: 4.41117e-02
I0213 05:13:33.770967 22509476222784 run_lib.py:146] step: 763600, eval_loss: 4.72028e-02
I0213 05:13:52.333171 22509476222784 run_lib.py:133] step: 763650, training_loss: 3.43863e-02
I0213 05:14:10.883839 22509476222784 run_lib.py:133] step: 763700, training_loss: 5.52654e-02
I0213 05:14:11.049149 22509476222784 run_lib.py:146] step: 763700, eval_loss: 4.36269e-02
I0213 05:14:29.785863 22509476222784 run_lib.py:133] step: 763750, training_loss: 3.46846e-02
I0213 05:14:48.370569 22509476222784 run_lib.py:133] step: 763800, training_loss: 4.38336e-02
I0213 05:14:48.537264 22509476222784 run_lib.py:146] step: 763800, eval_loss: 5.47912e-02
I0213 05:15:07.308844 22509476222784 run_lib.py:133] step: 763850, training_loss: 5.19572e-02
I0213 05:15:25.857444 22509476222784 run_lib.py:133] step: 763900, training_loss: 4.26359e-02
I0213 05:15:26.017847 22509476222784 run_lib.py:146] step: 763900, eval_loss: 4.47264e-02
I0213 05:15:44.714923 22509476222784 run_lib.py:133] step: 763950, training_loss: 5.19120e-02
I0213 05:16:03.308822 22509476222784 run_lib.py:133] step: 764000, training_loss: 3.60321e-02
I0213 05:16:03.476593 22509476222784 run_lib.py:146] step: 764000, eval_loss: 4.02593e-02
I0213 05:16:22.147437 22509476222784 run_lib.py:133] step: 764050, training_loss: 4.18361e-02
I0213 05:16:40.913549 22509476222784 run_lib.py:133] step: 764100, training_loss: 4.54889e-02
I0213 05:16:41.115720 22509476222784 run_lib.py:146] step: 764100, eval_loss: 5.36805e-02
I0213 05:16:59.634091 22509476222784 run_lib.py:133] step: 764150, training_loss: 4.00615e-02
I0213 05:17:18.300302 22509476222784 run_lib.py:133] step: 764200, training_loss: 4.66235e-02
I0213 05:17:18.470724 22509476222784 run_lib.py:146] step: 764200, eval_loss: 4.90841e-02
I0213 05:17:37.029843 22509476222784 run_lib.py:133] step: 764250, training_loss: 3.90040e-02
I0213 05:17:55.692929 22509476222784 run_lib.py:133] step: 764300, training_loss: 3.83664e-02
I0213 05:17:55.887154 22509476222784 run_lib.py:146] step: 764300, eval_loss: 5.74836e-02
I0213 05:18:14.668135 22509476222784 run_lib.py:133] step: 764350, training_loss: 4.34662e-02
I0213 05:18:33.189265 22509476222784 run_lib.py:133] step: 764400, training_loss: 5.10110e-02
I0213 05:18:33.351840 22509476222784 run_lib.py:146] step: 764400, eval_loss: 3.88734e-02
I0213 05:18:51.901329 22509476222784 run_lib.py:133] step: 764450, training_loss: 4.01343e-02
I0213 05:19:10.592611 22509476222784 run_lib.py:133] step: 764500, training_loss: 4.39273e-02
I0213 05:19:10.756765 22509476222784 run_lib.py:146] step: 764500, eval_loss: 4.08822e-02
I0213 05:19:29.305786 22509476222784 run_lib.py:133] step: 764550, training_loss: 4.10868e-02
I0213 05:19:47.934092 22509476222784 run_lib.py:133] step: 764600, training_loss: 5.40452e-02
I0213 05:19:48.101932 22509476222784 run_lib.py:146] step: 764600, eval_loss: 5.52427e-02
I0213 05:20:06.813006 22509476222784 run_lib.py:133] step: 764650, training_loss: 3.52037e-02
I0213 05:20:25.363588 22509476222784 run_lib.py:133] step: 764700, training_loss: 4.32710e-02
I0213 05:20:25.531609 22509476222784 run_lib.py:146] step: 764700, eval_loss: 3.79910e-02
I0213 05:20:44.059563 22509476222784 run_lib.py:133] step: 764750, training_loss: 3.00360e-02
I0213 05:21:02.594032 22509476222784 run_lib.py:133] step: 764800, training_loss: 3.91861e-02
I0213 05:21:02.791538 22509476222784 run_lib.py:146] step: 764800, eval_loss: 4.19684e-02
I0213 05:21:21.556503 22509476222784 run_lib.py:133] step: 764850, training_loss: 4.27865e-02
I0213 05:21:40.220330 22509476222784 run_lib.py:133] step: 764900, training_loss: 3.77515e-02
I0213 05:21:40.407732 22509476222784 run_lib.py:146] step: 764900, eval_loss: 4.65216e-02
I0213 05:21:58.925363 22509476222784 run_lib.py:133] step: 764950, training_loss: 4.30387e-02
I0213 05:22:17.492868 22509476222784 run_lib.py:133] step: 765000, training_loss: 4.28909e-02
I0213 05:22:17.687910 22509476222784 run_lib.py:146] step: 765000, eval_loss: 4.97760e-02
I0213 05:22:36.427194 22509476222784 run_lib.py:133] step: 765050, training_loss: 4.18337e-02
I0213 05:22:55.039051 22509476222784 run_lib.py:133] step: 765100, training_loss: 3.41986e-02
I0213 05:22:55.249769 22509476222784 run_lib.py:146] step: 765100, eval_loss: 4.95453e-02
I0213 05:23:13.985306 22509476222784 run_lib.py:133] step: 765150, training_loss: 3.65766e-02
I0213 05:23:32.576056 22509476222784 run_lib.py:133] step: 765200, training_loss: 5.82952e-02
I0213 05:23:32.767019 22509476222784 run_lib.py:146] step: 765200, eval_loss: 4.94620e-02
I0213 05:23:51.469086 22509476222784 run_lib.py:133] step: 765250, training_loss: 4.44661e-02
I0213 05:24:10.007130 22509476222784 run_lib.py:133] step: 765300, training_loss: 4.86154e-02
I0213 05:24:10.206439 22509476222784 run_lib.py:146] step: 765300, eval_loss: 4.64564e-02
I0213 05:24:28.921990 22509476222784 run_lib.py:133] step: 765350, training_loss: 4.39353e-02
I0213 05:24:47.526456 22509476222784 run_lib.py:133] step: 765400, training_loss: 4.11024e-02
I0213 05:24:47.694995 22509476222784 run_lib.py:146] step: 765400, eval_loss: 4.27542e-02
I0213 05:25:06.225281 22509476222784 run_lib.py:133] step: 765450, training_loss: 4.22913e-02
I0213 05:25:24.957712 22509476222784 run_lib.py:133] step: 765500, training_loss: 3.64932e-02
I0213 05:25:25.124889 22509476222784 run_lib.py:146] step: 765500, eval_loss: 3.83018e-02
I0213 05:25:43.631187 22509476222784 run_lib.py:133] step: 765550, training_loss: 5.50142e-02
I0213 05:26:02.226009 22509476222784 run_lib.py:133] step: 765600, training_loss: 3.24317e-02
I0213 05:26:02.408498 22509476222784 run_lib.py:146] step: 765600, eval_loss: 3.83210e-02
I0213 05:26:21.191089 22509476222784 run_lib.py:133] step: 765650, training_loss: 4.26619e-02
I0213 05:26:39.769506 22509476222784 run_lib.py:133] step: 765700, training_loss: 3.42546e-02
I0213 05:26:39.933430 22509476222784 run_lib.py:146] step: 765700, eval_loss: 4.24106e-02
I0213 05:26:58.679196 22509476222784 run_lib.py:133] step: 765750, training_loss: 3.68957e-02
I0213 05:27:17.165569 22509476222784 run_lib.py:133] step: 765800, training_loss: 4.57669e-02
I0213 05:27:17.325352 22509476222784 run_lib.py:146] step: 765800, eval_loss: 4.25928e-02
I0213 05:27:35.803575 22509476222784 run_lib.py:133] step: 765850, training_loss: 4.32869e-02
I0213 05:27:54.475054 22509476222784 run_lib.py:133] step: 765900, training_loss: 3.94208e-02
I0213 05:27:54.645815 22509476222784 run_lib.py:146] step: 765900, eval_loss: 4.57614e-02
I0213 05:28:13.161282 22509476222784 run_lib.py:133] step: 765950, training_loss: 4.97600e-02
I0213 05:28:31.743317 22509476222784 run_lib.py:133] step: 766000, training_loss: 4.20617e-02
I0213 05:28:31.908912 22509476222784 run_lib.py:146] step: 766000, eval_loss: 3.34981e-02
I0213 05:28:50.438472 22509476222784 run_lib.py:133] step: 766050, training_loss: 3.81376e-02
I0213 05:29:09.123667 22509476222784 run_lib.py:133] step: 766100, training_loss: 3.74636e-02
I0213 05:29:09.291744 22509476222784 run_lib.py:146] step: 766100, eval_loss: 3.79703e-02
I0213 05:29:27.859661 22509476222784 run_lib.py:133] step: 766150, training_loss: 4.05771e-02
I0213 05:29:46.567648 22509476222784 run_lib.py:133] step: 766200, training_loss: 4.54090e-02
I0213 05:29:46.759506 22509476222784 run_lib.py:146] step: 766200, eval_loss: 3.84980e-02
I0213 05:30:05.393347 22509476222784 run_lib.py:133] step: 766250, training_loss: 2.82348e-02
I0213 05:30:23.939990 22509476222784 run_lib.py:133] step: 766300, training_loss: 3.53953e-02
I0213 05:30:24.098880 22509476222784 run_lib.py:146] step: 766300, eval_loss: 4.03234e-02
I0213 05:30:42.800144 22509476222784 run_lib.py:133] step: 766350, training_loss: 4.08427e-02
I0213 05:31:01.429756 22509476222784 run_lib.py:133] step: 766400, training_loss: 4.05566e-02
I0213 05:31:01.607095 22509476222784 run_lib.py:146] step: 766400, eval_loss: 4.09778e-02
I0213 05:31:20.215272 22509476222784 run_lib.py:133] step: 766450, training_loss: 4.65464e-02
I0213 05:31:38.786612 22509476222784 run_lib.py:133] step: 766500, training_loss: 3.82522e-02
I0213 05:31:38.951776 22509476222784 run_lib.py:146] step: 766500, eval_loss: 4.43732e-02
I0213 05:31:57.646323 22509476222784 run_lib.py:133] step: 766550, training_loss: 4.60812e-02
I0213 05:32:16.186180 22509476222784 run_lib.py:133] step: 766600, training_loss: 5.29583e-02
I0213 05:32:16.350596 22509476222784 run_lib.py:146] step: 766600, eval_loss: 3.77690e-02
I0213 05:32:35.006849 22509476222784 run_lib.py:133] step: 766650, training_loss: 5.51116e-02
I0213 05:32:53.615592 22509476222784 run_lib.py:133] step: 766700, training_loss: 5.03736e-02
I0213 05:32:53.805886 22509476222784 run_lib.py:146] step: 766700, eval_loss: 3.95579e-02
I0213 05:33:12.586491 22509476222784 run_lib.py:133] step: 766750, training_loss: 3.68225e-02
I0213 05:33:31.125400 22509476222784 run_lib.py:133] step: 766800, training_loss: 3.97592e-02
I0213 05:33:31.323434 22509476222784 run_lib.py:146] step: 766800, eval_loss: 4.57467e-02
I0213 05:33:49.810876 22509476222784 run_lib.py:133] step: 766850, training_loss: 4.45662e-02
I0213 05:34:08.562702 22509476222784 run_lib.py:133] step: 766900, training_loss: 4.00393e-02
I0213 05:34:08.756949 22509476222784 run_lib.py:146] step: 766900, eval_loss: 4.66444e-02
I0213 05:34:27.413186 22509476222784 run_lib.py:133] step: 766950, training_loss: 4.05397e-02
I0213 05:34:46.227082 22509476222784 run_lib.py:133] step: 767000, training_loss: 4.53440e-02
I0213 05:34:46.429753 22509476222784 run_lib.py:146] step: 767000, eval_loss: 4.31214e-02
I0213 05:35:04.959177 22509476222784 run_lib.py:133] step: 767050, training_loss: 5.14960e-02
I0213 05:35:23.498359 22509476222784 run_lib.py:133] step: 767100, training_loss: 5.38252e-02
I0213 05:35:23.683501 22509476222784 run_lib.py:146] step: 767100, eval_loss: 4.99028e-02
I0213 05:35:42.368870 22509476222784 run_lib.py:133] step: 767150, training_loss: 4.49190e-02
I0213 05:36:00.986327 22509476222784 run_lib.py:133] step: 767200, training_loss: 4.56441e-02
I0213 05:36:01.186026 22509476222784 run_lib.py:146] step: 767200, eval_loss: 3.72138e-02
I0213 05:36:19.788330 22509476222784 run_lib.py:133] step: 767250, training_loss: 4.70295e-02
I0213 05:36:38.529477 22509476222784 run_lib.py:133] step: 767300, training_loss: 4.39238e-02
I0213 05:36:38.710778 22509476222784 run_lib.py:146] step: 767300, eval_loss: 4.22725e-02
I0213 05:36:57.258239 22509476222784 run_lib.py:133] step: 767350, training_loss: 4.38838e-02
I0213 05:37:15.795952 22509476222784 run_lib.py:133] step: 767400, training_loss: 2.52153e-02
I0213 05:37:16.111756 22509476222784 run_lib.py:146] step: 767400, eval_loss: 4.50648e-02
I0213 05:37:34.711680 22509476222784 run_lib.py:133] step: 767450, training_loss: 3.83392e-02
I0213 05:37:53.337283 22509476222784 run_lib.py:133] step: 767500, training_loss: 4.25478e-02
I0213 05:37:53.501917 22509476222784 run_lib.py:146] step: 767500, eval_loss: 4.82715e-02
I0213 05:38:12.040893 22509476222784 run_lib.py:133] step: 767550, training_loss: 3.44450e-02
I0213 05:38:30.527324 22509476222784 run_lib.py:133] step: 767600, training_loss: 3.73065e-02
I0213 05:38:30.690791 22509476222784 run_lib.py:146] step: 767600, eval_loss: 4.26796e-02
I0213 05:38:49.375308 22509476222784 run_lib.py:133] step: 767650, training_loss: 4.64713e-02
I0213 05:39:08.011318 22509476222784 run_lib.py:133] step: 767700, training_loss: 3.99462e-02
I0213 05:39:08.174621 22509476222784 run_lib.py:146] step: 767700, eval_loss: 4.83597e-02
I0213 05:39:26.778952 22509476222784 run_lib.py:133] step: 767750, training_loss: 3.78165e-02
I0213 05:39:45.360656 22509476222784 run_lib.py:133] step: 767800, training_loss: 3.80420e-02
I0213 05:39:45.524887 22509476222784 run_lib.py:146] step: 767800, eval_loss: 4.10112e-02
I0213 05:40:04.257915 22509476222784 run_lib.py:133] step: 767850, training_loss: 3.84410e-02
I0213 05:40:22.930516 22509476222784 run_lib.py:133] step: 767900, training_loss: 4.19086e-02
I0213 05:40:23.104967 22509476222784 run_lib.py:146] step: 767900, eval_loss: 3.96487e-02
I0213 05:40:41.663597 22509476222784 run_lib.py:133] step: 767950, training_loss: 4.83225e-02
I0213 05:41:00.283329 22509476222784 run_lib.py:133] step: 768000, training_loss: 3.88525e-02
I0213 05:41:00.448920 22509476222784 run_lib.py:146] step: 768000, eval_loss: 4.77799e-02
I0213 05:41:19.197082 22509476222784 run_lib.py:133] step: 768050, training_loss: 6.27197e-02
I0213 05:41:37.790389 22509476222784 run_lib.py:133] step: 768100, training_loss: 6.06148e-02
I0213 05:41:38.000818 22509476222784 run_lib.py:146] step: 768100, eval_loss: 4.42819e-02
I0213 05:41:56.697105 22509476222784 run_lib.py:133] step: 768150, training_loss: 4.41399e-02
I0213 05:42:15.228144 22509476222784 run_lib.py:133] step: 768200, training_loss: 5.53813e-02
I0213 05:42:15.389939 22509476222784 run_lib.py:146] step: 768200, eval_loss: 4.17769e-02
I0213 05:42:34.139071 22509476222784 run_lib.py:133] step: 768250, training_loss: 4.57447e-02
I0213 05:42:52.686513 22509476222784 run_lib.py:133] step: 768300, training_loss: 4.17585e-02
I0213 05:42:52.881060 22509476222784 run_lib.py:146] step: 768300, eval_loss: 4.46364e-02
I0213 05:43:11.414981 22509476222784 run_lib.py:133] step: 768350, training_loss: 3.55845e-02
I0213 05:43:30.174694 22509476222784 run_lib.py:133] step: 768400, training_loss: 4.70478e-02
I0213 05:43:30.359008 22509476222784 run_lib.py:146] step: 768400, eval_loss: 5.05908e-02
I0213 05:43:48.899799 22509476222784 run_lib.py:133] step: 768450, training_loss: 4.38800e-02
I0213 05:44:07.560633 22509476222784 run_lib.py:133] step: 768500, training_loss: 3.92995e-02
I0213 05:44:07.734674 22509476222784 run_lib.py:146] step: 768500, eval_loss: 3.49621e-02
I0213 05:44:26.337922 22509476222784 run_lib.py:133] step: 768550, training_loss: 4.21828e-02
I0213 05:44:44.885530 22509476222784 run_lib.py:133] step: 768600, training_loss: 4.05631e-02
I0213 05:44:45.049873 22509476222784 run_lib.py:146] step: 768600, eval_loss: 5.46915e-02
I0213 05:45:03.560925 22509476222784 run_lib.py:133] step: 768650, training_loss: 3.98588e-02
I0213 05:45:22.263884 22509476222784 run_lib.py:133] step: 768700, training_loss: 4.60645e-02
I0213 05:45:22.429724 22509476222784 run_lib.py:146] step: 768700, eval_loss: 4.19148e-02
I0213 05:45:41.006110 22509476222784 run_lib.py:133] step: 768750, training_loss: 4.51458e-02
I0213 05:45:59.595568 22509476222784 run_lib.py:133] step: 768800, training_loss: 3.54044e-02
I0213 05:45:59.776824 22509476222784 run_lib.py:146] step: 768800, eval_loss: 4.67301e-02
I0213 05:46:18.540711 22509476222784 run_lib.py:133] step: 768850, training_loss: 3.86576e-02
I0213 05:46:37.137424 22509476222784 run_lib.py:133] step: 768900, training_loss: 4.24886e-02
I0213 05:46:37.304013 22509476222784 run_lib.py:146] step: 768900, eval_loss: 4.98138e-02
I0213 05:46:55.965911 22509476222784 run_lib.py:133] step: 768950, training_loss: 4.91251e-02
I0213 05:47:14.479268 22509476222784 run_lib.py:133] step: 769000, training_loss: 4.59493e-02
I0213 05:47:14.677350 22509476222784 run_lib.py:146] step: 769000, eval_loss: 4.70868e-02
I0213 05:47:33.292448 22509476222784 run_lib.py:133] step: 769050, training_loss: 5.26977e-02
I0213 05:47:51.830692 22509476222784 run_lib.py:133] step: 769100, training_loss: 4.62060e-02
I0213 05:47:51.995942 22509476222784 run_lib.py:146] step: 769100, eval_loss: 4.07172e-02
I0213 05:48:10.751723 22509476222784 run_lib.py:133] step: 769150, training_loss: 3.84692e-02
I0213 05:48:29.394708 22509476222784 run_lib.py:133] step: 769200, training_loss: 4.85780e-02
I0213 05:48:29.578746 22509476222784 run_lib.py:146] step: 769200, eval_loss: 4.30093e-02
I0213 05:48:48.161420 22509476222784 run_lib.py:133] step: 769250, training_loss: 4.12918e-02
I0213 05:49:06.730433 22509476222784 run_lib.py:133] step: 769300, training_loss: 4.50561e-02
I0213 05:49:06.910649 22509476222784 run_lib.py:146] step: 769300, eval_loss: 4.03290e-02
I0213 05:49:25.652196 22509476222784 run_lib.py:133] step: 769350, training_loss: 3.84524e-02
I0213 05:49:44.187815 22509476222784 run_lib.py:133] step: 769400, training_loss: 4.76155e-02
I0213 05:49:44.373931 22509476222784 run_lib.py:146] step: 769400, eval_loss: 4.48608e-02
I0213 05:50:03.098253 22509476222784 run_lib.py:133] step: 769450, training_loss: 2.51157e-02
I0213 05:50:21.612750 22509476222784 run_lib.py:133] step: 769500, training_loss: 4.33901e-02
I0213 05:50:21.775928 22509476222784 run_lib.py:146] step: 769500, eval_loss: 4.61672e-02
I0213 05:50:40.432405 22509476222784 run_lib.py:133] step: 769550, training_loss: 4.15125e-02
I0213 05:50:59.028505 22509476222784 run_lib.py:133] step: 769600, training_loss: 4.72162e-02
I0213 05:50:59.224959 22509476222784 run_lib.py:146] step: 769600, eval_loss: 3.78119e-02
I0213 05:51:17.991183 22509476222784 run_lib.py:133] step: 769650, training_loss: 4.08010e-02
I0213 05:51:36.548491 22509476222784 run_lib.py:133] step: 769700, training_loss: 3.70536e-02
I0213 05:51:36.713775 22509476222784 run_lib.py:146] step: 769700, eval_loss: 4.53988e-02
I0213 05:51:55.236454 22509476222784 run_lib.py:133] step: 769750, training_loss: 4.72772e-02
I0213 05:52:13.992465 22509476222784 run_lib.py:133] step: 769800, training_loss: 3.36162e-02
I0213 05:52:14.200680 22509476222784 run_lib.py:146] step: 769800, eval_loss: 4.45475e-02
I0213 05:52:32.840883 22509476222784 run_lib.py:133] step: 769850, training_loss: 4.33420e-02
I0213 05:52:51.444133 22509476222784 run_lib.py:133] step: 769900, training_loss: 3.77143e-02
I0213 05:52:51.637943 22509476222784 run_lib.py:146] step: 769900, eval_loss: 3.82411e-02
I0213 05:53:10.339648 22509476222784 run_lib.py:133] step: 769950, training_loss: 5.62970e-02
I0213 05:53:29.034045 22509476222784 run_lib.py:133] step: 770000, training_loss: 3.11479e-02
I0213 05:53:29.769456 22509476222784 run_lib.py:146] step: 770000, eval_loss: 4.37098e-02
I0213 05:53:50.943527 22509476222784 run_lib.py:133] step: 770050, training_loss: 4.23909e-02
I0213 05:54:09.593927 22509476222784 run_lib.py:133] step: 770100, training_loss: 3.58215e-02
I0213 05:54:09.758964 22509476222784 run_lib.py:146] step: 770100, eval_loss: 3.66064e-02
I0213 05:54:28.359614 22509476222784 run_lib.py:133] step: 770150, training_loss: 3.69812e-02
I0213 05:54:46.870263 22509476222784 run_lib.py:133] step: 770200, training_loss: 3.56989e-02
I0213 05:54:47.038692 22509476222784 run_lib.py:146] step: 770200, eval_loss: 4.47405e-02
I0213 05:55:05.758581 22509476222784 run_lib.py:133] step: 770250, training_loss: 3.31478e-02
I0213 05:55:24.367961 22509476222784 run_lib.py:133] step: 770300, training_loss: 4.17419e-02
I0213 05:55:24.535025 22509476222784 run_lib.py:146] step: 770300, eval_loss: 5.38599e-02
I0213 05:55:43.035664 22509476222784 run_lib.py:133] step: 770350, training_loss: 5.63217e-02
I0213 05:56:01.636704 22509476222784 run_lib.py:133] step: 770400, training_loss: 4.07665e-02
I0213 05:56:01.809596 22509476222784 run_lib.py:146] step: 770400, eval_loss: 4.59433e-02
I0213 05:56:20.528231 22509476222784 run_lib.py:133] step: 770450, training_loss: 3.60481e-02
I0213 05:56:39.086006 22509476222784 run_lib.py:133] step: 770500, training_loss: 4.04413e-02
I0213 05:56:39.249943 22509476222784 run_lib.py:146] step: 770500, eval_loss: 3.03241e-02
I0213 05:56:57.905223 22509476222784 run_lib.py:133] step: 770550, training_loss: 3.46067e-02
I0213 05:57:16.419524 22509476222784 run_lib.py:133] step: 770600, training_loss: 4.89902e-02
I0213 05:57:16.619622 22509476222784 run_lib.py:146] step: 770600, eval_loss: 4.14806e-02
I0213 05:57:35.330305 22509476222784 run_lib.py:133] step: 770650, training_loss: 4.88443e-02
I0213 05:57:53.881783 22509476222784 run_lib.py:133] step: 770700, training_loss: 4.55478e-02
I0213 05:57:54.048939 22509476222784 run_lib.py:146] step: 770700, eval_loss: 4.70537e-02
I0213 05:58:12.653314 22509476222784 run_lib.py:133] step: 770750, training_loss: 3.97638e-02
I0213 05:58:31.437237 22509476222784 run_lib.py:133] step: 770800, training_loss: 3.75833e-02
I0213 05:58:31.604055 22509476222784 run_lib.py:146] step: 770800, eval_loss: 5.21896e-02
I0213 05:58:50.094038 22509476222784 run_lib.py:133] step: 770850, training_loss: 4.89493e-02
I0213 05:59:08.744863 22509476222784 run_lib.py:133] step: 770900, training_loss: 3.45536e-02
I0213 05:59:08.911747 22509476222784 run_lib.py:146] step: 770900, eval_loss: 3.99800e-02
I0213 05:59:27.438608 22509476222784 run_lib.py:133] step: 770950, training_loss: 4.18469e-02
I0213 05:59:46.018450 22509476222784 run_lib.py:133] step: 771000, training_loss: 5.77711e-02
I0213 05:59:46.184174 22509476222784 run_lib.py:146] step: 771000, eval_loss: 4.38729e-02
I0213 06:00:04.952644 22509476222784 run_lib.py:133] step: 771050, training_loss: 3.73057e-02
I0213 06:00:23.494251 22509476222784 run_lib.py:133] step: 771100, training_loss: 3.57661e-02
I0213 06:00:23.654663 22509476222784 run_lib.py:146] step: 771100, eval_loss: 4.83420e-02
I0213 06:00:42.203560 22509476222784 run_lib.py:133] step: 771150, training_loss: 3.53443e-02
I0213 06:01:00.922652 22509476222784 run_lib.py:133] step: 771200, training_loss: 4.79298e-02
I0213 06:01:01.111748 22509476222784 run_lib.py:146] step: 771200, eval_loss: 5.78171e-02
I0213 06:01:19.720246 22509476222784 run_lib.py:133] step: 771250, training_loss: 4.33792e-02
I0213 06:01:38.224922 22509476222784 run_lib.py:133] step: 771300, training_loss: 4.76243e-02
I0213 06:01:38.392553 22509476222784 run_lib.py:146] step: 771300, eval_loss: 5.34004e-02
I0213 06:01:57.076606 22509476222784 run_lib.py:133] step: 771350, training_loss: 4.28216e-02
I0213 06:02:15.662544 22509476222784 run_lib.py:133] step: 771400, training_loss: 4.83257e-02
I0213 06:02:15.826743 22509476222784 run_lib.py:146] step: 771400, eval_loss: 4.16134e-02
I0213 06:02:34.390098 22509476222784 run_lib.py:133] step: 771450, training_loss: 2.70482e-02
I0213 06:02:52.917151 22509476222784 run_lib.py:133] step: 771500, training_loss: 4.51583e-02
I0213 06:02:53.089500 22509476222784 run_lib.py:146] step: 771500, eval_loss: 4.72722e-02
I0213 06:03:11.893933 22509476222784 run_lib.py:133] step: 771550, training_loss: 4.75248e-02
I0213 06:03:30.633414 22509476222784 run_lib.py:133] step: 771600, training_loss: 4.13303e-02
I0213 06:03:30.815045 22509476222784 run_lib.py:146] step: 771600, eval_loss: 4.34910e-02
I0213 06:03:49.417877 22509476222784 run_lib.py:133] step: 771650, training_loss: 4.11279e-02
I0213 06:04:07.993458 22509476222784 run_lib.py:133] step: 771700, training_loss: 3.02635e-02
I0213 06:04:08.158641 22509476222784 run_lib.py:146] step: 771700, eval_loss: 5.17066e-02
I0213 06:04:26.825292 22509476222784 run_lib.py:133] step: 771750, training_loss: 4.46221e-02
I0213 06:04:45.471221 22509476222784 run_lib.py:133] step: 771800, training_loss: 4.48909e-02
I0213 06:04:45.652710 22509476222784 run_lib.py:146] step: 771800, eval_loss: 5.30992e-02
I0213 06:05:04.433980 22509476222784 run_lib.py:133] step: 771850, training_loss: 3.78851e-02
I0213 06:05:22.968980 22509476222784 run_lib.py:133] step: 771900, training_loss: 3.36048e-02
I0213 06:05:23.136735 22509476222784 run_lib.py:146] step: 771900, eval_loss: 3.09597e-02
I0213 06:05:41.882448 22509476222784 run_lib.py:133] step: 771950, training_loss: 4.73792e-02
I0213 06:06:00.401113 22509476222784 run_lib.py:133] step: 772000, training_loss: 3.70685e-02
I0213 06:06:00.563695 22509476222784 run_lib.py:146] step: 772000, eval_loss: 3.64269e-02
I0213 06:06:19.249596 22509476222784 run_lib.py:133] step: 772050, training_loss: 4.18826e-02
I0213 06:06:37.825312 22509476222784 run_lib.py:133] step: 772100, training_loss: 4.15981e-02
I0213 06:06:38.007010 22509476222784 run_lib.py:146] step: 772100, eval_loss: 4.99925e-02
I0213 06:06:56.591030 22509476222784 run_lib.py:133] step: 772150, training_loss: 4.20013e-02
I0213 06:07:15.347138 22509476222784 run_lib.py:133] step: 772200, training_loss: 3.92147e-02
I0213 06:07:15.521773 22509476222784 run_lib.py:146] step: 772200, eval_loss: 5.70341e-02
I0213 06:07:34.038087 22509476222784 run_lib.py:133] step: 772250, training_loss: 5.21996e-02
I0213 06:07:52.596414 22509476222784 run_lib.py:133] step: 772300, training_loss: 4.08704e-02
I0213 06:07:52.771781 22509476222784 run_lib.py:146] step: 772300, eval_loss: 3.37687e-02
I0213 06:08:11.483438 22509476222784 run_lib.py:133] step: 772350, training_loss: 4.81955e-02
I0213 06:08:30.028043 22509476222784 run_lib.py:133] step: 772400, training_loss: 3.95995e-02
I0213 06:08:30.199531 22509476222784 run_lib.py:146] step: 772400, eval_loss: 3.28723e-02
I0213 06:08:48.929385 22509476222784 run_lib.py:133] step: 772450, training_loss: 4.92087e-02
I0213 06:09:07.452147 22509476222784 run_lib.py:133] step: 772500, training_loss: 3.44974e-02
I0213 06:09:07.613373 22509476222784 run_lib.py:146] step: 772500, eval_loss: 5.18224e-02
I0213 06:09:26.152734 22509476222784 run_lib.py:133] step: 772550, training_loss: 4.83642e-02
I0213 06:09:44.905029 22509476222784 run_lib.py:133] step: 772600, training_loss: 4.38981e-02
I0213 06:09:45.073591 22509476222784 run_lib.py:146] step: 772600, eval_loss: 2.80552e-02
I0213 06:10:03.679600 22509476222784 run_lib.py:133] step: 772650, training_loss: 3.06134e-02
I0213 06:10:22.254059 22509476222784 run_lib.py:133] step: 772700, training_loss: 4.91905e-02
I0213 06:10:22.422053 22509476222784 run_lib.py:146] step: 772700, eval_loss: 4.24393e-02
I0213 06:10:40.976758 22509476222784 run_lib.py:133] step: 772750, training_loss: 4.63278e-02
I0213 06:10:59.742109 22509476222784 run_lib.py:133] step: 772800, training_loss: 4.52287e-02
I0213 06:10:59.908717 22509476222784 run_lib.py:146] step: 772800, eval_loss: 4.25023e-02
I0213 06:11:18.532298 22509476222784 run_lib.py:133] step: 772850, training_loss: 3.14232e-02
I0213 06:11:37.237773 22509476222784 run_lib.py:133] step: 772900, training_loss: 4.57542e-02
I0213 06:11:37.422684 22509476222784 run_lib.py:146] step: 772900, eval_loss: 4.35361e-02
I0213 06:11:56.028283 22509476222784 run_lib.py:133] step: 772950, training_loss: 3.40554e-02
I0213 06:12:14.585737 22509476222784 run_lib.py:133] step: 773000, training_loss: 4.33241e-02
I0213 06:12:14.746708 22509476222784 run_lib.py:146] step: 773000, eval_loss: 4.17385e-02
I0213 06:12:33.475736 22509476222784 run_lib.py:133] step: 773050, training_loss: 4.63349e-02
I0213 06:12:52.082367 22509476222784 run_lib.py:133] step: 773100, training_loss: 3.15928e-02
I0213 06:12:52.268100 22509476222784 run_lib.py:146] step: 773100, eval_loss: 4.00548e-02
I0213 06:13:10.918562 22509476222784 run_lib.py:133] step: 773150, training_loss: 4.43344e-02
I0213 06:13:29.531617 22509476222784 run_lib.py:133] step: 773200, training_loss: 3.26963e-02
I0213 06:13:29.721948 22509476222784 run_lib.py:146] step: 773200, eval_loss: 5.98278e-02
I0213 06:13:48.424680 22509476222784 run_lib.py:133] step: 773250, training_loss: 4.26502e-02
I0213 06:14:06.971428 22509476222784 run_lib.py:133] step: 773300, training_loss: 4.58901e-02
I0213 06:14:07.163614 22509476222784 run_lib.py:146] step: 773300, eval_loss: 4.73082e-02
I0213 06:14:25.810809 22509476222784 run_lib.py:133] step: 773350, training_loss: 3.96530e-02
I0213 06:14:44.403982 22509476222784 run_lib.py:133] step: 773400, training_loss: 4.38761e-02
I0213 06:14:44.607491 22509476222784 run_lib.py:146] step: 773400, eval_loss: 3.46140e-02
I0213 06:15:03.362930 22509476222784 run_lib.py:133] step: 773450, training_loss: 5.27205e-02
I0213 06:15:21.911338 22509476222784 run_lib.py:133] step: 773500, training_loss: 4.03922e-02
I0213 06:15:22.089765 22509476222784 run_lib.py:146] step: 773500, eval_loss: 4.12211e-02
I0213 06:15:40.644657 22509476222784 run_lib.py:133] step: 773550, training_loss: 3.92656e-02
I0213 06:15:59.376167 22509476222784 run_lib.py:133] step: 773600, training_loss: 3.94214e-02
I0213 06:15:59.545428 22509476222784 run_lib.py:146] step: 773600, eval_loss: 4.52065e-02
I0213 06:16:18.105486 22509476222784 run_lib.py:133] step: 773650, training_loss: 4.07260e-02
I0213 06:16:36.863605 22509476222784 run_lib.py:133] step: 773700, training_loss: 3.75259e-02
I0213 06:16:37.069725 22509476222784 run_lib.py:146] step: 773700, eval_loss: 5.22541e-02
I0213 06:16:55.650569 22509476222784 run_lib.py:133] step: 773750, training_loss: 5.22095e-02
I0213 06:17:14.234427 22509476222784 run_lib.py:133] step: 773800, training_loss: 3.46491e-02
I0213 06:17:14.426968 22509476222784 run_lib.py:146] step: 773800, eval_loss: 5.01454e-02
I0213 06:17:33.164925 22509476222784 run_lib.py:133] step: 773850, training_loss: 3.24013e-02
I0213 06:17:51.692525 22509476222784 run_lib.py:133] step: 773900, training_loss: 4.99557e-02
I0213 06:17:51.877817 22509476222784 run_lib.py:146] step: 773900, eval_loss: 2.97247e-02
I0213 06:18:10.460353 22509476222784 run_lib.py:133] step: 773950, training_loss: 5.34191e-02
I0213 06:18:29.193433 22509476222784 run_lib.py:133] step: 774000, training_loss: 3.74352e-02
I0213 06:18:29.359995 22509476222784 run_lib.py:146] step: 774000, eval_loss: 3.52297e-02
I0213 06:18:47.917280 22509476222784 run_lib.py:133] step: 774050, training_loss: 4.40003e-02
I0213 06:19:06.474166 22509476222784 run_lib.py:133] step: 774100, training_loss: 4.05221e-02
I0213 06:19:06.872871 22509476222784 run_lib.py:146] step: 774100, eval_loss: 3.86395e-02
I0213 06:19:25.420235 22509476222784 run_lib.py:133] step: 774150, training_loss: 4.39897e-02
I0213 06:19:43.925239 22509476222784 run_lib.py:133] step: 774200, training_loss: 3.93771e-02
I0213 06:19:44.098772 22509476222784 run_lib.py:146] step: 774200, eval_loss: 4.96362e-02
I0213 06:20:02.684805 22509476222784 run_lib.py:133] step: 774250, training_loss: 4.30130e-02
I0213 06:20:21.316470 22509476222784 run_lib.py:133] step: 774300, training_loss: 5.33094e-02
I0213 06:20:21.481173 22509476222784 run_lib.py:146] step: 774300, eval_loss: 4.96745e-02
I0213 06:20:40.236051 22509476222784 run_lib.py:133] step: 774350, training_loss: 4.41989e-02
I0213 06:20:58.822198 22509476222784 run_lib.py:133] step: 774400, training_loss: 4.52354e-02
I0213 06:20:58.982398 22509476222784 run_lib.py:146] step: 774400, eval_loss: 4.50333e-02
I0213 06:21:17.533525 22509476222784 run_lib.py:133] step: 774450, training_loss: 5.12448e-02
I0213 06:21:36.081375 22509476222784 run_lib.py:133] step: 774500, training_loss: 3.81878e-02
I0213 06:21:36.250007 22509476222784 run_lib.py:146] step: 774500, eval_loss: 3.24384e-02
I0213 06:21:55.041619 22509476222784 run_lib.py:133] step: 774550, training_loss: 4.68247e-02
I0213 06:22:13.750061 22509476222784 run_lib.py:133] step: 774600, training_loss: 3.81253e-02
I0213 06:22:13.939813 22509476222784 run_lib.py:146] step: 774600, eval_loss: 4.57233e-02
I0213 06:22:32.454645 22509476222784 run_lib.py:133] step: 774650, training_loss: 4.35374e-02
I0213 06:22:50.990706 22509476222784 run_lib.py:133] step: 774700, training_loss: 4.40869e-02
I0213 06:22:51.155852 22509476222784 run_lib.py:146] step: 774700, eval_loss: 4.16236e-02
I0213 06:23:09.874060 22509476222784 run_lib.py:133] step: 774750, training_loss: 3.36697e-02
I0213 06:23:28.529241 22509476222784 run_lib.py:133] step: 774800, training_loss: 4.18435e-02
I0213 06:23:28.729040 22509476222784 run_lib.py:146] step: 774800, eval_loss: 4.02540e-02
I0213 06:23:47.450468 22509476222784 run_lib.py:133] step: 774850, training_loss: 3.22314e-02
I0213 06:24:05.971928 22509476222784 run_lib.py:133] step: 774900, training_loss: 3.78580e-02
I0213 06:24:06.150823 22509476222784 run_lib.py:146] step: 774900, eval_loss: 4.58436e-02
I0213 06:24:24.840724 22509476222784 run_lib.py:133] step: 774950, training_loss: 3.89029e-02
I0213 06:24:43.452337 22509476222784 run_lib.py:133] step: 775000, training_loss: 4.19907e-02
I0213 06:24:43.621008 22509476222784 run_lib.py:146] step: 775000, eval_loss: 2.90636e-02
I0213 06:25:02.192126 22509476222784 run_lib.py:133] step: 775050, training_loss: 2.78069e-02
I0213 06:25:20.996618 22509476222784 run_lib.py:133] step: 775100, training_loss: 3.79192e-02
I0213 06:25:21.162860 22509476222784 run_lib.py:146] step: 775100, eval_loss: 4.43563e-02
I0213 06:25:39.733478 22509476222784 run_lib.py:133] step: 775150, training_loss: 4.04558e-02
I0213 06:25:58.442725 22509476222784 run_lib.py:133] step: 775200, training_loss: 4.60106e-02
I0213 06:25:58.612761 22509476222784 run_lib.py:146] step: 775200, eval_loss: 4.64312e-02
I0213 06:26:17.194114 22509476222784 run_lib.py:133] step: 775250, training_loss: 3.59297e-02
I0213 06:26:35.694821 22509476222784 run_lib.py:133] step: 775300, training_loss: 3.37804e-02
I0213 06:26:35.857887 22509476222784 run_lib.py:146] step: 775300, eval_loss: 4.39494e-02
I0213 06:26:54.612359 22509476222784 run_lib.py:133] step: 775350, training_loss: 4.77339e-02
I0213 06:27:13.158721 22509476222784 run_lib.py:133] step: 775400, training_loss: 4.76683e-02
I0213 06:27:13.317635 22509476222784 run_lib.py:146] step: 775400, eval_loss: 4.11944e-02
I0213 06:27:31.849700 22509476222784 run_lib.py:133] step: 775450, training_loss: 4.88873e-02
I0213 06:27:50.425490 22509476222784 run_lib.py:133] step: 775500, training_loss: 4.18414e-02
I0213 06:27:50.589497 22509476222784 run_lib.py:146] step: 775500, eval_loss: 4.67837e-02
I0213 06:28:09.287414 22509476222784 run_lib.py:133] step: 775550, training_loss: 4.59492e-02
I0213 06:28:27.833288 22509476222784 run_lib.py:133] step: 775600, training_loss: 3.80266e-02
I0213 06:28:28.013667 22509476222784 run_lib.py:146] step: 775600, eval_loss: 3.78410e-02
I0213 06:28:46.712165 22509476222784 run_lib.py:133] step: 775650, training_loss: 4.25804e-02
I0213 06:29:05.363335 22509476222784 run_lib.py:133] step: 775700, training_loss: 3.22084e-02
I0213 06:29:05.566792 22509476222784 run_lib.py:146] step: 775700, eval_loss: 4.06833e-02
I0213 06:29:24.155761 22509476222784 run_lib.py:133] step: 775750, training_loss: 2.85549e-02
I0213 06:29:42.699289 22509476222784 run_lib.py:133] step: 775800, training_loss: 3.60583e-02
I0213 06:29:42.891754 22509476222784 run_lib.py:146] step: 775800, eval_loss: 3.14301e-02
I0213 06:30:01.608663 22509476222784 run_lib.py:133] step: 775850, training_loss: 5.70685e-02
I0213 06:30:20.253184 22509476222784 run_lib.py:133] step: 775900, training_loss: 4.40907e-02
I0213 06:30:20.455167 22509476222784 run_lib.py:146] step: 775900, eval_loss: 4.61579e-02
I0213 06:30:39.071235 22509476222784 run_lib.py:133] step: 775950, training_loss: 3.94875e-02
I0213 06:30:57.651156 22509476222784 run_lib.py:133] step: 776000, training_loss: 3.80513e-02
I0213 06:30:57.823035 22509476222784 run_lib.py:146] step: 776000, eval_loss: 3.56694e-02
I0213 06:31:16.556339 22509476222784 run_lib.py:133] step: 776050, training_loss: 5.45700e-02
I0213 06:31:35.085295 22509476222784 run_lib.py:133] step: 776100, training_loss: 4.58682e-02
I0213 06:31:35.258839 22509476222784 run_lib.py:146] step: 776100, eval_loss: 3.70868e-02
I0213 06:31:53.956411 22509476222784 run_lib.py:133] step: 776150, training_loss: 4.22297e-02
I0213 06:32:12.534040 22509476222784 run_lib.py:133] step: 776200, training_loss: 3.14589e-02
I0213 06:32:12.700093 22509476222784 run_lib.py:146] step: 776200, eval_loss: 2.98635e-02
I0213 06:32:31.449673 22509476222784 run_lib.py:133] step: 776250, training_loss: 4.43184e-02
I0213 06:32:50.120837 22509476222784 run_lib.py:133] step: 776300, training_loss: 4.30100e-02
I0213 06:32:50.281798 22509476222784 run_lib.py:146] step: 776300, eval_loss: 5.73234e-02
I0213 06:33:08.956418 22509476222784 run_lib.py:133] step: 776350, training_loss: 3.21449e-02
I0213 06:33:27.570611 22509476222784 run_lib.py:133] step: 776400, training_loss: 4.13898e-02
I0213 06:33:27.741003 22509476222784 run_lib.py:146] step: 776400, eval_loss: 3.67427e-02
I0213 06:33:46.347159 22509476222784 run_lib.py:133] step: 776450, training_loss: 5.02757e-02
I0213 06:34:05.174553 22509476222784 run_lib.py:133] step: 776500, training_loss: 4.75935e-02
I0213 06:34:05.350294 22509476222784 run_lib.py:146] step: 776500, eval_loss: 5.51711e-02
I0213 06:34:23.891587 22509476222784 run_lib.py:133] step: 776550, training_loss: 4.40641e-02
I0213 06:34:42.373690 22509476222784 run_lib.py:133] step: 776600, training_loss: 4.42498e-02
I0213 06:34:42.537667 22509476222784 run_lib.py:146] step: 776600, eval_loss: 3.40571e-02
I0213 06:35:01.247499 22509476222784 run_lib.py:133] step: 776650, training_loss: 4.06403e-02
I0213 06:35:20.089653 22509476222784 run_lib.py:133] step: 776700, training_loss: 3.90372e-02
I0213 06:35:20.253943 22509476222784 run_lib.py:146] step: 776700, eval_loss: 3.90579e-02
I0213 06:35:38.848458 22509476222784 run_lib.py:133] step: 776750, training_loss: 2.91712e-02
I0213 06:35:57.351634 22509476222784 run_lib.py:133] step: 776800, training_loss: 4.51825e-02
I0213 06:35:57.510391 22509476222784 run_lib.py:146] step: 776800, eval_loss: 3.70580e-02
I0213 06:36:16.012876 22509476222784 run_lib.py:133] step: 776850, training_loss: 4.67942e-02
I0213 06:36:34.670781 22509476222784 run_lib.py:133] step: 776900, training_loss: 3.33054e-02
I0213 06:36:34.844109 22509476222784 run_lib.py:146] step: 776900, eval_loss: 5.05972e-02
I0213 06:36:53.489982 22509476222784 run_lib.py:133] step: 776950, training_loss: 3.18318e-02
I0213 06:37:12.083997 22509476222784 run_lib.py:133] step: 777000, training_loss: 4.45507e-02
I0213 06:37:12.254920 22509476222784 run_lib.py:146] step: 777000, eval_loss: 3.54540e-02
I0213 06:37:30.770177 22509476222784 run_lib.py:133] step: 777050, training_loss: 4.13700e-02
I0213 06:37:49.530430 22509476222784 run_lib.py:133] step: 777100, training_loss: 3.62918e-02
I0213 06:37:49.694678 22509476222784 run_lib.py:146] step: 777100, eval_loss: 5.05101e-02
I0213 06:38:08.193752 22509476222784 run_lib.py:133] step: 777150, training_loss: 3.03979e-02
I0213 06:38:26.921391 22509476222784 run_lib.py:133] step: 777200, training_loss: 3.49527e-02
I0213 06:38:27.104888 22509476222784 run_lib.py:146] step: 777200, eval_loss: 3.47859e-02
I0213 06:38:45.700644 22509476222784 run_lib.py:133] step: 777250, training_loss: 4.06194e-02
I0213 06:39:04.249849 22509476222784 run_lib.py:133] step: 777300, training_loss: 5.05092e-02
I0213 06:39:04.412697 22509476222784 run_lib.py:146] step: 777300, eval_loss: 3.94112e-02
I0213 06:39:23.184849 22509476222784 run_lib.py:133] step: 777350, training_loss: 4.34620e-02
I0213 06:39:41.837804 22509476222784 run_lib.py:133] step: 777400, training_loss: 4.08401e-02
I0213 06:39:42.000959 22509476222784 run_lib.py:146] step: 777400, eval_loss: 4.36039e-02
I0213 06:40:00.586369 22509476222784 run_lib.py:133] step: 777450, training_loss: 4.21521e-02
I0213 06:40:19.260336 22509476222784 run_lib.py:133] step: 777500, training_loss: 4.73435e-02
I0213 06:40:19.428787 22509476222784 run_lib.py:146] step: 777500, eval_loss: 5.04156e-02
I0213 06:40:38.155143 22509476222784 run_lib.py:133] step: 777550, training_loss: 4.81210e-02
I0213 06:40:56.713300 22509476222784 run_lib.py:133] step: 777600, training_loss: 3.00173e-02
I0213 06:40:56.878746 22509476222784 run_lib.py:146] step: 777600, eval_loss: 5.90243e-02
I0213 06:41:15.555299 22509476222784 run_lib.py:133] step: 777650, training_loss: 4.00257e-02
I0213 06:41:34.140323 22509476222784 run_lib.py:133] step: 777700, training_loss: 4.12997e-02
I0213 06:41:34.302501 22509476222784 run_lib.py:146] step: 777700, eval_loss: 5.18777e-02
I0213 06:41:53.161680 22509476222784 run_lib.py:133] step: 777750, training_loss: 3.72381e-02
I0213 06:42:11.779277 22509476222784 run_lib.py:133] step: 777800, training_loss: 4.15418e-02
I0213 06:42:11.941940 22509476222784 run_lib.py:146] step: 777800, eval_loss: 3.95042e-02
I0213 06:42:30.440828 22509476222784 run_lib.py:133] step: 777850, training_loss: 2.93621e-02
I0213 06:42:49.129984 22509476222784 run_lib.py:133] step: 777900, training_loss: 4.20992e-02
I0213 06:42:49.298476 22509476222784 run_lib.py:146] step: 777900, eval_loss: 4.15502e-02
I0213 06:43:07.813474 22509476222784 run_lib.py:133] step: 777950, training_loss: 3.52917e-02
I0213 06:43:26.517209 22509476222784 run_lib.py:133] step: 778000, training_loss: 5.27070e-02
I0213 06:43:26.707928 22509476222784 run_lib.py:146] step: 778000, eval_loss: 4.25640e-02
I0213 06:43:45.257471 22509476222784 run_lib.py:133] step: 778050, training_loss: 3.37348e-02
I0213 06:44:03.860846 22509476222784 run_lib.py:133] step: 778100, training_loss: 4.77854e-02
I0213 06:44:04.025613 22509476222784 run_lib.py:146] step: 778100, eval_loss: 3.35783e-02
I0213 06:44:22.770921 22509476222784 run_lib.py:133] step: 778150, training_loss: 5.18645e-02
I0213 06:44:41.305681 22509476222784 run_lib.py:133] step: 778200, training_loss: 4.79922e-02
I0213 06:44:41.484695 22509476222784 run_lib.py:146] step: 778200, eval_loss: 4.95991e-02
I0213 06:45:00.011541 22509476222784 run_lib.py:133] step: 778250, training_loss: 3.77926e-02
I0213 06:45:18.736279 22509476222784 run_lib.py:133] step: 778300, training_loss: 3.89403e-02
I0213 06:45:18.908898 22509476222784 run_lib.py:146] step: 778300, eval_loss: 4.10284e-02
I0213 06:45:37.446856 22509476222784 run_lib.py:133] step: 778350, training_loss: 3.67407e-02
I0213 06:45:56.012191 22509476222784 run_lib.py:133] step: 778400, training_loss: 3.89928e-02
I0213 06:45:56.184768 22509476222784 run_lib.py:146] step: 778400, eval_loss: 5.39011e-02
I0213 06:46:14.784789 22509476222784 run_lib.py:133] step: 778450, training_loss: 5.21782e-02
I0213 06:46:33.344055 22509476222784 run_lib.py:133] step: 778500, training_loss: 3.91968e-02
I0213 06:46:33.523756 22509476222784 run_lib.py:146] step: 778500, eval_loss: 4.17507e-02
I0213 06:46:52.109438 22509476222784 run_lib.py:133] step: 778550, training_loss: 3.53870e-02
I0213 06:47:10.728213 22509476222784 run_lib.py:133] step: 778600, training_loss: 3.33824e-02
I0213 06:47:10.891534 22509476222784 run_lib.py:146] step: 778600, eval_loss: 3.89084e-02
I0213 06:47:29.663357 22509476222784 run_lib.py:133] step: 778650, training_loss: 3.60675e-02
I0213 06:47:48.245925 22509476222784 run_lib.py:133] step: 778700, training_loss: 4.60108e-02
I0213 06:47:48.406625 22509476222784 run_lib.py:146] step: 778700, eval_loss: 5.00498e-02
I0213 06:48:06.914571 22509476222784 run_lib.py:133] step: 778750, training_loss: 4.60236e-02
I0213 06:48:25.481588 22509476222784 run_lib.py:133] step: 778800, training_loss: 5.93566e-02
I0213 06:48:25.663026 22509476222784 run_lib.py:146] step: 778800, eval_loss: 4.56708e-02
I0213 06:48:44.494141 22509476222784 run_lib.py:133] step: 778850, training_loss: 3.13650e-02
I0213 06:49:03.099345 22509476222784 run_lib.py:133] step: 778900, training_loss: 4.22297e-02
I0213 06:49:03.264800 22509476222784 run_lib.py:146] step: 778900, eval_loss: 4.96420e-02
I0213 06:49:21.970163 22509476222784 run_lib.py:133] step: 778950, training_loss: 4.59747e-02
I0213 06:49:40.524751 22509476222784 run_lib.py:133] step: 779000, training_loss: 4.59242e-02
I0213 06:49:40.688751 22509476222784 run_lib.py:146] step: 779000, eval_loss: 4.38294e-02
I0213 06:49:59.377622 22509476222784 run_lib.py:133] step: 779050, training_loss: 3.90369e-02
I0213 06:50:17.979231 22509476222784 run_lib.py:133] step: 779100, training_loss: 4.98194e-02
I0213 06:50:18.151806 22509476222784 run_lib.py:146] step: 779100, eval_loss: 3.72036e-02
I0213 06:50:36.944896 22509476222784 run_lib.py:133] step: 779150, training_loss: 4.21651e-02
I0213 06:50:55.471342 22509476222784 run_lib.py:133] step: 779200, training_loss: 3.91836e-02
I0213 06:50:55.632793 22509476222784 run_lib.py:146] step: 779200, eval_loss: 4.45730e-02
I0213 06:51:14.174233 22509476222784 run_lib.py:133] step: 779250, training_loss: 4.92892e-02
I0213 06:51:32.856822 22509476222784 run_lib.py:133] step: 779300, training_loss: 4.08193e-02
I0213 06:51:33.036896 22509476222784 run_lib.py:146] step: 779300, eval_loss: 4.73290e-02
I0213 06:51:51.628954 22509476222784 run_lib.py:133] step: 779350, training_loss: 3.36379e-02
I0213 06:52:10.228927 22509476222784 run_lib.py:133] step: 779400, training_loss: 3.91800e-02
I0213 06:52:10.433780 22509476222784 run_lib.py:146] step: 779400, eval_loss: 4.72953e-02
I0213 06:52:29.174484 22509476222784 run_lib.py:133] step: 779450, training_loss: 3.04324e-02
I0213 06:52:47.703988 22509476222784 run_lib.py:133] step: 779500, training_loss: 4.62400e-02
I0213 06:52:47.875450 22509476222784 run_lib.py:146] step: 779500, eval_loss: 3.85799e-02
I0213 06:53:06.596122 22509476222784 run_lib.py:133] step: 779550, training_loss: 5.24512e-02
I0213 06:53:25.196606 22509476222784 run_lib.py:133] step: 779600, training_loss: 4.53213e-02
I0213 06:53:25.359701 22509476222784 run_lib.py:146] step: 779600, eval_loss: 4.04707e-02
I0213 06:53:43.933642 22509476222784 run_lib.py:133] step: 779650, training_loss: 5.13602e-02
I0213 06:54:02.633230 22509476222784 run_lib.py:133] step: 779700, training_loss: 3.67473e-02
I0213 06:54:02.795677 22509476222784 run_lib.py:146] step: 779700, eval_loss: 6.28788e-02
I0213 06:54:21.318159 22509476222784 run_lib.py:133] step: 779750, training_loss: 3.98268e-02
I0213 06:54:39.912543 22509476222784 run_lib.py:133] step: 779800, training_loss: 4.43120e-02
I0213 06:54:40.079071 22509476222784 run_lib.py:146] step: 779800, eval_loss: 5.45212e-02
I0213 06:54:58.657546 22509476222784 run_lib.py:133] step: 779850, training_loss: 3.61104e-02
I0213 06:55:17.481328 22509476222784 run_lib.py:133] step: 779900, training_loss: 3.97058e-02
I0213 06:55:17.647032 22509476222784 run_lib.py:146] step: 779900, eval_loss: 4.70168e-02
I0213 06:55:36.174385 22509476222784 run_lib.py:133] step: 779950, training_loss: 3.49843e-02
I0213 06:55:54.817531 22509476222784 run_lib.py:133] step: 780000, training_loss: 5.42536e-02
I0213 06:55:55.612635 22509476222784 run_lib.py:146] step: 780000, eval_loss: 4.25039e-02
I0213 06:56:16.858325 22509476222784 run_lib.py:133] step: 780050, training_loss: 5.12657e-02
I0213 06:56:35.466423 22509476222784 run_lib.py:133] step: 780100, training_loss: 4.25748e-02
I0213 06:56:35.659456 22509476222784 run_lib.py:146] step: 780100, eval_loss: 4.58257e-02
I0213 06:56:54.460612 22509476222784 run_lib.py:133] step: 780150, training_loss: 3.73594e-02
I0213 06:57:13.035631 22509476222784 run_lib.py:133] step: 780200, training_loss: 4.72146e-02
I0213 06:57:13.197692 22509476222784 run_lib.py:146] step: 780200, eval_loss: 5.19516e-02
I0213 06:57:31.838715 22509476222784 run_lib.py:133] step: 780250, training_loss: 4.02881e-02
I0213 06:57:50.425359 22509476222784 run_lib.py:133] step: 780300, training_loss: 4.34444e-02
I0213 06:57:50.627710 22509476222784 run_lib.py:146] step: 780300, eval_loss: 3.28554e-02
I0213 06:58:09.187175 22509476222784 run_lib.py:133] step: 780350, training_loss: 5.16566e-02
I0213 06:58:27.787378 22509476222784 run_lib.py:133] step: 780400, training_loss: 4.04607e-02
I0213 06:58:27.977940 22509476222784 run_lib.py:146] step: 780400, eval_loss: 5.03950e-02
I0213 06:58:46.748675 22509476222784 run_lib.py:133] step: 780450, training_loss: 3.43055e-02
I0213 06:59:05.363935 22509476222784 run_lib.py:133] step: 780500, training_loss: 4.05586e-02
I0213 06:59:05.528866 22509476222784 run_lib.py:146] step: 780500, eval_loss: 4.48251e-02
I0213 06:59:24.115807 22509476222784 run_lib.py:133] step: 780550, training_loss: 3.18818e-02
I0213 06:59:42.674819 22509476222784 run_lib.py:133] step: 780600, training_loss: 4.52025e-02
I0213 06:59:42.840724 22509476222784 run_lib.py:146] step: 780600, eval_loss: 3.02253e-02
I0213 07:00:01.530720 22509476222784 run_lib.py:133] step: 780650, training_loss: 4.37203e-02
I0213 07:00:20.076315 22509476222784 run_lib.py:133] step: 780700, training_loss: 3.88103e-02
I0213 07:00:20.242959 22509476222784 run_lib.py:146] step: 780700, eval_loss: 3.97670e-02
I0213 07:00:39.020599 22509476222784 run_lib.py:133] step: 780750, training_loss: 4.72175e-02
I0213 07:00:57.615201 22509476222784 run_lib.py:133] step: 780800, training_loss: 5.12420e-02
I0213 07:00:57.780004 22509476222784 run_lib.py:146] step: 780800, eval_loss: 5.22695e-02
I0213 07:01:16.452752 22509476222784 run_lib.py:133] step: 780850, training_loss: 5.44935e-02
I0213 07:01:35.050431 22509476222784 run_lib.py:133] step: 780900, training_loss: 4.50449e-02
I0213 07:01:35.235780 22509476222784 run_lib.py:146] step: 780900, eval_loss: 4.62713e-02
I0213 07:01:53.843458 22509476222784 run_lib.py:133] step: 780950, training_loss: 3.90085e-02
I0213 07:02:12.625513 22509476222784 run_lib.py:133] step: 781000, training_loss: 4.22732e-02
I0213 07:02:12.807992 22509476222784 run_lib.py:146] step: 781000, eval_loss: 4.02718e-02
I0213 07:02:31.431606 22509476222784 run_lib.py:133] step: 781050, training_loss: 4.17555e-02
I0213 07:02:50.117239 22509476222784 run_lib.py:133] step: 781100, training_loss: 4.43925e-02
I0213 07:02:50.308759 22509476222784 run_lib.py:146] step: 781100, eval_loss: 2.72669e-02
I0213 07:03:08.817376 22509476222784 run_lib.py:133] step: 781150, training_loss: 3.98977e-02
I0213 07:03:27.392452 22509476222784 run_lib.py:133] step: 781200, training_loss: 4.15913e-02
I0213 07:03:27.580881 22509476222784 run_lib.py:146] step: 781200, eval_loss: 4.92624e-02
I0213 07:03:46.396145 22509476222784 run_lib.py:133] step: 781250, training_loss: 3.08912e-02
I0213 07:04:04.951864 22509476222784 run_lib.py:133] step: 781300, training_loss: 3.22209e-02
I0213 07:04:05.125712 22509476222784 run_lib.py:146] step: 781300, eval_loss: 4.72188e-02
I0213 07:04:23.625125 22509476222784 run_lib.py:133] step: 781350, training_loss: 3.87504e-02
I0213 07:04:42.296042 22509476222784 run_lib.py:133] step: 781400, training_loss: 3.96278e-02
I0213 07:04:42.483683 22509476222784 run_lib.py:146] step: 781400, eval_loss: 3.86356e-02
I0213 07:05:01.053295 22509476222784 run_lib.py:133] step: 781450, training_loss: 3.99526e-02
I0213 07:05:19.675283 22509476222784 run_lib.py:133] step: 781500, training_loss: 4.41459e-02
I0213 07:05:20.039065 22509476222784 run_lib.py:146] step: 781500, eval_loss: 3.40410e-02
I0213 07:05:38.600002 22509476222784 run_lib.py:133] step: 781550, training_loss: 5.03565e-02
I0213 07:05:57.187946 22509476222784 run_lib.py:133] step: 781600, training_loss: 4.12980e-02
I0213 07:05:57.369522 22509476222784 run_lib.py:146] step: 781600, eval_loss: 4.84145e-02
I0213 07:06:15.902344 22509476222784 run_lib.py:133] step: 781650, training_loss: 3.81543e-02
I0213 07:06:34.423870 22509476222784 run_lib.py:133] step: 781700, training_loss: 5.87177e-02
I0213 07:06:34.595843 22509476222784 run_lib.py:146] step: 781700, eval_loss: 5.07280e-02
I0213 07:06:53.336667 22509476222784 run_lib.py:133] step: 781750, training_loss: 3.17681e-02
I0213 07:07:12.028319 22509476222784 run_lib.py:133] step: 781800, training_loss: 4.46429e-02
I0213 07:07:12.193622 22509476222784 run_lib.py:146] step: 781800, eval_loss: 3.49615e-02
I0213 07:07:30.727169 22509476222784 run_lib.py:133] step: 781850, training_loss: 3.11601e-02
I0213 07:07:49.299172 22509476222784 run_lib.py:133] step: 781900, training_loss: 4.72418e-02
I0213 07:07:49.489788 22509476222784 run_lib.py:146] step: 781900, eval_loss: 4.39732e-02
I0213 07:08:08.214564 22509476222784 run_lib.py:133] step: 781950, training_loss: 5.26144e-02
I0213 07:08:26.930799 22509476222784 run_lib.py:133] step: 782000, training_loss: 5.25332e-02
I0213 07:08:27.150942 22509476222784 run_lib.py:146] step: 782000, eval_loss: 4.16803e-02
I0213 07:08:45.710077 22509476222784 run_lib.py:133] step: 782050, training_loss: 3.46518e-02
I0213 07:09:04.281023 22509476222784 run_lib.py:133] step: 782100, training_loss: 3.36538e-02
I0213 07:09:04.465699 22509476222784 run_lib.py:146] step: 782100, eval_loss: 4.41499e-02
I0213 07:09:23.202364 22509476222784 run_lib.py:133] step: 782150, training_loss: 4.65561e-02
I0213 07:09:41.695677 22509476222784 run_lib.py:133] step: 782200, training_loss: 4.62184e-02
I0213 07:09:41.856474 22509476222784 run_lib.py:146] step: 782200, eval_loss: 3.78007e-02
I0213 07:10:00.521020 22509476222784 run_lib.py:133] step: 782250, training_loss: 4.58590e-02
I0213 07:10:19.175148 22509476222784 run_lib.py:133] step: 782300, training_loss: 4.05798e-02
I0213 07:10:19.344717 22509476222784 run_lib.py:146] step: 782300, eval_loss: 4.62478e-02
I0213 07:10:38.040128 22509476222784 run_lib.py:133] step: 782350, training_loss: 4.53448e-02
I0213 07:10:56.627672 22509476222784 run_lib.py:133] step: 782400, training_loss: 4.08528e-02
I0213 07:10:56.817809 22509476222784 run_lib.py:146] step: 782400, eval_loss: 5.58806e-02
I0213 07:11:15.401004 22509476222784 run_lib.py:133] step: 782450, training_loss: 4.55978e-02
I0213 07:11:34.080114 22509476222784 run_lib.py:133] step: 782500, training_loss: 4.14889e-02
I0213 07:11:34.244600 22509476222784 run_lib.py:146] step: 782500, eval_loss: 3.69483e-02
I0213 07:11:52.826361 22509476222784 run_lib.py:133] step: 782550, training_loss: 4.18353e-02
I0213 07:12:11.582361 22509476222784 run_lib.py:133] step: 782600, training_loss: 4.01660e-02
I0213 07:12:11.745002 22509476222784 run_lib.py:146] step: 782600, eval_loss: 4.82435e-02
I0213 07:12:30.325154 22509476222784 run_lib.py:133] step: 782650, training_loss: 5.25942e-02
I0213 07:12:48.859118 22509476222784 run_lib.py:133] step: 782700, training_loss: 4.55999e-02
I0213 07:12:49.027294 22509476222784 run_lib.py:146] step: 782700, eval_loss: 4.81422e-02
I0213 07:13:07.589486 22509476222784 run_lib.py:133] step: 782750, training_loss: 4.55531e-02
I0213 07:13:26.304262 22509476222784 run_lib.py:133] step: 782800, training_loss: 3.32680e-02
I0213 07:13:26.478719 22509476222784 run_lib.py:146] step: 782800, eval_loss: 5.56402e-02
I0213 07:13:45.049851 22509476222784 run_lib.py:133] step: 782850, training_loss: 5.62302e-02
I0213 07:14:03.676956 22509476222784 run_lib.py:133] step: 782900, training_loss: 3.62479e-02
I0213 07:14:03.842178 22509476222784 run_lib.py:146] step: 782900, eval_loss: 4.12318e-02
I0213 07:14:22.532742 22509476222784 run_lib.py:133] step: 782950, training_loss: 4.09160e-02
I0213 07:14:41.088370 22509476222784 run_lib.py:133] step: 783000, training_loss: 4.71300e-02
I0213 07:14:41.373824 22509476222784 run_lib.py:146] step: 783000, eval_loss: 5.17527e-02
I0213 07:14:59.933327 22509476222784 run_lib.py:133] step: 783050, training_loss: 3.85271e-02
I0213 07:15:18.485852 22509476222784 run_lib.py:133] step: 783100, training_loss: 4.49207e-02
I0213 07:15:18.652387 22509476222784 run_lib.py:146] step: 783100, eval_loss: 4.26711e-02
I0213 07:15:37.228686 22509476222784 run_lib.py:133] step: 783150, training_loss: 4.76901e-02
I0213 07:15:55.751741 22509476222784 run_lib.py:133] step: 783200, training_loss: 2.91172e-02
I0213 07:15:55.917811 22509476222784 run_lib.py:146] step: 783200, eval_loss: 4.28594e-02
I0213 07:16:14.630095 22509476222784 run_lib.py:133] step: 783250, training_loss: 4.30960e-02
I0213 07:16:33.248006 22509476222784 run_lib.py:133] step: 783300, training_loss: 4.21371e-02
I0213 07:16:33.412756 22509476222784 run_lib.py:146] step: 783300, eval_loss: 3.72344e-02
I0213 07:16:51.971414 22509476222784 run_lib.py:133] step: 783350, training_loss: 3.63964e-02
I0213 07:17:10.598373 22509476222784 run_lib.py:133] step: 783400, training_loss: 4.88081e-02
I0213 07:17:10.785967 22509476222784 run_lib.py:146] step: 783400, eval_loss: 3.98907e-02
I0213 07:17:29.521653 22509476222784 run_lib.py:133] step: 783450, training_loss: 4.43041e-02
I0213 07:17:48.060341 22509476222784 run_lib.py:133] step: 783500, training_loss: 3.86584e-02
I0213 07:17:48.221729 22509476222784 run_lib.py:146] step: 783500, eval_loss: 5.68550e-02
I0213 07:18:06.873784 22509476222784 run_lib.py:133] step: 783550, training_loss: 4.78246e-02
I0213 07:18:25.452129 22509476222784 run_lib.py:133] step: 783600, training_loss: 4.20125e-02
I0213 07:18:25.637900 22509476222784 run_lib.py:146] step: 783600, eval_loss: 5.24710e-02
I0213 07:18:44.384475 22509476222784 run_lib.py:133] step: 783650, training_loss: 3.37512e-02
I0213 07:19:02.988337 22509476222784 run_lib.py:133] step: 783700, training_loss: 3.67529e-02
I0213 07:19:03.168769 22509476222784 run_lib.py:146] step: 783700, eval_loss: 4.96297e-02
I0213 07:19:21.897154 22509476222784 run_lib.py:133] step: 783750, training_loss: 3.38081e-02
I0213 07:19:40.411028 22509476222784 run_lib.py:133] step: 783800, training_loss: 3.43255e-02
I0213 07:19:40.586811 22509476222784 run_lib.py:146] step: 783800, eval_loss: 4.50568e-02
I0213 07:19:59.144335 22509476222784 run_lib.py:133] step: 783850, training_loss: 3.42694e-02
I0213 07:20:17.880235 22509476222784 run_lib.py:133] step: 783900, training_loss: 4.83750e-02
I0213 07:20:18.079478 22509476222784 run_lib.py:146] step: 783900, eval_loss: 4.29634e-02
I0213 07:20:36.693444 22509476222784 run_lib.py:133] step: 783950, training_loss: 3.96034e-02
I0213 07:20:55.266683 22509476222784 run_lib.py:133] step: 784000, training_loss: 4.40751e-02
I0213 07:20:55.428719 22509476222784 run_lib.py:146] step: 784000, eval_loss: 3.96914e-02
I0213 07:21:14.140100 22509476222784 run_lib.py:133] step: 784050, training_loss: 4.68277e-02
I0213 07:21:32.845680 22509476222784 run_lib.py:133] step: 784100, training_loss: 3.59365e-02
I0213 07:21:33.036719 22509476222784 run_lib.py:146] step: 784100, eval_loss: 5.25882e-02
I0213 07:21:51.598248 22509476222784 run_lib.py:133] step: 784150, training_loss: 4.83385e-02
I0213 07:22:10.186294 22509476222784 run_lib.py:133] step: 784200, training_loss: 4.07617e-02
I0213 07:22:10.352653 22509476222784 run_lib.py:146] step: 784200, eval_loss: 3.76588e-02
I0213 07:22:28.901096 22509476222784 run_lib.py:133] step: 784250, training_loss: 4.03359e-02
I0213 07:22:47.695795 22509476222784 run_lib.py:133] step: 784300, training_loss: 3.97162e-02
I0213 07:22:47.860993 22509476222784 run_lib.py:146] step: 784300, eval_loss: 4.16151e-02
I0213 07:23:06.458082 22509476222784 run_lib.py:133] step: 784350, training_loss: 4.64340e-02
I0213 07:23:25.005562 22509476222784 run_lib.py:133] step: 784400, training_loss: 3.59170e-02
I0213 07:23:25.369034 22509476222784 run_lib.py:146] step: 784400, eval_loss: 4.20487e-02
I0213 07:23:44.040847 22509476222784 run_lib.py:133] step: 784450, training_loss: 2.96564e-02
I0213 07:24:02.810719 22509476222784 run_lib.py:133] step: 784500, training_loss: 4.79594e-02
I0213 07:24:02.974112 22509476222784 run_lib.py:146] step: 784500, eval_loss: 4.76682e-02
I0213 07:24:21.540308 22509476222784 run_lib.py:133] step: 784550, training_loss: 3.89040e-02
I0213 07:24:40.217509 22509476222784 run_lib.py:133] step: 784600, training_loss: 3.75203e-02
I0213 07:24:40.384265 22509476222784 run_lib.py:146] step: 784600, eval_loss: 4.08761e-02
I0213 07:24:58.931876 22509476222784 run_lib.py:133] step: 784650, training_loss: 3.75840e-02
I0213 07:25:17.522208 22509476222784 run_lib.py:133] step: 784700, training_loss: 3.98045e-02
I0213 07:25:17.703727 22509476222784 run_lib.py:146] step: 784700, eval_loss: 3.36276e-02
I0213 07:25:36.451170 22509476222784 run_lib.py:133] step: 784750, training_loss: 4.34652e-02
I0213 07:25:55.144491 22509476222784 run_lib.py:133] step: 784800, training_loss: 5.10835e-02
I0213 07:25:55.309554 22509476222784 run_lib.py:146] step: 784800, eval_loss: 5.03419e-02
I0213 07:26:13.881335 22509476222784 run_lib.py:133] step: 784850, training_loss: 5.32853e-02
I0213 07:26:32.425610 22509476222784 run_lib.py:133] step: 784900, training_loss: 2.82074e-02
I0213 07:26:32.587545 22509476222784 run_lib.py:146] step: 784900, eval_loss: 4.69587e-02
I0213 07:26:51.267973 22509476222784 run_lib.py:133] step: 784950, training_loss: 4.02146e-02
I0213 07:27:09.809701 22509476222784 run_lib.py:133] step: 785000, training_loss: 4.63304e-02
I0213 07:27:09.979854 22509476222784 run_lib.py:146] step: 785000, eval_loss: 4.28703e-02
I0213 07:27:28.746689 22509476222784 run_lib.py:133] step: 785050, training_loss: 4.05272e-02
I0213 07:27:47.320899 22509476222784 run_lib.py:133] step: 785100, training_loss: 4.94688e-02
I0213 07:27:47.488089 22509476222784 run_lib.py:146] step: 785100, eval_loss: 2.15631e-02
I0213 07:28:06.202779 22509476222784 run_lib.py:133] step: 785150, training_loss: 4.01235e-02
I0213 07:28:24.752333 22509476222784 run_lib.py:133] step: 785200, training_loss: 3.46906e-02
I0213 07:28:24.915637 22509476222784 run_lib.py:146] step: 785200, eval_loss: 3.45317e-02
I0213 07:28:43.514290 22509476222784 run_lib.py:133] step: 785250, training_loss: 3.26932e-02
I0213 07:29:02.273137 22509476222784 run_lib.py:133] step: 785300, training_loss: 3.27648e-02
I0213 07:29:02.458521 22509476222784 run_lib.py:146] step: 785300, eval_loss: 4.17215e-02
I0213 07:29:21.029164 22509476222784 run_lib.py:133] step: 785350, training_loss: 3.83436e-02
I0213 07:29:39.700706 22509476222784 run_lib.py:133] step: 785400, training_loss: 4.24684e-02
I0213 07:29:39.886591 22509476222784 run_lib.py:146] step: 785400, eval_loss: 3.38805e-02
I0213 07:29:58.435522 22509476222784 run_lib.py:133] step: 785450, training_loss: 4.08243e-02
I0213 07:30:16.950972 22509476222784 run_lib.py:133] step: 785500, training_loss: 4.30476e-02
I0213 07:30:17.124906 22509476222784 run_lib.py:146] step: 785500, eval_loss: 4.26826e-02
I0213 07:30:35.875747 22509476222784 run_lib.py:133] step: 785550, training_loss: 3.93599e-02
I0213 07:30:54.417883 22509476222784 run_lib.py:133] step: 785600, training_loss: 4.93890e-02
I0213 07:30:54.584003 22509476222784 run_lib.py:146] step: 785600, eval_loss: 3.60572e-02
I0213 07:31:13.111623 22509476222784 run_lib.py:133] step: 785650, training_loss: 3.37031e-02
I0213 07:31:31.848072 22509476222784 run_lib.py:133] step: 785700, training_loss: 4.00767e-02
I0213 07:31:32.045788 22509476222784 run_lib.py:146] step: 785700, eval_loss: 5.67007e-02
I0213 07:31:50.638143 22509476222784 run_lib.py:133] step: 785750, training_loss: 5.42819e-02
I0213 07:32:09.220146 22509476222784 run_lib.py:133] step: 785800, training_loss: 4.46218e-02
I0213 07:32:09.384983 22509476222784 run_lib.py:146] step: 785800, eval_loss: 4.59703e-02
I0213 07:32:28.083521 22509476222784 run_lib.py:133] step: 785850, training_loss: 3.44647e-02
I0213 07:32:46.617789 22509476222784 run_lib.py:133] step: 785900, training_loss: 4.10124e-02
I0213 07:32:46.778738 22509476222784 run_lib.py:146] step: 785900, eval_loss: 3.63972e-02
I0213 07:33:05.306028 22509476222784 run_lib.py:133] step: 785950, training_loss: 4.39120e-02
I0213 07:33:23.879303 22509476222784 run_lib.py:133] step: 786000, training_loss: 4.39414e-02
I0213 07:33:24.055944 22509476222784 run_lib.py:146] step: 786000, eval_loss: 6.06272e-02
I0213 07:33:42.873126 22509476222784 run_lib.py:133] step: 786050, training_loss: 3.91183e-02
I0213 07:34:01.538227 22509476222784 run_lib.py:133] step: 786100, training_loss: 2.39887e-02
I0213 07:34:01.702943 22509476222784 run_lib.py:146] step: 786100, eval_loss: 5.04772e-02
I0213 07:34:20.220615 22509476222784 run_lib.py:133] step: 786150, training_loss: 3.74632e-02
I0213 07:34:38.789313 22509476222784 run_lib.py:133] step: 786200, training_loss: 3.62062e-02
I0213 07:34:38.970704 22509476222784 run_lib.py:146] step: 786200, eval_loss: 5.45094e-02
I0213 07:34:57.676799 22509476222784 run_lib.py:133] step: 786250, training_loss: 3.52491e-02
I0213 07:35:16.220420 22509476222784 run_lib.py:133] step: 786300, training_loss: 3.40909e-02
I0213 07:35:16.392690 22509476222784 run_lib.py:146] step: 786300, eval_loss: 4.71124e-02
I0213 07:35:35.075799 22509476222784 run_lib.py:133] step: 786350, training_loss: 4.08039e-02
I0213 07:35:53.616561 22509476222784 run_lib.py:133] step: 786400, training_loss: 5.50003e-02
I0213 07:35:53.822625 22509476222784 run_lib.py:146] step: 786400, eval_loss: 5.25070e-02
I0213 07:36:12.494025 22509476222784 run_lib.py:133] step: 786450, training_loss: 4.13686e-02
I0213 07:36:31.033856 22509476222784 run_lib.py:133] step: 786500, training_loss: 2.75650e-02
I0213 07:36:31.213755 22509476222784 run_lib.py:146] step: 786500, eval_loss: 4.42568e-02
I0213 07:36:49.973555 22509476222784 run_lib.py:133] step: 786550, training_loss: 3.03717e-02
I0213 07:37:08.488226 22509476222784 run_lib.py:133] step: 786600, training_loss: 4.72258e-02
I0213 07:37:08.725916 22509476222784 run_lib.py:146] step: 786600, eval_loss: 3.86127e-02
I0213 07:37:27.332319 22509476222784 run_lib.py:133] step: 786650, training_loss: 4.09405e-02
I0213 07:37:46.054771 22509476222784 run_lib.py:133] step: 786700, training_loss: 4.14456e-02
I0213 07:37:46.249967 22509476222784 run_lib.py:146] step: 786700, eval_loss: 4.72779e-02
I0213 07:38:04.813812 22509476222784 run_lib.py:133] step: 786750, training_loss: 4.56382e-02
I0213 07:38:23.412731 22509476222784 run_lib.py:133] step: 786800, training_loss: 5.27081e-02
I0213 07:38:23.630374 22509476222784 run_lib.py:146] step: 786800, eval_loss: 4.45967e-02
I0213 07:38:42.414857 22509476222784 run_lib.py:133] step: 786850, training_loss: 4.69820e-02
I0213 07:39:00.987158 22509476222784 run_lib.py:133] step: 786900, training_loss: 4.70108e-02
I0213 07:39:01.150949 22509476222784 run_lib.py:146] step: 786900, eval_loss: 5.05283e-02
I0213 07:39:19.787612 22509476222784 run_lib.py:133] step: 786950, training_loss: 4.26690e-02
I0213 07:39:38.320244 22509476222784 run_lib.py:133] step: 787000, training_loss: 3.83189e-02
I0213 07:39:38.501763 22509476222784 run_lib.py:146] step: 787000, eval_loss: 4.37961e-02
I0213 07:39:57.082455 22509476222784 run_lib.py:133] step: 787050, training_loss: 5.55850e-02
I0213 07:40:15.850407 22509476222784 run_lib.py:133] step: 787100, training_loss: 4.02860e-02
I0213 07:40:16.015919 22509476222784 run_lib.py:146] step: 787100, eval_loss: 4.09587e-02
I0213 07:40:34.514502 22509476222784 run_lib.py:133] step: 787150, training_loss: 4.73218e-02
I0213 07:40:53.070685 22509476222784 run_lib.py:133] step: 787200, training_loss: 4.83780e-02
I0213 07:40:53.234888 22509476222784 run_lib.py:146] step: 787200, eval_loss: 4.36443e-02
I0213 07:41:11.775042 22509476222784 run_lib.py:133] step: 787250, training_loss: 4.35038e-02
I0213 07:41:30.578476 22509476222784 run_lib.py:133] step: 787300, training_loss: 3.75896e-02
I0213 07:41:30.743101 22509476222784 run_lib.py:146] step: 787300, eval_loss: 4.00792e-02
I0213 07:41:49.371596 22509476222784 run_lib.py:133] step: 787350, training_loss: 4.26014e-02
I0213 07:42:08.027382 22509476222784 run_lib.py:133] step: 787400, training_loss: 4.27724e-02
I0213 07:42:08.192754 22509476222784 run_lib.py:146] step: 787400, eval_loss: 4.03596e-02
I0213 07:42:26.736417 22509476222784 run_lib.py:133] step: 787450, training_loss: 4.51054e-02
I0213 07:42:45.326905 22509476222784 run_lib.py:133] step: 787500, training_loss: 3.69598e-02
I0213 07:42:45.502620 22509476222784 run_lib.py:146] step: 787500, eval_loss: 5.41379e-02
I0213 07:43:04.218317 22509476222784 run_lib.py:133] step: 787550, training_loss: 3.50104e-02
I0213 07:43:22.920285 22509476222784 run_lib.py:133] step: 787600, training_loss: 4.18189e-02
I0213 07:43:23.085021 22509476222784 run_lib.py:146] step: 787600, eval_loss: 3.76634e-02
I0213 07:43:41.684113 22509476222784 run_lib.py:133] step: 787650, training_loss: 2.55705e-02
I0213 07:44:00.255788 22509476222784 run_lib.py:133] step: 787700, training_loss: 3.65490e-02
I0213 07:44:00.419742 22509476222784 run_lib.py:146] step: 787700, eval_loss: 4.03704e-02
I0213 07:44:19.115357 22509476222784 run_lib.py:133] step: 787750, training_loss: 4.96136e-02
I0213 07:44:37.753868 22509476222784 run_lib.py:133] step: 787800, training_loss: 3.91212e-02
I0213 07:44:37.934120 22509476222784 run_lib.py:146] step: 787800, eval_loss: 4.58392e-02
I0213 07:44:56.764062 22509476222784 run_lib.py:133] step: 787850, training_loss: 4.63319e-02
I0213 07:45:15.333122 22509476222784 run_lib.py:133] step: 787900, training_loss: 4.30253e-02
I0213 07:45:15.499540 22509476222784 run_lib.py:146] step: 787900, eval_loss: 4.16665e-02
I0213 07:45:34.137906 22509476222784 run_lib.py:133] step: 787950, training_loss: 4.35064e-02
I0213 07:45:52.669139 22509476222784 run_lib.py:133] step: 788000, training_loss: 3.38611e-02
I0213 07:45:52.844880 22509476222784 run_lib.py:146] step: 788000, eval_loss: 4.42971e-02
I0213 07:46:11.456971 22509476222784 run_lib.py:133] step: 788050, training_loss: 4.27858e-02
I0213 07:46:30.216050 22509476222784 run_lib.py:133] step: 788100, training_loss: 3.55226e-02
I0213 07:46:30.396908 22509476222784 run_lib.py:146] step: 788100, eval_loss: 4.11628e-02
I0213 07:46:48.964104 22509476222784 run_lib.py:133] step: 788150, training_loss: 3.18575e-02
I0213 07:47:07.671690 22509476222784 run_lib.py:133] step: 788200, training_loss: 4.08889e-02
I0213 07:47:07.835667 22509476222784 run_lib.py:146] step: 788200, eval_loss: 4.70636e-02
I0213 07:47:26.408322 22509476222784 run_lib.py:133] step: 788250, training_loss: 3.99319e-02
I0213 07:47:44.958816 22509476222784 run_lib.py:133] step: 788300, training_loss: 3.48176e-02
I0213 07:47:45.138958 22509476222784 run_lib.py:146] step: 788300, eval_loss: 4.99984e-02
I0213 07:48:03.944575 22509476222784 run_lib.py:133] step: 788350, training_loss: 3.34279e-02
I0213 07:48:22.528908 22509476222784 run_lib.py:133] step: 788400, training_loss: 4.76289e-02
I0213 07:48:22.695902 22509476222784 run_lib.py:146] step: 788400, eval_loss: 4.24420e-02
I0213 07:48:41.215344 22509476222784 run_lib.py:133] step: 788450, training_loss: 3.46093e-02
I0213 07:48:59.939725 22509476222784 run_lib.py:133] step: 788500, training_loss: 3.54344e-02
I0213 07:49:00.112797 22509476222784 run_lib.py:146] step: 788500, eval_loss: 6.44043e-02
I0213 07:49:18.627258 22509476222784 run_lib.py:133] step: 788550, training_loss: 3.51069e-02
I0213 07:49:37.273809 22509476222784 run_lib.py:133] step: 788600, training_loss: 5.07090e-02
I0213 07:49:37.589541 22509476222784 run_lib.py:146] step: 788600, eval_loss: 3.46144e-02
I0213 07:49:56.202349 22509476222784 run_lib.py:133] step: 788650, training_loss: 3.74804e-02
I0213 07:50:14.768445 22509476222784 run_lib.py:133] step: 788700, training_loss: 3.41719e-02
I0213 07:50:14.935846 22509476222784 run_lib.py:146] step: 788700, eval_loss: 3.60310e-02
I0213 07:50:33.472644 22509476222784 run_lib.py:133] step: 788750, training_loss: 5.30160e-02
I0213 07:50:51.979088 22509476222784 run_lib.py:133] step: 788800, training_loss: 4.73676e-02
I0213 07:50:52.141729 22509476222784 run_lib.py:146] step: 788800, eval_loss: 4.79677e-02
I0213 07:51:10.921476 22509476222784 run_lib.py:133] step: 788850, training_loss: 3.59969e-02
I0213 07:51:29.639291 22509476222784 run_lib.py:133] step: 788900, training_loss: 4.73953e-02
I0213 07:51:29.801607 22509476222784 run_lib.py:146] step: 788900, eval_loss: 4.30681e-02
I0213 07:51:48.343889 22509476222784 run_lib.py:133] step: 788950, training_loss: 3.73669e-02
I0213 07:52:06.865216 22509476222784 run_lib.py:133] step: 789000, training_loss: 3.19675e-02
I0213 07:52:07.042800 22509476222784 run_lib.py:146] step: 789000, eval_loss: 4.96065e-02
I0213 07:52:25.754564 22509476222784 run_lib.py:133] step: 789050, training_loss: 3.52122e-02
I0213 07:52:44.419738 22509476222784 run_lib.py:133] step: 789100, training_loss: 3.91308e-02
I0213 07:52:44.595875 22509476222784 run_lib.py:146] step: 789100, eval_loss: 4.67938e-02
I0213 07:53:03.211057 22509476222784 run_lib.py:133] step: 789150, training_loss: 3.96041e-02
I0213 07:53:21.749492 22509476222784 run_lib.py:133] step: 789200, training_loss: 3.11200e-02
I0213 07:53:21.909621 22509476222784 run_lib.py:146] step: 789200, eval_loss: 4.60438e-02
I0213 07:53:40.688027 22509476222784 run_lib.py:133] step: 789250, training_loss: 4.04913e-02
I0213 07:53:59.250650 22509476222784 run_lib.py:133] step: 789300, training_loss: 3.87702e-02
I0213 07:53:59.414817 22509476222784 run_lib.py:146] step: 789300, eval_loss: 3.93477e-02
I0213 07:54:18.062243 22509476222784 run_lib.py:133] step: 789350, training_loss: 3.87980e-02
I0213 07:54:36.637742 22509476222784 run_lib.py:133] step: 789400, training_loss: 4.73005e-02
I0213 07:54:36.847426 22509476222784 run_lib.py:146] step: 789400, eval_loss: 3.62859e-02
I0213 07:54:55.597173 22509476222784 run_lib.py:133] step: 789450, training_loss: 3.73705e-02
I0213 07:55:14.167629 22509476222784 run_lib.py:133] step: 789500, training_loss: 4.69893e-02
I0213 07:55:14.364847 22509476222784 run_lib.py:146] step: 789500, eval_loss: 4.28659e-02
I0213 07:55:32.911919 22509476222784 run_lib.py:133] step: 789550, training_loss: 4.48269e-02
I0213 07:55:51.617601 22509476222784 run_lib.py:133] step: 789600, training_loss: 6.29197e-02
I0213 07:55:51.806557 22509476222784 run_lib.py:146] step: 789600, eval_loss: 3.67396e-02
I0213 07:56:10.352558 22509476222784 run_lib.py:133] step: 789650, training_loss: 5.06187e-02
I0213 07:56:29.046923 22509476222784 run_lib.py:133] step: 789700, training_loss: 3.94252e-02
I0213 07:56:29.212057 22509476222784 run_lib.py:146] step: 789700, eval_loss: 4.50597e-02
I0213 07:56:47.817929 22509476222784 run_lib.py:133] step: 789750, training_loss: 4.32961e-02
I0213 07:57:06.367626 22509476222784 run_lib.py:133] step: 789800, training_loss: 3.54755e-02
I0213 07:57:06.546991 22509476222784 run_lib.py:146] step: 789800, eval_loss: 4.72236e-02
I0213 07:57:25.298176 22509476222784 run_lib.py:133] step: 789850, training_loss: 4.07082e-02
I0213 07:57:43.901922 22509476222784 run_lib.py:133] step: 789900, training_loss: 3.33669e-02
I0213 07:57:44.069052 22509476222784 run_lib.py:146] step: 789900, eval_loss: 3.41447e-02
I0213 07:58:02.649615 22509476222784 run_lib.py:133] step: 789950, training_loss: 3.67107e-02
I0213 07:58:21.304194 22509476222784 run_lib.py:133] step: 790000, training_loss: 5.81413e-02
I0213 07:58:22.081193 22509476222784 run_lib.py:146] step: 790000, eval_loss: 5.46943e-02
I0213 07:58:43.543913 22509476222784 run_lib.py:133] step: 790050, training_loss: 4.73549e-02
I0213 07:59:02.210369 22509476222784 run_lib.py:133] step: 790100, training_loss: 3.90393e-02
I0213 07:59:02.374683 22509476222784 run_lib.py:146] step: 790100, eval_loss: 4.18445e-02
I0213 07:59:20.873992 22509476222784 run_lib.py:133] step: 790150, training_loss: 5.91617e-02
I0213 07:59:39.499750 22509476222784 run_lib.py:133] step: 790200, training_loss: 4.10527e-02
I0213 07:59:39.699481 22509476222784 run_lib.py:146] step: 790200, eval_loss: 4.40480e-02
I0213 07:59:58.439376 22509476222784 run_lib.py:133] step: 790250, training_loss: 3.97782e-02
I0213 08:00:17.000356 22509476222784 run_lib.py:133] step: 790300, training_loss: 4.20841e-02
I0213 08:00:17.171798 22509476222784 run_lib.py:146] step: 790300, eval_loss: 3.70319e-02
I0213 08:00:35.661291 22509476222784 run_lib.py:133] step: 790350, training_loss: 4.65736e-02
I0213 08:00:54.222966 22509476222784 run_lib.py:133] step: 790400, training_loss: 3.54888e-02
I0213 08:00:54.404925 22509476222784 run_lib.py:146] step: 790400, eval_loss: 4.21918e-02
I0213 08:01:13.078097 22509476222784 run_lib.py:133] step: 790450, training_loss: 3.72845e-02
I0213 08:01:31.721170 22509476222784 run_lib.py:133] step: 790500, training_loss: 3.93691e-02
I0213 08:01:31.885817 22509476222784 run_lib.py:146] step: 790500, eval_loss: 4.40609e-02
I0213 08:01:50.523237 22509476222784 run_lib.py:133] step: 790550, training_loss: 3.97724e-02
I0213 08:02:09.035106 22509476222784 run_lib.py:133] step: 790600, training_loss: 3.76818e-02
I0213 08:02:09.200422 22509476222784 run_lib.py:146] step: 790600, eval_loss: 4.40629e-02
I0213 08:02:27.718727 22509476222784 run_lib.py:133] step: 790650, training_loss: 4.88359e-02
I0213 08:02:46.349308 22509476222784 run_lib.py:133] step: 790700, training_loss: 3.48687e-02
I0213 08:02:46.528941 22509476222784 run_lib.py:146] step: 790700, eval_loss: 3.93829e-02
I0213 08:03:05.316469 22509476222784 run_lib.py:133] step: 790750, training_loss: 4.54304e-02
I0213 08:03:24.030945 22509476222784 run_lib.py:133] step: 790800, training_loss: 3.55809e-02
I0213 08:03:24.195872 22509476222784 run_lib.py:146] step: 790800, eval_loss: 3.89615e-02
I0213 08:03:42.718572 22509476222784 run_lib.py:133] step: 790850, training_loss: 5.13903e-02
I0213 08:04:01.276966 22509476222784 run_lib.py:133] step: 790900, training_loss: 4.07545e-02
I0213 08:04:01.467912 22509476222784 run_lib.py:146] step: 790900, eval_loss: 3.93643e-02
I0213 08:04:20.175520 22509476222784 run_lib.py:133] step: 790950, training_loss: 3.82993e-02
I0213 08:04:38.847387 22509476222784 run_lib.py:133] step: 791000, training_loss: 2.44233e-02
I0213 08:04:39.035094 22509476222784 run_lib.py:146] step: 791000, eval_loss: 3.48099e-02
I0213 08:04:57.784813 22509476222784 run_lib.py:133] step: 791050, training_loss: 4.40790e-02
I0213 08:05:16.265023 22509476222784 run_lib.py:133] step: 791100, training_loss: 3.90709e-02
I0213 08:05:16.428719 22509476222784 run_lib.py:146] step: 791100, eval_loss: 4.23750e-02
I0213 08:05:35.043637 22509476222784 run_lib.py:133] step: 791150, training_loss: 3.65107e-02
I0213 08:05:53.561774 22509476222784 run_lib.py:133] step: 791200, training_loss: 3.87639e-02
I0213 08:05:53.736746 22509476222784 run_lib.py:146] step: 791200, eval_loss: 5.92708e-02
I0213 08:06:12.547858 22509476222784 run_lib.py:133] step: 791250, training_loss: 4.37572e-02
I0213 08:06:31.085284 22509476222784 run_lib.py:133] step: 791300, training_loss: 4.20262e-02
I0213 08:06:31.249736 22509476222784 run_lib.py:146] step: 791300, eval_loss: 3.15746e-02
I0213 08:06:49.800781 22509476222784 run_lib.py:133] step: 791350, training_loss: 3.39475e-02
I0213 08:07:08.558870 22509476222784 run_lib.py:133] step: 791400, training_loss: 4.49733e-02
I0213 08:07:08.727267 22509476222784 run_lib.py:146] step: 791400, eval_loss: 3.24670e-02
I0213 08:07:27.258242 22509476222784 run_lib.py:133] step: 791450, training_loss: 4.39454e-02
I0213 08:07:45.846797 22509476222784 run_lib.py:133] step: 791500, training_loss: 4.68553e-02
I0213 08:07:46.011587 22509476222784 run_lib.py:146] step: 791500, eval_loss: 3.53766e-02
I0213 08:08:04.742968 22509476222784 run_lib.py:133] step: 791550, training_loss: 4.18361e-02
I0213 08:08:23.282147 22509476222784 run_lib.py:133] step: 791600, training_loss: 3.96080e-02
I0213 08:08:23.446695 22509476222784 run_lib.py:146] step: 791600, eval_loss: 3.23291e-02
I0213 08:08:42.138966 22509476222784 run_lib.py:133] step: 791650, training_loss: 3.39749e-02
I0213 08:09:00.716455 22509476222784 run_lib.py:133] step: 791700, training_loss: 3.59028e-02
I0213 08:09:00.912030 22509476222784 run_lib.py:146] step: 791700, eval_loss: 4.16695e-02
I0213 08:09:19.585232 22509476222784 run_lib.py:133] step: 791750, training_loss: 3.84818e-02
I0213 08:09:38.320688 22509476222784 run_lib.py:133] step: 791800, training_loss: 4.19257e-02
I0213 08:09:38.487990 22509476222784 run_lib.py:146] step: 791800, eval_loss: 3.60847e-02
I0213 08:09:56.985487 22509476222784 run_lib.py:133] step: 791850, training_loss: 3.85750e-02
I0213 08:10:15.469597 22509476222784 run_lib.py:133] step: 791900, training_loss: 4.32465e-02
I0213 08:10:15.632729 22509476222784 run_lib.py:146] step: 791900, eval_loss: 3.58883e-02
I0213 08:10:34.160108 22509476222784 run_lib.py:133] step: 791950, training_loss: 5.15725e-02
I0213 08:10:52.933258 22509476222784 run_lib.py:133] step: 792000, training_loss: 4.87195e-02
I0213 08:10:53.098428 22509476222784 run_lib.py:146] step: 792000, eval_loss: 2.89616e-02
I0213 08:11:11.669616 22509476222784 run_lib.py:133] step: 792050, training_loss: 3.89336e-02
I0213 08:11:30.336771 22509476222784 run_lib.py:133] step: 792100, training_loss: 3.02657e-02
I0213 08:11:30.505748 22509476222784 run_lib.py:146] step: 792100, eval_loss: 3.83468e-02
I0213 08:11:48.993976 22509476222784 run_lib.py:133] step: 792150, training_loss: 3.93031e-02
I0213 08:12:07.527502 22509476222784 run_lib.py:133] step: 792200, training_loss: 3.67539e-02
I0213 08:12:07.716819 22509476222784 run_lib.py:146] step: 792200, eval_loss: 3.96269e-02
I0213 08:12:26.453586 22509476222784 run_lib.py:133] step: 792250, training_loss: 4.68480e-02
I0213 08:12:45.137737 22509476222784 run_lib.py:133] step: 792300, training_loss: 4.59735e-02
I0213 08:12:45.307579 22509476222784 run_lib.py:146] step: 792300, eval_loss: 4.36101e-02
I0213 08:13:03.880579 22509476222784 run_lib.py:133] step: 792350, training_loss: 5.02436e-02
I0213 08:13:22.424497 22509476222784 run_lib.py:133] step: 792400, training_loss: 4.13413e-02
I0213 08:13:22.621272 22509476222784 run_lib.py:146] step: 792400, eval_loss: 4.48350e-02
I0213 08:13:41.324490 22509476222784 run_lib.py:133] step: 792450, training_loss: 5.49574e-02
I0213 08:13:59.972170 22509476222784 run_lib.py:133] step: 792500, training_loss: 4.59002e-02
I0213 08:14:00.155507 22509476222784 run_lib.py:146] step: 792500, eval_loss: 4.17128e-02
I0213 08:14:18.971089 22509476222784 run_lib.py:133] step: 792550, training_loss: 3.91540e-02
I0213 08:14:37.531244 22509476222784 run_lib.py:133] step: 792600, training_loss: 6.21113e-02
I0213 08:14:37.717826 22509476222784 run_lib.py:146] step: 792600, eval_loss: 3.69528e-02
I0213 08:14:56.432903 22509476222784 run_lib.py:133] step: 792650, training_loss: 3.63120e-02
I0213 08:15:15.009190 22509476222784 run_lib.py:133] step: 792700, training_loss: 4.08528e-02
I0213 08:15:15.172752 22509476222784 run_lib.py:146] step: 792700, eval_loss: 3.86457e-02
I0213 08:15:33.741438 22509476222784 run_lib.py:133] step: 792750, training_loss: 5.15584e-02
I0213 08:15:52.528014 22509476222784 run_lib.py:133] step: 792800, training_loss: 3.67650e-02
I0213 08:15:52.742722 22509476222784 run_lib.py:146] step: 792800, eval_loss: 3.89636e-02
I0213 08:16:11.367574 22509476222784 run_lib.py:133] step: 792850, training_loss: 5.88835e-02
I0213 08:16:30.186470 22509476222784 run_lib.py:133] step: 792900, training_loss: 4.54158e-02
I0213 08:16:30.375798 22509476222784 run_lib.py:146] step: 792900, eval_loss: 4.53086e-02
I0213 08:16:49.015364 22509476222784 run_lib.py:133] step: 792950, training_loss: 3.81232e-02
I0213 08:17:07.554836 22509476222784 run_lib.py:133] step: 793000, training_loss: 4.34632e-02
I0213 08:17:07.734717 22509476222784 run_lib.py:146] step: 793000, eval_loss: 4.76363e-02
I0213 08:17:26.513755 22509476222784 run_lib.py:133] step: 793050, training_loss: 4.41588e-02
I0213 08:17:45.093776 22509476222784 run_lib.py:133] step: 793100, training_loss: 4.33828e-02
I0213 08:17:45.258016 22509476222784 run_lib.py:146] step: 793100, eval_loss: 4.16767e-02
I0213 08:18:03.877734 22509476222784 run_lib.py:133] step: 793150, training_loss: 4.28018e-02
I0213 08:18:22.611307 22509476222784 run_lib.py:133] step: 793200, training_loss: 3.42537e-02
I0213 08:18:22.777832 22509476222784 run_lib.py:146] step: 793200, eval_loss: 3.41332e-02
I0213 08:18:41.200809 22509476222784 run_lib.py:133] step: 793250, training_loss: 4.23354e-02
I0213 08:18:59.755270 22509476222784 run_lib.py:133] step: 793300, training_loss: 4.36619e-02
I0213 08:19:00.083549 22509476222784 run_lib.py:146] step: 793300, eval_loss: 4.21505e-02
I0213 08:19:18.707561 22509476222784 run_lib.py:133] step: 793350, training_loss: 4.79361e-02
I0213 08:19:37.241009 22509476222784 run_lib.py:133] step: 793400, training_loss: 4.91886e-02
I0213 08:19:37.405979 22509476222784 run_lib.py:146] step: 793400, eval_loss: 4.10708e-02
I0213 08:19:55.958853 22509476222784 run_lib.py:133] step: 793450, training_loss: 4.24374e-02
I0213 08:20:14.472715 22509476222784 run_lib.py:133] step: 793500, training_loss: 3.33851e-02
I0213 08:20:14.635798 22509476222784 run_lib.py:146] step: 793500, eval_loss: 3.89028e-02
I0213 08:20:33.345382 22509476222784 run_lib.py:133] step: 793550, training_loss: 5.44242e-02
I0213 08:20:52.011624 22509476222784 run_lib.py:133] step: 793600, training_loss: 4.74656e-02
I0213 08:20:52.179202 22509476222784 run_lib.py:146] step: 793600, eval_loss: 4.15426e-02
I0213 08:21:10.779349 22509476222784 run_lib.py:133] step: 793650, training_loss: 4.19096e-02
I0213 08:21:29.431567 22509476222784 run_lib.py:133] step: 793700, training_loss: 3.86091e-02
I0213 08:21:29.599128 22509476222784 run_lib.py:146] step: 793700, eval_loss: 4.97620e-02
I0213 08:21:48.292887 22509476222784 run_lib.py:133] step: 793750, training_loss: 3.93161e-02
I0213 08:22:06.845754 22509476222784 run_lib.py:133] step: 793800, training_loss: 4.67687e-02
I0213 08:22:07.013739 22509476222784 run_lib.py:146] step: 793800, eval_loss: 4.58444e-02
I0213 08:22:25.599265 22509476222784 run_lib.py:133] step: 793850, training_loss: 4.09342e-02
I0213 08:22:44.244001 22509476222784 run_lib.py:133] step: 793900, training_loss: 5.36695e-02
I0213 08:22:44.417557 22509476222784 run_lib.py:146] step: 793900, eval_loss: 3.52486e-02
I0213 08:23:03.196996 22509476222784 run_lib.py:133] step: 793950, training_loss: 5.55767e-02
I0213 08:23:21.754369 22509476222784 run_lib.py:133] step: 794000, training_loss: 3.70869e-02
I0213 08:23:21.914550 22509476222784 run_lib.py:146] step: 794000, eval_loss: 4.21959e-02
I0213 08:23:40.570799 22509476222784 run_lib.py:133] step: 794050, training_loss: 3.85398e-02
I0213 08:23:59.174851 22509476222784 run_lib.py:133] step: 794100, training_loss: 2.90367e-02
I0213 08:23:59.369910 22509476222784 run_lib.py:146] step: 794100, eval_loss: 3.95181e-02
I0213 08:24:18.130291 22509476222784 run_lib.py:133] step: 794150, training_loss: 3.61846e-02
I0213 08:24:36.706264 22509476222784 run_lib.py:133] step: 794200, training_loss: 4.44855e-02
I0213 08:24:36.899613 22509476222784 run_lib.py:146] step: 794200, eval_loss: 3.06507e-02
I0213 08:24:55.413867 22509476222784 run_lib.py:133] step: 794250, training_loss: 4.74020e-02
I0213 08:25:14.134179 22509476222784 run_lib.py:133] step: 794300, training_loss: 3.78387e-02
I0213 08:25:14.297673 22509476222784 run_lib.py:146] step: 794300, eval_loss: 4.14731e-02
I0213 08:25:32.875319 22509476222784 run_lib.py:133] step: 794350, training_loss: 4.14544e-02
I0213 08:25:51.623219 22509476222784 run_lib.py:133] step: 794400, training_loss: 5.16413e-02
I0213 08:25:51.796065 22509476222784 run_lib.py:146] step: 794400, eval_loss: 4.36697e-02
I0213 08:26:10.357919 22509476222784 run_lib.py:133] step: 794450, training_loss: 3.62788e-02
I0213 08:26:28.892402 22509476222784 run_lib.py:133] step: 794500, training_loss: 3.72630e-02
I0213 08:26:29.092819 22509476222784 run_lib.py:146] step: 794500, eval_loss: 3.74819e-02
I0213 08:26:47.871111 22509476222784 run_lib.py:133] step: 794550, training_loss: 5.18740e-02
I0213 08:27:06.436011 22509476222784 run_lib.py:133] step: 794600, training_loss: 4.93154e-02
I0213 08:27:06.600667 22509476222784 run_lib.py:146] step: 794600, eval_loss: 4.04091e-02
I0213 08:27:25.116690 22509476222784 run_lib.py:133] step: 794650, training_loss: 4.04527e-02
I0213 08:27:43.695262 22509476222784 run_lib.py:133] step: 794700, training_loss: 3.71158e-02
I0213 08:27:43.867419 22509476222784 run_lib.py:146] step: 794700, eval_loss: 2.80998e-02
I0213 08:28:02.571274 22509476222784 run_lib.py:133] step: 794750, training_loss: 4.00541e-02
I0213 08:28:21.126710 22509476222784 run_lib.py:133] step: 794800, training_loss: 4.90888e-02
I0213 08:28:21.292008 22509476222784 run_lib.py:146] step: 794800, eval_loss: 3.73590e-02
I0213 08:28:39.894610 22509476222784 run_lib.py:133] step: 794850, training_loss: 4.75719e-02
I0213 08:28:58.511146 22509476222784 run_lib.py:133] step: 794900, training_loss: 3.96618e-02
I0213 08:28:58.716903 22509476222784 run_lib.py:146] step: 794900, eval_loss: 3.41833e-02
I0213 08:29:17.316359 22509476222784 run_lib.py:133] step: 794950, training_loss: 5.49759e-02
I0213 08:29:35.836768 22509476222784 run_lib.py:133] step: 795000, training_loss: 4.07465e-02
I0213 08:29:35.996931 22509476222784 run_lib.py:146] step: 795000, eval_loss: 4.90460e-02
I0213 08:29:54.678892 22509476222784 run_lib.py:133] step: 795050, training_loss: 4.44564e-02
I0213 08:30:13.266548 22509476222784 run_lib.py:133] step: 795100, training_loss: 5.06487e-02
I0213 08:30:13.483152 22509476222784 run_lib.py:146] step: 795100, eval_loss: 4.65069e-02
I0213 08:30:31.996339 22509476222784 run_lib.py:133] step: 795150, training_loss: 3.51908e-02
I0213 08:30:50.602702 22509476222784 run_lib.py:133] step: 795200, training_loss: 4.48899e-02
I0213 08:30:50.768565 22509476222784 run_lib.py:146] step: 795200, eval_loss: 3.39392e-02
I0213 08:31:09.521345 22509476222784 run_lib.py:133] step: 795250, training_loss: 5.21094e-02
I0213 08:31:28.103720 22509476222784 run_lib.py:133] step: 795300, training_loss: 4.02168e-02
I0213 08:31:28.268919 22509476222784 run_lib.py:146] step: 795300, eval_loss: 3.22166e-02
I0213 08:31:46.962172 22509476222784 run_lib.py:133] step: 795350, training_loss: 4.17790e-02
I0213 08:32:05.541960 22509476222784 run_lib.py:133] step: 795400, training_loss: 4.13019e-02
I0213 08:32:05.705384 22509476222784 run_lib.py:146] step: 795400, eval_loss: 3.80395e-02
I0213 08:32:24.472779 22509476222784 run_lib.py:133] step: 795450, training_loss: 4.66533e-02
I0213 08:32:43.076881 22509476222784 run_lib.py:133] step: 795500, training_loss: 4.25929e-02
I0213 08:32:43.258916 22509476222784 run_lib.py:146] step: 795500, eval_loss: 4.16238e-02
I0213 08:33:01.980812 22509476222784 run_lib.py:133] step: 795550, training_loss: 4.53324e-02
I0213 08:33:20.535391 22509476222784 run_lib.py:133] step: 795600, training_loss: 4.11523e-02
I0213 08:33:20.709846 22509476222784 run_lib.py:146] step: 795600, eval_loss: 5.02464e-02
I0213 08:33:39.175343 22509476222784 run_lib.py:133] step: 795650, training_loss: 4.01959e-02
I0213 08:33:57.849340 22509476222784 run_lib.py:133] step: 795700, training_loss: 3.66265e-02
I0213 08:33:58.029852 22509476222784 run_lib.py:146] step: 795700, eval_loss: 5.34708e-02
I0213 08:34:16.599864 22509476222784 run_lib.py:133] step: 795750, training_loss: 4.81947e-02
I0213 08:34:35.188365 22509476222784 run_lib.py:133] step: 795800, training_loss: 3.62028e-02
I0213 08:34:35.352855 22509476222784 run_lib.py:146] step: 795800, eval_loss: 2.68674e-02
I0213 08:34:54.045066 22509476222784 run_lib.py:133] step: 795850, training_loss: 4.33309e-02
I0213 08:35:12.766431 22509476222784 run_lib.py:133] step: 795900, training_loss: 3.66348e-02
I0213 08:35:12.956279 22509476222784 run_lib.py:146] step: 795900, eval_loss: 5.57625e-02
I0213 08:35:31.480229 22509476222784 run_lib.py:133] step: 795950, training_loss: 4.99243e-02
I0213 08:35:50.111117 22509476222784 run_lib.py:133] step: 796000, training_loss: 4.39639e-02
I0213 08:35:50.303991 22509476222784 run_lib.py:146] step: 796000, eval_loss: 5.07085e-02
I0213 08:36:08.911691 22509476222784 run_lib.py:133] step: 796050, training_loss: 4.55413e-02
I0213 08:36:27.674534 22509476222784 run_lib.py:133] step: 796100, training_loss: 4.64784e-02
I0213 08:36:27.841866 22509476222784 run_lib.py:146] step: 796100, eval_loss: 3.91136e-02
I0213 08:36:46.379692 22509476222784 run_lib.py:133] step: 796150, training_loss: 4.00947e-02
I0213 08:37:04.892743 22509476222784 run_lib.py:133] step: 796200, training_loss: 4.71512e-02
I0213 08:37:05.068569 22509476222784 run_lib.py:146] step: 796200, eval_loss: 6.07448e-02
I0213 08:37:23.587288 22509476222784 run_lib.py:133] step: 796250, training_loss: 4.65388e-02
I0213 08:37:42.302986 22509476222784 run_lib.py:133] step: 796300, training_loss: 4.36725e-02
I0213 08:37:42.481626 22509476222784 run_lib.py:146] step: 796300, eval_loss: 4.35082e-02
I0213 08:38:01.069084 22509476222784 run_lib.py:133] step: 796350, training_loss: 4.10211e-02
I0213 08:38:19.632234 22509476222784 run_lib.py:133] step: 796400, training_loss: 4.80368e-02
I0213 08:38:19.817497 22509476222784 run_lib.py:146] step: 796400, eval_loss: 3.38702e-02
I0213 08:38:38.356171 22509476222784 run_lib.py:133] step: 796450, training_loss: 4.41788e-02
I0213 08:38:56.909870 22509476222784 run_lib.py:133] step: 796500, training_loss: 4.84992e-02
I0213 08:38:57.140045 22509476222784 run_lib.py:146] step: 796500, eval_loss: 3.08016e-02
I0213 08:39:15.897954 22509476222784 run_lib.py:133] step: 796550, training_loss: 3.87392e-02
I0213 08:39:34.586124 22509476222784 run_lib.py:133] step: 796600, training_loss: 3.94251e-02
I0213 08:39:34.753742 22509476222784 run_lib.py:146] step: 796600, eval_loss: 4.76523e-02
I0213 08:39:53.282401 22509476222784 run_lib.py:133] step: 796650, training_loss: 3.60196e-02
I0213 08:40:11.835167 22509476222784 run_lib.py:133] step: 796700, training_loss: 4.53554e-02
I0213 08:40:12.001646 22509476222784 run_lib.py:146] step: 796700, eval_loss: 3.93143e-02
I0213 08:40:30.703757 22509476222784 run_lib.py:133] step: 796750, training_loss: 3.16956e-02
I0213 08:40:49.386105 22509476222784 run_lib.py:133] step: 796800, training_loss: 5.07567e-02
I0213 08:40:49.548244 22509476222784 run_lib.py:146] step: 796800, eval_loss: 3.96977e-02
I0213 08:41:08.322143 22509476222784 run_lib.py:133] step: 796850, training_loss: 3.84913e-02
I0213 08:41:26.835314 22509476222784 run_lib.py:133] step: 796900, training_loss: 5.37508e-02
I0213 08:41:27.005826 22509476222784 run_lib.py:146] step: 796900, eval_loss: 4.26402e-02
I0213 08:41:45.712959 22509476222784 run_lib.py:133] step: 796950, training_loss: 3.21496e-02
I0213 08:42:04.302260 22509476222784 run_lib.py:133] step: 797000, training_loss: 3.36141e-02
I0213 08:42:04.469908 22509476222784 run_lib.py:146] step: 797000, eval_loss: 4.51998e-02
I0213 08:42:23.038507 22509476222784 run_lib.py:133] step: 797050, training_loss: 3.67309e-02
I0213 08:42:41.798194 22509476222784 run_lib.py:133] step: 797100, training_loss: 4.98772e-02
I0213 08:42:41.980178 22509476222784 run_lib.py:146] step: 797100, eval_loss: 4.48137e-02
I0213 08:43:00.484373 22509476222784 run_lib.py:133] step: 797150, training_loss: 3.76298e-02
I0213 08:43:19.171630 22509476222784 run_lib.py:133] step: 797200, training_loss: 2.51285e-02
I0213 08:43:19.381406 22509476222784 run_lib.py:146] step: 797200, eval_loss: 4.20558e-02
I0213 08:43:37.877178 22509476222784 run_lib.py:133] step: 797250, training_loss: 4.20930e-02
I0213 08:43:56.434253 22509476222784 run_lib.py:133] step: 797300, training_loss: 3.87748e-02
I0213 08:43:56.598132 22509476222784 run_lib.py:146] step: 797300, eval_loss: 3.70645e-02
I0213 08:44:15.347545 22509476222784 run_lib.py:133] step: 797350, training_loss: 3.36967e-02
I0213 08:44:33.884657 22509476222784 run_lib.py:133] step: 797400, training_loss: 4.29241e-02
I0213 08:44:34.047606 22509476222784 run_lib.py:146] step: 797400, eval_loss: 3.47474e-02
I0213 08:44:52.576009 22509476222784 run_lib.py:133] step: 797450, training_loss: 3.99258e-02
I0213 08:45:11.292401 22509476222784 run_lib.py:133] step: 797500, training_loss: 4.02536e-02
I0213 08:45:11.460039 22509476222784 run_lib.py:146] step: 797500, eval_loss: 3.95786e-02
I0213 08:45:30.002367 22509476222784 run_lib.py:133] step: 797550, training_loss: 3.74035e-02
I0213 08:45:48.650871 22509476222784 run_lib.py:133] step: 797600, training_loss: 3.56733e-02
I0213 08:45:48.815907 22509476222784 run_lib.py:146] step: 797600, eval_loss: 5.89842e-02
I0213 08:46:07.495905 22509476222784 run_lib.py:133] step: 797650, training_loss: 3.50866e-02
I0213 08:46:25.972717 22509476222784 run_lib.py:133] step: 797700, training_loss: 4.82710e-02
I0213 08:46:26.137488 22509476222784 run_lib.py:146] step: 797700, eval_loss: 4.48731e-02
I0213 08:46:44.660592 22509476222784 run_lib.py:133] step: 797750, training_loss: 5.46535e-02
I0213 08:47:03.166760 22509476222784 run_lib.py:133] step: 797800, training_loss: 4.25303e-02
I0213 08:47:03.329427 22509476222784 run_lib.py:146] step: 797800, eval_loss: 3.91503e-02
I0213 08:47:22.055202 22509476222784 run_lib.py:133] step: 797850, training_loss: 4.75629e-02
I0213 08:47:40.703371 22509476222784 run_lib.py:133] step: 797900, training_loss: 3.61845e-02
I0213 08:47:40.867860 22509476222784 run_lib.py:146] step: 797900, eval_loss: 4.41903e-02
I0213 08:47:59.403067 22509476222784 run_lib.py:133] step: 797950, training_loss: 3.57218e-02
I0213 08:48:17.954059 22509476222784 run_lib.py:133] step: 798000, training_loss: 3.46083e-02
I0213 08:48:18.138769 22509476222784 run_lib.py:146] step: 798000, eval_loss: 5.31850e-02
I0213 08:48:36.847626 22509476222784 run_lib.py:133] step: 798050, training_loss: 5.49100e-02
I0213 08:48:55.410098 22509476222784 run_lib.py:133] step: 798100, training_loss: 4.07194e-02
I0213 08:48:55.620645 22509476222784 run_lib.py:146] step: 798100, eval_loss: 4.45555e-02
I0213 08:49:14.351858 22509476222784 run_lib.py:133] step: 798150, training_loss: 3.46523e-02
I0213 08:49:32.964236 22509476222784 run_lib.py:133] step: 798200, training_loss: 5.34640e-02
I0213 08:49:33.149859 22509476222784 run_lib.py:146] step: 798200, eval_loss: 4.34468e-02
I0213 08:49:51.913784 22509476222784 run_lib.py:133] step: 798250, training_loss: 3.79011e-02
I0213 08:50:10.437431 22509476222784 run_lib.py:133] step: 798300, training_loss: 3.43359e-02
I0213 08:50:10.598643 22509476222784 run_lib.py:146] step: 798300, eval_loss: 4.06572e-02
I0213 08:50:29.213558 22509476222784 run_lib.py:133] step: 798350, training_loss: 4.51884e-02
I0213 08:50:47.853699 22509476222784 run_lib.py:133] step: 798400, training_loss: 4.77727e-02
I0213 08:50:48.030853 22509476222784 run_lib.py:146] step: 798400, eval_loss: 5.07051e-02
I0213 08:51:06.628187 22509476222784 run_lib.py:133] step: 798450, training_loss: 5.68884e-02
I0213 08:51:25.368747 22509476222784 run_lib.py:133] step: 798500, training_loss: 3.76302e-02
I0213 08:51:25.533361 22509476222784 run_lib.py:146] step: 798500, eval_loss: 3.57691e-02
I0213 08:51:44.072562 22509476222784 run_lib.py:133] step: 798550, training_loss: 3.51771e-02
I0213 08:52:02.598569 22509476222784 run_lib.py:133] step: 798600, training_loss: 4.53204e-02
I0213 08:52:02.782611 22509476222784 run_lib.py:146] step: 798600, eval_loss: 4.07665e-02
I0213 08:52:21.436157 22509476222784 run_lib.py:133] step: 798650, training_loss: 4.11283e-02
I0213 08:52:40.076611 22509476222784 run_lib.py:133] step: 798700, training_loss: 3.62602e-02
I0213 08:52:40.258841 22509476222784 run_lib.py:146] step: 798700, eval_loss: 3.80095e-02
I0213 08:52:59.087108 22509476222784 run_lib.py:133] step: 798750, training_loss: 4.77863e-02
I0213 08:53:17.671531 22509476222784 run_lib.py:133] step: 798800, training_loss: 3.67337e-02
I0213 08:53:17.837656 22509476222784 run_lib.py:146] step: 798800, eval_loss: 4.41833e-02
I0213 08:53:36.378498 22509476222784 run_lib.py:133] step: 798850, training_loss: 3.49564e-02
I0213 08:53:55.012311 22509476222784 run_lib.py:133] step: 798900, training_loss: 5.57042e-02
I0213 08:53:55.204742 22509476222784 run_lib.py:146] step: 798900, eval_loss: 3.78044e-02
I0213 08:54:13.756588 22509476222784 run_lib.py:133] step: 798950, training_loss: 3.83940e-02
I0213 08:54:32.363887 22509476222784 run_lib.py:133] step: 799000, training_loss: 5.16814e-02
I0213 08:54:32.537878 22509476222784 run_lib.py:146] step: 799000, eval_loss: 3.72625e-02
I0213 08:54:51.069615 22509476222784 run_lib.py:133] step: 799050, training_loss: 4.40602e-02
I0213 08:55:09.779784 22509476222784 run_lib.py:133] step: 799100, training_loss: 3.00729e-02
I0213 08:55:09.976885 22509476222784 run_lib.py:146] step: 799100, eval_loss: 4.73873e-02
I0213 08:55:28.515174 22509476222784 run_lib.py:133] step: 799150, training_loss: 3.77300e-02
I0213 08:55:47.139006 22509476222784 run_lib.py:133] step: 799200, training_loss: 5.50931e-02
I0213 08:55:47.307311 22509476222784 run_lib.py:146] step: 799200, eval_loss: 4.21744e-02
I0213 08:56:05.860792 22509476222784 run_lib.py:133] step: 799250, training_loss: 5.16841e-02
I0213 08:56:24.398004 22509476222784 run_lib.py:133] step: 799300, training_loss: 5.15193e-02
I0213 08:56:24.560597 22509476222784 run_lib.py:146] step: 799300, eval_loss: 4.21869e-02
I0213 08:56:43.313868 22509476222784 run_lib.py:133] step: 799350, training_loss: 3.61077e-02
I0213 08:57:01.950956 22509476222784 run_lib.py:133] step: 799400, training_loss: 4.48319e-02
I0213 08:57:02.116975 22509476222784 run_lib.py:146] step: 799400, eval_loss: 4.42574e-02
I0213 08:57:20.615612 22509476222784 run_lib.py:133] step: 799450, training_loss: 3.68680e-02
I0213 08:57:39.222692 22509476222784 run_lib.py:133] step: 799500, training_loss: 4.80002e-02
I0213 08:57:39.408933 22509476222784 run_lib.py:146] step: 799500, eval_loss: 4.92741e-02
I0213 08:57:58.123736 22509476222784 run_lib.py:133] step: 799550, training_loss: 4.04622e-02
I0213 08:58:16.659323 22509476222784 run_lib.py:133] step: 799600, training_loss: 4.65027e-02
I0213 08:58:16.824753 22509476222784 run_lib.py:146] step: 799600, eval_loss: 4.39254e-02
I0213 08:58:35.470081 22509476222784 run_lib.py:133] step: 799650, training_loss: 4.08939e-02
I0213 08:58:54.044478 22509476222784 run_lib.py:133] step: 799700, training_loss: 3.72120e-02
I0213 08:58:54.241100 22509476222784 run_lib.py:146] step: 799700, eval_loss: 4.03546e-02
I0213 08:59:12.981541 22509476222784 run_lib.py:133] step: 799750, training_loss: 4.31830e-02
I0213 08:59:31.525724 22509476222784 run_lib.py:133] step: 799800, training_loss: 5.22586e-02
I0213 08:59:31.692786 22509476222784 run_lib.py:146] step: 799800, eval_loss: 4.69736e-02
I0213 08:59:50.213800 22509476222784 run_lib.py:133] step: 799850, training_loss: 5.24801e-02
I0213 09:00:08.930020 22509476222784 run_lib.py:133] step: 799900, training_loss: 3.55203e-02
I0213 09:00:09.095800 22509476222784 run_lib.py:146] step: 799900, eval_loss: 4.37118e-02
I0213 09:00:27.611887 22509476222784 run_lib.py:133] step: 799950, training_loss: 3.79313e-02
I0213 09:00:46.365295 22509476222784 run_lib.py:133] step: 800000, training_loss: 4.81005e-02
I0213 09:00:47.111992 22509476222784 run_lib.py:146] step: 800000, eval_loss: 4.74291e-02
I0213 09:01:08.458805 22509476222784 run_lib.py:133] step: 800050, training_loss: 3.91821e-02
I0213 09:01:26.995669 22509476222784 run_lib.py:133] step: 800100, training_loss: 4.94367e-02
I0213 09:01:27.185489 22509476222784 run_lib.py:146] step: 800100, eval_loss: 4.36925e-02
I0213 09:01:45.708685 22509476222784 run_lib.py:133] step: 800150, training_loss: 3.32212e-02
I0213 09:02:04.266946 22509476222784 run_lib.py:133] step: 800200, training_loss: 4.99834e-02
I0213 09:02:04.431632 22509476222784 run_lib.py:146] step: 800200, eval_loss: 4.49226e-02
I0213 09:02:23.159348 22509476222784 run_lib.py:133] step: 800250, training_loss: 3.62771e-02
I0213 09:02:41.828484 22509476222784 run_lib.py:133] step: 800300, training_loss: 4.62231e-02
I0213 09:02:41.995864 22509476222784 run_lib.py:146] step: 800300, eval_loss: 5.21711e-02
I0213 09:03:00.550500 22509476222784 run_lib.py:133] step: 800350, training_loss: 3.78555e-02
I0213 09:03:19.083339 22509476222784 run_lib.py:133] step: 800400, training_loss: 4.47393e-02
I0213 09:03:19.278845 22509476222784 run_lib.py:146] step: 800400, eval_loss: 5.72199e-02
I0213 09:03:37.955031 22509476222784 run_lib.py:133] step: 800450, training_loss: 4.87367e-02
I0213 09:03:56.502027 22509476222784 run_lib.py:133] step: 800500, training_loss: 5.01735e-02
I0213 09:03:56.683630 22509476222784 run_lib.py:146] step: 800500, eval_loss: 4.98941e-02
I0213 09:04:15.437472 22509476222784 run_lib.py:133] step: 800550, training_loss: 4.53911e-02
I0213 09:04:33.968288 22509476222784 run_lib.py:133] step: 800600, training_loss: 4.20140e-02
I0213 09:04:34.132925 22509476222784 run_lib.py:146] step: 800600, eval_loss: 4.07237e-02
I0213 09:04:52.800342 22509476222784 run_lib.py:133] step: 800650, training_loss: 4.38872e-02
I0213 09:05:11.293711 22509476222784 run_lib.py:133] step: 800700, training_loss: 3.99342e-02
I0213 09:05:11.459702 22509476222784 run_lib.py:146] step: 800700, eval_loss: 3.99789e-02
I0213 09:05:30.192879 22509476222784 run_lib.py:133] step: 800750, training_loss: 4.26495e-02
I0213 09:05:48.734827 22509476222784 run_lib.py:133] step: 800800, training_loss: 4.55920e-02
I0213 09:05:48.902915 22509476222784 run_lib.py:146] step: 800800, eval_loss: 3.85619e-02
I0213 09:06:07.461468 22509476222784 run_lib.py:133] step: 800850, training_loss: 4.35897e-02
I0213 09:06:26.222930 22509476222784 run_lib.py:133] step: 800900, training_loss: 3.73757e-02
I0213 09:06:26.390069 22509476222784 run_lib.py:146] step: 800900, eval_loss: 3.58656e-02
I0213 09:06:44.920123 22509476222784 run_lib.py:133] step: 800950, training_loss: 3.74477e-02
I0213 09:07:03.480292 22509476222784 run_lib.py:133] step: 801000, training_loss: 6.04895e-02
I0213 09:07:03.656602 22509476222784 run_lib.py:146] step: 801000, eval_loss: 4.08119e-02
I0213 09:07:22.391402 22509476222784 run_lib.py:133] step: 801050, training_loss: 4.84340e-02
I0213 09:07:41.117431 22509476222784 run_lib.py:133] step: 801100, training_loss: 4.48288e-02
I0213 09:07:41.281842 22509476222784 run_lib.py:146] step: 801100, eval_loss: 4.27264e-02
I0213 09:07:59.819819 22509476222784 run_lib.py:133] step: 801150, training_loss: 4.14949e-02
I0213 09:08:18.289598 22509476222784 run_lib.py:133] step: 801200, training_loss: 4.05321e-02
I0213 09:08:18.470552 22509476222784 run_lib.py:146] step: 801200, eval_loss: 4.57583e-02
I0213 09:08:36.965587 22509476222784 run_lib.py:133] step: 801250, training_loss: 3.38176e-02
I0213 09:08:55.591355 22509476222784 run_lib.py:133] step: 801300, training_loss: 5.16294e-02
I0213 09:08:55.774624 22509476222784 run_lib.py:146] step: 801300, eval_loss: 4.49387e-02
I0213 09:09:14.396414 22509476222784 run_lib.py:133] step: 801350, training_loss: 4.00647e-02
I0213 09:09:32.945996 22509476222784 run_lib.py:133] step: 801400, training_loss: 4.03114e-02
I0213 09:09:33.112026 22509476222784 run_lib.py:146] step: 801400, eval_loss: 3.98611e-02
I0213 09:09:51.592379 22509476222784 run_lib.py:133] step: 801450, training_loss: 4.04512e-02
I0213 09:10:10.306890 22509476222784 run_lib.py:133] step: 801500, training_loss: 3.86919e-02
I0213 09:10:10.516745 22509476222784 run_lib.py:146] step: 801500, eval_loss: 3.50297e-02
I0213 09:10:29.064705 22509476222784 run_lib.py:133] step: 801550, training_loss: 5.21642e-02
I0213 09:10:47.736234 22509476222784 run_lib.py:133] step: 801600, training_loss: 3.68109e-02
I0213 09:10:47.919930 22509476222784 run_lib.py:146] step: 801600, eval_loss: 4.06742e-02
I0213 09:11:06.513297 22509476222784 run_lib.py:133] step: 801650, training_loss: 5.36177e-02
I0213 09:11:25.069216 22509476222784 run_lib.py:133] step: 801700, training_loss: 3.61830e-02
I0213 09:11:25.229641 22509476222784 run_lib.py:146] step: 801700, eval_loss: 2.97491e-02
I0213 09:11:43.990674 22509476222784 run_lib.py:133] step: 801750, training_loss: 5.78583e-02
I0213 09:12:02.642462 22509476222784 run_lib.py:133] step: 801800, training_loss: 3.93485e-02
I0213 09:12:02.817682 22509476222784 run_lib.py:146] step: 801800, eval_loss: 4.08459e-02
I0213 09:12:21.407038 22509476222784 run_lib.py:133] step: 801850, training_loss: 4.90652e-02
I0213 09:12:39.979690 22509476222784 run_lib.py:133] step: 801900, training_loss: 4.33355e-02
I0213 09:12:40.160589 22509476222784 run_lib.py:146] step: 801900, eval_loss: 3.92986e-02
I0213 09:12:58.864178 22509476222784 run_lib.py:133] step: 801950, training_loss: 4.66350e-02
I0213 09:13:17.381268 22509476222784 run_lib.py:133] step: 802000, training_loss: 5.87164e-02
I0213 09:13:17.579853 22509476222784 run_lib.py:146] step: 802000, eval_loss: 3.93205e-02
I0213 09:13:36.249500 22509476222784 run_lib.py:133] step: 802050, training_loss: 4.15667e-02
I0213 09:13:54.784710 22509476222784 run_lib.py:133] step: 802100, training_loss: 3.50255e-02
I0213 09:13:54.948272 22509476222784 run_lib.py:146] step: 802100, eval_loss: 3.57865e-02
I0213 09:14:13.683424 22509476222784 run_lib.py:133] step: 802150, training_loss: 4.49876e-02
I0213 09:14:32.234368 22509476222784 run_lib.py:133] step: 802200, training_loss: 3.91120e-02
I0213 09:14:32.397606 22509476222784 run_lib.py:146] step: 802200, eval_loss: 4.00893e-02
I0213 09:14:50.927655 22509476222784 run_lib.py:133] step: 802250, training_loss: 5.03260e-02
I0213 09:15:09.606016 22509476222784 run_lib.py:133] step: 802300, training_loss: 4.58256e-02
I0213 09:15:09.790680 22509476222784 run_lib.py:146] step: 802300, eval_loss: 4.91381e-02
I0213 09:15:28.362017 22509476222784 run_lib.py:133] step: 802350, training_loss: 4.74501e-02
I0213 09:15:47.137078 22509476222784 run_lib.py:133] step: 802400, training_loss: 4.02138e-02
I0213 09:15:47.322772 22509476222784 run_lib.py:146] step: 802400, eval_loss: 4.84167e-02
I0213 09:16:05.830760 22509476222784 run_lib.py:133] step: 802450, training_loss: 3.18993e-02
I0213 09:16:24.323809 22509476222784 run_lib.py:133] step: 802500, training_loss: 3.81120e-02
I0213 09:16:24.517464 22509476222784 run_lib.py:146] step: 802500, eval_loss: 3.95681e-02
I0213 09:16:43.159711 22509476222784 run_lib.py:133] step: 802550, training_loss: 4.57672e-02
I0213 09:17:01.736682 22509476222784 run_lib.py:133] step: 802600, training_loss: 4.41247e-02
I0213 09:17:01.944028 22509476222784 run_lib.py:146] step: 802600, eval_loss: 3.90941e-02
I0213 09:17:20.531222 22509476222784 run_lib.py:133] step: 802650, training_loss: 4.01414e-02
I0213 09:17:39.271860 22509476222784 run_lib.py:133] step: 802700, training_loss: 4.96046e-02
I0213 09:17:39.436928 22509476222784 run_lib.py:146] step: 802700, eval_loss: 4.17378e-02
I0213 09:17:57.954130 22509476222784 run_lib.py:133] step: 802750, training_loss: 4.20284e-02
I0213 09:18:16.521760 22509476222784 run_lib.py:133] step: 802800, training_loss: 4.56010e-02
I0213 09:18:16.712977 22509476222784 run_lib.py:146] step: 802800, eval_loss: 5.59967e-02
I0213 09:18:35.374517 22509476222784 run_lib.py:133] step: 802850, training_loss: 4.06253e-02
I0213 09:18:53.982238 22509476222784 run_lib.py:133] step: 802900, training_loss: 4.24029e-02
I0213 09:18:54.155789 22509476222784 run_lib.py:146] step: 802900, eval_loss: 4.87348e-02
I0213 09:19:12.666646 22509476222784 run_lib.py:133] step: 802950, training_loss: 4.55312e-02
I0213 09:19:31.228278 22509476222784 run_lib.py:133] step: 803000, training_loss: 3.62533e-02
I0213 09:19:31.396841 22509476222784 run_lib.py:146] step: 803000, eval_loss: 4.51953e-02
I0213 09:19:50.146403 22509476222784 run_lib.py:133] step: 803050, training_loss: 4.29501e-02
I0213 09:20:08.737995 22509476222784 run_lib.py:133] step: 803100, training_loss: 4.38058e-02
I0213 09:20:08.900847 22509476222784 run_lib.py:146] step: 803100, eval_loss: 4.71258e-02
I0213 09:20:27.561974 22509476222784 run_lib.py:133] step: 803150, training_loss: 3.82933e-02
I0213 09:20:46.121816 22509476222784 run_lib.py:133] step: 803200, training_loss: 4.35289e-02
I0213 09:20:46.286820 22509476222784 run_lib.py:146] step: 803200, eval_loss: 4.05589e-02
I0213 09:21:04.983752 22509476222784 run_lib.py:133] step: 803250, training_loss: 2.65221e-02
I0213 09:21:23.526612 22509476222784 run_lib.py:133] step: 803300, training_loss: 4.29311e-02
I0213 09:21:23.692812 22509476222784 run_lib.py:146] step: 803300, eval_loss: 4.52912e-02
I0213 09:21:42.413013 22509476222784 run_lib.py:133] step: 803350, training_loss: 5.04633e-02
I0213 09:22:01.046049 22509476222784 run_lib.py:133] step: 803400, training_loss: 4.47086e-02
I0213 09:22:01.210983 22509476222784 run_lib.py:146] step: 803400, eval_loss: 4.06773e-02
I0213 09:22:19.969487 22509476222784 run_lib.py:133] step: 803450, training_loss: 3.37527e-02
I0213 09:22:38.538202 22509476222784 run_lib.py:133] step: 803500, training_loss: 5.26858e-02
I0213 09:22:38.703808 22509476222784 run_lib.py:146] step: 803500, eval_loss: 3.89683e-02
I0213 09:22:57.377241 22509476222784 run_lib.py:133] step: 803550, training_loss: 3.77532e-02
I0213 09:23:15.951840 22509476222784 run_lib.py:133] step: 803600, training_loss: 4.87238e-02
I0213 09:23:16.147691 22509476222784 run_lib.py:146] step: 803600, eval_loss: 5.00724e-02
I0213 09:23:34.782958 22509476222784 run_lib.py:133] step: 803650, training_loss: 3.96266e-02
I0213 09:23:53.478825 22509476222784 run_lib.py:133] step: 803700, training_loss: 3.63997e-02
I0213 09:23:53.642671 22509476222784 run_lib.py:146] step: 803700, eval_loss: 3.13144e-02
I0213 09:24:12.168802 22509476222784 run_lib.py:133] step: 803750, training_loss: 4.05499e-02
I0213 09:24:30.803069 22509476222784 run_lib.py:133] step: 803800, training_loss: 3.97876e-02
I0213 09:24:30.969006 22509476222784 run_lib.py:146] step: 803800, eval_loss: 3.75974e-02
I0213 09:24:49.671246 22509476222784 run_lib.py:133] step: 803850, training_loss: 4.49742e-02
I0213 09:25:08.275717 22509476222784 run_lib.py:133] step: 803900, training_loss: 4.10945e-02
I0213 09:25:08.441495 22509476222784 run_lib.py:146] step: 803900, eval_loss: 4.77741e-02
I0213 09:25:27.179873 22509476222784 run_lib.py:133] step: 803950, training_loss: 3.30872e-02
I0213 09:25:45.686611 22509476222784 run_lib.py:133] step: 804000, training_loss: 4.39559e-02
I0213 09:25:45.850728 22509476222784 run_lib.py:146] step: 804000, eval_loss: 4.07797e-02
I0213 09:26:04.382166 22509476222784 run_lib.py:133] step: 804050, training_loss: 4.62186e-02
I0213 09:26:23.161301 22509476222784 run_lib.py:133] step: 804100, training_loss: 4.53230e-02
I0213 09:26:23.331763 22509476222784 run_lib.py:146] step: 804100, eval_loss: 5.25626e-02
I0213 09:26:41.909814 22509476222784 run_lib.py:133] step: 804150, training_loss: 4.33798e-02
I0213 09:27:00.484104 22509476222784 run_lib.py:133] step: 804200, training_loss: 4.26988e-02
I0213 09:27:00.842502 22509476222784 run_lib.py:146] step: 804200, eval_loss: 4.24556e-02
I0213 09:27:19.349180 22509476222784 run_lib.py:133] step: 804250, training_loss: 5.17418e-02
I0213 09:27:38.089354 22509476222784 run_lib.py:133] step: 804300, training_loss: 3.97189e-02
I0213 09:27:38.265673 22509476222784 run_lib.py:146] step: 804300, eval_loss: 4.30697e-02
I0213 09:27:56.800126 22509476222784 run_lib.py:133] step: 804350, training_loss: 4.25830e-02
I0213 09:28:15.404958 22509476222784 run_lib.py:133] step: 804400, training_loss: 4.35211e-02
I0213 09:28:15.570604 22509476222784 run_lib.py:146] step: 804400, eval_loss: 4.41495e-02
I0213 09:28:34.111858 22509476222784 run_lib.py:133] step: 804450, training_loss: 4.29832e-02
I0213 09:28:52.571845 22509476222784 run_lib.py:133] step: 804500, training_loss: 5.10458e-02
I0213 09:28:52.841148 22509476222784 run_lib.py:146] step: 804500, eval_loss: 3.62682e-02
I0213 09:29:11.531201 22509476222784 run_lib.py:133] step: 804550, training_loss: 4.85717e-02
I0213 09:29:30.121648 22509476222784 run_lib.py:133] step: 804600, training_loss: 6.25889e-02
I0213 09:29:30.285498 22509476222784 run_lib.py:146] step: 804600, eval_loss: 5.84026e-02
I0213 09:29:48.805568 22509476222784 run_lib.py:133] step: 804650, training_loss: 4.03151e-02
I0213 09:30:07.391955 22509476222784 run_lib.py:133] step: 804700, training_loss: 3.82052e-02
I0213 09:30:07.564748 22509476222784 run_lib.py:146] step: 804700, eval_loss: 3.44779e-02
I0213 09:30:26.308033 22509476222784 run_lib.py:133] step: 804750, training_loss: 5.53544e-02
I0213 09:30:44.849721 22509476222784 run_lib.py:133] step: 804800, training_loss: 4.66814e-02
I0213 09:30:45.016695 22509476222784 run_lib.py:146] step: 804800, eval_loss: 4.12954e-02
I0213 09:31:03.688269 22509476222784 run_lib.py:133] step: 804850, training_loss: 4.22240e-02
I0213 09:31:22.188541 22509476222784 run_lib.py:133] step: 804900, training_loss: 5.07713e-02
I0213 09:31:22.353621 22509476222784 run_lib.py:146] step: 804900, eval_loss: 4.39655e-02
I0213 09:31:41.140911 22509476222784 run_lib.py:133] step: 804950, training_loss: 4.39487e-02
I0213 09:31:59.679928 22509476222784 run_lib.py:133] step: 805000, training_loss: 4.90937e-02
I0213 09:31:59.842941 22509476222784 run_lib.py:146] step: 805000, eval_loss: 3.40725e-02
I0213 09:32:18.423695 22509476222784 run_lib.py:133] step: 805050, training_loss: 4.23162e-02
I0213 09:32:37.155981 22509476222784 run_lib.py:133] step: 805100, training_loss: 4.05139e-02
I0213 09:32:37.323611 22509476222784 run_lib.py:146] step: 805100, eval_loss: 3.95140e-02
I0213 09:32:55.797455 22509476222784 run_lib.py:133] step: 805150, training_loss: 5.62192e-02
I0213 09:33:14.450612 22509476222784 run_lib.py:133] step: 805200, training_loss: 4.40769e-02
I0213 09:33:14.632658 22509476222784 run_lib.py:146] step: 805200, eval_loss: 4.17721e-02
I0213 09:33:33.186568 22509476222784 run_lib.py:133] step: 805250, training_loss: 4.03978e-02
I0213 09:33:51.717620 22509476222784 run_lib.py:133] step: 805300, training_loss: 4.43198e-02
I0213 09:33:51.882762 22509476222784 run_lib.py:146] step: 805300, eval_loss: 4.09607e-02
I0213 09:34:10.652468 22509476222784 run_lib.py:133] step: 805350, training_loss: 4.29447e-02
I0213 09:34:29.188857 22509476222784 run_lib.py:133] step: 805400, training_loss: 4.85525e-02
I0213 09:34:29.352569 22509476222784 run_lib.py:146] step: 805400, eval_loss: 5.30533e-02
I0213 09:34:47.897234 22509476222784 run_lib.py:133] step: 805450, training_loss: 4.66097e-02
I0213 09:35:06.573398 22509476222784 run_lib.py:133] step: 805500, training_loss: 4.73801e-02
I0213 09:35:06.739216 22509476222784 run_lib.py:146] step: 805500, eval_loss: 4.07877e-02
I0213 09:35:25.355130 22509476222784 run_lib.py:133] step: 805550, training_loss: 4.03441e-02
I0213 09:35:43.844776 22509476222784 run_lib.py:133] step: 805600, training_loss: 5.15542e-02
I0213 09:35:44.201772 22509476222784 run_lib.py:146] step: 805600, eval_loss: 4.65264e-02
I0213 09:36:02.701964 22509476222784 run_lib.py:133] step: 805650, training_loss: 4.59698e-02
I0213 09:36:21.196151 22509476222784 run_lib.py:133] step: 805700, training_loss: 4.18542e-02
I0213 09:36:21.361983 22509476222784 run_lib.py:146] step: 805700, eval_loss: 4.43096e-02
I0213 09:36:39.882547 22509476222784 run_lib.py:133] step: 805750, training_loss: 4.80283e-02
I0213 09:36:58.483411 22509476222784 run_lib.py:133] step: 805800, training_loss: 3.84769e-02
I0213 09:36:58.648216 22509476222784 run_lib.py:146] step: 805800, eval_loss: 4.62132e-02
I0213 09:37:17.408678 22509476222784 run_lib.py:133] step: 805850, training_loss: 4.82860e-02
I0213 09:37:36.009756 22509476222784 run_lib.py:133] step: 805900, training_loss: 4.32095e-02
I0213 09:37:36.174630 22509476222784 run_lib.py:146] step: 805900, eval_loss: 4.10573e-02
I0213 09:37:54.685937 22509476222784 run_lib.py:133] step: 805950, training_loss: 4.84685e-02
I0213 09:38:13.293945 22509476222784 run_lib.py:133] step: 806000, training_loss: 3.57525e-02
I0213 09:38:13.462955 22509476222784 run_lib.py:146] step: 806000, eval_loss: 4.81223e-02
I0213 09:38:32.292938 22509476222784 run_lib.py:133] step: 806050, training_loss: 4.53113e-02
I0213 09:38:50.974576 22509476222784 run_lib.py:133] step: 806100, training_loss: 3.49692e-02
I0213 09:38:51.138409 22509476222784 run_lib.py:146] step: 806100, eval_loss: 5.23643e-02
I0213 09:39:09.674604 22509476222784 run_lib.py:133] step: 806150, training_loss: 3.61218e-02
I0213 09:39:28.226092 22509476222784 run_lib.py:133] step: 806200, training_loss: 4.17378e-02
I0213 09:39:28.396780 22509476222784 run_lib.py:146] step: 806200, eval_loss: 3.80420e-02
I0213 09:39:47.097395 22509476222784 run_lib.py:133] step: 806250, training_loss: 3.66716e-02
I0213 09:40:05.775570 22509476222784 run_lib.py:133] step: 806300, training_loss: 4.91568e-02
I0213 09:40:05.940668 22509476222784 run_lib.py:146] step: 806300, eval_loss: 4.85215e-02
I0213 09:40:24.712397 22509476222784 run_lib.py:133] step: 806350, training_loss: 5.11293e-02
I0213 09:40:43.276239 22509476222784 run_lib.py:133] step: 806400, training_loss: 3.29104e-02
I0213 09:40:43.435412 22509476222784 run_lib.py:146] step: 806400, eval_loss: 5.23636e-02
I0213 09:41:02.119875 22509476222784 run_lib.py:133] step: 806450, training_loss: 4.57077e-02
I0213 09:41:20.697971 22509476222784 run_lib.py:133] step: 806500, training_loss: 4.59379e-02
I0213 09:41:20.863998 22509476222784 run_lib.py:146] step: 806500, eval_loss: 6.37359e-02
I0213 09:41:39.436444 22509476222784 run_lib.py:133] step: 806550, training_loss: 3.52134e-02
I0213 09:41:58.248788 22509476222784 run_lib.py:133] step: 806600, training_loss: 3.86616e-02
I0213 09:41:58.414706 22509476222784 run_lib.py:146] step: 806600, eval_loss: 3.58631e-02
I0213 09:42:16.950114 22509476222784 run_lib.py:133] step: 806650, training_loss: 4.62257e-02
I0213 09:42:35.609516 22509476222784 run_lib.py:133] step: 806700, training_loss: 4.51013e-02
I0213 09:42:35.807246 22509476222784 run_lib.py:146] step: 806700, eval_loss: 4.16242e-02
I0213 09:42:54.366213 22509476222784 run_lib.py:133] step: 806750, training_loss: 2.80199e-02
I0213 09:43:12.976140 22509476222784 run_lib.py:133] step: 806800, training_loss: 3.77158e-02
I0213 09:43:13.167726 22509476222784 run_lib.py:146] step: 806800, eval_loss: 3.07463e-02
I0213 09:43:31.742766 22509476222784 run_lib.py:133] step: 806850, training_loss: 4.62242e-02
I0213 09:43:50.469154 22509476222784 run_lib.py:133] step: 806900, training_loss: 3.80844e-02
I0213 09:43:50.630745 22509476222784 run_lib.py:146] step: 806900, eval_loss: 5.55271e-02
I0213 09:44:09.123313 22509476222784 run_lib.py:133] step: 806950, training_loss: 5.20236e-02
I0213 09:44:27.708373 22509476222784 run_lib.py:133] step: 807000, training_loss: 5.15944e-02
I0213 09:44:27.905673 22509476222784 run_lib.py:146] step: 807000, eval_loss: 4.96317e-02
I0213 09:44:46.672537 22509476222784 run_lib.py:133] step: 807050, training_loss: 4.30372e-02
I0213 09:45:05.307736 22509476222784 run_lib.py:133] step: 807100, training_loss: 3.27250e-02
I0213 09:45:05.551609 22509476222784 run_lib.py:146] step: 807100, eval_loss: 5.06118e-02
I0213 09:45:24.200789 22509476222784 run_lib.py:133] step: 807150, training_loss: 3.47950e-02
I0213 09:45:42.763348 22509476222784 run_lib.py:133] step: 807200, training_loss: 4.10379e-02
I0213 09:45:42.952690 22509476222784 run_lib.py:146] step: 807200, eval_loss: 4.29188e-02
I0213 09:46:01.472806 22509476222784 run_lib.py:133] step: 807250, training_loss: 3.83983e-02
I0213 09:46:20.027260 22509476222784 run_lib.py:133] step: 807300, training_loss: 3.98952e-02
I0213 09:46:20.192019 22509476222784 run_lib.py:146] step: 807300, eval_loss: 3.03387e-02
I0213 09:46:38.905811 22509476222784 run_lib.py:133] step: 807350, training_loss: 4.54238e-02
I0213 09:46:57.583861 22509476222784 run_lib.py:133] step: 807400, training_loss: 3.34333e-02
I0213 09:46:57.762705 22509476222784 run_lib.py:146] step: 807400, eval_loss: 3.87543e-02
I0213 09:47:16.305015 22509476222784 run_lib.py:133] step: 807450, training_loss: 4.28764e-02
I0213 09:47:34.886809 22509476222784 run_lib.py:133] step: 807500, training_loss: 3.29956e-02
I0213 09:47:35.198191 22509476222784 run_lib.py:146] step: 807500, eval_loss: 4.77216e-02
I0213 09:47:53.864510 22509476222784 run_lib.py:133] step: 807550, training_loss: 4.48938e-02
I0213 09:48:12.480989 22509476222784 run_lib.py:133] step: 807600, training_loss: 3.74683e-02
I0213 09:48:12.645794 22509476222784 run_lib.py:146] step: 807600, eval_loss: 4.55505e-02
I0213 09:48:31.361460 22509476222784 run_lib.py:133] step: 807650, training_loss: 5.20292e-02
I0213 09:48:49.890616 22509476222784 run_lib.py:133] step: 807700, training_loss: 6.32550e-02
I0213 09:48:50.052131 22509476222784 run_lib.py:146] step: 807700, eval_loss: 3.18125e-02
I0213 09:49:08.723775 22509476222784 run_lib.py:133] step: 807750, training_loss: 4.61838e-02
I0213 09:49:27.254343 22509476222784 run_lib.py:133] step: 807800, training_loss: 4.51061e-02
I0213 09:49:27.421450 22509476222784 run_lib.py:146] step: 807800, eval_loss: 4.02181e-02
I0213 09:49:46.139564 22509476222784 run_lib.py:133] step: 807850, training_loss: 3.97349e-02
I0213 09:50:04.713051 22509476222784 run_lib.py:133] step: 807900, training_loss: 5.67347e-02
I0213 09:50:04.875790 22509476222784 run_lib.py:146] step: 807900, eval_loss: 5.08100e-02
I0213 09:50:23.471473 22509476222784 run_lib.py:133] step: 807950, training_loss: 4.35286e-02
I0213 09:50:42.229143 22509476222784 run_lib.py:133] step: 808000, training_loss: 4.57121e-02
I0213 09:50:42.435071 22509476222784 run_lib.py:146] step: 808000, eval_loss: 3.07976e-02
I0213 09:51:00.986467 22509476222784 run_lib.py:133] step: 808050, training_loss: 3.27011e-02
I0213 09:51:19.565510 22509476222784 run_lib.py:133] step: 808100, training_loss: 3.62820e-02
I0213 09:51:19.760728 22509476222784 run_lib.py:146] step: 808100, eval_loss: 3.44246e-02
I0213 09:51:38.469254 22509476222784 run_lib.py:133] step: 808150, training_loss: 4.44545e-02
I0213 09:51:57.230476 22509476222784 run_lib.py:133] step: 808200, training_loss: 4.40216e-02
I0213 09:51:57.416911 22509476222784 run_lib.py:146] step: 808200, eval_loss: 3.69340e-02
I0213 09:52:15.993750 22509476222784 run_lib.py:133] step: 808250, training_loss: 3.74458e-02
I0213 09:52:34.527716 22509476222784 run_lib.py:133] step: 808300, training_loss: 4.79407e-02
I0213 09:52:34.713504 22509476222784 run_lib.py:146] step: 808300, eval_loss: 4.99348e-02
I0213 09:52:53.273035 22509476222784 run_lib.py:133] step: 808350, training_loss: 4.12595e-02
I0213 09:53:11.976033 22509476222784 run_lib.py:133] step: 808400, training_loss: 4.04834e-02
I0213 09:53:12.152922 22509476222784 run_lib.py:146] step: 808400, eval_loss: 4.77926e-02
I0213 09:53:30.758281 22509476222784 run_lib.py:133] step: 808450, training_loss: 4.85848e-02
I0213 09:53:49.384706 22509476222784 run_lib.py:133] step: 808500, training_loss: 4.94423e-02
I0213 09:53:49.551668 22509476222784 run_lib.py:146] step: 808500, eval_loss: 4.01206e-02
I0213 09:54:08.062709 22509476222784 run_lib.py:133] step: 808550, training_loss: 5.38421e-02
I0213 09:54:26.804081 22509476222784 run_lib.py:133] step: 808600, training_loss: 4.88715e-02
I0213 09:54:26.968679 22509476222784 run_lib.py:146] step: 808600, eval_loss: 4.38437e-02
I0213 09:54:45.487586 22509476222784 run_lib.py:133] step: 808650, training_loss: 3.59068e-02
I0213 09:55:04.187470 22509476222784 run_lib.py:133] step: 808700, training_loss: 4.14980e-02
I0213 09:55:04.611742 22509476222784 run_lib.py:146] step: 808700, eval_loss: 4.45307e-02
I0213 09:55:23.176436 22509476222784 run_lib.py:133] step: 808750, training_loss: 4.71639e-02
I0213 09:55:41.688673 22509476222784 run_lib.py:133] step: 808800, training_loss: 3.49934e-02
I0213 09:55:41.854834 22509476222784 run_lib.py:146] step: 808800, eval_loss: 5.02243e-02
I0213 09:56:00.606254 22509476222784 run_lib.py:133] step: 808850, training_loss: 4.98820e-02
I0213 09:56:19.220870 22509476222784 run_lib.py:133] step: 808900, training_loss: 5.00250e-02
I0213 09:56:19.397843 22509476222784 run_lib.py:146] step: 808900, eval_loss: 4.30505e-02
I0213 09:56:38.031263 22509476222784 run_lib.py:133] step: 808950, training_loss: 3.41157e-02
I0213 09:56:56.571358 22509476222784 run_lib.py:133] step: 809000, training_loss: 3.84515e-02
I0213 09:56:56.735689 22509476222784 run_lib.py:146] step: 809000, eval_loss: 3.95916e-02
I0213 09:57:15.411858 22509476222784 run_lib.py:133] step: 809050, training_loss: 3.69399e-02
I0213 09:57:33.991402 22509476222784 run_lib.py:133] step: 809100, training_loss: 4.83953e-02
I0213 09:57:34.157758 22509476222784 run_lib.py:146] step: 809100, eval_loss: 4.65200e-02
I0213 09:57:52.909779 22509476222784 run_lib.py:133] step: 809150, training_loss: 4.00536e-02
I0213 09:58:11.504144 22509476222784 run_lib.py:133] step: 809200, training_loss: 3.67205e-02
I0213 09:58:11.675915 22509476222784 run_lib.py:146] step: 809200, eval_loss: 4.34069e-02
I0213 09:58:30.452009 22509476222784 run_lib.py:133] step: 809250, training_loss: 4.74322e-02
I0213 09:58:49.031916 22509476222784 run_lib.py:133] step: 809300, training_loss: 5.26987e-02
I0213 09:58:49.193665 22509476222784 run_lib.py:146] step: 809300, eval_loss: 3.98703e-02
I0213 09:59:07.706912 22509476222784 run_lib.py:133] step: 809350, training_loss: 5.10876e-02
I0213 09:59:26.381303 22509476222784 run_lib.py:133] step: 809400, training_loss: 3.68252e-02
I0213 09:59:26.549649 22509476222784 run_lib.py:146] step: 809400, eval_loss: 3.80029e-02
I0213 09:59:45.118874 22509476222784 run_lib.py:133] step: 809450, training_loss: 3.86026e-02
I0213 10:00:03.914821 22509476222784 run_lib.py:133] step: 809500, training_loss: 4.28602e-02
I0213 10:00:04.102771 22509476222784 run_lib.py:146] step: 809500, eval_loss: 3.76430e-02
I0213 10:00:22.634932 22509476222784 run_lib.py:133] step: 809550, training_loss: 5.14241e-02
I0213 10:00:41.158632 22509476222784 run_lib.py:133] step: 809600, training_loss: 3.71164e-02
I0213 10:00:41.323574 22509476222784 run_lib.py:146] step: 809600, eval_loss: 4.56711e-02
I0213 10:00:59.996677 22509476222784 run_lib.py:133] step: 809650, training_loss: 3.72041e-02
I0213 10:01:18.527279 22509476222784 run_lib.py:133] step: 809700, training_loss: 3.26362e-02
I0213 10:01:18.705706 22509476222784 run_lib.py:146] step: 809700, eval_loss: 5.41551e-02
I0213 10:01:37.276733 22509476222784 run_lib.py:133] step: 809750, training_loss: 3.88832e-02
I0213 10:01:56.014747 22509476222784 run_lib.py:133] step: 809800, training_loss: 3.82743e-02
I0213 10:01:56.179949 22509476222784 run_lib.py:146] step: 809800, eval_loss: 3.46038e-02
I0213 10:02:14.777622 22509476222784 run_lib.py:133] step: 809850, training_loss: 4.13507e-02
I0213 10:02:33.338150 22509476222784 run_lib.py:133] step: 809900, training_loss: 4.26444e-02
I0213 10:02:33.503952 22509476222784 run_lib.py:146] step: 809900, eval_loss: 3.47905e-02
I0213 10:02:52.120520 22509476222784 run_lib.py:133] step: 809950, training_loss: 4.24254e-02
I0213 10:03:10.658630 22509476222784 run_lib.py:133] step: 810000, training_loss: 3.58212e-02
I0213 10:03:11.401461 22509476222784 run_lib.py:146] step: 810000, eval_loss: 4.47919e-02
I0213 10:03:32.639305 22509476222784 run_lib.py:133] step: 810050, training_loss: 4.20590e-02
I0213 10:03:51.217784 22509476222784 run_lib.py:133] step: 810100, training_loss: 4.56220e-02
I0213 10:03:51.393954 22509476222784 run_lib.py:146] step: 810100, eval_loss: 4.83578e-02
I0213 10:04:10.131824 22509476222784 run_lib.py:133] step: 810150, training_loss: 2.66564e-02
I0213 10:04:28.640825 22509476222784 run_lib.py:133] step: 810200, training_loss: 3.41751e-02
I0213 10:04:28.804610 22509476222784 run_lib.py:146] step: 810200, eval_loss: 5.78679e-02
I0213 10:04:47.383095 22509476222784 run_lib.py:133] step: 810250, training_loss: 4.61551e-02
I0213 10:05:05.955085 22509476222784 run_lib.py:133] step: 810300, training_loss: 3.90880e-02
I0213 10:05:06.119790 22509476222784 run_lib.py:146] step: 810300, eval_loss: 3.75815e-02
I0213 10:05:24.738510 22509476222784 run_lib.py:133] step: 810350, training_loss: 3.71932e-02
I0213 10:05:43.274761 22509476222784 run_lib.py:133] step: 810400, training_loss: 2.14529e-02
I0213 10:05:43.457247 22509476222784 run_lib.py:146] step: 810400, eval_loss: 4.25333e-02
I0213 10:06:02.138678 22509476222784 run_lib.py:133] step: 810450, training_loss: 5.33458e-02
I0213 10:06:20.803511 22509476222784 run_lib.py:133] step: 810500, training_loss: 4.09841e-02
I0213 10:06:20.995744 22509476222784 run_lib.py:146] step: 810500, eval_loss: 3.58224e-02
I0213 10:06:39.580173 22509476222784 run_lib.py:133] step: 810550, training_loss: 3.70164e-02
I0213 10:06:58.195872 22509476222784 run_lib.py:133] step: 810600, training_loss: 4.02352e-02
I0213 10:06:58.359829 22509476222784 run_lib.py:146] step: 810600, eval_loss: 4.04217e-02
I0213 10:07:17.067517 22509476222784 run_lib.py:133] step: 810650, training_loss: 3.85342e-02
I0213 10:07:35.680828 22509476222784 run_lib.py:133] step: 810700, training_loss: 3.95349e-02
I0213 10:07:35.844625 22509476222784 run_lib.py:146] step: 810700, eval_loss: 3.85657e-02
I0213 10:07:54.503325 22509476222784 run_lib.py:133] step: 810750, training_loss: 4.26672e-02
I0213 10:08:13.102800 22509476222784 run_lib.py:133] step: 810800, training_loss: 4.66185e-02
I0213 10:08:13.268921 22509476222784 run_lib.py:146] step: 810800, eval_loss: 5.57972e-02
I0213 10:08:32.017207 22509476222784 run_lib.py:133] step: 810850, training_loss: 3.75195e-02
I0213 10:08:50.584519 22509476222784 run_lib.py:133] step: 810900, training_loss: 4.46090e-02
I0213 10:08:50.751744 22509476222784 run_lib.py:146] step: 810900, eval_loss: 4.75704e-02
I0213 10:09:09.446461 22509476222784 run_lib.py:133] step: 810950, training_loss: 4.03084e-02
I0213 10:09:27.978930 22509476222784 run_lib.py:133] step: 811000, training_loss: 4.27809e-02
I0213 10:09:28.142666 22509476222784 run_lib.py:146] step: 811000, eval_loss: 4.61470e-02
I0213 10:09:46.682013 22509476222784 run_lib.py:133] step: 811050, training_loss: 5.07038e-02
I0213 10:10:05.450228 22509476222784 run_lib.py:133] step: 811100, training_loss: 4.55697e-02
I0213 10:10:05.634068 22509476222784 run_lib.py:146] step: 811100, eval_loss: 4.59475e-02
I0213 10:10:24.193880 22509476222784 run_lib.py:133] step: 811150, training_loss: 4.63813e-02
I0213 10:10:42.681453 22509476222784 run_lib.py:133] step: 811200, training_loss: 4.54871e-02
I0213 10:10:42.843374 22509476222784 run_lib.py:146] step: 811200, eval_loss: 5.16983e-02
I0213 10:11:01.525365 22509476222784 run_lib.py:133] step: 811250, training_loss: 4.76466e-02
I0213 10:11:20.068434 22509476222784 run_lib.py:133] step: 811300, training_loss: 4.74097e-02
I0213 10:11:20.262789 22509476222784 run_lib.py:146] step: 811300, eval_loss: 3.49252e-02
I0213 10:11:38.977210 22509476222784 run_lib.py:133] step: 811350, training_loss: 3.76317e-02
I0213 10:11:57.582846 22509476222784 run_lib.py:133] step: 811400, training_loss: 3.82612e-02
I0213 10:11:57.749668 22509476222784 run_lib.py:146] step: 811400, eval_loss: 4.81041e-02
I0213 10:12:16.293547 22509476222784 run_lib.py:133] step: 811450, training_loss: 4.63245e-02
I0213 10:12:35.036984 22509476222784 run_lib.py:133] step: 811500, training_loss: 3.77232e-02
I0213 10:12:35.206687 22509476222784 run_lib.py:146] step: 811500, eval_loss: 4.80486e-02
I0213 10:12:53.717319 22509476222784 run_lib.py:133] step: 811550, training_loss: 3.45655e-02
I0213 10:13:12.293340 22509476222784 run_lib.py:133] step: 811600, training_loss: 4.50092e-02
I0213 10:13:12.459014 22509476222784 run_lib.py:146] step: 811600, eval_loss: 3.93327e-02
I0213 10:13:31.053819 22509476222784 run_lib.py:133] step: 811650, training_loss: 5.07794e-02
I0213 10:13:49.794655 22509476222784 run_lib.py:133] step: 811700, training_loss: 3.08506e-02
I0213 10:13:49.955064 22509476222784 run_lib.py:146] step: 811700, eval_loss: 4.24145e-02
I0213 10:14:08.419910 22509476222784 run_lib.py:133] step: 811750, training_loss: 5.21166e-02
I0213 10:14:27.013828 22509476222784 run_lib.py:133] step: 811800, training_loss: 4.12651e-02
I0213 10:14:27.179904 22509476222784 run_lib.py:146] step: 811800, eval_loss: 4.87376e-02
I0213 10:14:45.688569 22509476222784 run_lib.py:133] step: 811850, training_loss: 3.76697e-02
I0213 10:15:04.313011 22509476222784 run_lib.py:133] step: 811900, training_loss: 3.56636e-02
I0213 10:15:04.512766 22509476222784 run_lib.py:146] step: 811900, eval_loss: 3.27349e-02
I0213 10:15:23.225667 22509476222784 run_lib.py:133] step: 811950, training_loss: 3.94709e-02
I0213 10:15:41.833269 22509476222784 run_lib.py:133] step: 812000, training_loss: 3.90366e-02
I0213 10:15:41.998713 22509476222784 run_lib.py:146] step: 812000, eval_loss: 3.94508e-02
I0213 10:16:00.494629 22509476222784 run_lib.py:133] step: 812050, training_loss: 4.64001e-02
I0213 10:16:18.962528 22509476222784 run_lib.py:133] step: 812100, training_loss: 2.95861e-02
I0213 10:16:19.128863 22509476222784 run_lib.py:146] step: 812100, eval_loss: 4.50720e-02
I0213 10:16:37.876587 22509476222784 run_lib.py:133] step: 812150, training_loss: 3.70256e-02
I0213 10:16:56.493122 22509476222784 run_lib.py:133] step: 812200, training_loss: 5.06231e-02
I0213 10:16:56.659841 22509476222784 run_lib.py:146] step: 812200, eval_loss: 4.58601e-02
I0213 10:17:15.411285 22509476222784 run_lib.py:133] step: 812250, training_loss: 4.41845e-02
I0213 10:17:33.918620 22509476222784 run_lib.py:133] step: 812300, training_loss: 5.84433e-02
I0213 10:17:34.082419 22509476222784 run_lib.py:146] step: 812300, eval_loss: 4.24247e-02
I0213 10:17:52.764616 22509476222784 run_lib.py:133] step: 812350, training_loss: 3.36645e-02
I0213 10:18:11.288218 22509476222784 run_lib.py:133] step: 812400, training_loss: 3.80974e-02
I0213 10:18:11.468694 22509476222784 run_lib.py:146] step: 812400, eval_loss: 4.56642e-02
I0213 10:18:30.060916 22509476222784 run_lib.py:133] step: 812450, training_loss: 3.90298e-02
I0213 10:18:48.795634 22509476222784 run_lib.py:133] step: 812500, training_loss: 4.22379e-02
I0213 10:18:48.995976 22509476222784 run_lib.py:146] step: 812500, eval_loss: 4.04048e-02
I0213 10:19:07.582402 22509476222784 run_lib.py:133] step: 812550, training_loss: 4.62008e-02
I0213 10:19:26.247770 22509476222784 run_lib.py:133] step: 812600, training_loss: 3.76387e-02
I0213 10:19:26.412204 22509476222784 run_lib.py:146] step: 812600, eval_loss: 3.78213e-02
I0213 10:19:44.938169 22509476222784 run_lib.py:133] step: 812650, training_loss: 3.27722e-02
I0213 10:20:03.531307 22509476222784 run_lib.py:133] step: 812700, training_loss: 4.35973e-02
I0213 10:20:03.695934 22509476222784 run_lib.py:146] step: 812700, eval_loss: 4.08537e-02
I0213 10:20:22.455229 22509476222784 run_lib.py:133] step: 812750, training_loss: 3.12690e-02
I0213 10:20:41.002997 22509476222784 run_lib.py:133] step: 812800, training_loss: 5.44622e-02
I0213 10:20:41.204960 22509476222784 run_lib.py:146] step: 812800, eval_loss: 3.19203e-02
I0213 10:20:59.723346 22509476222784 run_lib.py:133] step: 812850, training_loss: 3.33651e-02
I0213 10:21:18.413465 22509476222784 run_lib.py:133] step: 812900, training_loss: 3.98080e-02
I0213 10:21:18.623720 22509476222784 run_lib.py:146] step: 812900, eval_loss: 3.74004e-02
I0213 10:21:37.224788 22509476222784 run_lib.py:133] step: 812950, training_loss: 5.02828e-02
I0213 10:21:55.798185 22509476222784 run_lib.py:133] step: 813000, training_loss: 5.44454e-02
I0213 10:21:56.152821 22509476222784 run_lib.py:146] step: 813000, eval_loss: 4.23747e-02
I0213 10:22:14.752173 22509476222784 run_lib.py:133] step: 813050, training_loss: 4.82738e-02
I0213 10:22:33.283653 22509476222784 run_lib.py:133] step: 813100, training_loss: 2.78366e-02
I0213 10:22:33.444726 22509476222784 run_lib.py:146] step: 813100, eval_loss: 4.52853e-02
I0213 10:22:51.975189 22509476222784 run_lib.py:133] step: 813150, training_loss: 4.46280e-02
I0213 10:23:10.539460 22509476222784 run_lib.py:133] step: 813200, training_loss: 3.95685e-02
I0213 10:23:10.708971 22509476222784 run_lib.py:146] step: 813200, eval_loss: 3.56016e-02
I0213 10:23:29.516611 22509476222784 run_lib.py:133] step: 813250, training_loss: 4.91893e-02
I0213 10:23:48.188290 22509476222784 run_lib.py:133] step: 813300, training_loss: 5.32510e-02
I0213 10:23:48.355975 22509476222784 run_lib.py:146] step: 813300, eval_loss: 5.11742e-02
I0213 10:24:06.859934 22509476222784 run_lib.py:133] step: 813350, training_loss: 4.49589e-02
I0213 10:24:25.529701 22509476222784 run_lib.py:133] step: 813400, training_loss: 4.11856e-02
I0213 10:24:25.703885 22509476222784 run_lib.py:146] step: 813400, eval_loss: 3.12479e-02
I0213 10:24:44.470033 22509476222784 run_lib.py:133] step: 813450, training_loss: 4.41149e-02
I0213 10:25:03.125867 22509476222784 run_lib.py:133] step: 813500, training_loss: 5.07172e-02
I0213 10:25:03.290391 22509476222784 run_lib.py:146] step: 813500, eval_loss: 3.91830e-02
I0213 10:25:21.816053 22509476222784 run_lib.py:133] step: 813550, training_loss: 4.40689e-02
I0213 10:25:40.344249 22509476222784 run_lib.py:133] step: 813600, training_loss: 4.33554e-02
I0213 10:25:40.518619 22509476222784 run_lib.py:146] step: 813600, eval_loss: 3.89569e-02
I0213 10:25:59.220766 22509476222784 run_lib.py:133] step: 813650, training_loss: 4.29132e-02
I0213 10:26:17.783555 22509476222784 run_lib.py:133] step: 813700, training_loss: 3.64955e-02
I0213 10:26:17.968987 22509476222784 run_lib.py:146] step: 813700, eval_loss: 3.75728e-02
I0213 10:26:36.657052 22509476222784 run_lib.py:133] step: 813750, training_loss: 4.13150e-02
I0213 10:26:55.175359 22509476222784 run_lib.py:133] step: 813800, training_loss: 4.32120e-02
I0213 10:26:55.340965 22509476222784 run_lib.py:146] step: 813800, eval_loss: 5.00377e-02
I0213 10:27:14.011858 22509476222784 run_lib.py:133] step: 813850, training_loss: 4.38065e-02
I0213 10:27:32.520198 22509476222784 run_lib.py:133] step: 813900, training_loss: 4.10869e-02
I0213 10:27:32.690805 22509476222784 run_lib.py:146] step: 813900, eval_loss: 3.88482e-02
I0213 10:27:51.268626 22509476222784 run_lib.py:133] step: 813950, training_loss: 3.51275e-02
I0213 10:28:10.071985 22509476222784 run_lib.py:133] step: 814000, training_loss: 4.22726e-02
I0213 10:28:10.236676 22509476222784 run_lib.py:146] step: 814000, eval_loss: 3.65641e-02
I0213 10:28:28.833395 22509476222784 run_lib.py:133] step: 814050, training_loss: 4.27363e-02
I0213 10:28:47.499537 22509476222784 run_lib.py:133] step: 814100, training_loss: 4.70055e-02
I0213 10:28:47.673749 22509476222784 run_lib.py:146] step: 814100, eval_loss: 4.32045e-02
I0213 10:29:06.213188 22509476222784 run_lib.py:133] step: 814150, training_loss: 5.52465e-02
I0213 10:29:24.728069 22509476222784 run_lib.py:133] step: 814200, training_loss: 4.61768e-02
I0213 10:29:24.902597 22509476222784 run_lib.py:146] step: 814200, eval_loss: 4.67121e-02
I0213 10:29:43.459243 22509476222784 run_lib.py:133] step: 814250, training_loss: 3.67261e-02
I0213 10:30:02.150019 22509476222784 run_lib.py:133] step: 814300, training_loss: 4.47529e-02
I0213 10:30:02.314907 22509476222784 run_lib.py:146] step: 814300, eval_loss: 5.75988e-02
I0213 10:30:20.838382 22509476222784 run_lib.py:133] step: 814350, training_loss: 4.29339e-02
I0213 10:30:39.384284 22509476222784 run_lib.py:133] step: 814400, training_loss: 5.71055e-02
I0213 10:30:39.552869 22509476222784 run_lib.py:146] step: 814400, eval_loss: 3.90101e-02
I0213 10:30:58.273507 22509476222784 run_lib.py:133] step: 814450, training_loss: 4.98474e-02
I0213 10:31:16.831854 22509476222784 run_lib.py:133] step: 814500, training_loss: 3.15590e-02
I0213 10:31:16.997992 22509476222784 run_lib.py:146] step: 814500, eval_loss: 4.43157e-02
I0213 10:31:35.732430 22509476222784 run_lib.py:133] step: 814550, training_loss: 4.61903e-02
I0213 10:31:54.277080 22509476222784 run_lib.py:133] step: 814600, training_loss: 4.49943e-02
I0213 10:31:54.479331 22509476222784 run_lib.py:146] step: 814600, eval_loss: 3.25111e-02
I0213 10:32:13.014520 22509476222784 run_lib.py:133] step: 814650, training_loss: 4.62330e-02
I0213 10:32:31.573379 22509476222784 run_lib.py:133] step: 814700, training_loss: 5.77005e-02
I0213 10:32:31.755574 22509476222784 run_lib.py:146] step: 814700, eval_loss: 4.33904e-02
I0213 10:32:50.480700 22509476222784 run_lib.py:133] step: 814750, training_loss: 4.19253e-02
I0213 10:33:09.076764 22509476222784 run_lib.py:133] step: 814800, training_loss: 4.59302e-02
I0213 10:33:09.243802 22509476222784 run_lib.py:146] step: 814800, eval_loss: 4.11475e-02
I0213 10:33:27.776300 22509476222784 run_lib.py:133] step: 814850, training_loss: 4.38182e-02
I0213 10:33:46.463117 22509476222784 run_lib.py:133] step: 814900, training_loss: 4.49766e-02
I0213 10:33:46.631077 22509476222784 run_lib.py:146] step: 814900, eval_loss: 4.99698e-02
I0213 10:34:05.350534 22509476222784 run_lib.py:133] step: 814950, training_loss: 3.88386e-02
I0213 10:34:24.003655 22509476222784 run_lib.py:133] step: 815000, training_loss: 4.62932e-02
I0213 10:34:24.168468 22509476222784 run_lib.py:146] step: 815000, eval_loss: 5.07976e-02
I0213 10:34:42.937842 22509476222784 run_lib.py:133] step: 815050, training_loss: 4.43860e-02
I0213 10:35:01.520405 22509476222784 run_lib.py:133] step: 815100, training_loss: 3.78154e-02
I0213 10:35:01.684784 22509476222784 run_lib.py:146] step: 815100, eval_loss: 3.88186e-02
I0213 10:35:20.406244 22509476222784 run_lib.py:133] step: 815150, training_loss: 4.11494e-02
I0213 10:35:39.002296 22509476222784 run_lib.py:133] step: 815200, training_loss: 4.68231e-02
I0213 10:35:39.189840 22509476222784 run_lib.py:146] step: 815200, eval_loss: 3.35047e-02
I0213 10:35:57.883955 22509476222784 run_lib.py:133] step: 815250, training_loss: 4.91216e-02
I0213 10:36:16.411107 22509476222784 run_lib.py:133] step: 815300, training_loss: 3.99336e-02
I0213 10:36:16.574965 22509476222784 run_lib.py:146] step: 815300, eval_loss: 5.61392e-02
I0213 10:36:35.106508 22509476222784 run_lib.py:133] step: 815350, training_loss: 4.37904e-02
I0213 10:36:53.832974 22509476222784 run_lib.py:133] step: 815400, training_loss: 3.94674e-02
I0213 10:36:54.005904 22509476222784 run_lib.py:146] step: 815400, eval_loss: 5.50415e-02
I0213 10:37:12.545451 22509476222784 run_lib.py:133] step: 815450, training_loss: 4.17530e-02
I0213 10:37:31.082368 22509476222784 run_lib.py:133] step: 815500, training_loss: 5.77886e-02
I0213 10:37:31.253767 22509476222784 run_lib.py:146] step: 815500, eval_loss: 3.34143e-02
I0213 10:37:50.056515 22509476222784 run_lib.py:133] step: 815550, training_loss: 4.13954e-02
I0213 10:38:08.827755 22509476222784 run_lib.py:133] step: 815600, training_loss: 4.97526e-02
I0213 10:38:08.995587 22509476222784 run_lib.py:146] step: 815600, eval_loss: 4.77139e-02
I0213 10:38:27.499021 22509476222784 run_lib.py:133] step: 815650, training_loss: 4.77730e-02
I0213 10:38:46.040750 22509476222784 run_lib.py:133] step: 815700, training_loss: 4.21752e-02
I0213 10:38:46.206984 22509476222784 run_lib.py:146] step: 815700, eval_loss: 3.68638e-02
I0213 10:39:04.794394 22509476222784 run_lib.py:133] step: 815750, training_loss: 4.69217e-02
I0213 10:39:23.615740 22509476222784 run_lib.py:133] step: 815800, training_loss: 4.19384e-02
I0213 10:39:23.780903 22509476222784 run_lib.py:146] step: 815800, eval_loss: 4.00245e-02
I0213 10:39:42.315288 22509476222784 run_lib.py:133] step: 815850, training_loss: 4.81706e-02
I0213 10:40:00.826175 22509476222784 run_lib.py:133] step: 815900, training_loss: 3.69163e-02
I0213 10:40:00.995575 22509476222784 run_lib.py:146] step: 815900, eval_loss: 4.33296e-02
I0213 10:40:19.505805 22509476222784 run_lib.py:133] step: 815950, training_loss: 3.26794e-02
I0213 10:40:38.232067 22509476222784 run_lib.py:133] step: 816000, training_loss: 5.67076e-02
I0213 10:40:38.423764 22509476222784 run_lib.py:146] step: 816000, eval_loss: 4.19805e-02
I0213 10:40:57.087774 22509476222784 run_lib.py:133] step: 816050, training_loss: 3.85073e-02
I0213 10:41:15.764966 22509476222784 run_lib.py:133] step: 816100, training_loss: 3.41631e-02
I0213 10:41:15.942700 22509476222784 run_lib.py:146] step: 816100, eval_loss: 3.13716e-02
I0213 10:41:34.490183 22509476222784 run_lib.py:133] step: 816150, training_loss: 4.29310e-02
I0213 10:41:53.052897 22509476222784 run_lib.py:133] step: 816200, training_loss: 4.57021e-02
I0213 10:41:53.226059 22509476222784 run_lib.py:146] step: 816200, eval_loss: 4.99450e-02
I0213 10:42:11.897394 22509476222784 run_lib.py:133] step: 816250, training_loss: 4.38669e-02
I0213 10:42:30.602403 22509476222784 run_lib.py:133] step: 816300, training_loss: 3.23248e-02
I0213 10:42:30.792540 22509476222784 run_lib.py:146] step: 816300, eval_loss: 3.87590e-02
I0213 10:42:49.342113 22509476222784 run_lib.py:133] step: 816350, training_loss: 4.29108e-02
I0213 10:43:07.866039 22509476222784 run_lib.py:133] step: 816400, training_loss: 3.69593e-02
I0213 10:43:08.034425 22509476222784 run_lib.py:146] step: 816400, eval_loss: 4.75757e-02
I0213 10:43:26.711304 22509476222784 run_lib.py:133] step: 816450, training_loss: 3.65398e-02
I0213 10:43:45.298174 22509476222784 run_lib.py:133] step: 816500, training_loss: 3.51860e-02
I0213 10:43:45.463792 22509476222784 run_lib.py:146] step: 816500, eval_loss: 5.73893e-02
I0213 10:44:04.236705 22509476222784 run_lib.py:133] step: 816550, training_loss: 3.67541e-02
I0213 10:44:22.865828 22509476222784 run_lib.py:133] step: 816600, training_loss: 4.24235e-02
I0213 10:44:23.031678 22509476222784 run_lib.py:146] step: 816600, eval_loss: 4.33780e-02
I0213 10:44:41.718354 22509476222784 run_lib.py:133] step: 816650, training_loss: 4.26207e-02
I0213 10:45:00.232906 22509476222784 run_lib.py:133] step: 816700, training_loss: 3.91614e-02
I0213 10:45:00.456730 22509476222784 run_lib.py:146] step: 816700, eval_loss: 3.28221e-02
I0213 10:45:18.990242 22509476222784 run_lib.py:133] step: 816750, training_loss: 3.78523e-02
I0213 10:45:37.749923 22509476222784 run_lib.py:133] step: 816800, training_loss: 3.52076e-02
I0213 10:45:37.915262 22509476222784 run_lib.py:146] step: 816800, eval_loss: 4.61706e-02
I0213 10:45:56.503716 22509476222784 run_lib.py:133] step: 816850, training_loss: 4.98118e-02
I0213 10:46:15.236944 22509476222784 run_lib.py:133] step: 816900, training_loss: 4.16477e-02
I0213 10:46:15.424748 22509476222784 run_lib.py:146] step: 816900, eval_loss: 4.03553e-02
I0213 10:46:34.000414 22509476222784 run_lib.py:133] step: 816950, training_loss: 3.28331e-02
I0213 10:46:52.560137 22509476222784 run_lib.py:133] step: 817000, training_loss: 4.05235e-02
I0213 10:46:52.728466 22509476222784 run_lib.py:146] step: 817000, eval_loss: 5.58502e-02
I0213 10:47:11.465988 22509476222784 run_lib.py:133] step: 817050, training_loss: 4.37537e-02
I0213 10:47:30.052892 22509476222784 run_lib.py:133] step: 817100, training_loss: 3.32069e-02
I0213 10:47:30.241702 22509476222784 run_lib.py:146] step: 817100, eval_loss: 4.01875e-02
I0213 10:47:48.815043 22509476222784 run_lib.py:133] step: 817150, training_loss: 3.06332e-02
I0213 10:48:07.490229 22509476222784 run_lib.py:133] step: 817200, training_loss: 4.84281e-02
I0213 10:48:07.654788 22509476222784 run_lib.py:146] step: 817200, eval_loss: 4.39518e-02
I0213 10:48:26.232394 22509476222784 run_lib.py:133] step: 817250, training_loss: 4.43880e-02
I0213 10:48:44.762388 22509476222784 run_lib.py:133] step: 817300, training_loss: 4.23352e-02
I0213 10:48:44.928995 22509476222784 run_lib.py:146] step: 817300, eval_loss: 4.04490e-02
I0213 10:49:03.638668 22509476222784 run_lib.py:133] step: 817350, training_loss: 3.53161e-02
I0213 10:49:22.190397 22509476222784 run_lib.py:133] step: 817400, training_loss: 3.95628e-02
I0213 10:49:22.365986 22509476222784 run_lib.py:146] step: 817400, eval_loss: 4.11360e-02
I0213 10:49:40.887920 22509476222784 run_lib.py:133] step: 817450, training_loss: 4.31229e-02
I0213 10:49:59.422415 22509476222784 run_lib.py:133] step: 817500, training_loss: 4.61646e-02
I0213 10:49:59.587703 22509476222784 run_lib.py:146] step: 817500, eval_loss: 5.39847e-02
I0213 10:50:18.322185 22509476222784 run_lib.py:133] step: 817550, training_loss: 4.14499e-02
I0213 10:50:36.998688 22509476222784 run_lib.py:133] step: 817600, training_loss: 6.14548e-02
I0213 10:50:37.174607 22509476222784 run_lib.py:146] step: 817600, eval_loss: 4.26739e-02
I0213 10:50:55.727078 22509476222784 run_lib.py:133] step: 817650, training_loss: 3.86172e-02
I0213 10:51:14.242676 22509476222784 run_lib.py:133] step: 817700, training_loss: 4.36493e-02
I0213 10:51:14.408433 22509476222784 run_lib.py:146] step: 817700, eval_loss: 3.68861e-02
I0213 10:51:33.158143 22509476222784 run_lib.py:133] step: 817750, training_loss: 4.71119e-02
I0213 10:51:51.749690 22509476222784 run_lib.py:133] step: 817800, training_loss: 5.31551e-02
I0213 10:51:51.935950 22509476222784 run_lib.py:146] step: 817800, eval_loss: 4.31179e-02
I0213 10:52:10.697880 22509476222784 run_lib.py:133] step: 817850, training_loss: 2.80780e-02
I0213 10:52:29.277118 22509476222784 run_lib.py:133] step: 817900, training_loss: 3.24411e-02
I0213 10:52:29.437672 22509476222784 run_lib.py:146] step: 817900, eval_loss: 4.60080e-02
I0213 10:52:48.199843 22509476222784 run_lib.py:133] step: 817950, training_loss: 4.94527e-02
I0213 10:53:06.757242 22509476222784 run_lib.py:133] step: 818000, training_loss: 4.68904e-02
I0213 10:53:06.929935 22509476222784 run_lib.py:146] step: 818000, eval_loss: 3.48040e-02
I0213 10:53:25.558687 22509476222784 run_lib.py:133] step: 818050, training_loss: 3.30445e-02
I0213 10:53:44.144107 22509476222784 run_lib.py:133] step: 818100, training_loss: 4.54289e-02
I0213 10:53:44.320659 22509476222784 run_lib.py:146] step: 818100, eval_loss: 3.33227e-02
I0213 10:54:02.926366 22509476222784 run_lib.py:133] step: 818150, training_loss: 3.81636e-02
I0213 10:54:21.677652 22509476222784 run_lib.py:133] step: 818200, training_loss: 5.45481e-02
I0213 10:54:21.842074 22509476222784 run_lib.py:146] step: 818200, eval_loss: 3.99046e-02
I0213 10:54:40.376476 22509476222784 run_lib.py:133] step: 818250, training_loss: 3.25548e-02
I0213 10:54:58.910618 22509476222784 run_lib.py:133] step: 818300, training_loss: 4.96198e-02
I0213 10:54:59.071218 22509476222784 run_lib.py:146] step: 818300, eval_loss: 3.92416e-02
I0213 10:55:17.835642 22509476222784 run_lib.py:133] step: 818350, training_loss: 3.10830e-02
I0213 10:55:36.389605 22509476222784 run_lib.py:133] step: 818400, training_loss: 3.60973e-02
I0213 10:55:36.558995 22509476222784 run_lib.py:146] step: 818400, eval_loss: 3.35029e-02
I0213 10:55:55.241055 22509476222784 run_lib.py:133] step: 818450, training_loss: 4.27002e-02
I0213 10:56:13.749251 22509476222784 run_lib.py:133] step: 818500, training_loss: 3.28711e-02
I0213 10:56:13.940942 22509476222784 run_lib.py:146] step: 818500, eval_loss: 3.36445e-02
I0213 10:56:32.481510 22509476222784 run_lib.py:133] step: 818550, training_loss: 3.66295e-02
I0213 10:56:51.202420 22509476222784 run_lib.py:133] step: 818600, training_loss: 4.41581e-02
I0213 10:56:51.382781 22509476222784 run_lib.py:146] step: 818600, eval_loss: 3.59974e-02
I0213 10:57:09.997710 22509476222784 run_lib.py:133] step: 818650, training_loss: 3.57543e-02
I0213 10:57:28.543148 22509476222784 run_lib.py:133] step: 818700, training_loss: 4.43478e-02
I0213 10:57:28.708531 22509476222784 run_lib.py:146] step: 818700, eval_loss: 4.99428e-02
I0213 10:57:47.237730 22509476222784 run_lib.py:133] step: 818750, training_loss: 3.35351e-02
I0213 10:58:05.955396 22509476222784 run_lib.py:133] step: 818800, training_loss: 3.16287e-02
I0213 10:58:06.116517 22509476222784 run_lib.py:146] step: 818800, eval_loss: 2.39946e-02
I0213 10:58:24.693661 22509476222784 run_lib.py:133] step: 818850, training_loss: 4.13755e-02
I0213 10:58:43.448540 22509476222784 run_lib.py:133] step: 818900, training_loss: 4.95417e-02
I0213 10:58:43.617288 22509476222784 run_lib.py:146] step: 818900, eval_loss: 4.07202e-02
I0213 10:59:02.169348 22509476222784 run_lib.py:133] step: 818950, training_loss: 3.50360e-02
I0213 10:59:20.698444 22509476222784 run_lib.py:133] step: 819000, training_loss: 4.43317e-02
I0213 10:59:20.873260 22509476222784 run_lib.py:146] step: 819000, eval_loss: 5.21862e-02
I0213 10:59:39.630080 22509476222784 run_lib.py:133] step: 819050, training_loss: 3.86247e-02
I0213 10:59:58.266144 22509476222784 run_lib.py:133] step: 819100, training_loss: 4.12870e-02
I0213 10:59:58.432768 22509476222784 run_lib.py:146] step: 819100, eval_loss: 3.97339e-02
I0213 11:00:16.994509 22509476222784 run_lib.py:133] step: 819150, training_loss: 4.54732e-02
I0213 11:00:35.554985 22509476222784 run_lib.py:133] step: 819200, training_loss: 4.29959e-02
I0213 11:00:35.719957 22509476222784 run_lib.py:146] step: 819200, eval_loss: 3.95501e-02
I0213 11:00:54.494519 22509476222784 run_lib.py:133] step: 819250, training_loss: 3.52025e-02
I0213 11:01:13.022602 22509476222784 run_lib.py:133] step: 819300, training_loss: 3.14962e-02
I0213 11:01:13.224692 22509476222784 run_lib.py:146] step: 819300, eval_loss: 3.72095e-02
I0213 11:01:31.869443 22509476222784 run_lib.py:133] step: 819350, training_loss: 4.68962e-02
I0213 11:01:50.433481 22509476222784 run_lib.py:133] step: 819400, training_loss: 4.05024e-02
I0213 11:01:50.632920 22509476222784 run_lib.py:146] step: 819400, eval_loss: 5.14518e-02
I0213 11:02:09.405791 22509476222784 run_lib.py:133] step: 819450, training_loss: 3.56763e-02
I0213 11:02:28.161191 22509476222784 run_lib.py:133] step: 819500, training_loss: 4.93122e-02
I0213 11:02:28.326985 22509476222784 run_lib.py:146] step: 819500, eval_loss: 3.80547e-02
I0213 11:02:46.851875 22509476222784 run_lib.py:133] step: 819550, training_loss: 4.08203e-02
I0213 11:03:05.563354 22509476222784 run_lib.py:133] step: 819600, training_loss: 4.02553e-02
I0213 11:03:05.727724 22509476222784 run_lib.py:146] step: 819600, eval_loss: 4.15677e-02
I0213 11:03:24.250883 22509476222784 run_lib.py:133] step: 819650, training_loss: 3.61201e-02
I0213 11:03:42.970257 22509476222784 run_lib.py:133] step: 819700, training_loss: 4.53282e-02
I0213 11:03:43.134999 22509476222784 run_lib.py:146] step: 819700, eval_loss: 4.43016e-02
I0213 11:04:01.659192 22509476222784 run_lib.py:133] step: 819750, training_loss: 3.46327e-02
I0213 11:04:20.163919 22509476222784 run_lib.py:133] step: 819800, training_loss: 4.92543e-02
I0213 11:04:20.321756 22509476222784 run_lib.py:146] step: 819800, eval_loss: 2.90065e-02
I0213 11:04:39.007389 22509476222784 run_lib.py:133] step: 819850, training_loss: 3.30636e-02
I0213 11:04:57.616757 22509476222784 run_lib.py:133] step: 819900, training_loss: 4.54530e-02
I0213 11:04:57.785815 22509476222784 run_lib.py:146] step: 819900, eval_loss: 3.73977e-02
I0213 11:05:16.376378 22509476222784 run_lib.py:133] step: 819950, training_loss: 3.68474e-02
I0213 11:05:35.125593 22509476222784 run_lib.py:133] step: 820000, training_loss: 3.62653e-02
I0213 11:05:36.107695 22509476222784 run_lib.py:146] step: 820000, eval_loss: 5.09802e-02
I0213 11:05:57.601565 22509476222784 run_lib.py:133] step: 820050, training_loss: 4.14127e-02
I0213 11:06:16.147346 22509476222784 run_lib.py:133] step: 820100, training_loss: 4.91006e-02
I0213 11:06:16.311867 22509476222784 run_lib.py:146] step: 820100, eval_loss: 5.30787e-02
I0213 11:06:34.930698 22509476222784 run_lib.py:133] step: 820150, training_loss: 3.65384e-02
I0213 11:06:53.537067 22509476222784 run_lib.py:133] step: 820200, training_loss: 4.01854e-02
I0213 11:06:53.704624 22509476222784 run_lib.py:146] step: 820200, eval_loss: 4.09971e-02
I0213 11:07:12.279563 22509476222784 run_lib.py:133] step: 820250, training_loss: 4.70551e-02
I0213 11:07:30.826141 22509476222784 run_lib.py:133] step: 820300, training_loss: 3.81012e-02
I0213 11:07:30.984380 22509476222784 run_lib.py:146] step: 820300, eval_loss: 3.34201e-02
I0213 11:07:49.676341 22509476222784 run_lib.py:133] step: 820350, training_loss: 3.22166e-02
I0213 11:08:08.225375 22509476222784 run_lib.py:133] step: 820400, training_loss: 3.66344e-02
I0213 11:08:08.447650 22509476222784 run_lib.py:146] step: 820400, eval_loss: 3.75729e-02
I0213 11:08:27.065315 22509476222784 run_lib.py:133] step: 820450, training_loss: 5.14338e-02
I0213 11:08:45.651951 22509476222784 run_lib.py:133] step: 820500, training_loss: 4.26925e-02
I0213 11:08:45.843710 22509476222784 run_lib.py:146] step: 820500, eval_loss: 4.16715e-02
I0213 11:09:04.348327 22509476222784 run_lib.py:133] step: 820550, training_loss: 3.64009e-02
I0213 11:09:22.867634 22509476222784 run_lib.py:133] step: 820600, training_loss: 4.14593e-02
I0213 11:09:23.059728 22509476222784 run_lib.py:146] step: 820600, eval_loss: 3.41179e-02
I0213 11:09:41.799327 22509476222784 run_lib.py:133] step: 820650, training_loss: 3.92407e-02
I0213 11:10:00.417522 22509476222784 run_lib.py:133] step: 820700, training_loss: 4.58150e-02
I0213 11:10:00.628447 22509476222784 run_lib.py:146] step: 820700, eval_loss: 5.20936e-02
I0213 11:10:19.228470 22509476222784 run_lib.py:133] step: 820750, training_loss: 4.50369e-02
I0213 11:10:37.853702 22509476222784 run_lib.py:133] step: 820800, training_loss: 3.91470e-02
I0213 11:10:38.053631 22509476222784 run_lib.py:146] step: 820800, eval_loss: 5.39795e-02
I0213 11:10:56.847357 22509476222784 run_lib.py:133] step: 820850, training_loss: 4.01542e-02
I0213 11:11:15.427071 22509476222784 run_lib.py:133] step: 820900, training_loss: 3.53931e-02
I0213 11:11:15.591735 22509476222784 run_lib.py:146] step: 820900, eval_loss: 5.29220e-02
I0213 11:11:34.270992 22509476222784 run_lib.py:133] step: 820950, training_loss: 3.31476e-02
I0213 11:11:52.842231 22509476222784 run_lib.py:133] step: 821000, training_loss: 4.45143e-02
I0213 11:11:53.130732 22509476222784 run_lib.py:146] step: 821000, eval_loss: 4.12611e-02
I0213 11:12:11.900258 22509476222784 run_lib.py:133] step: 821050, training_loss: 4.33610e-02
I0213 11:12:30.470339 22509476222784 run_lib.py:133] step: 821100, training_loss: 4.42015e-02
I0213 11:12:30.639868 22509476222784 run_lib.py:146] step: 821100, eval_loss: 3.63551e-02
I0213 11:12:49.296466 22509476222784 run_lib.py:133] step: 821150, training_loss: 4.49785e-02
I0213 11:13:07.782844 22509476222784 run_lib.py:133] step: 821200, training_loss: 4.17918e-02
I0213 11:13:07.946693 22509476222784 run_lib.py:146] step: 821200, eval_loss: 4.15330e-02
I0213 11:13:26.494709 22509476222784 run_lib.py:133] step: 821250, training_loss: 4.96644e-02
I0213 11:13:45.188704 22509476222784 run_lib.py:133] step: 821300, training_loss: 3.41525e-02
I0213 11:13:45.357971 22509476222784 run_lib.py:146] step: 821300, eval_loss: 3.74337e-02
I0213 11:14:04.011840 22509476222784 run_lib.py:133] step: 821350, training_loss: 4.04459e-02
I0213 11:14:22.604785 22509476222784 run_lib.py:133] step: 821400, training_loss: 4.62107e-02
I0213 11:14:22.801888 22509476222784 run_lib.py:146] step: 821400, eval_loss: 4.61197e-02
I0213 11:14:41.570276 22509476222784 run_lib.py:133] step: 821450, training_loss: 4.18470e-02
I0213 11:15:00.267723 22509476222784 run_lib.py:133] step: 821500, training_loss: 3.80537e-02
I0213 11:15:00.441066 22509476222784 run_lib.py:146] step: 821500, eval_loss: 3.34973e-02
I0213 11:15:19.005941 22509476222784 run_lib.py:133] step: 821550, training_loss: 3.52132e-02
I0213 11:15:37.604229 22509476222784 run_lib.py:133] step: 821600, training_loss: 4.57885e-02
I0213 11:15:37.768594 22509476222784 run_lib.py:146] step: 821600, eval_loss: 4.50209e-02
I0213 11:15:56.343947 22509476222784 run_lib.py:133] step: 821650, training_loss: 3.61394e-02
I0213 11:16:15.052023 22509476222784 run_lib.py:133] step: 821700, training_loss: 4.33448e-02
I0213 11:16:15.214570 22509476222784 run_lib.py:146] step: 821700, eval_loss: 5.78978e-02
I0213 11:16:33.731139 22509476222784 run_lib.py:133] step: 821750, training_loss: 4.03800e-02
I0213 11:16:52.275776 22509476222784 run_lib.py:133] step: 821800, training_loss: 3.85430e-02
I0213 11:16:52.438768 22509476222784 run_lib.py:146] step: 821800, eval_loss: 3.78085e-02
I0213 11:17:11.033299 22509476222784 run_lib.py:133] step: 821850, training_loss: 4.02772e-02
I0213 11:17:29.794867 22509476222784 run_lib.py:133] step: 821900, training_loss: 3.37002e-02
I0213 11:17:29.969258 22509476222784 run_lib.py:146] step: 821900, eval_loss: 4.53851e-02
I0213 11:17:48.474465 22509476222784 run_lib.py:133] step: 821950, training_loss: 4.59614e-02
I0213 11:18:07.032323 22509476222784 run_lib.py:133] step: 822000, training_loss: 4.15778e-02
I0213 11:18:07.196699 22509476222784 run_lib.py:146] step: 822000, eval_loss: 4.04705e-02
I0213 11:18:25.708423 22509476222784 run_lib.py:133] step: 822050, training_loss: 5.31558e-02
I0213 11:18:44.341516 22509476222784 run_lib.py:133] step: 822100, training_loss: 3.50273e-02
I0213 11:18:44.506584 22509476222784 run_lib.py:146] step: 822100, eval_loss: 5.65217e-02
I0213 11:19:03.218275 22509476222784 run_lib.py:133] step: 822150, training_loss: 4.16122e-02
I0213 11:19:21.855575 22509476222784 run_lib.py:133] step: 822200, training_loss: 4.53200e-02
I0213 11:19:22.050458 22509476222784 run_lib.py:146] step: 822200, eval_loss: 4.37490e-02
I0213 11:19:40.584862 22509476222784 run_lib.py:133] step: 822250, training_loss: 3.74120e-02
I0213 11:19:59.264784 22509476222784 run_lib.py:133] step: 822300, training_loss: 4.09013e-02
I0213 11:19:59.431869 22509476222784 run_lib.py:146] step: 822300, eval_loss: 4.19947e-02
I0213 11:20:18.092008 22509476222784 run_lib.py:133] step: 822350, training_loss: 4.27834e-02
I0213 11:20:36.693859 22509476222784 run_lib.py:133] step: 822400, training_loss: 3.86996e-02
I0213 11:20:36.859643 22509476222784 run_lib.py:146] step: 822400, eval_loss: 4.89137e-02
I0213 11:20:55.641811 22509476222784 run_lib.py:133] step: 822450, training_loss: 4.15903e-02
I0213 11:21:14.222738 22509476222784 run_lib.py:133] step: 822500, training_loss: 4.41921e-02
I0213 11:21:14.387812 22509476222784 run_lib.py:146] step: 822500, eval_loss: 3.99644e-02
I0213 11:21:33.086685 22509476222784 run_lib.py:133] step: 822550, training_loss: 3.54846e-02
I0213 11:21:51.596669 22509476222784 run_lib.py:133] step: 822600, training_loss: 4.22896e-02
I0213 11:21:51.778500 22509476222784 run_lib.py:146] step: 822600, eval_loss: 3.84374e-02
I0213 11:22:10.345798 22509476222784 run_lib.py:133] step: 822650, training_loss: 4.04660e-02
I0213 11:22:29.091557 22509476222784 run_lib.py:133] step: 822700, training_loss: 3.76016e-02
I0213 11:22:29.256929 22509476222784 run_lib.py:146] step: 822700, eval_loss: 4.42894e-02
I0213 11:22:47.839272 22509476222784 run_lib.py:133] step: 822750, training_loss: 3.70822e-02
I0213 11:23:06.564980 22509476222784 run_lib.py:133] step: 822800, training_loss: 4.01966e-02
I0213 11:23:06.729652 22509476222784 run_lib.py:146] step: 822800, eval_loss: 5.69109e-02
I0213 11:23:25.239509 22509476222784 run_lib.py:133] step: 822850, training_loss: 2.88555e-02
I0213 11:23:43.769727 22509476222784 run_lib.py:133] step: 822900, training_loss: 4.39347e-02
I0213 11:23:43.947701 22509476222784 run_lib.py:146] step: 822900, eval_loss: 4.66442e-02
I0213 11:24:02.679922 22509476222784 run_lib.py:133] step: 822950, training_loss: 3.58518e-02
I0213 11:24:21.297614 22509476222784 run_lib.py:133] step: 823000, training_loss: 3.79301e-02
I0213 11:24:21.477979 22509476222784 run_lib.py:146] step: 823000, eval_loss: 5.14346e-02
I0213 11:24:40.007593 22509476222784 run_lib.py:133] step: 823050, training_loss: 3.75813e-02
I0213 11:24:58.692724 22509476222784 run_lib.py:133] step: 823100, training_loss: 5.12558e-02
I0213 11:24:58.859690 22509476222784 run_lib.py:146] step: 823100, eval_loss: 5.26824e-02
I0213 11:25:17.376029 22509476222784 run_lib.py:133] step: 823150, training_loss: 3.61475e-02
I0213 11:25:35.955610 22509476222784 run_lib.py:133] step: 823200, training_loss: 5.12308e-02
I0213 11:25:36.120893 22509476222784 run_lib.py:146] step: 823200, eval_loss: 3.31876e-02
I0213 11:25:54.745247 22509476222784 run_lib.py:133] step: 823250, training_loss: 3.05557e-02
I0213 11:26:13.299038 22509476222784 run_lib.py:133] step: 823300, training_loss: 4.15307e-02
I0213 11:26:13.465899 22509476222784 run_lib.py:146] step: 823300, eval_loss: 4.63059e-02
I0213 11:26:31.993344 22509476222784 run_lib.py:133] step: 823350, training_loss: 5.85212e-02
I0213 11:26:50.496204 22509476222784 run_lib.py:133] step: 823400, training_loss: 3.67378e-02
I0213 11:26:50.659731 22509476222784 run_lib.py:146] step: 823400, eval_loss: 4.01877e-02
I0213 11:27:09.384843 22509476222784 run_lib.py:133] step: 823450, training_loss: 3.94783e-02
I0213 11:27:28.048591 22509476222784 run_lib.py:133] step: 823500, training_loss: 4.40771e-02
I0213 11:27:28.213205 22509476222784 run_lib.py:146] step: 823500, eval_loss: 5.24142e-02
I0213 11:27:46.780725 22509476222784 run_lib.py:133] step: 823550, training_loss: 4.46969e-02
I0213 11:28:05.333610 22509476222784 run_lib.py:133] step: 823600, training_loss: 4.29545e-02
I0213 11:28:05.567365 22509476222784 run_lib.py:146] step: 823600, eval_loss: 5.30467e-02
I0213 11:28:24.348984 22509476222784 run_lib.py:133] step: 823650, training_loss: 4.16011e-02
I0213 11:28:42.928608 22509476222784 run_lib.py:133] step: 823700, training_loss: 3.53553e-02
I0213 11:28:43.094949 22509476222784 run_lib.py:146] step: 823700, eval_loss: 3.85020e-02
I0213 11:29:01.846182 22509476222784 run_lib.py:133] step: 823750, training_loss: 4.98140e-02
I0213 11:29:20.468340 22509476222784 run_lib.py:133] step: 823800, training_loss: 4.89699e-02
I0213 11:29:20.635339 22509476222784 run_lib.py:146] step: 823800, eval_loss: 3.91417e-02
I0213 11:29:39.298484 22509476222784 run_lib.py:133] step: 823850, training_loss: 4.19730e-02
I0213 11:29:57.821090 22509476222784 run_lib.py:133] step: 823900, training_loss: 4.99602e-02
I0213 11:29:57.995712 22509476222784 run_lib.py:146] step: 823900, eval_loss: 3.42312e-02
I0213 11:30:16.617290 22509476222784 run_lib.py:133] step: 823950, training_loss: 2.75828e-02
I0213 11:30:35.189820 22509476222784 run_lib.py:133] step: 824000, training_loss: 4.51831e-02
I0213 11:30:35.359141 22509476222784 run_lib.py:146] step: 824000, eval_loss: 4.71009e-02
I0213 11:30:53.980318 22509476222784 run_lib.py:133] step: 824050, training_loss: 4.37017e-02
I0213 11:31:12.735292 22509476222784 run_lib.py:133] step: 824100, training_loss: 3.90386e-02
I0213 11:31:12.903503 22509476222784 run_lib.py:146] step: 824100, eval_loss: 4.42871e-02
I0213 11:31:31.425058 22509476222784 run_lib.py:133] step: 824150, training_loss: 3.22290e-02
I0213 11:31:50.020220 22509476222784 run_lib.py:133] step: 824200, training_loss: 4.11372e-02
I0213 11:31:50.193594 22509476222784 run_lib.py:146] step: 824200, eval_loss: 4.30656e-02
I0213 11:32:08.944613 22509476222784 run_lib.py:133] step: 824250, training_loss: 4.91764e-02
I0213 11:32:27.527436 22509476222784 run_lib.py:133] step: 824300, training_loss: 5.16222e-02
I0213 11:32:27.695687 22509476222784 run_lib.py:146] step: 824300, eval_loss: 4.14016e-02
I0213 11:32:46.394622 22509476222784 run_lib.py:133] step: 824350, training_loss: 4.35068e-02
I0213 11:33:04.920045 22509476222784 run_lib.py:133] step: 824400, training_loss: 3.03243e-02
I0213 11:33:05.085563 22509476222784 run_lib.py:146] step: 824400, eval_loss: 4.17945e-02
I0213 11:33:23.620442 22509476222784 run_lib.py:133] step: 824450, training_loss: 5.22597e-02
I0213 11:33:42.288432 22509476222784 run_lib.py:133] step: 824500, training_loss: 5.01568e-02
I0213 11:33:42.459770 22509476222784 run_lib.py:146] step: 824500, eval_loss: 3.49888e-02
I0213 11:34:01.066561 22509476222784 run_lib.py:133] step: 824550, training_loss: 4.47017e-02
I0213 11:34:19.591207 22509476222784 run_lib.py:133] step: 824600, training_loss: 4.57753e-02
I0213 11:34:19.778902 22509476222784 run_lib.py:146] step: 824600, eval_loss: 4.64818e-02
I0213 11:34:38.330853 22509476222784 run_lib.py:133] step: 824650, training_loss: 4.32490e-02
I0213 11:34:57.008347 22509476222784 run_lib.py:133] step: 824700, training_loss: 2.99063e-02
I0213 11:34:57.189479 22509476222784 run_lib.py:146] step: 824700, eval_loss: 4.42367e-02
I0213 11:35:15.699459 22509476222784 run_lib.py:133] step: 824750, training_loss: 5.05136e-02
I0213 11:35:34.364621 22509476222784 run_lib.py:133] step: 824800, training_loss: 4.84766e-02
I0213 11:35:34.553094 22509476222784 run_lib.py:146] step: 824800, eval_loss: 4.42562e-02
I0213 11:35:53.027048 22509476222784 run_lib.py:133] step: 824850, training_loss: 4.10648e-02
I0213 11:36:11.523473 22509476222784 run_lib.py:133] step: 824900, training_loss: 4.83611e-02
I0213 11:36:11.688794 22509476222784 run_lib.py:146] step: 824900, eval_loss: 3.68233e-02
I0213 11:36:30.374950 22509476222784 run_lib.py:133] step: 824950, training_loss: 3.16358e-02
I0213 11:36:48.937332 22509476222784 run_lib.py:133] step: 825000, training_loss: 3.76290e-02
I0213 11:36:49.100928 22509476222784 run_lib.py:146] step: 825000, eval_loss: 4.33586e-02
I0213 11:37:07.706138 22509476222784 run_lib.py:133] step: 825050, training_loss: 3.13718e-02
I0213 11:37:26.235507 22509476222784 run_lib.py:133] step: 825100, training_loss: 3.40897e-02
I0213 11:37:26.441716 22509476222784 run_lib.py:146] step: 825100, eval_loss: 4.13428e-02
I0213 11:37:45.161428 22509476222784 run_lib.py:133] step: 825150, training_loss: 4.19636e-02
I0213 11:38:03.701948 22509476222784 run_lib.py:133] step: 825200, training_loss: 4.17136e-02
I0213 11:38:03.918972 22509476222784 run_lib.py:146] step: 825200, eval_loss: 4.87847e-02
I0213 11:38:22.597584 22509476222784 run_lib.py:133] step: 825250, training_loss: 3.94855e-02
I0213 11:38:41.146016 22509476222784 run_lib.py:133] step: 825300, training_loss: 3.06787e-02
I0213 11:38:41.322608 22509476222784 run_lib.py:146] step: 825300, eval_loss: 5.16338e-02
I0213 11:39:00.110487 22509476222784 run_lib.py:133] step: 825350, training_loss: 3.78169e-02
I0213 11:39:18.760464 22509476222784 run_lib.py:133] step: 825400, training_loss: 4.28136e-02
I0213 11:39:18.926047 22509476222784 run_lib.py:146] step: 825400, eval_loss: 3.99153e-02
I0213 11:39:37.478711 22509476222784 run_lib.py:133] step: 825450, training_loss: 3.08362e-02
I0213 11:39:56.140660 22509476222784 run_lib.py:133] step: 825500, training_loss: 2.13390e-02
I0213 11:39:56.303596 22509476222784 run_lib.py:146] step: 825500, eval_loss: 4.01317e-02
I0213 11:40:14.879587 22509476222784 run_lib.py:133] step: 825550, training_loss: 4.52387e-02
I0213 11:40:33.647774 22509476222784 run_lib.py:133] step: 825600, training_loss: 4.12050e-02
I0213 11:40:33.845979 22509476222784 run_lib.py:146] step: 825600, eval_loss: 4.25593e-02
I0213 11:40:52.422759 22509476222784 run_lib.py:133] step: 825650, training_loss: 4.03814e-02
I0213 11:41:10.980368 22509476222784 run_lib.py:133] step: 825700, training_loss: 3.65017e-02
I0213 11:41:11.146924 22509476222784 run_lib.py:146] step: 825700, eval_loss: 4.10120e-02
I0213 11:41:29.902084 22509476222784 run_lib.py:133] step: 825750, training_loss: 4.55212e-02
I0213 11:41:48.471898 22509476222784 run_lib.py:133] step: 825800, training_loss: 3.57686e-02
I0213 11:41:48.666735 22509476222784 run_lib.py:146] step: 825800, eval_loss: 5.21736e-02
I0213 11:42:07.257852 22509476222784 run_lib.py:133] step: 825850, training_loss: 5.01291e-02
I0213 11:42:26.039175 22509476222784 run_lib.py:133] step: 825900, training_loss: 3.80470e-02
I0213 11:42:26.235852 22509476222784 run_lib.py:146] step: 825900, eval_loss: 3.94840e-02
I0213 11:42:44.840872 22509476222784 run_lib.py:133] step: 825950, training_loss: 3.56700e-02
I0213 11:43:03.349478 22509476222784 run_lib.py:133] step: 826000, training_loss: 5.12173e-02
I0213 11:43:03.655603 22509476222784 run_lib.py:146] step: 826000, eval_loss: 4.18684e-02
I0213 11:43:22.152420 22509476222784 run_lib.py:133] step: 826050, training_loss: 4.55673e-02
I0213 11:43:40.638002 22509476222784 run_lib.py:133] step: 826100, training_loss: 5.34882e-02
I0213 11:43:40.841068 22509476222784 run_lib.py:146] step: 826100, eval_loss: 4.25053e-02
I0213 11:43:59.472512 22509476222784 run_lib.py:133] step: 826150, training_loss: 4.46348e-02
I0213 11:44:18.005609 22509476222784 run_lib.py:133] step: 826200, training_loss: 3.98617e-02
I0213 11:44:18.194693 22509476222784 run_lib.py:146] step: 826200, eval_loss: 3.91873e-02
I0213 11:44:36.913056 22509476222784 run_lib.py:133] step: 826250, training_loss: 3.48081e-02
I0213 11:44:55.504663 22509476222784 run_lib.py:133] step: 826300, training_loss: 5.62530e-02
I0213 11:44:55.669760 22509476222784 run_lib.py:146] step: 826300, eval_loss: 4.58273e-02
I0213 11:45:14.213651 22509476222784 run_lib.py:133] step: 826350, training_loss: 5.93689e-02
I0213 11:45:32.795730 22509476222784 run_lib.py:133] step: 826400, training_loss: 3.32376e-02
I0213 11:45:32.996810 22509476222784 run_lib.py:146] step: 826400, eval_loss: 4.29829e-02
I0213 11:45:51.685804 22509476222784 run_lib.py:133] step: 826450, training_loss: 4.03825e-02
I0213 11:46:10.343682 22509476222784 run_lib.py:133] step: 826500, training_loss: 3.88360e-02
I0213 11:46:10.505613 22509476222784 run_lib.py:146] step: 826500, eval_loss: 4.30049e-02
I0213 11:46:29.071421 22509476222784 run_lib.py:133] step: 826550, training_loss: 5.21181e-02
I0213 11:46:47.698780 22509476222784 run_lib.py:133] step: 826600, training_loss: 3.45603e-02
I0213 11:46:47.877818 22509476222784 run_lib.py:146] step: 826600, eval_loss: 4.49440e-02
I0213 11:47:06.557946 22509476222784 run_lib.py:133] step: 826650, training_loss: 3.69386e-02
I0213 11:47:25.147160 22509476222784 run_lib.py:133] step: 826700, training_loss: 4.46552e-02
I0213 11:47:25.336803 22509476222784 run_lib.py:146] step: 826700, eval_loss: 3.76346e-02
I0213 11:47:44.100695 22509476222784 run_lib.py:133] step: 826750, training_loss: 3.24928e-02
I0213 11:48:02.685126 22509476222784 run_lib.py:133] step: 826800, training_loss: 3.81929e-02
I0213 11:48:02.849833 22509476222784 run_lib.py:146] step: 826800, eval_loss: 5.18261e-02
I0213 11:48:21.477279 22509476222784 run_lib.py:133] step: 826850, training_loss: 5.59184e-02
I0213 11:48:40.024005 22509476222784 run_lib.py:133] step: 826900, training_loss: 2.98501e-02
I0213 11:48:40.186619 22509476222784 run_lib.py:146] step: 826900, eval_loss: 3.59087e-02
I0213 11:48:58.737983 22509476222784 run_lib.py:133] step: 826950, training_loss: 3.56659e-02
I0213 11:49:17.472293 22509476222784 run_lib.py:133] step: 827000, training_loss: 4.43715e-02
I0213 11:49:17.638602 22509476222784 run_lib.py:146] step: 827000, eval_loss: 5.37879e-02
I0213 11:49:36.162081 22509476222784 run_lib.py:133] step: 827050, training_loss: 5.25322e-02
I0213 11:49:54.827151 22509476222784 run_lib.py:133] step: 827100, training_loss: 4.17452e-02
I0213 11:49:54.999894 22509476222784 run_lib.py:146] step: 827100, eval_loss: 4.37454e-02
I0213 11:50:13.505707 22509476222784 run_lib.py:133] step: 827150, training_loss: 4.31702e-02
I0213 11:50:32.050567 22509476222784 run_lib.py:133] step: 827200, training_loss: 4.37011e-02
I0213 11:50:32.222690 22509476222784 run_lib.py:146] step: 827200, eval_loss: 4.15515e-02
I0213 11:50:50.793900 22509476222784 run_lib.py:133] step: 827250, training_loss: 3.05735e-02
I0213 11:51:09.530840 22509476222784 run_lib.py:133] step: 827300, training_loss: 4.12874e-02
I0213 11:51:09.735568 22509476222784 run_lib.py:146] step: 827300, eval_loss: 3.98702e-02
I0213 11:51:28.305808 22509476222784 run_lib.py:133] step: 827350, training_loss: 3.37718e-02
I0213 11:51:46.801679 22509476222784 run_lib.py:133] step: 827400, training_loss: 4.68901e-02
I0213 11:51:46.969467 22509476222784 run_lib.py:146] step: 827400, eval_loss: 3.67997e-02
I0213 11:52:05.610847 22509476222784 run_lib.py:133] step: 827450, training_loss: 4.95963e-02
I0213 11:52:24.186828 22509476222784 run_lib.py:133] step: 827500, training_loss: 3.84762e-02
I0213 11:52:24.357852 22509476222784 run_lib.py:146] step: 827500, eval_loss: 4.30998e-02
I0213 11:52:43.011291 22509476222784 run_lib.py:133] step: 827550, training_loss: 3.77582e-02
I0213 11:53:01.536679 22509476222784 run_lib.py:133] step: 827600, training_loss: 4.68698e-02
I0213 11:53:01.700695 22509476222784 run_lib.py:146] step: 827600, eval_loss: 3.83428e-02
I0213 11:53:20.166150 22509476222784 run_lib.py:133] step: 827650, training_loss: 3.84293e-02
I0213 11:53:38.681765 22509476222784 run_lib.py:133] step: 827700, training_loss: 4.55783e-02
I0213 11:53:38.853690 22509476222784 run_lib.py:146] step: 827700, eval_loss: 5.41491e-02
I0213 11:53:57.583042 22509476222784 run_lib.py:133] step: 827750, training_loss: 4.04001e-02
I0213 11:54:16.271524 22509476222784 run_lib.py:133] step: 827800, training_loss: 4.78582e-02
I0213 11:54:16.439825 22509476222784 run_lib.py:146] step: 827800, eval_loss: 4.47423e-02
I0213 11:54:35.001159 22509476222784 run_lib.py:133] step: 827850, training_loss: 4.74508e-02
I0213 11:54:53.517994 22509476222784 run_lib.py:133] step: 827900, training_loss: 3.72887e-02
I0213 11:54:53.679739 22509476222784 run_lib.py:146] step: 827900, eval_loss: 4.26988e-02
I0213 11:55:12.414677 22509476222784 run_lib.py:133] step: 827950, training_loss: 4.97118e-02
I0213 11:55:30.936387 22509476222784 run_lib.py:133] step: 828000, training_loss: 3.70420e-02
I0213 11:55:31.099728 22509476222784 run_lib.py:146] step: 828000, eval_loss: 4.17362e-02
I0213 11:55:49.734245 22509476222784 run_lib.py:133] step: 828050, training_loss: 3.55648e-02
I0213 11:56:08.396593 22509476222784 run_lib.py:133] step: 828100, training_loss: 5.09092e-02
I0213 11:56:08.576596 22509476222784 run_lib.py:146] step: 828100, eval_loss: 5.09891e-02
I0213 11:56:27.293432 22509476222784 run_lib.py:133] step: 828150, training_loss: 3.78590e-02
I0213 11:56:45.789919 22509476222784 run_lib.py:133] step: 828200, training_loss: 4.51185e-02
I0213 11:56:45.955023 22509476222784 run_lib.py:146] step: 828200, eval_loss: 2.84975e-02
I0213 11:57:04.676632 22509476222784 run_lib.py:133] step: 828250, training_loss: 3.19271e-02
I0213 11:57:23.265993 22509476222784 run_lib.py:133] step: 828300, training_loss: 4.73009e-02
I0213 11:57:23.433907 22509476222784 run_lib.py:146] step: 828300, eval_loss: 3.94993e-02
I0213 11:57:42.048117 22509476222784 run_lib.py:133] step: 828350, training_loss: 3.92453e-02
I0213 11:58:00.745654 22509476222784 run_lib.py:133] step: 828400, training_loss: 4.81170e-02
I0213 11:58:00.908962 22509476222784 run_lib.py:146] step: 828400, eval_loss: 4.63818e-02
I0213 11:58:19.445873 22509476222784 run_lib.py:133] step: 828450, training_loss: 4.81503e-02
I0213 11:58:38.033802 22509476222784 run_lib.py:133] step: 828500, training_loss: 4.82659e-02
I0213 11:58:38.200953 22509476222784 run_lib.py:146] step: 828500, eval_loss: 4.91077e-02
I0213 11:58:56.829154 22509476222784 run_lib.py:133] step: 828550, training_loss: 3.72340e-02
I0213 11:59:15.484179 22509476222784 run_lib.py:133] step: 828600, training_loss: 4.60854e-02
I0213 11:59:15.658573 22509476222784 run_lib.py:146] step: 828600, eval_loss: 3.03406e-02
I0213 11:59:34.214810 22509476222784 run_lib.py:133] step: 828650, training_loss: 4.46690e-02
I0213 11:59:52.829152 22509476222784 run_lib.py:133] step: 828700, training_loss: 4.70452e-02
I0213 11:59:52.996037 22509476222784 run_lib.py:146] step: 828700, eval_loss: 4.54327e-02
I0213 12:00:11.558618 22509476222784 run_lib.py:133] step: 828750, training_loss: 4.44315e-02
I0213 12:00:30.290944 22509476222784 run_lib.py:133] step: 828800, training_loss: 4.07093e-02
I0213 12:00:30.454335 22509476222784 run_lib.py:146] step: 828800, eval_loss: 4.71027e-02
I0213 12:00:48.995548 22509476222784 run_lib.py:133] step: 828850, training_loss: 3.94655e-02
I0213 12:01:07.601670 22509476222784 run_lib.py:133] step: 828900, training_loss: 3.39194e-02
I0213 12:01:07.771908 22509476222784 run_lib.py:146] step: 828900, eval_loss: 3.87978e-02
I0213 12:01:26.307937 22509476222784 run_lib.py:133] step: 828950, training_loss: 3.36382e-02
I0213 12:01:45.042477 22509476222784 run_lib.py:133] step: 829000, training_loss: 4.11158e-02
I0213 12:01:45.210912 22509476222784 run_lib.py:146] step: 829000, eval_loss: 5.07899e-02
I0213 12:02:03.706623 22509476222784 run_lib.py:133] step: 829050, training_loss: 3.77947e-02
I0213 12:02:22.273877 22509476222784 run_lib.py:133] step: 829100, training_loss: 4.15259e-02
I0213 12:02:22.434156 22509476222784 run_lib.py:146] step: 829100, eval_loss: 3.28723e-02
I0213 12:02:40.995063 22509476222784 run_lib.py:133] step: 829150, training_loss: 4.96873e-02
I0213 12:02:59.616048 22509476222784 run_lib.py:133] step: 829200, training_loss: 3.79369e-02
I0213 12:02:59.781380 22509476222784 run_lib.py:146] step: 829200, eval_loss: 4.36067e-02
I0213 12:03:18.558532 22509476222784 run_lib.py:133] step: 829250, training_loss: 5.42514e-02
I0213 12:03:37.171349 22509476222784 run_lib.py:133] step: 829300, training_loss: 3.61293e-02
I0213 12:03:37.332595 22509476222784 run_lib.py:146] step: 829300, eval_loss: 4.41994e-02
I0213 12:03:55.828308 22509476222784 run_lib.py:133] step: 829350, training_loss: 4.08765e-02
I0213 12:04:14.327553 22509476222784 run_lib.py:133] step: 829400, training_loss: 3.74129e-02
I0213 12:04:14.498781 22509476222784 run_lib.py:146] step: 829400, eval_loss: 4.04747e-02
I0213 12:04:33.225862 22509476222784 run_lib.py:133] step: 829450, training_loss: 3.73493e-02
I0213 12:04:51.748082 22509476222784 run_lib.py:133] step: 829500, training_loss: 5.00617e-02
I0213 12:04:51.915761 22509476222784 run_lib.py:146] step: 829500, eval_loss: 2.87841e-02
I0213 12:05:10.622858 22509476222784 run_lib.py:133] step: 829550, training_loss: 3.74149e-02
I0213 12:05:29.150170 22509476222784 run_lib.py:133] step: 829600, training_loss: 3.59855e-02
I0213 12:05:29.394674 22509476222784 run_lib.py:146] step: 829600, eval_loss: 4.23962e-02
I0213 12:05:48.069556 22509476222784 run_lib.py:133] step: 829650, training_loss: 3.54618e-02
I0213 12:06:06.641382 22509476222784 run_lib.py:133] step: 829700, training_loss: 4.31637e-02
I0213 12:06:06.801914 22509476222784 run_lib.py:146] step: 829700, eval_loss: 3.26916e-02
I0213 12:06:25.389979 22509476222784 run_lib.py:133] step: 829750, training_loss: 4.28330e-02
I0213 12:06:44.074638 22509476222784 run_lib.py:133] step: 829800, training_loss: 4.01140e-02
I0213 12:06:44.237903 22509476222784 run_lib.py:146] step: 829800, eval_loss: 4.26130e-02
I0213 12:07:02.783474 22509476222784 run_lib.py:133] step: 829850, training_loss: 4.10261e-02
I0213 12:07:21.444277 22509476222784 run_lib.py:133] step: 829900, training_loss: 4.28748e-02
I0213 12:07:21.611164 22509476222784 run_lib.py:146] step: 829900, eval_loss: 3.59841e-02
I0213 12:07:40.186934 22509476222784 run_lib.py:133] step: 829950, training_loss: 3.28699e-02
I0213 12:07:58.823606 22509476222784 run_lib.py:133] step: 830000, training_loss: 4.41336e-02
I0213 12:07:59.642715 22509476222784 run_lib.py:146] step: 830000, eval_loss: 3.79906e-02
I0213 12:08:21.392052 22509476222784 run_lib.py:133] step: 830050, training_loss: 4.57834e-02
I0213 12:08:40.316244 22509476222784 run_lib.py:133] step: 830100, training_loss: 4.71707e-02
I0213 12:08:40.482893 22509476222784 run_lib.py:146] step: 830100, eval_loss: 3.26129e-02
I0213 12:08:59.023087 22509476222784 run_lib.py:133] step: 830150, training_loss: 3.29316e-02
I0213 12:09:17.805115 22509476222784 run_lib.py:133] step: 830200, training_loss: 4.26241e-02
I0213 12:09:17.970362 22509476222784 run_lib.py:146] step: 830200, eval_loss: 4.56233e-02
I0213 12:09:36.542231 22509476222784 run_lib.py:133] step: 830250, training_loss: 3.31916e-02
I0213 12:09:55.041259 22509476222784 run_lib.py:133] step: 830300, training_loss: 3.24746e-02
I0213 12:09:55.204835 22509476222784 run_lib.py:146] step: 830300, eval_loss: 3.57313e-02
I0213 12:10:13.878754 22509476222784 run_lib.py:133] step: 830350, training_loss: 5.39509e-02
I0213 12:10:32.407257 22509476222784 run_lib.py:133] step: 830400, training_loss: 3.76285e-02
I0213 12:10:32.600514 22509476222784 run_lib.py:146] step: 830400, eval_loss: 3.94633e-02
I0213 12:10:51.314544 22509476222784 run_lib.py:133] step: 830450, training_loss: 3.70986e-02
I0213 12:11:09.870817 22509476222784 run_lib.py:133] step: 830500, training_loss: 4.49579e-02
I0213 12:11:10.037686 22509476222784 run_lib.py:146] step: 830500, eval_loss: 5.16897e-02
I0213 12:11:28.547748 22509476222784 run_lib.py:133] step: 830550, training_loss: 4.27591e-02
I0213 12:11:47.254621 22509476222784 run_lib.py:133] step: 830600, training_loss: 5.36625e-02
I0213 12:11:47.437722 22509476222784 run_lib.py:146] step: 830600, eval_loss: 3.65687e-02
I0213 12:12:05.964237 22509476222784 run_lib.py:133] step: 830650, training_loss: 4.79007e-02
I0213 12:12:24.456924 22509476222784 run_lib.py:133] step: 830700, training_loss: 4.41279e-02
I0213 12:12:24.631537 22509476222784 run_lib.py:146] step: 830700, eval_loss: 4.43590e-02
I0213 12:12:43.238633 22509476222784 run_lib.py:133] step: 830750, training_loss: 4.66840e-02
I0213 12:13:02.009740 22509476222784 run_lib.py:133] step: 830800, training_loss: 3.74016e-02
I0213 12:13:02.172502 22509476222784 run_lib.py:146] step: 830800, eval_loss: 2.94089e-02
I0213 12:13:20.726822 22509476222784 run_lib.py:133] step: 830850, training_loss: 5.29899e-02
I0213 12:13:39.352011 22509476222784 run_lib.py:133] step: 830900, training_loss: 3.28568e-02
I0213 12:13:39.515662 22509476222784 run_lib.py:146] step: 830900, eval_loss: 3.36249e-02
I0213 12:13:58.013952 22509476222784 run_lib.py:133] step: 830950, training_loss: 4.21985e-02
I0213 12:14:16.561555 22509476222784 run_lib.py:133] step: 831000, training_loss: 4.18665e-02
I0213 12:14:16.732627 22509476222784 run_lib.py:146] step: 831000, eval_loss: 4.69058e-02
I0213 12:14:35.527404 22509476222784 run_lib.py:133] step: 831050, training_loss: 3.72149e-02
I0213 12:14:54.122262 22509476222784 run_lib.py:133] step: 831100, training_loss: 5.36138e-02
I0213 12:14:54.288928 22509476222784 run_lib.py:146] step: 831100, eval_loss: 3.84135e-02
I0213 12:15:12.822026 22509476222784 run_lib.py:133] step: 831150, training_loss: 4.52839e-02
I0213 12:15:31.343791 22509476222784 run_lib.py:133] step: 831200, training_loss: 4.03197e-02
I0213 12:15:31.561671 22509476222784 run_lib.py:146] step: 831200, eval_loss: 3.62836e-02
I0213 12:15:50.217660 22509476222784 run_lib.py:133] step: 831250, training_loss: 3.36517e-02
I0213 12:16:08.745559 22509476222784 run_lib.py:133] step: 831300, training_loss: 4.42419e-02
I0213 12:16:08.912859 22509476222784 run_lib.py:146] step: 831300, eval_loss: 3.75653e-02
I0213 12:16:27.668984 22509476222784 run_lib.py:133] step: 831350, training_loss: 4.71322e-02
I0213 12:16:46.214474 22509476222784 run_lib.py:133] step: 831400, training_loss: 4.56582e-02
I0213 12:16:46.379671 22509476222784 run_lib.py:146] step: 831400, eval_loss: 3.96216e-02
I0213 12:17:05.108691 22509476222784 run_lib.py:133] step: 831450, training_loss: 3.79797e-02
I0213 12:17:23.640755 22509476222784 run_lib.py:133] step: 831500, training_loss: 5.21200e-02
I0213 12:17:23.822748 22509476222784 run_lib.py:146] step: 831500, eval_loss: 4.21527e-02
I0213 12:17:42.401911 22509476222784 run_lib.py:133] step: 831550, training_loss: 3.71493e-02
I0213 12:18:01.157613 22509476222784 run_lib.py:133] step: 831600, training_loss: 3.77083e-02
I0213 12:18:01.322805 22509476222784 run_lib.py:146] step: 831600, eval_loss: 3.77319e-02
I0213 12:18:19.849620 22509476222784 run_lib.py:133] step: 831650, training_loss: 3.81001e-02
I0213 12:18:38.459566 22509476222784 run_lib.py:133] step: 831700, training_loss: 3.61982e-02
I0213 12:18:38.625793 22509476222784 run_lib.py:146] step: 831700, eval_loss: 5.70786e-02
I0213 12:18:57.219108 22509476222784 run_lib.py:133] step: 831750, training_loss: 3.58740e-02
I0213 12:19:15.844449 22509476222784 run_lib.py:133] step: 831800, training_loss: 3.54394e-02
I0213 12:19:16.010845 22509476222784 run_lib.py:146] step: 831800, eval_loss: 4.16671e-02
I0213 12:19:34.758895 22509476222784 run_lib.py:133] step: 831850, training_loss: 3.98638e-02
I0213 12:19:53.276260 22509476222784 run_lib.py:133] step: 831900, training_loss: 3.95096e-02
I0213 12:19:53.443052 22509476222784 run_lib.py:146] step: 831900, eval_loss: 3.95517e-02
I0213 12:20:11.954768 22509476222784 run_lib.py:133] step: 831950, training_loss: 4.03899e-02
I0213 12:20:30.624063 22509476222784 run_lib.py:133] step: 832000, training_loss: 4.07697e-02
I0213 12:20:30.789685 22509476222784 run_lib.py:146] step: 832000, eval_loss: 4.34025e-02
I0213 12:20:49.345686 22509476222784 run_lib.py:133] step: 832050, training_loss: 4.16596e-02
I0213 12:21:07.904230 22509476222784 run_lib.py:133] step: 832100, training_loss: 6.14980e-02
I0213 12:21:08.070055 22509476222784 run_lib.py:146] step: 832100, eval_loss: 3.62822e-02
I0213 12:21:26.717230 22509476222784 run_lib.py:133] step: 832150, training_loss: 4.21910e-02
I0213 12:21:45.249849 22509476222784 run_lib.py:133] step: 832200, training_loss: 4.51252e-02
I0213 12:21:45.412999 22509476222784 run_lib.py:146] step: 832200, eval_loss: 3.92341e-02
I0213 12:22:03.944512 22509476222784 run_lib.py:133] step: 832250, training_loss: 5.10410e-02
I0213 12:22:22.480954 22509476222784 run_lib.py:133] step: 832300, training_loss: 3.03503e-02
I0213 12:22:22.646824 22509476222784 run_lib.py:146] step: 832300, eval_loss: 4.77334e-02
I0213 12:22:41.366789 22509476222784 run_lib.py:133] step: 832350, training_loss: 3.07438e-02
I0213 12:23:00.081582 22509476222784 run_lib.py:133] step: 832400, training_loss: 4.58538e-02
I0213 12:23:00.255828 22509476222784 run_lib.py:146] step: 832400, eval_loss: 4.77958e-02
I0213 12:23:18.776839 22509476222784 run_lib.py:133] step: 832450, training_loss: 3.63251e-02
I0213 12:23:37.316671 22509476222784 run_lib.py:133] step: 832500, training_loss: 4.36219e-02
I0213 12:23:37.503622 22509476222784 run_lib.py:146] step: 832500, eval_loss: 3.29029e-02
I0213 12:23:56.160514 22509476222784 run_lib.py:133] step: 832550, training_loss: 4.45341e-02
I0213 12:24:14.813034 22509476222784 run_lib.py:133] step: 832600, training_loss: 4.78154e-02
I0213 12:24:15.007026 22509476222784 run_lib.py:146] step: 832600, eval_loss: 4.48594e-02
I0213 12:24:33.740827 22509476222784 run_lib.py:133] step: 832650, training_loss: 4.04177e-02
I0213 12:24:52.229963 22509476222784 run_lib.py:133] step: 832700, training_loss: 5.16161e-02
I0213 12:24:52.429656 22509476222784 run_lib.py:146] step: 832700, eval_loss: 4.92953e-02
I0213 12:25:11.157644 22509476222784 run_lib.py:133] step: 832750, training_loss: 3.15510e-02
I0213 12:25:29.725637 22509476222784 run_lib.py:133] step: 832800, training_loss: 5.14227e-02
I0213 12:25:29.889824 22509476222784 run_lib.py:146] step: 832800, eval_loss: 3.83150e-02
I0213 12:25:48.585444 22509476222784 run_lib.py:133] step: 832850, training_loss: 4.73363e-02
I0213 12:26:07.173976 22509476222784 run_lib.py:133] step: 832900, training_loss: 4.43210e-02
I0213 12:26:07.340882 22509476222784 run_lib.py:146] step: 832900, eval_loss: 3.32122e-02
I0213 12:26:25.888851 22509476222784 run_lib.py:133] step: 832950, training_loss: 4.37695e-02
I0213 12:26:44.602416 22509476222784 run_lib.py:133] step: 833000, training_loss: 4.29191e-02
I0213 12:26:44.767624 22509476222784 run_lib.py:146] step: 833000, eval_loss: 4.00646e-02
I0213 12:27:03.285921 22509476222784 run_lib.py:133] step: 833050, training_loss: 3.87986e-02
I0213 12:27:21.790732 22509476222784 run_lib.py:133] step: 833100, training_loss: 6.10126e-02
I0213 12:27:21.970827 22509476222784 run_lib.py:146] step: 833100, eval_loss: 4.31273e-02
I0213 12:27:40.739083 22509476222784 run_lib.py:133] step: 833150, training_loss: 3.44739e-02
I0213 12:27:59.268406 22509476222784 run_lib.py:133] step: 833200, training_loss: 4.96399e-02
I0213 12:27:59.431853 22509476222784 run_lib.py:146] step: 833200, eval_loss: 3.67865e-02
I0213 12:28:18.109570 22509476222784 run_lib.py:133] step: 833250, training_loss: 4.56204e-02
I0213 12:28:36.591626 22509476222784 run_lib.py:133] step: 833300, training_loss: 5.40315e-02
I0213 12:28:36.753593 22509476222784 run_lib.py:146] step: 833300, eval_loss: 3.67585e-02
I0213 12:28:55.194578 22509476222784 run_lib.py:133] step: 833350, training_loss: 4.48045e-02
I0213 12:29:13.834152 22509476222784 run_lib.py:133] step: 833400, training_loss: 4.43989e-02
I0213 12:29:14.014668 22509476222784 run_lib.py:146] step: 833400, eval_loss: 3.41771e-02
I0213 12:29:32.509117 22509476222784 run_lib.py:133] step: 833450, training_loss: 4.22723e-02
I0213 12:29:51.033345 22509476222784 run_lib.py:133] step: 833500, training_loss: 4.04161e-02
I0213 12:29:51.198199 22509476222784 run_lib.py:146] step: 833500, eval_loss: 4.60212e-02
I0213 12:30:09.703364 22509476222784 run_lib.py:133] step: 833550, training_loss: 3.19282e-02
I0213 12:30:28.362404 22509476222784 run_lib.py:133] step: 833600, training_loss: 3.41830e-02
I0213 12:30:28.525657 22509476222784 run_lib.py:146] step: 833600, eval_loss: 3.09318e-02
I0213 12:30:47.020026 22509476222784 run_lib.py:133] step: 833650, training_loss: 3.68321e-02
I0213 12:31:05.606204 22509476222784 run_lib.py:133] step: 833700, training_loss: 3.21140e-02
I0213 12:31:05.768887 22509476222784 run_lib.py:146] step: 833700, eval_loss: 4.16809e-02
I0213 12:31:24.331905 22509476222784 run_lib.py:133] step: 833750, training_loss: 4.09663e-02
I0213 12:31:42.817049 22509476222784 run_lib.py:133] step: 833800, training_loss: 4.39020e-02
I0213 12:31:42.983430 22509476222784 run_lib.py:146] step: 833800, eval_loss: 4.01029e-02
I0213 12:32:01.622422 22509476222784 run_lib.py:133] step: 833850, training_loss: 3.98015e-02
I0213 12:32:20.174273 22509476222784 run_lib.py:133] step: 833900, training_loss: 3.12269e-02
I0213 12:32:20.349608 22509476222784 run_lib.py:146] step: 833900, eval_loss: 3.81601e-02
I0213 12:32:38.925042 22509476222784 run_lib.py:133] step: 833950, training_loss: 3.51644e-02
I0213 12:32:57.447650 22509476222784 run_lib.py:133] step: 834000, training_loss: 2.94792e-02
I0213 12:32:57.617456 22509476222784 run_lib.py:146] step: 834000, eval_loss: 3.54668e-02
I0213 12:33:16.307975 22509476222784 run_lib.py:133] step: 834050, training_loss: 3.87456e-02
I0213 12:33:34.756773 22509476222784 run_lib.py:133] step: 834100, training_loss: 3.82007e-02
I0213 12:33:34.918536 22509476222784 run_lib.py:146] step: 834100, eval_loss: 4.68014e-02
I0213 12:33:53.533940 22509476222784 run_lib.py:133] step: 834150, training_loss: 3.48727e-02
I0213 12:34:12.051745 22509476222784 run_lib.py:133] step: 834200, training_loss: 4.27106e-02
I0213 12:34:12.220823 22509476222784 run_lib.py:146] step: 834200, eval_loss: 3.03363e-02
I0213 12:34:30.920511 22509476222784 run_lib.py:133] step: 834250, training_loss: 2.92794e-02
I0213 12:34:49.440533 22509476222784 run_lib.py:133] step: 834300, training_loss: 3.62376e-02
I0213 12:34:49.606032 22509476222784 run_lib.py:146] step: 834300, eval_loss: 3.25182e-02
I0213 12:35:08.082906 22509476222784 run_lib.py:133] step: 834350, training_loss: 3.87909e-02
I0213 12:35:26.664577 22509476222784 run_lib.py:133] step: 834400, training_loss: 4.28357e-02
I0213 12:35:26.834574 22509476222784 run_lib.py:146] step: 834400, eval_loss: 5.12061e-02
I0213 12:35:45.353638 22509476222784 run_lib.py:133] step: 834450, training_loss: 3.47015e-02
I0213 12:36:04.037321 22509476222784 run_lib.py:133] step: 834500, training_loss: 3.34336e-02
I0213 12:36:04.201376 22509476222784 run_lib.py:146] step: 834500, eval_loss: 5.50947e-02
I0213 12:36:22.698601 22509476222784 run_lib.py:133] step: 834550, training_loss: 3.55238e-02
I0213 12:36:41.167488 22509476222784 run_lib.py:133] step: 834600, training_loss: 4.74643e-02
I0213 12:36:41.327433 22509476222784 run_lib.py:146] step: 834600, eval_loss: 4.21389e-02
I0213 12:36:59.973997 22509476222784 run_lib.py:133] step: 834650, training_loss: 3.81570e-02
I0213 12:37:18.447113 22509476222784 run_lib.py:133] step: 834700, training_loss: 4.18993e-02
I0213 12:37:18.622828 22509476222784 run_lib.py:146] step: 834700, eval_loss: 4.68159e-02
I0213 12:37:37.173126 22509476222784 run_lib.py:133] step: 834750, training_loss: 4.12583e-02
I0213 12:37:55.895723 22509476222784 run_lib.py:133] step: 834800, training_loss: 3.68762e-02
I0213 12:37:56.065295 22509476222784 run_lib.py:146] step: 834800, eval_loss: 3.94408e-02
I0213 12:38:14.557649 22509476222784 run_lib.py:133] step: 834850, training_loss: 4.88565e-02
I0213 12:38:33.066456 22509476222784 run_lib.py:133] step: 834900, training_loss: 4.75449e-02
I0213 12:38:33.373707 22509476222784 run_lib.py:146] step: 834900, eval_loss: 4.44342e-02
I0213 12:38:51.862557 22509476222784 run_lib.py:133] step: 834950, training_loss: 3.75565e-02
I0213 12:39:10.380527 22509476222784 run_lib.py:133] step: 835000, training_loss: 3.20256e-02
I0213 12:39:10.543821 22509476222784 run_lib.py:146] step: 835000, eval_loss: 3.93861e-02
I0213 12:39:29.050199 22509476222784 run_lib.py:133] step: 835050, training_loss: 3.14112e-02
I0213 12:39:47.539178 22509476222784 run_lib.py:133] step: 835100, training_loss: 3.32120e-02
I0213 12:39:47.700680 22509476222784 run_lib.py:146] step: 835100, eval_loss: 3.71437e-02
I0213 12:40:06.360420 22509476222784 run_lib.py:133] step: 835150, training_loss: 4.58191e-02
I0213 12:40:24.963211 22509476222784 run_lib.py:133] step: 835200, training_loss: 3.62684e-02
I0213 12:40:25.137795 22509476222784 run_lib.py:146] step: 835200, eval_loss: 3.71379e-02
I0213 12:40:43.659998 22509476222784 run_lib.py:133] step: 835250, training_loss: 3.72787e-02
I0213 12:41:02.214055 22509476222784 run_lib.py:133] step: 835300, training_loss: 3.58788e-02
I0213 12:41:02.380889 22509476222784 run_lib.py:146] step: 835300, eval_loss: 3.61827e-02
I0213 12:41:21.077655 22509476222784 run_lib.py:133] step: 835350, training_loss: 3.65544e-02
I0213 12:41:39.643389 22509476222784 run_lib.py:133] step: 835400, training_loss: 3.33531e-02
I0213 12:41:39.809555 22509476222784 run_lib.py:146] step: 835400, eval_loss: 3.93599e-02
I0213 12:41:58.327299 22509476222784 run_lib.py:133] step: 835450, training_loss: 4.02806e-02
I0213 12:42:16.838491 22509476222784 run_lib.py:133] step: 835500, training_loss: 2.85679e-02
I0213 12:42:17.001796 22509476222784 run_lib.py:146] step: 835500, eval_loss: 4.76638e-02
I0213 12:42:35.697630 22509476222784 run_lib.py:133] step: 835550, training_loss: 3.72295e-02
I0213 12:42:54.181721 22509476222784 run_lib.py:133] step: 835600, training_loss: 4.17129e-02
I0213 12:42:54.345785 22509476222784 run_lib.py:146] step: 835600, eval_loss: 5.37204e-02
I0213 12:43:12.947134 22509476222784 run_lib.py:133] step: 835650, training_loss: 3.79616e-02
I0213 12:43:31.473297 22509476222784 run_lib.py:133] step: 835700, training_loss: 3.16270e-02
I0213 12:43:31.653788 22509476222784 run_lib.py:146] step: 835700, eval_loss: 4.55097e-02
I0213 12:43:50.364209 22509476222784 run_lib.py:133] step: 835750, training_loss: 3.64247e-02
I0213 12:44:08.883654 22509476222784 run_lib.py:133] step: 835800, training_loss: 4.40363e-02
I0213 12:44:09.057577 22509476222784 run_lib.py:146] step: 835800, eval_loss: 3.11791e-02
I0213 12:44:27.552995 22509476222784 run_lib.py:133] step: 835850, training_loss: 4.18551e-02
I0213 12:44:46.174912 22509476222784 run_lib.py:133] step: 835900, training_loss: 5.38542e-02
I0213 12:44:46.338760 22509476222784 run_lib.py:146] step: 835900, eval_loss: 5.29432e-02
I0213 12:45:04.806146 22509476222784 run_lib.py:133] step: 835950, training_loss: 3.54795e-02
I0213 12:45:23.544465 22509476222784 run_lib.py:133] step: 836000, training_loss: 6.40744e-02
I0213 12:45:23.706557 22509476222784 run_lib.py:146] step: 836000, eval_loss: 4.36818e-02
I0213 12:45:42.214676 22509476222784 run_lib.py:133] step: 836050, training_loss: 3.65281e-02
I0213 12:46:00.744092 22509476222784 run_lib.py:133] step: 836100, training_loss: 4.58893e-02
I0213 12:46:00.906589 22509476222784 run_lib.py:146] step: 836100, eval_loss: 4.12834e-02
I0213 12:46:19.390282 22509476222784 run_lib.py:133] step: 836150, training_loss: 5.15345e-02
I0213 12:46:38.025204 22509476222784 run_lib.py:133] step: 836200, training_loss: 3.34685e-02
I0213 12:46:38.207639 22509476222784 run_lib.py:146] step: 836200, eval_loss: 4.00022e-02
I0213 12:46:56.733953 22509476222784 run_lib.py:133] step: 836250, training_loss: 3.51005e-02
I0213 12:47:15.254443 22509476222784 run_lib.py:133] step: 836300, training_loss: 4.92318e-02
I0213 12:47:15.418844 22509476222784 run_lib.py:146] step: 836300, eval_loss: 5.58982e-02
I0213 12:47:34.063282 22509476222784 run_lib.py:133] step: 836350, training_loss: 5.18288e-02
I0213 12:47:52.546876 22509476222784 run_lib.py:133] step: 836400, training_loss: 3.75927e-02
I0213 12:47:52.709666 22509476222784 run_lib.py:146] step: 836400, eval_loss: 4.21111e-02
I0213 12:48:11.260763 22509476222784 run_lib.py:133] step: 836450, training_loss: 5.09359e-02
I0213 12:48:29.828538 22509476222784 run_lib.py:133] step: 836500, training_loss: 3.76343e-02
I0213 12:48:29.995846 22509476222784 run_lib.py:146] step: 836500, eval_loss: 4.20035e-02
I0213 12:48:48.533768 22509476222784 run_lib.py:133] step: 836550, training_loss: 3.44571e-02
I0213 12:49:06.987892 22509476222784 run_lib.py:133] step: 836600, training_loss: 3.78551e-02
I0213 12:49:07.152599 22509476222784 run_lib.py:146] step: 836600, eval_loss: 4.48898e-02
I0213 12:49:25.832357 22509476222784 run_lib.py:133] step: 836650, training_loss: 3.10469e-02
I0213 12:49:44.378127 22509476222784 run_lib.py:133] step: 836700, training_loss: 3.60192e-02
I0213 12:49:44.545564 22509476222784 run_lib.py:146] step: 836700, eval_loss: 4.22624e-02
I0213 12:50:03.056776 22509476222784 run_lib.py:133] step: 836750, training_loss: 3.04349e-02
I0213 12:50:21.622154 22509476222784 run_lib.py:133] step: 836800, training_loss: 3.63023e-02
I0213 12:50:21.790939 22509476222784 run_lib.py:146] step: 836800, eval_loss: 6.12960e-02
I0213 12:50:40.467928 22509476222784 run_lib.py:133] step: 836850, training_loss: 4.07166e-02
I0213 12:50:58.950616 22509476222784 run_lib.py:133] step: 836900, training_loss: 3.95225e-02
I0213 12:50:59.115662 22509476222784 run_lib.py:146] step: 836900, eval_loss: 3.48221e-02
I0213 12:51:17.768624 22509476222784 run_lib.py:133] step: 836950, training_loss: 4.50109e-02
I0213 12:51:36.294750 22509476222784 run_lib.py:133] step: 837000, training_loss: 3.64608e-02
I0213 12:51:36.456804 22509476222784 run_lib.py:146] step: 837000, eval_loss: 3.80874e-02
I0213 12:51:55.174231 22509476222784 run_lib.py:133] step: 837050, training_loss: 5.38364e-02
I0213 12:52:13.646287 22509476222784 run_lib.py:133] step: 837100, training_loss: 5.97342e-02
I0213 12:52:13.810350 22509476222784 run_lib.py:146] step: 837100, eval_loss: 4.26425e-02
I0213 12:52:32.456049 22509476222784 run_lib.py:133] step: 837150, training_loss: 4.69006e-02
I0213 12:52:50.968750 22509476222784 run_lib.py:133] step: 837200, training_loss: 4.41041e-02
I0213 12:52:51.131694 22509476222784 run_lib.py:146] step: 837200, eval_loss: 3.03304e-02
I0213 12:53:09.612418 22509476222784 run_lib.py:133] step: 837250, training_loss: 4.60013e-02
I0213 12:53:28.276888 22509476222784 run_lib.py:133] step: 837300, training_loss: 3.48526e-02
I0213 12:53:28.443718 22509476222784 run_lib.py:146] step: 837300, eval_loss: 4.27955e-02
I0213 12:53:46.962371 22509476222784 run_lib.py:133] step: 837350, training_loss: 4.13440e-02
I0213 12:54:05.434434 22509476222784 run_lib.py:133] step: 837400, training_loss: 3.56423e-02
I0213 12:54:05.596377 22509476222784 run_lib.py:146] step: 837400, eval_loss: 4.21610e-02
I0213 12:54:24.275770 22509476222784 run_lib.py:133] step: 837450, training_loss: 3.21454e-02
I0213 12:54:42.906004 22509476222784 run_lib.py:133] step: 837500, training_loss: 3.88555e-02
I0213 12:54:43.066592 22509476222784 run_lib.py:146] step: 837500, eval_loss: 5.30369e-02
I0213 12:55:01.557553 22509476222784 run_lib.py:133] step: 837550, training_loss: 3.56860e-02
I0213 12:55:20.092066 22509476222784 run_lib.py:133] step: 837600, training_loss: 4.85275e-02
I0213 12:55:20.272555 22509476222784 run_lib.py:146] step: 837600, eval_loss: 3.86783e-02
I0213 12:55:38.828961 22509476222784 run_lib.py:133] step: 837650, training_loss: 3.91523e-02
I0213 12:55:57.563861 22509476222784 run_lib.py:133] step: 837700, training_loss: 5.12899e-02
I0213 12:55:57.733787 22509476222784 run_lib.py:146] step: 837700, eval_loss: 5.37301e-02
I0213 12:56:16.229282 22509476222784 run_lib.py:133] step: 837750, training_loss: 5.46279e-02
I0213 12:56:34.666499 22509476222784 run_lib.py:133] step: 837800, training_loss: 3.69470e-02
I0213 12:56:34.832788 22509476222784 run_lib.py:146] step: 837800, eval_loss: 3.69379e-02
I0213 12:56:53.395475 22509476222784 run_lib.py:133] step: 837850, training_loss: 4.64610e-02
I0213 12:57:12.079299 22509476222784 run_lib.py:133] step: 837900, training_loss: 4.02990e-02
I0213 12:57:12.248959 22509476222784 run_lib.py:146] step: 837900, eval_loss: 3.63687e-02
I0213 12:57:30.808035 22509476222784 run_lib.py:133] step: 837950, training_loss: 4.52879e-02
I0213 12:57:49.363439 22509476222784 run_lib.py:133] step: 838000, training_loss: 3.60606e-02
I0213 12:57:49.525667 22509476222784 run_lib.py:146] step: 838000, eval_loss: 4.02181e-02
I0213 12:58:08.028102 22509476222784 run_lib.py:133] step: 838050, training_loss: 3.20675e-02
I0213 12:58:26.515197 22509476222784 run_lib.py:133] step: 838100, training_loss: 5.08018e-02
I0213 12:58:26.687237 22509476222784 run_lib.py:146] step: 838100, eval_loss: 4.54240e-02
I0213 12:58:45.407385 22509476222784 run_lib.py:133] step: 838150, training_loss: 4.61682e-02
I0213 12:59:04.096281 22509476222784 run_lib.py:133] step: 838200, training_loss: 4.83739e-02
I0213 12:59:04.267841 22509476222784 run_lib.py:146] step: 838200, eval_loss: 4.07786e-02
I0213 12:59:22.769036 22509476222784 run_lib.py:133] step: 838250, training_loss: 4.48876e-02
I0213 12:59:41.229520 22509476222784 run_lib.py:133] step: 838300, training_loss: 4.45381e-02
I0213 12:59:41.393567 22509476222784 run_lib.py:146] step: 838300, eval_loss: 4.30104e-02
I0213 13:00:00.009232 22509476222784 run_lib.py:133] step: 838350, training_loss: 5.02440e-02
I0213 13:00:18.534220 22509476222784 run_lib.py:133] step: 838400, training_loss: 4.75684e-02
I0213 13:00:18.712673 22509476222784 run_lib.py:146] step: 838400, eval_loss: 4.34113e-02
I0213 13:00:37.487309 22509476222784 run_lib.py:133] step: 838450, training_loss: 3.89846e-02
I0213 13:00:55.992262 22509476222784 run_lib.py:133] step: 838500, training_loss: 4.21542e-02
I0213 13:00:56.157664 22509476222784 run_lib.py:146] step: 838500, eval_loss: 4.18548e-02
I0213 13:01:14.813542 22509476222784 run_lib.py:133] step: 838550, training_loss: 4.04891e-02
I0213 13:01:33.305497 22509476222784 run_lib.py:133] step: 838600, training_loss: 3.99023e-02
I0213 13:01:33.470023 22509476222784 run_lib.py:146] step: 838600, eval_loss: 6.53955e-02
I0213 13:01:51.981789 22509476222784 run_lib.py:133] step: 838650, training_loss: 4.65030e-02
I0213 13:02:10.682037 22509476222784 run_lib.py:133] step: 838700, training_loss: 4.04920e-02
I0213 13:02:10.846892 22509476222784 run_lib.py:146] step: 838700, eval_loss: 5.86572e-02
I0213 13:02:29.333829 22509476222784 run_lib.py:133] step: 838750, training_loss: 5.40937e-02
I0213 13:02:47.964659 22509476222784 run_lib.py:133] step: 838800, training_loss: 3.93547e-02
I0213 13:02:48.128590 22509476222784 run_lib.py:146] step: 838800, eval_loss: 3.69610e-02
I0213 13:03:06.613645 22509476222784 run_lib.py:133] step: 838850, training_loss: 3.93870e-02
I0213 13:03:25.097106 22509476222784 run_lib.py:133] step: 838900, training_loss: 3.46748e-02
I0213 13:03:25.263555 22509476222784 run_lib.py:146] step: 838900, eval_loss: 3.32280e-02
I0213 13:03:43.960443 22509476222784 run_lib.py:133] step: 838950, training_loss: 2.90318e-02
I0213 13:04:02.479564 22509476222784 run_lib.py:133] step: 839000, training_loss: 5.84890e-02
I0213 13:04:02.650663 22509476222784 run_lib.py:146] step: 839000, eval_loss: 4.46355e-02
I0213 13:04:21.199705 22509476222784 run_lib.py:133] step: 839050, training_loss: 4.73053e-02
I0213 13:04:39.903851 22509476222784 run_lib.py:133] step: 839100, training_loss: 5.81857e-02
I0213 13:04:40.075747 22509476222784 run_lib.py:146] step: 839100, eval_loss: 4.25635e-02
I0213 13:04:58.612823 22509476222784 run_lib.py:133] step: 839150, training_loss: 3.86638e-02
I0213 13:05:17.179610 22509476222784 run_lib.py:133] step: 839200, training_loss: 4.50241e-02
I0213 13:05:17.344191 22509476222784 run_lib.py:146] step: 839200, eval_loss: 3.93835e-02
I0213 13:05:35.979271 22509476222784 run_lib.py:133] step: 839250, training_loss: 4.08727e-02
I0213 13:05:54.482856 22509476222784 run_lib.py:133] step: 839300, training_loss: 5.05962e-02
I0213 13:05:54.645515 22509476222784 run_lib.py:146] step: 839300, eval_loss: 3.68164e-02
I0213 13:06:13.151106 22509476222784 run_lib.py:133] step: 839350, training_loss: 3.53881e-02
I0213 13:06:31.623692 22509476222784 run_lib.py:133] step: 839400, training_loss: 4.10755e-02
I0213 13:06:31.784634 22509476222784 run_lib.py:146] step: 839400, eval_loss: 5.49419e-02
I0213 13:06:50.437639 22509476222784 run_lib.py:133] step: 839450, training_loss: 4.11073e-02
I0213 13:07:09.031366 22509476222784 run_lib.py:133] step: 839500, training_loss: 4.76931e-02
I0213 13:07:09.216500 22509476222784 run_lib.py:146] step: 839500, eval_loss: 4.06577e-02
I0213 13:07:27.747848 22509476222784 run_lib.py:133] step: 839550, training_loss: 3.60998e-02
I0213 13:07:46.268388 22509476222784 run_lib.py:133] step: 839600, training_loss: 5.40323e-02
I0213 13:07:46.432881 22509476222784 run_lib.py:146] step: 839600, eval_loss: 4.94068e-02
I0213 13:08:05.114101 22509476222784 run_lib.py:133] step: 839650, training_loss: 4.36490e-02
I0213 13:08:23.583804 22509476222784 run_lib.py:133] step: 839700, training_loss: 5.05924e-02
I0213 13:08:23.748427 22509476222784 run_lib.py:146] step: 839700, eval_loss: 3.73789e-02
I0213 13:08:42.412302 22509476222784 run_lib.py:133] step: 839750, training_loss: 4.71409e-02
I0213 13:09:00.957648 22509476222784 run_lib.py:133] step: 839800, training_loss: 3.86463e-02
I0213 13:09:01.122075 22509476222784 run_lib.py:146] step: 839800, eval_loss: 3.29276e-02
I0213 13:09:19.859160 22509476222784 run_lib.py:133] step: 839850, training_loss: 3.97811e-02
I0213 13:09:38.372134 22509476222784 run_lib.py:133] step: 839900, training_loss: 3.97479e-02
I0213 13:09:38.535701 22509476222784 run_lib.py:146] step: 839900, eval_loss: 4.85919e-02
I0213 13:09:57.187516 22509476222784 run_lib.py:133] step: 839950, training_loss: 3.21518e-02
I0213 13:10:15.688974 22509476222784 run_lib.py:133] step: 840000, training_loss: 3.20698e-02
I0213 13:10:16.466550 22509476222784 run_lib.py:146] step: 840000, eval_loss: 4.72202e-02
I0213 13:10:37.687954 22509476222784 run_lib.py:133] step: 840050, training_loss: 3.63901e-02
I0213 13:10:56.380331 22509476222784 run_lib.py:133] step: 840100, training_loss: 3.18087e-02
I0213 13:10:56.556560 22509476222784 run_lib.py:146] step: 840100, eval_loss: 5.65894e-02
I0213 13:11:15.015473 22509476222784 run_lib.py:133] step: 840150, training_loss: 4.48920e-02
I0213 13:11:33.556114 22509476222784 run_lib.py:133] step: 840200, training_loss: 3.59686e-02
I0213 13:11:33.719639 22509476222784 run_lib.py:146] step: 840200, eval_loss: 4.22818e-02
I0213 13:11:52.188809 22509476222784 run_lib.py:133] step: 840250, training_loss: 4.56516e-02
I0213 13:12:10.708819 22509476222784 run_lib.py:133] step: 840300, training_loss: 3.15175e-02
I0213 13:12:10.877804 22509476222784 run_lib.py:146] step: 840300, eval_loss: 4.83331e-02
I0213 13:12:29.598734 22509476222784 run_lib.py:133] step: 840350, training_loss: 4.31243e-02
I0213 13:12:48.160551 22509476222784 run_lib.py:133] step: 840400, training_loss: 3.72900e-02
I0213 13:12:48.322623 22509476222784 run_lib.py:146] step: 840400, eval_loss: 3.54460e-02
I0213 13:13:06.778250 22509476222784 run_lib.py:133] step: 840450, training_loss: 3.19335e-02
I0213 13:13:25.244158 22509476222784 run_lib.py:133] step: 840500, training_loss: 3.60126e-02
I0213 13:13:25.408871 22509476222784 run_lib.py:146] step: 840500, eval_loss: 3.36413e-02
I0213 13:13:44.110608 22509476222784 run_lib.py:133] step: 840550, training_loss: 3.71872e-02
I0213 13:14:02.699520 22509476222784 run_lib.py:133] step: 840600, training_loss: 3.74531e-02
I0213 13:14:02.864680 22509476222784 run_lib.py:146] step: 840600, eval_loss: 4.16890e-02
I0213 13:14:21.514237 22509476222784 run_lib.py:133] step: 840650, training_loss: 4.64020e-02
I0213 13:14:39.992780 22509476222784 run_lib.py:133] step: 840700, training_loss: 3.99331e-02
I0213 13:14:40.156446 22509476222784 run_lib.py:146] step: 840700, eval_loss: 5.40832e-02
I0213 13:14:58.777767 22509476222784 run_lib.py:133] step: 840750, training_loss: 3.58847e-02
I0213 13:15:17.317255 22509476222784 run_lib.py:133] step: 840800, training_loss: 4.19754e-02
I0213 13:15:17.482066 22509476222784 run_lib.py:146] step: 840800, eval_loss: 3.53104e-02
I0213 13:15:36.030734 22509476222784 run_lib.py:133] step: 840850, training_loss: 3.74139e-02
I0213 13:15:54.755148 22509476222784 run_lib.py:133] step: 840900, training_loss: 4.15411e-02
I0213 13:15:54.917760 22509476222784 run_lib.py:146] step: 840900, eval_loss: 4.34976e-02
I0213 13:16:13.419289 22509476222784 run_lib.py:133] step: 840950, training_loss: 3.42710e-02
I0213 13:16:32.113332 22509476222784 run_lib.py:133] step: 841000, training_loss: 3.55494e-02
I0213 13:16:32.278902 22509476222784 run_lib.py:146] step: 841000, eval_loss: 5.10563e-02
I0213 13:16:50.794984 22509476222784 run_lib.py:133] step: 841050, training_loss: 4.79065e-02
I0213 13:17:09.322151 22509476222784 run_lib.py:133] step: 841100, training_loss: 5.69686e-02
I0213 13:17:09.494553 22509476222784 run_lib.py:146] step: 841100, eval_loss: 5.41898e-02
I0213 13:17:28.213724 22509476222784 run_lib.py:133] step: 841150, training_loss: 3.77720e-02
I0213 13:17:46.779882 22509476222784 run_lib.py:133] step: 841200, training_loss: 5.23734e-02
I0213 13:17:46.944915 22509476222784 run_lib.py:146] step: 841200, eval_loss: 4.57056e-02
I0213 13:18:05.461338 22509476222784 run_lib.py:133] step: 841250, training_loss: 4.76359e-02
I0213 13:18:24.063456 22509476222784 run_lib.py:133] step: 841300, training_loss: 4.14283e-02
I0213 13:18:24.222676 22509476222784 run_lib.py:146] step: 841300, eval_loss: 6.61500e-02
I0213 13:18:42.713913 22509476222784 run_lib.py:133] step: 841350, training_loss: 4.42925e-02
I0213 13:19:01.263025 22509476222784 run_lib.py:133] step: 841400, training_loss: 3.12068e-02
I0213 13:19:01.446574 22509476222784 run_lib.py:146] step: 841400, eval_loss: 4.57468e-02
I0213 13:19:20.080320 22509476222784 run_lib.py:133] step: 841450, training_loss: 4.61963e-02
I0213 13:19:38.631793 22509476222784 run_lib.py:133] step: 841500, training_loss: 5.08780e-02
I0213 13:19:38.796941 22509476222784 run_lib.py:146] step: 841500, eval_loss: 4.64048e-02
I0213 13:19:57.278561 22509476222784 run_lib.py:133] step: 841550, training_loss: 5.47226e-02
I0213 13:20:15.773539 22509476222784 run_lib.py:133] step: 841600, training_loss: 3.32069e-02
I0213 13:20:15.943511 22509476222784 run_lib.py:146] step: 841600, eval_loss: 3.61821e-02
I0213 13:20:34.610738 22509476222784 run_lib.py:133] step: 841650, training_loss: 3.60206e-02
I0213 13:20:53.226346 22509476222784 run_lib.py:133] step: 841700, training_loss: 2.97565e-02
I0213 13:20:53.453918 22509476222784 run_lib.py:146] step: 841700, eval_loss: 3.75207e-02
I0213 13:21:11.958246 22509476222784 run_lib.py:133] step: 841750, training_loss: 3.30875e-02
I0213 13:21:30.475667 22509476222784 run_lib.py:133] step: 841800, training_loss: 4.42995e-02
I0213 13:21:30.638679 22509476222784 run_lib.py:146] step: 841800, eval_loss: 4.13319e-02
I0213 13:21:49.289871 22509476222784 run_lib.py:133] step: 841850, training_loss: 4.00838e-02
I0213 13:22:07.804844 22509476222784 run_lib.py:133] step: 841900, training_loss: 3.92615e-02
I0213 13:22:07.982233 22509476222784 run_lib.py:146] step: 841900, eval_loss: 3.77931e-02
I0213 13:22:26.770869 22509476222784 run_lib.py:133] step: 841950, training_loss: 4.83181e-02
I0213 13:22:45.260144 22509476222784 run_lib.py:133] step: 842000, training_loss: 5.26350e-02
I0213 13:22:45.424872 22509476222784 run_lib.py:146] step: 842000, eval_loss: 3.95253e-02
I0213 13:23:04.074732 22509476222784 run_lib.py:133] step: 842050, training_loss: 3.52822e-02
I0213 13:23:22.545308 22509476222784 run_lib.py:133] step: 842100, training_loss: 4.49240e-02
I0213 13:23:22.709635 22509476222784 run_lib.py:146] step: 842100, eval_loss: 3.82849e-02
I0213 13:23:41.343745 22509476222784 run_lib.py:133] step: 842150, training_loss: 4.85608e-02
I0213 13:23:59.920226 22509476222784 run_lib.py:133] step: 842200, training_loss: 4.17348e-02
I0213 13:24:00.084387 22509476222784 run_lib.py:146] step: 842200, eval_loss: 4.81663e-02
I0213 13:24:18.637351 22509476222784 run_lib.py:133] step: 842250, training_loss: 3.98181e-02
I0213 13:24:37.252105 22509476222784 run_lib.py:133] step: 842300, training_loss: 4.49928e-02
I0213 13:24:37.421379 22509476222784 run_lib.py:146] step: 842300, eval_loss: 3.73628e-02
I0213 13:24:55.928440 22509476222784 run_lib.py:133] step: 842350, training_loss: 4.09261e-02
I0213 13:25:14.368733 22509476222784 run_lib.py:133] step: 842400, training_loss: 3.78935e-02
I0213 13:25:14.544957 22509476222784 run_lib.py:146] step: 842400, eval_loss: 4.52654e-02
I0213 13:25:33.233337 22509476222784 run_lib.py:133] step: 842450, training_loss: 5.31896e-02
I0213 13:25:51.815760 22509476222784 run_lib.py:133] step: 842500, training_loss: 4.17008e-02
I0213 13:25:51.981383 22509476222784 run_lib.py:146] step: 842500, eval_loss: 3.73458e-02
I0213 13:26:10.626430 22509476222784 run_lib.py:133] step: 842550, training_loss: 4.40584e-02
I0213 13:26:29.062696 22509476222784 run_lib.py:133] step: 842600, training_loss: 4.88372e-02
I0213 13:26:29.233842 22509476222784 run_lib.py:146] step: 842600, eval_loss: 4.76767e-02
I0213 13:26:47.779254 22509476222784 run_lib.py:133] step: 842650, training_loss: 4.21451e-02
I0213 13:27:06.445615 22509476222784 run_lib.py:133] step: 842700, training_loss: 4.92520e-02
I0213 13:27:06.607712 22509476222784 run_lib.py:146] step: 842700, eval_loss: 4.90290e-02
I0213 13:27:25.188342 22509476222784 run_lib.py:133] step: 842750, training_loss: 3.98041e-02
I0213 13:27:43.639367 22509476222784 run_lib.py:133] step: 842800, training_loss: 3.93543e-02
I0213 13:27:43.815818 22509476222784 run_lib.py:146] step: 842800, eval_loss: 4.43811e-02
I0213 13:28:02.333712 22509476222784 run_lib.py:133] step: 842850, training_loss: 4.99497e-02
I0213 13:28:20.996661 22509476222784 run_lib.py:133] step: 842900, training_loss: 3.95243e-02
I0213 13:28:21.163056 22509476222784 run_lib.py:146] step: 842900, eval_loss: 4.83622e-02
I0213 13:28:39.639189 22509476222784 run_lib.py:133] step: 842950, training_loss: 4.73202e-02
I0213 13:28:58.280711 22509476222784 run_lib.py:133] step: 843000, training_loss: 4.10131e-02
I0213 13:28:58.443853 22509476222784 run_lib.py:146] step: 843000, eval_loss: 3.51490e-02
I0213 13:29:16.935585 22509476222784 run_lib.py:133] step: 843050, training_loss: 3.90518e-02
I0213 13:29:35.469251 22509476222784 run_lib.py:133] step: 843100, training_loss: 5.37748e-02
I0213 13:29:35.641403 22509476222784 run_lib.py:146] step: 843100, eval_loss: 4.51018e-02
I0213 13:29:54.379924 22509476222784 run_lib.py:133] step: 843150, training_loss: 3.12659e-02
I0213 13:30:12.935686 22509476222784 run_lib.py:133] step: 843200, training_loss: 5.30512e-02
I0213 13:30:13.095399 22509476222784 run_lib.py:146] step: 843200, eval_loss: 4.12869e-02
I0213 13:30:31.583411 22509476222784 run_lib.py:133] step: 843250, training_loss: 3.80655e-02
I0213 13:30:50.089367 22509476222784 run_lib.py:133] step: 843300, training_loss: 3.00869e-02
I0213 13:30:50.277820 22509476222784 run_lib.py:146] step: 843300, eval_loss: 4.50475e-02
I0213 13:31:09.018443 22509476222784 run_lib.py:133] step: 843350, training_loss: 4.32651e-02
I0213 13:31:27.493495 22509476222784 run_lib.py:133] step: 843400, training_loss: 3.72442e-02
I0213 13:31:27.661788 22509476222784 run_lib.py:146] step: 843400, eval_loss: 3.62426e-02
I0213 13:31:46.257016 22509476222784 run_lib.py:133] step: 843450, training_loss: 4.47207e-02
I0213 13:32:04.732294 22509476222784 run_lib.py:133] step: 843500, training_loss: 3.45688e-02
I0213 13:32:04.899681 22509476222784 run_lib.py:146] step: 843500, eval_loss: 3.73940e-02
I0213 13:32:23.561919 22509476222784 run_lib.py:133] step: 843550, training_loss: 4.63233e-02
I0213 13:32:42.090272 22509476222784 run_lib.py:133] step: 843600, training_loss: 3.76576e-02
I0213 13:32:42.254913 22509476222784 run_lib.py:146] step: 843600, eval_loss: 3.76039e-02
I0213 13:33:00.769403 22509476222784 run_lib.py:133] step: 843650, training_loss: 4.10685e-02
I0213 13:33:19.403180 22509476222784 run_lib.py:133] step: 843700, training_loss: 5.20105e-02
I0213 13:33:19.563762 22509476222784 run_lib.py:146] step: 843700, eval_loss: 3.66377e-02
I0213 13:33:38.055014 22509476222784 run_lib.py:133] step: 843750, training_loss: 4.16841e-02
I0213 13:33:56.671698 22509476222784 run_lib.py:133] step: 843800, training_loss: 4.04195e-02
I0213 13:33:56.838926 22509476222784 run_lib.py:146] step: 843800, eval_loss: 4.42748e-02
I0213 13:34:15.389138 22509476222784 run_lib.py:133] step: 843850, training_loss: 3.79304e-02
I0213 13:34:33.956421 22509476222784 run_lib.py:133] step: 843900, training_loss: 3.04769e-02
I0213 13:34:34.120614 22509476222784 run_lib.py:146] step: 843900, eval_loss: 3.63415e-02
I0213 13:34:52.824396 22509476222784 run_lib.py:133] step: 843950, training_loss: 4.58703e-02
I0213 13:35:11.293289 22509476222784 run_lib.py:133] step: 844000, training_loss: 4.14684e-02
I0213 13:35:11.459651 22509476222784 run_lib.py:146] step: 844000, eval_loss: 3.19888e-02
I0213 13:35:29.944484 22509476222784 run_lib.py:133] step: 844050, training_loss: 4.18047e-02
I0213 13:35:48.701320 22509476222784 run_lib.py:133] step: 844100, training_loss: 3.80696e-02
I0213 13:35:48.867820 22509476222784 run_lib.py:146] step: 844100, eval_loss: 4.73923e-02
I0213 13:36:07.354386 22509476222784 run_lib.py:133] step: 844150, training_loss: 3.59768e-02
I0213 13:36:25.808059 22509476222784 run_lib.py:133] step: 844200, training_loss: 2.88914e-02
I0213 13:36:26.156580 22509476222784 run_lib.py:146] step: 844200, eval_loss: 4.51655e-02
I0213 13:36:44.673876 22509476222784 run_lib.py:133] step: 844250, training_loss: 5.28452e-02
I0213 13:37:03.188604 22509476222784 run_lib.py:133] step: 844300, training_loss: 4.03391e-02
I0213 13:37:03.377183 22509476222784 run_lib.py:146] step: 844300, eval_loss: 3.50171e-02
I0213 13:37:22.055205 22509476222784 run_lib.py:133] step: 844350, training_loss: 4.91110e-02
I0213 13:37:40.851858 22509476222784 run_lib.py:133] step: 844400, training_loss: 4.74558e-02
I0213 13:37:41.018907 22509476222784 run_lib.py:146] step: 844400, eval_loss: 4.24450e-02
I0213 13:37:59.991435 22509476222784 run_lib.py:133] step: 844450, training_loss: 4.10555e-02
I0213 13:38:18.792074 22509476222784 run_lib.py:133] step: 844500, training_loss: 4.35941e-02
I0213 13:38:18.958834 22509476222784 run_lib.py:146] step: 844500, eval_loss: 5.33807e-02
I0213 13:38:37.664750 22509476222784 run_lib.py:133] step: 844550, training_loss: 4.16485e-02
I0213 13:38:56.399451 22509476222784 run_lib.py:133] step: 844600, training_loss: 4.06362e-02
I0213 13:38:56.564200 22509476222784 run_lib.py:146] step: 844600, eval_loss: 3.85492e-02
I0213 13:39:15.511904 22509476222784 run_lib.py:133] step: 844650, training_loss: 4.37177e-02
I0213 13:39:34.375711 22509476222784 run_lib.py:133] step: 844700, training_loss: 3.19836e-02
I0213 13:39:34.540191 22509476222784 run_lib.py:146] step: 844700, eval_loss: 4.03703e-02
I0213 13:39:53.203266 22509476222784 run_lib.py:133] step: 844750, training_loss: 4.30769e-02
I0213 13:40:11.927413 22509476222784 run_lib.py:133] step: 844800, training_loss: 4.92996e-02
I0213 13:40:12.097487 22509476222784 run_lib.py:146] step: 844800, eval_loss: 4.63074e-02
I0213 13:40:30.995990 22509476222784 run_lib.py:133] step: 844850, training_loss: 3.03982e-02
I0213 13:40:49.789367 22509476222784 run_lib.py:133] step: 844900, training_loss: 4.11170e-02
I0213 13:40:49.970098 22509476222784 run_lib.py:146] step: 844900, eval_loss: 3.53644e-02
I0213 13:41:08.845580 22509476222784 run_lib.py:133] step: 844950, training_loss: 4.31329e-02
I0213 13:41:27.573787 22509476222784 run_lib.py:133] step: 845000, training_loss: 3.60519e-02
I0213 13:41:27.742164 22509476222784 run_lib.py:146] step: 845000, eval_loss: 5.50082e-02
I0213 13:41:46.621764 22509476222784 run_lib.py:133] step: 845050, training_loss: 3.91716e-02
I0213 13:42:05.355922 22509476222784 run_lib.py:133] step: 845100, training_loss: 4.85289e-02
I0213 13:42:05.518960 22509476222784 run_lib.py:146] step: 845100, eval_loss: 4.03568e-02
I0213 13:42:24.242817 22509476222784 run_lib.py:133] step: 845150, training_loss: 3.40231e-02
I0213 13:42:43.147438 22509476222784 run_lib.py:133] step: 845200, training_loss: 3.64882e-02
I0213 13:42:43.318146 22509476222784 run_lib.py:146] step: 845200, eval_loss: 4.12679e-02
I0213 13:43:02.059618 22509476222784 run_lib.py:133] step: 845250, training_loss: 3.91651e-02
I0213 13:43:20.952235 22509476222784 run_lib.py:133] step: 845300, training_loss: 4.21758e-02
I0213 13:43:21.122064 22509476222784 run_lib.py:146] step: 845300, eval_loss: 3.14985e-02
I0213 13:43:39.802885 22509476222784 run_lib.py:133] step: 845350, training_loss: 4.14618e-02
I0213 13:43:58.520063 22509476222784 run_lib.py:133] step: 845400, training_loss: 4.55173e-02
I0213 13:43:58.691091 22509476222784 run_lib.py:146] step: 845400, eval_loss: 3.60293e-02
I0213 13:44:17.592141 22509476222784 run_lib.py:133] step: 845450, training_loss: 3.37113e-02
I0213 13:44:36.272878 22509476222784 run_lib.py:133] step: 845500, training_loss: 3.98761e-02
I0213 13:44:36.438001 22509476222784 run_lib.py:146] step: 845500, eval_loss: 5.15569e-02
I0213 13:44:55.152421 22509476222784 run_lib.py:133] step: 845550, training_loss: 3.71061e-02
I0213 13:45:13.845894 22509476222784 run_lib.py:133] step: 845600, training_loss: 4.71037e-02
I0213 13:45:14.007036 22509476222784 run_lib.py:146] step: 845600, eval_loss: 5.02167e-02
I0213 13:45:32.923357 22509476222784 run_lib.py:133] step: 845650, training_loss: 3.04637e-02
I0213 13:45:51.630815 22509476222784 run_lib.py:133] step: 845700, training_loss: 4.36560e-02
I0213 13:45:51.797046 22509476222784 run_lib.py:146] step: 845700, eval_loss: 3.38542e-02
I0213 13:46:10.576815 22509476222784 run_lib.py:133] step: 845750, training_loss: 3.92763e-02
I0213 13:46:29.307527 22509476222784 run_lib.py:133] step: 845800, training_loss: 3.46422e-02
I0213 13:46:29.476117 22509476222784 run_lib.py:146] step: 845800, eval_loss: 4.65242e-02
I0213 13:46:48.228178 22509476222784 run_lib.py:133] step: 845850, training_loss: 4.30667e-02
I0213 13:47:06.966650 22509476222784 run_lib.py:133] step: 845900, training_loss: 4.36230e-02
I0213 13:47:07.141469 22509476222784 run_lib.py:146] step: 845900, eval_loss: 4.92156e-02
I0213 13:47:25.980740 22509476222784 run_lib.py:133] step: 845950, training_loss: 4.14572e-02
I0213 13:47:44.851632 22509476222784 run_lib.py:133] step: 846000, training_loss: 4.30208e-02
I0213 13:47:45.016087 22509476222784 run_lib.py:146] step: 846000, eval_loss: 3.80806e-02
I0213 13:48:03.754289 22509476222784 run_lib.py:133] step: 846050, training_loss: 5.35948e-02
I0213 13:48:22.503214 22509476222784 run_lib.py:133] step: 846100, training_loss: 4.25423e-02
I0213 13:48:22.664482 22509476222784 run_lib.py:146] step: 846100, eval_loss: 2.67477e-02
I0213 13:48:41.488361 22509476222784 run_lib.py:133] step: 846150, training_loss: 4.19544e-02
I0213 13:49:00.205346 22509476222784 run_lib.py:133] step: 846200, training_loss: 4.15141e-02
I0213 13:49:00.386336 22509476222784 run_lib.py:146] step: 846200, eval_loss: 5.48713e-02
I0213 13:49:19.285417 22509476222784 run_lib.py:133] step: 846250, training_loss: 4.20337e-02
I0213 13:49:38.017776 22509476222784 run_lib.py:133] step: 846300, training_loss: 4.69885e-02
I0213 13:49:38.191756 22509476222784 run_lib.py:146] step: 846300, eval_loss: 3.47886e-02
I0213 13:49:57.086913 22509476222784 run_lib.py:133] step: 846350, training_loss: 4.98581e-02
I0213 13:50:15.771157 22509476222784 run_lib.py:133] step: 846400, training_loss: 4.58679e-02
I0213 13:50:15.936859 22509476222784 run_lib.py:146] step: 846400, eval_loss: 4.41693e-02
I0213 13:50:34.760998 22509476222784 run_lib.py:133] step: 846450, training_loss: 4.00326e-02
I0213 13:50:53.534053 22509476222784 run_lib.py:133] step: 846500, training_loss: 4.42459e-02
I0213 13:50:53.713187 22509476222784 run_lib.py:146] step: 846500, eval_loss: 4.68896e-02
I0213 13:51:12.455309 22509476222784 run_lib.py:133] step: 846550, training_loss: 5.80804e-02
I0213 13:51:31.310421 22509476222784 run_lib.py:133] step: 846600, training_loss: 3.40543e-02
I0213 13:51:31.483858 22509476222784 run_lib.py:146] step: 846600, eval_loss: 5.06148e-02
I0213 13:51:50.131367 22509476222784 run_lib.py:133] step: 846650, training_loss: 4.58038e-02
I0213 13:52:08.784725 22509476222784 run_lib.py:133] step: 846700, training_loss: 4.71883e-02
I0213 13:52:08.952363 22509476222784 run_lib.py:146] step: 846700, eval_loss: 5.42476e-02
I0213 13:52:27.817195 22509476222784 run_lib.py:133] step: 846750, training_loss: 4.41080e-02
I0213 13:52:46.763320 22509476222784 run_lib.py:133] step: 846800, training_loss: 3.57644e-02
I0213 13:52:46.930037 22509476222784 run_lib.py:146] step: 846800, eval_loss: 4.23182e-02
I0213 13:53:05.674618 22509476222784 run_lib.py:133] step: 846850, training_loss: 4.67066e-02
I0213 13:53:24.375551 22509476222784 run_lib.py:133] step: 846900, training_loss: 3.98760e-02
I0213 13:53:24.542726 22509476222784 run_lib.py:146] step: 846900, eval_loss: 5.30141e-02
I0213 13:53:43.323054 22509476222784 run_lib.py:133] step: 846950, training_loss: 4.08037e-02
I0213 13:54:02.262144 22509476222784 run_lib.py:133] step: 847000, training_loss: 3.69573e-02
I0213 13:54:02.426746 22509476222784 run_lib.py:146] step: 847000, eval_loss: 5.10353e-02
I0213 13:54:21.248624 22509476222784 run_lib.py:133] step: 847050, training_loss: 4.10327e-02
I0213 13:54:39.929077 22509476222784 run_lib.py:133] step: 847100, training_loss: 4.03282e-02
I0213 13:54:40.096246 22509476222784 run_lib.py:146] step: 847100, eval_loss: 3.28206e-02
I0213 13:54:58.768807 22509476222784 run_lib.py:133] step: 847150, training_loss: 3.50080e-02
I0213 13:55:17.664340 22509476222784 run_lib.py:133] step: 847200, training_loss: 3.53049e-02
I0213 13:55:17.834183 22509476222784 run_lib.py:146] step: 847200, eval_loss: 3.27929e-02
I0213 13:55:36.546616 22509476222784 run_lib.py:133] step: 847250, training_loss: 4.45166e-02
I0213 13:55:55.377380 22509476222784 run_lib.py:133] step: 847300, training_loss: 4.78583e-02
I0213 13:55:55.554230 22509476222784 run_lib.py:146] step: 847300, eval_loss: 4.11435e-02
I0213 13:56:14.232045 22509476222784 run_lib.py:133] step: 847350, training_loss: 4.13121e-02
I0213 13:56:32.896315 22509476222784 run_lib.py:133] step: 847400, training_loss: 4.33363e-02
I0213 13:56:33.061882 22509476222784 run_lib.py:146] step: 847400, eval_loss: 3.85002e-02
I0213 13:56:51.971940 22509476222784 run_lib.py:133] step: 847450, training_loss: 3.53054e-02
I0213 13:57:10.720116 22509476222784 run_lib.py:133] step: 847500, training_loss: 2.93897e-02
I0213 13:57:10.894924 22509476222784 run_lib.py:146] step: 847500, eval_loss: 3.20841e-02
I0213 13:57:29.661241 22509476222784 run_lib.py:133] step: 847550, training_loss: 4.86477e-02
I0213 13:57:48.310228 22509476222784 run_lib.py:133] step: 847600, training_loss: 4.59881e-02
I0213 13:57:48.475723 22509476222784 run_lib.py:146] step: 847600, eval_loss: 5.37539e-02
I0213 13:58:07.379494 22509476222784 run_lib.py:133] step: 847650, training_loss: 3.72569e-02
I0213 13:58:26.093551 22509476222784 run_lib.py:133] step: 847700, training_loss: 4.71704e-02
I0213 13:58:26.261750 22509476222784 run_lib.py:146] step: 847700, eval_loss: 4.02658e-02
I0213 13:58:45.108389 22509476222784 run_lib.py:133] step: 847750, training_loss: 2.58672e-02
I0213 13:59:03.868516 22509476222784 run_lib.py:133] step: 847800, training_loss: 4.29171e-02
I0213 13:59:04.035004 22509476222784 run_lib.py:146] step: 847800, eval_loss: 3.46069e-02
I0213 13:59:22.955177 22509476222784 run_lib.py:133] step: 847850, training_loss: 3.46855e-02
I0213 13:59:41.669643 22509476222784 run_lib.py:133] step: 847900, training_loss: 3.91086e-02
I0213 13:59:41.833738 22509476222784 run_lib.py:146] step: 847900, eval_loss: 4.04946e-02
I0213 14:00:00.503717 22509476222784 run_lib.py:133] step: 847950, training_loss: 4.80895e-02
I0213 14:00:19.385789 22509476222784 run_lib.py:133] step: 848000, training_loss: 4.65412e-02
I0213 14:00:19.549631 22509476222784 run_lib.py:146] step: 848000, eval_loss: 4.87121e-02
I0213 14:00:38.263936 22509476222784 run_lib.py:133] step: 848050, training_loss: 5.17813e-02
I0213 14:00:57.205676 22509476222784 run_lib.py:133] step: 848100, training_loss: 5.07506e-02
I0213 14:00:57.385725 22509476222784 run_lib.py:146] step: 848100, eval_loss: 4.18262e-02
I0213 14:01:16.130364 22509476222784 run_lib.py:133] step: 848150, training_loss: 4.03143e-02
I0213 14:01:34.878494 22509476222784 run_lib.py:133] step: 848200, training_loss: 4.43669e-02
I0213 14:01:35.044070 22509476222784 run_lib.py:146] step: 848200, eval_loss: 5.73460e-02
I0213 14:01:53.934820 22509476222784 run_lib.py:133] step: 848250, training_loss: 4.29285e-02
I0213 14:02:12.641730 22509476222784 run_lib.py:133] step: 848300, training_loss: 4.59604e-02
I0213 14:02:12.816979 22509476222784 run_lib.py:146] step: 848300, eval_loss: 5.42229e-02
I0213 14:02:31.567336 22509476222784 run_lib.py:133] step: 848350, training_loss: 3.68977e-02
I0213 14:02:50.511795 22509476222784 run_lib.py:133] step: 848400, training_loss: 3.98148e-02
I0213 14:02:50.673562 22509476222784 run_lib.py:146] step: 848400, eval_loss: 4.38617e-02
I0213 14:03:09.425582 22509476222784 run_lib.py:133] step: 848450, training_loss: 4.86742e-02
I0213 14:03:28.104091 22509476222784 run_lib.py:133] step: 848500, training_loss: 4.32818e-02
I0213 14:03:28.268424 22509476222784 run_lib.py:146] step: 848500, eval_loss: 3.90827e-02
I0213 14:03:47.020779 22509476222784 run_lib.py:133] step: 848550, training_loss: 4.31402e-02
I0213 14:04:05.763814 22509476222784 run_lib.py:133] step: 848600, training_loss: 3.37678e-02
I0213 14:04:05.947076 22509476222784 run_lib.py:146] step: 848600, eval_loss: 3.93374e-02
I0213 14:04:24.669297 22509476222784 run_lib.py:133] step: 848650, training_loss: 4.11167e-02
I0213 14:04:43.406347 22509476222784 run_lib.py:133] step: 848700, training_loss: 4.88770e-02
I0213 14:04:43.593198 22509476222784 run_lib.py:146] step: 848700, eval_loss: 5.68708e-02
I0213 14:05:02.456648 22509476222784 run_lib.py:133] step: 848750, training_loss: 4.52298e-02
I0213 14:05:21.236865 22509476222784 run_lib.py:133] step: 848800, training_loss: 6.08388e-02
I0213 14:05:21.404909 22509476222784 run_lib.py:146] step: 848800, eval_loss: 4.15040e-02
I0213 14:05:40.176838 22509476222784 run_lib.py:133] step: 848850, training_loss: 3.95548e-02
I0213 14:05:58.916573 22509476222784 run_lib.py:133] step: 848900, training_loss: 4.39244e-02
I0213 14:05:59.081257 22509476222784 run_lib.py:146] step: 848900, eval_loss: 4.62133e-02
I0213 14:06:17.990518 22509476222784 run_lib.py:133] step: 848950, training_loss: 4.65228e-02
I0213 14:06:36.692194 22509476222784 run_lib.py:133] step: 849000, training_loss: 3.17644e-02
I0213 14:06:36.857654 22509476222784 run_lib.py:146] step: 849000, eval_loss: 3.98235e-02
I0213 14:06:55.669548 22509476222784 run_lib.py:133] step: 849050, training_loss: 4.37100e-02
I0213 14:07:14.390732 22509476222784 run_lib.py:133] step: 849100, training_loss: 4.98566e-02
I0213 14:07:14.574960 22509476222784 run_lib.py:146] step: 849100, eval_loss: 6.31373e-02
I0213 14:07:33.510151 22509476222784 run_lib.py:133] step: 849150, training_loss: 4.28151e-02
I0213 14:07:52.269310 22509476222784 run_lib.py:133] step: 849200, training_loss: 3.04061e-02
I0213 14:07:52.436204 22509476222784 run_lib.py:146] step: 849200, eval_loss: 4.69927e-02
I0213 14:08:11.344637 22509476222784 run_lib.py:133] step: 849250, training_loss: 3.84196e-02
I0213 14:08:30.067711 22509476222784 run_lib.py:133] step: 849300, training_loss: 4.78184e-02
I0213 14:08:30.235469 22509476222784 run_lib.py:146] step: 849300, eval_loss: 4.21354e-02
I0213 14:08:48.915125 22509476222784 run_lib.py:133] step: 849350, training_loss: 5.60870e-02
I0213 14:09:07.854937 22509476222784 run_lib.py:133] step: 849400, training_loss: 4.11164e-02
I0213 14:09:08.021871 22509476222784 run_lib.py:146] step: 849400, eval_loss: 4.70113e-02
I0213 14:09:26.775466 22509476222784 run_lib.py:133] step: 849450, training_loss: 2.93258e-02
I0213 14:09:45.515846 22509476222784 run_lib.py:133] step: 849500, training_loss: 5.47455e-02
I0213 14:09:45.681567 22509476222784 run_lib.py:146] step: 849500, eval_loss: 4.99440e-02
I0213 14:10:04.640415 22509476222784 run_lib.py:133] step: 849550, training_loss: 3.91269e-02
I0213 14:10:23.389026 22509476222784 run_lib.py:133] step: 849600, training_loss: 4.77858e-02
I0213 14:10:23.568495 22509476222784 run_lib.py:146] step: 849600, eval_loss: 4.05089e-02
I0213 14:10:42.461028 22509476222784 run_lib.py:133] step: 849650, training_loss: 3.86686e-02
I0213 14:11:01.234185 22509476222784 run_lib.py:133] step: 849700, training_loss: 4.22133e-02
I0213 14:11:01.407840 22509476222784 run_lib.py:146] step: 849700, eval_loss: 4.51885e-02
I0213 14:11:20.151459 22509476222784 run_lib.py:133] step: 849750, training_loss: 3.52416e-02
I0213 14:11:39.062473 22509476222784 run_lib.py:133] step: 849800, training_loss: 3.19269e-02
I0213 14:11:39.226816 22509476222784 run_lib.py:146] step: 849800, eval_loss: 5.83041e-02
I0213 14:11:57.911239 22509476222784 run_lib.py:133] step: 849850, training_loss: 3.82424e-02
I0213 14:12:16.704621 22509476222784 run_lib.py:133] step: 849900, training_loss: 4.07091e-02
I0213 14:12:16.873130 22509476222784 run_lib.py:146] step: 849900, eval_loss: 5.55300e-02
I0213 14:12:35.658304 22509476222784 run_lib.py:133] step: 849950, training_loss: 4.45999e-02
I0213 14:12:54.549242 22509476222784 run_lib.py:133] step: 850000, training_loss: 5.20265e-02
I0213 14:12:55.338825 22509476222784 run_lib.py:146] step: 850000, eval_loss: 4.33524e-02
I0213 14:13:16.807992 22509476222784 run_lib.py:133] step: 850050, training_loss: 4.72219e-02
I0213 14:13:35.703903 22509476222784 run_lib.py:133] step: 850100, training_loss: 5.39748e-02
I0213 14:13:35.886922 22509476222784 run_lib.py:146] step: 850100, eval_loss: 4.19825e-02
I0213 14:13:54.645434 22509476222784 run_lib.py:133] step: 850150, training_loss: 4.24832e-02
I0213 14:14:13.425903 22509476222784 run_lib.py:133] step: 850200, training_loss: 4.10957e-02
I0213 14:14:13.599843 22509476222784 run_lib.py:146] step: 850200, eval_loss: 4.35980e-02
I0213 14:14:32.285653 22509476222784 run_lib.py:133] step: 850250, training_loss: 3.31289e-02
I0213 14:14:51.189168 22509476222784 run_lib.py:133] step: 850300, training_loss: 3.56397e-02
I0213 14:14:51.362835 22509476222784 run_lib.py:146] step: 850300, eval_loss: 3.83399e-02
I0213 14:15:10.252077 22509476222784 run_lib.py:133] step: 850350, training_loss: 3.62730e-02
I0213 14:15:28.924566 22509476222784 run_lib.py:133] step: 850400, training_loss: 3.33357e-02
I0213 14:15:29.089065 22509476222784 run_lib.py:146] step: 850400, eval_loss: 4.32085e-02
I0213 14:15:47.852922 22509476222784 run_lib.py:133] step: 850450, training_loss: 5.49712e-02
I0213 14:16:06.534630 22509476222784 run_lib.py:133] step: 850500, training_loss: 3.89064e-02
I0213 14:16:06.700809 22509476222784 run_lib.py:146] step: 850500, eval_loss: 4.69988e-02
I0213 14:16:25.594797 22509476222784 run_lib.py:133] step: 850550, training_loss: 3.94901e-02
I0213 14:16:44.339585 22509476222784 run_lib.py:133] step: 850600, training_loss: 3.76103e-02
I0213 14:16:44.508955 22509476222784 run_lib.py:146] step: 850600, eval_loss: 4.11832e-02
I0213 14:17:03.230689 22509476222784 run_lib.py:133] step: 850650, training_loss: 3.36261e-02
I0213 14:17:21.975614 22509476222784 run_lib.py:133] step: 850700, training_loss: 4.69258e-02
I0213 14:17:22.139095 22509476222784 run_lib.py:146] step: 850700, eval_loss: 3.56213e-02
I0213 14:17:41.081699 22509476222784 run_lib.py:133] step: 850750, training_loss: 4.01984e-02
I0213 14:17:59.768646 22509476222784 run_lib.py:133] step: 850800, training_loss: 4.55740e-02
I0213 14:17:59.933997 22509476222784 run_lib.py:146] step: 850800, eval_loss: 4.50618e-02
I0213 14:18:18.821905 22509476222784 run_lib.py:133] step: 850850, training_loss: 3.16880e-02
I0213 14:18:37.595244 22509476222784 run_lib.py:133] step: 850900, training_loss: 4.06807e-02
I0213 14:18:37.763940 22509476222784 run_lib.py:146] step: 850900, eval_loss: 3.48867e-02
I0213 14:18:56.732260 22509476222784 run_lib.py:133] step: 850950, training_loss: 4.34879e-02
I0213 14:19:15.496322 22509476222784 run_lib.py:133] step: 851000, training_loss: 4.93519e-02
I0213 14:19:15.662163 22509476222784 run_lib.py:146] step: 851000, eval_loss: 3.62778e-02
I0213 14:19:34.391989 22509476222784 run_lib.py:133] step: 851050, training_loss: 4.02665e-02
I0213 14:19:53.259549 22509476222784 run_lib.py:133] step: 851100, training_loss: 5.84989e-02
I0213 14:19:53.441858 22509476222784 run_lib.py:146] step: 851100, eval_loss: 3.90212e-02
I0213 14:20:12.242974 22509476222784 run_lib.py:133] step: 851150, training_loss: 4.56610e-02
I0213 14:20:31.216710 22509476222784 run_lib.py:133] step: 851200, training_loss: 3.60516e-02
I0213 14:20:31.389209 22509476222784 run_lib.py:146] step: 851200, eval_loss: 3.92236e-02
I0213 14:20:50.165788 22509476222784 run_lib.py:133] step: 851250, training_loss: 5.92384e-02
I0213 14:21:08.903332 22509476222784 run_lib.py:133] step: 851300, training_loss: 3.56589e-02
I0213 14:21:09.067938 22509476222784 run_lib.py:146] step: 851300, eval_loss: 4.41027e-02
I0213 14:21:27.996522 22509476222784 run_lib.py:133] step: 851350, training_loss: 4.06030e-02
I0213 14:21:46.745782 22509476222784 run_lib.py:133] step: 851400, training_loss: 3.76724e-02
I0213 14:21:46.913128 22509476222784 run_lib.py:146] step: 851400, eval_loss: 4.31826e-02
I0213 14:22:05.705418 22509476222784 run_lib.py:133] step: 851450, training_loss: 4.04667e-02
I0213 14:22:24.680254 22509476222784 run_lib.py:133] step: 851500, training_loss: 3.17913e-02
I0213 14:22:24.848802 22509476222784 run_lib.py:146] step: 851500, eval_loss: 5.30649e-02
I0213 14:22:43.499681 22509476222784 run_lib.py:133] step: 851550, training_loss: 4.75284e-02
I0213 14:23:02.147991 22509476222784 run_lib.py:133] step: 851600, training_loss: 2.56731e-02
I0213 14:23:02.470793 22509476222784 run_lib.py:146] step: 851600, eval_loss: 4.21213e-02
I0213 14:23:21.192391 22509476222784 run_lib.py:133] step: 851650, training_loss: 4.34636e-02
I0213 14:23:39.855381 22509476222784 run_lib.py:133] step: 851700, training_loss: 4.24239e-02
I0213 14:23:40.028663 22509476222784 run_lib.py:146] step: 851700, eval_loss: 4.90904e-02
I0213 14:23:58.750462 22509476222784 run_lib.py:133] step: 851750, training_loss: 3.80556e-02
I0213 14:24:17.444877 22509476222784 run_lib.py:133] step: 851800, training_loss: 4.07820e-02
I0213 14:24:17.618092 22509476222784 run_lib.py:146] step: 851800, eval_loss: 4.95224e-02
I0213 14:24:36.555821 22509476222784 run_lib.py:133] step: 851850, training_loss: 5.10584e-02
I0213 14:24:55.334298 22509476222784 run_lib.py:133] step: 851900, training_loss: 4.80643e-02
I0213 14:24:55.499555 22509476222784 run_lib.py:146] step: 851900, eval_loss: 5.06757e-02
I0213 14:25:14.215303 22509476222784 run_lib.py:133] step: 851950, training_loss: 3.65324e-02
I0213 14:25:32.945951 22509476222784 run_lib.py:133] step: 852000, training_loss: 3.04672e-02
I0213 14:25:33.129812 22509476222784 run_lib.py:146] step: 852000, eval_loss: 4.20370e-02
I0213 14:25:52.091527 22509476222784 run_lib.py:133] step: 852050, training_loss: 4.45450e-02
I0213 14:26:10.930629 22509476222784 run_lib.py:133] step: 852100, training_loss: 4.89900e-02
I0213 14:26:11.097999 22509476222784 run_lib.py:146] step: 852100, eval_loss: 3.73105e-02
I0213 14:26:29.876785 22509476222784 run_lib.py:133] step: 852150, training_loss: 5.21053e-02
I0213 14:26:48.588890 22509476222784 run_lib.py:133] step: 852200, training_loss: 3.73220e-02
I0213 14:26:48.754073 22509476222784 run_lib.py:146] step: 852200, eval_loss: 3.88259e-02
I0213 14:27:07.623996 22509476222784 run_lib.py:133] step: 852250, training_loss: 4.55898e-02
I0213 14:27:26.433094 22509476222784 run_lib.py:133] step: 852300, training_loss: 3.87311e-02
I0213 14:27:26.597995 22509476222784 run_lib.py:146] step: 852300, eval_loss: 3.43521e-02
I0213 14:27:45.552042 22509476222784 run_lib.py:133] step: 852350, training_loss: 4.20432e-02
I0213 14:28:04.331583 22509476222784 run_lib.py:133] step: 852400, training_loss: 3.54756e-02
I0213 14:28:04.504876 22509476222784 run_lib.py:146] step: 852400, eval_loss: 4.33940e-02
I0213 14:28:23.342526 22509476222784 run_lib.py:133] step: 852450, training_loss: 4.67857e-02
I0213 14:28:42.091655 22509476222784 run_lib.py:133] step: 852500, training_loss: 4.05153e-02
I0213 14:28:42.274035 22509476222784 run_lib.py:146] step: 852500, eval_loss: 5.67503e-02
I0213 14:29:01.020022 22509476222784 run_lib.py:133] step: 852550, training_loss: 4.66201e-02
I0213 14:29:20.005482 22509476222784 run_lib.py:133] step: 852600, training_loss: 4.06515e-02
I0213 14:29:20.172055 22509476222784 run_lib.py:146] step: 852600, eval_loss: 4.79444e-02
I0213 14:29:38.921388 22509476222784 run_lib.py:133] step: 852650, training_loss: 6.28938e-02
I0213 14:29:57.806326 22509476222784 run_lib.py:133] step: 852700, training_loss: 4.71047e-02
I0213 14:29:57.971881 22509476222784 run_lib.py:146] step: 852700, eval_loss: 4.62466e-02
I0213 14:30:16.686230 22509476222784 run_lib.py:133] step: 852750, training_loss: 5.83360e-02
I0213 14:30:35.491413 22509476222784 run_lib.py:133] step: 852800, training_loss: 4.69950e-02
I0213 14:30:35.658122 22509476222784 run_lib.py:146] step: 852800, eval_loss: 4.23455e-02
I0213 14:30:54.632884 22509476222784 run_lib.py:133] step: 852850, training_loss: 3.17835e-02
I0213 14:31:13.391696 22509476222784 run_lib.py:133] step: 852900, training_loss: 3.87406e-02
I0213 14:31:13.555904 22509476222784 run_lib.py:146] step: 852900, eval_loss: 3.91319e-02
I0213 14:31:32.227497 22509476222784 run_lib.py:133] step: 852950, training_loss: 3.92017e-02
I0213 14:31:50.916368 22509476222784 run_lib.py:133] step: 853000, training_loss: 4.33336e-02
I0213 14:31:51.097481 22509476222784 run_lib.py:146] step: 853000, eval_loss: 3.88644e-02
I0213 14:32:09.991029 22509476222784 run_lib.py:133] step: 853050, training_loss: 3.78237e-02
I0213 14:32:28.743019 22509476222784 run_lib.py:133] step: 853100, training_loss: 3.78338e-02
I0213 14:32:28.909610 22509476222784 run_lib.py:146] step: 853100, eval_loss: 3.95728e-02
I0213 14:32:47.845253 22509476222784 run_lib.py:133] step: 853150, training_loss: 3.56835e-02
I0213 14:33:06.566300 22509476222784 run_lib.py:133] step: 853200, training_loss: 4.26045e-02
I0213 14:33:06.729823 22509476222784 run_lib.py:146] step: 853200, eval_loss: 3.42776e-02
I0213 14:33:25.417878 22509476222784 run_lib.py:133] step: 853250, training_loss: 3.57569e-02
I0213 14:33:44.163429 22509476222784 run_lib.py:133] step: 853300, training_loss: 4.44323e-02
I0213 14:33:44.330957 22509476222784 run_lib.py:146] step: 853300, eval_loss: 3.53694e-02
I0213 14:34:03.228376 22509476222784 run_lib.py:133] step: 853350, training_loss: 5.66261e-02
I0213 14:34:22.012333 22509476222784 run_lib.py:133] step: 853400, training_loss: 4.47078e-02
I0213 14:34:22.181141 22509476222784 run_lib.py:146] step: 853400, eval_loss: 5.35363e-02
I0213 14:34:40.810563 22509476222784 run_lib.py:133] step: 853450, training_loss: 3.09182e-02
I0213 14:34:59.538967 22509476222784 run_lib.py:133] step: 853500, training_loss: 5.29480e-02
I0213 14:34:59.703792 22509476222784 run_lib.py:146] step: 853500, eval_loss: 3.17357e-02
I0213 14:35:18.592913 22509476222784 run_lib.py:133] step: 853550, training_loss: 4.37923e-02
I0213 14:35:37.370047 22509476222784 run_lib.py:133] step: 853600, training_loss: 3.07527e-02
I0213 14:35:37.537529 22509476222784 run_lib.py:146] step: 853600, eval_loss: 5.36284e-02
I0213 14:35:56.487006 22509476222784 run_lib.py:133] step: 853650, training_loss: 3.64246e-02
I0213 14:36:15.229293 22509476222784 run_lib.py:133] step: 853700, training_loss: 4.46875e-02
I0213 14:36:15.395061 22509476222784 run_lib.py:146] step: 853700, eval_loss: 4.11338e-02
I0213 14:36:34.272957 22509476222784 run_lib.py:133] step: 853750, training_loss: 5.05439e-02
I0213 14:36:53.065664 22509476222784 run_lib.py:133] step: 853800, training_loss: 4.14890e-02
I0213 14:36:53.242027 22509476222784 run_lib.py:146] step: 853800, eval_loss: 5.46634e-02
I0213 14:37:12.220381 22509476222784 run_lib.py:133] step: 853850, training_loss: 3.54415e-02
I0213 14:37:30.990318 22509476222784 run_lib.py:133] step: 853900, training_loss: 3.78355e-02
I0213 14:37:31.158716 22509476222784 run_lib.py:146] step: 853900, eval_loss: 2.72814e-02
I0213 14:37:49.911289 22509476222784 run_lib.py:133] step: 853950, training_loss: 4.69053e-02
I0213 14:38:08.833408 22509476222784 run_lib.py:133] step: 854000, training_loss: 4.65906e-02
I0213 14:38:08.999909 22509476222784 run_lib.py:146] step: 854000, eval_loss: 4.84186e-02
I0213 14:38:27.752902 22509476222784 run_lib.py:133] step: 854050, training_loss: 3.42135e-02
I0213 14:38:46.549961 22509476222784 run_lib.py:133] step: 854100, training_loss: 4.68688e-02
I0213 14:38:46.716526 22509476222784 run_lib.py:146] step: 854100, eval_loss: 3.95353e-02
I0213 14:39:05.720380 22509476222784 run_lib.py:133] step: 854150, training_loss: 4.59116e-02
I0213 14:39:24.645357 22509476222784 run_lib.py:133] step: 854200, training_loss: 3.07697e-02
I0213 14:39:24.809918 22509476222784 run_lib.py:146] step: 854200, eval_loss: 3.85471e-02
I0213 14:39:43.537138 22509476222784 run_lib.py:133] step: 854250, training_loss: 3.52365e-02
I0213 14:40:02.305853 22509476222784 run_lib.py:133] step: 854300, training_loss: 3.93805e-02
I0213 14:40:02.481098 22509476222784 run_lib.py:146] step: 854300, eval_loss: 4.69650e-02
I0213 14:40:21.281310 22509476222784 run_lib.py:133] step: 854350, training_loss: 4.90832e-02
I0213 14:40:40.276672 22509476222784 run_lib.py:133] step: 854400, training_loss: 4.32336e-02
I0213 14:40:40.443704 22509476222784 run_lib.py:146] step: 854400, eval_loss: 3.54885e-02
I0213 14:40:59.217275 22509476222784 run_lib.py:133] step: 854450, training_loss: 5.02769e-02
I0213 14:41:17.908284 22509476222784 run_lib.py:133] step: 854500, training_loss: 4.27215e-02
I0213 14:41:18.077944 22509476222784 run_lib.py:146] step: 854500, eval_loss: 4.44914e-02
I0213 14:41:36.826553 22509476222784 run_lib.py:133] step: 854550, training_loss: 2.94232e-02
I0213 14:41:55.749156 22509476222784 run_lib.py:133] step: 854600, training_loss: 5.03236e-02
I0213 14:41:55.929245 22509476222784 run_lib.py:146] step: 854600, eval_loss: 3.78603e-02
I0213 14:42:14.689383 22509476222784 run_lib.py:133] step: 854650, training_loss: 4.14777e-02
I0213 14:42:33.501582 22509476222784 run_lib.py:133] step: 854700, training_loss: 3.95499e-02
I0213 14:42:33.665348 22509476222784 run_lib.py:146] step: 854700, eval_loss: 3.49685e-02
I0213 14:42:52.355941 22509476222784 run_lib.py:133] step: 854750, training_loss: 5.04570e-02
I0213 14:43:11.038016 22509476222784 run_lib.py:133] step: 854800, training_loss: 3.68646e-02
I0213 14:43:11.208123 22509476222784 run_lib.py:146] step: 854800, eval_loss: 4.50560e-02
I0213 14:43:30.125411 22509476222784 run_lib.py:133] step: 854850, training_loss: 3.92452e-02
I0213 14:43:49.054378 22509476222784 run_lib.py:133] step: 854900, training_loss: 3.73797e-02
I0213 14:43:49.221980 22509476222784 run_lib.py:146] step: 854900, eval_loss: 4.89515e-02
I0213 14:44:07.927093 22509476222784 run_lib.py:133] step: 854950, training_loss: 3.74493e-02
I0213 14:44:26.694325 22509476222784 run_lib.py:133] step: 855000, training_loss: 4.85248e-02
I0213 14:44:26.859967 22509476222784 run_lib.py:146] step: 855000, eval_loss: 4.21707e-02
I0213 14:44:45.754029 22509476222784 run_lib.py:133] step: 855050, training_loss: 4.66900e-02
I0213 14:45:04.487720 22509476222784 run_lib.py:133] step: 855100, training_loss: 4.26543e-02
I0213 14:45:04.656111 22509476222784 run_lib.py:146] step: 855100, eval_loss: 3.35857e-02
I0213 14:45:23.622760 22509476222784 run_lib.py:133] step: 855150, training_loss: 3.95902e-02
I0213 14:45:42.361900 22509476222784 run_lib.py:133] step: 855200, training_loss: 4.65516e-02
I0213 14:45:42.526637 22509476222784 run_lib.py:146] step: 855200, eval_loss: 5.32566e-02
I0213 14:46:01.437632 22509476222784 run_lib.py:133] step: 855250, training_loss: 5.12375e-02
I0213 14:46:20.127436 22509476222784 run_lib.py:133] step: 855300, training_loss: 4.30484e-02
I0213 14:46:20.295078 22509476222784 run_lib.py:146] step: 855300, eval_loss: 3.98601e-02
I0213 14:46:39.042801 22509476222784 run_lib.py:133] step: 855350, training_loss: 4.53588e-02
I0213 14:46:58.002856 22509476222784 run_lib.py:133] step: 855400, training_loss: 4.01280e-02
I0213 14:46:58.168922 22509476222784 run_lib.py:146] step: 855400, eval_loss: 3.73300e-02
I0213 14:47:16.939543 22509476222784 run_lib.py:133] step: 855450, training_loss: 5.27764e-02
I0213 14:47:35.824630 22509476222784 run_lib.py:133] step: 855500, training_loss: 4.18060e-02
I0213 14:47:35.991436 22509476222784 run_lib.py:146] step: 855500, eval_loss: 5.72937e-02
I0213 14:47:54.734978 22509476222784 run_lib.py:133] step: 855550, training_loss: 4.02175e-02
I0213 14:48:13.470497 22509476222784 run_lib.py:133] step: 855600, training_loss: 3.75596e-02
I0213 14:48:13.634740 22509476222784 run_lib.py:146] step: 855600, eval_loss: 4.92708e-02
I0213 14:48:32.589694 22509476222784 run_lib.py:133] step: 855650, training_loss: 3.74499e-02
I0213 14:48:51.255403 22509476222784 run_lib.py:133] step: 855700, training_loss: 4.47735e-02
I0213 14:48:51.420838 22509476222784 run_lib.py:146] step: 855700, eval_loss: 3.89965e-02
I0213 14:49:10.162756 22509476222784 run_lib.py:133] step: 855750, training_loss: 5.05027e-02
I0213 14:49:29.051672 22509476222784 run_lib.py:133] step: 855800, training_loss: 3.26797e-02
I0213 14:49:29.219081 22509476222784 run_lib.py:146] step: 855800, eval_loss: 3.99127e-02
I0213 14:49:47.931210 22509476222784 run_lib.py:133] step: 855850, training_loss: 5.09955e-02
I0213 14:50:06.763405 22509476222784 run_lib.py:133] step: 855900, training_loss: 4.61706e-02
I0213 14:50:06.938820 22509476222784 run_lib.py:146] step: 855900, eval_loss: 3.95480e-02
I0213 14:50:25.781709 22509476222784 run_lib.py:133] step: 855950, training_loss: 3.38936e-02
I0213 14:50:44.501222 22509476222784 run_lib.py:133] step: 856000, training_loss: 4.00574e-02
I0213 14:50:44.674841 22509476222784 run_lib.py:146] step: 856000, eval_loss: 4.06508e-02
I0213 14:51:03.376050 22509476222784 run_lib.py:133] step: 856050, training_loss: 3.83870e-02
I0213 14:51:22.069910 22509476222784 run_lib.py:133] step: 856100, training_loss: 4.37461e-02
I0213 14:51:22.231794 22509476222784 run_lib.py:146] step: 856100, eval_loss: 3.39907e-02
I0213 14:51:41.147393 22509476222784 run_lib.py:133] step: 856150, training_loss: 2.61423e-02
I0213 14:51:59.934915 22509476222784 run_lib.py:133] step: 856200, training_loss: 4.73331e-02
I0213 14:52:00.104226 22509476222784 run_lib.py:146] step: 856200, eval_loss: 3.52442e-02
I0213 14:52:18.797809 22509476222784 run_lib.py:133] step: 856250, training_loss: 6.45579e-02
I0213 14:52:37.488518 22509476222784 run_lib.py:133] step: 856300, training_loss: 4.38786e-02
I0213 14:52:37.656041 22509476222784 run_lib.py:146] step: 856300, eval_loss: 5.16563e-02
I0213 14:52:56.555065 22509476222784 run_lib.py:133] step: 856350, training_loss: 4.64781e-02
I0213 14:53:15.365762 22509476222784 run_lib.py:133] step: 856400, training_loss: 4.58237e-02
I0213 14:53:15.533213 22509476222784 run_lib.py:146] step: 856400, eval_loss: 3.88642e-02
I0213 14:53:34.473405 22509476222784 run_lib.py:133] step: 856450, training_loss: 3.95946e-02
I0213 14:53:53.242080 22509476222784 run_lib.py:133] step: 856500, training_loss: 4.32621e-02
I0213 14:53:53.407955 22509476222784 run_lib.py:146] step: 856500, eval_loss: 3.96398e-02
I0213 14:54:12.312593 22509476222784 run_lib.py:133] step: 856550, training_loss: 4.76638e-02
I0213 14:54:31.064672 22509476222784 run_lib.py:133] step: 856600, training_loss: 4.62364e-02
I0213 14:54:31.230021 22509476222784 run_lib.py:146] step: 856600, eval_loss: 4.26090e-02
I0213 14:54:50.167564 22509476222784 run_lib.py:133] step: 856650, training_loss: 3.86723e-02
I0213 14:55:08.927669 22509476222784 run_lib.py:133] step: 856700, training_loss: 4.22183e-02
I0213 14:55:09.098311 22509476222784 run_lib.py:146] step: 856700, eval_loss: 4.01962e-02
I0213 14:55:27.776726 22509476222784 run_lib.py:133] step: 856750, training_loss: 4.79963e-02
I0213 14:55:46.724498 22509476222784 run_lib.py:133] step: 856800, training_loss: 3.11300e-02
I0213 14:55:46.891350 22509476222784 run_lib.py:146] step: 856800, eval_loss: 5.73108e-02
I0213 14:56:05.609035 22509476222784 run_lib.py:133] step: 856850, training_loss: 3.63419e-02
I0213 14:56:24.405888 22509476222784 run_lib.py:133] step: 856900, training_loss: 2.57516e-02
I0213 14:56:24.572409 22509476222784 run_lib.py:146] step: 856900, eval_loss: 3.49886e-02
I0213 14:56:43.537599 22509476222784 run_lib.py:133] step: 856950, training_loss: 3.14723e-02
I0213 14:57:02.266482 22509476222784 run_lib.py:133] step: 857000, training_loss: 4.15006e-02
I0213 14:57:02.430874 22509476222784 run_lib.py:146] step: 857000, eval_loss: 3.91144e-02
I0213 14:57:21.290880 22509476222784 run_lib.py:133] step: 857050, training_loss: 4.25199e-02
I0213 14:57:39.996461 22509476222784 run_lib.py:133] step: 857100, training_loss: 3.68455e-02
I0213 14:57:40.159379 22509476222784 run_lib.py:146] step: 857100, eval_loss: 4.45038e-02
I0213 14:57:58.917469 22509476222784 run_lib.py:133] step: 857150, training_loss: 3.32330e-02
I0213 14:58:17.910300 22509476222784 run_lib.py:133] step: 857200, training_loss: 4.56660e-02
I0213 14:58:18.080535 22509476222784 run_lib.py:146] step: 857200, eval_loss: 4.23897e-02
I0213 14:58:36.806980 22509476222784 run_lib.py:133] step: 857250, training_loss: 4.38443e-02
I0213 14:58:55.535039 22509476222784 run_lib.py:133] step: 857300, training_loss: 4.43785e-02
I0213 14:58:55.700773 22509476222784 run_lib.py:146] step: 857300, eval_loss: 4.94165e-02
I0213 14:59:14.473241 22509476222784 run_lib.py:133] step: 857350, training_loss: 4.96762e-02
I0213 14:59:33.453086 22509476222784 run_lib.py:133] step: 857400, training_loss: 4.68096e-02
I0213 14:59:33.619759 22509476222784 run_lib.py:146] step: 857400, eval_loss: 4.33964e-02
I0213 14:59:52.397686 22509476222784 run_lib.py:133] step: 857450, training_loss: 4.81058e-02
I0213 15:00:11.281412 22509476222784 run_lib.py:133] step: 857500, training_loss: 4.66128e-02
I0213 15:00:11.444899 22509476222784 run_lib.py:146] step: 857500, eval_loss: 3.82323e-02
I0213 15:00:30.202404 22509476222784 run_lib.py:133] step: 857550, training_loss: 5.22762e-02
I0213 15:00:48.965388 22509476222784 run_lib.py:133] step: 857600, training_loss: 3.79356e-02
I0213 15:00:49.130971 22509476222784 run_lib.py:146] step: 857600, eval_loss: 3.71788e-02
I0213 15:01:08.030068 22509476222784 run_lib.py:133] step: 857650, training_loss: 4.07634e-02
I0213 15:01:26.972420 22509476222784 run_lib.py:133] step: 857700, training_loss: 3.63577e-02
I0213 15:01:27.141963 22509476222784 run_lib.py:146] step: 857700, eval_loss: 3.63280e-02
I0213 15:01:45.901851 22509476222784 run_lib.py:133] step: 857750, training_loss: 4.40833e-02
I0213 15:02:04.663605 22509476222784 run_lib.py:133] step: 857800, training_loss: 5.24986e-02
I0213 15:02:04.831895 22509476222784 run_lib.py:146] step: 857800, eval_loss: 4.38858e-02
I0213 15:02:23.714973 22509476222784 run_lib.py:133] step: 857850, training_loss: 3.80996e-02
I0213 15:02:42.495047 22509476222784 run_lib.py:133] step: 857900, training_loss: 3.91976e-02
I0213 15:02:42.666616 22509476222784 run_lib.py:146] step: 857900, eval_loss: 4.05953e-02
I0213 15:03:01.606432 22509476222784 run_lib.py:133] step: 857950, training_loss: 3.00969e-02
I0213 15:03:20.420501 22509476222784 run_lib.py:133] step: 858000, training_loss: 3.53845e-02
I0213 15:03:20.586088 22509476222784 run_lib.py:146] step: 858000, eval_loss: 5.96118e-02
I0213 15:03:39.556026 22509476222784 run_lib.py:133] step: 858050, training_loss: 4.09419e-02
I0213 15:03:58.304430 22509476222784 run_lib.py:133] step: 858100, training_loss: 5.03160e-02
I0213 15:03:58.470859 22509476222784 run_lib.py:146] step: 858100, eval_loss: 3.61433e-02
I0213 15:04:17.193051 22509476222784 run_lib.py:133] step: 858150, training_loss: 4.84556e-02
I0213 15:04:36.137804 22509476222784 run_lib.py:133] step: 858200, training_loss: 3.95395e-02
I0213 15:04:36.310486 22509476222784 run_lib.py:146] step: 858200, eval_loss: 4.42787e-02
I0213 15:04:55.083483 22509476222784 run_lib.py:133] step: 858250, training_loss: 3.90184e-02
I0213 15:05:14.019007 22509476222784 run_lib.py:133] step: 858300, training_loss: 3.04962e-02
I0213 15:05:14.185969 22509476222784 run_lib.py:146] step: 858300, eval_loss: 4.16775e-02
I0213 15:05:32.991262 22509476222784 run_lib.py:133] step: 858350, training_loss: 4.17164e-02
I0213 15:05:51.749554 22509476222784 run_lib.py:133] step: 858400, training_loss: 3.75759e-02
I0213 15:05:51.916029 22509476222784 run_lib.py:146] step: 858400, eval_loss: 4.21932e-02
I0213 15:06:10.862026 22509476222784 run_lib.py:133] step: 858450, training_loss: 4.11580e-02
I0213 15:06:29.622311 22509476222784 run_lib.py:133] step: 858500, training_loss: 4.55829e-02
I0213 15:06:29.791147 22509476222784 run_lib.py:146] step: 858500, eval_loss: 3.57331e-02
I0213 15:06:48.575336 22509476222784 run_lib.py:133] step: 858550, training_loss: 5.08883e-02
I0213 15:07:07.503508 22509476222784 run_lib.py:133] step: 858600, training_loss: 4.06776e-02
I0213 15:07:07.673227 22509476222784 run_lib.py:146] step: 858600, eval_loss: 3.91166e-02
I0213 15:07:26.354472 22509476222784 run_lib.py:133] step: 858650, training_loss: 3.41129e-02
I0213 15:07:44.954993 22509476222784 run_lib.py:133] step: 858700, training_loss: 3.53717e-02
I0213 15:07:45.284717 22509476222784 run_lib.py:146] step: 858700, eval_loss: 3.59863e-02
I0213 15:08:04.062023 22509476222784 run_lib.py:133] step: 858750, training_loss: 3.10365e-02
I0213 15:08:22.790984 22509476222784 run_lib.py:133] step: 858800, training_loss: 4.73843e-02
I0213 15:08:22.956422 22509476222784 run_lib.py:146] step: 858800, eval_loss: 4.09939e-02
I0213 15:08:41.623537 22509476222784 run_lib.py:133] step: 858850, training_loss: 4.84302e-02
I0213 15:09:00.285583 22509476222784 run_lib.py:133] step: 858900, training_loss: 3.53021e-02
I0213 15:09:00.448810 22509476222784 run_lib.py:146] step: 858900, eval_loss: 4.37540e-02
I0213 15:09:19.323485 22509476222784 run_lib.py:133] step: 858950, training_loss: 3.44358e-02
I0213 15:09:38.152533 22509476222784 run_lib.py:133] step: 859000, training_loss: 4.27352e-02
I0213 15:09:38.329108 22509476222784 run_lib.py:146] step: 859000, eval_loss: 5.07921e-02
I0213 15:09:57.046841 22509476222784 run_lib.py:133] step: 859050, training_loss: 3.97837e-02
I0213 15:10:15.766633 22509476222784 run_lib.py:133] step: 859100, training_loss: 3.95949e-02
I0213 15:10:15.935127 22509476222784 run_lib.py:146] step: 859100, eval_loss: 4.03949e-02
I0213 15:10:34.805764 22509476222784 run_lib.py:133] step: 859150, training_loss: 4.58096e-02
I0213 15:10:53.570221 22509476222784 run_lib.py:133] step: 859200, training_loss: 3.49362e-02
I0213 15:10:53.738544 22509476222784 run_lib.py:146] step: 859200, eval_loss: 4.04245e-02
I0213 15:11:12.421169 22509476222784 run_lib.py:133] step: 859250, training_loss: 3.93239e-02
I0213 15:11:31.176326 22509476222784 run_lib.py:133] step: 859300, training_loss: 3.73698e-02
I0213 15:11:31.344734 22509476222784 run_lib.py:146] step: 859300, eval_loss: 3.95444e-02
I0213 15:11:50.268076 22509476222784 run_lib.py:133] step: 859350, training_loss: 4.74027e-02
I0213 15:12:08.937678 22509476222784 run_lib.py:133] step: 859400, training_loss: 4.75856e-02
I0213 15:12:09.098864 22509476222784 run_lib.py:146] step: 859400, eval_loss: 3.82932e-02
I0213 15:12:27.923589 22509476222784 run_lib.py:133] step: 859450, training_loss: 4.34324e-02
I0213 15:12:46.629910 22509476222784 run_lib.py:133] step: 859500, training_loss: 3.81157e-02
I0213 15:12:46.803274 22509476222784 run_lib.py:146] step: 859500, eval_loss: 5.03493e-02
I0213 15:13:05.799300 22509476222784 run_lib.py:133] step: 859550, training_loss: 3.99523e-02
I0213 15:13:24.574995 22509476222784 run_lib.py:133] step: 859600, training_loss: 3.50806e-02
I0213 15:13:24.742095 22509476222784 run_lib.py:146] step: 859600, eval_loss: 4.78947e-02
I0213 15:13:43.438498 22509476222784 run_lib.py:133] step: 859650, training_loss: 4.31667e-02
I0213 15:14:02.352574 22509476222784 run_lib.py:133] step: 859700, training_loss: 4.07111e-02
I0213 15:14:02.517964 22509476222784 run_lib.py:146] step: 859700, eval_loss: 3.80440e-02
I0213 15:14:21.291364 22509476222784 run_lib.py:133] step: 859750, training_loss: 4.88188e-02
I0213 15:14:40.238169 22509476222784 run_lib.py:133] step: 859800, training_loss: 3.38256e-02
I0213 15:14:40.403952 22509476222784 run_lib.py:146] step: 859800, eval_loss: 4.38011e-02
I0213 15:14:59.175449 22509476222784 run_lib.py:133] step: 859850, training_loss: 3.55159e-02
I0213 15:15:17.935925 22509476222784 run_lib.py:133] step: 859900, training_loss: 4.48000e-02
I0213 15:15:18.098233 22509476222784 run_lib.py:146] step: 859900, eval_loss: 4.42920e-02
I0213 15:15:37.000388 22509476222784 run_lib.py:133] step: 859950, training_loss: 4.70906e-02
I0213 15:15:55.707415 22509476222784 run_lib.py:133] step: 860000, training_loss: 3.06375e-02
I0213 15:15:56.533792 22509476222784 run_lib.py:146] step: 860000, eval_loss: 4.56743e-02
I0213 15:16:18.353124 22509476222784 run_lib.py:133] step: 860050, training_loss: 4.50321e-02
I0213 15:16:37.164694 22509476222784 run_lib.py:133] step: 860100, training_loss: 3.78249e-02
I0213 15:16:37.332828 22509476222784 run_lib.py:146] step: 860100, eval_loss: 3.48941e-02
I0213 15:16:56.009629 22509476222784 run_lib.py:133] step: 860150, training_loss: 3.89158e-02
I0213 15:17:14.693583 22509476222784 run_lib.py:133] step: 860200, training_loss: 4.44488e-02
I0213 15:17:14.859796 22509476222784 run_lib.py:146] step: 860200, eval_loss: 4.41004e-02
I0213 15:17:33.763811 22509476222784 run_lib.py:133] step: 860250, training_loss: 3.17561e-02
I0213 15:17:52.510468 22509476222784 run_lib.py:133] step: 860300, training_loss: 3.85319e-02
I0213 15:17:52.684271 22509476222784 run_lib.py:146] step: 860300, eval_loss: 3.84181e-02
I0213 15:18:11.430170 22509476222784 run_lib.py:133] step: 860350, training_loss: 3.71953e-02
I0213 15:18:30.203374 22509476222784 run_lib.py:133] step: 860400, training_loss: 4.40731e-02
I0213 15:18:30.367477 22509476222784 run_lib.py:146] step: 860400, eval_loss: 4.78830e-02
I0213 15:18:49.325873 22509476222784 run_lib.py:133] step: 860450, training_loss: 3.72974e-02
I0213 15:19:08.072111 22509476222784 run_lib.py:133] step: 860500, training_loss: 4.96638e-02
I0213 15:19:08.255816 22509476222784 run_lib.py:146] step: 860500, eval_loss: 3.61267e-02
I0213 15:19:27.138822 22509476222784 run_lib.py:133] step: 860550, training_loss: 4.97330e-02
I0213 15:19:45.921609 22509476222784 run_lib.py:133] step: 860600, training_loss: 4.21861e-02
I0213 15:19:46.100543 22509476222784 run_lib.py:146] step: 860600, eval_loss: 4.02599e-02
I0213 15:20:05.108764 22509476222784 run_lib.py:133] step: 860650, training_loss: 5.36912e-02
I0213 15:20:23.898360 22509476222784 run_lib.py:133] step: 860700, training_loss: 4.47807e-02
I0213 15:20:24.065829 22509476222784 run_lib.py:146] step: 860700, eval_loss: 3.14970e-02
I0213 15:20:42.784847 22509476222784 run_lib.py:133] step: 860750, training_loss: 5.55050e-02
I0213 15:21:01.625996 22509476222784 run_lib.py:133] step: 860800, training_loss: 4.68071e-02
I0213 15:21:01.794839 22509476222784 run_lib.py:146] step: 860800, eval_loss: 4.19980e-02
I0213 15:21:20.566814 22509476222784 run_lib.py:133] step: 860850, training_loss: 4.43958e-02
I0213 15:21:39.513456 22509476222784 run_lib.py:133] step: 860900, training_loss: 4.61300e-02
I0213 15:21:39.677071 22509476222784 run_lib.py:146] step: 860900, eval_loss: 4.63244e-02
I0213 15:21:58.389932 22509476222784 run_lib.py:133] step: 860950, training_loss: 3.48498e-02
I0213 15:22:17.049266 22509476222784 run_lib.py:133] step: 861000, training_loss: 4.09155e-02
I0213 15:22:17.214959 22509476222784 run_lib.py:146] step: 861000, eval_loss: 4.59200e-02
I0213 15:22:36.057668 22509476222784 run_lib.py:133] step: 861050, training_loss: 4.37620e-02
I0213 15:22:54.860508 22509476222784 run_lib.py:133] step: 861100, training_loss: 4.25950e-02
I0213 15:22:55.050907 22509476222784 run_lib.py:146] step: 861100, eval_loss: 2.53217e-02
I0213 15:23:13.833501 22509476222784 run_lib.py:133] step: 861150, training_loss: 3.64341e-02
I0213 15:23:32.574278 22509476222784 run_lib.py:133] step: 861200, training_loss: 4.40219e-02
I0213 15:23:32.741699 22509476222784 run_lib.py:146] step: 861200, eval_loss: 3.51277e-02
I0213 15:23:51.696516 22509476222784 run_lib.py:133] step: 861250, training_loss: 4.84871e-02
I0213 15:24:10.413750 22509476222784 run_lib.py:133] step: 861300, training_loss: 3.29891e-02
I0213 15:24:10.579103 22509476222784 run_lib.py:146] step: 861300, eval_loss: 6.07731e-02
I0213 15:24:29.345578 22509476222784 run_lib.py:133] step: 861350, training_loss: 4.52644e-02
I0213 15:24:48.108104 22509476222784 run_lib.py:133] step: 861400, training_loss: 4.14186e-02
I0213 15:24:48.276235 22509476222784 run_lib.py:146] step: 861400, eval_loss: 4.68101e-02
I0213 15:25:07.064429 22509476222784 run_lib.py:133] step: 861450, training_loss: 4.25569e-02
I0213 15:25:25.842191 22509476222784 run_lib.py:133] step: 861500, training_loss: 4.43063e-02
I0213 15:25:26.016690 22509476222784 run_lib.py:146] step: 861500, eval_loss: 3.61783e-02
I0213 15:25:44.906909 22509476222784 run_lib.py:133] step: 861550, training_loss: 4.34133e-02
I0213 15:26:03.729858 22509476222784 run_lib.py:133] step: 861600, training_loss: 4.61821e-02
I0213 15:26:03.912756 22509476222784 run_lib.py:146] step: 861600, eval_loss: 4.29909e-02
I0213 15:26:22.696820 22509476222784 run_lib.py:133] step: 861650, training_loss: 2.68098e-02
I0213 15:26:41.520418 22509476222784 run_lib.py:133] step: 861700, training_loss: 4.98050e-02
I0213 15:26:41.692120 22509476222784 run_lib.py:146] step: 861700, eval_loss: 3.48375e-02
I0213 15:27:00.611766 22509476222784 run_lib.py:133] step: 861750, training_loss: 3.93685e-02
I0213 15:27:19.295300 22509476222784 run_lib.py:133] step: 861800, training_loss: 3.95484e-02
I0213 15:27:19.460036 22509476222784 run_lib.py:146] step: 861800, eval_loss: 4.83668e-02
I0213 15:27:38.264827 22509476222784 run_lib.py:133] step: 861850, training_loss: 4.72988e-02
I0213 15:27:57.001102 22509476222784 run_lib.py:133] step: 861900, training_loss: 3.89812e-02
I0213 15:27:57.170017 22509476222784 run_lib.py:146] step: 861900, eval_loss: 4.17376e-02
I0213 15:28:16.106133 22509476222784 run_lib.py:133] step: 861950, training_loss: 4.20077e-02
I0213 15:28:34.811872 22509476222784 run_lib.py:133] step: 862000, training_loss: 3.54240e-02
I0213 15:28:34.980025 22509476222784 run_lib.py:146] step: 862000, eval_loss: 3.84462e-02
I0213 15:28:53.791238 22509476222784 run_lib.py:133] step: 862050, training_loss: 4.39588e-02
I0213 15:29:12.543876 22509476222784 run_lib.py:133] step: 862100, training_loss: 4.12904e-02
I0213 15:29:12.709097 22509476222784 run_lib.py:146] step: 862100, eval_loss: 4.84068e-02
I0213 15:29:31.487641 22509476222784 run_lib.py:133] step: 862150, training_loss: 3.95507e-02
I0213 15:29:50.447336 22509476222784 run_lib.py:133] step: 862200, training_loss: 3.59615e-02
I0213 15:29:50.622281 22509476222784 run_lib.py:146] step: 862200, eval_loss: 3.91521e-02
I0213 15:30:09.389020 22509476222784 run_lib.py:133] step: 862250, training_loss: 3.51182e-02
I0213 15:30:28.093884 22509476222784 run_lib.py:133] step: 862300, training_loss: 4.18390e-02
I0213 15:30:28.255838 22509476222784 run_lib.py:146] step: 862300, eval_loss: 3.63278e-02
I0213 15:30:47.163827 22509476222784 run_lib.py:133] step: 862350, training_loss: 5.65457e-02
I0213 15:31:06.102941 22509476222784 run_lib.py:133] step: 862400, training_loss: 4.19375e-02
I0213 15:31:06.275312 22509476222784 run_lib.py:146] step: 862400, eval_loss: 4.52943e-02
I0213 15:31:25.096412 22509476222784 run_lib.py:133] step: 862450, training_loss: 3.24048e-02
I0213 15:31:43.880027 22509476222784 run_lib.py:133] step: 862500, training_loss: 3.02062e-02
I0213 15:31:44.048816 22509476222784 run_lib.py:146] step: 862500, eval_loss: 3.86796e-02
I0213 15:32:02.746100 22509476222784 run_lib.py:133] step: 862550, training_loss: 4.30670e-02
I0213 15:32:21.661075 22509476222784 run_lib.py:133] step: 862600, training_loss: 4.07930e-02
I0213 15:32:21.826908 22509476222784 run_lib.py:146] step: 862600, eval_loss: 4.79251e-02
I0213 15:32:40.578555 22509476222784 run_lib.py:133] step: 862650, training_loss: 3.63908e-02
I0213 15:32:59.395107 22509476222784 run_lib.py:133] step: 862700, training_loss: 5.52091e-02
I0213 15:32:59.562049 22509476222784 run_lib.py:146] step: 862700, eval_loss: 4.48364e-02
I0213 15:33:18.334323 22509476222784 run_lib.py:133] step: 862750, training_loss: 3.14070e-02
I0213 15:33:37.190988 22509476222784 run_lib.py:133] step: 862800, training_loss: 4.40258e-02
I0213 15:33:37.353786 22509476222784 run_lib.py:146] step: 862800, eval_loss: 3.04477e-02
I0213 15:33:56.078041 22509476222784 run_lib.py:133] step: 862850, training_loss: 4.82770e-02
I0213 15:34:14.863092 22509476222784 run_lib.py:133] step: 862900, training_loss: 3.37059e-02
I0213 15:34:15.042094 22509476222784 run_lib.py:146] step: 862900, eval_loss: 3.94278e-02
I0213 15:34:33.815013 22509476222784 run_lib.py:133] step: 862950, training_loss: 4.95950e-02
I0213 15:34:52.594634 22509476222784 run_lib.py:133] step: 863000, training_loss: 3.75650e-02
I0213 15:34:52.763466 22509476222784 run_lib.py:146] step: 863000, eval_loss: 5.20785e-02
I0213 15:35:11.655586 22509476222784 run_lib.py:133] step: 863050, training_loss: 3.80573e-02
I0213 15:35:30.398897 22509476222784 run_lib.py:133] step: 863100, training_loss: 4.19022e-02
I0213 15:35:30.564945 22509476222784 run_lib.py:146] step: 863100, eval_loss: 5.18134e-02
I0213 15:35:49.250173 22509476222784 run_lib.py:133] step: 863150, training_loss: 3.45784e-02
I0213 15:36:07.979742 22509476222784 run_lib.py:133] step: 863200, training_loss: 3.21773e-02
I0213 15:36:08.147002 22509476222784 run_lib.py:146] step: 863200, eval_loss: 4.79578e-02
I0213 15:36:27.117407 22509476222784 run_lib.py:133] step: 863250, training_loss: 3.77677e-02
I0213 15:36:45.848117 22509476222784 run_lib.py:133] step: 863300, training_loss: 2.98258e-02
I0213 15:36:46.011952 22509476222784 run_lib.py:146] step: 863300, eval_loss: 3.17183e-02
I0213 15:37:04.862458 22509476222784 run_lib.py:133] step: 863350, training_loss: 2.91358e-02
I0213 15:37:23.593972 22509476222784 run_lib.py:133] step: 863400, training_loss: 4.30783e-02
I0213 15:37:23.770868 22509476222784 run_lib.py:146] step: 863400, eval_loss: 4.69888e-02
I0213 15:37:42.813403 22509476222784 run_lib.py:133] step: 863450, training_loss: 4.74281e-02
I0213 15:38:01.598571 22509476222784 run_lib.py:133] step: 863500, training_loss: 3.70252e-02
I0213 15:38:01.767998 22509476222784 run_lib.py:146] step: 863500, eval_loss: 4.29598e-02
I0213 15:38:20.525087 22509476222784 run_lib.py:133] step: 863550, training_loss: 4.76779e-02
I0213 15:38:39.433219 22509476222784 run_lib.py:133] step: 863600, training_loss: 4.02836e-02
I0213 15:38:39.598989 22509476222784 run_lib.py:146] step: 863600, eval_loss: 4.28809e-02
I0213 15:38:58.315582 22509476222784 run_lib.py:133] step: 863650, training_loss: 4.91040e-02
I0213 15:39:17.280243 22509476222784 run_lib.py:133] step: 863700, training_loss: 4.55848e-02
I0213 15:39:17.446328 22509476222784 run_lib.py:146] step: 863700, eval_loss: 4.17183e-02
I0213 15:39:36.205098 22509476222784 run_lib.py:133] step: 863750, training_loss: 4.16143e-02
I0213 15:39:54.912549 22509476222784 run_lib.py:133] step: 863800, training_loss: 3.14385e-02
I0213 15:39:55.076801 22509476222784 run_lib.py:146] step: 863800, eval_loss: 3.19826e-02
I0213 15:40:14.018957 22509476222784 run_lib.py:133] step: 863850, training_loss: 3.49706e-02
I0213 15:40:32.758611 22509476222784 run_lib.py:133] step: 863900, training_loss: 5.61637e-02
I0213 15:40:32.927184 22509476222784 run_lib.py:146] step: 863900, eval_loss: 3.94475e-02
I0213 15:40:51.663662 22509476222784 run_lib.py:133] step: 863950, training_loss: 3.45860e-02
I0213 15:41:10.610552 22509476222784 run_lib.py:133] step: 864000, training_loss: 4.20028e-02
I0213 15:41:10.777274 22509476222784 run_lib.py:146] step: 864000, eval_loss: 3.56707e-02
I0213 15:41:29.517435 22509476222784 run_lib.py:133] step: 864050, training_loss: 3.45973e-02
I0213 15:41:48.198311 22509476222784 run_lib.py:133] step: 864100, training_loss: 3.57956e-02
I0213 15:41:48.364616 22509476222784 run_lib.py:146] step: 864100, eval_loss: 4.70253e-02
I0213 15:42:07.134523 22509476222784 run_lib.py:133] step: 864150, training_loss: 4.42752e-02
I0213 15:42:25.771348 22509476222784 run_lib.py:133] step: 864200, training_loss: 3.13892e-02
I0213 15:42:25.931631 22509476222784 run_lib.py:146] step: 864200, eval_loss: 4.05965e-02
I0213 15:42:44.652255 22509476222784 run_lib.py:133] step: 864250, training_loss: 3.94780e-02
I0213 15:43:03.394738 22509476222784 run_lib.py:133] step: 864300, training_loss: 3.94193e-02
I0213 15:43:03.564960 22509476222784 run_lib.py:146] step: 864300, eval_loss: 4.84691e-02
I0213 15:43:22.515906 22509476222784 run_lib.py:133] step: 864350, training_loss: 4.28250e-02
I0213 15:43:41.365582 22509476222784 run_lib.py:133] step: 864400, training_loss: 3.43884e-02
I0213 15:43:41.532184 22509476222784 run_lib.py:146] step: 864400, eval_loss: 3.76249e-02
I0213 15:44:00.216608 22509476222784 run_lib.py:133] step: 864450, training_loss: 4.77142e-02
I0213 15:44:18.990087 22509476222784 run_lib.py:133] step: 864500, training_loss: 2.81339e-02
I0213 15:44:19.164849 22509476222784 run_lib.py:146] step: 864500, eval_loss: 3.59845e-02
I0213 15:44:38.088074 22509476222784 run_lib.py:133] step: 864550, training_loss: 2.98657e-02
I0213 15:44:56.881628 22509476222784 run_lib.py:133] step: 864600, training_loss: 4.60327e-02
I0213 15:44:57.047824 22509476222784 run_lib.py:146] step: 864600, eval_loss: 3.99174e-02
I0213 15:45:15.988579 22509476222784 run_lib.py:133] step: 864650, training_loss: 4.64218e-02
I0213 15:45:34.709513 22509476222784 run_lib.py:133] step: 864700, training_loss: 4.64475e-02
I0213 15:45:34.871823 22509476222784 run_lib.py:146] step: 864700, eval_loss: 5.53660e-02
I0213 15:45:53.724184 22509476222784 run_lib.py:133] step: 864750, training_loss: 4.60470e-02
I0213 15:46:12.474630 22509476222784 run_lib.py:133] step: 864800, training_loss: 3.39174e-02
I0213 15:46:12.644056 22509476222784 run_lib.py:146] step: 864800, eval_loss: 3.55257e-02
I0213 15:46:31.564785 22509476222784 run_lib.py:133] step: 864850, training_loss: 4.03579e-02
I0213 15:46:50.363001 22509476222784 run_lib.py:133] step: 864900, training_loss: 3.76337e-02
I0213 15:46:50.594902 22509476222784 run_lib.py:146] step: 864900, eval_loss: 5.60990e-02
I0213 15:47:09.271508 22509476222784 run_lib.py:133] step: 864950, training_loss: 4.07155e-02
I0213 15:47:28.219001 22509476222784 run_lib.py:133] step: 865000, training_loss: 4.06545e-02
I0213 15:47:28.385148 22509476222784 run_lib.py:146] step: 865000, eval_loss: 4.86877e-02
I0213 15:47:47.103685 22509476222784 run_lib.py:133] step: 865050, training_loss: 3.10388e-02
I0213 15:48:05.902190 22509476222784 run_lib.py:133] step: 865100, training_loss: 4.49671e-02
I0213 15:48:06.067834 22509476222784 run_lib.py:146] step: 865100, eval_loss: 4.01590e-02
I0213 15:48:25.022837 22509476222784 run_lib.py:133] step: 865150, training_loss: 6.31029e-02
I0213 15:48:43.728383 22509476222784 run_lib.py:133] step: 865200, training_loss: 2.94803e-02
I0213 15:48:43.890919 22509476222784 run_lib.py:146] step: 865200, eval_loss: 3.78235e-02
I0213 15:49:02.754284 22509476222784 run_lib.py:133] step: 865250, training_loss: 3.42318e-02
I0213 15:49:21.533701 22509476222784 run_lib.py:133] step: 865300, training_loss: 3.82926e-02
I0213 15:49:21.703809 22509476222784 run_lib.py:146] step: 865300, eval_loss: 3.44620e-02
I0213 15:49:40.480706 22509476222784 run_lib.py:133] step: 865350, training_loss: 4.33740e-02
I0213 15:49:59.470861 22509476222784 run_lib.py:133] step: 865400, training_loss: 4.54096e-02
I0213 15:49:59.643980 22509476222784 run_lib.py:146] step: 865400, eval_loss: 4.92943e-02
I0213 15:50:18.354608 22509476222784 run_lib.py:133] step: 865450, training_loss: 4.56259e-02
I0213 15:50:37.050374 22509476222784 run_lib.py:133] step: 865500, training_loss: 3.52975e-02
I0213 15:50:37.221561 22509476222784 run_lib.py:146] step: 865500, eval_loss: 4.02631e-02
I0213 15:50:55.933644 22509476222784 run_lib.py:133] step: 865550, training_loss: 3.22096e-02
I0213 15:51:14.914593 22509476222784 run_lib.py:133] step: 865600, training_loss: 4.31461e-02
I0213 15:51:15.095023 22509476222784 run_lib.py:146] step: 865600, eval_loss: 3.13022e-02
I0213 15:51:33.883514 22509476222784 run_lib.py:133] step: 865650, training_loss: 4.40544e-02
I0213 15:51:52.699913 22509476222784 run_lib.py:133] step: 865700, training_loss: 4.36838e-02
I0213 15:51:52.862779 22509476222784 run_lib.py:146] step: 865700, eval_loss: 4.97429e-02
I0213 15:52:11.607151 22509476222784 run_lib.py:133] step: 865750, training_loss: 4.46028e-02
I0213 15:52:30.342389 22509476222784 run_lib.py:133] step: 865800, training_loss: 4.28400e-02
I0213 15:52:30.509001 22509476222784 run_lib.py:146] step: 865800, eval_loss: 5.83830e-02
I0213 15:52:49.311556 22509476222784 run_lib.py:133] step: 865850, training_loss: 4.24930e-02
I0213 15:53:08.228682 22509476222784 run_lib.py:133] step: 865900, training_loss: 4.14852e-02
I0213 15:53:08.396407 22509476222784 run_lib.py:146] step: 865900, eval_loss: 4.49389e-02
I0213 15:53:27.135632 22509476222784 run_lib.py:133] step: 865950, training_loss: 4.09844e-02
I0213 15:53:45.899290 22509476222784 run_lib.py:133] step: 866000, training_loss: 4.44023e-02
I0213 15:53:46.067139 22509476222784 run_lib.py:146] step: 866000, eval_loss: 3.55987e-02
I0213 15:54:04.980762 22509476222784 run_lib.py:133] step: 866050, training_loss: 2.76823e-02
I0213 15:54:23.727730 22509476222784 run_lib.py:133] step: 866100, training_loss: 4.96155e-02
I0213 15:54:23.892162 22509476222784 run_lib.py:146] step: 866100, eval_loss: 3.88807e-02
I0213 15:54:42.801501 22509476222784 run_lib.py:133] step: 866150, training_loss: 4.88348e-02
I0213 15:55:01.518962 22509476222784 run_lib.py:133] step: 866200, training_loss: 5.25634e-02
I0213 15:55:01.685117 22509476222784 run_lib.py:146] step: 866200, eval_loss: 4.34539e-02
I0213 15:55:20.612766 22509476222784 run_lib.py:133] step: 866250, training_loss: 3.62129e-02
I0213 15:55:39.328497 22509476222784 run_lib.py:133] step: 866300, training_loss: 3.81646e-02
I0213 15:55:39.496010 22509476222784 run_lib.py:146] step: 866300, eval_loss: 5.30492e-02
I0213 15:55:58.177087 22509476222784 run_lib.py:133] step: 866350, training_loss: 4.08773e-02
I0213 15:56:17.119121 22509476222784 run_lib.py:133] step: 866400, training_loss: 4.82435e-02
I0213 15:56:17.296100 22509476222784 run_lib.py:146] step: 866400, eval_loss: 3.88307e-02
I0213 15:56:35.997675 22509476222784 run_lib.py:133] step: 866450, training_loss: 4.85070e-02
I0213 15:56:54.949658 22509476222784 run_lib.py:133] step: 866500, training_loss: 4.14528e-02
I0213 15:56:55.115147 22509476222784 run_lib.py:146] step: 866500, eval_loss: 3.71828e-02
I0213 15:57:13.807647 22509476222784 run_lib.py:133] step: 866550, training_loss: 4.53753e-02
I0213 15:57:32.486039 22509476222784 run_lib.py:133] step: 866600, training_loss: 4.38955e-02
I0213 15:57:32.647774 22509476222784 run_lib.py:146] step: 866600, eval_loss: 4.28100e-02
I0213 15:57:51.614058 22509476222784 run_lib.py:133] step: 866650, training_loss: 4.32002e-02
I0213 15:58:10.383121 22509476222784 run_lib.py:133] step: 866700, training_loss: 4.43949e-02
I0213 15:58:10.551167 22509476222784 run_lib.py:146] step: 866700, eval_loss: 3.69964e-02
I0213 15:58:29.276644 22509476222784 run_lib.py:133] step: 866750, training_loss: 4.65706e-02
I0213 15:58:48.190116 22509476222784 run_lib.py:133] step: 866800, training_loss: 6.17663e-02
I0213 15:58:48.362297 22509476222784 run_lib.py:146] step: 866800, eval_loss: 4.06997e-02
I0213 15:59:07.065593 22509476222784 run_lib.py:133] step: 866850, training_loss: 4.55249e-02
I0213 15:59:25.872021 22509476222784 run_lib.py:133] step: 866900, training_loss: 4.93218e-02
I0213 15:59:26.206993 22509476222784 run_lib.py:146] step: 866900, eval_loss: 4.69835e-02
I0213 15:59:44.942409 22509476222784 run_lib.py:133] step: 866950, training_loss: 4.18568e-02
I0213 16:00:03.628098 22509476222784 run_lib.py:133] step: 867000, training_loss: 3.90732e-02
I0213 16:00:03.793843 22509476222784 run_lib.py:146] step: 867000, eval_loss: 3.18219e-02
I0213 16:00:22.495232 22509476222784 run_lib.py:133] step: 867050, training_loss: 4.01547e-02
I0213 16:00:41.262357 22509476222784 run_lib.py:133] step: 867100, training_loss: 3.31310e-02
I0213 16:00:41.432191 22509476222784 run_lib.py:146] step: 867100, eval_loss: 5.20781e-02
I0213 16:01:00.456507 22509476222784 run_lib.py:133] step: 867150, training_loss: 4.77799e-02
I0213 16:01:19.278977 22509476222784 run_lib.py:133] step: 867200, training_loss: 4.08830e-02
I0213 16:01:19.458892 22509476222784 run_lib.py:146] step: 867200, eval_loss: 4.26918e-02
I0213 16:01:38.150158 22509476222784 run_lib.py:133] step: 867250, training_loss: 4.89324e-02
I0213 16:01:56.897753 22509476222784 run_lib.py:133] step: 867300, training_loss: 3.71724e-02
I0213 16:01:57.073936 22509476222784 run_lib.py:146] step: 867300, eval_loss: 4.48982e-02
I0213 16:02:15.979928 22509476222784 run_lib.py:133] step: 867350, training_loss: 3.66297e-02
I0213 16:02:34.859549 22509476222784 run_lib.py:133] step: 867400, training_loss: 4.70302e-02
I0213 16:02:35.036006 22509476222784 run_lib.py:146] step: 867400, eval_loss: 4.85390e-02
I0213 16:02:53.800556 22509476222784 run_lib.py:133] step: 867450, training_loss: 4.28855e-02
I0213 16:03:12.565195 22509476222784 run_lib.py:133] step: 867500, training_loss: 4.82800e-02
I0213 16:03:12.726913 22509476222784 run_lib.py:146] step: 867500, eval_loss: 4.02567e-02
I0213 16:03:31.674921 22509476222784 run_lib.py:133] step: 867550, training_loss: 3.32648e-02
I0213 16:03:50.360130 22509476222784 run_lib.py:133] step: 867600, training_loss: 4.53787e-02
I0213 16:03:50.522781 22509476222784 run_lib.py:146] step: 867600, eval_loss: 3.85144e-02
I0213 16:04:09.415839 22509476222784 run_lib.py:133] step: 867650, training_loss: 4.39081e-02
I0213 16:04:28.198815 22509476222784 run_lib.py:133] step: 867700, training_loss: 3.24205e-02
I0213 16:04:28.377795 22509476222784 run_lib.py:146] step: 867700, eval_loss: 4.17774e-02
I0213 16:04:47.319424 22509476222784 run_lib.py:133] step: 867750, training_loss: 3.70267e-02
I0213 16:05:06.069187 22509476222784 run_lib.py:133] step: 867800, training_loss: 3.38203e-02
I0213 16:05:06.234786 22509476222784 run_lib.py:146] step: 867800, eval_loss: 4.27918e-02
I0213 16:05:25.003085 22509476222784 run_lib.py:133] step: 867850, training_loss: 4.21555e-02
I0213 16:05:43.888180 22509476222784 run_lib.py:133] step: 867900, training_loss: 3.17791e-02
I0213 16:05:44.064579 22509476222784 run_lib.py:146] step: 867900, eval_loss: 3.83327e-02
I0213 16:06:02.823925 22509476222784 run_lib.py:133] step: 867950, training_loss: 3.49369e-02
I0213 16:06:21.784179 22509476222784 run_lib.py:133] step: 868000, training_loss: 5.89795e-02
I0213 16:06:21.947423 22509476222784 run_lib.py:146] step: 868000, eval_loss: 4.19635e-02
I0213 16:06:40.722141 22509476222784 run_lib.py:133] step: 868050, training_loss: 3.17666e-02
I0213 16:06:59.445243 22509476222784 run_lib.py:133] step: 868100, training_loss: 3.02235e-02
I0213 16:06:59.610748 22509476222784 run_lib.py:146] step: 868100, eval_loss: 3.28265e-02
I0213 16:07:18.446650 22509476222784 run_lib.py:133] step: 868150, training_loss: 3.13077e-02
I0213 16:07:37.235848 22509476222784 run_lib.py:133] step: 868200, training_loss: 5.77185e-02
I0213 16:07:37.418750 22509476222784 run_lib.py:146] step: 868200, eval_loss: 3.86645e-02
I0213 16:07:56.191406 22509476222784 run_lib.py:133] step: 868250, training_loss: 3.10193e-02
I0213 16:08:14.961195 22509476222784 run_lib.py:133] step: 868300, training_loss: 4.54907e-02
I0213 16:08:15.127333 22509476222784 run_lib.py:146] step: 868300, eval_loss: 4.67791e-02
I0213 16:08:34.080742 22509476222784 run_lib.py:133] step: 868350, training_loss: 5.28565e-02
I0213 16:08:52.770220 22509476222784 run_lib.py:133] step: 868400, training_loss: 4.64759e-02
I0213 16:08:52.937866 22509476222784 run_lib.py:146] step: 868400, eval_loss: 3.76768e-02
I0213 16:09:11.738480 22509476222784 run_lib.py:133] step: 868450, training_loss: 3.88065e-02
I0213 16:09:30.535614 22509476222784 run_lib.py:133] step: 868500, training_loss: 3.56657e-02
I0213 16:09:30.702050 22509476222784 run_lib.py:146] step: 868500, eval_loss: 5.49699e-02
I0213 16:09:49.471405 22509476222784 run_lib.py:133] step: 868550, training_loss: 3.98831e-02
I0213 16:10:08.180200 22509476222784 run_lib.py:133] step: 868600, training_loss: 4.63520e-02
I0213 16:10:08.345808 22509476222784 run_lib.py:146] step: 868600, eval_loss: 5.68012e-02
I0213 16:10:27.261606 22509476222784 run_lib.py:133] step: 868650, training_loss: 4.88618e-02
I0213 16:10:46.077229 22509476222784 run_lib.py:133] step: 868700, training_loss: 4.29735e-02
I0213 16:10:46.261028 22509476222784 run_lib.py:146] step: 868700, eval_loss: 3.32351e-02
I0213 16:11:05.045901 22509476222784 run_lib.py:133] step: 868750, training_loss: 5.17710e-02
I0213 16:11:23.783068 22509476222784 run_lib.py:133] step: 868800, training_loss: 4.98578e-02
I0213 16:11:23.983808 22509476222784 run_lib.py:146] step: 868800, eval_loss: 4.35902e-02
I0213 16:11:42.896210 22509476222784 run_lib.py:133] step: 868850, training_loss: 4.94003e-02
I0213 16:12:01.592119 22509476222784 run_lib.py:133] step: 868900, training_loss: 3.83010e-02
I0213 16:12:01.756202 22509476222784 run_lib.py:146] step: 868900, eval_loss: 3.45566e-02
I0213 16:12:20.632085 22509476222784 run_lib.py:133] step: 868950, training_loss: 3.79659e-02
I0213 16:12:39.384677 22509476222784 run_lib.py:133] step: 869000, training_loss: 5.06911e-02
I0213 16:12:39.552075 22509476222784 run_lib.py:146] step: 869000, eval_loss: 4.45217e-02
I0213 16:12:58.535167 22509476222784 run_lib.py:133] step: 869050, training_loss: 3.33147e-02
I0213 16:13:17.281534 22509476222784 run_lib.py:133] step: 869100, training_loss: 5.33734e-02
I0213 16:13:17.449324 22509476222784 run_lib.py:146] step: 869100, eval_loss: 4.61255e-02
I0213 16:13:36.328856 22509476222784 run_lib.py:133] step: 869150, training_loss: 4.33222e-02
I0213 16:13:55.063197 22509476222784 run_lib.py:133] step: 869200, training_loss: 4.81215e-02
I0213 16:13:55.244324 22509476222784 run_lib.py:146] step: 869200, eval_loss: 5.22666e-02
I0213 16:14:14.010694 22509476222784 run_lib.py:133] step: 869250, training_loss: 3.47424e-02
I0213 16:14:32.952015 22509476222784 run_lib.py:133] step: 869300, training_loss: 6.09963e-02
I0213 16:14:33.126045 22509476222784 run_lib.py:146] step: 869300, eval_loss: 5.24777e-02
I0213 16:14:51.872673 22509476222784 run_lib.py:133] step: 869350, training_loss: 5.50933e-02
I0213 16:15:10.623040 22509476222784 run_lib.py:133] step: 869400, training_loss: 3.45537e-02
I0213 16:15:10.785518 22509476222784 run_lib.py:146] step: 869400, eval_loss: 3.83489e-02
I0213 16:15:29.662797 22509476222784 run_lib.py:133] step: 869450, training_loss: 4.68488e-02
I0213 16:15:48.640781 22509476222784 run_lib.py:133] step: 869500, training_loss: 3.82580e-02
I0213 16:15:48.810076 22509476222784 run_lib.py:146] step: 869500, eval_loss: 4.53117e-02
I0213 16:16:07.540245 22509476222784 run_lib.py:133] step: 869550, training_loss: 5.21357e-02
I0213 16:16:26.291187 22509476222784 run_lib.py:133] step: 869600, training_loss: 3.34603e-02
I0213 16:16:26.460033 22509476222784 run_lib.py:146] step: 869600, eval_loss: 4.34287e-02
I0213 16:16:45.192206 22509476222784 run_lib.py:133] step: 869650, training_loss: 4.14830e-02
I0213 16:17:04.041364 22509476222784 run_lib.py:133] step: 869700, training_loss: 4.19749e-02
I0213 16:17:04.206904 22509476222784 run_lib.py:146] step: 869700, eval_loss: 4.44822e-02
I0213 16:17:22.907598 22509476222784 run_lib.py:133] step: 869750, training_loss: 4.55652e-02
I0213 16:17:41.692814 22509476222784 run_lib.py:133] step: 869800, training_loss: 3.51879e-02
I0213 16:17:41.860591 22509476222784 run_lib.py:146] step: 869800, eval_loss: 4.26647e-02
I0213 16:18:00.647938 22509476222784 run_lib.py:133] step: 869850, training_loss: 4.70948e-02
I0213 16:18:19.599702 22509476222784 run_lib.py:133] step: 869900, training_loss: 3.90798e-02
I0213 16:18:19.769819 22509476222784 run_lib.py:146] step: 869900, eval_loss: 3.48217e-02
I0213 16:18:38.459571 22509476222784 run_lib.py:133] step: 869950, training_loss: 3.75898e-02
I0213 16:18:57.276401 22509476222784 run_lib.py:133] step: 870000, training_loss: 4.19162e-02
I0213 16:18:58.061496 22509476222784 run_lib.py:146] step: 870000, eval_loss: 4.65120e-02
I0213 16:19:19.533453 22509476222784 run_lib.py:133] step: 870050, training_loss: 3.25469e-02
I0213 16:19:38.298092 22509476222784 run_lib.py:133] step: 870100, training_loss: 4.62069e-02
I0213 16:19:38.466949 22509476222784 run_lib.py:146] step: 870100, eval_loss: 4.20028e-02
I0213 16:19:57.166442 22509476222784 run_lib.py:133] step: 870150, training_loss: 4.94179e-02
I0213 16:20:16.126760 22509476222784 run_lib.py:133] step: 870200, training_loss: 2.42322e-02
I0213 16:20:16.295131 22509476222784 run_lib.py:146] step: 870200, eval_loss: 2.78687e-02
I0213 16:20:35.041902 22509476222784 run_lib.py:133] step: 870250, training_loss: 3.43389e-02
I0213 16:20:53.819535 22509476222784 run_lib.py:133] step: 870300, training_loss: 2.72126e-02
I0213 16:20:53.997872 22509476222784 run_lib.py:146] step: 870300, eval_loss: 4.09505e-02
I0213 16:21:12.734064 22509476222784 run_lib.py:133] step: 870350, training_loss: 4.01555e-02
I0213 16:21:31.488322 22509476222784 run_lib.py:133] step: 870400, training_loss: 4.48495e-02
I0213 16:21:31.669044 22509476222784 run_lib.py:146] step: 870400, eval_loss: 4.87275e-02
I0213 16:21:50.633048 22509476222784 run_lib.py:133] step: 870450, training_loss: 4.74694e-02
I0213 16:22:09.428184 22509476222784 run_lib.py:133] step: 870500, training_loss: 3.46126e-02
I0213 16:22:09.592020 22509476222784 run_lib.py:146] step: 870500, eval_loss: 3.40791e-02
I0213 16:22:28.305811 22509476222784 run_lib.py:133] step: 870550, training_loss: 5.04738e-02
I0213 16:22:47.067692 22509476222784 run_lib.py:133] step: 870600, training_loss: 4.13969e-02
I0213 16:22:47.249792 22509476222784 run_lib.py:146] step: 870600, eval_loss: 4.13589e-02
I0213 16:23:06.231522 22509476222784 run_lib.py:133] step: 870650, training_loss: 4.39155e-02
I0213 16:23:24.987174 22509476222784 run_lib.py:133] step: 870700, training_loss: 3.90389e-02
I0213 16:23:25.164834 22509476222784 run_lib.py:146] step: 870700, eval_loss: 3.46700e-02
I0213 16:23:44.052054 22509476222784 run_lib.py:133] step: 870750, training_loss: 4.46730e-02
I0213 16:24:02.808490 22509476222784 run_lib.py:133] step: 870800, training_loss: 4.48237e-02
I0213 16:24:02.995567 22509476222784 run_lib.py:146] step: 870800, eval_loss: 4.70571e-02
I0213 16:24:21.936172 22509476222784 run_lib.py:133] step: 870850, training_loss: 4.66652e-02
I0213 16:24:40.707161 22509476222784 run_lib.py:133] step: 870900, training_loss: 4.44049e-02
I0213 16:24:40.877575 22509476222784 run_lib.py:146] step: 870900, eval_loss: 4.93652e-02
I0213 16:24:59.626177 22509476222784 run_lib.py:133] step: 870950, training_loss: 3.60548e-02
I0213 16:25:18.535823 22509476222784 run_lib.py:133] step: 871000, training_loss: 4.90341e-02
I0213 16:25:18.699850 22509476222784 run_lib.py:146] step: 871000, eval_loss: 4.61984e-02
I0213 16:25:37.464324 22509476222784 run_lib.py:133] step: 871050, training_loss: 3.44227e-02
I0213 16:25:56.332677 22509476222784 run_lib.py:133] step: 871100, training_loss: 4.38956e-02
I0213 16:25:56.515049 22509476222784 run_lib.py:146] step: 871100, eval_loss: 3.26949e-02
I0213 16:26:15.242620 22509476222784 run_lib.py:133] step: 871150, training_loss: 4.20871e-02
I0213 16:26:33.973166 22509476222784 run_lib.py:133] step: 871200, training_loss: 5.01873e-02
I0213 16:26:34.141165 22509476222784 run_lib.py:146] step: 871200, eval_loss: 4.37002e-02
I0213 16:26:53.069925 22509476222784 run_lib.py:133] step: 871250, training_loss: 5.51243e-02
I0213 16:27:11.723298 22509476222784 run_lib.py:133] step: 871300, training_loss: 3.33045e-02
I0213 16:27:11.889742 22509476222784 run_lib.py:146] step: 871300, eval_loss: 4.46485e-02
I0213 16:27:30.576278 22509476222784 run_lib.py:133] step: 871350, training_loss: 3.93811e-02
I0213 16:27:49.461440 22509476222784 run_lib.py:133] step: 871400, training_loss: 4.76993e-02
I0213 16:27:49.626735 22509476222784 run_lib.py:146] step: 871400, eval_loss: 3.45432e-02
I0213 16:28:08.412391 22509476222784 run_lib.py:133] step: 871450, training_loss: 4.31647e-02
I0213 16:28:27.139025 22509476222784 run_lib.py:133] step: 871500, training_loss: 4.39449e-02
I0213 16:28:27.307897 22509476222784 run_lib.py:146] step: 871500, eval_loss: 4.43263e-02
I0213 16:28:46.090240 22509476222784 run_lib.py:133] step: 871550, training_loss: 3.13321e-02
I0213 16:29:04.821944 22509476222784 run_lib.py:133] step: 871600, training_loss: 4.27192e-02
I0213 16:29:04.996073 22509476222784 run_lib.py:146] step: 871600, eval_loss: 5.42625e-02
I0213 16:29:23.736054 22509476222784 run_lib.py:133] step: 871650, training_loss: 3.87413e-02
I0213 16:29:42.505100 22509476222784 run_lib.py:133] step: 871700, training_loss: 4.41785e-02
I0213 16:29:42.670926 22509476222784 run_lib.py:146] step: 871700, eval_loss: 4.11284e-02
I0213 16:30:01.546195 22509476222784 run_lib.py:133] step: 871750, training_loss: 4.23901e-02
I0213 16:30:20.381509 22509476222784 run_lib.py:133] step: 871800, training_loss: 5.72967e-02
I0213 16:30:20.545730 22509476222784 run_lib.py:146] step: 871800, eval_loss: 3.44882e-02
I0213 16:30:39.326873 22509476222784 run_lib.py:133] step: 871850, training_loss: 3.92513e-02
I0213 16:30:58.063802 22509476222784 run_lib.py:133] step: 871900, training_loss: 3.79900e-02
I0213 16:30:58.231973 22509476222784 run_lib.py:146] step: 871900, eval_loss: 4.30695e-02
I0213 16:31:17.092156 22509476222784 run_lib.py:133] step: 871950, training_loss: 4.64806e-02
I0213 16:31:35.887676 22509476222784 run_lib.py:133] step: 872000, training_loss: 3.35878e-02
I0213 16:31:36.157806 22509476222784 run_lib.py:146] step: 872000, eval_loss: 3.69388e-02
I0213 16:31:55.137799 22509476222784 run_lib.py:133] step: 872050, training_loss: 3.55507e-02
I0213 16:32:13.919878 22509476222784 run_lib.py:133] step: 872100, training_loss: 4.04145e-02
I0213 16:32:14.087042 22509476222784 run_lib.py:146] step: 872100, eval_loss: 3.43493e-02
I0213 16:32:32.939696 22509476222784 run_lib.py:133] step: 872150, training_loss: 4.28753e-02
I0213 16:32:51.675067 22509476222784 run_lib.py:133] step: 872200, training_loss: 3.86929e-02
I0213 16:32:51.851794 22509476222784 run_lib.py:146] step: 872200, eval_loss: 3.52335e-02
I0213 16:33:10.760177 22509476222784 run_lib.py:133] step: 872250, training_loss: 3.54691e-02
I0213 16:33:29.599864 22509476222784 run_lib.py:133] step: 872300, training_loss: 3.73404e-02
I0213 16:33:29.765122 22509476222784 run_lib.py:146] step: 872300, eval_loss: 4.25858e-02
I0213 16:33:48.514158 22509476222784 run_lib.py:133] step: 872350, training_loss: 5.46666e-02
I0213 16:34:07.424890 22509476222784 run_lib.py:133] step: 872400, training_loss: 4.19232e-02
I0213 16:34:07.588805 22509476222784 run_lib.py:146] step: 872400, eval_loss: 4.40461e-02
I0213 16:34:26.313574 22509476222784 run_lib.py:133] step: 872450, training_loss: 4.20241e-02
I0213 16:34:45.044697 22509476222784 run_lib.py:133] step: 872500, training_loss: 5.55825e-02
I0213 16:34:45.226753 22509476222784 run_lib.py:146] step: 872500, eval_loss: 4.58847e-02
I0213 16:35:04.157486 22509476222784 run_lib.py:133] step: 872550, training_loss: 3.58166e-02
I0213 16:35:22.885526 22509476222784 run_lib.py:133] step: 872600, training_loss: 3.63652e-02
I0213 16:35:23.052088 22509476222784 run_lib.py:146] step: 872600, eval_loss: 3.35350e-02
I0213 16:35:41.956393 22509476222784 run_lib.py:133] step: 872650, training_loss: 4.13773e-02
I0213 16:36:00.623681 22509476222784 run_lib.py:133] step: 872700, training_loss: 4.31709e-02
I0213 16:36:00.800865 22509476222784 run_lib.py:146] step: 872700, eval_loss: 4.83354e-02
I0213 16:36:19.583453 22509476222784 run_lib.py:133] step: 872750, training_loss: 3.78027e-02
I0213 16:36:38.533918 22509476222784 run_lib.py:133] step: 872800, training_loss: 4.65221e-02
I0213 16:36:38.696677 22509476222784 run_lib.py:146] step: 872800, eval_loss: 4.40647e-02
I0213 16:36:57.414813 22509476222784 run_lib.py:133] step: 872850, training_loss: 3.41517e-02
I0213 16:37:16.086501 22509476222784 run_lib.py:133] step: 872900, training_loss: 4.75324e-02
I0213 16:37:16.250906 22509476222784 run_lib.py:146] step: 872900, eval_loss: 3.83868e-02
I0213 16:37:34.901846 22509476222784 run_lib.py:133] step: 872950, training_loss: 3.72225e-02
I0213 16:37:53.727061 22509476222784 run_lib.py:133] step: 873000, training_loss: 5.49255e-02
I0213 16:37:53.912997 22509476222784 run_lib.py:146] step: 873000, eval_loss: 3.45860e-02
I0213 16:38:12.683752 22509476222784 run_lib.py:133] step: 873050, training_loss: 4.63575e-02
I0213 16:38:31.484389 22509476222784 run_lib.py:133] step: 873100, training_loss: 4.83045e-02
I0213 16:38:31.651198 22509476222784 run_lib.py:146] step: 873100, eval_loss: 3.68113e-02
I0213 16:38:50.366901 22509476222784 run_lib.py:133] step: 873150, training_loss: 3.45587e-02
I0213 16:39:09.033841 22509476222784 run_lib.py:133] step: 873200, training_loss: 5.22319e-02
I0213 16:39:09.207844 22509476222784 run_lib.py:146] step: 873200, eval_loss: 3.95847e-02
I0213 16:39:28.118562 22509476222784 run_lib.py:133] step: 873250, training_loss: 3.77597e-02
I0213 16:39:47.003525 22509476222784 run_lib.py:133] step: 873300, training_loss: 3.25137e-02
I0213 16:39:47.166024 22509476222784 run_lib.py:146] step: 873300, eval_loss: 3.63382e-02
I0213 16:40:05.914680 22509476222784 run_lib.py:133] step: 873350, training_loss: 4.45798e-02
I0213 16:40:24.676921 22509476222784 run_lib.py:133] step: 873400, training_loss: 3.67817e-02
I0213 16:40:24.842895 22509476222784 run_lib.py:146] step: 873400, eval_loss: 5.13161e-02
I0213 16:40:43.660872 22509476222784 run_lib.py:133] step: 873450, training_loss: 4.00049e-02
I0213 16:41:02.353374 22509476222784 run_lib.py:133] step: 873500, training_loss: 3.70965e-02
I0213 16:41:02.536699 22509476222784 run_lib.py:146] step: 873500, eval_loss: 4.85115e-02
I0213 16:41:21.463336 22509476222784 run_lib.py:133] step: 873550, training_loss: 3.51876e-02
I0213 16:41:40.141623 22509476222784 run_lib.py:133] step: 873600, training_loss: 4.78348e-02
I0213 16:41:40.332324 22509476222784 run_lib.py:146] step: 873600, eval_loss: 3.02021e-02
I0213 16:41:59.172076 22509476222784 run_lib.py:133] step: 873650, training_loss: 4.59076e-02
I0213 16:42:17.842796 22509476222784 run_lib.py:133] step: 873700, training_loss: 3.60579e-02
I0213 16:42:18.015015 22509476222784 run_lib.py:146] step: 873700, eval_loss: 3.96086e-02
I0213 16:42:36.665485 22509476222784 run_lib.py:133] step: 873750, training_loss: 5.24933e-02
I0213 16:42:55.574165 22509476222784 run_lib.py:133] step: 873800, training_loss: 4.93200e-02
I0213 16:42:55.748271 22509476222784 run_lib.py:146] step: 873800, eval_loss: 5.41939e-02
I0213 16:43:14.488077 22509476222784 run_lib.py:133] step: 873850, training_loss: 3.80998e-02
I0213 16:43:33.382339 22509476222784 run_lib.py:133] step: 873900, training_loss: 4.45468e-02
I0213 16:43:33.547620 22509476222784 run_lib.py:146] step: 873900, eval_loss: 3.64560e-02
I0213 16:43:52.203566 22509476222784 run_lib.py:133] step: 873950, training_loss: 3.05917e-02
I0213 16:44:10.961886 22509476222784 run_lib.py:133] step: 874000, training_loss: 5.27245e-02
I0213 16:44:11.147299 22509476222784 run_lib.py:146] step: 874000, eval_loss: 3.82687e-02
I0213 16:44:30.114311 22509476222784 run_lib.py:133] step: 874050, training_loss: 4.61802e-02
I0213 16:44:48.876943 22509476222784 run_lib.py:133] step: 874100, training_loss: 3.86272e-02
I0213 16:44:49.052012 22509476222784 run_lib.py:146] step: 874100, eval_loss: 4.60541e-02
I0213 16:45:07.778044 22509476222784 run_lib.py:133] step: 874150, training_loss: 4.33234e-02
I0213 16:45:26.640501 22509476222784 run_lib.py:133] step: 874200, training_loss: 3.78137e-02
I0213 16:45:26.802106 22509476222784 run_lib.py:146] step: 874200, eval_loss: 3.11366e-02
I0213 16:45:45.523371 22509476222784 run_lib.py:133] step: 874250, training_loss: 4.73027e-02
I0213 16:46:04.272664 22509476222784 run_lib.py:133] step: 874300, training_loss: 4.27537e-02
I0213 16:46:04.638163 22509476222784 run_lib.py:146] step: 874300, eval_loss: 4.34192e-02
I0213 16:46:23.413732 22509476222784 run_lib.py:133] step: 874350, training_loss: 3.17060e-02
I0213 16:46:42.143313 22509476222784 run_lib.py:133] step: 874400, training_loss: 3.72681e-02
I0213 16:46:42.313010 22509476222784 run_lib.py:146] step: 874400, eval_loss: 4.64735e-02
I0213 16:47:01.013038 22509476222784 run_lib.py:133] step: 874450, training_loss: 4.41752e-02
I0213 16:47:19.732106 22509476222784 run_lib.py:133] step: 874500, training_loss: 4.34124e-02
I0213 16:47:19.908693 22509476222784 run_lib.py:146] step: 874500, eval_loss: 4.41720e-02
I0213 16:47:38.818462 22509476222784 run_lib.py:133] step: 874550, training_loss: 5.29668e-02
I0213 16:47:57.736256 22509476222784 run_lib.py:133] step: 874600, training_loss: 4.62171e-02
I0213 16:47:57.902067 22509476222784 run_lib.py:146] step: 874600, eval_loss: 4.18204e-02
I0213 16:48:16.647888 22509476222784 run_lib.py:133] step: 874650, training_loss: 4.31806e-02
I0213 16:48:35.332049 22509476222784 run_lib.py:133] step: 874700, training_loss: 3.07152e-02
I0213 16:48:35.496903 22509476222784 run_lib.py:146] step: 874700, eval_loss: 3.41973e-02
I0213 16:48:54.372643 22509476222784 run_lib.py:133] step: 874750, training_loss: 5.10471e-02
I0213 16:49:13.293976 22509476222784 run_lib.py:133] step: 874800, training_loss: 5.92113e-02
I0213 16:49:13.467065 22509476222784 run_lib.py:146] step: 874800, eval_loss: 3.34395e-02
I0213 16:49:32.203884 22509476222784 run_lib.py:133] step: 874850, training_loss: 3.31033e-02
I0213 16:49:50.994012 22509476222784 run_lib.py:133] step: 874900, training_loss: 3.77323e-02
I0213 16:49:51.161727 22509476222784 run_lib.py:146] step: 874900, eval_loss: 5.11841e-02
I0213 16:50:09.939455 22509476222784 run_lib.py:133] step: 874950, training_loss: 4.82418e-02
I0213 16:50:28.665225 22509476222784 run_lib.py:133] step: 875000, training_loss: 4.00719e-02
I0213 16:50:28.832809 22509476222784 run_lib.py:146] step: 875000, eval_loss: 5.39293e-02
I0213 16:50:47.668730 22509476222784 run_lib.py:133] step: 875050, training_loss: 3.80965e-02
I0213 16:51:06.438084 22509476222784 run_lib.py:133] step: 875100, training_loss: 3.80410e-02
I0213 16:51:06.605518 22509476222784 run_lib.py:146] step: 875100, eval_loss: 5.32801e-02
I0213 16:51:25.569401 22509476222784 run_lib.py:133] step: 875150, training_loss: 4.54672e-02
I0213 16:51:44.315309 22509476222784 run_lib.py:133] step: 875200, training_loss: 4.73710e-02
I0213 16:51:44.483731 22509476222784 run_lib.py:146] step: 875200, eval_loss: 4.29562e-02
I0213 16:52:03.176538 22509476222784 run_lib.py:133] step: 875250, training_loss: 5.23131e-02
I0213 16:52:22.024001 22509476222784 run_lib.py:133] step: 875300, training_loss: 4.93769e-02
I0213 16:52:22.199895 22509476222784 run_lib.py:146] step: 875300, eval_loss: 5.42652e-02
I0213 16:52:40.988267 22509476222784 run_lib.py:133] step: 875350, training_loss: 3.65430e-02
I0213 16:52:59.834300 22509476222784 run_lib.py:133] step: 875400, training_loss: 4.52435e-02
I0213 16:53:00.000754 22509476222784 run_lib.py:146] step: 875400, eval_loss: 4.70384e-02
I0213 16:53:18.652109 22509476222784 run_lib.py:133] step: 875450, training_loss: 3.56101e-02
I0213 16:53:37.339243 22509476222784 run_lib.py:133] step: 875500, training_loss: 5.59773e-02
I0213 16:53:37.504885 22509476222784 run_lib.py:146] step: 875500, eval_loss: 3.09560e-02
I0213 16:53:56.359324 22509476222784 run_lib.py:133] step: 875550, training_loss: 4.57471e-02
I0213 16:54:15.101259 22509476222784 run_lib.py:133] step: 875600, training_loss: 3.79105e-02
I0213 16:54:15.267020 22509476222784 run_lib.py:146] step: 875600, eval_loss: 3.63627e-02
I0213 16:54:33.999328 22509476222784 run_lib.py:133] step: 875650, training_loss: 4.10929e-02
I0213 16:54:52.629027 22509476222784 run_lib.py:133] step: 875700, training_loss: 4.78198e-02
I0213 16:54:52.799896 22509476222784 run_lib.py:146] step: 875700, eval_loss: 4.90564e-02
I0213 16:55:11.717267 22509476222784 run_lib.py:133] step: 875750, training_loss: 3.32933e-02
I0213 16:55:30.431204 22509476222784 run_lib.py:133] step: 875800, training_loss: 3.46217e-02
I0213 16:55:30.604408 22509476222784 run_lib.py:146] step: 875800, eval_loss: 3.91364e-02
I0213 16:55:49.470208 22509476222784 run_lib.py:133] step: 875850, training_loss: 3.86611e-02
I0213 16:56:08.204317 22509476222784 run_lib.py:133] step: 875900, training_loss: 4.62040e-02
I0213 16:56:08.371902 22509476222784 run_lib.py:146] step: 875900, eval_loss: 4.01493e-02
I0213 16:56:27.037392 22509476222784 run_lib.py:133] step: 875950, training_loss: 4.99674e-02
I0213 16:56:45.778550 22509476222784 run_lib.py:133] step: 876000, training_loss: 4.01294e-02
I0213 16:56:45.943006 22509476222784 run_lib.py:146] step: 876000, eval_loss: 4.55863e-02
I0213 16:57:04.833440 22509476222784 run_lib.py:133] step: 876050, training_loss: 3.60598e-02
I0213 16:57:23.665313 22509476222784 run_lib.py:133] step: 876100, training_loss: 3.82082e-02
I0213 16:57:23.830031 22509476222784 run_lib.py:146] step: 876100, eval_loss: 4.77630e-02
I0213 16:57:42.575968 22509476222784 run_lib.py:133] step: 876150, training_loss: 4.78669e-02
I0213 16:58:01.223093 22509476222784 run_lib.py:133] step: 876200, training_loss: 3.92590e-02
I0213 16:58:01.386903 22509476222784 run_lib.py:146] step: 876200, eval_loss: 5.25881e-02
I0213 16:58:20.233157 22509476222784 run_lib.py:133] step: 876250, training_loss: 4.20551e-02
I0213 16:58:38.873332 22509476222784 run_lib.py:133] step: 876300, training_loss: 4.15394e-02
I0213 16:58:39.040639 22509476222784 run_lib.py:146] step: 876300, eval_loss: 5.55637e-02
I0213 16:58:57.953542 22509476222784 run_lib.py:133] step: 876350, training_loss: 3.48236e-02
I0213 16:59:16.681712 22509476222784 run_lib.py:133] step: 876400, training_loss: 3.38518e-02
I0213 16:59:16.845017 22509476222784 run_lib.py:146] step: 876400, eval_loss: 4.53017e-02
I0213 16:59:35.728764 22509476222784 run_lib.py:133] step: 876450, training_loss: 4.14960e-02
I0213 16:59:54.389413 22509476222784 run_lib.py:133] step: 876500, training_loss: 3.72647e-02
I0213 16:59:54.554561 22509476222784 run_lib.py:146] step: 876500, eval_loss: 4.22596e-02
I0213 17:00:13.373434 22509476222784 run_lib.py:133] step: 876550, training_loss: 3.46994e-02
I0213 17:00:32.041300 22509476222784 run_lib.py:133] step: 876600, training_loss: 3.32620e-02
I0213 17:00:32.202337 22509476222784 run_lib.py:146] step: 876600, eval_loss: 4.59797e-02
I0213 17:00:50.964454 22509476222784 run_lib.py:133] step: 876650, training_loss: 3.05855e-02
I0213 17:01:09.850697 22509476222784 run_lib.py:133] step: 876700, training_loss: 4.55605e-02
I0213 17:01:10.040353 22509476222784 run_lib.py:146] step: 876700, eval_loss: 4.45417e-02
I0213 17:01:28.758480 22509476222784 run_lib.py:133] step: 876750, training_loss: 3.82014e-02
I0213 17:01:47.501247 22509476222784 run_lib.py:133] step: 876800, training_loss: 3.99497e-02
I0213 17:01:47.669113 22509476222784 run_lib.py:146] step: 876800, eval_loss: 4.54387e-02
I0213 17:02:06.526453 22509476222784 run_lib.py:133] step: 876850, training_loss: 4.27959e-02
I0213 17:02:25.542828 22509476222784 run_lib.py:133] step: 876900, training_loss: 5.65831e-02
I0213 17:02:25.709133 22509476222784 run_lib.py:146] step: 876900, eval_loss: 5.99689e-02
I0213 17:02:44.429429 22509476222784 run_lib.py:133] step: 876950, training_loss: 3.67624e-02
I0213 17:03:03.111182 22509476222784 run_lib.py:133] step: 877000, training_loss: 3.48198e-02
I0213 17:03:03.282762 22509476222784 run_lib.py:146] step: 877000, eval_loss: 4.91590e-02
I0213 17:03:22.042605 22509476222784 run_lib.py:133] step: 877050, training_loss: 4.40067e-02
I0213 17:03:40.944180 22509476222784 run_lib.py:133] step: 877100, training_loss: 4.98926e-02
I0213 17:03:41.105934 22509476222784 run_lib.py:146] step: 877100, eval_loss: 4.11215e-02
I0213 17:03:59.846061 22509476222784 run_lib.py:133] step: 877150, training_loss: 4.24836e-02
I0213 17:04:18.596177 22509476222784 run_lib.py:133] step: 877200, training_loss: 4.63005e-02
I0213 17:04:18.775066 22509476222784 run_lib.py:146] step: 877200, eval_loss: 3.64392e-02
I0213 17:04:37.455256 22509476222784 run_lib.py:133] step: 877250, training_loss: 4.77766e-02
I0213 17:04:56.368101 22509476222784 run_lib.py:133] step: 877300, training_loss: 4.24740e-02
I0213 17:04:56.544915 22509476222784 run_lib.py:146] step: 877300, eval_loss: 3.01775e-02
I0213 17:05:15.235145 22509476222784 run_lib.py:133] step: 877350, training_loss: 4.90024e-02
I0213 17:05:34.028939 22509476222784 run_lib.py:133] step: 877400, training_loss: 4.11662e-02
I0213 17:05:34.208746 22509476222784 run_lib.py:146] step: 877400, eval_loss: 3.77029e-02
I0213 17:05:52.933345 22509476222784 run_lib.py:133] step: 877450, training_loss: 3.88865e-02
I0213 17:06:11.681560 22509476222784 run_lib.py:133] step: 877500, training_loss: 5.06157e-02
I0213 17:06:11.847966 22509476222784 run_lib.py:146] step: 877500, eval_loss: 4.07230e-02
I0213 17:06:30.742333 22509476222784 run_lib.py:133] step: 877550, training_loss: 4.07063e-02
I0213 17:06:49.509950 22509476222784 run_lib.py:133] step: 877600, training_loss: 4.91052e-02
I0213 17:06:49.672585 22509476222784 run_lib.py:146] step: 877600, eval_loss: 4.78743e-02
I0213 17:07:08.329161 22509476222784 run_lib.py:133] step: 877650, training_loss: 4.83900e-02
I0213 17:07:27.039423 22509476222784 run_lib.py:133] step: 877700, training_loss: 2.93920e-02
I0213 17:07:27.216863 22509476222784 run_lib.py:146] step: 877700, eval_loss: 4.70748e-02
I0213 17:07:46.107861 22509476222784 run_lib.py:133] step: 877750, training_loss: 3.40020e-02
I0213 17:08:04.818810 22509476222784 run_lib.py:133] step: 877800, training_loss: 5.88139e-02
I0213 17:08:04.983375 22509476222784 run_lib.py:146] step: 877800, eval_loss: 4.71623e-02
I0213 17:08:23.856226 22509476222784 run_lib.py:133] step: 877850, training_loss: 4.46896e-02
I0213 17:08:42.528321 22509476222784 run_lib.py:133] step: 877900, training_loss: 3.99408e-02
I0213 17:08:42.690264 22509476222784 run_lib.py:146] step: 877900, eval_loss: 5.15371e-02
I0213 17:09:01.502738 22509476222784 run_lib.py:133] step: 877950, training_loss: 3.57278e-02
I0213 17:09:20.205523 22509476222784 run_lib.py:133] step: 878000, training_loss: 3.89906e-02
I0213 17:09:20.371106 22509476222784 run_lib.py:146] step: 878000, eval_loss: 5.46234e-02
I0213 17:09:39.156672 22509476222784 run_lib.py:133] step: 878050, training_loss: 4.37749e-02
I0213 17:09:58.010545 22509476222784 run_lib.py:133] step: 878100, training_loss: 4.53876e-02
I0213 17:09:58.175370 22509476222784 run_lib.py:146] step: 878100, eval_loss: 4.56112e-02
I0213 17:10:16.910307 22509476222784 run_lib.py:133] step: 878150, training_loss: 4.28479e-02
I0213 17:10:35.793859 22509476222784 run_lib.py:133] step: 878200, training_loss: 4.93547e-02
I0213 17:10:35.968900 22509476222784 run_lib.py:146] step: 878200, eval_loss: 3.31580e-02
I0213 17:10:54.703246 22509476222784 run_lib.py:133] step: 878250, training_loss: 4.69851e-02
I0213 17:11:13.482924 22509476222784 run_lib.py:133] step: 878300, training_loss: 4.00771e-02
I0213 17:11:13.649142 22509476222784 run_lib.py:146] step: 878300, eval_loss: 3.82847e-02
I0213 17:11:32.497963 22509476222784 run_lib.py:133] step: 878350, training_loss: 4.85650e-02
I0213 17:11:51.189640 22509476222784 run_lib.py:133] step: 878400, training_loss: 3.76254e-02
I0213 17:11:51.357245 22509476222784 run_lib.py:146] step: 878400, eval_loss: 4.34787e-02
I0213 17:12:10.101162 22509476222784 run_lib.py:133] step: 878450, training_loss: 3.76376e-02
I0213 17:12:28.989914 22509476222784 run_lib.py:133] step: 878500, training_loss: 2.96348e-02
I0213 17:12:29.154942 22509476222784 run_lib.py:146] step: 878500, eval_loss: 3.41206e-02
I0213 17:12:47.960916 22509476222784 run_lib.py:133] step: 878550, training_loss: 3.41718e-02
I0213 17:13:06.667589 22509476222784 run_lib.py:133] step: 878600, training_loss: 3.29574e-02
I0213 17:13:06.836783 22509476222784 run_lib.py:146] step: 878600, eval_loss: 4.07124e-02
I0213 17:13:25.694127 22509476222784 run_lib.py:133] step: 878650, training_loss: 3.53061e-02
I0213 17:13:44.373106 22509476222784 run_lib.py:133] step: 878700, training_loss: 3.62327e-02
I0213 17:13:44.539944 22509476222784 run_lib.py:146] step: 878700, eval_loss: 4.40660e-02
I0213 17:14:03.306384 22509476222784 run_lib.py:133] step: 878750, training_loss: 3.71277e-02
I0213 17:14:22.109161 22509476222784 run_lib.py:133] step: 878800, training_loss: 4.02296e-02
I0213 17:14:22.276950 22509476222784 run_lib.py:146] step: 878800, eval_loss: 3.77171e-02
I0213 17:14:41.129860 22509476222784 run_lib.py:133] step: 878850, training_loss: 3.88954e-02
I0213 17:14:59.906805 22509476222784 run_lib.py:133] step: 878900, training_loss: 4.25781e-02
I0213 17:15:00.080480 22509476222784 run_lib.py:146] step: 878900, eval_loss: 4.54631e-02
I0213 17:15:18.781023 22509476222784 run_lib.py:133] step: 878950, training_loss: 3.07304e-02
I0213 17:15:37.447026 22509476222784 run_lib.py:133] step: 879000, training_loss: 4.14617e-02
I0213 17:15:37.610775 22509476222784 run_lib.py:146] step: 879000, eval_loss: 4.23875e-02
I0213 17:15:56.566614 22509476222784 run_lib.py:133] step: 879050, training_loss: 4.83731e-02
I0213 17:16:15.323260 22509476222784 run_lib.py:133] step: 879100, training_loss: 4.19062e-02
I0213 17:16:15.491038 22509476222784 run_lib.py:146] step: 879100, eval_loss: 4.13483e-02
I0213 17:16:34.367758 22509476222784 run_lib.py:133] step: 879150, training_loss: 3.77241e-02
I0213 17:16:53.045069 22509476222784 run_lib.py:133] step: 879200, training_loss: 4.60920e-02
I0213 17:16:53.213103 22509476222784 run_lib.py:146] step: 879200, eval_loss: 4.75320e-02
I0213 17:17:12.034949 22509476222784 run_lib.py:133] step: 879250, training_loss: 3.48733e-02
I0213 17:17:30.810381 22509476222784 run_lib.py:133] step: 879300, training_loss: 4.19090e-02
I0213 17:17:30.978923 22509476222784 run_lib.py:146] step: 879300, eval_loss: 4.40578e-02
I0213 17:17:49.953544 22509476222784 run_lib.py:133] step: 879350, training_loss: 3.92663e-02
I0213 17:18:08.716533 22509476222784 run_lib.py:133] step: 879400, training_loss: 4.01611e-02
I0213 17:18:08.881504 22509476222784 run_lib.py:146] step: 879400, eval_loss: 4.85950e-02
I0213 17:18:27.628707 22509476222784 run_lib.py:133] step: 879450, training_loss: 3.80656e-02
I0213 17:18:46.508426 22509476222784 run_lib.py:133] step: 879500, training_loss: 4.68082e-02
I0213 17:18:46.671920 22509476222784 run_lib.py:146] step: 879500, eval_loss: 3.92392e-02
I0213 17:19:05.437124 22509476222784 run_lib.py:133] step: 879550, training_loss: 3.70967e-02
I0213 17:19:24.174744 22509476222784 run_lib.py:133] step: 879600, training_loss: 4.51608e-02
I0213 17:19:24.349836 22509476222784 run_lib.py:146] step: 879600, eval_loss: 3.98095e-02
I0213 17:19:43.236388 22509476222784 run_lib.py:133] step: 879650, training_loss: 4.72621e-02
I0213 17:20:01.977630 22509476222784 run_lib.py:133] step: 879700, training_loss: 5.46981e-02
I0213 17:20:02.143403 22509476222784 run_lib.py:146] step: 879700, eval_loss: 4.13817e-02
I0213 17:20:20.942375 22509476222784 run_lib.py:133] step: 879750, training_loss: 3.85114e-02
I0213 17:20:39.610507 22509476222784 run_lib.py:133] step: 879800, training_loss: 5.46885e-02
I0213 17:20:39.776101 22509476222784 run_lib.py:146] step: 879800, eval_loss: 5.18588e-02
I0213 17:20:58.445877 22509476222784 run_lib.py:133] step: 879850, training_loss: 4.71699e-02
I0213 17:21:17.362917 22509476222784 run_lib.py:133] step: 879900, training_loss: 4.43145e-02
I0213 17:21:17.528151 22509476222784 run_lib.py:146] step: 879900, eval_loss: 5.33341e-02
I0213 17:21:36.279619 22509476222784 run_lib.py:133] step: 879950, training_loss: 4.83814e-02
I0213 17:21:55.003331 22509476222784 run_lib.py:133] step: 880000, training_loss: 3.63126e-02
I0213 17:21:55.781849 22509476222784 run_lib.py:146] step: 880000, eval_loss: 5.31176e-02
I0213 17:22:17.227382 22509476222784 run_lib.py:133] step: 880050, training_loss: 4.56840e-02
I0213 17:22:35.898679 22509476222784 run_lib.py:133] step: 880100, training_loss: 5.03618e-02
I0213 17:22:36.063772 22509476222784 run_lib.py:146] step: 880100, eval_loss: 3.71834e-02
I0213 17:22:54.911238 22509476222784 run_lib.py:133] step: 880150, training_loss: 4.19299e-02
I0213 17:23:13.675578 22509476222784 run_lib.py:133] step: 880200, training_loss: 3.64035e-02
I0213 17:23:13.843847 22509476222784 run_lib.py:146] step: 880200, eval_loss: 3.73085e-02
I0213 17:23:32.691632 22509476222784 run_lib.py:133] step: 880250, training_loss: 3.90909e-02
I0213 17:23:51.363802 22509476222784 run_lib.py:133] step: 880300, training_loss: 4.76549e-02
I0213 17:23:51.529783 22509476222784 run_lib.py:146] step: 880300, eval_loss: 3.59032e-02
I0213 17:24:10.217250 22509476222784 run_lib.py:133] step: 880350, training_loss: 3.44128e-02
I0213 17:24:28.928421 22509476222784 run_lib.py:133] step: 880400, training_loss: 4.26904e-02
I0213 17:24:29.094767 22509476222784 run_lib.py:146] step: 880400, eval_loss: 3.50513e-02
I0213 17:24:48.013609 22509476222784 run_lib.py:133] step: 880450, training_loss: 3.72928e-02
I0213 17:25:06.815138 22509476222784 run_lib.py:133] step: 880500, training_loss: 3.83627e-02
I0213 17:25:06.979802 22509476222784 run_lib.py:146] step: 880500, eval_loss: 4.17893e-02
I0213 17:25:25.689595 22509476222784 run_lib.py:133] step: 880550, training_loss: 3.80488e-02
I0213 17:25:44.366671 22509476222784 run_lib.py:133] step: 880600, training_loss: 5.23287e-02
I0213 17:25:44.532845 22509476222784 run_lib.py:146] step: 880600, eval_loss: 4.36560e-02
I0213 17:26:03.382886 22509476222784 run_lib.py:133] step: 880650, training_loss: 3.28355e-02
I0213 17:26:22.150839 22509476222784 run_lib.py:133] step: 880700, training_loss: 4.05486e-02
I0213 17:26:22.331821 22509476222784 run_lib.py:146] step: 880700, eval_loss: 4.52325e-02
I0213 17:26:41.292415 22509476222784 run_lib.py:133] step: 880750, training_loss: 4.15787e-02
I0213 17:27:00.022589 22509476222784 run_lib.py:133] step: 880800, training_loss: 4.86087e-02
I0213 17:27:00.189191 22509476222784 run_lib.py:146] step: 880800, eval_loss: 3.64934e-02
I0213 17:27:19.017854 22509476222784 run_lib.py:133] step: 880850, training_loss: 5.02907e-02
I0213 17:27:37.660871 22509476222784 run_lib.py:133] step: 880900, training_loss: 3.14408e-02
I0213 17:27:37.826573 22509476222784 run_lib.py:146] step: 880900, eval_loss: 4.41465e-02
I0213 17:27:56.635665 22509476222784 run_lib.py:133] step: 880950, training_loss: 3.22548e-02
I0213 17:28:15.362020 22509476222784 run_lib.py:133] step: 881000, training_loss: 5.90702e-02
I0213 17:28:15.526552 22509476222784 run_lib.py:146] step: 881000, eval_loss: 5.40525e-02
I0213 17:28:34.276605 22509476222784 run_lib.py:133] step: 881050, training_loss: 4.64045e-02
I0213 17:28:53.160035 22509476222784 run_lib.py:133] step: 881100, training_loss: 4.60019e-02
I0213 17:28:53.328340 22509476222784 run_lib.py:146] step: 881100, eval_loss: 4.32367e-02
I0213 17:29:12.037188 22509476222784 run_lib.py:133] step: 881150, training_loss: 4.82646e-02
I0213 17:29:30.704639 22509476222784 run_lib.py:133] step: 881200, training_loss: 4.51555e-02
I0213 17:29:30.887695 22509476222784 run_lib.py:146] step: 881200, eval_loss: 4.04791e-02
I0213 17:29:49.741868 22509476222784 run_lib.py:133] step: 881250, training_loss: 3.91503e-02
I0213 17:30:08.666805 22509476222784 run_lib.py:133] step: 881300, training_loss: 4.22678e-02
I0213 17:30:08.834912 22509476222784 run_lib.py:146] step: 881300, eval_loss: 4.52946e-02
I0213 17:30:27.501711 22509476222784 run_lib.py:133] step: 881350, training_loss: 3.27768e-02
I0213 17:30:46.187002 22509476222784 run_lib.py:133] step: 881400, training_loss: 4.34691e-02
I0213 17:30:46.349624 22509476222784 run_lib.py:146] step: 881400, eval_loss: 5.26068e-02
I0213 17:31:05.021109 22509476222784 run_lib.py:133] step: 881450, training_loss: 5.01545e-02
I0213 17:31:23.838807 22509476222784 run_lib.py:133] step: 881500, training_loss: 3.66776e-02
I0213 17:31:24.009902 22509476222784 run_lib.py:146] step: 881500, eval_loss: 4.13092e-02
I0213 17:31:42.745872 22509476222784 run_lib.py:133] step: 881550, training_loss: 4.81960e-02
I0213 17:32:01.489098 22509476222784 run_lib.py:133] step: 881600, training_loss: 4.67078e-02
I0213 17:32:01.656842 22509476222784 run_lib.py:146] step: 881600, eval_loss: 3.87421e-02
I0213 17:32:20.308949 22509476222784 run_lib.py:133] step: 881650, training_loss: 3.57469e-02
I0213 17:32:39.162201 22509476222784 run_lib.py:133] step: 881700, training_loss: 5.12166e-02
I0213 17:32:39.327828 22509476222784 run_lib.py:146] step: 881700, eval_loss: 3.20668e-02
I0213 17:32:58.074120 22509476222784 run_lib.py:133] step: 881750, training_loss: 3.56341e-02
I0213 17:33:16.951279 22509476222784 run_lib.py:133] step: 881800, training_loss: 3.70012e-02
I0213 17:33:17.119712 22509476222784 run_lib.py:146] step: 881800, eval_loss: 5.02580e-02
I0213 17:33:35.859297 22509476222784 run_lib.py:133] step: 881850, training_loss: 2.84909e-02
I0213 17:33:54.622453 22509476222784 run_lib.py:133] step: 881900, training_loss: 3.97041e-02
I0213 17:33:54.783844 22509476222784 run_lib.py:146] step: 881900, eval_loss: 5.77426e-02
I0213 17:34:13.649602 22509476222784 run_lib.py:133] step: 881950, training_loss: 5.10014e-02
I0213 17:34:32.466306 22509476222784 run_lib.py:133] step: 882000, training_loss: 3.91168e-02
I0213 17:34:32.641997 22509476222784 run_lib.py:146] step: 882000, eval_loss: 2.95741e-02
I0213 17:34:51.382994 22509476222784 run_lib.py:133] step: 882050, training_loss: 4.06961e-02
I0213 17:35:10.126433 22509476222784 run_lib.py:133] step: 882100, training_loss: 3.46481e-02
I0213 17:35:10.293668 22509476222784 run_lib.py:146] step: 882100, eval_loss: 4.63108e-02
I0213 17:35:29.150532 22509476222784 run_lib.py:133] step: 882150, training_loss: 4.40649e-02
I0213 17:35:47.809505 22509476222784 run_lib.py:133] step: 882200, training_loss: 4.33180e-02
I0213 17:35:47.975533 22509476222784 run_lib.py:146] step: 882200, eval_loss: 3.96897e-02
I0213 17:36:06.799746 22509476222784 run_lib.py:133] step: 882250, training_loss: 4.58315e-02
I0213 17:36:25.548649 22509476222784 run_lib.py:133] step: 882300, training_loss: 3.32062e-02
I0213 17:36:25.714018 22509476222784 run_lib.py:146] step: 882300, eval_loss: 4.20163e-02
I0213 17:36:44.636779 22509476222784 run_lib.py:133] step: 882350, training_loss: 4.32081e-02
I0213 17:37:03.325361 22509476222784 run_lib.py:133] step: 882400, training_loss: 3.85183e-02
I0213 17:37:03.487666 22509476222784 run_lib.py:146] step: 882400, eval_loss: 4.40188e-02
I0213 17:37:22.165029 22509476222784 run_lib.py:133] step: 882450, training_loss: 5.02312e-02
I0213 17:37:40.986601 22509476222784 run_lib.py:133] step: 882500, training_loss: 4.68494e-02
I0213 17:37:41.162727 22509476222784 run_lib.py:146] step: 882500, eval_loss: 2.48235e-02
I0213 17:37:59.933816 22509476222784 run_lib.py:133] step: 882550, training_loss: 3.82758e-02
I0213 17:38:18.885245 22509476222784 run_lib.py:133] step: 882600, training_loss: 5.06239e-02
I0213 17:38:19.087883 22509476222784 run_lib.py:146] step: 882600, eval_loss: 4.02358e-02
I0213 17:38:37.778628 22509476222784 run_lib.py:133] step: 882650, training_loss: 4.68671e-02
I0213 17:38:56.450244 22509476222784 run_lib.py:133] step: 882700, training_loss: 3.36220e-02
I0213 17:38:56.615727 22509476222784 run_lib.py:146] step: 882700, eval_loss: 4.30342e-02
I0213 17:39:15.431401 22509476222784 run_lib.py:133] step: 882750, training_loss: 4.75321e-02
I0213 17:39:34.189474 22509476222784 run_lib.py:133] step: 882800, training_loss: 2.89671e-02
I0213 17:39:34.354926 22509476222784 run_lib.py:146] step: 882800, eval_loss: 4.24874e-02
I0213 17:39:53.099616 22509476222784 run_lib.py:133] step: 882850, training_loss: 4.25652e-02
I0213 17:40:11.941711 22509476222784 run_lib.py:133] step: 882900, training_loss: 4.92368e-02
I0213 17:40:12.104771 22509476222784 run_lib.py:146] step: 882900, eval_loss: 3.71627e-02
I0213 17:40:30.811000 22509476222784 run_lib.py:133] step: 882950, training_loss: 2.60066e-02
I0213 17:40:49.473531 22509476222784 run_lib.py:133] step: 883000, training_loss: 3.79813e-02
I0213 17:40:49.646049 22509476222784 run_lib.py:146] step: 883000, eval_loss: 5.05793e-02
I0213 17:41:08.466495 22509476222784 run_lib.py:133] step: 883050, training_loss: 5.14805e-02
I0213 17:41:27.212591 22509476222784 run_lib.py:133] step: 883100, training_loss: 3.84110e-02
I0213 17:41:27.378925 22509476222784 run_lib.py:146] step: 883100, eval_loss: 4.38407e-02
I0213 17:41:46.051975 22509476222784 run_lib.py:133] step: 883150, training_loss: 3.85967e-02
I0213 17:42:04.758305 22509476222784 run_lib.py:133] step: 883200, training_loss: 4.03657e-02
I0213 17:42:04.922522 22509476222784 run_lib.py:146] step: 883200, eval_loss: 4.68934e-02
I0213 17:42:23.779364 22509476222784 run_lib.py:133] step: 883250, training_loss: 3.95716e-02
I0213 17:42:42.614974 22509476222784 run_lib.py:133] step: 883300, training_loss: 4.12536e-02
I0213 17:42:42.782592 22509476222784 run_lib.py:146] step: 883300, eval_loss: 4.58919e-02
I0213 17:43:01.548691 22509476222784 run_lib.py:133] step: 883350, training_loss: 4.40955e-02
I0213 17:43:20.237426 22509476222784 run_lib.py:133] step: 883400, training_loss: 6.22864e-02
I0213 17:43:20.403220 22509476222784 run_lib.py:146] step: 883400, eval_loss: 3.75617e-02
I0213 17:43:39.298741 22509476222784 run_lib.py:133] step: 883450, training_loss: 5.11079e-02
I0213 17:43:57.985781 22509476222784 run_lib.py:133] step: 883500, training_loss: 3.70790e-02
I0213 17:43:58.159441 22509476222784 run_lib.py:146] step: 883500, eval_loss: 4.40993e-02
I0213 17:44:16.969533 22509476222784 run_lib.py:133] step: 883550, training_loss: 5.07522e-02
I0213 17:44:35.738939 22509476222784 run_lib.py:133] step: 883600, training_loss: 4.31990e-02
I0213 17:44:35.905928 22509476222784 run_lib.py:146] step: 883600, eval_loss: 4.09117e-02
I0213 17:44:54.783957 22509476222784 run_lib.py:133] step: 883650, training_loss: 4.72418e-02
I0213 17:45:13.449137 22509476222784 run_lib.py:133] step: 883700, training_loss: 3.58454e-02
I0213 17:45:13.614981 22509476222784 run_lib.py:146] step: 883700, eval_loss: 5.15756e-02
I0213 17:45:32.412794 22509476222784 run_lib.py:133] step: 883750, training_loss: 5.37537e-02
I0213 17:45:51.062484 22509476222784 run_lib.py:133] step: 883800, training_loss: 4.86709e-02
I0213 17:45:51.225611 22509476222784 run_lib.py:146] step: 883800, eval_loss: 5.45560e-02
I0213 17:46:09.942498 22509476222784 run_lib.py:133] step: 883850, training_loss: 3.34793e-02
I0213 17:46:28.860226 22509476222784 run_lib.py:133] step: 883900, training_loss: 4.73504e-02
I0213 17:46:29.028178 22509476222784 run_lib.py:146] step: 883900, eval_loss: 3.88946e-02
I0213 17:46:47.704815 22509476222784 run_lib.py:133] step: 883950, training_loss: 3.90395e-02
I0213 17:47:06.399962 22509476222784 run_lib.py:133] step: 884000, training_loss: 4.04251e-02
I0213 17:47:06.567886 22509476222784 run_lib.py:146] step: 884000, eval_loss: 4.11543e-02
I0213 17:47:25.422589 22509476222784 run_lib.py:133] step: 884050, training_loss: 3.45870e-02
I0213 17:47:44.196911 22509476222784 run_lib.py:133] step: 884100, training_loss: 4.31483e-02
I0213 17:47:44.363953 22509476222784 run_lib.py:146] step: 884100, eval_loss: 4.29839e-02
I0213 17:48:03.257441 22509476222784 run_lib.py:133] step: 884150, training_loss: 3.78580e-02
I0213 17:48:21.900578 22509476222784 run_lib.py:133] step: 884200, training_loss: 4.68120e-02
I0213 17:48:22.067722 22509476222784 run_lib.py:146] step: 884200, eval_loss: 4.15307e-02
I0213 17:48:40.759665 22509476222784 run_lib.py:133] step: 884250, training_loss: 6.18039e-02
I0213 17:48:59.592995 22509476222784 run_lib.py:133] step: 884300, training_loss: 4.51800e-02
I0213 17:48:59.760024 22509476222784 run_lib.py:146] step: 884300, eval_loss: 4.56719e-02
I0213 17:49:18.546130 22509476222784 run_lib.py:133] step: 884350, training_loss: 3.95802e-02
I0213 17:49:37.202521 22509476222784 run_lib.py:133] step: 884400, training_loss: 4.56713e-02
I0213 17:49:37.368825 22509476222784 run_lib.py:146] step: 884400, eval_loss: 5.03229e-02
I0213 17:49:56.046705 22509476222784 run_lib.py:133] step: 884450, training_loss: 4.34725e-02
I0213 17:50:14.894752 22509476222784 run_lib.py:133] step: 884500, training_loss: 3.59794e-02
I0213 17:50:15.065053 22509476222784 run_lib.py:146] step: 884500, eval_loss: 3.37827e-02
I0213 17:50:33.767236 22509476222784 run_lib.py:133] step: 884550, training_loss: 4.41843e-02
I0213 17:50:52.598191 22509476222784 run_lib.py:133] step: 884600, training_loss: 3.26849e-02
I0213 17:50:52.767015 22509476222784 run_lib.py:146] step: 884600, eval_loss: 4.63288e-02
I0213 17:51:11.477216 22509476222784 run_lib.py:133] step: 884650, training_loss: 3.47426e-02
I0213 17:51:30.163195 22509476222784 run_lib.py:133] step: 884700, training_loss: 4.36751e-02
I0213 17:51:30.327279 22509476222784 run_lib.py:146] step: 884700, eval_loss: 3.66418e-02
I0213 17:51:49.227326 22509476222784 run_lib.py:133] step: 884750, training_loss: 4.25910e-02
I0213 17:52:08.012347 22509476222784 run_lib.py:133] step: 884800, training_loss: 3.52985e-02
I0213 17:52:08.174991 22509476222784 run_lib.py:146] step: 884800, eval_loss: 5.32888e-02
I0213 17:52:26.939561 22509476222784 run_lib.py:133] step: 884850, training_loss: 3.70729e-02
I0213 17:52:45.654754 22509476222784 run_lib.py:133] step: 884900, training_loss: 4.59671e-02
I0213 17:52:45.823799 22509476222784 run_lib.py:146] step: 884900, eval_loss: 4.38015e-02
I0213 17:53:04.718484 22509476222784 run_lib.py:133] step: 884950, training_loss: 4.97199e-02
I0213 17:53:23.388211 22509476222784 run_lib.py:133] step: 885000, training_loss: 4.85819e-02
I0213 17:53:23.554857 22509476222784 run_lib.py:146] step: 885000, eval_loss: 3.39003e-02
I0213 17:53:42.439589 22509476222784 run_lib.py:133] step: 885050, training_loss: 4.45950e-02
I0213 17:54:01.150899 22509476222784 run_lib.py:133] step: 885100, training_loss: 4.24238e-02
I0213 17:54:01.319048 22509476222784 run_lib.py:146] step: 885100, eval_loss: 4.25842e-02
I0213 17:54:20.249582 22509476222784 run_lib.py:133] step: 885150, training_loss: 4.35026e-02
I0213 17:54:38.908645 22509476222784 run_lib.py:133] step: 885200, training_loss: 5.55546e-02
I0213 17:54:39.072741 22509476222784 run_lib.py:146] step: 885200, eval_loss: 4.03728e-02
I0213 17:54:57.750604 22509476222784 run_lib.py:133] step: 885250, training_loss: 3.69417e-02
I0213 17:55:16.609283 22509476222784 run_lib.py:133] step: 885300, training_loss: 4.69316e-02
I0213 17:55:16.771933 22509476222784 run_lib.py:146] step: 885300, eval_loss: 4.06128e-02
I0213 17:55:35.501540 22509476222784 run_lib.py:133] step: 885350, training_loss: 4.35821e-02
I0213 17:55:54.436167 22509476222784 run_lib.py:133] step: 885400, training_loss: 4.05192e-02
I0213 17:55:54.602814 22509476222784 run_lib.py:146] step: 885400, eval_loss: 3.44126e-02
I0213 17:56:13.302910 22509476222784 run_lib.py:133] step: 885450, training_loss: 3.39234e-02
I0213 17:56:32.024217 22509476222784 run_lib.py:133] step: 885500, training_loss: 4.12914e-02
I0213 17:56:32.198962 22509476222784 run_lib.py:146] step: 885500, eval_loss: 3.93909e-02
I0213 17:56:51.073160 22509476222784 run_lib.py:133] step: 885550, training_loss: 5.61943e-02
I0213 17:57:09.833179 22509476222784 run_lib.py:133] step: 885600, training_loss: 2.80465e-02
I0213 17:57:10.000043 22509476222784 run_lib.py:146] step: 885600, eval_loss: 4.05694e-02
I0213 17:57:28.780106 22509476222784 run_lib.py:133] step: 885650, training_loss: 4.78017e-02
I0213 17:57:47.679926 22509476222784 run_lib.py:133] step: 885700, training_loss: 3.68718e-02
I0213 17:57:47.842876 22509476222784 run_lib.py:146] step: 885700, eval_loss: 3.59543e-02
I0213 17:58:06.515880 22509476222784 run_lib.py:133] step: 885750, training_loss: 3.25016e-02
I0213 17:58:25.236666 22509476222784 run_lib.py:133] step: 885800, training_loss: 5.82248e-02
I0213 17:58:25.554755 22509476222784 run_lib.py:146] step: 885800, eval_loss: 3.81750e-02
I0213 17:58:44.354377 22509476222784 run_lib.py:133] step: 885850, training_loss: 6.69240e-02
I0213 17:59:03.142477 22509476222784 run_lib.py:133] step: 885900, training_loss: 3.75288e-02
I0213 17:59:03.308860 22509476222784 run_lib.py:146] step: 885900, eval_loss: 2.91514e-02
I0213 17:59:22.020283 22509476222784 run_lib.py:133] step: 885950, training_loss: 4.90589e-02
I0213 17:59:40.703303 22509476222784 run_lib.py:133] step: 886000, training_loss: 3.37627e-02
I0213 17:59:40.870924 22509476222784 run_lib.py:146] step: 886000, eval_loss: 3.05381e-02
I0213 17:59:59.753248 22509476222784 run_lib.py:133] step: 886050, training_loss: 5.13761e-02
I0213 18:00:18.518201 22509476222784 run_lib.py:133] step: 886100, training_loss: 4.82913e-02
I0213 18:00:18.684010 22509476222784 run_lib.py:146] step: 886100, eval_loss: 4.56456e-02
I0213 18:00:37.413248 22509476222784 run_lib.py:133] step: 886150, training_loss: 3.42962e-02
I0213 18:00:56.124037 22509476222784 run_lib.py:133] step: 886200, training_loss: 5.09787e-02
I0213 18:00:56.288166 22509476222784 run_lib.py:146] step: 886200, eval_loss: 4.10746e-02
I0213 18:01:15.160290 22509476222784 run_lib.py:133] step: 886250, training_loss: 3.87425e-02
I0213 18:01:33.933010 22509476222784 run_lib.py:133] step: 886300, training_loss: 6.17257e-02
I0213 18:01:34.098057 22509476222784 run_lib.py:146] step: 886300, eval_loss: 4.89708e-02
I0213 18:01:52.799297 22509476222784 run_lib.py:133] step: 886350, training_loss: 4.42421e-02
I0213 18:02:11.573163 22509476222784 run_lib.py:133] step: 886400, training_loss: 5.35337e-02
I0213 18:02:11.747837 22509476222784 run_lib.py:146] step: 886400, eval_loss: 5.10799e-02
I0213 18:02:30.634887 22509476222784 run_lib.py:133] step: 886450, training_loss: 4.31169e-02
I0213 18:02:49.294728 22509476222784 run_lib.py:133] step: 886500, training_loss: 5.22153e-02
I0213 18:02:49.462208 22509476222784 run_lib.py:146] step: 886500, eval_loss: 4.71732e-02
I0213 18:03:08.283399 22509476222784 run_lib.py:133] step: 886550, training_loss: 3.04992e-02
I0213 18:03:26.963958 22509476222784 run_lib.py:133] step: 886600, training_loss: 4.21981e-02
I0213 18:03:27.128650 22509476222784 run_lib.py:146] step: 886600, eval_loss: 3.84373e-02
I0213 18:03:46.058886 22509476222784 run_lib.py:133] step: 886650, training_loss: 4.19443e-02
I0213 18:04:04.849416 22509476222784 run_lib.py:133] step: 886700, training_loss: 3.95222e-02
I0213 18:04:05.016020 22509476222784 run_lib.py:146] step: 886700, eval_loss: 4.64875e-02
I0213 18:04:23.745434 22509476222784 run_lib.py:133] step: 886750, training_loss: 4.00449e-02
I0213 18:04:42.583036 22509476222784 run_lib.py:133] step: 886800, training_loss: 4.81479e-02
I0213 18:04:42.752797 22509476222784 run_lib.py:146] step: 886800, eval_loss: 4.28819e-02
I0213 18:05:01.427686 22509476222784 run_lib.py:133] step: 886850, training_loss: 5.46726e-02
I0213 18:05:20.269707 22509476222784 run_lib.py:133] step: 886900, training_loss: 4.64566e-02
I0213 18:05:20.444868 22509476222784 run_lib.py:146] step: 886900, eval_loss: 2.25690e-02
I0213 18:05:39.155424 22509476222784 run_lib.py:133] step: 886950, training_loss: 3.59060e-02
I0213 18:05:57.877657 22509476222784 run_lib.py:133] step: 887000, training_loss: 3.88967e-02
I0213 18:05:58.059205 22509476222784 run_lib.py:146] step: 887000, eval_loss: 2.93616e-02
I0213 18:06:16.949990 22509476222784 run_lib.py:133] step: 887050, training_loss: 4.49947e-02
I0213 18:06:35.658180 22509476222784 run_lib.py:133] step: 887100, training_loss: 3.69819e-02
I0213 18:06:35.820785 22509476222784 run_lib.py:146] step: 887100, eval_loss: 3.98623e-02
I0213 18:06:54.456064 22509476222784 run_lib.py:133] step: 887150, training_loss: 3.50715e-02
I0213 18:07:13.115865 22509476222784 run_lib.py:133] step: 887200, training_loss: 5.16920e-02
I0213 18:07:13.286905 22509476222784 run_lib.py:146] step: 887200, eval_loss: 3.67285e-02
I0213 18:07:32.154054 22509476222784 run_lib.py:133] step: 887250, training_loss: 3.51113e-02
I0213 18:07:50.803112 22509476222784 run_lib.py:133] step: 887300, training_loss: 5.08081e-02
I0213 18:07:50.971905 22509476222784 run_lib.py:146] step: 887300, eval_loss: 3.33931e-02
I0213 18:08:09.725925 22509476222784 run_lib.py:133] step: 887350, training_loss: 4.01246e-02
I0213 18:08:28.406473 22509476222784 run_lib.py:133] step: 887400, training_loss: 3.75755e-02
I0213 18:08:28.572497 22509476222784 run_lib.py:146] step: 887400, eval_loss: 4.33502e-02
I0213 18:08:47.290795 22509476222784 run_lib.py:133] step: 887450, training_loss: 4.52899e-02
I0213 18:09:06.085994 22509476222784 run_lib.py:133] step: 887500, training_loss: 3.73947e-02
I0213 18:09:06.252096 22509476222784 run_lib.py:146] step: 887500, eval_loss: 4.44670e-02
I0213 18:09:25.188839 22509476222784 run_lib.py:133] step: 887550, training_loss: 4.98569e-02
I0213 18:09:44.011399 22509476222784 run_lib.py:133] step: 887600, training_loss: 4.17076e-02
I0213 18:09:44.174005 22509476222784 run_lib.py:146] step: 887600, eval_loss: 5.66804e-02
I0213 18:10:02.885770 22509476222784 run_lib.py:133] step: 887650, training_loss: 4.85610e-02
I0213 18:10:21.570967 22509476222784 run_lib.py:133] step: 887700, training_loss: 3.77285e-02
I0213 18:10:21.737287 22509476222784 run_lib.py:146] step: 887700, eval_loss: 4.63325e-02
I0213 18:10:40.650859 22509476222784 run_lib.py:133] step: 887750, training_loss: 3.78188e-02
I0213 18:10:59.423132 22509476222784 run_lib.py:133] step: 887800, training_loss: 4.32645e-02
I0213 18:10:59.592934 22509476222784 run_lib.py:146] step: 887800, eval_loss: 4.65302e-02
I0213 18:11:18.506102 22509476222784 run_lib.py:133] step: 887850, training_loss: 3.43631e-02
I0213 18:11:37.229818 22509476222784 run_lib.py:133] step: 887900, training_loss: 3.73440e-02
I0213 18:11:37.394687 22509476222784 run_lib.py:146] step: 887900, eval_loss: 3.65894e-02
I0213 18:11:56.291466 22509476222784 run_lib.py:133] step: 887950, training_loss: 4.00486e-02
I0213 18:12:15.021514 22509476222784 run_lib.py:133] step: 888000, training_loss: 3.96001e-02
I0213 18:12:15.191949 22509476222784 run_lib.py:146] step: 888000, eval_loss: 4.88622e-02
I0213 18:12:34.160558 22509476222784 run_lib.py:133] step: 888050, training_loss: 3.65220e-02
I0213 18:12:52.873732 22509476222784 run_lib.py:133] step: 888100, training_loss: 3.09820e-02
I0213 18:12:53.037122 22509476222784 run_lib.py:146] step: 888100, eval_loss: 5.06153e-02
I0213 18:13:11.745934 22509476222784 run_lib.py:133] step: 888150, training_loss: 2.49254e-02
I0213 18:13:30.656702 22509476222784 run_lib.py:133] step: 888200, training_loss: 4.47136e-02
I0213 18:13:30.824606 22509476222784 run_lib.py:146] step: 888200, eval_loss: 5.54382e-02
I0213 18:13:49.507829 22509476222784 run_lib.py:133] step: 888250, training_loss: 3.85301e-02
I0213 18:14:08.312117 22509476222784 run_lib.py:133] step: 888300, training_loss: 4.72089e-02
I0213 18:14:08.490765 22509476222784 run_lib.py:146] step: 888300, eval_loss: 4.06618e-02
I0213 18:14:27.401678 22509476222784 run_lib.py:133] step: 888350, training_loss: 3.63221e-02
I0213 18:14:46.250901 22509476222784 run_lib.py:133] step: 888400, training_loss: 4.33212e-02
I0213 18:14:46.416609 22509476222784 run_lib.py:146] step: 888400, eval_loss: 5.04203e-02
I0213 18:15:05.116077 22509476222784 run_lib.py:133] step: 888450, training_loss: 5.09053e-02
I0213 18:15:23.788810 22509476222784 run_lib.py:133] step: 888500, training_loss: 4.03515e-02
I0213 18:15:23.968923 22509476222784 run_lib.py:146] step: 888500, eval_loss: 5.07646e-02
I0213 18:15:42.695444 22509476222784 run_lib.py:133] step: 888550, training_loss: 4.92052e-02
I0213 18:16:01.622810 22509476222784 run_lib.py:133] step: 888600, training_loss: 4.41872e-02
I0213 18:16:01.791061 22509476222784 run_lib.py:146] step: 888600, eval_loss: 3.78868e-02
I0213 18:16:20.540452 22509476222784 run_lib.py:133] step: 888650, training_loss: 4.21696e-02
I0213 18:16:39.272144 22509476222784 run_lib.py:133] step: 888700, training_loss: 3.78637e-02
I0213 18:16:39.437501 22509476222784 run_lib.py:146] step: 888700, eval_loss: 3.69914e-02
I0213 18:16:58.090140 22509476222784 run_lib.py:133] step: 888750, training_loss: 4.17190e-02
I0213 18:17:17.007378 22509476222784 run_lib.py:133] step: 888800, training_loss: 3.74624e-02
I0213 18:17:17.181760 22509476222784 run_lib.py:146] step: 888800, eval_loss: 5.63601e-02
I0213 18:17:35.984998 22509476222784 run_lib.py:133] step: 888850, training_loss: 5.29448e-02
I0213 18:17:54.870405 22509476222784 run_lib.py:133] step: 888900, training_loss: 4.37470e-02
I0213 18:17:55.035632 22509476222784 run_lib.py:146] step: 888900, eval_loss: 3.80314e-02
I0213 18:18:13.674650 22509476222784 run_lib.py:133] step: 888950, training_loss: 4.63973e-02
I0213 18:18:32.359239 22509476222784 run_lib.py:133] step: 889000, training_loss: 4.24212e-02
I0213 18:18:32.521241 22509476222784 run_lib.py:146] step: 889000, eval_loss: 3.29491e-02
I0213 18:18:51.350133 22509476222784 run_lib.py:133] step: 889050, training_loss: 3.38777e-02
I0213 18:19:10.149805 22509476222784 run_lib.py:133] step: 889100, training_loss: 3.44993e-02
I0213 18:19:10.323148 22509476222784 run_lib.py:146] step: 889100, eval_loss: 4.82643e-02
I0213 18:19:29.017557 22509476222784 run_lib.py:133] step: 889150, training_loss: 3.73527e-02
I0213 18:19:47.733231 22509476222784 run_lib.py:133] step: 889200, training_loss: 3.66257e-02
I0213 18:19:47.901921 22509476222784 run_lib.py:146] step: 889200, eval_loss: 5.27954e-02
I0213 18:20:06.737568 22509476222784 run_lib.py:133] step: 889250, training_loss: 5.76158e-02
I0213 18:20:25.444094 22509476222784 run_lib.py:133] step: 889300, training_loss: 3.49803e-02
I0213 18:20:25.616771 22509476222784 run_lib.py:146] step: 889300, eval_loss: 4.23857e-02
I0213 18:20:44.483267 22509476222784 run_lib.py:133] step: 889350, training_loss: 4.41445e-02
I0213 18:21:03.248551 22509476222784 run_lib.py:133] step: 889400, training_loss: 4.59816e-02
I0213 18:21:03.416048 22509476222784 run_lib.py:146] step: 889400, eval_loss: 3.35089e-02
I0213 18:21:22.350224 22509476222784 run_lib.py:133] step: 889450, training_loss: 4.23723e-02
I0213 18:21:41.010859 22509476222784 run_lib.py:133] step: 889500, training_loss: 3.91170e-02
I0213 18:21:41.172852 22509476222784 run_lib.py:146] step: 889500, eval_loss: 3.99352e-02
I0213 18:21:59.875974 22509476222784 run_lib.py:133] step: 889550, training_loss: 5.40708e-02
I0213 18:22:18.727732 22509476222784 run_lib.py:133] step: 889600, training_loss: 4.36978e-02
I0213 18:22:18.903980 22509476222784 run_lib.py:146] step: 889600, eval_loss: 5.60321e-02
I0213 18:22:37.644929 22509476222784 run_lib.py:133] step: 889650, training_loss: 4.21626e-02
I0213 18:22:56.559874 22509476222784 run_lib.py:133] step: 889700, training_loss: 3.42168e-02
I0213 18:22:56.727061 22509476222784 run_lib.py:146] step: 889700, eval_loss: 4.22351e-02
I0213 18:23:15.415471 22509476222784 run_lib.py:133] step: 889750, training_loss: 3.71182e-02
I0213 18:23:34.148546 22509476222784 run_lib.py:133] step: 889800, training_loss: 4.51138e-02
I0213 18:23:34.315877 22509476222784 run_lib.py:146] step: 889800, eval_loss: 2.11369e-02
I0213 18:23:53.215928 22509476222784 run_lib.py:133] step: 889850, training_loss: 5.02425e-02
I0213 18:24:12.033525 22509476222784 run_lib.py:133] step: 889900, training_loss: 4.74971e-02
I0213 18:24:12.199984 22509476222784 run_lib.py:146] step: 889900, eval_loss: 4.86001e-02
I0213 18:24:30.940482 22509476222784 run_lib.py:133] step: 889950, training_loss: 3.91596e-02
I0213 18:24:49.873312 22509476222784 run_lib.py:133] step: 890000, training_loss: 3.26633e-02
I0213 18:24:50.668753 22509476222784 run_lib.py:146] step: 890000, eval_loss: 3.90781e-02
I0213 18:25:12.072078 22509476222784 run_lib.py:133] step: 890050, training_loss: 3.89204e-02
I0213 18:25:30.845630 22509476222784 run_lib.py:133] step: 890100, training_loss: 4.85521e-02
I0213 18:25:31.013007 22509476222784 run_lib.py:146] step: 890100, eval_loss: 3.96747e-02
I0213 18:25:49.757786 22509476222784 run_lib.py:133] step: 890150, training_loss: 3.58373e-02
I0213 18:26:08.742406 22509476222784 run_lib.py:133] step: 890200, training_loss: 3.35064e-02
I0213 18:26:08.910105 22509476222784 run_lib.py:146] step: 890200, eval_loss: 4.36922e-02
I0213 18:26:27.631624 22509476222784 run_lib.py:133] step: 890250, training_loss: 4.57020e-02
I0213 18:26:46.288474 22509476222784 run_lib.py:133] step: 890300, training_loss: 2.99296e-02
I0213 18:26:46.466730 22509476222784 run_lib.py:146] step: 890300, eval_loss: 4.42122e-02
I0213 18:27:05.384318 22509476222784 run_lib.py:133] step: 890350, training_loss: 5.51477e-02
I0213 18:27:24.166717 22509476222784 run_lib.py:133] step: 890400, training_loss: 4.79217e-02
I0213 18:27:24.332733 22509476222784 run_lib.py:146] step: 890400, eval_loss: 3.70154e-02
I0213 18:27:43.214914 22509476222784 run_lib.py:133] step: 890450, training_loss: 3.17801e-02
I0213 18:28:01.940727 22509476222784 run_lib.py:133] step: 890500, training_loss: 3.10832e-02
I0213 18:28:02.102814 22509476222784 run_lib.py:146] step: 890500, eval_loss: 4.34521e-02
I0213 18:28:20.836250 22509476222784 run_lib.py:133] step: 890550, training_loss: 5.28816e-02
I0213 18:28:39.642716 22509476222784 run_lib.py:133] step: 890600, training_loss: 3.87334e-02
I0213 18:28:39.820024 22509476222784 run_lib.py:146] step: 890600, eval_loss: 3.87997e-02
I0213 18:28:58.727921 22509476222784 run_lib.py:133] step: 890650, training_loss: 4.20529e-02
I0213 18:29:17.597975 22509476222784 run_lib.py:133] step: 890700, training_loss: 4.63762e-02
I0213 18:29:17.766135 22509476222784 run_lib.py:146] step: 890700, eval_loss: 4.74853e-02
I0213 18:29:36.447159 22509476222784 run_lib.py:133] step: 890750, training_loss: 4.94000e-02
I0213 18:29:55.169013 22509476222784 run_lib.py:133] step: 890800, training_loss: 3.77609e-02
I0213 18:29:55.336862 22509476222784 run_lib.py:146] step: 890800, eval_loss: 3.23745e-02
I0213 18:30:14.161209 22509476222784 run_lib.py:133] step: 890850, training_loss: 4.31819e-02
I0213 18:30:32.887280 22509476222784 run_lib.py:133] step: 890900, training_loss: 4.63530e-02
I0213 18:30:33.053798 22509476222784 run_lib.py:146] step: 890900, eval_loss: 4.27130e-02
I0213 18:30:52.008340 22509476222784 run_lib.py:133] step: 890950, training_loss: 5.49349e-02
I0213 18:31:10.706951 22509476222784 run_lib.py:133] step: 891000, training_loss: 3.95087e-02
I0213 18:31:10.875704 22509476222784 run_lib.py:146] step: 891000, eval_loss: 3.82446e-02
I0213 18:31:29.691217 22509476222784 run_lib.py:133] step: 891050, training_loss: 3.39490e-02
I0213 18:31:48.355827 22509476222784 run_lib.py:133] step: 891100, training_loss: 4.59760e-02
I0213 18:31:48.530917 22509476222784 run_lib.py:146] step: 891100, eval_loss: 4.86873e-02
I0213 18:32:07.371784 22509476222784 run_lib.py:133] step: 891150, training_loss: 4.19735e-02
I0213 18:32:26.152655 22509476222784 run_lib.py:133] step: 891200, training_loss: 3.73175e-02
I0213 18:32:26.323877 22509476222784 run_lib.py:146] step: 891200, eval_loss: 4.83482e-02
I0213 18:32:45.014520 22509476222784 run_lib.py:133] step: 891250, training_loss: 3.85788e-02
I0213 18:33:03.877975 22509476222784 run_lib.py:133] step: 891300, training_loss: 4.64472e-02
I0213 18:33:04.044624 22509476222784 run_lib.py:146] step: 891300, eval_loss: 4.00746e-02
I0213 18:33:22.735474 22509476222784 run_lib.py:133] step: 891350, training_loss: 4.82310e-02
I0213 18:33:41.428802 22509476222784 run_lib.py:133] step: 891400, training_loss: 2.75981e-02
I0213 18:33:41.592827 22509476222784 run_lib.py:146] step: 891400, eval_loss: 4.32507e-02
I0213 18:34:00.453171 22509476222784 run_lib.py:133] step: 891450, training_loss: 3.44517e-02
I0213 18:34:19.176936 22509476222784 run_lib.py:133] step: 891500, training_loss: 4.35152e-02
I0213 18:34:19.344118 22509476222784 run_lib.py:146] step: 891500, eval_loss: 4.62919e-02
I0213 18:34:38.268353 22509476222784 run_lib.py:133] step: 891550, training_loss: 5.05483e-02
I0213 18:34:57.004418 22509476222784 run_lib.py:133] step: 891600, training_loss: 3.67127e-02
I0213 18:34:57.173107 22509476222784 run_lib.py:146] step: 891600, eval_loss: 6.15695e-02
I0213 18:35:15.884121 22509476222784 run_lib.py:133] step: 891650, training_loss: 4.54795e-02
I0213 18:35:34.778957 22509476222784 run_lib.py:133] step: 891700, training_loss: 4.28595e-02
I0213 18:35:34.945078 22509476222784 run_lib.py:146] step: 891700, eval_loss: 3.85528e-02
I0213 18:35:53.660567 22509476222784 run_lib.py:133] step: 891750, training_loss: 5.13415e-02
I0213 18:36:12.428297 22509476222784 run_lib.py:133] step: 891800, training_loss: 3.33856e-02
I0213 18:36:12.595509 22509476222784 run_lib.py:146] step: 891800, eval_loss: 4.36158e-02
I0213 18:36:31.293514 22509476222784 run_lib.py:133] step: 891850, training_loss: 4.88206e-02
I0213 18:36:50.133279 22509476222784 run_lib.py:133] step: 891900, training_loss: 4.85815e-02
I0213 18:36:50.298236 22509476222784 run_lib.py:146] step: 891900, eval_loss: 5.77968e-02
I0213 18:37:08.979935 22509476222784 run_lib.py:133] step: 891950, training_loss: 3.93662e-02
I0213 18:37:27.744252 22509476222784 run_lib.py:133] step: 892000, training_loss: 3.49299e-02
I0213 18:37:27.913045 22509476222784 run_lib.py:146] step: 892000, eval_loss: 4.67848e-02
I0213 18:37:46.688546 22509476222784 run_lib.py:133] step: 892050, training_loss: 3.05097e-02
I0213 18:38:05.425682 22509476222784 run_lib.py:133] step: 892100, training_loss: 3.32002e-02
I0213 18:38:05.594888 22509476222784 run_lib.py:146] step: 892100, eval_loss: 4.21978e-02
I0213 18:38:24.538963 22509476222784 run_lib.py:133] step: 892150, training_loss: 4.35775e-02
I0213 18:38:43.304534 22509476222784 run_lib.py:133] step: 892200, training_loss: 4.82825e-02
I0213 18:38:43.469873 22509476222784 run_lib.py:146] step: 892200, eval_loss: 4.00719e-02
I0213 18:39:02.222176 22509476222784 run_lib.py:133] step: 892250, training_loss: 3.20664e-02
I0213 18:39:20.966315 22509476222784 run_lib.py:133] step: 892300, training_loss: 4.16221e-02
I0213 18:39:21.135776 22509476222784 run_lib.py:146] step: 892300, eval_loss: 3.84298e-02
I0213 18:39:40.195643 22509476222784 run_lib.py:133] step: 892350, training_loss: 4.26087e-02
I0213 18:39:58.924221 22509476222784 run_lib.py:133] step: 892400, training_loss: 3.89179e-02
I0213 18:39:59.087053 22509476222784 run_lib.py:146] step: 892400, eval_loss: 5.84787e-02
I0213 18:40:17.948079 22509476222784 run_lib.py:133] step: 892450, training_loss: 3.81429e-02
I0213 18:40:36.660412 22509476222784 run_lib.py:133] step: 892500, training_loss: 4.97663e-02
I0213 18:40:36.826755 22509476222784 run_lib.py:146] step: 892500, eval_loss: 4.34328e-02
I0213 18:40:55.709605 22509476222784 run_lib.py:133] step: 892550, training_loss: 4.25284e-02
I0213 18:41:14.472337 22509476222784 run_lib.py:133] step: 892600, training_loss: 3.75937e-02
I0213 18:41:14.652092 22509476222784 run_lib.py:146] step: 892600, eval_loss: 4.04303e-02
I0213 18:41:33.400540 22509476222784 run_lib.py:133] step: 892650, training_loss: 3.82058e-02
I0213 18:41:52.379342 22509476222784 run_lib.py:133] step: 892700, training_loss: 3.52848e-02
I0213 18:41:52.605933 22509476222784 run_lib.py:146] step: 892700, eval_loss: 4.86275e-02
I0213 18:42:11.332813 22509476222784 run_lib.py:133] step: 892750, training_loss: 2.93777e-02
I0213 18:42:30.222534 22509476222784 run_lib.py:133] step: 892800, training_loss: 3.92620e-02
I0213 18:42:30.389101 22509476222784 run_lib.py:146] step: 892800, eval_loss: 5.18866e-02
I0213 18:42:49.147818 22509476222784 run_lib.py:133] step: 892850, training_loss: 4.49605e-02
I0213 18:43:07.864369 22509476222784 run_lib.py:133] step: 892900, training_loss: 4.15159e-02
I0213 18:43:08.052862 22509476222784 run_lib.py:146] step: 892900, eval_loss: 3.55992e-02
I0213 18:43:26.991734 22509476222784 run_lib.py:133] step: 892950, training_loss: 3.57270e-02
I0213 18:43:45.714939 22509476222784 run_lib.py:133] step: 893000, training_loss: 5.50631e-02
I0213 18:43:45.880393 22509476222784 run_lib.py:146] step: 893000, eval_loss: 3.15985e-02
I0213 18:44:04.597337 22509476222784 run_lib.py:133] step: 893050, training_loss: 4.50509e-02
I0213 18:44:23.567369 22509476222784 run_lib.py:133] step: 893100, training_loss: 3.08664e-02
I0213 18:44:23.735618 22509476222784 run_lib.py:146] step: 893100, eval_loss: 3.89370e-02
I0213 18:44:42.489374 22509476222784 run_lib.py:133] step: 893150, training_loss: 3.97890e-02
I0213 18:45:01.233781 22509476222784 run_lib.py:133] step: 893200, training_loss: 3.49307e-02
I0213 18:45:01.595823 22509476222784 run_lib.py:146] step: 893200, eval_loss: 4.45043e-02
I0213 18:45:20.319334 22509476222784 run_lib.py:133] step: 893250, training_loss: 4.77158e-02
I0213 18:45:39.055591 22509476222784 run_lib.py:133] step: 893300, training_loss: 4.25241e-02
I0213 18:45:39.221099 22509476222784 run_lib.py:146] step: 893300, eval_loss: 3.59608e-02
I0213 18:45:57.982688 22509476222784 run_lib.py:133] step: 893350, training_loss: 4.35021e-02
I0213 18:46:16.715314 22509476222784 run_lib.py:133] step: 893400, training_loss: 3.73859e-02
I0213 18:46:16.887826 22509476222784 run_lib.py:146] step: 893400, eval_loss: 4.52377e-02
I0213 18:46:35.783263 22509476222784 run_lib.py:133] step: 893450, training_loss: 5.41580e-02
I0213 18:46:54.593643 22509476222784 run_lib.py:133] step: 893500, training_loss: 3.59391e-02
I0213 18:46:54.762101 22509476222784 run_lib.py:146] step: 893500, eval_loss: 4.67063e-02
I0213 18:47:13.513645 22509476222784 run_lib.py:133] step: 893550, training_loss: 4.79910e-02
I0213 18:47:32.323915 22509476222784 run_lib.py:133] step: 893600, training_loss: 4.29918e-02
I0213 18:47:32.489849 22509476222784 run_lib.py:146] step: 893600, eval_loss: 4.23660e-02
I0213 18:47:51.375622 22509476222784 run_lib.py:133] step: 893650, training_loss: 3.58580e-02
I0213 18:48:10.178106 22509476222784 run_lib.py:133] step: 893700, training_loss: 3.91339e-02
I0213 18:48:10.351956 22509476222784 run_lib.py:146] step: 893700, eval_loss: 5.17683e-02
I0213 18:48:29.093955 22509476222784 run_lib.py:133] step: 893750, training_loss: 5.99014e-02
I0213 18:48:47.860408 22509476222784 run_lib.py:133] step: 893800, training_loss: 4.69836e-02
I0213 18:48:48.032139 22509476222784 run_lib.py:146] step: 893800, eval_loss: 4.31366e-02
I0213 18:49:06.976373 22509476222784 run_lib.py:133] step: 893850, training_loss: 4.93673e-02
I0213 18:49:25.665967 22509476222784 run_lib.py:133] step: 893900, training_loss: 5.37621e-02
I0213 18:49:25.830970 22509476222784 run_lib.py:146] step: 893900, eval_loss: 3.21846e-02
I0213 18:49:44.695530 22509476222784 run_lib.py:133] step: 893950, training_loss: 4.43266e-02
I0213 18:50:03.397772 22509476222784 run_lib.py:133] step: 894000, training_loss: 4.15230e-02
I0213 18:50:03.562892 22509476222784 run_lib.py:146] step: 894000, eval_loss: 4.47402e-02
I0213 18:50:22.385279 22509476222784 run_lib.py:133] step: 894050, training_loss: 5.46530e-02
I0213 18:50:41.154161 22509476222784 run_lib.py:133] step: 894100, training_loss: 3.50828e-02
I0213 18:50:41.327053 22509476222784 run_lib.py:146] step: 894100, eval_loss: 4.01817e-02
I0213 18:51:00.014621 22509476222784 run_lib.py:133] step: 894150, training_loss: 4.19256e-02
I0213 18:51:18.929416 22509476222784 run_lib.py:133] step: 894200, training_loss: 4.01381e-02
I0213 18:51:19.100008 22509476222784 run_lib.py:146] step: 894200, eval_loss: 4.55320e-02
I0213 18:51:37.786969 22509476222784 run_lib.py:133] step: 894250, training_loss: 4.65680e-02
I0213 18:51:56.623043 22509476222784 run_lib.py:133] step: 894300, training_loss: 3.18353e-02
I0213 18:51:56.807952 22509476222784 run_lib.py:146] step: 894300, eval_loss: 3.65961e-02
I0213 18:52:15.484997 22509476222784 run_lib.py:133] step: 894350, training_loss: 3.81762e-02
I0213 18:52:34.254734 22509476222784 run_lib.py:133] step: 894400, training_loss: 3.60577e-02
I0213 18:52:34.452960 22509476222784 run_lib.py:146] step: 894400, eval_loss: 3.90638e-02
I0213 18:52:53.363686 22509476222784 run_lib.py:133] step: 894450, training_loss: 4.23100e-02
I0213 18:53:11.999700 22509476222784 run_lib.py:133] step: 894500, training_loss: 4.48302e-02
I0213 18:53:12.167754 22509476222784 run_lib.py:146] step: 894500, eval_loss: 4.01537e-02
I0213 18:53:30.872506 22509476222784 run_lib.py:133] step: 894550, training_loss: 3.93713e-02
I0213 18:53:49.520372 22509476222784 run_lib.py:133] step: 894600, training_loss: 3.55015e-02
I0213 18:53:49.685784 22509476222784 run_lib.py:146] step: 894600, eval_loss: 4.15583e-02
I0213 18:54:08.541244 22509476222784 run_lib.py:133] step: 894650, training_loss: 4.37494e-02
I0213 18:54:27.339236 22509476222784 run_lib.py:133] step: 894700, training_loss: 5.06525e-02
I0213 18:54:27.504904 22509476222784 run_lib.py:146] step: 894700, eval_loss: 3.59843e-02
I0213 18:54:46.386612 22509476222784 run_lib.py:133] step: 894750, training_loss: 4.73537e-02
I0213 18:55:05.054520 22509476222784 run_lib.py:133] step: 894800, training_loss: 4.24511e-02
I0213 18:55:05.217923 22509476222784 run_lib.py:146] step: 894800, eval_loss: 5.19963e-02
I0213 18:55:23.849902 22509476222784 run_lib.py:133] step: 894850, training_loss: 4.61581e-02
I0213 18:55:42.551437 22509476222784 run_lib.py:133] step: 894900, training_loss: 4.08613e-02
I0213 18:55:42.719998 22509476222784 run_lib.py:146] step: 894900, eval_loss: 4.66625e-02
I0213 18:56:01.627456 22509476222784 run_lib.py:133] step: 894950, training_loss: 4.39684e-02
I0213 18:56:20.523307 22509476222784 run_lib.py:133] step: 895000, training_loss: 4.12225e-02
I0213 18:56:20.691862 22509476222784 run_lib.py:146] step: 895000, eval_loss: 3.35496e-02
I0213 18:56:39.344335 22509476222784 run_lib.py:133] step: 895050, training_loss: 4.33089e-02
I0213 18:56:58.035320 22509476222784 run_lib.py:133] step: 895100, training_loss: 2.89991e-02
I0213 18:56:58.200774 22509476222784 run_lib.py:146] step: 895100, eval_loss: 3.85310e-02
I0213 18:57:17.021744 22509476222784 run_lib.py:133] step: 895150, training_loss: 4.33175e-02
I0213 18:57:35.707214 22509476222784 run_lib.py:133] step: 895200, training_loss: 3.45334e-02
I0213 18:57:35.873129 22509476222784 run_lib.py:146] step: 895200, eval_loss: 4.00382e-02
I0213 18:57:54.829590 22509476222784 run_lib.py:133] step: 895250, training_loss: 4.12336e-02
I0213 18:58:13.559411 22509476222784 run_lib.py:133] step: 895300, training_loss: 2.46858e-02
I0213 18:58:13.723926 22509476222784 run_lib.py:146] step: 895300, eval_loss: 4.68738e-02
I0213 18:58:32.602614 22509476222784 run_lib.py:133] step: 895350, training_loss: 3.75293e-02
I0213 18:58:51.286688 22509476222784 run_lib.py:133] step: 895400, training_loss: 3.95052e-02
I0213 18:58:51.464158 22509476222784 run_lib.py:146] step: 895400, eval_loss: 4.91726e-02
I0213 18:59:10.323126 22509476222784 run_lib.py:133] step: 895450, training_loss: 2.94728e-02
I0213 18:59:29.123289 22509476222784 run_lib.py:133] step: 895500, training_loss: 5.01646e-02
I0213 18:59:29.288627 22509476222784 run_lib.py:146] step: 895500, eval_loss: 4.61239e-02
I0213 18:59:47.981487 22509476222784 run_lib.py:133] step: 895550, training_loss: 4.22007e-02
I0213 19:00:06.871492 22509476222784 run_lib.py:133] step: 895600, training_loss: 4.31115e-02
I0213 19:00:07.037310 22509476222784 run_lib.py:146] step: 895600, eval_loss: 3.84087e-02
I0213 19:00:25.727769 22509476222784 run_lib.py:133] step: 895650, training_loss: 3.46431e-02
I0213 19:00:44.423277 22509476222784 run_lib.py:133] step: 895700, training_loss: 3.73148e-02
I0213 19:00:44.587749 22509476222784 run_lib.py:146] step: 895700, eval_loss: 3.97752e-02
I0213 19:01:03.451684 22509476222784 run_lib.py:133] step: 895750, training_loss: 3.93229e-02
I0213 19:01:22.387662 22509476222784 run_lib.py:133] step: 895800, training_loss: 5.33651e-02
I0213 19:01:22.555929 22509476222784 run_lib.py:146] step: 895800, eval_loss: 2.86375e-02
I0213 19:01:41.314043 22509476222784 run_lib.py:133] step: 895850, training_loss: 5.28805e-02
I0213 19:02:00.070094 22509476222784 run_lib.py:133] step: 895900, training_loss: 3.96066e-02
I0213 19:02:00.258004 22509476222784 run_lib.py:146] step: 895900, eval_loss: 4.05486e-02
I0213 19:02:18.978481 22509476222784 run_lib.py:133] step: 895950, training_loss: 4.38192e-02
I0213 19:02:37.855587 22509476222784 run_lib.py:133] step: 896000, training_loss: 4.20070e-02
I0213 19:02:38.021751 22509476222784 run_lib.py:146] step: 896000, eval_loss: 3.70945e-02
I0213 19:02:56.729214 22509476222784 run_lib.py:133] step: 896050, training_loss: 4.20824e-02
I0213 19:03:15.481756 22509476222784 run_lib.py:133] step: 896100, training_loss: 3.85228e-02
I0213 19:03:15.649193 22509476222784 run_lib.py:146] step: 896100, eval_loss: 3.97021e-02
I0213 19:03:34.449597 22509476222784 run_lib.py:133] step: 896150, training_loss: 3.99864e-02
I0213 19:03:53.384938 22509476222784 run_lib.py:133] step: 896200, training_loss: 4.25394e-02
I0213 19:03:53.547580 22509476222784 run_lib.py:146] step: 896200, eval_loss: 4.83352e-02
I0213 19:04:12.259887 22509476222784 run_lib.py:133] step: 896250, training_loss: 4.05283e-02
I0213 19:04:31.117131 22509476222784 run_lib.py:133] step: 896300, training_loss: 4.02043e-02
I0213 19:04:31.291909 22509476222784 run_lib.py:146] step: 896300, eval_loss: 3.33383e-02
I0213 19:04:50.076996 22509476222784 run_lib.py:133] step: 896350, training_loss: 3.97624e-02
I0213 19:05:08.801939 22509476222784 run_lib.py:133] step: 896400, training_loss: 5.11761e-02
I0213 19:05:08.969836 22509476222784 run_lib.py:146] step: 896400, eval_loss: 3.94919e-02
I0213 19:05:27.877497 22509476222784 run_lib.py:133] step: 896450, training_loss: 4.49436e-02
I0213 19:05:46.576850 22509476222784 run_lib.py:133] step: 896500, training_loss: 4.24751e-02
I0213 19:05:46.743759 22509476222784 run_lib.py:146] step: 896500, eval_loss: 4.77132e-02
I0213 19:06:05.371243 22509476222784 run_lib.py:133] step: 896550, training_loss: 3.77936e-02
I0213 19:06:24.048716 22509476222784 run_lib.py:133] step: 896600, training_loss: 4.34288e-02
I0213 19:06:24.217075 22509476222784 run_lib.py:146] step: 896600, eval_loss: 5.18360e-02
I0213 19:06:43.338907 22509476222784 run_lib.py:133] step: 896650, training_loss: 4.08647e-02
I0213 19:07:01.986541 22509476222784 run_lib.py:133] step: 896700, training_loss: 3.90374e-02
I0213 19:07:02.149979 22509476222784 run_lib.py:146] step: 896700, eval_loss: 4.31939e-02
I0213 19:07:21.000627 22509476222784 run_lib.py:133] step: 896750, training_loss: 4.58040e-02
I0213 19:07:39.646307 22509476222784 run_lib.py:133] step: 896800, training_loss: 4.46354e-02
I0213 19:07:39.812705 22509476222784 run_lib.py:146] step: 896800, eval_loss: 5.55348e-02
I0213 19:07:58.637904 22509476222784 run_lib.py:133] step: 896850, training_loss: 3.51203e-02
I0213 19:08:17.345049 22509476222784 run_lib.py:133] step: 896900, training_loss: 3.53707e-02
I0213 19:08:17.525815 22509476222784 run_lib.py:146] step: 896900, eval_loss: 3.89921e-02
I0213 19:08:36.271678 22509476222784 run_lib.py:133] step: 896950, training_loss: 3.93316e-02
I0213 19:08:55.214559 22509476222784 run_lib.py:133] step: 897000, training_loss: 5.04749e-02
I0213 19:08:55.380719 22509476222784 run_lib.py:146] step: 897000, eval_loss: 4.56019e-02
I0213 19:09:14.114768 22509476222784 run_lib.py:133] step: 897050, training_loss: 3.32178e-02
I0213 19:09:32.995606 22509476222784 run_lib.py:133] step: 897100, training_loss: 4.99382e-02
I0213 19:09:33.160693 22509476222784 run_lib.py:146] step: 897100, eval_loss: 4.13654e-02
I0213 19:09:51.921737 22509476222784 run_lib.py:133] step: 897150, training_loss: 4.18356e-02
I0213 19:10:10.675599 22509476222784 run_lib.py:133] step: 897200, training_loss: 4.52439e-02
I0213 19:10:10.840862 22509476222784 run_lib.py:146] step: 897200, eval_loss: 3.99140e-02
I0213 19:10:29.847414 22509476222784 run_lib.py:133] step: 897250, training_loss: 5.07327e-02
I0213 19:10:48.604959 22509476222784 run_lib.py:133] step: 897300, training_loss: 3.28867e-02
I0213 19:10:48.780217 22509476222784 run_lib.py:146] step: 897300, eval_loss: 5.99974e-02
I0213 19:11:07.470724 22509476222784 run_lib.py:133] step: 897350, training_loss: 3.46337e-02
I0213 19:11:26.348320 22509476222784 run_lib.py:133] step: 897400, training_loss: 4.85962e-02
I0213 19:11:26.512539 22509476222784 run_lib.py:146] step: 897400, eval_loss: 4.21326e-02
I0213 19:11:45.261330 22509476222784 run_lib.py:133] step: 897450, training_loss: 3.65908e-02
I0213 19:12:04.054842 22509476222784 run_lib.py:133] step: 897500, training_loss: 4.56558e-02
I0213 19:12:04.250379 22509476222784 run_lib.py:146] step: 897500, eval_loss: 4.26537e-02
I0213 19:12:23.114000 22509476222784 run_lib.py:133] step: 897550, training_loss: 4.07198e-02
I0213 19:12:41.814597 22509476222784 run_lib.py:133] step: 897600, training_loss: 4.24660e-02
I0213 19:12:41.977124 22509476222784 run_lib.py:146] step: 897600, eval_loss: 4.78897e-02
I0213 19:13:00.671453 22509476222784 run_lib.py:133] step: 897650, training_loss: 4.96304e-02
I0213 19:13:19.343936 22509476222784 run_lib.py:133] step: 897700, training_loss: 3.43256e-02
I0213 19:13:19.513994 22509476222784 run_lib.py:146] step: 897700, eval_loss: 3.35641e-02
I0213 19:13:38.436027 22509476222784 run_lib.py:133] step: 897750, training_loss: 4.16989e-02
I0213 19:13:57.240686 22509476222784 run_lib.py:133] step: 897800, training_loss: 4.14863e-02
I0213 19:13:57.415972 22509476222784 run_lib.py:146] step: 897800, eval_loss: 4.74550e-02
I0213 19:14:16.084618 22509476222784 run_lib.py:133] step: 897850, training_loss: 2.69199e-02
I0213 19:14:34.777435 22509476222784 run_lib.py:133] step: 897900, training_loss: 5.24712e-02
I0213 19:14:34.942723 22509476222784 run_lib.py:146] step: 897900, eval_loss: 4.56545e-02
I0213 19:14:53.808098 22509476222784 run_lib.py:133] step: 897950, training_loss: 3.82845e-02
I0213 19:15:12.567795 22509476222784 run_lib.py:133] step: 898000, training_loss: 4.06426e-02
I0213 19:15:12.735123 22509476222784 run_lib.py:146] step: 898000, eval_loss: 4.33819e-02
I0213 19:15:31.727332 22509476222784 run_lib.py:133] step: 898050, training_loss: 4.58906e-02
I0213 19:15:50.452613 22509476222784 run_lib.py:133] step: 898100, training_loss: 4.56739e-02
I0213 19:15:50.618870 22509476222784 run_lib.py:146] step: 898100, eval_loss: 4.73677e-02
I0213 19:16:09.481445 22509476222784 run_lib.py:133] step: 898150, training_loss: 5.12297e-02
I0213 19:16:28.226904 22509476222784 run_lib.py:133] step: 898200, training_loss: 3.70032e-02
I0213 19:16:28.400719 22509476222784 run_lib.py:146] step: 898200, eval_loss: 5.57737e-02
I0213 19:16:47.300717 22509476222784 run_lib.py:133] step: 898250, training_loss: 4.53043e-02
I0213 19:17:06.092519 22509476222784 run_lib.py:133] step: 898300, training_loss: 4.29759e-02
I0213 19:17:06.259865 22509476222784 run_lib.py:146] step: 898300, eval_loss: 4.56795e-02
I0213 19:17:24.973219 22509476222784 run_lib.py:133] step: 898350, training_loss: 4.91759e-02
I0213 19:17:43.934109 22509476222784 run_lib.py:133] step: 898400, training_loss: 5.65543e-02
I0213 19:17:44.105856 22509476222784 run_lib.py:146] step: 898400, eval_loss: 4.08016e-02
I0213 19:18:02.823715 22509476222784 run_lib.py:133] step: 898450, training_loss: 3.34220e-02
I0213 19:18:21.575533 22509476222784 run_lib.py:133] step: 898500, training_loss: 4.86860e-02
I0213 19:18:21.742229 22509476222784 run_lib.py:146] step: 898500, eval_loss: 3.97933e-02
I0213 19:18:40.738307 22509476222784 run_lib.py:133] step: 898550, training_loss: 4.70968e-02
I0213 19:18:59.511486 22509476222784 run_lib.py:133] step: 898600, training_loss: 3.75092e-02
I0213 19:18:59.676075 22509476222784 run_lib.py:146] step: 898600, eval_loss: 3.06112e-02
I0213 19:19:18.552208 22509476222784 run_lib.py:133] step: 898650, training_loss: 4.02792e-02
I0213 19:19:37.291252 22509476222784 run_lib.py:133] step: 898700, training_loss: 2.67269e-02
I0213 19:19:37.457922 22509476222784 run_lib.py:146] step: 898700, eval_loss: 4.76290e-02
I0213 19:19:56.216240 22509476222784 run_lib.py:133] step: 898750, training_loss: 4.11112e-02
I0213 19:20:15.217496 22509476222784 run_lib.py:133] step: 898800, training_loss: 4.24563e-02
I0213 19:20:15.423121 22509476222784 run_lib.py:146] step: 898800, eval_loss: 4.06925e-02
I0213 19:20:34.168263 22509476222784 run_lib.py:133] step: 898850, training_loss: 4.56443e-02
I0213 19:20:52.887999 22509476222784 run_lib.py:133] step: 898900, training_loss: 4.02965e-02
I0213 19:20:53.054904 22509476222784 run_lib.py:146] step: 898900, eval_loss: 4.62092e-02
I0213 19:21:11.760975 22509476222784 run_lib.py:133] step: 898950, training_loss: 4.10480e-02
I0213 19:21:30.703941 22509476222784 run_lib.py:133] step: 899000, training_loss: 4.00509e-02
I0213 19:21:30.866080 22509476222784 run_lib.py:146] step: 899000, eval_loss: 5.25877e-02
I0213 19:21:49.679723 22509476222784 run_lib.py:133] step: 899050, training_loss: 3.53020e-02
I0213 19:22:08.539159 22509476222784 run_lib.py:133] step: 899100, training_loss: 5.20946e-02
I0213 19:22:08.723885 22509476222784 run_lib.py:146] step: 899100, eval_loss: 5.17987e-02
I0213 19:22:27.474123 22509476222784 run_lib.py:133] step: 899150, training_loss: 3.80575e-02
I0213 19:22:46.262617 22509476222784 run_lib.py:133] step: 899200, training_loss: 4.00413e-02
I0213 19:22:46.440989 22509476222784 run_lib.py:146] step: 899200, eval_loss: 3.30502e-02
I0213 19:23:05.360229 22509476222784 run_lib.py:133] step: 899250, training_loss: 2.46504e-02
I0213 19:23:24.218216 22509476222784 run_lib.py:133] step: 899300, training_loss: 3.48441e-02
I0213 19:23:24.394957 22509476222784 run_lib.py:146] step: 899300, eval_loss: 3.97711e-02
I0213 19:23:43.199479 22509476222784 run_lib.py:133] step: 899350, training_loss: 4.33493e-02
I0213 19:24:02.008606 22509476222784 run_lib.py:133] step: 899400, training_loss: 3.79793e-02
I0213 19:24:02.175151 22509476222784 run_lib.py:146] step: 899400, eval_loss: 4.36134e-02
I0213 19:24:21.111474 22509476222784 run_lib.py:133] step: 899450, training_loss: 3.65620e-02
I0213 19:24:39.845316 22509476222784 run_lib.py:133] step: 899500, training_loss: 4.88883e-02
I0213 19:24:40.007884 22509476222784 run_lib.py:146] step: 899500, eval_loss: 4.59160e-02
I0213 19:24:58.904873 22509476222784 run_lib.py:133] step: 899550, training_loss: 4.02862e-02
I0213 19:25:17.668163 22509476222784 run_lib.py:133] step: 899600, training_loss: 5.52153e-02
I0213 19:25:17.838157 22509476222784 run_lib.py:146] step: 899600, eval_loss: 3.82103e-02
I0213 19:25:36.753410 22509476222784 run_lib.py:133] step: 899650, training_loss: 4.15331e-02
I0213 19:25:55.462988 22509476222784 run_lib.py:133] step: 899700, training_loss: 4.22216e-02
I0213 19:25:55.632200 22509476222784 run_lib.py:146] step: 899700, eval_loss: 4.10562e-02
I0213 19:26:14.306149 22509476222784 run_lib.py:133] step: 899750, training_loss: 3.71068e-02
I0213 19:26:33.141272 22509476222784 run_lib.py:133] step: 899800, training_loss: 4.70695e-02
I0213 19:26:33.311942 22509476222784 run_lib.py:146] step: 899800, eval_loss: 3.83504e-02
I0213 19:26:52.041713 22509476222784 run_lib.py:133] step: 899850, training_loss: 4.73134e-02
I0213 19:27:10.976478 22509476222784 run_lib.py:133] step: 899900, training_loss: 4.30039e-02
I0213 19:27:11.144885 22509476222784 run_lib.py:146] step: 899900, eval_loss: 3.60471e-02
I0213 19:27:29.939035 22509476222784 run_lib.py:133] step: 899950, training_loss: 3.97562e-02
I0213 19:27:48.673693 22509476222784 run_lib.py:133] step: 900000, training_loss: 4.71922e-02
I0213 19:27:49.444220 22509476222784 run_lib.py:146] step: 900000, eval_loss: 5.26286e-02
I0213 19:28:11.052422 22509476222784 run_lib.py:133] step: 900050, training_loss: 3.88243e-02
I0213 19:28:29.805886 22509476222784 run_lib.py:133] step: 900100, training_loss: 4.84359e-02
I0213 19:28:29.973039 22509476222784 run_lib.py:146] step: 900100, eval_loss: 4.85699e-02
I0213 19:28:48.936804 22509476222784 run_lib.py:133] step: 900150, training_loss: 4.25387e-02
I0213 19:29:07.687672 22509476222784 run_lib.py:133] step: 900200, training_loss: 4.05074e-02
I0213 19:29:07.854218 22509476222784 run_lib.py:146] step: 900200, eval_loss: 3.57063e-02
I0213 19:29:26.505214 22509476222784 run_lib.py:133] step: 900250, training_loss: 3.63676e-02
I0213 19:29:45.472478 22509476222784 run_lib.py:133] step: 900300, training_loss: 3.74611e-02
I0213 19:29:45.650017 22509476222784 run_lib.py:146] step: 900300, eval_loss: 3.30490e-02
I0213 19:30:04.432747 22509476222784 run_lib.py:133] step: 900350, training_loss: 5.67852e-02
I0213 19:30:23.422461 22509476222784 run_lib.py:133] step: 900400, training_loss: 4.99591e-02
I0213 19:30:23.590566 22509476222784 run_lib.py:146] step: 900400, eval_loss: 5.31603e-02
I0213 19:30:42.374307 22509476222784 run_lib.py:133] step: 900450, training_loss: 4.81704e-02
I0213 19:31:01.146664 22509476222784 run_lib.py:133] step: 900500, training_loss: 3.64670e-02
I0213 19:31:01.311018 22509476222784 run_lib.py:146] step: 900500, eval_loss: 4.02828e-02
I0213 19:31:20.021660 22509476222784 run_lib.py:133] step: 900550, training_loss: 4.04055e-02
I0213 19:31:38.951250 22509476222784 run_lib.py:133] step: 900600, training_loss: 4.73271e-02
I0213 19:31:39.127930 22509476222784 run_lib.py:146] step: 900600, eval_loss: 4.30631e-02
I0213 19:31:57.891297 22509476222784 run_lib.py:133] step: 900650, training_loss: 3.99554e-02
I0213 19:32:16.700382 22509476222784 run_lib.py:133] step: 900700, training_loss: 3.64971e-02
I0213 19:32:16.867304 22509476222784 run_lib.py:146] step: 900700, eval_loss: 4.51122e-02
I0213 19:32:35.761649 22509476222784 run_lib.py:133] step: 900750, training_loss: 3.44080e-02
I0213 19:32:54.465581 22509476222784 run_lib.py:133] step: 900800, training_loss: 3.41208e-02
I0213 19:32:54.631912 22509476222784 run_lib.py:146] step: 900800, eval_loss: 4.61094e-02
I0213 19:33:13.490007 22509476222784 run_lib.py:133] step: 900850, training_loss: 5.31638e-02
I0213 19:33:32.296643 22509476222784 run_lib.py:133] step: 900900, training_loss: 4.85000e-02
I0213 19:33:32.462853 22509476222784 run_lib.py:146] step: 900900, eval_loss: 2.38948e-02
I0213 19:33:51.257797 22509476222784 run_lib.py:133] step: 900950, training_loss: 3.80764e-02
I0213 19:34:09.950525 22509476222784 run_lib.py:133] step: 901000, training_loss: 4.79775e-02
I0213 19:34:10.112781 22509476222784 run_lib.py:146] step: 901000, eval_loss: 4.38990e-02
I0213 19:34:29.061675 22509476222784 run_lib.py:133] step: 901050, training_loss: 4.40184e-02
I0213 19:34:47.907395 22509476222784 run_lib.py:133] step: 901100, training_loss: 4.44395e-02
I0213 19:34:48.072879 22509476222784 run_lib.py:146] step: 901100, eval_loss: 3.45032e-02
I0213 19:35:06.847207 22509476222784 run_lib.py:133] step: 901150, training_loss: 3.44849e-02
I0213 19:35:25.599027 22509476222784 run_lib.py:133] step: 901200, training_loss: 4.85074e-02
I0213 19:35:25.773905 22509476222784 run_lib.py:146] step: 901200, eval_loss: 4.41913e-02
I0213 19:35:44.670109 22509476222784 run_lib.py:133] step: 901250, training_loss: 5.11132e-02
I0213 19:36:03.472379 22509476222784 run_lib.py:133] step: 901300, training_loss: 5.16706e-02
I0213 19:36:03.639748 22509476222784 run_lib.py:146] step: 901300, eval_loss: 4.29090e-02
I0213 19:36:22.506348 22509476222784 run_lib.py:133] step: 901350, training_loss: 5.76516e-02
I0213 19:36:41.152856 22509476222784 run_lib.py:133] step: 901400, training_loss: 3.83101e-02
I0213 19:36:41.328194 22509476222784 run_lib.py:146] step: 901400, eval_loss: 3.78412e-02
I0213 19:37:00.245938 22509476222784 run_lib.py:133] step: 901450, training_loss: 6.10885e-02
I0213 19:37:18.961498 22509476222784 run_lib.py:133] step: 901500, training_loss: 5.19276e-02
I0213 19:37:19.124127 22509476222784 run_lib.py:146] step: 901500, eval_loss: 4.77718e-02
I0213 19:37:38.024049 22509476222784 run_lib.py:133] step: 901550, training_loss: 4.05137e-02
I0213 19:37:56.704385 22509476222784 run_lib.py:133] step: 901600, training_loss: 3.74364e-02
I0213 19:37:56.868698 22509476222784 run_lib.py:146] step: 901600, eval_loss: 3.61286e-02
I0213 19:38:15.454845 22509476222784 run_lib.py:133] step: 901650, training_loss: 5.69623e-02
I0213 19:38:34.381341 22509476222784 run_lib.py:133] step: 901700, training_loss: 5.01172e-02
I0213 19:38:34.565028 22509476222784 run_lib.py:146] step: 901700, eval_loss: 5.04231e-02
I0213 19:38:53.321867 22509476222784 run_lib.py:133] step: 901750, training_loss: 4.28135e-02
I0213 19:39:12.144341 22509476222784 run_lib.py:133] step: 901800, training_loss: 4.40872e-02
I0213 19:39:12.311307 22509476222784 run_lib.py:146] step: 901800, eval_loss: 4.19365e-02
I0213 19:39:31.290793 22509476222784 run_lib.py:133] step: 901850, training_loss: 4.47805e-02
I0213 19:39:50.050058 22509476222784 run_lib.py:133] step: 901900, training_loss: 4.10824e-02
I0213 19:39:50.216903 22509476222784 run_lib.py:146] step: 901900, eval_loss: 3.47623e-02
I0213 19:40:09.148549 22509476222784 run_lib.py:133] step: 901950, training_loss: 4.09191e-02
I0213 19:40:27.932806 22509476222784 run_lib.py:133] step: 902000, training_loss: 5.66825e-02
I0213 19:40:28.104243 22509476222784 run_lib.py:146] step: 902000, eval_loss: 5.20725e-02
I0213 19:40:46.924705 22509476222784 run_lib.py:133] step: 902050, training_loss: 4.83133e-02
I0213 19:41:05.818309 22509476222784 run_lib.py:133] step: 902100, training_loss: 4.40882e-02
I0213 19:41:05.983117 22509476222784 run_lib.py:146] step: 902100, eval_loss: 5.01701e-02
I0213 19:41:24.686955 22509476222784 run_lib.py:133] step: 902150, training_loss: 3.11519e-02
I0213 19:41:43.356089 22509476222784 run_lib.py:133] step: 902200, training_loss: 3.19840e-02
I0213 19:41:43.534003 22509476222784 run_lib.py:146] step: 902200, eval_loss: 4.33897e-02
I0213 19:42:02.263607 22509476222784 run_lib.py:133] step: 902250, training_loss: 4.14115e-02
I0213 19:42:21.196732 22509476222784 run_lib.py:133] step: 902300, training_loss: 5.32285e-02
I0213 19:42:21.362155 22509476222784 run_lib.py:146] step: 902300, eval_loss: 4.32703e-02
I0213 19:42:40.046619 22509476222784 run_lib.py:133] step: 902350, training_loss: 4.10066e-02
I0213 19:42:58.801878 22509476222784 run_lib.py:133] step: 902400, training_loss: 4.23645e-02
I0213 19:42:58.968569 22509476222784 run_lib.py:146] step: 902400, eval_loss: 4.98033e-02
I0213 19:43:17.700083 22509476222784 run_lib.py:133] step: 902450, training_loss: 4.77945e-02
I0213 19:43:36.465551 22509476222784 run_lib.py:133] step: 902500, training_loss: 3.80855e-02
I0213 19:43:36.630805 22509476222784 run_lib.py:146] step: 902500, eval_loss: 5.29623e-02
I0213 19:43:55.546575 22509476222784 run_lib.py:133] step: 902550, training_loss: 4.61753e-02
I0213 19:44:14.335164 22509476222784 run_lib.py:133] step: 902600, training_loss: 4.28584e-02
I0213 19:44:14.503696 22509476222784 run_lib.py:146] step: 902600, eval_loss: 4.97755e-02
I0213 19:44:33.230598 22509476222784 run_lib.py:133] step: 902650, training_loss: 4.03100e-02
I0213 19:44:51.965486 22509476222784 run_lib.py:133] step: 902700, training_loss: 4.00387e-02
I0213 19:44:52.148995 22509476222784 run_lib.py:146] step: 902700, eval_loss: 4.22644e-02
I0213 19:45:11.028810 22509476222784 run_lib.py:133] step: 902750, training_loss: 3.94631e-02
I0213 19:45:29.801544 22509476222784 run_lib.py:133] step: 902800, training_loss: 4.76337e-02
I0213 19:45:29.969308 22509476222784 run_lib.py:146] step: 902800, eval_loss: 3.63249e-02
I0213 19:45:48.887572 22509476222784 run_lib.py:133] step: 902850, training_loss: 4.84942e-02
I0213 19:46:07.567272 22509476222784 run_lib.py:133] step: 902900, training_loss: 4.06450e-02
I0213 19:46:07.729966 22509476222784 run_lib.py:146] step: 902900, eval_loss: 4.79741e-02
I0213 19:46:26.557391 22509476222784 run_lib.py:133] step: 902950, training_loss: 4.13007e-02
I0213 19:46:45.252487 22509476222784 run_lib.py:133] step: 903000, training_loss: 4.17068e-02
I0213 19:46:45.428217 22509476222784 run_lib.py:146] step: 903000, eval_loss: 3.20979e-02
I0213 19:47:04.166353 22509476222784 run_lib.py:133] step: 903050, training_loss: 3.47985e-02
I0213 19:47:23.105178 22509476222784 run_lib.py:133] step: 903100, training_loss: 4.37074e-02
I0213 19:47:23.271835 22509476222784 run_lib.py:146] step: 903100, eval_loss: 3.79075e-02
I0213 19:47:41.942684 22509476222784 run_lib.py:133] step: 903150, training_loss: 2.94715e-02
I0213 19:48:00.732836 22509476222784 run_lib.py:133] step: 903200, training_loss: 4.77257e-02
I0213 19:48:00.900313 22509476222784 run_lib.py:146] step: 903200, eval_loss: 5.02416e-02
I0213 19:48:19.577729 22509476222784 run_lib.py:133] step: 903250, training_loss: 3.58838e-02
I0213 19:48:38.343771 22509476222784 run_lib.py:133] step: 903300, training_loss: 3.80484e-02
I0213 19:48:38.509286 22509476222784 run_lib.py:146] step: 903300, eval_loss: 3.66338e-02
I0213 19:48:57.426155 22509476222784 run_lib.py:133] step: 903350, training_loss: 3.15361e-02
I0213 19:49:16.125474 22509476222784 run_lib.py:133] step: 903400, training_loss: 3.33402e-02
I0213 19:49:16.288258 22509476222784 run_lib.py:146] step: 903400, eval_loss: 3.91509e-02
I0213 19:49:35.021675 22509476222784 run_lib.py:133] step: 903450, training_loss: 3.03007e-02
I0213 19:49:53.926683 22509476222784 run_lib.py:133] step: 903500, training_loss: 4.40227e-02
I0213 19:49:54.106393 22509476222784 run_lib.py:146] step: 903500, eval_loss: 3.97167e-02
I0213 19:50:12.863375 22509476222784 run_lib.py:133] step: 903550, training_loss: 4.81549e-02
I0213 19:50:31.664696 22509476222784 run_lib.py:133] step: 903600, training_loss: 4.32554e-02
I0213 19:50:32.031109 22509476222784 run_lib.py:146] step: 903600, eval_loss: 3.94333e-02
I0213 19:50:50.794883 22509476222784 run_lib.py:133] step: 903650, training_loss: 3.51266e-02
I0213 19:51:09.541060 22509476222784 run_lib.py:133] step: 903700, training_loss: 4.84285e-02
I0213 19:51:09.707037 22509476222784 run_lib.py:146] step: 903700, eval_loss: 3.77808e-02
I0213 19:51:28.457966 22509476222784 run_lib.py:133] step: 903750, training_loss: 4.44303e-02
I0213 19:51:47.222431 22509476222784 run_lib.py:133] step: 903800, training_loss: 3.51909e-02
I0213 19:51:47.389292 22509476222784 run_lib.py:146] step: 903800, eval_loss: 4.39865e-02
I0213 19:52:06.320583 22509476222784 run_lib.py:133] step: 903850, training_loss: 3.84780e-02
I0213 19:52:25.146039 22509476222784 run_lib.py:133] step: 903900, training_loss: 4.61571e-02
I0213 19:52:25.310895 22509476222784 run_lib.py:146] step: 903900, eval_loss: 3.99953e-02
I0213 19:52:43.981515 22509476222784 run_lib.py:133] step: 903950, training_loss: 4.22985e-02
I0213 19:53:02.724885 22509476222784 run_lib.py:133] step: 904000, training_loss: 3.51778e-02
I0213 19:53:02.906993 22509476222784 run_lib.py:146] step: 904000, eval_loss: 3.99117e-02
I0213 19:53:21.850963 22509476222784 run_lib.py:133] step: 904050, training_loss: 3.52974e-02
I0213 19:53:40.782351 22509476222784 run_lib.py:133] step: 904100, training_loss: 3.23919e-02
I0213 19:53:40.948960 22509476222784 run_lib.py:146] step: 904100, eval_loss: 3.21580e-02
I0213 19:53:59.694848 22509476222784 run_lib.py:133] step: 904150, training_loss: 4.61074e-02
I0213 19:54:18.445591 22509476222784 run_lib.py:133] step: 904200, training_loss: 3.52164e-02
I0213 19:54:18.612092 22509476222784 run_lib.py:146] step: 904200, eval_loss: 4.15787e-02
I0213 19:54:37.524873 22509476222784 run_lib.py:133] step: 904250, training_loss: 4.62336e-02
I0213 19:54:56.308641 22509476222784 run_lib.py:133] step: 904300, training_loss: 4.29725e-02
I0213 19:54:56.482248 22509476222784 run_lib.py:146] step: 904300, eval_loss: 4.31292e-02
I0213 19:55:15.431559 22509476222784 run_lib.py:133] step: 904350, training_loss: 4.88737e-02
I0213 19:55:34.158492 22509476222784 run_lib.py:133] step: 904400, training_loss: 3.09986e-02
I0213 19:55:34.323067 22509476222784 run_lib.py:146] step: 904400, eval_loss: 3.43795e-02
I0213 19:55:53.200417 22509476222784 run_lib.py:133] step: 904450, training_loss: 5.28397e-02
I0213 19:56:11.946492 22509476222784 run_lib.py:133] step: 904500, training_loss: 3.75578e-02
I0213 19:56:12.114244 22509476222784 run_lib.py:146] step: 904500, eval_loss: 4.34543e-02
I0213 19:56:30.879226 22509476222784 run_lib.py:133] step: 904550, training_loss: 3.83722e-02
I0213 19:56:49.857641 22509476222784 run_lib.py:133] step: 904600, training_loss: 4.66835e-02
I0213 19:56:50.026221 22509476222784 run_lib.py:146] step: 904600, eval_loss: 3.81573e-02
I0213 19:57:08.842115 22509476222784 run_lib.py:133] step: 904650, training_loss: 4.51543e-02
I0213 19:57:27.786697 22509476222784 run_lib.py:133] step: 904700, training_loss: 4.72230e-02
I0213 19:57:27.962996 22509476222784 run_lib.py:146] step: 904700, eval_loss: 4.02385e-02
I0213 19:57:46.696439 22509476222784 run_lib.py:133] step: 904750, training_loss: 3.77181e-02
I0213 19:58:05.414357 22509476222784 run_lib.py:133] step: 904800, training_loss: 3.86363e-02
I0213 19:58:05.576362 22509476222784 run_lib.py:146] step: 904800, eval_loss: 4.59052e-02
I0213 19:58:24.502756 22509476222784 run_lib.py:133] step: 904850, training_loss: 4.19721e-02
I0213 19:58:43.263701 22509476222784 run_lib.py:133] step: 904900, training_loss: 4.18701e-02
I0213 19:58:43.438383 22509476222784 run_lib.py:146] step: 904900, eval_loss: 5.61565e-02
I0213 19:59:02.216632 22509476222784 run_lib.py:133] step: 904950, training_loss: 2.66374e-02
I0213 19:59:20.985046 22509476222784 run_lib.py:133] step: 905000, training_loss: 4.14550e-02
I0213 19:59:21.162032 22509476222784 run_lib.py:146] step: 905000, eval_loss: 4.72935e-02
I0213 19:59:40.098543 22509476222784 run_lib.py:133] step: 905050, training_loss: 2.90963e-02
I0213 19:59:58.920420 22509476222784 run_lib.py:133] step: 905100, training_loss: 3.36965e-02
I0213 19:59:59.088157 22509476222784 run_lib.py:146] step: 905100, eval_loss: 3.05176e-02
I0213 20:00:17.959962 22509476222784 run_lib.py:133] step: 905150, training_loss: 3.52987e-02
I0213 20:00:36.735456 22509476222784 run_lib.py:133] step: 905200, training_loss: 4.99632e-02
I0213 20:00:36.900996 22509476222784 run_lib.py:146] step: 905200, eval_loss: 3.18164e-02
I0213 20:00:55.646292 22509476222784 run_lib.py:133] step: 905250, training_loss: 4.04340e-02
I0213 20:01:14.426433 22509476222784 run_lib.py:133] step: 905300, training_loss: 5.66701e-02
I0213 20:01:14.588025 22509476222784 run_lib.py:146] step: 905300, eval_loss: 5.02254e-02
I0213 20:01:33.465154 22509476222784 run_lib.py:133] step: 905350, training_loss: 4.38559e-02
I0213 20:01:52.332023 22509476222784 run_lib.py:133] step: 905400, training_loss: 4.84751e-02
I0213 20:01:52.507205 22509476222784 run_lib.py:146] step: 905400, eval_loss: 3.55307e-02
I0213 20:02:11.305531 22509476222784 run_lib.py:133] step: 905450, training_loss: 3.53564e-02
I0213 20:02:30.111596 22509476222784 run_lib.py:133] step: 905500, training_loss: 5.67597e-02
I0213 20:02:30.287310 22509476222784 run_lib.py:146] step: 905500, eval_loss: 4.39823e-02
I0213 20:02:49.193200 22509476222784 run_lib.py:133] step: 905550, training_loss: 5.31560e-02
I0213 20:03:07.970742 22509476222784 run_lib.py:133] step: 905600, training_loss: 3.91813e-02
I0213 20:03:08.146899 22509476222784 run_lib.py:146] step: 905600, eval_loss: 3.85881e-02
I0213 20:03:27.118944 22509476222784 run_lib.py:133] step: 905650, training_loss: 3.83067e-02
I0213 20:03:45.893957 22509476222784 run_lib.py:133] step: 905700, training_loss: 3.89462e-02
I0213 20:03:46.060217 22509476222784 run_lib.py:146] step: 905700, eval_loss: 4.07644e-02
I0213 20:04:04.999133 22509476222784 run_lib.py:133] step: 905750, training_loss: 5.05244e-02
I0213 20:04:23.678798 22509476222784 run_lib.py:133] step: 905800, training_loss: 4.51442e-02
I0213 20:04:23.840968 22509476222784 run_lib.py:146] step: 905800, eval_loss: 5.11879e-02
I0213 20:04:42.701879 22509476222784 run_lib.py:133] step: 905850, training_loss: 4.07217e-02
I0213 20:05:01.455505 22509476222784 run_lib.py:133] step: 905900, training_loss: 3.82809e-02
I0213 20:05:01.643577 22509476222784 run_lib.py:146] step: 905900, eval_loss: 4.58784e-02
I0213 20:05:20.393313 22509476222784 run_lib.py:133] step: 905950, training_loss: 3.62800e-02
I0213 20:05:39.322595 22509476222784 run_lib.py:133] step: 906000, training_loss: 3.98037e-02
I0213 20:05:39.490299 22509476222784 run_lib.py:146] step: 906000, eval_loss: 3.52184e-02
I0213 20:05:58.193524 22509476222784 run_lib.py:133] step: 906050, training_loss: 5.14671e-02
I0213 20:06:16.939934 22509476222784 run_lib.py:133] step: 906100, training_loss: 4.97815e-02
I0213 20:06:17.105094 22509476222784 run_lib.py:146] step: 906100, eval_loss: 3.65167e-02
I0213 20:06:35.936961 22509476222784 run_lib.py:133] step: 906150, training_loss: 3.32415e-02
I0213 20:06:54.857575 22509476222784 run_lib.py:133] step: 906200, training_loss: 3.47010e-02
I0213 20:06:55.023688 22509476222784 run_lib.py:146] step: 906200, eval_loss: 5.12480e-02
I0213 20:07:13.840898 22509476222784 run_lib.py:133] step: 906250, training_loss: 3.53162e-02
I0213 20:07:32.596182 22509476222784 run_lib.py:133] step: 906300, training_loss: 4.42906e-02
I0213 20:07:32.767101 22509476222784 run_lib.py:146] step: 906300, eval_loss: 3.95858e-02
I0213 20:07:51.485097 22509476222784 run_lib.py:133] step: 906350, training_loss: 4.30314e-02
I0213 20:08:10.392045 22509476222784 run_lib.py:133] step: 906400, training_loss: 3.62797e-02
I0213 20:08:10.560300 22509476222784 run_lib.py:146] step: 906400, eval_loss: 3.72153e-02
I0213 20:08:29.331002 22509476222784 run_lib.py:133] step: 906450, training_loss: 4.90208e-02
I0213 20:08:48.103951 22509476222784 run_lib.py:133] step: 906500, training_loss: 4.22535e-02
I0213 20:08:48.271270 22509476222784 run_lib.py:146] step: 906500, eval_loss: 4.20794e-02
I0213 20:09:06.986335 22509476222784 run_lib.py:133] step: 906550, training_loss: 4.53103e-02
I0213 20:09:25.881569 22509476222784 run_lib.py:133] step: 906600, training_loss: 4.95306e-02
I0213 20:09:26.048053 22509476222784 run_lib.py:146] step: 906600, eval_loss: 4.28066e-02
I0213 20:09:44.777360 22509476222784 run_lib.py:133] step: 906650, training_loss: 2.73841e-02
I0213 20:10:03.598667 22509476222784 run_lib.py:133] step: 906700, training_loss: 4.31555e-02
I0213 20:10:03.763286 22509476222784 run_lib.py:146] step: 906700, eval_loss: 3.75227e-02
I0213 20:10:22.529517 22509476222784 run_lib.py:133] step: 906750, training_loss: 3.77904e-02
I0213 20:10:41.216114 22509476222784 run_lib.py:133] step: 906800, training_loss: 5.30644e-02
I0213 20:10:41.381097 22509476222784 run_lib.py:146] step: 906800, eval_loss: 4.07230e-02
I0213 20:11:00.277113 22509476222784 run_lib.py:133] step: 906850, training_loss: 3.33247e-02
I0213 20:11:19.044620 22509476222784 run_lib.py:133] step: 906900, training_loss: 3.92612e-02
I0213 20:11:19.212206 22509476222784 run_lib.py:146] step: 906900, eval_loss: 3.94067e-02
I0213 20:11:37.904888 22509476222784 run_lib.py:133] step: 906950, training_loss: 4.12287e-02
I0213 20:11:56.713953 22509476222784 run_lib.py:133] step: 907000, training_loss: 3.98868e-02
I0213 20:11:56.886213 22509476222784 run_lib.py:146] step: 907000, eval_loss: 4.40073e-02
I0213 20:12:15.829128 22509476222784 run_lib.py:133] step: 907050, training_loss: 3.95453e-02
I0213 20:12:34.611282 22509476222784 run_lib.py:133] step: 907100, training_loss: 3.82241e-02
I0213 20:12:34.782973 22509476222784 run_lib.py:146] step: 907100, eval_loss: 4.52713e-02
I0213 20:12:53.674645 22509476222784 run_lib.py:133] step: 907150, training_loss: 4.26047e-02
I0213 20:13:12.406874 22509476222784 run_lib.py:133] step: 907200, training_loss: 4.64325e-02
I0213 20:13:12.572966 22509476222784 run_lib.py:146] step: 907200, eval_loss: 4.73617e-02
I0213 20:13:31.565847 22509476222784 run_lib.py:133] step: 907250, training_loss: 4.37791e-02
I0213 20:13:50.301625 22509476222784 run_lib.py:133] step: 907300, training_loss: 5.59316e-02
I0213 20:13:50.466286 22509476222784 run_lib.py:146] step: 907300, eval_loss: 4.84139e-02
I0213 20:14:09.177334 22509476222784 run_lib.py:133] step: 907350, training_loss: 4.48760e-02
I0213 20:14:28.036181 22509476222784 run_lib.py:133] step: 907400, training_loss: 3.84286e-02
I0213 20:14:28.205531 22509476222784 run_lib.py:146] step: 907400, eval_loss: 4.25609e-02
I0213 20:14:46.942939 22509476222784 run_lib.py:133] step: 907450, training_loss: 4.88225e-02
I0213 20:15:05.916265 22509476222784 run_lib.py:133] step: 907500, training_loss: 4.04601e-02
I0213 20:15:06.082285 22509476222784 run_lib.py:146] step: 907500, eval_loss: 4.65515e-02
I0213 20:15:24.778280 22509476222784 run_lib.py:133] step: 907550, training_loss: 5.40339e-02
I0213 20:15:43.450382 22509476222784 run_lib.py:133] step: 907600, training_loss: 3.63664e-02
I0213 20:15:43.615284 22509476222784 run_lib.py:146] step: 907600, eval_loss: 5.53412e-02
I0213 20:16:02.497096 22509476222784 run_lib.py:133] step: 907650, training_loss: 3.43136e-02
I0213 20:16:21.234109 22509476222784 run_lib.py:133] step: 907700, training_loss: 4.04120e-02
I0213 20:16:21.400152 22509476222784 run_lib.py:146] step: 907700, eval_loss: 4.75113e-02
I0213 20:16:40.164305 22509476222784 run_lib.py:133] step: 907750, training_loss: 3.56637e-02
I0213 20:16:59.059956 22509476222784 run_lib.py:133] step: 907800, training_loss: 3.97853e-02
I0213 20:16:59.227139 22509476222784 run_lib.py:146] step: 907800, eval_loss: 3.86017e-02
I0213 20:17:17.928033 22509476222784 run_lib.py:133] step: 907850, training_loss: 4.02170e-02
I0213 20:17:36.616691 22509476222784 run_lib.py:133] step: 907900, training_loss: 4.01891e-02
I0213 20:17:36.782260 22509476222784 run_lib.py:146] step: 907900, eval_loss: 4.04514e-02
I0213 20:17:55.592749 22509476222784 run_lib.py:133] step: 907950, training_loss: 4.62180e-02
I0213 20:18:14.386908 22509476222784 run_lib.py:133] step: 908000, training_loss: 3.88832e-02
I0213 20:18:14.561697 22509476222784 run_lib.py:146] step: 908000, eval_loss: 3.79752e-02
I0213 20:18:33.278457 22509476222784 run_lib.py:133] step: 908050, training_loss: 4.50131e-02
I0213 20:18:51.923067 22509476222784 run_lib.py:133] step: 908100, training_loss: 3.10993e-02
I0213 20:18:52.086758 22509476222784 run_lib.py:146] step: 908100, eval_loss: 4.04472e-02
I0213 20:19:10.960766 22509476222784 run_lib.py:133] step: 908150, training_loss: 4.59272e-02
I0213 20:19:29.769931 22509476222784 run_lib.py:133] step: 908200, training_loss: 5.03329e-02
I0213 20:19:29.935170 22509476222784 run_lib.py:146] step: 908200, eval_loss: 3.72639e-02
I0213 20:19:48.690101 22509476222784 run_lib.py:133] step: 908250, training_loss: 3.31759e-02
I0213 20:20:07.435490 22509476222784 run_lib.py:133] step: 908300, training_loss: 4.09030e-02
I0213 20:20:07.604939 22509476222784 run_lib.py:146] step: 908300, eval_loss: 4.84390e-02
I0213 20:20:26.483006 22509476222784 run_lib.py:133] step: 908350, training_loss: 3.67106e-02
I0213 20:20:45.173254 22509476222784 run_lib.py:133] step: 908400, training_loss: 4.88489e-02
I0213 20:20:45.339042 22509476222784 run_lib.py:146] step: 908400, eval_loss: 4.14906e-02
I0213 20:21:04.227521 22509476222784 run_lib.py:133] step: 908450, training_loss: 6.13918e-02
I0213 20:21:22.984990 22509476222784 run_lib.py:133] step: 908500, training_loss: 3.51906e-02
I0213 20:21:23.152286 22509476222784 run_lib.py:146] step: 908500, eval_loss: 3.87139e-02
I0213 20:21:42.126950 22509476222784 run_lib.py:133] step: 908550, training_loss: 5.03551e-02
I0213 20:22:00.805756 22509476222784 run_lib.py:133] step: 908600, training_loss: 3.12202e-02
I0213 20:22:00.968668 22509476222784 run_lib.py:146] step: 908600, eval_loss: 3.05547e-02
I0213 20:22:20.044497 22509476222784 run_lib.py:133] step: 908650, training_loss: 4.06585e-02
I0213 20:22:38.807610 22509476222784 run_lib.py:133] step: 908700, training_loss: 4.83152e-02
I0213 20:22:38.983173 22509476222784 run_lib.py:146] step: 908700, eval_loss: 3.24900e-02
I0213 20:22:57.773113 22509476222784 run_lib.py:133] step: 908750, training_loss: 4.12125e-02
I0213 20:23:16.563305 22509476222784 run_lib.py:133] step: 908800, training_loss: 4.71053e-02
I0213 20:23:16.730017 22509476222784 run_lib.py:146] step: 908800, eval_loss: 4.52226e-02
I0213 20:23:35.431700 22509476222784 run_lib.py:133] step: 908850, training_loss: 5.21845e-02
I0213 20:23:54.089789 22509476222784 run_lib.py:133] step: 908900, training_loss: 4.69633e-02
I0213 20:23:54.256066 22509476222784 run_lib.py:146] step: 908900, eval_loss: 4.78462e-02
I0213 20:24:13.125161 22509476222784 run_lib.py:133] step: 908950, training_loss: 4.13810e-02
I0213 20:24:31.799898 22509476222784 run_lib.py:133] step: 909000, training_loss: 4.03815e-02
I0213 20:24:31.966764 22509476222784 run_lib.py:146] step: 909000, eval_loss: 3.54663e-02
I0213 20:24:50.825631 22509476222784 run_lib.py:133] step: 909050, training_loss: 3.75062e-02
I0213 20:25:09.487519 22509476222784 run_lib.py:133] step: 909100, training_loss: 3.33610e-02
I0213 20:25:09.649930 22509476222784 run_lib.py:146] step: 909100, eval_loss: 4.19338e-02
I0213 20:25:28.389050 22509476222784 run_lib.py:133] step: 909150, training_loss: 3.83627e-02
I0213 20:25:47.277122 22509476222784 run_lib.py:133] step: 909200, training_loss: 3.48089e-02
I0213 20:25:47.443022 22509476222784 run_lib.py:146] step: 909200, eval_loss: 3.47721e-02
I0213 20:26:06.133796 22509476222784 run_lib.py:133] step: 909250, training_loss: 5.38484e-02
I0213 20:26:24.845209 22509476222784 run_lib.py:133] step: 909300, training_loss: 4.18921e-02
I0213 20:26:25.028911 22509476222784 run_lib.py:146] step: 909300, eval_loss: 5.08534e-02
I0213 20:26:43.802928 22509476222784 run_lib.py:133] step: 909350, training_loss: 3.54013e-02
I0213 20:27:02.717781 22509476222784 run_lib.py:133] step: 909400, training_loss: 4.29196e-02
I0213 20:27:02.884104 22509476222784 run_lib.py:146] step: 909400, eval_loss: 4.37459e-02
I0213 20:27:21.587376 22509476222784 run_lib.py:133] step: 909450, training_loss: 3.89903e-02
I0213 20:27:40.340169 22509476222784 run_lib.py:133] step: 909500, training_loss: 3.46762e-02
I0213 20:27:40.505174 22509476222784 run_lib.py:146] step: 909500, eval_loss: 4.08061e-02
I0213 20:27:59.228822 22509476222784 run_lib.py:133] step: 909550, training_loss: 4.63384e-02
I0213 20:28:18.004931 22509476222784 run_lib.py:133] step: 909600, training_loss: 3.77197e-02
I0213 20:28:18.172268 22509476222784 run_lib.py:146] step: 909600, eval_loss: 4.71751e-02
I0213 20:28:37.156916 22509476222784 run_lib.py:133] step: 909650, training_loss: 3.09139e-02
I0213 20:28:55.998783 22509476222784 run_lib.py:133] step: 909700, training_loss: 3.89077e-02
I0213 20:28:56.168272 22509476222784 run_lib.py:146] step: 909700, eval_loss: 3.69448e-02
I0213 20:29:14.863322 22509476222784 run_lib.py:133] step: 909750, training_loss: 4.92324e-02
I0213 20:29:33.558422 22509476222784 run_lib.py:133] step: 909800, training_loss: 5.45716e-02
I0213 20:29:33.726934 22509476222784 run_lib.py:146] step: 909800, eval_loss: 4.19131e-02
I0213 20:29:52.595167 22509476222784 run_lib.py:133] step: 909850, training_loss: 3.80925e-02
I0213 20:30:11.378253 22509476222784 run_lib.py:133] step: 909900, training_loss: 3.82785e-02
I0213 20:30:11.545989 22509476222784 run_lib.py:146] step: 909900, eval_loss: 4.15057e-02
I0213 20:30:30.465692 22509476222784 run_lib.py:133] step: 909950, training_loss: 4.90405e-02
I0213 20:30:49.170476 22509476222784 run_lib.py:133] step: 910000, training_loss: 3.53234e-02
I0213 20:30:49.975903 22509476222784 run_lib.py:146] step: 910000, eval_loss: 5.17556e-02
I0213 20:31:11.590361 22509476222784 run_lib.py:133] step: 910050, training_loss: 3.98955e-02
I0213 20:31:30.317163 22509476222784 run_lib.py:133] step: 910100, training_loss: 3.13912e-02
I0213 20:31:30.483380 22509476222784 run_lib.py:146] step: 910100, eval_loss: 5.36032e-02
I0213 20:31:49.354349 22509476222784 run_lib.py:133] step: 910150, training_loss: 3.66813e-02
I0213 20:32:08.025034 22509476222784 run_lib.py:133] step: 910200, training_loss: 4.69333e-02
I0213 20:32:08.190646 22509476222784 run_lib.py:146] step: 910200, eval_loss: 3.95258e-02
I0213 20:32:26.867049 22509476222784 run_lib.py:133] step: 910250, training_loss: 4.71457e-02
I0213 20:32:45.525412 22509476222784 run_lib.py:133] step: 910300, training_loss: 3.38240e-02
I0213 20:32:45.694126 22509476222784 run_lib.py:146] step: 910300, eval_loss: 4.00649e-02
I0213 20:33:04.580762 22509476222784 run_lib.py:133] step: 910350, training_loss: 3.90107e-02
I0213 20:33:23.481054 22509476222784 run_lib.py:133] step: 910400, training_loss: 3.95010e-02
I0213 20:33:23.653290 22509476222784 run_lib.py:146] step: 910400, eval_loss: 4.71931e-02
I0213 20:33:42.409584 22509476222784 run_lib.py:133] step: 910450, training_loss: 4.99979e-02
I0213 20:34:01.191256 22509476222784 run_lib.py:133] step: 910500, training_loss: 3.28414e-02
I0213 20:34:01.364990 22509476222784 run_lib.py:146] step: 910500, eval_loss: 4.40415e-02
I0213 20:34:20.293885 22509476222784 run_lib.py:133] step: 910550, training_loss: 3.76608e-02
I0213 20:34:39.051370 22509476222784 run_lib.py:133] step: 910600, training_loss: 5.69361e-02
I0213 20:34:39.231153 22509476222784 run_lib.py:146] step: 910600, eval_loss: 4.21085e-02
I0213 20:34:58.202827 22509476222784 run_lib.py:133] step: 910650, training_loss: 3.48964e-02
I0213 20:35:17.001420 22509476222784 run_lib.py:133] step: 910700, training_loss: 2.97024e-02
I0213 20:35:17.167745 22509476222784 run_lib.py:146] step: 910700, eval_loss: 4.51657e-02
I0213 20:35:36.102324 22509476222784 run_lib.py:133] step: 910750, training_loss: 3.35073e-02
I0213 20:35:54.842334 22509476222784 run_lib.py:133] step: 910800, training_loss: 4.53555e-02
I0213 20:35:55.011199 22509476222784 run_lib.py:146] step: 910800, eval_loss: 3.81827e-02
I0213 20:36:13.740005 22509476222784 run_lib.py:133] step: 910850, training_loss: 4.25134e-02
I0213 20:36:32.725198 22509476222784 run_lib.py:133] step: 910900, training_loss: 3.11422e-02
I0213 20:36:32.892264 22509476222784 run_lib.py:146] step: 910900, eval_loss: 4.49010e-02
I0213 20:36:51.619240 22509476222784 run_lib.py:133] step: 910950, training_loss: 2.82303e-02
I0213 20:37:10.518538 22509476222784 run_lib.py:133] step: 911000, training_loss: 4.26152e-02
I0213 20:37:10.682913 22509476222784 run_lib.py:146] step: 911000, eval_loss: 4.76511e-02
I0213 20:37:29.365920 22509476222784 run_lib.py:133] step: 911050, training_loss: 4.02687e-02
I0213 20:37:48.061766 22509476222784 run_lib.py:133] step: 911100, training_loss: 4.93904e-02
I0213 20:37:48.224932 22509476222784 run_lib.py:146] step: 911100, eval_loss: 4.52287e-02
I0213 20:38:07.059967 22509476222784 run_lib.py:133] step: 911150, training_loss: 4.77770e-02
I0213 20:38:25.796122 22509476222784 run_lib.py:133] step: 911200, training_loss: 3.58595e-02
I0213 20:38:25.978905 22509476222784 run_lib.py:146] step: 911200, eval_loss: 4.73903e-02
I0213 20:38:44.753847 22509476222784 run_lib.py:133] step: 911250, training_loss: 4.21585e-02
I0213 20:39:03.687784 22509476222784 run_lib.py:133] step: 911300, training_loss: 5.99856e-02
I0213 20:39:03.854226 22509476222784 run_lib.py:146] step: 911300, eval_loss: 6.27969e-02
I0213 20:39:22.562827 22509476222784 run_lib.py:133] step: 911350, training_loss: 5.48921e-02
I0213 20:39:41.287585 22509476222784 run_lib.py:133] step: 911400, training_loss: 3.50534e-02
I0213 20:39:41.618032 22509476222784 run_lib.py:146] step: 911400, eval_loss: 5.11240e-02
I0213 20:40:00.358122 22509476222784 run_lib.py:133] step: 911450, training_loss: 4.52929e-02
I0213 20:40:19.111395 22509476222784 run_lib.py:133] step: 911500, training_loss: 5.29460e-02
I0213 20:40:19.279055 22509476222784 run_lib.py:146] step: 911500, eval_loss: 3.80265e-02
I0213 20:40:38.036267 22509476222784 run_lib.py:133] step: 911550, training_loss: 4.00879e-02
I0213 20:40:56.774107 22509476222784 run_lib.py:133] step: 911600, training_loss: 4.12414e-02
I0213 20:40:56.944998 22509476222784 run_lib.py:146] step: 911600, eval_loss: 3.86772e-02
I0213 20:41:15.824441 22509476222784 run_lib.py:133] step: 911650, training_loss: 4.35484e-02
I0213 20:41:34.677382 22509476222784 run_lib.py:133] step: 911700, training_loss: 5.50341e-02
I0213 20:41:34.862032 22509476222784 run_lib.py:146] step: 911700, eval_loss: 3.80433e-02
I0213 20:41:53.607502 22509476222784 run_lib.py:133] step: 911750, training_loss: 3.80033e-02
I0213 20:42:12.357405 22509476222784 run_lib.py:133] step: 911800, training_loss: 4.95504e-02
I0213 20:42:12.532757 22509476222784 run_lib.py:146] step: 911800, eval_loss: 4.83439e-02
I0213 20:42:31.464621 22509476222784 run_lib.py:133] step: 911850, training_loss: 4.56717e-02
I0213 20:42:50.266815 22509476222784 run_lib.py:133] step: 911900, training_loss: 5.30875e-02
I0213 20:42:50.433572 22509476222784 run_lib.py:146] step: 911900, eval_loss: 3.68742e-02
I0213 20:43:09.177826 22509476222784 run_lib.py:133] step: 911950, training_loss: 5.52271e-02
I0213 20:43:27.957761 22509476222784 run_lib.py:133] step: 912000, training_loss: 4.23556e-02
I0213 20:43:28.124265 22509476222784 run_lib.py:146] step: 912000, eval_loss: 4.94259e-02
I0213 20:43:47.097843 22509476222784 run_lib.py:133] step: 912050, training_loss: 5.47310e-02
I0213 20:44:05.913072 22509476222784 run_lib.py:133] step: 912100, training_loss: 4.24870e-02
I0213 20:44:06.080135 22509476222784 run_lib.py:146] step: 912100, eval_loss: 3.95886e-02
I0213 20:44:24.957281 22509476222784 run_lib.py:133] step: 912150, training_loss: 4.48846e-02
I0213 20:44:43.719029 22509476222784 run_lib.py:133] step: 912200, training_loss: 3.18473e-02
I0213 20:44:43.901919 22509476222784 run_lib.py:146] step: 912200, eval_loss: 4.76160e-02
I0213 20:45:02.869005 22509476222784 run_lib.py:133] step: 912250, training_loss: 4.16827e-02
I0213 20:45:21.651762 22509476222784 run_lib.py:133] step: 912300, training_loss: 4.44283e-02
I0213 20:45:21.823257 22509476222784 run_lib.py:146] step: 912300, eval_loss: 3.20017e-02
I0213 20:45:40.577012 22509476222784 run_lib.py:133] step: 912350, training_loss: 4.19902e-02
I0213 20:45:59.430097 22509476222784 run_lib.py:133] step: 912400, training_loss: 3.75235e-02
I0213 20:45:59.594829 22509476222784 run_lib.py:146] step: 912400, eval_loss: 5.02365e-02
I0213 20:46:18.312102 22509476222784 run_lib.py:133] step: 912450, training_loss: 5.71261e-02
I0213 20:46:37.233858 22509476222784 run_lib.py:133] step: 912500, training_loss: 4.99291e-02
I0213 20:46:37.404415 22509476222784 run_lib.py:146] step: 912500, eval_loss: 4.25658e-02
I0213 20:46:56.193464 22509476222784 run_lib.py:133] step: 912550, training_loss: 5.22753e-02
I0213 20:47:14.940597 22509476222784 run_lib.py:133] step: 912600, training_loss: 4.79802e-02
I0213 20:47:15.106983 22509476222784 run_lib.py:146] step: 912600, eval_loss: 4.77505e-02
I0213 20:47:33.998205 22509476222784 run_lib.py:133] step: 912650, training_loss: 5.05005e-02
I0213 20:47:52.662852 22509476222784 run_lib.py:133] step: 912700, training_loss: 2.71501e-02
I0213 20:47:52.829240 22509476222784 run_lib.py:146] step: 912700, eval_loss: 4.42906e-02
I0213 20:48:11.531101 22509476222784 run_lib.py:133] step: 912750, training_loss: 3.68941e-02
I0213 20:48:30.302607 22509476222784 run_lib.py:133] step: 912800, training_loss: 3.21928e-02
I0213 20:48:30.468399 22509476222784 run_lib.py:146] step: 912800, eval_loss: 4.86042e-02
I0213 20:48:49.389686 22509476222784 run_lib.py:133] step: 912850, training_loss: 4.39481e-02
I0213 20:49:08.037744 22509476222784 run_lib.py:133] step: 912900, training_loss: 3.54614e-02
I0213 20:49:08.205025 22509476222784 run_lib.py:146] step: 912900, eval_loss: 4.44176e-02
I0213 20:49:27.066950 22509476222784 run_lib.py:133] step: 912950, training_loss: 3.85466e-02
I0213 20:49:45.817729 22509476222784 run_lib.py:133] step: 913000, training_loss: 5.19613e-02
I0213 20:49:45.981168 22509476222784 run_lib.py:146] step: 913000, eval_loss: 4.32948e-02
I0213 20:50:04.795199 22509476222784 run_lib.py:133] step: 913050, training_loss: 5.43981e-02
I0213 20:50:23.504343 22509476222784 run_lib.py:133] step: 913100, training_loss: 3.94360e-02
I0213 20:50:23.673918 22509476222784 run_lib.py:146] step: 913100, eval_loss: 4.72094e-02
I0213 20:50:42.618049 22509476222784 run_lib.py:133] step: 913150, training_loss: 2.95666e-02
I0213 20:51:01.418511 22509476222784 run_lib.py:133] step: 913200, training_loss: 3.76052e-02
I0213 20:51:01.582878 22509476222784 run_lib.py:146] step: 913200, eval_loss: 3.66610e-02
I0213 20:51:20.327929 22509476222784 run_lib.py:133] step: 913250, training_loss: 4.31649e-02
I0213 20:51:39.110299 22509476222784 run_lib.py:133] step: 913300, training_loss: 3.97040e-02
I0213 20:51:39.276719 22509476222784 run_lib.py:146] step: 913300, eval_loss: 2.80098e-02
I0213 20:51:58.274149 22509476222784 run_lib.py:133] step: 913350, training_loss: 3.27533e-02
I0213 20:52:17.033178 22509476222784 run_lib.py:133] step: 913400, training_loss: 3.99549e-02
I0213 20:52:17.195657 22509476222784 run_lib.py:146] step: 913400, eval_loss: 4.73754e-02
I0213 20:52:36.095999 22509476222784 run_lib.py:133] step: 913450, training_loss: 4.94210e-02
I0213 20:52:54.834626 22509476222784 run_lib.py:133] step: 913500, training_loss: 4.23632e-02
I0213 20:52:54.998553 22509476222784 run_lib.py:146] step: 913500, eval_loss: 4.81787e-02
I0213 20:53:13.891432 22509476222784 run_lib.py:133] step: 913550, training_loss: 4.37425e-02
I0213 20:53:32.666603 22509476222784 run_lib.py:133] step: 913600, training_loss: 3.54007e-02
I0213 20:53:32.840113 22509476222784 run_lib.py:146] step: 913600, eval_loss: 4.51158e-02
I0213 20:53:51.800203 22509476222784 run_lib.py:133] step: 913650, training_loss: 2.64745e-02
I0213 20:54:10.493746 22509476222784 run_lib.py:133] step: 913700, training_loss: 3.92532e-02
I0213 20:54:10.663850 22509476222784 run_lib.py:146] step: 913700, eval_loss: 3.76230e-02
I0213 20:54:29.427219 22509476222784 run_lib.py:133] step: 913750, training_loss: 3.53801e-02
I0213 20:54:48.291087 22509476222784 run_lib.py:133] step: 913800, training_loss: 3.64056e-02
I0213 20:54:48.455617 22509476222784 run_lib.py:146] step: 913800, eval_loss: 3.62670e-02
I0213 20:55:07.264060 22509476222784 run_lib.py:133] step: 913850, training_loss: 5.24341e-02
I0213 20:55:26.032488 22509476222784 run_lib.py:133] step: 913900, training_loss: 4.33042e-02
I0213 20:55:26.200065 22509476222784 run_lib.py:146] step: 913900, eval_loss: 3.82214e-02
I0213 20:55:45.147154 22509476222784 run_lib.py:133] step: 913950, training_loss: 4.22833e-02
I0213 20:56:04.009310 22509476222784 run_lib.py:133] step: 914000, training_loss: 4.06906e-02
I0213 20:56:04.175992 22509476222784 run_lib.py:146] step: 914000, eval_loss: 3.66430e-02
I0213 20:56:22.835823 22509476222784 run_lib.py:133] step: 914050, training_loss: 4.31264e-02
I0213 20:56:41.543650 22509476222784 run_lib.py:133] step: 914100, training_loss: 2.94474e-02
I0213 20:56:41.713824 22509476222784 run_lib.py:146] step: 914100, eval_loss: 4.45125e-02
I0213 20:57:00.448743 22509476222784 run_lib.py:133] step: 914150, training_loss: 4.19674e-02
I0213 20:57:19.422310 22509476222784 run_lib.py:133] step: 914200, training_loss: 4.05489e-02
I0213 20:57:19.595213 22509476222784 run_lib.py:146] step: 914200, eval_loss: 5.39046e-02
I0213 20:57:38.343427 22509476222784 run_lib.py:133] step: 914250, training_loss: 4.61767e-02
I0213 20:57:57.102619 22509476222784 run_lib.py:133] step: 914300, training_loss: 3.87407e-02
I0213 20:57:57.267692 22509476222784 run_lib.py:146] step: 914300, eval_loss: 2.87183e-02
I0213 20:58:15.979082 22509476222784 run_lib.py:133] step: 914350, training_loss: 2.96589e-02
I0213 20:58:34.899959 22509476222784 run_lib.py:133] step: 914400, training_loss: 3.57757e-02
I0213 20:58:35.067267 22509476222784 run_lib.py:146] step: 914400, eval_loss: 4.32977e-02
I0213 20:58:53.883952 22509476222784 run_lib.py:133] step: 914450, training_loss: 4.03178e-02
I0213 20:59:12.735206 22509476222784 run_lib.py:133] step: 914500, training_loss: 4.27065e-02
I0213 20:59:12.902252 22509476222784 run_lib.py:146] step: 914500, eval_loss: 4.99158e-02
I0213 20:59:31.681509 22509476222784 run_lib.py:133] step: 914550, training_loss: 3.45369e-02
I0213 20:59:50.436239 22509476222784 run_lib.py:133] step: 914600, training_loss: 3.64777e-02
I0213 20:59:50.607631 22509476222784 run_lib.py:146] step: 914600, eval_loss: 4.42745e-02
I0213 21:00:09.531923 22509476222784 run_lib.py:133] step: 914650, training_loss: 5.16647e-02
I0213 21:00:28.471105 22509476222784 run_lib.py:133] step: 914700, training_loss: 4.80827e-02
I0213 21:00:28.636656 22509476222784 run_lib.py:146] step: 914700, eval_loss: 3.44965e-02
I0213 21:00:47.393445 22509476222784 run_lib.py:133] step: 914750, training_loss: 3.24903e-02
I0213 21:01:06.102502 22509476222784 run_lib.py:133] step: 914800, training_loss: 3.21808e-02
I0213 21:01:06.268086 22509476222784 run_lib.py:146] step: 914800, eval_loss: 3.38035e-02
I0213 21:01:25.163859 22509476222784 run_lib.py:133] step: 914850, training_loss: 3.10245e-02
I0213 21:01:43.921843 22509476222784 run_lib.py:133] step: 914900, training_loss: 4.05548e-02
I0213 21:01:44.089992 22509476222784 run_lib.py:146] step: 914900, eval_loss: 3.64073e-02
I0213 21:02:03.066025 22509476222784 run_lib.py:133] step: 914950, training_loss: 5.66783e-02
I0213 21:02:21.876270 22509476222784 run_lib.py:133] step: 915000, training_loss: 4.56405e-02
I0213 21:02:22.053061 22509476222784 run_lib.py:146] step: 915000, eval_loss: 5.66535e-02
I0213 21:02:40.946443 22509476222784 run_lib.py:133] step: 915050, training_loss: 4.48184e-02
I0213 21:02:59.699023 22509476222784 run_lib.py:133] step: 915100, training_loss: 4.29946e-02
I0213 21:02:59.864930 22509476222784 run_lib.py:146] step: 915100, eval_loss: 5.12687e-02
I0213 21:03:18.607536 22509476222784 run_lib.py:133] step: 915150, training_loss: 5.64766e-02
I0213 21:03:37.613473 22509476222784 run_lib.py:133] step: 915200, training_loss: 4.44518e-02
I0213 21:03:37.780359 22509476222784 run_lib.py:146] step: 915200, eval_loss: 4.95063e-02
I0213 21:03:56.517973 22509476222784 run_lib.py:133] step: 915250, training_loss: 3.83100e-02
I0213 21:04:15.417934 22509476222784 run_lib.py:133] step: 915300, training_loss: 3.85998e-02
I0213 21:04:15.581999 22509476222784 run_lib.py:146] step: 915300, eval_loss: 4.52373e-02
I0213 21:04:34.353259 22509476222784 run_lib.py:133] step: 915350, training_loss: 3.36094e-02
I0213 21:04:53.134397 22509476222784 run_lib.py:133] step: 915400, training_loss: 4.90602e-02
I0213 21:04:53.299908 22509476222784 run_lib.py:146] step: 915400, eval_loss: 4.17249e-02
I0213 21:05:12.176677 22509476222784 run_lib.py:133] step: 915450, training_loss: 4.23176e-02
I0213 21:05:30.975531 22509476222784 run_lib.py:133] step: 915500, training_loss: 3.98981e-02
I0213 21:05:31.157048 22509476222784 run_lib.py:146] step: 915500, eval_loss: 3.26591e-02
I0213 21:05:49.918174 22509476222784 run_lib.py:133] step: 915550, training_loss: 4.98234e-02
I0213 21:06:08.914650 22509476222784 run_lib.py:133] step: 915600, training_loss: 3.67777e-02
I0213 21:06:09.081123 22509476222784 run_lib.py:146] step: 915600, eval_loss: 4.15672e-02
I0213 21:06:27.812060 22509476222784 run_lib.py:133] step: 915650, training_loss: 4.07424e-02
I0213 21:06:46.507396 22509476222784 run_lib.py:133] step: 915700, training_loss: 3.93759e-02
I0213 21:06:46.672680 22509476222784 run_lib.py:146] step: 915700, eval_loss: 4.63951e-02
I0213 21:07:05.477682 22509476222784 run_lib.py:133] step: 915750, training_loss: 5.23258e-02
I0213 21:07:24.294552 22509476222784 run_lib.py:133] step: 915800, training_loss: 4.25894e-02
I0213 21:07:24.462325 22509476222784 run_lib.py:146] step: 915800, eval_loss: 5.27897e-02
I0213 21:07:43.253962 22509476222784 run_lib.py:133] step: 915850, training_loss: 4.93048e-02
I0213 21:08:01.961218 22509476222784 run_lib.py:133] step: 915900, training_loss: 6.08325e-02
I0213 21:08:02.126826 22509476222784 run_lib.py:146] step: 915900, eval_loss: 4.02837e-02
I0213 21:08:20.867840 22509476222784 run_lib.py:133] step: 915950, training_loss: 4.39251e-02
I0213 21:08:39.716516 22509476222784 run_lib.py:133] step: 916000, training_loss: 2.94052e-02
I0213 21:08:39.901128 22509476222784 run_lib.py:146] step: 916000, eval_loss: 4.49783e-02
I0213 21:08:58.730389 22509476222784 run_lib.py:133] step: 916050, training_loss: 4.22921e-02
I0213 21:09:17.511067 22509476222784 run_lib.py:133] step: 916100, training_loss: 3.88832e-02
I0213 21:09:17.674079 22509476222784 run_lib.py:146] step: 916100, eval_loss: 3.93223e-02
I0213 21:09:36.586137 22509476222784 run_lib.py:133] step: 916150, training_loss: 5.46287e-02
I0213 21:09:55.375675 22509476222784 run_lib.py:133] step: 916200, training_loss: 5.06038e-02
I0213 21:09:55.540420 22509476222784 run_lib.py:146] step: 916200, eval_loss: 4.76727e-02
I0213 21:10:14.417905 22509476222784 run_lib.py:133] step: 916250, training_loss: 3.29354e-02
I0213 21:10:33.188642 22509476222784 run_lib.py:133] step: 916300, training_loss: 3.52745e-02
I0213 21:10:33.356726 22509476222784 run_lib.py:146] step: 916300, eval_loss: 4.53683e-02
I0213 21:10:52.365588 22509476222784 run_lib.py:133] step: 916350, training_loss: 4.67360e-02
I0213 21:11:11.145610 22509476222784 run_lib.py:133] step: 916400, training_loss: 3.63290e-02
I0213 21:11:11.315306 22509476222784 run_lib.py:146] step: 916400, eval_loss: 3.93699e-02
I0213 21:11:30.225419 22509476222784 run_lib.py:133] step: 916450, training_loss: 4.02853e-02
I0213 21:11:48.990251 22509476222784 run_lib.py:133] step: 916500, training_loss: 3.98852e-02
I0213 21:11:49.210043 22509476222784 run_lib.py:146] step: 916500, eval_loss: 4.11252e-02
I0213 21:12:07.995062 22509476222784 run_lib.py:133] step: 916550, training_loss: 4.65845e-02
I0213 21:12:26.962296 22509476222784 run_lib.py:133] step: 916600, training_loss: 4.17470e-02
I0213 21:12:27.129448 22509476222784 run_lib.py:146] step: 916600, eval_loss: 4.13816e-02
I0213 21:12:45.907634 22509476222784 run_lib.py:133] step: 916650, training_loss: 4.34817e-02
I0213 21:13:04.672563 22509476222784 run_lib.py:133] step: 916700, training_loss: 4.08506e-02
I0213 21:13:04.838047 22509476222784 run_lib.py:146] step: 916700, eval_loss: 3.61482e-02
I0213 21:13:23.826095 22509476222784 run_lib.py:133] step: 916750, training_loss: 4.71734e-02
I0213 21:13:42.605075 22509476222784 run_lib.py:133] step: 916800, training_loss: 3.57531e-02
I0213 21:13:42.780129 22509476222784 run_lib.py:146] step: 916800, eval_loss: 4.17139e-02
I0213 21:14:01.721205 22509476222784 run_lib.py:133] step: 916850, training_loss: 4.10125e-02
I0213 21:14:20.511421 22509476222784 run_lib.py:133] step: 916900, training_loss: 3.41012e-02
I0213 21:14:20.676428 22509476222784 run_lib.py:146] step: 916900, eval_loss: 5.04101e-02
I0213 21:14:39.387244 22509476222784 run_lib.py:133] step: 916950, training_loss: 3.49744e-02
I0213 21:14:58.322735 22509476222784 run_lib.py:133] step: 917000, training_loss: 5.68735e-02
I0213 21:14:58.489982 22509476222784 run_lib.py:146] step: 917000, eval_loss: 4.61781e-02
I0213 21:15:17.222240 22509476222784 run_lib.py:133] step: 917050, training_loss: 4.67681e-02
I0213 21:15:36.008531 22509476222784 run_lib.py:133] step: 917100, training_loss: 3.78222e-02
I0213 21:15:36.176539 22509476222784 run_lib.py:146] step: 917100, eval_loss: 3.42252e-02
I0213 21:15:54.954323 22509476222784 run_lib.py:133] step: 917150, training_loss: 5.01861e-02
I0213 21:16:13.920841 22509476222784 run_lib.py:133] step: 917200, training_loss: 4.95693e-02
I0213 21:16:14.082648 22509476222784 run_lib.py:146] step: 917200, eval_loss: 5.30593e-02
I0213 21:16:32.813734 22509476222784 run_lib.py:133] step: 917250, training_loss: 4.99208e-02
I0213 21:16:51.659502 22509476222784 run_lib.py:133] step: 917300, training_loss: 3.26985e-02
I0213 21:16:51.834327 22509476222784 run_lib.py:146] step: 917300, eval_loss: 4.45746e-02
I0213 21:17:10.604987 22509476222784 run_lib.py:133] step: 917350, training_loss: 4.14471e-02
I0213 21:17:29.375213 22509476222784 run_lib.py:133] step: 917400, training_loss: 3.99949e-02
I0213 21:17:29.542246 22509476222784 run_lib.py:146] step: 917400, eval_loss: 4.52973e-02
I0213 21:17:48.465074 22509476222784 run_lib.py:133] step: 917450, training_loss: 3.49061e-02
I0213 21:18:07.236408 22509476222784 run_lib.py:133] step: 917500, training_loss: 3.31726e-02
I0213 21:18:07.402074 22509476222784 run_lib.py:146] step: 917500, eval_loss: 4.52243e-02
I0213 21:18:26.105632 22509476222784 run_lib.py:133] step: 917550, training_loss: 5.19811e-02
I0213 21:18:44.923619 22509476222784 run_lib.py:133] step: 917600, training_loss: 3.38240e-02
I0213 21:18:45.094366 22509476222784 run_lib.py:146] step: 917600, eval_loss: 4.03422e-02
I0213 21:19:04.020758 22509476222784 run_lib.py:133] step: 917650, training_loss: 2.99593e-02
I0213 21:19:22.687869 22509476222784 run_lib.py:133] step: 917700, training_loss: 4.84856e-02
I0213 21:19:22.850967 22509476222784 run_lib.py:146] step: 917700, eval_loss: 3.68444e-02
I0213 21:19:41.731308 22509476222784 run_lib.py:133] step: 917750, training_loss: 4.38875e-02
I0213 21:20:00.465018 22509476222784 run_lib.py:133] step: 917800, training_loss: 4.19927e-02
I0213 21:20:00.642175 22509476222784 run_lib.py:146] step: 917800, eval_loss: 4.44514e-02
I0213 21:20:19.591037 22509476222784 run_lib.py:133] step: 917850, training_loss: 4.20130e-02
I0213 21:20:38.334291 22509476222784 run_lib.py:133] step: 917900, training_loss: 2.69707e-02
I0213 21:20:38.509891 22509476222784 run_lib.py:146] step: 917900, eval_loss: 4.69346e-02
I0213 21:20:57.280405 22509476222784 run_lib.py:133] step: 917950, training_loss: 4.72983e-02
I0213 21:21:16.146017 22509476222784 run_lib.py:133] step: 918000, training_loss: 3.92614e-02
I0213 21:21:16.314003 22509476222784 run_lib.py:146] step: 918000, eval_loss: 5.30061e-02
I0213 21:21:35.079543 22509476222784 run_lib.py:133] step: 918050, training_loss: 3.80297e-02
I0213 21:21:54.079128 22509476222784 run_lib.py:133] step: 918100, training_loss: 3.65546e-02
I0213 21:21:54.245221 22509476222784 run_lib.py:146] step: 918100, eval_loss: 4.03606e-02
I0213 21:22:13.027381 22509476222784 run_lib.py:133] step: 918150, training_loss: 4.77279e-02
I0213 21:22:31.766525 22509476222784 run_lib.py:133] step: 918200, training_loss: 4.73413e-02
I0213 21:22:31.955129 22509476222784 run_lib.py:146] step: 918200, eval_loss: 4.61632e-02
I0213 21:22:50.849506 22509476222784 run_lib.py:133] step: 918250, training_loss: 3.36995e-02
I0213 21:23:09.612119 22509476222784 run_lib.py:133] step: 918300, training_loss: 5.44420e-02
I0213 21:23:09.795101 22509476222784 run_lib.py:146] step: 918300, eval_loss: 3.00349e-02
I0213 21:23:28.604094 22509476222784 run_lib.py:133] step: 918350, training_loss: 3.97848e-02
I0213 21:23:47.573566 22509476222784 run_lib.py:133] step: 918400, training_loss: 5.23549e-02
I0213 21:23:47.739169 22509476222784 run_lib.py:146] step: 918400, eval_loss: 3.65998e-02
I0213 21:24:06.474463 22509476222784 run_lib.py:133] step: 918450, training_loss: 3.99318e-02
I0213 21:24:25.238538 22509476222784 run_lib.py:133] step: 918500, training_loss: 4.18980e-02
I0213 21:24:25.564089 22509476222784 run_lib.py:146] step: 918500, eval_loss: 4.15933e-02
I0213 21:24:44.331650 22509476222784 run_lib.py:133] step: 918550, training_loss: 6.02541e-02
I0213 21:25:03.150608 22509476222784 run_lib.py:133] step: 918600, training_loss: 3.48605e-02
I0213 21:25:03.315423 22509476222784 run_lib.py:146] step: 918600, eval_loss: 4.71397e-02
I0213 21:25:22.115005 22509476222784 run_lib.py:133] step: 918650, training_loss: 4.08701e-02
I0213 21:25:40.852968 22509476222784 run_lib.py:133] step: 918700, training_loss: 5.68019e-02
I0213 21:25:41.018052 22509476222784 run_lib.py:146] step: 918700, eval_loss: 4.39380e-02
I0213 21:25:59.920215 22509476222784 run_lib.py:133] step: 918750, training_loss: 4.32843e-02
I0213 21:26:18.723533 22509476222784 run_lib.py:133] step: 918800, training_loss: 3.84796e-02
I0213 21:26:18.903121 22509476222784 run_lib.py:146] step: 918800, eval_loss: 3.91461e-02
I0213 21:26:37.659078 22509476222784 run_lib.py:133] step: 918850, training_loss: 4.56883e-02
I0213 21:26:56.461534 22509476222784 run_lib.py:133] step: 918900, training_loss: 4.81188e-02
I0213 21:26:56.627420 22509476222784 run_lib.py:146] step: 918900, eval_loss: 4.65922e-02
I0213 21:27:15.563628 22509476222784 run_lib.py:133] step: 918950, training_loss: 3.95585e-02
I0213 21:27:34.377625 22509476222784 run_lib.py:133] step: 919000, training_loss: 3.78259e-02
I0213 21:27:34.549058 22509476222784 run_lib.py:146] step: 919000, eval_loss: 3.79739e-02
I0213 21:27:53.315683 22509476222784 run_lib.py:133] step: 919050, training_loss: 4.89425e-02
I0213 21:28:12.146067 22509476222784 run_lib.py:133] step: 919100, training_loss: 3.46433e-02
I0213 21:28:12.314353 22509476222784 run_lib.py:146] step: 919100, eval_loss: 4.95692e-02
I0213 21:28:31.264050 22509476222784 run_lib.py:133] step: 919150, training_loss: 4.27477e-02
I0213 21:28:49.977566 22509476222784 run_lib.py:133] step: 919200, training_loss: 4.15150e-02
I0213 21:28:50.144010 22509476222784 run_lib.py:146] step: 919200, eval_loss: 3.88792e-02
I0213 21:29:09.013671 22509476222784 run_lib.py:133] step: 919250, training_loss: 4.29887e-02
I0213 21:29:27.765896 22509476222784 run_lib.py:133] step: 919300, training_loss: 4.35195e-02
I0213 21:29:27.941542 22509476222784 run_lib.py:146] step: 919300, eval_loss: 3.46044e-02
I0213 21:29:46.819275 22509476222784 run_lib.py:133] step: 919350, training_loss: 3.84463e-02
I0213 21:30:05.632094 22509476222784 run_lib.py:133] step: 919400, training_loss: 5.28677e-02
I0213 21:30:05.799361 22509476222784 run_lib.py:146] step: 919400, eval_loss: 3.92478e-02
I0213 21:30:24.588125 22509476222784 run_lib.py:133] step: 919450, training_loss: 5.03088e-02
I0213 21:30:43.546427 22509476222784 run_lib.py:133] step: 919500, training_loss: 3.70462e-02
I0213 21:30:43.711774 22509476222784 run_lib.py:146] step: 919500, eval_loss: 3.58998e-02
I0213 21:31:02.471705 22509476222784 run_lib.py:133] step: 919550, training_loss: 4.40486e-02
I0213 21:31:21.396578 22509476222784 run_lib.py:133] step: 919600, training_loss: 3.81402e-02
I0213 21:31:21.561158 22509476222784 run_lib.py:146] step: 919600, eval_loss: 5.04225e-02
I0213 21:31:40.341332 22509476222784 run_lib.py:133] step: 919650, training_loss: 4.23227e-02
I0213 21:31:59.101401 22509476222784 run_lib.py:133] step: 919700, training_loss: 4.72567e-02
I0213 21:31:59.268105 22509476222784 run_lib.py:146] step: 919700, eval_loss: 4.53163e-02
I0213 21:32:18.239220 22509476222784 run_lib.py:133] step: 919750, training_loss: 3.83167e-02
I0213 21:32:36.988964 22509476222784 run_lib.py:133] step: 919800, training_loss: 3.72126e-02
I0213 21:32:37.178190 22509476222784 run_lib.py:146] step: 919800, eval_loss: 4.14343e-02
I0213 21:32:55.967025 22509476222784 run_lib.py:133] step: 919850, training_loss: 4.21947e-02
I0213 21:33:14.754266 22509476222784 run_lib.py:133] step: 919900, training_loss: 4.42339e-02
I0213 21:33:14.921270 22509476222784 run_lib.py:146] step: 919900, eval_loss: 4.27682e-02
I0213 21:33:33.846034 22509476222784 run_lib.py:133] step: 919950, training_loss: 3.46372e-02
I0213 21:33:52.560136 22509476222784 run_lib.py:133] step: 920000, training_loss: 4.04748e-02
I0213 21:33:53.366852 22509476222784 run_lib.py:146] step: 920000, eval_loss: 3.50689e-02
I0213 21:34:15.003634 22509476222784 run_lib.py:133] step: 920050, training_loss: 4.10707e-02
I0213 21:34:33.798487 22509476222784 run_lib.py:133] step: 920100, training_loss: 4.84881e-02
I0213 21:34:33.964966 22509476222784 run_lib.py:146] step: 920100, eval_loss: 4.64662e-02
I0213 21:34:52.899008 22509476222784 run_lib.py:133] step: 920150, training_loss: 4.07547e-02
I0213 21:35:11.568924 22509476222784 run_lib.py:133] step: 920200, training_loss: 3.48700e-02
I0213 21:35:11.733773 22509476222784 run_lib.py:146] step: 920200, eval_loss: 4.32406e-02
I0213 21:35:30.444983 22509476222784 run_lib.py:133] step: 920250, training_loss: 4.48453e-02
I0213 21:35:49.332225 22509476222784 run_lib.py:133] step: 920300, training_loss: 4.98086e-02
I0213 21:35:49.500777 22509476222784 run_lib.py:146] step: 920300, eval_loss: 4.68277e-02
I0213 21:36:08.267167 22509476222784 run_lib.py:133] step: 920350, training_loss: 3.94092e-02
I0213 21:36:27.068166 22509476222784 run_lib.py:133] step: 920400, training_loss: 4.46313e-02
I0213 21:36:27.243939 22509476222784 run_lib.py:146] step: 920400, eval_loss: 3.33248e-02
I0213 21:36:46.013056 22509476222784 run_lib.py:133] step: 920450, training_loss: 4.93829e-02
I0213 21:37:04.922999 22509476222784 run_lib.py:133] step: 920500, training_loss: 4.32327e-02
I0213 21:37:05.089771 22509476222784 run_lib.py:146] step: 920500, eval_loss: 2.87251e-02
I0213 21:37:23.823794 22509476222784 run_lib.py:133] step: 920550, training_loss: 4.10717e-02
I0213 21:37:42.659097 22509476222784 run_lib.py:133] step: 920600, training_loss: 4.13789e-02
I0213 21:37:42.823781 22509476222784 run_lib.py:146] step: 920600, eval_loss: 3.95400e-02
I0213 21:38:01.610403 22509476222784 run_lib.py:133] step: 920650, training_loss: 3.92452e-02
I0213 21:38:20.359929 22509476222784 run_lib.py:133] step: 920700, training_loss: 5.01168e-02
I0213 21:38:20.524863 22509476222784 run_lib.py:146] step: 920700, eval_loss: 4.11206e-02
I0213 21:38:39.393581 22509476222784 run_lib.py:133] step: 920750, training_loss: 3.00628e-02
I0213 21:38:58.223679 22509476222784 run_lib.py:133] step: 920800, training_loss: 4.86315e-02
I0213 21:38:58.391231 22509476222784 run_lib.py:146] step: 920800, eval_loss: 4.35195e-02
I0213 21:39:17.120860 22509476222784 run_lib.py:133] step: 920850, training_loss: 3.97490e-02
I0213 21:39:35.941234 22509476222784 run_lib.py:133] step: 920900, training_loss: 3.37619e-02
I0213 21:39:36.127484 22509476222784 run_lib.py:146] step: 920900, eval_loss: 4.58035e-02
I0213 21:39:55.082928 22509476222784 run_lib.py:133] step: 920950, training_loss: 4.07019e-02
I0213 21:40:13.795060 22509476222784 run_lib.py:133] step: 921000, training_loss: 4.40540e-02
I0213 21:40:13.956805 22509476222784 run_lib.py:146] step: 921000, eval_loss: 4.40057e-02
I0213 21:40:32.846136 22509476222784 run_lib.py:133] step: 921050, training_loss: 3.19833e-02
I0213 21:40:51.565222 22509476222784 run_lib.py:133] step: 921100, training_loss: 5.18679e-02
I0213 21:40:51.729203 22509476222784 run_lib.py:146] step: 921100, eval_loss: 3.21614e-02
I0213 21:41:10.685400 22509476222784 run_lib.py:133] step: 921150, training_loss: 4.31247e-02
I0213 21:41:29.418296 22509476222784 run_lib.py:133] step: 921200, training_loss: 5.12505e-02
I0213 21:41:29.585117 22509476222784 run_lib.py:146] step: 921200, eval_loss: 4.67476e-02
I0213 21:41:48.286730 22509476222784 run_lib.py:133] step: 921250, training_loss: 3.54920e-02
I0213 21:42:07.195517 22509476222784 run_lib.py:133] step: 921300, training_loss: 3.25922e-02
I0213 21:42:07.364233 22509476222784 run_lib.py:146] step: 921300, eval_loss: 2.66605e-02
I0213 21:42:26.098857 22509476222784 run_lib.py:133] step: 921350, training_loss: 4.05611e-02
I0213 21:42:45.116995 22509476222784 run_lib.py:133] step: 921400, training_loss: 3.90245e-02
I0213 21:42:45.296255 22509476222784 run_lib.py:146] step: 921400, eval_loss: 3.95379e-02
I0213 21:43:04.032494 22509476222784 run_lib.py:133] step: 921450, training_loss: 3.69465e-02
I0213 21:43:22.723572 22509476222784 run_lib.py:133] step: 921500, training_loss: 4.88968e-02
I0213 21:43:22.899956 22509476222784 run_lib.py:146] step: 921500, eval_loss: 4.13709e-02
I0213 21:43:41.770141 22509476222784 run_lib.py:133] step: 921550, training_loss: 4.48556e-02
I0213 21:44:00.478803 22509476222784 run_lib.py:133] step: 921600, training_loss: 4.53849e-02
I0213 21:44:00.647173 22509476222784 run_lib.py:146] step: 921600, eval_loss: 4.72677e-02
I0213 21:44:19.446211 22509476222784 run_lib.py:133] step: 921650, training_loss: 4.54718e-02
I0213 21:44:38.099474 22509476222784 run_lib.py:133] step: 921700, training_loss: 2.94999e-02
I0213 21:44:38.268041 22509476222784 run_lib.py:146] step: 921700, eval_loss: 3.55163e-02
I0213 21:44:57.170464 22509476222784 run_lib.py:133] step: 921750, training_loss: 4.00896e-02
I0213 21:45:15.888650 22509476222784 run_lib.py:133] step: 921800, training_loss: 4.49495e-02
I0213 21:45:16.054967 22509476222784 run_lib.py:146] step: 921800, eval_loss: 5.74989e-02
I0213 21:45:34.900940 22509476222784 run_lib.py:133] step: 921850, training_loss: 4.30979e-02
I0213 21:45:53.725068 22509476222784 run_lib.py:133] step: 921900, training_loss: 4.59673e-02
I0213 21:45:53.900385 22509476222784 run_lib.py:146] step: 921900, eval_loss: 3.98264e-02
I0213 21:46:12.622300 22509476222784 run_lib.py:133] step: 921950, training_loss: 4.60532e-02
I0213 21:46:31.284379 22509476222784 run_lib.py:133] step: 922000, training_loss: 3.00523e-02
I0213 21:46:31.448968 22509476222784 run_lib.py:146] step: 922000, eval_loss: 3.82413e-02
I0213 21:46:50.343442 22509476222784 run_lib.py:133] step: 922050, training_loss: 3.82855e-02
I0213 21:47:09.131657 22509476222784 run_lib.py:133] step: 922100, training_loss: 4.90105e-02
I0213 21:47:09.306255 22509476222784 run_lib.py:146] step: 922100, eval_loss: 4.27533e-02
I0213 21:47:28.164671 22509476222784 run_lib.py:133] step: 922150, training_loss: 4.58391e-02
I0213 21:47:46.975053 22509476222784 run_lib.py:133] step: 922200, training_loss: 3.73389e-02
I0213 21:47:47.151506 22509476222784 run_lib.py:146] step: 922200, eval_loss: 3.30932e-02
I0213 21:48:06.062607 22509476222784 run_lib.py:133] step: 922250, training_loss: 4.70445e-02
I0213 21:48:24.787048 22509476222784 run_lib.py:133] step: 922300, training_loss: 3.84921e-02
I0213 21:48:24.953993 22509476222784 run_lib.py:146] step: 922300, eval_loss: 3.14238e-02
I0213 21:48:43.850091 22509476222784 run_lib.py:133] step: 922350, training_loss: 4.22920e-02
I0213 21:49:02.641294 22509476222784 run_lib.py:133] step: 922400, training_loss: 4.63532e-02
I0213 21:49:02.809337 22509476222784 run_lib.py:146] step: 922400, eval_loss: 3.83386e-02
I0213 21:49:21.790585 22509476222784 run_lib.py:133] step: 922450, training_loss: 3.78461e-02
I0213 21:49:40.498864 22509476222784 run_lib.py:133] step: 922500, training_loss: 2.56126e-02
I0213 21:49:40.659940 22509476222784 run_lib.py:146] step: 922500, eval_loss: 3.64283e-02
I0213 21:49:59.488384 22509476222784 run_lib.py:133] step: 922550, training_loss: 4.77680e-02
I0213 21:50:18.175724 22509476222784 run_lib.py:133] step: 922600, training_loss: 3.53890e-02
I0213 21:50:18.343046 22509476222784 run_lib.py:146] step: 922600, eval_loss: 4.71039e-02
I0213 21:50:37.029686 22509476222784 run_lib.py:133] step: 922650, training_loss: 4.18135e-02
I0213 21:50:55.918558 22509476222784 run_lib.py:133] step: 922700, training_loss: 2.95300e-02
I0213 21:50:56.102063 22509476222784 run_lib.py:146] step: 922700, eval_loss: 4.28270e-02
I0213 21:51:14.816462 22509476222784 run_lib.py:133] step: 922750, training_loss: 4.05019e-02
I0213 21:51:33.538004 22509476222784 run_lib.py:133] step: 922800, training_loss: 4.27541e-02
I0213 21:51:33.705821 22509476222784 run_lib.py:146] step: 922800, eval_loss: 4.02602e-02
I0213 21:51:52.591260 22509476222784 run_lib.py:133] step: 922850, training_loss: 3.49262e-02
I0213 21:52:11.431635 22509476222784 run_lib.py:133] step: 922900, training_loss: 3.75200e-02
I0213 21:52:11.598947 22509476222784 run_lib.py:146] step: 922900, eval_loss: 4.52593e-02
I0213 21:52:30.349661 22509476222784 run_lib.py:133] step: 922950, training_loss: 5.31439e-02
I0213 21:52:49.084232 22509476222784 run_lib.py:133] step: 923000, training_loss: 4.32820e-02
I0213 21:52:49.270054 22509476222784 run_lib.py:146] step: 923000, eval_loss: 4.78311e-02
I0213 21:53:07.957578 22509476222784 run_lib.py:133] step: 923050, training_loss: 2.76594e-02
I0213 21:53:26.866247 22509476222784 run_lib.py:133] step: 923100, training_loss: 5.54768e-02
I0213 21:53:27.032959 22509476222784 run_lib.py:146] step: 923100, eval_loss: 4.58799e-02
I0213 21:53:45.727455 22509476222784 run_lib.py:133] step: 923150, training_loss: 4.98814e-02
I0213 21:54:04.452867 22509476222784 run_lib.py:133] step: 923200, training_loss: 4.74550e-02
I0213 21:54:04.625138 22509476222784 run_lib.py:146] step: 923200, eval_loss: 4.52166e-02
I0213 21:54:23.364205 22509476222784 run_lib.py:133] step: 923250, training_loss: 4.61957e-02
I0213 21:54:42.342272 22509476222784 run_lib.py:133] step: 923300, training_loss: 4.03478e-02
I0213 21:54:42.510352 22509476222784 run_lib.py:146] step: 923300, eval_loss: 4.32266e-02
I0213 21:55:01.255828 22509476222784 run_lib.py:133] step: 923350, training_loss: 4.25087e-02
I0213 21:55:20.021320 22509476222784 run_lib.py:133] step: 923400, training_loss: 4.48776e-02
I0213 21:55:20.187169 22509476222784 run_lib.py:146] step: 923400, eval_loss: 5.08561e-02
I0213 21:55:38.867739 22509476222784 run_lib.py:133] step: 923450, training_loss: 4.92883e-02
I0213 21:55:57.634366 22509476222784 run_lib.py:133] step: 923500, training_loss: 4.32561e-02
I0213 21:55:57.811010 22509476222784 run_lib.py:146] step: 923500, eval_loss: 3.73662e-02
I0213 21:56:16.777433 22509476222784 run_lib.py:133] step: 923550, training_loss: 4.56258e-02
I0213 21:56:35.623259 22509476222784 run_lib.py:133] step: 923600, training_loss: 3.45020e-02
I0213 21:56:35.792346 22509476222784 run_lib.py:146] step: 923600, eval_loss: 4.94268e-02
I0213 21:56:54.509840 22509476222784 run_lib.py:133] step: 923650, training_loss: 4.72777e-02
I0213 21:57:13.269363 22509476222784 run_lib.py:133] step: 923700, training_loss: 4.25159e-02
I0213 21:57:13.434985 22509476222784 run_lib.py:146] step: 923700, eval_loss: 4.34471e-02
I0213 21:57:32.338516 22509476222784 run_lib.py:133] step: 923750, training_loss: 3.85343e-02
I0213 21:57:51.117733 22509476222784 run_lib.py:133] step: 923800, training_loss: 5.24427e-02
I0213 21:57:51.285188 22509476222784 run_lib.py:146] step: 923800, eval_loss: 3.29101e-02
I0213 21:58:10.178063 22509476222784 run_lib.py:133] step: 923850, training_loss: 4.11707e-02
I0213 21:58:28.880915 22509476222784 run_lib.py:133] step: 923900, training_loss: 4.72690e-02
I0213 21:58:29.045992 22509476222784 run_lib.py:146] step: 923900, eval_loss: 3.98121e-02
I0213 21:58:47.876079 22509476222784 run_lib.py:133] step: 923950, training_loss: 3.66116e-02
I0213 21:59:06.630459 22509476222784 run_lib.py:133] step: 924000, training_loss: 4.18862e-02
I0213 21:59:06.796233 22509476222784 run_lib.py:146] step: 924000, eval_loss: 5.14586e-02
I0213 21:59:25.587235 22509476222784 run_lib.py:133] step: 924050, training_loss: 3.71176e-02
I0213 21:59:44.551494 22509476222784 run_lib.py:133] step: 924100, training_loss: 3.55802e-02
I0213 21:59:44.726491 22509476222784 run_lib.py:146] step: 924100, eval_loss: 4.28444e-02
I0213 22:00:03.464160 22509476222784 run_lib.py:133] step: 924150, training_loss: 5.21914e-02
I0213 22:00:22.341198 22509476222784 run_lib.py:133] step: 924200, training_loss: 3.23353e-02
I0213 22:00:22.513174 22509476222784 run_lib.py:146] step: 924200, eval_loss: 4.08786e-02
I0213 22:00:41.191738 22509476222784 run_lib.py:133] step: 924250, training_loss: 3.44444e-02
I0213 22:00:59.950710 22509476222784 run_lib.py:133] step: 924300, training_loss: 5.63581e-02
I0213 22:01:00.118189 22509476222784 run_lib.py:146] step: 924300, eval_loss: 5.06005e-02
I0213 22:01:19.123313 22509476222784 run_lib.py:133] step: 924350, training_loss: 4.12898e-02
I0213 22:01:37.826776 22509476222784 run_lib.py:133] step: 924400, training_loss: 4.02234e-02
I0213 22:01:37.988713 22509476222784 run_lib.py:146] step: 924400, eval_loss: 5.93830e-02
I0213 22:01:56.709025 22509476222784 run_lib.py:133] step: 924450, training_loss: 4.01184e-02
I0213 22:02:15.575770 22509476222784 run_lib.py:133] step: 924500, training_loss: 5.46318e-02
I0213 22:02:15.743151 22509476222784 run_lib.py:146] step: 924500, eval_loss: 3.05543e-02
I0213 22:02:34.526270 22509476222784 run_lib.py:133] step: 924550, training_loss: 5.49958e-02
I0213 22:02:53.297590 22509476222784 run_lib.py:133] step: 924600, training_loss: 4.49237e-02
I0213 22:02:53.495497 22509476222784 run_lib.py:146] step: 924600, eval_loss: 5.82919e-02
I0213 22:03:12.304719 22509476222784 run_lib.py:133] step: 924650, training_loss: 3.38016e-02
I0213 22:03:30.982556 22509476222784 run_lib.py:133] step: 924700, training_loss: 3.75103e-02
I0213 22:03:31.147897 22509476222784 run_lib.py:146] step: 924700, eval_loss: 4.85823e-02
I0213 22:03:49.832181 22509476222784 run_lib.py:133] step: 924750, training_loss: 4.29680e-02
I0213 22:04:08.598891 22509476222784 run_lib.py:133] step: 924800, training_loss: 5.14246e-02
I0213 22:04:08.764073 22509476222784 run_lib.py:146] step: 924800, eval_loss: 4.82232e-02
I0213 22:04:27.685494 22509476222784 run_lib.py:133] step: 924850, training_loss: 4.49063e-02
I0213 22:04:46.478747 22509476222784 run_lib.py:133] step: 924900, training_loss: 3.95893e-02
I0213 22:04:46.643888 22509476222784 run_lib.py:146] step: 924900, eval_loss: 5.37561e-02
I0213 22:05:05.331423 22509476222784 run_lib.py:133] step: 924950, training_loss: 5.29681e-02
I0213 22:05:24.013246 22509476222784 run_lib.py:133] step: 925000, training_loss: 4.20538e-02
I0213 22:05:24.179279 22509476222784 run_lib.py:146] step: 925000, eval_loss: 3.88819e-02
I0213 22:05:43.076251 22509476222784 run_lib.py:133] step: 925050, training_loss: 3.93828e-02
I0213 22:06:01.834867 22509476222784 run_lib.py:133] step: 925100, training_loss: 4.54262e-02
I0213 22:06:02.002957 22509476222784 run_lib.py:146] step: 925100, eval_loss: 4.01730e-02
I0213 22:06:20.970759 22509476222784 run_lib.py:133] step: 925150, training_loss: 4.09089e-02
I0213 22:06:39.694561 22509476222784 run_lib.py:133] step: 925200, training_loss: 4.04965e-02
I0213 22:06:39.861801 22509476222784 run_lib.py:146] step: 925200, eval_loss: 4.77465e-02
I0213 22:06:58.764726 22509476222784 run_lib.py:133] step: 925250, training_loss: 3.33335e-02
I0213 22:07:17.572105 22509476222784 run_lib.py:133] step: 925300, training_loss: 4.43103e-02
I0213 22:07:17.737725 22509476222784 run_lib.py:146] step: 925300, eval_loss: 3.61530e-02
I0213 22:07:36.718193 22509476222784 run_lib.py:133] step: 925350, training_loss: 4.03555e-02
I0213 22:07:55.438686 22509476222784 run_lib.py:133] step: 925400, training_loss: 3.44036e-02
I0213 22:07:55.607781 22509476222784 run_lib.py:146] step: 925400, eval_loss: 4.51165e-02
I0213 22:08:14.341550 22509476222784 run_lib.py:133] step: 925450, training_loss: 5.52587e-02
I0213 22:08:33.233278 22509476222784 run_lib.py:133] step: 925500, training_loss: 4.56405e-02
I0213 22:08:33.404930 22509476222784 run_lib.py:146] step: 925500, eval_loss: 4.27597e-02
I0213 22:08:52.239000 22509476222784 run_lib.py:133] step: 925550, training_loss: 3.79855e-02
I0213 22:09:11.015916 22509476222784 run_lib.py:133] step: 925600, training_loss: 4.58113e-02
I0213 22:09:11.182221 22509476222784 run_lib.py:146] step: 925600, eval_loss: 4.74366e-02
I0213 22:09:30.124431 22509476222784 run_lib.py:133] step: 925650, training_loss: 4.20208e-02
I0213 22:09:48.896443 22509476222784 run_lib.py:133] step: 925700, training_loss: 3.64316e-02
I0213 22:09:49.062315 22509476222784 run_lib.py:146] step: 925700, eval_loss: 4.61418e-02
I0213 22:10:07.966281 22509476222784 run_lib.py:133] step: 925750, training_loss: 3.94100e-02
I0213 22:10:26.739630 22509476222784 run_lib.py:133] step: 925800, training_loss: 3.18459e-02
I0213 22:10:26.903791 22509476222784 run_lib.py:146] step: 925800, eval_loss: 5.72237e-02
I0213 22:10:45.705051 22509476222784 run_lib.py:133] step: 925850, training_loss: 4.16697e-02
I0213 22:11:04.587758 22509476222784 run_lib.py:133] step: 925900, training_loss: 4.33777e-02
I0213 22:11:04.752900 22509476222784 run_lib.py:146] step: 925900, eval_loss: 3.91193e-02
I0213 22:11:23.462688 22509476222784 run_lib.py:133] step: 925950, training_loss: 3.53919e-02
I0213 22:11:42.173626 22509476222784 run_lib.py:133] step: 926000, training_loss: 3.07596e-02
I0213 22:11:42.347736 22509476222784 run_lib.py:146] step: 926000, eval_loss: 3.90615e-02
I0213 22:12:01.078294 22509476222784 run_lib.py:133] step: 926050, training_loss: 4.20764e-02
I0213 22:12:20.057714 22509476222784 run_lib.py:133] step: 926100, training_loss: 3.48302e-02
I0213 22:12:20.224999 22509476222784 run_lib.py:146] step: 926100, eval_loss: 4.57977e-02
I0213 22:12:38.941760 22509476222784 run_lib.py:133] step: 926150, training_loss: 4.12303e-02
I0213 22:12:57.755339 22509476222784 run_lib.py:133] step: 926200, training_loss: 4.23254e-02
I0213 22:12:57.921704 22509476222784 run_lib.py:146] step: 926200, eval_loss: 4.65470e-02
I0213 22:13:16.678320 22509476222784 run_lib.py:133] step: 926250, training_loss: 4.13309e-02
I0213 22:13:35.391036 22509476222784 run_lib.py:133] step: 926300, training_loss: 5.56225e-02
I0213 22:13:35.555629 22509476222784 run_lib.py:146] step: 926300, eval_loss: 4.85478e-02
I0213 22:13:54.501168 22509476222784 run_lib.py:133] step: 926350, training_loss: 3.97508e-02
I0213 22:14:13.340982 22509476222784 run_lib.py:133] step: 926400, training_loss: 3.75230e-02
I0213 22:14:13.507251 22509476222784 run_lib.py:146] step: 926400, eval_loss: 3.98457e-02
I0213 22:14:32.190380 22509476222784 run_lib.py:133] step: 926450, training_loss: 4.05318e-02
I0213 22:14:50.892354 22509476222784 run_lib.py:133] step: 926500, training_loss: 3.58134e-02
I0213 22:14:51.061089 22509476222784 run_lib.py:146] step: 926500, eval_loss: 4.44031e-02
I0213 22:15:09.909221 22509476222784 run_lib.py:133] step: 926550, training_loss: 4.83800e-02
I0213 22:15:28.624505 22509476222784 run_lib.py:133] step: 926600, training_loss: 3.27125e-02
I0213 22:15:28.798995 22509476222784 run_lib.py:146] step: 926600, eval_loss: 3.36939e-02
I0213 22:15:47.682559 22509476222784 run_lib.py:133] step: 926650, training_loss: 5.43311e-02
I0213 22:16:06.435548 22509476222784 run_lib.py:133] step: 926700, training_loss: 3.85190e-02
I0213 22:16:06.600015 22509476222784 run_lib.py:146] step: 926700, eval_loss: 4.12116e-02
I0213 22:16:25.516730 22509476222784 run_lib.py:133] step: 926750, training_loss: 4.04062e-02
I0213 22:16:44.215270 22509476222784 run_lib.py:133] step: 926800, training_loss: 4.70942e-02
I0213 22:16:44.395716 22509476222784 run_lib.py:146] step: 926800, eval_loss: 4.98244e-02
I0213 22:17:03.115933 22509476222784 run_lib.py:133] step: 926850, training_loss: 3.77061e-02
I0213 22:17:21.980855 22509476222784 run_lib.py:133] step: 926900, training_loss: 4.08240e-02
I0213 22:17:22.160146 22509476222784 run_lib.py:146] step: 926900, eval_loss: 4.44874e-02
I0213 22:17:40.946517 22509476222784 run_lib.py:133] step: 926950, training_loss: 4.01448e-02
I0213 22:17:59.939824 22509476222784 run_lib.py:133] step: 927000, training_loss: 4.85965e-02
I0213 22:18:00.106127 22509476222784 run_lib.py:146] step: 927000, eval_loss: 4.73922e-02
I0213 22:18:18.798886 22509476222784 run_lib.py:133] step: 927050, training_loss: 3.43538e-02
I0213 22:18:37.531669 22509476222784 run_lib.py:133] step: 927100, training_loss: 3.62550e-02
I0213 22:18:37.696898 22509476222784 run_lib.py:146] step: 927100, eval_loss: 4.39398e-02
I0213 22:18:56.556771 22509476222784 run_lib.py:133] step: 927150, training_loss: 3.35198e-02
I0213 22:19:15.339764 22509476222784 run_lib.py:133] step: 927200, training_loss: 2.92379e-02
I0213 22:19:15.504190 22509476222784 run_lib.py:146] step: 927200, eval_loss: 4.02730e-02
I0213 22:19:34.280746 22509476222784 run_lib.py:133] step: 927250, training_loss: 4.78276e-02
I0213 22:19:53.254271 22509476222784 run_lib.py:133] step: 927300, training_loss: 3.71884e-02
I0213 22:19:53.417878 22509476222784 run_lib.py:146] step: 927300, eval_loss: 4.54840e-02
I0213 22:20:12.151413 22509476222784 run_lib.py:133] step: 927350, training_loss: 4.49870e-02
I0213 22:20:30.873538 22509476222784 run_lib.py:133] step: 927400, training_loss: 3.15723e-02
I0213 22:20:31.210820 22509476222784 run_lib.py:146] step: 927400, eval_loss: 4.26024e-02
I0213 22:20:49.977560 22509476222784 run_lib.py:133] step: 927450, training_loss: 4.60743e-02
I0213 22:21:08.746775 22509476222784 run_lib.py:133] step: 927500, training_loss: 3.75530e-02
I0213 22:21:08.914232 22509476222784 run_lib.py:146] step: 927500, eval_loss: 5.24498e-02
I0213 22:21:27.620308 22509476222784 run_lib.py:133] step: 927550, training_loss: 4.11226e-02
I0213 22:21:46.288488 22509476222784 run_lib.py:133] step: 927600, training_loss: 5.04735e-02
I0213 22:21:46.454206 22509476222784 run_lib.py:146] step: 927600, eval_loss: 3.32116e-02
I0213 22:22:05.421091 22509476222784 run_lib.py:133] step: 927650, training_loss: 4.07977e-02
I0213 22:22:24.313292 22509476222784 run_lib.py:133] step: 927700, training_loss: 4.55755e-02
I0213 22:22:24.480152 22509476222784 run_lib.py:146] step: 927700, eval_loss: 5.13398e-02
I0213 22:22:43.221061 22509476222784 run_lib.py:133] step: 927750, training_loss: 4.04876e-02
I0213 22:23:01.918120 22509476222784 run_lib.py:133] step: 927800, training_loss: 4.98743e-02
I0213 22:23:02.084030 22509476222784 run_lib.py:146] step: 927800, eval_loss: 3.67745e-02
I0213 22:23:20.943786 22509476222784 run_lib.py:133] step: 927850, training_loss: 4.62528e-02
I0213 22:23:39.769266 22509476222784 run_lib.py:133] step: 927900, training_loss: 3.33074e-02
I0213 22:23:39.938100 22509476222784 run_lib.py:146] step: 927900, eval_loss: 2.77979e-02
I0213 22:23:58.687163 22509476222784 run_lib.py:133] step: 927950, training_loss: 4.23663e-02
I0213 22:24:17.471270 22509476222784 run_lib.py:133] step: 928000, training_loss: 4.49118e-02
I0213 22:24:17.638162 22509476222784 run_lib.py:146] step: 928000, eval_loss: 3.63340e-02
I0213 22:24:36.584430 22509476222784 run_lib.py:133] step: 928050, training_loss: 4.51325e-02
I0213 22:24:55.321157 22509476222784 run_lib.py:133] step: 928100, training_loss: 4.05812e-02
I0213 22:24:55.486995 22509476222784 run_lib.py:146] step: 928100, eval_loss: 5.04274e-02
I0213 22:25:14.354454 22509476222784 run_lib.py:133] step: 928150, training_loss: 5.37138e-02
I0213 22:25:33.116258 22509476222784 run_lib.py:133] step: 928200, training_loss: 3.89049e-02
I0213 22:25:33.281244 22509476222784 run_lib.py:146] step: 928200, eval_loss: 5.38980e-02
I0213 22:25:52.273482 22509476222784 run_lib.py:133] step: 928250, training_loss: 4.13122e-02
I0213 22:26:11.071114 22509476222784 run_lib.py:133] step: 928300, training_loss: 3.96587e-02
I0213 22:26:11.238190 22509476222784 run_lib.py:146] step: 928300, eval_loss: 4.83214e-02
I0213 22:26:29.907183 22509476222784 run_lib.py:133] step: 928350, training_loss: 3.41000e-02
I0213 22:26:48.785317 22509476222784 run_lib.py:133] step: 928400, training_loss: 4.07397e-02
I0213 22:26:48.954302 22509476222784 run_lib.py:146] step: 928400, eval_loss: 3.96356e-02
I0213 22:27:07.736610 22509476222784 run_lib.py:133] step: 928450, training_loss: 4.49268e-02
I0213 22:27:26.750902 22509476222784 run_lib.py:133] step: 928500, training_loss: 4.88107e-02
I0213 22:27:26.913048 22509476222784 run_lib.py:146] step: 928500, eval_loss: 4.63744e-02
I0213 22:27:45.633584 22509476222784 run_lib.py:133] step: 928550, training_loss: 4.98895e-02
I0213 22:28:04.328691 22509476222784 run_lib.py:133] step: 928600, training_loss: 3.87388e-02
I0213 22:28:04.494008 22509476222784 run_lib.py:146] step: 928600, eval_loss: 2.75911e-02
I0213 22:28:23.382486 22509476222784 run_lib.py:133] step: 928650, training_loss: 5.36046e-02
I0213 22:28:42.117378 22509476222784 run_lib.py:133] step: 928700, training_loss: 3.83251e-02
I0213 22:28:42.286205 22509476222784 run_lib.py:146] step: 928700, eval_loss: 4.27091e-02
I0213 22:29:01.047425 22509476222784 run_lib.py:133] step: 928750, training_loss: 4.19033e-02
I0213 22:29:19.784505 22509476222784 run_lib.py:133] step: 928800, training_loss: 4.47279e-02
I0213 22:29:19.953313 22509476222784 run_lib.py:146] step: 928800, eval_loss: 4.46306e-02
I0213 22:29:38.851580 22509476222784 run_lib.py:133] step: 928850, training_loss: 3.88485e-02
I0213 22:29:57.550379 22509476222784 run_lib.py:133] step: 928900, training_loss: 3.89375e-02
I0213 22:29:57.719645 22509476222784 run_lib.py:146] step: 928900, eval_loss: 5.45448e-02
I0213 22:30:16.511779 22509476222784 run_lib.py:133] step: 928950, training_loss: 3.87535e-02
I0213 22:30:35.301066 22509476222784 run_lib.py:133] step: 929000, training_loss: 4.64253e-02
I0213 22:30:35.467384 22509476222784 run_lib.py:146] step: 929000, eval_loss: 4.39600e-02
I0213 22:30:54.259605 22509476222784 run_lib.py:133] step: 929050, training_loss: 4.85101e-02
I0213 22:31:12.949598 22509476222784 run_lib.py:133] step: 929100, training_loss: 2.96484e-02
I0213 22:31:13.114165 22509476222784 run_lib.py:146] step: 929100, eval_loss: 4.55687e-02
I0213 22:31:32.012660 22509476222784 run_lib.py:133] step: 929150, training_loss: 4.22086e-02
I0213 22:31:50.801802 22509476222784 run_lib.py:133] step: 929200, training_loss: 5.48040e-02
I0213 22:31:50.968005 22509476222784 run_lib.py:146] step: 929200, eval_loss: 4.68733e-02
I0213 22:32:09.775324 22509476222784 run_lib.py:133] step: 929250, training_loss: 4.60363e-02
I0213 22:32:28.567906 22509476222784 run_lib.py:133] step: 929300, training_loss: 3.57739e-02
I0213 22:32:28.740221 22509476222784 run_lib.py:146] step: 929300, eval_loss: 4.30508e-02
I0213 22:32:47.708363 22509476222784 run_lib.py:133] step: 929350, training_loss: 4.39884e-02
I0213 22:33:06.474299 22509476222784 run_lib.py:133] step: 929400, training_loss: 4.85838e-02
I0213 22:33:06.648979 22509476222784 run_lib.py:146] step: 929400, eval_loss: 5.24089e-02
I0213 22:33:25.561634 22509476222784 run_lib.py:133] step: 929450, training_loss: 3.74931e-02
I0213 22:33:44.339929 22509476222784 run_lib.py:133] step: 929500, training_loss: 3.74605e-02
I0213 22:33:44.503614 22509476222784 run_lib.py:146] step: 929500, eval_loss: 3.53512e-02
I0213 22:34:03.492142 22509476222784 run_lib.py:133] step: 929550, training_loss: 3.88594e-02
I0213 22:34:22.182724 22509476222784 run_lib.py:133] step: 929600, training_loss: 4.29607e-02
I0213 22:34:22.345474 22509476222784 run_lib.py:146] step: 929600, eval_loss: 5.12433e-02
I0213 22:34:41.216416 22509476222784 run_lib.py:133] step: 929650, training_loss: 4.30447e-02
I0213 22:34:59.917879 22509476222784 run_lib.py:133] step: 929700, training_loss: 3.91848e-02
I0213 22:35:00.085108 22509476222784 run_lib.py:146] step: 929700, eval_loss: 3.83101e-02
I0213 22:35:18.862261 22509476222784 run_lib.py:133] step: 929750, training_loss: 4.02884e-02
I0213 22:35:37.791079 22509476222784 run_lib.py:133] step: 929800, training_loss: 4.43624e-02
I0213 22:35:37.967003 22509476222784 run_lib.py:146] step: 929800, eval_loss: 4.30308e-02
I0213 22:35:56.682269 22509476222784 run_lib.py:133] step: 929850, training_loss: 4.63959e-02
I0213 22:36:15.474304 22509476222784 run_lib.py:133] step: 929900, training_loss: 3.03154e-02
I0213 22:36:15.638190 22509476222784 run_lib.py:146] step: 929900, eval_loss: 5.09719e-02
I0213 22:36:34.590427 22509476222784 run_lib.py:133] step: 929950, training_loss: 5.51298e-02
I0213 22:36:53.549125 22509476222784 run_lib.py:133] step: 930000, training_loss: 4.33421e-02
I0213 22:36:54.566889 22509476222784 run_lib.py:146] step: 930000, eval_loss: 4.19156e-02
I0213 22:37:16.044080 22509476222784 run_lib.py:133] step: 930050, training_loss: 3.91202e-02
I0213 22:37:34.874882 22509476222784 run_lib.py:133] step: 930100, training_loss: 4.27031e-02
I0213 22:37:35.040023 22509476222784 run_lib.py:146] step: 930100, eval_loss: 5.14697e-02
I0213 22:37:53.782206 22509476222784 run_lib.py:133] step: 930150, training_loss: 5.09748e-02
I0213 22:38:12.520333 22509476222784 run_lib.py:133] step: 930200, training_loss: 3.37497e-02
I0213 22:38:12.682744 22509476222784 run_lib.py:146] step: 930200, eval_loss: 4.19387e-02
I0213 22:38:31.503672 22509476222784 run_lib.py:133] step: 930250, training_loss: 4.77345e-02
I0213 22:38:50.342252 22509476222784 run_lib.py:133] step: 930300, training_loss: 4.79392e-02
I0213 22:38:50.523154 22509476222784 run_lib.py:146] step: 930300, eval_loss: 5.34556e-02
I0213 22:39:09.273494 22509476222784 run_lib.py:133] step: 930350, training_loss: 4.31873e-02
I0213 22:39:28.028207 22509476222784 run_lib.py:133] step: 930400, training_loss: 4.23112e-02
I0213 22:39:28.195327 22509476222784 run_lib.py:146] step: 930400, eval_loss: 3.10082e-02
I0213 22:39:47.123306 22509476222784 run_lib.py:133] step: 930450, training_loss: 4.16198e-02
I0213 22:40:05.908034 22509476222784 run_lib.py:133] step: 930500, training_loss: 3.36974e-02
I0213 22:40:06.084161 22509476222784 run_lib.py:146] step: 930500, eval_loss: 4.67104e-02
I0213 22:40:25.019713 22509476222784 run_lib.py:133] step: 930550, training_loss: 4.05762e-02
I0213 22:40:43.777917 22509476222784 run_lib.py:133] step: 930600, training_loss: 4.78230e-02
I0213 22:40:43.941859 22509476222784 run_lib.py:146] step: 930600, eval_loss: 3.57048e-02
I0213 22:41:02.906053 22509476222784 run_lib.py:133] step: 930650, training_loss: 4.46297e-02
I0213 22:41:21.664274 22509476222784 run_lib.py:133] step: 930700, training_loss: 3.65871e-02
I0213 22:41:21.828963 22509476222784 run_lib.py:146] step: 930700, eval_loss: 3.97672e-02
I0213 22:41:40.519473 22509476222784 run_lib.py:133] step: 930750, training_loss: 4.21177e-02
I0213 22:41:59.480967 22509476222784 run_lib.py:133] step: 930800, training_loss: 3.60330e-02
I0213 22:41:59.692304 22509476222784 run_lib.py:146] step: 930800, eval_loss: 3.90150e-02
I0213 22:42:18.457636 22509476222784 run_lib.py:133] step: 930850, training_loss: 3.64761e-02
I0213 22:42:37.375140 22509476222784 run_lib.py:133] step: 930900, training_loss: 3.76647e-02
I0213 22:42:37.540901 22509476222784 run_lib.py:146] step: 930900, eval_loss: 3.17343e-02
I0213 22:42:56.313151 22509476222784 run_lib.py:133] step: 930950, training_loss: 4.49310e-02
I0213 22:43:15.115531 22509476222784 run_lib.py:133] step: 931000, training_loss: 4.10181e-02
I0213 22:43:15.289125 22509476222784 run_lib.py:146] step: 931000, eval_loss: 3.03546e-02
I0213 22:43:34.256683 22509476222784 run_lib.py:133] step: 931050, training_loss: 4.77080e-02
I0213 22:43:53.035020 22509476222784 run_lib.py:133] step: 931100, training_loss: 4.61911e-02
I0213 22:43:53.198291 22509476222784 run_lib.py:146] step: 931100, eval_loss: 3.60179e-02
I0213 22:44:11.950816 22509476222784 run_lib.py:133] step: 931150, training_loss: 4.03013e-02
I0213 22:44:30.929821 22509476222784 run_lib.py:133] step: 931200, training_loss: 3.34576e-02
I0213 22:44:31.095045 22509476222784 run_lib.py:146] step: 931200, eval_loss: 4.15027e-02
I0213 22:44:49.850435 22509476222784 run_lib.py:133] step: 931250, training_loss: 4.68047e-02
I0213 22:45:08.632471 22509476222784 run_lib.py:133] step: 931300, training_loss: 4.40947e-02
I0213 22:45:08.813990 22509476222784 run_lib.py:146] step: 931300, eval_loss: 4.28588e-02
I0213 22:45:27.697969 22509476222784 run_lib.py:133] step: 931350, training_loss: 4.61899e-02
I0213 22:45:46.455323 22509476222784 run_lib.py:133] step: 931400, training_loss: 3.86832e-02
I0213 22:45:46.622746 22509476222784 run_lib.py:146] step: 931400, eval_loss: 3.90863e-02
I0213 22:46:05.393608 22509476222784 run_lib.py:133] step: 931450, training_loss: 4.30421e-02
I0213 22:46:24.165943 22509476222784 run_lib.py:133] step: 931500, training_loss: 4.71880e-02
I0213 22:46:24.329925 22509476222784 run_lib.py:146] step: 931500, eval_loss: 4.19610e-02
I0213 22:46:43.221163 22509476222784 run_lib.py:133] step: 931550, training_loss: 4.48638e-02
I0213 22:47:02.164045 22509476222784 run_lib.py:133] step: 931600, training_loss: 3.68872e-02
I0213 22:47:02.332193 22509476222784 run_lib.py:146] step: 931600, eval_loss: 5.31763e-02
I0213 22:47:21.081244 22509476222784 run_lib.py:133] step: 931650, training_loss: 5.13448e-02
I0213 22:47:39.848936 22509476222784 run_lib.py:133] step: 931700, training_loss: 2.83701e-02
I0213 22:47:40.016072 22509476222784 run_lib.py:146] step: 931700, eval_loss: 3.92168e-02
I0213 22:47:58.896813 22509476222784 run_lib.py:133] step: 931750, training_loss: 4.69925e-02
I0213 22:48:17.705822 22509476222784 run_lib.py:133] step: 931800, training_loss: 4.33201e-02
I0213 22:48:17.890918 22509476222784 run_lib.py:146] step: 931800, eval_loss: 4.07708e-02
I0213 22:48:36.760543 22509476222784 run_lib.py:133] step: 931850, training_loss: 3.55206e-02
I0213 22:48:55.478564 22509476222784 run_lib.py:133] step: 931900, training_loss: 4.65126e-02
I0213 22:48:55.644205 22509476222784 run_lib.py:146] step: 931900, eval_loss: 3.47486e-02
I0213 22:49:14.546949 22509476222784 run_lib.py:133] step: 931950, training_loss: 3.11879e-02
I0213 22:49:33.216642 22509476222784 run_lib.py:133] step: 932000, training_loss: 5.78594e-02
I0213 22:49:33.379962 22509476222784 run_lib.py:146] step: 932000, eval_loss: 4.14577e-02
I0213 22:49:52.245858 22509476222784 run_lib.py:133] step: 932050, training_loss: 5.17474e-02
I0213 22:50:10.983201 22509476222784 run_lib.py:133] step: 932100, training_loss: 4.15796e-02
I0213 22:50:11.151185 22509476222784 run_lib.py:146] step: 932100, eval_loss: 3.94713e-02
I0213 22:50:29.913417 22509476222784 run_lib.py:133] step: 932150, training_loss: 4.87003e-02
I0213 22:50:48.823474 22509476222784 run_lib.py:133] step: 932200, training_loss: 3.58404e-02
I0213 22:50:48.996133 22509476222784 run_lib.py:146] step: 932200, eval_loss: 3.87110e-02
I0213 22:51:07.648572 22509476222784 run_lib.py:133] step: 932250, training_loss: 3.89367e-02
I0213 22:51:26.349025 22509476222784 run_lib.py:133] step: 932300, training_loss: 4.26425e-02
I0213 22:51:26.524989 22509476222784 run_lib.py:146] step: 932300, eval_loss: 4.53686e-02
I0213 22:51:45.468700 22509476222784 run_lib.py:133] step: 932350, training_loss: 4.13392e-02
I0213 22:52:04.245671 22509476222784 run_lib.py:133] step: 932400, training_loss: 3.60692e-02
I0213 22:52:04.414224 22509476222784 run_lib.py:146] step: 932400, eval_loss: 3.82774e-02
I0213 22:52:23.375786 22509476222784 run_lib.py:133] step: 932450, training_loss: 3.91078e-02
I0213 22:52:42.108800 22509476222784 run_lib.py:133] step: 932500, training_loss: 3.38848e-02
I0213 22:52:42.273052 22509476222784 run_lib.py:146] step: 932500, eval_loss: 5.03558e-02
I0213 22:53:01.001561 22509476222784 run_lib.py:133] step: 932550, training_loss: 3.92476e-02
I0213 22:53:19.962357 22509476222784 run_lib.py:133] step: 932600, training_loss: 3.47935e-02
I0213 22:53:20.139881 22509476222784 run_lib.py:146] step: 932600, eval_loss: 5.17387e-02
I0213 22:53:38.919094 22509476222784 run_lib.py:133] step: 932650, training_loss: 4.98843e-02
I0213 22:53:57.676383 22509476222784 run_lib.py:133] step: 932700, training_loss: 3.08555e-02
I0213 22:53:57.867702 22509476222784 run_lib.py:146] step: 932700, eval_loss: 5.17920e-02
I0213 22:54:16.592746 22509476222784 run_lib.py:133] step: 932750, training_loss: 3.95925e-02
I0213 22:54:35.579900 22509476222784 run_lib.py:133] step: 932800, training_loss: 3.58650e-02
I0213 22:54:35.745746 22509476222784 run_lib.py:146] step: 932800, eval_loss: 4.72716e-02
I0213 22:54:54.494504 22509476222784 run_lib.py:133] step: 932850, training_loss: 5.28856e-02
I0213 22:55:13.371588 22509476222784 run_lib.py:133] step: 932900, training_loss: 4.03936e-02
I0213 22:55:13.539230 22509476222784 run_lib.py:146] step: 932900, eval_loss: 4.22812e-02
I0213 22:55:32.326607 22509476222784 run_lib.py:133] step: 932950, training_loss: 3.00488e-02
I0213 22:55:51.054508 22509476222784 run_lib.py:133] step: 933000, training_loss: 5.19058e-02
I0213 22:55:51.219640 22509476222784 run_lib.py:146] step: 933000, eval_loss: 3.42607e-02
I0213 22:56:10.128385 22509476222784 run_lib.py:133] step: 933050, training_loss: 4.63574e-02
I0213 22:56:28.954938 22509476222784 run_lib.py:133] step: 933100, training_loss: 3.24716e-02
I0213 22:56:29.130249 22509476222784 run_lib.py:146] step: 933100, eval_loss: 4.15113e-02
I0213 22:56:47.938196 22509476222784 run_lib.py:133] step: 933150, training_loss: 4.63533e-02
I0213 22:57:06.701474 22509476222784 run_lib.py:133] step: 933200, training_loss: 4.46216e-02
I0213 22:57:06.868516 22509476222784 run_lib.py:146] step: 933200, eval_loss: 4.59893e-02
I0213 22:57:25.811141 22509476222784 run_lib.py:133] step: 933250, training_loss: 5.60443e-02
I0213 22:57:44.527709 22509476222784 run_lib.py:133] step: 933300, training_loss: 3.62054e-02
I0213 22:57:44.693961 22509476222784 run_lib.py:146] step: 933300, eval_loss: 4.17913e-02
I0213 22:58:03.527884 22509476222784 run_lib.py:133] step: 933350, training_loss: 3.76494e-02
I0213 22:58:22.315442 22509476222784 run_lib.py:133] step: 933400, training_loss: 3.52336e-02
I0213 22:58:22.482382 22509476222784 run_lib.py:146] step: 933400, eval_loss: 4.50220e-02
I0213 22:58:41.403992 22509476222784 run_lib.py:133] step: 933450, training_loss: 3.85438e-02
I0213 22:59:00.092628 22509476222784 run_lib.py:133] step: 933500, training_loss: 4.18479e-02
I0213 22:59:00.254885 22509476222784 run_lib.py:146] step: 933500, eval_loss: 3.81024e-02
I0213 22:59:18.969881 22509476222784 run_lib.py:133] step: 933550, training_loss: 3.52787e-02
I0213 22:59:37.864010 22509476222784 run_lib.py:133] step: 933600, training_loss: 2.67583e-02
I0213 22:59:38.042309 22509476222784 run_lib.py:146] step: 933600, eval_loss: 4.29155e-02
I0213 22:59:56.792000 22509476222784 run_lib.py:133] step: 933650, training_loss: 5.14573e-02
I0213 23:00:15.716516 22509476222784 run_lib.py:133] step: 933700, training_loss: 4.90636e-02
I0213 23:00:15.884944 22509476222784 run_lib.py:146] step: 933700, eval_loss: 4.92977e-02
I0213 23:00:34.661733 22509476222784 run_lib.py:133] step: 933750, training_loss: 4.22418e-02
I0213 23:00:53.393311 22509476222784 run_lib.py:133] step: 933800, training_loss: 4.56833e-02
I0213 23:00:53.558551 22509476222784 run_lib.py:146] step: 933800, eval_loss: 3.76912e-02
I0213 23:01:12.429398 22509476222784 run_lib.py:133] step: 933850, training_loss: 4.12495e-02
I0213 23:01:31.202704 22509476222784 run_lib.py:133] step: 933900, training_loss: 4.31196e-02
I0213 23:01:31.368235 22509476222784 run_lib.py:146] step: 933900, eval_loss: 3.83487e-02
I0213 23:01:50.163791 22509476222784 run_lib.py:133] step: 933950, training_loss: 2.91431e-02
I0213 23:02:09.112112 22509476222784 run_lib.py:133] step: 934000, training_loss: 3.08826e-02
I0213 23:02:09.276067 22509476222784 run_lib.py:146] step: 934000, eval_loss: 4.27541e-02
I0213 23:02:27.969287 22509476222784 run_lib.py:133] step: 934050, training_loss: 4.75296e-02
I0213 23:02:46.676160 22509476222784 run_lib.py:133] step: 934100, training_loss: 4.49780e-02
I0213 23:02:47.030805 22509476222784 run_lib.py:146] step: 934100, eval_loss: 4.10134e-02
I0213 23:03:05.831367 22509476222784 run_lib.py:133] step: 934150, training_loss: 4.47851e-02
I0213 23:03:24.568522 22509476222784 run_lib.py:133] step: 934200, training_loss: 4.13701e-02
I0213 23:03:24.738061 22509476222784 run_lib.py:146] step: 934200, eval_loss: 4.23392e-02
I0213 23:03:43.444388 22509476222784 run_lib.py:133] step: 934250, training_loss: 3.80542e-02
I0213 23:04:02.191849 22509476222784 run_lib.py:133] step: 934300, training_loss: 4.79878e-02
I0213 23:04:02.357173 22509476222784 run_lib.py:146] step: 934300, eval_loss: 3.69350e-02
I0213 23:04:21.285767 22509476222784 run_lib.py:133] step: 934350, training_loss: 3.44663e-02
I0213 23:04:40.152958 22509476222784 run_lib.py:133] step: 934400, training_loss: 3.40635e-02
I0213 23:04:40.320329 22509476222784 run_lib.py:146] step: 934400, eval_loss: 3.45280e-02
I0213 23:04:59.051167 22509476222784 run_lib.py:133] step: 934450, training_loss: 4.61795e-02
I0213 23:05:17.705536 22509476222784 run_lib.py:133] step: 934500, training_loss: 4.09545e-02
I0213 23:05:17.872011 22509476222784 run_lib.py:146] step: 934500, eval_loss: 4.55546e-02
I0213 23:05:36.758962 22509476222784 run_lib.py:133] step: 934550, training_loss: 3.97348e-02
I0213 23:05:55.527967 22509476222784 run_lib.py:133] step: 934600, training_loss: 4.27151e-02
I0213 23:05:55.696550 22509476222784 run_lib.py:146] step: 934600, eval_loss: 4.63412e-02
I0213 23:06:14.420016 22509476222784 run_lib.py:133] step: 934650, training_loss: 4.11211e-02
I0213 23:06:33.216765 22509476222784 run_lib.py:133] step: 934700, training_loss: 3.02449e-02
I0213 23:06:33.383224 22509476222784 run_lib.py:146] step: 934700, eval_loss: 3.95183e-02
I0213 23:06:52.352816 22509476222784 run_lib.py:133] step: 934750, training_loss: 3.77320e-02
I0213 23:07:11.079661 22509476222784 run_lib.py:133] step: 934800, training_loss: 4.39296e-02
I0213 23:07:11.245181 22509476222784 run_lib.py:146] step: 934800, eval_loss: 4.43049e-02
I0213 23:07:30.130645 22509476222784 run_lib.py:133] step: 934850, training_loss: 3.40610e-02
I0213 23:07:48.907162 22509476222784 run_lib.py:133] step: 934900, training_loss: 5.11476e-02
I0213 23:07:49.073395 22509476222784 run_lib.py:146] step: 934900, eval_loss: 4.93694e-02
I0213 23:08:08.124086 22509476222784 run_lib.py:133] step: 934950, training_loss: 3.82485e-02
I0213 23:08:26.886604 22509476222784 run_lib.py:133] step: 935000, training_loss: 4.56168e-02
I0213 23:08:27.054048 22509476222784 run_lib.py:146] step: 935000, eval_loss: 5.09161e-02
I0213 23:08:45.753713 22509476222784 run_lib.py:133] step: 935050, training_loss: 3.98828e-02
I0213 23:09:04.637637 22509476222784 run_lib.py:133] step: 935100, training_loss: 5.18008e-02
I0213 23:09:04.806941 22509476222784 run_lib.py:146] step: 935100, eval_loss: 4.58904e-02
I0213 23:09:23.607286 22509476222784 run_lib.py:133] step: 935150, training_loss: 3.52282e-02
I0213 23:09:42.579649 22509476222784 run_lib.py:133] step: 935200, training_loss: 5.08604e-02
I0213 23:09:42.746255 22509476222784 run_lib.py:146] step: 935200, eval_loss: 4.85538e-02
I0213 23:10:01.500269 22509476222784 run_lib.py:133] step: 935250, training_loss: 4.45773e-02
I0213 23:10:20.207734 22509476222784 run_lib.py:133] step: 935300, training_loss: 3.40604e-02
I0213 23:10:20.373048 22509476222784 run_lib.py:146] step: 935300, eval_loss: 3.68419e-02
I0213 23:10:39.282829 22509476222784 run_lib.py:133] step: 935350, training_loss: 3.73168e-02
I0213 23:10:58.067839 22509476222784 run_lib.py:133] step: 935400, training_loss: 4.52083e-02
I0213 23:10:58.243880 22509476222784 run_lib.py:146] step: 935400, eval_loss: 3.71126e-02
I0213 23:11:17.045800 22509476222784 run_lib.py:133] step: 935450, training_loss: 4.58850e-02
I0213 23:11:35.779285 22509476222784 run_lib.py:133] step: 935500, training_loss: 3.58765e-02
I0213 23:11:35.954776 22509476222784 run_lib.py:146] step: 935500, eval_loss: 3.62415e-02
I0213 23:11:54.921293 22509476222784 run_lib.py:133] step: 935550, training_loss: 3.78016e-02
I0213 23:12:13.688478 22509476222784 run_lib.py:133] step: 935600, training_loss: 4.47217e-02
I0213 23:12:13.874159 22509476222784 run_lib.py:146] step: 935600, eval_loss: 4.61913e-02
I0213 23:12:32.683570 22509476222784 run_lib.py:133] step: 935650, training_loss: 4.72832e-02
I0213 23:12:51.515768 22509476222784 run_lib.py:133] step: 935700, training_loss: 3.28887e-02
I0213 23:12:51.682910 22509476222784 run_lib.py:146] step: 935700, eval_loss: 4.53687e-02
I0213 23:13:10.479814 22509476222784 run_lib.py:133] step: 935750, training_loss: 4.39275e-02
I0213 23:13:29.217529 22509476222784 run_lib.py:133] step: 935800, training_loss: 3.80028e-02
I0213 23:13:29.382115 22509476222784 run_lib.py:146] step: 935800, eval_loss: 5.39447e-02
I0213 23:13:48.296871 22509476222784 run_lib.py:133] step: 935850, training_loss: 2.75943e-02
I0213 23:14:07.176143 22509476222784 run_lib.py:133] step: 935900, training_loss: 3.60051e-02
I0213 23:14:07.354034 22509476222784 run_lib.py:146] step: 935900, eval_loss: 5.34942e-02
I0213 23:14:26.137107 22509476222784 run_lib.py:133] step: 935950, training_loss: 2.54287e-02
I0213 23:14:44.829600 22509476222784 run_lib.py:133] step: 936000, training_loss: 3.29022e-02
I0213 23:14:44.997993 22509476222784 run_lib.py:146] step: 936000, eval_loss: 4.73836e-02
I0213 23:15:03.885354 22509476222784 run_lib.py:133] step: 936050, training_loss: 4.28672e-02
I0213 23:15:22.585825 22509476222784 run_lib.py:133] step: 936100, training_loss: 3.91805e-02
I0213 23:15:22.751943 22509476222784 run_lib.py:146] step: 936100, eval_loss: 4.25841e-02
I0213 23:15:41.608552 22509476222784 run_lib.py:133] step: 936150, training_loss: 5.16001e-02
I0213 23:16:00.403084 22509476222784 run_lib.py:133] step: 936200, training_loss: 3.81421e-02
I0213 23:16:00.570574 22509476222784 run_lib.py:146] step: 936200, eval_loss: 3.63314e-02
I0213 23:16:19.525949 22509476222784 run_lib.py:133] step: 936250, training_loss: 4.16301e-02
I0213 23:16:38.249963 22509476222784 run_lib.py:133] step: 936300, training_loss: 4.23256e-02
I0213 23:16:38.413989 22509476222784 run_lib.py:146] step: 936300, eval_loss: 3.59259e-02
I0213 23:16:57.290997 22509476222784 run_lib.py:133] step: 936350, training_loss: 3.89444e-02
I0213 23:17:16.053439 22509476222784 run_lib.py:133] step: 936400, training_loss: 4.22359e-02
I0213 23:17:16.226251 22509476222784 run_lib.py:146] step: 936400, eval_loss: 4.74640e-02
I0213 23:17:34.990631 22509476222784 run_lib.py:133] step: 936450, training_loss: 4.29320e-02
I0213 23:17:53.950949 22509476222784 run_lib.py:133] step: 936500, training_loss: 4.77246e-02
I0213 23:17:54.126012 22509476222784 run_lib.py:146] step: 936500, eval_loss: 3.89262e-02
I0213 23:18:12.809609 22509476222784 run_lib.py:133] step: 936550, training_loss: 3.92406e-02
I0213 23:18:31.490805 22509476222784 run_lib.py:133] step: 936600, training_loss: 3.77800e-02
I0213 23:18:31.657870 22509476222784 run_lib.py:146] step: 936600, eval_loss: 3.87412e-02
I0213 23:18:50.521413 22509476222784 run_lib.py:133] step: 936650, training_loss: 4.10358e-02
I0213 23:19:09.479000 22509476222784 run_lib.py:133] step: 936700, training_loss: 3.34779e-02
I0213 23:19:09.646224 22509476222784 run_lib.py:146] step: 936700, eval_loss: 4.03590e-02
I0213 23:19:28.365438 22509476222784 run_lib.py:133] step: 936750, training_loss: 3.98132e-02
I0213 23:19:47.107193 22509476222784 run_lib.py:133] step: 936800, training_loss: 2.60549e-02
I0213 23:19:47.270029 22509476222784 run_lib.py:146] step: 936800, eval_loss: 4.30761e-02
I0213 23:20:06.010688 22509476222784 run_lib.py:133] step: 936850, training_loss: 2.95332e-02
I0213 23:20:24.950152 22509476222784 run_lib.py:133] step: 936900, training_loss: 3.70191e-02
I0213 23:20:25.127385 22509476222784 run_lib.py:146] step: 936900, eval_loss: 3.44620e-02
I0213 23:20:43.913060 22509476222784 run_lib.py:133] step: 936950, training_loss: 4.17728e-02
I0213 23:21:02.711762 22509476222784 run_lib.py:133] step: 937000, training_loss: 3.75261e-02
I0213 23:21:02.878886 22509476222784 run_lib.py:146] step: 937000, eval_loss: 4.19950e-02
I0213 23:21:21.627700 22509476222784 run_lib.py:133] step: 937050, training_loss: 3.11706e-02
I0213 23:21:40.590052 22509476222784 run_lib.py:133] step: 937100, training_loss: 3.71094e-02
I0213 23:21:40.769030 22509476222784 run_lib.py:146] step: 937100, eval_loss: 3.69409e-02
I0213 23:21:59.564178 22509476222784 run_lib.py:133] step: 937150, training_loss: 4.18059e-02
I0213 23:22:18.442697 22509476222784 run_lib.py:133] step: 937200, training_loss: 4.18843e-02
I0213 23:22:18.614687 22509476222784 run_lib.py:146] step: 937200, eval_loss: 4.04575e-02
I0213 23:22:37.402565 22509476222784 run_lib.py:133] step: 937250, training_loss: 3.08846e-02
I0213 23:22:56.150112 22509476222784 run_lib.py:133] step: 937300, training_loss: 3.83699e-02
I0213 23:22:56.314989 22509476222784 run_lib.py:146] step: 937300, eval_loss: 4.08664e-02
I0213 23:23:15.248791 22509476222784 run_lib.py:133] step: 937350, training_loss: 3.95425e-02
I0213 23:23:33.992243 22509476222784 run_lib.py:133] step: 937400, training_loss: 4.53757e-02
I0213 23:23:34.169089 22509476222784 run_lib.py:146] step: 937400, eval_loss: 3.28998e-02
I0213 23:23:52.906584 22509476222784 run_lib.py:133] step: 937450, training_loss: 3.19646e-02
I0213 23:24:11.675580 22509476222784 run_lib.py:133] step: 937500, training_loss: 3.64112e-02
I0213 23:24:11.843954 22509476222784 run_lib.py:146] step: 937500, eval_loss: 5.14503e-02
I0213 23:24:30.736923 22509476222784 run_lib.py:133] step: 937550, training_loss: 4.16887e-02
I0213 23:24:49.447494 22509476222784 run_lib.py:133] step: 937600, training_loss: 3.34770e-02
I0213 23:24:49.614178 22509476222784 run_lib.py:146] step: 937600, eval_loss: 3.63014e-02
I0213 23:25:08.497285 22509476222784 run_lib.py:133] step: 937650, training_loss: 4.05856e-02
I0213 23:25:27.296164 22509476222784 run_lib.py:133] step: 937700, training_loss: 5.04736e-02
I0213 23:25:27.462230 22509476222784 run_lib.py:146] step: 937700, eval_loss: 3.65727e-02
I0213 23:25:46.427741 22509476222784 run_lib.py:133] step: 937750, training_loss: 5.05891e-02
I0213 23:26:05.131550 22509476222784 run_lib.py:133] step: 937800, training_loss: 4.58081e-02
I0213 23:26:05.295955 22509476222784 run_lib.py:146] step: 937800, eval_loss: 4.47820e-02
I0213 23:26:24.011775 22509476222784 run_lib.py:133] step: 937850, training_loss: 3.62562e-02
I0213 23:26:42.892675 22509476222784 run_lib.py:133] step: 937900, training_loss: 4.64684e-02
I0213 23:26:43.079078 22509476222784 run_lib.py:146] step: 937900, eval_loss: 4.95867e-02
I0213 23:27:01.833879 22509476222784 run_lib.py:133] step: 937950, training_loss: 3.41393e-02
I0213 23:27:20.781264 22509476222784 run_lib.py:133] step: 938000, training_loss: 5.56926e-02
I0213 23:27:20.946885 22509476222784 run_lib.py:146] step: 938000, eval_loss: 4.80749e-02
I0213 23:27:39.734803 22509476222784 run_lib.py:133] step: 938050, training_loss: 4.37576e-02
I0213 23:27:58.406610 22509476222784 run_lib.py:133] step: 938100, training_loss: 4.62035e-02
I0213 23:27:58.572686 22509476222784 run_lib.py:146] step: 938100, eval_loss: 5.06869e-02
I0213 23:28:17.456317 22509476222784 run_lib.py:133] step: 938150, training_loss: 4.17076e-02
I0213 23:28:36.217285 22509476222784 run_lib.py:133] step: 938200, training_loss: 3.45322e-02
I0213 23:28:36.382816 22509476222784 run_lib.py:146] step: 938200, eval_loss: 2.92633e-02
I0213 23:28:55.195565 22509476222784 run_lib.py:133] step: 938250, training_loss: 4.82665e-02
I0213 23:29:14.108185 22509476222784 run_lib.py:133] step: 938300, training_loss: 4.66228e-02
I0213 23:29:14.272654 22509476222784 run_lib.py:146] step: 938300, eval_loss: 4.18252e-02
I0213 23:29:33.007076 22509476222784 run_lib.py:133] step: 938350, training_loss: 4.19048e-02
I0213 23:29:51.769767 22509476222784 run_lib.py:133] step: 938400, training_loss: 4.33319e-02
I0213 23:29:51.945419 22509476222784 run_lib.py:146] step: 938400, eval_loss: 4.00058e-02
I0213 23:30:10.790900 22509476222784 run_lib.py:133] step: 938450, training_loss: 3.85237e-02
I0213 23:30:29.622297 22509476222784 run_lib.py:133] step: 938500, training_loss: 3.87183e-02
I0213 23:30:29.795104 22509476222784 run_lib.py:146] step: 938500, eval_loss: 5.15059e-02
I0213 23:30:48.585995 22509476222784 run_lib.py:133] step: 938550, training_loss: 4.16570e-02
I0213 23:31:07.318480 22509476222784 run_lib.py:133] step: 938600, training_loss: 3.94647e-02
I0213 23:31:07.493951 22509476222784 run_lib.py:146] step: 938600, eval_loss: 3.81372e-02
I0213 23:31:26.434653 22509476222784 run_lib.py:133] step: 938650, training_loss: 3.99902e-02
I0213 23:31:45.250768 22509476222784 run_lib.py:133] step: 938700, training_loss: 4.82625e-02
I0213 23:31:45.418201 22509476222784 run_lib.py:146] step: 938700, eval_loss: 4.75408e-02
I0213 23:32:04.223673 22509476222784 run_lib.py:133] step: 938750, training_loss: 3.48565e-02
I0213 23:32:22.945011 22509476222784 run_lib.py:133] step: 938800, training_loss: 4.35986e-02
I0213 23:32:23.112011 22509476222784 run_lib.py:146] step: 938800, eval_loss: 4.35181e-02
I0213 23:32:42.017911 22509476222784 run_lib.py:133] step: 938850, training_loss: 4.56633e-02
I0213 23:33:00.733738 22509476222784 run_lib.py:133] step: 938900, training_loss: 5.13503e-02
I0213 23:33:00.901165 22509476222784 run_lib.py:146] step: 938900, eval_loss: 5.02734e-02
I0213 23:33:19.800668 22509476222784 run_lib.py:133] step: 938950, training_loss: 3.68678e-02
I0213 23:33:38.639391 22509476222784 run_lib.py:133] step: 939000, training_loss: 2.92020e-02
I0213 23:33:38.806294 22509476222784 run_lib.py:146] step: 939000, eval_loss: 4.26716e-02
I0213 23:33:57.735055 22509476222784 run_lib.py:133] step: 939050, training_loss: 3.37146e-02
I0213 23:34:16.499214 22509476222784 run_lib.py:133] step: 939100, training_loss: 4.25892e-02
I0213 23:34:16.664024 22509476222784 run_lib.py:146] step: 939100, eval_loss: 4.84434e-02
I0213 23:34:35.539096 22509476222784 run_lib.py:133] step: 939150, training_loss: 4.42985e-02
I0213 23:34:54.332853 22509476222784 run_lib.py:133] step: 939200, training_loss: 3.58739e-02
I0213 23:34:54.502113 22509476222784 run_lib.py:146] step: 939200, eval_loss: 4.11040e-02
I0213 23:35:13.349558 22509476222784 run_lib.py:133] step: 939250, training_loss: 4.28868e-02
I0213 23:35:32.256040 22509476222784 run_lib.py:133] step: 939300, training_loss: 4.40981e-02
I0213 23:35:32.422868 22509476222784 run_lib.py:146] step: 939300, eval_loss: 3.72071e-02
I0213 23:35:51.156154 22509476222784 run_lib.py:133] step: 939350, training_loss: 3.25320e-02
I0213 23:36:09.937270 22509476222784 run_lib.py:133] step: 939400, training_loss: 4.89485e-02
I0213 23:36:10.114251 22509476222784 run_lib.py:146] step: 939400, eval_loss: 4.52682e-02
I0213 23:36:29.068850 22509476222784 run_lib.py:133] step: 939450, training_loss: 3.40616e-02
I0213 23:36:47.853377 22509476222784 run_lib.py:133] step: 939500, training_loss: 4.62981e-02
I0213 23:36:48.017846 22509476222784 run_lib.py:146] step: 939500, eval_loss: 4.25192e-02
I0213 23:37:06.974846 22509476222784 run_lib.py:133] step: 939550, training_loss: 3.74646e-02
I0213 23:37:25.727302 22509476222784 run_lib.py:133] step: 939600, training_loss: 2.77975e-02
I0213 23:37:25.891978 22509476222784 run_lib.py:146] step: 939600, eval_loss: 4.46076e-02
I0213 23:37:44.599297 22509476222784 run_lib.py:133] step: 939650, training_loss: 5.41243e-02
I0213 23:38:03.531800 22509476222784 run_lib.py:133] step: 939700, training_loss: 4.42480e-02
I0213 23:38:03.703120 22509476222784 run_lib.py:146] step: 939700, eval_loss: 4.32167e-02
I0213 23:38:22.505253 22509476222784 run_lib.py:133] step: 939750, training_loss: 5.34511e-02
I0213 23:38:41.290199 22509476222784 run_lib.py:133] step: 939800, training_loss: 4.62255e-02
I0213 23:38:41.458252 22509476222784 run_lib.py:146] step: 939800, eval_loss: 4.83591e-02
I0213 23:39:00.204621 22509476222784 run_lib.py:133] step: 939850, training_loss: 4.53122e-02
I0213 23:39:19.143668 22509476222784 run_lib.py:133] step: 939900, training_loss: 4.57036e-02
I0213 23:39:19.310989 22509476222784 run_lib.py:146] step: 939900, eval_loss: 5.21274e-02
I0213 23:39:38.072552 22509476222784 run_lib.py:133] step: 939950, training_loss: 3.97930e-02
I0213 23:39:56.978444 22509476222784 run_lib.py:133] step: 940000, training_loss: 3.94897e-02
I0213 23:39:57.764357 22509476222784 run_lib.py:146] step: 940000, eval_loss: 3.81654e-02
I0213 23:40:19.237306 22509476222784 run_lib.py:133] step: 940050, training_loss: 2.98346e-02
I0213 23:40:38.033715 22509476222784 run_lib.py:133] step: 940100, training_loss: 3.49107e-02
I0213 23:40:38.200022 22509476222784 run_lib.py:146] step: 940100, eval_loss: 3.13071e-02
I0213 23:40:57.167752 22509476222784 run_lib.py:133] step: 940150, training_loss: 4.67895e-02
I0213 23:41:15.911641 22509476222784 run_lib.py:133] step: 940200, training_loss: 4.16427e-02
I0213 23:41:16.088244 22509476222784 run_lib.py:146] step: 940200, eval_loss: 3.66191e-02
I0213 23:41:35.024433 22509476222784 run_lib.py:133] step: 940250, training_loss: 4.42884e-02
I0213 23:41:53.709900 22509476222784 run_lib.py:133] step: 940300, training_loss: 4.48829e-02
I0213 23:41:53.876245 22509476222784 run_lib.py:146] step: 940300, eval_loss: 2.83166e-02
I0213 23:42:12.546739 22509476222784 run_lib.py:133] step: 940350, training_loss: 4.62005e-02
I0213 23:42:31.281675 22509476222784 run_lib.py:133] step: 940400, training_loss: 4.09820e-02
I0213 23:42:31.448077 22509476222784 run_lib.py:146] step: 940400, eval_loss: 3.70458e-02
I0213 23:42:50.296911 22509476222784 run_lib.py:133] step: 940450, training_loss: 4.53434e-02
I0213 23:43:09.096147 22509476222784 run_lib.py:133] step: 940500, training_loss: 2.43966e-02
I0213 23:43:09.274975 22509476222784 run_lib.py:146] step: 940500, eval_loss: 3.86316e-02
I0213 23:43:28.013321 22509476222784 run_lib.py:133] step: 940550, training_loss: 3.58261e-02
I0213 23:43:46.774979 22509476222784 run_lib.py:133] step: 940600, training_loss: 4.17649e-02
I0213 23:43:46.940814 22509476222784 run_lib.py:146] step: 940600, eval_loss: 2.91337e-02
I0213 23:44:05.879925 22509476222784 run_lib.py:133] step: 940650, training_loss: 4.35544e-02
I0213 23:44:24.636401 22509476222784 run_lib.py:133] step: 940700, training_loss: 3.92918e-02
I0213 23:44:24.798932 22509476222784 run_lib.py:146] step: 940700, eval_loss: 4.58956e-02
I0213 23:44:43.733984 22509476222784 run_lib.py:133] step: 940750, training_loss: 4.90272e-02
I0213 23:45:02.451609 22509476222784 run_lib.py:133] step: 940800, training_loss: 4.74176e-02
I0213 23:45:02.620477 22509476222784 run_lib.py:146] step: 940800, eval_loss: 3.50309e-02
I0213 23:45:21.535018 22509476222784 run_lib.py:133] step: 940850, training_loss: 3.79447e-02
I0213 23:45:40.257930 22509476222784 run_lib.py:133] step: 940900, training_loss: 4.04967e-02
I0213 23:45:40.426184 22509476222784 run_lib.py:146] step: 940900, eval_loss: 3.75805e-02
I0213 23:45:59.127774 22509476222784 run_lib.py:133] step: 940950, training_loss: 4.81515e-02
I0213 23:46:18.089694 22509476222784 run_lib.py:133] step: 941000, training_loss: 4.79850e-02
I0213 23:46:18.256622 22509476222784 run_lib.py:146] step: 941000, eval_loss: 4.19149e-02
I0213 23:46:36.983529 22509476222784 run_lib.py:133] step: 941050, training_loss: 4.91865e-02
I0213 23:46:55.860801 22509476222784 run_lib.py:133] step: 941100, training_loss: 4.57307e-02
I0213 23:46:56.028013 22509476222784 run_lib.py:146] step: 941100, eval_loss: 3.40310e-02
I0213 23:47:14.739105 22509476222784 run_lib.py:133] step: 941150, training_loss: 4.05778e-02
I0213 23:47:33.459787 22509476222784 run_lib.py:133] step: 941200, training_loss: 4.70409e-02
I0213 23:47:33.626149 22509476222784 run_lib.py:146] step: 941200, eval_loss: 3.58973e-02
I0213 23:47:52.588855 22509476222784 run_lib.py:133] step: 941250, training_loss: 3.83312e-02
I0213 23:48:11.349529 22509476222784 run_lib.py:133] step: 941300, training_loss: 3.57014e-02
I0213 23:48:11.518909 22509476222784 run_lib.py:146] step: 941300, eval_loss: 4.50460e-02
I0213 23:48:30.236416 22509476222784 run_lib.py:133] step: 941350, training_loss: 3.44198e-02
I0213 23:48:49.162932 22509476222784 run_lib.py:133] step: 941400, training_loss: 4.31946e-02
I0213 23:48:49.329201 22509476222784 run_lib.py:146] step: 941400, eval_loss: 3.64810e-02
I0213 23:49:08.071223 22509476222784 run_lib.py:133] step: 941450, training_loss: 4.86756e-02
I0213 23:49:26.838049 22509476222784 run_lib.py:133] step: 941500, training_loss: 4.19960e-02
I0213 23:49:27.157731 22509476222784 run_lib.py:146] step: 941500, eval_loss: 4.71773e-02
I0213 23:49:45.943994 22509476222784 run_lib.py:133] step: 941550, training_loss: 4.27394e-02
I0213 23:50:04.677005 22509476222784 run_lib.py:133] step: 941600, training_loss: 4.98284e-02
I0213 23:50:04.839699 22509476222784 run_lib.py:146] step: 941600, eval_loss: 5.31602e-02
I0213 23:50:23.537582 22509476222784 run_lib.py:133] step: 941650, training_loss: 4.41343e-02
I0213 23:50:42.244100 22509476222784 run_lib.py:133] step: 941700, training_loss: 5.11594e-02
I0213 23:50:42.408917 22509476222784 run_lib.py:146] step: 941700, eval_loss: 4.77754e-02
I0213 23:51:01.319437 22509476222784 run_lib.py:133] step: 941750, training_loss: 3.43565e-02
I0213 23:51:20.220194 22509476222784 run_lib.py:133] step: 941800, training_loss: 4.18569e-02
I0213 23:51:20.387945 22509476222784 run_lib.py:146] step: 941800, eval_loss: 3.39797e-02
I0213 23:51:39.109465 22509476222784 run_lib.py:133] step: 941850, training_loss: 3.75913e-02
I0213 23:51:57.880267 22509476222784 run_lib.py:133] step: 941900, training_loss: 4.85277e-02
I0213 23:51:58.045937 22509476222784 run_lib.py:146] step: 941900, eval_loss: 3.98224e-02
I0213 23:52:16.952561 22509476222784 run_lib.py:133] step: 941950, training_loss: 2.58584e-02
I0213 23:52:35.741439 22509476222784 run_lib.py:133] step: 942000, training_loss: 4.07939e-02
I0213 23:52:35.916986 22509476222784 run_lib.py:146] step: 942000, eval_loss: 4.11437e-02
I0213 23:52:54.716351 22509476222784 run_lib.py:133] step: 942050, training_loss: 4.60503e-02
I0213 23:53:13.500612 22509476222784 run_lib.py:133] step: 942100, training_loss: 5.64777e-02
I0213 23:53:13.667328 22509476222784 run_lib.py:146] step: 942100, eval_loss: 4.39335e-02
I0213 23:53:32.717148 22509476222784 run_lib.py:133] step: 942150, training_loss: 4.23734e-02
I0213 23:53:51.453475 22509476222784 run_lib.py:133] step: 942200, training_loss: 4.63727e-02
I0213 23:53:51.621749 22509476222784 run_lib.py:146] step: 942200, eval_loss: 3.22931e-02
I0213 23:54:10.505837 22509476222784 run_lib.py:133] step: 942250, training_loss: 4.94190e-02
I0213 23:54:29.316439 22509476222784 run_lib.py:133] step: 942300, training_loss: 3.74127e-02
I0213 23:54:29.487978 22509476222784 run_lib.py:146] step: 942300, eval_loss: 4.88847e-02
I0213 23:54:48.398313 22509476222784 run_lib.py:133] step: 942350, training_loss: 4.59371e-02
I0213 23:55:07.123119 22509476222784 run_lib.py:133] step: 942400, training_loss: 4.16770e-02
I0213 23:55:07.289908 22509476222784 run_lib.py:146] step: 942400, eval_loss: 3.84806e-02
I0213 23:55:26.000354 22509476222784 run_lib.py:133] step: 942450, training_loss: 5.46202e-02
I0213 23:55:44.918625 22509476222784 run_lib.py:133] step: 942500, training_loss: 3.82056e-02
I0213 23:55:45.084300 22509476222784 run_lib.py:146] step: 942500, eval_loss: 4.97120e-02
I0213 23:56:03.852216 22509476222784 run_lib.py:133] step: 942550, training_loss: 3.61595e-02
I0213 23:56:22.729096 22509476222784 run_lib.py:133] step: 942600, training_loss: 4.08346e-02
I0213 23:56:22.892915 22509476222784 run_lib.py:146] step: 942600, eval_loss: 3.81808e-02
I0213 23:56:41.599322 22509476222784 run_lib.py:133] step: 942650, training_loss: 3.48849e-02
I0213 23:57:00.316353 22509476222784 run_lib.py:133] step: 942700, training_loss: 4.13596e-02
I0213 23:57:00.486621 22509476222784 run_lib.py:146] step: 942700, eval_loss: 3.62078e-02
I0213 23:57:19.367927 22509476222784 run_lib.py:133] step: 942750, training_loss: 3.90190e-02
I0213 23:57:38.189636 22509476222784 run_lib.py:133] step: 942800, training_loss: 4.40082e-02
I0213 23:57:38.355935 22509476222784 run_lib.py:146] step: 942800, eval_loss: 3.90548e-02
I0213 23:57:57.158736 22509476222784 run_lib.py:133] step: 942850, training_loss: 4.72372e-02
I0213 23:58:15.878015 22509476222784 run_lib.py:133] step: 942900, training_loss: 4.45522e-02
I0213 23:58:16.044095 22509476222784 run_lib.py:146] step: 942900, eval_loss: 4.19403e-02
I0213 23:58:34.968596 22509476222784 run_lib.py:133] step: 942950, training_loss: 3.56419e-02
I0213 23:58:53.686976 22509476222784 run_lib.py:133] step: 943000, training_loss: 3.52343e-02
I0213 23:58:53.864578 22509476222784 run_lib.py:146] step: 943000, eval_loss: 3.52659e-02
I0213 23:59:12.770081 22509476222784 run_lib.py:133] step: 943050, training_loss: 3.52558e-02
I0213 23:59:31.515764 22509476222784 run_lib.py:133] step: 943100, training_loss: 4.94267e-02
I0213 23:59:31.682245 22509476222784 run_lib.py:146] step: 943100, eval_loss: 5.11077e-02
I0213 23:59:50.412256 22509476222784 run_lib.py:133] step: 943150, training_loss: 4.03137e-02
I0214 00:00:09.132035 22509476222784 run_lib.py:133] step: 943200, training_loss: 4.00460e-02
I0214 00:00:09.300246 22509476222784 run_lib.py:146] step: 943200, eval_loss: 4.34925e-02
I0214 00:00:28.215372 22509476222784 run_lib.py:133] step: 943250, training_loss: 5.10682e-02
I0214 00:00:47.121337 22509476222784 run_lib.py:133] step: 943300, training_loss: 2.77955e-02
I0214 00:00:47.287242 22509476222784 run_lib.py:146] step: 943300, eval_loss: 3.86498e-02
I0214 00:01:06.014946 22509476222784 run_lib.py:133] step: 943350, training_loss: 3.86869e-02
I0214 00:01:24.731126 22509476222784 run_lib.py:133] step: 943400, training_loss: 4.57224e-02
I0214 00:01:24.898823 22509476222784 run_lib.py:146] step: 943400, eval_loss: 5.12602e-02
I0214 00:01:43.845239 22509476222784 run_lib.py:133] step: 943450, training_loss: 3.90244e-02
I0214 00:02:02.578458 22509476222784 run_lib.py:133] step: 943500, training_loss: 3.32141e-02
I0214 00:02:02.752149 22509476222784 run_lib.py:146] step: 943500, eval_loss: 3.65402e-02
I0214 00:02:21.710572 22509476222784 run_lib.py:133] step: 943550, training_loss: 3.53779e-02
I0214 00:02:40.476446 22509476222784 run_lib.py:133] step: 943600, training_loss: 5.01472e-02
I0214 00:02:40.642117 22509476222784 run_lib.py:146] step: 943600, eval_loss: 3.21664e-02
I0214 00:02:59.571742 22509476222784 run_lib.py:133] step: 943650, training_loss: 4.83961e-02
I0214 00:03:18.354014 22509476222784 run_lib.py:133] step: 943700, training_loss: 4.16896e-02
I0214 00:03:18.542157 22509476222784 run_lib.py:146] step: 943700, eval_loss: 4.21111e-02
I0214 00:03:37.468340 22509476222784 run_lib.py:133] step: 943750, training_loss: 3.46450e-02
I0214 00:03:56.300156 22509476222784 run_lib.py:133] step: 943800, training_loss: 4.26249e-02
I0214 00:03:56.467069 22509476222784 run_lib.py:146] step: 943800, eval_loss: 4.38775e-02
I0214 00:04:15.216411 22509476222784 run_lib.py:133] step: 943850, training_loss: 3.22314e-02
I0214 00:04:34.190781 22509476222784 run_lib.py:133] step: 943900, training_loss: 3.71429e-02
I0214 00:04:34.356051 22509476222784 run_lib.py:146] step: 943900, eval_loss: 4.04649e-02
I0214 00:04:53.141439 22509476222784 run_lib.py:133] step: 943950, training_loss: 5.04880e-02
I0214 00:05:11.933574 22509476222784 run_lib.py:133] step: 944000, training_loss: 4.68091e-02
I0214 00:05:12.104199 22509476222784 run_lib.py:146] step: 944000, eval_loss: 3.97177e-02
I0214 00:05:31.094040 22509476222784 run_lib.py:133] step: 944050, training_loss: 4.66668e-02
I0214 00:05:50.086050 22509476222784 run_lib.py:133] step: 944100, training_loss: 4.42350e-02
I0214 00:05:50.253983 22509476222784 run_lib.py:146] step: 944100, eval_loss: 4.10962e-02
I0214 00:06:09.031409 22509476222784 run_lib.py:133] step: 944150, training_loss: 3.70205e-02
I0214 00:06:27.772027 22509476222784 run_lib.py:133] step: 944200, training_loss: 4.50247e-02
I0214 00:06:27.945260 22509476222784 run_lib.py:146] step: 944200, eval_loss: 3.67800e-02
I0214 00:06:46.688791 22509476222784 run_lib.py:133] step: 944250, training_loss: 4.53361e-02
I0214 00:07:05.677284 22509476222784 run_lib.py:133] step: 944300, training_loss: 4.33143e-02
I0214 00:07:05.844344 22509476222784 run_lib.py:146] step: 944300, eval_loss: 4.82461e-02
I0214 00:07:24.534825 22509476222784 run_lib.py:133] step: 944350, training_loss: 4.09163e-02
I0214 00:07:43.240438 22509476222784 run_lib.py:133] step: 944400, training_loss: 4.38937e-02
I0214 00:07:43.407003 22509476222784 run_lib.py:146] step: 944400, eval_loss: 3.72072e-02
I0214 00:08:02.127171 22509476222784 run_lib.py:133] step: 944450, training_loss: 3.46640e-02
I0214 00:08:21.035920 22509476222784 run_lib.py:133] step: 944500, training_loss: 4.01369e-02
I0214 00:08:21.202188 22509476222784 run_lib.py:146] step: 944500, eval_loss: 4.90912e-02
I0214 00:08:39.916847 22509476222784 run_lib.py:133] step: 944550, training_loss: 3.72468e-02
I0214 00:08:58.736546 22509476222784 run_lib.py:133] step: 944600, training_loss: 3.00088e-02
I0214 00:08:58.905041 22509476222784 run_lib.py:146] step: 944600, eval_loss: 4.41613e-02
I0214 00:09:17.626101 22509476222784 run_lib.py:133] step: 944650, training_loss: 4.57677e-02
I0214 00:09:36.392343 22509476222784 run_lib.py:133] step: 944700, training_loss: 3.18880e-02
I0214 00:09:36.559534 22509476222784 run_lib.py:146] step: 944700, eval_loss: 4.26287e-02
I0214 00:09:55.469319 22509476222784 run_lib.py:133] step: 944750, training_loss: 4.42674e-02
I0214 00:10:14.364281 22509476222784 run_lib.py:133] step: 944800, training_loss: 5.17638e-02
I0214 00:10:14.530679 22509476222784 run_lib.py:146] step: 944800, eval_loss: 5.49668e-02
I0214 00:10:33.331625 22509476222784 run_lib.py:133] step: 944850, training_loss: 4.42170e-02
I0214 00:10:52.083657 22509476222784 run_lib.py:133] step: 944900, training_loss: 3.55919e-02
I0214 00:10:52.256598 22509476222784 run_lib.py:146] step: 944900, eval_loss: 5.51695e-02
I0214 00:11:11.139531 22509476222784 run_lib.py:133] step: 944950, training_loss: 3.14955e-02
I0214 00:11:29.878617 22509476222784 run_lib.py:133] step: 945000, training_loss: 3.61971e-02
I0214 00:11:30.045054 22509476222784 run_lib.py:146] step: 945000, eval_loss: 4.45015e-02
I0214 00:11:48.948103 22509476222784 run_lib.py:133] step: 945050, training_loss: 3.62316e-02
I0214 00:12:07.710340 22509476222784 run_lib.py:133] step: 945100, training_loss: 5.62114e-02
I0214 00:12:07.879000 22509476222784 run_lib.py:146] step: 945100, eval_loss: 4.10873e-02
I0214 00:12:26.793065 22509476222784 run_lib.py:133] step: 945150, training_loss: 4.50681e-02
I0214 00:12:45.504211 22509476222784 run_lib.py:133] step: 945200, training_loss: 4.85187e-02
I0214 00:12:45.667923 22509476222784 run_lib.py:146] step: 945200, eval_loss: 4.68233e-02
I0214 00:13:04.384994 22509476222784 run_lib.py:133] step: 945250, training_loss: 3.91420e-02
I0214 00:13:23.274568 22509476222784 run_lib.py:133] step: 945300, training_loss: 3.73497e-02
I0214 00:13:23.455713 22509476222784 run_lib.py:146] step: 945300, eval_loss: 3.67980e-02
I0214 00:13:42.195969 22509476222784 run_lib.py:133] step: 945350, training_loss: 3.64254e-02
I0214 00:14:01.132470 22509476222784 run_lib.py:133] step: 945400, training_loss: 4.14417e-02
I0214 00:14:01.297857 22509476222784 run_lib.py:146] step: 945400, eval_loss: 5.48460e-02
I0214 00:14:20.095561 22509476222784 run_lib.py:133] step: 945450, training_loss: 3.70218e-02
I0214 00:14:38.882491 22509476222784 run_lib.py:133] step: 945500, training_loss: 3.48281e-02
I0214 00:14:39.048960 22509476222784 run_lib.py:146] step: 945500, eval_loss: 4.31046e-02
I0214 00:14:57.991224 22509476222784 run_lib.py:133] step: 945550, training_loss: 4.78740e-02
I0214 00:15:16.738385 22509476222784 run_lib.py:133] step: 945600, training_loss: 3.86921e-02
I0214 00:15:16.906944 22509476222784 run_lib.py:146] step: 945600, eval_loss: 4.58387e-02
I0214 00:15:35.672487 22509476222784 run_lib.py:133] step: 945650, training_loss: 3.81779e-02
I0214 00:15:54.677720 22509476222784 run_lib.py:133] step: 945700, training_loss: 3.68918e-02
I0214 00:15:54.853469 22509476222784 run_lib.py:146] step: 945700, eval_loss: 3.92894e-02
I0214 00:16:13.508356 22509476222784 run_lib.py:133] step: 945750, training_loss: 2.71575e-02
I0214 00:16:32.213337 22509476222784 run_lib.py:133] step: 945800, training_loss: 2.99268e-02
I0214 00:16:32.378690 22509476222784 run_lib.py:146] step: 945800, eval_loss: 2.90461e-02
I0214 00:16:51.177245 22509476222784 run_lib.py:133] step: 945850, training_loss: 3.20908e-02
I0214 00:17:09.905930 22509476222784 run_lib.py:133] step: 945900, training_loss: 3.39396e-02
I0214 00:17:10.069976 22509476222784 run_lib.py:146] step: 945900, eval_loss: 6.02405e-02
I0214 00:17:28.794749 22509476222784 run_lib.py:133] step: 945950, training_loss: 4.07330e-02
I0214 00:17:47.600983 22509476222784 run_lib.py:133] step: 946000, training_loss: 5.58253e-02
I0214 00:17:47.774100 22509476222784 run_lib.py:146] step: 946000, eval_loss: 5.20561e-02
I0214 00:18:06.723576 22509476222784 run_lib.py:133] step: 946050, training_loss: 5.11650e-02
I0214 00:18:25.565626 22509476222784 run_lib.py:133] step: 946100, training_loss: 3.48152e-02
I0214 00:18:25.733455 22509476222784 run_lib.py:146] step: 946100, eval_loss: 3.74282e-02
I0214 00:18:44.399000 22509476222784 run_lib.py:133] step: 946150, training_loss: 3.11565e-02
I0214 00:19:03.100235 22509476222784 run_lib.py:133] step: 946200, training_loss: 4.16093e-02
I0214 00:19:03.277204 22509476222784 run_lib.py:146] step: 946200, eval_loss: 3.14948e-02
I0214 00:19:22.221339 22509476222784 run_lib.py:133] step: 946250, training_loss: 3.36022e-02
I0214 00:19:40.959816 22509476222784 run_lib.py:133] step: 946300, training_loss: 5.86032e-02
I0214 00:19:41.125102 22509476222784 run_lib.py:146] step: 946300, eval_loss: 4.43106e-02
I0214 00:20:00.075649 22509476222784 run_lib.py:133] step: 946350, training_loss: 2.88909e-02
I0214 00:20:18.771634 22509476222784 run_lib.py:133] step: 946400, training_loss: 4.14432e-02
I0214 00:20:18.935811 22509476222784 run_lib.py:146] step: 946400, eval_loss: 4.69625e-02
I0214 00:20:37.844940 22509476222784 run_lib.py:133] step: 946450, training_loss: 4.67761e-02
I0214 00:20:56.617580 22509476222784 run_lib.py:133] step: 946500, training_loss: 3.70180e-02
I0214 00:20:56.800049 22509476222784 run_lib.py:146] step: 946500, eval_loss: 4.48136e-02
I0214 00:21:15.761616 22509476222784 run_lib.py:133] step: 946550, training_loss: 6.37954e-02
I0214 00:21:34.570623 22509476222784 run_lib.py:133] step: 946600, training_loss: 5.03657e-02
I0214 00:21:34.736104 22509476222784 run_lib.py:146] step: 946600, eval_loss: 4.77792e-02
I0214 00:21:53.491848 22509476222784 run_lib.py:133] step: 946650, training_loss: 4.89816e-02
I0214 00:22:12.378667 22509476222784 run_lib.py:133] step: 946700, training_loss: 3.79763e-02
I0214 00:22:12.555130 22509476222784 run_lib.py:146] step: 946700, eval_loss: 3.09639e-02
I0214 00:22:31.321245 22509476222784 run_lib.py:133] step: 946750, training_loss: 3.49076e-02
I0214 00:22:50.116360 22509476222784 run_lib.py:133] step: 946800, training_loss: 4.85159e-02
I0214 00:22:50.281991 22509476222784 run_lib.py:146] step: 946800, eval_loss: 4.35381e-02
I0214 00:23:09.292077 22509476222784 run_lib.py:133] step: 946850, training_loss: 5.13121e-02
I0214 00:23:28.071853 22509476222784 run_lib.py:133] step: 946900, training_loss: 3.99924e-02
I0214 00:23:28.253388 22509476222784 run_lib.py:146] step: 946900, eval_loss: 5.75169e-02
I0214 00:23:47.148443 22509476222784 run_lib.py:133] step: 946950, training_loss: 3.98361e-02
I0214 00:24:05.921886 22509476222784 run_lib.py:133] step: 947000, training_loss: 3.76836e-02
I0214 00:24:06.104079 22509476222784 run_lib.py:146] step: 947000, eval_loss: 4.70757e-02
I0214 00:24:24.903694 22509476222784 run_lib.py:133] step: 947050, training_loss: 4.30606e-02
I0214 00:24:43.885756 22509476222784 run_lib.py:133] step: 947100, training_loss: 3.63089e-02
I0214 00:24:44.053398 22509476222784 run_lib.py:146] step: 947100, eval_loss: 4.15300e-02
I0214 00:25:02.808743 22509476222784 run_lib.py:133] step: 947150, training_loss: 4.06632e-02
I0214 00:25:21.553924 22509476222784 run_lib.py:133] step: 947200, training_loss: 4.67393e-02
I0214 00:25:21.728499 22509476222784 run_lib.py:146] step: 947200, eval_loss: 3.89948e-02
I0214 00:25:40.581234 22509476222784 run_lib.py:133] step: 947250, training_loss: 4.78372e-02
I0214 00:25:59.553783 22509476222784 run_lib.py:133] step: 947300, training_loss: 4.82835e-02
I0214 00:25:59.726482 22509476222784 run_lib.py:146] step: 947300, eval_loss: 4.19717e-02
I0214 00:26:18.480041 22509476222784 run_lib.py:133] step: 947350, training_loss: 5.01793e-02
I0214 00:26:37.294137 22509476222784 run_lib.py:133] step: 947400, training_loss: 3.21511e-02
I0214 00:26:37.460776 22509476222784 run_lib.py:146] step: 947400, eval_loss: 3.53846e-02
I0214 00:26:56.272492 22509476222784 run_lib.py:133] step: 947450, training_loss: 3.54026e-02
I0214 00:27:15.065053 22509476222784 run_lib.py:133] step: 947500, training_loss: 4.14346e-02
I0214 00:27:15.234947 22509476222784 run_lib.py:146] step: 947500, eval_loss: 3.76899e-02
I0214 00:27:34.127342 22509476222784 run_lib.py:133] step: 947550, training_loss: 5.18670e-02
I0214 00:27:52.931404 22509476222784 run_lib.py:133] step: 947600, training_loss: 3.89358e-02
I0214 00:27:53.098985 22509476222784 run_lib.py:146] step: 947600, eval_loss: 3.68943e-02
I0214 00:28:11.826968 22509476222784 run_lib.py:133] step: 947650, training_loss: 4.20339e-02
I0214 00:28:30.560539 22509476222784 run_lib.py:133] step: 947700, training_loss: 4.52098e-02
I0214 00:28:30.727187 22509476222784 run_lib.py:146] step: 947700, eval_loss: 3.51280e-02
I0214 00:28:49.717507 22509476222784 run_lib.py:133] step: 947750, training_loss: 4.20968e-02
I0214 00:29:08.500055 22509476222784 run_lib.py:133] step: 947800, training_loss: 4.51625e-02
I0214 00:29:08.662972 22509476222784 run_lib.py:146] step: 947800, eval_loss: 4.97097e-02
I0214 00:29:27.602414 22509476222784 run_lib.py:133] step: 947850, training_loss: 5.64796e-02
I0214 00:29:46.363755 22509476222784 run_lib.py:133] step: 947900, training_loss: 3.12886e-02
I0214 00:29:46.529754 22509476222784 run_lib.py:146] step: 947900, eval_loss: 4.61886e-02
I0214 00:30:05.450231 22509476222784 run_lib.py:133] step: 947950, training_loss: 2.82517e-02
I0214 00:30:24.222138 22509476222784 run_lib.py:133] step: 948000, training_loss: 4.05516e-02
I0214 00:30:24.399978 22509476222784 run_lib.py:146] step: 948000, eval_loss: 4.97249e-02
I0214 00:30:43.189739 22509476222784 run_lib.py:133] step: 948050, training_loss: 5.39392e-02
I0214 00:31:02.124529 22509476222784 run_lib.py:133] step: 948100, training_loss: 6.03506e-02
I0214 00:31:02.291317 22509476222784 run_lib.py:146] step: 948100, eval_loss: 4.82801e-02
I0214 00:31:21.002559 22509476222784 run_lib.py:133] step: 948150, training_loss: 3.07702e-02
I0214 00:31:39.885316 22509476222784 run_lib.py:133] step: 948200, training_loss: 3.79622e-02
I0214 00:31:40.058226 22509476222784 run_lib.py:146] step: 948200, eval_loss: 4.47458e-02
I0214 00:31:58.819990 22509476222784 run_lib.py:133] step: 948250, training_loss: 4.16790e-02
I0214 00:32:17.564810 22509476222784 run_lib.py:133] step: 948300, training_loss: 4.94865e-02
I0214 00:32:17.729162 22509476222784 run_lib.py:146] step: 948300, eval_loss: 4.86578e-02
I0214 00:32:36.663452 22509476222784 run_lib.py:133] step: 948350, training_loss: 4.64676e-02
I0214 00:32:55.394968 22509476222784 run_lib.py:133] step: 948400, training_loss: 4.60660e-02
I0214 00:32:55.563848 22509476222784 run_lib.py:146] step: 948400, eval_loss: 4.32421e-02
I0214 00:33:14.274388 22509476222784 run_lib.py:133] step: 948450, training_loss: 3.66568e-02
I0214 00:33:33.189576 22509476222784 run_lib.py:133] step: 948500, training_loss: 4.97502e-02
I0214 00:33:33.389024 22509476222784 run_lib.py:146] step: 948500, eval_loss: 4.62226e-02
I0214 00:33:52.191736 22509476222784 run_lib.py:133] step: 948550, training_loss: 3.66354e-02
I0214 00:34:10.950790 22509476222784 run_lib.py:133] step: 948600, training_loss: 4.37441e-02
I0214 00:34:11.317013 22509476222784 run_lib.py:146] step: 948600, eval_loss: 4.07483e-02
I0214 00:34:30.069804 22509476222784 run_lib.py:133] step: 948650, training_loss: 5.26525e-02
I0214 00:34:48.739040 22509476222784 run_lib.py:133] step: 948700, training_loss: 3.91686e-02
I0214 00:34:48.902055 22509476222784 run_lib.py:146] step: 948700, eval_loss: 5.14347e-02
I0214 00:35:07.673731 22509476222784 run_lib.py:133] step: 948750, training_loss: 3.63479e-02
I0214 00:35:26.430631 22509476222784 run_lib.py:133] step: 948800, training_loss: 4.05843e-02
I0214 00:35:26.606984 22509476222784 run_lib.py:146] step: 948800, eval_loss: 3.91763e-02
I0214 00:35:45.499062 22509476222784 run_lib.py:133] step: 948850, training_loss: 4.81820e-02
I0214 00:36:04.298231 22509476222784 run_lib.py:133] step: 948900, training_loss: 3.56398e-02
I0214 00:36:04.485150 22509476222784 run_lib.py:146] step: 948900, eval_loss: 5.00479e-02
I0214 00:36:23.188994 22509476222784 run_lib.py:133] step: 948950, training_loss: 5.77606e-02
I0214 00:36:41.978348 22509476222784 run_lib.py:133] step: 949000, training_loss: 4.30050e-02
I0214 00:36:42.152140 22509476222784 run_lib.py:146] step: 949000, eval_loss: 4.12310e-02
I0214 00:37:01.073111 22509476222784 run_lib.py:133] step: 949050, training_loss: 3.71747e-02
I0214 00:37:19.922824 22509476222784 run_lib.py:133] step: 949100, training_loss: 4.61092e-02
I0214 00:37:20.089167 22509476222784 run_lib.py:146] step: 949100, eval_loss: 3.94047e-02
I0214 00:37:38.814011 22509476222784 run_lib.py:133] step: 949150, training_loss: 3.67696e-02
I0214 00:37:57.516058 22509476222784 run_lib.py:133] step: 949200, training_loss: 4.34060e-02
I0214 00:37:57.690824 22509476222784 run_lib.py:146] step: 949200, eval_loss: 4.26138e-02
I0214 00:38:16.664066 22509476222784 run_lib.py:133] step: 949250, training_loss: 3.95519e-02
I0214 00:38:35.368898 22509476222784 run_lib.py:133] step: 949300, training_loss: 4.53331e-02
I0214 00:38:35.534880 22509476222784 run_lib.py:146] step: 949300, eval_loss: 4.59106e-02
I0214 00:38:54.370770 22509476222784 run_lib.py:133] step: 949350, training_loss: 4.40628e-02
I0214 00:39:13.099248 22509476222784 run_lib.py:133] step: 949400, training_loss: 4.51759e-02
I0214 00:39:13.276126 22509476222784 run_lib.py:146] step: 949400, eval_loss: 3.11730e-02
I0214 00:39:32.187083 22509476222784 run_lib.py:133] step: 949450, training_loss: 4.97715e-02
I0214 00:39:50.961395 22509476222784 run_lib.py:133] step: 949500, training_loss: 4.26833e-02
I0214 00:39:51.128021 22509476222784 run_lib.py:146] step: 949500, eval_loss: 2.77549e-02
I0214 00:40:09.816606 22509476222784 run_lib.py:133] step: 949550, training_loss: 3.83650e-02
I0214 00:40:28.761415 22509476222784 run_lib.py:133] step: 949600, training_loss: 3.11039e-02
I0214 00:40:28.927998 22509476222784 run_lib.py:146] step: 949600, eval_loss: 4.75380e-02
I0214 00:40:47.669980 22509476222784 run_lib.py:133] step: 949650, training_loss: 3.60909e-02
I0214 00:41:06.609154 22509476222784 run_lib.py:133] step: 949700, training_loss: 3.00955e-02
I0214 00:41:06.783148 22509476222784 run_lib.py:146] step: 949700, eval_loss: 3.96176e-02
I0214 00:41:25.550982 22509476222784 run_lib.py:133] step: 949750, training_loss: 4.04518e-02
I0214 00:41:44.307526 22509476222784 run_lib.py:133] step: 949800, training_loss: 3.02097e-02
I0214 00:41:44.475182 22509476222784 run_lib.py:146] step: 949800, eval_loss: 4.44084e-02
I0214 00:42:03.413358 22509476222784 run_lib.py:133] step: 949850, training_loss: 4.12728e-02
I0214 00:42:22.159209 22509476222784 run_lib.py:133] step: 949900, training_loss: 3.78541e-02
I0214 00:42:22.326175 22509476222784 run_lib.py:146] step: 949900, eval_loss: 3.48198e-02
I0214 00:42:41.085183 22509476222784 run_lib.py:133] step: 949950, training_loss: 3.30221e-02
I0214 00:42:59.915372 22509476222784 run_lib.py:133] step: 950000, training_loss: 4.65329e-02
I0214 00:43:00.752396 22509476222784 run_lib.py:146] step: 950000, eval_loss: 5.13300e-02
I0214 00:43:22.448249 22509476222784 run_lib.py:133] step: 950050, training_loss: 3.53216e-02
I0214 00:43:41.336975 22509476222784 run_lib.py:133] step: 950100, training_loss: 4.13284e-02
I0214 00:43:41.518193 22509476222784 run_lib.py:146] step: 950100, eval_loss: 4.24108e-02
I0214 00:44:00.254454 22509476222784 run_lib.py:133] step: 950150, training_loss: 3.69544e-02
I0214 00:44:19.070382 22509476222784 run_lib.py:133] step: 950200, training_loss: 3.88525e-02
I0214 00:44:19.242730 22509476222784 run_lib.py:146] step: 950200, eval_loss: 4.85871e-02
I0214 00:44:38.255633 22509476222784 run_lib.py:133] step: 950250, training_loss: 3.73895e-02
I0214 00:44:57.040484 22509476222784 run_lib.py:133] step: 950300, training_loss: 2.92084e-02
I0214 00:44:57.208960 22509476222784 run_lib.py:146] step: 950300, eval_loss: 5.06805e-02
I0214 00:45:15.995163 22509476222784 run_lib.py:133] step: 950350, training_loss: 4.62835e-02
I0214 00:45:34.765241 22509476222784 run_lib.py:133] step: 950400, training_loss: 3.37987e-02
I0214 00:45:34.947580 22509476222784 run_lib.py:146] step: 950400, eval_loss: 3.40676e-02
I0214 00:45:53.875458 22509476222784 run_lib.py:133] step: 950450, training_loss: 4.23292e-02
I0214 00:46:12.658411 22509476222784 run_lib.py:133] step: 950500, training_loss: 4.66637e-02
I0214 00:46:12.834224 22509476222784 run_lib.py:146] step: 950500, eval_loss: 5.99384e-02
I0214 00:46:31.737878 22509476222784 run_lib.py:133] step: 950550, training_loss: 4.29103e-02
I0214 00:46:50.470609 22509476222784 run_lib.py:133] step: 950600, training_loss: 4.18227e-02
I0214 00:46:50.637986 22509476222784 run_lib.py:146] step: 950600, eval_loss: 3.80035e-02
I0214 00:47:09.404181 22509476222784 run_lib.py:133] step: 950650, training_loss: 3.69064e-02
I0214 00:47:28.174115 22509476222784 run_lib.py:133] step: 950700, training_loss: 4.28039e-02
I0214 00:47:28.342269 22509476222784 run_lib.py:146] step: 950700, eval_loss: 4.53795e-02
I0214 00:47:47.304765 22509476222784 run_lib.py:133] step: 950750, training_loss: 3.59070e-02
I0214 00:48:06.158924 22509476222784 run_lib.py:133] step: 950800, training_loss: 4.10656e-02
I0214 00:48:06.325780 22509476222784 run_lib.py:146] step: 950800, eval_loss: 3.57838e-02
I0214 00:48:25.053538 22509476222784 run_lib.py:133] step: 950850, training_loss: 4.18816e-02
I0214 00:48:43.764451 22509476222784 run_lib.py:133] step: 950900, training_loss: 3.99629e-02
I0214 00:48:43.947889 22509476222784 run_lib.py:146] step: 950900, eval_loss: 3.99161e-02
I0214 00:49:02.869091 22509476222784 run_lib.py:133] step: 950950, training_loss: 4.33281e-02
I0214 00:49:21.605825 22509476222784 run_lib.py:133] step: 951000, training_loss: 3.96203e-02
I0214 00:49:21.772144 22509476222784 run_lib.py:146] step: 951000, eval_loss: 4.15921e-02
I0214 00:49:40.697596 22509476222784 run_lib.py:133] step: 951050, training_loss: 4.45265e-02
I0214 00:49:59.337850 22509476222784 run_lib.py:133] step: 951100, training_loss: 3.07973e-02
I0214 00:49:59.502980 22509476222784 run_lib.py:146] step: 951100, eval_loss: 4.02369e-02
I0214 00:50:18.339138 22509476222784 run_lib.py:133] step: 951150, training_loss: 4.49887e-02
I0214 00:50:37.082941 22509476222784 run_lib.py:133] step: 951200, training_loss: 4.55593e-02
I0214 00:50:37.252256 22509476222784 run_lib.py:146] step: 951200, eval_loss: 5.00527e-02
I0214 00:50:56.218087 22509476222784 run_lib.py:133] step: 951250, training_loss: 3.49844e-02
I0214 00:51:14.924025 22509476222784 run_lib.py:133] step: 951300, training_loss: 4.80528e-02
I0214 00:51:15.092302 22509476222784 run_lib.py:146] step: 951300, eval_loss: 5.21758e-02
I0214 00:51:33.797728 22509476222784 run_lib.py:133] step: 951350, training_loss: 3.47113e-02
I0214 00:51:52.678042 22509476222784 run_lib.py:133] step: 951400, training_loss: 3.68803e-02
I0214 00:51:52.845150 22509476222784 run_lib.py:146] step: 951400, eval_loss: 3.40280e-02
I0214 00:52:11.617315 22509476222784 run_lib.py:133] step: 951450, training_loss: 3.69419e-02
I0214 00:52:30.399285 22509476222784 run_lib.py:133] step: 951500, training_loss: 4.25641e-02
I0214 00:52:30.566852 22509476222784 run_lib.py:146] step: 951500, eval_loss: 4.23658e-02
I0214 00:52:49.534948 22509476222784 run_lib.py:133] step: 951550, training_loss: 4.00493e-02
I0214 00:53:08.247601 22509476222784 run_lib.py:133] step: 951600, training_loss: 2.89005e-02
I0214 00:53:08.410904 22509476222784 run_lib.py:146] step: 951600, eval_loss: 3.50414e-02
I0214 00:53:27.253427 22509476222784 run_lib.py:133] step: 951650, training_loss: 3.48556e-02
I0214 00:53:45.911364 22509476222784 run_lib.py:133] step: 951700, training_loss: 4.51489e-02
I0214 00:53:46.087141 22509476222784 run_lib.py:146] step: 951700, eval_loss: 4.53076e-02
I0214 00:54:04.837647 22509476222784 run_lib.py:133] step: 951750, training_loss: 4.10710e-02
I0214 00:54:23.759310 22509476222784 run_lib.py:133] step: 951800, training_loss: 4.41331e-02
I0214 00:54:23.929352 22509476222784 run_lib.py:146] step: 951800, eval_loss: 4.56873e-02
I0214 00:54:42.730561 22509476222784 run_lib.py:133] step: 951850, training_loss: 5.57966e-02
I0214 00:55:01.475169 22509476222784 run_lib.py:133] step: 951900, training_loss: 4.14767e-02
I0214 00:55:01.638804 22509476222784 run_lib.py:146] step: 951900, eval_loss: 4.84897e-02
I0214 00:55:20.395964 22509476222784 run_lib.py:133] step: 951950, training_loss: 4.04462e-02
I0214 00:55:39.361720 22509476222784 run_lib.py:133] step: 952000, training_loss: 4.75742e-02
I0214 00:55:39.528310 22509476222784 run_lib.py:146] step: 952000, eval_loss: 3.54657e-02
I0214 00:55:58.279490 22509476222784 run_lib.py:133] step: 952050, training_loss: 4.10452e-02
I0214 00:56:17.110888 22509476222784 run_lib.py:133] step: 952100, training_loss: 3.68948e-02
I0214 00:56:17.272980 22509476222784 run_lib.py:146] step: 952100, eval_loss: 4.22010e-02
I0214 00:56:35.983442 22509476222784 run_lib.py:133] step: 952150, training_loss: 4.56404e-02
I0214 00:56:54.716920 22509476222784 run_lib.py:133] step: 952200, training_loss: 5.01870e-02
I0214 00:56:54.893229 22509476222784 run_lib.py:146] step: 952200, eval_loss: 4.79347e-02
I0214 00:57:13.854315 22509476222784 run_lib.py:133] step: 952250, training_loss: 4.35733e-02
I0214 00:57:32.723466 22509476222784 run_lib.py:133] step: 952300, training_loss: 4.62647e-02
I0214 00:57:32.898948 22509476222784 run_lib.py:146] step: 952300, eval_loss: 4.61481e-02
I0214 00:57:51.602286 22509476222784 run_lib.py:133] step: 952350, training_loss: 4.91408e-02
I0214 00:58:10.289386 22509476222784 run_lib.py:133] step: 952400, training_loss: 2.73907e-02
I0214 00:58:10.454950 22509476222784 run_lib.py:146] step: 952400, eval_loss: 4.58187e-02
I0214 00:58:29.388349 22509476222784 run_lib.py:133] step: 952450, training_loss: 4.36334e-02
I0214 00:58:48.219806 22509476222784 run_lib.py:133] step: 952500, training_loss: 5.97288e-02
I0214 00:58:48.386697 22509476222784 run_lib.py:146] step: 952500, eval_loss: 4.94701e-02
I0214 00:59:07.360371 22509476222784 run_lib.py:133] step: 952550, training_loss: 4.26103e-02
I0214 00:59:26.146861 22509476222784 run_lib.py:133] step: 952600, training_loss: 4.39781e-02
I0214 00:59:26.307758 22509476222784 run_lib.py:146] step: 952600, eval_loss: 3.52990e-02
I0214 00:59:45.200138 22509476222784 run_lib.py:133] step: 952650, training_loss: 3.66103e-02
I0214 01:00:03.952085 22509476222784 run_lib.py:133] step: 952700, training_loss: 3.46263e-02
I0214 01:00:04.133943 22509476222784 run_lib.py:146] step: 952700, eval_loss: 4.01299e-02
I0214 01:00:22.925434 22509476222784 run_lib.py:133] step: 952750, training_loss: 5.12207e-02
I0214 01:00:41.928923 22509476222784 run_lib.py:133] step: 952800, training_loss: 2.47658e-02
I0214 01:00:42.096648 22509476222784 run_lib.py:146] step: 952800, eval_loss: 4.56473e-02
I0214 01:01:00.794266 22509476222784 run_lib.py:133] step: 952850, training_loss: 3.90770e-02
I0214 01:01:19.646873 22509476222784 run_lib.py:133] step: 952900, training_loss: 3.47713e-02
I0214 01:01:19.812982 22509476222784 run_lib.py:146] step: 952900, eval_loss: 4.22095e-02
I0214 01:01:38.568068 22509476222784 run_lib.py:133] step: 952950, training_loss: 4.24583e-02
I0214 01:01:57.346005 22509476222784 run_lib.py:133] step: 953000, training_loss: 4.48721e-02
I0214 01:01:57.512037 22509476222784 run_lib.py:146] step: 953000, eval_loss: 4.65937e-02
I0214 01:02:16.494434 22509476222784 run_lib.py:133] step: 953050, training_loss: 3.90515e-02
I0214 01:02:35.239409 22509476222784 run_lib.py:133] step: 953100, training_loss: 4.18341e-02
I0214 01:02:35.406860 22509476222784 run_lib.py:146] step: 953100, eval_loss: 4.36689e-02
I0214 01:02:54.151784 22509476222784 run_lib.py:133] step: 953150, training_loss: 3.80159e-02
I0214 01:03:12.989175 22509476222784 run_lib.py:133] step: 953200, training_loss: 4.13616e-02
I0214 01:03:13.157144 22509476222784 run_lib.py:146] step: 953200, eval_loss: 4.54832e-02
I0214 01:03:31.938072 22509476222784 run_lib.py:133] step: 953250, training_loss: 2.91876e-02
I0214 01:03:50.750985 22509476222784 run_lib.py:133] step: 953300, training_loss: 4.83497e-02
I0214 01:03:51.126706 22509476222784 run_lib.py:146] step: 953300, eval_loss: 4.06166e-02
I0214 01:04:09.840917 22509476222784 run_lib.py:133] step: 953350, training_loss: 4.38670e-02
I0214 01:04:28.509348 22509476222784 run_lib.py:133] step: 953400, training_loss: 4.48097e-02
I0214 01:04:28.674993 22509476222784 run_lib.py:146] step: 953400, eval_loss: 5.04727e-02
I0214 01:04:47.394726 22509476222784 run_lib.py:133] step: 953450, training_loss: 4.54108e-02
I0214 01:05:06.097274 22509476222784 run_lib.py:133] step: 953500, training_loss: 3.25682e-02
I0214 01:05:06.262111 22509476222784 run_lib.py:146] step: 953500, eval_loss: 4.35606e-02
I0214 01:05:25.202550 22509476222784 run_lib.py:133] step: 953550, training_loss: 3.54484e-02
I0214 01:05:44.003109 22509476222784 run_lib.py:133] step: 953600, training_loss: 4.33967e-02
I0214 01:05:44.167868 22509476222784 run_lib.py:146] step: 953600, eval_loss: 3.81907e-02
I0214 01:06:02.838949 22509476222784 run_lib.py:133] step: 953650, training_loss: 3.83744e-02
I0214 01:06:21.570586 22509476222784 run_lib.py:133] step: 953700, training_loss: 4.50891e-02
I0214 01:06:21.739062 22509476222784 run_lib.py:146] step: 953700, eval_loss: 5.28788e-02
I0214 01:06:40.589358 22509476222784 run_lib.py:133] step: 953750, training_loss: 4.60606e-02
I0214 01:06:59.452141 22509476222784 run_lib.py:133] step: 953800, training_loss: 4.51498e-02
I0214 01:06:59.617964 22509476222784 run_lib.py:146] step: 953800, eval_loss: 3.59650e-02
I0214 01:07:18.342549 22509476222784 run_lib.py:133] step: 953850, training_loss: 3.48309e-02
I0214 01:07:37.021512 22509476222784 run_lib.py:133] step: 953900, training_loss: 4.90316e-02
I0214 01:07:37.187515 22509476222784 run_lib.py:146] step: 953900, eval_loss: 4.04013e-02
I0214 01:07:56.028498 22509476222784 run_lib.py:133] step: 953950, training_loss: 3.95024e-02
I0214 01:08:14.695260 22509476222784 run_lib.py:133] step: 954000, training_loss: 4.00184e-02
I0214 01:08:14.856722 22509476222784 run_lib.py:146] step: 954000, eval_loss: 4.75570e-02
I0214 01:08:33.681546 22509476222784 run_lib.py:133] step: 954050, training_loss: 4.76904e-02
I0214 01:08:52.432273 22509476222784 run_lib.py:133] step: 954100, training_loss: 5.00014e-02
I0214 01:08:52.612094 22509476222784 run_lib.py:146] step: 954100, eval_loss: 5.06505e-02
I0214 01:09:11.540369 22509476222784 run_lib.py:133] step: 954150, training_loss: 3.45193e-02
I0214 01:09:30.248939 22509476222784 run_lib.py:133] step: 954200, training_loss: 3.37471e-02
I0214 01:09:30.421061 22509476222784 run_lib.py:146] step: 954200, eval_loss: 3.80920e-02
I0214 01:09:49.087248 22509476222784 run_lib.py:133] step: 954250, training_loss: 3.23723e-02
I0214 01:10:07.918622 22509476222784 run_lib.py:133] step: 954300, training_loss: 4.03792e-02
I0214 01:10:08.090874 22509476222784 run_lib.py:146] step: 954300, eval_loss: 4.13647e-02
I0214 01:10:26.745703 22509476222784 run_lib.py:133] step: 954350, training_loss: 4.25591e-02
I0214 01:10:45.628253 22509476222784 run_lib.py:133] step: 954400, training_loss: 4.73274e-02
I0214 01:10:45.794068 22509476222784 run_lib.py:146] step: 954400, eval_loss: 4.12537e-02
I0214 01:11:04.524494 22509476222784 run_lib.py:133] step: 954450, training_loss: 5.08715e-02
I0214 01:11:23.146598 22509476222784 run_lib.py:133] step: 954500, training_loss: 3.14165e-02
I0214 01:11:23.309865 22509476222784 run_lib.py:146] step: 954500, eval_loss: 4.06788e-02
I0214 01:11:42.250551 22509476222784 run_lib.py:133] step: 954550, training_loss: 4.58148e-02
I0214 01:12:00.944243 22509476222784 run_lib.py:133] step: 954600, training_loss: 3.69425e-02
I0214 01:12:01.110917 22509476222784 run_lib.py:146] step: 954600, eval_loss: 4.50389e-02
I0214 01:12:19.899212 22509476222784 run_lib.py:133] step: 954650, training_loss: 4.13202e-02
I0214 01:12:38.619321 22509476222784 run_lib.py:133] step: 954700, training_loss: 3.95840e-02
I0214 01:12:38.794837 22509476222784 run_lib.py:146] step: 954700, eval_loss: 3.13867e-02
I0214 01:12:57.719989 22509476222784 run_lib.py:133] step: 954750, training_loss: 4.40646e-02
I0214 01:13:16.408669 22509476222784 run_lib.py:133] step: 954800, training_loss: 4.56038e-02
I0214 01:13:16.633839 22509476222784 run_lib.py:146] step: 954800, eval_loss: 5.46414e-02
I0214 01:13:35.422309 22509476222784 run_lib.py:133] step: 954850, training_loss: 3.96199e-02
I0214 01:13:54.067448 22509476222784 run_lib.py:133] step: 954900, training_loss: 3.88107e-02
I0214 01:13:54.232845 22509476222784 run_lib.py:146] step: 954900, eval_loss: 4.34850e-02
I0214 01:14:12.910011 22509476222784 run_lib.py:133] step: 954950, training_loss: 4.43370e-02
I0214 01:14:31.626592 22509476222784 run_lib.py:133] step: 955000, training_loss: 5.11239e-02
I0214 01:14:31.793397 22509476222784 run_lib.py:146] step: 955000, eval_loss: 4.68371e-02
I0214 01:14:50.742351 22509476222784 run_lib.py:133] step: 955050, training_loss: 4.70316e-02
I0214 01:15:09.534860 22509476222784 run_lib.py:133] step: 955100, training_loss: 5.36118e-02
I0214 01:15:09.705211 22509476222784 run_lib.py:146] step: 955100, eval_loss: 4.68963e-02
I0214 01:15:28.441456 22509476222784 run_lib.py:133] step: 955150, training_loss: 4.43221e-02
I0214 01:15:47.215269 22509476222784 run_lib.py:133] step: 955200, training_loss: 3.67870e-02
I0214 01:15:47.388014 22509476222784 run_lib.py:146] step: 955200, eval_loss: 5.52965e-02
I0214 01:16:06.378438 22509476222784 run_lib.py:133] step: 955250, training_loss: 4.82057e-02
I0214 01:16:25.138803 22509476222784 run_lib.py:133] step: 955300, training_loss: 3.55708e-02
I0214 01:16:25.305139 22509476222784 run_lib.py:146] step: 955300, eval_loss: 4.21326e-02
I0214 01:16:44.230511 22509476222784 run_lib.py:133] step: 955350, training_loss: 3.76476e-02
I0214 01:17:02.926742 22509476222784 run_lib.py:133] step: 955400, training_loss: 3.22876e-02
I0214 01:17:03.089829 22509476222784 run_lib.py:146] step: 955400, eval_loss: 3.47035e-02
I0214 01:17:21.986772 22509476222784 run_lib.py:133] step: 955450, training_loss: 4.49373e-02
I0214 01:17:40.752192 22509476222784 run_lib.py:133] step: 955500, training_loss: 5.43613e-02
I0214 01:17:40.924263 22509476222784 run_lib.py:146] step: 955500, eval_loss: 4.73433e-02
I0214 01:17:59.851097 22509476222784 run_lib.py:133] step: 955550, training_loss: 4.94847e-02
I0214 01:18:18.641254 22509476222784 run_lib.py:133] step: 955600, training_loss: 3.71359e-02
I0214 01:18:18.820026 22509476222784 run_lib.py:146] step: 955600, eval_loss: 4.41898e-02
I0214 01:18:37.518500 22509476222784 run_lib.py:133] step: 955650, training_loss: 4.76841e-02
I0214 01:18:56.352586 22509476222784 run_lib.py:133] step: 955700, training_loss: 4.26354e-02
I0214 01:18:56.529726 22509476222784 run_lib.py:146] step: 955700, eval_loss: 4.42039e-02
I0214 01:19:15.282737 22509476222784 run_lib.py:133] step: 955750, training_loss: 3.86834e-02
I0214 01:19:34.048470 22509476222784 run_lib.py:133] step: 955800, training_loss: 4.82370e-02
I0214 01:19:34.217098 22509476222784 run_lib.py:146] step: 955800, eval_loss: 3.16318e-02
I0214 01:19:53.189759 22509476222784 run_lib.py:133] step: 955850, training_loss: 4.06018e-02
I0214 01:20:12.070022 22509476222784 run_lib.py:133] step: 955900, training_loss: 5.27123e-02
I0214 01:20:12.231884 22509476222784 run_lib.py:146] step: 955900, eval_loss: 4.65955e-02
I0214 01:20:30.966308 22509476222784 run_lib.py:133] step: 955950, training_loss: 4.59585e-02
I0214 01:20:49.753333 22509476222784 run_lib.py:133] step: 956000, training_loss: 4.50017e-02
I0214 01:20:49.940468 22509476222784 run_lib.py:146] step: 956000, eval_loss: 4.79182e-02
I0214 01:21:08.637818 22509476222784 run_lib.py:133] step: 956050, training_loss: 3.93198e-02
I0214 01:21:27.523140 22509476222784 run_lib.py:133] step: 956100, training_loss: 2.93860e-02
I0214 01:21:27.691000 22509476222784 run_lib.py:146] step: 956100, eval_loss: 4.61803e-02
I0214 01:21:46.377250 22509476222784 run_lib.py:133] step: 956150, training_loss: 3.70354e-02
I0214 01:22:05.082448 22509476222784 run_lib.py:133] step: 956200, training_loss: 4.62342e-02
I0214 01:22:05.263821 22509476222784 run_lib.py:146] step: 956200, eval_loss: 4.66664e-02
I0214 01:22:24.014087 22509476222784 run_lib.py:133] step: 956250, training_loss: 5.42570e-02
I0214 01:22:42.924228 22509476222784 run_lib.py:133] step: 956300, training_loss: 3.11411e-02
I0214 01:22:43.090049 22509476222784 run_lib.py:146] step: 956300, eval_loss: 3.85912e-02
I0214 01:23:01.815522 22509476222784 run_lib.py:133] step: 956350, training_loss: 4.16222e-02
I0214 01:23:20.549726 22509476222784 run_lib.py:133] step: 956400, training_loss: 4.91156e-02
I0214 01:23:20.711916 22509476222784 run_lib.py:146] step: 956400, eval_loss: 4.68844e-02
I0214 01:23:39.394005 22509476222784 run_lib.py:133] step: 956450, training_loss: 3.67660e-02
I0214 01:23:58.079314 22509476222784 run_lib.py:133] step: 956500, training_loss: 4.08735e-02
I0214 01:23:58.256948 22509476222784 run_lib.py:146] step: 956500, eval_loss: 3.84979e-02
I0214 01:24:17.158498 22509476222784 run_lib.py:133] step: 956550, training_loss: 3.87352e-02
I0214 01:24:35.979746 22509476222784 run_lib.py:133] step: 956600, training_loss: 4.39414e-02
I0214 01:24:36.148711 22509476222784 run_lib.py:146] step: 956600, eval_loss: 3.84362e-02
I0214 01:24:54.809496 22509476222784 run_lib.py:133] step: 956650, training_loss: 4.64964e-02
I0214 01:25:13.497167 22509476222784 run_lib.py:133] step: 956700, training_loss: 3.90309e-02
I0214 01:25:13.667829 22509476222784 run_lib.py:146] step: 956700, eval_loss: 4.15947e-02
I0214 01:25:32.527115 22509476222784 run_lib.py:133] step: 956750, training_loss: 4.50112e-02
I0214 01:25:51.337444 22509476222784 run_lib.py:133] step: 956800, training_loss: 4.60298e-02
I0214 01:25:51.504030 22509476222784 run_lib.py:146] step: 956800, eval_loss: 4.11978e-02
I0214 01:26:10.456404 22509476222784 run_lib.py:133] step: 956850, training_loss: 3.64027e-02
I0214 01:26:29.190312 22509476222784 run_lib.py:133] step: 956900, training_loss: 5.02141e-02
I0214 01:26:29.354729 22509476222784 run_lib.py:146] step: 956900, eval_loss: 3.51816e-02
I0214 01:26:48.270873 22509476222784 run_lib.py:133] step: 956950, training_loss: 3.84907e-02
I0214 01:27:07.033643 22509476222784 run_lib.py:133] step: 957000, training_loss: 4.92367e-02
I0214 01:27:07.216927 22509476222784 run_lib.py:146] step: 957000, eval_loss: 2.96015e-02
I0214 01:27:26.012493 22509476222784 run_lib.py:133] step: 957050, training_loss: 5.05956e-02
I0214 01:27:44.981871 22509476222784 run_lib.py:133] step: 957100, training_loss: 5.29251e-02
I0214 01:27:45.148811 22509476222784 run_lib.py:146] step: 957100, eval_loss: 4.04887e-02
I0214 01:28:03.892532 22509476222784 run_lib.py:133] step: 957150, training_loss: 4.67452e-02
I0214 01:28:22.811572 22509476222784 run_lib.py:133] step: 957200, training_loss: 3.42718e-02
I0214 01:28:22.979794 22509476222784 run_lib.py:146] step: 957200, eval_loss: 4.12784e-02
I0214 01:28:41.762066 22509476222784 run_lib.py:133] step: 957250, training_loss: 3.93244e-02
I0214 01:29:00.543276 22509476222784 run_lib.py:133] step: 957300, training_loss: 4.01017e-02
I0214 01:29:00.706720 22509476222784 run_lib.py:146] step: 957300, eval_loss: 3.31218e-02
I0214 01:29:19.707547 22509476222784 run_lib.py:133] step: 957350, training_loss: 3.38303e-02
I0214 01:29:38.482619 22509476222784 run_lib.py:133] step: 957400, training_loss: 3.47414e-02
I0214 01:29:38.657030 22509476222784 run_lib.py:146] step: 957400, eval_loss: 4.47296e-02
I0214 01:29:57.361905 22509476222784 run_lib.py:133] step: 957450, training_loss: 3.86701e-02
I0214 01:30:16.269111 22509476222784 run_lib.py:133] step: 957500, training_loss: 4.10651e-02
I0214 01:30:16.450112 22509476222784 run_lib.py:146] step: 957500, eval_loss: 3.64120e-02
I0214 01:30:35.203667 22509476222784 run_lib.py:133] step: 957550, training_loss: 4.46421e-02
I0214 01:30:53.986169 22509476222784 run_lib.py:133] step: 957600, training_loss: 3.03995e-02
I0214 01:30:54.153138 22509476222784 run_lib.py:146] step: 957600, eval_loss: 4.48196e-02
I0214 01:31:13.008516 22509476222784 run_lib.py:133] step: 957650, training_loss: 4.20568e-02
I0214 01:31:31.726334 22509476222784 run_lib.py:133] step: 957700, training_loss: 5.59040e-02
I0214 01:31:31.892794 22509476222784 run_lib.py:146] step: 957700, eval_loss: 2.87666e-02
I0214 01:31:50.663068 22509476222784 run_lib.py:133] step: 957750, training_loss: 4.94904e-02
I0214 01:32:09.477035 22509476222784 run_lib.py:133] step: 957800, training_loss: 3.68664e-02
I0214 01:32:09.641803 22509476222784 run_lib.py:146] step: 957800, eval_loss: 4.46958e-02
I0214 01:32:28.617096 22509476222784 run_lib.py:133] step: 957850, training_loss: 3.72219e-02
I0214 01:32:47.482708 22509476222784 run_lib.py:133] step: 957900, training_loss: 3.91131e-02
I0214 01:32:47.649781 22509476222784 run_lib.py:146] step: 957900, eval_loss: 4.11111e-02
I0214 01:33:06.329045 22509476222784 run_lib.py:133] step: 957950, training_loss: 5.43631e-02
I0214 01:33:25.101405 22509476222784 run_lib.py:133] step: 958000, training_loss: 4.38595e-02
I0214 01:33:25.269216 22509476222784 run_lib.py:146] step: 958000, eval_loss: 3.47721e-02
I0214 01:33:44.181804 22509476222784 run_lib.py:133] step: 958050, training_loss: 3.70559e-02
I0214 01:34:03.081380 22509476222784 run_lib.py:133] step: 958100, training_loss: 3.97316e-02
I0214 01:34:03.257022 22509476222784 run_lib.py:146] step: 958100, eval_loss: 4.10579e-02
I0214 01:34:22.233299 22509476222784 run_lib.py:133] step: 958150, training_loss: 3.09976e-02
I0214 01:34:40.965902 22509476222784 run_lib.py:133] step: 958200, training_loss: 3.85410e-02
I0214 01:34:41.132039 22509476222784 run_lib.py:146] step: 958200, eval_loss: 3.33967e-02
I0214 01:34:59.993072 22509476222784 run_lib.py:133] step: 958250, training_loss: 4.23410e-02
I0214 01:35:18.725468 22509476222784 run_lib.py:133] step: 958300, training_loss: 4.05567e-02
I0214 01:35:18.891194 22509476222784 run_lib.py:146] step: 958300, eval_loss: 4.26519e-02
I0214 01:35:37.887394 22509476222784 run_lib.py:133] step: 958350, training_loss: 4.81114e-02
I0214 01:35:56.603885 22509476222784 run_lib.py:133] step: 958400, training_loss: 3.62114e-02
I0214 01:35:56.768887 22509476222784 run_lib.py:146] step: 958400, eval_loss: 5.45234e-02
I0214 01:36:15.507421 22509476222784 run_lib.py:133] step: 958450, training_loss: 3.80272e-02
I0214 01:36:34.388919 22509476222784 run_lib.py:133] step: 958500, training_loss: 3.38519e-02
I0214 01:36:34.560277 22509476222784 run_lib.py:146] step: 958500, eval_loss: 4.44490e-02
I0214 01:36:53.288495 22509476222784 run_lib.py:133] step: 958550, training_loss: 4.07111e-02
I0214 01:37:12.130038 22509476222784 run_lib.py:133] step: 958600, training_loss: 3.87578e-02
I0214 01:37:12.301313 22509476222784 run_lib.py:146] step: 958600, eval_loss: 4.00456e-02
I0214 01:37:31.254252 22509476222784 run_lib.py:133] step: 958650, training_loss: 4.49525e-02
I0214 01:37:49.986372 22509476222784 run_lib.py:133] step: 958700, training_loss: 4.01667e-02
I0214 01:37:50.156961 22509476222784 run_lib.py:146] step: 958700, eval_loss: 3.35742e-02
I0214 01:38:09.048202 22509476222784 run_lib.py:133] step: 958750, training_loss: 4.11593e-02
I0214 01:38:27.775732 22509476222784 run_lib.py:133] step: 958800, training_loss: 3.89728e-02
I0214 01:38:27.948058 22509476222784 run_lib.py:146] step: 958800, eval_loss: 4.13881e-02
I0214 01:38:46.792038 22509476222784 run_lib.py:133] step: 958850, training_loss: 3.31558e-02
I0214 01:39:05.670797 22509476222784 run_lib.py:133] step: 958900, training_loss: 4.50177e-02
I0214 01:39:05.840904 22509476222784 run_lib.py:146] step: 958900, eval_loss: 5.13476e-02
I0214 01:39:24.632999 22509476222784 run_lib.py:133] step: 958950, training_loss: 2.98332e-02
I0214 01:39:43.379720 22509476222784 run_lib.py:133] step: 959000, training_loss: 3.49565e-02
I0214 01:39:43.545157 22509476222784 run_lib.py:146] step: 959000, eval_loss: 4.06882e-02
I0214 01:40:02.262243 22509476222784 run_lib.py:133] step: 959050, training_loss: 4.65977e-02
I0214 01:40:21.190226 22509476222784 run_lib.py:133] step: 959100, training_loss: 2.65680e-02
I0214 01:40:21.365738 22509476222784 run_lib.py:146] step: 959100, eval_loss: 4.73935e-02
I0214 01:40:40.115078 22509476222784 run_lib.py:133] step: 959150, training_loss: 4.05168e-02
I0214 01:40:58.862708 22509476222784 run_lib.py:133] step: 959200, training_loss: 3.62025e-02
I0214 01:40:59.037867 22509476222784 run_lib.py:146] step: 959200, eval_loss: 4.38109e-02
I0214 01:41:17.675413 22509476222784 run_lib.py:133] step: 959250, training_loss: 5.57698e-02
I0214 01:41:36.335514 22509476222784 run_lib.py:133] step: 959300, training_loss: 5.66108e-02
I0214 01:41:36.500971 22509476222784 run_lib.py:146] step: 959300, eval_loss: 3.96033e-02
I0214 01:41:55.469848 22509476222784 run_lib.py:133] step: 959350, training_loss: 4.47910e-02
I0214 01:42:14.368739 22509476222784 run_lib.py:133] step: 959400, training_loss: 5.29315e-02
I0214 01:42:14.536705 22509476222784 run_lib.py:146] step: 959400, eval_loss: 4.19210e-02
I0214 01:42:33.269428 22509476222784 run_lib.py:133] step: 959450, training_loss: 4.56889e-02
I0214 01:42:51.978162 22509476222784 run_lib.py:133] step: 959500, training_loss: 4.22463e-02
I0214 01:42:52.143973 22509476222784 run_lib.py:146] step: 959500, eval_loss: 4.35749e-02
I0214 01:43:11.035272 22509476222784 run_lib.py:133] step: 959550, training_loss: 4.53176e-02
I0214 01:43:29.798887 22509476222784 run_lib.py:133] step: 959600, training_loss: 5.77644e-02
I0214 01:43:29.966120 22509476222784 run_lib.py:146] step: 959600, eval_loss: 4.33906e-02
I0214 01:43:48.958884 22509476222784 run_lib.py:133] step: 959650, training_loss: 3.69361e-02
I0214 01:44:07.711505 22509476222784 run_lib.py:133] step: 959700, training_loss: 4.30360e-02
I0214 01:44:07.874034 22509476222784 run_lib.py:146] step: 959700, eval_loss: 4.34495e-02
I0214 01:44:26.834731 22509476222784 run_lib.py:133] step: 959750, training_loss: 3.23803e-02
I0214 01:44:45.616609 22509476222784 run_lib.py:133] step: 959800, training_loss: 4.46833e-02
I0214 01:44:45.778560 22509476222784 run_lib.py:146] step: 959800, eval_loss: 5.30748e-02
I0214 01:45:04.550270 22509476222784 run_lib.py:133] step: 959850, training_loss: 4.28643e-02
I0214 01:45:23.489508 22509476222784 run_lib.py:133] step: 959900, training_loss: 4.44665e-02
I0214 01:45:23.672007 22509476222784 run_lib.py:146] step: 959900, eval_loss: 3.90186e-02
I0214 01:45:42.479594 22509476222784 run_lib.py:133] step: 959950, training_loss: 4.01311e-02
I0214 01:46:01.451176 22509476222784 run_lib.py:133] step: 960000, training_loss: 4.25588e-02
I0214 01:46:02.291162 22509476222784 run_lib.py:146] step: 960000, eval_loss: 5.27866e-02
I0214 01:46:23.804826 22509476222784 run_lib.py:133] step: 960050, training_loss: 4.71257e-02
I0214 01:46:42.528082 22509476222784 run_lib.py:133] step: 960100, training_loss: 2.82290e-02
I0214 01:46:42.694035 22509476222784 run_lib.py:146] step: 960100, eval_loss: 4.75152e-02
I0214 01:47:01.408837 22509476222784 run_lib.py:133] step: 960150, training_loss: 4.14513e-02
I0214 01:47:20.216070 22509476222784 run_lib.py:133] step: 960200, training_loss: 4.65454e-02
I0214 01:47:20.380764 22509476222784 run_lib.py:146] step: 960200, eval_loss: 4.03067e-02
I0214 01:47:39.354650 22509476222784 run_lib.py:133] step: 960250, training_loss: 4.01065e-02
I0214 01:47:58.189445 22509476222784 run_lib.py:133] step: 960300, training_loss: 4.44498e-02
I0214 01:47:58.354068 22509476222784 run_lib.py:146] step: 960300, eval_loss: 4.41465e-02
I0214 01:48:17.037649 22509476222784 run_lib.py:133] step: 960350, training_loss: 5.45549e-02
I0214 01:48:35.789160 22509476222784 run_lib.py:133] step: 960400, training_loss: 4.86541e-02
I0214 01:48:35.970901 22509476222784 run_lib.py:146] step: 960400, eval_loss: 3.81760e-02
I0214 01:48:54.919957 22509476222784 run_lib.py:133] step: 960450, training_loss: 3.68700e-02
I0214 01:49:13.690544 22509476222784 run_lib.py:133] step: 960500, training_loss: 3.65224e-02
I0214 01:49:13.856215 22509476222784 run_lib.py:146] step: 960500, eval_loss: 5.14515e-02
I0214 01:49:32.794621 22509476222784 run_lib.py:133] step: 960550, training_loss: 5.09061e-02
I0214 01:49:51.534769 22509476222784 run_lib.py:133] step: 960600, training_loss: 4.45357e-02
I0214 01:49:51.707223 22509476222784 run_lib.py:146] step: 960600, eval_loss: 3.82429e-02
I0214 01:50:10.591200 22509476222784 run_lib.py:133] step: 960650, training_loss: 4.18862e-02
I0214 01:50:29.353506 22509476222784 run_lib.py:133] step: 960700, training_loss: 5.27906e-02
I0214 01:50:29.529595 22509476222784 run_lib.py:146] step: 960700, eval_loss: 4.91693e-02
I0214 01:50:48.524899 22509476222784 run_lib.py:133] step: 960750, training_loss: 3.50821e-02
I0214 01:51:07.271642 22509476222784 run_lib.py:133] step: 960800, training_loss: 3.58748e-02
I0214 01:51:07.437212 22509476222784 run_lib.py:146] step: 960800, eval_loss: 5.85853e-02
I0214 01:51:26.190264 22509476222784 run_lib.py:133] step: 960850, training_loss: 4.69003e-02
I0214 01:51:45.117263 22509476222784 run_lib.py:133] step: 960900, training_loss: 3.73483e-02
I0214 01:51:45.285395 22509476222784 run_lib.py:146] step: 960900, eval_loss: 3.42705e-02
I0214 01:52:04.053125 22509476222784 run_lib.py:133] step: 960950, training_loss: 4.95190e-02
I0214 01:52:22.860110 22509476222784 run_lib.py:133] step: 961000, training_loss: 4.95591e-02
I0214 01:52:23.039119 22509476222784 run_lib.py:146] step: 961000, eval_loss: 4.85457e-02
I0214 01:52:41.979888 22509476222784 run_lib.py:133] step: 961050, training_loss: 3.96760e-02
I0214 01:53:00.963407 22509476222784 run_lib.py:133] step: 961100, training_loss: 4.98271e-02
I0214 01:53:01.130171 22509476222784 run_lib.py:146] step: 961100, eval_loss: 4.44806e-02
I0214 01:53:19.876345 22509476222784 run_lib.py:133] step: 961150, training_loss: 4.26931e-02
I0214 01:53:38.574290 22509476222784 run_lib.py:133] step: 961200, training_loss: 3.34544e-02
I0214 01:53:38.736938 22509476222784 run_lib.py:146] step: 961200, eval_loss: 3.53495e-02
I0214 01:53:57.524289 22509476222784 run_lib.py:133] step: 961250, training_loss: 3.58479e-02
I0214 01:54:16.457725 22509476222784 run_lib.py:133] step: 961300, training_loss: 4.17659e-02
I0214 01:54:16.635169 22509476222784 run_lib.py:146] step: 961300, eval_loss: 4.77980e-02
I0214 01:54:35.358506 22509476222784 run_lib.py:133] step: 961350, training_loss: 2.95847e-02
I0214 01:54:54.106847 22509476222784 run_lib.py:133] step: 961400, training_loss: 5.12602e-02
I0214 01:54:54.273999 22509476222784 run_lib.py:146] step: 961400, eval_loss: 3.84482e-02
I0214 01:55:12.980555 22509476222784 run_lib.py:133] step: 961450, training_loss: 4.02627e-02
I0214 01:55:31.906700 22509476222784 run_lib.py:133] step: 961500, training_loss: 4.46243e-02
I0214 01:55:32.071983 22509476222784 run_lib.py:146] step: 961500, eval_loss: 3.92948e-02
I0214 01:55:50.829668 22509476222784 run_lib.py:133] step: 961550, training_loss: 3.45311e-02
I0214 01:56:09.741178 22509476222784 run_lib.py:133] step: 961600, training_loss: 4.58511e-02
I0214 01:56:09.905774 22509476222784 run_lib.py:146] step: 961600, eval_loss: 3.88728e-02
I0214 01:56:28.664088 22509476222784 run_lib.py:133] step: 961650, training_loss: 5.83724e-02
I0214 01:56:47.436119 22509476222784 run_lib.py:133] step: 961700, training_loss: 4.11269e-02
I0214 01:56:47.599310 22509476222784 run_lib.py:146] step: 961700, eval_loss: 3.93846e-02
I0214 01:57:06.464982 22509476222784 run_lib.py:133] step: 961750, training_loss: 4.47708e-02
I0214 01:57:25.261349 22509476222784 run_lib.py:133] step: 961800, training_loss: 3.89672e-02
I0214 01:57:25.439012 22509476222784 run_lib.py:146] step: 961800, eval_loss: 3.73292e-02
I0214 01:57:44.217880 22509476222784 run_lib.py:133] step: 961850, training_loss: 4.20408e-02
I0214 01:58:03.006011 22509476222784 run_lib.py:133] step: 961900, training_loss: 5.23662e-02
I0214 01:58:03.177105 22509476222784 run_lib.py:146] step: 961900, eval_loss: 5.26651e-02
I0214 01:58:22.122807 22509476222784 run_lib.py:133] step: 961950, training_loss: 4.86420e-02
I0214 01:58:40.867503 22509476222784 run_lib.py:133] step: 962000, training_loss: 4.07828e-02
I0214 01:58:41.041161 22509476222784 run_lib.py:146] step: 962000, eval_loss: 4.45405e-02
I0214 01:58:59.984477 22509476222784 run_lib.py:133] step: 962050, training_loss: 4.33856e-02
I0214 01:59:18.747176 22509476222784 run_lib.py:133] step: 962100, training_loss: 4.05980e-02
I0214 01:59:18.914182 22509476222784 run_lib.py:146] step: 962100, eval_loss: 4.04733e-02
I0214 01:59:37.825414 22509476222784 run_lib.py:133] step: 962150, training_loss: 4.07829e-02
I0214 01:59:56.536822 22509476222784 run_lib.py:133] step: 962200, training_loss: 4.19758e-02
I0214 01:59:56.700034 22509476222784 run_lib.py:146] step: 962200, eval_loss: 3.90215e-02
I0214 02:00:15.424346 22509476222784 run_lib.py:133] step: 962250, training_loss: 4.27064e-02
I0214 02:00:34.332396 22509476222784 run_lib.py:133] step: 962300, training_loss: 5.24831e-02
I0214 02:00:34.514949 22509476222784 run_lib.py:146] step: 962300, eval_loss: 4.89368e-02
I0214 02:00:53.222675 22509476222784 run_lib.py:133] step: 962350, training_loss: 5.09080e-02
I0214 02:01:12.189064 22509476222784 run_lib.py:133] step: 962400, training_loss: 3.43782e-02
I0214 02:01:12.358073 22509476222784 run_lib.py:146] step: 962400, eval_loss: 3.97376e-02
I0214 02:01:31.076967 22509476222784 run_lib.py:133] step: 962450, training_loss: 4.44968e-02
I0214 02:01:49.831969 22509476222784 run_lib.py:133] step: 962500, training_loss: 4.47514e-02
I0214 02:01:49.996750 22509476222784 run_lib.py:146] step: 962500, eval_loss: 4.29726e-02
I0214 02:02:08.857589 22509476222784 run_lib.py:133] step: 962550, training_loss: 3.94250e-02
I0214 02:02:27.773515 22509476222784 run_lib.py:133] step: 962600, training_loss: 4.74348e-02
I0214 02:02:27.939902 22509476222784 run_lib.py:146] step: 962600, eval_loss: 4.89038e-02
I0214 02:02:46.729856 22509476222784 run_lib.py:133] step: 962650, training_loss: 4.03066e-02
I0214 02:03:05.776396 22509476222784 run_lib.py:133] step: 962700, training_loss: 4.50053e-02
I0214 02:03:05.942076 22509476222784 run_lib.py:146] step: 962700, eval_loss: 4.87381e-02
I0214 02:03:24.691756 22509476222784 run_lib.py:133] step: 962750, training_loss: 4.83592e-02
I0214 02:03:43.516495 22509476222784 run_lib.py:133] step: 962800, training_loss: 3.11603e-02
I0214 02:03:43.695125 22509476222784 run_lib.py:146] step: 962800, eval_loss: 3.94737e-02
I0214 02:04:02.571431 22509476222784 run_lib.py:133] step: 962850, training_loss: 4.72090e-02
I0214 02:04:21.419418 22509476222784 run_lib.py:133] step: 962900, training_loss: 4.73428e-02
I0214 02:04:21.589345 22509476222784 run_lib.py:146] step: 962900, eval_loss: 4.76898e-02
I0214 02:04:40.383948 22509476222784 run_lib.py:133] step: 962950, training_loss: 5.50551e-02
I0214 02:04:59.122678 22509476222784 run_lib.py:133] step: 963000, training_loss: 2.96876e-02
I0214 02:04:59.294926 22509476222784 run_lib.py:146] step: 963000, eval_loss: 3.89337e-02
I0214 02:05:18.352308 22509476222784 run_lib.py:133] step: 963050, training_loss: 4.02237e-02
I0214 02:05:37.210487 22509476222784 run_lib.py:133] step: 963100, training_loss: 3.66476e-02
I0214 02:05:37.379102 22509476222784 run_lib.py:146] step: 963100, eval_loss: 4.29635e-02
I0214 02:05:56.319488 22509476222784 run_lib.py:133] step: 963150, training_loss: 4.46890e-02
I0214 02:06:15.089918 22509476222784 run_lib.py:133] step: 963200, training_loss: 4.29382e-02
I0214 02:06:15.256925 22509476222784 run_lib.py:146] step: 963200, eval_loss: 4.44598e-02
I0214 02:06:34.280190 22509476222784 run_lib.py:133] step: 963250, training_loss: 4.48393e-02
I0214 02:06:53.033257 22509476222784 run_lib.py:133] step: 963300, training_loss: 4.63763e-02
I0214 02:06:53.213169 22509476222784 run_lib.py:146] step: 963300, eval_loss: 4.73128e-02
I0214 02:07:12.173811 22509476222784 run_lib.py:133] step: 963350, training_loss: 2.97112e-02
I0214 02:07:31.068017 22509476222784 run_lib.py:133] step: 963400, training_loss: 4.10583e-02
I0214 02:07:31.235157 22509476222784 run_lib.py:146] step: 963400, eval_loss: 5.71716e-02
I0214 02:07:50.141436 22509476222784 run_lib.py:133] step: 963450, training_loss: 4.68200e-02
I0214 02:08:08.942973 22509476222784 run_lib.py:133] step: 963500, training_loss: 2.89006e-02
I0214 02:08:09.111219 22509476222784 run_lib.py:146] step: 963500, eval_loss: 3.37104e-02
I0214 02:08:27.968553 22509476222784 run_lib.py:133] step: 963550, training_loss: 4.00111e-02
I0214 02:08:46.764256 22509476222784 run_lib.py:133] step: 963600, training_loss: 4.03721e-02
I0214 02:08:46.928234 22509476222784 run_lib.py:146] step: 963600, eval_loss: 2.85558e-02
I0214 02:09:05.780761 22509476222784 run_lib.py:133] step: 963650, training_loss: 3.67789e-02
I0214 02:09:24.755334 22509476222784 run_lib.py:133] step: 963700, training_loss: 4.08055e-02
I0214 02:09:24.927135 22509476222784 run_lib.py:146] step: 963700, eval_loss: 4.29937e-02
I0214 02:09:43.772106 22509476222784 run_lib.py:133] step: 963750, training_loss: 3.09533e-02
I0214 02:10:02.505516 22509476222784 run_lib.py:133] step: 963800, training_loss: 4.08311e-02
I0214 02:10:02.676196 22509476222784 run_lib.py:146] step: 963800, eval_loss: 3.65375e-02
I0214 02:10:21.756971 22509476222784 run_lib.py:133] step: 963850, training_loss: 4.09591e-02
I0214 02:10:40.590105 22509476222784 run_lib.py:133] step: 963900, training_loss: 4.80352e-02
I0214 02:10:40.756821 22509476222784 run_lib.py:146] step: 963900, eval_loss: 3.25135e-02
I0214 02:10:59.837247 22509476222784 run_lib.py:133] step: 963950, training_loss: 4.97853e-02
I0214 02:11:18.597954 22509476222784 run_lib.py:133] step: 964000, training_loss: 3.71193e-02
I0214 02:11:18.764071 22509476222784 run_lib.py:146] step: 964000, eval_loss: 5.23249e-02
I0214 02:11:37.630172 22509476222784 run_lib.py:133] step: 964050, training_loss: 4.44764e-02
I0214 02:11:56.514812 22509476222784 run_lib.py:133] step: 964100, training_loss: 3.11459e-02
I0214 02:11:56.680220 22509476222784 run_lib.py:146] step: 964100, eval_loss: 3.86842e-02
I0214 02:12:15.568021 22509476222784 run_lib.py:133] step: 964150, training_loss: 4.27608e-02
I0214 02:12:34.367130 22509476222784 run_lib.py:133] step: 964200, training_loss: 5.00724e-02
I0214 02:12:34.535956 22509476222784 run_lib.py:146] step: 964200, eval_loss: 3.96056e-02
I0214 02:12:53.326032 22509476222784 run_lib.py:133] step: 964250, training_loss: 3.80851e-02
I0214 02:13:12.440023 22509476222784 run_lib.py:133] step: 964300, training_loss: 4.64328e-02
I0214 02:13:12.605962 22509476222784 run_lib.py:146] step: 964300, eval_loss: 4.61821e-02
I0214 02:13:31.348771 22509476222784 run_lib.py:133] step: 964350, training_loss: 5.01023e-02
I0214 02:13:50.346722 22509476222784 run_lib.py:133] step: 964400, training_loss: 3.85910e-02
I0214 02:13:50.512871 22509476222784 run_lib.py:146] step: 964400, eval_loss: 4.67618e-02
I0214 02:14:09.297355 22509476222784 run_lib.py:133] step: 964450, training_loss: 3.99026e-02
I0214 02:14:28.121741 22509476222784 run_lib.py:133] step: 964500, training_loss: 4.89814e-02
I0214 02:14:28.292204 22509476222784 run_lib.py:146] step: 964500, eval_loss: 3.92988e-02
I0214 02:14:47.205514 22509476222784 run_lib.py:133] step: 964550, training_loss: 3.46163e-02
I0214 02:15:06.134849 22509476222784 run_lib.py:133] step: 964600, training_loss: 5.20566e-02
I0214 02:15:06.301178 22509476222784 run_lib.py:146] step: 964600, eval_loss: 5.01000e-02
I0214 02:15:25.130964 22509476222784 run_lib.py:133] step: 964650, training_loss: 3.72164e-02
I0214 02:15:43.900076 22509476222784 run_lib.py:133] step: 964700, training_loss: 4.27651e-02
I0214 02:15:44.073095 22509476222784 run_lib.py:146] step: 964700, eval_loss: 3.86150e-02
I0214 02:16:03.042681 22509476222784 run_lib.py:133] step: 964750, training_loss: 4.29332e-02
I0214 02:16:21.784067 22509476222784 run_lib.py:133] step: 964800, training_loss: 4.59542e-02
I0214 02:16:21.950593 22509476222784 run_lib.py:146] step: 964800, eval_loss: 4.24908e-02
I0214 02:16:40.935011 22509476222784 run_lib.py:133] step: 964850, training_loss: 3.96066e-02
I0214 02:16:59.704971 22509476222784 run_lib.py:133] step: 964900, training_loss: 4.62860e-02
I0214 02:16:59.871233 22509476222784 run_lib.py:146] step: 964900, eval_loss: 3.40702e-02
I0214 02:17:18.976906 22509476222784 run_lib.py:133] step: 964950, training_loss: 2.94386e-02
I0214 02:17:37.721147 22509476222784 run_lib.py:133] step: 965000, training_loss: 4.14364e-02
I0214 02:17:37.883980 22509476222784 run_lib.py:146] step: 965000, eval_loss: 5.11041e-02
I0214 02:17:56.692254 22509476222784 run_lib.py:133] step: 965050, training_loss: 4.03305e-02
I0214 02:18:15.576745 22509476222784 run_lib.py:133] step: 965100, training_loss: 4.46804e-02
I0214 02:18:15.758225 22509476222784 run_lib.py:146] step: 965100, eval_loss: 4.62538e-02
I0214 02:18:34.580090 22509476222784 run_lib.py:133] step: 965150, training_loss: 3.84747e-02
I0214 02:18:53.615343 22509476222784 run_lib.py:133] step: 965200, training_loss: 3.97275e-02
I0214 02:18:53.791005 22509476222784 run_lib.py:146] step: 965200, eval_loss: 4.44524e-02
I0214 02:19:12.565443 22509476222784 run_lib.py:133] step: 965250, training_loss: 3.78525e-02
I0214 02:19:31.383323 22509476222784 run_lib.py:133] step: 965300, training_loss: 4.58741e-02
I0214 02:19:31.548863 22509476222784 run_lib.py:146] step: 965300, eval_loss: 4.25588e-02
I0214 02:19:50.389982 22509476222784 run_lib.py:133] step: 965350, training_loss: 3.67103e-02
I0214 02:20:09.286309 22509476222784 run_lib.py:133] step: 965400, training_loss: 4.27927e-02
I0214 02:20:09.454260 22509476222784 run_lib.py:146] step: 965400, eval_loss: 3.72254e-02
I0214 02:20:28.240621 22509476222784 run_lib.py:133] step: 965450, training_loss: 3.67766e-02
I0214 02:20:47.317322 22509476222784 run_lib.py:133] step: 965500, training_loss: 3.45013e-02
I0214 02:20:47.487345 22509476222784 run_lib.py:146] step: 965500, eval_loss: 4.57357e-02
I0214 02:21:06.228474 22509476222784 run_lib.py:133] step: 965550, training_loss: 3.92922e-02
I0214 02:21:25.106307 22509476222784 run_lib.py:133] step: 965600, training_loss: 3.73615e-02
I0214 02:21:25.430306 22509476222784 run_lib.py:146] step: 965600, eval_loss: 4.48517e-02
I0214 02:21:44.112192 22509476222784 run_lib.py:133] step: 965650, training_loss: 5.87583e-02
I0214 02:22:03.012592 22509476222784 run_lib.py:133] step: 965700, training_loss: 3.88497e-02
I0214 02:22:03.188840 22509476222784 run_lib.py:146] step: 965700, eval_loss: 5.46367e-02
I0214 02:22:21.974176 22509476222784 run_lib.py:133] step: 965750, training_loss: 3.96935e-02
I0214 02:22:40.801819 22509476222784 run_lib.py:133] step: 965800, training_loss: 4.50410e-02
I0214 02:22:40.973962 22509476222784 run_lib.py:146] step: 965800, eval_loss: 4.54486e-02
I0214 02:23:00.026507 22509476222784 run_lib.py:133] step: 965850, training_loss: 4.24407e-02
I0214 02:23:18.843893 22509476222784 run_lib.py:133] step: 965900, training_loss: 3.05360e-02
I0214 02:23:19.008243 22509476222784 run_lib.py:146] step: 965900, eval_loss: 3.80743e-02
I0214 02:23:37.851842 22509476222784 run_lib.py:133] step: 965950, training_loss: 2.76564e-02
I0214 02:23:56.616293 22509476222784 run_lib.py:133] step: 966000, training_loss: 4.91216e-02
I0214 02:23:56.787166 22509476222784 run_lib.py:146] step: 966000, eval_loss: 5.03160e-02
I0214 02:24:15.985672 22509476222784 run_lib.py:133] step: 966050, training_loss: 3.47124e-02
I0214 02:24:34.694431 22509476222784 run_lib.py:133] step: 966100, training_loss: 3.75203e-02
I0214 02:24:34.861109 22509476222784 run_lib.py:146] step: 966100, eval_loss: 4.76130e-02
I0214 02:24:53.648042 22509476222784 run_lib.py:133] step: 966150, training_loss: 4.83370e-02
I0214 02:25:12.456934 22509476222784 run_lib.py:133] step: 966200, training_loss: 4.80897e-02
I0214 02:25:12.623988 22509476222784 run_lib.py:146] step: 966200, eval_loss: 3.25730e-02
I0214 02:25:31.633202 22509476222784 run_lib.py:133] step: 966250, training_loss: 4.23910e-02
I0214 02:25:50.529302 22509476222784 run_lib.py:133] step: 966300, training_loss: 5.18159e-02
I0214 02:25:50.703766 22509476222784 run_lib.py:146] step: 966300, eval_loss: 4.22685e-02
I0214 02:26:09.670341 22509476222784 run_lib.py:133] step: 966350, training_loss: 4.44205e-02
I0214 02:26:28.538243 22509476222784 run_lib.py:133] step: 966400, training_loss: 3.54669e-02
I0214 02:26:28.700100 22509476222784 run_lib.py:146] step: 966400, eval_loss: 3.89330e-02
I0214 02:26:47.616929 22509476222784 run_lib.py:133] step: 966450, training_loss: 4.55181e-02
I0214 02:27:06.514307 22509476222784 run_lib.py:133] step: 966500, training_loss: 4.62559e-02
I0214 02:27:06.692392 22509476222784 run_lib.py:146] step: 966500, eval_loss: 4.01872e-02
I0214 02:27:25.497359 22509476222784 run_lib.py:133] step: 966550, training_loss: 4.14894e-02
I0214 02:27:44.532894 22509476222784 run_lib.py:133] step: 966600, training_loss: 3.95266e-02
I0214 02:27:44.699160 22509476222784 run_lib.py:146] step: 966600, eval_loss: 4.26882e-02
I0214 02:28:03.384497 22509476222784 run_lib.py:133] step: 966650, training_loss: 3.76785e-02
I0214 02:28:22.314057 22509476222784 run_lib.py:133] step: 966700, training_loss: 3.54679e-02
I0214 02:28:22.482028 22509476222784 run_lib.py:146] step: 966700, eval_loss: 4.29147e-02
I0214 02:28:41.260368 22509476222784 run_lib.py:133] step: 966750, training_loss: 4.50832e-02
I0214 02:29:00.019957 22509476222784 run_lib.py:133] step: 966800, training_loss: 4.45145e-02
I0214 02:29:00.187195 22509476222784 run_lib.py:146] step: 966800, eval_loss: 3.61336e-02
I0214 02:29:19.293421 22509476222784 run_lib.py:133] step: 966850, training_loss: 4.36533e-02
I0214 02:29:37.993359 22509476222784 run_lib.py:133] step: 966900, training_loss: 3.42604e-02
I0214 02:29:38.156007 22509476222784 run_lib.py:146] step: 966900, eval_loss: 3.79350e-02
I0214 02:29:56.987405 22509476222784 run_lib.py:133] step: 966950, training_loss: 4.34307e-02
I0214 02:30:15.692397 22509476222784 run_lib.py:133] step: 967000, training_loss: 5.31502e-02
I0214 02:30:15.861187 22509476222784 run_lib.py:146] step: 967000, eval_loss: 4.28865e-02
I0214 02:30:34.905878 22509476222784 run_lib.py:133] step: 967050, training_loss: 5.14448e-02
I0214 02:30:53.688733 22509476222784 run_lib.py:133] step: 967100, training_loss: 5.09588e-02
I0214 02:30:53.857375 22509476222784 run_lib.py:146] step: 967100, eval_loss: 4.37872e-02
I0214 02:31:12.823776 22509476222784 run_lib.py:133] step: 967150, training_loss: 4.24427e-02
I0214 02:31:31.617899 22509476222784 run_lib.py:133] step: 967200, training_loss: 3.53594e-02
I0214 02:31:31.783724 22509476222784 run_lib.py:146] step: 967200, eval_loss: 3.48703e-02
I0214 02:31:50.496587 22509476222784 run_lib.py:133] step: 967250, training_loss: 4.50305e-02
I0214 02:32:09.289989 22509476222784 run_lib.py:133] step: 967300, training_loss: 3.96599e-02
I0214 02:32:09.455093 22509476222784 run_lib.py:146] step: 967300, eval_loss: 5.10759e-02
I0214 02:32:28.394918 22509476222784 run_lib.py:133] step: 967350, training_loss: 4.75000e-02
I0214 02:32:47.390938 22509476222784 run_lib.py:133] step: 967400, training_loss: 3.11821e-02
I0214 02:32:47.553033 22509476222784 run_lib.py:146] step: 967400, eval_loss: 4.26616e-02
I0214 02:33:06.318790 22509476222784 run_lib.py:133] step: 967450, training_loss: 3.63328e-02
I0214 02:33:25.146090 22509476222784 run_lib.py:133] step: 967500, training_loss: 5.36329e-02
I0214 02:33:25.316040 22509476222784 run_lib.py:146] step: 967500, eval_loss: 5.09550e-02
I0214 02:33:44.160944 22509476222784 run_lib.py:133] step: 967550, training_loss: 3.75005e-02
I0214 02:34:02.996197 22509476222784 run_lib.py:133] step: 967600, training_loss: 4.98247e-02
I0214 02:34:03.178400 22509476222784 run_lib.py:146] step: 967600, eval_loss: 3.81708e-02
I0214 02:34:22.170534 22509476222784 run_lib.py:133] step: 967650, training_loss: 4.46295e-02
I0214 02:34:40.910241 22509476222784 run_lib.py:133] step: 967700, training_loss: 4.30340e-02
I0214 02:34:41.085323 22509476222784 run_lib.py:146] step: 967700, eval_loss: 3.73774e-02
I0214 02:35:00.092558 22509476222784 run_lib.py:133] step: 967750, training_loss: 3.80602e-02
I0214 02:35:18.779365 22509476222784 run_lib.py:133] step: 967800, training_loss: 3.26486e-02
I0214 02:35:18.942744 22509476222784 run_lib.py:146] step: 967800, eval_loss: 3.64757e-02
I0214 02:35:38.017795 22509476222784 run_lib.py:133] step: 967850, training_loss: 3.02073e-02
I0214 02:35:56.739618 22509476222784 run_lib.py:133] step: 967900, training_loss: 5.53863e-02
I0214 02:35:56.910213 22509476222784 run_lib.py:146] step: 967900, eval_loss: 3.51719e-02
I0214 02:36:15.735312 22509476222784 run_lib.py:133] step: 967950, training_loss: 3.35841e-02
I0214 02:36:34.702849 22509476222784 run_lib.py:133] step: 968000, training_loss: 3.86976e-02
I0214 02:36:34.871187 22509476222784 run_lib.py:146] step: 968000, eval_loss: 4.04250e-02
I0214 02:36:53.685162 22509476222784 run_lib.py:133] step: 968050, training_loss: 3.88449e-02
I0214 02:37:12.504861 22509476222784 run_lib.py:133] step: 968100, training_loss: 3.81483e-02
I0214 02:37:12.681072 22509476222784 run_lib.py:146] step: 968100, eval_loss: 4.63459e-02
I0214 02:37:31.630064 22509476222784 run_lib.py:133] step: 968150, training_loss: 4.94116e-02
I0214 02:37:50.562064 22509476222784 run_lib.py:133] step: 968200, training_loss: 3.25845e-02
I0214 02:37:50.733151 22509476222784 run_lib.py:146] step: 968200, eval_loss: 5.15906e-02
I0214 02:38:09.607729 22509476222784 run_lib.py:133] step: 968250, training_loss: 4.33824e-02
I0214 02:38:28.354678 22509476222784 run_lib.py:133] step: 968300, training_loss: 2.91335e-02
I0214 02:38:28.516700 22509476222784 run_lib.py:146] step: 968300, eval_loss: 3.53363e-02
I0214 02:38:47.351020 22509476222784 run_lib.py:133] step: 968350, training_loss: 4.28909e-02
I0214 02:39:06.202332 22509476222784 run_lib.py:133] step: 968400, training_loss: 3.56337e-02
I0214 02:39:06.383168 22509476222784 run_lib.py:146] step: 968400, eval_loss: 3.39466e-02
I0214 02:39:25.238169 22509476222784 run_lib.py:133] step: 968450, training_loss: 4.18417e-02
I0214 02:39:44.001156 22509476222784 run_lib.py:133] step: 968500, training_loss: 4.32221e-02
I0214 02:39:44.167983 22509476222784 run_lib.py:146] step: 968500, eval_loss: 5.53473e-02
I0214 02:40:02.859721 22509476222784 run_lib.py:133] step: 968550, training_loss: 4.28527e-02
I0214 02:40:21.897793 22509476222784 run_lib.py:133] step: 968600, training_loss: 3.01988e-02
I0214 02:40:22.061923 22509476222784 run_lib.py:146] step: 968600, eval_loss: 4.22424e-02
I0214 02:40:40.800649 22509476222784 run_lib.py:133] step: 968650, training_loss: 3.01304e-02
I0214 02:40:59.832244 22509476222784 run_lib.py:133] step: 968700, training_loss: 3.53983e-02
I0214 02:40:59.998285 22509476222784 run_lib.py:146] step: 968700, eval_loss: 3.20986e-02
I0214 02:41:18.806320 22509476222784 run_lib.py:133] step: 968750, training_loss: 4.28442e-02
I0214 02:41:37.613674 22509476222784 run_lib.py:133] step: 968800, training_loss: 4.58094e-02
I0214 02:41:37.783178 22509476222784 run_lib.py:146] step: 968800, eval_loss: 3.32618e-02
I0214 02:41:56.762052 22509476222784 run_lib.py:133] step: 968850, training_loss: 3.69351e-02
I0214 02:42:15.583876 22509476222784 run_lib.py:133] step: 968900, training_loss: 4.63783e-02
I0214 02:42:15.776293 22509476222784 run_lib.py:146] step: 968900, eval_loss: 3.52163e-02
I0214 02:42:34.619820 22509476222784 run_lib.py:133] step: 968950, training_loss: 3.60584e-02
I0214 02:42:53.378955 22509476222784 run_lib.py:133] step: 969000, training_loss: 4.13380e-02
I0214 02:42:53.545957 22509476222784 run_lib.py:146] step: 969000, eval_loss: 4.63761e-02
I0214 02:43:12.518810 22509476222784 run_lib.py:133] step: 969050, training_loss: 3.82252e-02
I0214 02:43:31.273297 22509476222784 run_lib.py:133] step: 969100, training_loss: 3.61160e-02
I0214 02:43:31.443986 22509476222784 run_lib.py:146] step: 969100, eval_loss: 4.17880e-02
I0214 02:43:50.507281 22509476222784 run_lib.py:133] step: 969150, training_loss: 4.27238e-02
I0214 02:44:09.306574 22509476222784 run_lib.py:133] step: 969200, training_loss: 3.68774e-02
I0214 02:44:09.488096 22509476222784 run_lib.py:146] step: 969200, eval_loss: 4.06036e-02
I0214 02:44:28.536159 22509476222784 run_lib.py:133] step: 969250, training_loss: 3.92708e-02
I0214 02:44:47.358172 22509476222784 run_lib.py:133] step: 969300, training_loss: 3.50894e-02
I0214 02:44:47.521051 22509476222784 run_lib.py:146] step: 969300, eval_loss: 3.39545e-02
I0214 02:45:06.217948 22509476222784 run_lib.py:133] step: 969350, training_loss: 4.50777e-02
I0214 02:45:25.189439 22509476222784 run_lib.py:133] step: 969400, training_loss: 3.96729e-02
I0214 02:45:25.362191 22509476222784 run_lib.py:146] step: 969400, eval_loss: 4.53749e-02
I0214 02:45:44.173846 22509476222784 run_lib.py:133] step: 969450, training_loss: 4.20957e-02
I0214 02:46:03.282212 22509476222784 run_lib.py:133] step: 969500, training_loss: 4.87056e-02
I0214 02:46:03.451711 22509476222784 run_lib.py:146] step: 969500, eval_loss: 4.50404e-02
I0214 02:46:22.176304 22509476222784 run_lib.py:133] step: 969550, training_loss: 3.30860e-02
I0214 02:46:41.038852 22509476222784 run_lib.py:133] step: 969600, training_loss: 4.66562e-02
I0214 02:46:41.203901 22509476222784 run_lib.py:146] step: 969600, eval_loss: 3.75733e-02
I0214 02:47:00.105443 22509476222784 run_lib.py:133] step: 969650, training_loss: 4.89266e-02
I0214 02:47:18.966970 22509476222784 run_lib.py:133] step: 969700, training_loss: 4.00970e-02
I0214 02:47:19.134917 22509476222784 run_lib.py:146] step: 969700, eval_loss: 3.83428e-02
I0214 02:47:37.927088 22509476222784 run_lib.py:133] step: 969750, training_loss: 3.88512e-02
I0214 02:47:56.849311 22509476222784 run_lib.py:133] step: 969800, training_loss: 4.71556e-02
I0214 02:47:57.013890 22509476222784 run_lib.py:146] step: 969800, eval_loss: 4.62676e-02
I0214 02:48:15.816941 22509476222784 run_lib.py:133] step: 969850, training_loss: 5.03183e-02
I0214 02:48:34.590519 22509476222784 run_lib.py:133] step: 969900, training_loss: 5.43020e-02
I0214 02:48:34.770068 22509476222784 run_lib.py:146] step: 969900, eval_loss: 3.64269e-02
I0214 02:48:53.690690 22509476222784 run_lib.py:133] step: 969950, training_loss: 4.01973e-02
I0214 02:49:12.507781 22509476222784 run_lib.py:133] step: 970000, training_loss: 3.11698e-02
I0214 02:49:13.293808 22509476222784 run_lib.py:146] step: 970000, eval_loss: 3.91885e-02
I0214 02:49:34.748072 22509476222784 run_lib.py:133] step: 970050, training_loss: 3.46895e-02
I0214 02:49:53.510306 22509476222784 run_lib.py:133] step: 970100, training_loss: 4.89175e-02
I0214 02:49:53.675820 22509476222784 run_lib.py:146] step: 970100, eval_loss: 3.76069e-02
I0214 02:50:12.599958 22509476222784 run_lib.py:133] step: 970150, training_loss: 4.80877e-02
I0214 02:50:31.479011 22509476222784 run_lib.py:133] step: 970200, training_loss: 4.41759e-02
I0214 02:50:31.645194 22509476222784 run_lib.py:146] step: 970200, eval_loss: 3.59839e-02
I0214 02:50:50.502161 22509476222784 run_lib.py:133] step: 970250, training_loss: 3.56172e-02
I0214 02:51:09.378306 22509476222784 run_lib.py:133] step: 970300, training_loss: 5.08827e-02
I0214 02:51:09.542940 22509476222784 run_lib.py:146] step: 970300, eval_loss: 4.26839e-02
I0214 02:51:28.266605 22509476222784 run_lib.py:133] step: 970350, training_loss: 3.32364e-02
I0214 02:51:47.095340 22509476222784 run_lib.py:133] step: 970400, training_loss: 3.84387e-02
I0214 02:51:47.267294 22509476222784 run_lib.py:146] step: 970400, eval_loss: 3.96730e-02
I0214 02:52:06.157669 22509476222784 run_lib.py:133] step: 970450, training_loss: 4.33547e-02
I0214 02:52:25.082369 22509476222784 run_lib.py:133] step: 970500, training_loss: 4.77971e-02
I0214 02:52:25.256970 22509476222784 run_lib.py:146] step: 970500, eval_loss: 4.67417e-02
I0214 02:52:44.096088 22509476222784 run_lib.py:133] step: 970550, training_loss: 4.65162e-02
I0214 02:53:02.860277 22509476222784 run_lib.py:133] step: 970600, training_loss: 4.57240e-02
I0214 02:53:03.027159 22509476222784 run_lib.py:146] step: 970600, eval_loss: 4.13870e-02
I0214 02:53:22.085150 22509476222784 run_lib.py:133] step: 970650, training_loss: 4.21694e-02
I0214 02:53:40.839793 22509476222784 run_lib.py:133] step: 970700, training_loss: 4.13858e-02
I0214 02:53:41.005327 22509476222784 run_lib.py:146] step: 970700, eval_loss: 4.01837e-02
I0214 02:54:00.107392 22509476222784 run_lib.py:133] step: 970750, training_loss: 4.27184e-02
I0214 02:54:18.928221 22509476222784 run_lib.py:133] step: 970800, training_loss: 3.75998e-02
I0214 02:54:19.110857 22509476222784 run_lib.py:146] step: 970800, eval_loss: 4.58486e-02
I0214 02:54:38.184579 22509476222784 run_lib.py:133] step: 970850, training_loss: 4.16634e-02
I0214 02:54:56.954025 22509476222784 run_lib.py:133] step: 970900, training_loss: 3.81433e-02
I0214 02:54:57.122158 22509476222784 run_lib.py:146] step: 970900, eval_loss: 4.53826e-02
I0214 02:55:16.163072 22509476222784 run_lib.py:133] step: 970950, training_loss: 3.54007e-02
I0214 02:55:35.039454 22509476222784 run_lib.py:133] step: 971000, training_loss: 4.10271e-02
I0214 02:55:35.216199 22509476222784 run_lib.py:146] step: 971000, eval_loss: 3.82171e-02
I0214 02:55:53.992257 22509476222784 run_lib.py:133] step: 971050, training_loss: 3.22565e-02
I0214 02:56:13.062561 22509476222784 run_lib.py:133] step: 971100, training_loss: 3.95005e-02
I0214 02:56:13.228947 22509476222784 run_lib.py:146] step: 971100, eval_loss: 4.74883e-02
I0214 02:56:31.982782 22509476222784 run_lib.py:133] step: 971150, training_loss: 3.26377e-02
I0214 02:56:50.883898 22509476222784 run_lib.py:133] step: 971200, training_loss: 4.10169e-02
I0214 02:56:51.058434 22509476222784 run_lib.py:146] step: 971200, eval_loss: 4.07959e-02
I0214 02:57:10.116776 22509476222784 run_lib.py:133] step: 971250, training_loss: 3.97342e-02
I0214 02:57:28.915471 22509476222784 run_lib.py:133] step: 971300, training_loss: 4.84469e-02
I0214 02:57:29.079912 22509476222784 run_lib.py:146] step: 971300, eval_loss: 5.36770e-02
I0214 02:57:48.047584 22509476222784 run_lib.py:133] step: 971350, training_loss: 4.18415e-02
I0214 02:58:06.819779 22509476222784 run_lib.py:133] step: 971400, training_loss: 3.18026e-02
I0214 02:58:06.996130 22509476222784 run_lib.py:146] step: 971400, eval_loss: 4.62981e-02
I0214 02:58:25.854408 22509476222784 run_lib.py:133] step: 971450, training_loss: 5.43023e-02
I0214 02:58:44.852567 22509476222784 run_lib.py:133] step: 971500, training_loss: 4.71044e-02
I0214 02:58:45.021340 22509476222784 run_lib.py:146] step: 971500, eval_loss: 4.23766e-02
I0214 02:59:03.874445 22509476222784 run_lib.py:133] step: 971550, training_loss: 4.98041e-02
I0214 02:59:22.655598 22509476222784 run_lib.py:133] step: 971600, training_loss: 3.75799e-02
I0214 02:59:22.822991 22509476222784 run_lib.py:146] step: 971600, eval_loss: 3.35285e-02
I0214 02:59:41.605777 22509476222784 run_lib.py:133] step: 971650, training_loss: 3.29521e-02
I0214 03:00:00.672263 22509476222784 run_lib.py:133] step: 971700, training_loss: 3.28508e-02
I0214 03:00:00.840732 22509476222784 run_lib.py:146] step: 971700, eval_loss: 5.17973e-02
I0214 03:00:19.677576 22509476222784 run_lib.py:133] step: 971750, training_loss: 4.04319e-02
I0214 03:00:38.677481 22509476222784 run_lib.py:133] step: 971800, training_loss: 3.49147e-02
I0214 03:00:38.842909 22509476222784 run_lib.py:146] step: 971800, eval_loss: 4.45370e-02
I0214 03:00:57.614128 22509476222784 run_lib.py:133] step: 971850, training_loss: 4.36916e-02
I0214 03:01:16.451372 22509476222784 run_lib.py:133] step: 971900, training_loss: 4.12851e-02
I0214 03:01:16.622685 22509476222784 run_lib.py:146] step: 971900, eval_loss: 4.35043e-02
I0214 03:01:35.508208 22509476222784 run_lib.py:133] step: 971950, training_loss: 2.75094e-02
I0214 03:01:54.439546 22509476222784 run_lib.py:133] step: 972000, training_loss: 4.21460e-02
I0214 03:01:54.611187 22509476222784 run_lib.py:146] step: 972000, eval_loss: 5.13660e-02
I0214 03:02:13.539813 22509476222784 run_lib.py:133] step: 972050, training_loss: 3.70413e-02
I0214 03:02:32.255398 22509476222784 run_lib.py:133] step: 972100, training_loss: 4.24490e-02
I0214 03:02:32.421888 22509476222784 run_lib.py:146] step: 972100, eval_loss: 5.20412e-02
I0214 03:02:51.449965 22509476222784 run_lib.py:133] step: 972150, training_loss: 3.04276e-02
I0214 03:03:10.151850 22509476222784 run_lib.py:133] step: 972200, training_loss: 3.57460e-02
I0214 03:03:10.313912 22509476222784 run_lib.py:146] step: 972200, eval_loss: 5.35405e-02
I0214 03:03:29.395179 22509476222784 run_lib.py:133] step: 972250, training_loss: 4.17428e-02
I0214 03:03:48.140382 22509476222784 run_lib.py:133] step: 972300, training_loss: 3.67741e-02
I0214 03:03:48.315673 22509476222784 run_lib.py:146] step: 972300, eval_loss: 4.18097e-02
I0214 03:04:07.408273 22509476222784 run_lib.py:133] step: 972350, training_loss: 4.13309e-02
I0214 03:04:26.190472 22509476222784 run_lib.py:133] step: 972400, training_loss: 3.72477e-02
I0214 03:04:26.370370 22509476222784 run_lib.py:146] step: 972400, eval_loss: 4.07824e-02
I0214 03:04:45.124713 22509476222784 run_lib.py:133] step: 972450, training_loss: 4.61258e-02
I0214 03:05:04.189939 22509476222784 run_lib.py:133] step: 972500, training_loss: 3.62134e-02
I0214 03:05:04.363143 22509476222784 run_lib.py:146] step: 972500, eval_loss: 3.45465e-02
I0214 03:05:23.139760 22509476222784 run_lib.py:133] step: 972550, training_loss: 3.45348e-02
I0214 03:05:42.173929 22509476222784 run_lib.py:133] step: 972600, training_loss: 4.98176e-02
I0214 03:05:42.338855 22509476222784 run_lib.py:146] step: 972600, eval_loss: 4.44222e-02
I0214 03:06:01.074714 22509476222784 run_lib.py:133] step: 972650, training_loss: 3.97383e-02
I0214 03:06:19.924284 22509476222784 run_lib.py:133] step: 972700, training_loss: 3.74318e-02
I0214 03:06:20.091500 22509476222784 run_lib.py:146] step: 972700, eval_loss: 4.90576e-02
I0214 03:06:39.045960 22509476222784 run_lib.py:133] step: 972750, training_loss: 4.17188e-02
I0214 03:06:57.831205 22509476222784 run_lib.py:133] step: 972800, training_loss: 3.44233e-02
I0214 03:06:58.005357 22509476222784 run_lib.py:146] step: 972800, eval_loss: 3.88749e-02
I0214 03:07:16.904396 22509476222784 run_lib.py:133] step: 972850, training_loss: 3.94415e-02
I0214 03:07:35.872928 22509476222784 run_lib.py:133] step: 972900, training_loss: 4.00663e-02
I0214 03:07:36.039451 22509476222784 run_lib.py:146] step: 972900, eval_loss: 4.63549e-02
I0214 03:07:54.872554 22509476222784 run_lib.py:133] step: 972950, training_loss: 3.51446e-02
I0214 03:08:13.672217 22509476222784 run_lib.py:133] step: 973000, training_loss: 3.67871e-02
I0214 03:08:13.996946 22509476222784 run_lib.py:146] step: 973000, eval_loss: 3.14827e-02
I0214 03:08:32.870692 22509476222784 run_lib.py:133] step: 973050, training_loss: 4.65909e-02
I0214 03:08:51.597819 22509476222784 run_lib.py:133] step: 973100, training_loss: 3.64123e-02
I0214 03:08:51.760951 22509476222784 run_lib.py:146] step: 973100, eval_loss: 4.37567e-02
I0214 03:09:10.487637 22509476222784 run_lib.py:133] step: 973150, training_loss: 4.37903e-02
I0214 03:09:29.341547 22509476222784 run_lib.py:133] step: 973200, training_loss: 3.60209e-02
I0214 03:09:29.505670 22509476222784 run_lib.py:146] step: 973200, eval_loss: 4.48618e-02
I0214 03:09:48.417346 22509476222784 run_lib.py:133] step: 973250, training_loss: 4.14824e-02
I0214 03:10:07.299216 22509476222784 run_lib.py:133] step: 973300, training_loss: 4.65891e-02
I0214 03:10:07.481975 22509476222784 run_lib.py:146] step: 973300, eval_loss: 3.35859e-02
I0214 03:10:26.273684 22509476222784 run_lib.py:133] step: 973350, training_loss: 3.92379e-02
I0214 03:10:45.193776 22509476222784 run_lib.py:133] step: 973400, training_loss: 3.82594e-02
I0214 03:10:45.360265 22509476222784 run_lib.py:146] step: 973400, eval_loss: 3.05365e-02
I0214 03:11:04.292980 22509476222784 run_lib.py:133] step: 973450, training_loss: 4.21984e-02
I0214 03:11:23.094131 22509476222784 run_lib.py:133] step: 973500, training_loss: 4.08607e-02
I0214 03:11:23.260061 22509476222784 run_lib.py:146] step: 973500, eval_loss: 4.46410e-02
I0214 03:11:42.157674 22509476222784 run_lib.py:133] step: 973550, training_loss: 4.13994e-02
I0214 03:12:00.933520 22509476222784 run_lib.py:133] step: 973600, training_loss: 3.77126e-02
I0214 03:12:01.099199 22509476222784 run_lib.py:146] step: 973600, eval_loss: 3.36358e-02
I0214 03:12:20.112058 22509476222784 run_lib.py:133] step: 973650, training_loss: 3.33135e-02
I0214 03:12:38.931688 22509476222784 run_lib.py:133] step: 973700, training_loss: 3.84746e-02
I0214 03:12:39.097887 22509476222784 run_lib.py:146] step: 973700, eval_loss: 4.37612e-02
I0214 03:12:57.943605 22509476222784 run_lib.py:133] step: 973750, training_loss: 4.02399e-02
I0214 03:13:16.797365 22509476222784 run_lib.py:133] step: 973800, training_loss: 2.75064e-02
I0214 03:13:16.976916 22509476222784 run_lib.py:146] step: 973800, eval_loss: 4.47002e-02
I0214 03:13:35.900562 22509476222784 run_lib.py:133] step: 973850, training_loss: 3.92703e-02
I0214 03:13:54.799178 22509476222784 run_lib.py:133] step: 973900, training_loss: 3.10697e-02
I0214 03:13:54.969125 22509476222784 run_lib.py:146] step: 973900, eval_loss: 3.37755e-02
I0214 03:14:13.727275 22509476222784 run_lib.py:133] step: 973950, training_loss: 4.10951e-02
I0214 03:14:32.738403 22509476222784 run_lib.py:133] step: 974000, training_loss: 5.47976e-02
I0214 03:14:32.929981 22509476222784 run_lib.py:146] step: 974000, eval_loss: 4.94342e-02
I0214 03:14:51.659616 22509476222784 run_lib.py:133] step: 974050, training_loss: 3.23132e-02
I0214 03:15:10.538196 22509476222784 run_lib.py:133] step: 974100, training_loss: 4.11344e-02
I0214 03:15:10.709872 22509476222784 run_lib.py:146] step: 974100, eval_loss: 6.53301e-02
I0214 03:15:29.646216 22509476222784 run_lib.py:133] step: 974150, training_loss: 3.32615e-02
I0214 03:15:48.398456 22509476222784 run_lib.py:133] step: 974200, training_loss: 4.30309e-02
I0214 03:15:48.565055 22509476222784 run_lib.py:146] step: 974200, eval_loss: 3.13704e-02
I0214 03:16:07.644503 22509476222784 run_lib.py:133] step: 974250, training_loss: 3.68798e-02
I0214 03:16:26.424594 22509476222784 run_lib.py:133] step: 974300, training_loss: 3.60334e-02
I0214 03:16:26.593140 22509476222784 run_lib.py:146] step: 974300, eval_loss: 4.57604e-02
I0214 03:16:45.454527 22509476222784 run_lib.py:133] step: 974350, training_loss: 4.53968e-02
I0214 03:17:04.354410 22509476222784 run_lib.py:133] step: 974400, training_loss: 4.20475e-02
I0214 03:17:04.521213 22509476222784 run_lib.py:146] step: 974400, eval_loss: 4.42872e-02
I0214 03:17:23.509079 22509476222784 run_lib.py:133] step: 974450, training_loss: 4.18315e-02
I0214 03:17:42.336202 22509476222784 run_lib.py:133] step: 974500, training_loss: 3.62600e-02
I0214 03:17:42.514094 22509476222784 run_lib.py:146] step: 974500, eval_loss: 5.56736e-02
I0214 03:18:01.346229 22509476222784 run_lib.py:133] step: 974550, training_loss: 4.26228e-02
I0214 03:18:20.252738 22509476222784 run_lib.py:133] step: 974600, training_loss: 3.82845e-02
I0214 03:18:20.417585 22509476222784 run_lib.py:146] step: 974600, eval_loss: 5.15408e-02
I0214 03:18:39.258761 22509476222784 run_lib.py:133] step: 974650, training_loss: 4.45773e-02
I0214 03:18:58.132604 22509476222784 run_lib.py:133] step: 974700, training_loss: 3.08455e-02
I0214 03:18:58.311152 22509476222784 run_lib.py:146] step: 974700, eval_loss: 3.66617e-02
I0214 03:19:17.298135 22509476222784 run_lib.py:133] step: 974750, training_loss: 4.45558e-02
I0214 03:19:36.141424 22509476222784 run_lib.py:133] step: 974800, training_loss: 4.71139e-02
I0214 03:19:36.308803 22509476222784 run_lib.py:146] step: 974800, eval_loss: 3.77401e-02
I0214 03:19:55.178364 22509476222784 run_lib.py:133] step: 974850, training_loss: 3.62570e-02
I0214 03:20:13.957846 22509476222784 run_lib.py:133] step: 974900, training_loss: 3.47773e-02
I0214 03:20:14.130865 22509476222784 run_lib.py:146] step: 974900, eval_loss: 5.11083e-02
I0214 03:20:33.242252 22509476222784 run_lib.py:133] step: 974950, training_loss: 3.69316e-02
I0214 03:20:52.000747 22509476222784 run_lib.py:133] step: 975000, training_loss: 4.62325e-02
I0214 03:20:52.163879 22509476222784 run_lib.py:146] step: 975000, eval_loss: 3.66189e-02
I0214 03:21:11.086157 22509476222784 run_lib.py:133] step: 975050, training_loss: 4.18660e-02
I0214 03:21:29.821586 22509476222784 run_lib.py:133] step: 975100, training_loss: 4.43978e-02
I0214 03:21:29.995872 22509476222784 run_lib.py:146] step: 975100, eval_loss: 3.97187e-02
I0214 03:21:48.972473 22509476222784 run_lib.py:133] step: 975150, training_loss: 3.75994e-02
I0214 03:22:07.879564 22509476222784 run_lib.py:133] step: 975200, training_loss: 4.09933e-02
I0214 03:22:08.046921 22509476222784 run_lib.py:146] step: 975200, eval_loss: 4.50086e-02
I0214 03:22:26.929714 22509476222784 run_lib.py:133] step: 975250, training_loss: 4.00442e-02
I0214 03:22:45.854380 22509476222784 run_lib.py:133] step: 975300, training_loss: 4.37601e-02
I0214 03:22:46.022062 22509476222784 run_lib.py:146] step: 975300, eval_loss: 5.21334e-02
I0214 03:23:04.792629 22509476222784 run_lib.py:133] step: 975350, training_loss: 4.47834e-02
I0214 03:23:23.813716 22509476222784 run_lib.py:133] step: 975400, training_loss: 4.21613e-02
I0214 03:23:23.995749 22509476222784 run_lib.py:146] step: 975400, eval_loss: 4.15798e-02
I0214 03:23:42.782174 22509476222784 run_lib.py:133] step: 975450, training_loss: 4.82532e-02
I0214 03:24:01.693344 22509476222784 run_lib.py:133] step: 975500, training_loss: 4.01614e-02
I0214 03:24:01.858604 22509476222784 run_lib.py:146] step: 975500, eval_loss: 4.80061e-02
I0214 03:24:20.911554 22509476222784 run_lib.py:133] step: 975550, training_loss: 4.84788e-02
I0214 03:24:39.817383 22509476222784 run_lib.py:133] step: 975600, training_loss: 3.70383e-02
I0214 03:24:39.998920 22509476222784 run_lib.py:146] step: 975600, eval_loss: 4.62362e-02
I0214 03:24:58.796376 22509476222784 run_lib.py:133] step: 975650, training_loss: 3.94320e-02
I0214 03:25:17.528275 22509476222784 run_lib.py:133] step: 975700, training_loss: 4.11298e-02
I0214 03:25:17.699049 22509476222784 run_lib.py:146] step: 975700, eval_loss: 4.08178e-02
I0214 03:25:36.610223 22509476222784 run_lib.py:133] step: 975750, training_loss: 3.08979e-02
I0214 03:25:55.618877 22509476222784 run_lib.py:133] step: 975800, training_loss: 5.56003e-02
I0214 03:25:55.784175 22509476222784 run_lib.py:146] step: 975800, eval_loss: 4.47646e-02
I0214 03:26:14.576266 22509476222784 run_lib.py:133] step: 975850, training_loss: 3.28205e-02
I0214 03:26:33.326809 22509476222784 run_lib.py:133] step: 975900, training_loss: 3.67617e-02
I0214 03:26:33.492887 22509476222784 run_lib.py:146] step: 975900, eval_loss: 5.38425e-02
I0214 03:26:52.209169 22509476222784 run_lib.py:133] step: 975950, training_loss: 3.20607e-02
I0214 03:27:11.190668 22509476222784 run_lib.py:133] step: 976000, training_loss: 3.90260e-02
I0214 03:27:11.366175 22509476222784 run_lib.py:146] step: 976000, eval_loss: 3.90588e-02
I0214 03:27:30.232125 22509476222784 run_lib.py:133] step: 976050, training_loss: 3.60631e-02
I0214 03:27:49.143108 22509476222784 run_lib.py:133] step: 976100, training_loss: 4.43053e-02
I0214 03:27:49.308896 22509476222784 run_lib.py:146] step: 976100, eval_loss: 4.33643e-02
I0214 03:28:08.177476 22509476222784 run_lib.py:133] step: 976150, training_loss: 5.60851e-02
I0214 03:28:26.884239 22509476222784 run_lib.py:133] step: 976200, training_loss: 4.15268e-02
I0214 03:28:27.054343 22509476222784 run_lib.py:146] step: 976200, eval_loss: 5.17270e-02
I0214 03:28:46.075579 22509476222784 run_lib.py:133] step: 976250, training_loss: 3.71763e-02
I0214 03:29:05.049759 22509476222784 run_lib.py:133] step: 976300, training_loss: 4.40982e-02
I0214 03:29:05.216657 22509476222784 run_lib.py:146] step: 976300, eval_loss: 3.11846e-02
I0214 03:29:23.977865 22509476222784 run_lib.py:133] step: 976350, training_loss: 3.90237e-02
I0214 03:29:42.830632 22509476222784 run_lib.py:133] step: 976400, training_loss: 3.93206e-02
I0214 03:29:42.996819 22509476222784 run_lib.py:146] step: 976400, eval_loss: 4.94734e-02
I0214 03:30:01.862728 22509476222784 run_lib.py:133] step: 976450, training_loss: 5.38915e-02
I0214 03:30:20.672354 22509476222784 run_lib.py:133] step: 976500, training_loss: 3.94267e-02
I0214 03:30:20.838399 22509476222784 run_lib.py:146] step: 976500, eval_loss: 5.51310e-02
I0214 03:30:39.796960 22509476222784 run_lib.py:133] step: 976550, training_loss: 3.85529e-02
I0214 03:30:58.653382 22509476222784 run_lib.py:133] step: 976600, training_loss: 4.72320e-02
I0214 03:30:58.830031 22509476222784 run_lib.py:146] step: 976600, eval_loss: 4.88297e-02
I0214 03:31:17.751519 22509476222784 run_lib.py:133] step: 976650, training_loss: 4.68210e-02
I0214 03:31:36.482148 22509476222784 run_lib.py:133] step: 976700, training_loss: 3.84959e-02
I0214 03:31:36.652014 22509476222784 run_lib.py:146] step: 976700, eval_loss: 3.83481e-02
I0214 03:31:55.501556 22509476222784 run_lib.py:133] step: 976750, training_loss: 3.29188e-02
I0214 03:32:14.383553 22509476222784 run_lib.py:133] step: 976800, training_loss: 4.49004e-02
I0214 03:32:14.559096 22509476222784 run_lib.py:146] step: 976800, eval_loss: 3.67537e-02
I0214 03:32:33.464943 22509476222784 run_lib.py:133] step: 976850, training_loss: 3.87911e-02
I0214 03:32:52.432037 22509476222784 run_lib.py:133] step: 976900, training_loss: 4.24553e-02
I0214 03:32:52.613187 22509476222784 run_lib.py:146] step: 976900, eval_loss: 4.63731e-02
I0214 03:33:11.403010 22509476222784 run_lib.py:133] step: 976950, training_loss: 4.05270e-02
I0214 03:33:30.191286 22509476222784 run_lib.py:133] step: 977000, training_loss: 4.73550e-02
I0214 03:33:30.356862 22509476222784 run_lib.py:146] step: 977000, eval_loss: 4.80013e-02
I0214 03:33:49.317950 22509476222784 run_lib.py:133] step: 977050, training_loss: 4.39886e-02
I0214 03:34:08.208129 22509476222784 run_lib.py:133] step: 977100, training_loss: 3.44653e-02
I0214 03:34:08.377903 22509476222784 run_lib.py:146] step: 977100, eval_loss: 4.13944e-02
I0214 03:34:27.085561 22509476222784 run_lib.py:133] step: 977150, training_loss: 4.14506e-02
I0214 03:34:46.107656 22509476222784 run_lib.py:133] step: 977200, training_loss: 4.71080e-02
I0214 03:34:46.272820 22509476222784 run_lib.py:146] step: 977200, eval_loss: 4.56580e-02
I0214 03:35:04.995064 22509476222784 run_lib.py:133] step: 977250, training_loss: 4.70793e-02
I0214 03:35:23.804905 22509476222784 run_lib.py:133] step: 977300, training_loss: 4.20015e-02
I0214 03:35:23.978005 22509476222784 run_lib.py:146] step: 977300, eval_loss: 4.84845e-02
I0214 03:35:42.860797 22509476222784 run_lib.py:133] step: 977350, training_loss: 4.58049e-02
I0214 03:36:01.726323 22509476222784 run_lib.py:133] step: 977400, training_loss: 3.95438e-02
I0214 03:36:01.889297 22509476222784 run_lib.py:146] step: 977400, eval_loss: 5.32998e-02
I0214 03:36:20.711697 22509476222784 run_lib.py:133] step: 977450, training_loss: 3.51371e-02
I0214 03:36:39.419657 22509476222784 run_lib.py:133] step: 977500, training_loss: 5.12043e-02
I0214 03:36:39.585873 22509476222784 run_lib.py:146] step: 977500, eval_loss: 3.71161e-02
I0214 03:36:58.672620 22509476222784 run_lib.py:133] step: 977550, training_loss: 4.50979e-02
I0214 03:37:17.533131 22509476222784 run_lib.py:133] step: 977600, training_loss: 4.13651e-02
I0214 03:37:17.724987 22509476222784 run_lib.py:146] step: 977600, eval_loss: 3.90397e-02
I0214 03:37:36.564540 22509476222784 run_lib.py:133] step: 977650, training_loss: 4.17195e-02
I0214 03:37:55.338335 22509476222784 run_lib.py:133] step: 977700, training_loss: 4.62972e-02
I0214 03:37:55.504793 22509476222784 run_lib.py:146] step: 977700, eval_loss: 3.65885e-02
I0214 03:38:14.529171 22509476222784 run_lib.py:133] step: 977750, training_loss: 4.81659e-02
I0214 03:38:33.260481 22509476222784 run_lib.py:133] step: 977800, training_loss: 4.61640e-02
I0214 03:38:33.432155 22509476222784 run_lib.py:146] step: 977800, eval_loss: 4.82703e-02
I0214 03:38:52.347159 22509476222784 run_lib.py:133] step: 977850, training_loss: 3.72504e-02
I0214 03:39:11.163310 22509476222784 run_lib.py:133] step: 977900, training_loss: 5.24360e-02
I0214 03:39:11.326127 22509476222784 run_lib.py:146] step: 977900, eval_loss: 4.44473e-02
I0214 03:39:30.273518 22509476222784 run_lib.py:133] step: 977950, training_loss: 5.52782e-02
I0214 03:39:49.084242 22509476222784 run_lib.py:133] step: 978000, training_loss: 4.00982e-02
I0214 03:39:49.251937 22509476222784 run_lib.py:146] step: 978000, eval_loss: 4.34698e-02
I0214 03:40:08.217703 22509476222784 run_lib.py:133] step: 978050, training_loss: 3.65098e-02
I0214 03:40:27.065721 22509476222784 run_lib.py:133] step: 978100, training_loss: 4.63940e-02
I0214 03:40:27.233908 22509476222784 run_lib.py:146] step: 978100, eval_loss: 4.01364e-02
I0214 03:40:46.075752 22509476222784 run_lib.py:133] step: 978150, training_loss: 3.64554e-02
I0214 03:41:04.968939 22509476222784 run_lib.py:133] step: 978200, training_loss: 4.53614e-02
I0214 03:41:05.135098 22509476222784 run_lib.py:146] step: 978200, eval_loss: 3.25866e-02
I0214 03:41:23.968951 22509476222784 run_lib.py:133] step: 978250, training_loss: 3.97676e-02
I0214 03:41:42.669651 22509476222784 run_lib.py:133] step: 978300, training_loss: 4.23387e-02
I0214 03:41:42.834989 22509476222784 run_lib.py:146] step: 978300, eval_loss: 4.71834e-02
I0214 03:42:01.874800 22509476222784 run_lib.py:133] step: 978350, training_loss: 5.15759e-02
I0214 03:42:20.675151 22509476222784 run_lib.py:133] step: 978400, training_loss: 4.13571e-02
I0214 03:42:20.842141 22509476222784 run_lib.py:146] step: 978400, eval_loss: 4.85580e-02
I0214 03:42:39.801601 22509476222784 run_lib.py:133] step: 978450, training_loss: 3.14994e-02
I0214 03:42:58.650910 22509476222784 run_lib.py:133] step: 978500, training_loss: 3.85262e-02
I0214 03:42:58.824279 22509476222784 run_lib.py:146] step: 978500, eval_loss: 4.79202e-02
I0214 03:43:17.528062 22509476222784 run_lib.py:133] step: 978550, training_loss: 3.73773e-02
I0214 03:43:36.545262 22509476222784 run_lib.py:133] step: 978600, training_loss: 3.75917e-02
I0214 03:43:36.724226 22509476222784 run_lib.py:146] step: 978600, eval_loss: 4.21222e-02
I0214 03:43:55.509584 22509476222784 run_lib.py:133] step: 978650, training_loss: 4.52196e-02
I0214 03:44:14.363004 22509476222784 run_lib.py:133] step: 978700, training_loss: 5.49965e-02
I0214 03:44:14.539258 22509476222784 run_lib.py:146] step: 978700, eval_loss: 4.30048e-02
I0214 03:44:33.327062 22509476222784 run_lib.py:133] step: 978750, training_loss: 4.39878e-02
I0214 03:44:52.216378 22509476222784 run_lib.py:133] step: 978800, training_loss: 6.71611e-02
I0214 03:44:52.379739 22509476222784 run_lib.py:146] step: 978800, eval_loss: 4.22453e-02
I0214 03:45:11.274706 22509476222784 run_lib.py:133] step: 978850, training_loss: 2.29265e-02
I0214 03:45:30.110348 22509476222784 run_lib.py:133] step: 978900, training_loss: 4.71651e-02
I0214 03:45:30.283091 22509476222784 run_lib.py:146] step: 978900, eval_loss: 4.61613e-02
I0214 03:45:49.113720 22509476222784 run_lib.py:133] step: 978950, training_loss: 4.49434e-02
I0214 03:46:07.886496 22509476222784 run_lib.py:133] step: 979000, training_loss: 4.60991e-02
I0214 03:46:08.055288 22509476222784 run_lib.py:146] step: 979000, eval_loss: 3.87649e-02
I0214 03:46:27.021335 22509476222784 run_lib.py:133] step: 979050, training_loss: 3.94821e-02
I0214 03:46:45.801015 22509476222784 run_lib.py:133] step: 979100, training_loss: 4.33682e-02
I0214 03:46:45.978234 22509476222784 run_lib.py:146] step: 979100, eval_loss: 5.18022e-02
I0214 03:47:04.831263 22509476222784 run_lib.py:133] step: 979150, training_loss: 4.60025e-02
I0214 03:47:23.643267 22509476222784 run_lib.py:133] step: 979200, training_loss: 4.55023e-02
I0214 03:47:23.808077 22509476222784 run_lib.py:146] step: 979200, eval_loss: 4.59294e-02
I0214 03:47:42.734416 22509476222784 run_lib.py:133] step: 979250, training_loss: 3.76309e-02
I0214 03:48:01.563160 22509476222784 run_lib.py:133] step: 979300, training_loss: 3.69419e-02
I0214 03:48:01.734466 22509476222784 run_lib.py:146] step: 979300, eval_loss: 5.63672e-02
I0214 03:48:20.616945 22509476222784 run_lib.py:133] step: 979350, training_loss: 5.10859e-02
I0214 03:48:39.486562 22509476222784 run_lib.py:133] step: 979400, training_loss: 4.46721e-02
I0214 03:48:39.661056 22509476222784 run_lib.py:146] step: 979400, eval_loss: 4.15779e-02
I0214 03:48:58.636704 22509476222784 run_lib.py:133] step: 979450, training_loss: 3.90269e-02
I0214 03:49:17.466586 22509476222784 run_lib.py:133] step: 979500, training_loss: 4.37253e-02
I0214 03:49:17.640358 22509476222784 run_lib.py:146] step: 979500, eval_loss: 4.12463e-02
I0214 03:49:36.382205 22509476222784 run_lib.py:133] step: 979550, training_loss: 3.59336e-02
I0214 03:49:55.373783 22509476222784 run_lib.py:133] step: 979600, training_loss: 4.66573e-02
I0214 03:49:55.541045 22509476222784 run_lib.py:146] step: 979600, eval_loss: 4.40203e-02
I0214 03:50:14.461478 22509476222784 run_lib.py:133] step: 979650, training_loss: 4.17179e-02
I0214 03:50:33.420546 22509476222784 run_lib.py:133] step: 979700, training_loss: 3.33857e-02
I0214 03:50:33.585988 22509476222784 run_lib.py:146] step: 979700, eval_loss: 4.46867e-02
I0214 03:50:52.436778 22509476222784 run_lib.py:133] step: 979750, training_loss: 3.41334e-02
I0214 03:51:11.191654 22509476222784 run_lib.py:133] step: 979800, training_loss: 3.78180e-02
I0214 03:51:11.356112 22509476222784 run_lib.py:146] step: 979800, eval_loss: 3.74810e-02
I0214 03:51:30.346405 22509476222784 run_lib.py:133] step: 979850, training_loss: 3.47280e-02
I0214 03:51:49.201343 22509476222784 run_lib.py:133] step: 979900, training_loss: 4.15302e-02
I0214 03:51:49.380012 22509476222784 run_lib.py:146] step: 979900, eval_loss: 5.29276e-02
I0214 03:52:08.166177 22509476222784 run_lib.py:133] step: 979950, training_loss: 4.33762e-02
I0214 03:52:27.165730 22509476222784 run_lib.py:133] step: 980000, training_loss: 4.39749e-02
I0214 03:52:28.150009 22509476222784 run_lib.py:146] step: 980000, eval_loss: 4.58535e-02
I0214 03:52:49.704945 22509476222784 run_lib.py:133] step: 980050, training_loss: 4.86841e-02
I0214 03:53:08.518219 22509476222784 run_lib.py:133] step: 980100, training_loss: 3.98377e-02
I0214 03:53:08.704976 22509476222784 run_lib.py:146] step: 980100, eval_loss: 3.25497e-02
I0214 03:53:27.724298 22509476222784 run_lib.py:133] step: 980150, training_loss: 3.98362e-02
I0214 03:53:46.519444 22509476222784 run_lib.py:133] step: 980200, training_loss: 3.81925e-02
I0214 03:53:46.689048 22509476222784 run_lib.py:146] step: 980200, eval_loss: 3.63020e-02
I0214 03:54:05.643070 22509476222784 run_lib.py:133] step: 980250, training_loss: 3.98827e-02
I0214 03:54:24.412449 22509476222784 run_lib.py:133] step: 980300, training_loss: 4.23677e-02
I0214 03:54:24.573975 22509476222784 run_lib.py:146] step: 980300, eval_loss: 3.94434e-02
I0214 03:54:43.563660 22509476222784 run_lib.py:133] step: 980350, training_loss: 4.16319e-02
I0214 03:55:02.230572 22509476222784 run_lib.py:133] step: 980400, training_loss: 3.68639e-02
I0214 03:55:02.405004 22509476222784 run_lib.py:146] step: 980400, eval_loss: 4.94786e-02
I0214 03:55:21.355481 22509476222784 run_lib.py:133] step: 980450, training_loss: 5.37219e-02
I0214 03:55:40.167523 22509476222784 run_lib.py:133] step: 980500, training_loss: 3.59131e-02
I0214 03:55:40.334020 22509476222784 run_lib.py:146] step: 980500, eval_loss: 4.97793e-02
I0214 03:55:59.112178 22509476222784 run_lib.py:133] step: 980550, training_loss: 3.98687e-02
I0214 03:56:17.916358 22509476222784 run_lib.py:133] step: 980600, training_loss: 4.20722e-02
I0214 03:56:18.085933 22509476222784 run_lib.py:146] step: 980600, eval_loss: 2.58229e-02
I0214 03:56:37.007695 22509476222784 run_lib.py:133] step: 980650, training_loss: 4.87000e-02
I0214 03:56:55.986902 22509476222784 run_lib.py:133] step: 980700, training_loss: 3.13119e-02
I0214 03:56:56.153841 22509476222784 run_lib.py:146] step: 980700, eval_loss: 4.44228e-02
I0214 03:57:14.911819 22509476222784 run_lib.py:133] step: 980750, training_loss: 4.54953e-02
I0214 03:57:33.667742 22509476222784 run_lib.py:133] step: 980800, training_loss: 3.56105e-02
I0214 03:57:33.829926 22509476222784 run_lib.py:146] step: 980800, eval_loss: 5.22621e-02
I0214 03:57:52.859302 22509476222784 run_lib.py:133] step: 980850, training_loss: 4.21930e-02
I0214 03:58:11.580467 22509476222784 run_lib.py:133] step: 980900, training_loss: 2.94910e-02
I0214 03:58:11.761090 22509476222784 run_lib.py:146] step: 980900, eval_loss: 3.51428e-02
I0214 03:58:30.782902 22509476222784 run_lib.py:133] step: 980950, training_loss: 3.47882e-02
I0214 03:58:49.563006 22509476222784 run_lib.py:133] step: 981000, training_loss: 5.36732e-02
I0214 03:58:49.732012 22509476222784 run_lib.py:146] step: 981000, eval_loss: 4.90543e-02
I0214 03:59:08.744582 22509476222784 run_lib.py:133] step: 981050, training_loss: 3.78472e-02
I0214 03:59:27.426012 22509476222784 run_lib.py:133] step: 981100, training_loss: 4.36112e-02
I0214 03:59:27.598189 22509476222784 run_lib.py:146] step: 981100, eval_loss: 3.07897e-02
I0214 03:59:46.600123 22509476222784 run_lib.py:133] step: 981150, training_loss: 2.91844e-02
I0214 04:00:05.402073 22509476222784 run_lib.py:133] step: 981200, training_loss: 4.00507e-02
I0214 04:00:05.567249 22509476222784 run_lib.py:146] step: 981200, eval_loss: 4.50937e-02
I0214 04:00:24.448536 22509476222784 run_lib.py:133] step: 981250, training_loss: 4.24230e-02
I0214 04:00:43.396985 22509476222784 run_lib.py:133] step: 981300, training_loss: 5.22359e-02
I0214 04:00:43.587983 22509476222784 run_lib.py:146] step: 981300, eval_loss: 4.09649e-02
I0214 04:01:02.304183 22509476222784 run_lib.py:133] step: 981350, training_loss: 3.98488e-02
I0214 04:01:21.131363 22509476222784 run_lib.py:133] step: 981400, training_loss: 5.52685e-02
I0214 04:01:21.300240 22509476222784 run_lib.py:146] step: 981400, eval_loss: 4.23683e-02
I0214 04:01:40.262955 22509476222784 run_lib.py:133] step: 981450, training_loss: 4.67019e-02
I0214 04:01:59.382024 22509476222784 run_lib.py:133] step: 981500, training_loss: 4.66889e-02
I0214 04:01:59.547913 22509476222784 run_lib.py:146] step: 981500, eval_loss: 3.69344e-02
I0214 04:02:18.219235 22509476222784 run_lib.py:133] step: 981550, training_loss: 2.87905e-02
I0214 04:02:37.069462 22509476222784 run_lib.py:133] step: 981600, training_loss: 6.57066e-02
I0214 04:02:37.234873 22509476222784 run_lib.py:146] step: 981600, eval_loss: 4.32674e-02
I0214 04:02:55.969652 22509476222784 run_lib.py:133] step: 981650, training_loss: 3.69572e-02
I0214 04:03:14.942188 22509476222784 run_lib.py:133] step: 981700, training_loss: 4.81492e-02
I0214 04:03:15.107820 22509476222784 run_lib.py:146] step: 981700, eval_loss: 4.04462e-02
I0214 04:03:33.887202 22509476222784 run_lib.py:133] step: 981750, training_loss: 4.15350e-02
I0214 04:03:52.654471 22509476222784 run_lib.py:133] step: 981800, training_loss: 4.19356e-02
I0214 04:03:52.826290 22509476222784 run_lib.py:146] step: 981800, eval_loss: 3.87623e-02
I0214 04:04:11.649957 22509476222784 run_lib.py:133] step: 981850, training_loss: 4.51623e-02
I0214 04:04:30.571200 22509476222784 run_lib.py:133] step: 981900, training_loss: 4.03556e-02
I0214 04:04:30.739145 22509476222784 run_lib.py:146] step: 981900, eval_loss: 4.48789e-02
I0214 04:04:49.586432 22509476222784 run_lib.py:133] step: 981950, training_loss: 3.98664e-02
I0214 04:05:08.417653 22509476222784 run_lib.py:133] step: 982000, training_loss: 4.98493e-02
I0214 04:05:08.583079 22509476222784 run_lib.py:146] step: 982000, eval_loss: 3.93681e-02
I0214 04:05:27.258780 22509476222784 run_lib.py:133] step: 982050, training_loss: 4.93986e-02
I0214 04:05:46.104910 22509476222784 run_lib.py:133] step: 982100, training_loss: 3.90757e-02
I0214 04:05:46.271713 22509476222784 run_lib.py:146] step: 982100, eval_loss: 4.11322e-02
I0214 04:06:05.278732 22509476222784 run_lib.py:133] step: 982150, training_loss: 4.62653e-02
I0214 04:06:24.167102 22509476222784 run_lib.py:133] step: 982200, training_loss: 4.47960e-02
I0214 04:06:24.331717 22509476222784 run_lib.py:146] step: 982200, eval_loss: 4.12670e-02
I0214 04:06:43.122714 22509476222784 run_lib.py:133] step: 982250, training_loss: 3.92766e-02
I0214 04:07:01.862149 22509476222784 run_lib.py:133] step: 982300, training_loss: 3.26928e-02
I0214 04:07:02.028828 22509476222784 run_lib.py:146] step: 982300, eval_loss: 4.70005e-02
I0214 04:07:21.094716 22509476222784 run_lib.py:133] step: 982350, training_loss: 4.24703e-02
I0214 04:07:39.909396 22509476222784 run_lib.py:133] step: 982400, training_loss: 4.39336e-02
I0214 04:07:40.078969 22509476222784 run_lib.py:146] step: 982400, eval_loss: 4.73124e-02
I0214 04:07:59.176938 22509476222784 run_lib.py:133] step: 982450, training_loss: 5.02464e-02
I0214 04:08:17.951929 22509476222784 run_lib.py:133] step: 982500, training_loss: 4.60955e-02
I0214 04:08:18.118928 22509476222784 run_lib.py:146] step: 982500, eval_loss: 5.02904e-02
I0214 04:08:37.140818 22509476222784 run_lib.py:133] step: 982550, training_loss: 4.67853e-02
I0214 04:08:55.903866 22509476222784 run_lib.py:133] step: 982600, training_loss: 3.83431e-02
I0214 04:08:56.069967 22509476222784 run_lib.py:146] step: 982600, eval_loss: 3.65298e-02
I0214 04:09:14.947204 22509476222784 run_lib.py:133] step: 982650, training_loss: 5.29842e-02
I0214 04:09:34.000114 22509476222784 run_lib.py:133] step: 982700, training_loss: 3.16143e-02
I0214 04:09:34.173985 22509476222784 run_lib.py:146] step: 982700, eval_loss: 3.58261e-02
I0214 04:09:52.972286 22509476222784 run_lib.py:133] step: 982750, training_loss: 4.62547e-02
I0214 04:10:11.964572 22509476222784 run_lib.py:133] step: 982800, training_loss: 3.61089e-02
I0214 04:10:12.157154 22509476222784 run_lib.py:146] step: 982800, eval_loss: 4.42536e-02
I0214 04:10:30.926079 22509476222784 run_lib.py:133] step: 982850, training_loss: 3.75235e-02
I0214 04:10:49.835052 22509476222784 run_lib.py:133] step: 982900, training_loss: 4.17807e-02
I0214 04:10:50.015333 22509476222784 run_lib.py:146] step: 982900, eval_loss: 3.81844e-02
I0214 04:11:09.024735 22509476222784 run_lib.py:133] step: 982950, training_loss: 4.16192e-02
I0214 04:11:27.933741 22509476222784 run_lib.py:133] step: 983000, training_loss: 2.91079e-02
I0214 04:11:28.100230 22509476222784 run_lib.py:146] step: 983000, eval_loss: 5.10622e-02
I0214 04:11:46.883294 22509476222784 run_lib.py:133] step: 983050, training_loss: 3.51395e-02
I0214 04:12:05.851439 22509476222784 run_lib.py:133] step: 983100, training_loss: 3.79252e-02
I0214 04:12:06.023230 22509476222784 run_lib.py:146] step: 983100, eval_loss: 4.66862e-02
I0214 04:12:24.820910 22509476222784 run_lib.py:133] step: 983150, training_loss: 5.44608e-02
I0214 04:12:43.642363 22509476222784 run_lib.py:133] step: 983200, training_loss: 4.29595e-02
I0214 04:12:43.818978 22509476222784 run_lib.py:146] step: 983200, eval_loss: 3.95673e-02
I0214 04:13:02.838311 22509476222784 run_lib.py:133] step: 983250, training_loss: 4.49967e-02
I0214 04:13:21.578633 22509476222784 run_lib.py:133] step: 983300, training_loss: 3.62721e-02
I0214 04:13:21.751548 22509476222784 run_lib.py:146] step: 983300, eval_loss: 4.23787e-02
I0214 04:13:40.552927 22509476222784 run_lib.py:133] step: 983350, training_loss: 3.86514e-02
I0214 04:13:59.294078 22509476222784 run_lib.py:133] step: 983400, training_loss: 3.75711e-02
I0214 04:13:59.467970 22509476222784 run_lib.py:146] step: 983400, eval_loss: 3.98669e-02
I0214 04:14:18.420916 22509476222784 run_lib.py:133] step: 983450, training_loss: 3.85735e-02
I0214 04:14:37.461638 22509476222784 run_lib.py:133] step: 983500, training_loss: 4.69389e-02
I0214 04:14:37.629271 22509476222784 run_lib.py:146] step: 983500, eval_loss: 5.48559e-02
I0214 04:14:56.383666 22509476222784 run_lib.py:133] step: 983550, training_loss: 4.55359e-02
I0214 04:15:15.255122 22509476222784 run_lib.py:133] step: 983600, training_loss: 4.46755e-02
I0214 04:15:15.418960 22509476222784 run_lib.py:146] step: 983600, eval_loss: 3.01689e-02
I0214 04:15:34.347506 22509476222784 run_lib.py:133] step: 983650, training_loss: 4.46850e-02
I0214 04:15:53.137511 22509476222784 run_lib.py:133] step: 983700, training_loss: 4.62735e-02
I0214 04:15:53.312565 22509476222784 run_lib.py:146] step: 983700, eval_loss: 4.48904e-02
I0214 04:16:12.344365 22509476222784 run_lib.py:133] step: 983750, training_loss: 3.86073e-02
I0214 04:16:31.106695 22509476222784 run_lib.py:133] step: 983800, training_loss: 4.40095e-02
I0214 04:16:31.277695 22509476222784 run_lib.py:146] step: 983800, eval_loss: 5.41415e-02
I0214 04:16:50.279903 22509476222784 run_lib.py:133] step: 983850, training_loss: 4.52100e-02
I0214 04:17:09.026533 22509476222784 run_lib.py:133] step: 983900, training_loss: 4.25663e-02
I0214 04:17:09.193042 22509476222784 run_lib.py:146] step: 983900, eval_loss: 3.79436e-02
I0214 04:17:28.189464 22509476222784 run_lib.py:133] step: 983950, training_loss: 4.86314e-02
I0214 04:17:46.999131 22509476222784 run_lib.py:133] step: 984000, training_loss: 3.99058e-02
I0214 04:17:47.170507 22509476222784 run_lib.py:146] step: 984000, eval_loss: 3.97512e-02
I0214 04:18:06.024566 22509476222784 run_lib.py:133] step: 984050, training_loss: 3.56452e-02
I0214 04:18:24.966104 22509476222784 run_lib.py:133] step: 984100, training_loss: 3.80704e-02
I0214 04:18:25.132977 22509476222784 run_lib.py:146] step: 984100, eval_loss: 5.07085e-02
I0214 04:18:43.863662 22509476222784 run_lib.py:133] step: 984150, training_loss: 3.90154e-02
I0214 04:19:02.665662 22509476222784 run_lib.py:133] step: 984200, training_loss: 4.26410e-02
I0214 04:19:02.842165 22509476222784 run_lib.py:146] step: 984200, eval_loss: 3.48401e-02
I0214 04:19:21.806388 22509476222784 run_lib.py:133] step: 984250, training_loss: 3.44508e-02
I0214 04:19:40.693065 22509476222784 run_lib.py:133] step: 984300, training_loss: 4.41543e-02
I0214 04:19:40.862088 22509476222784 run_lib.py:146] step: 984300, eval_loss: 4.05820e-02
I0214 04:19:59.751552 22509476222784 run_lib.py:133] step: 984350, training_loss: 3.55906e-02
I0214 04:20:18.514587 22509476222784 run_lib.py:133] step: 984400, training_loss: 4.09892e-02
I0214 04:20:18.686356 22509476222784 run_lib.py:146] step: 984400, eval_loss: 4.57811e-02
I0214 04:20:37.434200 22509476222784 run_lib.py:133] step: 984450, training_loss: 4.51804e-02
I0214 04:20:56.357513 22509476222784 run_lib.py:133] step: 984500, training_loss: 3.98113e-02
I0214 04:20:56.528266 22509476222784 run_lib.py:146] step: 984500, eval_loss: 3.09105e-02
I0214 04:21:15.511455 22509476222784 run_lib.py:133] step: 984550, training_loss: 4.05547e-02
I0214 04:21:34.245816 22509476222784 run_lib.py:133] step: 984600, training_loss: 4.11640e-02
I0214 04:21:34.410131 22509476222784 run_lib.py:146] step: 984600, eval_loss: 5.10824e-02
I0214 04:21:53.271948 22509476222784 run_lib.py:133] step: 984650, training_loss: 4.57758e-02
I0214 04:22:12.217324 22509476222784 run_lib.py:133] step: 984700, training_loss: 3.61574e-02
I0214 04:22:12.385560 22509476222784 run_lib.py:146] step: 984700, eval_loss: 4.19256e-02
I0214 04:22:31.292698 22509476222784 run_lib.py:133] step: 984750, training_loss: 2.85371e-02
I0214 04:22:50.204575 22509476222784 run_lib.py:133] step: 984800, training_loss: 3.57722e-02
I0214 04:22:50.372485 22509476222784 run_lib.py:146] step: 984800, eval_loss: 3.56242e-02
I0214 04:23:09.149260 22509476222784 run_lib.py:133] step: 984850, training_loss: 5.30673e-02
I0214 04:23:27.996150 22509476222784 run_lib.py:133] step: 984900, training_loss: 4.86171e-02
I0214 04:23:28.163025 22509476222784 run_lib.py:146] step: 984900, eval_loss: 4.78821e-02
I0214 04:23:47.032887 22509476222784 run_lib.py:133] step: 984950, training_loss: 4.06263e-02
I0214 04:24:05.990596 22509476222784 run_lib.py:133] step: 985000, training_loss: 4.13582e-02
I0214 04:24:06.160737 22509476222784 run_lib.py:146] step: 985000, eval_loss: 4.51166e-02
I0214 04:24:24.973733 22509476222784 run_lib.py:133] step: 985050, training_loss: 4.06680e-02
I0214 04:24:43.791269 22509476222784 run_lib.py:133] step: 985100, training_loss: 4.18958e-02
I0214 04:24:43.970550 22509476222784 run_lib.py:146] step: 985100, eval_loss: 3.94164e-02
I0214 04:25:02.929576 22509476222784 run_lib.py:133] step: 985150, training_loss: 3.26062e-02
I0214 04:25:21.670157 22509476222784 run_lib.py:133] step: 985200, training_loss: 4.78683e-02
I0214 04:25:21.842583 22509476222784 run_lib.py:146] step: 985200, eval_loss: 3.85314e-02
I0214 04:25:40.815208 22509476222784 run_lib.py:133] step: 985250, training_loss: 4.93010e-02
I0214 04:25:59.582896 22509476222784 run_lib.py:133] step: 985300, training_loss: 4.03571e-02
I0214 04:25:59.749992 22509476222784 run_lib.py:146] step: 985300, eval_loss: 3.81986e-02
I0214 04:26:18.761182 22509476222784 run_lib.py:133] step: 985350, training_loss: 3.98501e-02
I0214 04:26:37.479378 22509476222784 run_lib.py:133] step: 985400, training_loss: 3.12693e-02
I0214 04:26:37.644905 22509476222784 run_lib.py:146] step: 985400, eval_loss: 4.09058e-02
I0214 04:26:56.464461 22509476222784 run_lib.py:133] step: 985450, training_loss: 4.82987e-02
I0214 04:27:15.428808 22509476222784 run_lib.py:133] step: 985500, training_loss: 3.72281e-02
I0214 04:27:15.594347 22509476222784 run_lib.py:146] step: 985500, eval_loss: 5.01036e-02
I0214 04:27:34.427328 22509476222784 run_lib.py:133] step: 985550, training_loss: 4.05702e-02
I0214 04:27:53.490818 22509476222784 run_lib.py:133] step: 985600, training_loss: 5.41190e-02
I0214 04:27:53.655996 22509476222784 run_lib.py:146] step: 985600, eval_loss: 4.12334e-02
I0214 04:28:12.405353 22509476222784 run_lib.py:133] step: 985650, training_loss: 4.19147e-02
I0214 04:28:31.247694 22509476222784 run_lib.py:133] step: 985700, training_loss: 3.97193e-02
I0214 04:28:31.416318 22509476222784 run_lib.py:146] step: 985700, eval_loss: 4.18628e-02
I0214 04:28:50.364822 22509476222784 run_lib.py:133] step: 985750, training_loss: 4.33448e-02
I0214 04:29:09.225733 22509476222784 run_lib.py:133] step: 985800, training_loss: 4.02744e-02
I0214 04:29:09.392114 22509476222784 run_lib.py:146] step: 985800, eval_loss: 4.65311e-02
I0214 04:29:28.199883 22509476222784 run_lib.py:133] step: 985850, training_loss: 4.59395e-02
I0214 04:29:47.140247 22509476222784 run_lib.py:133] step: 985900, training_loss: 3.69132e-02
I0214 04:29:47.307924 22509476222784 run_lib.py:146] step: 985900, eval_loss: 4.29064e-02
I0214 04:30:06.188765 22509476222784 run_lib.py:133] step: 985950, training_loss: 5.28185e-02
I0214 04:30:24.969269 22509476222784 run_lib.py:133] step: 986000, training_loss: 3.54801e-02
I0214 04:30:25.289073 22509476222784 run_lib.py:146] step: 986000, eval_loss: 4.67518e-02
I0214 04:30:44.163043 22509476222784 run_lib.py:133] step: 986050, training_loss: 4.70887e-02
I0214 04:31:02.896098 22509476222784 run_lib.py:133] step: 986100, training_loss: 4.28740e-02
I0214 04:31:03.062114 22509476222784 run_lib.py:146] step: 986100, eval_loss: 4.84749e-02
I0214 04:31:21.819024 22509476222784 run_lib.py:133] step: 986150, training_loss: 4.01165e-02
I0214 04:31:40.566159 22509476222784 run_lib.py:133] step: 986200, training_loss: 4.72732e-02
I0214 04:31:40.733911 22509476222784 run_lib.py:146] step: 986200, eval_loss: 3.23171e-02
I0214 04:31:59.724250 22509476222784 run_lib.py:133] step: 986250, training_loss: 4.24582e-02
I0214 04:32:18.720461 22509476222784 run_lib.py:133] step: 986300, training_loss: 4.66355e-02
I0214 04:32:18.888246 22509476222784 run_lib.py:146] step: 986300, eval_loss: 5.34736e-02
I0214 04:32:37.660541 22509476222784 run_lib.py:133] step: 986350, training_loss: 4.11684e-02
I0214 04:32:56.534528 22509476222784 run_lib.py:133] step: 986400, training_loss: 4.48412e-02
I0214 04:32:56.702985 22509476222784 run_lib.py:146] step: 986400, eval_loss: 4.42407e-02
I0214 04:33:15.637302 22509476222784 run_lib.py:133] step: 986450, training_loss: 4.21345e-02
I0214 04:33:34.621969 22509476222784 run_lib.py:133] step: 986500, training_loss: 3.90907e-02
I0214 04:33:34.795573 22509476222784 run_lib.py:146] step: 986500, eval_loss: 4.72037e-02
I0214 04:33:53.617613 22509476222784 run_lib.py:133] step: 986550, training_loss: 3.75156e-02
I0214 04:34:12.420840 22509476222784 run_lib.py:133] step: 986600, training_loss: 3.30955e-02
I0214 04:34:12.589454 22509476222784 run_lib.py:146] step: 986600, eval_loss: 3.58148e-02
I0214 04:34:31.616983 22509476222784 run_lib.py:133] step: 986650, training_loss: 5.25982e-02
I0214 04:34:50.357266 22509476222784 run_lib.py:133] step: 986700, training_loss: 4.66862e-02
I0214 04:34:50.524271 22509476222784 run_lib.py:146] step: 986700, eval_loss: 4.42946e-02
I0214 04:35:09.552527 22509476222784 run_lib.py:133] step: 986750, training_loss: 4.04231e-02
I0214 04:35:28.331892 22509476222784 run_lib.py:133] step: 986800, training_loss: 3.78769e-02
I0214 04:35:28.499146 22509476222784 run_lib.py:146] step: 986800, eval_loss: 4.54311e-02
I0214 04:35:47.583465 22509476222784 run_lib.py:133] step: 986850, training_loss: 4.75955e-02
I0214 04:36:06.324820 22509476222784 run_lib.py:133] step: 986900, training_loss: 4.34432e-02
I0214 04:36:06.488873 22509476222784 run_lib.py:146] step: 986900, eval_loss: 4.64912e-02
I0214 04:36:25.256483 22509476222784 run_lib.py:133] step: 986950, training_loss: 4.03083e-02
I0214 04:36:44.284808 22509476222784 run_lib.py:133] step: 987000, training_loss: 3.78075e-02
I0214 04:36:44.445636 22509476222784 run_lib.py:146] step: 987000, eval_loss: 4.22977e-02
I0214 04:37:03.166926 22509476222784 run_lib.py:133] step: 987050, training_loss: 4.64567e-02
I0214 04:37:22.160436 22509476222784 run_lib.py:133] step: 987100, training_loss: 4.71864e-02
I0214 04:37:22.346923 22509476222784 run_lib.py:146] step: 987100, eval_loss: 4.52794e-02
I0214 04:37:41.150794 22509476222784 run_lib.py:133] step: 987150, training_loss: 3.79853e-02
I0214 04:37:59.900863 22509476222784 run_lib.py:133] step: 987200, training_loss: 3.78175e-02
I0214 04:38:00.083077 22509476222784 run_lib.py:146] step: 987200, eval_loss: 5.41624e-02
I0214 04:38:19.109662 22509476222784 run_lib.py:133] step: 987250, training_loss: 3.46708e-02
I0214 04:38:37.796500 22509476222784 run_lib.py:133] step: 987300, training_loss: 5.35836e-02
I0214 04:38:37.972750 22509476222784 run_lib.py:146] step: 987300, eval_loss: 4.18207e-02
I0214 04:38:56.857435 22509476222784 run_lib.py:133] step: 987350, training_loss: 4.96990e-02
I0214 04:39:15.621492 22509476222784 run_lib.py:133] step: 987400, training_loss: 3.69764e-02
I0214 04:39:15.784738 22509476222784 run_lib.py:146] step: 987400, eval_loss: 4.61632e-02
I0214 04:39:34.902806 22509476222784 run_lib.py:133] step: 987450, training_loss: 3.31200e-02
I0214 04:39:53.665889 22509476222784 run_lib.py:133] step: 987500, training_loss: 4.95947e-02
I0214 04:39:53.832037 22509476222784 run_lib.py:146] step: 987500, eval_loss: 3.44480e-02
I0214 04:40:12.595295 22509476222784 run_lib.py:133] step: 987550, training_loss: 4.04987e-02
I0214 04:40:31.361570 22509476222784 run_lib.py:133] step: 987600, training_loss: 3.77304e-02
I0214 04:40:31.545053 22509476222784 run_lib.py:146] step: 987600, eval_loss: 5.61530e-02
I0214 04:40:50.352372 22509476222784 run_lib.py:133] step: 987650, training_loss: 3.93344e-02
I0214 04:41:09.207170 22509476222784 run_lib.py:133] step: 987700, training_loss: 4.04203e-02
I0214 04:41:09.374169 22509476222784 run_lib.py:146] step: 987700, eval_loss: 4.15909e-02
I0214 04:41:28.270442 22509476222784 run_lib.py:133] step: 987750, training_loss: 4.61962e-02
I0214 04:41:47.173247 22509476222784 run_lib.py:133] step: 987800, training_loss: 4.65573e-02
I0214 04:41:47.337908 22509476222784 run_lib.py:146] step: 987800, eval_loss: 4.29018e-02
I0214 04:42:06.070031 22509476222784 run_lib.py:133] step: 987850, training_loss: 4.90416e-02
I0214 04:42:24.953203 22509476222784 run_lib.py:133] step: 987900, training_loss: 5.18614e-02
I0214 04:42:25.126195 22509476222784 run_lib.py:146] step: 987900, eval_loss: 4.31996e-02
I0214 04:42:44.038964 22509476222784 run_lib.py:133] step: 987950, training_loss: 4.93716e-02
I0214 04:43:02.816462 22509476222784 run_lib.py:133] step: 988000, training_loss: 4.10528e-02
I0214 04:43:02.983025 22509476222784 run_lib.py:146] step: 988000, eval_loss: 2.91530e-02
I0214 04:43:21.897195 22509476222784 run_lib.py:133] step: 988050, training_loss: 4.05789e-02
I0214 04:43:40.724942 22509476222784 run_lib.py:133] step: 988100, training_loss: 3.14197e-02
I0214 04:43:40.903936 22509476222784 run_lib.py:146] step: 988100, eval_loss: 3.95920e-02
I0214 04:44:00.006948 22509476222784 run_lib.py:133] step: 988150, training_loss: 2.45010e-02
I0214 04:44:18.777059 22509476222784 run_lib.py:133] step: 988200, training_loss: 3.20746e-02
I0214 04:44:18.943231 22509476222784 run_lib.py:146] step: 988200, eval_loss: 3.25723e-02
I0214 04:44:37.998954 22509476222784 run_lib.py:133] step: 988250, training_loss: 3.69948e-02
I0214 04:44:56.732695 22509476222784 run_lib.py:133] step: 988300, training_loss: 5.03847e-02
I0214 04:44:56.898222 22509476222784 run_lib.py:146] step: 988300, eval_loss: 3.99306e-02
I0214 04:45:15.861492 22509476222784 run_lib.py:133] step: 988350, training_loss: 4.53029e-02
I0214 04:45:34.825496 22509476222784 run_lib.py:133] step: 988400, training_loss: 3.94389e-02
I0214 04:45:34.992093 22509476222784 run_lib.py:146] step: 988400, eval_loss: 3.28259e-02
I0214 04:45:53.861417 22509476222784 run_lib.py:133] step: 988450, training_loss: 4.05674e-02
I0214 04:46:12.623611 22509476222784 run_lib.py:133] step: 988500, training_loss: 4.72721e-02
I0214 04:46:12.791202 22509476222784 run_lib.py:146] step: 988500, eval_loss: 5.01369e-02
I0214 04:46:31.659808 22509476222784 run_lib.py:133] step: 988550, training_loss: 3.92572e-02
I0214 04:46:50.772228 22509476222784 run_lib.py:133] step: 988600, training_loss: 4.08998e-02
I0214 04:46:50.937990 22509476222784 run_lib.py:146] step: 988600, eval_loss: 4.41294e-02
I0214 04:47:09.663594 22509476222784 run_lib.py:133] step: 988650, training_loss: 4.25250e-02
I0214 04:47:28.469362 22509476222784 run_lib.py:133] step: 988700, training_loss: 4.28779e-02
I0214 04:47:28.635842 22509476222784 run_lib.py:146] step: 988700, eval_loss: 3.55392e-02
I0214 04:47:47.333346 22509476222784 run_lib.py:133] step: 988750, training_loss: 3.11381e-02
I0214 04:48:06.260255 22509476222784 run_lib.py:133] step: 988800, training_loss: 4.77462e-02
I0214 04:48:06.425054 22509476222784 run_lib.py:146] step: 988800, eval_loss: 4.37843e-02
I0214 04:48:25.201519 22509476222784 run_lib.py:133] step: 988850, training_loss: 5.76979e-02
I0214 04:48:44.082399 22509476222784 run_lib.py:133] step: 988900, training_loss: 3.08722e-02
I0214 04:48:44.251251 22509476222784 run_lib.py:146] step: 988900, eval_loss: 4.54545e-02
I0214 04:49:03.032718 22509476222784 run_lib.py:133] step: 988950, training_loss: 4.83917e-02
I0214 04:49:22.026751 22509476222784 run_lib.py:133] step: 989000, training_loss: 3.36629e-02
I0214 04:49:22.196114 22509476222784 run_lib.py:146] step: 989000, eval_loss: 4.17408e-02
I0214 04:49:41.050210 22509476222784 run_lib.py:133] step: 989050, training_loss: 4.86256e-02
I0214 04:49:59.846722 22509476222784 run_lib.py:133] step: 989100, training_loss: 4.63010e-02
I0214 04:50:00.020480 22509476222784 run_lib.py:146] step: 989100, eval_loss: 3.62177e-02
I0214 04:50:18.930520 22509476222784 run_lib.py:133] step: 989150, training_loss: 3.98396e-02
I0214 04:50:37.661211 22509476222784 run_lib.py:133] step: 989200, training_loss: 3.37441e-02
I0214 04:50:37.826370 22509476222784 run_lib.py:146] step: 989200, eval_loss: 4.61054e-02
I0214 04:50:56.924781 22509476222784 run_lib.py:133] step: 989250, training_loss: 3.99048e-02
I0214 04:51:15.773949 22509476222784 run_lib.py:133] step: 989300, training_loss: 4.17098e-02
I0214 04:51:15.936082 22509476222784 run_lib.py:146] step: 989300, eval_loss: 4.79048e-02
I0214 04:51:34.829939 22509476222784 run_lib.py:133] step: 989350, training_loss: 5.47261e-02
I0214 04:51:53.587599 22509476222784 run_lib.py:133] step: 989400, training_loss: 4.64518e-02
I0214 04:51:53.764150 22509476222784 run_lib.py:146] step: 989400, eval_loss: 3.43894e-02
I0214 04:52:12.791407 22509476222784 run_lib.py:133] step: 989450, training_loss: 3.59118e-02
I0214 04:52:31.665716 22509476222784 run_lib.py:133] step: 989500, training_loss: 4.89770e-02
I0214 04:52:31.832095 22509476222784 run_lib.py:146] step: 989500, eval_loss: 4.51775e-02
I0214 04:52:50.750440 22509476222784 run_lib.py:133] step: 989550, training_loss: 4.18922e-02
I0214 04:53:09.619924 22509476222784 run_lib.py:133] step: 989600, training_loss: 5.77349e-02
I0214 04:53:09.790948 22509476222784 run_lib.py:146] step: 989600, eval_loss: 3.42786e-02
I0214 04:53:28.737633 22509476222784 run_lib.py:133] step: 989650, training_loss: 3.13087e-02
I0214 04:53:47.596760 22509476222784 run_lib.py:133] step: 989700, training_loss: 3.87003e-02
I0214 04:53:47.773927 22509476222784 run_lib.py:146] step: 989700, eval_loss: 5.82893e-02
I0214 04:54:06.585756 22509476222784 run_lib.py:133] step: 989750, training_loss: 4.45787e-02
I0214 04:54:25.663995 22509476222784 run_lib.py:133] step: 989800, training_loss: 4.50210e-02
I0214 04:54:25.828190 22509476222784 run_lib.py:146] step: 989800, eval_loss: 3.87660e-02
I0214 04:54:44.630549 22509476222784 run_lib.py:133] step: 989850, training_loss: 4.83912e-02
I0214 04:55:03.603075 22509476222784 run_lib.py:133] step: 989900, training_loss: 3.75240e-02
I0214 04:55:03.775191 22509476222784 run_lib.py:146] step: 989900, eval_loss: 3.66917e-02
I0214 04:55:22.527419 22509476222784 run_lib.py:133] step: 989950, training_loss: 4.31190e-02
I0214 04:55:41.338513 22509476222784 run_lib.py:133] step: 990000, training_loss: 4.98251e-02
I0214 04:55:42.149512 22509476222784 run_lib.py:146] step: 990000, eval_loss: 4.25959e-02
I0214 04:56:03.675283 22509476222784 run_lib.py:133] step: 990050, training_loss: 3.37542e-02
I0214 04:56:22.589345 22509476222784 run_lib.py:133] step: 990100, training_loss: 5.49184e-02
I0214 04:56:22.765022 22509476222784 run_lib.py:146] step: 990100, eval_loss: 3.23171e-02
I0214 04:56:41.598239 22509476222784 run_lib.py:133] step: 990150, training_loss: 5.66285e-02
I0214 04:57:00.541193 22509476222784 run_lib.py:133] step: 990200, training_loss: 3.62919e-02
I0214 04:57:00.708910 22509476222784 run_lib.py:146] step: 990200, eval_loss: 3.07637e-02
I0214 04:57:19.511649 22509476222784 run_lib.py:133] step: 990250, training_loss: 4.51637e-02
I0214 04:57:38.293942 22509476222784 run_lib.py:133] step: 990300, training_loss: 4.90881e-02
I0214 04:57:38.460199 22509476222784 run_lib.py:146] step: 990300, eval_loss: 4.75768e-02
I0214 04:57:57.530803 22509476222784 run_lib.py:133] step: 990350, training_loss: 3.67970e-02
I0214 04:58:16.344429 22509476222784 run_lib.py:133] step: 990400, training_loss: 5.19278e-02
I0214 04:58:16.507953 22509476222784 run_lib.py:146] step: 990400, eval_loss: 4.64512e-02
I0214 04:58:35.415698 22509476222784 run_lib.py:133] step: 990450, training_loss: 4.10950e-02
I0214 04:58:54.256809 22509476222784 run_lib.py:133] step: 990500, training_loss: 3.72379e-02
I0214 04:58:54.434967 22509476222784 run_lib.py:146] step: 990500, eval_loss: 3.92789e-02
I0214 04:59:13.191214 22509476222784 run_lib.py:133] step: 990550, training_loss: 4.79719e-02
I0214 04:59:32.261357 22509476222784 run_lib.py:133] step: 990600, training_loss: 5.57438e-02
I0214 04:59:32.427267 22509476222784 run_lib.py:146] step: 990600, eval_loss: 4.05764e-02
I0214 04:59:51.177089 22509476222784 run_lib.py:133] step: 990650, training_loss: 3.73593e-02
I0214 05:00:10.011191 22509476222784 run_lib.py:133] step: 990700, training_loss: 4.13803e-02
I0214 05:00:10.180774 22509476222784 run_lib.py:146] step: 990700, eval_loss: 3.48437e-02
I0214 05:00:28.950535 22509476222784 run_lib.py:133] step: 990750, training_loss: 4.94197e-02
I0214 05:00:47.930059 22509476222784 run_lib.py:133] step: 990800, training_loss: 3.68148e-02
I0214 05:00:48.095459 22509476222784 run_lib.py:146] step: 990800, eval_loss: 4.57457e-02
I0214 05:01:06.994258 22509476222784 run_lib.py:133] step: 990850, training_loss: 3.72253e-02
I0214 05:01:25.848314 22509476222784 run_lib.py:133] step: 990900, training_loss: 3.52896e-02
I0214 05:01:26.013921 22509476222784 run_lib.py:146] step: 990900, eval_loss: 3.29371e-02
I0214 05:01:44.880557 22509476222784 run_lib.py:133] step: 990950, training_loss: 3.68916e-02
I0214 05:02:03.631273 22509476222784 run_lib.py:133] step: 991000, training_loss: 5.19273e-02
I0214 05:02:03.807495 22509476222784 run_lib.py:146] step: 991000, eval_loss: 4.83932e-02
I0214 05:02:22.755411 22509476222784 run_lib.py:133] step: 991050, training_loss: 3.75614e-02
I0214 05:02:41.680243 22509476222784 run_lib.py:133] step: 991100, training_loss: 3.44806e-02
I0214 05:02:41.846109 22509476222784 run_lib.py:146] step: 991100, eval_loss: 5.21735e-02
I0214 05:03:00.651163 22509476222784 run_lib.py:133] step: 991150, training_loss: 4.58210e-02
I0214 05:03:19.428606 22509476222784 run_lib.py:133] step: 991200, training_loss: 4.05730e-02
I0214 05:03:19.594918 22509476222784 run_lib.py:146] step: 991200, eval_loss: 6.06772e-02
I0214 05:03:38.517787 22509476222784 run_lib.py:133] step: 991250, training_loss: 3.51046e-02
I0214 05:03:57.345715 22509476222784 run_lib.py:133] step: 991300, training_loss: 4.70177e-02
I0214 05:03:57.504791 22509476222784 run_lib.py:146] step: 991300, eval_loss: 3.55182e-02
I0214 05:04:16.423787 22509476222784 run_lib.py:133] step: 991350, training_loss: 4.65074e-02
I0214 05:04:35.307220 22509476222784 run_lib.py:133] step: 991400, training_loss: 3.89602e-02
I0214 05:04:35.483259 22509476222784 run_lib.py:146] step: 991400, eval_loss: 4.09857e-02
I0214 05:04:54.497780 22509476222784 run_lib.py:133] step: 991450, training_loss: 3.92773e-02
I0214 05:05:13.413616 22509476222784 run_lib.py:133] step: 991500, training_loss: 3.84075e-02
I0214 05:05:13.581069 22509476222784 run_lib.py:146] step: 991500, eval_loss: 3.82175e-02
I0214 05:05:32.360339 22509476222784 run_lib.py:133] step: 991550, training_loss: 4.02980e-02
I0214 05:05:51.305344 22509476222784 run_lib.py:133] step: 991600, training_loss: 3.90566e-02
I0214 05:05:51.478795 22509476222784 run_lib.py:146] step: 991600, eval_loss: 3.53830e-02
I0214 05:06:10.259368 22509476222784 run_lib.py:133] step: 991650, training_loss: 3.67078e-02
I0214 05:06:29.219606 22509476222784 run_lib.py:133] step: 991700, training_loss: 4.29288e-02
I0214 05:06:29.388802 22509476222784 run_lib.py:146] step: 991700, eval_loss: 4.47602e-02
I0214 05:06:48.319828 22509476222784 run_lib.py:133] step: 991750, training_loss: 3.75359e-02
I0214 05:07:07.065861 22509476222784 run_lib.py:133] step: 991800, training_loss: 5.21826e-02
I0214 05:07:07.234897 22509476222784 run_lib.py:146] step: 991800, eval_loss: 3.91616e-02
I0214 05:07:26.278905 22509476222784 run_lib.py:133] step: 991850, training_loss: 4.59288e-02
I0214 05:07:44.965279 22509476222784 run_lib.py:133] step: 991900, training_loss: 3.87289e-02
I0214 05:07:45.134282 22509476222784 run_lib.py:146] step: 991900, eval_loss: 3.69140e-02
I0214 05:08:04.032486 22509476222784 run_lib.py:133] step: 991950, training_loss: 5.94231e-02
I0214 05:08:23.037025 22509476222784 run_lib.py:133] step: 992000, training_loss: 4.13788e-02
I0214 05:08:23.202930 22509476222784 run_lib.py:146] step: 992000, eval_loss: 5.13062e-02
I0214 05:08:42.066304 22509476222784 run_lib.py:133] step: 992050, training_loss: 3.77298e-02
I0214 05:09:00.831351 22509476222784 run_lib.py:133] step: 992100, training_loss: 3.81043e-02
I0214 05:09:00.998167 22509476222784 run_lib.py:146] step: 992100, eval_loss: 4.53556e-02
I0214 05:09:19.859863 22509476222784 run_lib.py:133] step: 992150, training_loss: 4.67018e-02
I0214 05:09:38.672061 22509476222784 run_lib.py:133] step: 992200, training_loss: 3.64023e-02
I0214 05:09:38.846403 22509476222784 run_lib.py:146] step: 992200, eval_loss: 4.13152e-02
I0214 05:09:57.609099 22509476222784 run_lib.py:133] step: 992250, training_loss: 4.37486e-02
I0214 05:10:16.500793 22509476222784 run_lib.py:133] step: 992300, training_loss: 2.88123e-02
I0214 05:10:16.664031 22509476222784 run_lib.py:146] step: 992300, eval_loss: 3.52346e-02
I0214 05:10:35.570575 22509476222784 run_lib.py:133] step: 992350, training_loss: 3.62511e-02
I0214 05:10:54.513685 22509476222784 run_lib.py:133] step: 992400, training_loss: 3.91046e-02
I0214 05:10:54.682352 22509476222784 run_lib.py:146] step: 992400, eval_loss: 4.17116e-02
I0214 05:11:13.466447 22509476222784 run_lib.py:133] step: 992450, training_loss: 3.50810e-02
I0214 05:11:32.357731 22509476222784 run_lib.py:133] step: 992500, training_loss: 3.73860e-02
I0214 05:11:32.524204 22509476222784 run_lib.py:146] step: 992500, eval_loss: 4.49794e-02
I0214 05:11:51.527549 22509476222784 run_lib.py:133] step: 992550, training_loss: 3.06161e-02
I0214 05:12:10.273720 22509476222784 run_lib.py:133] step: 992600, training_loss: 3.89893e-02
I0214 05:12:10.444752 22509476222784 run_lib.py:146] step: 992600, eval_loss: 4.42040e-02
I0214 05:12:29.405441 22509476222784 run_lib.py:133] step: 992650, training_loss: 3.31486e-02
I0214 05:12:48.163825 22509476222784 run_lib.py:133] step: 992700, training_loss: 4.43135e-02
I0214 05:12:48.338405 22509476222784 run_lib.py:146] step: 992700, eval_loss: 5.27227e-02
I0214 05:13:07.433992 22509476222784 run_lib.py:133] step: 992750, training_loss: 4.80855e-02
I0214 05:13:26.202546 22509476222784 run_lib.py:133] step: 992800, training_loss: 4.75267e-02
I0214 05:13:26.369946 22509476222784 run_lib.py:146] step: 992800, eval_loss: 4.96750e-02
I0214 05:13:45.370825 22509476222784 run_lib.py:133] step: 992850, training_loss: 4.20363e-02
I0214 05:14:04.134700 22509476222784 run_lib.py:133] step: 992900, training_loss: 3.49091e-02
I0214 05:14:04.302127 22509476222784 run_lib.py:146] step: 992900, eval_loss: 2.88839e-02
I0214 05:14:23.189481 22509476222784 run_lib.py:133] step: 992950, training_loss: 4.67741e-02
I0214 05:14:42.216558 22509476222784 run_lib.py:133] step: 993000, training_loss: 3.94471e-02
I0214 05:14:42.384114 22509476222784 run_lib.py:146] step: 993000, eval_loss: 3.08391e-02
I0214 05:15:01.168947 22509476222784 run_lib.py:133] step: 993050, training_loss: 4.45850e-02
I0214 05:15:20.007070 22509476222784 run_lib.py:133] step: 993100, training_loss: 3.52813e-02
I0214 05:15:20.288938 22509476222784 run_lib.py:146] step: 993100, eval_loss: 4.46766e-02
I0214 05:15:39.512962 22509476222784 run_lib.py:133] step: 993150, training_loss: 4.05485e-02
I0214 05:15:58.421579 22509476222784 run_lib.py:133] step: 993200, training_loss: 3.48890e-02
I0214 05:15:58.586309 22509476222784 run_lib.py:146] step: 993200, eval_loss: 4.21960e-02
I0214 05:16:17.575600 22509476222784 run_lib.py:133] step: 993250, training_loss: 4.19301e-02
I0214 05:16:36.448173 22509476222784 run_lib.py:133] step: 993300, training_loss: 4.39205e-02
I0214 05:16:36.624024 22509476222784 run_lib.py:146] step: 993300, eval_loss: 4.38256e-02
I0214 05:16:55.388874 22509476222784 run_lib.py:133] step: 993350, training_loss: 3.94483e-02
I0214 05:17:14.415646 22509476222784 run_lib.py:133] step: 993400, training_loss: 3.65766e-02
I0214 05:17:14.588679 22509476222784 run_lib.py:146] step: 993400, eval_loss: 3.77054e-02
I0214 05:17:33.373942 22509476222784 run_lib.py:133] step: 993450, training_loss: 3.20631e-02
I0214 05:17:52.177167 22509476222784 run_lib.py:133] step: 993500, training_loss: 3.48023e-02
I0214 05:17:52.355841 22509476222784 run_lib.py:146] step: 993500, eval_loss: 5.33660e-02
I0214 05:18:11.266813 22509476222784 run_lib.py:133] step: 993550, training_loss: 3.93154e-02
I0214 05:18:30.243543 22509476222784 run_lib.py:133] step: 993600, training_loss: 4.35488e-02
I0214 05:18:30.408176 22509476222784 run_lib.py:146] step: 993600, eval_loss: 5.42447e-02
I0214 05:18:49.298601 22509476222784 run_lib.py:133] step: 993650, training_loss: 2.87465e-02
I0214 05:19:08.142059 22509476222784 run_lib.py:133] step: 993700, training_loss: 4.58203e-02
I0214 05:19:08.305113 22509476222784 run_lib.py:146] step: 993700, eval_loss: 3.75219e-02
I0214 05:19:27.169872 22509476222784 run_lib.py:133] step: 993750, training_loss: 3.02879e-02
I0214 05:19:45.950516 22509476222784 run_lib.py:133] step: 993800, training_loss: 4.62979e-02
I0214 05:19:46.130988 22509476222784 run_lib.py:146] step: 993800, eval_loss: 4.96016e-02
I0214 05:20:05.266237 22509476222784 run_lib.py:133] step: 993850, training_loss: 4.44147e-02
I0214 05:20:24.114132 22509476222784 run_lib.py:133] step: 993900, training_loss: 4.38111e-02
I0214 05:20:24.280113 22509476222784 run_lib.py:146] step: 993900, eval_loss: 5.09140e-02
I0214 05:20:43.045584 22509476222784 run_lib.py:133] step: 993950, training_loss: 3.26783e-02
I0214 05:21:01.881380 22509476222784 run_lib.py:133] step: 994000, training_loss: 3.57758e-02
I0214 05:21:02.054839 22509476222784 run_lib.py:146] step: 994000, eval_loss: 3.75824e-02
I0214 05:21:21.027151 22509476222784 run_lib.py:133] step: 994050, training_loss: 3.53353e-02
I0214 05:21:39.941806 22509476222784 run_lib.py:133] step: 994100, training_loss: 3.51996e-02
I0214 05:21:40.106670 22509476222784 run_lib.py:146] step: 994100, eval_loss: 4.18847e-02
I0214 05:21:59.000585 22509476222784 run_lib.py:133] step: 994150, training_loss: 3.47466e-02
I0214 05:22:17.850772 22509476222784 run_lib.py:133] step: 994200, training_loss: 3.57619e-02
I0214 05:22:18.016011 22509476222784 run_lib.py:146] step: 994200, eval_loss: 4.08310e-02
I0214 05:22:36.922280 22509476222784 run_lib.py:133] step: 994250, training_loss: 3.67985e-02
I0214 05:22:55.795959 22509476222784 run_lib.py:133] step: 994300, training_loss: 4.26534e-02
I0214 05:22:55.972101 22509476222784 run_lib.py:146] step: 994300, eval_loss: 3.24741e-02
I0214 05:23:14.720569 22509476222784 run_lib.py:133] step: 994350, training_loss: 4.68399e-02
I0214 05:23:33.680043 22509476222784 run_lib.py:133] step: 994400, training_loss: 5.04719e-02
I0214 05:23:33.855118 22509476222784 run_lib.py:146] step: 994400, eval_loss: 4.18939e-02
I0214 05:23:52.692478 22509476222784 run_lib.py:133] step: 994450, training_loss: 3.81442e-02
I0214 05:24:11.565109 22509476222784 run_lib.py:133] step: 994500, training_loss: 4.69265e-02
I0214 05:24:11.732627 22509476222784 run_lib.py:146] step: 994500, eval_loss: 4.51353e-02
I0214 05:24:30.616840 22509476222784 run_lib.py:133] step: 994550, training_loss: 3.92849e-02
I0214 05:24:49.410658 22509476222784 run_lib.py:133] step: 994600, training_loss: 3.76943e-02
I0214 05:24:49.577514 22509476222784 run_lib.py:146] step: 994600, eval_loss: 4.93909e-02
I0214 05:25:08.677540 22509476222784 run_lib.py:133] step: 994650, training_loss: 3.86542e-02
I0214 05:25:27.350282 22509476222784 run_lib.py:133] step: 994700, training_loss: 3.76122e-02
I0214 05:25:27.552036 22509476222784 run_lib.py:146] step: 994700, eval_loss: 3.68513e-02
I0214 05:25:46.318301 22509476222784 run_lib.py:133] step: 994750, training_loss: 3.00792e-02
I0214 05:26:05.334684 22509476222784 run_lib.py:133] step: 994800, training_loss: 3.62373e-02
I0214 05:26:05.513684 22509476222784 run_lib.py:146] step: 994800, eval_loss: 3.83992e-02
I0214 05:26:24.317729 22509476222784 run_lib.py:133] step: 994850, training_loss: 4.83755e-02
I0214 05:26:43.341460 22509476222784 run_lib.py:133] step: 994900, training_loss: 4.77050e-02
I0214 05:26:43.714014 22509476222784 run_lib.py:146] step: 994900, eval_loss: 3.68978e-02
I0214 05:27:02.414623 22509476222784 run_lib.py:133] step: 994950, training_loss: 4.45704e-02
I0214 05:27:21.216181 22509476222784 run_lib.py:133] step: 995000, training_loss: 4.91372e-02
I0214 05:27:21.380977 22509476222784 run_lib.py:146] step: 995000, eval_loss: 4.05331e-02
I0214 05:27:40.161402 22509476222784 run_lib.py:133] step: 995050, training_loss: 4.43325e-02
I0214 05:27:59.122105 22509476222784 run_lib.py:133] step: 995100, training_loss: 4.43892e-02
I0214 05:27:59.288200 22509476222784 run_lib.py:146] step: 995100, eval_loss: 4.58426e-02
I0214 05:28:18.304151 22509476222784 run_lib.py:133] step: 995150, training_loss: 4.00669e-02
I0214 05:28:37.188800 22509476222784 run_lib.py:133] step: 995200, training_loss: 3.85239e-02
I0214 05:28:37.358343 22509476222784 run_lib.py:146] step: 995200, eval_loss: 3.90378e-02
I0214 05:28:56.152156 22509476222784 run_lib.py:133] step: 995250, training_loss: 2.98280e-02
I0214 05:29:14.943115 22509476222784 run_lib.py:133] step: 995300, training_loss: 3.21461e-02
I0214 05:29:15.122318 22509476222784 run_lib.py:146] step: 995300, eval_loss: 5.05500e-02
I0214 05:29:34.191677 22509476222784 run_lib.py:133] step: 995350, training_loss: 3.13291e-02
I0214 05:29:53.119129 22509476222784 run_lib.py:133] step: 995400, training_loss: 4.56868e-02
I0214 05:29:53.285172 22509476222784 run_lib.py:146] step: 995400, eval_loss: 4.60483e-02
I0214 05:30:12.147645 22509476222784 run_lib.py:133] step: 995450, training_loss: 3.45883e-02
I0214 05:30:30.888188 22509476222784 run_lib.py:133] step: 995500, training_loss: 4.19050e-02
I0214 05:30:31.051011 22509476222784 run_lib.py:146] step: 995500, eval_loss: 4.25060e-02
I0214 05:30:50.046317 22509476222784 run_lib.py:133] step: 995550, training_loss: 4.43218e-02
I0214 05:31:08.819695 22509476222784 run_lib.py:133] step: 995600, training_loss: 4.81519e-02
I0214 05:31:08.983088 22509476222784 run_lib.py:146] step: 995600, eval_loss: 4.30071e-02
I0214 05:31:28.008852 22509476222784 run_lib.py:133] step: 995650, training_loss: 4.43644e-02
I0214 05:31:46.892512 22509476222784 run_lib.py:133] step: 995700, training_loss: 4.56878e-02
I0214 05:31:47.071003 22509476222784 run_lib.py:146] step: 995700, eval_loss: 5.46011e-02
I0214 05:32:06.028580 22509476222784 run_lib.py:133] step: 995750, training_loss: 4.54375e-02
I0214 05:32:24.887279 22509476222784 run_lib.py:133] step: 995800, training_loss: 5.10586e-02
I0214 05:32:25.065105 22509476222784 run_lib.py:146] step: 995800, eval_loss: 3.21347e-02
I0214 05:32:43.830118 22509476222784 run_lib.py:133] step: 995850, training_loss: 2.73274e-02
I0214 05:33:03.006998 22509476222784 run_lib.py:133] step: 995900, training_loss: 2.96073e-02
I0214 05:33:03.174443 22509476222784 run_lib.py:146] step: 995900, eval_loss: 5.36895e-02
I0214 05:33:21.970892 22509476222784 run_lib.py:133] step: 995950, training_loss: 4.25026e-02
I0214 05:33:40.966729 22509476222784 run_lib.py:133] step: 996000, training_loss: 5.48544e-02
I0214 05:33:41.129220 22509476222784 run_lib.py:146] step: 996000, eval_loss: 3.97629e-02
I0214 05:34:00.002739 22509476222784 run_lib.py:133] step: 996050, training_loss: 3.99653e-02
I0214 05:34:18.879537 22509476222784 run_lib.py:133] step: 996100, training_loss: 4.06143e-02
I0214 05:34:19.052213 22509476222784 run_lib.py:146] step: 996100, eval_loss: 4.93406e-02
I0214 05:34:38.148416 22509476222784 run_lib.py:133] step: 996150, training_loss: 5.85351e-02
I0214 05:34:56.946645 22509476222784 run_lib.py:133] step: 996200, training_loss: 3.94554e-02
I0214 05:34:57.114876 22509476222784 run_lib.py:146] step: 996200, eval_loss: 3.90649e-02
I0214 05:35:16.016961 22509476222784 run_lib.py:133] step: 996250, training_loss: 4.41227e-02
I0214 05:35:34.789956 22509476222784 run_lib.py:133] step: 996300, training_loss: 4.25919e-02
I0214 05:35:34.995952 22509476222784 run_lib.py:146] step: 996300, eval_loss: 4.66800e-02
I0214 05:35:54.042933 22509476222784 run_lib.py:133] step: 996350, training_loss: 3.05962e-02
I0214 05:36:12.857354 22509476222784 run_lib.py:133] step: 996400, training_loss: 2.89887e-02
I0214 05:36:13.024352 22509476222784 run_lib.py:146] step: 996400, eval_loss: 4.54099e-02
I0214 05:36:32.128302 22509476222784 run_lib.py:133] step: 996450, training_loss: 4.30551e-02
I0214 05:36:50.904153 22509476222784 run_lib.py:133] step: 996500, training_loss: 4.90451e-02
I0214 05:36:51.067021 22509476222784 run_lib.py:146] step: 996500, eval_loss: 5.15404e-02
I0214 05:37:09.806493 22509476222784 run_lib.py:133] step: 996550, training_loss: 4.47910e-02
I0214 05:37:28.656177 22509476222784 run_lib.py:133] step: 996600, training_loss: 4.57601e-02
I0214 05:37:28.835198 22509476222784 run_lib.py:146] step: 996600, eval_loss: 4.43095e-02
I0214 05:37:47.794927 22509476222784 run_lib.py:133] step: 996650, training_loss: 3.61749e-02
I0214 05:38:06.800749 22509476222784 run_lib.py:133] step: 996700, training_loss: 4.68451e-02
I0214 05:38:06.968919 22509476222784 run_lib.py:146] step: 996700, eval_loss: 4.14653e-02
I0214 05:38:25.673471 22509476222784 run_lib.py:133] step: 996750, training_loss: 4.89370e-02
I0214 05:38:44.477096 22509476222784 run_lib.py:133] step: 996800, training_loss: 4.59592e-02
I0214 05:38:44.643901 22509476222784 run_lib.py:146] step: 996800, eval_loss: 4.12761e-02
I0214 05:39:03.478484 22509476222784 run_lib.py:133] step: 996850, training_loss: 3.76765e-02
I0214 05:39:22.345290 22509476222784 run_lib.py:133] step: 996900, training_loss: 3.54554e-02
I0214 05:39:22.514395 22509476222784 run_lib.py:146] step: 996900, eval_loss: 4.59623e-02
I0214 05:39:41.472577 22509476222784 run_lib.py:133] step: 996950, training_loss: 3.99871e-02
I0214 05:40:00.268577 22509476222784 run_lib.py:133] step: 997000, training_loss: 4.59443e-02
I0214 05:40:00.432607 22509476222784 run_lib.py:146] step: 997000, eval_loss: 4.26492e-02
I0214 05:40:19.421666 22509476222784 run_lib.py:133] step: 997050, training_loss: 4.39213e-02
I0214 05:40:38.138977 22509476222784 run_lib.py:133] step: 997100, training_loss: 3.80056e-02
I0214 05:40:38.304742 22509476222784 run_lib.py:146] step: 997100, eval_loss: 4.36953e-02
I0214 05:40:57.356578 22509476222784 run_lib.py:133] step: 997150, training_loss: 4.84654e-02
I0214 05:41:16.142190 22509476222784 run_lib.py:133] step: 997200, training_loss: 4.77772e-02
I0214 05:41:16.309975 22509476222784 run_lib.py:146] step: 997200, eval_loss: 4.58997e-02
I0214 05:41:35.195341 22509476222784 run_lib.py:133] step: 997250, training_loss: 4.06833e-02
I0214 05:41:54.149933 22509476222784 run_lib.py:133] step: 997300, training_loss: 4.93195e-02
I0214 05:41:54.316013 22509476222784 run_lib.py:146] step: 997300, eval_loss: 3.44228e-02
I0214 05:42:13.130136 22509476222784 run_lib.py:133] step: 997350, training_loss: 3.73322e-02
I0214 05:42:31.933404 22509476222784 run_lib.py:133] step: 997400, training_loss: 5.41071e-02
I0214 05:42:32.099414 22509476222784 run_lib.py:146] step: 997400, eval_loss: 3.95237e-02
I0214 05:42:51.191952 22509476222784 run_lib.py:133] step: 997450, training_loss: 5.12069e-02
I0214 05:43:10.176367 22509476222784 run_lib.py:133] step: 997500, training_loss: 3.84093e-02
I0214 05:43:10.339042 22509476222784 run_lib.py:146] step: 997500, eval_loss: 3.43512e-02
I0214 05:43:29.138049 22509476222784 run_lib.py:133] step: 997550, training_loss: 5.12940e-02
I0214 05:43:48.015451 22509476222784 run_lib.py:133] step: 997600, training_loss: 2.85847e-02
I0214 05:43:48.184848 22509476222784 run_lib.py:146] step: 997600, eval_loss: 4.11609e-02
I0214 05:44:06.945436 22509476222784 run_lib.py:133] step: 997650, training_loss: 3.79923e-02
I0214 05:44:26.055355 22509476222784 run_lib.py:133] step: 997700, training_loss: 5.04774e-02
I0214 05:44:26.223331 22509476222784 run_lib.py:146] step: 997700, eval_loss: 4.57574e-02
I0214 05:44:44.953383 22509476222784 run_lib.py:133] step: 997750, training_loss: 3.31718e-02
I0214 05:45:03.803587 22509476222784 run_lib.py:133] step: 997800, training_loss: 3.79595e-02
I0214 05:45:03.971272 22509476222784 run_lib.py:146] step: 997800, eval_loss: 3.97364e-02
I0214 05:45:22.719630 22509476222784 run_lib.py:133] step: 997850, training_loss: 4.94702e-02
I0214 05:45:41.681933 22509476222784 run_lib.py:133] step: 997900, training_loss: 3.65972e-02
I0214 05:45:41.862252 22509476222784 run_lib.py:146] step: 997900, eval_loss: 5.10022e-02
I0214 05:46:00.679050 22509476222784 run_lib.py:133] step: 997950, training_loss: 3.77190e-02
I0214 05:46:19.543854 22509476222784 run_lib.py:133] step: 998000, training_loss: 2.82439e-02
I0214 05:46:19.723241 22509476222784 run_lib.py:146] step: 998000, eval_loss: 4.48484e-02
I0214 05:46:38.589522 22509476222784 run_lib.py:133] step: 998050, training_loss: 4.41933e-02
I0214 05:46:57.331010 22509476222784 run_lib.py:133] step: 998100, training_loss: 2.76032e-02
I0214 05:46:57.505165 22509476222784 run_lib.py:146] step: 998100, eval_loss: 4.39641e-02
I0214 05:47:16.531225 22509476222784 run_lib.py:133] step: 998150, training_loss: 3.37301e-02
I0214 05:47:35.397744 22509476222784 run_lib.py:133] step: 998200, training_loss: 2.85710e-02
I0214 05:47:35.574083 22509476222784 run_lib.py:146] step: 998200, eval_loss: 4.26989e-02
I0214 05:47:54.451660 22509476222784 run_lib.py:133] step: 998250, training_loss: 3.26638e-02
I0214 05:48:13.222267 22509476222784 run_lib.py:133] step: 998300, training_loss: 3.86229e-02
I0214 05:48:13.396697 22509476222784 run_lib.py:146] step: 998300, eval_loss: 5.28616e-02
I0214 05:48:32.383112 22509476222784 run_lib.py:133] step: 998350, training_loss: 4.80728e-02
I0214 05:48:51.130378 22509476222784 run_lib.py:133] step: 998400, training_loss: 5.39899e-02
I0214 05:48:51.294980 22509476222784 run_lib.py:146] step: 998400, eval_loss: 4.18302e-02
I0214 05:49:10.194681 22509476222784 run_lib.py:133] step: 998450, training_loss: 4.48870e-02
I0214 05:49:29.128628 22509476222784 run_lib.py:133] step: 998500, training_loss: 4.54441e-02
I0214 05:49:29.306359 22509476222784 run_lib.py:146] step: 998500, eval_loss: 3.98767e-02
I0214 05:49:48.251914 22509476222784 run_lib.py:133] step: 998550, training_loss: 4.30537e-02
I0214 05:50:07.180958 22509476222784 run_lib.py:133] step: 998600, training_loss: 4.37964e-02
I0214 05:50:07.350207 22509476222784 run_lib.py:146] step: 998600, eval_loss: 3.98342e-02
I0214 05:50:26.074701 22509476222784 run_lib.py:133] step: 998650, training_loss: 4.01878e-02
I0214 05:50:45.088432 22509476222784 run_lib.py:133] step: 998700, training_loss: 4.05937e-02
I0214 05:50:45.266935 22509476222784 run_lib.py:146] step: 998700, eval_loss: 3.50731e-02
I0214 05:51:04.056778 22509476222784 run_lib.py:133] step: 998750, training_loss: 4.44528e-02
I0214 05:51:23.184875 22509476222784 run_lib.py:133] step: 998800, training_loss: 3.62452e-02
I0214 05:51:23.361913 22509476222784 run_lib.py:146] step: 998800, eval_loss: 4.84347e-02
I0214 05:51:42.123078 22509476222784 run_lib.py:133] step: 998850, training_loss: 4.97364e-02
I0214 05:52:00.889488 22509476222784 run_lib.py:133] step: 998900, training_loss: 4.18711e-02
I0214 05:52:01.052906 22509476222784 run_lib.py:146] step: 998900, eval_loss: 4.33874e-02
I0214 05:52:20.040457 22509476222784 run_lib.py:133] step: 998950, training_loss: 4.80174e-02
I0214 05:52:38.820463 22509476222784 run_lib.py:133] step: 999000, training_loss: 4.02618e-02
I0214 05:52:39.014541 22509476222784 run_lib.py:146] step: 999000, eval_loss: 3.61889e-02
I0214 05:52:57.989841 22509476222784 run_lib.py:133] step: 999050, training_loss: 4.56373e-02
I0214 05:53:16.958709 22509476222784 run_lib.py:133] step: 999100, training_loss: 3.81117e-02
I0214 05:53:17.130945 22509476222784 run_lib.py:146] step: 999100, eval_loss: 3.17282e-02
I0214 05:53:35.995611 22509476222784 run_lib.py:133] step: 999150, training_loss: 3.65672e-02
I0214 05:53:54.776733 22509476222784 run_lib.py:133] step: 999200, training_loss: 4.02141e-02
I0214 05:53:54.942091 22509476222784 run_lib.py:146] step: 999200, eval_loss: 3.98789e-02
I0214 05:54:13.908093 22509476222784 run_lib.py:133] step: 999250, training_loss: 4.81289e-02
I0214 05:54:32.748157 22509476222784 run_lib.py:133] step: 999300, training_loss: 3.94674e-02
I0214 05:54:32.913285 22509476222784 run_lib.py:146] step: 999300, eval_loss: 3.86496e-02
I0214 05:54:51.770074 22509476222784 run_lib.py:133] step: 999350, training_loss: 3.48354e-02
I0214 05:55:10.591170 22509476222784 run_lib.py:133] step: 999400, training_loss: 3.98556e-02
I0214 05:55:10.764034 22509476222784 run_lib.py:146] step: 999400, eval_loss: 4.44666e-02
I0214 05:55:29.693103 22509476222784 run_lib.py:133] step: 999450, training_loss: 3.50880e-02
I0214 05:55:48.618298 22509476222784 run_lib.py:133] step: 999500, training_loss: 3.51901e-02
I0214 05:55:48.807426 22509476222784 run_lib.py:146] step: 999500, eval_loss: 4.34244e-02
I0214 05:56:07.585199 22509476222784 run_lib.py:133] step: 999550, training_loss: 4.10424e-02
I0214 05:56:26.547045 22509476222784 run_lib.py:133] step: 999600, training_loss: 4.36928e-02
I0214 05:56:26.715289 22509476222784 run_lib.py:146] step: 999600, eval_loss: 5.13937e-02
I0214 05:56:45.627038 22509476222784 run_lib.py:133] step: 999650, training_loss: 5.99721e-02
I0214 05:57:04.375411 22509476222784 run_lib.py:133] step: 999700, training_loss: 3.96592e-02
I0214 05:57:04.545554 22509476222784 run_lib.py:146] step: 999700, eval_loss: 5.49595e-02
I0214 05:57:23.409384 22509476222784 run_lib.py:133] step: 999750, training_loss: 4.18627e-02
I0214 05:57:42.284108 22509476222784 run_lib.py:133] step: 999800, training_loss: 3.82256e-02
I0214 05:57:42.452891 22509476222784 run_lib.py:146] step: 999800, eval_loss: 3.71176e-02
I0214 05:58:01.467222 22509476222784 run_lib.py:133] step: 999850, training_loss: 4.55411e-02
I0214 05:58:20.260348 22509476222784 run_lib.py:133] step: 999900, training_loss: 3.69966e-02
I0214 05:58:20.427238 22509476222784 run_lib.py:146] step: 999900, eval_loss: 4.29795e-02
I0214 05:58:39.394619 22509476222784 run_lib.py:133] step: 999950, training_loss: 2.90480e-02
I0214 05:58:58.177984 22509476222784 run_lib.py:133] step: 1000000, training_loss: 3.88331e-02
I0214 05:58:58.950009 22509476222784 run_lib.py:146] step: 1000000, eval_loss: 4.53419e-02
I0214 05:59:20.575403 22509476222784 run_lib.py:133] step: 1000050, training_loss: 3.75456e-02
I0214 05:59:39.565315 22509476222784 run_lib.py:133] step: 1000100, training_loss: 5.24909e-02
I0214 05:59:39.734067 22509476222784 run_lib.py:146] step: 1000100, eval_loss: 4.31541e-02
I0214 05:59:58.628037 22509476222784 run_lib.py:133] step: 1000150, training_loss: 5.69228e-02
I0214 06:00:17.425251 22509476222784 run_lib.py:133] step: 1000200, training_loss: 4.30384e-02
I0214 06:00:17.592153 22509476222784 run_lib.py:146] step: 1000200, eval_loss: 4.39257e-02
I0214 06:00:36.432154 22509476222784 run_lib.py:133] step: 1000250, training_loss: 4.44692e-02
I0214 06:00:55.204240 22509476222784 run_lib.py:133] step: 1000300, training_loss: 4.70226e-02
I0214 06:00:55.370034 22509476222784 run_lib.py:146] step: 1000300, eval_loss: 4.50540e-02
I0214 06:01:14.504533 22509476222784 run_lib.py:133] step: 1000350, training_loss: 4.37284e-02
I0214 06:01:33.327936 22509476222784 run_lib.py:133] step: 1000400, training_loss: 4.66019e-02
I0214 06:01:33.489915 22509476222784 run_lib.py:146] step: 1000400, eval_loss: 4.38739e-02
I0214 06:01:52.340247 22509476222784 run_lib.py:133] step: 1000450, training_loss: 4.29374e-02
I0214 06:02:11.153537 22509476222784 run_lib.py:133] step: 1000500, training_loss: 6.64636e-02
I0214 06:02:11.331485 22509476222784 run_lib.py:146] step: 1000500, eval_loss: 4.23664e-02
I0214 06:02:30.214772 22509476222784 run_lib.py:133] step: 1000550, training_loss: 4.44103e-02
I0214 06:02:49.153291 22509476222784 run_lib.py:133] step: 1000600, training_loss: 3.60754e-02
I0214 06:02:49.320082 22509476222784 run_lib.py:146] step: 1000600, eval_loss: 3.43871e-02
I0214 06:03:08.281511 22509476222784 run_lib.py:133] step: 1000650, training_loss: 3.44493e-02
I0214 06:03:27.120202 22509476222784 run_lib.py:133] step: 1000700, training_loss: 4.51641e-02
I0214 06:03:27.286223 22509476222784 run_lib.py:146] step: 1000700, eval_loss: 3.91993e-02
I0214 06:03:46.286975 22509476222784 run_lib.py:133] step: 1000750, training_loss: 3.58008e-02
I0214 06:04:05.130039 22509476222784 run_lib.py:133] step: 1000800, training_loss: 4.43370e-02
I0214 06:04:05.295076 22509476222784 run_lib.py:146] step: 1000800, eval_loss: 4.21292e-02
I0214 06:04:24.121056 22509476222784 run_lib.py:133] step: 1000850, training_loss: 4.70868e-02
I0214 06:04:43.025466 22509476222784 run_lib.py:133] step: 1000900, training_loss: 4.13663e-02
I0214 06:04:43.190194 22509476222784 run_lib.py:146] step: 1000900, eval_loss: 3.87288e-02
I0214 06:05:02.047392 22509476222784 run_lib.py:133] step: 1000950, training_loss: 3.78666e-02
I0214 06:05:20.890411 22509476222784 run_lib.py:133] step: 1001000, training_loss: 4.01262e-02
I0214 06:05:21.066281 22509476222784 run_lib.py:146] step: 1001000, eval_loss: 4.51961e-02
I0214 06:05:39.846237 22509476222784 run_lib.py:133] step: 1001050, training_loss: 4.00324e-02
I0214 06:05:58.694802 22509476222784 run_lib.py:133] step: 1001100, training_loss: 4.75468e-02
I0214 06:05:58.861901 22509476222784 run_lib.py:146] step: 1001100, eval_loss: 2.47088e-02
I0214 06:06:17.882982 22509476222784 run_lib.py:133] step: 1001150, training_loss: 4.26824e-02
I0214 06:06:36.654698 22509476222784 run_lib.py:133] step: 1001200, training_loss: 2.92363e-02
I0214 06:06:36.818201 22509476222784 run_lib.py:146] step: 1001200, eval_loss: 4.28585e-02
I0214 06:06:55.547933 22509476222784 run_lib.py:133] step: 1001250, training_loss: 3.68738e-02
I0214 06:07:14.477271 22509476222784 run_lib.py:133] step: 1001300, training_loss: 5.16113e-02
I0214 06:07:14.640054 22509476222784 run_lib.py:146] step: 1001300, eval_loss: 5.25344e-02
I0214 06:07:33.352972 22509476222784 run_lib.py:133] step: 1001350, training_loss: 5.06996e-02
I0214 06:07:52.189432 22509476222784 run_lib.py:133] step: 1001400, training_loss: 3.67202e-02
I0214 06:07:52.363392 22509476222784 run_lib.py:146] step: 1001400, eval_loss: 5.34516e-02
I0214 06:08:11.233075 22509476222784 run_lib.py:133] step: 1001450, training_loss: 4.18497e-02
I0214 06:08:30.074714 22509476222784 run_lib.py:133] step: 1001500, training_loss: 3.19898e-02
I0214 06:08:30.241224 22509476222784 run_lib.py:146] step: 1001500, eval_loss: 3.84635e-02
I0214 06:08:48.942525 22509476222784 run_lib.py:133] step: 1001550, training_loss: 3.27511e-02
I0214 06:09:07.758375 22509476222784 run_lib.py:133] step: 1001600, training_loss: 4.70065e-02
I0214 06:09:07.935174 22509476222784 run_lib.py:146] step: 1001600, eval_loss: 4.52982e-02
I0214 06:09:26.917375 22509476222784 run_lib.py:133] step: 1001650, training_loss: 3.85206e-02
I0214 06:09:45.873207 22509476222784 run_lib.py:133] step: 1001700, training_loss: 4.30612e-02
I0214 06:09:46.045257 22509476222784 run_lib.py:146] step: 1001700, eval_loss: 4.54317e-02
I0214 06:10:04.992278 22509476222784 run_lib.py:133] step: 1001750, training_loss: 5.55869e-02
I0214 06:10:23.649490 22509476222784 run_lib.py:133] step: 1001800, training_loss: 3.21950e-02
I0214 06:10:23.810853 22509476222784 run_lib.py:146] step: 1001800, eval_loss: 4.64555e-02
I0214 06:10:42.698598 22509476222784 run_lib.py:133] step: 1001850, training_loss: 4.68518e-02
I0214 06:11:01.388300 22509476222784 run_lib.py:133] step: 1001900, training_loss: 3.65946e-02
I0214 06:11:01.555016 22509476222784 run_lib.py:146] step: 1001900, eval_loss: 3.75465e-02
I0214 06:11:20.655817 22509476222784 run_lib.py:133] step: 1001950, training_loss: 5.21557e-02
I0214 06:11:39.474614 22509476222784 run_lib.py:133] step: 1002000, training_loss: 6.31019e-02
I0214 06:11:39.643022 22509476222784 run_lib.py:146] step: 1002000, eval_loss: 4.31903e-02
I0214 06:11:58.635293 22509476222784 run_lib.py:133] step: 1002050, training_loss: 4.68575e-02
I0214 06:12:17.423235 22509476222784 run_lib.py:133] step: 1002100, training_loss: 4.06088e-02
I0214 06:12:17.590045 22509476222784 run_lib.py:146] step: 1002100, eval_loss: 4.33836e-02
I0214 06:12:36.443077 22509476222784 run_lib.py:133] step: 1002150, training_loss: 2.73214e-02
I0214 06:12:55.322689 22509476222784 run_lib.py:133] step: 1002200, training_loss: 3.91386e-02
I0214 06:12:55.495168 22509476222784 run_lib.py:146] step: 1002200, eval_loss: 3.81108e-02
I0214 06:13:14.270571 22509476222784 run_lib.py:133] step: 1002250, training_loss: 5.35707e-02
I0214 06:13:33.303215 22509476222784 run_lib.py:133] step: 1002300, training_loss: 3.86281e-02
I0214 06:13:33.466994 22509476222784 run_lib.py:146] step: 1002300, eval_loss: 4.42011e-02
I0214 06:13:52.176404 22509476222784 run_lib.py:133] step: 1002350, training_loss: 5.24705e-02
I0214 06:14:11.038638 22509476222784 run_lib.py:133] step: 1002400, training_loss: 3.89495e-02
I0214 06:14:11.207850 22509476222784 run_lib.py:146] step: 1002400, eval_loss: 3.67110e-02
I0214 06:14:30.124400 22509476222784 run_lib.py:133] step: 1002450, training_loss: 4.84531e-02
I0214 06:14:48.960186 22509476222784 run_lib.py:133] step: 1002500, training_loss: 3.30476e-02
I0214 06:14:49.134054 22509476222784 run_lib.py:146] step: 1002500, eval_loss: 3.94766e-02
I0214 06:15:08.105077 22509476222784 run_lib.py:133] step: 1002550, training_loss: 4.21185e-02
I0214 06:15:26.784470 22509476222784 run_lib.py:133] step: 1002600, training_loss: 3.16965e-02
I0214 06:15:26.950048 22509476222784 run_lib.py:146] step: 1002600, eval_loss: 3.65928e-02
I0214 06:15:45.800246 22509476222784 run_lib.py:133] step: 1002650, training_loss: 5.34488e-02
I0214 06:16:04.718810 22509476222784 run_lib.py:133] step: 1002700, training_loss: 4.23120e-02
I0214 06:16:04.883365 22509476222784 run_lib.py:146] step: 1002700, eval_loss: 5.32833e-02
I0214 06:16:23.830538 22509476222784 run_lib.py:133] step: 1002750, training_loss: 4.20481e-02
I0214 06:16:42.595457 22509476222784 run_lib.py:133] step: 1002800, training_loss: 4.66665e-02
I0214 06:16:42.760898 22509476222784 run_lib.py:146] step: 1002800, eval_loss: 4.32486e-02
I0214 06:17:01.633241 22509476222784 run_lib.py:133] step: 1002850, training_loss: 3.76428e-02
I0214 06:17:20.610329 22509476222784 run_lib.py:133] step: 1002900, training_loss: 6.22284e-02
I0214 06:17:20.785943 22509476222784 run_lib.py:146] step: 1002900, eval_loss: 4.23470e-02
I0214 06:17:39.545993 22509476222784 run_lib.py:133] step: 1002950, training_loss: 2.77931e-02
I0214 06:17:58.550417 22509476222784 run_lib.py:133] step: 1003000, training_loss: 5.55249e-02
I0214 06:17:58.717232 22509476222784 run_lib.py:146] step: 1003000, eval_loss: 3.87997e-02
I0214 06:18:17.438511 22509476222784 run_lib.py:133] step: 1003050, training_loss: 4.49460e-02
I0214 06:18:36.224838 22509476222784 run_lib.py:133] step: 1003100, training_loss: 4.74546e-02
I0214 06:18:36.391774 22509476222784 run_lib.py:146] step: 1003100, eval_loss: 3.62900e-02
I0214 06:18:55.315850 22509476222784 run_lib.py:133] step: 1003150, training_loss: 4.21960e-02
I0214 06:19:14.281055 22509476222784 run_lib.py:133] step: 1003200, training_loss: 4.27354e-02
I0214 06:19:14.446921 22509476222784 run_lib.py:146] step: 1003200, eval_loss: 4.28545e-02
I0214 06:19:33.315982 22509476222784 run_lib.py:133] step: 1003250, training_loss: 4.23027e-02
I0214 06:19:52.104171 22509476222784 run_lib.py:133] step: 1003300, training_loss: 3.98928e-02
I0214 06:19:52.275370 22509476222784 run_lib.py:146] step: 1003300, eval_loss: 4.08462e-02
I0214 06:20:11.286097 22509476222784 run_lib.py:133] step: 1003350, training_loss: 3.99665e-02
I0214 06:20:30.040024 22509476222784 run_lib.py:133] step: 1003400, training_loss: 4.22486e-02
I0214 06:20:30.219127 22509476222784 run_lib.py:146] step: 1003400, eval_loss: 4.44761e-02
I0214 06:20:49.285977 22509476222784 run_lib.py:133] step: 1003450, training_loss: 4.62196e-02
I0214 06:21:08.100156 22509476222784 run_lib.py:133] step: 1003500, training_loss: 3.82873e-02
I0214 06:21:08.268254 22509476222784 run_lib.py:146] step: 1003500, eval_loss: 5.72598e-02
I0214 06:21:27.262960 22509476222784 run_lib.py:133] step: 1003550, training_loss: 5.30200e-02
I0214 06:21:45.988389 22509476222784 run_lib.py:133] step: 1003600, training_loss: 4.33825e-02
I0214 06:21:46.156941 22509476222784 run_lib.py:146] step: 1003600, eval_loss: 3.66587e-02
I0214 06:22:04.963917 22509476222784 run_lib.py:133] step: 1003650, training_loss: 3.97557e-02
I0214 06:22:23.939477 22509476222784 run_lib.py:133] step: 1003700, training_loss: 5.06579e-02
I0214 06:22:24.113078 22509476222784 run_lib.py:146] step: 1003700, eval_loss: 3.62960e-02
I0214 06:22:42.970100 22509476222784 run_lib.py:133] step: 1003750, training_loss: 4.12645e-02
I0214 06:23:01.991193 22509476222784 run_lib.py:133] step: 1003800, training_loss: 4.15121e-02
I0214 06:23:02.156920 22509476222784 run_lib.py:146] step: 1003800, eval_loss: 2.54219e-02
I0214 06:23:20.842782 22509476222784 run_lib.py:133] step: 1003850, training_loss: 4.02641e-02
I0214 06:23:39.703759 22509476222784 run_lib.py:133] step: 1003900, training_loss: 5.43241e-02
I0214 06:23:39.871852 22509476222784 run_lib.py:146] step: 1003900, eval_loss: 4.04081e-02
I0214 06:23:58.755252 22509476222784 run_lib.py:133] step: 1003950, training_loss: 3.75176e-02
I0214 06:24:17.696244 22509476222784 run_lib.py:133] step: 1004000, training_loss: 4.70347e-02
I0214 06:24:17.866449 22509476222784 run_lib.py:146] step: 1004000, eval_loss: 3.89136e-02
I0214 06:24:36.632328 22509476222784 run_lib.py:133] step: 1004050, training_loss: 4.35695e-02
I0214 06:24:55.654847 22509476222784 run_lib.py:133] step: 1004100, training_loss: 3.70321e-02
I0214 06:24:55.825570 22509476222784 run_lib.py:146] step: 1004100, eval_loss: 5.25008e-02
I0214 06:25:14.614829 22509476222784 run_lib.py:133] step: 1004150, training_loss: 4.09628e-02
I0214 06:25:33.416137 22509476222784 run_lib.py:133] step: 1004200, training_loss: 4.23984e-02
I0214 06:25:33.741388 22509476222784 run_lib.py:146] step: 1004200, eval_loss: 5.17665e-02
I0214 06:25:52.665688 22509476222784 run_lib.py:133] step: 1004250, training_loss: 4.84512e-02
I0214 06:26:11.423618 22509476222784 run_lib.py:133] step: 1004300, training_loss: 4.28472e-02
I0214 06:26:11.595034 22509476222784 run_lib.py:146] step: 1004300, eval_loss: 3.88385e-02
I0214 06:26:30.435581 22509476222784 run_lib.py:133] step: 1004350, training_loss: 3.31079e-02
I0214 06:26:49.219528 22509476222784 run_lib.py:133] step: 1004400, training_loss: 4.06897e-02
I0214 06:26:49.386263 22509476222784 run_lib.py:146] step: 1004400, eval_loss: 3.98700e-02
I0214 06:27:08.411208 22509476222784 run_lib.py:133] step: 1004450, training_loss: 2.62878e-02
I0214 06:27:27.323133 22509476222784 run_lib.py:133] step: 1004500, training_loss: 3.22601e-02
I0214 06:27:27.498199 22509476222784 run_lib.py:146] step: 1004500, eval_loss: 3.81757e-02
I0214 06:27:46.294720 22509476222784 run_lib.py:133] step: 1004550, training_loss: 3.27579e-02
I0214 06:28:05.127236 22509476222784 run_lib.py:133] step: 1004600, training_loss: 2.96305e-02
I0214 06:28:05.286648 22509476222784 run_lib.py:146] step: 1004600, eval_loss: 4.23352e-02
I0214 06:28:24.270127 22509476222784 run_lib.py:133] step: 1004650, training_loss: 3.75873e-02
I0214 06:28:43.242323 22509476222784 run_lib.py:133] step: 1004700, training_loss: 3.68420e-02
I0214 06:28:43.406964 22509476222784 run_lib.py:146] step: 1004700, eval_loss: 4.02007e-02
I0214 06:29:02.166530 22509476222784 run_lib.py:133] step: 1004750, training_loss: 5.06967e-02
I0214 06:29:21.034793 22509476222784 run_lib.py:133] step: 1004800, training_loss: 3.13741e-02
I0214 06:29:21.209731 22509476222784 run_lib.py:146] step: 1004800, eval_loss: 3.28598e-02
I0214 06:29:40.308002 22509476222784 run_lib.py:133] step: 1004850, training_loss: 4.72019e-02
I0214 06:29:59.060703 22509476222784 run_lib.py:133] step: 1004900, training_loss: 4.08988e-02
I0214 06:29:59.226458 22509476222784 run_lib.py:146] step: 1004900, eval_loss: 3.55985e-02
I0214 06:30:18.242562 22509476222784 run_lib.py:133] step: 1004950, training_loss: 4.30895e-02
I0214 06:30:36.983110 22509476222784 run_lib.py:133] step: 1005000, training_loss: 4.52921e-02
I0214 06:30:37.156186 22509476222784 run_lib.py:146] step: 1005000, eval_loss: 4.79227e-02
I0214 06:30:56.253576 22509476222784 run_lib.py:133] step: 1005050, training_loss: 4.12201e-02
I0214 06:31:14.990496 22509476222784 run_lib.py:133] step: 1005100, training_loss: 4.86345e-02
I0214 06:31:15.153297 22509476222784 run_lib.py:146] step: 1005100, eval_loss: 3.80564e-02
I0214 06:31:33.959801 22509476222784 run_lib.py:133] step: 1005150, training_loss: 3.31954e-02
I0214 06:31:52.845224 22509476222784 run_lib.py:133] step: 1005200, training_loss: 4.87151e-02
I0214 06:31:53.009915 22509476222784 run_lib.py:146] step: 1005200, eval_loss: 3.45370e-02
I0214 06:32:11.723027 22509476222784 run_lib.py:133] step: 1005250, training_loss: 4.48986e-02
I0214 06:32:30.770095 22509476222784 run_lib.py:133] step: 1005300, training_loss: 3.55820e-02
I0214 06:32:30.952964 22509476222784 run_lib.py:146] step: 1005300, eval_loss: 3.19180e-02
I0214 06:32:49.699402 22509476222784 run_lib.py:133] step: 1005350, training_loss: 4.40561e-02
I0214 06:33:08.620666 22509476222784 run_lib.py:133] step: 1005400, training_loss: 3.13548e-02
I0214 06:33:08.787205 22509476222784 run_lib.py:146] step: 1005400, eval_loss: 4.10739e-02
I0214 06:33:27.760263 22509476222784 run_lib.py:133] step: 1005450, training_loss: 3.89481e-02
I0214 06:33:46.586326 22509476222784 run_lib.py:133] step: 1005500, training_loss: 4.39575e-02
I0214 06:33:46.753123 22509476222784 run_lib.py:146] step: 1005500, eval_loss: 3.86157e-02
I0214 06:34:05.536818 22509476222784 run_lib.py:133] step: 1005550, training_loss: 3.73210e-02
I0214 06:34:24.308119 22509476222784 run_lib.py:133] step: 1005600, training_loss: 3.87869e-02
I0214 06:34:24.479415 22509476222784 run_lib.py:146] step: 1005600, eval_loss: 3.54670e-02
I0214 06:34:43.632788 22509476222784 run_lib.py:133] step: 1005650, training_loss: 4.09727e-02
I0214 06:35:02.384253 22509476222784 run_lib.py:133] step: 1005700, training_loss: 3.84026e-02
I0214 06:35:02.551039 22509476222784 run_lib.py:146] step: 1005700, eval_loss: 5.02397e-02
I0214 06:35:21.353015 22509476222784 run_lib.py:133] step: 1005750, training_loss: 4.18871e-02
I0214 06:35:40.167590 22509476222784 run_lib.py:133] step: 1005800, training_loss: 5.03475e-02
I0214 06:35:40.361757 22509476222784 run_lib.py:146] step: 1005800, eval_loss: 4.50158e-02
I0214 06:35:59.222103 22509476222784 run_lib.py:133] step: 1005850, training_loss: 3.18423e-02
I0214 06:36:18.047371 22509476222784 run_lib.py:133] step: 1005900, training_loss: 4.93615e-02
I0214 06:36:18.219149 22509476222784 run_lib.py:146] step: 1005900, eval_loss: 5.83698e-02
I0214 06:36:37.177511 22509476222784 run_lib.py:133] step: 1005950, training_loss: 5.20374e-02
I0214 06:36:56.073565 22509476222784 run_lib.py:133] step: 1006000, training_loss: 4.15370e-02
I0214 06:36:56.238869 22509476222784 run_lib.py:146] step: 1006000, eval_loss: 3.33632e-02
I0214 06:37:15.037305 22509476222784 run_lib.py:133] step: 1006050, training_loss: 4.93114e-02
I0214 06:37:33.982948 22509476222784 run_lib.py:133] step: 1006100, training_loss: 3.75573e-02
I0214 06:37:34.151376 22509476222784 run_lib.py:146] step: 1006100, eval_loss: 3.58150e-02
I0214 06:37:53.127838 22509476222784 run_lib.py:133] step: 1006150, training_loss: 3.81731e-02
I0214 06:38:12.030088 22509476222784 run_lib.py:133] step: 1006200, training_loss: 3.49667e-02
I0214 06:38:12.207264 22509476222784 run_lib.py:146] step: 1006200, eval_loss: 4.32589e-02
I0214 06:38:31.101350 22509476222784 run_lib.py:133] step: 1006250, training_loss: 4.90222e-02
I0214 06:38:49.893795 22509476222784 run_lib.py:133] step: 1006300, training_loss: 5.28775e-02
I0214 06:38:50.196942 22509476222784 run_lib.py:146] step: 1006300, eval_loss: 4.18502e-02
I0214 06:39:09.215996 22509476222784 run_lib.py:133] step: 1006350, training_loss: 5.04753e-02
I0214 06:39:27.980812 22509476222784 run_lib.py:133] step: 1006400, training_loss: 4.92837e-02
I0214 06:39:28.146159 22509476222784 run_lib.py:146] step: 1006400, eval_loss: 3.82596e-02
I0214 06:39:47.123988 22509476222784 run_lib.py:133] step: 1006450, training_loss: 3.71509e-02
I0214 06:40:05.817005 22509476222784 run_lib.py:133] step: 1006500, training_loss: 3.23590e-02
I0214 06:40:05.980801 22509476222784 run_lib.py:146] step: 1006500, eval_loss: 5.07876e-02
I0214 06:40:24.841588 22509476222784 run_lib.py:133] step: 1006550, training_loss: 4.25066e-02
I0214 06:40:43.778384 22509476222784 run_lib.py:133] step: 1006600, training_loss: 5.68911e-02
I0214 06:40:43.948179 22509476222784 run_lib.py:146] step: 1006600, eval_loss: 3.29184e-02
I0214 06:41:02.729561 22509476222784 run_lib.py:133] step: 1006650, training_loss: 5.16885e-02
I0214 06:41:21.532763 22509476222784 run_lib.py:133] step: 1006700, training_loss: 3.61334e-02
I0214 06:41:21.701220 22509476222784 run_lib.py:146] step: 1006700, eval_loss: 5.04828e-02
I0214 06:41:40.610795 22509476222784 run_lib.py:133] step: 1006750, training_loss: 3.75046e-02
I0214 06:41:59.579010 22509476222784 run_lib.py:133] step: 1006800, training_loss: 4.52519e-02
I0214 06:41:59.746905 22509476222784 run_lib.py:146] step: 1006800, eval_loss: 3.39069e-02
I0214 06:42:18.542548 22509476222784 run_lib.py:133] step: 1006850, training_loss: 4.62733e-02
I0214 06:42:37.427956 22509476222784 run_lib.py:133] step: 1006900, training_loss: 4.09647e-02
I0214 06:42:37.600173 22509476222784 run_lib.py:146] step: 1006900, eval_loss: 3.61544e-02
I0214 06:42:56.359390 22509476222784 run_lib.py:133] step: 1006950, training_loss: 4.06243e-02
I0214 06:43:15.388416 22509476222784 run_lib.py:133] step: 1007000, training_loss: 4.69775e-02
I0214 06:43:15.549710 22509476222784 run_lib.py:146] step: 1007000, eval_loss: 4.72460e-02
I0214 06:43:34.280714 22509476222784 run_lib.py:133] step: 1007050, training_loss: 4.33206e-02
I0214 06:43:53.127019 22509476222784 run_lib.py:133] step: 1007100, training_loss: 4.47537e-02
I0214 06:43:53.311506 22509476222784 run_lib.py:146] step: 1007100, eval_loss: 4.96121e-02
I0214 06:44:12.124247 22509476222784 run_lib.py:133] step: 1007150, training_loss: 3.82005e-02
I0214 06:44:31.104578 22509476222784 run_lib.py:133] step: 1007200, training_loss: 4.04808e-02
I0214 06:44:31.273126 22509476222784 run_lib.py:146] step: 1007200, eval_loss: 5.42004e-02
I0214 06:44:50.143067 22509476222784 run_lib.py:133] step: 1007250, training_loss: 4.48171e-02
I0214 06:45:08.890054 22509476222784 run_lib.py:133] step: 1007300, training_loss: 3.26185e-02
I0214 06:45:09.061529 22509476222784 run_lib.py:146] step: 1007300, eval_loss: 4.11617e-02
I0214 06:45:27.931345 22509476222784 run_lib.py:133] step: 1007350, training_loss: 3.24942e-02
I0214 06:45:46.796943 22509476222784 run_lib.py:133] step: 1007400, training_loss: 3.46921e-02
I0214 06:45:46.962966 22509476222784 run_lib.py:146] step: 1007400, eval_loss: 4.48267e-02
I0214 06:46:05.962183 22509476222784 run_lib.py:133] step: 1007450, training_loss: 4.31238e-02
I0214 06:46:24.761447 22509476222784 run_lib.py:133] step: 1007500, training_loss: 3.37359e-02
I0214 06:46:24.926921 22509476222784 run_lib.py:146] step: 1007500, eval_loss: 4.12791e-02
I0214 06:46:43.686269 22509476222784 run_lib.py:133] step: 1007550, training_loss: 3.75857e-02
I0214 06:47:02.505357 22509476222784 run_lib.py:133] step: 1007600, training_loss: 4.47663e-02
I0214 06:47:02.682229 22509476222784 run_lib.py:146] step: 1007600, eval_loss: 4.61655e-02
I0214 06:47:21.632246 22509476222784 run_lib.py:133] step: 1007650, training_loss: 4.19957e-02
I0214 06:47:40.507119 22509476222784 run_lib.py:133] step: 1007700, training_loss: 2.82128e-02
I0214 06:47:40.676066 22509476222784 run_lib.py:146] step: 1007700, eval_loss: 4.44321e-02
I0214 06:47:59.547125 22509476222784 run_lib.py:133] step: 1007750, training_loss: 4.54732e-02
I0214 06:48:18.397430 22509476222784 run_lib.py:133] step: 1007800, training_loss: 3.49061e-02
I0214 06:48:18.563021 22509476222784 run_lib.py:146] step: 1007800, eval_loss: 4.04314e-02
I0214 06:48:37.499207 22509476222784 run_lib.py:133] step: 1007850, training_loss: 4.54755e-02
I0214 06:48:56.351036 22509476222784 run_lib.py:133] step: 1007900, training_loss: 5.54685e-02
I0214 06:48:56.520148 22509476222784 run_lib.py:146] step: 1007900, eval_loss: 4.08030e-02
I0214 06:49:15.281388 22509476222784 run_lib.py:133] step: 1007950, training_loss: 3.01654e-02
I0214 06:49:34.193866 22509476222784 run_lib.py:133] step: 1008000, training_loss: 3.68697e-02
I0214 06:49:34.357000 22509476222784 run_lib.py:146] step: 1008000, eval_loss: 3.97655e-02
I0214 06:49:53.178068 22509476222784 run_lib.py:133] step: 1008050, training_loss: 3.24820e-02
I0214 06:50:12.061339 22509476222784 run_lib.py:133] step: 1008100, training_loss: 4.60620e-02
I0214 06:50:12.244968 22509476222784 run_lib.py:146] step: 1008100, eval_loss: 3.62071e-02
I0214 06:50:31.107715 22509476222784 run_lib.py:133] step: 1008150, training_loss: 3.58712e-02
I0214 06:50:49.882634 22509476222784 run_lib.py:133] step: 1008200, training_loss: 4.09694e-02
I0214 06:50:50.050390 22509476222784 run_lib.py:146] step: 1008200, eval_loss: 4.14670e-02
I0214 06:51:09.105359 22509476222784 run_lib.py:133] step: 1008250, training_loss: 3.62291e-02
I0214 06:51:27.870195 22509476222784 run_lib.py:133] step: 1008300, training_loss: 4.29259e-02
I0214 06:51:28.036259 22509476222784 run_lib.py:146] step: 1008300, eval_loss: 5.47373e-02
I0214 06:51:46.805001 22509476222784 run_lib.py:133] step: 1008350, training_loss: 3.23799e-02
I0214 06:52:05.882302 22509476222784 run_lib.py:133] step: 1008400, training_loss: 5.21973e-02
I0214 06:52:06.053383 22509476222784 run_lib.py:146] step: 1008400, eval_loss: 3.31922e-02
I0214 06:52:24.895407 22509476222784 run_lib.py:133] step: 1008450, training_loss: 4.23273e-02
I0214 06:52:43.721360 22509476222784 run_lib.py:133] step: 1008500, training_loss: 3.30499e-02
I0214 06:52:43.886910 22509476222784 run_lib.py:146] step: 1008500, eval_loss: 3.78887e-02
I0214 06:53:02.648181 22509476222784 run_lib.py:133] step: 1008550, training_loss: 3.52164e-02
I0214 06:53:21.455662 22509476222784 run_lib.py:133] step: 1008600, training_loss: 4.08222e-02
I0214 06:53:21.637936 22509476222784 run_lib.py:146] step: 1008600, eval_loss: 4.02684e-02
I0214 06:53:40.417307 22509476222784 run_lib.py:133] step: 1008650, training_loss: 4.37350e-02
I0214 06:53:59.268671 22509476222784 run_lib.py:133] step: 1008700, training_loss: 4.34084e-02
I0214 06:53:59.435227 22509476222784 run_lib.py:146] step: 1008700, eval_loss: 4.92097e-02
I0214 06:54:18.436904 22509476222784 run_lib.py:133] step: 1008750, training_loss: 4.89065e-02
I0214 06:54:37.335043 22509476222784 run_lib.py:133] step: 1008800, training_loss: 4.10220e-02
I0214 06:54:37.501533 22509476222784 run_lib.py:146] step: 1008800, eval_loss: 5.57278e-02
I0214 06:54:56.277958 22509476222784 run_lib.py:133] step: 1008850, training_loss: 4.27253e-02
I0214 06:55:15.144966 22509476222784 run_lib.py:133] step: 1008900, training_loss: 4.88697e-02
I0214 06:55:15.319391 22509476222784 run_lib.py:146] step: 1008900, eval_loss: 4.83561e-02
I0214 06:55:34.382935 22509476222784 run_lib.py:133] step: 1008950, training_loss: 4.48923e-02
I0214 06:55:53.008327 22509476222784 run_lib.py:133] step: 1009000, training_loss: 2.79944e-02
I0214 06:55:53.175956 22509476222784 run_lib.py:146] step: 1009000, eval_loss: 4.32248e-02
I0214 06:56:12.162812 22509476222784 run_lib.py:133] step: 1009050, training_loss: 4.34802e-02
I0214 06:56:30.887460 22509476222784 run_lib.py:133] step: 1009100, training_loss: 4.32324e-02
I0214 06:56:31.070041 22509476222784 run_lib.py:146] step: 1009100, eval_loss: 4.81982e-02
I0214 06:56:50.170964 22509476222784 run_lib.py:133] step: 1009150, training_loss: 4.18253e-02
I0214 06:57:08.905884 22509476222784 run_lib.py:133] step: 1009200, training_loss: 4.42850e-02
I0214 06:57:09.085153 22509476222784 run_lib.py:146] step: 1009200, eval_loss: 4.77104e-02
I0214 06:57:28.077708 22509476222784 run_lib.py:133] step: 1009250, training_loss: 3.26001e-02
I0214 06:57:46.824386 22509476222784 run_lib.py:133] step: 1009300, training_loss: 4.28667e-02
I0214 06:57:46.995954 22509476222784 run_lib.py:146] step: 1009300, eval_loss: 2.84508e-02
I0214 06:58:05.809106 22509476222784 run_lib.py:133] step: 1009350, training_loss: 4.88972e-02
I0214 06:58:24.842334 22509476222784 run_lib.py:133] step: 1009400, training_loss: 3.94800e-02
I0214 06:58:25.018421 22509476222784 run_lib.py:146] step: 1009400, eval_loss: 5.08637e-02
I0214 06:58:43.767681 22509476222784 run_lib.py:133] step: 1009450, training_loss: 4.01602e-02
I0214 06:59:02.597204 22509476222784 run_lib.py:133] step: 1009500, training_loss: 3.11587e-02
I0214 06:59:02.764707 22509476222784 run_lib.py:146] step: 1009500, eval_loss: 3.86451e-02
I0214 06:59:21.703619 22509476222784 run_lib.py:133] step: 1009550, training_loss: 5.04227e-02
I0214 06:59:40.563466 22509476222784 run_lib.py:133] step: 1009600, training_loss: 3.41619e-02
I0214 06:59:40.748957 22509476222784 run_lib.py:146] step: 1009600, eval_loss: 3.98787e-02
I0214 06:59:59.720916 22509476222784 run_lib.py:133] step: 1009650, training_loss: 4.40395e-02
I0214 07:00:18.592939 22509476222784 run_lib.py:133] step: 1009700, training_loss: 4.18689e-02
I0214 07:00:18.760320 22509476222784 run_lib.py:146] step: 1009700, eval_loss: 4.16511e-02
I0214 07:00:37.555001 22509476222784 run_lib.py:133] step: 1009750, training_loss: 3.99918e-02
I0214 07:00:56.533569 22509476222784 run_lib.py:133] step: 1009800, training_loss: 3.32582e-02
I0214 07:00:56.699848 22509476222784 run_lib.py:146] step: 1009800, eval_loss: 3.89620e-02
I0214 07:01:15.465120 22509476222784 run_lib.py:133] step: 1009850, training_loss: 4.76546e-02
I0214 07:01:34.217673 22509476222784 run_lib.py:133] step: 1009900, training_loss: 4.95090e-02
I0214 07:01:34.378065 22509476222784 run_lib.py:146] step: 1009900, eval_loss: 5.17252e-02
I0214 07:01:53.303622 22509476222784 run_lib.py:133] step: 1009950, training_loss: 3.69725e-02
I0214 07:02:12.233005 22509476222784 run_lib.py:133] step: 1010000, training_loss: 3.82117e-02
I0214 07:02:13.034897 22509476222784 run_lib.py:146] step: 1010000, eval_loss: 4.03586e-02
I0214 07:02:34.504709 22509476222784 run_lib.py:133] step: 1010050, training_loss: 3.89572e-02
I0214 07:02:53.423821 22509476222784 run_lib.py:133] step: 1010100, training_loss: 3.64256e-02
I0214 07:02:53.590271 22509476222784 run_lib.py:146] step: 1010100, eval_loss: 5.14318e-02
I0214 07:03:12.421812 22509476222784 run_lib.py:133] step: 1010150, training_loss: 4.06015e-02
I0214 07:03:31.216239 22509476222784 run_lib.py:133] step: 1010200, training_loss: 4.79359e-02
I0214 07:03:31.391269 22509476222784 run_lib.py:146] step: 1010200, eval_loss: 4.90738e-02
I0214 07:03:50.269808 22509476222784 run_lib.py:133] step: 1010250, training_loss: 3.32187e-02
I0214 07:04:09.242311 22509476222784 run_lib.py:133] step: 1010300, training_loss: 4.17674e-02
I0214 07:04:09.408974 22509476222784 run_lib.py:146] step: 1010300, eval_loss: 4.23005e-02
I0214 07:04:28.265797 22509476222784 run_lib.py:133] step: 1010350, training_loss: 3.53312e-02
I0214 07:04:47.065609 22509476222784 run_lib.py:133] step: 1010400, training_loss: 3.53033e-02
I0214 07:04:47.227856 22509476222784 run_lib.py:146] step: 1010400, eval_loss: 4.42049e-02
I0214 07:05:05.911576 22509476222784 run_lib.py:133] step: 1010450, training_loss: 4.31981e-02
I0214 07:05:24.742396 22509476222784 run_lib.py:133] step: 1010500, training_loss: 3.14939e-02
I0214 07:05:24.925128 22509476222784 run_lib.py:146] step: 1010500, eval_loss: 5.22517e-02
I0214 07:05:43.872548 22509476222784 run_lib.py:133] step: 1010550, training_loss: 4.01116e-02
I0214 07:06:02.842411 22509476222784 run_lib.py:133] step: 1010600, training_loss: 3.51789e-02
I0214 07:06:03.008216 22509476222784 run_lib.py:146] step: 1010600, eval_loss: 5.33371e-02
I0214 07:06:21.714115 22509476222784 run_lib.py:133] step: 1010650, training_loss: 4.30726e-02
I0214 07:06:40.542837 22509476222784 run_lib.py:133] step: 1010700, training_loss: 3.70039e-02
I0214 07:06:40.726568 22509476222784 run_lib.py:146] step: 1010700, eval_loss: 4.32617e-02
I0214 07:06:59.677365 22509476222784 run_lib.py:133] step: 1010750, training_loss: 4.59535e-02
I0214 07:07:18.434720 22509476222784 run_lib.py:133] step: 1010800, training_loss: 4.16629e-02
I0214 07:07:18.600148 22509476222784 run_lib.py:146] step: 1010800, eval_loss: 4.78895e-02
I0214 07:07:37.633166 22509476222784 run_lib.py:133] step: 1010850, training_loss: 3.76255e-02
I0214 07:07:56.395783 22509476222784 run_lib.py:133] step: 1010900, training_loss: 4.96230e-02
I0214 07:07:56.559161 22509476222784 run_lib.py:146] step: 1010900, eval_loss: 4.78249e-02
I0214 07:08:15.493190 22509476222784 run_lib.py:133] step: 1010950, training_loss: 2.36314e-02
I0214 07:08:34.363548 22509476222784 run_lib.py:133] step: 1011000, training_loss: 4.12555e-02
I0214 07:08:34.537850 22509476222784 run_lib.py:146] step: 1011000, eval_loss: 5.25690e-02
I0214 07:08:53.283687 22509476222784 run_lib.py:133] step: 1011050, training_loss: 4.12212e-02
I0214 07:09:12.371056 22509476222784 run_lib.py:133] step: 1011100, training_loss: 4.05299e-02
I0214 07:09:12.538304 22509476222784 run_lib.py:146] step: 1011100, eval_loss: 4.11783e-02
I0214 07:09:31.304140 22509476222784 run_lib.py:133] step: 1011150, training_loss: 3.98364e-02
I0214 07:09:50.295355 22509476222784 run_lib.py:133] step: 1011200, training_loss: 4.75224e-02
I0214 07:09:50.470171 22509476222784 run_lib.py:146] step: 1011200, eval_loss: 3.52335e-02
I0214 07:10:09.259761 22509476222784 run_lib.py:133] step: 1011250, training_loss: 5.81251e-02
I0214 07:10:28.096786 22509476222784 run_lib.py:133] step: 1011300, training_loss: 3.49238e-02
I0214 07:10:28.265259 22509476222784 run_lib.py:146] step: 1011300, eval_loss: 4.77370e-02
I0214 07:10:47.340862 22509476222784 run_lib.py:133] step: 1011350, training_loss: 4.32004e-02
I0214 07:11:06.055450 22509476222784 run_lib.py:133] step: 1011400, training_loss: 4.08058e-02
I0214 07:11:06.221072 22509476222784 run_lib.py:146] step: 1011400, eval_loss: 4.69432e-02
I0214 07:11:25.170849 22509476222784 run_lib.py:133] step: 1011450, training_loss: 4.32025e-02
I0214 07:11:44.112541 22509476222784 run_lib.py:133] step: 1011500, training_loss: 4.27806e-02
I0214 07:11:44.280164 22509476222784 run_lib.py:146] step: 1011500, eval_loss: 4.42395e-02
I0214 07:12:03.138094 22509476222784 run_lib.py:133] step: 1011550, training_loss: 3.71315e-02
I0214 07:12:21.896252 22509476222784 run_lib.py:133] step: 1011600, training_loss: 4.87293e-02
I0214 07:12:22.244791 22509476222784 run_lib.py:146] step: 1011600, eval_loss: 4.36579e-02
I0214 07:12:41.038768 22509476222784 run_lib.py:133] step: 1011650, training_loss: 4.16325e-02
I0214 07:12:59.914999 22509476222784 run_lib.py:133] step: 1011700, training_loss: 3.23796e-02
I0214 07:13:00.081862 22509476222784 run_lib.py:146] step: 1011700, eval_loss: 3.38284e-02
I0214 07:13:18.873458 22509476222784 run_lib.py:133] step: 1011750, training_loss: 4.31221e-02
I0214 07:13:37.783968 22509476222784 run_lib.py:133] step: 1011800, training_loss: 3.72232e-02
I0214 07:13:37.947692 22509476222784 run_lib.py:146] step: 1011800, eval_loss: 4.64244e-02
I0214 07:13:56.846215 22509476222784 run_lib.py:133] step: 1011850, training_loss: 4.46056e-02
I0214 07:14:15.831914 22509476222784 run_lib.py:133] step: 1011900, training_loss: 3.99469e-02
I0214 07:14:15.997202 22509476222784 run_lib.py:146] step: 1011900, eval_loss: 4.45111e-02
I0214 07:14:34.768240 22509476222784 run_lib.py:133] step: 1011950, training_loss: 3.84262e-02
I0214 07:14:53.679417 22509476222784 run_lib.py:133] step: 1012000, training_loss: 5.31198e-02
I0214 07:14:53.857919 22509476222784 run_lib.py:146] step: 1012000, eval_loss: 3.02958e-02
I0214 07:15:12.824577 22509476222784 run_lib.py:133] step: 1012050, training_loss: 4.77586e-02
I0214 07:15:31.694971 22509476222784 run_lib.py:133] step: 1012100, training_loss: 4.05936e-02
I0214 07:15:31.880032 22509476222784 run_lib.py:146] step: 1012100, eval_loss: 5.38384e-02
I0214 07:15:50.669651 22509476222784 run_lib.py:133] step: 1012150, training_loss: 3.87743e-02
I0214 07:16:09.363462 22509476222784 run_lib.py:133] step: 1012200, training_loss: 3.99097e-02
I0214 07:16:09.533970 22509476222784 run_lib.py:146] step: 1012200, eval_loss: 5.17053e-02
I0214 07:16:28.606888 22509476222784 run_lib.py:133] step: 1012250, training_loss: 3.81728e-02
I0214 07:16:47.343386 22509476222784 run_lib.py:133] step: 1012300, training_loss: 3.72757e-02
I0214 07:16:47.507809 22509476222784 run_lib.py:146] step: 1012300, eval_loss: 3.33454e-02
I0214 07:17:06.491006 22509476222784 run_lib.py:133] step: 1012350, training_loss: 4.51698e-02
I0214 07:17:25.177196 22509476222784 run_lib.py:133] step: 1012400, training_loss: 5.07476e-02
I0214 07:17:25.344014 22509476222784 run_lib.py:146] step: 1012400, eval_loss: 4.23660e-02
I0214 07:17:44.220731 22509476222784 run_lib.py:133] step: 1012450, training_loss: 3.90844e-02
I0214 07:18:03.046452 22509476222784 run_lib.py:133] step: 1012500, training_loss: 4.09442e-02
I0214 07:18:03.230013 22509476222784 run_lib.py:146] step: 1012500, eval_loss: 3.82306e-02
I0214 07:18:21.986618 22509476222784 run_lib.py:133] step: 1012550, training_loss: 3.51706e-02
I0214 07:18:41.047484 22509476222784 run_lib.py:133] step: 1012600, training_loss: 6.24065e-02
I0214 07:18:41.214255 22509476222784 run_lib.py:146] step: 1012600, eval_loss: 4.21017e-02
I0214 07:18:59.939126 22509476222784 run_lib.py:133] step: 1012650, training_loss: 3.80060e-02
I0214 07:19:18.882656 22509476222784 run_lib.py:133] step: 1012700, training_loss: 3.35143e-02
I0214 07:19:19.049234 22509476222784 run_lib.py:146] step: 1012700, eval_loss: 2.99650e-02
I0214 07:19:37.819914 22509476222784 run_lib.py:133] step: 1012750, training_loss: 3.09793e-02
I0214 07:19:56.604066 22509476222784 run_lib.py:133] step: 1012800, training_loss: 3.89069e-02
I0214 07:19:56.779162 22509476222784 run_lib.py:146] step: 1012800, eval_loss: 3.94344e-02
I0214 07:20:15.835281 22509476222784 run_lib.py:133] step: 1012850, training_loss: 3.68309e-02
I0214 07:20:34.579519 22509476222784 run_lib.py:133] step: 1012900, training_loss: 4.37883e-02
I0214 07:20:34.754217 22509476222784 run_lib.py:146] step: 1012900, eval_loss: 5.40191e-02
I0214 07:20:53.628602 22509476222784 run_lib.py:133] step: 1012950, training_loss: 4.58776e-02
I0214 07:21:12.362145 22509476222784 run_lib.py:133] step: 1013000, training_loss: 5.49330e-02
I0214 07:21:12.540996 22509476222784 run_lib.py:146] step: 1013000, eval_loss: 3.82114e-02
I0214 07:21:31.620983 22509476222784 run_lib.py:133] step: 1013050, training_loss: 3.65132e-02
I0214 07:21:50.348279 22509476222784 run_lib.py:133] step: 1013100, training_loss: 5.53146e-02
I0214 07:21:50.513733 22509476222784 run_lib.py:146] step: 1013100, eval_loss: 4.97537e-02
I0214 07:22:09.391430 22509476222784 run_lib.py:133] step: 1013150, training_loss: 4.12686e-02
I0214 07:22:28.136169 22509476222784 run_lib.py:133] step: 1013200, training_loss: 3.79141e-02
I0214 07:22:28.300799 22509476222784 run_lib.py:146] step: 1013200, eval_loss: 4.15507e-02
I0214 07:22:47.060034 22509476222784 run_lib.py:133] step: 1013250, training_loss: 4.82371e-02
I0214 07:23:05.839456 22509476222784 run_lib.py:133] step: 1013300, training_loss: 3.98502e-02
I0214 07:23:06.006390 22509476222784 run_lib.py:146] step: 1013300, eval_loss: 3.25019e-02
I0214 07:23:24.946532 22509476222784 run_lib.py:133] step: 1013350, training_loss: 4.08636e-02
I0214 07:23:43.821192 22509476222784 run_lib.py:133] step: 1013400, training_loss: 4.32094e-02
I0214 07:23:44.000218 22509476222784 run_lib.py:146] step: 1013400, eval_loss: 3.57082e-02
I0214 07:24:02.769266 22509476222784 run_lib.py:133] step: 1013450, training_loss: 4.19254e-02
I0214 07:24:21.474351 22509476222784 run_lib.py:133] step: 1013500, training_loss: 4.57040e-02
I0214 07:24:21.653002 22509476222784 run_lib.py:146] step: 1013500, eval_loss: 3.25794e-02
I0214 07:24:40.718819 22509476222784 run_lib.py:133] step: 1013550, training_loss: 5.16367e-02
I0214 07:24:59.530847 22509476222784 run_lib.py:133] step: 1013600, training_loss: 3.02662e-02
I0214 07:24:59.696366 22509476222784 run_lib.py:146] step: 1013600, eval_loss: 5.35131e-02
I0214 07:25:18.755053 22509476222784 run_lib.py:133] step: 1013650, training_loss: 3.55464e-02
I0214 07:25:37.490157 22509476222784 run_lib.py:133] step: 1013700, training_loss: 4.11847e-02
I0214 07:25:37.651557 22509476222784 run_lib.py:146] step: 1013700, eval_loss: 3.86439e-02
I0214 07:25:56.718663 22509476222784 run_lib.py:133] step: 1013750, training_loss: 4.49440e-02
I0214 07:26:15.454648 22509476222784 run_lib.py:133] step: 1013800, training_loss: 5.04894e-02
I0214 07:26:15.630492 22509476222784 run_lib.py:146] step: 1013800, eval_loss: 5.87134e-02
I0214 07:26:34.625098 22509476222784 run_lib.py:133] step: 1013850, training_loss: 3.21274e-02
I0214 07:26:53.430202 22509476222784 run_lib.py:133] step: 1013900, training_loss: 4.11798e-02
I0214 07:26:53.596248 22509476222784 run_lib.py:146] step: 1013900, eval_loss: 4.82214e-02
I0214 07:27:12.321484 22509476222784 run_lib.py:133] step: 1013950, training_loss: 4.65942e-02
I0214 07:27:31.374817 22509476222784 run_lib.py:133] step: 1014000, training_loss: 4.20829e-02
I0214 07:27:31.560475 22509476222784 run_lib.py:146] step: 1014000, eval_loss: 4.17547e-02
I0214 07:27:50.344570 22509476222784 run_lib.py:133] step: 1014050, training_loss: 4.14157e-02
I0214 07:28:09.250005 22509476222784 run_lib.py:133] step: 1014100, training_loss: 3.22351e-02
I0214 07:28:09.415163 22509476222784 run_lib.py:146] step: 1014100, eval_loss: 4.57422e-02
I0214 07:28:28.340657 22509476222784 run_lib.py:133] step: 1014150, training_loss: 4.71635e-02
I0214 07:28:47.260041 22509476222784 run_lib.py:133] step: 1014200, training_loss: 3.96451e-02
I0214 07:28:47.420984 22509476222784 run_lib.py:146] step: 1014200, eval_loss: 3.92095e-02
I0214 07:29:06.179090 22509476222784 run_lib.py:133] step: 1014250, training_loss: 5.53289e-02
I0214 07:29:24.902059 22509476222784 run_lib.py:133] step: 1014300, training_loss: 5.67792e-02
I0214 07:29:25.083259 22509476222784 run_lib.py:146] step: 1014300, eval_loss: 4.88299e-02
I0214 07:29:43.982329 22509476222784 run_lib.py:133] step: 1014350, training_loss: 3.63798e-02
I0214 07:30:02.982864 22509476222784 run_lib.py:133] step: 1014400, training_loss: 3.57851e-02
I0214 07:30:03.151087 22509476222784 run_lib.py:146] step: 1014400, eval_loss: 4.88429e-02
I0214 07:30:21.936043 22509476222784 run_lib.py:133] step: 1014450, training_loss: 4.30448e-02
I0214 07:30:40.687361 22509476222784 run_lib.py:133] step: 1014500, training_loss: 4.30824e-02
I0214 07:30:40.866940 22509476222784 run_lib.py:146] step: 1014500, eval_loss: 4.27217e-02
I0214 07:30:59.724534 22509476222784 run_lib.py:133] step: 1014550, training_loss: 3.59325e-02
I0214 07:31:18.741239 22509476222784 run_lib.py:133] step: 1014600, training_loss: 4.81692e-02
I0214 07:31:18.906229 22509476222784 run_lib.py:146] step: 1014600, eval_loss: 4.48468e-02
I0214 07:31:37.751028 22509476222784 run_lib.py:133] step: 1014650, training_loss: 3.45676e-02
I0214 07:31:56.642589 22509476222784 run_lib.py:133] step: 1014700, training_loss: 4.16310e-02
I0214 07:31:56.804027 22509476222784 run_lib.py:146] step: 1014700, eval_loss: 2.62266e-02
I0214 07:32:15.576473 22509476222784 run_lib.py:133] step: 1014750, training_loss: 4.34238e-02
I0214 07:32:34.438525 22509476222784 run_lib.py:133] step: 1014800, training_loss: 4.30315e-02
I0214 07:32:34.619057 22509476222784 run_lib.py:146] step: 1014800, eval_loss: 5.16521e-02
I0214 07:32:53.571320 22509476222784 run_lib.py:133] step: 1014850, training_loss: 5.24382e-02
I0214 07:33:12.519533 22509476222784 run_lib.py:133] step: 1014900, training_loss: 4.82723e-02
I0214 07:33:12.697497 22509476222784 run_lib.py:146] step: 1014900, eval_loss: 4.06046e-02
I0214 07:33:31.405179 22509476222784 run_lib.py:133] step: 1014950, training_loss: 4.56145e-02
I0214 07:33:50.269220 22509476222784 run_lib.py:133] step: 1015000, training_loss: 3.22216e-02
I0214 07:33:50.434077 22509476222784 run_lib.py:146] step: 1015000, eval_loss: 4.55569e-02
I0214 07:34:09.374546 22509476222784 run_lib.py:133] step: 1015050, training_loss: 3.31359e-02
I0214 07:34:28.111849 22509476222784 run_lib.py:133] step: 1015100, training_loss: 4.39114e-02
I0214 07:34:28.278974 22509476222784 run_lib.py:146] step: 1015100, eval_loss: 3.14304e-02
I0214 07:34:47.207860 22509476222784 run_lib.py:133] step: 1015150, training_loss: 6.04256e-02
I0214 07:35:05.924475 22509476222784 run_lib.py:133] step: 1015200, training_loss: 3.46189e-02
I0214 07:35:06.088007 22509476222784 run_lib.py:146] step: 1015200, eval_loss: 4.87296e-02
I0214 07:35:25.012021 22509476222784 run_lib.py:133] step: 1015250, training_loss: 4.21366e-02
I0214 07:35:43.814716 22509476222784 run_lib.py:133] step: 1015300, training_loss: 4.03365e-02
I0214 07:35:44.005084 22509476222784 run_lib.py:146] step: 1015300, eval_loss: 4.05021e-02
I0214 07:36:02.882726 22509476222784 run_lib.py:133] step: 1015350, training_loss: 3.32759e-02
I0214 07:36:21.896551 22509476222784 run_lib.py:133] step: 1015400, training_loss: 4.23313e-02
I0214 07:36:22.071201 22509476222784 run_lib.py:146] step: 1015400, eval_loss: 3.23620e-02
I0214 07:36:40.877720 22509476222784 run_lib.py:133] step: 1015450, training_loss: 4.51050e-02
I0214 07:36:59.800351 22509476222784 run_lib.py:133] step: 1015500, training_loss: 3.00959e-02
I0214 07:36:59.970942 22509476222784 run_lib.py:146] step: 1015500, eval_loss: 3.99537e-02
I0214 07:37:18.751671 22509476222784 run_lib.py:133] step: 1015550, training_loss: 3.61981e-02
I0214 07:37:37.661329 22509476222784 run_lib.py:133] step: 1015600, training_loss: 3.58181e-02
I0214 07:37:37.823811 22509476222784 run_lib.py:146] step: 1015600, eval_loss: 2.70579e-02
I0214 07:37:56.782277 22509476222784 run_lib.py:133] step: 1015650, training_loss: 4.00781e-02
I0214 07:38:15.680428 22509476222784 run_lib.py:133] step: 1015700, training_loss: 3.39620e-02
I0214 07:38:15.844986 22509476222784 run_lib.py:146] step: 1015700, eval_loss: 3.60817e-02
I0214 07:38:34.593436 22509476222784 run_lib.py:133] step: 1015750, training_loss: 4.26172e-02
I0214 07:38:53.656803 22509476222784 run_lib.py:133] step: 1015800, training_loss: 3.36447e-02
I0214 07:38:53.831092 22509476222784 run_lib.py:146] step: 1015800, eval_loss: 4.01006e-02
I0214 07:39:12.578803 22509476222784 run_lib.py:133] step: 1015850, training_loss: 6.27362e-02
I0214 07:39:31.285409 22509476222784 run_lib.py:133] step: 1015900, training_loss: 4.67140e-02
I0214 07:39:31.451269 22509476222784 run_lib.py:146] step: 1015900, eval_loss: 5.00192e-02
I0214 07:39:50.356256 22509476222784 run_lib.py:133] step: 1015950, training_loss: 4.40219e-02
I0214 07:40:09.121851 22509476222784 run_lib.py:133] step: 1016000, training_loss: 2.65103e-02
I0214 07:40:09.291146 22509476222784 run_lib.py:146] step: 1016000, eval_loss: 4.45017e-02
I0214 07:40:28.210916 22509476222784 run_lib.py:133] step: 1016050, training_loss: 3.39434e-02
I0214 07:40:46.937347 22509476222784 run_lib.py:133] step: 1016100, training_loss: 2.68466e-02
I0214 07:40:47.102076 22509476222784 run_lib.py:146] step: 1016100, eval_loss: 4.29819e-02
I0214 07:41:06.116211 22509476222784 run_lib.py:133] step: 1016150, training_loss: 5.05337e-02
I0214 07:41:24.966586 22509476222784 run_lib.py:133] step: 1016200, training_loss: 4.29320e-02
I0214 07:41:25.133020 22509476222784 run_lib.py:146] step: 1016200, eval_loss: 2.46524e-02
I0214 07:41:43.972332 22509476222784 run_lib.py:133] step: 1016250, training_loss: 3.57470e-02
I0214 07:42:02.737109 22509476222784 run_lib.py:133] step: 1016300, training_loss: 3.04777e-02
I0214 07:42:02.920990 22509476222784 run_lib.py:146] step: 1016300, eval_loss: 3.48473e-02
I0214 07:42:21.875217 22509476222784 run_lib.py:133] step: 1016350, training_loss: 3.92648e-02
I0214 07:42:40.671402 22509476222784 run_lib.py:133] step: 1016400, training_loss: 3.23626e-02
I0214 07:42:40.837183 22509476222784 run_lib.py:146] step: 1016400, eval_loss: 5.04266e-02
I0214 07:42:59.670068 22509476222784 run_lib.py:133] step: 1016450, training_loss: 4.61844e-02
I0214 07:43:18.508116 22509476222784 run_lib.py:133] step: 1016500, training_loss: 4.37102e-02
I0214 07:43:18.692192 22509476222784 run_lib.py:146] step: 1016500, eval_loss: 4.60535e-02
I0214 07:43:37.639750 22509476222784 run_lib.py:133] step: 1016550, training_loss: 3.56510e-02
I0214 07:43:56.486740 22509476222784 run_lib.py:133] step: 1016600, training_loss: 4.65912e-02
I0214 07:43:56.652272 22509476222784 run_lib.py:146] step: 1016600, eval_loss: 4.73475e-02
I0214 07:44:15.573431 22509476222784 run_lib.py:133] step: 1016650, training_loss: 3.91140e-02
I0214 07:44:34.428033 22509476222784 run_lib.py:133] step: 1016700, training_loss: 4.76572e-02
I0214 07:44:34.598143 22509476222784 run_lib.py:146] step: 1016700, eval_loss: 3.29596e-02
I0214 07:44:53.360638 22509476222784 run_lib.py:133] step: 1016750, training_loss: 4.77343e-02
I0214 07:45:12.342219 22509476222784 run_lib.py:133] step: 1016800, training_loss: 3.60626e-02
I0214 07:45:12.516662 22509476222784 run_lib.py:146] step: 1016800, eval_loss: 4.09932e-02
I0214 07:45:31.321559 22509476222784 run_lib.py:133] step: 1016850, training_loss: 2.73191e-02
I0214 07:45:50.024517 22509476222784 run_lib.py:133] step: 1016900, training_loss: 4.72199e-02
I0214 07:45:50.191088 22509476222784 run_lib.py:146] step: 1016900, eval_loss: 4.41129e-02
I0214 07:46:09.266593 22509476222784 run_lib.py:133] step: 1016950, training_loss: 4.82508e-02
I0214 07:46:28.029232 22509476222784 run_lib.py:133] step: 1017000, training_loss: 4.57776e-02
I0214 07:46:28.194110 22509476222784 run_lib.py:146] step: 1017000, eval_loss: 4.08418e-02
I0214 07:46:47.216842 22509476222784 run_lib.py:133] step: 1017050, training_loss: 4.41475e-02
I0214 07:47:05.987144 22509476222784 run_lib.py:133] step: 1017100, training_loss: 4.57004e-02
I0214 07:47:06.153307 22509476222784 run_lib.py:146] step: 1017100, eval_loss: 2.63172e-02
I0214 07:47:25.045506 22509476222784 run_lib.py:133] step: 1017150, training_loss: 4.29629e-02
I0214 07:47:44.010393 22509476222784 run_lib.py:133] step: 1017200, training_loss: 4.84464e-02
I0214 07:47:44.179208 22509476222784 run_lib.py:146] step: 1017200, eval_loss: 4.63797e-02
I0214 07:48:02.859297 22509476222784 run_lib.py:133] step: 1017250, training_loss: 3.11576e-02
I0214 07:48:21.641928 22509476222784 run_lib.py:133] step: 1017300, training_loss: 3.99916e-02
I0214 07:48:21.817013 22509476222784 run_lib.py:146] step: 1017300, eval_loss: 3.14753e-02
I0214 07:48:40.579325 22509476222784 run_lib.py:133] step: 1017350, training_loss: 4.02977e-02
I0214 07:48:59.536539 22509476222784 run_lib.py:133] step: 1017400, training_loss: 4.47561e-02
I0214 07:48:59.703176 22509476222784 run_lib.py:146] step: 1017400, eval_loss: 4.03032e-02
I0214 07:49:18.467680 22509476222784 run_lib.py:133] step: 1017450, training_loss: 4.85688e-02
I0214 07:49:37.226284 22509476222784 run_lib.py:133] step: 1017500, training_loss: 4.05964e-02
I0214 07:49:37.388024 22509476222784 run_lib.py:146] step: 1017500, eval_loss: 3.76734e-02
I0214 07:49:56.269208 22509476222784 run_lib.py:133] step: 1017550, training_loss: 3.27123e-02
I0214 07:50:15.070872 22509476222784 run_lib.py:133] step: 1017600, training_loss: 2.90043e-02
I0214 07:50:15.248113 22509476222784 run_lib.py:146] step: 1017600, eval_loss: 5.36852e-02
I0214 07:50:34.188280 22509476222784 run_lib.py:133] step: 1017650, training_loss: 4.18521e-02
I0214 07:50:53.175048 22509476222784 run_lib.py:133] step: 1017700, training_loss: 3.64398e-02
I0214 07:50:53.344380 22509476222784 run_lib.py:146] step: 1017700, eval_loss: 3.54696e-02
I0214 07:51:12.078154 22509476222784 run_lib.py:133] step: 1017750, training_loss: 4.10476e-02
I0214 07:51:30.875941 22509476222784 run_lib.py:133] step: 1017800, training_loss: 4.04339e-02
I0214 07:51:31.056139 22509476222784 run_lib.py:146] step: 1017800, eval_loss: 2.99842e-02
I0214 07:51:50.009434 22509476222784 run_lib.py:133] step: 1017850, training_loss: 3.20621e-02
I0214 07:52:08.789997 22509476222784 run_lib.py:133] step: 1017900, training_loss: 4.12179e-02
I0214 07:52:08.956257 22509476222784 run_lib.py:146] step: 1017900, eval_loss: 5.53154e-02
I0214 07:52:27.962236 22509476222784 run_lib.py:133] step: 1017950, training_loss: 3.55121e-02
I0214 07:52:46.743719 22509476222784 run_lib.py:133] step: 1018000, training_loss: 5.11408e-02
I0214 07:52:46.906030 22509476222784 run_lib.py:146] step: 1018000, eval_loss: 4.91058e-02
I0214 07:53:05.807571 22509476222784 run_lib.py:133] step: 1018050, training_loss: 5.21892e-02
I0214 07:53:24.696513 22509476222784 run_lib.py:133] step: 1018100, training_loss: 4.04746e-02
I0214 07:53:24.875316 22509476222784 run_lib.py:146] step: 1018100, eval_loss: 3.40777e-02
I0214 07:53:43.672929 22509476222784 run_lib.py:133] step: 1018150, training_loss: 3.55629e-02
I0214 07:54:02.708429 22509476222784 run_lib.py:133] step: 1018200, training_loss: 4.22488e-02
I0214 07:54:02.879117 22509476222784 run_lib.py:146] step: 1018200, eval_loss: 3.69247e-02
I0214 07:54:21.688743 22509476222784 run_lib.py:133] step: 1018250, training_loss: 3.60054e-02
I0214 07:54:40.540851 22509476222784 run_lib.py:133] step: 1018300, training_loss: 3.78628e-02
I0214 07:54:40.710942 22509476222784 run_lib.py:146] step: 1018300, eval_loss: 4.12547e-02
I0214 07:54:59.565218 22509476222784 run_lib.py:133] step: 1018350, training_loss: 4.08210e-02
I0214 07:55:18.341655 22509476222784 run_lib.py:133] step: 1018400, training_loss: 4.78413e-02
I0214 07:55:18.575219 22509476222784 run_lib.py:146] step: 1018400, eval_loss: 4.12516e-02
I0214 07:55:37.638706 22509476222784 run_lib.py:133] step: 1018450, training_loss: 3.79941e-02
I0214 07:55:56.402162 22509476222784 run_lib.py:133] step: 1018500, training_loss: 5.62616e-02
I0214 07:55:56.564996 22509476222784 run_lib.py:146] step: 1018500, eval_loss: 4.41133e-02
I0214 07:56:15.326873 22509476222784 run_lib.py:133] step: 1018550, training_loss: 3.95996e-02
I0214 07:56:34.387746 22509476222784 run_lib.py:133] step: 1018600, training_loss: 3.29787e-02
I0214 07:56:34.571988 22509476222784 run_lib.py:146] step: 1018600, eval_loss: 4.12243e-02
I0214 07:56:53.371497 22509476222784 run_lib.py:133] step: 1018650, training_loss: 5.48430e-02
I0214 07:57:12.260497 22509476222784 run_lib.py:133] step: 1018700, training_loss: 3.43732e-02
I0214 07:57:12.623850 22509476222784 run_lib.py:146] step: 1018700, eval_loss: 3.18858e-02
I0214 07:57:31.397279 22509476222784 run_lib.py:133] step: 1018750, training_loss: 3.83961e-02
I0214 07:57:50.224197 22509476222784 run_lib.py:133] step: 1018800, training_loss: 4.51856e-02
I0214 07:57:50.391780 22509476222784 run_lib.py:146] step: 1018800, eval_loss: 4.52061e-02
I0214 07:58:09.230912 22509476222784 run_lib.py:133] step: 1018850, training_loss: 3.81310e-02
I0214 07:58:28.031187 22509476222784 run_lib.py:133] step: 1018900, training_loss: 4.26874e-02
I0214 07:58:28.198361 22509476222784 run_lib.py:146] step: 1018900, eval_loss: 4.00063e-02
I0214 07:58:47.269868 22509476222784 run_lib.py:133] step: 1018950, training_loss: 4.67489e-02
I0214 07:59:06.133033 22509476222784 run_lib.py:133] step: 1019000, training_loss: 4.30209e-02
I0214 07:59:06.292926 22509476222784 run_lib.py:146] step: 1019000, eval_loss: 3.46049e-02
I0214 07:59:25.048886 22509476222784 run_lib.py:133] step: 1019050, training_loss: 3.07742e-02
I0214 07:59:43.876431 22509476222784 run_lib.py:133] step: 1019100, training_loss: 3.65663e-02
I0214 07:59:44.044255 22509476222784 run_lib.py:146] step: 1019100, eval_loss: 4.12226e-02
I0214 08:00:02.926371 22509476222784 run_lib.py:133] step: 1019150, training_loss: 3.72515e-02
I0214 08:00:21.978528 22509476222784 run_lib.py:133] step: 1019200, training_loss: 5.21529e-02
I0214 08:00:22.150199 22509476222784 run_lib.py:146] step: 1019200, eval_loss: 2.81892e-02
I0214 08:00:40.875084 22509476222784 run_lib.py:133] step: 1019250, training_loss: 3.62576e-02
I0214 08:00:59.680679 22509476222784 run_lib.py:133] step: 1019300, training_loss: 3.65963e-02
I0214 08:00:59.845680 22509476222784 run_lib.py:146] step: 1019300, eval_loss: 4.29524e-02
I0214 08:01:18.775065 22509476222784 run_lib.py:133] step: 1019350, training_loss: 4.47749e-02
I0214 08:01:37.477853 22509476222784 run_lib.py:133] step: 1019400, training_loss: 3.85766e-02
I0214 08:01:37.651856 22509476222784 run_lib.py:146] step: 1019400, eval_loss: 3.44494e-02
I0214 08:01:56.657354 22509476222784 run_lib.py:133] step: 1019450, training_loss: 3.74123e-02
I0214 08:02:15.396039 22509476222784 run_lib.py:133] step: 1019500, training_loss: 4.40875e-02
I0214 08:02:15.573258 22509476222784 run_lib.py:146] step: 1019500, eval_loss: 4.47911e-02
I0214 08:02:34.582410 22509476222784 run_lib.py:133] step: 1019550, training_loss: 3.70067e-02
I0214 08:02:53.312304 22509476222784 run_lib.py:133] step: 1019600, training_loss: 5.44823e-02
I0214 08:02:53.481003 22509476222784 run_lib.py:146] step: 1019600, eval_loss: 4.18491e-02
I0214 08:03:12.246821 22509476222784 run_lib.py:133] step: 1019650, training_loss: 4.47231e-02
I0214 08:03:31.147243 22509476222784 run_lib.py:133] step: 1019700, training_loss: 4.04672e-02
I0214 08:03:31.315082 22509476222784 run_lib.py:146] step: 1019700, eval_loss: 4.22629e-02
I0214 08:03:50.101753 22509476222784 run_lib.py:133] step: 1019750, training_loss: 5.49574e-02
I0214 08:04:09.216326 22509476222784 run_lib.py:133] step: 1019800, training_loss: 4.86020e-02
I0214 08:04:09.382770 22509476222784 run_lib.py:146] step: 1019800, eval_loss: 3.95869e-02
I0214 08:04:28.101731 22509476222784 run_lib.py:133] step: 1019850, training_loss: 4.01986e-02
I0214 08:04:46.993711 22509476222784 run_lib.py:133] step: 1019900, training_loss: 4.59919e-02
I0214 08:04:47.157146 22509476222784 run_lib.py:146] step: 1019900, eval_loss: 4.14136e-02
I0214 08:05:06.115619 22509476222784 run_lib.py:133] step: 1019950, training_loss: 4.67920e-02
I0214 08:05:24.974708 22509476222784 run_lib.py:133] step: 1020000, training_loss: 5.24039e-02
I0214 08:05:25.771640 22509476222784 run_lib.py:146] step: 1020000, eval_loss: 5.42907e-02
I0214 08:05:47.488109 22509476222784 run_lib.py:133] step: 1020050, training_loss: 4.01446e-02
I0214 08:06:06.422360 22509476222784 run_lib.py:133] step: 1020100, training_loss: 3.13519e-02
I0214 08:06:06.591102 22509476222784 run_lib.py:146] step: 1020100, eval_loss: 3.29705e-02
I0214 08:06:25.259221 22509476222784 run_lib.py:133] step: 1020150, training_loss: 5.01644e-02
I0214 08:06:43.999534 22509476222784 run_lib.py:133] step: 1020200, training_loss: 4.30326e-02
I0214 08:06:44.165954 22509476222784 run_lib.py:146] step: 1020200, eval_loss: 4.16918e-02
I0214 08:07:03.108566 22509476222784 run_lib.py:133] step: 1020250, training_loss: 2.89357e-02
I0214 08:07:22.012576 22509476222784 run_lib.py:133] step: 1020300, training_loss: 3.68634e-02
I0214 08:07:22.179204 22509476222784 run_lib.py:146] step: 1020300, eval_loss: 4.04597e-02
I0214 08:07:41.029050 22509476222784 run_lib.py:133] step: 1020350, training_loss: 4.42373e-02
I0214 08:07:59.705885 22509476222784 run_lib.py:133] step: 1020400, training_loss: 3.70586e-02
I0214 08:07:59.869969 22509476222784 run_lib.py:146] step: 1020400, eval_loss: 5.13936e-02
I0214 08:08:18.825172 22509476222784 run_lib.py:133] step: 1020450, training_loss: 3.26304e-02
I0214 08:08:37.623316 22509476222784 run_lib.py:133] step: 1020500, training_loss: 5.08916e-02
I0214 08:08:37.802153 22509476222784 run_lib.py:146] step: 1020500, eval_loss: 4.13237e-02
I0214 08:08:56.847515 22509476222784 run_lib.py:133] step: 1020550, training_loss: 4.19877e-02
I0214 08:09:15.669170 22509476222784 run_lib.py:133] step: 1020600, training_loss: 4.21502e-02
I0214 08:09:15.836890 22509476222784 run_lib.py:146] step: 1020600, eval_loss: 3.98764e-02
I0214 08:09:34.798311 22509476222784 run_lib.py:133] step: 1020650, training_loss: 5.41062e-02
I0214 08:09:53.678399 22509476222784 run_lib.py:133] step: 1020700, training_loss: 4.25882e-02
I0214 08:09:53.853035 22509476222784 run_lib.py:146] step: 1020700, eval_loss: 5.36271e-02
I0214 08:10:12.602186 22509476222784 run_lib.py:133] step: 1020750, training_loss: 5.17175e-02
I0214 08:10:31.653231 22509476222784 run_lib.py:133] step: 1020800, training_loss: 4.14104e-02
I0214 08:10:31.821123 22509476222784 run_lib.py:146] step: 1020800, eval_loss: 3.83168e-02
I0214 08:10:50.647874 22509476222784 run_lib.py:133] step: 1020850, training_loss: 4.43608e-02
I0214 08:11:09.563159 22509476222784 run_lib.py:133] step: 1020900, training_loss: 4.07902e-02
I0214 08:11:09.725652 22509476222784 run_lib.py:146] step: 1020900, eval_loss: 3.82244e-02
I0214 08:11:28.514228 22509476222784 run_lib.py:133] step: 1020950, training_loss: 4.02270e-02
I0214 08:11:47.232491 22509476222784 run_lib.py:133] step: 1021000, training_loss: 3.74767e-02
I0214 08:11:47.410084 22509476222784 run_lib.py:146] step: 1021000, eval_loss: 5.12258e-02
I0214 08:12:06.406172 22509476222784 run_lib.py:133] step: 1021050, training_loss: 4.34941e-02
I0214 08:12:25.283385 22509476222784 run_lib.py:133] step: 1021100, training_loss: 5.38589e-02
I0214 08:12:25.451105 22509476222784 run_lib.py:146] step: 1021100, eval_loss: 4.69266e-02
I0214 08:12:44.177062 22509476222784 run_lib.py:133] step: 1021150, training_loss: 3.48257e-02
I0214 08:13:03.012931 22509476222784 run_lib.py:133] step: 1021200, training_loss: 5.28735e-02
I0214 08:13:03.178909 22509476222784 run_lib.py:146] step: 1021200, eval_loss: 4.54516e-02
I0214 08:13:22.088372 22509476222784 run_lib.py:133] step: 1021250, training_loss: 4.65818e-02
I0214 08:13:40.879726 22509476222784 run_lib.py:133] step: 1021300, training_loss: 4.06254e-02
I0214 08:13:41.054278 22509476222784 run_lib.py:146] step: 1021300, eval_loss: 4.25773e-02
I0214 08:13:59.972636 22509476222784 run_lib.py:133] step: 1021350, training_loss: 4.32864e-02
I0214 08:14:18.714334 22509476222784 run_lib.py:133] step: 1021400, training_loss: 4.82417e-02
I0214 08:14:18.876976 22509476222784 run_lib.py:146] step: 1021400, eval_loss: 3.36221e-02
I0214 08:14:37.753677 22509476222784 run_lib.py:133] step: 1021450, training_loss: 5.25712e-02
I0214 08:14:56.536357 22509476222784 run_lib.py:133] step: 1021500, training_loss: 3.45344e-02
I0214 08:14:56.714843 22509476222784 run_lib.py:146] step: 1021500, eval_loss: 3.94679e-02
I0214 08:15:15.738380 22509476222784 run_lib.py:133] step: 1021550, training_loss: 4.57850e-02
I0214 08:15:34.741076 22509476222784 run_lib.py:133] step: 1021600, training_loss: 4.75685e-02
I0214 08:15:34.907865 22509476222784 run_lib.py:146] step: 1021600, eval_loss: 3.98698e-02
I0214 08:15:53.664209 22509476222784 run_lib.py:133] step: 1021650, training_loss: 4.48892e-02
I0214 08:16:12.514855 22509476222784 run_lib.py:133] step: 1021700, training_loss: 3.96169e-02
I0214 08:16:12.690666 22509476222784 run_lib.py:146] step: 1021700, eval_loss: 5.37254e-02
I0214 08:16:31.637258 22509476222784 run_lib.py:133] step: 1021750, training_loss: 3.90812e-02
I0214 08:16:50.495848 22509476222784 run_lib.py:133] step: 1021800, training_loss: 3.18380e-02
I0214 08:16:50.671004 22509476222784 run_lib.py:146] step: 1021800, eval_loss: 4.87309e-02
I0214 08:17:09.699800 22509476222784 run_lib.py:133] step: 1021850, training_loss: 5.15415e-02
I0214 08:17:28.480692 22509476222784 run_lib.py:133] step: 1021900, training_loss: 4.97712e-02
I0214 08:17:28.649411 22509476222784 run_lib.py:146] step: 1021900, eval_loss: 4.30185e-02
I0214 08:17:47.571721 22509476222784 run_lib.py:133] step: 1021950, training_loss: 3.89482e-02
I0214 08:18:06.350982 22509476222784 run_lib.py:133] step: 1022000, training_loss: 4.40249e-02
I0214 08:18:06.533400 22509476222784 run_lib.py:146] step: 1022000, eval_loss: 3.81593e-02
I0214 08:18:25.622030 22509476222784 run_lib.py:133] step: 1022050, training_loss: 3.55697e-02
I0214 08:18:44.378616 22509476222784 run_lib.py:133] step: 1022100, training_loss: 3.39283e-02
I0214 08:18:44.545188 22509476222784 run_lib.py:146] step: 1022100, eval_loss: 4.40540e-02
I0214 08:19:03.454663 22509476222784 run_lib.py:133] step: 1022150, training_loss: 3.80392e-02
I0214 08:19:22.366164 22509476222784 run_lib.py:133] step: 1022200, training_loss: 4.30480e-02
I0214 08:19:22.535415 22509476222784 run_lib.py:146] step: 1022200, eval_loss: 4.97285e-02
I0214 08:19:41.430755 22509476222784 run_lib.py:133] step: 1022250, training_loss: 3.60781e-02
I0214 08:20:00.282565 22509476222784 run_lib.py:133] step: 1022300, training_loss: 4.56740e-02
I0214 08:20:00.448299 22509476222784 run_lib.py:146] step: 1022300, eval_loss: 3.78402e-02
I0214 08:20:19.424244 22509476222784 run_lib.py:133] step: 1022350, training_loss: 4.36659e-02
I0214 08:20:38.487651 22509476222784 run_lib.py:133] step: 1022400, training_loss: 2.90373e-02
I0214 08:20:38.652888 22509476222784 run_lib.py:146] step: 1022400, eval_loss: 4.84365e-02
I0214 08:20:57.412290 22509476222784 run_lib.py:133] step: 1022450, training_loss: 4.64199e-02
I0214 08:21:16.279453 22509476222784 run_lib.py:133] step: 1022500, training_loss: 3.94466e-02
I0214 08:21:16.461650 22509476222784 run_lib.py:146] step: 1022500, eval_loss: 4.53930e-02
I0214 08:21:35.239707 22509476222784 run_lib.py:133] step: 1022550, training_loss: 4.37534e-02
I0214 08:21:54.267289 22509476222784 run_lib.py:133] step: 1022600, training_loss: 3.79345e-02
I0214 08:21:54.438012 22509476222784 run_lib.py:146] step: 1022600, eval_loss: 5.23255e-02
I0214 08:22:13.241291 22509476222784 run_lib.py:133] step: 1022650, training_loss: 4.62857e-02
I0214 08:22:32.053331 22509476222784 run_lib.py:133] step: 1022700, training_loss: 3.37806e-02
I0214 08:22:32.220957 22509476222784 run_lib.py:146] step: 1022700, eval_loss: 4.33842e-02
I0214 08:22:51.088711 22509476222784 run_lib.py:133] step: 1022750, training_loss: 4.22203e-02
I0214 08:23:10.046463 22509476222784 run_lib.py:133] step: 1022800, training_loss: 3.78772e-02
I0214 08:23:10.219064 22509476222784 run_lib.py:146] step: 1022800, eval_loss: 4.17568e-02
I0214 08:23:29.141912 22509476222784 run_lib.py:133] step: 1022850, training_loss: 4.18001e-02
I0214 08:23:47.993716 22509476222784 run_lib.py:133] step: 1022900, training_loss: 3.76000e-02
I0214 08:23:48.160900 22509476222784 run_lib.py:146] step: 1022900, eval_loss: 4.26583e-02
I0214 08:24:06.972742 22509476222784 run_lib.py:133] step: 1022950, training_loss: 4.32216e-02
I0214 08:24:25.751316 22509476222784 run_lib.py:133] step: 1023000, training_loss: 4.73033e-02
I0214 08:24:25.933921 22509476222784 run_lib.py:146] step: 1023000, eval_loss: 3.41996e-02
I0214 08:24:44.968944 22509476222784 run_lib.py:133] step: 1023050, training_loss: 3.88923e-02
I0214 08:25:03.877133 22509476222784 run_lib.py:133] step: 1023100, training_loss: 4.66822e-02
I0214 08:25:04.054178 22509476222784 run_lib.py:146] step: 1023100, eval_loss: 4.38236e-02
I0214 08:25:22.776072 22509476222784 run_lib.py:133] step: 1023150, training_loss: 3.92990e-02
I0214 08:25:41.590340 22509476222784 run_lib.py:133] step: 1023200, training_loss: 4.81945e-02
I0214 08:25:41.771270 22509476222784 run_lib.py:146] step: 1023200, eval_loss: 4.16256e-02
I0214 08:26:00.665569 22509476222784 run_lib.py:133] step: 1023250, training_loss: 5.13162e-02
I0214 08:26:19.433339 22509476222784 run_lib.py:133] step: 1023300, training_loss: 4.56927e-02
I0214 08:26:19.598255 22509476222784 run_lib.py:146] step: 1023300, eval_loss: 5.00427e-02
I0214 08:26:38.692486 22509476222784 run_lib.py:133] step: 1023350, training_loss: 3.76128e-02
I0214 08:26:57.471698 22509476222784 run_lib.py:133] step: 1023400, training_loss: 3.45233e-02
I0214 08:26:57.638104 22509476222784 run_lib.py:146] step: 1023400, eval_loss: 4.54553e-02
I0214 08:27:16.732530 22509476222784 run_lib.py:133] step: 1023450, training_loss: 3.63848e-02
I0214 08:27:35.537701 22509476222784 run_lib.py:133] step: 1023500, training_loss: 4.13098e-02
I0214 08:27:35.704953 22509476222784 run_lib.py:146] step: 1023500, eval_loss: 4.66972e-02
I0214 08:27:54.595006 22509476222784 run_lib.py:133] step: 1023550, training_loss: 4.64767e-02
I0214 08:28:13.548261 22509476222784 run_lib.py:133] step: 1023600, training_loss: 3.21450e-02
I0214 08:28:13.714146 22509476222784 run_lib.py:146] step: 1023600, eval_loss: 3.88812e-02
I0214 08:28:32.496738 22509476222784 run_lib.py:133] step: 1023650, training_loss: 3.72114e-02
I0214 08:28:51.500334 22509476222784 run_lib.py:133] step: 1023700, training_loss: 4.42800e-02
I0214 08:28:51.666706 22509476222784 run_lib.py:146] step: 1023700, eval_loss: 3.46290e-02
I0214 08:29:10.459547 22509476222784 run_lib.py:133] step: 1023750, training_loss: 3.21099e-02
I0214 08:29:29.321589 22509476222784 run_lib.py:133] step: 1023800, training_loss: 4.55294e-02
I0214 08:29:29.501055 22509476222784 run_lib.py:146] step: 1023800, eval_loss: 4.67678e-02
I0214 08:29:48.372801 22509476222784 run_lib.py:133] step: 1023850, training_loss: 4.44761e-02
I0214 08:30:07.062011 22509476222784 run_lib.py:133] step: 1023900, training_loss: 2.93816e-02
I0214 08:30:07.237176 22509476222784 run_lib.py:146] step: 1023900, eval_loss: 3.80501e-02
I0214 08:30:26.018437 22509476222784 run_lib.py:133] step: 1023950, training_loss: 4.80944e-02
I0214 08:30:44.958271 22509476222784 run_lib.py:133] step: 1024000, training_loss: 3.87923e-02
I0214 08:30:45.124158 22509476222784 run_lib.py:146] step: 1024000, eval_loss: 4.51951e-02
I0214 08:31:03.981199 22509476222784 run_lib.py:133] step: 1024050, training_loss: 4.43874e-02
I0214 08:31:22.685143 22509476222784 run_lib.py:133] step: 1024100, training_loss: 3.61262e-02
I0214 08:31:22.850619 22509476222784 run_lib.py:146] step: 1024100, eval_loss: 5.34844e-02
I0214 08:31:41.779087 22509476222784 run_lib.py:133] step: 1024150, training_loss: 3.28497e-02
I0214 08:32:00.472744 22509476222784 run_lib.py:133] step: 1024200, training_loss: 4.18441e-02
I0214 08:32:00.635025 22509476222784 run_lib.py:146] step: 1024200, eval_loss: 4.83091e-02
I0214 08:32:19.383624 22509476222784 run_lib.py:133] step: 1024250, training_loss: 3.06486e-02
I0214 08:32:38.254225 22509476222784 run_lib.py:133] step: 1024300, training_loss: 4.02429e-02
I0214 08:32:38.427111 22509476222784 run_lib.py:146] step: 1024300, eval_loss: 3.70641e-02
I0214 08:32:57.326711 22509476222784 run_lib.py:133] step: 1024350, training_loss: 3.97880e-02
I0214 08:33:16.306899 22509476222784 run_lib.py:133] step: 1024400, training_loss: 4.51501e-02
I0214 08:33:16.474913 22509476222784 run_lib.py:146] step: 1024400, eval_loss: 3.06900e-02
I0214 08:33:35.203319 22509476222784 run_lib.py:133] step: 1024450, training_loss: 4.21756e-02
I0214 08:33:54.033747 22509476222784 run_lib.py:133] step: 1024500, training_loss: 4.04548e-02
I0214 08:33:54.212942 22509476222784 run_lib.py:146] step: 1024500, eval_loss: 4.87892e-02
I0214 08:34:13.196028 22509476222784 run_lib.py:133] step: 1024550, training_loss: 3.50073e-02
I0214 08:34:31.944019 22509476222784 run_lib.py:133] step: 1024600, training_loss: 4.29678e-02
I0214 08:34:32.116817 22509476222784 run_lib.py:146] step: 1024600, eval_loss: 4.18475e-02
I0214 08:34:51.174363 22509476222784 run_lib.py:133] step: 1024650, training_loss: 4.83687e-02
I0214 08:35:09.822367 22509476222784 run_lib.py:133] step: 1024700, training_loss: 4.58696e-02
I0214 08:35:10.006943 22509476222784 run_lib.py:146] step: 1024700, eval_loss: 3.63264e-02
I0214 08:35:29.020542 22509476222784 run_lib.py:133] step: 1024750, training_loss: 2.95441e-02
I0214 08:35:47.745057 22509476222784 run_lib.py:133] step: 1024800, training_loss: 4.31986e-02
I0214 08:35:47.922204 22509476222784 run_lib.py:146] step: 1024800, eval_loss: 3.21212e-02
I0214 08:36:06.942354 22509476222784 run_lib.py:133] step: 1024850, training_loss: 3.18672e-02
I0214 08:36:25.734531 22509476222784 run_lib.py:133] step: 1024900, training_loss: 5.24132e-02
I0214 08:36:25.903219 22509476222784 run_lib.py:146] step: 1024900, eval_loss: 5.20738e-02
I0214 08:36:44.629452 22509476222784 run_lib.py:133] step: 1024950, training_loss: 4.93112e-02
I0214 08:37:03.610156 22509476222784 run_lib.py:133] step: 1025000, training_loss: 4.15345e-02
I0214 08:37:03.775079 22509476222784 run_lib.py:146] step: 1025000, eval_loss: 4.40105e-02
I0214 08:37:22.455612 22509476222784 run_lib.py:133] step: 1025050, training_loss: 4.80716e-02
I0214 08:37:41.347817 22509476222784 run_lib.py:133] step: 1025100, training_loss: 4.06347e-02
I0214 08:37:41.517229 22509476222784 run_lib.py:146] step: 1025100, eval_loss: 5.05854e-02
I0214 08:38:00.494808 22509476222784 run_lib.py:133] step: 1025150, training_loss: 4.06948e-02
I0214 08:38:19.216161 22509476222784 run_lib.py:133] step: 1025200, training_loss: 3.47715e-02
I0214 08:38:19.378966 22509476222784 run_lib.py:146] step: 1025200, eval_loss: 3.30150e-02
I0214 08:38:38.453231 22509476222784 run_lib.py:133] step: 1025250, training_loss: 3.81264e-02
I0214 08:38:57.203131 22509476222784 run_lib.py:133] step: 1025300, training_loss: 3.81381e-02
I0214 08:38:57.372147 22509476222784 run_lib.py:146] step: 1025300, eval_loss: 3.72333e-02
I0214 08:39:16.287564 22509476222784 run_lib.py:133] step: 1025350, training_loss: 5.37459e-02
I0214 08:39:35.248222 22509476222784 run_lib.py:133] step: 1025400, training_loss: 3.33436e-02
I0214 08:39:35.423022 22509476222784 run_lib.py:146] step: 1025400, eval_loss: 2.99311e-02
I0214 08:39:54.225219 22509476222784 run_lib.py:133] step: 1025450, training_loss: 3.73864e-02
I0214 08:40:13.015532 22509476222784 run_lib.py:133] step: 1025500, training_loss: 4.11728e-02
I0214 08:40:13.178428 22509476222784 run_lib.py:146] step: 1025500, eval_loss: 5.49643e-02
I0214 08:40:31.947653 22509476222784 run_lib.py:133] step: 1025550, training_loss: 4.25287e-02
I0214 08:40:51.087523 22509476222784 run_lib.py:133] step: 1025600, training_loss: 4.68482e-02
I0214 08:40:51.260705 22509476222784 run_lib.py:146] step: 1025600, eval_loss: 5.14193e-02
I0214 08:41:10.033745 22509476222784 run_lib.py:133] step: 1025650, training_loss: 3.73111e-02
I0214 08:41:28.941456 22509476222784 run_lib.py:133] step: 1025700, training_loss: 5.22000e-02
I0214 08:41:29.108980 22509476222784 run_lib.py:146] step: 1025700, eval_loss: 4.08983e-02
I0214 08:41:47.916099 22509476222784 run_lib.py:133] step: 1025750, training_loss: 4.20872e-02
I0214 08:42:06.703694 22509476222784 run_lib.py:133] step: 1025800, training_loss: 3.21703e-02
I0214 08:42:06.873184 22509476222784 run_lib.py:146] step: 1025800, eval_loss: 5.20137e-02
I0214 08:42:25.907652 22509476222784 run_lib.py:133] step: 1025850, training_loss: 3.95174e-02
I0214 08:42:44.749754 22509476222784 run_lib.py:133] step: 1025900, training_loss: 3.89787e-02
I0214 08:42:44.929193 22509476222784 run_lib.py:146] step: 1025900, eval_loss: 4.89484e-02
I0214 08:43:03.827215 22509476222784 run_lib.py:133] step: 1025950, training_loss: 4.38615e-02
I0214 08:43:22.593412 22509476222784 run_lib.py:133] step: 1026000, training_loss: 4.29847e-02
I0214 08:43:22.760709 22509476222784 run_lib.py:146] step: 1026000, eval_loss: 4.55193e-02
I0214 08:43:41.778919 22509476222784 run_lib.py:133] step: 1026050, training_loss: 4.02229e-02
I0214 08:44:00.566674 22509476222784 run_lib.py:133] step: 1026100, training_loss: 2.70214e-02
I0214 08:44:00.729239 22509476222784 run_lib.py:146] step: 1026100, eval_loss: 5.74465e-02
I0214 08:44:19.757161 22509476222784 run_lib.py:133] step: 1026150, training_loss: 4.61718e-02
I0214 08:44:38.597342 22509476222784 run_lib.py:133] step: 1026200, training_loss: 3.72239e-02
I0214 08:44:38.764456 22509476222784 run_lib.py:146] step: 1026200, eval_loss: 3.86034e-02
I0214 08:44:57.728705 22509476222784 run_lib.py:133] step: 1026250, training_loss: 5.80268e-02
I0214 08:45:16.679071 22509476222784 run_lib.py:133] step: 1026300, training_loss: 4.23050e-02
I0214 08:45:16.848283 22509476222784 run_lib.py:146] step: 1026300, eval_loss: 3.62628e-02
I0214 08:45:35.666801 22509476222784 run_lib.py:133] step: 1026350, training_loss: 2.56586e-02
I0214 08:45:54.697907 22509476222784 run_lib.py:133] step: 1026400, training_loss: 5.18272e-02
I0214 08:45:54.864177 22509476222784 run_lib.py:146] step: 1026400, eval_loss: 5.08673e-02
I0214 08:46:13.658696 22509476222784 run_lib.py:133] step: 1026450, training_loss: 4.54937e-02
I0214 08:46:32.547277 22509476222784 run_lib.py:133] step: 1026500, training_loss: 3.35696e-02
I0214 08:46:32.712977 22509476222784 run_lib.py:146] step: 1026500, eval_loss: 4.45340e-02
I0214 08:46:51.613072 22509476222784 run_lib.py:133] step: 1026550, training_loss: 4.29511e-02
I0214 08:47:10.407702 22509476222784 run_lib.py:133] step: 1026600, training_loss: 4.42059e-02
I0214 08:47:10.573159 22509476222784 run_lib.py:146] step: 1026600, eval_loss: 4.52481e-02
I0214 08:47:29.699625 22509476222784 run_lib.py:133] step: 1026650, training_loss: 4.29201e-02
I0214 08:47:48.470983 22509476222784 run_lib.py:133] step: 1026700, training_loss: 4.11311e-02
I0214 08:47:48.649966 22509476222784 run_lib.py:146] step: 1026700, eval_loss: 3.52362e-02
I0214 08:48:07.431957 22509476222784 run_lib.py:133] step: 1026750, training_loss: 2.78557e-02
I0214 08:48:26.335521 22509476222784 run_lib.py:133] step: 1026800, training_loss: 3.01448e-02
I0214 08:48:26.503256 22509476222784 run_lib.py:146] step: 1026800, eval_loss: 4.40000e-02
I0214 08:48:45.197767 22509476222784 run_lib.py:133] step: 1026850, training_loss: 5.09017e-02
I0214 08:49:04.173134 22509476222784 run_lib.py:133] step: 1026900, training_loss: 4.55369e-02
I0214 08:49:04.505105 22509476222784 run_lib.py:146] step: 1026900, eval_loss: 4.70010e-02
I0214 08:49:23.202459 22509476222784 run_lib.py:133] step: 1026950, training_loss: 4.20686e-02
I0214 08:49:42.012550 22509476222784 run_lib.py:133] step: 1027000, training_loss: 3.40727e-02
I0214 08:49:42.188275 22509476222784 run_lib.py:146] step: 1027000, eval_loss: 3.54377e-02
I0214 08:50:00.872527 22509476222784 run_lib.py:133] step: 1027050, training_loss: 4.35513e-02
I0214 08:50:19.625940 22509476222784 run_lib.py:133] step: 1027100, training_loss: 4.50001e-02
I0214 08:50:19.790320 22509476222784 run_lib.py:146] step: 1027100, eval_loss: 4.42789e-02
I0214 08:50:38.834584 22509476222784 run_lib.py:133] step: 1027150, training_loss: 3.68916e-02
I0214 08:50:57.741623 22509476222784 run_lib.py:133] step: 1027200, training_loss: 3.44050e-02
I0214 08:50:57.911004 22509476222784 run_lib.py:146] step: 1027200, eval_loss: 4.77702e-02
I0214 08:51:16.710407 22509476222784 run_lib.py:133] step: 1027250, training_loss: 4.60826e-02
I0214 08:51:35.488665 22509476222784 run_lib.py:133] step: 1027300, training_loss: 4.31485e-02
I0214 08:51:35.664605 22509476222784 run_lib.py:146] step: 1027300, eval_loss: 4.57505e-02
I0214 08:51:54.707054 22509476222784 run_lib.py:133] step: 1027350, training_loss: 3.72716e-02
I0214 08:52:13.616597 22509476222784 run_lib.py:133] step: 1027400, training_loss: 3.83250e-02
I0214 08:52:13.792456 22509476222784 run_lib.py:146] step: 1027400, eval_loss: 4.48370e-02
I0214 08:52:32.699646 22509476222784 run_lib.py:133] step: 1027450, training_loss: 4.44755e-02
I0214 08:52:51.485770 22509476222784 run_lib.py:133] step: 1027500, training_loss: 4.40392e-02
I0214 08:52:51.651017 22509476222784 run_lib.py:146] step: 1027500, eval_loss: 5.22419e-02
I0214 08:53:10.649933 22509476222784 run_lib.py:133] step: 1027550, training_loss: 4.52911e-02
I0214 08:53:29.439393 22509476222784 run_lib.py:133] step: 1027600, training_loss: 3.55931e-02
I0214 08:53:29.602966 22509476222784 run_lib.py:146] step: 1027600, eval_loss: 4.14340e-02
I0214 08:53:48.536063 22509476222784 run_lib.py:133] step: 1027650, training_loss: 4.31897e-02
I0214 08:54:07.545693 22509476222784 run_lib.py:133] step: 1027700, training_loss: 3.70901e-02
I0214 08:54:07.723304 22509476222784 run_lib.py:146] step: 1027700, eval_loss: 5.07519e-02
I0214 08:54:26.679215 22509476222784 run_lib.py:133] step: 1027750, training_loss: 3.27095e-02
I0214 08:54:45.466020 22509476222784 run_lib.py:133] step: 1027800, training_loss: 4.94428e-02
I0214 08:54:45.629919 22509476222784 run_lib.py:146] step: 1027800, eval_loss: 4.14280e-02
I0214 08:55:04.415894 22509476222784 run_lib.py:133] step: 1027850, training_loss: 3.62450e-02
I0214 08:55:23.388904 22509476222784 run_lib.py:133] step: 1027900, training_loss: 3.58192e-02
I0214 08:55:23.555748 22509476222784 run_lib.py:146] step: 1027900, eval_loss: 5.27833e-02
I0214 08:55:42.431327 22509476222784 run_lib.py:133] step: 1027950, training_loss: 4.59138e-02
I0214 08:56:01.382958 22509476222784 run_lib.py:133] step: 1028000, training_loss: 4.95340e-02
I0214 08:56:01.554451 22509476222784 run_lib.py:146] step: 1028000, eval_loss: 5.23007e-02
I0214 08:56:20.440304 22509476222784 run_lib.py:133] step: 1028050, training_loss: 5.01272e-02
I0214 08:56:39.167259 22509476222784 run_lib.py:133] step: 1028100, training_loss: 5.05156e-02
I0214 08:56:39.333972 22509476222784 run_lib.py:146] step: 1028100, eval_loss: 3.88777e-02
I0214 08:56:58.205957 22509476222784 run_lib.py:133] step: 1028150, training_loss: 4.36124e-02
I0214 08:57:16.995623 22509476222784 run_lib.py:133] step: 1028200, training_loss: 4.20333e-02
I0214 08:57:17.176993 22509476222784 run_lib.py:146] step: 1028200, eval_loss: 4.01509e-02
I0214 08:57:36.024487 22509476222784 run_lib.py:133] step: 1028250, training_loss: 4.31828e-02
I0214 08:57:54.870288 22509476222784 run_lib.py:133] step: 1028300, training_loss: 5.04898e-02
I0214 08:57:55.037035 22509476222784 run_lib.py:146] step: 1028300, eval_loss: 3.52561e-02
I0214 08:58:13.939049 22509476222784 run_lib.py:133] step: 1028350, training_loss: 5.00445e-02
I0214 08:58:32.895774 22509476222784 run_lib.py:133] step: 1028400, training_loss: 4.65481e-02
I0214 08:58:33.065251 22509476222784 run_lib.py:146] step: 1028400, eval_loss: 5.23847e-02
I0214 08:58:51.980218 22509476222784 run_lib.py:133] step: 1028450, training_loss: 3.67322e-02
I0214 08:59:10.819967 22509476222784 run_lib.py:133] step: 1028500, training_loss: 3.90954e-02
I0214 08:59:10.982090 22509476222784 run_lib.py:146] step: 1028500, eval_loss: 4.15454e-02
I0214 08:59:29.780435 22509476222784 run_lib.py:133] step: 1028550, training_loss: 4.29522e-02
I0214 08:59:48.487837 22509476222784 run_lib.py:133] step: 1028600, training_loss: 4.02606e-02
I0214 08:59:48.653878 22509476222784 run_lib.py:146] step: 1028600, eval_loss: 4.08684e-02
I0214 09:00:07.725619 22509476222784 run_lib.py:133] step: 1028650, training_loss: 4.30412e-02
I0214 09:00:26.611885 22509476222784 run_lib.py:133] step: 1028700, training_loss: 3.66051e-02
I0214 09:00:26.782911 22509476222784 run_lib.py:146] step: 1028700, eval_loss: 4.91266e-02
I0214 09:00:45.589223 22509476222784 run_lib.py:133] step: 1028750, training_loss: 3.91058e-02
I0214 09:01:04.288113 22509476222784 run_lib.py:133] step: 1028800, training_loss: 3.32463e-02
I0214 09:01:04.454722 22509476222784 run_lib.py:146] step: 1028800, eval_loss: 4.80541e-02
I0214 09:01:23.353770 22509476222784 run_lib.py:133] step: 1028850, training_loss: 4.05388e-02
I0214 09:01:42.141972 22509476222784 run_lib.py:133] step: 1028900, training_loss: 4.37061e-02
I0214 09:01:42.307530 22509476222784 run_lib.py:146] step: 1028900, eval_loss: 4.71136e-02
I0214 09:02:01.282432 22509476222784 run_lib.py:133] step: 1028950, training_loss: 4.38760e-02
I0214 09:02:20.120078 22509476222784 run_lib.py:133] step: 1029000, training_loss: 4.51058e-02
I0214 09:02:20.283072 22509476222784 run_lib.py:146] step: 1029000, eval_loss: 3.29678e-02
I0214 09:02:39.203205 22509476222784 run_lib.py:133] step: 1029050, training_loss: 5.12946e-02
I0214 09:02:58.030798 22509476222784 run_lib.py:133] step: 1029100, training_loss: 4.64982e-02
I0214 09:02:58.199411 22509476222784 run_lib.py:146] step: 1029100, eval_loss: 3.87751e-02
I0214 09:03:17.125353 22509476222784 run_lib.py:133] step: 1029150, training_loss: 5.08326e-02
I0214 09:03:35.998077 22509476222784 run_lib.py:133] step: 1029200, training_loss: 4.62137e-02
I0214 09:03:36.170949 22509476222784 run_lib.py:146] step: 1029200, eval_loss: 4.73159e-02
I0214 09:03:54.950122 22509476222784 run_lib.py:133] step: 1029250, training_loss: 4.77759e-02
I0214 09:04:13.906040 22509476222784 run_lib.py:133] step: 1029300, training_loss: 4.09427e-02
I0214 09:04:14.069946 22509476222784 run_lib.py:146] step: 1029300, eval_loss: 5.03494e-02
I0214 09:04:32.935160 22509476222784 run_lib.py:133] step: 1029350, training_loss: 4.95480e-02
I0214 09:04:51.709589 22509476222784 run_lib.py:133] step: 1029400, training_loss: 3.12067e-02
I0214 09:04:51.874977 22509476222784 run_lib.py:146] step: 1029400, eval_loss: 4.72295e-02
I0214 09:05:10.985888 22509476222784 run_lib.py:133] step: 1029450, training_loss: 4.01621e-02
I0214 09:05:29.859974 22509476222784 run_lib.py:133] step: 1029500, training_loss: 4.99703e-02
I0214 09:05:30.023909 22509476222784 run_lib.py:146] step: 1029500, eval_loss: 3.76701e-02
I0214 09:05:48.801439 22509476222784 run_lib.py:133] step: 1029550, training_loss: 4.91129e-02
I0214 09:06:07.610096 22509476222784 run_lib.py:133] step: 1029600, training_loss: 5.29236e-02
I0214 09:06:07.790415 22509476222784 run_lib.py:146] step: 1029600, eval_loss: 4.94208e-02
I0214 09:06:26.543259 22509476222784 run_lib.py:133] step: 1029650, training_loss: 3.87684e-02
I0214 09:06:45.617886 22509476222784 run_lib.py:133] step: 1029700, training_loss: 3.90506e-02
I0214 09:06:45.784085 22509476222784 run_lib.py:146] step: 1029700, eval_loss: 4.88542e-02
I0214 09:07:04.544604 22509476222784 run_lib.py:133] step: 1029750, training_loss: 3.88960e-02
I0214 09:07:23.323772 22509476222784 run_lib.py:133] step: 1029800, training_loss: 3.35659e-02
I0214 09:07:23.490067 22509476222784 run_lib.py:146] step: 1029800, eval_loss: 4.60432e-02
I0214 09:07:42.277048 22509476222784 run_lib.py:133] step: 1029850, training_loss: 4.77902e-02
I0214 09:08:01.217644 22509476222784 run_lib.py:133] step: 1029900, training_loss: 5.71785e-02
I0214 09:08:01.387513 22509476222784 run_lib.py:146] step: 1029900, eval_loss: 4.36375e-02
I0214 09:08:20.300109 22509476222784 run_lib.py:133] step: 1029950, training_loss: 4.46994e-02
I0214 09:08:39.120141 22509476222784 run_lib.py:133] step: 1030000, training_loss: 4.21633e-02
I0214 09:08:39.927955 22509476222784 run_lib.py:146] step: 1030000, eval_loss: 3.70107e-02
I0214 09:09:01.537638 22509476222784 run_lib.py:133] step: 1030050, training_loss: 5.24589e-02
I0214 09:09:20.287592 22509476222784 run_lib.py:133] step: 1030100, training_loss: 4.18776e-02
I0214 09:09:20.454331 22509476222784 run_lib.py:146] step: 1030100, eval_loss: 3.66638e-02
I0214 09:09:39.187638 22509476222784 run_lib.py:133] step: 1030150, training_loss: 3.64540e-02
I0214 09:09:58.223619 22509476222784 run_lib.py:133] step: 1030200, training_loss: 3.54443e-02
I0214 09:09:58.400870 22509476222784 run_lib.py:146] step: 1030200, eval_loss: 4.47304e-02
I0214 09:10:17.089664 22509476222784 run_lib.py:133] step: 1030250, training_loss: 4.44349e-02
I0214 09:10:36.102845 22509476222784 run_lib.py:133] step: 1030300, training_loss: 4.30561e-02
I0214 09:10:36.270008 22509476222784 run_lib.py:146] step: 1030300, eval_loss: 4.42958e-02
I0214 09:10:54.893295 22509476222784 run_lib.py:133] step: 1030350, training_loss: 4.95997e-02
I0214 09:11:13.645472 22509476222784 run_lib.py:133] step: 1030400, training_loss: 4.59875e-02
I0214 09:11:13.810163 22509476222784 run_lib.py:146] step: 1030400, eval_loss: 3.38724e-02
I0214 09:11:32.836281 22509476222784 run_lib.py:133] step: 1030450, training_loss: 4.29585e-02
I0214 09:11:51.759891 22509476222784 run_lib.py:133] step: 1030500, training_loss: 4.19807e-02
I0214 09:11:51.929713 22509476222784 run_lib.py:146] step: 1030500, eval_loss: 4.53024e-02
I0214 09:12:10.737333 22509476222784 run_lib.py:133] step: 1030550, training_loss: 3.95033e-02
I0214 09:12:29.470130 22509476222784 run_lib.py:133] step: 1030600, training_loss: 4.62685e-02
I0214 09:12:29.639468 22509476222784 run_lib.py:146] step: 1030600, eval_loss: 4.57745e-02
I0214 09:12:48.650768 22509476222784 run_lib.py:133] step: 1030650, training_loss: 4.34409e-02
I0214 09:13:07.412364 22509476222784 run_lib.py:133] step: 1030700, training_loss: 3.95323e-02
I0214 09:13:07.583078 22509476222784 run_lib.py:146] step: 1030700, eval_loss: 4.80046e-02
I0214 09:13:26.662903 22509476222784 run_lib.py:133] step: 1030750, training_loss: 5.61041e-02
I0214 09:13:45.452857 22509476222784 run_lib.py:133] step: 1030800, training_loss: 3.42705e-02
I0214 09:13:45.618723 22509476222784 run_lib.py:146] step: 1030800, eval_loss: 4.09224e-02
I0214 09:14:04.603380 22509476222784 run_lib.py:133] step: 1030850, training_loss: 4.06238e-02
I0214 09:14:23.374665 22509476222784 run_lib.py:133] step: 1030900, training_loss: 4.16228e-02
I0214 09:14:23.540780 22509476222784 run_lib.py:146] step: 1030900, eval_loss: 3.82961e-02
I0214 09:14:42.288696 22509476222784 run_lib.py:133] step: 1030950, training_loss: 5.01705e-02
I0214 09:15:01.368522 22509476222784 run_lib.py:133] step: 1031000, training_loss: 4.36113e-02
I0214 09:15:01.680076 22509476222784 run_lib.py:146] step: 1031000, eval_loss: 3.83252e-02
I0214 09:15:20.452596 22509476222784 run_lib.py:133] step: 1031050, training_loss: 3.30148e-02
I0214 09:15:39.436525 22509476222784 run_lib.py:133] step: 1031100, training_loss: 4.15936e-02
I0214 09:15:39.609127 22509476222784 run_lib.py:146] step: 1031100, eval_loss: 3.61466e-02
I0214 09:15:58.282009 22509476222784 run_lib.py:133] step: 1031150, training_loss: 3.94313e-02
I0214 09:16:16.994674 22509476222784 run_lib.py:133] step: 1031200, training_loss: 4.99164e-02
I0214 09:16:17.174392 22509476222784 run_lib.py:146] step: 1031200, eval_loss: 3.25792e-02
I0214 09:16:36.215973 22509476222784 run_lib.py:133] step: 1031250, training_loss: 3.45903e-02
I0214 09:16:54.981110 22509476222784 run_lib.py:133] step: 1031300, training_loss: 3.95761e-02
I0214 09:16:55.152769 22509476222784 run_lib.py:146] step: 1031300, eval_loss: 3.43099e-02
I0214 09:17:14.050621 22509476222784 run_lib.py:133] step: 1031350, training_loss: 3.79398e-02
I0214 09:17:32.924341 22509476222784 run_lib.py:133] step: 1031400, training_loss: 6.17696e-02
I0214 09:17:33.086774 22509476222784 run_lib.py:146] step: 1031400, eval_loss: 3.33898e-02
I0214 09:17:51.909236 22509476222784 run_lib.py:133] step: 1031450, training_loss: 3.51769e-02
I0214 09:18:10.718656 22509476222784 run_lib.py:133] step: 1031500, training_loss: 3.74288e-02
I0214 09:18:10.896125 22509476222784 run_lib.py:146] step: 1031500, eval_loss: 3.77980e-02
I0214 09:18:29.821113 22509476222784 run_lib.py:133] step: 1031550, training_loss: 4.81281e-02
I0214 09:18:48.707231 22509476222784 run_lib.py:133] step: 1031600, training_loss: 4.59077e-02
I0214 09:18:48.879130 22509476222784 run_lib.py:146] step: 1031600, eval_loss: 4.32098e-02
I0214 09:19:07.588208 22509476222784 run_lib.py:133] step: 1031650, training_loss: 3.77039e-02
I0214 09:19:26.455024 22509476222784 run_lib.py:133] step: 1031700, training_loss: 6.17505e-02
I0214 09:19:26.623085 22509476222784 run_lib.py:146] step: 1031700, eval_loss: 4.61698e-02
I0214 09:19:45.493898 22509476222784 run_lib.py:133] step: 1031750, training_loss: 4.52062e-02
I0214 09:20:04.463588 22509476222784 run_lib.py:133] step: 1031800, training_loss: 3.63017e-02
I0214 09:20:04.631253 22509476222784 run_lib.py:146] step: 1031800, eval_loss: 3.98376e-02
I0214 09:20:23.423703 22509476222784 run_lib.py:133] step: 1031850, training_loss: 5.06664e-02
I0214 09:20:42.083228 22509476222784 run_lib.py:133] step: 1031900, training_loss: 5.05197e-02
I0214 09:20:42.246917 22509476222784 run_lib.py:146] step: 1031900, eval_loss: 3.41130e-02
I0214 09:21:01.290099 22509476222784 run_lib.py:133] step: 1031950, training_loss: 2.83700e-02
I0214 09:21:20.043595 22509476222784 run_lib.py:133] step: 1032000, training_loss: 3.56083e-02
I0214 09:21:20.211870 22509476222784 run_lib.py:146] step: 1032000, eval_loss: 3.94419e-02
I0214 09:21:39.226475 22509476222784 run_lib.py:133] step: 1032050, training_loss: 4.76431e-02
I0214 09:21:58.023649 22509476222784 run_lib.py:133] step: 1032100, training_loss: 3.45815e-02
I0214 09:21:58.191901 22509476222784 run_lib.py:146] step: 1032100, eval_loss: 5.33484e-02
I0214 09:22:17.125428 22509476222784 run_lib.py:133] step: 1032150, training_loss: 3.90552e-02
I0214 09:22:35.905020 22509476222784 run_lib.py:133] step: 1032200, training_loss: 3.40685e-02
I0214 09:22:36.070971 22509476222784 run_lib.py:146] step: 1032200, eval_loss: 4.18633e-02
I0214 09:22:54.936283 22509476222784 run_lib.py:133] step: 1032250, training_loss: 3.85959e-02
I0214 09:23:13.711668 22509476222784 run_lib.py:133] step: 1032300, training_loss: 4.36243e-02
I0214 09:23:13.877260 22509476222784 run_lib.py:146] step: 1032300, eval_loss: 3.58663e-02
I0214 09:23:32.656847 22509476222784 run_lib.py:133] step: 1032350, training_loss: 4.52574e-02
I0214 09:23:51.775710 22509476222784 run_lib.py:133] step: 1032400, training_loss: 5.00142e-02
I0214 09:23:51.947199 22509476222784 run_lib.py:146] step: 1032400, eval_loss: 6.30866e-02
I0214 09:24:10.748460 22509476222784 run_lib.py:133] step: 1032450, training_loss: 4.51405e-02
I0214 09:24:29.504202 22509476222784 run_lib.py:133] step: 1032500, training_loss: 4.18657e-02
I0214 09:24:29.673344 22509476222784 run_lib.py:146] step: 1032500, eval_loss: 3.41753e-02
I0214 09:24:48.670486 22509476222784 run_lib.py:133] step: 1032550, training_loss: 4.09465e-02
I0214 09:25:07.459261 22509476222784 run_lib.py:133] step: 1032600, training_loss: 2.99238e-02
I0214 09:25:07.639899 22509476222784 run_lib.py:146] step: 1032600, eval_loss: 4.02398e-02
I0214 09:25:26.746162 22509476222784 run_lib.py:133] step: 1032650, training_loss: 3.52575e-02
I0214 09:25:45.511505 22509476222784 run_lib.py:133] step: 1032700, training_loss: 4.03177e-02
I0214 09:25:45.677368 22509476222784 run_lib.py:146] step: 1032700, eval_loss: 4.59779e-02
I0214 09:26:04.616727 22509476222784 run_lib.py:133] step: 1032750, training_loss: 3.20746e-02
I0214 09:26:23.606904 22509476222784 run_lib.py:133] step: 1032800, training_loss: 4.75770e-02
I0214 09:26:23.774029 22509476222784 run_lib.py:146] step: 1032800, eval_loss: 4.05427e-02
I0214 09:26:42.555685 22509476222784 run_lib.py:133] step: 1032850, training_loss: 4.68004e-02
I0214 09:27:01.441332 22509476222784 run_lib.py:133] step: 1032900, training_loss: 3.69298e-02
I0214 09:27:01.617369 22509476222784 run_lib.py:146] step: 1032900, eval_loss: 4.87212e-02
I0214 09:27:20.409090 22509476222784 run_lib.py:133] step: 1032950, training_loss: 4.19424e-02
I0214 09:27:39.375551 22509476222784 run_lib.py:133] step: 1033000, training_loss: 3.65836e-02
I0214 09:27:39.554174 22509476222784 run_lib.py:146] step: 1033000, eval_loss: 2.70186e-02
I0214 09:27:58.430682 22509476222784 run_lib.py:133] step: 1033050, training_loss: 4.83912e-02
I0214 09:28:17.242195 22509476222784 run_lib.py:133] step: 1033100, training_loss: 4.26909e-02
I0214 09:28:17.417942 22509476222784 run_lib.py:146] step: 1033100, eval_loss: 5.13758e-02
I0214 09:28:36.361799 22509476222784 run_lib.py:133] step: 1033150, training_loss: 4.98505e-02
I0214 09:28:55.163347 22509476222784 run_lib.py:133] step: 1033200, training_loss: 4.30712e-02
I0214 09:28:55.329281 22509476222784 run_lib.py:146] step: 1033200, eval_loss: 3.51065e-02
I0214 09:29:14.356400 22509476222784 run_lib.py:133] step: 1033250, training_loss: 3.89507e-02
I0214 09:29:33.163192 22509476222784 run_lib.py:133] step: 1033300, training_loss: 3.44407e-02
I0214 09:29:33.326059 22509476222784 run_lib.py:146] step: 1033300, eval_loss: 3.91226e-02
I0214 09:29:52.147913 22509476222784 run_lib.py:133] step: 1033350, training_loss: 4.36522e-02
I0214 09:30:11.064088 22509476222784 run_lib.py:133] step: 1033400, training_loss: 3.44174e-02
I0214 09:30:11.242212 22509476222784 run_lib.py:146] step: 1033400, eval_loss: 4.28882e-02
I0214 09:30:30.194914 22509476222784 run_lib.py:133] step: 1033450, training_loss: 4.32509e-02
I0214 09:30:49.032451 22509476222784 run_lib.py:133] step: 1033500, training_loss: 4.56716e-02
I0214 09:30:49.200214 22509476222784 run_lib.py:146] step: 1033500, eval_loss: 3.98341e-02
I0214 09:31:08.081566 22509476222784 run_lib.py:133] step: 1033550, training_loss: 4.06138e-02
I0214 09:31:26.944014 22509476222784 run_lib.py:133] step: 1033600, training_loss: 3.92880e-02
I0214 09:31:27.122914 22509476222784 run_lib.py:146] step: 1033600, eval_loss: 4.47664e-02
I0214 09:31:46.057878 22509476222784 run_lib.py:133] step: 1033650, training_loss: 3.05440e-02
I0214 09:32:04.821506 22509476222784 run_lib.py:133] step: 1033700, training_loss: 3.21944e-02
I0214 09:32:04.989017 22509476222784 run_lib.py:146] step: 1033700, eval_loss: 2.63902e-02
I0214 09:32:23.962286 22509476222784 run_lib.py:133] step: 1033750, training_loss: 5.02501e-02
I0214 09:32:42.825600 22509476222784 run_lib.py:133] step: 1033800, training_loss: 5.06949e-02
I0214 09:32:42.996055 22509476222784 run_lib.py:146] step: 1033800, eval_loss: 4.31536e-02
I0214 09:33:01.840199 22509476222784 run_lib.py:133] step: 1033850, training_loss: 4.80135e-02
I0214 09:33:20.772104 22509476222784 run_lib.py:133] step: 1033900, training_loss: 3.62123e-02
I0214 09:33:20.948793 22509476222784 run_lib.py:146] step: 1033900, eval_loss: 3.64029e-02
I0214 09:33:39.850126 22509476222784 run_lib.py:133] step: 1033950, training_loss: 4.94008e-02
I0214 09:33:58.639791 22509476222784 run_lib.py:133] step: 1034000, training_loss: 3.87699e-02
I0214 09:33:58.825417 22509476222784 run_lib.py:146] step: 1034000, eval_loss: 4.48082e-02
I0214 09:34:17.712690 22509476222784 run_lib.py:133] step: 1034050, training_loss: 4.74848e-02
I0214 09:34:36.550522 22509476222784 run_lib.py:133] step: 1034100, training_loss: 4.08256e-02
I0214 09:34:36.727159 22509476222784 run_lib.py:146] step: 1034100, eval_loss: 4.37291e-02
I0214 09:34:55.528119 22509476222784 run_lib.py:133] step: 1034150, training_loss: 3.45866e-02
I0214 09:35:14.602698 22509476222784 run_lib.py:133] step: 1034200, training_loss: 4.38262e-02
I0214 09:35:14.769364 22509476222784 run_lib.py:146] step: 1034200, eval_loss: 3.79941e-02
I0214 09:35:33.531651 22509476222784 run_lib.py:133] step: 1034250, training_loss: 5.00002e-02
I0214 09:35:52.317663 22509476222784 run_lib.py:133] step: 1034300, training_loss: 4.21132e-02
I0214 09:35:52.639889 22509476222784 run_lib.py:146] step: 1034300, eval_loss: 4.90255e-02
I0214 09:36:11.490349 22509476222784 run_lib.py:133] step: 1034350, training_loss: 3.00227e-02
I0214 09:36:30.229142 22509476222784 run_lib.py:133] step: 1034400, training_loss: 4.65453e-02
I0214 09:36:30.413040 22509476222784 run_lib.py:146] step: 1034400, eval_loss: 3.61140e-02
I0214 09:36:49.323452 22509476222784 run_lib.py:133] step: 1034450, training_loss: 4.57669e-02
I0214 09:37:08.068250 22509476222784 run_lib.py:133] step: 1034500, training_loss: 3.40910e-02
I0214 09:37:08.244163 22509476222784 run_lib.py:146] step: 1034500, eval_loss: 3.91360e-02
I0214 09:37:27.212977 22509476222784 run_lib.py:133] step: 1034550, training_loss: 4.76287e-02
I0214 09:37:46.048098 22509476222784 run_lib.py:133] step: 1034600, training_loss: 4.11555e-02
I0214 09:37:46.215264 22509476222784 run_lib.py:146] step: 1034600, eval_loss: 5.47278e-02
I0214 09:38:04.965139 22509476222784 run_lib.py:133] step: 1034650, training_loss: 4.41558e-02
I0214 09:38:23.739066 22509476222784 run_lib.py:133] step: 1034700, training_loss: 3.46853e-02
I0214 09:38:23.903344 22509476222784 run_lib.py:146] step: 1034700, eval_loss: 4.58575e-02
I0214 09:38:42.877689 22509476222784 run_lib.py:133] step: 1034750, training_loss: 3.45332e-02
I0214 09:39:01.793100 22509476222784 run_lib.py:133] step: 1034800, training_loss: 3.83394e-02
I0214 09:39:01.968926 22509476222784 run_lib.py:146] step: 1034800, eval_loss: 4.04301e-02
I0214 09:39:20.654932 22509476222784 run_lib.py:133] step: 1034850, training_loss: 4.64012e-02
I0214 09:39:39.431918 22509476222784 run_lib.py:133] step: 1034900, training_loss: 2.46470e-02
I0214 09:39:39.602568 22509476222784 run_lib.py:146] step: 1034900, eval_loss: 4.89943e-02
I0214 09:39:58.516571 22509476222784 run_lib.py:133] step: 1034950, training_loss: 3.16443e-02
I0214 09:40:17.297712 22509476222784 run_lib.py:133] step: 1035000, training_loss: 4.81618e-02
I0214 09:40:17.464236 22509476222784 run_lib.py:146] step: 1035000, eval_loss: 5.08442e-02
I0214 09:40:36.546802 22509476222784 run_lib.py:133] step: 1035050, training_loss: 3.66688e-02
I0214 09:40:55.258862 22509476222784 run_lib.py:133] step: 1035100, training_loss: 4.64400e-02
I0214 09:40:55.424983 22509476222784 run_lib.py:146] step: 1035100, eval_loss: 4.24301e-02
I0214 09:41:14.400065 22509476222784 run_lib.py:133] step: 1035150, training_loss: 5.42160e-02
I0214 09:41:33.117330 22509476222784 run_lib.py:133] step: 1035200, training_loss: 4.44036e-02
I0214 09:41:33.282134 22509476222784 run_lib.py:146] step: 1035200, eval_loss: 3.99838e-02
I0214 09:41:52.091215 22509476222784 run_lib.py:133] step: 1035250, training_loss: 2.95555e-02
I0214 09:42:11.091801 22509476222784 run_lib.py:133] step: 1035300, training_loss: 3.76187e-02
I0214 09:42:11.254238 22509476222784 run_lib.py:146] step: 1035300, eval_loss: 4.13531e-02
I0214 09:42:29.985416 22509476222784 run_lib.py:133] step: 1035350, training_loss: 3.92991e-02
I0214 09:42:49.020862 22509476222784 run_lib.py:133] step: 1035400, training_loss: 3.07141e-02
I0214 09:42:49.191011 22509476222784 run_lib.py:146] step: 1035400, eval_loss: 4.02382e-02
I0214 09:43:07.964150 22509476222784 run_lib.py:133] step: 1035450, training_loss: 3.97098e-02
I0214 09:43:26.890630 22509476222784 run_lib.py:133] step: 1035500, training_loss: 3.41061e-02
I0214 09:43:27.063035 22509476222784 run_lib.py:146] step: 1035500, eval_loss: 4.71750e-02
I0214 09:43:46.029484 22509476222784 run_lib.py:133] step: 1035550, training_loss: 4.04041e-02
I0214 09:44:04.763875 22509476222784 run_lib.py:133] step: 1035600, training_loss: 3.78704e-02
I0214 09:44:04.933856 22509476222784 run_lib.py:146] step: 1035600, eval_loss: 5.38675e-02
I0214 09:44:23.763817 22509476222784 run_lib.py:133] step: 1035650, training_loss: 4.31110e-02
I0214 09:44:42.513821 22509476222784 run_lib.py:133] step: 1035700, training_loss: 4.18553e-02
I0214 09:44:42.679211 22509476222784 run_lib.py:146] step: 1035700, eval_loss: 3.92760e-02
I0214 09:45:01.782426 22509476222784 run_lib.py:133] step: 1035750, training_loss: 5.54642e-02
I0214 09:45:20.574826 22509476222784 run_lib.py:133] step: 1035800, training_loss: 3.31860e-02
I0214 09:45:20.740991 22509476222784 run_lib.py:146] step: 1035800, eval_loss: 4.52738e-02
I0214 09:45:39.625152 22509476222784 run_lib.py:133] step: 1035850, training_loss: 3.16579e-02
I0214 09:45:58.455309 22509476222784 run_lib.py:133] step: 1035900, training_loss: 3.89305e-02
I0214 09:45:58.621141 22509476222784 run_lib.py:146] step: 1035900, eval_loss: 5.03046e-02
I0214 09:46:17.374033 22509476222784 run_lib.py:133] step: 1035950, training_loss: 5.25569e-02
I0214 09:46:36.253366 22509476222784 run_lib.py:133] step: 1036000, training_loss: 4.08846e-02
I0214 09:46:36.432140 22509476222784 run_lib.py:146] step: 1036000, eval_loss: 3.98709e-02
I0214 09:46:55.359494 22509476222784 run_lib.py:133] step: 1036050, training_loss: 3.98959e-02
I0214 09:47:14.293137 22509476222784 run_lib.py:133] step: 1036100, training_loss: 5.59689e-02
I0214 09:47:14.459984 22509476222784 run_lib.py:146] step: 1036100, eval_loss: 3.63218e-02
I0214 09:47:33.288070 22509476222784 run_lib.py:133] step: 1036150, training_loss: 3.31957e-02
I0214 09:47:52.077544 22509476222784 run_lib.py:133] step: 1036200, training_loss: 4.18148e-02
I0214 09:47:52.244853 22509476222784 run_lib.py:146] step: 1036200, eval_loss: 3.59031e-02
I0214 09:48:11.293733 22509476222784 run_lib.py:133] step: 1036250, training_loss: 4.35890e-02
I0214 09:48:30.103535 22509476222784 run_lib.py:133] step: 1036300, training_loss: 4.00761e-02
I0214 09:48:30.287086 22509476222784 run_lib.py:146] step: 1036300, eval_loss: 3.89159e-02
I0214 09:48:49.323656 22509476222784 run_lib.py:133] step: 1036350, training_loss: 3.50841e-02
I0214 09:49:08.107417 22509476222784 run_lib.py:133] step: 1036400, training_loss: 4.15251e-02
I0214 09:49:08.274316 22509476222784 run_lib.py:146] step: 1036400, eval_loss: 3.52905e-02
I0214 09:49:27.194812 22509476222784 run_lib.py:133] step: 1036450, training_loss: 5.15617e-02
I0214 09:49:45.923739 22509476222784 run_lib.py:133] step: 1036500, training_loss: 4.73804e-02
I0214 09:49:46.089113 22509476222784 run_lib.py:146] step: 1036500, eval_loss: 3.15834e-02
I0214 09:50:05.018735 22509476222784 run_lib.py:133] step: 1036550, training_loss: 5.53674e-02
I0214 09:50:23.895827 22509476222784 run_lib.py:133] step: 1036600, training_loss: 4.95152e-02
I0214 09:50:24.062723 22509476222784 run_lib.py:146] step: 1036600, eval_loss: 5.12518e-02
I0214 09:50:42.842783 22509476222784 run_lib.py:133] step: 1036650, training_loss: 3.71571e-02
I0214 09:51:01.893474 22509476222784 run_lib.py:133] step: 1036700, training_loss: 6.01766e-02
I0214 09:51:02.059110 22509476222784 run_lib.py:146] step: 1036700, eval_loss: 3.75127e-02
I0214 09:51:20.831912 22509476222784 run_lib.py:133] step: 1036750, training_loss: 4.58040e-02
I0214 09:51:39.628743 22509476222784 run_lib.py:133] step: 1036800, training_loss: 4.89463e-02
I0214 09:51:39.794217 22509476222784 run_lib.py:146] step: 1036800, eval_loss: 3.29316e-02
I0214 09:51:58.847538 22509476222784 run_lib.py:133] step: 1036850, training_loss: 3.73318e-02
I0214 09:52:17.840794 22509476222784 run_lib.py:133] step: 1036900, training_loss: 4.33976e-02
I0214 09:52:18.023350 22509476222784 run_lib.py:146] step: 1036900, eval_loss: 4.99570e-02
I0214 09:52:36.913394 22509476222784 run_lib.py:133] step: 1036950, training_loss: 4.34704e-02
I0214 09:52:55.636254 22509476222784 run_lib.py:133] step: 1037000, training_loss: 3.52656e-02
I0214 09:52:55.803282 22509476222784 run_lib.py:146] step: 1037000, eval_loss: 4.21517e-02
I0214 09:53:14.633691 22509476222784 run_lib.py:133] step: 1037050, training_loss: 3.57276e-02
I0214 09:53:33.607102 22509476222784 run_lib.py:133] step: 1037100, training_loss: 4.08973e-02
I0214 09:53:33.769147 22509476222784 run_lib.py:146] step: 1037100, eval_loss: 5.41537e-02
I0214 09:53:52.519452 22509476222784 run_lib.py:133] step: 1037150, training_loss: 5.13745e-02
I0214 09:54:11.528929 22509476222784 run_lib.py:133] step: 1037200, training_loss: 4.66296e-02
I0214 09:54:11.706121 22509476222784 run_lib.py:146] step: 1037200, eval_loss: 5.37233e-02
I0214 09:54:30.510020 22509476222784 run_lib.py:133] step: 1037250, training_loss: 3.69575e-02
I0214 09:54:49.612984 22509476222784 run_lib.py:133] step: 1037300, training_loss: 4.18769e-02
I0214 09:54:49.810105 22509476222784 run_lib.py:146] step: 1037300, eval_loss: 4.57000e-02
I0214 09:55:08.541342 22509476222784 run_lib.py:133] step: 1037350, training_loss: 3.56351e-02
I0214 09:55:27.388131 22509476222784 run_lib.py:133] step: 1037400, training_loss: 5.33646e-02
I0214 09:55:27.555859 22509476222784 run_lib.py:146] step: 1037400, eval_loss: 5.39449e-02
I0214 09:55:46.375635 22509476222784 run_lib.py:133] step: 1037450, training_loss: 3.93541e-02
I0214 09:56:05.109555 22509476222784 run_lib.py:133] step: 1037500, training_loss: 4.68842e-02
I0214 09:56:05.275114 22509476222784 run_lib.py:146] step: 1037500, eval_loss: 4.31907e-02
I0214 09:56:24.335531 22509476222784 run_lib.py:133] step: 1037550, training_loss: 4.19054e-02
I0214 09:56:43.203941 22509476222784 run_lib.py:133] step: 1037600, training_loss: 4.10746e-02
I0214 09:56:43.365984 22509476222784 run_lib.py:146] step: 1037600, eval_loss: 4.39278e-02
I0214 09:57:02.277018 22509476222784 run_lib.py:133] step: 1037650, training_loss: 3.29730e-02
I0214 09:57:21.125295 22509476222784 run_lib.py:133] step: 1037700, training_loss: 3.49455e-02
I0214 09:57:21.305962 22509476222784 run_lib.py:146] step: 1037700, eval_loss: 4.85694e-02
I0214 09:57:40.287665 22509476222784 run_lib.py:133] step: 1037750, training_loss: 4.31041e-02
I0214 09:57:59.223972 22509476222784 run_lib.py:133] step: 1037800, training_loss: 4.28501e-02
I0214 09:57:59.391219 22509476222784 run_lib.py:146] step: 1037800, eval_loss: 3.37812e-02
I0214 09:58:18.261893 22509476222784 run_lib.py:133] step: 1037850, training_loss: 4.66574e-02
I0214 09:58:37.087432 22509476222784 run_lib.py:133] step: 1037900, training_loss: 3.55249e-02
I0214 09:58:37.263642 22509476222784 run_lib.py:146] step: 1037900, eval_loss: 5.00840e-02
I0214 09:58:56.217242 22509476222784 run_lib.py:133] step: 1037950, training_loss: 3.95384e-02
I0214 09:59:15.083441 22509476222784 run_lib.py:133] step: 1038000, training_loss: 3.59726e-02
I0214 09:59:15.251326 22509476222784 run_lib.py:146] step: 1038000, eval_loss: 3.90927e-02
I0214 09:59:34.069349 22509476222784 run_lib.py:133] step: 1038050, training_loss: 4.36054e-02
I0214 09:59:53.020044 22509476222784 run_lib.py:133] step: 1038100, training_loss: 4.20494e-02
I0214 09:59:53.191896 22509476222784 run_lib.py:146] step: 1038100, eval_loss: 4.36704e-02
I0214 10:00:12.016294 22509476222784 run_lib.py:133] step: 1038150, training_loss: 3.84837e-02
I0214 10:00:30.996529 22509476222784 run_lib.py:133] step: 1038200, training_loss: 4.11948e-02
I0214 10:00:31.178901 22509476222784 run_lib.py:146] step: 1038200, eval_loss: 5.13652e-02
I0214 10:00:50.071412 22509476222784 run_lib.py:133] step: 1038250, training_loss: 4.10691e-02
I0214 10:01:08.829246 22509476222784 run_lib.py:133] step: 1038300, training_loss: 3.54269e-02
I0214 10:01:08.995952 22509476222784 run_lib.py:146] step: 1038300, eval_loss: 4.28592e-02
I0214 10:01:27.985091 22509476222784 run_lib.py:133] step: 1038350, training_loss: 4.00243e-02
I0214 10:01:46.805478 22509476222784 run_lib.py:133] step: 1038400, training_loss: 4.70795e-02
I0214 10:01:46.975696 22509476222784 run_lib.py:146] step: 1038400, eval_loss: 4.58730e-02
I0214 10:02:05.799743 22509476222784 run_lib.py:133] step: 1038450, training_loss: 3.55578e-02
I0214 10:02:24.887768 22509476222784 run_lib.py:133] step: 1038500, training_loss: 4.92699e-02
I0214 10:02:25.050007 22509476222784 run_lib.py:146] step: 1038500, eval_loss: 3.95615e-02
I0214 10:02:43.794373 22509476222784 run_lib.py:133] step: 1038550, training_loss: 4.41711e-02
I0214 10:03:02.636062 22509476222784 run_lib.py:133] step: 1038600, training_loss: 3.68242e-02
I0214 10:03:02.801927 22509476222784 run_lib.py:146] step: 1038600, eval_loss: 3.88259e-02
I0214 10:03:21.630936 22509476222784 run_lib.py:133] step: 1038650, training_loss: 6.49726e-02
I0214 10:03:40.444157 22509476222784 run_lib.py:133] step: 1038700, training_loss: 3.58531e-02
I0214 10:03:40.619936 22509476222784 run_lib.py:146] step: 1038700, eval_loss: 4.49687e-02
I0214 10:03:59.501499 22509476222784 run_lib.py:133] step: 1038750, training_loss: 4.35803e-02
I0214 10:04:18.264264 22509476222784 run_lib.py:133] step: 1038800, training_loss: 3.53266e-02
I0214 10:04:18.431226 22509476222784 run_lib.py:146] step: 1038800, eval_loss: 4.40580e-02
I0214 10:04:37.474295 22509476222784 run_lib.py:133] step: 1038850, training_loss: 5.14677e-02
I0214 10:04:56.325676 22509476222784 run_lib.py:133] step: 1038900, training_loss: 5.60964e-02
I0214 10:04:56.507815 22509476222784 run_lib.py:146] step: 1038900, eval_loss: 3.72136e-02
I0214 10:05:15.375745 22509476222784 run_lib.py:133] step: 1038950, training_loss: 4.12692e-02
I0214 10:05:34.225779 22509476222784 run_lib.py:133] step: 1039000, training_loss: 3.91165e-02
I0214 10:05:34.389563 22509476222784 run_lib.py:146] step: 1039000, eval_loss: 3.64068e-02
I0214 10:05:53.361328 22509476222784 run_lib.py:133] step: 1039050, training_loss: 3.96327e-02
I0214 10:06:12.216948 22509476222784 run_lib.py:133] step: 1039100, training_loss: 4.13227e-02
I0214 10:06:12.382884 22509476222784 run_lib.py:146] step: 1039100, eval_loss: 3.85636e-02
I0214 10:06:31.253905 22509476222784 run_lib.py:133] step: 1039150, training_loss: 5.58983e-02
I0214 10:06:50.203207 22509476222784 run_lib.py:133] step: 1039200, training_loss: 3.76182e-02
I0214 10:06:50.379214 22509476222784 run_lib.py:146] step: 1039200, eval_loss: 3.57395e-02
I0214 10:07:09.362153 22509476222784 run_lib.py:133] step: 1039250, training_loss: 4.86628e-02
I0214 10:07:28.066950 22509476222784 run_lib.py:133] step: 1039300, training_loss: 4.34539e-02
I0214 10:07:28.233189 22509476222784 run_lib.py:146] step: 1039300, eval_loss: 4.16929e-02
I0214 10:07:47.250317 22509476222784 run_lib.py:133] step: 1039350, training_loss: 4.02256e-02
I0214 10:08:06.002502 22509476222784 run_lib.py:133] step: 1039400, training_loss: 3.02551e-02
I0214 10:08:06.168156 22509476222784 run_lib.py:146] step: 1039400, eval_loss: 3.43743e-02
I0214 10:08:24.981978 22509476222784 run_lib.py:133] step: 1039450, training_loss: 3.47852e-02
I0214 10:08:44.014151 22509476222784 run_lib.py:133] step: 1039500, training_loss: 3.69364e-02
I0214 10:08:44.181919 22509476222784 run_lib.py:146] step: 1039500, eval_loss: 3.89012e-02
I0214 10:09:02.958477 22509476222784 run_lib.py:133] step: 1039550, training_loss: 4.72521e-02
I0214 10:09:21.839611 22509476222784 run_lib.py:133] step: 1039600, training_loss: 4.51534e-02
I0214 10:09:22.011384 22509476222784 run_lib.py:146] step: 1039600, eval_loss: 4.20074e-02
I0214 10:09:40.838851 22509476222784 run_lib.py:133] step: 1039650, training_loss: 4.23419e-02
I0214 10:09:59.566049 22509476222784 run_lib.py:133] step: 1039700, training_loss: 4.21420e-02
I0214 10:09:59.753096 22509476222784 run_lib.py:146] step: 1039700, eval_loss: 4.73406e-02
I0214 10:10:18.767426 22509476222784 run_lib.py:133] step: 1039750, training_loss: 3.64072e-02
I0214 10:10:37.523449 22509476222784 run_lib.py:133] step: 1039800, training_loss: 3.94431e-02
I0214 10:10:37.689218 22509476222784 run_lib.py:146] step: 1039800, eval_loss: 4.82330e-02
I0214 10:10:56.544646 22509476222784 run_lib.py:133] step: 1039850, training_loss: 4.25664e-02
I0214 10:11:15.531039 22509476222784 run_lib.py:133] step: 1039900, training_loss: 5.63119e-02
I0214 10:11:15.700997 22509476222784 run_lib.py:146] step: 1039900, eval_loss: 3.36545e-02
I0214 10:11:34.497687 22509476222784 run_lib.py:133] step: 1039950, training_loss: 4.36843e-02
I0214 10:11:53.267306 22509476222784 run_lib.py:133] step: 1040000, training_loss: 5.07498e-02
I0214 10:11:55.654869 22509476222784 run_lib.py:146] step: 1040000, eval_loss: 3.27073e-02
I0214 10:12:19.015990 22509476222784 run_lib.py:133] step: 1040050, training_loss: 3.83555e-02
I0214 10:12:37.803680 22509476222784 run_lib.py:133] step: 1040100, training_loss: 4.71281e-02
I0214 10:12:37.970433 22509476222784 run_lib.py:146] step: 1040100, eval_loss: 2.53622e-02
I0214 10:12:56.885276 22509476222784 run_lib.py:133] step: 1040150, training_loss: 4.64661e-02
I0214 10:13:15.734541 22509476222784 run_lib.py:133] step: 1040200, training_loss: 3.36292e-02
I0214 10:13:15.911141 22509476222784 run_lib.py:146] step: 1040200, eval_loss: 4.26764e-02
I0214 10:13:34.683949 22509476222784 run_lib.py:133] step: 1040250, training_loss: 4.74762e-02
I0214 10:13:53.623928 22509476222784 run_lib.py:133] step: 1040300, training_loss: 4.42888e-02
I0214 10:13:53.790161 22509476222784 run_lib.py:146] step: 1040300, eval_loss: 4.52676e-02
I0214 10:14:12.529137 22509476222784 run_lib.py:133] step: 1040350, training_loss: 4.80646e-02
I0214 10:14:31.344727 22509476222784 run_lib.py:133] step: 1040400, training_loss: 5.26320e-02
I0214 10:14:31.509950 22509476222784 run_lib.py:146] step: 1040400, eval_loss: 3.56535e-02
I0214 10:14:50.449394 22509476222784 run_lib.py:133] step: 1040450, training_loss: 4.88829e-02
I0214 10:15:09.367145 22509476222784 run_lib.py:133] step: 1040500, training_loss: 4.09667e-02
I0214 10:15:09.531092 22509476222784 run_lib.py:146] step: 1040500, eval_loss: 4.08051e-02
I0214 10:15:28.412489 22509476222784 run_lib.py:133] step: 1040550, training_loss: 4.10195e-02
I0214 10:15:47.138851 22509476222784 run_lib.py:133] step: 1040600, training_loss: 4.98712e-02
I0214 10:15:47.308103 22509476222784 run_lib.py:146] step: 1040600, eval_loss: 5.82696e-02
I0214 10:16:06.365042 22509476222784 run_lib.py:133] step: 1040650, training_loss: 3.46173e-02
I0214 10:16:25.079401 22509476222784 run_lib.py:133] step: 1040700, training_loss: 4.25341e-02
I0214 10:16:25.247206 22509476222784 run_lib.py:146] step: 1040700, eval_loss: 4.24557e-02
I0214 10:16:44.165935 22509476222784 run_lib.py:133] step: 1040750, training_loss: 4.94824e-02
I0214 10:17:02.906784 22509476222784 run_lib.py:133] step: 1040800, training_loss: 4.39716e-02
I0214 10:17:03.079451 22509476222784 run_lib.py:146] step: 1040800, eval_loss: 2.92462e-02
I0214 10:17:22.088108 22509476222784 run_lib.py:133] step: 1040850, training_loss: 4.56152e-02
I0214 10:17:40.860532 22509476222784 run_lib.py:133] step: 1040900, training_loss: 4.46241e-02
I0214 10:17:41.025280 22509476222784 run_lib.py:146] step: 1040900, eval_loss: 5.00970e-02
I0214 10:18:00.000335 22509476222784 run_lib.py:133] step: 1040950, training_loss: 5.41701e-02
I0214 10:18:18.784793 22509476222784 run_lib.py:133] step: 1041000, training_loss: 3.69619e-02
I0214 10:18:18.947954 22509476222784 run_lib.py:146] step: 1041000, eval_loss: 4.28410e-02
I0214 10:18:37.664259 22509476222784 run_lib.py:133] step: 1041050, training_loss: 4.55410e-02
I0214 10:18:56.753622 22509476222784 run_lib.py:133] step: 1041100, training_loss: 3.55070e-02
I0214 10:18:56.937018 22509476222784 run_lib.py:146] step: 1041100, eval_loss: 4.96957e-02
I0214 10:19:15.702847 22509476222784 run_lib.py:133] step: 1041150, training_loss: 4.21080e-02
I0214 10:19:34.561483 22509476222784 run_lib.py:133] step: 1041200, training_loss: 3.47882e-02
I0214 10:19:34.735238 22509476222784 run_lib.py:146] step: 1041200, eval_loss: 3.75235e-02
I0214 10:19:53.619636 22509476222784 run_lib.py:133] step: 1041250, training_loss: 3.99983e-02
I0214 10:20:12.672751 22509476222784 run_lib.py:133] step: 1041300, training_loss: 3.03090e-02
I0214 10:20:12.851490 22509476222784 run_lib.py:146] step: 1041300, eval_loss: 3.77421e-02
I0214 10:20:31.656933 22509476222784 run_lib.py:133] step: 1041350, training_loss: 4.86297e-02
I0214 10:20:50.439641 22509476222784 run_lib.py:133] step: 1041400, training_loss: 3.71468e-02
I0214 10:20:50.608385 22509476222784 run_lib.py:146] step: 1041400, eval_loss: 3.46120e-02
I0214 10:21:09.425572 22509476222784 run_lib.py:133] step: 1041450, training_loss: 4.40342e-02
I0214 10:21:28.373527 22509476222784 run_lib.py:133] step: 1041500, training_loss: 4.41984e-02
I0214 10:21:28.541984 22509476222784 run_lib.py:146] step: 1041500, eval_loss: 3.26210e-02
I0214 10:21:47.313755 22509476222784 run_lib.py:133] step: 1041550, training_loss: 4.01909e-02
I0214 10:22:06.094809 22509476222784 run_lib.py:133] step: 1041600, training_loss: 4.61241e-02
I0214 10:22:06.278913 22509476222784 run_lib.py:146] step: 1041600, eval_loss: 5.30672e-02
I0214 10:22:25.169940 22509476222784 run_lib.py:133] step: 1041650, training_loss: 5.41333e-02
I0214 10:22:44.222752 22509476222784 run_lib.py:133] step: 1041700, training_loss: 4.51232e-02
I0214 10:22:44.398585 22509476222784 run_lib.py:146] step: 1041700, eval_loss: 4.05194e-02
I0214 10:23:03.197875 22509476222784 run_lib.py:133] step: 1041750, training_loss: 3.50269e-02
I0214 10:23:22.156995 22509476222784 run_lib.py:133] step: 1041800, training_loss: 3.05936e-02
I0214 10:23:22.324249 22509476222784 run_lib.py:146] step: 1041800, eval_loss: 5.34043e-02
I0214 10:23:41.102377 22509476222784 run_lib.py:133] step: 1041850, training_loss: 4.33320e-02
I0214 10:24:00.044503 22509476222784 run_lib.py:133] step: 1041900, training_loss: 4.12086e-02
I0214 10:24:00.209140 22509476222784 run_lib.py:146] step: 1041900, eval_loss: 3.92106e-02
I0214 10:24:19.199382 22509476222784 run_lib.py:133] step: 1041950, training_loss: 3.55249e-02
I0214 10:24:38.077234 22509476222784 run_lib.py:133] step: 1042000, training_loss: 4.97096e-02
I0214 10:24:38.251940 22509476222784 run_lib.py:146] step: 1042000, eval_loss: 5.03327e-02
I0214 10:24:57.067361 22509476222784 run_lib.py:133] step: 1042050, training_loss: 3.69653e-02
I0214 10:25:15.808966 22509476222784 run_lib.py:133] step: 1042100, training_loss: 4.03482e-02
I0214 10:25:15.998464 22509476222784 run_lib.py:146] step: 1042100, eval_loss: 5.74627e-02
I0214 10:25:35.193449 22509476222784 run_lib.py:133] step: 1042150, training_loss: 4.66821e-02
I0214 10:25:53.976247 22509476222784 run_lib.py:133] step: 1042200, training_loss: 4.38876e-02
I0214 10:25:54.142726 22509476222784 run_lib.py:146] step: 1042200, eval_loss: 4.88504e-02
I0214 10:26:13.167398 22509476222784 run_lib.py:133] step: 1042250, training_loss: 4.59559e-02
I0214 10:26:31.837044 22509476222784 run_lib.py:133] step: 1042300, training_loss: 3.37570e-02
I0214 10:26:32.005919 22509476222784 run_lib.py:146] step: 1042300, eval_loss: 3.41869e-02
I0214 10:26:50.905969 22509476222784 run_lib.py:133] step: 1042350, training_loss: 3.63865e-02
I0214 10:27:09.737424 22509476222784 run_lib.py:133] step: 1042400, training_loss: 5.21773e-02
I0214 10:27:09.903149 22509476222784 run_lib.py:146] step: 1042400, eval_loss: 3.74897e-02
I0214 10:27:28.665399 22509476222784 run_lib.py:133] step: 1042450, training_loss: 2.93344e-02
I0214 10:27:47.675022 22509476222784 run_lib.py:133] step: 1042500, training_loss: 5.00426e-02
I0214 10:27:47.845157 22509476222784 run_lib.py:146] step: 1042500, eval_loss: 4.90360e-02
I0214 10:28:06.614498 22509476222784 run_lib.py:133] step: 1042550, training_loss: 3.69666e-02
I0214 10:28:25.564469 22509476222784 run_lib.py:133] step: 1042600, training_loss: 3.01937e-02
I0214 10:28:25.756170 22509476222784 run_lib.py:146] step: 1042600, eval_loss: 3.33477e-02
I0214 10:28:44.608554 22509476222784 run_lib.py:133] step: 1042650, training_loss: 4.83160e-02
I0214 10:29:03.356138 22509476222784 run_lib.py:133] step: 1042700, training_loss: 4.31465e-02
I0214 10:29:03.522100 22509476222784 run_lib.py:146] step: 1042700, eval_loss: 3.22751e-02
I0214 10:29:22.608995 22509476222784 run_lib.py:133] step: 1042750, training_loss: 3.50503e-02
I0214 10:29:41.306582 22509476222784 run_lib.py:133] step: 1042800, training_loss: 3.88920e-02
I0214 10:29:41.473002 22509476222784 run_lib.py:146] step: 1042800, eval_loss: 5.69152e-02
I0214 10:30:00.337780 22509476222784 run_lib.py:133] step: 1042850, training_loss: 3.87597e-02
I0214 10:30:19.285686 22509476222784 run_lib.py:133] step: 1042900, training_loss: 3.24873e-02
I0214 10:30:19.457110 22509476222784 run_lib.py:146] step: 1042900, eval_loss: 4.25776e-02
I0214 10:30:38.289227 22509476222784 run_lib.py:133] step: 1042950, training_loss: 3.68551e-02
I0214 10:30:57.183304 22509476222784 run_lib.py:133] step: 1043000, training_loss: 5.01860e-02
I0214 10:30:57.353583 22509476222784 run_lib.py:146] step: 1043000, eval_loss: 4.63199e-02
I0214 10:31:16.215354 22509476222784 run_lib.py:133] step: 1043050, training_loss: 3.81922e-02
I0214 10:31:35.140625 22509476222784 run_lib.py:133] step: 1043100, training_loss: 4.75456e-02
I0214 10:31:35.308237 22509476222784 run_lib.py:146] step: 1043100, eval_loss: 3.93638e-02
I0214 10:31:54.067042 22509476222784 run_lib.py:133] step: 1043150, training_loss: 3.12115e-02
I0214 10:32:12.889557 22509476222784 run_lib.py:133] step: 1043200, training_loss: 5.45873e-02
I0214 10:32:13.054737 22509476222784 run_lib.py:146] step: 1043200, eval_loss: 4.26668e-02
I0214 10:32:32.028934 22509476222784 run_lib.py:133] step: 1043250, training_loss: 3.64436e-02
I0214 10:32:50.851988 22509476222784 run_lib.py:133] step: 1043300, training_loss: 5.00293e-02
I0214 10:32:51.015610 22509476222784 run_lib.py:146] step: 1043300, eval_loss: 5.77460e-02
I0214 10:33:09.835984 22509476222784 run_lib.py:133] step: 1043350, training_loss: 4.99244e-02
I0214 10:33:28.509069 22509476222784 run_lib.py:133] step: 1043400, training_loss: 4.73868e-02
I0214 10:33:28.685981 22509476222784 run_lib.py:146] step: 1043400, eval_loss: 5.73257e-02
I0214 10:33:47.757996 22509476222784 run_lib.py:133] step: 1043450, training_loss: 4.69344e-02
I0214 10:34:06.483427 22509476222784 run_lib.py:133] step: 1043500, training_loss: 4.12085e-02
I0214 10:34:06.651128 22509476222784 run_lib.py:146] step: 1043500, eval_loss: 5.39005e-02
I0214 10:34:25.508533 22509476222784 run_lib.py:133] step: 1043550, training_loss: 4.48297e-02
I0214 10:34:44.327534 22509476222784 run_lib.py:133] step: 1043600, training_loss: 3.93741e-02
I0214 10:34:44.681902 22509476222784 run_lib.py:146] step: 1043600, eval_loss: 4.95769e-02
I0214 10:35:03.590118 22509476222784 run_lib.py:133] step: 1043650, training_loss: 3.17175e-02
I0214 10:35:22.496274 22509476222784 run_lib.py:133] step: 1043700, training_loss: 4.53400e-02
I0214 10:35:22.664674 22509476222784 run_lib.py:146] step: 1043700, eval_loss: 4.29620e-02
I0214 10:35:41.690655 22509476222784 run_lib.py:133] step: 1043750, training_loss: 3.93987e-02
I0214 10:36:00.447479 22509476222784 run_lib.py:133] step: 1043800, training_loss: 4.17365e-02
I0214 10:36:00.615056 22509476222784 run_lib.py:146] step: 1043800, eval_loss: 4.24911e-02
I0214 10:36:19.436728 22509476222784 run_lib.py:133] step: 1043850, training_loss: 5.10781e-02
I0214 10:36:38.341117 22509476222784 run_lib.py:133] step: 1043900, training_loss: 4.52340e-02
I0214 10:36:38.524570 22509476222784 run_lib.py:146] step: 1043900, eval_loss: 4.40104e-02
I0214 10:36:57.463266 22509476222784 run_lib.py:133] step: 1043950, training_loss: 5.01729e-02
I0214 10:37:16.222449 22509476222784 run_lib.py:133] step: 1044000, training_loss: 3.73693e-02
I0214 10:37:16.394826 22509476222784 run_lib.py:146] step: 1044000, eval_loss: 4.54779e-02
I0214 10:37:35.473072 22509476222784 run_lib.py:133] step: 1044050, training_loss: 5.91199e-02
I0214 10:37:54.266473 22509476222784 run_lib.py:133] step: 1044100, training_loss: 4.79982e-02
I0214 10:37:54.432909 22509476222784 run_lib.py:146] step: 1044100, eval_loss: 4.33525e-02
I0214 10:38:13.375428 22509476222784 run_lib.py:133] step: 1044150, training_loss: 4.90953e-02
I0214 10:38:32.146984 22509476222784 run_lib.py:133] step: 1044200, training_loss: 3.88884e-02
I0214 10:38:32.368361 22509476222784 run_lib.py:146] step: 1044200, eval_loss: 3.78537e-02
I0214 10:38:51.212677 22509476222784 run_lib.py:133] step: 1044250, training_loss: 3.80096e-02
I0214 10:39:10.264538 22509476222784 run_lib.py:133] step: 1044300, training_loss: 5.38013e-02
I0214 10:39:10.426877 22509476222784 run_lib.py:146] step: 1044300, eval_loss: 5.01531e-02
I0214 10:39:29.115633 22509476222784 run_lib.py:133] step: 1044350, training_loss: 5.55758e-02
I0214 10:39:47.960821 22509476222784 run_lib.py:133] step: 1044400, training_loss: 5.08322e-02
I0214 10:39:48.137670 22509476222784 run_lib.py:146] step: 1044400, eval_loss: 3.34546e-02
I0214 10:40:06.922060 22509476222784 run_lib.py:133] step: 1044450, training_loss: 3.89080e-02
I0214 10:40:26.005328 22509476222784 run_lib.py:133] step: 1044500, training_loss: 3.58133e-02
I0214 10:40:26.172959 22509476222784 run_lib.py:146] step: 1044500, eval_loss: 3.44171e-02
I0214 10:40:44.905675 22509476222784 run_lib.py:133] step: 1044550, training_loss: 3.84382e-02
I0214 10:41:03.608757 22509476222784 run_lib.py:133] step: 1044600, training_loss: 3.25492e-02
I0214 10:41:03.786108 22509476222784 run_lib.py:146] step: 1044600, eval_loss: 3.60001e-02
I0214 10:41:22.627471 22509476222784 run_lib.py:133] step: 1044650, training_loss: 4.19102e-02
I0214 10:41:41.438122 22509476222784 run_lib.py:133] step: 1044700, training_loss: 4.24035e-02
I0214 10:41:41.610233 22509476222784 run_lib.py:146] step: 1044700, eval_loss: 4.00718e-02
I0214 10:42:00.779453 22509476222784 run_lib.py:133] step: 1044750, training_loss: 3.56895e-02
I0214 10:42:19.532164 22509476222784 run_lib.py:133] step: 1044800, training_loss: 4.56000e-02
I0214 10:42:19.695883 22509476222784 run_lib.py:146] step: 1044800, eval_loss: 4.40427e-02
I0214 10:42:38.455542 22509476222784 run_lib.py:133] step: 1044850, training_loss: 4.15845e-02
I0214 10:42:57.203964 22509476222784 run_lib.py:133] step: 1044900, training_loss: 4.35690e-02
I0214 10:42:57.373961 22509476222784 run_lib.py:146] step: 1044900, eval_loss: 3.33089e-02
I0214 10:43:16.250347 22509476222784 run_lib.py:133] step: 1044950, training_loss: 4.80729e-02
I0214 10:43:35.140677 22509476222784 run_lib.py:133] step: 1045000, training_loss: 3.65297e-02
I0214 10:43:35.308291 22509476222784 run_lib.py:146] step: 1045000, eval_loss: 4.48060e-02
I0214 10:43:54.275031 22509476222784 run_lib.py:133] step: 1045050, training_loss: 5.08701e-02
I0214 10:44:13.221743 22509476222784 run_lib.py:133] step: 1045100, training_loss: 3.54425e-02
I0214 10:44:13.387972 22509476222784 run_lib.py:146] step: 1045100, eval_loss: 3.10222e-02
I0214 10:44:32.293240 22509476222784 run_lib.py:133] step: 1045150, training_loss: 3.67303e-02
I0214 10:44:51.155929 22509476222784 run_lib.py:133] step: 1045200, training_loss: 4.38720e-02
I0214 10:44:51.413763 22509476222784 run_lib.py:146] step: 1045200, eval_loss: 4.63649e-02
I0214 10:45:10.172142 22509476222784 run_lib.py:133] step: 1045250, training_loss: 3.74148e-02
I0214 10:45:29.102058 22509476222784 run_lib.py:133] step: 1045300, training_loss: 2.97194e-02
I0214 10:45:29.270141 22509476222784 run_lib.py:146] step: 1045300, eval_loss: 3.52925e-02
I0214 10:45:48.209567 22509476222784 run_lib.py:133] step: 1045350, training_loss: 3.51102e-02
I0214 10:46:07.160630 22509476222784 run_lib.py:133] step: 1045400, training_loss: 4.81668e-02
I0214 10:46:07.330620 22509476222784 run_lib.py:146] step: 1045400, eval_loss: 4.99832e-02
I0214 10:46:26.150166 22509476222784 run_lib.py:133] step: 1045450, training_loss: 4.75334e-02
I0214 10:46:44.917780 22509476222784 run_lib.py:133] step: 1045500, training_loss: 3.59803e-02
I0214 10:46:45.097884 22509476222784 run_lib.py:146] step: 1045500, eval_loss: 3.27882e-02
I0214 10:47:04.063880 22509476222784 run_lib.py:133] step: 1045550, training_loss: 5.06827e-02
I0214 10:47:22.899037 22509476222784 run_lib.py:133] step: 1045600, training_loss: 4.36571e-02
I0214 10:47:23.066263 22509476222784 run_lib.py:146] step: 1045600, eval_loss: 4.51543e-02
I0214 10:47:41.873517 22509476222784 run_lib.py:133] step: 1045650, training_loss: 3.32173e-02
I0214 10:48:00.944210 22509476222784 run_lib.py:133] step: 1045700, training_loss: 3.16136e-02
I0214 10:48:01.106009 22509476222784 run_lib.py:146] step: 1045700, eval_loss: 4.81160e-02
I0214 10:48:19.829009 22509476222784 run_lib.py:133] step: 1045750, training_loss: 4.89946e-02
I0214 10:48:38.610412 22509476222784 run_lib.py:133] step: 1045800, training_loss: 5.43436e-02
I0214 10:48:38.942076 22509476222784 run_lib.py:146] step: 1045800, eval_loss: 4.21121e-02
I0214 10:48:57.718155 22509476222784 run_lib.py:133] step: 1045850, training_loss: 3.57695e-02
I0214 10:49:16.486932 22509476222784 run_lib.py:133] step: 1045900, training_loss: 4.79901e-02
I0214 10:49:16.660892 22509476222784 run_lib.py:146] step: 1045900, eval_loss: 3.80288e-02
I0214 10:49:35.429919 22509476222784 run_lib.py:133] step: 1045950, training_loss: 3.03473e-02
I0214 10:49:54.150116 22509476222784 run_lib.py:133] step: 1046000, training_loss: 4.71337e-02
I0214 10:49:54.318083 22509476222784 run_lib.py:146] step: 1046000, eval_loss: 4.88872e-02
I0214 10:50:13.280660 22509476222784 run_lib.py:133] step: 1046050, training_loss: 3.96701e-02
I0214 10:50:32.266738 22509476222784 run_lib.py:133] step: 1046100, training_loss: 2.89895e-02
I0214 10:50:32.434207 22509476222784 run_lib.py:146] step: 1046100, eval_loss: 3.72776e-02
I0214 10:50:51.170348 22509476222784 run_lib.py:133] step: 1046150, training_loss: 3.67273e-02
I0214 10:51:10.035690 22509476222784 run_lib.py:133] step: 1046200, training_loss: 5.02257e-02
I0214 10:51:10.197628 22509476222784 run_lib.py:146] step: 1046200, eval_loss: 4.04963e-02
I0214 10:51:29.063363 22509476222784 run_lib.py:133] step: 1046250, training_loss: 4.64725e-02
I0214 10:51:47.942737 22509476222784 run_lib.py:133] step: 1046300, training_loss: 3.90988e-02
I0214 10:51:48.118765 22509476222784 run_lib.py:146] step: 1046300, eval_loss: 4.51162e-02
I0214 10:52:06.881322 22509476222784 run_lib.py:133] step: 1046350, training_loss: 3.16095e-02
I0214 10:52:25.652810 22509476222784 run_lib.py:133] step: 1046400, training_loss: 3.55012e-02
I0214 10:52:25.826980 22509476222784 run_lib.py:146] step: 1046400, eval_loss: 4.94520e-02
I0214 10:52:44.781965 22509476222784 run_lib.py:133] step: 1046450, training_loss: 3.18037e-02
I0214 10:53:03.461572 22509476222784 run_lib.py:133] step: 1046500, training_loss: 4.25045e-02
I0214 10:53:03.631952 22509476222784 run_lib.py:146] step: 1046500, eval_loss: 4.56985e-02
I0214 10:53:22.573895 22509476222784 run_lib.py:133] step: 1046550, training_loss: 5.33143e-02
I0214 10:53:41.350323 22509476222784 run_lib.py:133] step: 1046600, training_loss: 5.21914e-02
I0214 10:53:41.516972 22509476222784 run_lib.py:146] step: 1046600, eval_loss: 4.86433e-02
I0214 10:54:00.583825 22509476222784 run_lib.py:133] step: 1046650, training_loss: 4.43433e-02
I0214 10:54:19.358164 22509476222784 run_lib.py:133] step: 1046700, training_loss: 5.17668e-02
I0214 10:54:19.521722 22509476222784 run_lib.py:146] step: 1046700, eval_loss: 4.43943e-02
I0214 10:54:38.241284 22509476222784 run_lib.py:133] step: 1046750, training_loss: 4.15147e-02
I0214 10:54:57.277021 22509476222784 run_lib.py:133] step: 1046800, training_loss: 4.00373e-02
I0214 10:54:57.445538 22509476222784 run_lib.py:146] step: 1046800, eval_loss: 4.35932e-02
I0214 10:55:16.260323 22509476222784 run_lib.py:133] step: 1046850, training_loss: 4.77721e-02
I0214 10:55:35.396928 22509476222784 run_lib.py:133] step: 1046900, training_loss: 3.86291e-02
I0214 10:55:35.564359 22509476222784 run_lib.py:146] step: 1046900, eval_loss: 4.52033e-02
I0214 10:55:54.334594 22509476222784 run_lib.py:133] step: 1046950, training_loss: 4.24165e-02
I0214 10:56:13.059866 22509476222784 run_lib.py:133] step: 1047000, training_loss: 4.63080e-02
I0214 10:56:13.229095 22509476222784 run_lib.py:146] step: 1047000, eval_loss: 4.57324e-02
I0214 10:56:32.220915 22509476222784 run_lib.py:133] step: 1047050, training_loss: 3.67597e-02
I0214 10:56:51.004641 22509476222784 run_lib.py:133] step: 1047100, training_loss: 4.20436e-02
I0214 10:56:51.193501 22509476222784 run_lib.py:146] step: 1047100, eval_loss: 3.94064e-02
I0214 10:57:10.242329 22509476222784 run_lib.py:133] step: 1047150, training_loss: 4.58851e-02
I0214 10:57:28.973683 22509476222784 run_lib.py:133] step: 1047200, training_loss: 4.17489e-02
I0214 10:57:29.138990 22509476222784 run_lib.py:146] step: 1047200, eval_loss: 3.50477e-02
I0214 10:57:48.135558 22509476222784 run_lib.py:133] step: 1047250, training_loss: 4.04477e-02
I0214 10:58:06.876767 22509476222784 run_lib.py:133] step: 1047300, training_loss: 5.05459e-02
I0214 10:58:07.046612 22509476222784 run_lib.py:146] step: 1047300, eval_loss: 3.55195e-02
I0214 10:58:25.879960 22509476222784 run_lib.py:133] step: 1047350, training_loss: 4.46225e-02
I0214 10:58:44.722525 22509476222784 run_lib.py:133] step: 1047400, training_loss: 4.43208e-02
I0214 10:58:44.890370 22509476222784 run_lib.py:146] step: 1047400, eval_loss: 4.10412e-02
I0214 10:59:03.631147 22509476222784 run_lib.py:133] step: 1047450, training_loss: 3.98462e-02
I0214 10:59:22.470508 22509476222784 run_lib.py:133] step: 1047500, training_loss: 4.98664e-02
I0214 10:59:22.637031 22509476222784 run_lib.py:146] step: 1047500, eval_loss: 4.71779e-02
I0214 10:59:41.574186 22509476222784 run_lib.py:133] step: 1047550, training_loss: 4.13857e-02
I0214 11:00:00.509205 22509476222784 run_lib.py:133] step: 1047600, training_loss: 3.74755e-02
I0214 11:00:00.676178 22509476222784 run_lib.py:146] step: 1047600, eval_loss: 3.89619e-02
I0214 11:00:19.474681 22509476222784 run_lib.py:133] step: 1047650, training_loss: 3.44314e-02
I0214 11:00:38.188129 22509476222784 run_lib.py:133] step: 1047700, training_loss: 4.16706e-02
I0214 11:00:38.353770 22509476222784 run_lib.py:146] step: 1047700, eval_loss: 5.05977e-02
I0214 11:00:57.323211 22509476222784 run_lib.py:133] step: 1047750, training_loss: 4.18654e-02
I0214 11:01:16.070590 22509476222784 run_lib.py:133] step: 1047800, training_loss: 3.14508e-02
I0214 11:01:16.236947 22509476222784 run_lib.py:146] step: 1047800, eval_loss: 5.44202e-02
I0214 11:01:35.198932 22509476222784 run_lib.py:133] step: 1047850, training_loss: 4.10841e-02
I0214 11:01:54.020677 22509476222784 run_lib.py:133] step: 1047900, training_loss: 3.40088e-02
I0214 11:01:54.188100 22509476222784 run_lib.py:146] step: 1047900, eval_loss: 5.83491e-02
I0214 11:02:13.109644 22509476222784 run_lib.py:133] step: 1047950, training_loss: 4.00649e-02
I0214 11:02:31.910478 22509476222784 run_lib.py:133] step: 1048000, training_loss: 3.78478e-02
I0214 11:02:32.076814 22509476222784 run_lib.py:146] step: 1048000, eval_loss: 3.86903e-02
I0214 11:02:50.977715 22509476222784 run_lib.py:133] step: 1048050, training_loss: 4.42936e-02
I0214 11:03:09.842426 22509476222784 run_lib.py:133] step: 1048100, training_loss: 4.19515e-02
I0214 11:03:10.004878 22509476222784 run_lib.py:146] step: 1048100, eval_loss: 4.37070e-02
I0214 11:03:28.742983 22509476222784 run_lib.py:133] step: 1048150, training_loss: 4.62742e-02
I0214 11:03:47.701678 22509476222784 run_lib.py:133] step: 1048200, training_loss: 3.52630e-02
I0214 11:03:47.876886 22509476222784 run_lib.py:146] step: 1048200, eval_loss: 3.72813e-02
I0214 11:04:06.636537 22509476222784 run_lib.py:133] step: 1048250, training_loss: 4.06591e-02
I0214 11:04:25.332226 22509476222784 run_lib.py:133] step: 1048300, training_loss: 4.36157e-02
I0214 11:04:25.499105 22509476222784 run_lib.py:146] step: 1048300, eval_loss: 3.34688e-02
I0214 11:04:44.565153 22509476222784 run_lib.py:133] step: 1048350, training_loss: 3.70022e-02
I0214 11:05:03.464120 22509476222784 run_lib.py:133] step: 1048400, training_loss: 3.78978e-02
I0214 11:05:03.631967 22509476222784 run_lib.py:146] step: 1048400, eval_loss: 3.21452e-02
I0214 11:05:22.430109 22509476222784 run_lib.py:133] step: 1048450, training_loss: 3.25383e-02
I0214 11:05:41.217673 22509476222784 run_lib.py:133] step: 1048500, training_loss: 4.25119e-02
I0214 11:05:41.384123 22509476222784 run_lib.py:146] step: 1048500, eval_loss: 5.49416e-02
I0214 11:06:00.243073 22509476222784 run_lib.py:133] step: 1048550, training_loss: 4.57650e-02
I0214 11:06:19.292963 22509476222784 run_lib.py:133] step: 1048600, training_loss: 4.18775e-02
I0214 11:06:19.454911 22509476222784 run_lib.py:146] step: 1048600, eval_loss: 5.02872e-02
I0214 11:06:38.117702 22509476222784 run_lib.py:133] step: 1048650, training_loss: 4.63722e-02
I0214 11:06:57.000887 22509476222784 run_lib.py:133] step: 1048700, training_loss: 3.41013e-02
I0214 11:06:57.183671 22509476222784 run_lib.py:146] step: 1048700, eval_loss: 6.79517e-02
I0214 11:07:15.910210 22509476222784 run_lib.py:133] step: 1048750, training_loss: 4.28814e-02
I0214 11:07:34.971899 22509476222784 run_lib.py:133] step: 1048800, training_loss: 3.21614e-02
I0214 11:07:35.139845 22509476222784 run_lib.py:146] step: 1048800, eval_loss: 4.26671e-02
I0214 11:07:53.838408 22509476222784 run_lib.py:133] step: 1048850, training_loss: 3.73818e-02
I0214 11:08:12.668567 22509476222784 run_lib.py:133] step: 1048900, training_loss: 4.05905e-02
I0214 11:08:12.849244 22509476222784 run_lib.py:146] step: 1048900, eval_loss: 5.94675e-02
I0214 11:08:31.690219 22509476222784 run_lib.py:133] step: 1048950, training_loss: 3.78518e-02
I0214 11:08:50.427755 22509476222784 run_lib.py:133] step: 1049000, training_loss: 4.52189e-02
I0214 11:08:50.590640 22509476222784 run_lib.py:146] step: 1049000, eval_loss: 3.93994e-02
I0214 11:09:09.698455 22509476222784 run_lib.py:133] step: 1049050, training_loss: 4.06577e-02
I0214 11:09:28.498469 22509476222784 run_lib.py:133] step: 1049100, training_loss: 5.20917e-02
I0214 11:09:28.662844 22509476222784 run_lib.py:146] step: 1049100, eval_loss: 5.49511e-02
I0214 11:09:47.409323 22509476222784 run_lib.py:133] step: 1049150, training_loss: 3.93662e-02
I0214 11:10:06.172447 22509476222784 run_lib.py:133] step: 1049200, training_loss: 5.33068e-02
I0214 11:10:06.355705 22509476222784 run_lib.py:146] step: 1049200, eval_loss: 3.77610e-02
I0214 11:10:25.292121 22509476222784 run_lib.py:133] step: 1049250, training_loss: 3.22086e-02
I0214 11:10:44.136940 22509476222784 run_lib.py:133] step: 1049300, training_loss: 4.89969e-02
I0214 11:10:44.303301 22509476222784 run_lib.py:146] step: 1049300, eval_loss: 3.37468e-02
I0214 11:11:03.206397 22509476222784 run_lib.py:133] step: 1049350, training_loss: 4.47614e-02
I0214 11:11:22.015845 22509476222784 run_lib.py:133] step: 1049400, training_loss: 3.39494e-02
I0214 11:11:22.182017 22509476222784 run_lib.py:146] step: 1049400, eval_loss: 5.31143e-02
I0214 11:11:41.093659 22509476222784 run_lib.py:133] step: 1049450, training_loss: 3.84644e-02
I0214 11:11:59.896440 22509476222784 run_lib.py:133] step: 1049500, training_loss: 3.04143e-02
I0214 11:12:00.066320 22509476222784 run_lib.py:146] step: 1049500, eval_loss: 3.08400e-02
I0214 11:12:18.937655 22509476222784 run_lib.py:133] step: 1049550, training_loss: 4.48210e-02
I0214 11:12:37.858689 22509476222784 run_lib.py:133] step: 1049600, training_loss: 4.72068e-02
I0214 11:12:38.022780 22509476222784 run_lib.py:146] step: 1049600, eval_loss: 3.94381e-02
I0214 11:12:56.851741 22509476222784 run_lib.py:133] step: 1049650, training_loss: 3.92459e-02
I0214 11:13:15.690654 22509476222784 run_lib.py:133] step: 1049700, training_loss: 5.02436e-02
I0214 11:13:15.861897 22509476222784 run_lib.py:146] step: 1049700, eval_loss: 5.74913e-02
I0214 11:13:34.704295 22509476222784 run_lib.py:133] step: 1049750, training_loss: 5.31406e-02
I0214 11:13:53.555889 22509476222784 run_lib.py:133] step: 1049800, training_loss: 3.92816e-02
I0214 11:13:53.722363 22509476222784 run_lib.py:146] step: 1049800, eval_loss: 3.97281e-02
I0214 11:14:12.625179 22509476222784 run_lib.py:133] step: 1049850, training_loss: 4.10849e-02
I0214 11:14:31.407725 22509476222784 run_lib.py:133] step: 1049900, training_loss: 4.22106e-02
I0214 11:14:31.598003 22509476222784 run_lib.py:146] step: 1049900, eval_loss: 3.49549e-02
I0214 11:14:50.308522 22509476222784 run_lib.py:133] step: 1049950, training_loss: 4.59289e-02
I0214 11:15:09.302638 22509476222784 run_lib.py:133] step: 1050000, training_loss: 3.44768e-02
I0214 11:15:10.229969 22509476222784 run_lib.py:146] step: 1050000, eval_loss: 4.91576e-02
I0214 11:15:31.961101 22509476222784 run_lib.py:133] step: 1050050, training_loss: 4.25948e-02
I0214 11:15:50.673183 22509476222784 run_lib.py:133] step: 1050100, training_loss: 4.26359e-02
I0214 11:15:50.837344 22509476222784 run_lib.py:146] step: 1050100, eval_loss: 3.90925e-02
I0214 11:16:09.633185 22509476222784 run_lib.py:133] step: 1050150, training_loss: 3.84591e-02
I0214 11:16:28.499186 22509476222784 run_lib.py:133] step: 1050200, training_loss: 4.58928e-02
I0214 11:16:28.669991 22509476222784 run_lib.py:146] step: 1050200, eval_loss: 4.19486e-02
I0214 11:16:47.490318 22509476222784 run_lib.py:133] step: 1050250, training_loss: 6.07551e-02
I0214 11:17:06.295026 22509476222784 run_lib.py:133] step: 1050300, training_loss: 3.19985e-02
I0214 11:17:06.461988 22509476222784 run_lib.py:146] step: 1050300, eval_loss: 3.82828e-02
I0214 11:17:25.423806 22509476222784 run_lib.py:133] step: 1050350, training_loss: 4.01235e-02
I0214 11:17:44.284335 22509476222784 run_lib.py:133] step: 1050400, training_loss: 3.39070e-02
I0214 11:17:44.460041 22509476222784 run_lib.py:146] step: 1050400, eval_loss: 4.40181e-02
I0214 11:18:03.287737 22509476222784 run_lib.py:133] step: 1050450, training_loss: 3.99350e-02
I0214 11:18:22.094956 22509476222784 run_lib.py:133] step: 1050500, training_loss: 4.13177e-02
I0214 11:18:22.261740 22509476222784 run_lib.py:146] step: 1050500, eval_loss: 3.63555e-02
I0214 11:18:41.061431 22509476222784 run_lib.py:133] step: 1050550, training_loss: 3.86655e-02
I0214 11:18:59.776322 22509476222784 run_lib.py:133] step: 1050600, training_loss: 4.33731e-02
I0214 11:18:59.949012 22509476222784 run_lib.py:146] step: 1050600, eval_loss: 4.13356e-02
I0214 11:19:18.938050 22509476222784 run_lib.py:133] step: 1050650, training_loss: 4.25370e-02
I0214 11:19:37.786982 22509476222784 run_lib.py:133] step: 1050700, training_loss: 3.88323e-02
I0214 11:19:37.956695 22509476222784 run_lib.py:146] step: 1050700, eval_loss: 3.35234e-02
I0214 11:19:56.716008 22509476222784 run_lib.py:133] step: 1050750, training_loss: 4.18505e-02
I0214 11:20:15.642323 22509476222784 run_lib.py:133] step: 1050800, training_loss: 4.13736e-02
I0214 11:20:15.807810 22509476222784 run_lib.py:146] step: 1050800, eval_loss: 4.22831e-02
I0214 11:20:34.710295 22509476222784 run_lib.py:133] step: 1050850, training_loss: 4.49295e-02
I0214 11:20:53.524801 22509476222784 run_lib.py:133] step: 1050900, training_loss: 3.34511e-02
I0214 11:20:53.690890 22509476222784 run_lib.py:146] step: 1050900, eval_loss: 4.17791e-02
I0214 11:21:12.611529 22509476222784 run_lib.py:133] step: 1050950, training_loss: 3.87545e-02
I0214 11:21:31.360947 22509476222784 run_lib.py:133] step: 1051000, training_loss: 3.61974e-02
I0214 11:21:31.537302 22509476222784 run_lib.py:146] step: 1051000, eval_loss: 3.56252e-02
I0214 11:21:50.543560 22509476222784 run_lib.py:133] step: 1051050, training_loss: 3.64401e-02
I0214 11:22:09.330178 22509476222784 run_lib.py:133] step: 1051100, training_loss: 4.25249e-02
I0214 11:22:09.500120 22509476222784 run_lib.py:146] step: 1051100, eval_loss: 4.47587e-02
I0214 11:22:28.490442 22509476222784 run_lib.py:133] step: 1051150, training_loss: 4.44051e-02
I0214 11:22:47.189378 22509476222784 run_lib.py:133] step: 1051200, training_loss: 4.45164e-02
I0214 11:22:47.358034 22509476222784 run_lib.py:146] step: 1051200, eval_loss: 4.76825e-02
I0214 11:23:06.140681 22509476222784 run_lib.py:133] step: 1051250, training_loss: 4.53155e-02
I0214 11:23:25.025222 22509476222784 run_lib.py:133] step: 1051300, training_loss: 4.09433e-02
I0214 11:23:25.198000 22509476222784 run_lib.py:146] step: 1051300, eval_loss: 4.51378e-02
I0214 11:23:44.010096 22509476222784 run_lib.py:133] step: 1051350, training_loss: 4.40923e-02
I0214 11:24:02.804467 22509476222784 run_lib.py:133] step: 1051400, training_loss: 4.45751e-02
I0214 11:24:02.970055 22509476222784 run_lib.py:146] step: 1051400, eval_loss: 3.07434e-02
I0214 11:24:21.904664 22509476222784 run_lib.py:133] step: 1051450, training_loss: 3.70824e-02
I0214 11:24:40.812924 22509476222784 run_lib.py:133] step: 1051500, training_loss: 4.48683e-02
I0214 11:24:41.047936 22509476222784 run_lib.py:146] step: 1051500, eval_loss: 2.88868e-02
I0214 11:24:59.967580 22509476222784 run_lib.py:133] step: 1051550, training_loss: 4.12720e-02
I0214 11:25:18.899946 22509476222784 run_lib.py:133] step: 1051600, training_loss: 3.71926e-02
I0214 11:25:19.084069 22509476222784 run_lib.py:146] step: 1051600, eval_loss: 4.22699e-02
I0214 11:25:37.843599 22509476222784 run_lib.py:133] step: 1051650, training_loss: 4.92760e-02
I0214 11:25:56.788428 22509476222784 run_lib.py:133] step: 1051700, training_loss: 3.42389e-02
I0214 11:25:56.956689 22509476222784 run_lib.py:146] step: 1051700, eval_loss: 4.14142e-02
I0214 11:26:15.774176 22509476222784 run_lib.py:133] step: 1051750, training_loss: 4.43815e-02
I0214 11:26:34.513170 22509476222784 run_lib.py:133] step: 1051800, training_loss: 3.74019e-02
I0214 11:26:34.690218 22509476222784 run_lib.py:146] step: 1051800, eval_loss: 5.14896e-02
I0214 11:26:53.521743 22509476222784 run_lib.py:133] step: 1051850, training_loss: 4.14161e-02
I0214 11:27:12.429866 22509476222784 run_lib.py:133] step: 1051900, training_loss: 4.62085e-02
I0214 11:27:12.597147 22509476222784 run_lib.py:146] step: 1051900, eval_loss: 4.79323e-02
I0214 11:27:31.363842 22509476222784 run_lib.py:133] step: 1051950, training_loss: 4.17661e-02
I0214 11:27:50.195727 22509476222784 run_lib.py:133] step: 1052000, training_loss: 3.75276e-02
I0214 11:27:50.358855 22509476222784 run_lib.py:146] step: 1052000, eval_loss: 4.09285e-02
I0214 11:28:09.048813 22509476222784 run_lib.py:133] step: 1052050, training_loss: 4.18790e-02
I0214 11:28:27.942383 22509476222784 run_lib.py:133] step: 1052100, training_loss: 3.81552e-02
I0214 11:28:28.126046 22509476222784 run_lib.py:146] step: 1052100, eval_loss: 3.91907e-02
I0214 11:28:47.087566 22509476222784 run_lib.py:133] step: 1052150, training_loss: 4.58672e-02
I0214 11:29:05.926604 22509476222784 run_lib.py:133] step: 1052200, training_loss: 2.92734e-02
I0214 11:29:06.092182 22509476222784 run_lib.py:146] step: 1052200, eval_loss: 3.59056e-02
I0214 11:29:24.817801 22509476222784 run_lib.py:133] step: 1052250, training_loss: 3.26836e-02
I0214 11:29:43.487637 22509476222784 run_lib.py:133] step: 1052300, training_loss: 3.54166e-02
I0214 11:29:43.666201 22509476222784 run_lib.py:146] step: 1052300, eval_loss: 3.45973e-02
I0214 11:30:02.603611 22509476222784 run_lib.py:133] step: 1052350, training_loss: 3.14738e-02
I0214 11:30:21.289466 22509476222784 run_lib.py:133] step: 1052400, training_loss: 4.11815e-02
I0214 11:30:21.451621 22509476222784 run_lib.py:146] step: 1052400, eval_loss: 3.82663e-02
I0214 11:30:40.484641 22509476222784 run_lib.py:133] step: 1052450, training_loss: 3.80273e-02
I0214 11:30:59.199073 22509476222784 run_lib.py:133] step: 1052500, training_loss: 3.93364e-02
I0214 11:30:59.364919 22509476222784 run_lib.py:146] step: 1052500, eval_loss: 3.74107e-02
I0214 11:31:18.232023 22509476222784 run_lib.py:133] step: 1052550, training_loss: 3.52321e-02
I0214 11:31:37.038607 22509476222784 run_lib.py:133] step: 1052600, training_loss: 2.91420e-02
I0214 11:31:37.218241 22509476222784 run_lib.py:146] step: 1052600, eval_loss: 4.58164e-02
I0214 11:31:55.870475 22509476222784 run_lib.py:133] step: 1052650, training_loss: 4.13749e-02
I0214 11:32:14.800301 22509476222784 run_lib.py:133] step: 1052700, training_loss: 3.91183e-02
I0214 11:32:14.971254 22509476222784 run_lib.py:146] step: 1052700, eval_loss: 4.28332e-02
I0214 11:32:33.627887 22509476222784 run_lib.py:133] step: 1052750, training_loss: 4.03400e-02
I0214 11:32:52.462802 22509476222784 run_lib.py:133] step: 1052800, training_loss: 5.25391e-02
I0214 11:32:52.633414 22509476222784 run_lib.py:146] step: 1052800, eval_loss: 4.87821e-02
I0214 11:33:11.467881 22509476222784 run_lib.py:133] step: 1052850, training_loss: 4.05857e-02
I0214 11:33:30.136983 22509476222784 run_lib.py:133] step: 1052900, training_loss: 4.22222e-02
I0214 11:33:30.298856 22509476222784 run_lib.py:146] step: 1052900, eval_loss: 6.11846e-02
I0214 11:33:49.310352 22509476222784 run_lib.py:133] step: 1052950, training_loss: 3.68611e-02
I0214 11:34:08.008548 22509476222784 run_lib.py:133] step: 1053000, training_loss: 4.01999e-02
I0214 11:34:08.173893 22509476222784 run_lib.py:146] step: 1053000, eval_loss: 4.60245e-02
I0214 11:34:26.809223 22509476222784 run_lib.py:133] step: 1053050, training_loss: 3.55561e-02
I0214 11:34:45.869878 22509476222784 run_lib.py:133] step: 1053100, training_loss: 3.29940e-02
I0214 11:34:46.038033 22509476222784 run_lib.py:146] step: 1053100, eval_loss: 4.10766e-02
I0214 11:35:04.717195 22509476222784 run_lib.py:133] step: 1053150, training_loss: 4.51291e-02
I0214 11:35:23.529080 22509476222784 run_lib.py:133] step: 1053200, training_loss: 3.05467e-02
I0214 11:35:23.890901 22509476222784 run_lib.py:146] step: 1053200, eval_loss: 6.04668e-02
I0214 11:35:42.554797 22509476222784 run_lib.py:133] step: 1053250, training_loss: 3.23221e-02
I0214 11:36:01.331871 22509476222784 run_lib.py:133] step: 1053300, training_loss: 4.83295e-02
I0214 11:36:01.498164 22509476222784 run_lib.py:146] step: 1053300, eval_loss: 4.12520e-02
I0214 11:36:20.371951 22509476222784 run_lib.py:133] step: 1053350, training_loss: 3.94190e-02
I0214 11:36:39.128623 22509476222784 run_lib.py:133] step: 1053400, training_loss: 3.45641e-02
I0214 11:36:39.290883 22509476222784 run_lib.py:146] step: 1053400, eval_loss: 5.26442e-02
I0214 11:36:58.321429 22509476222784 run_lib.py:133] step: 1053450, training_loss: 4.05101e-02
I0214 11:37:17.079603 22509476222784 run_lib.py:133] step: 1053500, training_loss: 4.58872e-02
I0214 11:37:17.247647 22509476222784 run_lib.py:146] step: 1053500, eval_loss: 4.89898e-02
I0214 11:37:36.028364 22509476222784 run_lib.py:133] step: 1053550, training_loss: 4.05509e-02
I0214 11:37:54.797775 22509476222784 run_lib.py:133] step: 1053600, training_loss: 3.96956e-02
I0214 11:37:54.969965 22509476222784 run_lib.py:146] step: 1053600, eval_loss: 3.76014e-02
I0214 11:38:13.988467 22509476222784 run_lib.py:133] step: 1053650, training_loss: 3.34897e-02
I0214 11:38:32.773996 22509476222784 run_lib.py:133] step: 1053700, training_loss: 4.30761e-02
I0214 11:38:32.941155 22509476222784 run_lib.py:146] step: 1053700, eval_loss: 3.95875e-02
I0214 11:38:51.640723 22509476222784 run_lib.py:133] step: 1053750, training_loss: 4.36085e-02
I0214 11:39:10.532720 22509476222784 run_lib.py:133] step: 1053800, training_loss: 3.83802e-02
I0214 11:39:10.704734 22509476222784 run_lib.py:146] step: 1053800, eval_loss: 4.59371e-02
I0214 11:39:29.508179 22509476222784 run_lib.py:133] step: 1053850, training_loss: 4.62525e-02
I0214 11:39:48.410317 22509476222784 run_lib.py:133] step: 1053900, training_loss: 4.08645e-02
I0214 11:39:48.579258 22509476222784 run_lib.py:146] step: 1053900, eval_loss: 4.07160e-02
I0214 11:40:07.502193 22509476222784 run_lib.py:133] step: 1053950, training_loss: 2.97703e-02
I0214 11:40:26.238930 22509476222784 run_lib.py:133] step: 1054000, training_loss: 3.41232e-02
I0214 11:40:26.415183 22509476222784 run_lib.py:146] step: 1054000, eval_loss: 4.33400e-02
I0214 11:40:45.323103 22509476222784 run_lib.py:133] step: 1054050, training_loss: 4.40840e-02
I0214 11:41:04.021320 22509476222784 run_lib.py:133] step: 1054100, training_loss: 3.52430e-02
I0214 11:41:04.197021 22509476222784 run_lib.py:146] step: 1054100, eval_loss: 4.01105e-02
I0214 11:41:23.011744 22509476222784 run_lib.py:133] step: 1054150, training_loss: 4.73988e-02
I0214 11:41:42.014193 22509476222784 run_lib.py:133] step: 1054200, training_loss: 4.29421e-02
I0214 11:41:42.178321 22509476222784 run_lib.py:146] step: 1054200, eval_loss: 5.10327e-02
I0214 11:42:00.934334 22509476222784 run_lib.py:133] step: 1054250, training_loss: 4.29795e-02
I0214 11:42:19.959778 22509476222784 run_lib.py:133] step: 1054300, training_loss: 3.89774e-02
I0214 11:42:20.126026 22509476222784 run_lib.py:146] step: 1054300, eval_loss: 4.14192e-02
I0214 11:42:38.818469 22509476222784 run_lib.py:133] step: 1054350, training_loss: 4.60204e-02
I0214 11:42:57.652009 22509476222784 run_lib.py:133] step: 1054400, training_loss: 5.45211e-02
I0214 11:42:57.843284 22509476222784 run_lib.py:146] step: 1054400, eval_loss: 3.60051e-02
I0214 11:43:16.908643 22509476222784 run_lib.py:133] step: 1054450, training_loss: 5.15104e-02
I0214 11:43:35.702591 22509476222784 run_lib.py:133] step: 1054500, training_loss: 3.61278e-02
I0214 11:43:35.870522 22509476222784 run_lib.py:146] step: 1054500, eval_loss: 4.66902e-02
I0214 11:43:54.731585 22509476222784 run_lib.py:133] step: 1054550, training_loss: 5.16163e-02
I0214 11:44:13.492875 22509476222784 run_lib.py:133] step: 1054600, training_loss: 4.22975e-02
I0214 11:44:13.666893 22509476222784 run_lib.py:146] step: 1054600, eval_loss: 4.48136e-02
I0214 11:44:32.712691 22509476222784 run_lib.py:133] step: 1054650, training_loss: 3.53483e-02
I0214 11:44:51.511748 22509476222784 run_lib.py:133] step: 1054700, training_loss: 3.66588e-02
I0214 11:44:51.678177 22509476222784 run_lib.py:146] step: 1054700, eval_loss: 3.79793e-02
I0214 11:45:10.515434 22509476222784 run_lib.py:133] step: 1054750, training_loss: 4.12064e-02
I0214 11:45:29.350077 22509476222784 run_lib.py:133] step: 1054800, training_loss: 5.64797e-02
I0214 11:45:29.512953 22509476222784 run_lib.py:146] step: 1054800, eval_loss: 4.31774e-02
I0214 11:45:48.280975 22509476222784 run_lib.py:133] step: 1054850, training_loss: 3.40139e-02
I0214 11:46:07.133584 22509476222784 run_lib.py:133] step: 1054900, training_loss: 5.20742e-02
I0214 11:46:07.307435 22509476222784 run_lib.py:146] step: 1054900, eval_loss: 4.98258e-02
I0214 11:46:26.242762 22509476222784 run_lib.py:133] step: 1054950, training_loss: 4.05596e-02
I0214 11:46:45.165643 22509476222784 run_lib.py:133] step: 1055000, training_loss: 3.59869e-02
I0214 11:46:45.341150 22509476222784 run_lib.py:146] step: 1055000, eval_loss: 3.33921e-02
I0214 11:47:04.179737 22509476222784 run_lib.py:133] step: 1055050, training_loss: 5.67172e-02
I0214 11:47:22.972346 22509476222784 run_lib.py:133] step: 1055100, training_loss: 3.90850e-02
I0214 11:47:23.139449 22509476222784 run_lib.py:146] step: 1055100, eval_loss: 4.90837e-02
I0214 11:47:42.172645 22509476222784 run_lib.py:133] step: 1055150, training_loss: 6.65849e-02
I0214 11:48:00.942525 22509476222784 run_lib.py:133] step: 1055200, training_loss: 3.47327e-02
I0214 11:48:01.106952 22509476222784 run_lib.py:146] step: 1055200, eval_loss: 4.41182e-02
I0214 11:48:20.063716 22509476222784 run_lib.py:133] step: 1055250, training_loss: 5.62968e-02
I0214 11:48:38.846698 22509476222784 run_lib.py:133] step: 1055300, training_loss: 5.58514e-02
I0214 11:48:39.014265 22509476222784 run_lib.py:146] step: 1055300, eval_loss: 4.84462e-02
I0214 11:48:57.943645 22509476222784 run_lib.py:133] step: 1055350, training_loss: 4.46497e-02
I0214 11:49:16.800612 22509476222784 run_lib.py:133] step: 1055400, training_loss: 4.77466e-02
I0214 11:49:16.975234 22509476222784 run_lib.py:146] step: 1055400, eval_loss: 4.01000e-02
I0214 11:49:35.820473 22509476222784 run_lib.py:133] step: 1055450, training_loss: 4.29885e-02
I0214 11:49:54.595488 22509476222784 run_lib.py:133] step: 1055500, training_loss: 3.81776e-02
I0214 11:49:54.772645 22509476222784 run_lib.py:146] step: 1055500, eval_loss: 3.09898e-02
I0214 11:50:13.566671 22509476222784 run_lib.py:133] step: 1055550, training_loss: 3.17237e-02
I0214 11:50:32.556962 22509476222784 run_lib.py:133] step: 1055600, training_loss: 3.18742e-02
I0214 11:50:32.722590 22509476222784 run_lib.py:146] step: 1055600, eval_loss: 4.56724e-02
I0214 11:50:51.618252 22509476222784 run_lib.py:133] step: 1055650, training_loss: 5.58161e-02
I0214 11:51:10.381153 22509476222784 run_lib.py:133] step: 1055700, training_loss: 3.68055e-02
I0214 11:51:10.543783 22509476222784 run_lib.py:146] step: 1055700, eval_loss: 3.96935e-02
I0214 11:51:29.617388 22509476222784 run_lib.py:133] step: 1055750, training_loss: 3.42100e-02
I0214 11:51:48.616916 22509476222784 run_lib.py:133] step: 1055800, training_loss: 4.15755e-02
I0214 11:51:48.793154 22509476222784 run_lib.py:146] step: 1055800, eval_loss: 4.83930e-02
I0214 11:52:07.620139 22509476222784 run_lib.py:133] step: 1055850, training_loss: 4.11264e-02
I0214 11:52:26.492113 22509476222784 run_lib.py:133] step: 1055900, training_loss: 3.57682e-02
I0214 11:52:26.661477 22509476222784 run_lib.py:146] step: 1055900, eval_loss: 4.52116e-02
I0214 11:52:45.430934 22509476222784 run_lib.py:133] step: 1055950, training_loss: 3.86364e-02
I0214 11:53:04.428445 22509476222784 run_lib.py:133] step: 1056000, training_loss: 4.22475e-02
I0214 11:53:04.600249 22509476222784 run_lib.py:146] step: 1056000, eval_loss: 4.81082e-02
I0214 11:53:23.500586 22509476222784 run_lib.py:133] step: 1056050, training_loss: 3.31188e-02
I0214 11:53:42.241358 22509476222784 run_lib.py:133] step: 1056100, training_loss: 2.99540e-02
I0214 11:53:42.407813 22509476222784 run_lib.py:146] step: 1056100, eval_loss: 4.79420e-02
I0214 11:54:01.273133 22509476222784 run_lib.py:133] step: 1056150, training_loss: 3.40542e-02
I0214 11:54:20.189475 22509476222784 run_lib.py:133] step: 1056200, training_loss: 4.02495e-02
I0214 11:54:20.408809 22509476222784 run_lib.py:146] step: 1056200, eval_loss: 4.06708e-02
I0214 11:54:39.285133 22509476222784 run_lib.py:133] step: 1056250, training_loss: 4.56733e-02
I0214 11:54:58.173121 22509476222784 run_lib.py:133] step: 1056300, training_loss: 5.37903e-02
I0214 11:54:58.345285 22509476222784 run_lib.py:146] step: 1056300, eval_loss: 5.16319e-02
I0214 11:55:17.127940 22509476222784 run_lib.py:133] step: 1056350, training_loss: 5.41035e-02
I0214 11:55:36.056123 22509476222784 run_lib.py:133] step: 1056400, training_loss: 4.98946e-02
I0214 11:55:36.232296 22509476222784 run_lib.py:146] step: 1056400, eval_loss: 4.00091e-02
I0214 11:55:55.164453 22509476222784 run_lib.py:133] step: 1056450, training_loss: 4.69535e-02
I0214 11:56:14.111560 22509476222784 run_lib.py:133] step: 1056500, training_loss: 4.54230e-02
I0214 11:56:14.287005 22509476222784 run_lib.py:146] step: 1056500, eval_loss: 4.98396e-02
I0214 11:56:33.079031 22509476222784 run_lib.py:133] step: 1056550, training_loss: 3.79315e-02
I0214 11:56:51.903179 22509476222784 run_lib.py:133] step: 1056600, training_loss: 4.13632e-02
I0214 11:56:52.073135 22509476222784 run_lib.py:146] step: 1056600, eval_loss: 3.97715e-02
I0214 11:57:11.115331 22509476222784 run_lib.py:133] step: 1056650, training_loss: 4.54245e-02
I0214 11:57:29.842839 22509476222784 run_lib.py:133] step: 1056700, training_loss: 4.05053e-02
I0214 11:57:30.007539 22509476222784 run_lib.py:146] step: 1056700, eval_loss: 4.19807e-02
I0214 11:57:49.033477 22509476222784 run_lib.py:133] step: 1056750, training_loss: 3.94932e-02
I0214 11:58:07.863738 22509476222784 run_lib.py:133] step: 1056800, training_loss: 4.15477e-02
I0214 11:58:08.046105 22509476222784 run_lib.py:146] step: 1056800, eval_loss: 5.10334e-02
I0214 11:58:27.004818 22509476222784 run_lib.py:133] step: 1056850, training_loss: 3.90194e-02
I0214 11:58:45.781986 22509476222784 run_lib.py:133] step: 1056900, training_loss: 4.57113e-02
I0214 11:58:45.950144 22509476222784 run_lib.py:146] step: 1056900, eval_loss: 4.85821e-02
I0214 11:59:04.692183 22509476222784 run_lib.py:133] step: 1056950, training_loss: 4.74962e-02
I0214 11:59:23.762752 22509476222784 run_lib.py:133] step: 1057000, training_loss: 4.52191e-02
I0214 11:59:23.947015 22509476222784 run_lib.py:146] step: 1057000, eval_loss: 3.96749e-02
I0214 11:59:42.741940 22509476222784 run_lib.py:133] step: 1057050, training_loss: 5.60563e-02
I0214 12:00:01.764523 22509476222784 run_lib.py:133] step: 1057100, training_loss: 3.95699e-02
I0214 12:00:01.939192 22509476222784 run_lib.py:146] step: 1057100, eval_loss: 4.44568e-02
I0214 12:00:20.754633 22509476222784 run_lib.py:133] step: 1057150, training_loss: 3.42836e-02
I0214 12:00:39.556142 22509476222784 run_lib.py:133] step: 1057200, training_loss: 4.86548e-02
I0214 12:00:39.725683 22509476222784 run_lib.py:146] step: 1057200, eval_loss: 3.25673e-02
I0214 12:00:58.705461 22509476222784 run_lib.py:133] step: 1057250, training_loss: 3.49488e-02
I0214 12:01:17.485259 22509476222784 run_lib.py:133] step: 1057300, training_loss: 3.11932e-02
I0214 12:01:17.686809 22509476222784 run_lib.py:146] step: 1057300, eval_loss: 3.05838e-02
I0214 12:01:36.544642 22509476222784 run_lib.py:133] step: 1057350, training_loss: 5.20284e-02
I0214 12:01:55.504864 22509476222784 run_lib.py:133] step: 1057400, training_loss: 3.86440e-02
I0214 12:01:55.673318 22509476222784 run_lib.py:146] step: 1057400, eval_loss: 4.35270e-02
I0214 12:02:14.371645 22509476222784 run_lib.py:133] step: 1057450, training_loss: 3.75373e-02
I0214 12:02:33.126882 22509476222784 run_lib.py:133] step: 1057500, training_loss: 6.42526e-02
I0214 12:02:33.293203 22509476222784 run_lib.py:146] step: 1057500, eval_loss: 4.82753e-02
I0214 12:02:52.113847 22509476222784 run_lib.py:133] step: 1057550, training_loss: 4.69001e-02
I0214 12:03:11.036721 22509476222784 run_lib.py:133] step: 1057600, training_loss: 3.87300e-02
I0214 12:03:11.206909 22509476222784 run_lib.py:146] step: 1057600, eval_loss: 4.29101e-02
I0214 12:03:29.912978 22509476222784 run_lib.py:133] step: 1057650, training_loss: 3.93007e-02
I0214 12:03:48.713256 22509476222784 run_lib.py:133] step: 1057700, training_loss: 4.44912e-02
I0214 12:03:48.877983 22509476222784 run_lib.py:146] step: 1057700, eval_loss: 4.14423e-02
I0214 12:04:07.803024 22509476222784 run_lib.py:133] step: 1057750, training_loss: 5.05688e-02
I0214 12:04:26.595057 22509476222784 run_lib.py:133] step: 1057800, training_loss: 3.85757e-02
I0214 12:04:26.783169 22509476222784 run_lib.py:146] step: 1057800, eval_loss: 3.68172e-02
I0214 12:04:45.687598 22509476222784 run_lib.py:133] step: 1057850, training_loss: 3.94591e-02
I0214 12:05:04.521257 22509476222784 run_lib.py:133] step: 1057900, training_loss: 4.45067e-02
I0214 12:05:04.697449 22509476222784 run_lib.py:146] step: 1057900, eval_loss: 4.28307e-02
I0214 12:05:23.783480 22509476222784 run_lib.py:133] step: 1057950, training_loss: 4.11737e-02
I0214 12:05:42.537093 22509476222784 run_lib.py:133] step: 1058000, training_loss: 4.88315e-02
I0214 12:05:42.703034 22509476222784 run_lib.py:146] step: 1058000, eval_loss: 4.91606e-02
I0214 12:06:01.703203 22509476222784 run_lib.py:133] step: 1058050, training_loss: 2.87812e-02
I0214 12:06:20.520885 22509476222784 run_lib.py:133] step: 1058100, training_loss: 4.57329e-02
I0214 12:06:20.694256 22509476222784 run_lib.py:146] step: 1058100, eval_loss: 4.55848e-02
I0214 12:06:39.707077 22509476222784 run_lib.py:133] step: 1058150, training_loss: 5.09345e-02
I0214 12:06:58.551848 22509476222784 run_lib.py:133] step: 1058200, training_loss: 4.60122e-02
I0214 12:06:58.720895 22509476222784 run_lib.py:146] step: 1058200, eval_loss: 4.66872e-02
I0214 12:07:17.649426 22509476222784 run_lib.py:133] step: 1058250, training_loss: 4.19296e-02
I0214 12:07:36.503984 22509476222784 run_lib.py:133] step: 1058300, training_loss: 4.34750e-02
I0214 12:07:36.672209 22509476222784 run_lib.py:146] step: 1058300, eval_loss: 5.04377e-02
I0214 12:07:55.376848 22509476222784 run_lib.py:133] step: 1058350, training_loss: 3.61177e-02
I0214 12:08:14.440541 22509476222784 run_lib.py:133] step: 1058400, training_loss: 4.60760e-02
I0214 12:08:14.611163 22509476222784 run_lib.py:146] step: 1058400, eval_loss: 3.40459e-02
I0214 12:08:33.421127 22509476222784 run_lib.py:133] step: 1058450, training_loss: 4.16907e-02
I0214 12:08:52.137497 22509476222784 run_lib.py:133] step: 1058500, training_loss: 4.03349e-02
I0214 12:08:52.303933 22509476222784 run_lib.py:146] step: 1058500, eval_loss: 4.92575e-02
I0214 12:09:11.364151 22509476222784 run_lib.py:133] step: 1058550, training_loss: 5.11019e-02
I0214 12:09:30.152512 22509476222784 run_lib.py:133] step: 1058600, training_loss: 3.45202e-02
I0214 12:09:30.318935 22509476222784 run_lib.py:146] step: 1058600, eval_loss: 3.88955e-02
I0214 12:09:49.316708 22509476222784 run_lib.py:133] step: 1058650, training_loss: 4.73987e-02
I0214 12:10:08.202656 22509476222784 run_lib.py:133] step: 1058700, training_loss: 4.07540e-02
I0214 12:10:08.365676 22509476222784 run_lib.py:146] step: 1058700, eval_loss: 5.00719e-02
I0214 12:10:27.144750 22509476222784 run_lib.py:133] step: 1058750, training_loss: 3.63877e-02
I0214 12:10:46.237539 22509476222784 run_lib.py:133] step: 1058800, training_loss: 4.35143e-02
I0214 12:10:46.406741 22509476222784 run_lib.py:146] step: 1058800, eval_loss: 3.83249e-02
I0214 12:11:05.054917 22509476222784 run_lib.py:133] step: 1058850, training_loss: 3.60152e-02
I0214 12:11:23.781092 22509476222784 run_lib.py:133] step: 1058900, training_loss: 3.76387e-02
I0214 12:11:23.956078 22509476222784 run_lib.py:146] step: 1058900, eval_loss: 4.13496e-02
I0214 12:11:42.869727 22509476222784 run_lib.py:133] step: 1058950, training_loss: 2.89985e-02
I0214 12:12:01.842628 22509476222784 run_lib.py:133] step: 1059000, training_loss: 4.37742e-02
I0214 12:12:02.008201 22509476222784 run_lib.py:146] step: 1059000, eval_loss: 5.28585e-02
I0214 12:12:20.893379 22509476222784 run_lib.py:133] step: 1059050, training_loss: 3.62774e-02
I0214 12:12:39.753324 22509476222784 run_lib.py:133] step: 1059100, training_loss: 3.49948e-02
I0214 12:12:39.918168 22509476222784 run_lib.py:146] step: 1059100, eval_loss: 5.16736e-02
I0214 12:12:58.883046 22509476222784 run_lib.py:133] step: 1059150, training_loss: 3.68903e-02
I0214 12:13:17.696972 22509476222784 run_lib.py:133] step: 1059200, training_loss: 3.81456e-02
I0214 12:13:17.865954 22509476222784 run_lib.py:146] step: 1059200, eval_loss: 3.31160e-02
I0214 12:13:36.951951 22509476222784 run_lib.py:133] step: 1059250, training_loss: 5.26825e-02
I0214 12:13:55.843724 22509476222784 run_lib.py:133] step: 1059300, training_loss: 3.30409e-02
I0214 12:13:56.009967 22509476222784 run_lib.py:146] step: 1059300, eval_loss: 5.79931e-02
I0214 12:14:14.765038 22509476222784 run_lib.py:133] step: 1059350, training_loss: 3.52401e-02
I0214 12:14:33.762914 22509476222784 run_lib.py:133] step: 1059400, training_loss: 4.06211e-02
I0214 12:14:33.935146 22509476222784 run_lib.py:146] step: 1059400, eval_loss: 4.05410e-02
I0214 12:14:52.928107 22509476222784 run_lib.py:133] step: 1059450, training_loss: 4.53478e-02
I0214 12:15:11.758482 22509476222784 run_lib.py:133] step: 1059500, training_loss: 4.88198e-02
I0214 12:15:11.933319 22509476222784 run_lib.py:146] step: 1059500, eval_loss: 4.28521e-02
I0214 12:15:30.989049 22509476222784 run_lib.py:133] step: 1059550, training_loss: 3.55006e-02
I0214 12:15:49.762702 22509476222784 run_lib.py:133] step: 1059600, training_loss: 4.20362e-02
I0214 12:15:49.929076 22509476222784 run_lib.py:146] step: 1059600, eval_loss: 4.44153e-02
I0214 12:16:08.855275 22509476222784 run_lib.py:133] step: 1059650, training_loss: 4.35388e-02
I0214 12:16:27.753690 22509476222784 run_lib.py:133] step: 1059700, training_loss: 4.04655e-02
I0214 12:16:27.938219 22509476222784 run_lib.py:146] step: 1059700, eval_loss: 3.64859e-02
I0214 12:16:46.759688 22509476222784 run_lib.py:133] step: 1059750, training_loss: 5.17996e-02
I0214 12:17:05.883060 22509476222784 run_lib.py:133] step: 1059800, training_loss: 4.54382e-02
I0214 12:17:06.059092 22509476222784 run_lib.py:146] step: 1059800, eval_loss: 3.89392e-02
I0214 12:17:24.874901 22509476222784 run_lib.py:133] step: 1059850, training_loss: 3.65942e-02
I0214 12:17:43.832478 22509476222784 run_lib.py:133] step: 1059900, training_loss: 5.18875e-02
I0214 12:17:44.003229 22509476222784 run_lib.py:146] step: 1059900, eval_loss: 4.35781e-02
I0214 12:18:02.900036 22509476222784 run_lib.py:133] step: 1059950, training_loss: 4.05161e-02
I0214 12:18:21.729742 22509476222784 run_lib.py:133] step: 1060000, training_loss: 4.45309e-02
I0214 12:18:23.036945 22509476222784 run_lib.py:146] step: 1060000, eval_loss: 4.08456e-02
I0214 12:18:45.344687 22509476222784 run_lib.py:133] step: 1060050, training_loss: 3.99040e-02
I0214 12:19:04.142697 22509476222784 run_lib.py:133] step: 1060100, training_loss: 3.24646e-02
I0214 12:19:04.306979 22509476222784 run_lib.py:146] step: 1060100, eval_loss: 4.81353e-02
I0214 12:19:23.297437 22509476222784 run_lib.py:133] step: 1060150, training_loss: 3.97573e-02
I0214 12:19:42.101614 22509476222784 run_lib.py:133] step: 1060200, training_loss: 3.36615e-02
I0214 12:19:42.279979 22509476222784 run_lib.py:146] step: 1060200, eval_loss: 3.13998e-02
I0214 12:20:01.119007 22509476222784 run_lib.py:133] step: 1060250, training_loss: 4.40564e-02
I0214 12:20:20.262526 22509476222784 run_lib.py:133] step: 1060300, training_loss: 3.75330e-02
I0214 12:20:20.430356 22509476222784 run_lib.py:146] step: 1060300, eval_loss: 3.67394e-02
I0214 12:20:39.223492 22509476222784 run_lib.py:133] step: 1060350, training_loss: 3.12788e-02
I0214 12:20:58.258811 22509476222784 run_lib.py:133] step: 1060400, training_loss: 3.70862e-02
I0214 12:20:58.422347 22509476222784 run_lib.py:146] step: 1060400, eval_loss: 4.01642e-02
I0214 12:21:17.202826 22509476222784 run_lib.py:133] step: 1060450, training_loss: 3.12207e-02
I0214 12:21:36.131983 22509476222784 run_lib.py:133] step: 1060500, training_loss: 3.96171e-02
I0214 12:21:36.304247 22509476222784 run_lib.py:146] step: 1060500, eval_loss: 5.75858e-02
I0214 12:21:55.189559 22509476222784 run_lib.py:133] step: 1060550, training_loss: 3.27520e-02
I0214 12:22:14.136285 22509476222784 run_lib.py:133] step: 1060600, training_loss: 3.35480e-02
I0214 12:22:14.309059 22509476222784 run_lib.py:146] step: 1060600, eval_loss: 2.64289e-02
I0214 12:22:33.177272 22509476222784 run_lib.py:133] step: 1060650, training_loss: 4.42394e-02
I0214 12:22:51.990987 22509476222784 run_lib.py:133] step: 1060700, training_loss: 3.99319e-02
I0214 12:22:52.174744 22509476222784 run_lib.py:146] step: 1060700, eval_loss: 5.37393e-02
I0214 12:23:11.314882 22509476222784 run_lib.py:133] step: 1060750, training_loss: 3.39141e-02
I0214 12:23:30.124828 22509476222784 run_lib.py:133] step: 1060800, training_loss: 4.52483e-02
I0214 12:23:30.291180 22509476222784 run_lib.py:146] step: 1060800, eval_loss: 2.91090e-02
I0214 12:23:49.191533 22509476222784 run_lib.py:133] step: 1060850, training_loss: 3.05267e-02
I0214 12:24:08.043943 22509476222784 run_lib.py:133] step: 1060900, training_loss: 4.10351e-02
I0214 12:24:08.210758 22509476222784 run_lib.py:146] step: 1060900, eval_loss: 4.54438e-02
I0214 12:24:27.043172 22509476222784 run_lib.py:133] step: 1060950, training_loss: 4.72581e-02
I0214 12:24:45.888657 22509476222784 run_lib.py:133] step: 1061000, training_loss: 4.27385e-02
I0214 12:24:46.057439 22509476222784 run_lib.py:146] step: 1061000, eval_loss: 4.11473e-02
I0214 12:25:05.251757 22509476222784 run_lib.py:133] step: 1061050, training_loss: 4.35416e-02
I0214 12:25:24.166385 22509476222784 run_lib.py:133] step: 1061100, training_loss: 3.81065e-02
I0214 12:25:24.332996 22509476222784 run_lib.py:146] step: 1061100, eval_loss: 3.95960e-02
I0214 12:25:43.116564 22509476222784 run_lib.py:133] step: 1061150, training_loss: 4.07761e-02
I0214 12:26:01.924065 22509476222784 run_lib.py:133] step: 1061200, training_loss: 4.11929e-02
I0214 12:26:02.110049 22509476222784 run_lib.py:146] step: 1061200, eval_loss: 5.58078e-02
I0214 12:26:21.117483 22509476222784 run_lib.py:133] step: 1061250, training_loss: 3.41856e-02
I0214 12:26:40.027718 22509476222784 run_lib.py:133] step: 1061300, training_loss: 4.17460e-02
I0214 12:26:40.194582 22509476222784 run_lib.py:146] step: 1061300, eval_loss: 5.07487e-02
I0214 12:26:59.132750 22509476222784 run_lib.py:133] step: 1061350, training_loss: 5.08318e-02
I0214 12:27:18.002627 22509476222784 run_lib.py:133] step: 1061400, training_loss: 3.74810e-02
I0214 12:27:18.175911 22509476222784 run_lib.py:146] step: 1061400, eval_loss: 4.77989e-02
I0214 12:27:37.178689 22509476222784 run_lib.py:133] step: 1061450, training_loss: 4.55970e-02
I0214 12:27:56.084451 22509476222784 run_lib.py:133] step: 1061500, training_loss: 4.24692e-02
I0214 12:27:56.258466 22509476222784 run_lib.py:146] step: 1061500, eval_loss: 5.56484e-02
I0214 12:28:15.350685 22509476222784 run_lib.py:133] step: 1061550, training_loss: 4.77991e-02
I0214 12:28:34.127336 22509476222784 run_lib.py:133] step: 1061600, training_loss: 3.95860e-02
I0214 12:28:34.294055 22509476222784 run_lib.py:146] step: 1061600, eval_loss: 4.99298e-02
I0214 12:28:53.215678 22509476222784 run_lib.py:133] step: 1061650, training_loss: 5.03172e-02
I0214 12:29:12.239313 22509476222784 run_lib.py:133] step: 1061700, training_loss: 4.29709e-02
I0214 12:29:12.408086 22509476222784 run_lib.py:146] step: 1061700, eval_loss: 4.85774e-02
I0214 12:29:31.154911 22509476222784 run_lib.py:133] step: 1061750, training_loss: 3.70059e-02
I0214 12:29:50.074078 22509476222784 run_lib.py:133] step: 1061800, training_loss: 4.03753e-02
I0214 12:29:50.238191 22509476222784 run_lib.py:146] step: 1061800, eval_loss: 4.50888e-02
I0214 12:30:09.204437 22509476222784 run_lib.py:133] step: 1061850, training_loss: 4.41771e-02
I0214 12:30:28.016090 22509476222784 run_lib.py:133] step: 1061900, training_loss: 4.47831e-02
I0214 12:30:28.181939 22509476222784 run_lib.py:146] step: 1061900, eval_loss: 4.40968e-02
I0214 12:30:47.219589 22509476222784 run_lib.py:133] step: 1061950, training_loss: 3.67602e-02
I0214 12:31:06.024180 22509476222784 run_lib.py:133] step: 1062000, training_loss: 3.82517e-02
I0214 12:31:06.192164 22509476222784 run_lib.py:146] step: 1062000, eval_loss: 4.84180e-02
I0214 12:31:25.181065 22509476222784 run_lib.py:133] step: 1062050, training_loss: 3.36246e-02
I0214 12:31:44.286149 22509476222784 run_lib.py:133] step: 1062100, training_loss: 3.81221e-02
I0214 12:31:44.453088 22509476222784 run_lib.py:146] step: 1062100, eval_loss: 4.40195e-02
I0214 12:32:03.203853 22509476222784 run_lib.py:133] step: 1062150, training_loss: 4.77739e-02
I0214 12:32:22.049400 22509476222784 run_lib.py:133] step: 1062200, training_loss: 4.22716e-02
I0214 12:32:22.217698 22509476222784 run_lib.py:146] step: 1062200, eval_loss: 4.96734e-02
I0214 12:32:40.979614 22509476222784 run_lib.py:133] step: 1062250, training_loss: 3.35119e-02
I0214 12:33:00.132957 22509476222784 run_lib.py:133] step: 1062300, training_loss: 3.79249e-02
I0214 12:33:00.299775 22509476222784 run_lib.py:146] step: 1062300, eval_loss: 3.95344e-02
I0214 12:33:19.084565 22509476222784 run_lib.py:133] step: 1062350, training_loss: 4.51865e-02
I0214 12:33:38.064030 22509476222784 run_lib.py:133] step: 1062400, training_loss: 4.74566e-02
I0214 12:33:38.231432 22509476222784 run_lib.py:146] step: 1062400, eval_loss: 4.05949e-02
I0214 12:33:57.004935 22509476222784 run_lib.py:133] step: 1062450, training_loss: 4.38621e-02
I0214 12:34:15.768293 22509476222784 run_lib.py:133] step: 1062500, training_loss: 3.31855e-02
I0214 12:34:15.950258 22509476222784 run_lib.py:146] step: 1062500, eval_loss: 4.63216e-02
I0214 12:34:35.152643 22509476222784 run_lib.py:133] step: 1062550, training_loss: 4.90339e-02
I0214 12:34:54.070689 22509476222784 run_lib.py:133] step: 1062600, training_loss: 5.35722e-02
I0214 12:34:54.239179 22509476222784 run_lib.py:146] step: 1062600, eval_loss: 4.16633e-02
I0214 12:35:13.167143 22509476222784 run_lib.py:133] step: 1062650, training_loss: 4.13683e-02
I0214 12:35:31.973922 22509476222784 run_lib.py:133] step: 1062700, training_loss: 4.91327e-02
I0214 12:35:32.140007 22509476222784 run_lib.py:146] step: 1062700, eval_loss: 4.00186e-02
I0214 12:35:51.101390 22509476222784 run_lib.py:133] step: 1062750, training_loss: 4.14684e-02
I0214 12:36:10.044994 22509476222784 run_lib.py:133] step: 1062800, training_loss: 4.09726e-02
I0214 12:36:10.219145 22509476222784 run_lib.py:146] step: 1062800, eval_loss: 4.64632e-02
I0214 12:36:29.207766 22509476222784 run_lib.py:133] step: 1062850, training_loss: 3.78982e-02
I0214 12:36:48.098596 22509476222784 run_lib.py:133] step: 1062900, training_loss: 3.68734e-02
I0214 12:36:48.263938 22509476222784 run_lib.py:146] step: 1062900, eval_loss: 5.45980e-02
I0214 12:37:07.191842 22509476222784 run_lib.py:133] step: 1062950, training_loss: 4.70626e-02
I0214 12:37:25.989326 22509476222784 run_lib.py:133] step: 1063000, training_loss: 3.94745e-02
I0214 12:37:26.156843 22509476222784 run_lib.py:146] step: 1063000, eval_loss: 4.69508e-02
I0214 12:37:45.053059 22509476222784 run_lib.py:133] step: 1063050, training_loss: 4.59790e-02
I0214 12:38:04.009563 22509476222784 run_lib.py:133] step: 1063100, training_loss: 3.69086e-02
I0214 12:38:04.190059 22509476222784 run_lib.py:146] step: 1063100, eval_loss: 5.28757e-02
I0214 12:38:23.042591 22509476222784 run_lib.py:133] step: 1063150, training_loss: 5.16006e-02
I0214 12:38:42.018247 22509476222784 run_lib.py:133] step: 1063200, training_loss: 3.83652e-02
I0214 12:38:42.185391 22509476222784 run_lib.py:146] step: 1063200, eval_loss: 4.40918e-02
I0214 12:39:00.914794 22509476222784 run_lib.py:133] step: 1063250, training_loss: 4.02997e-02
I0214 12:39:19.735043 22509476222784 run_lib.py:133] step: 1063300, training_loss: 4.91465e-02
I0214 12:39:19.901529 22509476222784 run_lib.py:146] step: 1063300, eval_loss: 4.15009e-02
I0214 12:39:38.832955 22509476222784 run_lib.py:133] step: 1063350, training_loss: 4.29369e-02
I0214 12:39:57.634179 22509476222784 run_lib.py:133] step: 1063400, training_loss: 3.69962e-02
I0214 12:39:57.811024 22509476222784 run_lib.py:146] step: 1063400, eval_loss: 5.35470e-02
I0214 12:40:16.696140 22509476222784 run_lib.py:133] step: 1063450, training_loss: 3.27957e-02
I0214 12:40:35.621930 22509476222784 run_lib.py:133] step: 1063500, training_loss: 5.40575e-02
I0214 12:40:35.788206 22509476222784 run_lib.py:146] step: 1063500, eval_loss: 4.06299e-02
I0214 12:40:54.622612 22509476222784 run_lib.py:133] step: 1063550, training_loss: 3.26241e-02
I0214 12:41:13.412868 22509476222784 run_lib.py:133] step: 1063600, training_loss: 4.34882e-02
I0214 12:41:13.753030 22509476222784 run_lib.py:146] step: 1063600, eval_loss: 3.76667e-02
I0214 12:41:32.610552 22509476222784 run_lib.py:133] step: 1063650, training_loss: 4.62444e-02
I0214 12:41:51.465532 22509476222784 run_lib.py:133] step: 1063700, training_loss: 4.69631e-02
I0214 12:41:51.630374 22509476222784 run_lib.py:146] step: 1063700, eval_loss: 4.11477e-02
I0214 12:42:10.427926 22509476222784 run_lib.py:133] step: 1063750, training_loss: 3.61381e-02
I0214 12:42:29.224619 22509476222784 run_lib.py:133] step: 1063800, training_loss: 4.47565e-02
I0214 12:42:29.392900 22509476222784 run_lib.py:146] step: 1063800, eval_loss: 4.48252e-02
I0214 12:42:48.387138 22509476222784 run_lib.py:133] step: 1063850, training_loss: 3.34835e-02
I0214 12:43:07.273661 22509476222784 run_lib.py:133] step: 1063900, training_loss: 5.15557e-02
I0214 12:43:07.440736 22509476222784 run_lib.py:146] step: 1063900, eval_loss: 4.14321e-02
I0214 12:43:26.296822 22509476222784 run_lib.py:133] step: 1063950, training_loss: 4.53872e-02
I0214 12:43:45.072524 22509476222784 run_lib.py:133] step: 1064000, training_loss: 3.94375e-02
I0214 12:43:45.242143 22509476222784 run_lib.py:146] step: 1064000, eval_loss: 4.81264e-02
I0214 12:44:04.123540 22509476222784 run_lib.py:133] step: 1064050, training_loss: 5.13865e-02
I0214 12:44:23.044763 22509476222784 run_lib.py:133] step: 1064100, training_loss: 4.78950e-02
I0214 12:44:23.264485 22509476222784 run_lib.py:146] step: 1064100, eval_loss: 3.59943e-02
I0214 12:44:42.043204 22509476222784 run_lib.py:133] step: 1064150, training_loss: 3.87309e-02
I0214 12:45:00.929817 22509476222784 run_lib.py:133] step: 1064200, training_loss: 3.36907e-02
I0214 12:45:01.095281 22509476222784 run_lib.py:146] step: 1064200, eval_loss: 3.64771e-02
I0214 12:45:20.055396 22509476222784 run_lib.py:133] step: 1064250, training_loss: 3.51806e-02
I0214 12:45:38.793378 22509476222784 run_lib.py:133] step: 1064300, training_loss: 4.82872e-02
I0214 12:45:38.968892 22509476222784 run_lib.py:146] step: 1064300, eval_loss: 4.04088e-02
I0214 12:45:58.004712 22509476222784 run_lib.py:133] step: 1064350, training_loss: 4.35246e-02
I0214 12:46:16.790711 22509476222784 run_lib.py:133] step: 1064400, training_loss: 4.44906e-02
I0214 12:46:16.957098 22509476222784 run_lib.py:146] step: 1064400, eval_loss: 3.74818e-02
I0214 12:46:36.097874 22509476222784 run_lib.py:133] step: 1064450, training_loss: 4.31355e-02
I0214 12:46:54.886261 22509476222784 run_lib.py:133] step: 1064500, training_loss: 2.97575e-02
I0214 12:46:55.056385 22509476222784 run_lib.py:146] step: 1064500, eval_loss: 5.98598e-02
I0214 12:47:13.833607 22509476222784 run_lib.py:133] step: 1064550, training_loss: 3.96308e-02
I0214 12:47:32.793462 22509476222784 run_lib.py:133] step: 1064600, training_loss: 3.49706e-02
I0214 12:47:32.982914 22509476222784 run_lib.py:146] step: 1064600, eval_loss: 4.40117e-02
I0214 12:47:51.771701 22509476222784 run_lib.py:133] step: 1064650, training_loss: 4.21661e-02
I0214 12:48:10.843317 22509476222784 run_lib.py:133] step: 1064700, training_loss: 5.05809e-02
I0214 12:48:11.008403 22509476222784 run_lib.py:146] step: 1064700, eval_loss: 4.70676e-02
I0214 12:48:29.792896 22509476222784 run_lib.py:133] step: 1064750, training_loss: 3.43705e-02
I0214 12:48:48.648398 22509476222784 run_lib.py:133] step: 1064800, training_loss: 4.24781e-02
I0214 12:48:48.816372 22509476222784 run_lib.py:146] step: 1064800, eval_loss: 4.67391e-02
I0214 12:49:07.790813 22509476222784 run_lib.py:133] step: 1064850, training_loss: 3.50053e-02
I0214 12:49:26.567103 22509476222784 run_lib.py:133] step: 1064900, training_loss: 4.18939e-02
I0214 12:49:26.742199 22509476222784 run_lib.py:146] step: 1064900, eval_loss: 3.86965e-02
I0214 12:49:45.673754 22509476222784 run_lib.py:133] step: 1064950, training_loss: 4.59499e-02
I0214 12:50:04.494031 22509476222784 run_lib.py:133] step: 1065000, training_loss: 4.05552e-02
I0214 12:50:04.661980 22509476222784 run_lib.py:146] step: 1065000, eval_loss: 4.42411e-02
I0214 12:50:23.722787 22509476222784 run_lib.py:133] step: 1065050, training_loss: 3.61373e-02
I0214 12:50:42.517019 22509476222784 run_lib.py:133] step: 1065100, training_loss: 3.52366e-02
I0214 12:50:42.684037 22509476222784 run_lib.py:146] step: 1065100, eval_loss: 3.50423e-02
I0214 12:51:01.549384 22509476222784 run_lib.py:133] step: 1065150, training_loss: 3.39747e-02
I0214 12:51:20.430724 22509476222784 run_lib.py:133] step: 1065200, training_loss: 4.33833e-02
I0214 12:51:20.598181 22509476222784 run_lib.py:146] step: 1065200, eval_loss: 2.47475e-02
I0214 12:51:39.340012 22509476222784 run_lib.py:133] step: 1065250, training_loss: 4.08380e-02
I0214 12:51:58.169193 22509476222784 run_lib.py:133] step: 1065300, training_loss: 4.42382e-02
I0214 12:51:58.340904 22509476222784 run_lib.py:146] step: 1065300, eval_loss: 4.64566e-02
I0214 12:52:17.285800 22509476222784 run_lib.py:133] step: 1065350, training_loss: 4.01845e-02
I0214 12:52:36.099920 22509476222784 run_lib.py:133] step: 1065400, training_loss: 3.93974e-02
I0214 12:52:36.277953 22509476222784 run_lib.py:146] step: 1065400, eval_loss: 4.42744e-02
I0214 12:52:55.137113 22509476222784 run_lib.py:133] step: 1065450, training_loss: 4.85458e-02
I0214 12:53:13.925551 22509476222784 run_lib.py:133] step: 1065500, training_loss: 3.86640e-02
I0214 12:53:14.095444 22509476222784 run_lib.py:146] step: 1065500, eval_loss: 3.83689e-02
I0214 12:53:33.113395 22509476222784 run_lib.py:133] step: 1065550, training_loss: 4.11385e-02
I0214 12:53:51.892621 22509476222784 run_lib.py:133] step: 1065600, training_loss: 3.98619e-02
I0214 12:53:52.058399 22509476222784 run_lib.py:146] step: 1065600, eval_loss: 4.94536e-02
I0214 12:54:11.085798 22509476222784 run_lib.py:133] step: 1065650, training_loss: 2.89040e-02
I0214 12:54:30.053173 22509476222784 run_lib.py:133] step: 1065700, training_loss: 4.09714e-02
I0214 12:54:30.227533 22509476222784 run_lib.py:146] step: 1065700, eval_loss: 4.09295e-02
I0214 12:54:49.135045 22509476222784 run_lib.py:133] step: 1065750, training_loss: 3.97008e-02
I0214 12:55:08.042061 22509476222784 run_lib.py:133] step: 1065800, training_loss: 4.42010e-02
I0214 12:55:08.206252 22509476222784 run_lib.py:146] step: 1065800, eval_loss: 4.66311e-02
I0214 12:55:27.151252 22509476222784 run_lib.py:133] step: 1065850, training_loss: 5.83276e-02
I0214 12:55:46.107535 22509476222784 run_lib.py:133] step: 1065900, training_loss: 4.15390e-02
I0214 12:55:46.279351 22509476222784 run_lib.py:146] step: 1065900, eval_loss: 5.72528e-02
I0214 12:56:05.032813 22509476222784 run_lib.py:133] step: 1065950, training_loss: 4.23190e-02
I0214 12:56:23.912289 22509476222784 run_lib.py:133] step: 1066000, training_loss: 3.91380e-02
I0214 12:56:24.085879 22509476222784 run_lib.py:146] step: 1066000, eval_loss: 4.28476e-02
I0214 12:56:42.907176 22509476222784 run_lib.py:133] step: 1066050, training_loss: 4.13726e-02
I0214 12:57:01.671688 22509476222784 run_lib.py:133] step: 1066100, training_loss: 4.36941e-02
I0214 12:57:01.841119 22509476222784 run_lib.py:146] step: 1066100, eval_loss: 4.13411e-02
I0214 12:57:20.977876 22509476222784 run_lib.py:133] step: 1066150, training_loss: 3.74398e-02
I0214 12:57:39.850632 22509476222784 run_lib.py:133] step: 1066200, training_loss: 3.17101e-02
I0214 12:57:40.015759 22509476222784 run_lib.py:146] step: 1066200, eval_loss: 4.31812e-02
I0214 12:57:58.819281 22509476222784 run_lib.py:133] step: 1066250, training_loss: 4.20004e-02
I0214 12:58:17.664645 22509476222784 run_lib.py:133] step: 1066300, training_loss: 4.29138e-02
I0214 12:58:17.844477 22509476222784 run_lib.py:146] step: 1066300, eval_loss: 4.51475e-02
I0214 12:58:36.639145 22509476222784 run_lib.py:133] step: 1066350, training_loss: 4.00922e-02
I0214 12:58:55.695962 22509476222784 run_lib.py:133] step: 1066400, training_loss: 5.86319e-02
I0214 12:58:55.866165 22509476222784 run_lib.py:146] step: 1066400, eval_loss: 3.39758e-02
I0214 12:59:14.539984 22509476222784 run_lib.py:133] step: 1066450, training_loss: 4.74812e-02
I0214 12:59:33.367343 22509476222784 run_lib.py:133] step: 1066500, training_loss: 4.74558e-02
I0214 12:59:33.541907 22509476222784 run_lib.py:146] step: 1066500, eval_loss: 3.51973e-02
I0214 12:59:52.321757 22509476222784 run_lib.py:133] step: 1066550, training_loss: 3.25217e-02
I0214 13:00:11.253529 22509476222784 run_lib.py:133] step: 1066600, training_loss: 4.71831e-02
I0214 13:00:11.420301 22509476222784 run_lib.py:146] step: 1066600, eval_loss: 3.89122e-02
I0214 13:00:30.312750 22509476222784 run_lib.py:133] step: 1066650, training_loss: 3.49646e-02
I0214 13:00:49.107327 22509476222784 run_lib.py:133] step: 1066700, training_loss: 4.39182e-02
I0214 13:00:49.270081 22509476222784 run_lib.py:146] step: 1066700, eval_loss: 4.64043e-02
I0214 13:01:08.122143 22509476222784 run_lib.py:133] step: 1066750, training_loss: 2.98441e-02
I0214 13:01:26.892040 22509476222784 run_lib.py:133] step: 1066800, training_loss: 3.94903e-02
I0214 13:01:27.074419 22509476222784 run_lib.py:146] step: 1066800, eval_loss: 5.37292e-02
I0214 13:01:46.120974 22509476222784 run_lib.py:133] step: 1066850, training_loss: 4.47700e-02
I0214 13:02:05.023428 22509476222784 run_lib.py:133] step: 1066900, training_loss: 3.81467e-02
I0214 13:02:05.191145 22509476222784 run_lib.py:146] step: 1066900, eval_loss: 5.02745e-02
I0214 13:02:23.921601 22509476222784 run_lib.py:133] step: 1066950, training_loss: 3.74695e-02
I0214 13:02:42.793551 22509476222784 run_lib.py:133] step: 1067000, training_loss: 4.77553e-02
I0214 13:02:42.969407 22509476222784 run_lib.py:146] step: 1067000, eval_loss: 3.49058e-02
I0214 13:03:01.889559 22509476222784 run_lib.py:133] step: 1067050, training_loss: 3.27328e-02
I0214 13:03:20.827964 22509476222784 run_lib.py:133] step: 1067100, training_loss: 3.92155e-02
I0214 13:03:20.996215 22509476222784 run_lib.py:146] step: 1067100, eval_loss: 4.39151e-02
I0214 13:03:39.982585 22509476222784 run_lib.py:133] step: 1067150, training_loss: 5.02848e-02
I0214 13:03:58.779821 22509476222784 run_lib.py:133] step: 1067200, training_loss: 3.80601e-02
I0214 13:03:58.951969 22509476222784 run_lib.py:146] step: 1067200, eval_loss: 4.51285e-02
I0214 13:04:17.919133 22509476222784 run_lib.py:133] step: 1067250, training_loss: 4.14519e-02
I0214 13:04:36.728123 22509476222784 run_lib.py:133] step: 1067300, training_loss: 3.77024e-02
I0214 13:04:36.907093 22509476222784 run_lib.py:146] step: 1067300, eval_loss: 3.31309e-02
I0214 13:04:55.825230 22509476222784 run_lib.py:133] step: 1067350, training_loss: 5.31535e-02
I0214 13:05:14.811015 22509476222784 run_lib.py:133] step: 1067400, training_loss: 3.74437e-02
I0214 13:05:14.979267 22509476222784 run_lib.py:146] step: 1067400, eval_loss: 4.05524e-02
I0214 13:05:33.820191 22509476222784 run_lib.py:133] step: 1067450, training_loss: 3.26367e-02
I0214 13:05:52.759522 22509476222784 run_lib.py:133] step: 1067500, training_loss: 3.95303e-02
I0214 13:05:52.956616 22509476222784 run_lib.py:146] step: 1067500, eval_loss: 5.02030e-02
I0214 13:06:11.881589 22509476222784 run_lib.py:133] step: 1067550, training_loss: 5.18638e-02
I0214 13:06:30.748270 22509476222784 run_lib.py:133] step: 1067600, training_loss: 4.32524e-02
I0214 13:06:30.922261 22509476222784 run_lib.py:146] step: 1067600, eval_loss: 3.79247e-02
I0214 13:06:49.916564 22509476222784 run_lib.py:133] step: 1067650, training_loss: 4.48592e-02
I0214 13:07:08.720231 22509476222784 run_lib.py:133] step: 1067700, training_loss: 4.78571e-02
I0214 13:07:08.882963 22509476222784 run_lib.py:146] step: 1067700, eval_loss: 4.71507e-02
I0214 13:07:27.598676 22509476222784 run_lib.py:133] step: 1067750, training_loss: 4.29494e-02
I0214 13:07:46.671669 22509476222784 run_lib.py:133] step: 1067800, training_loss: 4.59645e-02
I0214 13:07:46.855076 22509476222784 run_lib.py:146] step: 1067800, eval_loss: 4.23349e-02
I0214 13:08:05.667165 22509476222784 run_lib.py:133] step: 1067850, training_loss: 4.72455e-02
I0214 13:08:24.459555 22509476222784 run_lib.py:133] step: 1067900, training_loss: 3.70736e-02
I0214 13:08:24.627333 22509476222784 run_lib.py:146] step: 1067900, eval_loss: 3.06086e-02
I0214 13:08:43.515544 22509476222784 run_lib.py:133] step: 1067950, training_loss: 3.58882e-02
I0214 13:09:02.216040 22509476222784 run_lib.py:133] step: 1068000, training_loss: 4.31079e-02
I0214 13:09:02.385628 22509476222784 run_lib.py:146] step: 1068000, eval_loss: 4.28360e-02
I0214 13:09:21.216596 22509476222784 run_lib.py:133] step: 1068050, training_loss: 3.81267e-02
I0214 13:09:40.017353 22509476222784 run_lib.py:133] step: 1068100, training_loss: 4.30662e-02
I0214 13:09:40.184757 22509476222784 run_lib.py:146] step: 1068100, eval_loss: 3.06956e-02
I0214 13:09:59.230669 22509476222784 run_lib.py:133] step: 1068150, training_loss: 4.13472e-02
I0214 13:10:18.068958 22509476222784 run_lib.py:133] step: 1068200, training_loss: 4.73363e-02
I0214 13:10:18.241888 22509476222784 run_lib.py:146] step: 1068200, eval_loss: 3.53643e-02
I0214 13:10:37.020399 22509476222784 run_lib.py:133] step: 1068250, training_loss: 4.22209e-02
I0214 13:10:55.815952 22509476222784 run_lib.py:133] step: 1068300, training_loss: 4.31698e-02
I0214 13:10:55.999877 22509476222784 run_lib.py:146] step: 1068300, eval_loss: 3.80405e-02
I0214 13:11:15.025046 22509476222784 run_lib.py:133] step: 1068350, training_loss: 5.37532e-02
I0214 13:11:33.856051 22509476222784 run_lib.py:133] step: 1068400, training_loss: 6.26141e-02
I0214 13:11:34.024037 22509476222784 run_lib.py:146] step: 1068400, eval_loss: 3.43545e-02
I0214 13:11:52.901448 22509476222784 run_lib.py:133] step: 1068450, training_loss: 3.82589e-02
I0214 13:12:11.735164 22509476222784 run_lib.py:133] step: 1068500, training_loss: 4.65817e-02
I0214 13:12:11.912937 22509476222784 run_lib.py:146] step: 1068500, eval_loss: 4.11776e-02
I0214 13:12:30.895960 22509476222784 run_lib.py:133] step: 1068550, training_loss: 4.11692e-02
I0214 13:12:49.822123 22509476222784 run_lib.py:133] step: 1068600, training_loss: 3.77536e-02
I0214 13:12:49.992658 22509476222784 run_lib.py:146] step: 1068600, eval_loss: 5.31178e-02
I0214 13:13:08.965378 22509476222784 run_lib.py:133] step: 1068650, training_loss: 4.72075e-02
I0214 13:13:27.714724 22509476222784 run_lib.py:133] step: 1068700, training_loss: 4.04870e-02
I0214 13:13:27.880003 22509476222784 run_lib.py:146] step: 1068700, eval_loss: 4.07255e-02
I0214 13:13:46.707936 22509476222784 run_lib.py:133] step: 1068750, training_loss: 3.23277e-02
I0214 13:14:05.674489 22509476222784 run_lib.py:133] step: 1068800, training_loss: 4.42711e-02
I0214 13:14:05.863106 22509476222784 run_lib.py:146] step: 1068800, eval_loss: 5.33408e-02
I0214 13:14:24.764053 22509476222784 run_lib.py:133] step: 1068850, training_loss: 3.75808e-02
I0214 13:14:43.580907 22509476222784 run_lib.py:133] step: 1068900, training_loss: 4.45919e-02
I0214 13:14:43.748456 22509476222784 run_lib.py:146] step: 1068900, eval_loss: 3.73494e-02
I0214 13:15:02.770614 22509476222784 run_lib.py:133] step: 1068950, training_loss: 4.21742e-02
I0214 13:15:21.550264 22509476222784 run_lib.py:133] step: 1069000, training_loss: 3.20324e-02
I0214 13:15:21.724167 22509476222784 run_lib.py:146] step: 1069000, eval_loss: 4.47330e-02
I0214 13:15:40.648679 22509476222784 run_lib.py:133] step: 1069050, training_loss: 3.65708e-02
I0214 13:15:59.501656 22509476222784 run_lib.py:133] step: 1069100, training_loss: 4.23368e-02
I0214 13:15:59.674513 22509476222784 run_lib.py:146] step: 1069100, eval_loss: 4.28047e-02
I0214 13:16:18.440379 22509476222784 run_lib.py:133] step: 1069150, training_loss: 4.64942e-02
I0214 13:16:37.548826 22509476222784 run_lib.py:133] step: 1069200, training_loss: 3.95933e-02
I0214 13:16:37.715934 22509476222784 run_lib.py:146] step: 1069200, eval_loss: 5.18013e-02
I0214 13:16:56.447630 22509476222784 run_lib.py:133] step: 1069250, training_loss: 5.82674e-02
I0214 13:17:15.178052 22509476222784 run_lib.py:133] step: 1069300, training_loss: 3.65478e-02
I0214 13:17:15.360937 22509476222784 run_lib.py:146] step: 1069300, eval_loss: 3.39732e-02
I0214 13:17:34.215735 22509476222784 run_lib.py:133] step: 1069350, training_loss: 4.38830e-02
I0214 13:17:53.206307 22509476222784 run_lib.py:133] step: 1069400, training_loss: 4.14009e-02
I0214 13:17:53.373192 22509476222784 run_lib.py:146] step: 1069400, eval_loss: 4.56827e-02
I0214 13:18:12.228109 22509476222784 run_lib.py:133] step: 1069450, training_loss: 5.20592e-02
I0214 13:18:31.059092 22509476222784 run_lib.py:133] step: 1069500, training_loss: 4.93445e-02
I0214 13:18:31.222979 22509476222784 run_lib.py:146] step: 1069500, eval_loss: 4.94829e-02
I0214 13:18:50.064571 22509476222784 run_lib.py:133] step: 1069550, training_loss: 5.14471e-02
I0214 13:19:08.920185 22509476222784 run_lib.py:133] step: 1069600, training_loss: 4.30203e-02
I0214 13:19:09.088098 22509476222784 run_lib.py:146] step: 1069600, eval_loss: 4.48586e-02
I0214 13:19:28.072039 22509476222784 run_lib.py:133] step: 1069650, training_loss: 5.07491e-02
I0214 13:19:47.059170 22509476222784 run_lib.py:133] step: 1069700, training_loss: 4.99814e-02
I0214 13:19:47.230263 22509476222784 run_lib.py:146] step: 1069700, eval_loss: 3.02411e-02
I0214 13:20:05.895718 22509476222784 run_lib.py:133] step: 1069750, training_loss: 4.68870e-02
I0214 13:20:24.770025 22509476222784 run_lib.py:133] step: 1069800, training_loss: 4.98115e-02
I0214 13:20:24.937179 22509476222784 run_lib.py:146] step: 1069800, eval_loss: 3.73661e-02
I0214 13:20:43.864559 22509476222784 run_lib.py:133] step: 1069850, training_loss: 3.86047e-02
I0214 13:21:02.730847 22509476222784 run_lib.py:133] step: 1069900, training_loss: 3.80175e-02
I0214 13:21:02.902731 22509476222784 run_lib.py:146] step: 1069900, eval_loss: 4.14420e-02
I0214 13:21:21.906539 22509476222784 run_lib.py:133] step: 1069950, training_loss: 4.69024e-02
I0214 13:21:40.649842 22509476222784 run_lib.py:133] step: 1070000, training_loss: 4.25071e-02
I0214 13:21:41.661652 22509476222784 run_lib.py:146] step: 1070000, eval_loss: 3.93618e-02
I0214 13:22:03.703469 22509476222784 run_lib.py:133] step: 1070050, training_loss: 3.61484e-02
I0214 13:22:22.470756 22509476222784 run_lib.py:133] step: 1070100, training_loss: 4.45462e-02
I0214 13:22:22.639233 22509476222784 run_lib.py:146] step: 1070100, eval_loss: 4.56194e-02
I0214 13:22:41.722340 22509476222784 run_lib.py:133] step: 1070150, training_loss: 4.09398e-02
I0214 13:23:00.497659 22509476222784 run_lib.py:133] step: 1070200, training_loss: 3.58230e-02
I0214 13:23:00.663882 22509476222784 run_lib.py:146] step: 1070200, eval_loss: 4.69494e-02
I0214 13:23:19.412766 22509476222784 run_lib.py:133] step: 1070250, training_loss: 5.26318e-02
I0214 13:23:38.175979 22509476222784 run_lib.py:133] step: 1070300, training_loss: 3.35999e-02
I0214 13:23:38.346925 22509476222784 run_lib.py:146] step: 1070300, eval_loss: 5.45119e-02
I0214 13:23:57.284372 22509476222784 run_lib.py:133] step: 1070350, training_loss: 2.93345e-02
I0214 13:24:16.219537 22509476222784 run_lib.py:133] step: 1070400, training_loss: 3.77987e-02
I0214 13:24:16.411051 22509476222784 run_lib.py:146] step: 1070400, eval_loss: 3.82040e-02
I0214 13:24:35.197202 22509476222784 run_lib.py:133] step: 1070450, training_loss: 3.55277e-02
I0214 13:24:54.128764 22509476222784 run_lib.py:133] step: 1070500, training_loss: 4.20172e-02
I0214 13:24:54.295220 22509476222784 run_lib.py:146] step: 1070500, eval_loss: 3.82507e-02
I0214 13:25:13.262175 22509476222784 run_lib.py:133] step: 1070550, training_loss: 3.84713e-02
I0214 13:25:32.167156 22509476222784 run_lib.py:133] step: 1070600, training_loss: 4.74941e-02
I0214 13:25:32.332330 22509476222784 run_lib.py:146] step: 1070600, eval_loss: 4.91893e-02
I0214 13:25:51.268053 22509476222784 run_lib.py:133] step: 1070650, training_loss: 3.04054e-02
I0214 13:26:10.175025 22509476222784 run_lib.py:133] step: 1070700, training_loss: 4.59698e-02
I0214 13:26:10.351232 22509476222784 run_lib.py:146] step: 1070700, eval_loss: 4.82374e-02
I0214 13:26:29.379868 22509476222784 run_lib.py:133] step: 1070750, training_loss: 4.80812e-02
I0214 13:26:48.179649 22509476222784 run_lib.py:133] step: 1070800, training_loss: 3.82516e-02
I0214 13:26:48.345492 22509476222784 run_lib.py:146] step: 1070800, eval_loss: 4.32785e-02
I0214 13:27:07.216681 22509476222784 run_lib.py:133] step: 1070850, training_loss: 4.62310e-02
I0214 13:27:26.094714 22509476222784 run_lib.py:133] step: 1070900, training_loss: 3.34397e-02
I0214 13:27:26.262966 22509476222784 run_lib.py:146] step: 1070900, eval_loss: 4.76638e-02
I0214 13:27:45.103956 22509476222784 run_lib.py:133] step: 1070950, training_loss: 4.04396e-02
I0214 13:28:04.107194 22509476222784 run_lib.py:133] step: 1071000, training_loss: 4.35399e-02
I0214 13:28:04.271739 22509476222784 run_lib.py:146] step: 1071000, eval_loss: 4.97325e-02
I0214 13:28:23.109204 22509476222784 run_lib.py:133] step: 1071050, training_loss: 5.23102e-02
I0214 13:28:41.887671 22509476222784 run_lib.py:133] step: 1071100, training_loss: 4.44214e-02
I0214 13:28:42.050935 22509476222784 run_lib.py:146] step: 1071100, eval_loss: 4.95471e-02
I0214 13:29:01.035454 22509476222784 run_lib.py:133] step: 1071150, training_loss: 4.59754e-02
I0214 13:29:19.902654 22509476222784 run_lib.py:133] step: 1071200, training_loss: 4.22966e-02
I0214 13:29:20.084999 22509476222784 run_lib.py:146] step: 1071200, eval_loss: 3.35715e-02
I0214 13:29:38.872514 22509476222784 run_lib.py:133] step: 1071250, training_loss: 4.40143e-02
I0214 13:29:57.979574 22509476222784 run_lib.py:133] step: 1071300, training_loss: 4.85206e-02
I0214 13:29:58.146104 22509476222784 run_lib.py:146] step: 1071300, eval_loss: 3.93202e-02
I0214 13:30:16.879089 22509476222784 run_lib.py:133] step: 1071350, training_loss: 4.42444e-02
I0214 13:30:35.668665 22509476222784 run_lib.py:133] step: 1071400, training_loss: 4.22647e-02
I0214 13:30:36.001280 22509476222784 run_lib.py:146] step: 1071400, eval_loss: 3.77832e-02
I0214 13:30:54.770950 22509476222784 run_lib.py:133] step: 1071450, training_loss: 3.84826e-02
I0214 13:31:13.523499 22509476222784 run_lib.py:133] step: 1071500, training_loss: 4.08169e-02
I0214 13:31:13.688389 22509476222784 run_lib.py:146] step: 1071500, eval_loss: 3.89393e-02
I0214 13:31:32.522698 22509476222784 run_lib.py:133] step: 1071550, training_loss: 4.18876e-02
I0214 13:31:51.235511 22509476222784 run_lib.py:133] step: 1071600, training_loss: 5.22769e-02
I0214 13:31:51.402222 22509476222784 run_lib.py:146] step: 1071600, eval_loss: 5.43809e-02
I0214 13:32:10.442996 22509476222784 run_lib.py:133] step: 1071650, training_loss: 3.77990e-02
I0214 13:32:29.329050 22509476222784 run_lib.py:133] step: 1071700, training_loss: 4.44769e-02
I0214 13:32:29.514017 22509476222784 run_lib.py:146] step: 1071700, eval_loss: 4.24853e-02
I0214 13:32:48.293165 22509476222784 run_lib.py:133] step: 1071750, training_loss: 4.23978e-02
I0214 13:33:07.145174 22509476222784 run_lib.py:133] step: 1071800, training_loss: 4.54782e-02
I0214 13:33:07.314160 22509476222784 run_lib.py:146] step: 1071800, eval_loss: 4.42624e-02
I0214 13:33:26.231021 22509476222784 run_lib.py:133] step: 1071850, training_loss: 4.00048e-02
I0214 13:33:45.146709 22509476222784 run_lib.py:133] step: 1071900, training_loss: 3.55815e-02
I0214 13:33:45.343974 22509476222784 run_lib.py:146] step: 1071900, eval_loss: 3.64575e-02
I0214 13:34:04.121133 22509476222784 run_lib.py:133] step: 1071950, training_loss: 4.19588e-02
I0214 13:34:22.892951 22509476222784 run_lib.py:133] step: 1072000, training_loss: 4.34012e-02
I0214 13:34:23.065611 22509476222784 run_lib.py:146] step: 1072000, eval_loss: 5.06085e-02
I0214 13:34:42.028505 22509476222784 run_lib.py:133] step: 1072050, training_loss: 3.30569e-02
I0214 13:35:00.805803 22509476222784 run_lib.py:133] step: 1072100, training_loss: 4.59801e-02
I0214 13:35:00.973652 22509476222784 run_lib.py:146] step: 1072100, eval_loss: 3.71223e-02
I0214 13:35:19.918579 22509476222784 run_lib.py:133] step: 1072150, training_loss: 4.35998e-02
I0214 13:35:38.668122 22509476222784 run_lib.py:133] step: 1072200, training_loss: 3.46271e-02
I0214 13:35:38.845943 22509476222784 run_lib.py:146] step: 1072200, eval_loss: 5.26187e-02
I0214 13:35:57.965261 22509476222784 run_lib.py:133] step: 1072250, training_loss: 3.55836e-02
I0214 13:36:16.709863 22509476222784 run_lib.py:133] step: 1072300, training_loss: 4.34777e-02
I0214 13:36:16.877453 22509476222784 run_lib.py:146] step: 1072300, eval_loss: 4.17503e-02
I0214 13:36:35.707265 22509476222784 run_lib.py:133] step: 1072350, training_loss: 5.26456e-02
I0214 13:36:54.544463 22509476222784 run_lib.py:133] step: 1072400, training_loss: 5.99450e-02
I0214 13:36:54.711034 22509476222784 run_lib.py:146] step: 1072400, eval_loss: 4.49013e-02
I0214 13:37:13.513251 22509476222784 run_lib.py:133] step: 1072450, training_loss: 3.96132e-02
I0214 13:37:32.526425 22509476222784 run_lib.py:133] step: 1072500, training_loss: 3.41140e-02
I0214 13:37:32.692929 22509476222784 run_lib.py:146] step: 1072500, eval_loss: 4.19987e-02
I0214 13:37:51.461367 22509476222784 run_lib.py:133] step: 1072550, training_loss: 5.77922e-02
I0214 13:38:10.300957 22509476222784 run_lib.py:133] step: 1072600, training_loss: 3.82619e-02
I0214 13:38:10.475265 22509476222784 run_lib.py:146] step: 1072600, eval_loss: 4.19102e-02
I0214 13:38:29.377046 22509476222784 run_lib.py:133] step: 1072650, training_loss: 4.55395e-02
I0214 13:38:48.269050 22509476222784 run_lib.py:133] step: 1072700, training_loss: 5.01706e-02
I0214 13:38:48.449038 22509476222784 run_lib.py:146] step: 1072700, eval_loss: 4.37686e-02
I0214 13:39:07.258013 22509476222784 run_lib.py:133] step: 1072750, training_loss: 3.73306e-02
I0214 13:39:26.183527 22509476222784 run_lib.py:133] step: 1072800, training_loss: 5.53935e-02
I0214 13:39:26.362504 22509476222784 run_lib.py:146] step: 1072800, eval_loss: 4.03897e-02
I0214 13:39:45.370530 22509476222784 run_lib.py:133] step: 1072850, training_loss: 3.73857e-02
I0214 13:40:04.064736 22509476222784 run_lib.py:133] step: 1072900, training_loss: 3.75587e-02
I0214 13:40:04.228753 22509476222784 run_lib.py:146] step: 1072900, eval_loss: 3.30885e-02
I0214 13:40:23.073222 22509476222784 run_lib.py:133] step: 1072950, training_loss: 3.69307e-02
I0214 13:40:41.818236 22509476222784 run_lib.py:133] step: 1073000, training_loss: 3.87745e-02
I0214 13:40:41.983060 22509476222784 run_lib.py:146] step: 1073000, eval_loss: 3.65609e-02
I0214 13:41:00.894604 22509476222784 run_lib.py:133] step: 1073050, training_loss: 3.21369e-02
I0214 13:41:19.613978 22509476222784 run_lib.py:133] step: 1073100, training_loss: 4.49999e-02
I0214 13:41:19.786860 22509476222784 run_lib.py:146] step: 1073100, eval_loss: 3.72913e-02
I0214 13:41:38.746607 22509476222784 run_lib.py:133] step: 1073150, training_loss: 4.10165e-02
I0214 13:41:57.595989 22509476222784 run_lib.py:133] step: 1073200, training_loss: 4.34247e-02
I0214 13:41:57.771602 22509476222784 run_lib.py:146] step: 1073200, eval_loss: 3.72117e-02
I0214 13:42:16.585194 22509476222784 run_lib.py:133] step: 1073250, training_loss: 4.00874e-02
I0214 13:42:35.583548 22509476222784 run_lib.py:133] step: 1073300, training_loss: 4.02082e-02
I0214 13:42:35.753877 22509476222784 run_lib.py:146] step: 1073300, eval_loss: 4.94547e-02
I0214 13:42:54.738864 22509476222784 run_lib.py:133] step: 1073350, training_loss: 3.58847e-02
I0214 13:43:13.649288 22509476222784 run_lib.py:133] step: 1073400, training_loss: 4.66085e-02
I0214 13:43:13.813265 22509476222784 run_lib.py:146] step: 1073400, eval_loss: 4.51734e-02
I0214 13:43:32.752107 22509476222784 run_lib.py:133] step: 1073450, training_loss: 4.82141e-02
I0214 13:43:51.552782 22509476222784 run_lib.py:133] step: 1073500, training_loss: 4.46635e-02
I0214 13:43:51.717947 22509476222784 run_lib.py:146] step: 1073500, eval_loss: 4.22023e-02
I0214 13:44:10.729336 22509476222784 run_lib.py:133] step: 1073550, training_loss: 3.40404e-02
I0214 13:44:29.593533 22509476222784 run_lib.py:133] step: 1073600, training_loss: 4.12925e-02
I0214 13:44:29.766390 22509476222784 run_lib.py:146] step: 1073600, eval_loss: 4.18854e-02
I0214 13:44:48.857968 22509476222784 run_lib.py:133] step: 1073650, training_loss: 4.66273e-02
I0214 13:45:07.587049 22509476222784 run_lib.py:133] step: 1073700, training_loss: 4.33036e-02
I0214 13:45:07.754956 22509476222784 run_lib.py:146] step: 1073700, eval_loss: 4.26487e-02
I0214 13:45:26.540723 22509476222784 run_lib.py:133] step: 1073750, training_loss: 4.71720e-02
I0214 13:45:45.531821 22509476222784 run_lib.py:133] step: 1073800, training_loss: 4.55208e-02
I0214 13:45:45.696862 22509476222784 run_lib.py:146] step: 1073800, eval_loss: 4.76568e-02
I0214 13:46:04.560305 22509476222784 run_lib.py:133] step: 1073850, training_loss: 4.18449e-02
I0214 13:46:23.389035 22509476222784 run_lib.py:133] step: 1073900, training_loss: 4.46952e-02
I0214 13:46:23.557359 22509476222784 run_lib.py:146] step: 1073900, eval_loss: 4.10032e-02
I0214 13:46:42.463728 22509476222784 run_lib.py:133] step: 1073950, training_loss: 4.22776e-02
I0214 13:47:01.510760 22509476222784 run_lib.py:133] step: 1074000, training_loss: 2.42465e-02
I0214 13:47:01.673930 22509476222784 run_lib.py:146] step: 1074000, eval_loss: 4.22554e-02
I0214 13:47:20.323796 22509476222784 run_lib.py:133] step: 1074050, training_loss: 4.90519e-02
I0214 13:47:39.189773 22509476222784 run_lib.py:133] step: 1074100, training_loss: 3.01221e-02
I0214 13:47:39.370010 22509476222784 run_lib.py:146] step: 1074100, eval_loss: 3.57941e-02
I0214 13:47:58.214946 22509476222784 run_lib.py:133] step: 1074150, training_loss: 4.65071e-02
I0214 13:48:17.220137 22509476222784 run_lib.py:133] step: 1074200, training_loss: 4.13110e-02
I0214 13:48:17.387162 22509476222784 run_lib.py:146] step: 1074200, eval_loss: 4.27667e-02
I0214 13:48:36.189207 22509476222784 run_lib.py:133] step: 1074250, training_loss: 3.44164e-02
I0214 13:48:54.970800 22509476222784 run_lib.py:133] step: 1074300, training_loss: 3.94126e-02
I0214 13:48:55.145010 22509476222784 run_lib.py:146] step: 1074300, eval_loss: 3.76033e-02
I0214 13:49:14.098459 22509476222784 run_lib.py:133] step: 1074350, training_loss: 3.81951e-02
I0214 13:49:33.058700 22509476222784 run_lib.py:133] step: 1074400, training_loss: 4.30314e-02
I0214 13:49:33.221979 22509476222784 run_lib.py:146] step: 1074400, eval_loss: 4.74106e-02
I0214 13:49:52.114799 22509476222784 run_lib.py:133] step: 1074450, training_loss: 3.10760e-02
I0214 13:50:10.921589 22509476222784 run_lib.py:133] step: 1074500, training_loss: 4.28243e-02
I0214 13:50:11.097018 22509476222784 run_lib.py:146] step: 1074500, eval_loss: 4.18685e-02
I0214 13:50:29.901244 22509476222784 run_lib.py:133] step: 1074550, training_loss: 3.99904e-02
I0214 13:50:48.723269 22509476222784 run_lib.py:133] step: 1074600, training_loss: 3.69592e-02
I0214 13:50:48.891036 22509476222784 run_lib.py:146] step: 1074600, eval_loss: 3.29429e-02
I0214 13:51:07.759721 22509476222784 run_lib.py:133] step: 1074650, training_loss: 3.90307e-02
I0214 13:51:26.660404 22509476222784 run_lib.py:133] step: 1074700, training_loss: 3.30477e-02
I0214 13:51:26.827093 22509476222784 run_lib.py:146] step: 1074700, eval_loss: 4.07987e-02
I0214 13:51:45.527014 22509476222784 run_lib.py:133] step: 1074750, training_loss: 4.53137e-02
I0214 13:52:04.383968 22509476222784 run_lib.py:133] step: 1074800, training_loss: 4.93766e-02
I0214 13:52:04.559952 22509476222784 run_lib.py:146] step: 1074800, eval_loss: 4.19285e-02
I0214 13:52:23.562999 22509476222784 run_lib.py:133] step: 1074850, training_loss: 3.45346e-02
I0214 13:52:42.359685 22509476222784 run_lib.py:133] step: 1074900, training_loss: 4.17077e-02
I0214 13:52:42.533649 22509476222784 run_lib.py:146] step: 1074900, eval_loss: 3.31370e-02
I0214 13:53:01.558553 22509476222784 run_lib.py:133] step: 1074950, training_loss: 3.00273e-02
I0214 13:53:20.297772 22509476222784 run_lib.py:133] step: 1075000, training_loss: 4.22814e-02
I0214 13:53:20.466196 22509476222784 run_lib.py:146] step: 1075000, eval_loss: 5.12761e-02
I0214 13:53:39.448441 22509476222784 run_lib.py:133] step: 1075050, training_loss: 4.28212e-02
I0214 13:53:58.223187 22509476222784 run_lib.py:133] step: 1075100, training_loss: 6.16399e-02
I0214 13:53:58.402973 22509476222784 run_lib.py:146] step: 1075100, eval_loss: 4.12425e-02
I0214 13:54:17.241829 22509476222784 run_lib.py:133] step: 1075150, training_loss: 4.66448e-02
I0214 13:54:36.238853 22509476222784 run_lib.py:133] step: 1075200, training_loss: 3.09498e-02
I0214 13:54:36.404975 22509476222784 run_lib.py:146] step: 1075200, eval_loss: 3.86806e-02
I0214 13:54:55.147566 22509476222784 run_lib.py:133] step: 1075250, training_loss: 4.31805e-02
I0214 13:55:14.115298 22509476222784 run_lib.py:133] step: 1075300, training_loss: 4.58399e-02
I0214 13:55:14.278124 22509476222784 run_lib.py:146] step: 1075300, eval_loss: 5.83652e-02
I0214 13:55:33.059355 22509476222784 run_lib.py:133] step: 1075350, training_loss: 5.20523e-02
I0214 13:55:51.956787 22509476222784 run_lib.py:133] step: 1075400, training_loss: 4.71004e-02
I0214 13:55:52.137065 22509476222784 run_lib.py:146] step: 1075400, eval_loss: 4.54704e-02
I0214 13:56:11.133661 22509476222784 run_lib.py:133] step: 1075450, training_loss: 3.65874e-02
I0214 13:56:29.960896 22509476222784 run_lib.py:133] step: 1075500, training_loss: 4.54377e-02
I0214 13:56:30.139541 22509476222784 run_lib.py:146] step: 1075500, eval_loss: 4.84224e-02
I0214 13:56:49.027676 22509476222784 run_lib.py:133] step: 1075550, training_loss: 5.28421e-02
I0214 13:57:07.980690 22509476222784 run_lib.py:133] step: 1075600, training_loss: 4.75335e-02
I0214 13:57:08.161185 22509476222784 run_lib.py:146] step: 1075600, eval_loss: 3.90461e-02
I0214 13:57:27.026286 22509476222784 run_lib.py:133] step: 1075650, training_loss: 5.12889e-02
I0214 13:57:45.768212 22509476222784 run_lib.py:133] step: 1075700, training_loss: 3.22879e-02
I0214 13:57:45.935269 22509476222784 run_lib.py:146] step: 1075700, eval_loss: 4.28919e-02
I0214 13:58:04.943644 22509476222784 run_lib.py:133] step: 1075750, training_loss: 3.79140e-02
I0214 13:58:23.694292 22509476222784 run_lib.py:133] step: 1075800, training_loss: 4.52029e-02
I0214 13:58:23.856028 22509476222784 run_lib.py:146] step: 1075800, eval_loss: 4.29062e-02
I0214 13:58:42.635861 22509476222784 run_lib.py:133] step: 1075850, training_loss: 4.28666e-02
I0214 13:59:01.604581 22509476222784 run_lib.py:133] step: 1075900, training_loss: 4.40468e-02
I0214 13:59:01.778953 22509476222784 run_lib.py:146] step: 1075900, eval_loss: 4.11343e-02
I0214 13:59:20.776924 22509476222784 run_lib.py:133] step: 1075950, training_loss: 4.43513e-02
I0214 13:59:39.695696 22509476222784 run_lib.py:133] step: 1076000, training_loss: 3.57361e-02
I0214 13:59:39.864217 22509476222784 run_lib.py:146] step: 1076000, eval_loss: 4.23111e-02
I0214 13:59:58.621455 22509476222784 run_lib.py:133] step: 1076050, training_loss: 3.40327e-02
I0214 14:00:17.467788 22509476222784 run_lib.py:133] step: 1076100, training_loss: 3.78089e-02
I0214 14:00:17.658032 22509476222784 run_lib.py:146] step: 1076100, eval_loss: 4.20282e-02
I0214 14:00:36.653193 22509476222784 run_lib.py:133] step: 1076150, training_loss: 3.99253e-02
I0214 14:00:55.432937 22509476222784 run_lib.py:133] step: 1076200, training_loss: 3.27648e-02
I0214 14:00:55.599060 22509476222784 run_lib.py:146] step: 1076200, eval_loss: 3.63715e-02
I0214 14:01:14.665875 22509476222784 run_lib.py:133] step: 1076250, training_loss: 5.29783e-02
I0214 14:01:33.395186 22509476222784 run_lib.py:133] step: 1076300, training_loss: 3.24060e-02
I0214 14:01:33.559052 22509476222784 run_lib.py:146] step: 1076300, eval_loss: 4.34147e-02
I0214 14:01:52.563336 22509476222784 run_lib.py:133] step: 1076350, training_loss: 4.82378e-02
I0214 14:02:11.326527 22509476222784 run_lib.py:133] step: 1076400, training_loss: 4.24893e-02
I0214 14:02:11.507482 22509476222784 run_lib.py:146] step: 1076400, eval_loss: 4.28490e-02
I0214 14:02:30.559193 22509476222784 run_lib.py:133] step: 1076450, training_loss: 4.05553e-02
I0214 14:02:49.389917 22509476222784 run_lib.py:133] step: 1076500, training_loss: 4.67385e-02
I0214 14:02:49.559046 22509476222784 run_lib.py:146] step: 1076500, eval_loss: 4.39721e-02
I0214 14:03:08.303827 22509476222784 run_lib.py:133] step: 1076550, training_loss: 4.57326e-02
I0214 14:03:27.342048 22509476222784 run_lib.py:133] step: 1076600, training_loss: 3.80401e-02
I0214 14:03:27.511133 22509476222784 run_lib.py:146] step: 1076600, eval_loss: 4.60100e-02
I0214 14:03:46.278964 22509476222784 run_lib.py:133] step: 1076650, training_loss: 4.26249e-02
I0214 14:04:05.191723 22509476222784 run_lib.py:133] step: 1076700, training_loss: 3.72045e-02
I0214 14:04:05.373205 22509476222784 run_lib.py:146] step: 1076700, eval_loss: 4.46753e-02
I0214 14:04:24.399378 22509476222784 run_lib.py:133] step: 1076750, training_loss: 3.92931e-02
I0214 14:04:43.286848 22509476222784 run_lib.py:133] step: 1076800, training_loss: 3.56380e-02
I0214 14:04:43.450959 22509476222784 run_lib.py:146] step: 1076800, eval_loss: 3.80090e-02
I0214 14:05:02.332575 22509476222784 run_lib.py:133] step: 1076850, training_loss: 6.12377e-02
I0214 14:05:21.192884 22509476222784 run_lib.py:133] step: 1076900, training_loss: 5.88505e-02
I0214 14:05:21.384553 22509476222784 run_lib.py:146] step: 1076900, eval_loss: 3.72078e-02
I0214 14:05:40.203148 22509476222784 run_lib.py:133] step: 1076950, training_loss: 4.27510e-02
I0214 14:05:59.176360 22509476222784 run_lib.py:133] step: 1077000, training_loss: 3.73242e-02
I0214 14:05:59.344399 22509476222784 run_lib.py:146] step: 1077000, eval_loss: 4.20068e-02
I0214 14:06:18.177207 22509476222784 run_lib.py:133] step: 1077050, training_loss: 3.42221e-02
I0214 14:06:36.880195 22509476222784 run_lib.py:133] step: 1077100, training_loss: 4.87937e-02
I0214 14:06:37.053854 22509476222784 run_lib.py:146] step: 1077100, eval_loss: 4.18301e-02
I0214 14:06:55.833409 22509476222784 run_lib.py:133] step: 1077150, training_loss: 4.68006e-02
I0214 14:07:14.830233 22509476222784 run_lib.py:133] step: 1077200, training_loss: 4.74930e-02
I0214 14:07:14.995737 22509476222784 run_lib.py:146] step: 1077200, eval_loss: 3.46233e-02
I0214 14:07:33.766213 22509476222784 run_lib.py:133] step: 1077250, training_loss: 4.30312e-02
I0214 14:07:52.689773 22509476222784 run_lib.py:133] step: 1077300, training_loss: 5.25688e-02
I0214 14:07:52.863147 22509476222784 run_lib.py:146] step: 1077300, eval_loss: 4.56296e-02
I0214 14:08:11.544015 22509476222784 run_lib.py:133] step: 1077350, training_loss: 3.69936e-02
I0214 14:08:30.422363 22509476222784 run_lib.py:133] step: 1077400, training_loss: 3.57182e-02
I0214 14:08:30.603158 22509476222784 run_lib.py:146] step: 1077400, eval_loss: 4.49197e-02
I0214 14:08:49.561501 22509476222784 run_lib.py:133] step: 1077450, training_loss: 3.84345e-02
I0214 14:09:08.552774 22509476222784 run_lib.py:133] step: 1077500, training_loss: 3.60704e-02
I0214 14:09:08.719220 22509476222784 run_lib.py:146] step: 1077500, eval_loss: 3.53348e-02
I0214 14:09:27.556771 22509476222784 run_lib.py:133] step: 1077550, training_loss: 4.47008e-02
I0214 14:09:46.289960 22509476222784 run_lib.py:133] step: 1077600, training_loss: 4.47810e-02
I0214 14:09:46.454864 22509476222784 run_lib.py:146] step: 1077600, eval_loss: 3.36943e-02
I0214 14:10:05.526370 22509476222784 run_lib.py:133] step: 1077650, training_loss: 4.05554e-02
I0214 14:10:24.330355 22509476222784 run_lib.py:133] step: 1077700, training_loss: 2.86084e-02
I0214 14:10:24.508137 22509476222784 run_lib.py:146] step: 1077700, eval_loss: 3.43913e-02
I0214 14:10:43.625468 22509476222784 run_lib.py:133] step: 1077750, training_loss: 4.61765e-02
I0214 14:11:02.417559 22509476222784 run_lib.py:133] step: 1077800, training_loss: 4.00833e-02
I0214 14:11:02.586894 22509476222784 run_lib.py:146] step: 1077800, eval_loss: 4.28065e-02
I0214 14:11:21.518409 22509476222784 run_lib.py:133] step: 1077850, training_loss: 4.63837e-02
I0214 14:11:40.370384 22509476222784 run_lib.py:133] step: 1077900, training_loss: 4.48053e-02
I0214 14:11:40.549209 22509476222784 run_lib.py:146] step: 1077900, eval_loss: 4.20949e-02
I0214 14:11:59.325164 22509476222784 run_lib.py:133] step: 1077950, training_loss: 4.01843e-02
I0214 14:12:18.434894 22509476222784 run_lib.py:133] step: 1078000, training_loss: 4.79046e-02
I0214 14:12:18.610980 22509476222784 run_lib.py:146] step: 1078000, eval_loss: 4.09425e-02
I0214 14:12:37.380472 22509476222784 run_lib.py:133] step: 1078050, training_loss: 4.51391e-02
I0214 14:12:56.420611 22509476222784 run_lib.py:133] step: 1078100, training_loss: 3.35150e-02
I0214 14:12:56.586669 22509476222784 run_lib.py:146] step: 1078100, eval_loss: 3.70716e-02
I0214 14:13:15.336471 22509476222784 run_lib.py:133] step: 1078150, training_loss: 4.18424e-02
I0214 14:13:34.193422 22509476222784 run_lib.py:133] step: 1078200, training_loss: 4.67917e-02
I0214 14:13:34.363159 22509476222784 run_lib.py:146] step: 1078200, eval_loss: 4.36525e-02
I0214 14:13:53.432949 22509476222784 run_lib.py:133] step: 1078250, training_loss: 4.27537e-02
I0214 14:14:12.250806 22509476222784 run_lib.py:133] step: 1078300, training_loss: 4.20678e-02
I0214 14:14:12.423320 22509476222784 run_lib.py:146] step: 1078300, eval_loss: 4.62837e-02
I0214 14:14:31.215726 22509476222784 run_lib.py:133] step: 1078350, training_loss: 4.51796e-02
I0214 14:14:50.099586 22509476222784 run_lib.py:133] step: 1078400, training_loss: 4.05752e-02
I0214 14:14:50.275879 22509476222784 run_lib.py:146] step: 1078400, eval_loss: 2.39872e-02
I0214 14:15:09.168029 22509476222784 run_lib.py:133] step: 1078450, training_loss: 4.40539e-02
I0214 14:15:27.956861 22509476222784 run_lib.py:133] step: 1078500, training_loss: 3.20368e-02
I0214 14:15:28.318249 22509476222784 run_lib.py:146] step: 1078500, eval_loss: 4.64941e-02
I0214 14:15:47.106822 22509476222784 run_lib.py:133] step: 1078550, training_loss: 4.54525e-02
I0214 14:16:05.919502 22509476222784 run_lib.py:133] step: 1078600, training_loss: 4.04810e-02
I0214 14:16:06.082716 22509476222784 run_lib.py:146] step: 1078600, eval_loss: 4.06991e-02
I0214 14:16:24.783469 22509476222784 run_lib.py:133] step: 1078650, training_loss: 4.39024e-02
I0214 14:16:43.698578 22509476222784 run_lib.py:133] step: 1078700, training_loss: 2.89308e-02
I0214 14:16:43.865148 22509476222784 run_lib.py:146] step: 1078700, eval_loss: 4.38347e-02
I0214 14:17:02.836286 22509476222784 run_lib.py:133] step: 1078750, training_loss: 3.66611e-02
I0214 14:17:21.835144 22509476222784 run_lib.py:133] step: 1078800, training_loss: 3.08410e-02
I0214 14:17:22.004239 22509476222784 run_lib.py:146] step: 1078800, eval_loss: 3.92752e-02
I0214 14:17:40.693117 22509476222784 run_lib.py:133] step: 1078850, training_loss: 3.42015e-02
I0214 14:17:59.480933 22509476222784 run_lib.py:133] step: 1078900, training_loss: 4.17771e-02
I0214 14:17:59.647901 22509476222784 run_lib.py:146] step: 1078900, eval_loss: 4.82736e-02
I0214 14:18:18.600685 22509476222784 run_lib.py:133] step: 1078950, training_loss: 5.11847e-02
I0214 14:18:37.513100 22509476222784 run_lib.py:133] step: 1079000, training_loss: 2.53090e-02
I0214 14:18:37.680573 22509476222784 run_lib.py:146] step: 1079000, eval_loss: 3.92370e-02
I0214 14:18:56.538464 22509476222784 run_lib.py:133] step: 1079050, training_loss: 3.80933e-02
I0214 14:19:15.245164 22509476222784 run_lib.py:133] step: 1079100, training_loss: 4.91389e-02
I0214 14:19:15.407953 22509476222784 run_lib.py:146] step: 1079100, eval_loss: 5.19977e-02
I0214 14:19:34.393344 22509476222784 run_lib.py:133] step: 1079150, training_loss: 4.85067e-02
I0214 14:19:53.174674 22509476222784 run_lib.py:133] step: 1079200, training_loss: 3.40610e-02
I0214 14:19:53.353245 22509476222784 run_lib.py:146] step: 1079200, eval_loss: 5.15631e-02
I0214 14:20:12.402366 22509476222784 run_lib.py:133] step: 1079250, training_loss: 4.52874e-02
I0214 14:20:31.208223 22509476222784 run_lib.py:133] step: 1079300, training_loss: 3.30865e-02
I0214 14:20:31.377158 22509476222784 run_lib.py:146] step: 1079300, eval_loss: 4.00059e-02
I0214 14:20:50.247164 22509476222784 run_lib.py:133] step: 1079350, training_loss: 4.09874e-02
I0214 14:21:09.026864 22509476222784 run_lib.py:133] step: 1079400, training_loss: 5.16918e-02
I0214 14:21:09.195957 22509476222784 run_lib.py:146] step: 1079400, eval_loss: 4.61640e-02
I0214 14:21:28.019552 22509476222784 run_lib.py:133] step: 1079450, training_loss: 4.23095e-02
I0214 14:21:47.054970 22509476222784 run_lib.py:133] step: 1079500, training_loss: 3.92146e-02
I0214 14:21:47.229977 22509476222784 run_lib.py:146] step: 1079500, eval_loss: 4.60545e-02
I0214 14:22:06.025480 22509476222784 run_lib.py:133] step: 1079550, training_loss: 3.58719e-02
I0214 14:22:24.941026 22509476222784 run_lib.py:133] step: 1079600, training_loss: 4.73212e-02
I0214 14:22:25.104048 22509476222784 run_lib.py:146] step: 1079600, eval_loss: 3.86076e-02
I0214 14:22:43.979974 22509476222784 run_lib.py:133] step: 1079650, training_loss: 3.70461e-02
I0214 14:23:02.753031 22509476222784 run_lib.py:133] step: 1079700, training_loss: 5.44513e-02
I0214 14:23:02.933241 22509476222784 run_lib.py:146] step: 1079700, eval_loss: 4.40808e-02
I0214 14:23:21.995568 22509476222784 run_lib.py:133] step: 1079750, training_loss: 3.78793e-02
I0214 14:23:40.787225 22509476222784 run_lib.py:133] step: 1079800, training_loss: 3.61006e-02
I0214 14:23:40.956743 22509476222784 run_lib.py:146] step: 1079800, eval_loss: 4.34745e-02
I0214 14:23:59.781146 22509476222784 run_lib.py:133] step: 1079850, training_loss: 4.04889e-02
I0214 14:24:18.685877 22509476222784 run_lib.py:133] step: 1079900, training_loss: 3.72398e-02
I0214 14:24:18.861035 22509476222784 run_lib.py:146] step: 1079900, eval_loss: 3.98622e-02
I0214 14:24:37.805737 22509476222784 run_lib.py:133] step: 1079950, training_loss: 4.16643e-02
I0214 14:24:56.711622 22509476222784 run_lib.py:133] step: 1080000, training_loss: 5.04970e-02
I0214 14:24:57.502017 22509476222784 run_lib.py:146] step: 1080000, eval_loss: 5.18013e-02
I0214 14:25:19.221726 22509476222784 run_lib.py:133] step: 1080050, training_loss: 4.55523e-02
I0214 14:25:37.989031 22509476222784 run_lib.py:133] step: 1080100, training_loss: 2.55365e-02
I0214 14:25:38.152756 22509476222784 run_lib.py:146] step: 1080100, eval_loss: 3.53100e-02
I0214 14:25:57.038635 22509476222784 run_lib.py:133] step: 1080150, training_loss: 4.78396e-02
I0214 14:26:15.837885 22509476222784 run_lib.py:133] step: 1080200, training_loss: 3.87321e-02
I0214 14:26:16.011217 22509476222784 run_lib.py:146] step: 1080200, eval_loss: 4.65061e-02
I0214 14:26:34.751302 22509476222784 run_lib.py:133] step: 1080250, training_loss: 3.72305e-02
I0214 14:26:53.724113 22509476222784 run_lib.py:133] step: 1080300, training_loss: 4.94293e-02
I0214 14:26:53.893926 22509476222784 run_lib.py:146] step: 1080300, eval_loss: 3.98377e-02
I0214 14:27:12.750304 22509476222784 run_lib.py:133] step: 1080350, training_loss: 3.52079e-02
I0214 14:27:31.533615 22509476222784 run_lib.py:133] step: 1080400, training_loss: 4.23551e-02
I0214 14:27:31.710913 22509476222784 run_lib.py:146] step: 1080400, eval_loss: 4.96624e-02
I0214 14:27:50.660697 22509476222784 run_lib.py:133] step: 1080450, training_loss: 3.71946e-02
I0214 14:28:09.598799 22509476222784 run_lib.py:133] step: 1080500, training_loss: 4.83443e-02
I0214 14:28:09.764681 22509476222784 run_lib.py:146] step: 1080500, eval_loss: 3.94411e-02
I0214 14:28:28.646487 22509476222784 run_lib.py:133] step: 1080550, training_loss: 3.72815e-02
I0214 14:28:47.436663 22509476222784 run_lib.py:133] step: 1080600, training_loss: 5.58160e-02
I0214 14:28:47.599655 22509476222784 run_lib.py:146] step: 1080600, eval_loss: 4.19595e-02
I0214 14:29:06.372910 22509476222784 run_lib.py:133] step: 1080650, training_loss: 3.17812e-02
I0214 14:29:25.132468 22509476222784 run_lib.py:133] step: 1080700, training_loss: 4.33842e-02
I0214 14:29:25.311243 22509476222784 run_lib.py:146] step: 1080700, eval_loss: 4.20633e-02
I0214 14:29:44.239745 22509476222784 run_lib.py:133] step: 1080750, training_loss: 4.27699e-02
I0214 14:30:03.151075 22509476222784 run_lib.py:133] step: 1080800, training_loss: 4.26995e-02
I0214 14:30:03.327403 22509476222784 run_lib.py:146] step: 1080800, eval_loss: 3.48795e-02
I0214 14:30:21.989151 22509476222784 run_lib.py:133] step: 1080850, training_loss: 4.65318e-02
I0214 14:30:40.737591 22509476222784 run_lib.py:133] step: 1080900, training_loss: 4.05809e-02
I0214 14:30:40.902968 22509476222784 run_lib.py:146] step: 1080900, eval_loss: 6.05853e-02
I0214 14:30:59.756085 22509476222784 run_lib.py:133] step: 1080950, training_loss: 4.18222e-02
I0214 14:31:18.661583 22509476222784 run_lib.py:133] step: 1081000, training_loss: 2.82640e-02
I0214 14:31:18.827600 22509476222784 run_lib.py:146] step: 1081000, eval_loss: 5.25920e-02
I0214 14:31:37.776482 22509476222784 run_lib.py:133] step: 1081050, training_loss: 4.49448e-02
I0214 14:31:56.572510 22509476222784 run_lib.py:133] step: 1081100, training_loss: 4.47146e-02
I0214 14:31:56.741048 22509476222784 run_lib.py:146] step: 1081100, eval_loss: 3.21268e-02
I0214 14:32:15.613616 22509476222784 run_lib.py:133] step: 1081150, training_loss: 3.77167e-02
I0214 14:32:34.351624 22509476222784 run_lib.py:133] step: 1081200, training_loss: 4.36302e-02
I0214 14:32:34.537970 22509476222784 run_lib.py:146] step: 1081200, eval_loss: 3.85676e-02
I0214 14:32:53.413297 22509476222784 run_lib.py:133] step: 1081250, training_loss: 4.41062e-02
I0214 14:33:12.355564 22509476222784 run_lib.py:133] step: 1081300, training_loss: 3.97670e-02
I0214 14:33:12.523210 22509476222784 run_lib.py:146] step: 1081300, eval_loss: 3.58905e-02
I0214 14:33:31.341228 22509476222784 run_lib.py:133] step: 1081350, training_loss: 4.31525e-02
I0214 14:33:50.206554 22509476222784 run_lib.py:133] step: 1081400, training_loss: 4.30804e-02
I0214 14:33:50.374604 22509476222784 run_lib.py:146] step: 1081400, eval_loss: 5.02748e-02
I0214 14:34:09.216771 22509476222784 run_lib.py:133] step: 1081450, training_loss: 3.54385e-02
I0214 14:34:28.011640 22509476222784 run_lib.py:133] step: 1081500, training_loss: 5.40622e-02
I0214 14:34:28.177223 22509476222784 run_lib.py:146] step: 1081500, eval_loss: 3.22449e-02
I0214 14:34:47.176169 22509476222784 run_lib.py:133] step: 1081550, training_loss: 4.15842e-02
I0214 14:35:05.939036 22509476222784 run_lib.py:133] step: 1081600, training_loss: 4.01830e-02
I0214 14:35:06.102842 22509476222784 run_lib.py:146] step: 1081600, eval_loss: 3.98109e-02
I0214 14:35:24.751209 22509476222784 run_lib.py:133] step: 1081650, training_loss: 3.79412e-02
I0214 14:35:43.513010 22509476222784 run_lib.py:133] step: 1081700, training_loss: 3.94051e-02
I0214 14:35:43.700842 22509476222784 run_lib.py:146] step: 1081700, eval_loss: 4.11154e-02
I0214 14:36:02.608955 22509476222784 run_lib.py:133] step: 1081750, training_loss: 4.78894e-02
I0214 14:36:21.455441 22509476222784 run_lib.py:133] step: 1081800, training_loss: 4.92784e-02
I0214 14:36:21.622225 22509476222784 run_lib.py:146] step: 1081800, eval_loss: 4.91668e-02
I0214 14:36:40.439757 22509476222784 run_lib.py:133] step: 1081850, training_loss: 5.39396e-02
I0214 14:36:59.203978 22509476222784 run_lib.py:133] step: 1081900, training_loss: 3.15536e-02
I0214 14:36:59.380131 22509476222784 run_lib.py:146] step: 1081900, eval_loss: 3.51436e-02
I0214 14:37:18.118562 22509476222784 run_lib.py:133] step: 1081950, training_loss: 3.78598e-02
I0214 14:37:36.921215 22509476222784 run_lib.py:133] step: 1082000, training_loss: 5.00996e-02
I0214 14:37:37.086282 22509476222784 run_lib.py:146] step: 1082000, eval_loss: 4.78417e-02
I0214 14:37:56.114241 22509476222784 run_lib.py:133] step: 1082050, training_loss: 5.35515e-02
I0214 14:38:14.868896 22509476222784 run_lib.py:133] step: 1082100, training_loss: 4.62851e-02
I0214 14:38:15.048913 22509476222784 run_lib.py:146] step: 1082100, eval_loss: 3.91578e-02
I0214 14:38:33.857706 22509476222784 run_lib.py:133] step: 1082150, training_loss: 3.74241e-02
I0214 14:38:52.548464 22509476222784 run_lib.py:133] step: 1082200, training_loss: 4.75811e-02
I0214 14:38:52.732936 22509476222784 run_lib.py:146] step: 1082200, eval_loss: 4.27470e-02
I0214 14:39:11.776062 22509476222784 run_lib.py:133] step: 1082250, training_loss: 3.13445e-02
I0214 14:39:30.540100 22509476222784 run_lib.py:133] step: 1082300, training_loss: 3.82368e-02
I0214 14:39:30.707272 22509476222784 run_lib.py:146] step: 1082300, eval_loss: 3.93476e-02
I0214 14:39:49.700768 22509476222784 run_lib.py:133] step: 1082350, training_loss: 4.27462e-02
I0214 14:40:08.487096 22509476222784 run_lib.py:133] step: 1082400, training_loss: 4.39912e-02
I0214 14:40:08.650001 22509476222784 run_lib.py:146] step: 1082400, eval_loss: 4.68150e-02
I0214 14:40:27.509838 22509476222784 run_lib.py:133] step: 1082450, training_loss: 3.36690e-02
I0214 14:40:46.394700 22509476222784 run_lib.py:133] step: 1082500, training_loss: 3.49182e-02
I0214 14:40:46.560252 22509476222784 run_lib.py:146] step: 1082500, eval_loss: 4.75601e-02
I0214 14:41:05.509428 22509476222784 run_lib.py:133] step: 1082550, training_loss: 4.17296e-02
I0214 14:41:24.314275 22509476222784 run_lib.py:133] step: 1082600, training_loss: 3.64364e-02
I0214 14:41:24.482107 22509476222784 run_lib.py:146] step: 1082600, eval_loss: 3.39120e-02
I0214 14:41:43.177509 22509476222784 run_lib.py:133] step: 1082650, training_loss: 4.55173e-02
I0214 14:42:02.070348 22509476222784 run_lib.py:133] step: 1082700, training_loss: 4.31851e-02
I0214 14:42:02.243129 22509476222784 run_lib.py:146] step: 1082700, eval_loss: 4.20632e-02
I0214 14:42:21.084371 22509476222784 run_lib.py:133] step: 1082750, training_loss: 3.10745e-02
I0214 14:42:39.860181 22509476222784 run_lib.py:133] step: 1082800, training_loss: 4.30343e-02
I0214 14:42:40.035253 22509476222784 run_lib.py:146] step: 1082800, eval_loss: 4.21877e-02
I0214 14:42:59.073295 22509476222784 run_lib.py:133] step: 1082850, training_loss: 4.04600e-02
I0214 14:43:17.948621 22509476222784 run_lib.py:133] step: 1082900, training_loss: 4.18087e-02
I0214 14:43:18.114869 22509476222784 run_lib.py:146] step: 1082900, eval_loss: 4.90149e-02
I0214 14:43:36.889116 22509476222784 run_lib.py:133] step: 1082950, training_loss: 4.50073e-02
I0214 14:43:55.714673 22509476222784 run_lib.py:133] step: 1083000, training_loss: 4.78192e-02
I0214 14:43:55.910000 22509476222784 run_lib.py:146] step: 1083000, eval_loss: 4.59972e-02
I0214 14:44:14.738077 22509476222784 run_lib.py:133] step: 1083050, training_loss: 5.66084e-02
I0214 14:44:33.779113 22509476222784 run_lib.py:133] step: 1083100, training_loss: 4.82070e-02
I0214 14:44:33.946722 22509476222784 run_lib.py:146] step: 1083100, eval_loss: 4.91813e-02
I0214 14:44:52.704904 22509476222784 run_lib.py:133] step: 1083150, training_loss: 4.56045e-02
I0214 14:45:11.529338 22509476222784 run_lib.py:133] step: 1083200, training_loss: 4.01643e-02
I0214 14:45:11.700270 22509476222784 run_lib.py:146] step: 1083200, eval_loss: 3.54167e-02
I0214 14:45:30.439503 22509476222784 run_lib.py:133] step: 1083250, training_loss: 4.73952e-02
I0214 14:45:49.530012 22509476222784 run_lib.py:133] step: 1083300, training_loss: 5.21586e-02
I0214 14:45:49.697126 22509476222784 run_lib.py:146] step: 1083300, eval_loss: 4.13970e-02
I0214 14:46:08.497499 22509476222784 run_lib.py:133] step: 1083350, training_loss: 3.10344e-02
I0214 14:46:27.374296 22509476222784 run_lib.py:133] step: 1083400, training_loss: 5.24509e-02
I0214 14:46:27.544320 22509476222784 run_lib.py:146] step: 1083400, eval_loss: 4.53112e-02
I0214 14:46:46.447246 22509476222784 run_lib.py:133] step: 1083450, training_loss: 4.51096e-02
I0214 14:47:05.240235 22509476222784 run_lib.py:133] step: 1083500, training_loss: 3.76117e-02
I0214 14:47:05.409250 22509476222784 run_lib.py:146] step: 1083500, eval_loss: 3.47280e-02
I0214 14:47:24.605159 22509476222784 run_lib.py:133] step: 1083550, training_loss: 5.21269e-02
I0214 14:47:43.462563 22509476222784 run_lib.py:133] step: 1083600, training_loss: 4.20587e-02
I0214 14:47:43.640113 22509476222784 run_lib.py:146] step: 1083600, eval_loss: 3.27034e-02
I0214 14:48:02.493910 22509476222784 run_lib.py:133] step: 1083650, training_loss: 5.98097e-02
I0214 14:48:21.315107 22509476222784 run_lib.py:133] step: 1083700, training_loss: 4.01564e-02
I0214 14:48:21.484979 22509476222784 run_lib.py:146] step: 1083700, eval_loss: 4.61081e-02
I0214 14:48:40.426051 22509476222784 run_lib.py:133] step: 1083750, training_loss: 2.99180e-02
I0214 14:48:59.371527 22509476222784 run_lib.py:133] step: 1083800, training_loss: 4.42853e-02
I0214 14:48:59.539352 22509476222784 run_lib.py:146] step: 1083800, eval_loss: 4.36620e-02
I0214 14:49:18.491341 22509476222784 run_lib.py:133] step: 1083850, training_loss: 5.19148e-02
I0214 14:49:37.377716 22509476222784 run_lib.py:133] step: 1083900, training_loss: 3.95441e-02
I0214 14:49:37.540936 22509476222784 run_lib.py:146] step: 1083900, eval_loss: 4.17982e-02
I0214 14:49:56.477343 22509476222784 run_lib.py:133] step: 1083950, training_loss: 3.22125e-02
I0214 14:50:15.246989 22509476222784 run_lib.py:133] step: 1084000, training_loss: 3.17494e-02
I0214 14:50:15.418105 22509476222784 run_lib.py:146] step: 1084000, eval_loss: 4.64786e-02
I0214 14:50:34.259644 22509476222784 run_lib.py:133] step: 1084050, training_loss: 4.39421e-02
I0214 14:50:53.223525 22509476222784 run_lib.py:133] step: 1084100, training_loss: 4.49666e-02
I0214 14:50:53.392220 22509476222784 run_lib.py:146] step: 1084100, eval_loss: 3.55841e-02
I0214 14:51:12.238479 22509476222784 run_lib.py:133] step: 1084150, training_loss: 3.27960e-02
I0214 14:51:31.129065 22509476222784 run_lib.py:133] step: 1084200, training_loss: 4.65158e-02
I0214 14:51:31.294000 22509476222784 run_lib.py:146] step: 1084200, eval_loss: 4.51110e-02
I0214 14:51:50.150945 22509476222784 run_lib.py:133] step: 1084250, training_loss: 3.95220e-02
I0214 14:52:09.074138 22509476222784 run_lib.py:133] step: 1084300, training_loss: 4.43873e-02
I0214 14:52:09.241239 22509476222784 run_lib.py:146] step: 1084300, eval_loss: 4.99947e-02
I0214 14:52:28.209968 22509476222784 run_lib.py:133] step: 1084350, training_loss: 3.89157e-02
I0214 14:52:47.085719 22509476222784 run_lib.py:133] step: 1084400, training_loss: 4.63636e-02
I0214 14:52:47.249159 22509476222784 run_lib.py:146] step: 1084400, eval_loss: 5.31591e-02
I0214 14:53:05.987037 22509476222784 run_lib.py:133] step: 1084450, training_loss: 3.58010e-02
I0214 14:53:24.963801 22509476222784 run_lib.py:133] step: 1084500, training_loss: 3.81448e-02
I0214 14:53:25.135041 22509476222784 run_lib.py:146] step: 1084500, eval_loss: 3.89053e-02
I0214 14:53:44.006523 22509476222784 run_lib.py:133] step: 1084550, training_loss: 3.65027e-02
I0214 14:54:02.806650 22509476222784 run_lib.py:133] step: 1084600, training_loss: 4.23224e-02
I0214 14:54:02.973884 22509476222784 run_lib.py:146] step: 1084600, eval_loss: 3.89522e-02
I0214 14:54:21.971349 22509476222784 run_lib.py:133] step: 1084650, training_loss: 4.03257e-02
I0214 14:54:40.730701 22509476222784 run_lib.py:133] step: 1084700, training_loss: 3.40227e-02
I0214 14:54:40.897910 22509476222784 run_lib.py:146] step: 1084700, eval_loss: 3.49108e-02
I0214 14:54:59.771208 22509476222784 run_lib.py:133] step: 1084750, training_loss: 4.45513e-02
I0214 14:55:18.531306 22509476222784 run_lib.py:133] step: 1084800, training_loss: 4.97479e-02
I0214 14:55:18.700053 22509476222784 run_lib.py:146] step: 1084800, eval_loss: 4.07150e-02
I0214 14:55:37.600173 22509476222784 run_lib.py:133] step: 1084850, training_loss: 4.05506e-02
I0214 14:55:56.692052 22509476222784 run_lib.py:133] step: 1084900, training_loss: 4.58118e-02
I0214 14:55:56.856822 22509476222784 run_lib.py:146] step: 1084900, eval_loss: 4.27576e-02
I0214 14:56:15.652856 22509476222784 run_lib.py:133] step: 1084950, training_loss: 3.82693e-02
I0214 14:56:34.543863 22509476222784 run_lib.py:133] step: 1085000, training_loss: 4.80559e-02
I0214 14:56:34.723155 22509476222784 run_lib.py:146] step: 1085000, eval_loss: 4.53520e-02
I0214 14:56:53.599764 22509476222784 run_lib.py:133] step: 1085050, training_loss: 4.49513e-02
I0214 14:57:12.405730 22509476222784 run_lib.py:133] step: 1085100, training_loss: 3.22056e-02
I0214 14:57:12.593373 22509476222784 run_lib.py:146] step: 1085100, eval_loss: 3.63050e-02
I0214 14:57:31.613684 22509476222784 run_lib.py:133] step: 1085150, training_loss: 4.19188e-02
I0214 14:57:50.372624 22509476222784 run_lib.py:133] step: 1085200, training_loss: 4.74697e-02
I0214 14:57:50.539189 22509476222784 run_lib.py:146] step: 1085200, eval_loss: 4.28388e-02
I0214 14:58:09.643575 22509476222784 run_lib.py:133] step: 1085250, training_loss: 4.53153e-02
I0214 14:58:28.396070 22509476222784 run_lib.py:133] step: 1085300, training_loss: 4.07988e-02
I0214 14:58:28.561003 22509476222784 run_lib.py:146] step: 1085300, eval_loss: 4.20633e-02
I0214 14:58:47.529187 22509476222784 run_lib.py:133] step: 1085350, training_loss: 3.68445e-02
I0214 14:59:06.326276 22509476222784 run_lib.py:133] step: 1085400, training_loss: 3.58860e-02
I0214 14:59:06.494223 22509476222784 run_lib.py:146] step: 1085400, eval_loss: 4.01052e-02
I0214 14:59:25.405508 22509476222784 run_lib.py:133] step: 1085450, training_loss: 4.12073e-02
I0214 14:59:44.451267 22509476222784 run_lib.py:133] step: 1085500, training_loss: 3.79972e-02
I0214 14:59:44.620219 22509476222784 run_lib.py:146] step: 1085500, eval_loss: 5.50069e-02
I0214 15:00:03.363596 22509476222784 run_lib.py:133] step: 1085550, training_loss: 3.84720e-02
I0214 15:00:22.173778 22509476222784 run_lib.py:133] step: 1085600, training_loss: 3.88506e-02
I0214 15:00:22.346084 22509476222784 run_lib.py:146] step: 1085600, eval_loss: 3.57915e-02
I0214 15:00:41.287656 22509476222784 run_lib.py:133] step: 1085650, training_loss: 3.72712e-02
I0214 15:01:00.204324 22509476222784 run_lib.py:133] step: 1085700, training_loss: 4.97239e-02
I0214 15:01:00.373873 22509476222784 run_lib.py:146] step: 1085700, eval_loss: 4.24573e-02
I0214 15:01:19.309441 22509476222784 run_lib.py:133] step: 1085750, training_loss: 4.42191e-02
I0214 15:01:37.997668 22509476222784 run_lib.py:133] step: 1085800, training_loss: 3.59199e-02
I0214 15:01:38.160974 22509476222784 run_lib.py:146] step: 1085800, eval_loss: 3.96199e-02
I0214 15:01:56.957550 22509476222784 run_lib.py:133] step: 1085850, training_loss: 3.48445e-02
I0214 15:02:15.875769 22509476222784 run_lib.py:133] step: 1085900, training_loss: 4.75572e-02
I0214 15:02:16.053334 22509476222784 run_lib.py:146] step: 1085900, eval_loss: 4.27829e-02
I0214 15:02:34.940687 22509476222784 run_lib.py:133] step: 1085950, training_loss: 3.96265e-02
I0214 15:02:53.698035 22509476222784 run_lib.py:133] step: 1086000, training_loss: 4.60599e-02
I0214 15:02:53.866999 22509476222784 run_lib.py:146] step: 1086000, eval_loss: 3.98791e-02
I0214 15:03:12.542254 22509476222784 run_lib.py:133] step: 1086050, training_loss: 3.80295e-02
I0214 15:03:31.598264 22509476222784 run_lib.py:133] step: 1086100, training_loss: 4.55704e-02
I0214 15:03:31.764897 22509476222784 run_lib.py:146] step: 1086100, eval_loss: 3.42029e-02
I0214 15:03:50.484942 22509476222784 run_lib.py:133] step: 1086150, training_loss: 5.85309e-02
I0214 15:04:09.466288 22509476222784 run_lib.py:133] step: 1086200, training_loss: 5.40520e-02
I0214 15:04:09.639295 22509476222784 run_lib.py:146] step: 1086200, eval_loss: 3.75044e-02
I0214 15:04:28.478970 22509476222784 run_lib.py:133] step: 1086250, training_loss: 4.36792e-02
I0214 15:04:47.202019 22509476222784 run_lib.py:133] step: 1086300, training_loss: 5.36145e-02
I0214 15:04:47.366011 22509476222784 run_lib.py:146] step: 1086300, eval_loss: 5.22420e-02
I0214 15:05:06.402505 22509476222784 run_lib.py:133] step: 1086350, training_loss: 5.19697e-02
I0214 15:05:25.214003 22509476222784 run_lib.py:133] step: 1086400, training_loss: 4.00950e-02
I0214 15:05:25.391239 22509476222784 run_lib.py:146] step: 1086400, eval_loss: 4.41185e-02
I0214 15:05:44.322361 22509476222784 run_lib.py:133] step: 1086450, training_loss: 4.03254e-02
I0214 15:06:03.176898 22509476222784 run_lib.py:133] step: 1086500, training_loss: 3.50548e-02
I0214 15:06:03.352012 22509476222784 run_lib.py:146] step: 1086500, eval_loss: 4.51026e-02
I0214 15:06:22.372759 22509476222784 run_lib.py:133] step: 1086550, training_loss: 3.07916e-02
I0214 15:06:41.164291 22509476222784 run_lib.py:133] step: 1086600, training_loss: 4.00288e-02
I0214 15:06:41.330293 22509476222784 run_lib.py:146] step: 1086600, eval_loss: 5.15726e-02
I0214 15:07:00.282698 22509476222784 run_lib.py:133] step: 1086650, training_loss: 4.03698e-02
I0214 15:07:19.222857 22509476222784 run_lib.py:133] step: 1086700, training_loss: 3.35723e-02
I0214 15:07:19.389960 22509476222784 run_lib.py:146] step: 1086700, eval_loss: 4.17258e-02
I0214 15:07:38.370111 22509476222784 run_lib.py:133] step: 1086750, training_loss: 3.91491e-02
I0214 15:07:57.230302 22509476222784 run_lib.py:133] step: 1086800, training_loss: 3.75147e-02
I0214 15:07:57.394123 22509476222784 run_lib.py:146] step: 1086800, eval_loss: 4.51536e-02
I0214 15:08:16.137560 22509476222784 run_lib.py:133] step: 1086850, training_loss: 5.01032e-02
I0214 15:08:35.190156 22509476222784 run_lib.py:133] step: 1086900, training_loss: 4.02354e-02
I0214 15:08:35.370019 22509476222784 run_lib.py:146] step: 1086900, eval_loss: 4.37970e-02
I0214 15:08:54.178589 22509476222784 run_lib.py:133] step: 1086950, training_loss: 4.25731e-02
I0214 15:09:13.240721 22509476222784 run_lib.py:133] step: 1087000, training_loss: 4.81425e-02
I0214 15:09:13.405896 22509476222784 run_lib.py:146] step: 1087000, eval_loss: 3.85464e-02
I0214 15:09:32.292232 22509476222784 run_lib.py:133] step: 1087050, training_loss: 4.69405e-02
I0214 15:09:51.035481 22509476222784 run_lib.py:133] step: 1087100, training_loss: 3.54708e-02
I0214 15:09:51.200860 22509476222784 run_lib.py:146] step: 1087100, eval_loss: 5.73433e-02
I0214 15:10:10.162553 22509476222784 run_lib.py:133] step: 1087150, training_loss: 5.69552e-02
I0214 15:10:29.008525 22509476222784 run_lib.py:133] step: 1087200, training_loss: 4.01316e-02
I0214 15:10:29.173998 22509476222784 run_lib.py:146] step: 1087200, eval_loss: 4.04040e-02
I0214 15:10:48.094276 22509476222784 run_lib.py:133] step: 1087250, training_loss: 3.49250e-02
I0214 15:11:07.111059 22509476222784 run_lib.py:133] step: 1087300, training_loss: 4.60294e-02
I0214 15:11:07.275005 22509476222784 run_lib.py:146] step: 1087300, eval_loss: 4.16564e-02
I0214 15:11:26.083621 22509476222784 run_lib.py:133] step: 1087350, training_loss: 4.63381e-02
I0214 15:11:44.860572 22509476222784 run_lib.py:133] step: 1087400, training_loss: 4.61900e-02
I0214 15:11:45.197713 22509476222784 run_lib.py:146] step: 1087400, eval_loss: 3.83992e-02
I0214 15:12:03.977230 22509476222784 run_lib.py:133] step: 1087450, training_loss: 5.28910e-02
I0214 15:12:22.884261 22509476222784 run_lib.py:133] step: 1087500, training_loss: 3.79267e-02
I0214 15:12:23.048746 22509476222784 run_lib.py:146] step: 1087500, eval_loss: 3.24078e-02
I0214 15:12:41.847763 22509476222784 run_lib.py:133] step: 1087550, training_loss: 4.50942e-02
I0214 15:13:00.652521 22509476222784 run_lib.py:133] step: 1087600, training_loss: 4.35821e-02
I0214 15:13:00.822702 22509476222784 run_lib.py:146] step: 1087600, eval_loss: 3.89061e-02
I0214 15:13:19.820926 22509476222784 run_lib.py:133] step: 1087650, training_loss: 4.08126e-02
I0214 15:13:38.695983 22509476222784 run_lib.py:133] step: 1087700, training_loss: 3.23090e-02
I0214 15:13:38.860427 22509476222784 run_lib.py:146] step: 1087700, eval_loss: 4.74133e-02
I0214 15:13:57.787585 22509476222784 run_lib.py:133] step: 1087750, training_loss: 4.96879e-02
I0214 15:14:16.533188 22509476222784 run_lib.py:133] step: 1087800, training_loss: 4.45349e-02
I0214 15:14:16.701054 22509476222784 run_lib.py:146] step: 1087800, eval_loss: 4.00384e-02
I0214 15:14:35.681711 22509476222784 run_lib.py:133] step: 1087850, training_loss: 4.21524e-02
I0214 15:14:54.536284 22509476222784 run_lib.py:133] step: 1087900, training_loss: 4.53711e-02
I0214 15:14:54.718502 22509476222784 run_lib.py:146] step: 1087900, eval_loss: 3.45628e-02
I0214 15:15:13.554352 22509476222784 run_lib.py:133] step: 1087950, training_loss: 3.49424e-02
I0214 15:15:32.383625 22509476222784 run_lib.py:133] step: 1088000, training_loss: 4.04652e-02
I0214 15:15:32.549634 22509476222784 run_lib.py:146] step: 1088000, eval_loss: 4.42613e-02
I0214 15:15:51.511593 22509476222784 run_lib.py:133] step: 1088050, training_loss: 3.20926e-02
I0214 15:16:10.400365 22509476222784 run_lib.py:133] step: 1088100, training_loss: 4.79680e-02
I0214 15:16:10.568106 22509476222784 run_lib.py:146] step: 1088100, eval_loss: 3.81819e-02
I0214 15:16:29.497357 22509476222784 run_lib.py:133] step: 1088150, training_loss: 3.80093e-02
I0214 15:16:48.400980 22509476222784 run_lib.py:133] step: 1088200, training_loss: 4.48099e-02
I0214 15:16:48.568051 22509476222784 run_lib.py:146] step: 1088200, eval_loss: 3.49175e-02
I0214 15:17:07.568854 22509476222784 run_lib.py:133] step: 1088250, training_loss: 4.38945e-02
I0214 15:17:26.347227 22509476222784 run_lib.py:133] step: 1088300, training_loss: 4.35094e-02
I0214 15:17:26.514045 22509476222784 run_lib.py:146] step: 1088300, eval_loss: 4.28158e-02
I0214 15:17:45.256078 22509476222784 run_lib.py:133] step: 1088350, training_loss: 5.27987e-02
I0214 15:18:04.259903 22509476222784 run_lib.py:133] step: 1088400, training_loss: 3.81176e-02
I0214 15:18:04.444916 22509476222784 run_lib.py:146] step: 1088400, eval_loss: 4.75220e-02
I0214 15:18:23.261614 22509476222784 run_lib.py:133] step: 1088450, training_loss: 5.51932e-02
I0214 15:18:42.375701 22509476222784 run_lib.py:133] step: 1088500, training_loss: 6.15127e-02
I0214 15:18:42.540909 22509476222784 run_lib.py:146] step: 1088500, eval_loss: 4.99657e-02
I0214 15:19:01.291498 22509476222784 run_lib.py:133] step: 1088550, training_loss: 4.27038e-02
I0214 15:19:20.143010 22509476222784 run_lib.py:133] step: 1088600, training_loss: 3.95283e-02
I0214 15:19:20.319165 22509476222784 run_lib.py:146] step: 1088600, eval_loss: 3.67991e-02
I0214 15:19:39.314481 22509476222784 run_lib.py:133] step: 1088650, training_loss: 4.29868e-02
I0214 15:19:58.094946 22509476222784 run_lib.py:133] step: 1088700, training_loss: 3.84377e-02
I0214 15:19:58.260173 22509476222784 run_lib.py:146] step: 1088700, eval_loss: 5.39053e-02
I0214 15:20:17.187322 22509476222784 run_lib.py:133] step: 1088750, training_loss: 4.13185e-02
I0214 15:20:35.985090 22509476222784 run_lib.py:133] step: 1088800, training_loss: 4.53632e-02
I0214 15:20:36.154149 22509476222784 run_lib.py:146] step: 1088800, eval_loss: 3.68796e-02
I0214 15:20:55.137756 22509476222784 run_lib.py:133] step: 1088850, training_loss: 3.23905e-02
I0214 15:21:14.072324 22509476222784 run_lib.py:133] step: 1088900, training_loss: 3.83629e-02
I0214 15:21:14.247011 22509476222784 run_lib.py:146] step: 1088900, eval_loss: 4.74043e-02
I0214 15:21:33.136183 22509476222784 run_lib.py:133] step: 1088950, training_loss: 3.89973e-02
I0214 15:21:52.021912 22509476222784 run_lib.py:133] step: 1089000, training_loss: 3.24980e-02
I0214 15:21:52.185431 22509476222784 run_lib.py:146] step: 1089000, eval_loss: 3.55005e-02
I0214 15:22:10.944574 22509476222784 run_lib.py:133] step: 1089050, training_loss: 5.24332e-02
I0214 15:22:29.758326 22509476222784 run_lib.py:133] step: 1089100, training_loss: 3.79074e-02
I0214 15:22:29.924222 22509476222784 run_lib.py:146] step: 1089100, eval_loss: 5.05131e-02
I0214 15:22:48.851030 22509476222784 run_lib.py:133] step: 1089150, training_loss: 4.28101e-02
I0214 15:23:07.776789 22509476222784 run_lib.py:133] step: 1089200, training_loss: 3.88907e-02
I0214 15:23:07.948381 22509476222784 run_lib.py:146] step: 1089200, eval_loss: 4.96459e-02
I0214 15:23:26.808975 22509476222784 run_lib.py:133] step: 1089250, training_loss: 4.06808e-02
I0214 15:23:45.577434 22509476222784 run_lib.py:133] step: 1089300, training_loss: 5.71654e-02
I0214 15:23:45.763239 22509476222784 run_lib.py:146] step: 1089300, eval_loss: 3.19718e-02
I0214 15:24:04.786717 22509476222784 run_lib.py:133] step: 1089350, training_loss: 4.15266e-02
I0214 15:24:23.604174 22509476222784 run_lib.py:133] step: 1089400, training_loss: 2.93900e-02
I0214 15:24:23.778971 22509476222784 run_lib.py:146] step: 1089400, eval_loss: 4.74830e-02
I0214 15:24:42.867894 22509476222784 run_lib.py:133] step: 1089450, training_loss: 3.81892e-02
I0214 15:25:01.658875 22509476222784 run_lib.py:133] step: 1089500, training_loss: 4.63182e-02
I0214 15:25:01.829005 22509476222784 run_lib.py:146] step: 1089500, eval_loss: 6.35517e-02
I0214 15:25:20.814322 22509476222784 run_lib.py:133] step: 1089550, training_loss: 4.26702e-02
I0214 15:25:39.655091 22509476222784 run_lib.py:133] step: 1089600, training_loss: 3.60650e-02
I0214 15:25:39.816975 22509476222784 run_lib.py:146] step: 1089600, eval_loss: 3.84005e-02
I0214 15:25:58.756342 22509476222784 run_lib.py:133] step: 1089650, training_loss: 3.60337e-02
I0214 15:26:17.664317 22509476222784 run_lib.py:133] step: 1089700, training_loss: 4.38374e-02
I0214 15:26:17.836221 22509476222784 run_lib.py:146] step: 1089700, eval_loss: 4.07212e-02
I0214 15:26:36.637844 22509476222784 run_lib.py:133] step: 1089750, training_loss: 4.43458e-02
I0214 15:26:55.726290 22509476222784 run_lib.py:133] step: 1089800, training_loss: 2.89929e-02
I0214 15:26:55.896231 22509476222784 run_lib.py:146] step: 1089800, eval_loss: 4.00309e-02
I0214 15:27:14.641122 22509476222784 run_lib.py:133] step: 1089850, training_loss: 4.15285e-02
I0214 15:27:33.440148 22509476222784 run_lib.py:133] step: 1089900, training_loss: 3.65098e-02
I0214 15:27:33.618192 22509476222784 run_lib.py:146] step: 1089900, eval_loss: 3.92688e-02
I0214 15:27:52.689970 22509476222784 run_lib.py:133] step: 1089950, training_loss: 4.19706e-02
I0214 15:28:11.598444 22509476222784 run_lib.py:133] step: 1090000, training_loss: 3.80280e-02
I0214 15:28:13.028696 22509476222784 run_lib.py:146] step: 1090000, eval_loss: 4.93042e-02
I0214 15:28:35.943769 22509476222784 run_lib.py:133] step: 1090050, training_loss: 5.15648e-02
I0214 15:28:54.793508 22509476222784 run_lib.py:133] step: 1090100, training_loss: 4.23214e-02
I0214 15:28:54.956721 22509476222784 run_lib.py:146] step: 1090100, eval_loss: 4.27089e-02
I0214 15:29:13.851523 22509476222784 run_lib.py:133] step: 1090150, training_loss: 4.37011e-02
I0214 15:29:32.609213 22509476222784 run_lib.py:133] step: 1090200, training_loss: 3.80197e-02
I0214 15:29:32.772748 22509476222784 run_lib.py:146] step: 1090200, eval_loss: 3.28755e-02
I0214 15:29:51.727868 22509476222784 run_lib.py:133] step: 1090250, training_loss: 5.64966e-02
I0214 15:30:10.612461 22509476222784 run_lib.py:133] step: 1090300, training_loss: 5.24579e-02
I0214 15:30:10.783586 22509476222784 run_lib.py:146] step: 1090300, eval_loss: 4.85878e-02
I0214 15:30:29.546368 22509476222784 run_lib.py:133] step: 1090350, training_loss: 4.74478e-02
I0214 15:30:48.519221 22509476222784 run_lib.py:133] step: 1090400, training_loss: 3.85034e-02
I0214 15:30:48.685904 22509476222784 run_lib.py:146] step: 1090400, eval_loss: 5.28462e-02
I0214 15:31:07.579427 22509476222784 run_lib.py:133] step: 1090450, training_loss: 5.43063e-02
I0214 15:31:26.349524 22509476222784 run_lib.py:133] step: 1090500, training_loss: 4.68785e-02
I0214 15:31:26.519173 22509476222784 run_lib.py:146] step: 1090500, eval_loss: 4.88525e-02
I0214 15:31:45.450263 22509476222784 run_lib.py:133] step: 1090550, training_loss: 4.48913e-02
I0214 15:32:04.223982 22509476222784 run_lib.py:133] step: 1090600, training_loss: 4.94401e-02
I0214 15:32:04.389119 22509476222784 run_lib.py:146] step: 1090600, eval_loss: 3.78136e-02
I0214 15:32:23.446915 22509476222784 run_lib.py:133] step: 1090650, training_loss: 4.42759e-02
I0214 15:32:42.189788 22509476222784 run_lib.py:133] step: 1090700, training_loss: 4.55967e-02
I0214 15:32:42.354145 22509476222784 run_lib.py:146] step: 1090700, eval_loss: 4.18918e-02
I0214 15:33:01.125475 22509476222784 run_lib.py:133] step: 1090750, training_loss: 3.64947e-02
I0214 15:33:20.026140 22509476222784 run_lib.py:133] step: 1090800, training_loss: 3.54537e-02
I0214 15:33:20.194170 22509476222784 run_lib.py:146] step: 1090800, eval_loss: 3.36924e-02
I0214 15:33:38.900525 22509476222784 run_lib.py:133] step: 1090850, training_loss: 4.61758e-02
I0214 15:33:58.013463 22509476222784 run_lib.py:133] step: 1090900, training_loss: 4.47682e-02
I0214 15:33:58.180390 22509476222784 run_lib.py:146] step: 1090900, eval_loss: 2.99580e-02
I0214 15:34:16.946297 22509476222784 run_lib.py:133] step: 1090950, training_loss: 4.08059e-02
I0214 15:34:35.744084 22509476222784 run_lib.py:133] step: 1091000, training_loss: 3.99734e-02
I0214 15:34:35.912464 22509476222784 run_lib.py:146] step: 1091000, eval_loss: 3.61180e-02
I0214 15:34:54.891504 22509476222784 run_lib.py:133] step: 1091050, training_loss: 4.40293e-02
I0214 15:35:13.576640 22509476222784 run_lib.py:133] step: 1091100, training_loss: 5.53428e-02
I0214 15:35:13.739135 22509476222784 run_lib.py:146] step: 1091100, eval_loss: 4.76039e-02
I0214 15:35:32.686582 22509476222784 run_lib.py:133] step: 1091150, training_loss: 5.05698e-02
I0214 15:35:51.637009 22509476222784 run_lib.py:133] step: 1091200, training_loss: 4.24871e-02
I0214 15:35:51.817464 22509476222784 run_lib.py:146] step: 1091200, eval_loss: 4.52910e-02
I0214 15:36:10.678322 22509476222784 run_lib.py:133] step: 1091250, training_loss: 4.50913e-02
I0214 15:36:29.470575 22509476222784 run_lib.py:133] step: 1091300, training_loss: 3.29031e-02
I0214 15:36:29.637340 22509476222784 run_lib.py:146] step: 1091300, eval_loss: 4.17169e-02
I0214 15:36:48.500736 22509476222784 run_lib.py:133] step: 1091350, training_loss: 3.23348e-02
I0214 15:37:07.463684 22509476222784 run_lib.py:133] step: 1091400, training_loss: 4.39311e-02
I0214 15:37:07.629163 22509476222784 run_lib.py:146] step: 1091400, eval_loss: 4.42112e-02
I0214 15:37:26.433303 22509476222784 run_lib.py:133] step: 1091450, training_loss: 3.52783e-02
I0214 15:37:45.198784 22509476222784 run_lib.py:133] step: 1091500, training_loss: 4.17043e-02
I0214 15:37:45.365967 22509476222784 run_lib.py:146] step: 1091500, eval_loss: 5.41630e-02
I0214 15:38:04.481241 22509476222784 run_lib.py:133] step: 1091550, training_loss: 3.38912e-02
I0214 15:38:23.291876 22509476222784 run_lib.py:133] step: 1091600, training_loss: 5.56873e-02
I0214 15:38:23.455120 22509476222784 run_lib.py:146] step: 1091600, eval_loss: 3.80628e-02
I0214 15:38:42.422529 22509476222784 run_lib.py:133] step: 1091650, training_loss: 4.60979e-02
I0214 15:39:01.200857 22509476222784 run_lib.py:133] step: 1091700, training_loss: 3.02249e-02
I0214 15:39:01.369247 22509476222784 run_lib.py:146] step: 1091700, eval_loss: 2.72595e-02
I0214 15:39:20.312855 22509476222784 run_lib.py:133] step: 1091750, training_loss: 4.33457e-02
I0214 15:39:39.141838 22509476222784 run_lib.py:133] step: 1091800, training_loss: 2.74836e-02
I0214 15:39:39.312266 22509476222784 run_lib.py:146] step: 1091800, eval_loss: 3.61087e-02
I0214 15:39:58.229509 22509476222784 run_lib.py:133] step: 1091850, training_loss: 4.35190e-02
I0214 15:40:17.105012 22509476222784 run_lib.py:133] step: 1091900, training_loss: 3.37748e-02
I0214 15:40:17.273256 22509476222784 run_lib.py:146] step: 1091900, eval_loss: 4.30933e-02
I0214 15:40:36.274135 22509476222784 run_lib.py:133] step: 1091950, training_loss: 4.15325e-02
I0214 15:40:55.057806 22509476222784 run_lib.py:133] step: 1092000, training_loss: 3.32077e-02
I0214 15:40:55.225827 22509476222784 run_lib.py:146] step: 1092000, eval_loss: 4.04000e-02
I0214 15:41:14.169196 22509476222784 run_lib.py:133] step: 1092050, training_loss: 3.62084e-02
I0214 15:41:32.951919 22509476222784 run_lib.py:133] step: 1092100, training_loss: 2.80525e-02
I0214 15:41:33.117956 22509476222784 run_lib.py:146] step: 1092100, eval_loss: 4.05404e-02
I0214 15:41:52.178172 22509476222784 run_lib.py:133] step: 1092150, training_loss: 3.94191e-02
I0214 15:42:11.163320 22509476222784 run_lib.py:133] step: 1092200, training_loss: 5.64388e-02
I0214 15:42:11.328994 22509476222784 run_lib.py:146] step: 1092200, eval_loss: 4.37412e-02
I0214 15:42:30.130907 22509476222784 run_lib.py:133] step: 1092250, training_loss: 4.12020e-02
I0214 15:42:48.866453 22509476222784 run_lib.py:133] step: 1092300, training_loss: 3.67916e-02
I0214 15:42:49.160261 22509476222784 run_lib.py:146] step: 1092300, eval_loss: 3.94878e-02
I0214 15:43:08.135816 22509476222784 run_lib.py:133] step: 1092350, training_loss: 6.00800e-02
I0214 15:43:27.134591 22509476222784 run_lib.py:133] step: 1092400, training_loss: 4.41178e-02
I0214 15:43:27.307766 22509476222784 run_lib.py:146] step: 1092400, eval_loss: 4.17562e-02
I0214 15:43:46.492634 22509476222784 run_lib.py:133] step: 1092450, training_loss: 5.61377e-02
I0214 15:44:05.429326 22509476222784 run_lib.py:133] step: 1092500, training_loss: 4.04290e-02
I0214 15:44:05.592897 22509476222784 run_lib.py:146] step: 1092500, eval_loss: 3.70187e-02
I0214 15:44:24.351273 22509476222784 run_lib.py:133] step: 1092550, training_loss: 5.23323e-02
I0214 15:44:43.386070 22509476222784 run_lib.py:133] step: 1092600, training_loss: 5.19905e-02
I0214 15:44:43.555219 22509476222784 run_lib.py:146] step: 1092600, eval_loss: 4.11865e-02
I0214 15:45:02.425948 22509476222784 run_lib.py:133] step: 1092650, training_loss: 3.59962e-02
I0214 15:45:21.176716 22509476222784 run_lib.py:133] step: 1092700, training_loss: 5.26697e-02
I0214 15:45:21.344948 22509476222784 run_lib.py:146] step: 1092700, eval_loss: 4.01062e-02
I0214 15:45:40.242273 22509476222784 run_lib.py:133] step: 1092750, training_loss: 4.85256e-02
I0214 15:45:59.240388 22509476222784 run_lib.py:133] step: 1092800, training_loss: 4.11684e-02
I0214 15:45:59.406406 22509476222784 run_lib.py:146] step: 1092800, eval_loss: 3.16443e-02
I0214 15:46:18.273437 22509476222784 run_lib.py:133] step: 1092850, training_loss: 4.87844e-02
I0214 15:46:37.190333 22509476222784 run_lib.py:133] step: 1092900, training_loss: 4.06492e-02
I0214 15:46:37.360570 22509476222784 run_lib.py:146] step: 1092900, eval_loss: 5.37588e-02
I0214 15:46:56.208609 22509476222784 run_lib.py:133] step: 1092950, training_loss: 4.33390e-02
I0214 15:47:15.004687 22509476222784 run_lib.py:133] step: 1093000, training_loss: 4.51003e-02
I0214 15:47:15.168849 22509476222784 run_lib.py:146] step: 1093000, eval_loss: 3.85601e-02
I0214 15:47:34.134174 22509476222784 run_lib.py:133] step: 1093050, training_loss: 5.64310e-02
I0214 15:47:53.035685 22509476222784 run_lib.py:133] step: 1093100, training_loss: 4.69198e-02
I0214 15:47:53.213841 22509476222784 run_lib.py:146] step: 1093100, eval_loss: 5.02906e-02
I0214 15:48:12.170023 22509476222784 run_lib.py:133] step: 1093150, training_loss: 4.68155e-02
I0214 15:48:30.987071 22509476222784 run_lib.py:133] step: 1093200, training_loss: 3.19807e-02
I0214 15:48:31.156287 22509476222784 run_lib.py:146] step: 1093200, eval_loss: 3.99632e-02
I0214 15:48:50.096477 22509476222784 run_lib.py:133] step: 1093250, training_loss: 3.74726e-02
I0214 15:49:08.877068 22509476222784 run_lib.py:133] step: 1093300, training_loss: 4.24791e-02
I0214 15:49:09.042918 22509476222784 run_lib.py:146] step: 1093300, eval_loss: 3.90146e-02
I0214 15:49:27.919042 22509476222784 run_lib.py:133] step: 1093350, training_loss: 3.80771e-02
I0214 15:49:46.824225 22509476222784 run_lib.py:133] step: 1093400, training_loss: 3.53084e-02
I0214 15:49:46.996026 22509476222784 run_lib.py:146] step: 1093400, eval_loss: 3.33515e-02
I0214 15:50:05.990545 22509476222784 run_lib.py:133] step: 1093450, training_loss: 4.63369e-02
I0214 15:50:24.763998 22509476222784 run_lib.py:133] step: 1093500, training_loss: 4.26925e-02
I0214 15:50:24.932940 22509476222784 run_lib.py:146] step: 1093500, eval_loss: 3.78997e-02
I0214 15:50:43.819124 22509476222784 run_lib.py:133] step: 1093550, training_loss: 4.22332e-02
I0214 15:51:02.764383 22509476222784 run_lib.py:133] step: 1093600, training_loss: 4.09451e-02
I0214 15:51:02.930912 22509476222784 run_lib.py:146] step: 1093600, eval_loss: 4.92974e-02
I0214 15:51:21.756117 22509476222784 run_lib.py:133] step: 1093650, training_loss: 4.65388e-02
I0214 15:51:40.665282 22509476222784 run_lib.py:133] step: 1093700, training_loss: 2.93497e-02
I0214 15:51:40.848839 22509476222784 run_lib.py:146] step: 1093700, eval_loss: 4.49275e-02
I0214 15:51:59.707961 22509476222784 run_lib.py:133] step: 1093750, training_loss: 3.20666e-02
I0214 15:52:18.526162 22509476222784 run_lib.py:133] step: 1093800, training_loss: 4.30532e-02
I0214 15:52:18.694107 22509476222784 run_lib.py:146] step: 1093800, eval_loss: 3.07644e-02
I0214 15:52:37.662338 22509476222784 run_lib.py:133] step: 1093850, training_loss: 4.71877e-02
I0214 15:52:56.506207 22509476222784 run_lib.py:133] step: 1093900, training_loss: 4.11805e-02
I0214 15:52:56.670853 22509476222784 run_lib.py:146] step: 1093900, eval_loss: 4.31793e-02
I0214 15:53:15.444021 22509476222784 run_lib.py:133] step: 1093950, training_loss: 4.17727e-02
I0214 15:53:34.553767 22509476222784 run_lib.py:133] step: 1094000, training_loss: 5.38576e-02
I0214 15:53:34.722148 22509476222784 run_lib.py:146] step: 1094000, eval_loss: 3.91401e-02
I0214 15:53:53.608169 22509476222784 run_lib.py:133] step: 1094050, training_loss: 4.98784e-02
I0214 15:54:12.385204 22509476222784 run_lib.py:133] step: 1094100, training_loss: 4.10984e-02
I0214 15:54:12.753149 22509476222784 run_lib.py:146] step: 1094100, eval_loss: 4.92610e-02
I0214 15:54:31.666885 22509476222784 run_lib.py:133] step: 1094150, training_loss: 3.57785e-02
I0214 15:54:50.414093 22509476222784 run_lib.py:133] step: 1094200, training_loss: 3.89992e-02
I0214 15:54:50.587838 22509476222784 run_lib.py:146] step: 1094200, eval_loss: 4.47730e-02
I0214 15:55:09.503019 22509476222784 run_lib.py:133] step: 1094250, training_loss: 5.53803e-02
I0214 15:55:28.375882 22509476222784 run_lib.py:133] step: 1094300, training_loss: 4.25116e-02
I0214 15:55:28.542554 22509476222784 run_lib.py:146] step: 1094300, eval_loss: 5.10505e-02
I0214 15:55:47.537278 22509476222784 run_lib.py:133] step: 1094350, training_loss: 2.71652e-02
I0214 15:56:06.411103 22509476222784 run_lib.py:133] step: 1094400, training_loss: 4.25573e-02
I0214 15:56:06.574502 22509476222784 run_lib.py:146] step: 1094400, eval_loss: 4.08360e-02
I0214 15:56:25.306803 22509476222784 run_lib.py:133] step: 1094450, training_loss: 3.67674e-02
I0214 15:56:44.102304 22509476222784 run_lib.py:133] step: 1094500, training_loss: 4.12420e-02
I0214 15:56:44.280991 22509476222784 run_lib.py:146] step: 1094500, eval_loss: 3.96502e-02
I0214 15:57:03.168396 22509476222784 run_lib.py:133] step: 1094550, training_loss: 3.50651e-02
I0214 15:57:22.111475 22509476222784 run_lib.py:133] step: 1094600, training_loss: 3.34096e-02
I0214 15:57:22.287981 22509476222784 run_lib.py:146] step: 1094600, eval_loss: 4.17681e-02
I0214 15:57:41.093499 22509476222784 run_lib.py:133] step: 1094650, training_loss: 4.14199e-02
I0214 15:57:59.878636 22509476222784 run_lib.py:133] step: 1094700, training_loss: 3.77486e-02
I0214 15:58:00.043911 22509476222784 run_lib.py:146] step: 1094700, eval_loss: 4.90409e-02
I0214 15:58:19.105230 22509476222784 run_lib.py:133] step: 1094750, training_loss: 3.69266e-02
I0214 15:58:37.898624 22509476222784 run_lib.py:133] step: 1094800, training_loss: 3.99887e-02
I0214 15:58:38.065229 22509476222784 run_lib.py:146] step: 1094800, eval_loss: 3.73145e-02
I0214 15:58:57.078873 22509476222784 run_lib.py:133] step: 1094850, training_loss: 3.63693e-02
I0214 15:59:15.862266 22509476222784 run_lib.py:133] step: 1094900, training_loss: 3.88831e-02
I0214 15:59:16.026008 22509476222784 run_lib.py:146] step: 1094900, eval_loss: 4.44949e-02
I0214 15:59:34.903445 22509476222784 run_lib.py:133] step: 1094950, training_loss: 4.06369e-02
I0214 15:59:53.790096 22509476222784 run_lib.py:133] step: 1095000, training_loss: 4.16461e-02
I0214 15:59:53.969090 22509476222784 run_lib.py:146] step: 1095000, eval_loss: 4.62667e-02
I0214 16:00:12.807809 22509476222784 run_lib.py:133] step: 1095050, training_loss: 3.69744e-02
I0214 16:00:31.935754 22509476222784 run_lib.py:133] step: 1095100, training_loss: 3.10407e-02
I0214 16:00:32.110258 22509476222784 run_lib.py:146] step: 1095100, eval_loss: 6.20034e-02
I0214 16:00:50.882977 22509476222784 run_lib.py:133] step: 1095150, training_loss: 4.83696e-02
I0214 16:01:09.794056 22509476222784 run_lib.py:133] step: 1095200, training_loss: 3.43403e-02
I0214 16:01:10.341341 22509476222784 run_lib.py:146] step: 1095200, eval_loss: 3.86200e-02
I0214 16:01:29.235194 22509476222784 run_lib.py:133] step: 1095250, training_loss: 4.38554e-02
I0214 16:01:48.040724 22509476222784 run_lib.py:133] step: 1095300, training_loss: 3.73662e-02
I0214 16:01:48.208045 22509476222784 run_lib.py:146] step: 1095300, eval_loss: 3.61236e-02
I0214 16:02:07.275093 22509476222784 run_lib.py:133] step: 1095350, training_loss: 3.72575e-02
I0214 16:02:26.011944 22509476222784 run_lib.py:133] step: 1095400, training_loss: 5.17235e-02
I0214 16:02:26.174845 22509476222784 run_lib.py:146] step: 1095400, eval_loss: 5.04571e-02
I0214 16:02:44.914553 22509476222784 run_lib.py:133] step: 1095450, training_loss: 3.80680e-02
I0214 16:03:03.681316 22509476222784 run_lib.py:133] step: 1095500, training_loss: 3.52363e-02
I0214 16:03:03.860679 22509476222784 run_lib.py:146] step: 1095500, eval_loss: 5.45886e-02
I0214 16:03:22.842191 22509476222784 run_lib.py:133] step: 1095550, training_loss: 4.77781e-02
I0214 16:03:41.734022 22509476222784 run_lib.py:133] step: 1095600, training_loss: 3.74802e-02
I0214 16:03:41.956828 22509476222784 run_lib.py:146] step: 1095600, eval_loss: 4.22616e-02
I0214 16:04:00.765105 22509476222784 run_lib.py:133] step: 1095650, training_loss: 4.79661e-02
I0214 16:04:19.534795 22509476222784 run_lib.py:133] step: 1095700, training_loss: 3.62114e-02
I0214 16:04:19.700974 22509476222784 run_lib.py:146] step: 1095700, eval_loss: 3.62809e-02
I0214 16:04:38.577032 22509476222784 run_lib.py:133] step: 1095750, training_loss: 3.98469e-02
I0214 16:04:57.347292 22509476222784 run_lib.py:133] step: 1095800, training_loss: 3.54546e-02
I0214 16:04:57.513011 22509476222784 run_lib.py:146] step: 1095800, eval_loss: 4.17670e-02
I0214 16:05:16.567277 22509476222784 run_lib.py:133] step: 1095850, training_loss: 4.30164e-02
I0214 16:05:35.382334 22509476222784 run_lib.py:133] step: 1095900, training_loss: 3.01274e-02
I0214 16:05:35.544855 22509476222784 run_lib.py:146] step: 1095900, eval_loss: 3.94509e-02
I0214 16:05:54.354580 22509476222784 run_lib.py:133] step: 1095950, training_loss: 3.84360e-02
I0214 16:06:13.129877 22509476222784 run_lib.py:133] step: 1096000, training_loss: 5.47420e-02
I0214 16:06:13.316475 22509476222784 run_lib.py:146] step: 1096000, eval_loss: 4.03782e-02
I0214 16:06:32.265307 22509476222784 run_lib.py:133] step: 1096050, training_loss: 4.23210e-02
I0214 16:06:51.143113 22509476222784 run_lib.py:133] step: 1096100, training_loss: 4.19628e-02
I0214 16:06:51.309241 22509476222784 run_lib.py:146] step: 1096100, eval_loss: 3.84378e-02
I0214 16:07:10.216512 22509476222784 run_lib.py:133] step: 1096150, training_loss: 3.40783e-02
I0214 16:07:28.945759 22509476222784 run_lib.py:133] step: 1096200, training_loss: 3.54298e-02
I0214 16:07:29.118518 22509476222784 run_lib.py:146] step: 1096200, eval_loss: 2.97041e-02
I0214 16:07:48.093858 22509476222784 run_lib.py:133] step: 1096250, training_loss: 5.73875e-02
I0214 16:08:06.925427 22509476222784 run_lib.py:133] step: 1096300, training_loss: 4.59397e-02
I0214 16:08:07.089264 22509476222784 run_lib.py:146] step: 1096300, eval_loss: 4.78830e-02
I0214 16:08:26.160287 22509476222784 run_lib.py:133] step: 1096350, training_loss: 5.36405e-02
I0214 16:08:45.066243 22509476222784 run_lib.py:133] step: 1096400, training_loss: 3.84458e-02
I0214 16:08:45.231951 22509476222784 run_lib.py:146] step: 1096400, eval_loss: 5.29371e-02
I0214 16:09:03.984228 22509476222784 run_lib.py:133] step: 1096450, training_loss: 3.61595e-02
I0214 16:09:22.886190 22509476222784 run_lib.py:133] step: 1096500, training_loss: 3.57136e-02
I0214 16:09:23.057567 22509476222784 run_lib.py:146] step: 1096500, eval_loss: 4.83195e-02
I0214 16:09:41.807267 22509476222784 run_lib.py:133] step: 1096550, training_loss: 4.20411e-02
I0214 16:10:00.628002 22509476222784 run_lib.py:133] step: 1096600, training_loss: 3.81618e-02
I0214 16:10:00.799384 22509476222784 run_lib.py:146] step: 1096600, eval_loss: 4.17522e-02
I0214 16:10:19.906066 22509476222784 run_lib.py:133] step: 1096650, training_loss: 5.21533e-02
I0214 16:10:39.083953 22509476222784 run_lib.py:133] step: 1096700, training_loss: 4.63730e-02
I0214 16:10:39.251821 22509476222784 run_lib.py:146] step: 1096700, eval_loss: 4.75984e-02
I0214 16:10:57.988227 22509476222784 run_lib.py:133] step: 1096750, training_loss: 4.76971e-02
I0214 16:11:16.854465 22509476222784 run_lib.py:133] step: 1096800, training_loss: 3.49505e-02
I0214 16:11:17.024280 22509476222784 run_lib.py:146] step: 1096800, eval_loss: 5.12906e-02
I0214 16:11:35.845249 22509476222784 run_lib.py:133] step: 1096850, training_loss: 4.22746e-02
I0214 16:11:54.756120 22509476222784 run_lib.py:133] step: 1096900, training_loss: 3.85530e-02
I0214 16:11:54.923110 22509476222784 run_lib.py:146] step: 1096900, eval_loss: 3.56439e-02
I0214 16:12:13.713956 22509476222784 run_lib.py:133] step: 1096950, training_loss: 3.62462e-02
I0214 16:12:32.459735 22509476222784 run_lib.py:133] step: 1097000, training_loss: 5.07363e-02
I0214 16:12:32.627273 22509476222784 run_lib.py:146] step: 1097000, eval_loss: 3.94065e-02
I0214 16:12:51.413637 22509476222784 run_lib.py:133] step: 1097050, training_loss: 3.86081e-02
I0214 16:13:10.397098 22509476222784 run_lib.py:133] step: 1097100, training_loss: 4.84966e-02
I0214 16:13:10.565094 22509476222784 run_lib.py:146] step: 1097100, eval_loss: 4.18102e-02
I0214 16:13:29.320754 22509476222784 run_lib.py:133] step: 1097150, training_loss: 5.06708e-02
I0214 16:13:48.342186 22509476222784 run_lib.py:133] step: 1097200, training_loss: 2.95508e-02
I0214 16:13:48.507766 22509476222784 run_lib.py:146] step: 1097200, eval_loss: 4.28753e-02
I0214 16:14:07.266939 22509476222784 run_lib.py:133] step: 1097250, training_loss: 5.17321e-02
I0214 16:14:26.134086 22509476222784 run_lib.py:133] step: 1097300, training_loss: 3.11745e-02
I0214 16:14:26.302845 22509476222784 run_lib.py:146] step: 1097300, eval_loss: 4.87698e-02
I0214 16:14:45.288872 22509476222784 run_lib.py:133] step: 1097350, training_loss: 3.50560e-02
I0214 16:15:04.216687 22509476222784 run_lib.py:133] step: 1097400, training_loss: 5.49624e-02
I0214 16:15:04.386343 22509476222784 run_lib.py:146] step: 1097400, eval_loss: 3.68431e-02
I0214 16:15:23.218800 22509476222784 run_lib.py:133] step: 1097450, training_loss: 4.31580e-02
I0214 16:15:41.944099 22509476222784 run_lib.py:133] step: 1097500, training_loss: 4.59630e-02
I0214 16:15:42.113153 22509476222784 run_lib.py:146] step: 1097500, eval_loss: 4.55711e-02
I0214 16:16:01.128887 22509476222784 run_lib.py:133] step: 1097550, training_loss: 3.72892e-02
I0214 16:16:19.884705 22509476222784 run_lib.py:133] step: 1097600, training_loss: 4.14086e-02
I0214 16:16:20.056935 22509476222784 run_lib.py:146] step: 1097600, eval_loss: 4.57277e-02
I0214 16:16:38.965444 22509476222784 run_lib.py:133] step: 1097650, training_loss: 4.86820e-02
I0214 16:16:57.853462 22509476222784 run_lib.py:133] step: 1097700, training_loss: 2.92535e-02
I0214 16:16:58.018791 22509476222784 run_lib.py:146] step: 1097700, eval_loss: 4.69596e-02
I0214 16:17:17.013391 22509476222784 run_lib.py:133] step: 1097750, training_loss: 4.45133e-02
I0214 16:17:35.879895 22509476222784 run_lib.py:133] step: 1097800, training_loss: 4.13706e-02
I0214 16:17:36.043037 22509476222784 run_lib.py:146] step: 1097800, eval_loss: 5.21953e-02
I0214 16:17:54.772086 22509476222784 run_lib.py:133] step: 1097850, training_loss: 3.91194e-02
I0214 16:18:13.730423 22509476222784 run_lib.py:133] step: 1097900, training_loss: 4.39684e-02
I0214 16:18:13.920305 22509476222784 run_lib.py:146] step: 1097900, eval_loss: 4.46877e-02
I0214 16:18:32.748350 22509476222784 run_lib.py:133] step: 1097950, training_loss: 3.76864e-02
I0214 16:18:51.703441 22509476222784 run_lib.py:133] step: 1098000, training_loss: 4.57124e-02
I0214 16:18:51.871276 22509476222784 run_lib.py:146] step: 1098000, eval_loss: 4.70331e-02
I0214 16:19:10.775497 22509476222784 run_lib.py:133] step: 1098050, training_loss: 3.85069e-02
I0214 16:19:29.524621 22509476222784 run_lib.py:133] step: 1098100, training_loss: 3.71736e-02
I0214 16:19:29.691413 22509476222784 run_lib.py:146] step: 1098100, eval_loss: 4.01173e-02
I0214 16:19:49.174208 22509476222784 run_lib.py:133] step: 1098150, training_loss: 4.05407e-02
I0214 16:20:07.964523 22509476222784 run_lib.py:133] step: 1098200, training_loss: 4.63085e-02
I0214 16:20:08.129166 22509476222784 run_lib.py:146] step: 1098200, eval_loss: 4.58398e-02
I0214 16:20:26.924810 22509476222784 run_lib.py:133] step: 1098250, training_loss: 4.34899e-02
I0214 16:20:45.941340 22509476222784 run_lib.py:133] step: 1098300, training_loss: 4.39782e-02
I0214 16:20:46.106190 22509476222784 run_lib.py:146] step: 1098300, eval_loss: 5.21872e-02
I0214 16:21:04.768704 22509476222784 run_lib.py:133] step: 1098350, training_loss: 4.00504e-02
I0214 16:21:23.628720 22509476222784 run_lib.py:133] step: 1098400, training_loss: 5.70234e-02
I0214 16:21:23.814218 22509476222784 run_lib.py:146] step: 1098400, eval_loss: 4.79031e-02
I0214 16:21:42.655782 22509476222784 run_lib.py:133] step: 1098450, training_loss: 4.60519e-02
I0214 16:22:01.550305 22509476222784 run_lib.py:133] step: 1098500, training_loss: 4.58329e-02
I0214 16:22:01.725043 22509476222784 run_lib.py:146] step: 1098500, eval_loss: 4.74011e-02
I0214 16:22:20.489110 22509476222784 run_lib.py:133] step: 1098550, training_loss: 4.09353e-02
I0214 16:22:39.295791 22509476222784 run_lib.py:133] step: 1098600, training_loss: 4.02564e-02
I0214 16:22:39.463029 22509476222784 run_lib.py:146] step: 1098600, eval_loss: 4.98608e-02
I0214 16:22:58.478829 22509476222784 run_lib.py:133] step: 1098650, training_loss: 4.10987e-02
I0214 16:23:17.406636 22509476222784 run_lib.py:133] step: 1098700, training_loss: 4.74659e-02
I0214 16:23:17.568931 22509476222784 run_lib.py:146] step: 1098700, eval_loss: 3.26926e-02
I0214 16:23:36.396897 22509476222784 run_lib.py:133] step: 1098750, training_loss: 3.55429e-02
I0214 16:23:55.177255 22509476222784 run_lib.py:133] step: 1098800, training_loss: 3.90354e-02
I0214 16:23:55.342894 22509476222784 run_lib.py:146] step: 1098800, eval_loss: 4.44644e-02
I0214 16:24:14.252976 22509476222784 run_lib.py:133] step: 1098850, training_loss: 4.98715e-02
I0214 16:24:33.066814 22509476222784 run_lib.py:133] step: 1098900, training_loss: 3.49574e-02
I0214 16:24:33.245645 22509476222784 run_lib.py:146] step: 1098900, eval_loss: 3.90447e-02
I0214 16:24:52.292367 22509476222784 run_lib.py:133] step: 1098950, training_loss: 4.37510e-02
I0214 16:25:11.084546 22509476222784 run_lib.py:133] step: 1099000, training_loss: 3.95854e-02
I0214 16:25:11.250916 22509476222784 run_lib.py:146] step: 1099000, eval_loss: 3.74244e-02
I0214 16:25:30.278384 22509476222784 run_lib.py:133] step: 1099050, training_loss: 3.77938e-02
I0214 16:25:49.011945 22509476222784 run_lib.py:133] step: 1099100, training_loss: 3.47786e-02
I0214 16:25:49.186045 22509476222784 run_lib.py:146] step: 1099100, eval_loss: 3.13810e-02
I0214 16:26:08.319509 22509476222784 run_lib.py:133] step: 1099150, training_loss: 4.03570e-02
I0214 16:26:27.080299 22509476222784 run_lib.py:133] step: 1099200, training_loss: 4.53103e-02
I0214 16:26:27.244000 22509476222784 run_lib.py:146] step: 1099200, eval_loss: 4.27522e-02
I0214 16:26:46.013252 22509476222784 run_lib.py:133] step: 1099250, training_loss: 4.89652e-02
I0214 16:27:04.967337 22509476222784 run_lib.py:133] step: 1099300, training_loss: 4.48731e-02
I0214 16:27:05.137211 22509476222784 run_lib.py:146] step: 1099300, eval_loss: 3.81789e-02
I0214 16:27:23.816173 22509476222784 run_lib.py:133] step: 1099350, training_loss: 3.95057e-02
I0214 16:27:42.765371 22509476222784 run_lib.py:133] step: 1099400, training_loss: 5.06543e-02
I0214 16:27:42.938758 22509476222784 run_lib.py:146] step: 1099400, eval_loss: 4.01127e-02
I0214 16:28:01.871158 22509476222784 run_lib.py:133] step: 1099450, training_loss: 3.09026e-02
I0214 16:28:20.699991 22509476222784 run_lib.py:133] step: 1099500, training_loss: 3.85204e-02
I0214 16:28:20.866743 22509476222784 run_lib.py:146] step: 1099500, eval_loss: 4.05064e-02
I0214 16:28:39.773791 22509476222784 run_lib.py:133] step: 1099550, training_loss: 4.24360e-02
I0214 16:28:58.655383 22509476222784 run_lib.py:133] step: 1099600, training_loss: 4.44553e-02
I0214 16:28:58.825889 22509476222784 run_lib.py:146] step: 1099600, eval_loss: 4.22453e-02
I0214 16:29:17.661338 22509476222784 run_lib.py:133] step: 1099650, training_loss: 3.92727e-02
I0214 16:29:36.588362 22509476222784 run_lib.py:133] step: 1099700, training_loss: 3.63095e-02
I0214 16:29:36.759909 22509476222784 run_lib.py:146] step: 1099700, eval_loss: 5.60442e-02
I0214 16:29:55.656997 22509476222784 run_lib.py:133] step: 1099750, training_loss: 2.71455e-02
I0214 16:30:14.411971 22509476222784 run_lib.py:133] step: 1099800, training_loss: 5.12460e-02
I0214 16:30:14.580260 22509476222784 run_lib.py:146] step: 1099800, eval_loss: 3.27257e-02
I0214 16:30:33.521485 22509476222784 run_lib.py:133] step: 1099850, training_loss: 3.86513e-02
I0214 16:30:52.504421 22509476222784 run_lib.py:133] step: 1099900, training_loss: 4.03997e-02
I0214 16:30:52.672197 22509476222784 run_lib.py:146] step: 1099900, eval_loss: 5.59521e-02
I0214 16:31:11.518103 22509476222784 run_lib.py:133] step: 1099950, training_loss: 2.88750e-02
I0214 16:31:30.493457 22509476222784 run_lib.py:133] step: 1100000, training_loss: 4.85988e-02
I0214 16:31:34.257836 22509476222784 run_lib.py:146] step: 1100000, eval_loss: 4.16910e-02
I0214 16:31:58.821224 22509476222784 run_lib.py:133] step: 1100050, training_loss: 5.87261e-02
I0214 16:32:17.499572 22509476222784 run_lib.py:133] step: 1100100, training_loss: 3.78663e-02
I0214 16:32:17.673819 22509476222784 run_lib.py:146] step: 1100100, eval_loss: 3.72498e-02
I0214 16:32:36.664915 22509476222784 run_lib.py:133] step: 1100150, training_loss: 3.15710e-02
I0214 16:32:55.470865 22509476222784 run_lib.py:133] step: 1100200, training_loss: 4.27844e-02
I0214 16:32:55.639043 22509476222784 run_lib.py:146] step: 1100200, eval_loss: 3.74200e-02
I0214 16:33:14.505767 22509476222784 run_lib.py:133] step: 1100250, training_loss: 3.77923e-02
I0214 16:33:33.389160 22509476222784 run_lib.py:133] step: 1100300, training_loss: 4.51785e-02
I0214 16:33:33.556868 22509476222784 run_lib.py:146] step: 1100300, eval_loss: 4.47921e-02
I0214 16:33:52.280674 22509476222784 run_lib.py:133] step: 1100350, training_loss: 3.63159e-02
I0214 16:34:11.003047 22509476222784 run_lib.py:133] step: 1100400, training_loss: 3.88106e-02
I0214 16:34:11.187113 22509476222784 run_lib.py:146] step: 1100400, eval_loss: 4.24563e-02
I0214 16:34:30.260270 22509476222784 run_lib.py:133] step: 1100450, training_loss: 3.99697e-02
I0214 16:34:49.117514 22509476222784 run_lib.py:133] step: 1100500, training_loss: 4.18551e-02
I0214 16:34:49.285068 22509476222784 run_lib.py:146] step: 1100500, eval_loss: 3.67872e-02
I0214 16:35:08.122132 22509476222784 run_lib.py:133] step: 1100550, training_loss: 5.13746e-02
I0214 16:35:26.825099 22509476222784 run_lib.py:133] step: 1100600, training_loss: 4.78613e-02
I0214 16:35:26.996184 22509476222784 run_lib.py:146] step: 1100600, eval_loss: 4.98092e-02
I0214 16:35:45.872600 22509476222784 run_lib.py:133] step: 1100650, training_loss: 4.50684e-02
I0214 16:36:04.774922 22509476222784 run_lib.py:133] step: 1100700, training_loss: 4.76819e-02
I0214 16:36:04.942048 22509476222784 run_lib.py:146] step: 1100700, eval_loss: 4.26204e-02
I0214 16:36:23.953941 22509476222784 run_lib.py:133] step: 1100750, training_loss: 4.19850e-02
I0214 16:36:42.795822 22509476222784 run_lib.py:133] step: 1100800, training_loss: 3.68099e-02
I0214 16:36:42.969066 22509476222784 run_lib.py:146] step: 1100800, eval_loss: 3.43351e-02
I0214 16:37:01.894920 22509476222784 run_lib.py:133] step: 1100850, training_loss: 4.09231e-02
I0214 16:37:20.690604 22509476222784 run_lib.py:133] step: 1100900, training_loss: 4.19530e-02
I0214 16:37:20.871880 22509476222784 run_lib.py:146] step: 1100900, eval_loss: 3.98635e-02
I0214 16:37:39.792635 22509476222784 run_lib.py:133] step: 1100950, training_loss: 4.16609e-02
I0214 16:37:58.726006 22509476222784 run_lib.py:133] step: 1101000, training_loss: 3.68073e-02
I0214 16:37:58.894186 22509476222784 run_lib.py:146] step: 1101000, eval_loss: 4.32227e-02
I0214 16:38:17.795523 22509476222784 run_lib.py:133] step: 1101050, training_loss: 4.53105e-02
I0214 16:38:36.718504 22509476222784 run_lib.py:133] step: 1101100, training_loss: 5.13504e-02
I0214 16:38:36.879974 22509476222784 run_lib.py:146] step: 1101100, eval_loss: 4.28587e-02
I0214 16:38:55.721318 22509476222784 run_lib.py:133] step: 1101150, training_loss: 4.99933e-02
I0214 16:39:14.486225 22509476222784 run_lib.py:133] step: 1101200, training_loss: 4.53638e-02
I0214 16:39:14.662091 22509476222784 run_lib.py:146] step: 1101200, eval_loss: 4.04810e-02
I0214 16:39:33.663666 22509476222784 run_lib.py:133] step: 1101250, training_loss: 2.50172e-02
I0214 16:39:52.517104 22509476222784 run_lib.py:133] step: 1101300, training_loss: 3.25228e-02
I0214 16:39:52.685166 22509476222784 run_lib.py:146] step: 1101300, eval_loss: 4.85289e-02
I0214 16:40:11.415122 22509476222784 run_lib.py:133] step: 1101350, training_loss: 5.19608e-02
I0214 16:40:30.452254 22509476222784 run_lib.py:133] step: 1101400, training_loss: 4.59813e-02
I0214 16:40:30.619106 22509476222784 run_lib.py:146] step: 1101400, eval_loss: 4.21565e-02
I0214 16:40:49.387345 22509476222784 run_lib.py:133] step: 1101450, training_loss: 3.77794e-02
I0214 16:41:08.327599 22509476222784 run_lib.py:133] step: 1101500, training_loss: 4.07739e-02
I0214 16:41:08.701542 22509476222784 run_lib.py:146] step: 1101500, eval_loss: 5.23210e-02
I0214 16:41:27.536388 22509476222784 run_lib.py:133] step: 1101550, training_loss: 4.50432e-02
I0214 16:41:46.291718 22509476222784 run_lib.py:133] step: 1101600, training_loss: 4.22335e-02
I0214 16:41:46.461264 22509476222784 run_lib.py:146] step: 1101600, eval_loss: 3.84155e-02
I0214 16:42:05.186619 22509476222784 run_lib.py:133] step: 1101650, training_loss: 4.81682e-02
I0214 16:42:23.979802 22509476222784 run_lib.py:133] step: 1101700, training_loss: 4.43850e-02
I0214 16:42:24.159313 22509476222784 run_lib.py:146] step: 1101700, eval_loss: 3.58649e-02
I0214 16:42:43.275968 22509476222784 run_lib.py:133] step: 1101750, training_loss: 4.00149e-02
I0214 16:43:02.173953 22509476222784 run_lib.py:133] step: 1101800, training_loss: 4.43836e-02
I0214 16:43:02.341910 22509476222784 run_lib.py:146] step: 1101800, eval_loss: 3.88009e-02
I0214 16:43:21.192091 22509476222784 run_lib.py:133] step: 1101850, training_loss: 4.64310e-02
I0214 16:43:39.984378 22509476222784 run_lib.py:133] step: 1101900, training_loss: 2.92006e-02
I0214 16:43:40.253660 22509476222784 run_lib.py:146] step: 1101900, eval_loss: 5.56552e-02
I0214 16:43:59.246056 22509476222784 run_lib.py:133] step: 1101950, training_loss: 3.58673e-02
I0214 16:44:18.213091 22509476222784 run_lib.py:133] step: 1102000, training_loss: 5.17604e-02
I0214 16:44:18.378655 22509476222784 run_lib.py:146] step: 1102000, eval_loss: 3.41928e-02
I0214 16:44:37.159313 22509476222784 run_lib.py:133] step: 1102050, training_loss: 3.50738e-02
I0214 16:44:56.049130 22509476222784 run_lib.py:133] step: 1102100, training_loss: 2.94772e-02
I0214 16:44:56.212814 22509476222784 run_lib.py:146] step: 1102100, eval_loss: 5.69244e-02
I0214 16:45:15.107929 22509476222784 run_lib.py:133] step: 1102150, training_loss: 5.26923e-02
I0214 16:45:33.979650 22509476222784 run_lib.py:133] step: 1102200, training_loss: 3.37849e-02
I0214 16:45:34.145941 22509476222784 run_lib.py:146] step: 1102200, eval_loss: 4.02791e-02
I0214 16:45:53.073825 22509476222784 run_lib.py:133] step: 1102250, training_loss: 4.29936e-02
I0214 16:46:11.922344 22509476222784 run_lib.py:133] step: 1102300, training_loss: 4.13510e-02
I0214 16:46:12.091927 22509476222784 run_lib.py:146] step: 1102300, eval_loss: 4.85131e-02
I0214 16:46:31.107535 22509476222784 run_lib.py:133] step: 1102350, training_loss: 3.79487e-02
I0214 16:46:49.816547 22509476222784 run_lib.py:133] step: 1102400, training_loss: 4.87547e-02
I0214 16:46:49.984364 22509476222784 run_lib.py:146] step: 1102400, eval_loss: 4.46789e-02
I0214 16:47:08.779657 22509476222784 run_lib.py:133] step: 1102450, training_loss: 4.28527e-02
I0214 16:47:27.737634 22509476222784 run_lib.py:133] step: 1102500, training_loss: 4.18795e-02
I0214 16:47:27.934928 22509476222784 run_lib.py:146] step: 1102500, eval_loss: 4.29174e-02
I0214 16:47:46.842820 22509476222784 run_lib.py:133] step: 1102550, training_loss: 3.76105e-02
I0214 16:48:05.800048 22509476222784 run_lib.py:133] step: 1102600, training_loss: 3.53937e-02
I0214 16:48:05.967818 22509476222784 run_lib.py:146] step: 1102600, eval_loss: 3.87391e-02
I0214 16:48:24.691593 22509476222784 run_lib.py:133] step: 1102650, training_loss: 3.87789e-02
I0214 16:48:43.528751 22509476222784 run_lib.py:133] step: 1102700, training_loss: 4.93431e-02
I0214 16:48:43.698625 22509476222784 run_lib.py:146] step: 1102700, eval_loss: 3.91615e-02
I0214 16:49:02.665626 22509476222784 run_lib.py:133] step: 1102750, training_loss: 4.26546e-02
I0214 16:49:21.517431 22509476222784 run_lib.py:133] step: 1102800, training_loss: 4.07381e-02
I0214 16:49:21.690558 22509476222784 run_lib.py:146] step: 1102800, eval_loss: 4.73405e-02
I0214 16:49:40.486956 22509476222784 run_lib.py:133] step: 1102850, training_loss: 4.20752e-02
I0214 16:49:59.284730 22509476222784 run_lib.py:133] step: 1102900, training_loss: 2.51571e-02
I0214 16:49:59.450204 22509476222784 run_lib.py:146] step: 1102900, eval_loss: 5.21565e-02
I0214 16:50:18.493417 22509476222784 run_lib.py:133] step: 1102950, training_loss: 5.38659e-02
I0214 16:50:37.235154 22509476222784 run_lib.py:133] step: 1103000, training_loss: 4.57715e-02
I0214 16:50:37.402990 22509476222784 run_lib.py:146] step: 1103000, eval_loss: 3.70129e-02
I0214 16:50:56.406459 22509476222784 run_lib.py:133] step: 1103050, training_loss: 4.55829e-02
I0214 16:51:15.172079 22509476222784 run_lib.py:133] step: 1103100, training_loss: 2.74588e-02
I0214 16:51:15.338220 22509476222784 run_lib.py:146] step: 1103100, eval_loss: 3.65464e-02
I0214 16:51:34.087272 22509476222784 run_lib.py:133] step: 1103150, training_loss: 3.69401e-02
I0214 16:51:52.948204 22509476222784 run_lib.py:133] step: 1103200, training_loss: 4.36502e-02
I0214 16:51:53.115137 22509476222784 run_lib.py:146] step: 1103200, eval_loss: 4.72563e-02
I0214 16:52:12.077647 22509476222784 run_lib.py:133] step: 1103250, training_loss: 4.71098e-02
I0214 16:52:31.052888 22509476222784 run_lib.py:133] step: 1103300, training_loss: 4.07387e-02
I0214 16:52:31.225403 22509476222784 run_lib.py:146] step: 1103300, eval_loss: 3.69877e-02
I0214 16:52:50.008029 22509476222784 run_lib.py:133] step: 1103350, training_loss: 4.83333e-02
I0214 16:53:08.719470 22509476222784 run_lib.py:133] step: 1103400, training_loss: 4.28161e-02
I0214 16:53:08.886020 22509476222784 run_lib.py:146] step: 1103400, eval_loss: 4.35029e-02
I0214 16:53:27.891478 22509476222784 run_lib.py:133] step: 1103450, training_loss: 3.84562e-02
I0214 16:53:46.688358 22509476222784 run_lib.py:133] step: 1103500, training_loss: 3.97369e-02
I0214 16:53:46.863285 22509476222784 run_lib.py:146] step: 1103500, eval_loss: 4.32414e-02
I0214 16:54:05.968379 22509476222784 run_lib.py:133] step: 1103550, training_loss: 4.08985e-02
I0214 16:54:24.754867 22509476222784 run_lib.py:133] step: 1103600, training_loss: 5.02223e-02
I0214 16:54:24.922204 22509476222784 run_lib.py:146] step: 1103600, eval_loss: 4.13300e-02
I0214 16:54:43.926867 22509476222784 run_lib.py:133] step: 1103650, training_loss: 3.47017e-02
I0214 16:55:02.819784 22509476222784 run_lib.py:133] step: 1103700, training_loss: 3.91882e-02
I0214 16:55:02.996151 22509476222784 run_lib.py:146] step: 1103700, eval_loss: 3.78068e-02
I0214 16:55:21.934315 22509476222784 run_lib.py:133] step: 1103750, training_loss: 3.66784e-02
I0214 16:55:40.899717 22509476222784 run_lib.py:133] step: 1103800, training_loss: 3.75533e-02
I0214 16:55:41.074975 22509476222784 run_lib.py:146] step: 1103800, eval_loss: 5.15407e-02
I0214 16:55:59.828503 22509476222784 run_lib.py:133] step: 1103850, training_loss: 5.54847e-02
I0214 16:56:18.867681 22509476222784 run_lib.py:133] step: 1103900, training_loss: 3.78204e-02
I0214 16:56:19.035010 22509476222784 run_lib.py:146] step: 1103900, eval_loss: 3.27391e-02
I0214 16:56:37.772927 22509476222784 run_lib.py:133] step: 1103950, training_loss: 4.30849e-02
I0214 16:56:56.570072 22509476222784 run_lib.py:133] step: 1104000, training_loss: 3.58742e-02
I0214 16:56:56.738021 22509476222784 run_lib.py:146] step: 1104000, eval_loss: 3.76228e-02
I0214 16:57:15.805126 22509476222784 run_lib.py:133] step: 1104050, training_loss: 4.83543e-02
I0214 16:57:34.715042 22509476222784 run_lib.py:133] step: 1104100, training_loss: 4.25971e-02
I0214 16:57:34.880895 22509476222784 run_lib.py:146] step: 1104100, eval_loss: 4.44328e-02
I0214 16:57:53.658277 22509476222784 run_lib.py:133] step: 1104150, training_loss: 4.64078e-02
I0214 16:58:12.371405 22509476222784 run_lib.py:133] step: 1104200, training_loss: 4.78460e-02
I0214 16:58:12.539127 22509476222784 run_lib.py:146] step: 1104200, eval_loss: 4.55536e-02
I0214 16:58:31.379817 22509476222784 run_lib.py:133] step: 1104250, training_loss: 3.92214e-02
I0214 16:58:50.395453 22509476222784 run_lib.py:133] step: 1104300, training_loss: 4.10359e-02
I0214 16:58:50.562170 22509476222784 run_lib.py:146] step: 1104300, eval_loss: 5.04935e-02
I0214 16:59:09.253121 22509476222784 run_lib.py:133] step: 1104350, training_loss: 4.04850e-02
I0214 16:59:28.058772 22509476222784 run_lib.py:133] step: 1104400, training_loss: 5.10463e-02
I0214 16:59:28.224065 22509476222784 run_lib.py:146] step: 1104400, eval_loss: 4.39210e-02
I0214 16:59:46.960529 22509476222784 run_lib.py:133] step: 1104450, training_loss: 5.12229e-02
I0214 17:00:05.983571 22509476222784 run_lib.py:133] step: 1104500, training_loss: 4.58564e-02
I0214 17:00:06.155239 22509476222784 run_lib.py:146] step: 1104500, eval_loss: 4.33384e-02
I0214 17:00:24.993031 22509476222784 run_lib.py:133] step: 1104550, training_loss: 4.28722e-02
I0214 17:00:43.848001 22509476222784 run_lib.py:133] step: 1104600, training_loss: 4.38324e-02
I0214 17:00:44.019969 22509476222784 run_lib.py:146] step: 1104600, eval_loss: 3.64195e-02
I0214 17:01:02.875334 22509476222784 run_lib.py:133] step: 1104650, training_loss: 3.48754e-02
I0214 17:01:21.603662 22509476222784 run_lib.py:133] step: 1104700, training_loss: 3.47357e-02
I0214 17:01:21.775076 22509476222784 run_lib.py:146] step: 1104700, eval_loss: 4.80802e-02
I0214 17:01:40.716552 22509476222784 run_lib.py:133] step: 1104750, training_loss: 3.52908e-02
I0214 17:01:59.597452 22509476222784 run_lib.py:133] step: 1104800, training_loss: 6.15691e-02
I0214 17:01:59.763413 22509476222784 run_lib.py:146] step: 1104800, eval_loss: 4.78350e-02
I0214 17:02:18.589570 22509476222784 run_lib.py:133] step: 1104850, training_loss: 5.62693e-02
I0214 17:02:37.346810 22509476222784 run_lib.py:133] step: 1104900, training_loss: 3.93656e-02
I0214 17:02:37.512653 22509476222784 run_lib.py:146] step: 1104900, eval_loss: 4.45651e-02
I0214 17:02:56.404339 22509476222784 run_lib.py:133] step: 1104950, training_loss: 5.18237e-02
I0214 17:03:15.235172 22509476222784 run_lib.py:133] step: 1105000, training_loss: 3.46819e-02
I0214 17:03:15.405051 22509476222784 run_lib.py:146] step: 1105000, eval_loss: 3.41576e-02
I0214 17:03:34.365564 22509476222784 run_lib.py:133] step: 1105050, training_loss: 3.56327e-02
I0214 17:03:53.335750 22509476222784 run_lib.py:133] step: 1105100, training_loss: 4.09347e-02
I0214 17:03:53.512869 22509476222784 run_lib.py:146] step: 1105100, eval_loss: 5.11313e-02
I0214 17:04:12.497601 22509476222784 run_lib.py:133] step: 1105150, training_loss: 3.57876e-02
I0214 17:04:31.219982 22509476222784 run_lib.py:133] step: 1105200, training_loss: 3.28501e-02
I0214 17:04:31.385895 22509476222784 run_lib.py:146] step: 1105200, eval_loss: 3.59015e-02
I0214 17:04:50.276115 22509476222784 run_lib.py:133] step: 1105250, training_loss: 4.43047e-02
I0214 17:05:09.237545 22509476222784 run_lib.py:133] step: 1105300, training_loss: 4.81882e-02
I0214 17:05:09.405619 22509476222784 run_lib.py:146] step: 1105300, eval_loss: 3.69425e-02
I0214 17:05:28.297760 22509476222784 run_lib.py:133] step: 1105350, training_loss: 4.65219e-02
I0214 17:05:47.252914 22509476222784 run_lib.py:133] step: 1105400, training_loss: 3.41755e-02
I0214 17:05:47.432554 22509476222784 run_lib.py:146] step: 1105400, eval_loss: 4.21871e-02
I0214 17:06:06.155039 22509476222784 run_lib.py:133] step: 1105450, training_loss: 3.74032e-02
I0214 17:06:25.001181 22509476222784 run_lib.py:133] step: 1105500, training_loss: 4.21843e-02
I0214 17:06:25.178275 22509476222784 run_lib.py:146] step: 1105500, eval_loss: 4.34325e-02
I0214 17:06:44.158613 22509476222784 run_lib.py:133] step: 1105550, training_loss: 3.43679e-02
I0214 17:07:02.930462 22509476222784 run_lib.py:133] step: 1105600, training_loss: 4.96503e-02
I0214 17:07:03.098957 22509476222784 run_lib.py:146] step: 1105600, eval_loss: 4.55313e-02
I0214 17:07:21.962233 22509476222784 run_lib.py:133] step: 1105650, training_loss: 2.97192e-02
I0214 17:07:40.867298 22509476222784 run_lib.py:133] step: 1105700, training_loss: 3.34055e-02
I0214 17:07:41.032835 22509476222784 run_lib.py:146] step: 1105700, eval_loss: 3.78031e-02
I0214 17:07:59.774427 22509476222784 run_lib.py:133] step: 1105750, training_loss: 3.38393e-02
I0214 17:08:18.701579 22509476222784 run_lib.py:133] step: 1105800, training_loss: 3.86862e-02
I0214 17:08:18.868798 22509476222784 run_lib.py:146] step: 1105800, eval_loss: 4.74525e-02
I0214 17:08:37.768504 22509476222784 run_lib.py:133] step: 1105850, training_loss: 4.10712e-02
I0214 17:08:56.591781 22509476222784 run_lib.py:133] step: 1105900, training_loss: 3.78505e-02
I0214 17:08:56.755057 22509476222784 run_lib.py:146] step: 1105900, eval_loss: 3.71447e-02
I0214 17:09:15.466035 22509476222784 run_lib.py:133] step: 1105950, training_loss: 4.56594e-02
I0214 17:09:34.339259 22509476222784 run_lib.py:133] step: 1106000, training_loss: 3.47667e-02
I0214 17:09:34.521198 22509476222784 run_lib.py:146] step: 1106000, eval_loss: 4.11022e-02
I0214 17:09:53.523180 22509476222784 run_lib.py:133] step: 1106050, training_loss: 3.43069e-02
I0214 17:10:12.405660 22509476222784 run_lib.py:133] step: 1106100, training_loss: 3.27418e-02
I0214 17:10:12.572997 22509476222784 run_lib.py:146] step: 1106100, eval_loss: 3.13779e-02
I0214 17:10:31.415151 22509476222784 run_lib.py:133] step: 1106150, training_loss: 4.71835e-02
I0214 17:10:50.117553 22509476222784 run_lib.py:133] step: 1106200, training_loss: 4.12339e-02
I0214 17:10:50.283974 22509476222784 run_lib.py:146] step: 1106200, eval_loss: 3.87100e-02
I0214 17:11:09.307017 22509476222784 run_lib.py:133] step: 1106250, training_loss: 5.03783e-02
I0214 17:11:28.104167 22509476222784 run_lib.py:133] step: 1106300, training_loss: 5.45966e-02
I0214 17:11:28.277926 22509476222784 run_lib.py:146] step: 1106300, eval_loss: 3.18989e-02
I0214 17:11:47.268766 22509476222784 run_lib.py:133] step: 1106350, training_loss: 4.79315e-02
I0214 17:12:06.108422 22509476222784 run_lib.py:133] step: 1106400, training_loss: 4.19440e-02
I0214 17:12:06.272883 22509476222784 run_lib.py:146] step: 1106400, eval_loss: 4.19175e-02
I0214 17:12:25.152141 22509476222784 run_lib.py:133] step: 1106450, training_loss: 3.87584e-02
I0214 17:12:44.058581 22509476222784 run_lib.py:133] step: 1106500, training_loss: 3.41203e-02
I0214 17:12:44.239897 22509476222784 run_lib.py:146] step: 1106500, eval_loss: 4.20382e-02
I0214 17:13:03.238729 22509476222784 run_lib.py:133] step: 1106550, training_loss: 4.11595e-02
I0214 17:13:22.166821 22509476222784 run_lib.py:133] step: 1106600, training_loss: 3.67653e-02
I0214 17:13:22.336954 22509476222784 run_lib.py:146] step: 1106600, eval_loss: 4.14627e-02
I0214 17:13:41.105803 22509476222784 run_lib.py:133] step: 1106650, training_loss: 4.22301e-02
I0214 17:13:59.957288 22509476222784 run_lib.py:133] step: 1106700, training_loss: 5.10844e-02
I0214 17:14:00.124057 22509476222784 run_lib.py:146] step: 1106700, eval_loss: 4.05446e-02
I0214 17:14:19.004797 22509476222784 run_lib.py:133] step: 1106750, training_loss: 3.60618e-02
I0214 17:14:37.771331 22509476222784 run_lib.py:133] step: 1106800, training_loss: 5.00131e-02
I0214 17:14:37.935573 22509476222784 run_lib.py:146] step: 1106800, eval_loss: 3.82556e-02
I0214 17:14:56.884265 22509476222784 run_lib.py:133] step: 1106850, training_loss: 4.62346e-02
I0214 17:15:15.718941 22509476222784 run_lib.py:133] step: 1106900, training_loss: 3.28765e-02
I0214 17:15:15.882928 22509476222784 run_lib.py:146] step: 1106900, eval_loss: 3.51310e-02
I0214 17:15:34.799554 22509476222784 run_lib.py:133] step: 1106950, training_loss: 4.22500e-02
I0214 17:15:53.745521 22509476222784 run_lib.py:133] step: 1107000, training_loss: 5.00756e-02
I0214 17:15:53.928828 22509476222784 run_lib.py:146] step: 1107000, eval_loss: 4.58561e-02
I0214 17:16:12.723245 22509476222784 run_lib.py:133] step: 1107050, training_loss: 4.00275e-02
I0214 17:16:31.702316 22509476222784 run_lib.py:133] step: 1107100, training_loss: 4.85174e-02
I0214 17:16:31.872756 22509476222784 run_lib.py:146] step: 1107100, eval_loss: 4.87533e-02
I0214 17:16:50.707188 22509476222784 run_lib.py:133] step: 1107150, training_loss: 2.47872e-02
I0214 17:17:09.404485 22509476222784 run_lib.py:133] step: 1107200, training_loss: 3.88388e-02
I0214 17:17:09.579041 22509476222784 run_lib.py:146] step: 1107200, eval_loss: 5.62052e-02
I0214 17:17:28.451149 22509476222784 run_lib.py:133] step: 1107250, training_loss: 3.35307e-02
I0214 17:17:47.418647 22509476222784 run_lib.py:133] step: 1107300, training_loss: 4.46565e-02
I0214 17:17:47.590272 22509476222784 run_lib.py:146] step: 1107300, eval_loss: 4.27334e-02
I0214 17:18:06.517554 22509476222784 run_lib.py:133] step: 1107350, training_loss: 4.30956e-02
I0214 17:18:25.341130 22509476222784 run_lib.py:133] step: 1107400, training_loss: 3.52174e-02
I0214 17:18:25.508968 22509476222784 run_lib.py:146] step: 1107400, eval_loss: 4.34912e-02
I0214 17:18:44.256794 22509476222784 run_lib.py:133] step: 1107450, training_loss: 3.65147e-02
I0214 17:19:03.121589 22509476222784 run_lib.py:133] step: 1107500, training_loss: 3.90895e-02
I0214 17:19:03.308036 22509476222784 run_lib.py:146] step: 1107500, eval_loss: 3.91621e-02
I0214 17:19:22.203522 22509476222784 run_lib.py:133] step: 1107550, training_loss: 4.10653e-02
I0214 17:19:41.235896 22509476222784 run_lib.py:133] step: 1107600, training_loss: 4.78381e-02
I0214 17:19:41.402088 22509476222784 run_lib.py:146] step: 1107600, eval_loss: 4.38190e-02
I0214 17:20:00.133023 22509476222784 run_lib.py:133] step: 1107650, training_loss: 4.63671e-02
I0214 17:20:18.872727 22509476222784 run_lib.py:133] step: 1107700, training_loss: 4.08926e-02
I0214 17:20:19.039926 22509476222784 run_lib.py:146] step: 1107700, eval_loss: 4.42021e-02
I0214 17:20:37.968584 22509476222784 run_lib.py:133] step: 1107750, training_loss: 4.42855e-02
I0214 17:20:56.772123 22509476222784 run_lib.py:133] step: 1107800, training_loss: 3.89648e-02
I0214 17:20:56.938884 22509476222784 run_lib.py:146] step: 1107800, eval_loss: 4.36361e-02
I0214 17:21:16.085577 22509476222784 run_lib.py:133] step: 1107850, training_loss: 4.08898e-02
I0214 17:21:34.887270 22509476222784 run_lib.py:133] step: 1107900, training_loss: 4.01736e-02
I0214 17:21:35.054453 22509476222784 run_lib.py:146] step: 1107900, eval_loss: 3.72797e-02
I0214 17:21:54.006892 22509476222784 run_lib.py:133] step: 1107950, training_loss: 2.89570e-02
I0214 17:22:12.801617 22509476222784 run_lib.py:133] step: 1108000, training_loss: 3.46874e-02
I0214 17:22:12.992506 22509476222784 run_lib.py:146] step: 1108000, eval_loss: 4.56036e-02
I0214 17:22:31.783244 22509476222784 run_lib.py:133] step: 1108050, training_loss: 4.03652e-02
I0214 17:22:50.916192 22509476222784 run_lib.py:133] step: 1108100, training_loss: 3.34153e-02
I0214 17:22:51.084167 22509476222784 run_lib.py:146] step: 1108100, eval_loss: 4.23630e-02
I0214 17:23:09.873269 22509476222784 run_lib.py:133] step: 1108150, training_loss: 4.56997e-02
I0214 17:23:28.922363 22509476222784 run_lib.py:133] step: 1108200, training_loss: 4.66969e-02
I0214 17:23:29.118378 22509476222784 run_lib.py:146] step: 1108200, eval_loss: 5.19003e-02
I0214 17:23:47.893051 22509476222784 run_lib.py:133] step: 1108250, training_loss: 5.08723e-02
I0214 17:24:06.676919 22509476222784 run_lib.py:133] step: 1108300, training_loss: 3.61585e-02
I0214 17:24:06.846788 22509476222784 run_lib.py:146] step: 1108300, eval_loss: 4.04926e-02
I0214 17:24:25.940319 22509476222784 run_lib.py:133] step: 1108350, training_loss: 2.89224e-02
I0214 17:24:44.744503 22509476222784 run_lib.py:133] step: 1108400, training_loss: 3.37185e-02
I0214 17:24:44.913914 22509476222784 run_lib.py:146] step: 1108400, eval_loss: 3.78563e-02
I0214 17:25:03.730996 22509476222784 run_lib.py:133] step: 1108450, training_loss: 4.72331e-02
I0214 17:25:22.670115 22509476222784 run_lib.py:133] step: 1108500, training_loss: 4.47751e-02
I0214 17:25:22.851632 22509476222784 run_lib.py:146] step: 1108500, eval_loss: 4.56809e-02
I0214 17:25:41.668808 22509476222784 run_lib.py:133] step: 1108550, training_loss: 3.31944e-02
I0214 17:26:00.481467 22509476222784 run_lib.py:133] step: 1108600, training_loss: 4.06930e-02
I0214 17:26:00.843224 22509476222784 run_lib.py:146] step: 1108600, eval_loss: 3.70339e-02
I0214 17:26:19.557309 22509476222784 run_lib.py:133] step: 1108650, training_loss: 3.09541e-02
I0214 17:26:38.380559 22509476222784 run_lib.py:133] step: 1108700, training_loss: 4.36364e-02
I0214 17:26:38.552956 22509476222784 run_lib.py:146] step: 1108700, eval_loss: 3.92898e-02
I0214 17:26:57.316445 22509476222784 run_lib.py:133] step: 1108750, training_loss: 5.65033e-02
I0214 17:27:16.053189 22509476222784 run_lib.py:133] step: 1108800, training_loss: 3.81608e-02
I0214 17:27:16.220991 22509476222784 run_lib.py:146] step: 1108800, eval_loss: 5.93947e-02
I0214 17:27:35.064438 22509476222784 run_lib.py:133] step: 1108850, training_loss: 4.81042e-02
I0214 17:27:53.870514 22509476222784 run_lib.py:133] step: 1108900, training_loss: 4.71296e-02
I0214 17:27:54.045183 22509476222784 run_lib.py:146] step: 1108900, eval_loss: 4.30948e-02
I0214 17:28:12.860248 22509476222784 run_lib.py:133] step: 1108950, training_loss: 3.66118e-02
I0214 17:28:31.595664 22509476222784 run_lib.py:133] step: 1109000, training_loss: 4.24081e-02
I0214 17:28:31.785949 22509476222784 run_lib.py:146] step: 1109000, eval_loss: 4.69595e-02
I0214 17:28:50.911954 22509476222784 run_lib.py:133] step: 1109050, training_loss: 5.32941e-02
I0214 17:29:09.812191 22509476222784 run_lib.py:133] step: 1109100, training_loss: 4.32811e-02
I0214 17:29:09.978567 22509476222784 run_lib.py:146] step: 1109100, eval_loss: 4.43538e-02
I0214 17:29:28.848567 22509476222784 run_lib.py:133] step: 1109150, training_loss: 3.48274e-02
I0214 17:29:47.609971 22509476222784 run_lib.py:133] step: 1109200, training_loss: 4.05421e-02
I0214 17:29:47.772753 22509476222784 run_lib.py:146] step: 1109200, eval_loss: 4.76086e-02
I0214 17:30:06.700859 22509476222784 run_lib.py:133] step: 1109250, training_loss: 4.04422e-02
I0214 17:30:25.566989 22509476222784 run_lib.py:133] step: 1109300, training_loss: 3.45030e-02
I0214 17:30:25.746203 22509476222784 run_lib.py:146] step: 1109300, eval_loss: 3.73814e-02
I0214 17:30:44.731882 22509476222784 run_lib.py:133] step: 1109350, training_loss: 4.59815e-02
I0214 17:31:03.564948 22509476222784 run_lib.py:133] step: 1109400, training_loss: 5.45612e-02
I0214 17:31:03.734133 22509476222784 run_lib.py:146] step: 1109400, eval_loss: 4.46865e-02
I0214 17:31:22.644399 22509476222784 run_lib.py:133] step: 1109450, training_loss: 4.05168e-02
I0214 17:31:41.450388 22509476222784 run_lib.py:133] step: 1109500, training_loss: 3.98043e-02
I0214 17:31:41.614800 22509476222784 run_lib.py:146] step: 1109500, eval_loss: 4.28763e-02
I0214 17:32:00.456934 22509476222784 run_lib.py:133] step: 1109550, training_loss: 4.10366e-02
I0214 17:32:19.434306 22509476222784 run_lib.py:133] step: 1109600, training_loss: 3.38935e-02
I0214 17:32:19.601004 22509476222784 run_lib.py:146] step: 1109600, eval_loss: 4.79624e-02
I0214 17:32:38.526494 22509476222784 run_lib.py:133] step: 1109650, training_loss: 4.54221e-02
I0214 17:32:57.452108 22509476222784 run_lib.py:133] step: 1109700, training_loss: 4.90773e-02
I0214 17:32:57.614905 22509476222784 run_lib.py:146] step: 1109700, eval_loss: 4.95787e-02
I0214 17:33:16.465264 22509476222784 run_lib.py:133] step: 1109750, training_loss: 4.59427e-02
I0214 17:33:35.269083 22509476222784 run_lib.py:133] step: 1109800, training_loss: 4.80838e-02
I0214 17:33:35.475890 22509476222784 run_lib.py:146] step: 1109800, eval_loss: 3.92430e-02
I0214 17:33:54.459530 22509476222784 run_lib.py:133] step: 1109850, training_loss: 4.20234e-02
I0214 17:34:13.397747 22509476222784 run_lib.py:133] step: 1109900, training_loss: 3.95312e-02
I0214 17:34:13.565873 22509476222784 run_lib.py:146] step: 1109900, eval_loss: 4.10498e-02
I0214 17:34:32.255491 22509476222784 run_lib.py:133] step: 1109950, training_loss: 3.71053e-02
I0214 17:34:51.038235 22509476222784 run_lib.py:133] step: 1110000, training_loss: 4.35467e-02
I0214 17:34:51.821891 22509476222784 run_lib.py:146] step: 1110000, eval_loss: 3.08516e-02
I0214 17:35:13.416606 22509476222784 run_lib.py:133] step: 1110050, training_loss: 4.57341e-02
I0214 17:35:32.357930 22509476222784 run_lib.py:133] step: 1110100, training_loss: 4.10205e-02
I0214 17:35:32.535348 22509476222784 run_lib.py:146] step: 1110100, eval_loss: 5.21075e-02
I0214 17:35:51.345696 22509476222784 run_lib.py:133] step: 1110150, training_loss: 3.65700e-02
I0214 17:36:10.116731 22509476222784 run_lib.py:133] step: 1110200, training_loss: 3.67281e-02
I0214 17:36:10.279943 22509476222784 run_lib.py:146] step: 1110200, eval_loss: 4.99506e-02
I0214 17:36:29.335656 22509476222784 run_lib.py:133] step: 1110250, training_loss: 5.31592e-02
I0214 17:36:48.096888 22509476222784 run_lib.py:133] step: 1110300, training_loss: 4.57866e-02
I0214 17:36:48.261836 22509476222784 run_lib.py:146] step: 1110300, eval_loss: 3.63708e-02
I0214 17:37:07.086649 22509476222784 run_lib.py:133] step: 1110350, training_loss: 4.02826e-02
I0214 17:37:25.925982 22509476222784 run_lib.py:133] step: 1110400, training_loss: 3.89054e-02
I0214 17:37:26.108934 22509476222784 run_lib.py:146] step: 1110400, eval_loss: 4.65055e-02
I0214 17:37:45.067535 22509476222784 run_lib.py:133] step: 1110450, training_loss: 4.90711e-02
I0214 17:38:03.925687 22509476222784 run_lib.py:133] step: 1110500, training_loss: 3.17681e-02
I0214 17:38:04.092167 22509476222784 run_lib.py:146] step: 1110500, eval_loss: 4.64682e-02
I0214 17:38:22.910355 22509476222784 run_lib.py:133] step: 1110550, training_loss: 4.40105e-02
I0214 17:38:41.738646 22509476222784 run_lib.py:133] step: 1110600, training_loss: 3.94217e-02
I0214 17:38:41.905889 22509476222784 run_lib.py:146] step: 1110600, eval_loss: 4.16340e-02
I0214 17:39:00.621973 22509476222784 run_lib.py:133] step: 1110650, training_loss: 4.44067e-02
I0214 17:39:19.390987 22509476222784 run_lib.py:133] step: 1110700, training_loss: 4.92316e-02
I0214 17:39:19.557060 22509476222784 run_lib.py:146] step: 1110700, eval_loss: 4.14235e-02
I0214 17:39:38.579878 22509476222784 run_lib.py:133] step: 1110750, training_loss: 3.86554e-02
I0214 17:39:57.426537 22509476222784 run_lib.py:133] step: 1110800, training_loss: 4.52763e-02
I0214 17:39:57.591888 22509476222784 run_lib.py:146] step: 1110800, eval_loss: 4.31330e-02
I0214 17:40:16.415910 22509476222784 run_lib.py:133] step: 1110850, training_loss: 3.52735e-02
I0214 17:40:35.136398 22509476222784 run_lib.py:133] step: 1110900, training_loss: 4.21747e-02
I0214 17:40:35.308231 22509476222784 run_lib.py:146] step: 1110900, eval_loss: 3.66642e-02
I0214 17:40:54.278186 22509476222784 run_lib.py:133] step: 1110950, training_loss: 4.09993e-02
I0214 17:41:13.148071 22509476222784 run_lib.py:133] step: 1111000, training_loss: 4.66351e-02
I0214 17:41:13.314066 22509476222784 run_lib.py:146] step: 1111000, eval_loss: 3.19609e-02
I0214 17:41:32.201917 22509476222784 run_lib.py:133] step: 1111050, training_loss: 3.54441e-02
I0214 17:41:51.027626 22509476222784 run_lib.py:133] step: 1111100, training_loss: 4.01304e-02
I0214 17:41:51.194159 22509476222784 run_lib.py:146] step: 1111100, eval_loss: 4.84739e-02
I0214 17:42:10.069154 22509476222784 run_lib.py:133] step: 1111150, training_loss: 4.93345e-02
I0214 17:42:28.879271 22509476222784 run_lib.py:133] step: 1111200, training_loss: 4.37229e-02
I0214 17:42:29.043263 22509476222784 run_lib.py:146] step: 1111200, eval_loss: 3.91713e-02
I0214 17:42:48.063353 22509476222784 run_lib.py:133] step: 1111250, training_loss: 3.88372e-02
I0214 17:43:06.828430 22509476222784 run_lib.py:133] step: 1111300, training_loss: 3.47848e-02
I0214 17:43:07.005885 22509476222784 run_lib.py:146] step: 1111300, eval_loss: 5.68229e-02
I0214 17:43:25.795414 22509476222784 run_lib.py:133] step: 1111350, training_loss: 4.46345e-02
I0214 17:43:44.690944 22509476222784 run_lib.py:133] step: 1111400, training_loss: 5.18371e-02
I0214 17:43:44.854927 22509476222784 run_lib.py:146] step: 1111400, eval_loss: 3.38073e-02
I0214 17:44:03.604340 22509476222784 run_lib.py:133] step: 1111450, training_loss: 4.06671e-02
I0214 17:44:22.355512 22509476222784 run_lib.py:133] step: 1111500, training_loss: 4.14268e-02
I0214 17:44:22.521955 22509476222784 run_lib.py:146] step: 1111500, eval_loss: 3.71562e-02
I0214 17:44:41.581853 22509476222784 run_lib.py:133] step: 1111550, training_loss: 3.72967e-02
I0214 17:45:00.378447 22509476222784 run_lib.py:133] step: 1111600, training_loss: 4.43338e-02
I0214 17:45:00.542710 22509476222784 run_lib.py:146] step: 1111600, eval_loss: 3.45830e-02
I0214 17:45:19.547002 22509476222784 run_lib.py:133] step: 1111650, training_loss: 3.96548e-02
I0214 17:45:38.466177 22509476222784 run_lib.py:133] step: 1111700, training_loss: 4.55683e-02
I0214 17:45:38.629131 22509476222784 run_lib.py:146] step: 1111700, eval_loss: 4.33985e-02
I0214 17:45:57.348140 22509476222784 run_lib.py:133] step: 1111750, training_loss: 4.36206e-02
I0214 17:46:16.428398 22509476222784 run_lib.py:133] step: 1111800, training_loss: 2.28569e-02
I0214 17:46:16.610076 22509476222784 run_lib.py:146] step: 1111800, eval_loss: 4.09269e-02
I0214 17:46:35.379098 22509476222784 run_lib.py:133] step: 1111850, training_loss: 3.19764e-02
I0214 17:46:54.200510 22509476222784 run_lib.py:133] step: 1111900, training_loss: 3.34668e-02
I0214 17:46:54.371384 22509476222784 run_lib.py:146] step: 1111900, eval_loss: 3.87957e-02
I0214 17:47:13.216602 22509476222784 run_lib.py:133] step: 1111950, training_loss: 4.30927e-02
I0214 17:47:32.135391 22509476222784 run_lib.py:133] step: 1112000, training_loss: 3.92084e-02
I0214 17:47:32.315358 22509476222784 run_lib.py:146] step: 1112000, eval_loss: 4.99633e-02
I0214 17:47:51.239412 22509476222784 run_lib.py:133] step: 1112050, training_loss: 3.47959e-02
I0214 17:48:10.174398 22509476222784 run_lib.py:133] step: 1112100, training_loss: 3.74623e-02
I0214 17:48:10.337255 22509476222784 run_lib.py:146] step: 1112100, eval_loss: 3.41382e-02
I0214 17:48:29.171200 22509476222784 run_lib.py:133] step: 1112150, training_loss: 3.54452e-02
I0214 17:48:48.005788 22509476222784 run_lib.py:133] step: 1112200, training_loss: 4.87596e-02
I0214 17:48:48.171738 22509476222784 run_lib.py:146] step: 1112200, eval_loss: 4.49356e-02
I0214 17:49:07.037758 22509476222784 run_lib.py:133] step: 1112250, training_loss: 3.63027e-02
I0214 17:49:25.997971 22509476222784 run_lib.py:133] step: 1112300, training_loss: 4.78180e-02
I0214 17:49:26.182465 22509476222784 run_lib.py:146] step: 1112300, eval_loss: 4.29469e-02
I0214 17:49:44.959932 22509476222784 run_lib.py:133] step: 1112350, training_loss: 4.16058e-02
I0214 17:50:03.812838 22509476222784 run_lib.py:133] step: 1112400, training_loss: 3.75620e-02
I0214 17:50:03.983047 22509476222784 run_lib.py:146] step: 1112400, eval_loss: 3.90792e-02
I0214 17:50:22.979335 22509476222784 run_lib.py:133] step: 1112450, training_loss: 3.12072e-02
I0214 17:50:41.736268 22509476222784 run_lib.py:133] step: 1112500, training_loss: 5.11748e-02
I0214 17:50:41.913022 22509476222784 run_lib.py:146] step: 1112500, eval_loss: 4.49064e-02
I0214 17:51:00.973928 22509476222784 run_lib.py:133] step: 1112550, training_loss: 5.31089e-02
I0214 17:51:19.732957 22509476222784 run_lib.py:133] step: 1112600, training_loss: 4.34548e-02
I0214 17:51:19.906176 22509476222784 run_lib.py:146] step: 1112600, eval_loss: 3.58775e-02
I0214 17:51:39.024465 22509476222784 run_lib.py:133] step: 1112650, training_loss: 3.00919e-02
I0214 17:51:57.830925 22509476222784 run_lib.py:133] step: 1112700, training_loss: 3.90881e-02
I0214 17:51:58.012988 22509476222784 run_lib.py:146] step: 1112700, eval_loss: 4.14395e-02
I0214 17:52:16.750593 22509476222784 run_lib.py:133] step: 1112750, training_loss: 4.04674e-02
I0214 17:52:35.796068 22509476222784 run_lib.py:133] step: 1112800, training_loss: 4.59410e-02
I0214 17:52:35.976950 22509476222784 run_lib.py:146] step: 1112800, eval_loss: 4.89801e-02
I0214 17:52:54.776792 22509476222784 run_lib.py:133] step: 1112850, training_loss: 4.10811e-02
I0214 17:53:13.892361 22509476222784 run_lib.py:133] step: 1112900, training_loss: 3.80251e-02
I0214 17:53:14.065231 22509476222784 run_lib.py:146] step: 1112900, eval_loss: 4.11456e-02
I0214 17:53:32.805773 22509476222784 run_lib.py:133] step: 1112950, training_loss: 4.86942e-02
I0214 17:53:51.547555 22509476222784 run_lib.py:133] step: 1113000, training_loss: 3.93688e-02
I0214 17:53:51.716084 22509476222784 run_lib.py:146] step: 1113000, eval_loss: 4.29954e-02
I0214 17:54:10.633066 22509476222784 run_lib.py:133] step: 1113050, training_loss: 4.27958e-02
I0214 17:54:29.438222 22509476222784 run_lib.py:133] step: 1113100, training_loss: 4.62929e-02
I0214 17:54:29.607560 22509476222784 run_lib.py:146] step: 1113100, eval_loss: 5.14231e-02
I0214 17:54:48.566613 22509476222784 run_lib.py:133] step: 1113150, training_loss: 3.97682e-02
I0214 17:55:07.502426 22509476222784 run_lib.py:133] step: 1113200, training_loss: 4.66952e-02
I0214 17:55:07.679020 22509476222784 run_lib.py:146] step: 1113200, eval_loss: 5.72519e-02
I0214 17:55:26.521495 22509476222784 run_lib.py:133] step: 1113250, training_loss: 4.67051e-02
I0214 17:55:45.204027 22509476222784 run_lib.py:133] step: 1113300, training_loss: 3.82106e-02
I0214 17:55:45.527198 22509476222784 run_lib.py:146] step: 1113300, eval_loss: 4.29698e-02
I0214 17:56:04.464111 22509476222784 run_lib.py:133] step: 1113350, training_loss: 3.91685e-02
I0214 17:56:23.268948 22509476222784 run_lib.py:133] step: 1113400, training_loss: 3.49491e-02
I0214 17:56:23.436450 22509476222784 run_lib.py:146] step: 1113400, eval_loss: 4.72777e-02
I0214 17:56:42.192589 22509476222784 run_lib.py:133] step: 1113450, training_loss: 4.23418e-02
I0214 17:57:00.959338 22509476222784 run_lib.py:133] step: 1113500, training_loss: 4.59354e-02
I0214 17:57:01.125040 22509476222784 run_lib.py:146] step: 1113500, eval_loss: 4.56615e-02
I0214 17:57:20.048528 22509476222784 run_lib.py:133] step: 1113550, training_loss: 4.16968e-02
I0214 17:57:38.990233 22509476222784 run_lib.py:133] step: 1113600, training_loss: 5.53479e-02
I0214 17:57:39.164410 22509476222784 run_lib.py:146] step: 1113600, eval_loss: 3.23291e-02
I0214 17:57:57.986821 22509476222784 run_lib.py:133] step: 1113650, training_loss: 3.97366e-02
I0214 17:58:16.792691 22509476222784 run_lib.py:133] step: 1113700, training_loss: 5.06511e-02
I0214 17:58:16.970063 22509476222784 run_lib.py:146] step: 1113700, eval_loss: 4.49787e-02
I0214 17:58:35.881881 22509476222784 run_lib.py:133] step: 1113750, training_loss: 4.99084e-02
I0214 17:58:54.662550 22509476222784 run_lib.py:133] step: 1113800, training_loss: 4.63732e-02
I0214 17:58:54.832919 22509476222784 run_lib.py:146] step: 1113800, eval_loss: 3.83242e-02
I0214 17:59:13.688956 22509476222784 run_lib.py:133] step: 1113850, training_loss: 4.43696e-02
I0214 17:59:32.505115 22509476222784 run_lib.py:133] step: 1113900, training_loss: 3.03828e-02
I0214 17:59:32.671770 22509476222784 run_lib.py:146] step: 1113900, eval_loss: 4.01323e-02
I0214 17:59:51.828121 22509476222784 run_lib.py:133] step: 1113950, training_loss: 4.05219e-02
I0214 18:00:10.601095 22509476222784 run_lib.py:133] step: 1114000, training_loss: 4.45632e-02
I0214 18:00:10.763754 22509476222784 run_lib.py:146] step: 1114000, eval_loss: 4.56210e-02
I0214 18:00:29.737377 22509476222784 run_lib.py:133] step: 1114050, training_loss: 4.36538e-02
I0214 18:00:48.539344 22509476222784 run_lib.py:133] step: 1114100, training_loss: 3.14943e-02
I0214 18:00:48.713243 22509476222784 run_lib.py:146] step: 1114100, eval_loss: 3.57705e-02
I0214 18:01:07.717094 22509476222784 run_lib.py:133] step: 1114150, training_loss: 4.38507e-02
I0214 18:01:26.650423 22509476222784 run_lib.py:133] step: 1114200, training_loss: 3.24296e-02
I0214 18:01:26.826946 22509476222784 run_lib.py:146] step: 1114200, eval_loss: 5.23469e-02
I0214 18:01:45.616956 22509476222784 run_lib.py:133] step: 1114250, training_loss: 3.33185e-02
I0214 18:02:04.608289 22509476222784 run_lib.py:133] step: 1114300, training_loss: 3.71185e-02
I0214 18:02:04.774314 22509476222784 run_lib.py:146] step: 1114300, eval_loss: 4.89322e-02
I0214 18:02:23.559548 22509476222784 run_lib.py:133] step: 1114350, training_loss: 3.68182e-02
I0214 18:02:42.599315 22509476222784 run_lib.py:133] step: 1114400, training_loss: 4.56610e-02
I0214 18:02:42.770941 22509476222784 run_lib.py:146] step: 1114400, eval_loss: 4.52914e-02
I0214 18:03:01.596844 22509476222784 run_lib.py:133] step: 1114450, training_loss: 4.71655e-02
I0214 18:03:20.315793 22509476222784 run_lib.py:133] step: 1114500, training_loss: 4.42847e-02
I0214 18:03:20.512367 22509476222784 run_lib.py:146] step: 1114500, eval_loss: 4.26467e-02
I0214 18:03:39.511455 22509476222784 run_lib.py:133] step: 1114550, training_loss: 4.59476e-02
I0214 18:03:58.261688 22509476222784 run_lib.py:133] step: 1114600, training_loss: 4.18477e-02
I0214 18:03:58.428954 22509476222784 run_lib.py:146] step: 1114600, eval_loss: 3.65579e-02
I0214 18:04:17.224662 22509476222784 run_lib.py:133] step: 1114650, training_loss: 4.11227e-02
I0214 18:04:36.047000 22509476222784 run_lib.py:133] step: 1114700, training_loss: 4.33506e-02
I0214 18:04:36.216967 22509476222784 run_lib.py:146] step: 1114700, eval_loss: 3.22830e-02
I0214 18:04:55.205856 22509476222784 run_lib.py:133] step: 1114750, training_loss: 3.58716e-02
I0214 18:05:14.086157 22509476222784 run_lib.py:133] step: 1114800, training_loss: 4.80892e-02
I0214 18:05:14.254132 22509476222784 run_lib.py:146] step: 1114800, eval_loss: 4.12749e-02
I0214 18:05:33.066606 22509476222784 run_lib.py:133] step: 1114850, training_loss: 2.79808e-02
I0214 18:05:51.894726 22509476222784 run_lib.py:133] step: 1114900, training_loss: 3.90773e-02
I0214 18:05:52.062623 22509476222784 run_lib.py:146] step: 1114900, eval_loss: 4.15474e-02
I0214 18:06:10.885039 22509476222784 run_lib.py:133] step: 1114950, training_loss: 3.60305e-02
I0214 18:06:29.701689 22509476222784 run_lib.py:133] step: 1115000, training_loss: 4.23252e-02
I0214 18:06:29.870035 22509476222784 run_lib.py:146] step: 1115000, eval_loss: 4.55734e-02
I0214 18:06:48.833145 22509476222784 run_lib.py:133] step: 1115050, training_loss: 4.53223e-02
I0214 18:07:07.616200 22509476222784 run_lib.py:133] step: 1115100, training_loss: 3.58633e-02
I0214 18:07:07.787415 22509476222784 run_lib.py:146] step: 1115100, eval_loss: 5.46153e-02
I0214 18:07:26.563006 22509476222784 run_lib.py:133] step: 1115150, training_loss: 3.52098e-02
I0214 18:07:45.297116 22509476222784 run_lib.py:133] step: 1115200, training_loss: 4.38348e-02
I0214 18:07:45.463972 22509476222784 run_lib.py:146] step: 1115200, eval_loss: 3.79541e-02
I0214 18:08:04.535189 22509476222784 run_lib.py:133] step: 1115250, training_loss: 4.66597e-02
I0214 18:08:23.253246 22509476222784 run_lib.py:133] step: 1115300, training_loss: 4.68387e-02
I0214 18:08:23.419241 22509476222784 run_lib.py:146] step: 1115300, eval_loss: 3.78688e-02
I0214 18:08:42.365442 22509476222784 run_lib.py:133] step: 1115350, training_loss: 3.18670e-02
I0214 18:09:01.111879 22509476222784 run_lib.py:133] step: 1115400, training_loss: 4.51692e-02
I0214 18:09:01.276530 22509476222784 run_lib.py:146] step: 1115400, eval_loss: 3.51690e-02
I0214 18:09:20.132190 22509476222784 run_lib.py:133] step: 1115450, training_loss: 5.06712e-02
I0214 18:09:38.963223 22509476222784 run_lib.py:133] step: 1115500, training_loss: 2.58856e-02
I0214 18:09:39.130124 22509476222784 run_lib.py:146] step: 1115500, eval_loss: 3.99397e-02
I0214 18:09:58.097634 22509476222784 run_lib.py:133] step: 1115550, training_loss: 4.06996e-02
I0214 18:10:16.973676 22509476222784 run_lib.py:133] step: 1115600, training_loss: 4.48874e-02
I0214 18:10:17.157134 22509476222784 run_lib.py:146] step: 1115600, eval_loss: 5.63908e-02
I0214 18:10:35.884734 22509476222784 run_lib.py:133] step: 1115650, training_loss: 3.76669e-02
I0214 18:10:54.867823 22509476222784 run_lib.py:133] step: 1115700, training_loss: 4.67272e-02
I0214 18:10:55.037120 22509476222784 run_lib.py:146] step: 1115700, eval_loss: 5.22471e-02
I0214 18:11:13.833493 22509476222784 run_lib.py:133] step: 1115750, training_loss: 4.09281e-02
I0214 18:11:32.590862 22509476222784 run_lib.py:133] step: 1115800, training_loss: 5.16419e-02
I0214 18:11:32.768434 22509476222784 run_lib.py:146] step: 1115800, eval_loss: 4.07047e-02
I0214 18:11:51.864392 22509476222784 run_lib.py:133] step: 1115850, training_loss: 5.34334e-02
I0214 18:12:10.733637 22509476222784 run_lib.py:133] step: 1115900, training_loss: 4.18705e-02
I0214 18:12:10.896040 22509476222784 run_lib.py:146] step: 1115900, eval_loss: 3.52765e-02
I0214 18:12:29.645455 22509476222784 run_lib.py:133] step: 1115950, training_loss: 3.10882e-02
I0214 18:12:48.418002 22509476222784 run_lib.py:133] step: 1116000, training_loss: 4.36706e-02
I0214 18:12:48.601150 22509476222784 run_lib.py:146] step: 1116000, eval_loss: 4.84906e-02
I0214 18:13:07.440818 22509476222784 run_lib.py:133] step: 1116050, training_loss: 4.00142e-02
I0214 18:13:26.755934 22509476222784 run_lib.py:133] step: 1116100, training_loss: 3.95499e-02
I0214 18:13:26.924181 22509476222784 run_lib.py:146] step: 1116100, eval_loss: 4.05643e-02
I0214 18:13:45.628018 22509476222784 run_lib.py:133] step: 1116150, training_loss: 5.92469e-02
I0214 18:14:04.476545 22509476222784 run_lib.py:133] step: 1116200, training_loss: 5.23611e-02
I0214 18:14:04.652010 22509476222784 run_lib.py:146] step: 1116200, eval_loss: 4.89651e-02
I0214 18:14:23.384475 22509476222784 run_lib.py:133] step: 1116250, training_loss: 2.95456e-02
I0214 18:14:42.427311 22509476222784 run_lib.py:133] step: 1116300, training_loss: 3.58146e-02
I0214 18:14:42.593300 22509476222784 run_lib.py:146] step: 1116300, eval_loss: 3.97041e-02
I0214 18:15:01.380604 22509476222784 run_lib.py:133] step: 1116350, training_loss: 4.25564e-02
I0214 18:15:20.297578 22509476222784 run_lib.py:133] step: 1116400, training_loss: 3.86357e-02
I0214 18:15:20.466860 22509476222784 run_lib.py:146] step: 1116400, eval_loss: 4.34551e-02
I0214 18:15:39.225100 22509476222784 run_lib.py:133] step: 1116450, training_loss: 4.17835e-02
I0214 18:15:57.926918 22509476222784 run_lib.py:133] step: 1116500, training_loss: 3.86794e-02
I0214 18:15:58.110131 22509476222784 run_lib.py:146] step: 1116500, eval_loss: 3.71950e-02
I0214 18:16:17.170701 22509476222784 run_lib.py:133] step: 1116550, training_loss: 2.88361e-02
I0214 18:16:36.069260 22509476222784 run_lib.py:133] step: 1116600, training_loss: 3.31997e-02
I0214 18:16:36.237045 22509476222784 run_lib.py:146] step: 1116600, eval_loss: 4.94372e-02
I0214 18:16:55.053336 22509476222784 run_lib.py:133] step: 1116650, training_loss: 4.70077e-02
I0214 18:17:13.766722 22509476222784 run_lib.py:133] step: 1116700, training_loss: 5.08421e-02
I0214 18:17:13.937386 22509476222784 run_lib.py:146] step: 1116700, eval_loss: 4.39021e-02
I0214 18:17:32.859250 22509476222784 run_lib.py:133] step: 1116750, training_loss: 5.15388e-02
I0214 18:17:51.713207 22509476222784 run_lib.py:133] step: 1116800, training_loss: 4.02090e-02
I0214 18:17:51.882653 22509476222784 run_lib.py:146] step: 1116800, eval_loss: 3.75707e-02
I0214 18:18:10.874789 22509476222784 run_lib.py:133] step: 1116850, training_loss: 3.83580e-02
I0214 18:18:29.720983 22509476222784 run_lib.py:133] step: 1116900, training_loss: 4.19447e-02
I0214 18:18:29.888553 22509476222784 run_lib.py:146] step: 1116900, eval_loss: 4.02165e-02
I0214 18:18:48.790970 22509476222784 run_lib.py:133] step: 1116950, training_loss: 4.26278e-02
I0214 18:19:07.602499 22509476222784 run_lib.py:133] step: 1117000, training_loss: 3.79084e-02
I0214 18:19:07.771221 22509476222784 run_lib.py:146] step: 1117000, eval_loss: 4.02110e-02
I0214 18:19:26.488684 22509476222784 run_lib.py:133] step: 1117050, training_loss: 3.22328e-02
I0214 18:19:45.495110 22509476222784 run_lib.py:133] step: 1117100, training_loss: 4.34143e-02
I0214 18:19:45.661083 22509476222784 run_lib.py:146] step: 1117100, eval_loss: 4.81404e-02
I0214 18:20:04.488647 22509476222784 run_lib.py:133] step: 1117150, training_loss: 3.28718e-02
I0214 18:20:23.517205 22509476222784 run_lib.py:133] step: 1117200, training_loss: 4.56370e-02
I0214 18:20:23.678746 22509476222784 run_lib.py:146] step: 1117200, eval_loss: 3.79648e-02
I0214 18:20:42.418036 22509476222784 run_lib.py:133] step: 1117250, training_loss: 4.62853e-02
I0214 18:21:01.240319 22509476222784 run_lib.py:133] step: 1117300, training_loss: 4.05341e-02
I0214 18:21:01.402910 22509476222784 run_lib.py:146] step: 1117300, eval_loss: 5.36661e-02
I0214 18:21:20.332981 22509476222784 run_lib.py:133] step: 1117350, training_loss: 3.54782e-02
I0214 18:21:39.216229 22509476222784 run_lib.py:133] step: 1117400, training_loss: 3.99639e-02
I0214 18:21:39.395524 22509476222784 run_lib.py:146] step: 1117400, eval_loss: 3.94733e-02
I0214 18:21:58.222617 22509476222784 run_lib.py:133] step: 1117450, training_loss: 4.65825e-02
I0214 18:22:17.216104 22509476222784 run_lib.py:133] step: 1117500, training_loss: 3.25191e-02
I0214 18:22:17.385275 22509476222784 run_lib.py:146] step: 1117500, eval_loss: 4.39610e-02
I0214 18:22:36.216510 22509476222784 run_lib.py:133] step: 1117550, training_loss: 4.66728e-02
I0214 18:22:54.958781 22509476222784 run_lib.py:133] step: 1117600, training_loss: 4.54938e-02
I0214 18:22:55.124934 22509476222784 run_lib.py:146] step: 1117600, eval_loss: 4.93274e-02
I0214 18:23:14.110893 22509476222784 run_lib.py:133] step: 1117650, training_loss: 4.58163e-02
I0214 18:23:33.077440 22509476222784 run_lib.py:133] step: 1117700, training_loss: 4.87935e-02
I0214 18:23:33.243845 22509476222784 run_lib.py:146] step: 1117700, eval_loss: 3.57217e-02
I0214 18:23:52.124108 22509476222784 run_lib.py:133] step: 1117750, training_loss: 3.11107e-02
I0214 18:24:10.849829 22509476222784 run_lib.py:133] step: 1117800, training_loss: 3.49110e-02
I0214 18:24:11.019712 22509476222784 run_lib.py:146] step: 1117800, eval_loss: 4.27431e-02
I0214 18:24:29.961748 22509476222784 run_lib.py:133] step: 1117850, training_loss: 3.47654e-02
I0214 18:24:48.846371 22509476222784 run_lib.py:133] step: 1117900, training_loss: 5.40488e-02
I0214 18:24:49.025117 22509476222784 run_lib.py:146] step: 1117900, eval_loss: 5.04745e-02
I0214 18:25:07.789660 22509476222784 run_lib.py:133] step: 1117950, training_loss: 3.90810e-02
I0214 18:25:26.612645 22509476222784 run_lib.py:133] step: 1118000, training_loss: 4.50482e-02
I0214 18:25:26.780842 22509476222784 run_lib.py:146] step: 1118000, eval_loss: 5.51749e-02
I0214 18:25:45.613287 22509476222784 run_lib.py:133] step: 1118050, training_loss: 3.68437e-02
I0214 18:26:04.510899 22509476222784 run_lib.py:133] step: 1118100, training_loss: 4.02047e-02
I0214 18:26:04.678618 22509476222784 run_lib.py:146] step: 1118100, eval_loss: 5.09619e-02
I0214 18:26:23.547776 22509476222784 run_lib.py:133] step: 1118150, training_loss: 4.90705e-02
I0214 18:26:42.325521 22509476222784 run_lib.py:133] step: 1118200, training_loss: 3.97222e-02
I0214 18:26:42.499161 22509476222784 run_lib.py:146] step: 1118200, eval_loss: 4.43455e-02
I0214 18:27:01.615638 22509476222784 run_lib.py:133] step: 1118250, training_loss: 3.94023e-02
I0214 18:27:20.289004 22509476222784 run_lib.py:133] step: 1118300, training_loss: 4.53098e-02
I0214 18:27:20.452664 22509476222784 run_lib.py:146] step: 1118300, eval_loss: 4.75606e-02
I0214 18:27:39.467061 22509476222784 run_lib.py:133] step: 1118350, training_loss: 4.60888e-02
I0214 18:27:58.177049 22509476222784 run_lib.py:133] step: 1118400, training_loss: 5.47170e-02
I0214 18:27:58.353108 22509476222784 run_lib.py:146] step: 1118400, eval_loss: 5.13755e-02
I0214 18:28:17.192905 22509476222784 run_lib.py:133] step: 1118450, training_loss: 4.89197e-02
I0214 18:28:36.241972 22509476222784 run_lib.py:133] step: 1118500, training_loss: 3.55868e-02
I0214 18:28:36.410986 22509476222784 run_lib.py:146] step: 1118500, eval_loss: 3.90611e-02
I0214 18:28:55.107696 22509476222784 run_lib.py:133] step: 1118550, training_loss: 3.37188e-02
I0214 18:29:13.943791 22509476222784 run_lib.py:133] step: 1118600, training_loss: 4.54796e-02
I0214 18:29:14.118004 22509476222784 run_lib.py:146] step: 1118600, eval_loss: 3.87133e-02
I0214 18:29:32.987177 22509476222784 run_lib.py:133] step: 1118650, training_loss: 4.36240e-02
I0214 18:29:51.842367 22509476222784 run_lib.py:133] step: 1118700, training_loss: 2.59996e-02
I0214 18:29:52.008192 22509476222784 run_lib.py:146] step: 1118700, eval_loss: 3.99836e-02
I0214 18:30:10.928923 22509476222784 run_lib.py:133] step: 1118750, training_loss: 3.85539e-02
I0214 18:30:29.600110 22509476222784 run_lib.py:133] step: 1118800, training_loss: 3.32307e-02
I0214 18:30:29.762923 22509476222784 run_lib.py:146] step: 1118800, eval_loss: 4.02102e-02
I0214 18:30:48.537343 22509476222784 run_lib.py:133] step: 1118850, training_loss: 3.96401e-02
I0214 18:31:07.444057 22509476222784 run_lib.py:133] step: 1118900, training_loss: 4.10059e-02
I0214 18:31:07.613186 22509476222784 run_lib.py:146] step: 1118900, eval_loss: 4.39500e-02
I0214 18:31:26.513001 22509476222784 run_lib.py:133] step: 1118950, training_loss: 4.50576e-02
I0214 18:31:45.409701 22509476222784 run_lib.py:133] step: 1119000, training_loss: 4.16149e-02
I0214 18:31:45.576134 22509476222784 run_lib.py:146] step: 1119000, eval_loss: 4.83001e-02
I0214 18:32:04.351727 22509476222784 run_lib.py:133] step: 1119050, training_loss: 4.70646e-02
I0214 18:32:23.453741 22509476222784 run_lib.py:133] step: 1119100, training_loss: 4.09125e-02
I0214 18:32:23.619060 22509476222784 run_lib.py:146] step: 1119100, eval_loss: 3.79257e-02
I0214 18:32:42.344243 22509476222784 run_lib.py:133] step: 1119150, training_loss: 4.99623e-02
I0214 18:33:01.261566 22509476222784 run_lib.py:133] step: 1119200, training_loss: 3.46098e-02
I0214 18:33:01.423740 22509476222784 run_lib.py:146] step: 1119200, eval_loss: 3.99945e-02
I0214 18:33:20.195156 22509476222784 run_lib.py:133] step: 1119250, training_loss: 3.88919e-02
I0214 18:33:38.979645 22509476222784 run_lib.py:133] step: 1119300, training_loss: 3.97216e-02
I0214 18:33:39.145343 22509476222784 run_lib.py:146] step: 1119300, eval_loss: 3.98370e-02
I0214 18:33:58.113088 22509476222784 run_lib.py:133] step: 1119350, training_loss: 4.34109e-02
I0214 18:34:16.994309 22509476222784 run_lib.py:133] step: 1119400, training_loss: 3.99157e-02
I0214 18:34:17.164322 22509476222784 run_lib.py:146] step: 1119400, eval_loss: 3.31982e-02
I0214 18:34:35.985583 22509476222784 run_lib.py:133] step: 1119450, training_loss: 3.76494e-02
I0214 18:34:54.806499 22509476222784 run_lib.py:133] step: 1119500, training_loss: 3.93865e-02
I0214 18:34:54.974894 22509476222784 run_lib.py:146] step: 1119500, eval_loss: 4.47489e-02
I0214 18:35:14.029438 22509476222784 run_lib.py:133] step: 1119550, training_loss: 3.73941e-02
I0214 18:35:32.777094 22509476222784 run_lib.py:133] step: 1119600, training_loss: 4.31659e-02
I0214 18:35:32.946331 22509476222784 run_lib.py:146] step: 1119600, eval_loss: 3.80148e-02
I0214 18:35:51.838232 22509476222784 run_lib.py:133] step: 1119650, training_loss: 4.01386e-02
I0214 18:36:10.671001 22509476222784 run_lib.py:133] step: 1119700, training_loss: 4.54729e-02
I0214 18:36:10.837210 22509476222784 run_lib.py:146] step: 1119700, eval_loss: 3.83720e-02
I0214 18:36:29.870869 22509476222784 run_lib.py:133] step: 1119750, training_loss: 4.16882e-02
I0214 18:36:48.733711 22509476222784 run_lib.py:133] step: 1119800, training_loss: 4.58363e-02
I0214 18:36:48.901546 22509476222784 run_lib.py:146] step: 1119800, eval_loss: 4.88500e-02
I0214 18:37:07.649902 22509476222784 run_lib.py:133] step: 1119850, training_loss: 3.65701e-02
I0214 18:37:26.763818 22509476222784 run_lib.py:133] step: 1119900, training_loss: 4.00746e-02
I0214 18:37:26.940214 22509476222784 run_lib.py:146] step: 1119900, eval_loss: 3.88831e-02
I0214 18:37:45.671008 22509476222784 run_lib.py:133] step: 1119950, training_loss: 4.14061e-02
I0214 18:38:04.655172 22509476222784 run_lib.py:133] step: 1120000, training_loss: 3.88131e-02
I0214 18:38:08.209891 22509476222784 run_lib.py:146] step: 1120000, eval_loss: 4.81031e-02
I0214 18:38:32.645535 22509476222784 run_lib.py:133] step: 1120050, training_loss: 2.83893e-02
I0214 18:38:51.472592 22509476222784 run_lib.py:133] step: 1120100, training_loss: 4.27480e-02
I0214 18:38:51.638000 22509476222784 run_lib.py:146] step: 1120100, eval_loss: 3.91214e-02
I0214 18:39:10.441172 22509476222784 run_lib.py:133] step: 1120150, training_loss: 3.92771e-02
I0214 18:39:29.133453 22509476222784 run_lib.py:133] step: 1120200, training_loss: 3.82744e-02
I0214 18:39:29.299075 22509476222784 run_lib.py:146] step: 1120200, eval_loss: 4.49978e-02
I0214 18:39:48.386148 22509476222784 run_lib.py:133] step: 1120250, training_loss: 5.02707e-02
I0214 18:40:07.324172 22509476222784 run_lib.py:133] step: 1120300, training_loss: 4.71777e-02
I0214 18:40:07.489112 22509476222784 run_lib.py:146] step: 1120300, eval_loss: 3.91294e-02
I0214 18:40:26.331422 22509476222784 run_lib.py:133] step: 1120350, training_loss: 4.91019e-02
I0214 18:40:45.078634 22509476222784 run_lib.py:133] step: 1120400, training_loss: 4.18928e-02
I0214 18:40:45.246855 22509476222784 run_lib.py:146] step: 1120400, eval_loss: 3.59484e-02
I0214 18:41:04.129513 22509476222784 run_lib.py:133] step: 1120450, training_loss: 3.39141e-02
I0214 18:41:22.998673 22509476222784 run_lib.py:133] step: 1120500, training_loss: 4.11048e-02
I0214 18:41:23.174924 22509476222784 run_lib.py:146] step: 1120500, eval_loss: 3.86330e-02
I0214 18:41:42.177487 22509476222784 run_lib.py:133] step: 1120550, training_loss: 4.01620e-02
I0214 18:42:00.929165 22509476222784 run_lib.py:133] step: 1120600, training_loss: 4.78369e-02
I0214 18:42:01.095328 22509476222784 run_lib.py:146] step: 1120600, eval_loss: 3.81371e-02
I0214 18:42:20.188985 22509476222784 run_lib.py:133] step: 1120650, training_loss: 3.96733e-02
I0214 18:42:38.934972 22509476222784 run_lib.py:133] step: 1120700, training_loss: 5.14588e-02
I0214 18:42:39.100936 22509476222784 run_lib.py:146] step: 1120700, eval_loss: 4.31297e-02
I0214 18:42:57.892558 22509476222784 run_lib.py:133] step: 1120750, training_loss: 3.69703e-02
I0214 18:43:16.794082 22509476222784 run_lib.py:133] step: 1120800, training_loss: 3.67559e-02
I0214 18:43:17.139005 22509476222784 run_lib.py:146] step: 1120800, eval_loss: 4.30921e-02
I0214 18:43:35.882654 22509476222784 run_lib.py:133] step: 1120850, training_loss: 4.99192e-02
I0214 18:43:54.916081 22509476222784 run_lib.py:133] step: 1120900, training_loss: 3.73599e-02
I0214 18:43:55.087906 22509476222784 run_lib.py:146] step: 1120900, eval_loss: 4.49194e-02
I0214 18:44:13.817639 22509476222784 run_lib.py:133] step: 1120950, training_loss: 3.94557e-02
I0214 18:44:32.508585 22509476222784 run_lib.py:133] step: 1121000, training_loss: 3.95553e-02
I0214 18:44:32.687384 22509476222784 run_lib.py:146] step: 1121000, eval_loss: 4.41540e-02
I0214 18:44:51.710710 22509476222784 run_lib.py:133] step: 1121050, training_loss: 3.62292e-02
I0214 18:45:10.652315 22509476222784 run_lib.py:133] step: 1121100, training_loss: 4.32736e-02
I0214 18:45:10.817125 22509476222784 run_lib.py:146] step: 1121100, eval_loss: 4.14040e-02
I0214 18:45:29.694119 22509476222784 run_lib.py:133] step: 1121150, training_loss: 4.03049e-02
I0214 18:45:48.415221 22509476222784 run_lib.py:133] step: 1121200, training_loss: 3.65359e-02
I0214 18:45:48.576098 22509476222784 run_lib.py:146] step: 1121200, eval_loss: 4.27587e-02
I0214 18:46:07.452572 22509476222784 run_lib.py:133] step: 1121250, training_loss: 4.07851e-02
I0214 18:46:26.508445 22509476222784 run_lib.py:133] step: 1121300, training_loss: 4.87572e-02
I0214 18:46:26.689145 22509476222784 run_lib.py:146] step: 1121300, eval_loss: 4.33861e-02
I0214 18:46:45.450860 22509476222784 run_lib.py:133] step: 1121350, training_loss: 4.01640e-02
I0214 18:47:04.259896 22509476222784 run_lib.py:133] step: 1121400, training_loss: 4.81410e-02
I0214 18:47:04.428279 22509476222784 run_lib.py:146] step: 1121400, eval_loss: 3.83507e-02
I0214 18:47:23.286790 22509476222784 run_lib.py:133] step: 1121450, training_loss: 4.85039e-02
I0214 18:47:42.405412 22509476222784 run_lib.py:133] step: 1121500, training_loss: 4.93098e-02
I0214 18:47:42.578418 22509476222784 run_lib.py:146] step: 1121500, eval_loss: 3.31675e-02
I0214 18:48:01.356863 22509476222784 run_lib.py:133] step: 1121550, training_loss: 4.33558e-02
I0214 18:48:20.298728 22509476222784 run_lib.py:133] step: 1121600, training_loss: 4.37276e-02
I0214 18:48:20.466714 22509476222784 run_lib.py:146] step: 1121600, eval_loss: 3.58983e-02
I0214 18:48:39.355312 22509476222784 run_lib.py:133] step: 1121650, training_loss: 4.49062e-02
I0214 18:48:58.119967 22509476222784 run_lib.py:133] step: 1121700, training_loss: 3.68023e-02
I0214 18:48:58.284061 22509476222784 run_lib.py:146] step: 1121700, eval_loss: 4.62747e-02
I0214 18:49:17.331917 22509476222784 run_lib.py:133] step: 1121750, training_loss: 4.15437e-02
I0214 18:49:36.176692 22509476222784 run_lib.py:133] step: 1121800, training_loss: 3.43212e-02
I0214 18:49:36.343820 22509476222784 run_lib.py:146] step: 1121800, eval_loss: 3.99738e-02
I0214 18:49:55.100570 22509476222784 run_lib.py:133] step: 1121850, training_loss: 3.75599e-02
I0214 18:50:13.884633 22509476222784 run_lib.py:133] step: 1121900, training_loss: 3.89470e-02
I0214 18:50:14.051172 22509476222784 run_lib.py:146] step: 1121900, eval_loss: 3.17342e-02
I0214 18:50:32.891436 22509476222784 run_lib.py:133] step: 1121950, training_loss: 3.17742e-02
I0214 18:50:51.723426 22509476222784 run_lib.py:133] step: 1122000, training_loss: 3.88207e-02
I0214 18:50:51.892988 22509476222784 run_lib.py:146] step: 1122000, eval_loss: 4.32852e-02
I0214 18:51:10.813920 22509476222784 run_lib.py:133] step: 1122050, training_loss: 3.80563e-02
I0214 18:51:29.594174 22509476222784 run_lib.py:133] step: 1122100, training_loss: 3.91076e-02
I0214 18:51:29.763710 22509476222784 run_lib.py:146] step: 1122100, eval_loss: 3.88739e-02
I0214 18:51:48.766881 22509476222784 run_lib.py:133] step: 1122150, training_loss: 3.77914e-02
I0214 18:52:07.530464 22509476222784 run_lib.py:133] step: 1122200, training_loss: 3.60896e-02
I0214 18:52:07.693495 22509476222784 run_lib.py:146] step: 1122200, eval_loss: 4.52180e-02
I0214 18:52:26.518656 22509476222784 run_lib.py:133] step: 1122250, training_loss: 3.27289e-02
I0214 18:52:45.466356 22509476222784 run_lib.py:133] step: 1122300, training_loss: 3.79932e-02
I0214 18:52:45.650014 22509476222784 run_lib.py:146] step: 1122300, eval_loss: 4.21690e-02
I0214 18:53:04.461378 22509476222784 run_lib.py:133] step: 1122350, training_loss: 4.24924e-02
I0214 18:53:23.483188 22509476222784 run_lib.py:133] step: 1122400, training_loss: 3.33238e-02
I0214 18:53:23.648913 22509476222784 run_lib.py:146] step: 1122400, eval_loss: 4.98666e-02
I0214 18:53:42.445300 22509476222784 run_lib.py:133] step: 1122450, training_loss: 5.28462e-02
I0214 18:54:01.300459 22509476222784 run_lib.py:133] step: 1122500, training_loss: 3.34120e-02
I0214 18:54:01.475871 22509476222784 run_lib.py:146] step: 1122500, eval_loss: 4.10367e-02
I0214 18:54:20.449996 22509476222784 run_lib.py:133] step: 1122550, training_loss: 3.21563e-02
I0214 18:54:39.256372 22509476222784 run_lib.py:133] step: 1122600, training_loss: 4.35963e-02
I0214 18:54:39.418818 22509476222784 run_lib.py:146] step: 1122600, eval_loss: 4.83530e-02
slurmstepd: error: *** JOB 47702051 ON gl1516 CANCELLED AT 2023-02-14T18:54:49 ***
