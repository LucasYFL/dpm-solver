2
WARNING:tensorflow:From /home/yifulu/.conda/envs/dpm/lib/python3.9/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.

I0214 21:15:22.356190 23126066861888 main.py:54] Conditional: True
W0214 21:15:37.669886 23126066861888 utils.py:10] No checkpoint found at experiments/dpm_one_step/checkpoints-meta/checkpoint.pth. Returned the same state as input
I0214 21:15:37.712330 23126066861888 xla_bridge.py:355] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0214 21:15:37.712544 23126066861888 xla_bridge.py:355] Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0214 21:15:37.712627 23126066861888 xla_bridge.py:355] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0214 21:15:37.720835 23126066861888 xla_bridge.py:355] Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.
I0214 21:15:37.720957 23126066861888 xla_bridge.py:355] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
W0214 21:15:37.721046 23126066861888 xla_bridge.py:362] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0214 21:15:37.726083 23126066861888 dataset_info.py:358] Load dataset info from /home/yifulu/tensorflow_datasets/cifar10/3.0.2
W0214 21:15:37.733594 23126066861888 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
W0214 21:15:37.733703 23126066861888 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
I0214 21:15:37.733839 23126066861888 dataset_builder.py:351] Reusing dataset cifar10 (/home/yifulu/tensorflow_datasets/cifar10/3.0.2)
I0214 21:15:37.733936 23126066861888 logging_logger.py:35] Constructing tf.data.Dataset cifar10 for split train, from /home/yifulu/tensorflow_datasets/cifar10/3.0.2
W0214 21:15:37.985896 23126066861888 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
W0214 21:15:37.986102 23126066861888 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
I0214 21:15:37.986227 23126066861888 dataset_builder.py:351] Reusing dataset cifar10 (/home/yifulu/tensorflow_datasets/cifar10/3.0.2)
I0214 21:15:37.986313 23126066861888 logging_logger.py:35] Constructing tf.data.Dataset cifar10 for split test, from /home/yifulu/tensorflow_datasets/cifar10/3.0.2
I0214 21:15:38.270219 23126066861888 losses.py:57] Sde loss
I0214 21:15:38.270457 23126066861888 losses.py:59] Fewer: 2
I0214 21:15:38.270576 23126066861888 losses.py:71] one step set
I0214 21:15:38.270651 23126066861888 losses.py:57] Sde loss
I0214 21:15:38.270711 23126066861888 losses.py:59] Fewer: 2
I0214 21:15:38.270772 23126066861888 losses.py:71] one step set
I0214 21:15:38.270855 23126066861888 sampling.py:98] dpm_solver
I0214 21:15:38.270971 23126066861888 run_lib.py:123] Starting training loop at step 0.
I0214 21:16:27.277792 23126066861888 run_lib.py:133] step: 0, training_loss: 1.00156e+00
I0214 21:16:29.480727 23126066861888 run_lib.py:146] step: 0, eval_loss: 9.99823e-01
I0214 21:16:48.857411 23126066861888 run_lib.py:133] step: 50, training_loss: 9.92283e-01
I0214 21:17:08.102487 23126066861888 run_lib.py:133] step: 100, training_loss: 9.56675e-01
I0214 21:17:08.269190 23126066861888 run_lib.py:146] step: 100, eval_loss: 9.63962e-01
I0214 21:17:27.557011 23126066861888 run_lib.py:133] step: 150, training_loss: 8.86255e-01
I0214 21:17:44.872710 23126066861888 run_lib.py:133] step: 200, training_loss: 7.96716e-01
I0214 21:17:45.035833 23126066861888 run_lib.py:146] step: 200, eval_loss: 8.31990e-01
I0214 21:18:02.527657 23126066861888 run_lib.py:133] step: 250, training_loss: 6.94037e-01
I0214 21:18:19.848414 23126066861888 run_lib.py:133] step: 300, training_loss: 5.87480e-01
I0214 21:18:20.003024 23126066861888 run_lib.py:146] step: 300, eval_loss: 6.45538e-01
I0214 21:18:37.361700 23126066861888 run_lib.py:133] step: 350, training_loss: 4.76191e-01
I0214 21:18:54.845139 23126066861888 run_lib.py:133] step: 400, training_loss: 3.61786e-01
I0214 21:18:55.005984 23126066861888 run_lib.py:146] step: 400, eval_loss: 4.39526e-01
I0214 21:19:12.348229 23126066861888 run_lib.py:133] step: 450, training_loss: 2.54488e-01
I0214 21:19:29.801661 23126066861888 run_lib.py:133] step: 500, training_loss: 1.59209e-01
I0214 21:19:29.965560 23126066861888 run_lib.py:146] step: 500, eval_loss: 2.42206e-01
I0214 21:19:47.311477 23126066861888 run_lib.py:133] step: 550, training_loss: 8.74062e-02
I0214 21:20:04.626223 23126066861888 run_lib.py:133] step: 600, training_loss: 4.88560e-02
I0214 21:20:04.781599 23126066861888 run_lib.py:146] step: 600, eval_loss: 9.32974e-02
I0214 21:20:22.292993 23126066861888 run_lib.py:133] step: 650, training_loss: 3.45875e-02
I0214 21:20:39.569620 23126066861888 run_lib.py:133] step: 700, training_loss: 3.11374e-02
I0214 21:20:39.721515 23126066861888 run_lib.py:146] step: 700, eval_loss: 3.91098e-02
I0214 21:20:57.007165 23126066861888 run_lib.py:133] step: 750, training_loss: 2.92491e-02
I0214 21:21:14.456711 23126066861888 run_lib.py:133] step: 800, training_loss: 3.03228e-02
I0214 21:21:14.615872 23126066861888 run_lib.py:146] step: 800, eval_loss: 2.98688e-02
I0214 21:21:32.030579 23126066861888 run_lib.py:133] step: 850, training_loss: 2.87296e-02
I0214 21:21:49.384024 23126066861888 run_lib.py:133] step: 900, training_loss: 2.81933e-02
I0214 21:21:49.539933 23126066861888 run_lib.py:146] step: 900, eval_loss: 2.69852e-02
I0214 21:22:06.965145 23126066861888 run_lib.py:133] step: 950, training_loss: 2.84596e-02
I0214 21:22:24.278316 23126066861888 run_lib.py:133] step: 1000, training_loss: 2.78588e-02
I0214 21:22:24.432900 23126066861888 run_lib.py:146] step: 1000, eval_loss: 2.72754e-02
I0214 21:22:41.771713 23126066861888 run_lib.py:133] step: 1050, training_loss: 2.80517e-02
I0214 21:22:59.127998 23126066861888 run_lib.py:133] step: 1100, training_loss: 2.73143e-02
I0214 21:22:59.285987 23126066861888 run_lib.py:146] step: 1100, eval_loss: 2.65053e-02
I0214 21:23:16.780023 23126066861888 run_lib.py:133] step: 1150, training_loss: 2.70609e-02
I0214 21:23:34.210242 23126066861888 run_lib.py:133] step: 1200, training_loss: 2.86610e-02
I0214 21:23:34.359175 23126066861888 run_lib.py:146] step: 1200, eval_loss: 2.60210e-02
I0214 21:23:51.639035 23126066861888 run_lib.py:133] step: 1250, training_loss: 2.67269e-02
I0214 21:24:08.989769 23126066861888 run_lib.py:133] step: 1300, training_loss: 2.77736e-02
I0214 21:24:09.143772 23126066861888 run_lib.py:146] step: 1300, eval_loss: 2.66196e-02
I0214 21:24:26.607769 23126066861888 run_lib.py:133] step: 1350, training_loss: 2.70171e-02
I0214 21:24:43.912811 23126066861888 run_lib.py:133] step: 1400, training_loss: 2.76518e-02
I0214 21:24:44.083731 23126066861888 run_lib.py:146] step: 1400, eval_loss: 2.57143e-02
I0214 21:25:01.419913 23126066861888 run_lib.py:133] step: 1450, training_loss: 2.70484e-02
I0214 21:25:18.952594 23126066861888 run_lib.py:133] step: 1500, training_loss: 2.77257e-02
I0214 21:25:19.106956 23126066861888 run_lib.py:146] step: 1500, eval_loss: 2.63625e-02
I0214 21:25:36.431800 23126066861888 run_lib.py:133] step: 1550, training_loss: 2.67604e-02
I0214 21:25:53.874300 23126066861888 run_lib.py:133] step: 1600, training_loss: 2.77441e-02
I0214 21:25:54.028840 23126066861888 run_lib.py:146] step: 1600, eval_loss: 2.54098e-02
I0214 21:26:11.362548 23126066861888 run_lib.py:133] step: 1650, training_loss: 2.58385e-02
I0214 21:26:28.723246 23126066861888 run_lib.py:133] step: 1700, training_loss: 2.70703e-02
I0214 21:26:28.880106 23126066861888 run_lib.py:146] step: 1700, eval_loss: 2.64556e-02
I0214 21:26:46.449835 23126066861888 run_lib.py:133] step: 1750, training_loss: 2.68875e-02
I0214 21:27:03.748914 23126066861888 run_lib.py:133] step: 1800, training_loss: 2.68067e-02
I0214 21:27:03.904647 23126066861888 run_lib.py:146] step: 1800, eval_loss: 2.59280e-02
I0214 21:27:21.211684 23126066861888 run_lib.py:133] step: 1850, training_loss: 2.61023e-02
I0214 21:27:38.674785 23126066861888 run_lib.py:133] step: 1900, training_loss: 2.66585e-02
I0214 21:27:38.829952 23126066861888 run_lib.py:146] step: 1900, eval_loss: 2.52539e-02
I0214 21:27:56.169059 23126066861888 run_lib.py:133] step: 1950, training_loss: 2.60635e-02
I0214 21:28:13.521856 23126066861888 run_lib.py:133] step: 2000, training_loss: 2.61356e-02
I0214 21:28:13.681915 23126066861888 run_lib.py:146] step: 2000, eval_loss: 2.55249e-02
I0214 21:28:31.057107 23126066861888 run_lib.py:133] step: 2050, training_loss: 2.58047e-02
I0214 21:28:48.421688 23126066861888 run_lib.py:133] step: 2100, training_loss: 2.61936e-02
I0214 21:28:48.574627 23126066861888 run_lib.py:146] step: 2100, eval_loss: 2.60377e-02
I0214 21:29:05.914775 23126066861888 run_lib.py:133] step: 2150, training_loss: 2.62264e-02
I0214 21:29:23.227822 23126066861888 run_lib.py:133] step: 2200, training_loss: 2.60868e-02
I0214 21:29:23.380768 23126066861888 run_lib.py:146] step: 2200, eval_loss: 2.52484e-02
I0214 21:29:40.995348 23126066861888 run_lib.py:133] step: 2250, training_loss: 2.67146e-02
I0214 21:29:58.478561 23126066861888 run_lib.py:133] step: 2300, training_loss: 2.74321e-02
I0214 21:29:58.650635 23126066861888 run_lib.py:146] step: 2300, eval_loss: 2.45656e-02
I0214 21:30:15.988595 23126066861888 run_lib.py:133] step: 2350, training_loss: 2.63276e-02
I0214 21:30:33.284622 23126066861888 run_lib.py:133] step: 2400, training_loss: 2.57897e-02
I0214 21:30:33.438760 23126066861888 run_lib.py:146] step: 2400, eval_loss: 2.49411e-02
I0214 21:30:50.926909 23126066861888 run_lib.py:133] step: 2450, training_loss: 2.65961e-02
I0214 21:31:08.242428 23126066861888 run_lib.py:133] step: 2500, training_loss: 2.67990e-02
I0214 21:31:08.394658 23126066861888 run_lib.py:146] step: 2500, eval_loss: 2.57032e-02
I0214 21:31:25.707728 23126066861888 run_lib.py:133] step: 2550, training_loss: 2.52417e-02
I0214 21:31:43.236772 23126066861888 run_lib.py:133] step: 2600, training_loss: 2.59056e-02
I0214 21:31:43.389122 23126066861888 run_lib.py:146] step: 2600, eval_loss: 2.61758e-02
I0214 21:32:00.721739 23126066861888 run_lib.py:133] step: 2650, training_loss: 2.60492e-02
I0214 21:32:18.254040 23126066861888 run_lib.py:133] step: 2700, training_loss: 2.67501e-02
I0214 21:32:18.408752 23126066861888 run_lib.py:146] step: 2700, eval_loss: 2.52688e-02
I0214 21:32:35.709147 23126066861888 run_lib.py:133] step: 2750, training_loss: 2.56075e-02
I0214 21:32:53.025467 23126066861888 run_lib.py:133] step: 2800, training_loss: 2.56982e-02
I0214 21:32:53.181934 23126066861888 run_lib.py:146] step: 2800, eval_loss: 2.47355e-02
I0214 21:33:10.707963 23126066861888 run_lib.py:133] step: 2850, training_loss: 2.61785e-02
I0214 21:33:28.067656 23126066861888 run_lib.py:133] step: 2900, training_loss: 2.59110e-02
I0214 21:33:28.224009 23126066861888 run_lib.py:146] step: 2900, eval_loss: 2.47798e-02
I0214 21:33:45.503260 23126066861888 run_lib.py:133] step: 2950, training_loss: 2.57826e-02
I0214 21:34:02.988787 23126066861888 run_lib.py:133] step: 3000, training_loss: 2.56184e-02
I0214 21:34:03.141522 23126066861888 run_lib.py:146] step: 3000, eval_loss: 2.51289e-02
I0214 21:34:20.436599 23126066861888 run_lib.py:133] step: 3050, training_loss: 2.56869e-02
I0214 21:34:37.774551 23126066861888 run_lib.py:133] step: 3100, training_loss: 2.59910e-02
I0214 21:34:37.925752 23126066861888 run_lib.py:146] step: 3100, eval_loss: 2.58432e-02
I0214 21:34:55.328907 23126066861888 run_lib.py:133] step: 3150, training_loss: 2.55194e-02
I0214 21:35:12.656135 23126066861888 run_lib.py:133] step: 3200, training_loss: 2.62164e-02
I0214 21:35:12.816052 23126066861888 run_lib.py:146] step: 3200, eval_loss: 2.50466e-02
I0214 21:35:30.122103 23126066861888 run_lib.py:133] step: 3250, training_loss: 2.66699e-02
I0214 21:35:47.488287 23126066861888 run_lib.py:133] step: 3300, training_loss: 2.56998e-02
I0214 21:35:47.654913 23126066861888 run_lib.py:146] step: 3300, eval_loss: 2.52586e-02
I0214 21:36:05.183294 23126066861888 run_lib.py:133] step: 3350, training_loss: 2.54081e-02
I0214 21:36:22.605319 23126066861888 run_lib.py:133] step: 3400, training_loss: 2.59493e-02
I0214 21:36:22.768856 23126066861888 run_lib.py:146] step: 3400, eval_loss: 2.49426e-02
I0214 21:36:40.131840 23126066861888 run_lib.py:133] step: 3450, training_loss: 2.62149e-02
I0214 21:36:57.502749 23126066861888 run_lib.py:133] step: 3500, training_loss: 2.54485e-02
I0214 21:36:57.656102 23126066861888 run_lib.py:146] step: 3500, eval_loss: 2.49995e-02
I0214 21:37:15.139253 23126066861888 run_lib.py:133] step: 3550, training_loss: 2.56215e-02
I0214 21:37:32.460032 23126066861888 run_lib.py:133] step: 3600, training_loss: 2.52866e-02
I0214 21:37:32.613753 23126066861888 run_lib.py:146] step: 3600, eval_loss: 2.54216e-02
I0214 21:37:49.930988 23126066861888 run_lib.py:133] step: 3650, training_loss: 2.59945e-02
I0214 21:38:07.445230 23126066861888 run_lib.py:133] step: 3700, training_loss: 2.63128e-02
I0214 21:38:07.610832 23126066861888 run_lib.py:146] step: 3700, eval_loss: 2.56786e-02
I0214 21:38:24.938986 23126066861888 run_lib.py:133] step: 3750, training_loss: 2.50174e-02
I0214 21:38:42.444303 23126066861888 run_lib.py:133] step: 3800, training_loss: 2.54762e-02
I0214 21:38:42.598281 23126066861888 run_lib.py:146] step: 3800, eval_loss: 2.53699e-02
I0214 21:38:59.917994 23126066861888 run_lib.py:133] step: 3850, training_loss: 2.58754e-02
I0214 21:39:17.262126 23126066861888 run_lib.py:133] step: 3900, training_loss: 2.62488e-02
I0214 21:39:17.415778 23126066861888 run_lib.py:146] step: 3900, eval_loss: 2.56079e-02
I0214 21:39:34.882430 23126066861888 run_lib.py:133] step: 3950, training_loss: 2.55869e-02
I0214 21:39:52.274638 23126066861888 run_lib.py:133] step: 4000, training_loss: 2.56408e-02
I0214 21:39:52.427120 23126066861888 run_lib.py:146] step: 4000, eval_loss: 2.49771e-02
I0214 21:40:09.802906 23126066861888 run_lib.py:133] step: 4050, training_loss: 2.64814e-02
I0214 21:40:27.296088 23126066861888 run_lib.py:133] step: 4100, training_loss: 2.47055e-02
I0214 21:40:27.449912 23126066861888 run_lib.py:146] step: 4100, eval_loss: 2.51803e-02
I0214 21:40:44.734782 23126066861888 run_lib.py:133] step: 4150, training_loss: 2.59603e-02
I0214 21:41:02.055684 23126066861888 run_lib.py:133] step: 4200, training_loss: 2.60121e-02
I0214 21:41:02.211995 23126066861888 run_lib.py:146] step: 4200, eval_loss: 2.55994e-02
I0214 21:41:19.563201 23126066861888 run_lib.py:133] step: 4250, training_loss: 2.62787e-02
I0214 21:41:36.912946 23126066861888 run_lib.py:133] step: 4300, training_loss: 2.51964e-02
I0214 21:41:37.070105 23126066861888 run_lib.py:146] step: 4300, eval_loss: 2.44630e-02
I0214 21:41:54.383627 23126066861888 run_lib.py:133] step: 4350, training_loss: 2.49724e-02
I0214 21:42:11.686311 23126066861888 run_lib.py:133] step: 4400, training_loss: 2.55826e-02
I0214 21:42:11.841069 23126066861888 run_lib.py:146] step: 4400, eval_loss: 2.52344e-02
I0214 21:42:29.420399 23126066861888 run_lib.py:133] step: 4450, training_loss: 2.59155e-02
I0214 21:42:46.790068 23126066861888 run_lib.py:133] step: 4500, training_loss: 2.50185e-02
I0214 21:42:46.949791 23126066861888 run_lib.py:146] step: 4500, eval_loss: 2.47276e-02
I0214 21:43:04.261671 23126066861888 run_lib.py:133] step: 4550, training_loss: 2.50982e-02
I0214 21:43:21.567615 23126066861888 run_lib.py:133] step: 4600, training_loss: 2.62620e-02
I0214 21:43:21.723938 23126066861888 run_lib.py:146] step: 4600, eval_loss: 2.48399e-02
I0214 21:43:39.232486 23126066861888 run_lib.py:133] step: 4650, training_loss: 2.60069e-02
I0214 21:43:56.529521 23126066861888 run_lib.py:133] step: 4700, training_loss: 2.52440e-02
I0214 21:43:56.685044 23126066861888 run_lib.py:146] step: 4700, eval_loss: 2.53506e-02
I0214 21:44:13.973838 23126066861888 run_lib.py:133] step: 4750, training_loss: 2.51213e-02
I0214 21:44:31.438565 23126066861888 run_lib.py:133] step: 4800, training_loss: 2.46607e-02
I0214 21:44:31.600921 23126066861888 run_lib.py:146] step: 4800, eval_loss: 2.53322e-02
I0214 21:44:48.964669 23126066861888 run_lib.py:133] step: 4850, training_loss: 2.51105e-02
I0214 21:45:06.468206 23126066861888 run_lib.py:133] step: 4900, training_loss: 2.48930e-02
I0214 21:45:06.629707 23126066861888 run_lib.py:146] step: 4900, eval_loss: 2.55579e-02
I0214 21:45:23.968447 23126066861888 run_lib.py:133] step: 4950, training_loss: 2.54494e-02
I0214 21:45:41.266981 23126066861888 run_lib.py:133] step: 5000, training_loss: 2.56078e-02
I0214 21:45:41.419239 23126066861888 run_lib.py:146] step: 5000, eval_loss: 2.44384e-02
I0214 21:45:58.940762 23126066861888 run_lib.py:133] step: 5050, training_loss: 2.51397e-02
I0214 21:46:16.284810 23126066861888 run_lib.py:133] step: 5100, training_loss: 2.58269e-02
I0214 21:46:16.442787 23126066861888 run_lib.py:146] step: 5100, eval_loss: 2.44437e-02
I0214 21:46:33.782037 23126066861888 run_lib.py:133] step: 5150, training_loss: 2.51629e-02
I0214 21:46:51.336998 23126066861888 run_lib.py:133] step: 5200, training_loss: 2.49857e-02
I0214 21:46:51.492855 23126066861888 run_lib.py:146] step: 5200, eval_loss: 2.38188e-02
I0214 21:47:08.829894 23126066861888 run_lib.py:133] step: 5250, training_loss: 2.42990e-02
I0214 21:47:26.120062 23126066861888 run_lib.py:133] step: 5300, training_loss: 2.55404e-02
I0214 21:47:26.273742 23126066861888 run_lib.py:146] step: 5300, eval_loss: 2.46509e-02
I0214 21:47:43.676805 23126066861888 run_lib.py:133] step: 5350, training_loss: 2.48923e-02
I0214 21:48:00.976479 23126066861888 run_lib.py:133] step: 5400, training_loss: 2.41937e-02
I0214 21:48:01.128702 23126066861888 run_lib.py:146] step: 5400, eval_loss: 2.51388e-02
I0214 21:48:18.421605 23126066861888 run_lib.py:133] step: 5450, training_loss: 2.51659e-02
I0214 21:48:35.776689 23126066861888 run_lib.py:133] step: 5500, training_loss: 2.43534e-02
I0214 21:48:35.931995 23126066861888 run_lib.py:146] step: 5500, eval_loss: 2.50693e-02
I0214 21:48:53.502916 23126066861888 run_lib.py:133] step: 5550, training_loss: 2.55336e-02
I0214 21:49:10.911884 23126066861888 run_lib.py:133] step: 5600, training_loss: 2.50459e-02
I0214 21:49:11.075821 23126066861888 run_lib.py:146] step: 5600, eval_loss: 2.53580e-02
I0214 21:49:28.381483 23126066861888 run_lib.py:133] step: 5650, training_loss: 2.54669e-02
I0214 21:49:45.666625 23126066861888 run_lib.py:133] step: 5700, training_loss: 2.55212e-02
I0214 21:49:45.821730 23126066861888 run_lib.py:146] step: 5700, eval_loss: 2.38919e-02
I0214 21:50:03.327522 23126066861888 run_lib.py:133] step: 5750, training_loss: 2.53001e-02
I0214 21:50:20.711844 23126066861888 run_lib.py:133] step: 5800, training_loss: 2.48943e-02
I0214 21:50:20.868088 23126066861888 run_lib.py:146] step: 5800, eval_loss: 2.55678e-02
I0214 21:50:38.217991 23126066861888 run_lib.py:133] step: 5850, training_loss: 2.50019e-02
I0214 21:50:55.699662 23126066861888 run_lib.py:133] step: 5900, training_loss: 2.55222e-02
I0214 21:50:55.860905 23126066861888 run_lib.py:146] step: 5900, eval_loss: 2.53215e-02
I0214 21:51:13.185962 23126066861888 run_lib.py:133] step: 5950, training_loss: 2.46763e-02
I0214 21:51:30.663522 23126066861888 run_lib.py:133] step: 6000, training_loss: 2.47069e-02
I0214 21:51:30.818033 23126066861888 run_lib.py:146] step: 6000, eval_loss: 2.51087e-02
I0214 21:51:48.147895 23126066861888 run_lib.py:133] step: 6050, training_loss: 2.61065e-02
I0214 21:52:05.478308 23126066861888 run_lib.py:133] step: 6100, training_loss: 2.57284e-02
I0214 21:52:05.635864 23126066861888 run_lib.py:146] step: 6100, eval_loss: 2.37771e-02
I0214 21:52:23.132454 23126066861888 run_lib.py:133] step: 6150, training_loss: 2.46658e-02
I0214 21:52:40.437363 23126066861888 run_lib.py:133] step: 6200, training_loss: 2.42367e-02
I0214 21:52:40.588120 23126066861888 run_lib.py:146] step: 6200, eval_loss: 2.40792e-02
I0214 21:52:57.888949 23126066861888 run_lib.py:133] step: 6250, training_loss: 2.47106e-02
I0214 21:53:15.300510 23126066861888 run_lib.py:133] step: 6300, training_loss: 2.53046e-02
I0214 21:53:15.453939 23126066861888 run_lib.py:146] step: 6300, eval_loss: 2.53575e-02
I0214 21:53:32.781170 23126066861888 run_lib.py:133] step: 6350, training_loss: 2.48839e-02
I0214 21:53:50.130498 23126066861888 run_lib.py:133] step: 6400, training_loss: 2.49324e-02
I0214 21:53:50.283107 23126066861888 run_lib.py:146] step: 6400, eval_loss: 2.46299e-02
I0214 21:54:07.715516 23126066861888 run_lib.py:133] step: 6450, training_loss: 2.46988e-02
I0214 21:54:25.078897 23126066861888 run_lib.py:133] step: 6500, training_loss: 2.52624e-02
I0214 21:54:25.232717 23126066861888 run_lib.py:146] step: 6500, eval_loss: 2.56550e-02
I0214 21:54:42.526384 23126066861888 run_lib.py:133] step: 6550, training_loss: 2.50058e-02
I0214 21:54:59.913839 23126066861888 run_lib.py:133] step: 6600, training_loss: 2.41802e-02
I0214 21:55:00.082755 23126066861888 run_lib.py:146] step: 6600, eval_loss: 2.38125e-02
I0214 21:55:17.571771 23126066861888 run_lib.py:133] step: 6650, training_loss: 2.46878e-02
I0214 21:55:35.042463 23126066861888 run_lib.py:133] step: 6700, training_loss: 2.53106e-02
I0214 21:55:35.197166 23126066861888 run_lib.py:146] step: 6700, eval_loss: 2.48034e-02
I0214 21:55:52.589420 23126066861888 run_lib.py:133] step: 6750, training_loss: 2.60952e-02
I0214 21:56:09.873554 23126066861888 run_lib.py:133] step: 6800, training_loss: 2.56952e-02
I0214 21:56:10.025671 23126066861888 run_lib.py:146] step: 6800, eval_loss: 2.45579e-02
I0214 21:56:27.529196 23126066861888 run_lib.py:133] step: 6850, training_loss: 2.51146e-02
I0214 21:56:44.875859 23126066861888 run_lib.py:133] step: 6900, training_loss: 2.56189e-02
I0214 21:56:45.031021 23126066861888 run_lib.py:146] step: 6900, eval_loss: 2.45239e-02
I0214 21:57:02.408770 23126066861888 run_lib.py:133] step: 6950, training_loss: 2.48375e-02
I0214 21:57:20.023043 23126066861888 run_lib.py:133] step: 7000, training_loss: 2.47873e-02
I0214 21:57:20.187956 23126066861888 run_lib.py:146] step: 7000, eval_loss: 2.38327e-02
I0214 21:57:37.479346 23126066861888 run_lib.py:133] step: 7050, training_loss: 2.44412e-02
I0214 21:57:54.913425 23126066861888 run_lib.py:133] step: 7100, training_loss: 2.55182e-02
I0214 21:57:55.071001 23126066861888 run_lib.py:146] step: 7100, eval_loss: 2.45825e-02
I0214 21:58:12.414859 23126066861888 run_lib.py:133] step: 7150, training_loss: 2.49420e-02
I0214 21:58:29.724867 23126066861888 run_lib.py:133] step: 7200, training_loss: 2.43733e-02
I0214 21:58:29.889805 23126066861888 run_lib.py:146] step: 7200, eval_loss: 2.44551e-02
I0214 21:58:47.410319 23126066861888 run_lib.py:133] step: 7250, training_loss: 2.58711e-02
I0214 21:59:04.753652 23126066861888 run_lib.py:133] step: 7300, training_loss: 2.51466e-02
I0214 21:59:04.907055 23126066861888 run_lib.py:146] step: 7300, eval_loss: 2.37108e-02
I0214 21:59:22.253305 23126066861888 run_lib.py:133] step: 7350, training_loss: 2.48151e-02
I0214 21:59:39.799065 23126066861888 run_lib.py:133] step: 7400, training_loss: 2.44448e-02
I0214 21:59:39.950755 23126066861888 run_lib.py:146] step: 7400, eval_loss: 2.44524e-02
I0214 21:59:57.268455 23126066861888 run_lib.py:133] step: 7450, training_loss: 2.49480e-02
I0214 22:00:14.646922 23126066861888 run_lib.py:133] step: 7500, training_loss: 2.54154e-02
I0214 22:00:14.821788 23126066861888 run_lib.py:146] step: 7500, eval_loss: 2.53230e-02
I0214 22:00:32.223555 23126066861888 run_lib.py:133] step: 7550, training_loss: 2.56942e-02
I0214 22:00:49.555891 23126066861888 run_lib.py:133] step: 7600, training_loss: 2.48468e-02
I0214 22:00:49.712445 23126066861888 run_lib.py:146] step: 7600, eval_loss: 2.43121e-02
I0214 22:01:07.040660 23126066861888 run_lib.py:133] step: 7650, training_loss: 2.52328e-02
I0214 22:01:24.350865 23126066861888 run_lib.py:133] step: 7700, training_loss: 2.48096e-02
I0214 22:01:24.503837 23126066861888 run_lib.py:146] step: 7700, eval_loss: 2.39390e-02
I0214 22:01:41.982697 23126066861888 run_lib.py:133] step: 7750, training_loss: 2.52327e-02
I0214 22:01:59.476302 23126066861888 run_lib.py:133] step: 7800, training_loss: 2.53653e-02
I0214 22:01:59.628545 23126066861888 run_lib.py:146] step: 7800, eval_loss: 2.47621e-02
I0214 22:02:16.931118 23126066861888 run_lib.py:133] step: 7850, training_loss: 2.52058e-02
I0214 22:02:34.269056 23126066861888 run_lib.py:133] step: 7900, training_loss: 2.47733e-02
I0214 22:02:34.427795 23126066861888 run_lib.py:146] step: 7900, eval_loss: 2.44762e-02
I0214 22:02:51.943737 23126066861888 run_lib.py:133] step: 7950, training_loss: 2.50156e-02
I0214 22:03:09.324932 23126066861888 run_lib.py:133] step: 8000, training_loss: 2.54063e-02
I0214 22:03:09.488629 23126066861888 run_lib.py:146] step: 8000, eval_loss: 2.40725e-02
I0214 22:03:26.790301 23126066861888 run_lib.py:133] step: 8050, training_loss: 2.47247e-02
I0214 22:03:44.328188 23126066861888 run_lib.py:133] step: 8100, training_loss: 2.45084e-02
I0214 22:03:44.490113 23126066861888 run_lib.py:146] step: 8100, eval_loss: 2.41878e-02
I0214 22:04:01.819279 23126066861888 run_lib.py:133] step: 8150, training_loss: 2.44338e-02
I0214 22:04:19.329072 23126066861888 run_lib.py:133] step: 8200, training_loss: 2.49146e-02
I0214 22:04:19.491825 23126066861888 run_lib.py:146] step: 8200, eval_loss: 2.39642e-02
I0214 22:04:36.816497 23126066861888 run_lib.py:133] step: 8250, training_loss: 2.47358e-02
I0214 22:04:54.090329 23126066861888 run_lib.py:133] step: 8300, training_loss: 2.56304e-02
I0214 22:04:54.239826 23126066861888 run_lib.py:146] step: 8300, eval_loss: 2.52999e-02
I0214 22:05:11.662472 23126066861888 run_lib.py:133] step: 8350, training_loss: 2.45425e-02
I0214 22:05:29.019490 23126066861888 run_lib.py:133] step: 8400, training_loss: 2.49990e-02
I0214 22:05:29.186213 23126066861888 run_lib.py:146] step: 8400, eval_loss: 2.49086e-02
I0214 22:05:46.496633 23126066861888 run_lib.py:133] step: 8450, training_loss: 2.44251e-02
I0214 22:06:04.071372 23126066861888 run_lib.py:133] step: 8500, training_loss: 2.54423e-02
I0214 22:06:04.230087 23126066861888 run_lib.py:146] step: 8500, eval_loss: 2.47412e-02
I0214 22:06:21.637050 23126066861888 run_lib.py:133] step: 8550, training_loss: 2.50062e-02
I0214 22:06:38.953509 23126066861888 run_lib.py:133] step: 8600, training_loss: 2.54120e-02
I0214 22:06:39.103220 23126066861888 run_lib.py:146] step: 8600, eval_loss: 2.49857e-02
I0214 22:06:56.544336 23126066861888 run_lib.py:133] step: 8650, training_loss: 2.51124e-02
I0214 22:07:13.927295 23126066861888 run_lib.py:133] step: 8700, training_loss: 2.45655e-02
I0214 22:07:14.081220 23126066861888 run_lib.py:146] step: 8700, eval_loss: 2.50995e-02
I0214 22:07:31.457014 23126066861888 run_lib.py:133] step: 8750, training_loss: 2.51307e-02
I0214 22:07:48.758106 23126066861888 run_lib.py:133] step: 8800, training_loss: 2.53936e-02
I0214 22:07:48.909816 23126066861888 run_lib.py:146] step: 8800, eval_loss: 2.51373e-02
I0214 22:08:06.380820 23126066861888 run_lib.py:133] step: 8850, training_loss: 2.46311e-02
I0214 22:08:23.836259 23126066861888 run_lib.py:133] step: 8900, training_loss: 2.57462e-02
I0214 22:08:23.991028 23126066861888 run_lib.py:146] step: 8900, eval_loss: 2.38627e-02
I0214 22:08:41.386361 23126066861888 run_lib.py:133] step: 8950, training_loss: 2.52308e-02
I0214 22:08:58.734435 23126066861888 run_lib.py:133] step: 9000, training_loss: 2.48276e-02
I0214 22:08:58.890724 23126066861888 run_lib.py:146] step: 9000, eval_loss: 2.44246e-02
I0214 22:09:16.410871 23126066861888 run_lib.py:133] step: 9050, training_loss: 2.46889e-02
I0214 22:09:33.680830 23126066861888 run_lib.py:133] step: 9100, training_loss: 2.55943e-02
I0214 22:09:33.844426 23126066861888 run_lib.py:146] step: 9100, eval_loss: 2.40020e-02
I0214 22:09:51.250759 23126066861888 run_lib.py:133] step: 9150, training_loss: 2.41408e-02
I0214 22:10:08.716264 23126066861888 run_lib.py:133] step: 9200, training_loss: 2.51977e-02
I0214 22:10:08.878032 23126066861888 run_lib.py:146] step: 9200, eval_loss: 2.45733e-02
I0214 22:10:26.342179 23126066861888 run_lib.py:133] step: 9250, training_loss: 2.50319e-02
I0214 22:10:43.892094 23126066861888 run_lib.py:133] step: 9300, training_loss: 2.47687e-02
I0214 22:10:44.044963 23126066861888 run_lib.py:146] step: 9300, eval_loss: 2.34290e-02
I0214 22:11:01.398699 23126066861888 run_lib.py:133] step: 9350, training_loss: 2.41833e-02
I0214 22:11:18.745636 23126066861888 run_lib.py:133] step: 9400, training_loss: 2.40979e-02
I0214 22:11:18.899113 23126066861888 run_lib.py:146] step: 9400, eval_loss: 2.43610e-02
I0214 22:11:36.360916 23126066861888 run_lib.py:133] step: 9450, training_loss: 2.42627e-02
I0214 22:11:53.641113 23126066861888 run_lib.py:133] step: 9500, training_loss: 2.47458e-02
I0214 22:11:53.802794 23126066861888 run_lib.py:146] step: 9500, eval_loss: 2.38370e-02
I0214 22:12:11.132144 23126066861888 run_lib.py:133] step: 9550, training_loss: 2.46435e-02
I0214 22:12:28.660469 23126066861888 run_lib.py:133] step: 9600, training_loss: 2.52870e-02
I0214 22:12:28.814639 23126066861888 run_lib.py:146] step: 9600, eval_loss: 2.44570e-02
I0214 22:12:46.203141 23126066861888 run_lib.py:133] step: 9650, training_loss: 2.46886e-02
I0214 22:13:03.518333 23126066861888 run_lib.py:133] step: 9700, training_loss: 2.46888e-02
I0214 22:13:03.669779 23126066861888 run_lib.py:146] step: 9700, eval_loss: 2.42988e-02
I0214 22:13:21.042628 23126066861888 run_lib.py:133] step: 9750, training_loss: 2.43458e-02
I0214 22:13:38.395080 23126066861888 run_lib.py:133] step: 9800, training_loss: 2.44624e-02
I0214 22:13:38.555051 23126066861888 run_lib.py:146] step: 9800, eval_loss: 2.38101e-02
I0214 22:13:55.883708 23126066861888 run_lib.py:133] step: 9850, training_loss: 2.41205e-02
I0214 22:14:13.224257 23126066861888 run_lib.py:133] step: 9900, training_loss: 2.33872e-02
I0214 22:14:13.383936 23126066861888 run_lib.py:146] step: 9900, eval_loss: 2.39766e-02
I0214 22:14:30.911004 23126066861888 run_lib.py:133] step: 9950, training_loss: 2.44459e-02
I0214 22:14:48.265894 23126066861888 run_lib.py:133] step: 10000, training_loss: 2.44070e-02
I0214 22:14:48.965607 23126066861888 run_lib.py:146] step: 10000, eval_loss: 2.58519e-02
I0214 22:15:09.080036 23126066861888 run_lib.py:133] step: 10050, training_loss: 2.48152e-02
I0214 22:15:26.571972 23126066861888 run_lib.py:133] step: 10100, training_loss: 2.41875e-02
I0214 22:15:26.727137 23126066861888 run_lib.py:146] step: 10100, eval_loss: 2.43203e-02
I0214 22:15:44.028257 23126066861888 run_lib.py:133] step: 10150, training_loss: 2.43121e-02
I0214 22:16:01.316154 23126066861888 run_lib.py:133] step: 10200, training_loss: 2.38802e-02
I0214 22:16:01.468728 23126066861888 run_lib.py:146] step: 10200, eval_loss: 2.45342e-02
I0214 22:16:18.973410 23126066861888 run_lib.py:133] step: 10250, training_loss: 2.53672e-02
I0214 22:16:36.291690 23126066861888 run_lib.py:133] step: 10300, training_loss: 2.45549e-02
I0214 22:16:36.442747 23126066861888 run_lib.py:146] step: 10300, eval_loss: 2.53189e-02
I0214 22:16:53.934897 23126066861888 run_lib.py:133] step: 10350, training_loss: 2.49815e-02
I0214 22:17:11.267392 23126066861888 run_lib.py:133] step: 10400, training_loss: 2.41901e-02
I0214 22:17:11.439475 23126066861888 run_lib.py:146] step: 10400, eval_loss: 2.46614e-02
I0214 22:17:28.968899 23126066861888 run_lib.py:133] step: 10450, training_loss: 2.53662e-02
I0214 22:17:46.292258 23126066861888 run_lib.py:133] step: 10500, training_loss: 2.43675e-02
I0214 22:17:46.447780 23126066861888 run_lib.py:146] step: 10500, eval_loss: 2.44615e-02
I0214 22:18:03.751729 23126066861888 run_lib.py:133] step: 10550, training_loss: 2.60340e-02
I0214 22:18:21.028879 23126066861888 run_lib.py:133] step: 10600, training_loss: 2.47609e-02
I0214 22:18:21.182663 23126066861888 run_lib.py:146] step: 10600, eval_loss: 2.50953e-02
I0214 22:18:38.650766 23126066861888 run_lib.py:133] step: 10650, training_loss: 2.43954e-02
I0214 22:18:56.217179 23126066861888 run_lib.py:133] step: 10700, training_loss: 2.39893e-02
I0214 22:18:56.367586 23126066861888 run_lib.py:146] step: 10700, eval_loss: 2.43102e-02
I0214 22:19:13.749239 23126066861888 run_lib.py:133] step: 10750, training_loss: 2.49885e-02
I0214 22:19:31.114596 23126066861888 run_lib.py:133] step: 10800, training_loss: 2.43156e-02
I0214 22:19:31.269914 23126066861888 run_lib.py:146] step: 10800, eval_loss: 2.51656e-02
I0214 22:19:48.644679 23126066861888 run_lib.py:133] step: 10850, training_loss: 2.44971e-02
I0214 22:20:06.202660 23126066861888 run_lib.py:133] step: 10900, training_loss: 2.40021e-02
I0214 22:20:06.365047 23126066861888 run_lib.py:146] step: 10900, eval_loss: 2.49551e-02
I0214 22:20:23.690321 23126066861888 run_lib.py:133] step: 10950, training_loss: 2.48327e-02
I0214 22:20:41.106777 23126066861888 run_lib.py:133] step: 11000, training_loss: 2.40754e-02
I0214 22:20:41.269631 23126066861888 run_lib.py:146] step: 11000, eval_loss: 2.34098e-02
I0214 22:20:58.582114 23126066861888 run_lib.py:133] step: 11050, training_loss: 2.43033e-02
I0214 22:21:16.106952 23126066861888 run_lib.py:133] step: 11100, training_loss: 2.41044e-02
I0214 22:21:16.261953 23126066861888 run_lib.py:146] step: 11100, eval_loss: 2.42723e-02
I0214 22:21:33.581527 23126066861888 run_lib.py:133] step: 11150, training_loss: 2.46690e-02
I0214 22:21:50.959910 23126066861888 run_lib.py:133] step: 11200, training_loss: 2.39112e-02
I0214 22:21:51.116307 23126066861888 run_lib.py:146] step: 11200, eval_loss: 2.42446e-02
I0214 22:22:08.434042 23126066861888 run_lib.py:133] step: 11250, training_loss: 2.56364e-02
I0214 22:22:25.812136 23126066861888 run_lib.py:133] step: 11300, training_loss: 2.39746e-02
I0214 22:22:25.973943 23126066861888 run_lib.py:146] step: 11300, eval_loss: 2.41655e-02
I0214 22:22:43.495756 23126066861888 run_lib.py:133] step: 11350, training_loss: 2.40411e-02
I0214 22:23:00.846081 23126066861888 run_lib.py:133] step: 11400, training_loss: 2.41002e-02
I0214 22:23:01.004830 23126066861888 run_lib.py:146] step: 11400, eval_loss: 2.43546e-02
I0214 22:23:18.529025 23126066861888 run_lib.py:133] step: 11450, training_loss: 2.45815e-02
I0214 22:23:35.849092 23126066861888 run_lib.py:133] step: 11500, training_loss: 2.44974e-02
I0214 22:23:36.003805 23126066861888 run_lib.py:146] step: 11500, eval_loss: 2.46292e-02
I0214 22:23:53.460047 23126066861888 run_lib.py:133] step: 11550, training_loss: 2.51245e-02
I0214 22:24:10.795108 23126066861888 run_lib.py:133] step: 11600, training_loss: 2.48592e-02
I0214 22:24:10.952069 23126066861888 run_lib.py:146] step: 11600, eval_loss: 2.37485e-02
I0214 22:24:28.296609 23126066861888 run_lib.py:133] step: 11650, training_loss: 2.50604e-02
I0214 22:24:45.633121 23126066861888 run_lib.py:133] step: 11700, training_loss: 2.56639e-02
I0214 22:24:45.785006 23126066861888 run_lib.py:146] step: 11700, eval_loss: 2.44845e-02
I0214 22:25:03.339684 23126066861888 run_lib.py:133] step: 11750, training_loss: 2.49906e-02
I0214 22:25:20.777413 23126066861888 run_lib.py:133] step: 11800, training_loss: 2.33827e-02
I0214 22:25:20.940025 23126066861888 run_lib.py:146] step: 11800, eval_loss: 2.52816e-02
I0214 22:25:38.243632 23126066861888 run_lib.py:133] step: 11850, training_loss: 2.34183e-02
I0214 22:25:55.604794 23126066861888 run_lib.py:133] step: 11900, training_loss: 2.45970e-02
I0214 22:25:55.775840 23126066861888 run_lib.py:146] step: 11900, eval_loss: 2.46125e-02
I0214 22:26:13.125120 23126066861888 run_lib.py:133] step: 11950, training_loss: 2.46791e-02
I0214 22:26:30.656809 23126066861888 run_lib.py:133] step: 12000, training_loss: 2.46316e-02
I0214 22:26:30.810970 23126066861888 run_lib.py:146] step: 12000, eval_loss: 2.42933e-02
I0214 22:26:48.129762 23126066861888 run_lib.py:133] step: 12050, training_loss: 2.41927e-02
I0214 22:27:05.423645 23126066861888 run_lib.py:133] step: 12100, training_loss: 2.30174e-02
I0214 22:27:05.585183 23126066861888 run_lib.py:146] step: 12100, eval_loss: 2.40939e-02
I0214 22:27:22.952126 23126066861888 run_lib.py:133] step: 12150, training_loss: 2.44363e-02
I0214 22:27:40.449972 23126066861888 run_lib.py:133] step: 12200, training_loss: 2.48762e-02
I0214 22:27:40.605212 23126066861888 run_lib.py:146] step: 12200, eval_loss: 2.49423e-02
I0214 22:27:57.969934 23126066861888 run_lib.py:133] step: 12250, training_loss: 2.56282e-02
I0214 22:28:15.401682 23126066861888 run_lib.py:133] step: 12300, training_loss: 2.38728e-02
I0214 22:28:15.555696 23126066861888 run_lib.py:146] step: 12300, eval_loss: 2.40288e-02
I0214 22:28:32.838782 23126066861888 run_lib.py:133] step: 12350, training_loss: 2.38181e-02
I0214 22:28:50.204479 23126066861888 run_lib.py:133] step: 12400, training_loss: 2.45592e-02
I0214 22:28:50.360804 23126066861888 run_lib.py:146] step: 12400, eval_loss: 2.40334e-02
I0214 22:29:07.807694 23126066861888 run_lib.py:133] step: 12450, training_loss: 2.49802e-02
I0214 22:29:25.163080 23126066861888 run_lib.py:133] step: 12500, training_loss: 2.45404e-02
I0214 22:29:25.316486 23126066861888 run_lib.py:146] step: 12500, eval_loss: 2.50071e-02
I0214 22:29:42.876665 23126066861888 run_lib.py:133] step: 12550, training_loss: 2.44446e-02
I0214 22:30:00.203176 23126066861888 run_lib.py:133] step: 12600, training_loss: 2.32581e-02
I0214 22:30:00.356892 23126066861888 run_lib.py:146] step: 12600, eval_loss: 2.57007e-02
I0214 22:30:17.845421 23126066861888 run_lib.py:133] step: 12650, training_loss: 2.43721e-02
I0214 22:30:35.260773 23126066861888 run_lib.py:133] step: 12700, training_loss: 2.41829e-02
I0214 22:30:35.411840 23126066861888 run_lib.py:146] step: 12700, eval_loss: 2.37513e-02
I0214 22:30:52.727666 23126066861888 run_lib.py:133] step: 12750, training_loss: 2.43688e-02
I0214 22:31:10.099440 23126066861888 run_lib.py:133] step: 12800, training_loss: 2.46258e-02
I0214 22:31:10.276842 23126066861888 run_lib.py:146] step: 12800, eval_loss: 2.37003e-02
I0214 22:31:27.862824 23126066861888 run_lib.py:133] step: 12850, training_loss: 2.46347e-02
I0214 22:31:45.365697 23126066861888 run_lib.py:133] step: 12900, training_loss: 2.52508e-02
I0214 22:31:45.522073 23126066861888 run_lib.py:146] step: 12900, eval_loss: 2.37732e-02
I0214 22:32:02.836044 23126066861888 run_lib.py:133] step: 12950, training_loss: 2.44439e-02
I0214 22:32:20.177450 23126066861888 run_lib.py:133] step: 13000, training_loss: 2.51409e-02
I0214 22:32:20.331585 23126066861888 run_lib.py:146] step: 13000, eval_loss: 2.50932e-02
I0214 22:32:37.660106 23126066861888 run_lib.py:133] step: 13050, training_loss: 2.52473e-02
I0214 22:32:55.219671 23126066861888 run_lib.py:133] step: 13100, training_loss: 2.57031e-02
I0214 22:32:55.374716 23126066861888 run_lib.py:146] step: 13100, eval_loss: 2.46810e-02
I0214 22:33:12.796053 23126066861888 run_lib.py:133] step: 13150, training_loss: 2.44480e-02
I0214 22:33:30.153588 23126066861888 run_lib.py:133] step: 13200, training_loss: 2.54739e-02
I0214 22:33:30.306722 23126066861888 run_lib.py:146] step: 13200, eval_loss: 2.41899e-02
I0214 22:33:47.620949 23126066861888 run_lib.py:133] step: 13250, training_loss: 2.40650e-02
I0214 22:34:05.213935 23126066861888 run_lib.py:133] step: 13300, training_loss: 2.49054e-02
I0214 22:34:05.371214 23126066861888 run_lib.py:146] step: 13300, eval_loss: 2.40315e-02
I0214 22:34:22.790533 23126066861888 run_lib.py:133] step: 13350, training_loss: 2.44584e-02
I0214 22:34:40.302388 23126066861888 run_lib.py:133] step: 13400, training_loss: 2.48806e-02
I0214 22:34:40.459194 23126066861888 run_lib.py:146] step: 13400, eval_loss: 2.39141e-02
I0214 22:34:57.852463 23126066861888 run_lib.py:133] step: 13450, training_loss: 2.40473e-02
I0214 22:35:15.150724 23126066861888 run_lib.py:133] step: 13500, training_loss: 2.35952e-02
I0214 22:35:15.305945 23126066861888 run_lib.py:146] step: 13500, eval_loss: 2.40883e-02
I0214 22:35:32.831571 23126066861888 run_lib.py:133] step: 13550, training_loss: 2.34498e-02
I0214 22:35:50.192767 23126066861888 run_lib.py:133] step: 13600, training_loss: 2.33551e-02
I0214 22:35:50.356191 23126066861888 run_lib.py:146] step: 13600, eval_loss: 2.36379e-02
I0214 22:36:07.982424 23126066861888 run_lib.py:133] step: 13650, training_loss: 2.46623e-02
I0214 22:36:25.332844 23126066861888 run_lib.py:133] step: 13700, training_loss: 2.45052e-02
I0214 22:36:25.489898 23126066861888 run_lib.py:146] step: 13700, eval_loss: 2.44497e-02
I0214 22:36:43.026079 23126066861888 run_lib.py:133] step: 13750, training_loss: 2.36231e-02
I0214 22:37:00.389655 23126066861888 run_lib.py:133] step: 13800, training_loss: 2.40672e-02
I0214 22:37:00.547389 23126066861888 run_lib.py:146] step: 13800, eval_loss: 2.43552e-02
I0214 22:37:17.890687 23126066861888 run_lib.py:133] step: 13850, training_loss: 2.43677e-02
I0214 22:37:35.246629 23126066861888 run_lib.py:133] step: 13900, training_loss: 2.38024e-02
I0214 22:37:35.412853 23126066861888 run_lib.py:146] step: 13900, eval_loss: 2.54986e-02
I0214 22:37:52.983106 23126066861888 run_lib.py:133] step: 13950, training_loss: 2.45208e-02
I0214 22:38:10.573014 23126066861888 run_lib.py:133] step: 14000, training_loss: 2.41184e-02
I0214 22:38:10.727085 23126066861888 run_lib.py:146] step: 14000, eval_loss: 2.43455e-02
I0214 22:38:28.151137 23126066861888 run_lib.py:133] step: 14050, training_loss: 2.46290e-02
I0214 22:38:45.523839 23126066861888 run_lib.py:133] step: 14100, training_loss: 2.32951e-02
I0214 22:38:45.675959 23126066861888 run_lib.py:146] step: 14100, eval_loss: 2.34102e-02
I0214 22:39:03.012194 23126066861888 run_lib.py:133] step: 14150, training_loss: 2.50312e-02
I0214 22:39:20.553064 23126066861888 run_lib.py:133] step: 14200, training_loss: 2.39428e-02
I0214 22:39:20.715698 23126066861888 run_lib.py:146] step: 14200, eval_loss: 2.38850e-02
I0214 22:39:38.177310 23126066861888 run_lib.py:133] step: 14250, training_loss: 2.49232e-02
I0214 22:39:55.597698 23126066861888 run_lib.py:133] step: 14300, training_loss: 2.39747e-02
I0214 22:39:55.753582 23126066861888 run_lib.py:146] step: 14300, eval_loss: 2.41252e-02
I0214 22:40:13.096486 23126066861888 run_lib.py:133] step: 14350, training_loss: 2.49159e-02
I0214 22:40:30.631552 23126066861888 run_lib.py:133] step: 14400, training_loss: 2.47849e-02
I0214 22:40:30.785926 23126066861888 run_lib.py:146] step: 14400, eval_loss: 2.41100e-02
I0214 22:40:48.154972 23126066861888 run_lib.py:133] step: 14450, training_loss: 2.39625e-02
I0214 22:41:05.577823 23126066861888 run_lib.py:133] step: 14500, training_loss: 2.40968e-02
I0214 22:41:05.735556 23126066861888 run_lib.py:146] step: 14500, eval_loss: 2.46883e-02
I0214 22:41:23.153630 23126066861888 run_lib.py:133] step: 14550, training_loss: 2.46944e-02
I0214 22:41:40.521333 23126066861888 run_lib.py:133] step: 14600, training_loss: 2.37666e-02
I0214 22:41:40.673937 23126066861888 run_lib.py:146] step: 14600, eval_loss: 2.45200e-02
I0214 22:41:58.182197 23126066861888 run_lib.py:133] step: 14650, training_loss: 2.48708e-02
I0214 22:42:15.534657 23126066861888 run_lib.py:133] step: 14700, training_loss: 2.44097e-02
I0214 22:42:15.693034 23126066861888 run_lib.py:146] step: 14700, eval_loss: 2.35744e-02
I0214 22:42:33.158170 23126066861888 run_lib.py:133] step: 14750, training_loss: 2.36886e-02
I0214 22:42:50.534059 23126066861888 run_lib.py:133] step: 14800, training_loss: 2.47357e-02
I0214 22:42:50.696045 23126066861888 run_lib.py:146] step: 14800, eval_loss: 2.42183e-02
I0214 22:43:08.229377 23126066861888 run_lib.py:133] step: 14850, training_loss: 2.40514e-02
I0214 22:43:25.560488 23126066861888 run_lib.py:133] step: 14900, training_loss: 2.38584e-02
I0214 22:43:25.717563 23126066861888 run_lib.py:146] step: 14900, eval_loss: 2.37214e-02
I0214 22:43:43.028137 23126066861888 run_lib.py:133] step: 14950, training_loss: 2.33119e-02
I0214 22:44:00.351461 23126066861888 run_lib.py:133] step: 15000, training_loss: 2.40836e-02
I0214 22:44:00.507948 23126066861888 run_lib.py:146] step: 15000, eval_loss: 2.41204e-02
I0214 22:44:17.971108 23126066861888 run_lib.py:133] step: 15050, training_loss: 2.44411e-02
I0214 22:44:35.460428 23126066861888 run_lib.py:133] step: 15100, training_loss: 2.45177e-02
I0214 22:44:35.628983 23126066861888 run_lib.py:146] step: 15100, eval_loss: 2.38532e-02
I0214 22:44:52.961672 23126066861888 run_lib.py:133] step: 15150, training_loss: 2.40786e-02
I0214 22:45:10.286398 23126066861888 run_lib.py:133] step: 15200, training_loss: 2.45809e-02
I0214 22:45:10.444015 23126066861888 run_lib.py:146] step: 15200, eval_loss: 2.51282e-02
I0214 22:45:27.758275 23126066861888 run_lib.py:133] step: 15250, training_loss: 2.41564e-02
I0214 22:45:45.294716 23126066861888 run_lib.py:133] step: 15300, training_loss: 2.40854e-02
I0214 22:45:45.451796 23126066861888 run_lib.py:146] step: 15300, eval_loss: 2.38571e-02
I0214 22:46:02.763993 23126066861888 run_lib.py:133] step: 15350, training_loss: 2.43042e-02
I0214 22:46:20.206939 23126066861888 run_lib.py:133] step: 15400, training_loss: 2.40742e-02
I0214 22:46:20.363996 23126066861888 run_lib.py:146] step: 15400, eval_loss: 2.43049e-02
I0214 22:46:37.681357 23126066861888 run_lib.py:133] step: 15450, training_loss: 2.38590e-02
I0214 22:46:55.161067 23126066861888 run_lib.py:133] step: 15500, training_loss: 2.48502e-02
I0214 22:46:55.314014 23126066861888 run_lib.py:146] step: 15500, eval_loss: 2.45094e-02
I0214 22:47:12.616182 23126066861888 run_lib.py:133] step: 15550, training_loss: 2.38347e-02
I0214 22:47:30.072857 23126066861888 run_lib.py:133] step: 15600, training_loss: 2.42134e-02
I0214 22:47:30.226800 23126066861888 run_lib.py:146] step: 15600, eval_loss: 2.46358e-02
I0214 22:47:47.654807 23126066861888 run_lib.py:133] step: 15650, training_loss: 2.40016e-02
I0214 22:48:05.060997 23126066861888 run_lib.py:133] step: 15700, training_loss: 2.38662e-02
I0214 22:48:05.216132 23126066861888 run_lib.py:146] step: 15700, eval_loss: 2.43916e-02
I0214 22:48:22.713726 23126066861888 run_lib.py:133] step: 15750, training_loss: 2.33558e-02
I0214 22:48:40.022398 23126066861888 run_lib.py:133] step: 15800, training_loss: 2.41288e-02
I0214 22:48:40.176824 23126066861888 run_lib.py:146] step: 15800, eval_loss: 2.43110e-02
I0214 22:48:57.672398 23126066861888 run_lib.py:133] step: 15850, training_loss: 2.47075e-02
I0214 22:49:15.048186 23126066861888 run_lib.py:133] step: 15900, training_loss: 2.46046e-02
I0214 22:49:15.205794 23126066861888 run_lib.py:146] step: 15900, eval_loss: 2.31882e-02
I0214 22:49:32.739665 23126066861888 run_lib.py:133] step: 15950, training_loss: 2.41184e-02
I0214 22:49:50.189834 23126066861888 run_lib.py:133] step: 16000, training_loss: 2.40747e-02
I0214 22:49:50.343965 23126066861888 run_lib.py:146] step: 16000, eval_loss: 2.44256e-02
I0214 22:50:07.703249 23126066861888 run_lib.py:133] step: 16050, training_loss: 2.50882e-02
I0214 22:50:25.078755 23126066861888 run_lib.py:133] step: 16100, training_loss: 2.44731e-02
I0214 22:50:25.232986 23126066861888 run_lib.py:146] step: 16100, eval_loss: 2.44859e-02
I0214 22:50:42.780469 23126066861888 run_lib.py:133] step: 16150, training_loss: 2.47875e-02
I0214 22:51:00.346877 23126066861888 run_lib.py:133] step: 16200, training_loss: 2.37140e-02
I0214 22:51:00.500969 23126066861888 run_lib.py:146] step: 16200, eval_loss: 2.45595e-02
I0214 22:51:17.889258 23126066861888 run_lib.py:133] step: 16250, training_loss: 2.35839e-02
I0214 22:51:35.307313 23126066861888 run_lib.py:133] step: 16300, training_loss: 2.41738e-02
I0214 22:51:35.468990 23126066861888 run_lib.py:146] step: 16300, eval_loss: 2.40723e-02
I0214 22:51:52.865556 23126066861888 run_lib.py:133] step: 16350, training_loss: 2.41643e-02
I0214 22:52:10.451494 23126066861888 run_lib.py:133] step: 16400, training_loss: 2.40401e-02
I0214 22:52:10.603816 23126066861888 run_lib.py:146] step: 16400, eval_loss: 2.43748e-02
I0214 22:52:27.937086 23126066861888 run_lib.py:133] step: 16450, training_loss: 2.41708e-02
I0214 22:52:45.331833 23126066861888 run_lib.py:133] step: 16500, training_loss: 2.36827e-02
I0214 22:52:45.484751 23126066861888 run_lib.py:146] step: 16500, eval_loss: 2.40642e-02
I0214 22:53:02.882767 23126066861888 run_lib.py:133] step: 16550, training_loss: 2.48799e-02
I0214 22:53:20.496802 23126066861888 run_lib.py:133] step: 16600, training_loss: 2.37959e-02
I0214 22:53:20.655750 23126066861888 run_lib.py:146] step: 16600, eval_loss: 2.42971e-02
I0214 22:53:37.983881 23126066861888 run_lib.py:133] step: 16650, training_loss: 2.35915e-02
I0214 22:53:55.460968 23126066861888 run_lib.py:133] step: 16700, training_loss: 2.34117e-02
I0214 22:53:55.614922 23126066861888 run_lib.py:146] step: 16700, eval_loss: 2.48190e-02
I0214 22:54:12.972211 23126066861888 run_lib.py:133] step: 16750, training_loss: 2.43888e-02
I0214 22:54:30.348202 23126066861888 run_lib.py:133] step: 16800, training_loss: 2.39831e-02
I0214 22:54:30.504106 23126066861888 run_lib.py:146] step: 16800, eval_loss: 2.46400e-02
I0214 22:54:47.999128 23126066861888 run_lib.py:133] step: 16850, training_loss: 2.43823e-02
I0214 22:55:05.380898 23126066861888 run_lib.py:133] step: 16900, training_loss: 2.46689e-02
I0214 22:55:05.536714 23126066861888 run_lib.py:146] step: 16900, eval_loss: 2.38204e-02
I0214 22:55:23.175305 23126066861888 run_lib.py:133] step: 16950, training_loss: 2.47090e-02
I0214 22:55:40.530442 23126066861888 run_lib.py:133] step: 17000, training_loss: 2.37908e-02
I0214 22:55:40.693942 23126066861888 run_lib.py:146] step: 17000, eval_loss: 2.35108e-02
I0214 22:55:58.248756 23126066861888 run_lib.py:133] step: 17050, training_loss: 2.37620e-02
I0214 22:56:15.593242 23126066861888 run_lib.py:133] step: 17100, training_loss: 2.36168e-02
I0214 22:56:15.752191 23126066861888 run_lib.py:146] step: 17100, eval_loss: 2.39972e-02
I0214 22:56:33.194541 23126066861888 run_lib.py:133] step: 17150, training_loss: 2.40827e-02
I0214 22:56:50.560682 23126066861888 run_lib.py:133] step: 17200, training_loss: 2.38136e-02
I0214 22:56:50.722328 23126066861888 run_lib.py:146] step: 17200, eval_loss: 2.44068e-02
I0214 22:57:08.265988 23126066861888 run_lib.py:133] step: 17250, training_loss: 2.33418e-02
I0214 22:57:25.816146 23126066861888 run_lib.py:133] step: 17300, training_loss: 2.39308e-02
I0214 22:57:25.973181 23126066861888 run_lib.py:146] step: 17300, eval_loss: 2.42851e-02
I0214 22:57:43.341077 23126066861888 run_lib.py:133] step: 17350, training_loss: 2.47793e-02
I0214 22:58:00.700230 23126066861888 run_lib.py:133] step: 17400, training_loss: 2.39194e-02
I0214 22:58:00.851962 23126066861888 run_lib.py:146] step: 17400, eval_loss: 2.39596e-02
I0214 22:58:18.188858 23126066861888 run_lib.py:133] step: 17450, training_loss: 2.43237e-02
I0214 22:58:35.716603 23126066861888 run_lib.py:133] step: 17500, training_loss: 2.43366e-02
I0214 22:58:35.886149 23126066861888 run_lib.py:146] step: 17500, eval_loss: 2.42725e-02
I0214 22:58:53.320784 23126066861888 run_lib.py:133] step: 17550, training_loss: 2.43168e-02
I0214 22:59:10.662066 23126066861888 run_lib.py:133] step: 17600, training_loss: 2.40432e-02
I0214 22:59:10.819147 23126066861888 run_lib.py:146] step: 17600, eval_loss: 2.38056e-02
I0214 22:59:28.182765 23126066861888 run_lib.py:133] step: 17650, training_loss: 2.30948e-02
I0214 22:59:45.743252 23126066861888 run_lib.py:133] step: 17700, training_loss: 2.41855e-02
I0214 22:59:45.901844 23126066861888 run_lib.py:146] step: 17700, eval_loss: 2.39601e-02
I0214 23:00:03.268686 23126066861888 run_lib.py:133] step: 17750, training_loss: 2.38827e-02
I0214 23:00:20.786488 23126066861888 run_lib.py:133] step: 17800, training_loss: 2.46488e-02
I0214 23:00:20.950260 23126066861888 run_lib.py:146] step: 17800, eval_loss: 2.36418e-02
I0214 23:00:38.368029 23126066861888 run_lib.py:133] step: 17850, training_loss: 2.45792e-02
I0214 23:00:55.758726 23126066861888 run_lib.py:133] step: 17900, training_loss: 2.34374e-02
I0214 23:00:55.919980 23126066861888 run_lib.py:146] step: 17900, eval_loss: 2.35427e-02
I0214 23:01:13.506021 23126066861888 run_lib.py:133] step: 17950, training_loss: 2.44249e-02
I0214 23:01:30.865139 23126066861888 run_lib.py:133] step: 18000, training_loss: 2.44719e-02
I0214 23:01:31.023150 23126066861888 run_lib.py:146] step: 18000, eval_loss: 2.51995e-02
I0214 23:01:48.594968 23126066861888 run_lib.py:133] step: 18050, training_loss: 2.41328e-02
I0214 23:02:06.053664 23126066861888 run_lib.py:133] step: 18100, training_loss: 2.26109e-02
I0214 23:02:06.208182 23126066861888 run_lib.py:146] step: 18100, eval_loss: 2.41802e-02
I0214 23:02:23.781984 23126066861888 run_lib.py:133] step: 18150, training_loss: 2.45923e-02
I0214 23:02:41.147724 23126066861888 run_lib.py:133] step: 18200, training_loss: 2.39156e-02
I0214 23:02:41.310728 23126066861888 run_lib.py:146] step: 18200, eval_loss: 2.41423e-02
I0214 23:02:58.665261 23126066861888 run_lib.py:133] step: 18250, training_loss: 2.42745e-02
I0214 23:03:16.042722 23126066861888 run_lib.py:133] step: 18300, training_loss: 2.43311e-02
I0214 23:03:16.199111 23126066861888 run_lib.py:146] step: 18300, eval_loss: 2.48776e-02
I0214 23:03:33.825474 23126066861888 run_lib.py:133] step: 18350, training_loss: 2.40836e-02
I0214 23:03:51.421915 23126066861888 run_lib.py:133] step: 18400, training_loss: 2.42341e-02
I0214 23:03:51.578999 23126066861888 run_lib.py:146] step: 18400, eval_loss: 2.46794e-02
I0214 23:04:08.912664 23126066861888 run_lib.py:133] step: 18450, training_loss: 2.42539e-02
I0214 23:04:26.229628 23126066861888 run_lib.py:133] step: 18500, training_loss: 2.39605e-02
I0214 23:04:26.385052 23126066861888 run_lib.py:146] step: 18500, eval_loss: 2.39642e-02
I0214 23:04:43.740831 23126066861888 run_lib.py:133] step: 18550, training_loss: 2.39010e-02
I0214 23:05:01.290283 23126066861888 run_lib.py:133] step: 18600, training_loss: 2.49290e-02
I0214 23:05:01.460711 23126066861888 run_lib.py:146] step: 18600, eval_loss: 2.41233e-02
I0214 23:05:18.857502 23126066861888 run_lib.py:133] step: 18650, training_loss: 2.38222e-02
I0214 23:05:36.210969 23126066861888 run_lib.py:133] step: 18700, training_loss: 2.44189e-02
I0214 23:05:36.368214 23126066861888 run_lib.py:146] step: 18700, eval_loss: 2.44362e-02
I0214 23:05:53.757518 23126066861888 run_lib.py:133] step: 18750, training_loss: 2.43119e-02
I0214 23:06:11.328699 23126066861888 run_lib.py:133] step: 18800, training_loss: 2.41037e-02
I0214 23:06:11.487632 23126066861888 run_lib.py:146] step: 18800, eval_loss: 2.32233e-02
I0214 23:06:28.828548 23126066861888 run_lib.py:133] step: 18850, training_loss: 2.39856e-02
I0214 23:06:46.285507 23126066861888 run_lib.py:133] step: 18900, training_loss: 2.40371e-02
I0214 23:06:46.448102 23126066861888 run_lib.py:146] step: 18900, eval_loss: 2.46654e-02
I0214 23:07:03.837466 23126066861888 run_lib.py:133] step: 18950, training_loss: 2.43085e-02
I0214 23:07:21.207952 23126066861888 run_lib.py:133] step: 19000, training_loss: 2.38898e-02
I0214 23:07:21.365118 23126066861888 run_lib.py:146] step: 19000, eval_loss: 2.42160e-02
I0214 23:07:38.886385 23126066861888 run_lib.py:133] step: 19050, training_loss: 2.37225e-02
I0214 23:07:56.230650 23126066861888 run_lib.py:133] step: 19100, training_loss: 2.39834e-02
I0214 23:07:56.384843 23126066861888 run_lib.py:146] step: 19100, eval_loss: 2.40032e-02
I0214 23:08:13.947321 23126066861888 run_lib.py:133] step: 19150, training_loss: 2.41917e-02
I0214 23:08:31.397124 23126066861888 run_lib.py:133] step: 19200, training_loss: 2.42907e-02
I0214 23:08:31.556040 23126066861888 run_lib.py:146] step: 19200, eval_loss: 2.40203e-02
I0214 23:08:49.082005 23126066861888 run_lib.py:133] step: 19250, training_loss: 2.40284e-02
I0214 23:09:06.448363 23126066861888 run_lib.py:133] step: 19300, training_loss: 2.54183e-02
I0214 23:09:06.600736 23126066861888 run_lib.py:146] step: 19300, eval_loss: 2.37632e-02
I0214 23:09:23.948919 23126066861888 run_lib.py:133] step: 19350, training_loss: 2.37917e-02
I0214 23:09:41.341448 23126066861888 run_lib.py:133] step: 19400, training_loss: 2.40092e-02
I0214 23:09:41.506014 23126066861888 run_lib.py:146] step: 19400, eval_loss: 2.27865e-02
I0214 23:09:59.077021 23126066861888 run_lib.py:133] step: 19450, training_loss: 2.35761e-02
I0214 23:10:16.718034 23126066861888 run_lib.py:133] step: 19500, training_loss: 2.46649e-02
I0214 23:10:16.877721 23126066861888 run_lib.py:146] step: 19500, eval_loss: 2.41271e-02
I0214 23:10:34.227116 23126066861888 run_lib.py:133] step: 19550, training_loss: 2.39465e-02
I0214 23:10:51.585922 23126066861888 run_lib.py:133] step: 19600, training_loss: 2.35895e-02
I0214 23:10:51.739775 23126066861888 run_lib.py:146] step: 19600, eval_loss: 2.38537e-02
I0214 23:11:09.135023 23126066861888 run_lib.py:133] step: 19650, training_loss: 2.46205e-02
I0214 23:11:26.758777 23126066861888 run_lib.py:133] step: 19700, training_loss: 2.42646e-02
I0214 23:11:26.914082 23126066861888 run_lib.py:146] step: 19700, eval_loss: 2.46461e-02
I0214 23:11:44.283131 23126066861888 run_lib.py:133] step: 19750, training_loss: 2.43625e-02
I0214 23:12:01.612039 23126066861888 run_lib.py:133] step: 19800, training_loss: 2.40252e-02
I0214 23:12:01.763721 23126066861888 run_lib.py:146] step: 19800, eval_loss: 2.39043e-02
I0214 23:12:19.152793 23126066861888 run_lib.py:133] step: 19850, training_loss: 2.41319e-02
I0214 23:12:36.741272 23126066861888 run_lib.py:133] step: 19900, training_loss: 2.44330e-02
I0214 23:12:36.908086 23126066861888 run_lib.py:146] step: 19900, eval_loss: 2.53530e-02
I0214 23:12:54.257228 23126066861888 run_lib.py:133] step: 19950, training_loss: 2.48530e-02
I0214 23:13:11.763103 23126066861888 run_lib.py:133] step: 20000, training_loss: 2.37014e-02
I0214 23:13:12.446543 23126066861888 run_lib.py:146] step: 20000, eval_loss: 2.33731e-02
I0214 23:13:32.426964 23126066861888 run_lib.py:133] step: 20050, training_loss: 2.44520e-02
I0214 23:13:49.812371 23126066861888 run_lib.py:133] step: 20100, training_loss: 2.36510e-02
I0214 23:13:49.971921 23126066861888 run_lib.py:146] step: 20100, eval_loss: 2.38407e-02
I0214 23:14:07.327403 23126066861888 run_lib.py:133] step: 20150, training_loss: 2.39756e-02
I0214 23:14:24.909824 23126066861888 run_lib.py:133] step: 20200, training_loss: 2.40897e-02
I0214 23:14:25.072201 23126066861888 run_lib.py:146] step: 20200, eval_loss: 2.44653e-02
I0214 23:14:42.642119 23126066861888 run_lib.py:133] step: 20250, training_loss: 2.38799e-02
I0214 23:15:00.020798 23126066861888 run_lib.py:133] step: 20300, training_loss: 2.45158e-02
I0214 23:15:00.174087 23126066861888 run_lib.py:146] step: 20300, eval_loss: 2.36227e-02
I0214 23:15:17.507887 23126066861888 run_lib.py:133] step: 20350, training_loss: 2.40831e-02
I0214 23:15:34.881544 23126066861888 run_lib.py:133] step: 20400, training_loss: 2.40162e-02
I0214 23:15:35.037747 23126066861888 run_lib.py:146] step: 20400, eval_loss: 2.41622e-02
I0214 23:15:52.573470 23126066861888 run_lib.py:133] step: 20450, training_loss: 2.28990e-02
I0214 23:16:10.114218 23126066861888 run_lib.py:133] step: 20500, training_loss: 2.41918e-02
I0214 23:16:10.286956 23126066861888 run_lib.py:146] step: 20500, eval_loss: 2.46394e-02
I0214 23:16:27.685836 23126066861888 run_lib.py:133] step: 20550, training_loss: 2.40045e-02
I0214 23:16:45.099133 23126066861888 run_lib.py:133] step: 20600, training_loss: 2.39208e-02
I0214 23:16:45.252379 23126066861888 run_lib.py:146] step: 20600, eval_loss: 2.40424e-02
I0214 23:17:02.832496 23126066861888 run_lib.py:133] step: 20650, training_loss: 2.49676e-02
I0214 23:17:20.180173 23126066861888 run_lib.py:133] step: 20700, training_loss: 2.38352e-02
I0214 23:17:20.332729 23126066861888 run_lib.py:146] step: 20700, eval_loss: 2.44920e-02
I0214 23:17:37.678644 23126066861888 run_lib.py:133] step: 20750, training_loss: 2.50021e-02
I0214 23:17:55.218287 23126066861888 run_lib.py:133] step: 20800, training_loss: 2.38963e-02
I0214 23:17:55.375131 23126066861888 run_lib.py:146] step: 20800, eval_loss: 2.41421e-02
I0214 23:18:12.802940 23126066861888 run_lib.py:133] step: 20850, training_loss: 2.43297e-02
I0214 23:18:30.400914 23126066861888 run_lib.py:133] step: 20900, training_loss: 2.37091e-02
I0214 23:18:30.564966 23126066861888 run_lib.py:146] step: 20900, eval_loss: 2.41420e-02
I0214 23:18:47.899632 23126066861888 run_lib.py:133] step: 20950, training_loss: 2.40923e-02
I0214 23:19:05.335381 23126066861888 run_lib.py:133] step: 21000, training_loss: 2.34805e-02
I0214 23:19:05.492753 23126066861888 run_lib.py:146] step: 21000, eval_loss: 2.42002e-02
I0214 23:19:23.032493 23126066861888 run_lib.py:133] step: 21050, training_loss: 2.42103e-02
I0214 23:19:40.490560 23126066861888 run_lib.py:133] step: 21100, training_loss: 2.43735e-02
I0214 23:19:40.648241 23126066861888 run_lib.py:146] step: 21100, eval_loss: 2.45143e-02
I0214 23:19:57.998722 23126066861888 run_lib.py:133] step: 21150, training_loss: 2.45894e-02
I0214 23:20:15.394463 23126066861888 run_lib.py:133] step: 21200, training_loss: 2.39648e-02
I0214 23:20:15.550954 23126066861888 run_lib.py:146] step: 21200, eval_loss: 2.42832e-02
I0214 23:20:33.150306 23126066861888 run_lib.py:133] step: 21250, training_loss: 2.40850e-02
I0214 23:20:50.534336 23126066861888 run_lib.py:133] step: 21300, training_loss: 2.37196e-02
I0214 23:20:50.687668 23126066861888 run_lib.py:146] step: 21300, eval_loss: 2.41483e-02
I0214 23:21:08.221372 23126066861888 run_lib.py:133] step: 21350, training_loss: 2.40337e-02
I0214 23:21:25.618185 23126066861888 run_lib.py:133] step: 21400, training_loss: 2.47366e-02
I0214 23:21:25.776916 23126066861888 run_lib.py:146] step: 21400, eval_loss: 2.50135e-02
I0214 23:21:43.175364 23126066861888 run_lib.py:133] step: 21450, training_loss: 2.44905e-02
I0214 23:22:00.528370 23126066861888 run_lib.py:133] step: 21500, training_loss: 2.39919e-02
I0214 23:22:00.684265 23126066861888 run_lib.py:146] step: 21500, eval_loss: 2.41917e-02
I0214 23:22:18.244328 23126066861888 run_lib.py:133] step: 21550, training_loss: 2.29053e-02
I0214 23:22:35.729128 23126066861888 run_lib.py:133] step: 21600, training_loss: 2.32608e-02
I0214 23:22:35.893752 23126066861888 run_lib.py:146] step: 21600, eval_loss: 2.39435e-02
I0214 23:22:53.316071 23126066861888 run_lib.py:133] step: 21650, training_loss: 2.42505e-02
I0214 23:23:10.737535 23126066861888 run_lib.py:133] step: 21700, training_loss: 2.40443e-02
I0214 23:23:10.893990 23126066861888 run_lib.py:146] step: 21700, eval_loss: 2.36019e-02
I0214 23:23:28.413038 23126066861888 run_lib.py:133] step: 21750, training_loss: 2.44453e-02
I0214 23:23:45.754166 23126066861888 run_lib.py:133] step: 21800, training_loss: 2.33759e-02
I0214 23:23:45.916313 23126066861888 run_lib.py:146] step: 21800, eval_loss: 2.37349e-02
I0214 23:24:03.280183 23126066861888 run_lib.py:133] step: 21850, training_loss: 2.42409e-02
I0214 23:24:20.836388 23126066861888 run_lib.py:133] step: 21900, training_loss: 2.40266e-02
I0214 23:24:21.011889 23126066861888 run_lib.py:146] step: 21900, eval_loss: 2.46274e-02
I0214 23:24:38.402031 23126066861888 run_lib.py:133] step: 21950, training_loss: 2.28967e-02
I0214 23:24:55.990175 23126066861888 run_lib.py:133] step: 22000, training_loss: 2.34337e-02
I0214 23:24:56.145077 23126066861888 run_lib.py:146] step: 22000, eval_loss: 2.48680e-02
I0214 23:25:13.551926 23126066861888 run_lib.py:133] step: 22050, training_loss: 2.38121e-02
I0214 23:25:30.914081 23126066861888 run_lib.py:133] step: 22100, training_loss: 2.38036e-02
I0214 23:25:31.068555 23126066861888 run_lib.py:146] step: 22100, eval_loss: 2.32141e-02
I0214 23:25:48.569959 23126066861888 run_lib.py:133] step: 22150, training_loss: 2.32287e-02
I0214 23:26:06.004283 23126066861888 run_lib.py:133] step: 22200, training_loss: 2.35688e-02
I0214 23:26:06.165544 23126066861888 run_lib.py:146] step: 22200, eval_loss: 2.40913e-02
I0214 23:26:23.580147 23126066861888 run_lib.py:133] step: 22250, training_loss: 2.34564e-02
I0214 23:26:41.125692 23126066861888 run_lib.py:133] step: 22300, training_loss: 2.41591e-02
I0214 23:26:41.286815 23126066861888 run_lib.py:146] step: 22300, eval_loss: 2.39660e-02
I0214 23:26:58.660626 23126066861888 run_lib.py:133] step: 22350, training_loss: 2.40588e-02
I0214 23:27:16.012576 23126066861888 run_lib.py:133] step: 22400, training_loss: 2.35657e-02
I0214 23:27:16.170055 23126066861888 run_lib.py:146] step: 22400, eval_loss: 2.44527e-02
I0214 23:27:33.655860 23126066861888 run_lib.py:133] step: 22450, training_loss: 2.39912e-02
I0214 23:27:51.095250 23126066861888 run_lib.py:133] step: 22500, training_loss: 2.51725e-02
I0214 23:27:51.255949 23126066861888 run_lib.py:146] step: 22500, eval_loss: 2.40382e-02
I0214 23:28:08.614540 23126066861888 run_lib.py:133] step: 22550, training_loss: 2.43912e-02
I0214 23:28:25.966957 23126066861888 run_lib.py:133] step: 22600, training_loss: 2.45494e-02
I0214 23:28:26.120679 23126066861888 run_lib.py:146] step: 22600, eval_loss: 2.38498e-02
I0214 23:28:43.698359 23126066861888 run_lib.py:133] step: 22650, training_loss: 2.31616e-02
I0214 23:29:01.138168 23126066861888 run_lib.py:133] step: 22700, training_loss: 2.43520e-02
I0214 23:29:01.290840 23126066861888 run_lib.py:146] step: 22700, eval_loss: 2.41290e-02
I0214 23:29:18.690387 23126066861888 run_lib.py:133] step: 22750, training_loss: 2.37382e-02
I0214 23:29:36.041961 23126066861888 run_lib.py:133] step: 22800, training_loss: 2.40765e-02
I0214 23:29:36.211932 23126066861888 run_lib.py:146] step: 22800, eval_loss: 2.46314e-02
I0214 23:29:53.830348 23126066861888 run_lib.py:133] step: 22850, training_loss: 2.41696e-02
I0214 23:30:11.221852 23126066861888 run_lib.py:133] step: 22900, training_loss: 2.36359e-02
I0214 23:30:11.379063 23126066861888 run_lib.py:146] step: 22900, eval_loss: 2.37446e-02
I0214 23:30:28.716806 23126066861888 run_lib.py:133] step: 22950, training_loss: 2.42173e-02
I0214 23:30:46.311423 23126066861888 run_lib.py:133] step: 23000, training_loss: 2.43614e-02
I0214 23:30:46.478305 23126066861888 run_lib.py:146] step: 23000, eval_loss: 2.47765e-02
I0214 23:31:03.904109 23126066861888 run_lib.py:133] step: 23050, training_loss: 2.40077e-02
I0214 23:31:21.484522 23126066861888 run_lib.py:133] step: 23100, training_loss: 2.30595e-02
I0214 23:31:21.645784 23126066861888 run_lib.py:146] step: 23100, eval_loss: 2.46550e-02
I0214 23:31:38.995547 23126066861888 run_lib.py:133] step: 23150, training_loss: 2.33175e-02
I0214 23:31:56.360779 23126066861888 run_lib.py:133] step: 23200, training_loss: 2.36576e-02
I0214 23:31:56.523065 23126066861888 run_lib.py:146] step: 23200, eval_loss: 2.48093e-02
I0214 23:32:14.072343 23126066861888 run_lib.py:133] step: 23250, training_loss: 2.36357e-02
I0214 23:32:31.485145 23126066861888 run_lib.py:133] step: 23300, training_loss: 2.31148e-02
I0214 23:32:31.658979 23126066861888 run_lib.py:146] step: 23300, eval_loss: 2.31366e-02
I0214 23:32:49.058691 23126066861888 run_lib.py:133] step: 23350, training_loss: 2.42190e-02
I0214 23:33:06.635108 23126066861888 run_lib.py:133] step: 23400, training_loss: 2.35640e-02
I0214 23:33:06.790891 23126066861888 run_lib.py:146] step: 23400, eval_loss: 2.50280e-02
I0214 23:33:24.155761 23126066861888 run_lib.py:133] step: 23450, training_loss: 2.35873e-02
I0214 23:33:41.472632 23126066861888 run_lib.py:133] step: 23500, training_loss: 2.37016e-02
I0214 23:33:41.628784 23126066861888 run_lib.py:146] step: 23500, eval_loss: 2.35065e-02
I0214 23:33:59.074032 23126066861888 run_lib.py:133] step: 23550, training_loss: 2.35360e-02
I0214 23:34:16.562811 23126066861888 run_lib.py:133] step: 23600, training_loss: 2.38957e-02
I0214 23:34:16.714384 23126066861888 run_lib.py:146] step: 23600, eval_loss: 2.41670e-02
I0214 23:34:34.079286 23126066861888 run_lib.py:133] step: 23650, training_loss: 2.35170e-02
I0214 23:34:51.470114 23126066861888 run_lib.py:133] step: 23700, training_loss: 2.30949e-02
I0214 23:34:51.628871 23126066861888 run_lib.py:146] step: 23700, eval_loss: 2.37243e-02
I0214 23:35:09.203861 23126066861888 run_lib.py:133] step: 23750, training_loss: 2.48204e-02
I0214 23:35:26.540810 23126066861888 run_lib.py:133] step: 23800, training_loss: 2.38598e-02
I0214 23:35:26.698793 23126066861888 run_lib.py:146] step: 23800, eval_loss: 2.48902e-02
I0214 23:35:44.105976 23126066861888 run_lib.py:133] step: 23850, training_loss: 2.33867e-02
I0214 23:36:01.497763 23126066861888 run_lib.py:133] step: 23900, training_loss: 2.52441e-02
I0214 23:36:01.660108 23126066861888 run_lib.py:146] step: 23900, eval_loss: 2.41574e-02
I0214 23:36:19.230334 23126066861888 run_lib.py:133] step: 23950, training_loss: 2.35549e-02
I0214 23:36:36.578948 23126066861888 run_lib.py:133] step: 24000, training_loss: 2.40544e-02
I0214 23:36:36.734230 23126066861888 run_lib.py:146] step: 24000, eval_loss: 2.39311e-02
I0214 23:36:54.038054 23126066861888 run_lib.py:133] step: 24050, training_loss: 2.46600e-02
I0214 23:37:11.627246 23126066861888 run_lib.py:133] step: 24100, training_loss: 2.34280e-02
I0214 23:37:11.782527 23126066861888 run_lib.py:146] step: 24100, eval_loss: 2.46862e-02
I0214 23:37:29.156533 23126066861888 run_lib.py:133] step: 24150, training_loss: 2.38877e-02
I0214 23:37:46.674531 23126066861888 run_lib.py:133] step: 24200, training_loss: 2.46863e-02
I0214 23:37:46.831056 23126066861888 run_lib.py:146] step: 24200, eval_loss: 2.40763e-02
I0214 23:38:04.146558 23126066861888 run_lib.py:133] step: 24250, training_loss: 2.43177e-02
I0214 23:38:21.483599 23126066861888 run_lib.py:133] step: 24300, training_loss: 2.47140e-02
I0214 23:38:21.641121 23126066861888 run_lib.py:146] step: 24300, eval_loss: 2.40224e-02
I0214 23:38:39.163621 23126066861888 run_lib.py:133] step: 24350, training_loss: 2.37814e-02
I0214 23:38:56.588937 23126066861888 run_lib.py:133] step: 24400, training_loss: 2.37269e-02
I0214 23:38:56.741442 23126066861888 run_lib.py:146] step: 24400, eval_loss: 2.39212e-02
I0214 23:39:14.065551 23126066861888 run_lib.py:133] step: 24450, training_loss: 2.34328e-02
I0214 23:39:31.640696 23126066861888 run_lib.py:133] step: 24500, training_loss: 2.36822e-02
I0214 23:39:31.797943 23126066861888 run_lib.py:146] step: 24500, eval_loss: 2.39499e-02
I0214 23:39:49.165510 23126066861888 run_lib.py:133] step: 24550, training_loss: 2.47187e-02
I0214 23:40:06.499828 23126066861888 run_lib.py:133] step: 24600, training_loss: 2.34141e-02
I0214 23:40:06.651999 23126066861888 run_lib.py:146] step: 24600, eval_loss: 2.43007e-02
I0214 23:40:24.130458 23126066861888 run_lib.py:133] step: 24650, training_loss: 2.37314e-02
I0214 23:40:41.532772 23126066861888 run_lib.py:133] step: 24700, training_loss: 2.26272e-02
I0214 23:40:41.694726 23126066861888 run_lib.py:146] step: 24700, eval_loss: 2.37573e-02
I0214 23:40:59.063585 23126066861888 run_lib.py:133] step: 24750, training_loss: 2.37085e-02
I0214 23:41:16.399681 23126066861888 run_lib.py:133] step: 24800, training_loss: 2.37385e-02
I0214 23:41:16.554345 23126066861888 run_lib.py:146] step: 24800, eval_loss: 2.37857e-02
I0214 23:41:34.081963 23126066861888 run_lib.py:133] step: 24850, training_loss: 2.35963e-02
I0214 23:41:51.514798 23126066861888 run_lib.py:133] step: 24900, training_loss: 2.33355e-02
I0214 23:41:51.677141 23126066861888 run_lib.py:146] step: 24900, eval_loss: 2.34084e-02
I0214 23:42:09.062424 23126066861888 run_lib.py:133] step: 24950, training_loss: 2.30290e-02
I0214 23:42:26.439631 23126066861888 run_lib.py:133] step: 25000, training_loss: 2.34123e-02
I0214 23:42:26.600965 23126066861888 run_lib.py:146] step: 25000, eval_loss: 2.33729e-02
I0214 23:42:44.114563 23126066861888 run_lib.py:133] step: 25050, training_loss: 2.34315e-02
I0214 23:43:01.464685 23126066861888 run_lib.py:133] step: 25100, training_loss: 2.30136e-02
I0214 23:43:01.625890 23126066861888 run_lib.py:146] step: 25100, eval_loss: 2.38903e-02
I0214 23:43:18.966528 23126066861888 run_lib.py:133] step: 25150, training_loss: 2.28239e-02
I0214 23:43:36.525011 23126066861888 run_lib.py:133] step: 25200, training_loss: 2.47043e-02
I0214 23:43:36.697847 23126066861888 run_lib.py:146] step: 25200, eval_loss: 2.36542e-02
I0214 23:43:54.125623 23126066861888 run_lib.py:133] step: 25250, training_loss: 2.45261e-02
I0214 23:44:11.696883 23126066861888 run_lib.py:133] step: 25300, training_loss: 2.36373e-02
I0214 23:44:11.859151 23126066861888 run_lib.py:146] step: 25300, eval_loss: 2.36581e-02
I0214 23:44:29.265105 23126066861888 run_lib.py:133] step: 25350, training_loss: 2.32539e-02
I0214 23:44:46.575644 23126066861888 run_lib.py:133] step: 25400, training_loss: 2.34896e-02
I0214 23:44:46.730799 23126066861888 run_lib.py:146] step: 25400, eval_loss: 2.45318e-02
I0214 23:45:04.242489 23126066861888 run_lib.py:133] step: 25450, training_loss: 2.45787e-02
I0214 23:45:21.706496 23126066861888 run_lib.py:133] step: 25500, training_loss: 2.33116e-02
I0214 23:45:21.858295 23126066861888 run_lib.py:146] step: 25500, eval_loss: 2.37109e-02
I0214 23:45:39.257018 23126066861888 run_lib.py:133] step: 25550, training_loss: 2.43480e-02
I0214 23:45:56.886597 23126066861888 run_lib.py:133] step: 25600, training_loss: 2.41751e-02
I0214 23:45:57.039802 23126066861888 run_lib.py:146] step: 25600, eval_loss: 2.50680e-02
I0214 23:46:14.417695 23126066861888 run_lib.py:133] step: 25650, training_loss: 2.37113e-02
I0214 23:46:31.776969 23126066861888 run_lib.py:133] step: 25700, training_loss: 2.39215e-02
I0214 23:46:31.937333 23126066861888 run_lib.py:146] step: 25700, eval_loss: 2.40023e-02
I0214 23:46:49.399045 23126066861888 run_lib.py:133] step: 25750, training_loss: 2.39975e-02
I0214 23:47:06.785910 23126066861888 run_lib.py:133] step: 25800, training_loss: 2.38677e-02
I0214 23:47:06.944304 23126066861888 run_lib.py:146] step: 25800, eval_loss: 2.36199e-02
I0214 23:47:24.272206 23126066861888 run_lib.py:133] step: 25850, training_loss: 2.37870e-02
I0214 23:47:41.598322 23126066861888 run_lib.py:133] step: 25900, training_loss: 2.34384e-02
I0214 23:47:41.752757 23126066861888 run_lib.py:146] step: 25900, eval_loss: 2.36178e-02
I0214 23:47:59.269520 23126066861888 run_lib.py:133] step: 25950, training_loss: 2.39913e-02
I0214 23:48:16.714097 23126066861888 run_lib.py:133] step: 26000, training_loss: 2.39430e-02
I0214 23:48:16.865154 23126066861888 run_lib.py:146] step: 26000, eval_loss: 2.40067e-02
I0214 23:48:34.292294 23126066861888 run_lib.py:133] step: 26050, training_loss: 2.43364e-02
I0214 23:48:51.627122 23126066861888 run_lib.py:133] step: 26100, training_loss: 2.41902e-02
I0214 23:48:51.783210 23126066861888 run_lib.py:146] step: 26100, eval_loss: 2.43746e-02
I0214 23:49:09.347606 23126066861888 run_lib.py:133] step: 26150, training_loss: 2.42747e-02
I0214 23:49:26.681069 23126066861888 run_lib.py:133] step: 26200, training_loss: 2.34258e-02
I0214 23:49:26.836913 23126066861888 run_lib.py:146] step: 26200, eval_loss: 2.33796e-02
I0214 23:49:44.177518 23126066861888 run_lib.py:133] step: 26250, training_loss: 2.42772e-02
I0214 23:50:01.650737 23126066861888 run_lib.py:133] step: 26300, training_loss: 2.41297e-02
I0214 23:50:01.815816 23126066861888 run_lib.py:146] step: 26300, eval_loss: 2.35898e-02
I0214 23:50:19.225728 23126066861888 run_lib.py:133] step: 26350, training_loss: 2.35107e-02
I0214 23:50:36.753911 23126066861888 run_lib.py:133] step: 26400, training_loss: 2.33091e-02
I0214 23:50:36.911625 23126066861888 run_lib.py:146] step: 26400, eval_loss: 2.41927e-02
I0214 23:50:54.312476 23126066861888 run_lib.py:133] step: 26450, training_loss: 2.40257e-02
I0214 23:51:11.657698 23126066861888 run_lib.py:133] step: 26500, training_loss: 2.33318e-02
I0214 23:51:11.809567 23126066861888 run_lib.py:146] step: 26500, eval_loss: 2.42704e-02
I0214 23:51:29.273670 23126066861888 run_lib.py:133] step: 26550, training_loss: 2.33901e-02
I0214 23:51:46.629135 23126066861888 run_lib.py:133] step: 26600, training_loss: 2.35811e-02
I0214 23:51:46.797994 23126066861888 run_lib.py:146] step: 26600, eval_loss: 2.38843e-02
I0214 23:52:04.199373 23126066861888 run_lib.py:133] step: 26650, training_loss: 2.32475e-02
I0214 23:52:21.786762 23126066861888 run_lib.py:133] step: 26700, training_loss: 2.36995e-02
I0214 23:52:21.944111 23126066861888 run_lib.py:146] step: 26700, eval_loss: 2.44690e-02
I0214 23:52:39.301862 23126066861888 run_lib.py:133] step: 26750, training_loss: 2.36449e-02
I0214 23:52:56.617785 23126066861888 run_lib.py:133] step: 26800, training_loss: 2.37188e-02
I0214 23:52:56.772991 23126066861888 run_lib.py:146] step: 26800, eval_loss: 2.34396e-02
I0214 23:53:14.206294 23126066861888 run_lib.py:133] step: 26850, training_loss: 2.30765e-02
I0214 23:53:31.598167 23126066861888 run_lib.py:133] step: 26900, training_loss: 2.34165e-02
I0214 23:53:31.755818 23126066861888 run_lib.py:146] step: 26900, eval_loss: 2.37051e-02
I0214 23:53:49.127444 23126066861888 run_lib.py:133] step: 26950, training_loss: 2.43507e-02
I0214 23:54:06.446815 23126066861888 run_lib.py:133] step: 27000, training_loss: 2.39828e-02
I0214 23:54:06.606769 23126066861888 run_lib.py:146] step: 27000, eval_loss: 2.41507e-02
I0214 23:54:24.136720 23126066861888 run_lib.py:133] step: 27050, training_loss: 2.38642e-02
I0214 23:54:41.529441 23126066861888 run_lib.py:133] step: 27100, training_loss: 2.34791e-02
I0214 23:54:41.693113 23126066861888 run_lib.py:146] step: 27100, eval_loss: 2.46209e-02
I0214 23:54:59.080924 23126066861888 run_lib.py:133] step: 27150, training_loss: 2.29571e-02
I0214 23:55:16.508463 23126066861888 run_lib.py:133] step: 27200, training_loss: 2.28807e-02
I0214 23:55:16.671667 23126066861888 run_lib.py:146] step: 27200, eval_loss: 2.43159e-02
I0214 23:55:34.183271 23126066861888 run_lib.py:133] step: 27250, training_loss: 2.31034e-02
I0214 23:55:51.596594 23126066861888 run_lib.py:133] step: 27300, training_loss: 2.33692e-02
I0214 23:55:51.750588 23126066861888 run_lib.py:146] step: 27300, eval_loss: 2.35937e-02
I0214 23:56:09.086967 23126066861888 run_lib.py:133] step: 27350, training_loss: 2.41484e-02
I0214 23:56:26.574625 23126066861888 run_lib.py:133] step: 27400, training_loss: 2.32178e-02
I0214 23:56:26.726058 23126066861888 run_lib.py:146] step: 27400, eval_loss: 2.44356e-02
I0214 23:56:44.102570 23126066861888 run_lib.py:133] step: 27450, training_loss: 2.36300e-02
I0214 23:57:01.685577 23126066861888 run_lib.py:133] step: 27500, training_loss: 2.40162e-02
I0214 23:57:01.842037 23126066861888 run_lib.py:146] step: 27500, eval_loss: 2.44532e-02
I0214 23:57:19.182686 23126066861888 run_lib.py:133] step: 27550, training_loss: 2.34217e-02
I0214 23:57:36.497233 23126066861888 run_lib.py:133] step: 27600, training_loss: 2.33920e-02
I0214 23:57:36.654043 23126066861888 run_lib.py:146] step: 27600, eval_loss: 2.41665e-02
I0214 23:57:54.146819 23126066861888 run_lib.py:133] step: 27650, training_loss: 2.41059e-02
I0214 23:58:11.592119 23126066861888 run_lib.py:133] step: 27700, training_loss: 2.44815e-02
I0214 23:58:11.757359 23126066861888 run_lib.py:146] step: 27700, eval_loss: 2.37626e-02
I0214 23:58:29.063085 23126066861888 run_lib.py:133] step: 27750, training_loss: 2.34268e-02
I0214 23:58:46.618953 23126066861888 run_lib.py:133] step: 27800, training_loss: 2.34032e-02
I0214 23:58:46.772971 23126066861888 run_lib.py:146] step: 27800, eval_loss: 2.37217e-02
I0214 23:59:04.119510 23126066861888 run_lib.py:133] step: 27850, training_loss: 2.38978e-02
I0214 23:59:21.439385 23126066861888 run_lib.py:133] step: 27900, training_loss: 2.45643e-02
I0214 23:59:21.594952 23126066861888 run_lib.py:146] step: 27900, eval_loss: 2.42230e-02
I0214 23:59:38.997475 23126066861888 run_lib.py:133] step: 27950, training_loss: 2.33373e-02
I0214 23:59:56.346096 23126066861888 run_lib.py:133] step: 28000, training_loss: 2.42659e-02
I0214 23:59:56.517124 23126066861888 run_lib.py:146] step: 28000, eval_loss: 2.38870e-02
I0215 00:00:13.906227 23126066861888 run_lib.py:133] step: 28050, training_loss: 2.36680e-02
I0215 00:00:31.280037 23126066861888 run_lib.py:133] step: 28100, training_loss: 2.43930e-02
I0215 00:00:31.442964 23126066861888 run_lib.py:146] step: 28100, eval_loss: 2.34114e-02
I0215 00:00:48.973043 23126066861888 run_lib.py:133] step: 28150, training_loss: 2.32913e-02
I0215 00:01:06.411067 23126066861888 run_lib.py:133] step: 28200, training_loss: 2.34997e-02
I0215 00:01:06.564861 23126066861888 run_lib.py:146] step: 28200, eval_loss: 2.42216e-02
I0215 00:01:23.943360 23126066861888 run_lib.py:133] step: 28250, training_loss: 2.38721e-02
I0215 00:01:41.369536 23126066861888 run_lib.py:133] step: 28300, training_loss: 2.40360e-02
I0215 00:01:41.530727 23126066861888 run_lib.py:146] step: 28300, eval_loss: 2.43567e-02
I0215 00:01:59.131997 23126066861888 run_lib.py:133] step: 28350, training_loss: 2.39487e-02
I0215 00:02:16.477240 23126066861888 run_lib.py:133] step: 28400, training_loss: 2.42851e-02
I0215 00:02:16.628762 23126066861888 run_lib.py:146] step: 28400, eval_loss: 2.46667e-02
I0215 00:02:33.954072 23126066861888 run_lib.py:133] step: 28450, training_loss: 2.32603e-02
I0215 00:02:51.472806 23126066861888 run_lib.py:133] step: 28500, training_loss: 2.24187e-02
I0215 00:02:51.636826 23126066861888 run_lib.py:146] step: 28500, eval_loss: 2.49818e-02
I0215 00:03:09.052971 23126066861888 run_lib.py:133] step: 28550, training_loss: 2.40704e-02
I0215 00:03:26.579438 23126066861888 run_lib.py:133] step: 28600, training_loss: 2.41194e-02
I0215 00:03:26.729824 23126066861888 run_lib.py:146] step: 28600, eval_loss: 2.32810e-02
I0215 00:03:44.037914 23126066861888 run_lib.py:133] step: 28650, training_loss: 2.33137e-02
I0215 00:04:01.381517 23126066861888 run_lib.py:133] step: 28700, training_loss: 2.41538e-02
I0215 00:04:01.535708 23126066861888 run_lib.py:146] step: 28700, eval_loss: 2.36971e-02
I0215 00:04:19.009335 23126066861888 run_lib.py:133] step: 28750, training_loss: 2.42304e-02
I0215 00:04:36.367607 23126066861888 run_lib.py:133] step: 28800, training_loss: 2.24507e-02
I0215 00:04:36.521637 23126066861888 run_lib.py:146] step: 28800, eval_loss: 2.37208e-02
I0215 00:04:53.958955 23126066861888 run_lib.py:133] step: 28850, training_loss: 2.34736e-02
I0215 00:05:11.475027 23126066861888 run_lib.py:133] step: 28900, training_loss: 2.36764e-02
I0215 00:05:11.628922 23126066861888 run_lib.py:146] step: 28900, eval_loss: 2.51552e-02
I0215 00:05:28.918883 23126066861888 run_lib.py:133] step: 28950, training_loss: 2.34320e-02
I0215 00:05:46.232440 23126066861888 run_lib.py:133] step: 29000, training_loss: 2.38684e-02
I0215 00:05:46.397453 23126066861888 run_lib.py:146] step: 29000, eval_loss: 2.33802e-02
I0215 00:06:03.803653 23126066861888 run_lib.py:133] step: 29050, training_loss: 2.34150e-02
I0215 00:06:21.222084 23126066861888 run_lib.py:133] step: 29100, training_loss: 2.36369e-02
I0215 00:06:21.378047 23126066861888 run_lib.py:146] step: 29100, eval_loss: 2.33453e-02
I0215 00:06:38.664821 23126066861888 run_lib.py:133] step: 29150, training_loss: 2.33836e-02
I0215 00:06:55.989730 23126066861888 run_lib.py:133] step: 29200, training_loss: 2.41430e-02
I0215 00:06:56.143335 23126066861888 run_lib.py:146] step: 29200, eval_loss: 2.51274e-02
I0215 00:07:13.697963 23126066861888 run_lib.py:133] step: 29250, training_loss: 2.35628e-02
I0215 00:07:31.106778 23126066861888 run_lib.py:133] step: 29300, training_loss: 2.32562e-02
I0215 00:07:31.256446 23126066861888 run_lib.py:146] step: 29300, eval_loss: 2.45348e-02
I0215 00:07:48.579446 23126066861888 run_lib.py:133] step: 29350, training_loss: 2.28773e-02
I0215 00:08:05.947862 23126066861888 run_lib.py:133] step: 29400, training_loss: 2.45633e-02
I0215 00:08:06.119042 23126066861888 run_lib.py:146] step: 29400, eval_loss: 2.40283e-02
I0215 00:08:23.737100 23126066861888 run_lib.py:133] step: 29450, training_loss: 2.34888e-02
I0215 00:08:41.104731 23126066861888 run_lib.py:133] step: 29500, training_loss: 2.40870e-02
I0215 00:08:41.270295 23126066861888 run_lib.py:146] step: 29500, eval_loss: 2.40574e-02
I0215 00:08:58.572355 23126066861888 run_lib.py:133] step: 29550, training_loss: 2.33877e-02
I0215 00:09:16.020940 23126066861888 run_lib.py:133] step: 29600, training_loss: 2.36426e-02
I0215 00:09:16.185802 23126066861888 run_lib.py:146] step: 29600, eval_loss: 2.40200e-02
I0215 00:09:33.586253 23126066861888 run_lib.py:133] step: 29650, training_loss: 2.36018e-02
I0215 00:09:51.113474 23126066861888 run_lib.py:133] step: 29700, training_loss: 2.34461e-02
I0215 00:09:51.270641 23126066861888 run_lib.py:146] step: 29700, eval_loss: 2.38661e-02
I0215 00:10:08.591941 23126066861888 run_lib.py:133] step: 29750, training_loss: 2.30371e-02
I0215 00:10:25.946176 23126066861888 run_lib.py:133] step: 29800, training_loss: 2.38049e-02
I0215 00:10:26.096795 23126066861888 run_lib.py:146] step: 29800, eval_loss: 2.40931e-02
I0215 00:10:43.577985 23126066861888 run_lib.py:133] step: 29850, training_loss: 2.46123e-02
I0215 00:11:00.909874 23126066861888 run_lib.py:133] step: 29900, training_loss: 2.36990e-02
I0215 00:11:01.076093 23126066861888 run_lib.py:146] step: 29900, eval_loss: 2.37808e-02
I0215 00:11:18.415465 23126066861888 run_lib.py:133] step: 29950, training_loss: 2.35570e-02
I0215 00:11:35.934752 23126066861888 run_lib.py:133] step: 30000, training_loss: 2.43987e-02
I0215 00:11:36.615601 23126066861888 run_lib.py:146] step: 30000, eval_loss: 2.40968e-02
I0215 00:11:56.606678 23126066861888 run_lib.py:133] step: 30050, training_loss: 2.32206e-02
I0215 00:12:13.900230 23126066861888 run_lib.py:133] step: 30100, training_loss: 2.32878e-02
I0215 00:12:14.054976 23126066861888 run_lib.py:146] step: 30100, eval_loss: 2.40217e-02
I0215 00:12:31.339285 23126066861888 run_lib.py:133] step: 30150, training_loss: 2.37210e-02
I0215 00:12:48.913698 23126066861888 run_lib.py:133] step: 30200, training_loss: 2.35689e-02
I0215 00:12:49.075611 23126066861888 run_lib.py:146] step: 30200, eval_loss: 2.36754e-02
I0215 00:13:06.446717 23126066861888 run_lib.py:133] step: 30250, training_loss: 2.39447e-02
I0215 00:13:23.759354 23126066861888 run_lib.py:133] step: 30300, training_loss: 2.29927e-02
I0215 00:13:23.910857 23126066861888 run_lib.py:146] step: 30300, eval_loss: 2.40096e-02
I0215 00:13:41.456071 23126066861888 run_lib.py:133] step: 30350, training_loss: 2.29282e-02
I0215 00:13:58.813485 23126066861888 run_lib.py:133] step: 30400, training_loss: 2.30414e-02
I0215 00:13:58.967058 23126066861888 run_lib.py:146] step: 30400, eval_loss: 2.36924e-02
I0215 00:14:16.431752 23126066861888 run_lib.py:133] step: 30450, training_loss: 2.38631e-02
I0215 00:14:33.747050 23126066861888 run_lib.py:133] step: 30500, training_loss: 2.31201e-02
I0215 00:14:33.902799 23126066861888 run_lib.py:146] step: 30500, eval_loss: 2.48296e-02
I0215 00:14:51.239607 23126066861888 run_lib.py:133] step: 30550, training_loss: 2.28373e-02
I0215 00:15:08.563133 23126066861888 run_lib.py:133] step: 30600, training_loss: 2.41942e-02
I0215 00:15:08.716886 23126066861888 run_lib.py:146] step: 30600, eval_loss: 2.49023e-02
I0215 00:15:26.260699 23126066861888 run_lib.py:133] step: 30650, training_loss: 2.41560e-02
I0215 00:15:43.660686 23126066861888 run_lib.py:133] step: 30700, training_loss: 2.31680e-02
I0215 00:15:43.815631 23126066861888 run_lib.py:146] step: 30700, eval_loss: 2.37662e-02
I0215 00:16:01.222581 23126066861888 run_lib.py:133] step: 30750, training_loss: 2.28745e-02
I0215 00:16:18.656212 23126066861888 run_lib.py:133] step: 30800, training_loss: 2.43857e-02
I0215 00:16:18.806993 23126066861888 run_lib.py:146] step: 30800, eval_loss: 2.37062e-02
I0215 00:16:36.322320 23126066861888 run_lib.py:133] step: 30850, training_loss: 2.26310e-02
I0215 00:16:53.719443 23126066861888 run_lib.py:133] step: 30900, training_loss: 2.39831e-02
I0215 00:16:53.875912 23126066861888 run_lib.py:146] step: 30900, eval_loss: 2.38821e-02
I0215 00:17:11.209998 23126066861888 run_lib.py:133] step: 30950, training_loss: 2.26765e-02
I0215 00:17:28.784866 23126066861888 run_lib.py:133] step: 31000, training_loss: 2.36714e-02
I0215 00:17:28.945008 23126066861888 run_lib.py:146] step: 31000, eval_loss: 2.34765e-02
I0215 00:17:46.314264 23126066861888 run_lib.py:133] step: 31050, training_loss: 2.37132e-02
I0215 00:18:03.790148 23126066861888 run_lib.py:133] step: 31100, training_loss: 2.32608e-02
I0215 00:18:03.944840 23126066861888 run_lib.py:146] step: 31100, eval_loss: 2.40751e-02
I0215 00:18:21.294217 23126066861888 run_lib.py:133] step: 31150, training_loss: 2.28423e-02
I0215 00:18:38.605714 23126066861888 run_lib.py:133] step: 31200, training_loss: 2.36963e-02
I0215 00:18:38.759072 23126066861888 run_lib.py:146] step: 31200, eval_loss: 2.46392e-02
I0215 00:18:56.318450 23126066861888 run_lib.py:133] step: 31250, training_loss: 2.31404e-02
I0215 00:19:13.720102 23126066861888 run_lib.py:133] step: 31300, training_loss: 2.27608e-02
I0215 00:19:13.872979 23126066861888 run_lib.py:146] step: 31300, eval_loss: 2.36856e-02
I0215 00:19:31.235312 23126066861888 run_lib.py:133] step: 31350, training_loss: 2.24281e-02
I0215 00:19:48.594700 23126066861888 run_lib.py:133] step: 31400, training_loss: 2.30435e-02
I0215 00:19:48.751728 23126066861888 run_lib.py:146] step: 31400, eval_loss: 2.37916e-02
I0215 00:20:06.343483 23126066861888 run_lib.py:133] step: 31450, training_loss: 2.34020e-02
I0215 00:20:23.675347 23126066861888 run_lib.py:133] step: 31500, training_loss: 2.36454e-02
I0215 00:20:23.850821 23126066861888 run_lib.py:146] step: 31500, eval_loss: 2.49430e-02
I0215 00:20:41.333107 23126066861888 run_lib.py:133] step: 31550, training_loss: 2.40885e-02
I0215 00:20:58.700267 23126066861888 run_lib.py:133] step: 31600, training_loss: 2.41323e-02
I0215 00:20:58.853086 23126066861888 run_lib.py:146] step: 31600, eval_loss: 2.49230e-02
I0215 00:21:16.238036 23126066861888 run_lib.py:133] step: 31650, training_loss: 2.37526e-02
I0215 00:21:33.574754 23126066861888 run_lib.py:133] step: 31700, training_loss: 2.31946e-02
I0215 00:21:33.725787 23126066861888 run_lib.py:146] step: 31700, eval_loss: 2.40733e-02
I0215 00:21:51.267976 23126066861888 run_lib.py:133] step: 31750, training_loss: 2.29946e-02
I0215 00:22:08.712678 23126066861888 run_lib.py:133] step: 31800, training_loss: 2.34125e-02
I0215 00:22:08.866478 23126066861888 run_lib.py:146] step: 31800, eval_loss: 2.41990e-02
I0215 00:22:26.275142 23126066861888 run_lib.py:133] step: 31850, training_loss: 2.37180e-02
I0215 00:22:43.621120 23126066861888 run_lib.py:133] step: 31900, training_loss: 2.35275e-02
I0215 00:22:43.783212 23126066861888 run_lib.py:146] step: 31900, eval_loss: 2.38102e-02
I0215 00:23:01.317687 23126066861888 run_lib.py:133] step: 31950, training_loss: 2.31302e-02
I0215 00:23:18.706490 23126066861888 run_lib.py:133] step: 32000, training_loss: 2.37471e-02
I0215 00:23:18.861006 23126066861888 run_lib.py:146] step: 32000, eval_loss: 2.42595e-02
I0215 00:23:36.256318 23126066861888 run_lib.py:133] step: 32050, training_loss: 2.43767e-02
I0215 00:23:53.786223 23126066861888 run_lib.py:133] step: 32100, training_loss: 2.41160e-02
I0215 00:23:53.940002 23126066861888 run_lib.py:146] step: 32100, eval_loss: 2.37509e-02
I0215 00:24:11.287113 23126066861888 run_lib.py:133] step: 32150, training_loss: 2.49927e-02
I0215 00:24:28.830045 23126066861888 run_lib.py:133] step: 32200, training_loss: 2.32860e-02
I0215 00:24:28.981550 23126066861888 run_lib.py:146] step: 32200, eval_loss: 2.35730e-02
I0215 00:24:46.293702 23126066861888 run_lib.py:133] step: 32250, training_loss: 2.36431e-02
I0215 00:25:03.664387 23126066861888 run_lib.py:133] step: 32300, training_loss: 2.39339e-02
I0215 00:25:03.817077 23126066861888 run_lib.py:146] step: 32300, eval_loss: 2.36109e-02
I0215 00:25:21.382372 23126066861888 run_lib.py:133] step: 32350, training_loss: 2.27191e-02
I0215 00:25:38.770926 23126066861888 run_lib.py:133] step: 32400, training_loss: 2.37700e-02
I0215 00:25:38.927868 23126066861888 run_lib.py:146] step: 32400, eval_loss: 2.40210e-02
I0215 00:25:56.276837 23126066861888 run_lib.py:133] step: 32450, training_loss: 2.28183e-02
I0215 00:26:13.763944 23126066861888 run_lib.py:133] step: 32500, training_loss: 2.34024e-02
I0215 00:26:13.921778 23126066861888 run_lib.py:146] step: 32500, eval_loss: 2.37691e-02
I0215 00:26:31.260059 23126066861888 run_lib.py:133] step: 32550, training_loss: 2.45871e-02
I0215 00:26:48.601366 23126066861888 run_lib.py:133] step: 32600, training_loss: 2.35549e-02
I0215 00:26:48.756940 23126066861888 run_lib.py:146] step: 32600, eval_loss: 2.40347e-02
I0215 00:27:06.205598 23126066861888 run_lib.py:133] step: 32650, training_loss: 2.27403e-02
I0215 00:27:23.543151 23126066861888 run_lib.py:133] step: 32700, training_loss: 2.42351e-02
I0215 00:27:23.697001 23126066861888 run_lib.py:146] step: 32700, eval_loss: 2.45470e-02
I0215 00:27:41.044074 23126066861888 run_lib.py:133] step: 32750, training_loss: 2.34545e-02
I0215 00:27:58.396811 23126066861888 run_lib.py:133] step: 32800, training_loss: 2.37701e-02
I0215 00:27:58.552085 23126066861888 run_lib.py:146] step: 32800, eval_loss: 2.40921e-02
I0215 00:28:16.033186 23126066861888 run_lib.py:133] step: 32850, training_loss: 2.28078e-02
I0215 00:28:33.462762 23126066861888 run_lib.py:133] step: 32900, training_loss: 2.38879e-02
I0215 00:28:33.635780 23126066861888 run_lib.py:146] step: 32900, eval_loss: 2.37471e-02
I0215 00:28:50.988640 23126066861888 run_lib.py:133] step: 32950, training_loss: 2.33261e-02
I0215 00:29:08.334948 23126066861888 run_lib.py:133] step: 33000, training_loss: 2.38703e-02
I0215 00:29:08.489015 23126066861888 run_lib.py:146] step: 33000, eval_loss: 2.36228e-02
I0215 00:29:26.016567 23126066861888 run_lib.py:133] step: 33050, training_loss: 2.35414e-02
I0215 00:29:43.319399 23126066861888 run_lib.py:133] step: 33100, training_loss: 2.31231e-02
I0215 00:29:43.471800 23126066861888 run_lib.py:146] step: 33100, eval_loss: 2.42853e-02
I0215 00:30:00.750319 23126066861888 run_lib.py:133] step: 33150, training_loss: 2.29262e-02
I0215 00:30:18.267303 23126066861888 run_lib.py:133] step: 33200, training_loss: 2.37072e-02
I0215 00:30:18.429172 23126066861888 run_lib.py:146] step: 33200, eval_loss: 2.38130e-02
I0215 00:30:35.805607 23126066861888 run_lib.py:133] step: 33250, training_loss: 2.31035e-02
I0215 00:30:53.352686 23126066861888 run_lib.py:133] step: 33300, training_loss: 2.34091e-02
I0215 00:30:53.512956 23126066861888 run_lib.py:146] step: 33300, eval_loss: 2.42171e-02
I0215 00:31:10.833347 23126066861888 run_lib.py:133] step: 33350, training_loss: 2.32874e-02
I0215 00:31:28.148508 23126066861888 run_lib.py:133] step: 33400, training_loss: 2.40139e-02
I0215 00:31:28.305033 23126066861888 run_lib.py:146] step: 33400, eval_loss: 2.34442e-02
I0215 00:31:45.786791 23126066861888 run_lib.py:133] step: 33450, training_loss: 2.36724e-02
I0215 00:32:03.136334 23126066861888 run_lib.py:133] step: 33500, training_loss: 2.35350e-02
I0215 00:32:03.297037 23126066861888 run_lib.py:146] step: 33500, eval_loss: 2.45524e-02
I0215 00:32:20.654759 23126066861888 run_lib.py:133] step: 33550, training_loss: 2.30130e-02
I0215 00:32:38.193259 23126066861888 run_lib.py:133] step: 33600, training_loss: 2.39298e-02
I0215 00:32:38.345852 23126066861888 run_lib.py:146] step: 33600, eval_loss: 2.41027e-02
I0215 00:32:55.631448 23126066861888 run_lib.py:133] step: 33650, training_loss: 2.35265e-02
I0215 00:33:12.939439 23126066861888 run_lib.py:133] step: 33700, training_loss: 2.27018e-02
I0215 00:33:13.092084 23126066861888 run_lib.py:146] step: 33700, eval_loss: 2.42005e-02
I0215 00:33:30.590243 23126066861888 run_lib.py:133] step: 33750, training_loss: 2.32609e-02
I0215 00:33:47.931094 23126066861888 run_lib.py:133] step: 33800, training_loss: 2.36994e-02
I0215 00:33:48.088867 23126066861888 run_lib.py:146] step: 33800, eval_loss: 2.32063e-02
I0215 00:34:05.379063 23126066861888 run_lib.py:133] step: 33850, training_loss: 2.36635e-02
I0215 00:34:22.688908 23126066861888 run_lib.py:133] step: 33900, training_loss: 2.36579e-02
I0215 00:34:22.847012 23126066861888 run_lib.py:146] step: 33900, eval_loss: 2.43316e-02
I0215 00:34:40.327959 23126066861888 run_lib.py:133] step: 33950, training_loss: 2.36577e-02
I0215 00:34:57.722280 23126066861888 run_lib.py:133] step: 34000, training_loss: 2.24468e-02
I0215 00:34:57.888449 23126066861888 run_lib.py:146] step: 34000, eval_loss: 2.40272e-02
I0215 00:35:15.211011 23126066861888 run_lib.py:133] step: 34050, training_loss: 2.36731e-02
I0215 00:35:32.523009 23126066861888 run_lib.py:133] step: 34100, training_loss: 2.32477e-02
I0215 00:35:32.676865 23126066861888 run_lib.py:146] step: 34100, eval_loss: 2.43020e-02
I0215 00:35:50.240109 23126066861888 run_lib.py:133] step: 34150, training_loss: 2.33558e-02
I0215 00:36:07.564196 23126066861888 run_lib.py:133] step: 34200, training_loss: 2.40440e-02
I0215 00:36:07.715795 23126066861888 run_lib.py:146] step: 34200, eval_loss: 2.38404e-02
I0215 00:36:25.023106 23126066861888 run_lib.py:133] step: 34250, training_loss: 2.28797e-02
I0215 00:36:42.496309 23126066861888 run_lib.py:133] step: 34300, training_loss: 2.38223e-02
I0215 00:36:42.667263 23126066861888 run_lib.py:146] step: 34300, eval_loss: 2.35934e-02
I0215 00:37:00.040892 23126066861888 run_lib.py:133] step: 34350, training_loss: 2.41562e-02
I0215 00:37:17.525923 23126066861888 run_lib.py:133] step: 34400, training_loss: 2.33198e-02
I0215 00:37:17.679923 23126066861888 run_lib.py:146] step: 34400, eval_loss: 2.39384e-02
I0215 00:37:34.982482 23126066861888 run_lib.py:133] step: 34450, training_loss: 2.42285e-02
I0215 00:37:52.267720 23126066861888 run_lib.py:133] step: 34500, training_loss: 2.40557e-02
I0215 00:37:52.425567 23126066861888 run_lib.py:146] step: 34500, eval_loss: 2.38563e-02
I0215 00:38:09.890272 23126066861888 run_lib.py:133] step: 34550, training_loss: 2.31148e-02
I0215 00:38:27.259560 23126066861888 run_lib.py:133] step: 34600, training_loss: 2.20217e-02
I0215 00:38:27.412627 23126066861888 run_lib.py:146] step: 34600, eval_loss: 2.31601e-02
I0215 00:38:44.802382 23126066861888 run_lib.py:133] step: 34650, training_loss: 2.36318e-02
I0215 00:39:02.302963 23126066861888 run_lib.py:133] step: 34700, training_loss: 2.33702e-02
I0215 00:39:02.456818 23126066861888 run_lib.py:146] step: 34700, eval_loss: 2.46989e-02
I0215 00:39:19.767791 23126066861888 run_lib.py:133] step: 34750, training_loss: 2.34642e-02
I0215 00:39:37.064152 23126066861888 run_lib.py:133] step: 34800, training_loss: 2.31822e-02
I0215 00:39:37.226111 23126066861888 run_lib.py:146] step: 34800, eval_loss: 2.38042e-02
I0215 00:39:54.640492 23126066861888 run_lib.py:133] step: 34850, training_loss: 2.34229e-02
I0215 00:40:12.034739 23126066861888 run_lib.py:133] step: 34900, training_loss: 2.37700e-02
I0215 00:40:12.189185 23126066861888 run_lib.py:146] step: 34900, eval_loss: 2.34630e-02
I0215 00:40:29.538693 23126066861888 run_lib.py:133] step: 34950, training_loss: 2.29635e-02
I0215 00:40:46.879318 23126066861888 run_lib.py:133] step: 35000, training_loss: 2.28492e-02
I0215 00:40:47.033764 23126066861888 run_lib.py:146] step: 35000, eval_loss: 2.44006e-02
I0215 00:41:04.507508 23126066861888 run_lib.py:133] step: 35050, training_loss: 2.38862e-02
I0215 00:41:21.937007 23126066861888 run_lib.py:133] step: 35100, training_loss: 2.36015e-02
I0215 00:41:22.098075 23126066861888 run_lib.py:146] step: 35100, eval_loss: 2.44949e-02
I0215 00:41:39.498727 23126066861888 run_lib.py:133] step: 35150, training_loss: 2.37042e-02
I0215 00:41:56.801831 23126066861888 run_lib.py:133] step: 35200, training_loss: 2.37685e-02
I0215 00:41:56.954749 23126066861888 run_lib.py:146] step: 35200, eval_loss: 2.44941e-02
I0215 00:42:14.422029 23126066861888 run_lib.py:133] step: 35250, training_loss: 2.35601e-02
I0215 00:42:31.704796 23126066861888 run_lib.py:133] step: 35300, training_loss: 2.41123e-02
I0215 00:42:31.861067 23126066861888 run_lib.py:146] step: 35300, eval_loss: 2.45107e-02
I0215 00:42:49.196424 23126066861888 run_lib.py:133] step: 35350, training_loss: 2.32318e-02
I0215 00:43:06.718410 23126066861888 run_lib.py:133] step: 35400, training_loss: 2.30382e-02
I0215 00:43:06.873949 23126066861888 run_lib.py:146] step: 35400, eval_loss: 2.49123e-02
I0215 00:43:24.233461 23126066861888 run_lib.py:133] step: 35450, training_loss: 2.35577e-02
I0215 00:43:41.728911 23126066861888 run_lib.py:133] step: 35500, training_loss: 2.39873e-02
I0215 00:43:41.880803 23126066861888 run_lib.py:146] step: 35500, eval_loss: 2.38928e-02
I0215 00:43:59.220329 23126066861888 run_lib.py:133] step: 35550, training_loss: 2.32741e-02
I0215 00:44:16.533487 23126066861888 run_lib.py:133] step: 35600, training_loss: 2.29661e-02
I0215 00:44:16.685804 23126066861888 run_lib.py:146] step: 35600, eval_loss: 2.35493e-02
I0215 00:44:34.133669 23126066861888 run_lib.py:133] step: 35650, training_loss: 2.43770e-02
I0215 00:44:51.506047 23126066861888 run_lib.py:133] step: 35700, training_loss: 2.29383e-02
I0215 00:44:51.677764 23126066861888 run_lib.py:146] step: 35700, eval_loss: 2.43610e-02
I0215 00:45:09.022041 23126066861888 run_lib.py:133] step: 35750, training_loss: 2.36636e-02
I0215 00:45:26.536082 23126066861888 run_lib.py:133] step: 35800, training_loss: 2.31002e-02
I0215 00:45:26.690166 23126066861888 run_lib.py:146] step: 35800, eval_loss: 2.41477e-02
I0215 00:45:44.023178 23126066861888 run_lib.py:133] step: 35850, training_loss: 2.34917e-02
I0215 00:46:01.341863 23126066861888 run_lib.py:133] step: 35900, training_loss: 2.31052e-02
I0215 00:46:01.495945 23126066861888 run_lib.py:146] step: 35900, eval_loss: 2.44284e-02
I0215 00:46:18.899561 23126066861888 run_lib.py:133] step: 35950, training_loss: 2.26695e-02
I0215 00:46:36.229954 23126066861888 run_lib.py:133] step: 36000, training_loss: 2.30532e-02
I0215 00:46:36.382052 23126066861888 run_lib.py:146] step: 36000, eval_loss: 2.28858e-02
I0215 00:46:53.773853 23126066861888 run_lib.py:133] step: 36050, training_loss: 2.36588e-02
I0215 00:47:11.139083 23126066861888 run_lib.py:133] step: 36100, training_loss: 2.29969e-02
I0215 00:47:11.293785 23126066861888 run_lib.py:146] step: 36100, eval_loss: 2.35653e-02
I0215 00:47:28.812065 23126066861888 run_lib.py:133] step: 36150, training_loss: 2.29128e-02
I0215 00:47:46.224664 23126066861888 run_lib.py:133] step: 36200, training_loss: 2.22635e-02
I0215 00:47:46.382224 23126066861888 run_lib.py:146] step: 36200, eval_loss: 2.39355e-02
I0215 00:48:03.694023 23126066861888 run_lib.py:133] step: 36250, training_loss: 2.25093e-02
I0215 00:48:21.096274 23126066861888 run_lib.py:133] step: 36300, training_loss: 2.33025e-02
I0215 00:48:21.251219 23126066861888 run_lib.py:146] step: 36300, eval_loss: 2.35408e-02
I0215 00:48:38.816099 23126066861888 run_lib.py:133] step: 36350, training_loss: 2.38084e-02
I0215 00:48:56.145198 23126066861888 run_lib.py:133] step: 36400, training_loss: 2.33857e-02
I0215 00:48:56.298865 23126066861888 run_lib.py:146] step: 36400, eval_loss: 2.41134e-02
I0215 00:49:13.634756 23126066861888 run_lib.py:133] step: 36450, training_loss: 2.30229e-02
I0215 00:49:31.206537 23126066861888 run_lib.py:133] step: 36500, training_loss: 2.40524e-02
I0215 00:49:31.360144 23126066861888 run_lib.py:146] step: 36500, eval_loss: 2.37769e-02
I0215 00:49:48.737258 23126066861888 run_lib.py:133] step: 36550, training_loss: 2.26017e-02
I0215 00:50:06.255764 23126066861888 run_lib.py:133] step: 36600, training_loss: 2.29326e-02
I0215 00:50:06.409751 23126066861888 run_lib.py:146] step: 36600, eval_loss: 2.48088e-02
I0215 00:50:23.696038 23126066861888 run_lib.py:133] step: 36650, training_loss: 2.35932e-02
I0215 00:50:41.054628 23126066861888 run_lib.py:133] step: 36700, training_loss: 2.32513e-02
I0215 00:50:41.213064 23126066861888 run_lib.py:146] step: 36700, eval_loss: 2.52030e-02
I0215 00:50:58.690087 23126066861888 run_lib.py:133] step: 36750, training_loss: 2.35989e-02
I0215 00:51:16.065218 23126066861888 run_lib.py:133] step: 36800, training_loss: 2.37794e-02
I0215 00:51:16.220122 23126066861888 run_lib.py:146] step: 36800, eval_loss: 2.45776e-02
I0215 00:51:33.580505 23126066861888 run_lib.py:133] step: 36850, training_loss: 2.33672e-02
I0215 00:51:51.209258 23126066861888 run_lib.py:133] step: 36900, training_loss: 2.31553e-02
I0215 00:51:51.365890 23126066861888 run_lib.py:146] step: 36900, eval_loss: 2.38914e-02
I0215 00:52:08.745048 23126066861888 run_lib.py:133] step: 36950, training_loss: 2.35881e-02
I0215 00:52:26.090428 23126066861888 run_lib.py:133] step: 37000, training_loss: 2.19211e-02
I0215 00:52:26.242812 23126066861888 run_lib.py:146] step: 37000, eval_loss: 2.45176e-02
I0215 00:52:43.662656 23126066861888 run_lib.py:133] step: 37050, training_loss: 2.37760e-02
I0215 00:53:01.054861 23126066861888 run_lib.py:133] step: 37100, training_loss: 2.24937e-02
I0215 00:53:01.219599 23126066861888 run_lib.py:146] step: 37100, eval_loss: 2.40804e-02
I0215 00:53:18.616278 23126066861888 run_lib.py:133] step: 37150, training_loss: 2.25421e-02
I0215 00:53:35.984540 23126066861888 run_lib.py:133] step: 37200, training_loss: 2.38647e-02
I0215 00:53:36.140058 23126066861888 run_lib.py:146] step: 37200, eval_loss: 2.38228e-02
I0215 00:53:53.688660 23126066861888 run_lib.py:133] step: 37250, training_loss: 2.28282e-02
I0215 00:54:11.089910 23126066861888 run_lib.py:133] step: 37300, training_loss: 2.34249e-02
I0215 00:54:11.240753 23126066861888 run_lib.py:146] step: 37300, eval_loss: 2.32120e-02
I0215 00:54:28.580061 23126066861888 run_lib.py:133] step: 37350, training_loss: 2.20116e-02
I0215 00:54:45.957972 23126066861888 run_lib.py:133] step: 37400, training_loss: 2.30647e-02
I0215 00:54:46.113153 23126066861888 run_lib.py:146] step: 37400, eval_loss: 2.34423e-02
I0215 00:55:03.692305 23126066861888 run_lib.py:133] step: 37450, training_loss: 2.32336e-02
I0215 00:55:21.059270 23126066861888 run_lib.py:133] step: 37500, training_loss: 2.29244e-02
I0215 00:55:21.211771 23126066861888 run_lib.py:146] step: 37500, eval_loss: 2.39615e-02
I0215 00:55:38.543637 23126066861888 run_lib.py:133] step: 37550, training_loss: 2.34694e-02
I0215 00:55:56.094736 23126066861888 run_lib.py:133] step: 37600, training_loss: 2.23000e-02
I0215 00:55:56.268900 23126066861888 run_lib.py:146] step: 37600, eval_loss: 2.29846e-02
I0215 00:56:13.698947 23126066861888 run_lib.py:133] step: 37650, training_loss: 2.33309e-02
I0215 00:56:31.260190 23126066861888 run_lib.py:133] step: 37700, training_loss: 2.44997e-02
I0215 00:56:31.414006 23126066861888 run_lib.py:146] step: 37700, eval_loss: 2.43629e-02
I0215 00:56:48.801926 23126066861888 run_lib.py:133] step: 37750, training_loss: 2.24317e-02
I0215 00:57:06.160087 23126066861888 run_lib.py:133] step: 37800, training_loss: 2.35859e-02
I0215 00:57:06.312505 23126066861888 run_lib.py:146] step: 37800, eval_loss: 2.42595e-02
I0215 00:57:23.805662 23126066861888 run_lib.py:133] step: 37850, training_loss: 2.33542e-02
I0215 00:57:41.213234 23126066861888 run_lib.py:133] step: 37900, training_loss: 2.33072e-02
I0215 00:57:41.365748 23126066861888 run_lib.py:146] step: 37900, eval_loss: 2.33419e-02
I0215 00:57:58.790604 23126066861888 run_lib.py:133] step: 37950, training_loss: 2.34412e-02
I0215 00:58:16.351784 23126066861888 run_lib.py:133] step: 38000, training_loss: 2.35197e-02
I0215 00:58:16.506939 23126066861888 run_lib.py:146] step: 38000, eval_loss: 2.46913e-02
I0215 00:58:33.870111 23126066861888 run_lib.py:133] step: 38050, training_loss: 2.33685e-02
I0215 00:58:51.224249 23126066861888 run_lib.py:133] step: 38100, training_loss: 2.25019e-02
I0215 00:58:51.382172 23126066861888 run_lib.py:146] step: 38100, eval_loss: 2.35938e-02
I0215 00:59:08.785408 23126066861888 run_lib.py:133] step: 38150, training_loss: 2.26972e-02
I0215 00:59:26.181610 23126066861888 run_lib.py:133] step: 38200, training_loss: 2.33430e-02
I0215 00:59:26.346986 23126066861888 run_lib.py:146] step: 38200, eval_loss: 2.41183e-02
I0215 00:59:43.710532 23126066861888 run_lib.py:133] step: 38250, training_loss: 2.26097e-02
I0215 01:00:01.055451 23126066861888 run_lib.py:133] step: 38300, training_loss: 2.28046e-02
I0215 01:00:01.211536 23126066861888 run_lib.py:146] step: 38300, eval_loss: 2.34765e-02
I0215 01:00:18.744868 23126066861888 run_lib.py:133] step: 38350, training_loss: 2.33918e-02
I0215 01:00:36.178836 23126066861888 run_lib.py:133] step: 38400, training_loss: 2.26757e-02
I0215 01:00:36.331031 23126066861888 run_lib.py:146] step: 38400, eval_loss: 2.42439e-02
I0215 01:00:53.749792 23126066861888 run_lib.py:133] step: 38450, training_loss: 2.31573e-02
I0215 01:01:11.124195 23126066861888 run_lib.py:133] step: 38500, training_loss: 2.43562e-02
I0215 01:01:11.286210 23126066861888 run_lib.py:146] step: 38500, eval_loss: 2.45898e-02
I0215 01:01:28.855191 23126066861888 run_lib.py:133] step: 38550, training_loss: 2.34412e-02
I0215 01:01:46.202994 23126066861888 run_lib.py:133] step: 38600, training_loss: 2.35997e-02
I0215 01:01:46.360205 23126066861888 run_lib.py:146] step: 38600, eval_loss: 2.41406e-02
I0215 01:02:03.723479 23126066861888 run_lib.py:133] step: 38650, training_loss: 2.33810e-02
I0215 01:02:21.186165 23126066861888 run_lib.py:133] step: 38700, training_loss: 2.31947e-02
I0215 01:02:21.355970 23126066861888 run_lib.py:146] step: 38700, eval_loss: 2.49961e-02
I0215 01:02:38.750793 23126066861888 run_lib.py:133] step: 38750, training_loss: 2.30521e-02
I0215 01:02:56.330712 23126066861888 run_lib.py:133] step: 38800, training_loss: 2.31708e-02
I0215 01:02:56.484741 23126066861888 run_lib.py:146] step: 38800, eval_loss: 2.44638e-02
I0215 01:03:13.841753 23126066861888 run_lib.py:133] step: 38850, training_loss: 2.41333e-02
I0215 01:03:31.251908 23126066861888 run_lib.py:133] step: 38900, training_loss: 2.38526e-02
I0215 01:03:31.404062 23126066861888 run_lib.py:146] step: 38900, eval_loss: 2.46944e-02
I0215 01:03:48.925207 23126066861888 run_lib.py:133] step: 38950, training_loss: 2.24291e-02
I0215 01:04:06.378394 23126066861888 run_lib.py:133] step: 39000, training_loss: 2.35346e-02
I0215 01:04:06.546828 23126066861888 run_lib.py:146] step: 39000, eval_loss: 2.30554e-02
I0215 01:04:23.951110 23126066861888 run_lib.py:133] step: 39050, training_loss: 2.33760e-02
I0215 01:04:41.540951 23126066861888 run_lib.py:133] step: 39100, training_loss: 2.32958e-02
I0215 01:04:41.698913 23126066861888 run_lib.py:146] step: 39100, eval_loss: 2.38674e-02
I0215 01:04:59.053757 23126066861888 run_lib.py:133] step: 39150, training_loss: 2.23972e-02
I0215 01:05:16.394213 23126066861888 run_lib.py:133] step: 39200, training_loss: 2.26876e-02
I0215 01:05:16.549018 23126066861888 run_lib.py:146] step: 39200, eval_loss: 2.49915e-02
I0215 01:05:34.006074 23126066861888 run_lib.py:133] step: 39250, training_loss: 2.41813e-02
I0215 01:05:51.443739 23126066861888 run_lib.py:133] step: 39300, training_loss: 2.36896e-02
I0215 01:05:51.600652 23126066861888 run_lib.py:146] step: 39300, eval_loss: 2.38223e-02
I0215 01:06:09.009221 23126066861888 run_lib.py:133] step: 39350, training_loss: 2.28348e-02
I0215 01:06:26.395974 23126066861888 run_lib.py:133] step: 39400, training_loss: 2.35492e-02
I0215 01:06:26.556799 23126066861888 run_lib.py:146] step: 39400, eval_loss: 2.42032e-02
I0215 01:06:44.106567 23126066861888 run_lib.py:133] step: 39450, training_loss: 2.28740e-02
I0215 01:07:01.559914 23126066861888 run_lib.py:133] step: 39500, training_loss: 2.37713e-02
I0215 01:07:01.715065 23126066861888 run_lib.py:146] step: 39500, eval_loss: 2.33094e-02
I0215 01:07:19.105748 23126066861888 run_lib.py:133] step: 39550, training_loss: 2.35980e-02
I0215 01:07:36.581830 23126066861888 run_lib.py:133] step: 39600, training_loss: 2.27902e-02
I0215 01:07:36.739256 23126066861888 run_lib.py:146] step: 39600, eval_loss: 2.50963e-02
I0215 01:07:54.303953 23126066861888 run_lib.py:133] step: 39650, training_loss: 2.32398e-02
I0215 01:08:11.653201 23126066861888 run_lib.py:133] step: 39700, training_loss: 2.32446e-02
I0215 01:08:11.807618 23126066861888 run_lib.py:146] step: 39700, eval_loss: 2.44133e-02
I0215 01:08:29.212117 23126066861888 run_lib.py:133] step: 39750, training_loss: 2.30486e-02
I0215 01:08:46.717610 23126066861888 run_lib.py:133] step: 39800, training_loss: 2.33799e-02
I0215 01:08:46.868322 23126066861888 run_lib.py:146] step: 39800, eval_loss: 2.40971e-02
I0215 01:09:04.220344 23126066861888 run_lib.py:133] step: 39850, training_loss: 2.29442e-02
I0215 01:09:21.801966 23126066861888 run_lib.py:133] step: 39900, training_loss: 2.33930e-02
I0215 01:09:21.973509 23126066861888 run_lib.py:146] step: 39900, eval_loss: 2.48126e-02
I0215 01:09:39.399785 23126066861888 run_lib.py:133] step: 39950, training_loss: 2.30355e-02
I0215 01:09:56.861751 23126066861888 run_lib.py:133] step: 40000, training_loss: 2.27683e-02
I0215 01:09:57.571046 23126066861888 run_lib.py:146] step: 40000, eval_loss: 2.43171e-02
I0215 01:10:17.737066 23126066861888 run_lib.py:133] step: 40050, training_loss: 2.27704e-02
I0215 01:10:35.047466 23126066861888 run_lib.py:133] step: 40100, training_loss: 2.24924e-02
I0215 01:10:35.204167 23126066861888 run_lib.py:146] step: 40100, eval_loss: 2.36096e-02
I0215 01:10:52.618017 23126066861888 run_lib.py:133] step: 40150, training_loss: 2.29671e-02
I0215 01:11:10.234359 23126066861888 run_lib.py:133] step: 40200, training_loss: 2.31264e-02
I0215 01:11:10.399137 23126066861888 run_lib.py:146] step: 40200, eval_loss: 2.37356e-02
I0215 01:11:27.764955 23126066861888 run_lib.py:133] step: 40250, training_loss: 2.25927e-02
I0215 01:11:45.166696 23126066861888 run_lib.py:133] step: 40300, training_loss: 2.28087e-02
I0215 01:11:45.328950 23126066861888 run_lib.py:146] step: 40300, eval_loss: 2.32865e-02
I0215 01:12:02.872868 23126066861888 run_lib.py:133] step: 40350, training_loss: 2.30213e-02
I0215 01:12:20.313805 23126066861888 run_lib.py:133] step: 40400, training_loss: 2.33910e-02
I0215 01:12:20.468387 23126066861888 run_lib.py:146] step: 40400, eval_loss: 2.44747e-02
I0215 01:12:38.092950 23126066861888 run_lib.py:133] step: 40450, training_loss: 2.23713e-02
I0215 01:12:55.504742 23126066861888 run_lib.py:133] step: 40500, training_loss: 2.27273e-02
I0215 01:12:55.663037 23126066861888 run_lib.py:146] step: 40500, eval_loss: 2.46120e-02
I0215 01:13:13.024987 23126066861888 run_lib.py:133] step: 40550, training_loss: 2.34547e-02
I0215 01:13:30.401031 23126066861888 run_lib.py:133] step: 40600, training_loss: 2.30416e-02
I0215 01:13:30.557247 23126066861888 run_lib.py:146] step: 40600, eval_loss: 2.39687e-02
I0215 01:13:48.069235 23126066861888 run_lib.py:133] step: 40650, training_loss: 2.34981e-02
I0215 01:14:05.499684 23126066861888 run_lib.py:133] step: 40700, training_loss: 2.24864e-02
I0215 01:14:05.657433 23126066861888 run_lib.py:146] step: 40700, eval_loss: 2.42649e-02
I0215 01:14:23.052779 23126066861888 run_lib.py:133] step: 40750, training_loss: 2.24619e-02
I0215 01:14:40.410273 23126066861888 run_lib.py:133] step: 40800, training_loss: 2.42309e-02
I0215 01:14:40.569777 23126066861888 run_lib.py:146] step: 40800, eval_loss: 2.32491e-02
I0215 01:14:58.120643 23126066861888 run_lib.py:133] step: 40850, training_loss: 2.29881e-02
I0215 01:15:15.587118 23126066861888 run_lib.py:133] step: 40900, training_loss: 2.38474e-02
I0215 01:15:15.739927 23126066861888 run_lib.py:146] step: 40900, eval_loss: 2.47579e-02
I0215 01:15:33.063298 23126066861888 run_lib.py:133] step: 40950, training_loss: 2.24015e-02
I0215 01:15:50.526504 23126066861888 run_lib.py:133] step: 41000, training_loss: 2.28047e-02
I0215 01:15:50.693934 23126066861888 run_lib.py:146] step: 41000, eval_loss: 2.42191e-02
I0215 01:16:08.230785 23126066861888 run_lib.py:133] step: 41050, training_loss: 2.23798e-02
I0215 01:16:25.582835 23126066861888 run_lib.py:133] step: 41100, training_loss: 2.32727e-02
I0215 01:16:25.734124 23126066861888 run_lib.py:146] step: 41100, eval_loss: 2.37836e-02
I0215 01:16:43.101727 23126066861888 run_lib.py:133] step: 41150, training_loss: 2.36089e-02
I0215 01:17:00.649821 23126066861888 run_lib.py:133] step: 41200, training_loss: 2.31918e-02
I0215 01:17:00.806198 23126066861888 run_lib.py:146] step: 41200, eval_loss: 2.42885e-02
I0215 01:17:18.192280 23126066861888 run_lib.py:133] step: 41250, training_loss: 2.29687e-02
I0215 01:17:35.787965 23126066861888 run_lib.py:133] step: 41300, training_loss: 2.35077e-02
I0215 01:17:35.941776 23126066861888 run_lib.py:146] step: 41300, eval_loss: 2.43290e-02
I0215 01:17:53.331625 23126066861888 run_lib.py:133] step: 41350, training_loss: 2.31916e-02
I0215 01:18:10.719644 23126066861888 run_lib.py:133] step: 41400, training_loss: 2.27148e-02
I0215 01:18:10.872116 23126066861888 run_lib.py:146] step: 41400, eval_loss: 2.39626e-02
I0215 01:18:28.353625 23126066861888 run_lib.py:133] step: 41450, training_loss: 2.34518e-02
I0215 01:18:45.748408 23126066861888 run_lib.py:133] step: 41500, training_loss: 2.36959e-02
I0215 01:18:45.920938 23126066861888 run_lib.py:146] step: 41500, eval_loss: 2.44388e-02
I0215 01:19:03.334850 23126066861888 run_lib.py:133] step: 41550, training_loss: 2.36155e-02
I0215 01:19:20.915386 23126066861888 run_lib.py:133] step: 41600, training_loss: 2.38592e-02
I0215 01:19:21.074179 23126066861888 run_lib.py:146] step: 41600, eval_loss: 2.42272e-02
I0215 01:19:38.472214 23126066861888 run_lib.py:133] step: 41650, training_loss: 2.32618e-02
I0215 01:19:55.815783 23126066861888 run_lib.py:133] step: 41700, training_loss: 2.35413e-02
I0215 01:19:55.968647 23126066861888 run_lib.py:146] step: 41700, eval_loss: 2.47241e-02
I0215 01:20:13.410937 23126066861888 run_lib.py:133] step: 41750, training_loss: 2.26729e-02
I0215 01:20:30.848875 23126066861888 run_lib.py:133] step: 41800, training_loss: 2.34521e-02
I0215 01:20:31.003051 23126066861888 run_lib.py:146] step: 41800, eval_loss: 2.38806e-02
I0215 01:20:48.415305 23126066861888 run_lib.py:133] step: 41850, training_loss: 2.19454e-02
I0215 01:21:05.811982 23126066861888 run_lib.py:133] step: 41900, training_loss: 2.34137e-02
I0215 01:21:05.966845 23126066861888 run_lib.py:146] step: 41900, eval_loss: 2.45258e-02
I0215 01:21:23.486909 23126066861888 run_lib.py:133] step: 41950, training_loss: 2.32866e-02
I0215 01:21:40.974472 23126066861888 run_lib.py:133] step: 42000, training_loss: 2.43898e-02
I0215 01:21:41.134128 23126066861888 run_lib.py:146] step: 42000, eval_loss: 2.34735e-02
I0215 01:21:58.556965 23126066861888 run_lib.py:133] step: 42050, training_loss: 2.33064e-02
I0215 01:22:16.005313 23126066861888 run_lib.py:133] step: 42100, training_loss: 2.25574e-02
I0215 01:22:16.161098 23126066861888 run_lib.py:146] step: 42100, eval_loss: 2.39275e-02
I0215 01:22:33.713376 23126066861888 run_lib.py:133] step: 42150, training_loss: 2.29776e-02
I0215 01:22:51.028779 23126066861888 run_lib.py:133] step: 42200, training_loss: 2.27451e-02
I0215 01:22:51.181771 23126066861888 run_lib.py:146] step: 42200, eval_loss: 2.41745e-02
I0215 01:23:08.525717 23126066861888 run_lib.py:133] step: 42250, training_loss: 2.28389e-02
I0215 01:23:26.053543 23126066861888 run_lib.py:133] step: 42300, training_loss: 2.27493e-02
I0215 01:23:26.205992 23126066861888 run_lib.py:146] step: 42300, eval_loss: 2.37120e-02
I0215 01:23:43.631018 23126066861888 run_lib.py:133] step: 42350, training_loss: 2.31938e-02
I0215 01:24:01.185356 23126066861888 run_lib.py:133] step: 42400, training_loss: 2.35668e-02
I0215 01:24:01.341819 23126066861888 run_lib.py:146] step: 42400, eval_loss: 2.49789e-02
I0215 01:24:18.625641 23126066861888 run_lib.py:133] step: 42450, training_loss: 2.19238e-02
I0215 01:24:35.854358 23126066861888 run_lib.py:133] step: 42500, training_loss: 2.27537e-02
I0215 01:24:36.010032 23126066861888 run_lib.py:146] step: 42500, eval_loss: 2.46507e-02
I0215 01:24:53.510257 23126066861888 run_lib.py:133] step: 42550, training_loss: 2.32396e-02
I0215 01:25:10.856562 23126066861888 run_lib.py:133] step: 42600, training_loss: 2.35828e-02
I0215 01:25:11.017688 23126066861888 run_lib.py:146] step: 42600, eval_loss: 2.45782e-02
I0215 01:25:28.364097 23126066861888 run_lib.py:133] step: 42650, training_loss: 2.30168e-02
I0215 01:25:45.928022 23126066861888 run_lib.py:133] step: 42700, training_loss: 2.37698e-02
I0215 01:25:46.080050 23126066861888 run_lib.py:146] step: 42700, eval_loss: 2.44086e-02
I0215 01:26:03.414149 23126066861888 run_lib.py:133] step: 42750, training_loss: 2.29778e-02
I0215 01:26:20.817718 23126066861888 run_lib.py:133] step: 42800, training_loss: 2.33398e-02
I0215 01:26:20.970182 23126066861888 run_lib.py:146] step: 42800, eval_loss: 2.32264e-02
I0215 01:26:38.362084 23126066861888 run_lib.py:133] step: 42850, training_loss: 2.31680e-02
I0215 01:26:55.718626 23126066861888 run_lib.py:133] step: 42900, training_loss: 2.30953e-02
I0215 01:26:55.890595 23126066861888 run_lib.py:146] step: 42900, eval_loss: 2.46125e-02
I0215 01:27:13.267819 23126066861888 run_lib.py:133] step: 42950, training_loss: 2.26656e-02
I0215 01:27:30.576563 23126066861888 run_lib.py:133] step: 43000, training_loss: 2.28687e-02
I0215 01:27:30.732192 23126066861888 run_lib.py:146] step: 43000, eval_loss: 2.26334e-02
I0215 01:27:48.255878 23126066861888 run_lib.py:133] step: 43050, training_loss: 2.32645e-02
I0215 01:28:05.632406 23126066861888 run_lib.py:133] step: 43100, training_loss: 2.33212e-02
I0215 01:28:05.786579 23126066861888 run_lib.py:146] step: 43100, eval_loss: 2.50920e-02
I0215 01:28:23.109923 23126066861888 run_lib.py:133] step: 43150, training_loss: 2.28904e-02
I0215 01:28:40.513014 23126066861888 run_lib.py:133] step: 43200, training_loss: 2.31883e-02
I0215 01:28:40.666949 23126066861888 run_lib.py:146] step: 43200, eval_loss: 2.40021e-02
I0215 01:28:58.228497 23126066861888 run_lib.py:133] step: 43250, training_loss: 2.26141e-02
I0215 01:29:15.584533 23126066861888 run_lib.py:133] step: 43300, training_loss: 2.25776e-02
I0215 01:29:15.739923 23126066861888 run_lib.py:146] step: 43300, eval_loss: 2.41873e-02
I0215 01:29:33.111698 23126066861888 run_lib.py:133] step: 43350, training_loss: 2.33839e-02
I0215 01:29:50.651079 23126066861888 run_lib.py:133] step: 43400, training_loss: 2.32789e-02
I0215 01:29:50.816065 23126066861888 run_lib.py:146] step: 43400, eval_loss: 2.39398e-02
I0215 01:30:08.194115 23126066861888 run_lib.py:133] step: 43450, training_loss: 2.36990e-02
I0215 01:30:25.757793 23126066861888 run_lib.py:133] step: 43500, training_loss: 2.26114e-02
I0215 01:30:25.912116 23126066861888 run_lib.py:146] step: 43500, eval_loss: 2.44716e-02
I0215 01:30:43.274214 23126066861888 run_lib.py:133] step: 43550, training_loss: 2.27327e-02
I0215 01:31:00.643830 23126066861888 run_lib.py:133] step: 43600, training_loss: 2.28952e-02
I0215 01:31:00.796854 23126066861888 run_lib.py:146] step: 43600, eval_loss: 2.37350e-02
I0215 01:31:18.289954 23126066861888 run_lib.py:133] step: 43650, training_loss: 2.25090e-02
I0215 01:31:35.636482 23126066861888 run_lib.py:133] step: 43700, training_loss: 2.24914e-02
I0215 01:31:35.790115 23126066861888 run_lib.py:146] step: 43700, eval_loss: 2.47448e-02
I0215 01:31:53.222123 23126066861888 run_lib.py:133] step: 43750, training_loss: 2.36655e-02
I0215 01:32:10.831764 23126066861888 run_lib.py:133] step: 43800, training_loss: 2.27929e-02
I0215 01:32:10.987745 23126066861888 run_lib.py:146] step: 43800, eval_loss: 2.45275e-02
I0215 01:32:28.306408 23126066861888 run_lib.py:133] step: 43850, training_loss: 2.27041e-02
I0215 01:32:45.663423 23126066861888 run_lib.py:133] step: 43900, training_loss: 2.31073e-02
I0215 01:32:45.822112 23126066861888 run_lib.py:146] step: 43900, eval_loss: 2.38825e-02
I0215 01:33:03.275034 23126066861888 run_lib.py:133] step: 43950, training_loss: 2.30888e-02
I0215 01:33:20.703489 23126066861888 run_lib.py:133] step: 44000, training_loss: 2.31245e-02
I0215 01:33:20.857054 23126066861888 run_lib.py:146] step: 44000, eval_loss: 2.45876e-02
I0215 01:33:38.215958 23126066861888 run_lib.py:133] step: 44050, training_loss: 2.27150e-02
I0215 01:33:55.589211 23126066861888 run_lib.py:133] step: 44100, training_loss: 2.20685e-02
I0215 01:33:55.739982 23126066861888 run_lib.py:146] step: 44100, eval_loss: 2.43311e-02
I0215 01:34:13.256098 23126066861888 run_lib.py:133] step: 44150, training_loss: 2.21215e-02
I0215 01:34:30.695575 23126066861888 run_lib.py:133] step: 44200, training_loss: 2.30767e-02
I0215 01:34:30.851117 23126066861888 run_lib.py:146] step: 44200, eval_loss: 2.41554e-02
I0215 01:34:48.246868 23126066861888 run_lib.py:133] step: 44250, training_loss: 2.18934e-02
I0215 01:35:05.644980 23126066861888 run_lib.py:133] step: 44300, training_loss: 2.33705e-02
I0215 01:35:05.800878 23126066861888 run_lib.py:146] step: 44300, eval_loss: 2.43835e-02
I0215 01:35:23.294804 23126066861888 run_lib.py:133] step: 44350, training_loss: 2.28619e-02
I0215 01:35:40.613684 23126066861888 run_lib.py:133] step: 44400, training_loss: 2.31817e-02
I0215 01:35:40.768048 23126066861888 run_lib.py:146] step: 44400, eval_loss: 2.43962e-02
I0215 01:35:58.139155 23126066861888 run_lib.py:133] step: 44450, training_loss: 2.31881e-02
I0215 01:36:15.718733 23126066861888 run_lib.py:133] step: 44500, training_loss: 2.26935e-02
I0215 01:36:15.874089 23126066861888 run_lib.py:146] step: 44500, eval_loss: 2.30549e-02
I0215 01:36:33.261510 23126066861888 run_lib.py:133] step: 44550, training_loss: 2.29131e-02
I0215 01:36:50.802017 23126066861888 run_lib.py:133] step: 44600, training_loss: 2.25149e-02
I0215 01:36:50.953543 23126066861888 run_lib.py:146] step: 44600, eval_loss: 2.36351e-02
I0215 01:37:08.307592 23126066861888 run_lib.py:133] step: 44650, training_loss: 2.30898e-02
I0215 01:37:25.650827 23126066861888 run_lib.py:133] step: 44700, training_loss: 2.22540e-02
I0215 01:37:25.803875 23126066861888 run_lib.py:146] step: 44700, eval_loss: 2.39179e-02
I0215 01:37:43.263082 23126066861888 run_lib.py:133] step: 44750, training_loss: 2.28673e-02
I0215 01:38:00.662353 23126066861888 run_lib.py:133] step: 44800, training_loss: 2.31861e-02
I0215 01:38:00.831668 23126066861888 run_lib.py:146] step: 44800, eval_loss: 2.31943e-02
I0215 01:38:18.201114 23126066861888 run_lib.py:133] step: 44850, training_loss: 2.28486e-02
I0215 01:38:35.768226 23126066861888 run_lib.py:133] step: 44900, training_loss: 2.25202e-02
I0215 01:38:35.921842 23126066861888 run_lib.py:146] step: 44900, eval_loss: 2.43506e-02
I0215 01:38:53.276417 23126066861888 run_lib.py:133] step: 44950, training_loss: 2.40697e-02
I0215 01:39:10.581046 23126066861888 run_lib.py:133] step: 45000, training_loss: 2.30711e-02
I0215 01:39:10.742820 23126066861888 run_lib.py:146] step: 45000, eval_loss: 2.34367e-02
I0215 01:39:28.252680 23126066861888 run_lib.py:133] step: 45050, training_loss: 2.38715e-02
I0215 01:39:45.666018 23126066861888 run_lib.py:133] step: 45100, training_loss: 2.29902e-02
I0215 01:39:45.819133 23126066861888 run_lib.py:146] step: 45100, eval_loss: 2.37610e-02
I0215 01:40:03.177007 23126066861888 run_lib.py:133] step: 45150, training_loss: 2.21220e-02
I0215 01:40:20.498619 23126066861888 run_lib.py:133] step: 45200, training_loss: 2.27041e-02
I0215 01:40:20.655125 23126066861888 run_lib.py:146] step: 45200, eval_loss: 2.51253e-02
I0215 01:40:38.180396 23126066861888 run_lib.py:133] step: 45250, training_loss: 2.33386e-02
I0215 01:40:55.591573 23126066861888 run_lib.py:133] step: 45300, training_loss: 2.32847e-02
I0215 01:40:55.749020 23126066861888 run_lib.py:146] step: 45300, eval_loss: 2.34988e-02
I0215 01:41:13.191707 23126066861888 run_lib.py:133] step: 45350, training_loss: 2.26904e-02
I0215 01:41:30.596117 23126066861888 run_lib.py:133] step: 45400, training_loss: 2.23820e-02
I0215 01:41:30.751081 23126066861888 run_lib.py:146] step: 45400, eval_loss: 2.31538e-02
I0215 01:41:48.295612 23126066861888 run_lib.py:133] step: 45450, training_loss: 2.29267e-02
I0215 01:42:05.619142 23126066861888 run_lib.py:133] step: 45500, training_loss: 2.33090e-02
I0215 01:42:05.772840 23126066861888 run_lib.py:146] step: 45500, eval_loss: 2.44818e-02
I0215 01:42:23.072678 23126066861888 run_lib.py:133] step: 45550, training_loss: 2.33095e-02
I0215 01:42:40.573535 23126066861888 run_lib.py:133] step: 45600, training_loss: 2.27382e-02
I0215 01:42:40.729174 23126066861888 run_lib.py:146] step: 45600, eval_loss: 2.30661e-02
I0215 01:42:58.160066 23126066861888 run_lib.py:133] step: 45650, training_loss: 2.29546e-02
I0215 01:43:15.680504 23126066861888 run_lib.py:133] step: 45700, training_loss: 2.36710e-02
I0215 01:43:15.835056 23126066861888 run_lib.py:146] step: 45700, eval_loss: 2.47054e-02
I0215 01:43:33.146560 23126066861888 run_lib.py:133] step: 45750, training_loss: 2.28248e-02
I0215 01:43:50.469512 23126066861888 run_lib.py:133] step: 45800, training_loss: 2.30041e-02
I0215 01:43:50.629201 23126066861888 run_lib.py:146] step: 45800, eval_loss: 2.46091e-02
I0215 01:44:08.142785 23126066861888 run_lib.py:133] step: 45850, training_loss: 2.32441e-02
I0215 01:44:25.510869 23126066861888 run_lib.py:133] step: 45900, training_loss: 2.36407e-02
I0215 01:44:25.670856 23126066861888 run_lib.py:146] step: 45900, eval_loss: 2.39309e-02
I0215 01:44:43.048021 23126066861888 run_lib.py:133] step: 45950, training_loss: 2.31031e-02
I0215 01:45:00.632795 23126066861888 run_lib.py:133] step: 46000, training_loss: 2.30874e-02
I0215 01:45:00.786935 23126066861888 run_lib.py:146] step: 46000, eval_loss: 2.41111e-02
I0215 01:45:18.171539 23126066861888 run_lib.py:133] step: 46050, training_loss: 2.30428e-02
I0215 01:45:35.509098 23126066861888 run_lib.py:133] step: 46100, training_loss: 2.24870e-02
I0215 01:45:35.660815 23126066861888 run_lib.py:146] step: 46100, eval_loss: 2.44400e-02
I0215 01:45:53.059337 23126066861888 run_lib.py:133] step: 46150, training_loss: 2.28651e-02
I0215 01:46:10.422518 23126066861888 run_lib.py:133] step: 46200, training_loss: 2.28597e-02
I0215 01:46:10.600334 23126066861888 run_lib.py:146] step: 46200, eval_loss: 2.51780e-02
I0215 01:46:28.018283 23126066861888 run_lib.py:133] step: 46250, training_loss: 2.33808e-02
I0215 01:46:45.379589 23126066861888 run_lib.py:133] step: 46300, training_loss: 2.23533e-02
I0215 01:46:45.532889 23126066861888 run_lib.py:146] step: 46300, eval_loss: 2.42036e-02
I0215 01:47:03.031673 23126066861888 run_lib.py:133] step: 46350, training_loss: 2.29928e-02
I0215 01:47:20.475215 23126066861888 run_lib.py:133] step: 46400, training_loss: 2.36126e-02
I0215 01:47:20.629664 23126066861888 run_lib.py:146] step: 46400, eval_loss: 2.27535e-02
I0215 01:47:37.974437 23126066861888 run_lib.py:133] step: 46450, training_loss: 2.28096e-02
I0215 01:47:55.372776 23126066861888 run_lib.py:133] step: 46500, training_loss: 2.31803e-02
I0215 01:47:55.538106 23126066861888 run_lib.py:146] step: 46500, eval_loss: 2.35334e-02
I0215 01:48:13.119947 23126066861888 run_lib.py:133] step: 46550, training_loss: 2.30922e-02
I0215 01:48:30.515767 23126066861888 run_lib.py:133] step: 46600, training_loss: 2.31133e-02
I0215 01:48:30.668927 23126066861888 run_lib.py:146] step: 46600, eval_loss: 2.44218e-02
I0215 01:48:48.083791 23126066861888 run_lib.py:133] step: 46650, training_loss: 2.34704e-02
I0215 01:49:05.600013 23126066861888 run_lib.py:133] step: 46700, training_loss: 2.25668e-02
I0215 01:49:05.758228 23126066861888 run_lib.py:146] step: 46700, eval_loss: 2.40545e-02
I0215 01:49:23.147549 23126066861888 run_lib.py:133] step: 46750, training_loss: 2.35786e-02
I0215 01:49:40.700205 23126066861888 run_lib.py:133] step: 46800, training_loss: 2.31469e-02
I0215 01:49:40.856286 23126066861888 run_lib.py:146] step: 46800, eval_loss: 2.41896e-02
I0215 01:49:58.285194 23126066861888 run_lib.py:133] step: 46850, training_loss: 2.31349e-02
I0215 01:50:15.586361 23126066861888 run_lib.py:133] step: 46900, training_loss: 2.29704e-02
I0215 01:50:15.739535 23126066861888 run_lib.py:146] step: 46900, eval_loss: 2.28545e-02
I0215 01:50:33.304929 23126066861888 run_lib.py:133] step: 46950, training_loss: 2.30931e-02
I0215 01:50:50.649455 23126066861888 run_lib.py:133] step: 47000, training_loss: 2.32085e-02
I0215 01:50:50.799490 23126066861888 run_lib.py:146] step: 47000, eval_loss: 2.43676e-02
I0215 01:51:08.202284 23126066861888 run_lib.py:133] step: 47050, training_loss: 2.29196e-02
I0215 01:51:25.818632 23126066861888 run_lib.py:133] step: 47100, training_loss: 2.22762e-02
I0215 01:51:25.985149 23126066861888 run_lib.py:146] step: 47100, eval_loss: 2.36103e-02
I0215 01:51:43.415650 23126066861888 run_lib.py:133] step: 47150, training_loss: 2.29948e-02
I0215 01:52:00.804078 23126066861888 run_lib.py:133] step: 47200, training_loss: 2.24757e-02
I0215 01:52:00.967249 23126066861888 run_lib.py:146] step: 47200, eval_loss: 2.36760e-02
I0215 01:52:18.445012 23126066861888 run_lib.py:133] step: 47250, training_loss: 2.28352e-02
I0215 01:52:35.802839 23126066861888 run_lib.py:133] step: 47300, training_loss: 2.28131e-02
I0215 01:52:35.963983 23126066861888 run_lib.py:146] step: 47300, eval_loss: 2.39473e-02
I0215 01:52:53.355071 23126066861888 run_lib.py:133] step: 47350, training_loss: 2.27680e-02
I0215 01:53:10.751860 23126066861888 run_lib.py:133] step: 47400, training_loss: 2.22691e-02
I0215 01:53:10.906037 23126066861888 run_lib.py:146] step: 47400, eval_loss: 2.45117e-02
I0215 01:53:28.464947 23126066861888 run_lib.py:133] step: 47450, training_loss: 2.34816e-02
I0215 01:53:45.874500 23126066861888 run_lib.py:133] step: 47500, training_loss: 2.32813e-02
I0215 01:53:46.027989 23126066861888 run_lib.py:146] step: 47500, eval_loss: 2.30054e-02
I0215 01:54:03.330471 23126066861888 run_lib.py:133] step: 47550, training_loss: 2.23474e-02
I0215 01:54:20.677357 23126066861888 run_lib.py:133] step: 47600, training_loss: 2.29774e-02
I0215 01:54:20.844017 23126066861888 run_lib.py:146] step: 47600, eval_loss: 2.31304e-02
I0215 01:54:38.398091 23126066861888 run_lib.py:133] step: 47650, training_loss: 2.25636e-02
I0215 01:54:55.746300 23126066861888 run_lib.py:133] step: 47700, training_loss: 2.29857e-02
I0215 01:54:55.902861 23126066861888 run_lib.py:146] step: 47700, eval_loss: 2.38988e-02
I0215 01:55:13.241317 23126066861888 run_lib.py:133] step: 47750, training_loss: 2.33526e-02
I0215 01:55:30.732556 23126066861888 run_lib.py:133] step: 47800, training_loss: 2.29843e-02
I0215 01:55:30.886822 23126066861888 run_lib.py:146] step: 47800, eval_loss: 2.34605e-02
I0215 01:55:48.255798 23126066861888 run_lib.py:133] step: 47850, training_loss: 2.30504e-02
I0215 01:56:05.859708 23126066861888 run_lib.py:133] step: 47900, training_loss: 2.38129e-02
I0215 01:56:06.015135 23126066861888 run_lib.py:146] step: 47900, eval_loss: 2.50944e-02
I0215 01:56:23.455727 23126066861888 run_lib.py:133] step: 47950, training_loss: 2.32066e-02
I0215 01:56:40.785560 23126066861888 run_lib.py:133] step: 48000, training_loss: 2.24799e-02
I0215 01:56:40.939064 23126066861888 run_lib.py:146] step: 48000, eval_loss: 2.44079e-02
I0215 01:56:58.498723 23126066861888 run_lib.py:133] step: 48050, training_loss: 2.36461e-02
I0215 01:57:15.872880 23126066861888 run_lib.py:133] step: 48100, training_loss: 2.28676e-02
I0215 01:57:16.031300 23126066861888 run_lib.py:146] step: 48100, eval_loss: 2.56175e-02
I0215 01:57:33.367944 23126066861888 run_lib.py:133] step: 48150, training_loss: 2.24431e-02
I0215 01:57:50.953694 23126066861888 run_lib.py:133] step: 48200, training_loss: 2.20870e-02
I0215 01:57:51.108110 23126066861888 run_lib.py:146] step: 48200, eval_loss: 2.37756e-02
I0215 01:58:08.455167 23126066861888 run_lib.py:133] step: 48250, training_loss: 2.21894e-02
I0215 01:58:25.767901 23126066861888 run_lib.py:133] step: 48300, training_loss: 2.36123e-02
I0215 01:58:25.923933 23126066861888 run_lib.py:146] step: 48300, eval_loss: 2.40177e-02
I0215 01:58:43.404914 23126066861888 run_lib.py:133] step: 48350, training_loss: 2.33415e-02
I0215 01:59:00.776804 23126066861888 run_lib.py:133] step: 48400, training_loss: 2.25261e-02
I0215 01:59:00.926856 23126066861888 run_lib.py:146] step: 48400, eval_loss: 2.47906e-02
I0215 01:59:18.265369 23126066861888 run_lib.py:133] step: 48450, training_loss: 2.35441e-02
I0215 01:59:35.636711 23126066861888 run_lib.py:133] step: 48500, training_loss: 2.20712e-02
I0215 01:59:35.797071 23126066861888 run_lib.py:146] step: 48500, eval_loss: 2.37828e-02
I0215 01:59:53.367302 23126066861888 run_lib.py:133] step: 48550, training_loss: 2.29960e-02
I0215 02:00:10.858498 23126066861888 run_lib.py:133] step: 48600, training_loss: 2.22262e-02
I0215 02:00:11.018270 23126066861888 run_lib.py:146] step: 48600, eval_loss: 2.44565e-02
I0215 02:00:28.390784 23126066861888 run_lib.py:133] step: 48650, training_loss: 2.40887e-02
I0215 02:00:45.746106 23126066861888 run_lib.py:133] step: 48700, training_loss: 2.33128e-02
I0215 02:00:45.911953 23126066861888 run_lib.py:146] step: 48700, eval_loss: 2.35556e-02
I0215 02:01:03.471733 23126066861888 run_lib.py:133] step: 48750, training_loss: 2.26045e-02
I0215 02:01:20.868108 23126066861888 run_lib.py:133] step: 48800, training_loss: 2.18356e-02
I0215 02:01:21.025127 23126066861888 run_lib.py:146] step: 48800, eval_loss: 2.31527e-02
I0215 02:01:38.412232 23126066861888 run_lib.py:133] step: 48850, training_loss: 2.30594e-02
I0215 02:01:55.900978 23126066861888 run_lib.py:133] step: 48900, training_loss: 2.19578e-02
I0215 02:01:56.053093 23126066861888 run_lib.py:146] step: 48900, eval_loss: 2.37461e-02
I0215 02:02:13.393498 23126066861888 run_lib.py:133] step: 48950, training_loss: 2.25081e-02
I0215 02:02:30.905117 23126066861888 run_lib.py:133] step: 49000, training_loss: 2.25874e-02
I0215 02:02:31.072216 23126066861888 run_lib.py:146] step: 49000, eval_loss: 2.41627e-02
I0215 02:02:48.468442 23126066861888 run_lib.py:133] step: 49050, training_loss: 2.33429e-02
I0215 02:03:05.866941 23126066861888 run_lib.py:133] step: 49100, training_loss: 2.27355e-02
I0215 02:03:06.023838 23126066861888 run_lib.py:146] step: 49100, eval_loss: 2.43042e-02
I0215 02:03:23.590534 23126066861888 run_lib.py:133] step: 49150, training_loss: 2.28288e-02
I0215 02:03:40.922191 23126066861888 run_lib.py:133] step: 49200, training_loss: 2.30199e-02
I0215 02:03:41.076839 23126066861888 run_lib.py:146] step: 49200, eval_loss: 2.45766e-02
I0215 02:03:58.427830 23126066861888 run_lib.py:133] step: 49250, training_loss: 2.35303e-02
I0215 02:04:15.949723 23126066861888 run_lib.py:133] step: 49300, training_loss: 2.22430e-02
I0215 02:04:16.104020 23126066861888 run_lib.py:146] step: 49300, eval_loss: 2.48647e-02
I0215 02:04:33.472614 23126066861888 run_lib.py:133] step: 49350, training_loss: 2.27980e-02
I0215 02:04:50.887976 23126066861888 run_lib.py:133] step: 49400, training_loss: 2.21353e-02
I0215 02:04:51.040094 23126066861888 run_lib.py:146] step: 49400, eval_loss: 2.54591e-02
I0215 02:05:08.543810 23126066861888 run_lib.py:133] step: 49450, training_loss: 2.21077e-02
I0215 02:05:25.940501 23126066861888 run_lib.py:133] step: 49500, training_loss: 2.26659e-02
I0215 02:05:26.093599 23126066861888 run_lib.py:146] step: 49500, eval_loss: 2.32798e-02
I0215 02:05:43.446562 23126066861888 run_lib.py:133] step: 49550, training_loss: 2.34196e-02
I0215 02:06:00.930868 23126066861888 run_lib.py:133] step: 49600, training_loss: 2.34583e-02
I0215 02:06:01.100470 23126066861888 run_lib.py:146] step: 49600, eval_loss: 2.30290e-02
I0215 02:06:18.655910 23126066861888 run_lib.py:133] step: 49650, training_loss: 2.25938e-02
I0215 02:06:36.119248 23126066861888 run_lib.py:133] step: 49700, training_loss: 2.30367e-02
I0215 02:06:36.275992 23126066861888 run_lib.py:146] step: 49700, eval_loss: 2.40413e-02
I0215 02:06:53.679122 23126066861888 run_lib.py:133] step: 49750, training_loss: 2.27547e-02
I0215 02:07:11.017911 23126066861888 run_lib.py:133] step: 49800, training_loss: 2.27484e-02
I0215 02:07:11.173116 23126066861888 run_lib.py:146] step: 49800, eval_loss: 2.48250e-02
I0215 02:07:28.738319 23126066861888 run_lib.py:133] step: 49850, training_loss: 2.27478e-02
I0215 02:07:46.104573 23126066861888 run_lib.py:133] step: 49900, training_loss: 2.32141e-02
I0215 02:07:46.258232 23126066861888 run_lib.py:146] step: 49900, eval_loss: 2.45511e-02
I0215 02:08:03.650849 23126066861888 run_lib.py:133] step: 49950, training_loss: 2.22365e-02
I0215 02:08:21.283936 23126066861888 run_lib.py:133] step: 50000, training_loss: 2.20292e-02
I0215 02:08:21.976938 23126066861888 run_lib.py:146] step: 50000, eval_loss: 2.42038e-02
I0215 02:08:41.908506 23126066861888 run_lib.py:133] step: 50050, training_loss: 2.28495e-02
I0215 02:08:59.417173 23126066861888 run_lib.py:133] step: 50100, training_loss: 2.30133e-02
I0215 02:08:59.588896 23126066861888 run_lib.py:146] step: 50100, eval_loss: 2.36112e-02
I0215 02:09:16.971268 23126066861888 run_lib.py:133] step: 50150, training_loss: 2.26521e-02
I0215 02:09:34.486978 23126066861888 run_lib.py:133] step: 50200, training_loss: 2.22264e-02
I0215 02:09:34.643181 23126066861888 run_lib.py:146] step: 50200, eval_loss: 2.41673e-02
I0215 02:09:52.048515 23126066861888 run_lib.py:133] step: 50250, training_loss: 2.28931e-02
I0215 02:10:09.406261 23126066861888 run_lib.py:133] step: 50300, training_loss: 2.28130e-02
I0215 02:10:09.563856 23126066861888 run_lib.py:146] step: 50300, eval_loss: 2.48146e-02
I0215 02:10:27.090176 23126066861888 run_lib.py:133] step: 50350, training_loss: 2.29269e-02
I0215 02:10:44.481218 23126066861888 run_lib.py:133] step: 50400, training_loss: 2.23621e-02
I0215 02:10:44.641099 23126066861888 run_lib.py:146] step: 50400, eval_loss: 2.36661e-02
I0215 02:11:02.189543 23126066861888 run_lib.py:133] step: 50450, training_loss: 2.22447e-02
I0215 02:11:19.502968 23126066861888 run_lib.py:133] step: 50500, training_loss: 2.25683e-02
I0215 02:11:19.656902 23126066861888 run_lib.py:146] step: 50500, eval_loss: 2.41478e-02
I0215 02:11:37.048059 23126066861888 run_lib.py:133] step: 50550, training_loss: 2.30591e-02
I0215 02:11:54.545950 23126066861888 run_lib.py:133] step: 50600, training_loss: 2.32838e-02
I0215 02:11:54.704208 23126066861888 run_lib.py:146] step: 50600, eval_loss: 2.43563e-02
I0215 02:12:12.088647 23126066861888 run_lib.py:133] step: 50650, training_loss: 2.17893e-02
I0215 02:12:29.461639 23126066861888 run_lib.py:133] step: 50700, training_loss: 2.22621e-02
I0215 02:12:29.616137 23126066861888 run_lib.py:146] step: 50700, eval_loss: 2.47598e-02
I0215 02:12:47.282913 23126066861888 run_lib.py:133] step: 50750, training_loss: 2.28517e-02
I0215 02:13:04.612781 23126066861888 run_lib.py:133] step: 50800, training_loss: 2.30378e-02
I0215 02:13:04.767636 23126066861888 run_lib.py:146] step: 50800, eval_loss: 2.43457e-02
I0215 02:13:22.283344 23126066861888 run_lib.py:133] step: 50850, training_loss: 2.22436e-02
I0215 02:13:39.609461 23126066861888 run_lib.py:133] step: 50900, training_loss: 2.26298e-02
I0215 02:13:39.763987 23126066861888 run_lib.py:146] step: 50900, eval_loss: 2.45354e-02
I0215 02:13:57.171782 23126066861888 run_lib.py:133] step: 50950, training_loss: 2.32274e-02
I0215 02:14:14.692959 23126066861888 run_lib.py:133] step: 51000, training_loss: 2.31121e-02
I0215 02:14:14.847872 23126066861888 run_lib.py:146] step: 51000, eval_loss: 2.32538e-02
I0215 02:14:32.150811 23126066861888 run_lib.py:133] step: 51050, training_loss: 2.26310e-02
I0215 02:14:49.459911 23126066861888 run_lib.py:133] step: 51100, training_loss: 2.37295e-02
I0215 02:14:49.616017 23126066861888 run_lib.py:146] step: 51100, eval_loss: 2.39378e-02
I0215 02:15:06.983125 23126066861888 run_lib.py:133] step: 51150, training_loss: 2.17705e-02
I0215 02:15:24.322379 23126066861888 run_lib.py:133] step: 51200, training_loss: 2.27081e-02
I0215 02:15:24.486030 23126066861888 run_lib.py:146] step: 51200, eval_loss: 2.44574e-02
I0215 02:15:42.016863 23126066861888 run_lib.py:133] step: 51250, training_loss: 2.30428e-02
I0215 02:15:59.478718 23126066861888 run_lib.py:133] step: 51300, training_loss: 2.22640e-02
I0215 02:15:59.635612 23126066861888 run_lib.py:146] step: 51300, eval_loss: 2.50379e-02
I0215 02:16:16.983916 23126066861888 run_lib.py:133] step: 51350, training_loss: 2.32433e-02
I0215 02:16:34.286394 23126066861888 run_lib.py:133] step: 51400, training_loss: 2.30693e-02
I0215 02:16:34.445091 23126066861888 run_lib.py:146] step: 51400, eval_loss: 2.44584e-02
I0215 02:16:51.888334 23126066861888 run_lib.py:133] step: 51450, training_loss: 2.28118e-02
I0215 02:17:09.228878 23126066861888 run_lib.py:133] step: 51500, training_loss: 2.34250e-02
I0215 02:17:09.400804 23126066861888 run_lib.py:146] step: 51500, eval_loss: 2.41215e-02
I0215 02:17:27.050205 23126066861888 run_lib.py:133] step: 51550, training_loss: 2.27106e-02
I0215 02:17:44.374150 23126066861888 run_lib.py:133] step: 51600, training_loss: 2.25098e-02
I0215 02:17:44.528074 23126066861888 run_lib.py:146] step: 51600, eval_loss: 2.39822e-02
I0215 02:18:01.863503 23126066861888 run_lib.py:133] step: 51650, training_loss: 2.33932e-02
I0215 02:18:19.300945 23126066861888 run_lib.py:133] step: 51700, training_loss: 2.26632e-02
I0215 02:18:19.454604 23126066861888 run_lib.py:146] step: 51700, eval_loss: 2.43522e-02
I0215 02:18:36.755914 23126066861888 run_lib.py:133] step: 51750, training_loss: 2.22964e-02
I0215 02:18:54.156347 23126066861888 run_lib.py:133] step: 51800, training_loss: 2.26436e-02
I0215 02:18:54.317666 23126066861888 run_lib.py:146] step: 51800, eval_loss: 2.47999e-02
I0215 02:19:11.884598 23126066861888 run_lib.py:133] step: 51850, training_loss: 2.24031e-02
I0215 02:19:29.211442 23126066861888 run_lib.py:133] step: 51900, training_loss: 2.26107e-02
I0215 02:19:29.364896 23126066861888 run_lib.py:146] step: 51900, eval_loss: 2.45258e-02
I0215 02:19:46.817082 23126066861888 run_lib.py:133] step: 51950, training_loss: 2.22860e-02
I0215 02:20:04.130125 23126066861888 run_lib.py:133] step: 52000, training_loss: 2.20171e-02
I0215 02:20:04.290803 23126066861888 run_lib.py:146] step: 52000, eval_loss: 2.41850e-02
I0215 02:20:21.599342 23126066861888 run_lib.py:133] step: 52050, training_loss: 2.21729e-02
I0215 02:20:39.121569 23126066861888 run_lib.py:133] step: 52100, training_loss: 2.29032e-02
I0215 02:20:39.276036 23126066861888 run_lib.py:146] step: 52100, eval_loss: 2.42021e-02
I0215 02:20:56.526157 23126066861888 run_lib.py:133] step: 52150, training_loss: 2.23108e-02
I0215 02:21:13.790142 23126066861888 run_lib.py:133] step: 52200, training_loss: 2.27472e-02
I0215 02:21:13.946027 23126066861888 run_lib.py:146] step: 52200, eval_loss: 2.44733e-02
I0215 02:21:31.359946 23126066861888 run_lib.py:133] step: 52250, training_loss: 2.28300e-02
I0215 02:21:48.804299 23126066861888 run_lib.py:133] step: 52300, training_loss: 2.30583e-02
I0215 02:21:49.019527 23126066861888 run_lib.py:146] step: 52300, eval_loss: 2.38798e-02
I0215 02:22:06.745780 23126066861888 run_lib.py:133] step: 52350, training_loss: 2.35111e-02
I0215 02:22:24.298011 23126066861888 run_lib.py:133] step: 52400, training_loss: 2.25793e-02
I0215 02:22:24.450574 23126066861888 run_lib.py:146] step: 52400, eval_loss: 2.46987e-02
I0215 02:22:41.875144 23126066861888 run_lib.py:133] step: 52450, training_loss: 2.31436e-02
I0215 02:22:59.322010 23126066861888 run_lib.py:133] step: 52500, training_loss: 2.25745e-02
I0215 02:22:59.514385 23126066861888 run_lib.py:146] step: 52500, eval_loss: 2.41829e-02
I0215 02:23:17.123667 23126066861888 run_lib.py:133] step: 52550, training_loss: 2.27538e-02
I0215 02:23:34.536466 23126066861888 run_lib.py:133] step: 52600, training_loss: 2.21251e-02
I0215 02:23:34.693071 23126066861888 run_lib.py:146] step: 52600, eval_loss: 2.42167e-02
I0215 02:23:52.153928 23126066861888 run_lib.py:133] step: 52650, training_loss: 2.23628e-02
I0215 02:24:09.462302 23126066861888 run_lib.py:133] step: 52700, training_loss: 2.23717e-02
I0215 02:24:09.615050 23126066861888 run_lib.py:146] step: 52700, eval_loss: 2.42572e-02
I0215 02:24:26.885148 23126066861888 run_lib.py:133] step: 52750, training_loss: 2.32592e-02
I0215 02:24:44.319820 23126066861888 run_lib.py:133] step: 52800, training_loss: 2.33345e-02
I0215 02:24:44.475425 23126066861888 run_lib.py:146] step: 52800, eval_loss: 2.45637e-02
I0215 02:25:01.747940 23126066861888 run_lib.py:133] step: 52850, training_loss: 2.26220e-02
I0215 02:25:19.082252 23126066861888 run_lib.py:133] step: 52900, training_loss: 2.27725e-02
I0215 02:25:19.251019 23126066861888 run_lib.py:146] step: 52900, eval_loss: 2.52757e-02
I0215 02:25:36.696692 23126066861888 run_lib.py:133] step: 52950, training_loss: 2.23685e-02
I0215 02:25:54.005356 23126066861888 run_lib.py:133] step: 53000, training_loss: 2.28384e-02
I0215 02:25:54.160199 23126066861888 run_lib.py:146] step: 53000, eval_loss: 2.53236e-02
I0215 02:26:11.428777 23126066861888 run_lib.py:133] step: 53050, training_loss: 2.25302e-02
I0215 02:26:28.841213 23126066861888 run_lib.py:133] step: 53100, training_loss: 2.21249e-02
I0215 02:26:29.002019 23126066861888 run_lib.py:146] step: 53100, eval_loss: 2.46528e-02
I0215 02:26:46.330188 23126066861888 run_lib.py:133] step: 53150, training_loss: 2.14795e-02
I0215 02:27:03.674745 23126066861888 run_lib.py:133] step: 53200, training_loss: 2.23826e-02
I0215 02:27:03.826681 23126066861888 run_lib.py:146] step: 53200, eval_loss: 2.40683e-02
I0215 02:27:21.238934 23126066861888 run_lib.py:133] step: 53250, training_loss: 2.25377e-02
I0215 02:27:38.502291 23126066861888 run_lib.py:133] step: 53300, training_loss: 2.27979e-02
I0215 02:27:38.653861 23126066861888 run_lib.py:146] step: 53300, eval_loss: 2.37526e-02
I0215 02:27:55.907984 23126066861888 run_lib.py:133] step: 53350, training_loss: 2.25502e-02
I0215 02:28:13.199747 23126066861888 run_lib.py:133] step: 53400, training_loss: 2.22103e-02
I0215 02:28:13.380091 23126066861888 run_lib.py:146] step: 53400, eval_loss: 2.51663e-02
I0215 02:28:30.802484 23126066861888 run_lib.py:133] step: 53450, training_loss: 2.22732e-02
I0215 02:28:48.203338 23126066861888 run_lib.py:133] step: 53500, training_loss: 2.33940e-02
I0215 02:28:48.366230 23126066861888 run_lib.py:146] step: 53500, eval_loss: 2.51636e-02
I0215 02:29:05.803031 23126066861888 run_lib.py:133] step: 53550, training_loss: 2.22691e-02
I0215 02:29:23.240056 23126066861888 run_lib.py:133] step: 53600, training_loss: 2.23283e-02
I0215 02:29:23.439109 23126066861888 run_lib.py:146] step: 53600, eval_loss: 2.40591e-02
I0215 02:29:41.033525 23126066861888 run_lib.py:133] step: 53650, training_loss: 2.27749e-02
I0215 02:29:58.510177 23126066861888 run_lib.py:133] step: 53700, training_loss: 2.35273e-02
I0215 02:29:58.667812 23126066861888 run_lib.py:146] step: 53700, eval_loss: 2.43218e-02
I0215 02:30:16.071083 23126066861888 run_lib.py:133] step: 53750, training_loss: 2.30220e-02
I0215 02:30:33.703889 23126066861888 run_lib.py:133] step: 53800, training_loss: 2.32485e-02
I0215 02:30:33.883515 23126066861888 run_lib.py:146] step: 53800, eval_loss: 2.39929e-02
I0215 02:30:51.239489 23126066861888 run_lib.py:133] step: 53850, training_loss: 2.25273e-02
I0215 02:31:08.637445 23126066861888 run_lib.py:133] step: 53900, training_loss: 2.22099e-02
I0215 02:31:08.793186 23126066861888 run_lib.py:146] step: 53900, eval_loss: 2.50103e-02
I0215 02:31:26.042007 23126066861888 run_lib.py:133] step: 53950, training_loss: 2.29351e-02
I0215 02:31:43.414481 23126066861888 run_lib.py:133] step: 54000, training_loss: 2.27583e-02
I0215 02:31:43.585164 23126066861888 run_lib.py:146] step: 54000, eval_loss: 2.48626e-02
I0215 02:32:01.051296 23126066861888 run_lib.py:133] step: 54050, training_loss: 2.33392e-02
I0215 02:32:18.291212 23126066861888 run_lib.py:133] step: 54100, training_loss: 2.29504e-02
I0215 02:32:18.439961 23126066861888 run_lib.py:146] step: 54100, eval_loss: 2.35925e-02
I0215 02:32:35.711432 23126066861888 run_lib.py:133] step: 54150, training_loss: 2.25482e-02
I0215 02:32:53.110740 23126066861888 run_lib.py:133] step: 54200, training_loss: 2.23622e-02
I0215 02:32:53.259924 23126066861888 run_lib.py:146] step: 54200, eval_loss: 2.43736e-02
I0215 02:33:10.522115 23126066861888 run_lib.py:133] step: 54250, training_loss: 2.26986e-02
I0215 02:33:27.802071 23126066861888 run_lib.py:133] step: 54300, training_loss: 2.26819e-02
I0215 02:33:27.976132 23126066861888 run_lib.py:146] step: 54300, eval_loss: 2.50339e-02
I0215 02:33:45.379005 23126066861888 run_lib.py:133] step: 54350, training_loss: 2.21525e-02
I0215 02:34:02.650238 23126066861888 run_lib.py:133] step: 54400, training_loss: 2.24400e-02
I0215 02:34:02.805150 23126066861888 run_lib.py:146] step: 54400, eval_loss: 2.47266e-02
I0215 02:34:20.061312 23126066861888 run_lib.py:133] step: 54450, training_loss: 2.12679e-02
I0215 02:34:37.325862 23126066861888 run_lib.py:133] step: 54500, training_loss: 2.25136e-02
I0215 02:34:37.478985 23126066861888 run_lib.py:146] step: 54500, eval_loss: 2.38048e-02
I0215 02:34:54.901643 23126066861888 run_lib.py:133] step: 54550, training_loss: 2.19062e-02
I0215 02:35:12.326921 23126066861888 run_lib.py:133] step: 54600, training_loss: 2.20923e-02
I0215 02:35:12.479202 23126066861888 run_lib.py:146] step: 54600, eval_loss: 2.44288e-02
I0215 02:35:29.746099 23126066861888 run_lib.py:133] step: 54650, training_loss: 2.19291e-02
I0215 02:35:47.014430 23126066861888 run_lib.py:133] step: 54700, training_loss: 2.29702e-02
I0215 02:35:47.166071 23126066861888 run_lib.py:146] step: 54700, eval_loss: 2.43611e-02
I0215 02:36:04.584480 23126066861888 run_lib.py:133] step: 54750, training_loss: 2.22969e-02
I0215 02:36:21.826476 23126066861888 run_lib.py:133] step: 54800, training_loss: 2.24714e-02
I0215 02:36:21.982035 23126066861888 run_lib.py:146] step: 54800, eval_loss: 2.43196e-02
I0215 02:36:39.331466 23126066861888 run_lib.py:133] step: 54850, training_loss: 2.15472e-02
I0215 02:36:56.782482 23126066861888 run_lib.py:133] step: 54900, training_loss: 2.20170e-02
I0215 02:36:56.937949 23126066861888 run_lib.py:146] step: 54900, eval_loss: 2.45844e-02
I0215 02:37:14.193039 23126066861888 run_lib.py:133] step: 54950, training_loss: 2.18770e-02
I0215 02:37:31.634511 23126066861888 run_lib.py:133] step: 55000, training_loss: 2.23634e-02
I0215 02:37:31.794728 23126066861888 run_lib.py:146] step: 55000, eval_loss: 2.29539e-02
I0215 02:37:49.045685 23126066861888 run_lib.py:133] step: 55050, training_loss: 2.16524e-02
I0215 02:38:06.285165 23126066861888 run_lib.py:133] step: 55100, training_loss: 2.33328e-02
I0215 02:38:06.441662 23126066861888 run_lib.py:146] step: 55100, eval_loss: 2.42457e-02
I0215 02:38:23.884203 23126066861888 run_lib.py:133] step: 55150, training_loss: 2.20226e-02
I0215 02:38:41.207006 23126066861888 run_lib.py:133] step: 55200, training_loss: 2.27784e-02
I0215 02:38:41.364128 23126066861888 run_lib.py:146] step: 55200, eval_loss: 2.38711e-02
I0215 02:38:58.646183 23126066861888 run_lib.py:133] step: 55250, training_loss: 2.24403e-02
I0215 02:39:16.115306 23126066861888 run_lib.py:133] step: 55300, training_loss: 2.20339e-02
I0215 02:39:16.272212 23126066861888 run_lib.py:146] step: 55300, eval_loss: 2.49473e-02
I0215 02:39:33.524066 23126066861888 run_lib.py:133] step: 55350, training_loss: 2.30865e-02
I0215 02:39:50.807475 23126066861888 run_lib.py:133] step: 55400, training_loss: 2.34130e-02
I0215 02:39:50.987911 23126066861888 run_lib.py:146] step: 55400, eval_loss: 2.38279e-02
I0215 02:40:08.371273 23126066861888 run_lib.py:133] step: 55450, training_loss: 2.30856e-02
I0215 02:40:25.651606 23126066861888 run_lib.py:133] step: 55500, training_loss: 2.16287e-02
I0215 02:40:25.818287 23126066861888 run_lib.py:146] step: 55500, eval_loss: 2.49858e-02
I0215 02:40:43.135108 23126066861888 run_lib.py:133] step: 55550, training_loss: 2.24331e-02
I0215 02:41:00.405861 23126066861888 run_lib.py:133] step: 55600, training_loss: 2.26319e-02
I0215 02:41:00.554806 23126066861888 run_lib.py:146] step: 55600, eval_loss: 2.50334e-02
I0215 02:41:18.022941 23126066861888 run_lib.py:133] step: 55650, training_loss: 2.23764e-02
I0215 02:41:35.395401 23126066861888 run_lib.py:133] step: 55700, training_loss: 2.24936e-02
I0215 02:41:35.559190 23126066861888 run_lib.py:146] step: 55700, eval_loss: 2.44895e-02
I0215 02:41:52.911741 23126066861888 run_lib.py:133] step: 55750, training_loss: 2.21460e-02
I0215 02:42:10.196976 23126066861888 run_lib.py:133] step: 55800, training_loss: 2.34656e-02
I0215 02:42:10.352940 23126066861888 run_lib.py:146] step: 55800, eval_loss: 2.37833e-02
I0215 02:42:27.802057 23126066861888 run_lib.py:133] step: 55850, training_loss: 2.18688e-02
I0215 02:42:45.053355 23126066861888 run_lib.py:133] step: 55900, training_loss: 2.24074e-02
I0215 02:42:45.206024 23126066861888 run_lib.py:146] step: 55900, eval_loss: 2.44260e-02
I0215 02:43:02.478932 23126066861888 run_lib.py:133] step: 55950, training_loss: 2.27167e-02
I0215 02:43:19.949227 23126066861888 run_lib.py:133] step: 56000, training_loss: 2.26302e-02
I0215 02:43:20.101754 23126066861888 run_lib.py:146] step: 56000, eval_loss: 2.36823e-02
I0215 02:43:37.401596 23126066861888 run_lib.py:133] step: 56050, training_loss: 2.26111e-02
I0215 02:43:54.837757 23126066861888 run_lib.py:133] step: 56100, training_loss: 2.12642e-02
I0215 02:43:54.987696 23126066861888 run_lib.py:146] step: 56100, eval_loss: 2.43857e-02
I0215 02:44:12.240863 23126066861888 run_lib.py:133] step: 56150, training_loss: 2.22844e-02
I0215 02:44:29.546200 23126066861888 run_lib.py:133] step: 56200, training_loss: 2.33246e-02
I0215 02:44:29.702938 23126066861888 run_lib.py:146] step: 56200, eval_loss: 2.50057e-02
I0215 02:44:47.125597 23126066861888 run_lib.py:133] step: 56250, training_loss: 2.16207e-02
I0215 02:45:04.450228 23126066861888 run_lib.py:133] step: 56300, training_loss: 2.24702e-02
I0215 02:45:04.609031 23126066861888 run_lib.py:146] step: 56300, eval_loss: 2.43450e-02
I0215 02:45:21.849294 23126066861888 run_lib.py:133] step: 56350, training_loss: 2.22680e-02
I0215 02:45:39.323080 23126066861888 run_lib.py:133] step: 56400, training_loss: 2.25784e-02
I0215 02:45:39.475973 23126066861888 run_lib.py:146] step: 56400, eval_loss: 2.47193e-02
I0215 02:45:56.761492 23126066861888 run_lib.py:133] step: 56450, training_loss: 2.29142e-02
I0215 02:46:14.035327 23126066861888 run_lib.py:133] step: 56500, training_loss: 2.23022e-02
I0215 02:46:14.191760 23126066861888 run_lib.py:146] step: 56500, eval_loss: 2.38248e-02
I0215 02:46:31.560256 23126066861888 run_lib.py:133] step: 56550, training_loss: 2.31782e-02
I0215 02:46:48.899966 23126066861888 run_lib.py:133] step: 56600, training_loss: 2.16323e-02
I0215 02:46:49.052194 23126066861888 run_lib.py:146] step: 56600, eval_loss: 2.43789e-02
I0215 02:47:06.340152 23126066861888 run_lib.py:133] step: 56650, training_loss: 2.22457e-02
I0215 02:47:23.600772 23126066861888 run_lib.py:133] step: 56700, training_loss: 2.19312e-02
I0215 02:47:23.757414 23126066861888 run_lib.py:146] step: 56700, eval_loss: 2.38809e-02
I0215 02:47:41.149536 23126066861888 run_lib.py:133] step: 56750, training_loss: 2.23534e-02
I0215 02:47:58.531287 23126066861888 run_lib.py:133] step: 56800, training_loss: 2.19919e-02
I0215 02:47:58.690043 23126066861888 run_lib.py:146] step: 56800, eval_loss: 2.40505e-02
I0215 02:48:15.956606 23126066861888 run_lib.py:133] step: 56850, training_loss: 2.26020e-02
I0215 02:48:33.240364 23126066861888 run_lib.py:133] step: 56900, training_loss: 2.22481e-02
I0215 02:48:33.394209 23126066861888 run_lib.py:146] step: 56900, eval_loss: 2.45952e-02
I0215 02:48:50.849226 23126066861888 run_lib.py:133] step: 56950, training_loss: 2.18087e-02
I0215 02:49:08.210440 23126066861888 run_lib.py:133] step: 57000, training_loss: 2.33231e-02
I0215 02:49:08.370789 23126066861888 run_lib.py:146] step: 57000, eval_loss: 2.43446e-02
I0215 02:49:25.619769 23126066861888 run_lib.py:133] step: 57050, training_loss: 2.24312e-02
I0215 02:49:43.080878 23126066861888 run_lib.py:133] step: 57100, training_loss: 2.26343e-02
I0215 02:49:43.237049 23126066861888 run_lib.py:146] step: 57100, eval_loss: 2.34026e-02
I0215 02:50:00.536308 23126066861888 run_lib.py:133] step: 57150, training_loss: 2.29396e-02
I0215 02:50:18.007131 23126066861888 run_lib.py:133] step: 57200, training_loss: 2.20719e-02
I0215 02:50:18.161840 23126066861888 run_lib.py:146] step: 57200, eval_loss: 2.42221e-02
I0215 02:50:35.421077 23126066861888 run_lib.py:133] step: 57250, training_loss: 2.19657e-02
I0215 02:50:52.693580 23126066861888 run_lib.py:133] step: 57300, training_loss: 2.27598e-02
I0215 02:50:52.847022 23126066861888 run_lib.py:146] step: 57300, eval_loss: 2.49189e-02
I0215 02:51:10.395261 23126066861888 run_lib.py:133] step: 57350, training_loss: 2.17480e-02
I0215 02:51:27.944566 23126066861888 run_lib.py:133] step: 57400, training_loss: 2.26413e-02
I0215 02:51:28.131244 23126066861888 run_lib.py:146] step: 57400, eval_loss: 2.33440e-02
I0215 02:51:45.592434 23126066861888 run_lib.py:133] step: 57450, training_loss: 2.25927e-02
I0215 02:52:03.161748 23126066861888 run_lib.py:133] step: 57500, training_loss: 2.25356e-02
I0215 02:52:03.313621 23126066861888 run_lib.py:146] step: 57500, eval_loss: 2.37622e-02
I0215 02:52:20.690276 23126066861888 run_lib.py:133] step: 57550, training_loss: 2.23379e-02
I0215 02:52:38.137012 23126066861888 run_lib.py:133] step: 57600, training_loss: 2.29347e-02
I0215 02:52:38.325934 23126066861888 run_lib.py:146] step: 57600, eval_loss: 2.35684e-02
I0215 02:52:55.793376 23126066861888 run_lib.py:133] step: 57650, training_loss: 2.24551e-02
I0215 02:53:13.241624 23126066861888 run_lib.py:133] step: 57700, training_loss: 2.10635e-02
I0215 02:53:13.411997 23126066861888 run_lib.py:146] step: 57700, eval_loss: 2.36336e-02
I0215 02:53:30.684717 23126066861888 run_lib.py:133] step: 57750, training_loss: 2.18919e-02
I0215 02:53:47.969350 23126066861888 run_lib.py:133] step: 57800, training_loss: 2.29406e-02
I0215 02:53:48.124954 23126066861888 run_lib.py:146] step: 57800, eval_loss: 2.40775e-02
I0215 02:54:05.562881 23126066861888 run_lib.py:133] step: 57850, training_loss: 2.28550e-02
I0215 02:54:22.866650 23126066861888 run_lib.py:133] step: 57900, training_loss: 2.26322e-02
I0215 02:54:23.019017 23126066861888 run_lib.py:146] step: 57900, eval_loss: 2.43025e-02
I0215 02:54:40.287084 23126066861888 run_lib.py:133] step: 57950, training_loss: 2.21909e-02
I0215 02:54:57.628873 23126066861888 run_lib.py:133] step: 58000, training_loss: 2.31397e-02
I0215 02:54:57.784234 23126066861888 run_lib.py:146] step: 58000, eval_loss: 2.35849e-02
I0215 02:55:15.262954 23126066861888 run_lib.py:133] step: 58050, training_loss: 2.21634e-02
I0215 02:55:32.532567 23126066861888 run_lib.py:133] step: 58100, training_loss: 2.23791e-02
I0215 02:55:32.686946 23126066861888 run_lib.py:146] step: 58100, eval_loss: 2.42925e-02
I0215 02:55:49.916770 23126066861888 run_lib.py:133] step: 58150, training_loss: 2.23474e-02
I0215 02:56:07.337219 23126066861888 run_lib.py:133] step: 58200, training_loss: 2.28684e-02
I0215 02:56:07.497004 23126066861888 run_lib.py:146] step: 58200, eval_loss: 2.45989e-02
I0215 02:56:24.804080 23126066861888 run_lib.py:133] step: 58250, training_loss: 2.14211e-02
I0215 02:56:42.265376 23126066861888 run_lib.py:133] step: 58300, training_loss: 2.19910e-02
I0215 02:56:42.421183 23126066861888 run_lib.py:146] step: 58300, eval_loss: 2.38286e-02
I0215 02:56:59.708353 23126066861888 run_lib.py:133] step: 58350, training_loss: 2.27708e-02
I0215 02:57:16.987710 23126066861888 run_lib.py:133] step: 58400, training_loss: 2.32902e-02
I0215 02:57:17.140802 23126066861888 run_lib.py:146] step: 58400, eval_loss: 2.41188e-02
I0215 02:57:34.561733 23126066861888 run_lib.py:133] step: 58450, training_loss: 2.23455e-02
I0215 02:57:51.881345 23126066861888 run_lib.py:133] step: 58500, training_loss: 2.23568e-02
I0215 02:57:52.037123 23126066861888 run_lib.py:146] step: 58500, eval_loss: 2.46629e-02
I0215 02:58:09.365462 23126066861888 run_lib.py:133] step: 58550, training_loss: 2.24990e-02
I0215 02:58:26.855246 23126066861888 run_lib.py:133] step: 58600, training_loss: 2.19745e-02
I0215 02:58:27.010931 23126066861888 run_lib.py:146] step: 58600, eval_loss: 2.44322e-02
I0215 02:58:44.284540 23126066861888 run_lib.py:133] step: 58650, training_loss: 2.34722e-02
I0215 02:59:01.502858 23126066861888 run_lib.py:133] step: 58700, training_loss: 2.29271e-02
I0215 02:59:01.659200 23126066861888 run_lib.py:146] step: 58700, eval_loss: 2.31844e-02
I0215 02:59:18.984118 23126066861888 run_lib.py:133] step: 58750, training_loss: 2.26313e-02
I0215 02:59:36.245302 23126066861888 run_lib.py:133] step: 58800, training_loss: 2.28774e-02
I0215 02:59:36.401728 23126066861888 run_lib.py:146] step: 58800, eval_loss: 2.54568e-02
I0215 02:59:53.678667 23126066861888 run_lib.py:133] step: 58850, training_loss: 2.15955e-02
I0215 03:00:10.913152 23126066861888 run_lib.py:133] step: 58900, training_loss: 2.24935e-02
I0215 03:00:11.064072 23126066861888 run_lib.py:146] step: 58900, eval_loss: 2.44142e-02
I0215 03:00:28.526619 23126066861888 run_lib.py:133] step: 58950, training_loss: 2.14656e-02
I0215 03:00:45.857713 23126066861888 run_lib.py:133] step: 59000, training_loss: 2.26067e-02
I0215 03:00:46.009910 23126066861888 run_lib.py:146] step: 59000, eval_loss: 2.38769e-02
I0215 03:01:03.254004 23126066861888 run_lib.py:133] step: 59050, training_loss: 2.25030e-02
I0215 03:01:20.516168 23126066861888 run_lib.py:133] step: 59100, training_loss: 2.21773e-02
I0215 03:01:20.687986 23126066861888 run_lib.py:146] step: 59100, eval_loss: 2.47948e-02
I0215 03:01:38.195122 23126066861888 run_lib.py:133] step: 59150, training_loss: 2.23671e-02
I0215 03:01:55.450587 23126066861888 run_lib.py:133] step: 59200, training_loss: 2.21898e-02
I0215 03:01:55.605124 23126066861888 run_lib.py:146] step: 59200, eval_loss: 2.39893e-02
I0215 03:02:12.846725 23126066861888 run_lib.py:133] step: 59250, training_loss: 2.17626e-02
I0215 03:02:30.242153 23126066861888 run_lib.py:133] step: 59300, training_loss: 2.22306e-02
I0215 03:02:30.394591 23126066861888 run_lib.py:146] step: 59300, eval_loss: 2.39644e-02
I0215 03:02:47.670064 23126066861888 run_lib.py:133] step: 59350, training_loss: 2.26670e-02
I0215 03:03:05.084285 23126066861888 run_lib.py:133] step: 59400, training_loss: 2.22228e-02
I0215 03:03:05.241772 23126066861888 run_lib.py:146] step: 59400, eval_loss: 2.44338e-02
I0215 03:03:22.537857 23126066861888 run_lib.py:133] step: 59450, training_loss: 2.27816e-02
I0215 03:03:39.797694 23126066861888 run_lib.py:133] step: 59500, training_loss: 2.19503e-02
I0215 03:03:39.951228 23126066861888 run_lib.py:146] step: 59500, eval_loss: 2.36382e-02
I0215 03:03:57.433986 23126066861888 run_lib.py:133] step: 59550, training_loss: 2.24721e-02
I0215 03:04:14.722592 23126066861888 run_lib.py:133] step: 59600, training_loss: 2.27590e-02
I0215 03:04:14.879241 23126066861888 run_lib.py:146] step: 59600, eval_loss: 2.40016e-02
I0215 03:04:32.175909 23126066861888 run_lib.py:133] step: 59650, training_loss: 2.32680e-02
I0215 03:04:49.635215 23126066861888 run_lib.py:133] step: 59700, training_loss: 2.24194e-02
I0215 03:04:49.788177 23126066861888 run_lib.py:146] step: 59700, eval_loss: 2.55475e-02
I0215 03:05:07.070048 23126066861888 run_lib.py:133] step: 59750, training_loss: 2.23934e-02
I0215 03:05:24.356349 23126066861888 run_lib.py:133] step: 59800, training_loss: 2.20352e-02
I0215 03:05:24.508908 23126066861888 run_lib.py:146] step: 59800, eval_loss: 2.59503e-02
I0215 03:05:41.878342 23126066861888 run_lib.py:133] step: 59850, training_loss: 2.18981e-02
I0215 03:05:59.153244 23126066861888 run_lib.py:133] step: 59900, training_loss: 2.27840e-02
I0215 03:05:59.304005 23126066861888 run_lib.py:146] step: 59900, eval_loss: 2.44005e-02
I0215 03:06:16.640545 23126066861888 run_lib.py:133] step: 59950, training_loss: 2.27341e-02
I0215 03:06:33.973567 23126066861888 run_lib.py:133] step: 60000, training_loss: 2.24545e-02
I0215 03:06:34.639485 23126066861888 run_lib.py:146] step: 60000, eval_loss: 2.48331e-02
I0215 03:06:54.760724 23126066861888 run_lib.py:133] step: 60050, training_loss: 2.21090e-02
I0215 03:07:12.071657 23126066861888 run_lib.py:133] step: 60100, training_loss: 2.25067e-02
I0215 03:07:12.229207 23126066861888 run_lib.py:146] step: 60100, eval_loss: 2.41601e-02
I0215 03:07:29.523384 23126066861888 run_lib.py:133] step: 60150, training_loss: 2.29324e-02
I0215 03:07:46.775681 23126066861888 run_lib.py:133] step: 60200, training_loss: 2.30971e-02
I0215 03:07:46.935254 23126066861888 run_lib.py:146] step: 60200, eval_loss: 2.38947e-02
I0215 03:08:04.245873 23126066861888 run_lib.py:133] step: 60250, training_loss: 2.22037e-02
I0215 03:08:21.598349 23126066861888 run_lib.py:133] step: 60300, training_loss: 2.27991e-02
I0215 03:08:21.752561 23126066861888 run_lib.py:146] step: 60300, eval_loss: 2.35769e-02
I0215 03:08:39.221048 23126066861888 run_lib.py:133] step: 60350, training_loss: 2.24458e-02
I0215 03:08:56.526734 23126066861888 run_lib.py:133] step: 60400, training_loss: 2.27336e-02
I0215 03:08:56.682943 23126066861888 run_lib.py:146] step: 60400, eval_loss: 2.38605e-02
I0215 03:09:13.922353 23126066861888 run_lib.py:133] step: 60450, training_loss: 2.32041e-02
I0215 03:09:31.236396 23126066861888 run_lib.py:133] step: 60500, training_loss: 2.21181e-02
I0215 03:09:31.404385 23126066861888 run_lib.py:146] step: 60500, eval_loss: 2.41715e-02
I0215 03:09:48.933793 23126066861888 run_lib.py:133] step: 60550, training_loss: 2.19144e-02
I0215 03:10:06.221182 23126066861888 run_lib.py:133] step: 60600, training_loss: 2.26140e-02
I0215 03:10:06.381072 23126066861888 run_lib.py:146] step: 60600, eval_loss: 2.42345e-02
I0215 03:10:23.645182 23126066861888 run_lib.py:133] step: 60650, training_loss: 2.24528e-02
I0215 03:10:41.058171 23126066861888 run_lib.py:133] step: 60700, training_loss: 2.28132e-02
I0215 03:10:41.212054 23126066861888 run_lib.py:146] step: 60700, eval_loss: 2.50564e-02
I0215 03:10:58.492395 23126066861888 run_lib.py:133] step: 60750, training_loss: 2.24427e-02
I0215 03:11:15.967618 23126066861888 run_lib.py:133] step: 60800, training_loss: 2.17903e-02
I0215 03:11:16.122220 23126066861888 run_lib.py:146] step: 60800, eval_loss: 2.40621e-02
I0215 03:11:33.442531 23126066861888 run_lib.py:133] step: 60850, training_loss: 2.19261e-02
I0215 03:11:50.726186 23126066861888 run_lib.py:133] step: 60900, training_loss: 2.30863e-02
I0215 03:11:50.880075 23126066861888 run_lib.py:146] step: 60900, eval_loss: 2.40267e-02
I0215 03:12:08.299403 23126066861888 run_lib.py:133] step: 60950, training_loss: 2.19674e-02
I0215 03:12:25.588458 23126066861888 run_lib.py:133] step: 61000, training_loss: 2.25385e-02
I0215 03:12:25.742257 23126066861888 run_lib.py:146] step: 61000, eval_loss: 2.49507e-02
I0215 03:12:43.081516 23126066861888 run_lib.py:133] step: 61050, training_loss: 2.21608e-02
I0215 03:13:00.608336 23126066861888 run_lib.py:133] step: 61100, training_loss: 2.19123e-02
I0215 03:13:00.766099 23126066861888 run_lib.py:146] step: 61100, eval_loss: 2.40576e-02
I0215 03:13:18.005888 23126066861888 run_lib.py:133] step: 61150, training_loss: 2.27350e-02
I0215 03:13:35.248383 23126066861888 run_lib.py:133] step: 61200, training_loss: 2.23095e-02
I0215 03:13:35.403027 23126066861888 run_lib.py:146] step: 61200, eval_loss: 2.43881e-02
I0215 03:13:52.732105 23126066861888 run_lib.py:133] step: 61250, training_loss: 2.23572e-02
I0215 03:14:09.966064 23126066861888 run_lib.py:133] step: 61300, training_loss: 2.23006e-02
I0215 03:14:10.118997 23126066861888 run_lib.py:146] step: 61300, eval_loss: 2.41757e-02
I0215 03:14:27.397712 23126066861888 run_lib.py:133] step: 61350, training_loss: 2.23830e-02
I0215 03:14:44.678795 23126066861888 run_lib.py:133] step: 61400, training_loss: 2.21854e-02
I0215 03:14:44.832198 23126066861888 run_lib.py:146] step: 61400, eval_loss: 2.36806e-02
I0215 03:15:02.317530 23126066861888 run_lib.py:133] step: 61450, training_loss: 2.20394e-02
I0215 03:15:19.720878 23126066861888 run_lib.py:133] step: 61500, training_loss: 2.23719e-02
I0215 03:15:19.873769 23126066861888 run_lib.py:146] step: 61500, eval_loss: 2.42996e-02
I0215 03:15:37.104947 23126066861888 run_lib.py:133] step: 61550, training_loss: 2.21631e-02
I0215 03:15:54.344482 23126066861888 run_lib.py:133] step: 61600, training_loss: 2.25865e-02
I0215 03:15:54.505897 23126066861888 run_lib.py:146] step: 61600, eval_loss: 2.44357e-02
I0215 03:16:11.947426 23126066861888 run_lib.py:133] step: 61650, training_loss: 2.19128e-02
I0215 03:16:29.262674 23126066861888 run_lib.py:133] step: 61700, training_loss: 2.24468e-02
I0215 03:16:29.417103 23126066861888 run_lib.py:146] step: 61700, eval_loss: 2.43380e-02
I0215 03:16:46.674309 23126066861888 run_lib.py:133] step: 61750, training_loss: 2.29417e-02
I0215 03:17:04.127983 23126066861888 run_lib.py:133] step: 61800, training_loss: 2.17246e-02
I0215 03:17:04.281964 23126066861888 run_lib.py:146] step: 61800, eval_loss: 2.57568e-02
I0215 03:17:21.554338 23126066861888 run_lib.py:133] step: 61850, training_loss: 2.23925e-02
I0215 03:17:39.025475 23126066861888 run_lib.py:133] step: 61900, training_loss: 2.36925e-02
I0215 03:17:39.177170 23126066861888 run_lib.py:146] step: 61900, eval_loss: 2.37942e-02
I0215 03:17:56.510153 23126066861888 run_lib.py:133] step: 61950, training_loss: 2.26423e-02
I0215 03:18:13.787290 23126066861888 run_lib.py:133] step: 62000, training_loss: 2.16290e-02
I0215 03:18:13.946051 23126066861888 run_lib.py:146] step: 62000, eval_loss: 2.52170e-02
I0215 03:18:31.387839 23126066861888 run_lib.py:133] step: 62050, training_loss: 2.18870e-02
I0215 03:18:48.665449 23126066861888 run_lib.py:133] step: 62100, training_loss: 2.29771e-02
I0215 03:18:48.820096 23126066861888 run_lib.py:146] step: 62100, eval_loss: 2.49641e-02
I0215 03:19:06.084861 23126066861888 run_lib.py:133] step: 62150, training_loss: 2.28374e-02
I0215 03:19:23.450223 23126066861888 run_lib.py:133] step: 62200, training_loss: 2.20609e-02
I0215 03:19:23.604816 23126066861888 run_lib.py:146] step: 62200, eval_loss: 2.36702e-02
I0215 03:19:40.938427 23126066861888 run_lib.py:133] step: 62250, training_loss: 2.25056e-02
I0215 03:19:58.313806 23126066861888 run_lib.py:133] step: 62300, training_loss: 2.26454e-02
I0215 03:19:58.468739 23126066861888 run_lib.py:146] step: 62300, eval_loss: 2.34494e-02
I0215 03:20:15.846857 23126066861888 run_lib.py:133] step: 62350, training_loss: 2.21840e-02
I0215 03:20:33.151062 23126066861888 run_lib.py:133] step: 62400, training_loss: 2.23162e-02
I0215 03:20:33.303040 23126066861888 run_lib.py:146] step: 62400, eval_loss: 2.39401e-02
I0215 03:20:50.585565 23126066861888 run_lib.py:133] step: 62450, training_loss: 2.21453e-02
I0215 03:21:07.891589 23126066861888 run_lib.py:133] step: 62500, training_loss: 2.20360e-02
I0215 03:21:08.062930 23126066861888 run_lib.py:146] step: 62500, eval_loss: 2.52519e-02
I0215 03:21:25.541016 23126066861888 run_lib.py:133] step: 62550, training_loss: 2.23306e-02
I0215 03:21:42.945433 23126066861888 run_lib.py:133] step: 62600, training_loss: 2.21722e-02
I0215 03:21:43.099327 23126066861888 run_lib.py:146] step: 62600, eval_loss: 2.42488e-02
I0215 03:22:00.382885 23126066861888 run_lib.py:133] step: 62650, training_loss: 2.17535e-02
I0215 03:22:17.628728 23126066861888 run_lib.py:133] step: 62700, training_loss: 2.19492e-02
I0215 03:22:17.781932 23126066861888 run_lib.py:146] step: 62700, eval_loss: 2.45900e-02
I0215 03:22:35.177153 23126066861888 run_lib.py:133] step: 62750, training_loss: 2.18847e-02
I0215 03:22:52.456790 23126066861888 run_lib.py:133] step: 62800, training_loss: 2.22227e-02
I0215 03:22:52.607963 23126066861888 run_lib.py:146] step: 62800, eval_loss: 2.48258e-02
I0215 03:23:09.966579 23126066861888 run_lib.py:133] step: 62850, training_loss: 2.19757e-02
I0215 03:23:27.402890 23126066861888 run_lib.py:133] step: 62900, training_loss: 2.09919e-02
I0215 03:23:27.557996 23126066861888 run_lib.py:146] step: 62900, eval_loss: 2.46504e-02
I0215 03:23:44.825708 23126066861888 run_lib.py:133] step: 62950, training_loss: 2.23448e-02
I0215 03:24:02.290683 23126066861888 run_lib.py:133] step: 63000, training_loss: 2.16518e-02
I0215 03:24:02.453473 23126066861888 run_lib.py:146] step: 63000, eval_loss: 2.39476e-02
I0215 03:24:19.713212 23126066861888 run_lib.py:133] step: 63050, training_loss: 2.24276e-02
I0215 03:24:36.987227 23126066861888 run_lib.py:133] step: 63100, training_loss: 2.20446e-02
I0215 03:24:37.154983 23126066861888 run_lib.py:146] step: 63100, eval_loss: 2.52751e-02
I0215 03:24:54.631440 23126066861888 run_lib.py:133] step: 63150, training_loss: 2.20406e-02
I0215 03:25:11.935479 23126066861888 run_lib.py:133] step: 63200, training_loss: 2.21992e-02
I0215 03:25:12.086772 23126066861888 run_lib.py:146] step: 63200, eval_loss: 2.46376e-02
I0215 03:25:29.383307 23126066861888 run_lib.py:133] step: 63250, training_loss: 2.23497e-02
I0215 03:25:46.830223 23126066861888 run_lib.py:133] step: 63300, training_loss: 2.21654e-02
I0215 03:25:46.980091 23126066861888 run_lib.py:146] step: 63300, eval_loss: 2.36512e-02
I0215 03:26:04.225405 23126066861888 run_lib.py:133] step: 63350, training_loss: 2.23649e-02
I0215 03:26:21.494081 23126066861888 run_lib.py:133] step: 63400, training_loss: 2.23756e-02
I0215 03:26:21.659544 23126066861888 run_lib.py:146] step: 63400, eval_loss: 2.37756e-02
I0215 03:26:39.059450 23126066861888 run_lib.py:133] step: 63450, training_loss: 2.26702e-02
I0215 03:26:56.346626 23126066861888 run_lib.py:133] step: 63500, training_loss: 2.22328e-02
I0215 03:26:56.502041 23126066861888 run_lib.py:146] step: 63500, eval_loss: 2.46749e-02
I0215 03:27:13.817198 23126066861888 run_lib.py:133] step: 63550, training_loss: 2.25357e-02
I0215 03:27:31.079805 23126066861888 run_lib.py:133] step: 63600, training_loss: 2.23852e-02
I0215 03:27:31.233986 23126066861888 run_lib.py:146] step: 63600, eval_loss: 2.42649e-02
I0215 03:27:48.664631 23126066861888 run_lib.py:133] step: 63650, training_loss: 2.24304e-02
I0215 03:28:06.036990 23126066861888 run_lib.py:133] step: 63700, training_loss: 2.07799e-02
I0215 03:28:06.190533 23126066861888 run_lib.py:146] step: 63700, eval_loss: 2.40185e-02
I0215 03:28:23.477529 23126066861888 run_lib.py:133] step: 63750, training_loss: 2.27928e-02
I0215 03:28:40.726203 23126066861888 run_lib.py:133] step: 63800, training_loss: 2.27154e-02
I0215 03:28:40.880959 23126066861888 run_lib.py:146] step: 63800, eval_loss: 2.44378e-02
I0215 03:28:58.303216 23126066861888 run_lib.py:133] step: 63850, training_loss: 2.23964e-02
I0215 03:29:15.577425 23126066861888 run_lib.py:133] step: 63900, training_loss: 2.21377e-02
I0215 03:29:15.733272 23126066861888 run_lib.py:146] step: 63900, eval_loss: 2.44367e-02
I0215 03:29:32.986722 23126066861888 run_lib.py:133] step: 63950, training_loss: 2.33908e-02
I0215 03:29:50.473196 23126066861888 run_lib.py:133] step: 64000, training_loss: 2.26571e-02
I0215 03:29:50.629132 23126066861888 run_lib.py:146] step: 64000, eval_loss: 2.41720e-02
I0215 03:30:07.933915 23126066861888 run_lib.py:133] step: 64050, training_loss: 2.17077e-02
I0215 03:30:25.367684 23126066861888 run_lib.py:133] step: 64100, training_loss: 2.10005e-02
I0215 03:30:25.520669 23126066861888 run_lib.py:146] step: 64100, eval_loss: 2.41844e-02
I0215 03:30:42.785380 23126066861888 run_lib.py:133] step: 64150, training_loss: 2.27290e-02
I0215 03:31:00.035695 23126066861888 run_lib.py:133] step: 64200, training_loss: 2.22358e-02
I0215 03:31:00.185895 23126066861888 run_lib.py:146] step: 64200, eval_loss: 2.51801e-02
I0215 03:31:17.599102 23126066861888 run_lib.py:133] step: 64250, training_loss: 2.27388e-02
I0215 03:31:34.934056 23126066861888 run_lib.py:133] step: 64300, training_loss: 2.28348e-02
I0215 03:31:35.095022 23126066861888 run_lib.py:146] step: 64300, eval_loss: 2.49415e-02
I0215 03:31:52.429018 23126066861888 run_lib.py:133] step: 64350, training_loss: 2.18073e-02
I0215 03:32:09.894926 23126066861888 run_lib.py:133] step: 64400, training_loss: 2.33179e-02
I0215 03:32:10.058804 23126066861888 run_lib.py:146] step: 64400, eval_loss: 2.40613e-02
I0215 03:32:27.327074 23126066861888 run_lib.py:133] step: 64450, training_loss: 2.22852e-02
I0215 03:32:44.596982 23126066861888 run_lib.py:133] step: 64500, training_loss: 2.19420e-02
I0215 03:32:44.751881 23126066861888 run_lib.py:146] step: 64500, eval_loss: 2.49200e-02
I0215 03:33:02.051065 23126066861888 run_lib.py:133] step: 64550, training_loss: 2.18837e-02
I0215 03:33:19.372289 23126066861888 run_lib.py:133] step: 64600, training_loss: 2.17925e-02
I0215 03:33:19.526656 23126066861888 run_lib.py:146] step: 64600, eval_loss: 2.39500e-02
I0215 03:33:36.806821 23126066861888 run_lib.py:133] step: 64650, training_loss: 2.29468e-02
I0215 03:33:54.068043 23126066861888 run_lib.py:133] step: 64700, training_loss: 2.27328e-02
I0215 03:33:54.217914 23126066861888 run_lib.py:146] step: 64700, eval_loss: 2.44756e-02
I0215 03:34:11.650881 23126066861888 run_lib.py:133] step: 64750, training_loss: 2.13494e-02
I0215 03:34:29.003319 23126066861888 run_lib.py:133] step: 64800, training_loss: 2.19375e-02
I0215 03:34:29.172236 23126066861888 run_lib.py:146] step: 64800, eval_loss: 2.46303e-02
I0215 03:34:46.487882 23126066861888 run_lib.py:133] step: 64850, training_loss: 2.22028e-02
I0215 03:35:03.789928 23126066861888 run_lib.py:133] step: 64900, training_loss: 2.22414e-02
I0215 03:35:03.950987 23126066861888 run_lib.py:146] step: 64900, eval_loss: 2.44790e-02
I0215 03:35:21.440784 23126066861888 run_lib.py:133] step: 64950, training_loss: 2.21295e-02
I0215 03:35:38.689625 23126066861888 run_lib.py:133] step: 65000, training_loss: 2.29490e-02
I0215 03:35:38.849019 23126066861888 run_lib.py:146] step: 65000, eval_loss: 2.52537e-02
I0215 03:35:56.118306 23126066861888 run_lib.py:133] step: 65050, training_loss: 2.23485e-02
I0215 03:36:13.549049 23126066861888 run_lib.py:133] step: 65100, training_loss: 2.23973e-02
I0215 03:36:13.719144 23126066861888 run_lib.py:146] step: 65100, eval_loss: 2.40271e-02
I0215 03:36:31.062810 23126066861888 run_lib.py:133] step: 65150, training_loss: 2.21108e-02
I0215 03:36:48.539995 23126066861888 run_lib.py:133] step: 65200, training_loss: 2.23298e-02
I0215 03:36:48.691028 23126066861888 run_lib.py:146] step: 65200, eval_loss: 2.39968e-02
I0215 03:37:05.999060 23126066861888 run_lib.py:133] step: 65250, training_loss: 2.21581e-02
I0215 03:37:23.302360 23126066861888 run_lib.py:133] step: 65300, training_loss: 2.27915e-02
I0215 03:37:23.458194 23126066861888 run_lib.py:146] step: 65300, eval_loss: 2.49094e-02
I0215 03:37:40.871077 23126066861888 run_lib.py:133] step: 65350, training_loss: 2.22641e-02
I0215 03:37:58.182526 23126066861888 run_lib.py:133] step: 65400, training_loss: 2.23306e-02
I0215 03:37:58.348008 23126066861888 run_lib.py:146] step: 65400, eval_loss: 2.40833e-02
I0215 03:38:15.641509 23126066861888 run_lib.py:133] step: 65450, training_loss: 2.23717e-02
I0215 03:38:33.139836 23126066861888 run_lib.py:133] step: 65500, training_loss: 2.17514e-02
I0215 03:38:33.294190 23126066861888 run_lib.py:146] step: 65500, eval_loss: 2.44218e-02
I0215 03:38:50.539125 23126066861888 run_lib.py:133] step: 65550, training_loss: 2.19022e-02
I0215 03:39:07.789671 23126066861888 run_lib.py:133] step: 65600, training_loss: 2.20356e-02
I0215 03:39:07.940780 23126066861888 run_lib.py:146] step: 65600, eval_loss: 2.45803e-02
I0215 03:39:25.262460 23126066861888 run_lib.py:133] step: 65650, training_loss: 2.29036e-02
I0215 03:39:42.563447 23126066861888 run_lib.py:133] step: 65700, training_loss: 2.14207e-02
I0215 03:39:42.719262 23126066861888 run_lib.py:146] step: 65700, eval_loss: 2.46535e-02
I0215 03:40:00.025983 23126066861888 run_lib.py:133] step: 65750, training_loss: 2.23215e-02
I0215 03:40:17.342409 23126066861888 run_lib.py:133] step: 65800, training_loss: 2.26594e-02
I0215 03:40:17.498145 23126066861888 run_lib.py:146] step: 65800, eval_loss: 2.39388e-02
I0215 03:40:34.932109 23126066861888 run_lib.py:133] step: 65850, training_loss: 2.16344e-02
I0215 03:40:52.247491 23126066861888 run_lib.py:133] step: 65900, training_loss: 2.19353e-02
I0215 03:40:52.399620 23126066861888 run_lib.py:146] step: 65900, eval_loss: 2.48504e-02
I0215 03:41:09.693041 23126066861888 run_lib.py:133] step: 65950, training_loss: 2.17270e-02
I0215 03:41:27.010854 23126066861888 run_lib.py:133] step: 66000, training_loss: 2.19740e-02
I0215 03:41:27.165235 23126066861888 run_lib.py:146] step: 66000, eval_loss: 2.42657e-02
I0215 03:41:44.660992 23126066861888 run_lib.py:133] step: 66050, training_loss: 2.27636e-02
I0215 03:42:01.875542 23126066861888 run_lib.py:133] step: 66100, training_loss: 2.23681e-02
I0215 03:42:02.033616 23126066861888 run_lib.py:146] step: 66100, eval_loss: 2.38416e-02
I0215 03:42:19.250641 23126066861888 run_lib.py:133] step: 66150, training_loss: 2.14480e-02
I0215 03:42:36.686266 23126066861888 run_lib.py:133] step: 66200, training_loss: 2.22803e-02
I0215 03:42:36.847151 23126066861888 run_lib.py:146] step: 66200, eval_loss: 2.45369e-02
I0215 03:42:54.149795 23126066861888 run_lib.py:133] step: 66250, training_loss: 2.17058e-02
I0215 03:43:11.605622 23126066861888 run_lib.py:133] step: 66300, training_loss: 2.17798e-02
I0215 03:43:11.761830 23126066861888 run_lib.py:146] step: 66300, eval_loss: 2.41166e-02
I0215 03:43:29.020300 23126066861888 run_lib.py:133] step: 66350, training_loss: 2.19095e-02
I0215 03:43:46.251861 23126066861888 run_lib.py:133] step: 66400, training_loss: 2.21856e-02
I0215 03:43:46.407111 23126066861888 run_lib.py:146] step: 66400, eval_loss: 2.40088e-02
I0215 03:44:03.862792 23126066861888 run_lib.py:133] step: 66450, training_loss: 2.17060e-02
I0215 03:44:21.120614 23126066861888 run_lib.py:133] step: 66500, training_loss: 2.22458e-02
I0215 03:44:21.284655 23126066861888 run_lib.py:146] step: 66500, eval_loss: 2.44139e-02
I0215 03:44:38.608456 23126066861888 run_lib.py:133] step: 66550, training_loss: 2.17556e-02
I0215 03:44:56.119391 23126066861888 run_lib.py:133] step: 66600, training_loss: 2.23233e-02
I0215 03:44:56.271201 23126066861888 run_lib.py:146] step: 66600, eval_loss: 2.63050e-02
I0215 03:45:13.565314 23126066861888 run_lib.py:133] step: 66650, training_loss: 2.25531e-02
I0215 03:45:30.842192 23126066861888 run_lib.py:133] step: 66700, training_loss: 2.17560e-02
I0215 03:45:31.177937 23126066861888 run_lib.py:146] step: 66700, eval_loss: 2.48814e-02
I0215 03:45:48.509101 23126066861888 run_lib.py:133] step: 66750, training_loss: 2.21167e-02
I0215 03:46:05.816680 23126066861888 run_lib.py:133] step: 66800, training_loss: 2.16620e-02
I0215 03:46:05.988077 23126066861888 run_lib.py:146] step: 66800, eval_loss: 2.39781e-02
I0215 03:46:23.322370 23126066861888 run_lib.py:133] step: 66850, training_loss: 2.18157e-02
I0215 03:46:40.610946 23126066861888 run_lib.py:133] step: 66900, training_loss: 2.22364e-02
I0215 03:46:40.765209 23126066861888 run_lib.py:146] step: 66900, eval_loss: 2.41736e-02
I0215 03:46:58.276770 23126066861888 run_lib.py:133] step: 66950, training_loss: 2.19111e-02
I0215 03:47:15.619799 23126066861888 run_lib.py:133] step: 67000, training_loss: 2.17602e-02
I0215 03:47:15.770936 23126066861888 run_lib.py:146] step: 67000, eval_loss: 2.57620e-02
I0215 03:47:33.033663 23126066861888 run_lib.py:133] step: 67050, training_loss: 2.23552e-02
I0215 03:47:50.355833 23126066861888 run_lib.py:133] step: 67100, training_loss: 2.19283e-02
I0215 03:47:50.510112 23126066861888 run_lib.py:146] step: 67100, eval_loss: 2.49569e-02
I0215 03:48:07.989618 23126066861888 run_lib.py:133] step: 67150, training_loss: 2.22097e-02
I0215 03:48:25.252204 23126066861888 run_lib.py:133] step: 67200, training_loss: 2.31079e-02
I0215 03:48:25.408235 23126066861888 run_lib.py:146] step: 67200, eval_loss: 2.39312e-02
I0215 03:48:42.629088 23126066861888 run_lib.py:133] step: 67250, training_loss: 2.31835e-02
I0215 03:49:00.039451 23126066861888 run_lib.py:133] step: 67300, training_loss: 2.24007e-02
I0215 03:49:00.195213 23126066861888 run_lib.py:146] step: 67300, eval_loss: 2.41060e-02
I0215 03:49:17.528473 23126066861888 run_lib.py:133] step: 67350, training_loss: 2.26363e-02
I0215 03:49:34.957548 23126066861888 run_lib.py:133] step: 67400, training_loss: 2.20406e-02
I0215 03:49:35.113669 23126066861888 run_lib.py:146] step: 67400, eval_loss: 2.37485e-02
I0215 03:49:52.395184 23126066861888 run_lib.py:133] step: 67450, training_loss: 2.25321e-02
I0215 03:50:09.638828 23126066861888 run_lib.py:133] step: 67500, training_loss: 2.18654e-02
I0215 03:50:09.789058 23126066861888 run_lib.py:146] step: 67500, eval_loss: 2.48241e-02
I0215 03:50:27.213304 23126066861888 run_lib.py:133] step: 67550, training_loss: 2.23021e-02
I0215 03:50:44.462973 23126066861888 run_lib.py:133] step: 67600, training_loss: 2.25163e-02
I0215 03:50:44.635043 23126066861888 run_lib.py:146] step: 67600, eval_loss: 2.48712e-02
I0215 03:51:01.940132 23126066861888 run_lib.py:133] step: 67650, training_loss: 2.21146e-02
I0215 03:51:19.405475 23126066861888 run_lib.py:133] step: 67700, training_loss: 2.22784e-02
I0215 03:51:19.560945 23126066861888 run_lib.py:146] step: 67700, eval_loss: 2.49783e-02
I0215 03:51:36.816145 23126066861888 run_lib.py:133] step: 67750, training_loss: 2.21903e-02
I0215 03:51:54.057906 23126066861888 run_lib.py:133] step: 67800, training_loss: 2.17434e-02
I0215 03:51:54.211986 23126066861888 run_lib.py:146] step: 67800, eval_loss: 2.48446e-02
I0215 03:52:11.531303 23126066861888 run_lib.py:133] step: 67850, training_loss: 2.19689e-02
I0215 03:52:28.782826 23126066861888 run_lib.py:133] step: 67900, training_loss: 2.25661e-02
I0215 03:52:28.939049 23126066861888 run_lib.py:146] step: 67900, eval_loss: 2.50890e-02
I0215 03:52:46.246218 23126066861888 run_lib.py:133] step: 67950, training_loss: 2.25258e-02
I0215 03:53:03.500306 23126066861888 run_lib.py:133] step: 68000, training_loss: 2.27780e-02
I0215 03:53:03.649882 23126066861888 run_lib.py:146] step: 68000, eval_loss: 2.46887e-02
I0215 03:53:21.081305 23126066861888 run_lib.py:133] step: 68050, training_loss: 2.21564e-02
I0215 03:53:38.402609 23126066861888 run_lib.py:133] step: 68100, training_loss: 2.26216e-02
I0215 03:53:38.556006 23126066861888 run_lib.py:146] step: 68100, eval_loss: 2.44131e-02
I0215 03:53:55.887119 23126066861888 run_lib.py:133] step: 68150, training_loss: 2.17175e-02
I0215 03:54:13.201869 23126066861888 run_lib.py:133] step: 68200, training_loss: 2.19691e-02
I0215 03:54:13.366957 23126066861888 run_lib.py:146] step: 68200, eval_loss: 2.36252e-02
I0215 03:54:30.836142 23126066861888 run_lib.py:133] step: 68250, training_loss: 2.34227e-02
I0215 03:54:48.069906 23126066861888 run_lib.py:133] step: 68300, training_loss: 2.19867e-02
I0215 03:54:48.236006 23126066861888 run_lib.py:146] step: 68300, eval_loss: 2.57360e-02
I0215 03:55:05.496121 23126066861888 run_lib.py:133] step: 68350, training_loss: 2.17992e-02
I0215 03:55:22.874110 23126066861888 run_lib.py:133] step: 68400, training_loss: 2.15374e-02
I0215 03:55:23.034632 23126066861888 run_lib.py:146] step: 68400, eval_loss: 2.49108e-02
I0215 03:55:40.357588 23126066861888 run_lib.py:133] step: 68450, training_loss: 2.20500e-02
I0215 03:55:57.837625 23126066861888 run_lib.py:133] step: 68500, training_loss: 2.20634e-02
I0215 03:55:57.988187 23126066861888 run_lib.py:146] step: 68500, eval_loss: 2.42330e-02
I0215 03:56:15.283020 23126066861888 run_lib.py:133] step: 68550, training_loss: 2.21320e-02
I0215 03:56:32.588889 23126066861888 run_lib.py:133] step: 68600, training_loss: 2.18930e-02
I0215 03:56:32.742974 23126066861888 run_lib.py:146] step: 68600, eval_loss: 2.37601e-02
I0215 03:56:50.182030 23126066861888 run_lib.py:133] step: 68650, training_loss: 2.16581e-02
I0215 03:57:07.475380 23126066861888 run_lib.py:133] step: 68700, training_loss: 2.31319e-02
I0215 03:57:07.646975 23126066861888 run_lib.py:146] step: 68700, eval_loss: 2.42826e-02
I0215 03:57:24.971243 23126066861888 run_lib.py:133] step: 68750, training_loss: 2.15764e-02
I0215 03:57:42.472450 23126066861888 run_lib.py:133] step: 68800, training_loss: 2.14021e-02
I0215 03:57:42.629089 23126066861888 run_lib.py:146] step: 68800, eval_loss: 2.44270e-02
I0215 03:57:59.946748 23126066861888 run_lib.py:133] step: 68850, training_loss: 2.22677e-02
I0215 03:58:17.188746 23126066861888 run_lib.py:133] step: 68900, training_loss: 2.26182e-02
I0215 03:58:17.367969 23126066861888 run_lib.py:146] step: 68900, eval_loss: 2.47317e-02
I0215 03:58:34.676277 23126066861888 run_lib.py:133] step: 68950, training_loss: 2.25114e-02
I0215 03:58:51.956345 23126066861888 run_lib.py:133] step: 69000, training_loss: 2.30500e-02
I0215 03:58:52.110152 23126066861888 run_lib.py:146] step: 69000, eval_loss: 2.49075e-02
I0215 03:59:09.421293 23126066861888 run_lib.py:133] step: 69050, training_loss: 2.25073e-02
I0215 03:59:26.728368 23126066861888 run_lib.py:133] step: 69100, training_loss: 2.17677e-02
I0215 03:59:26.887311 23126066861888 run_lib.py:146] step: 69100, eval_loss: 2.49891e-02
I0215 03:59:44.303393 23126066861888 run_lib.py:133] step: 69150, training_loss: 2.12563e-02
I0215 04:00:01.599742 23126066861888 run_lib.py:133] step: 69200, training_loss: 2.16086e-02
I0215 04:00:01.755126 23126066861888 run_lib.py:146] step: 69200, eval_loss: 2.48449e-02
I0215 04:00:19.046741 23126066861888 run_lib.py:133] step: 69250, training_loss: 2.24905e-02
I0215 04:00:36.409415 23126066861888 run_lib.py:133] step: 69300, training_loss: 2.23196e-02
I0215 04:00:36.563203 23126066861888 run_lib.py:146] step: 69300, eval_loss: 2.51973e-02
I0215 04:00:54.046098 23126066861888 run_lib.py:133] step: 69350, training_loss: 2.18442e-02
I0215 04:01:11.346854 23126066861888 run_lib.py:133] step: 69400, training_loss: 2.21005e-02
I0215 04:01:11.497673 23126066861888 run_lib.py:146] step: 69400, eval_loss: 2.42807e-02
I0215 04:01:28.736101 23126066861888 run_lib.py:133] step: 69450, training_loss: 2.24620e-02
I0215 04:01:46.198104 23126066861888 run_lib.py:133] step: 69500, training_loss: 2.22270e-02
I0215 04:01:46.351423 23126066861888 run_lib.py:146] step: 69500, eval_loss: 2.42689e-02
I0215 04:02:03.637660 23126066861888 run_lib.py:133] step: 69550, training_loss: 2.15974e-02
I0215 04:02:21.146121 23126066861888 run_lib.py:133] step: 69600, training_loss: 2.20765e-02
I0215 04:02:21.302931 23126066861888 run_lib.py:146] step: 69600, eval_loss: 2.38712e-02
I0215 04:02:38.566028 23126066861888 run_lib.py:133] step: 69650, training_loss: 2.21011e-02
I0215 04:02:55.831413 23126066861888 run_lib.py:133] step: 69700, training_loss: 2.16699e-02
I0215 04:02:55.984993 23126066861888 run_lib.py:146] step: 69700, eval_loss: 2.42550e-02
I0215 04:03:13.446915 23126066861888 run_lib.py:133] step: 69750, training_loss: 2.18167e-02
I0215 04:03:30.669747 23126066861888 run_lib.py:133] step: 69800, training_loss: 2.25314e-02
I0215 04:03:30.830029 23126066861888 run_lib.py:146] step: 69800, eval_loss: 2.35413e-02
I0215 04:03:48.107351 23126066861888 run_lib.py:133] step: 69850, training_loss: 2.18226e-02
I0215 04:04:05.633205 23126066861888 run_lib.py:133] step: 69900, training_loss: 2.18037e-02
I0215 04:04:05.784208 23126066861888 run_lib.py:146] step: 69900, eval_loss: 2.42408e-02
I0215 04:04:23.063569 23126066861888 run_lib.py:133] step: 69950, training_loss: 2.19781e-02
I0215 04:04:40.340395 23126066861888 run_lib.py:133] step: 70000, training_loss: 2.15462e-02
I0215 04:04:41.011861 23126066861888 run_lib.py:146] step: 70000, eval_loss: 2.42880e-02
I0215 04:05:01.037688 23126066861888 run_lib.py:133] step: 70050, training_loss: 2.20347e-02
I0215 04:05:18.508274 23126066861888 run_lib.py:133] step: 70100, training_loss: 2.28451e-02
I0215 04:05:18.674181 23126066861888 run_lib.py:146] step: 70100, eval_loss: 2.40411e-02
I0215 04:05:35.996705 23126066861888 run_lib.py:133] step: 70150, training_loss: 2.14341e-02
I0215 04:05:53.341157 23126066861888 run_lib.py:133] step: 70200, training_loss: 2.19355e-02
I0215 04:05:53.498233 23126066861888 run_lib.py:146] step: 70200, eval_loss: 2.55583e-02
I0215 04:06:10.800049 23126066861888 run_lib.py:133] step: 70250, training_loss: 2.21705e-02
I0215 04:06:28.234986 23126066861888 run_lib.py:133] step: 70300, training_loss: 2.26533e-02
I0215 04:06:28.388007 23126066861888 run_lib.py:146] step: 70300, eval_loss: 2.42452e-02
I0215 04:06:45.660281 23126066861888 run_lib.py:133] step: 70350, training_loss: 2.21540e-02
I0215 04:07:02.982487 23126066861888 run_lib.py:133] step: 70400, training_loss: 2.25223e-02
I0215 04:07:03.149912 23126066861888 run_lib.py:146] step: 70400, eval_loss: 2.46660e-02
I0215 04:07:20.451030 23126066861888 run_lib.py:133] step: 70450, training_loss: 2.14900e-02
I0215 04:07:37.935262 23126066861888 run_lib.py:133] step: 70500, training_loss: 2.15372e-02
I0215 04:07:38.086934 23126066861888 run_lib.py:146] step: 70500, eval_loss: 2.30934e-02
I0215 04:07:55.340867 23126066861888 run_lib.py:133] step: 70550, training_loss: 2.11363e-02
I0215 04:08:12.679727 23126066861888 run_lib.py:133] step: 70600, training_loss: 2.25545e-02
I0215 04:08:12.835958 23126066861888 run_lib.py:146] step: 70600, eval_loss: 2.44177e-02
I0215 04:08:30.117352 23126066861888 run_lib.py:133] step: 70650, training_loss: 2.20436e-02
I0215 04:08:47.450360 23126066861888 run_lib.py:133] step: 70700, training_loss: 2.23623e-02
I0215 04:08:47.603899 23126066861888 run_lib.py:146] step: 70700, eval_loss: 2.40034e-02
I0215 04:09:05.062153 23126066861888 run_lib.py:133] step: 70750, training_loss: 2.16183e-02
I0215 04:09:22.335919 23126066861888 run_lib.py:133] step: 70800, training_loss: 2.25606e-02
I0215 04:09:22.491650 23126066861888 run_lib.py:146] step: 70800, eval_loss: 2.38729e-02
I0215 04:09:39.906320 23126066861888 run_lib.py:133] step: 70850, training_loss: 2.15069e-02
I0215 04:09:57.247220 23126066861888 run_lib.py:133] step: 70900, training_loss: 2.20608e-02
I0215 04:09:57.398175 23126066861888 run_lib.py:146] step: 70900, eval_loss: 2.45280e-02
I0215 04:10:14.728401 23126066861888 run_lib.py:133] step: 70950, training_loss: 2.16091e-02
I0215 04:10:32.162775 23126066861888 run_lib.py:133] step: 71000, training_loss: 2.22783e-02
I0215 04:10:32.314964 23126066861888 run_lib.py:146] step: 71000, eval_loss: 2.49814e-02
I0215 04:10:49.564800 23126066861888 run_lib.py:133] step: 71050, training_loss: 2.18826e-02
I0215 04:11:06.850170 23126066861888 run_lib.py:133] step: 71100, training_loss: 2.18918e-02
I0215 04:11:07.004089 23126066861888 run_lib.py:146] step: 71100, eval_loss: 2.37898e-02
I0215 04:11:24.432398 23126066861888 run_lib.py:133] step: 71150, training_loss: 2.18195e-02
I0215 04:11:41.742499 23126066861888 run_lib.py:133] step: 71200, training_loss: 2.16616e-02
I0215 04:11:41.897277 23126066861888 run_lib.py:146] step: 71200, eval_loss: 2.40587e-02
I0215 04:11:59.345044 23126066861888 run_lib.py:133] step: 71250, training_loss: 2.19643e-02
I0215 04:12:16.591639 23126066861888 run_lib.py:133] step: 71300, training_loss: 2.25856e-02
I0215 04:12:16.744746 23126066861888 run_lib.py:146] step: 71300, eval_loss: 2.44909e-02
I0215 04:12:33.979125 23126066861888 run_lib.py:133] step: 71350, training_loss: 2.26286e-02
I0215 04:12:51.423038 23126066861888 run_lib.py:133] step: 71400, training_loss: 2.19108e-02
I0215 04:12:51.576762 23126066861888 run_lib.py:146] step: 71400, eval_loss: 2.46362e-02
I0215 04:13:08.837215 23126066861888 run_lib.py:133] step: 71450, training_loss: 2.19762e-02
I0215 04:13:26.099639 23126066861888 run_lib.py:133] step: 71500, training_loss: 2.27617e-02
I0215 04:13:26.270152 23126066861888 run_lib.py:146] step: 71500, eval_loss: 2.51606e-02
I0215 04:13:43.567790 23126066861888 run_lib.py:133] step: 71550, training_loss: 2.15025e-02
I0215 04:14:00.881867 23126066861888 run_lib.py:133] step: 71600, training_loss: 2.20190e-02
I0215 04:14:01.038161 23126066861888 run_lib.py:146] step: 71600, eval_loss: 2.56622e-02
I0215 04:14:18.474189 23126066861888 run_lib.py:133] step: 71650, training_loss: 2.16635e-02
I0215 04:14:35.766084 23126066861888 run_lib.py:133] step: 71700, training_loss: 2.24006e-02
I0215 04:14:35.919019 23126066861888 run_lib.py:146] step: 71700, eval_loss: 2.41736e-02
I0215 04:14:53.184532 23126066861888 run_lib.py:133] step: 71750, training_loss: 2.21681e-02
I0215 04:15:10.520843 23126066861888 run_lib.py:133] step: 71800, training_loss: 2.18285e-02
I0215 04:15:10.674652 23126066861888 run_lib.py:146] step: 71800, eval_loss: 2.45622e-02
I0215 04:15:28.159439 23126066861888 run_lib.py:133] step: 71850, training_loss: 2.21957e-02
I0215 04:15:45.426403 23126066861888 run_lib.py:133] step: 71900, training_loss: 2.27531e-02
I0215 04:15:45.586876 23126066861888 run_lib.py:146] step: 71900, eval_loss: 2.48602e-02
I0215 04:16:03.011553 23126066861888 run_lib.py:133] step: 71950, training_loss: 2.14118e-02
I0215 04:16:20.256950 23126066861888 run_lib.py:133] step: 72000, training_loss: 2.17636e-02
I0215 04:16:20.409788 23126066861888 run_lib.py:146] step: 72000, eval_loss: 2.51145e-02
I0215 04:16:37.677967 23126066861888 run_lib.py:133] step: 72050, training_loss: 2.22963e-02
I0215 04:16:55.154182 23126066861888 run_lib.py:133] step: 72100, training_loss: 2.15416e-02
I0215 04:16:55.306948 23126066861888 run_lib.py:146] step: 72100, eval_loss: 2.49171e-02
I0215 04:17:12.537997 23126066861888 run_lib.py:133] step: 72150, training_loss: 2.19224e-02
I0215 04:17:29.758764 23126066861888 run_lib.py:133] step: 72200, training_loss: 2.17285e-02
I0215 04:17:29.912921 23126066861888 run_lib.py:146] step: 72200, eval_loss: 2.48696e-02
I0215 04:17:47.365483 23126066861888 run_lib.py:133] step: 72250, training_loss: 2.17074e-02
I0215 04:18:04.650665 23126066861888 run_lib.py:133] step: 72300, training_loss: 2.17333e-02
I0215 04:18:04.805168 23126066861888 run_lib.py:146] step: 72300, eval_loss: 2.43045e-02
I0215 04:18:22.255098 23126066861888 run_lib.py:133] step: 72350, training_loss: 2.21528e-02
I0215 04:18:39.535823 23126066861888 run_lib.py:133] step: 72400, training_loss: 2.24614e-02
I0215 04:18:39.687961 23126066861888 run_lib.py:146] step: 72400, eval_loss: 2.52228e-02
I0215 04:18:56.913527 23126066861888 run_lib.py:133] step: 72450, training_loss: 2.17915e-02
I0215 04:19:14.382979 23126066861888 run_lib.py:133] step: 72500, training_loss: 2.14964e-02
I0215 04:19:14.547209 23126066861888 run_lib.py:146] step: 72500, eval_loss: 2.59813e-02
I0215 04:19:31.771502 23126066861888 run_lib.py:133] step: 72550, training_loss: 2.14900e-02
I0215 04:19:49.013852 23126066861888 run_lib.py:133] step: 72600, training_loss: 2.11879e-02
I0215 04:19:49.178927 23126066861888 run_lib.py:146] step: 72600, eval_loss: 2.44539e-02
I0215 04:20:06.476154 23126066861888 run_lib.py:133] step: 72650, training_loss: 2.21387e-02
I0215 04:20:23.751648 23126066861888 run_lib.py:133] step: 72700, training_loss: 2.18142e-02
I0215 04:20:23.913920 23126066861888 run_lib.py:146] step: 72700, eval_loss: 2.49622e-02
I0215 04:20:41.357740 23126066861888 run_lib.py:133] step: 72750, training_loss: 2.26952e-02
I0215 04:20:58.685248 23126066861888 run_lib.py:133] step: 72800, training_loss: 2.19346e-02
I0215 04:20:58.835031 23126066861888 run_lib.py:146] step: 72800, eval_loss: 2.51970e-02
I0215 04:21:16.088179 23126066861888 run_lib.py:133] step: 72850, training_loss: 2.25972e-02
I0215 04:21:33.377882 23126066861888 run_lib.py:133] step: 72900, training_loss: 2.24629e-02
I0215 04:21:33.541175 23126066861888 run_lib.py:146] step: 72900, eval_loss: 2.54818e-02
I0215 04:21:51.040816 23126066861888 run_lib.py:133] step: 72950, training_loss: 2.11559e-02
I0215 04:22:08.283832 23126066861888 run_lib.py:133] step: 73000, training_loss: 2.22871e-02
I0215 04:22:08.440240 23126066861888 run_lib.py:146] step: 73000, eval_loss: 2.40751e-02
I0215 04:22:25.870832 23126066861888 run_lib.py:133] step: 73050, training_loss: 2.12407e-02
I0215 04:22:43.108969 23126066861888 run_lib.py:133] step: 73100, training_loss: 2.30726e-02
I0215 04:22:43.261946 23126066861888 run_lib.py:146] step: 73100, eval_loss: 2.46125e-02
I0215 04:23:00.543484 23126066861888 run_lib.py:133] step: 73150, training_loss: 2.14787e-02
I0215 04:23:18.047502 23126066861888 run_lib.py:133] step: 73200, training_loss: 2.16999e-02
I0215 04:23:18.209505 23126066861888 run_lib.py:146] step: 73200, eval_loss: 2.53571e-02
I0215 04:23:35.462375 23126066861888 run_lib.py:133] step: 73250, training_loss: 2.16518e-02
I0215 04:23:52.642022 23126066861888 run_lib.py:133] step: 73300, training_loss: 2.15482e-02
I0215 04:23:52.793004 23126066861888 run_lib.py:146] step: 73300, eval_loss: 2.32598e-02
I0215 04:24:10.212608 23126066861888 run_lib.py:133] step: 73350, training_loss: 2.23161e-02
I0215 04:24:27.510423 23126066861888 run_lib.py:133] step: 73400, training_loss: 2.18668e-02
I0215 04:24:27.662913 23126066861888 run_lib.py:146] step: 73400, eval_loss: 2.51737e-02
I0215 04:24:44.953754 23126066861888 run_lib.py:133] step: 73450, training_loss: 2.21540e-02
I0215 04:25:02.391999 23126066861888 run_lib.py:133] step: 73500, training_loss: 2.28613e-02
I0215 04:25:02.548011 23126066861888 run_lib.py:146] step: 73500, eval_loss: 2.51995e-02
I0215 04:25:19.802179 23126066861888 run_lib.py:133] step: 73550, training_loss: 2.17401e-02
I0215 04:25:37.043728 23126066861888 run_lib.py:133] step: 73600, training_loss: 2.23101e-02
I0215 04:25:37.199917 23126066861888 run_lib.py:146] step: 73600, eval_loss: 2.53479e-02
I0215 04:25:54.548682 23126066861888 run_lib.py:133] step: 73650, training_loss: 2.15349e-02
I0215 04:26:11.801919 23126066861888 run_lib.py:133] step: 73700, training_loss: 2.24936e-02
I0215 04:26:11.953758 23126066861888 run_lib.py:146] step: 73700, eval_loss: 2.33442e-02
I0215 04:26:29.223300 23126066861888 run_lib.py:133] step: 73750, training_loss: 2.14414e-02
I0215 04:26:46.560817 23126066861888 run_lib.py:133] step: 73800, training_loss: 2.16993e-02
I0215 04:26:46.715129 23126066861888 run_lib.py:146] step: 73800, eval_loss: 2.36967e-02
I0215 04:27:04.124140 23126066861888 run_lib.py:133] step: 73850, training_loss: 2.28381e-02
I0215 04:27:21.479164 23126066861888 run_lib.py:133] step: 73900, training_loss: 2.13192e-02
I0215 04:27:21.636926 23126066861888 run_lib.py:146] step: 73900, eval_loss: 2.51521e-02
I0215 04:27:38.900523 23126066861888 run_lib.py:133] step: 73950, training_loss: 2.18885e-02
I0215 04:27:56.145795 23126066861888 run_lib.py:133] step: 74000, training_loss: 2.21311e-02
I0215 04:27:56.301987 23126066861888 run_lib.py:146] step: 74000, eval_loss: 2.49020e-02
I0215 04:28:13.724965 23126066861888 run_lib.py:133] step: 74050, training_loss: 2.17646e-02
I0215 04:28:31.034999 23126066861888 run_lib.py:133] step: 74100, training_loss: 2.17957e-02
I0215 04:28:31.197608 23126066861888 run_lib.py:146] step: 74100, eval_loss: 2.53058e-02
I0215 04:28:48.449771 23126066861888 run_lib.py:133] step: 74150, training_loss: 2.24476e-02
I0215 04:29:05.896574 23126066861888 run_lib.py:133] step: 74200, training_loss: 2.16875e-02
I0215 04:29:06.047956 23126066861888 run_lib.py:146] step: 74200, eval_loss: 2.60196e-02
I0215 04:29:23.315623 23126066861888 run_lib.py:133] step: 74250, training_loss: 2.13265e-02
I0215 04:29:40.736092 23126066861888 run_lib.py:133] step: 74300, training_loss: 2.21757e-02
I0215 04:29:40.892187 23126066861888 run_lib.py:146] step: 74300, eval_loss: 2.52609e-02
I0215 04:29:58.198379 23126066861888 run_lib.py:133] step: 74350, training_loss: 2.19240e-02
I0215 04:30:15.487270 23126066861888 run_lib.py:133] step: 74400, training_loss: 2.14605e-02
I0215 04:30:15.643855 23126066861888 run_lib.py:146] step: 74400, eval_loss: 2.45630e-02
I0215 04:30:33.078963 23126066861888 run_lib.py:133] step: 74450, training_loss: 2.24135e-02
I0215 04:30:50.338228 23126066861888 run_lib.py:133] step: 74500, training_loss: 2.24015e-02
I0215 04:30:50.492024 23126066861888 run_lib.py:146] step: 74500, eval_loss: 2.54721e-02
I0215 04:31:07.731060 23126066861888 run_lib.py:133] step: 74550, training_loss: 2.21929e-02
I0215 04:31:25.176301 23126066861888 run_lib.py:133] step: 74600, training_loss: 2.23730e-02
I0215 04:31:25.338773 23126066861888 run_lib.py:146] step: 74600, eval_loss: 2.42129e-02
I0215 04:31:42.651281 23126066861888 run_lib.py:133] step: 74650, training_loss: 2.10595e-02
I0215 04:31:59.919793 23126066861888 run_lib.py:133] step: 74700, training_loss: 2.17234e-02
I0215 04:32:00.069766 23126066861888 run_lib.py:146] step: 74700, eval_loss: 2.43642e-02
I0215 04:32:17.447134 23126066861888 run_lib.py:133] step: 74750, training_loss: 2.21435e-02
I0215 04:32:34.766756 23126066861888 run_lib.py:133] step: 74800, training_loss: 2.14939e-02
I0215 04:32:34.925972 23126066861888 run_lib.py:146] step: 74800, eval_loss: 2.49246e-02
I0215 04:32:52.183260 23126066861888 run_lib.py:133] step: 74850, training_loss: 2.24512e-02
I0215 04:33:09.467072 23126066861888 run_lib.py:133] step: 74900, training_loss: 2.27408e-02
I0215 04:33:09.640547 23126066861888 run_lib.py:146] step: 74900, eval_loss: 2.44769e-02
I0215 04:33:27.116731 23126066861888 run_lib.py:133] step: 74950, training_loss: 2.16565e-02
I0215 04:33:44.484955 23126066861888 run_lib.py:133] step: 75000, training_loss: 2.21835e-02
I0215 04:33:44.646094 23126066861888 run_lib.py:146] step: 75000, eval_loss: 2.41441e-02
I0215 04:34:01.887074 23126066861888 run_lib.py:133] step: 75050, training_loss: 2.12166e-02
I0215 04:34:19.127494 23126066861888 run_lib.py:133] step: 75100, training_loss: 2.15747e-02
I0215 04:34:19.279982 23126066861888 run_lib.py:146] step: 75100, eval_loss: 2.44446e-02
I0215 04:34:36.671686 23126066861888 run_lib.py:133] step: 75150, training_loss: 2.22599e-02
I0215 04:34:53.967527 23126066861888 run_lib.py:133] step: 75200, training_loss: 2.18931e-02
I0215 04:34:54.119432 23126066861888 run_lib.py:146] step: 75200, eval_loss: 2.49036e-02
I0215 04:35:11.441435 23126066861888 run_lib.py:133] step: 75250, training_loss: 2.18022e-02
I0215 04:35:28.890614 23126066861888 run_lib.py:133] step: 75300, training_loss: 2.17794e-02
I0215 04:35:29.044065 23126066861888 run_lib.py:146] step: 75300, eval_loss: 2.53196e-02
I0215 04:35:46.343198 23126066861888 run_lib.py:133] step: 75350, training_loss: 2.26215e-02
I0215 04:36:03.776646 23126066861888 run_lib.py:133] step: 75400, training_loss: 2.12596e-02
I0215 04:36:03.934309 23126066861888 run_lib.py:146] step: 75400, eval_loss: 2.42857e-02
I0215 04:36:21.192726 23126066861888 run_lib.py:133] step: 75450, training_loss: 2.21829e-02
I0215 04:36:38.507121 23126066861888 run_lib.py:133] step: 75500, training_loss: 2.13360e-02
I0215 04:36:38.661185 23126066861888 run_lib.py:146] step: 75500, eval_loss: 2.42018e-02
I0215 04:36:56.154189 23126066861888 run_lib.py:133] step: 75550, training_loss: 2.23953e-02
I0215 04:37:13.439674 23126066861888 run_lib.py:133] step: 75600, training_loss: 2.20549e-02
I0215 04:37:13.588674 23126066861888 run_lib.py:146] step: 75600, eval_loss: 2.48849e-02
I0215 04:37:30.817095 23126066861888 run_lib.py:133] step: 75650, training_loss: 2.21117e-02
I0215 04:37:48.247859 23126066861888 run_lib.py:133] step: 75700, training_loss: 2.15445e-02
I0215 04:37:48.399884 23126066861888 run_lib.py:146] step: 75700, eval_loss: 2.44740e-02
I0215 04:38:05.695080 23126066861888 run_lib.py:133] step: 75750, training_loss: 2.18885e-02
I0215 04:38:22.969709 23126066861888 run_lib.py:133] step: 75800, training_loss: 2.10910e-02
I0215 04:38:23.124794 23126066861888 run_lib.py:146] step: 75800, eval_loss: 2.46083e-02
I0215 04:38:40.505055 23126066861888 run_lib.py:133] step: 75850, training_loss: 2.19139e-02
I0215 04:38:57.735068 23126066861888 run_lib.py:133] step: 75900, training_loss: 2.17195e-02
I0215 04:38:57.889300 23126066861888 run_lib.py:146] step: 75900, eval_loss: 2.42552e-02
I0215 04:39:15.219397 23126066861888 run_lib.py:133] step: 75950, training_loss: 2.25258e-02
I0215 04:39:32.482211 23126066861888 run_lib.py:133] step: 76000, training_loss: 2.13044e-02
I0215 04:39:32.644485 23126066861888 run_lib.py:146] step: 76000, eval_loss: 2.48594e-02
I0215 04:39:50.079692 23126066861888 run_lib.py:133] step: 76050, training_loss: 2.21639e-02
I0215 04:40:07.477147 23126066861888 run_lib.py:133] step: 76100, training_loss: 2.15104e-02
I0215 04:40:07.626013 23126066861888 run_lib.py:146] step: 76100, eval_loss: 2.44969e-02
I0215 04:40:24.917392 23126066861888 run_lib.py:133] step: 76150, training_loss: 2.29677e-02
I0215 04:40:42.192841 23126066861888 run_lib.py:133] step: 76200, training_loss: 2.20255e-02
I0215 04:40:42.343952 23126066861888 run_lib.py:146] step: 76200, eval_loss: 2.51881e-02
I0215 04:40:59.756279 23126066861888 run_lib.py:133] step: 76250, training_loss: 2.22703e-02
I0215 04:41:16.976230 23126066861888 run_lib.py:133] step: 76300, training_loss: 2.08570e-02
I0215 04:41:17.147935 23126066861888 run_lib.py:146] step: 76300, eval_loss: 2.43028e-02
I0215 04:41:34.489215 23126066861888 run_lib.py:133] step: 76350, training_loss: 2.15715e-02
I0215 04:41:51.956594 23126066861888 run_lib.py:133] step: 76400, training_loss: 2.07183e-02
I0215 04:41:52.110167 23126066861888 run_lib.py:146] step: 76400, eval_loss: 2.52453e-02
I0215 04:42:09.362719 23126066861888 run_lib.py:133] step: 76450, training_loss: 2.20067e-02
I0215 04:42:26.740287 23126066861888 run_lib.py:133] step: 76500, training_loss: 2.20236e-02
I0215 04:42:26.893776 23126066861888 run_lib.py:146] step: 76500, eval_loss: 2.49356e-02
I0215 04:42:44.160247 23126066861888 run_lib.py:133] step: 76550, training_loss: 2.22060e-02
I0215 04:43:01.408584 23126066861888 run_lib.py:133] step: 76600, training_loss: 2.26131e-02
I0215 04:43:01.558693 23126066861888 run_lib.py:146] step: 76600, eval_loss: 2.50672e-02
I0215 04:43:19.024436 23126066861888 run_lib.py:133] step: 76650, training_loss: 2.14084e-02
I0215 04:43:36.275511 23126066861888 run_lib.py:133] step: 76700, training_loss: 2.13523e-02
I0215 04:43:36.433926 23126066861888 run_lib.py:146] step: 76700, eval_loss: 2.48774e-02
I0215 04:43:53.701948 23126066861888 run_lib.py:133] step: 76750, training_loss: 2.21426e-02
I0215 04:44:11.117086 23126066861888 run_lib.py:133] step: 76800, training_loss: 2.15021e-02
I0215 04:44:11.274131 23126066861888 run_lib.py:146] step: 76800, eval_loss: 2.43189e-02
I0215 04:44:28.531794 23126066861888 run_lib.py:133] step: 76850, training_loss: 2.19052e-02
I0215 04:44:45.799113 23126066861888 run_lib.py:133] step: 76900, training_loss: 2.12934e-02
I0215 04:44:45.953209 23126066861888 run_lib.py:146] step: 76900, eval_loss: 2.48714e-02
I0215 04:45:03.320255 23126066861888 run_lib.py:133] step: 76950, training_loss: 2.15340e-02
I0215 04:45:20.612337 23126066861888 run_lib.py:133] step: 77000, training_loss: 2.14584e-02
I0215 04:45:20.764919 23126066861888 run_lib.py:146] step: 77000, eval_loss: 2.45831e-02
I0215 04:45:38.003478 23126066861888 run_lib.py:133] step: 77050, training_loss: 2.23753e-02
I0215 04:45:55.253433 23126066861888 run_lib.py:133] step: 77100, training_loss: 2.25196e-02
I0215 04:45:55.409886 23126066861888 run_lib.py:146] step: 77100, eval_loss: 2.51713e-02
I0215 04:46:12.858691 23126066861888 run_lib.py:133] step: 77150, training_loss: 2.11274e-02
I0215 04:46:30.217130 23126066861888 run_lib.py:133] step: 77200, training_loss: 2.13151e-02
I0215 04:46:30.380007 23126066861888 run_lib.py:146] step: 77200, eval_loss: 2.46697e-02
I0215 04:46:47.678883 23126066861888 run_lib.py:133] step: 77250, training_loss: 2.19191e-02
I0215 04:47:04.924670 23126066861888 run_lib.py:133] step: 77300, training_loss: 2.26673e-02
I0215 04:47:05.081379 23126066861888 run_lib.py:146] step: 77300, eval_loss: 2.52152e-02
I0215 04:47:22.529295 23126066861888 run_lib.py:133] step: 77350, training_loss: 2.21480e-02
I0215 04:47:39.760075 23126066861888 run_lib.py:133] step: 77400, training_loss: 2.15631e-02
I0215 04:47:39.913974 23126066861888 run_lib.py:146] step: 77400, eval_loss: 2.47143e-02
I0215 04:47:57.168701 23126066861888 run_lib.py:133] step: 77450, training_loss: 2.13988e-02
I0215 04:48:14.647949 23126066861888 run_lib.py:133] step: 77500, training_loss: 2.19611e-02
I0215 04:48:14.808196 23126066861888 run_lib.py:146] step: 77500, eval_loss: 2.51153e-02
I0215 04:48:32.100501 23126066861888 run_lib.py:133] step: 77550, training_loss: 2.17788e-02
I0215 04:48:49.515411 23126066861888 run_lib.py:133] step: 77600, training_loss: 2.22527e-02
I0215 04:48:49.666944 23126066861888 run_lib.py:146] step: 77600, eval_loss: 2.38871e-02
I0215 04:49:06.897140 23126066861888 run_lib.py:133] step: 77650, training_loss: 2.15145e-02
I0215 04:49:24.171902 23126066861888 run_lib.py:133] step: 77700, training_loss: 2.15853e-02
I0215 04:49:24.339905 23126066861888 run_lib.py:146] step: 77700, eval_loss: 2.45480e-02
I0215 04:49:41.810626 23126066861888 run_lib.py:133] step: 77750, training_loss: 2.17578e-02
I0215 04:49:59.124273 23126066861888 run_lib.py:133] step: 77800, training_loss: 2.23595e-02
I0215 04:49:59.280863 23126066861888 run_lib.py:146] step: 77800, eval_loss: 2.51768e-02
I0215 04:50:16.534264 23126066861888 run_lib.py:133] step: 77850, training_loss: 2.12898e-02
I0215 04:50:33.959977 23126066861888 run_lib.py:133] step: 77900, training_loss: 2.15658e-02
I0215 04:50:34.112983 23126066861888 run_lib.py:146] step: 77900, eval_loss: 2.44254e-02
I0215 04:50:51.380657 23126066861888 run_lib.py:133] step: 77950, training_loss: 2.18276e-02
I0215 04:51:08.733306 23126066861888 run_lib.py:133] step: 78000, training_loss: 2.20995e-02
I0215 04:51:08.896838 23126066861888 run_lib.py:146] step: 78000, eval_loss: 2.47669e-02
I0215 04:51:26.283210 23126066861888 run_lib.py:133] step: 78050, training_loss: 2.20471e-02
I0215 04:51:43.553651 23126066861888 run_lib.py:133] step: 78100, training_loss: 2.09119e-02
I0215 04:51:43.704975 23126066861888 run_lib.py:146] step: 78100, eval_loss: 2.53160e-02
I0215 04:52:00.992767 23126066861888 run_lib.py:133] step: 78150, training_loss: 2.18979e-02
I0215 04:52:18.252331 23126066861888 run_lib.py:133] step: 78200, training_loss: 2.23089e-02
I0215 04:52:18.409137 23126066861888 run_lib.py:146] step: 78200, eval_loss: 2.41331e-02
I0215 04:52:35.830091 23126066861888 run_lib.py:133] step: 78250, training_loss: 2.10182e-02
I0215 04:52:53.236552 23126066861888 run_lib.py:133] step: 78300, training_loss: 2.11043e-02
I0215 04:52:53.387156 23126066861888 run_lib.py:146] step: 78300, eval_loss: 2.44786e-02
I0215 04:53:10.671189 23126066861888 run_lib.py:133] step: 78350, training_loss: 2.16745e-02
I0215 04:53:27.910426 23126066861888 run_lib.py:133] step: 78400, training_loss: 2.05669e-02
I0215 04:53:28.064147 23126066861888 run_lib.py:146] step: 78400, eval_loss: 2.49641e-02
I0215 04:53:45.500651 23126066861888 run_lib.py:133] step: 78450, training_loss: 2.17005e-02
I0215 04:54:02.739971 23126066861888 run_lib.py:133] step: 78500, training_loss: 2.22978e-02
I0215 04:54:02.891711 23126066861888 run_lib.py:146] step: 78500, eval_loss: 2.47560e-02
I0215 04:54:20.153085 23126066861888 run_lib.py:133] step: 78550, training_loss: 2.22816e-02
I0215 04:54:37.631079 23126066861888 run_lib.py:133] step: 78600, training_loss: 2.16426e-02
I0215 04:54:37.792149 23126066861888 run_lib.py:146] step: 78600, eval_loss: 2.44479e-02
I0215 04:54:55.068802 23126066861888 run_lib.py:133] step: 78650, training_loss: 2.09514e-02
I0215 04:55:12.538995 23126066861888 run_lib.py:133] step: 78700, training_loss: 2.19761e-02
I0215 04:55:12.694869 23126066861888 run_lib.py:146] step: 78700, eval_loss: 2.51783e-02
I0215 04:55:29.938567 23126066861888 run_lib.py:133] step: 78750, training_loss: 2.21718e-02
I0215 04:55:47.174434 23126066861888 run_lib.py:133] step: 78800, training_loss: 2.24205e-02
I0215 04:55:47.327945 23126066861888 run_lib.py:146] step: 78800, eval_loss: 2.42577e-02
I0215 04:56:04.728251 23126066861888 run_lib.py:133] step: 78850, training_loss: 2.22978e-02
I0215 04:56:22.081525 23126066861888 run_lib.py:133] step: 78900, training_loss: 2.15820e-02
I0215 04:56:22.240262 23126066861888 run_lib.py:146] step: 78900, eval_loss: 2.49576e-02
I0215 04:56:39.520191 23126066861888 run_lib.py:133] step: 78950, training_loss: 2.23002e-02
I0215 04:56:56.946034 23126066861888 run_lib.py:133] step: 79000, training_loss: 2.20223e-02
I0215 04:56:57.096898 23126066861888 run_lib.py:146] step: 79000, eval_loss: 2.44351e-02
I0215 04:57:14.331971 23126066861888 run_lib.py:133] step: 79050, training_loss: 2.16455e-02
I0215 04:57:31.599771 23126066861888 run_lib.py:133] step: 79100, training_loss: 2.17336e-02
I0215 04:57:31.752972 23126066861888 run_lib.py:146] step: 79100, eval_loss: 2.42189e-02
I0215 04:57:49.063959 23126066861888 run_lib.py:133] step: 79150, training_loss: 2.15749e-02
I0215 04:58:06.403540 23126066861888 run_lib.py:133] step: 79200, training_loss: 2.21599e-02
I0215 04:58:06.560202 23126066861888 run_lib.py:146] step: 79200, eval_loss: 2.39241e-02
I0215 04:58:23.811700 23126066861888 run_lib.py:133] step: 79250, training_loss: 2.09529e-02
I0215 04:58:41.087022 23126066861888 run_lib.py:133] step: 79300, training_loss: 2.22992e-02
I0215 04:58:41.241079 23126066861888 run_lib.py:146] step: 79300, eval_loss: 2.42198e-02
I0215 04:58:58.706777 23126066861888 run_lib.py:133] step: 79350, training_loss: 2.12983e-02
I0215 04:59:16.011891 23126066861888 run_lib.py:133] step: 79400, training_loss: 2.14733e-02
I0215 04:59:16.162920 23126066861888 run_lib.py:146] step: 79400, eval_loss: 2.54304e-02
I0215 04:59:33.461856 23126066861888 run_lib.py:133] step: 79450, training_loss: 2.20968e-02
I0215 04:59:50.732025 23126066861888 run_lib.py:133] step: 79500, training_loss: 2.16158e-02
I0215 04:59:50.894126 23126066861888 run_lib.py:146] step: 79500, eval_loss: 2.46163e-02
I0215 05:00:08.358497 23126066861888 run_lib.py:133] step: 79550, training_loss: 2.14546e-02
I0215 05:00:25.643502 23126066861888 run_lib.py:133] step: 79600, training_loss: 2.18999e-02
I0215 05:00:25.823203 23126066861888 run_lib.py:146] step: 79600, eval_loss: 2.46249e-02
I0215 05:00:43.047766 23126066861888 run_lib.py:133] step: 79650, training_loss: 2.16619e-02
I0215 05:01:00.470547 23126066861888 run_lib.py:133] step: 79700, training_loss: 2.18505e-02
I0215 05:01:00.629214 23126066861888 run_lib.py:146] step: 79700, eval_loss: 2.42562e-02
I0215 05:01:17.925431 23126066861888 run_lib.py:133] step: 79750, training_loss: 2.18336e-02
I0215 05:01:35.394980 23126066861888 run_lib.py:133] step: 79800, training_loss: 2.17644e-02
I0215 05:01:35.549770 23126066861888 run_lib.py:146] step: 79800, eval_loss: 2.50671e-02
I0215 05:01:52.835176 23126066861888 run_lib.py:133] step: 79850, training_loss: 2.25530e-02
I0215 05:02:10.062175 23126066861888 run_lib.py:133] step: 79900, training_loss: 2.16324e-02
I0215 05:02:10.213143 23126066861888 run_lib.py:146] step: 79900, eval_loss: 2.42365e-02
I0215 05:02:27.663490 23126066861888 run_lib.py:133] step: 79950, training_loss: 2.22054e-02
I0215 05:02:44.942320 23126066861888 run_lib.py:133] step: 80000, training_loss: 2.16560e-02
I0215 05:02:45.611936 23126066861888 run_lib.py:146] step: 80000, eval_loss: 2.46961e-02
I0215 05:03:05.601073 23126066861888 run_lib.py:133] step: 80050, training_loss: 2.13970e-02
I0215 05:03:23.002173 23126066861888 run_lib.py:133] step: 80100, training_loss: 2.21120e-02
I0215 05:03:23.167109 23126066861888 run_lib.py:146] step: 80100, eval_loss: 2.47919e-02
I0215 05:03:40.396037 23126066861888 run_lib.py:133] step: 80150, training_loss: 2.11961e-02
I0215 05:03:57.657088 23126066861888 run_lib.py:133] step: 80200, training_loss: 2.15986e-02
I0215 05:03:57.814166 23126066861888 run_lib.py:146] step: 80200, eval_loss: 2.45858e-02
I0215 05:04:15.227331 23126066861888 run_lib.py:133] step: 80250, training_loss: 2.16094e-02
I0215 05:04:32.464298 23126066861888 run_lib.py:133] step: 80300, training_loss: 2.17530e-02
I0215 05:04:32.628950 23126066861888 run_lib.py:146] step: 80300, eval_loss: 2.43308e-02
I0215 05:04:50.108728 23126066861888 run_lib.py:133] step: 80350, training_loss: 2.20207e-02
I0215 05:05:07.384786 23126066861888 run_lib.py:133] step: 80400, training_loss: 2.23006e-02
I0215 05:05:07.536715 23126066861888 run_lib.py:146] step: 80400, eval_loss: 2.46780e-02
I0215 05:05:24.839607 23126066861888 run_lib.py:133] step: 80450, training_loss: 2.09995e-02
I0215 05:05:42.257717 23126066861888 run_lib.py:133] step: 80500, training_loss: 2.17635e-02
I0215 05:05:42.415302 23126066861888 run_lib.py:146] step: 80500, eval_loss: 2.44550e-02
I0215 05:05:59.655593 23126066861888 run_lib.py:133] step: 80550, training_loss: 2.17507e-02
I0215 05:06:16.937861 23126066861888 run_lib.py:133] step: 80600, training_loss: 2.12102e-02
I0215 05:06:17.102043 23126066861888 run_lib.py:146] step: 80600, eval_loss: 2.45140e-02
I0215 05:06:34.593314 23126066861888 run_lib.py:133] step: 80650, training_loss: 2.13439e-02
I0215 05:06:51.884365 23126066861888 run_lib.py:133] step: 80700, training_loss: 2.14558e-02
I0215 05:06:52.048015 23126066861888 run_lib.py:146] step: 80700, eval_loss: 2.50545e-02
I0215 05:07:09.463488 23126066861888 run_lib.py:133] step: 80750, training_loss: 2.16763e-02
I0215 05:07:26.663536 23126066861888 run_lib.py:133] step: 80800, training_loss: 2.28323e-02
I0215 05:07:26.816984 23126066861888 run_lib.py:146] step: 80800, eval_loss: 2.49230e-02
I0215 05:07:44.154141 23126066861888 run_lib.py:133] step: 80850, training_loss: 2.23724e-02
I0215 05:08:01.477424 23126066861888 run_lib.py:133] step: 80900, training_loss: 2.12204e-02
I0215 05:08:01.788306 23126066861888 run_lib.py:146] step: 80900, eval_loss: 2.47991e-02
I0215 05:08:19.077751 23126066861888 run_lib.py:133] step: 80950, training_loss: 2.15104e-02
I0215 05:08:36.324832 23126066861888 run_lib.py:133] step: 81000, training_loss: 2.16113e-02
I0215 05:08:36.483933 23126066861888 run_lib.py:146] step: 81000, eval_loss: 2.44047e-02
I0215 05:08:53.729570 23126066861888 run_lib.py:133] step: 81050, training_loss: 2.13651e-02
I0215 05:09:11.002328 23126066861888 run_lib.py:133] step: 81100, training_loss: 2.09610e-02
I0215 05:09:11.158422 23126066861888 run_lib.py:146] step: 81100, eval_loss: 2.50672e-02
I0215 05:09:28.573490 23126066861888 run_lib.py:133] step: 81150, training_loss: 2.14372e-02
I0215 05:09:45.929222 23126066861888 run_lib.py:133] step: 81200, training_loss: 2.20218e-02
I0215 05:09:46.098034 23126066861888 run_lib.py:146] step: 81200, eval_loss: 2.37905e-02
I0215 05:10:03.406334 23126066861888 run_lib.py:133] step: 81250, training_loss: 2.17925e-02
I0215 05:10:20.674167 23126066861888 run_lib.py:133] step: 81300, training_loss: 2.26956e-02
I0215 05:10:20.827910 23126066861888 run_lib.py:146] step: 81300, eval_loss: 2.49485e-02
I0215 05:10:38.273863 23126066861888 run_lib.py:133] step: 81350, training_loss: 2.16331e-02
I0215 05:10:55.525451 23126066861888 run_lib.py:133] step: 81400, training_loss: 2.15774e-02
I0215 05:10:55.673084 23126066861888 run_lib.py:146] step: 81400, eval_loss: 2.50848e-02
I0215 05:11:12.962544 23126066861888 run_lib.py:133] step: 81450, training_loss: 2.19579e-02
I0215 05:11:30.459939 23126066861888 run_lib.py:133] step: 81500, training_loss: 2.22537e-02
I0215 05:11:30.616223 23126066861888 run_lib.py:146] step: 81500, eval_loss: 2.53707e-02
I0215 05:11:47.924282 23126066861888 run_lib.py:133] step: 81550, training_loss: 2.19156e-02
I0215 05:12:05.400114 23126066861888 run_lib.py:133] step: 81600, training_loss: 2.22864e-02
I0215 05:12:05.557153 23126066861888 run_lib.py:146] step: 81600, eval_loss: 2.42076e-02
I0215 05:12:22.803520 23126066861888 run_lib.py:133] step: 81650, training_loss: 2.18818e-02
I0215 05:12:40.047295 23126066861888 run_lib.py:133] step: 81700, training_loss: 2.28137e-02
I0215 05:12:40.203074 23126066861888 run_lib.py:146] step: 81700, eval_loss: 2.43674e-02
I0215 05:12:57.619200 23126066861888 run_lib.py:133] step: 81750, training_loss: 2.10741e-02
I0215 05:13:14.930967 23126066861888 run_lib.py:133] step: 81800, training_loss: 2.23979e-02
I0215 05:13:15.093391 23126066861888 run_lib.py:146] step: 81800, eval_loss: 2.53067e-02
I0215 05:13:32.357969 23126066861888 run_lib.py:133] step: 81850, training_loss: 2.18199e-02
I0215 05:13:49.779133 23126066861888 run_lib.py:133] step: 81900, training_loss: 2.14530e-02
I0215 05:13:49.930781 23126066861888 run_lib.py:146] step: 81900, eval_loss: 2.47776e-02
I0215 05:14:07.192168 23126066861888 run_lib.py:133] step: 81950, training_loss: 2.09289e-02
I0215 05:14:24.494368 23126066861888 run_lib.py:133] step: 82000, training_loss: 2.13535e-02
I0215 05:14:24.648225 23126066861888 run_lib.py:146] step: 82000, eval_loss: 2.46626e-02
I0215 05:14:42.031993 23126066861888 run_lib.py:133] step: 82050, training_loss: 2.13048e-02
I0215 05:14:59.325313 23126066861888 run_lib.py:133] step: 82100, training_loss: 2.15274e-02
I0215 05:14:59.482076 23126066861888 run_lib.py:146] step: 82100, eval_loss: 2.51009e-02
I0215 05:15:16.754872 23126066861888 run_lib.py:133] step: 82150, training_loss: 2.16887e-02
I0215 05:15:34.011030 23126066861888 run_lib.py:133] step: 82200, training_loss: 2.09376e-02
I0215 05:15:34.163933 23126066861888 run_lib.py:146] step: 82200, eval_loss: 2.50302e-02
I0215 05:15:51.603214 23126066861888 run_lib.py:133] step: 82250, training_loss: 2.17059e-02
I0215 05:16:08.959858 23126066861888 run_lib.py:133] step: 82300, training_loss: 2.12954e-02
I0215 05:16:09.126754 23126066861888 run_lib.py:146] step: 82300, eval_loss: 2.50689e-02
I0215 05:16:26.469548 23126066861888 run_lib.py:133] step: 82350, training_loss: 2.13148e-02
I0215 05:16:43.768844 23126066861888 run_lib.py:133] step: 82400, training_loss: 2.21174e-02
I0215 05:16:43.919058 23126066861888 run_lib.py:146] step: 82400, eval_loss: 2.41785e-02
I0215 05:17:01.359079 23126066861888 run_lib.py:133] step: 82450, training_loss: 2.14198e-02
I0215 05:17:18.658157 23126066861888 run_lib.py:133] step: 82500, training_loss: 2.17773e-02
I0215 05:17:18.814999 23126066861888 run_lib.py:146] step: 82500, eval_loss: 2.55076e-02
I0215 05:17:36.049002 23126066861888 run_lib.py:133] step: 82550, training_loss: 2.16901e-02
I0215 05:17:53.461904 23126066861888 run_lib.py:133] step: 82600, training_loss: 2.16456e-02
I0215 05:17:53.633092 23126066861888 run_lib.py:146] step: 82600, eval_loss: 2.51621e-02
I0215 05:18:10.971478 23126066861888 run_lib.py:133] step: 82650, training_loss: 2.04356e-02
I0215 05:18:28.415914 23126066861888 run_lib.py:133] step: 82700, training_loss: 2.15832e-02
I0215 05:18:28.570240 23126066861888 run_lib.py:146] step: 82700, eval_loss: 2.39971e-02
I0215 05:18:45.844195 23126066861888 run_lib.py:133] step: 82750, training_loss: 2.27562e-02
I0215 05:19:03.112075 23126066861888 run_lib.py:133] step: 82800, training_loss: 2.06926e-02
I0215 05:19:03.264047 23126066861888 run_lib.py:146] step: 82800, eval_loss: 2.54499e-02
I0215 05:19:20.684521 23126066861888 run_lib.py:133] step: 82850, training_loss: 2.20232e-02
I0215 05:19:37.930048 23126066861888 run_lib.py:133] step: 82900, training_loss: 2.13505e-02
I0215 05:19:38.086206 23126066861888 run_lib.py:146] step: 82900, eval_loss: 2.35211e-02
I0215 05:19:55.412124 23126066861888 run_lib.py:133] step: 82950, training_loss: 2.14829e-02
I0215 05:20:12.905185 23126066861888 run_lib.py:133] step: 83000, training_loss: 2.19080e-02
I0215 05:20:13.058979 23126066861888 run_lib.py:146] step: 83000, eval_loss: 2.48623e-02
I0215 05:20:30.311729 23126066861888 run_lib.py:133] step: 83050, training_loss: 2.11590e-02
I0215 05:20:47.590018 23126066861888 run_lib.py:133] step: 83100, training_loss: 2.13681e-02
I0215 05:20:47.744230 23126066861888 run_lib.py:146] step: 83100, eval_loss: 2.45348e-02
I0215 05:21:05.058297 23126066861888 run_lib.py:133] step: 83150, training_loss: 2.14658e-02
I0215 05:21:22.414535 23126066861888 run_lib.py:133] step: 83200, training_loss: 2.18257e-02
I0215 05:21:22.569779 23126066861888 run_lib.py:146] step: 83200, eval_loss: 2.54874e-02
I0215 05:21:39.849156 23126066861888 run_lib.py:133] step: 83250, training_loss: 2.15452e-02
I0215 05:21:57.116164 23126066861888 run_lib.py:133] step: 83300, training_loss: 2.18374e-02
I0215 05:21:57.268981 23126066861888 run_lib.py:146] step: 83300, eval_loss: 2.49835e-02
I0215 05:22:14.723092 23126066861888 run_lib.py:133] step: 83350, training_loss: 2.12102e-02
I0215 05:22:32.100622 23126066861888 run_lib.py:133] step: 83400, training_loss: 2.14999e-02
I0215 05:22:32.252974 23126066861888 run_lib.py:146] step: 83400, eval_loss: 2.48996e-02
I0215 05:22:49.521095 23126066861888 run_lib.py:133] step: 83450, training_loss: 2.24864e-02
I0215 05:23:06.835952 23126066861888 run_lib.py:133] step: 83500, training_loss: 2.17765e-02
I0215 05:23:06.992945 23126066861888 run_lib.py:146] step: 83500, eval_loss: 2.49975e-02
I0215 05:23:24.552656 23126066861888 run_lib.py:133] step: 83550, training_loss: 2.18840e-02
I0215 05:23:41.807144 23126066861888 run_lib.py:133] step: 83600, training_loss: 2.21645e-02
I0215 05:23:41.960995 23126066861888 run_lib.py:146] step: 83600, eval_loss: 2.40838e-02
I0215 05:23:59.242196 23126066861888 run_lib.py:133] step: 83650, training_loss: 2.09782e-02
I0215 05:24:16.655266 23126066861888 run_lib.py:133] step: 83700, training_loss: 2.11293e-02
I0215 05:24:16.810710 23126066861888 run_lib.py:146] step: 83700, eval_loss: 2.38818e-02
I0215 05:24:34.139909 23126066861888 run_lib.py:133] step: 83750, training_loss: 2.15275e-02
I0215 05:24:51.597206 23126066861888 run_lib.py:133] step: 83800, training_loss: 2.19820e-02
I0215 05:24:51.773798 23126066861888 run_lib.py:146] step: 83800, eval_loss: 2.44333e-02
I0215 05:25:09.081220 23126066861888 run_lib.py:133] step: 83850, training_loss: 2.13581e-02
I0215 05:25:26.353370 23126066861888 run_lib.py:133] step: 83900, training_loss: 2.15307e-02
I0215 05:25:26.506955 23126066861888 run_lib.py:146] step: 83900, eval_loss: 2.55962e-02
I0215 05:25:43.888145 23126066861888 run_lib.py:133] step: 83950, training_loss: 2.13348e-02
I0215 05:26:01.155689 23126066861888 run_lib.py:133] step: 84000, training_loss: 2.09562e-02
I0215 05:26:01.326872 23126066861888 run_lib.py:146] step: 84000, eval_loss: 2.56711e-02
I0215 05:26:18.612479 23126066861888 run_lib.py:133] step: 84050, training_loss: 2.20058e-02
I0215 05:26:36.094343 23126066861888 run_lib.py:133] step: 84100, training_loss: 2.11223e-02
I0215 05:26:36.249217 23126066861888 run_lib.py:146] step: 84100, eval_loss: 2.49182e-02
I0215 05:26:53.542715 23126066861888 run_lib.py:133] step: 84150, training_loss: 2.10981e-02
I0215 05:27:10.775449 23126066861888 run_lib.py:133] step: 84200, training_loss: 2.16698e-02
I0215 05:27:10.929006 23126066861888 run_lib.py:146] step: 84200, eval_loss: 2.44793e-02
I0215 05:27:28.279966 23126066861888 run_lib.py:133] step: 84250, training_loss: 2.16352e-02
I0215 05:27:45.531980 23126066861888 run_lib.py:133] step: 84300, training_loss: 2.19354e-02
I0215 05:27:45.684164 23126066861888 run_lib.py:146] step: 84300, eval_loss: 2.48047e-02
I0215 05:28:03.014975 23126066861888 run_lib.py:133] step: 84350, training_loss: 2.19173e-02
I0215 05:28:20.289332 23126066861888 run_lib.py:133] step: 84400, training_loss: 2.18135e-02
I0215 05:28:20.446956 23126066861888 run_lib.py:146] step: 84400, eval_loss: 2.54467e-02
I0215 05:28:37.876138 23126066861888 run_lib.py:133] step: 84450, training_loss: 2.11774e-02
I0215 05:28:55.184947 23126066861888 run_lib.py:133] step: 84500, training_loss: 2.16532e-02
I0215 05:28:55.349249 23126066861888 run_lib.py:146] step: 84500, eval_loss: 2.51991e-02
I0215 05:29:12.631211 23126066861888 run_lib.py:133] step: 84550, training_loss: 2.20321e-02
I0215 05:29:29.922923 23126066861888 run_lib.py:133] step: 84600, training_loss: 2.19349e-02
I0215 05:29:30.078314 23126066861888 run_lib.py:146] step: 84600, eval_loss: 2.61151e-02
I0215 05:29:47.555311 23126066861888 run_lib.py:133] step: 84650, training_loss: 2.05580e-02
I0215 05:30:04.842962 23126066861888 run_lib.py:133] step: 84700, training_loss: 2.20221e-02
I0215 05:30:04.995001 23126066861888 run_lib.py:146] step: 84700, eval_loss: 2.46350e-02
I0215 05:30:22.283405 23126066861888 run_lib.py:133] step: 84750, training_loss: 2.18823e-02
I0215 05:30:39.760028 23126066861888 run_lib.py:133] step: 84800, training_loss: 2.07464e-02
I0215 05:30:39.917932 23126066861888 run_lib.py:146] step: 84800, eval_loss: 2.50017e-02
I0215 05:30:57.217800 23126066861888 run_lib.py:133] step: 84850, training_loss: 2.17276e-02
I0215 05:31:14.640211 23126066861888 run_lib.py:133] step: 84900, training_loss: 2.14406e-02
I0215 05:31:14.798929 23126066861888 run_lib.py:146] step: 84900, eval_loss: 2.49456e-02
I0215 05:31:32.059828 23126066861888 run_lib.py:133] step: 84950, training_loss: 2.10019e-02
I0215 05:31:49.355323 23126066861888 run_lib.py:133] step: 85000, training_loss: 2.17561e-02
I0215 05:31:49.509252 23126066861888 run_lib.py:146] step: 85000, eval_loss: 2.53178e-02
I0215 05:32:06.950313 23126066861888 run_lib.py:133] step: 85050, training_loss: 2.14671e-02
I0215 05:32:24.227930 23126066861888 run_lib.py:133] step: 85100, training_loss: 2.13012e-02
I0215 05:32:24.383860 23126066861888 run_lib.py:146] step: 85100, eval_loss: 2.41910e-02
I0215 05:32:41.696277 23126066861888 run_lib.py:133] step: 85150, training_loss: 2.19621e-02
I0215 05:32:59.186093 23126066861888 run_lib.py:133] step: 85200, training_loss: 2.13906e-02
I0215 05:32:59.342142 23126066861888 run_lib.py:146] step: 85200, eval_loss: 2.59773e-02
I0215 05:33:16.641644 23126066861888 run_lib.py:133] step: 85250, training_loss: 2.18815e-02
I0215 05:33:33.899051 23126066861888 run_lib.py:133] step: 85300, training_loss: 2.10489e-02
I0215 05:33:34.082914 23126066861888 run_lib.py:146] step: 85300, eval_loss: 2.47115e-02
I0215 05:33:51.388367 23126066861888 run_lib.py:133] step: 85350, training_loss: 2.14408e-02
I0215 05:34:08.623431 23126066861888 run_lib.py:133] step: 85400, training_loss: 2.17432e-02
I0215 05:34:08.795047 23126066861888 run_lib.py:146] step: 85400, eval_loss: 2.37867e-02
I0215 05:34:26.084722 23126066861888 run_lib.py:133] step: 85450, training_loss: 2.18317e-02
I0215 05:34:43.373501 23126066861888 run_lib.py:133] step: 85500, training_loss: 2.19338e-02
I0215 05:34:43.527282 23126066861888 run_lib.py:146] step: 85500, eval_loss: 2.47371e-02
I0215 05:35:00.969407 23126066861888 run_lib.py:133] step: 85550, training_loss: 2.10496e-02
I0215 05:35:18.278659 23126066861888 run_lib.py:133] step: 85600, training_loss: 2.04176e-02
I0215 05:35:18.435023 23126066861888 run_lib.py:146] step: 85600, eval_loss: 2.49130e-02
I0215 05:35:35.695746 23126066861888 run_lib.py:133] step: 85650, training_loss: 2.14670e-02
I0215 05:35:53.041630 23126066861888 run_lib.py:133] step: 85700, training_loss: 2.08445e-02
I0215 05:35:53.193310 23126066861888 run_lib.py:146] step: 85700, eval_loss: 2.59359e-02
I0215 05:36:10.680686 23126066861888 run_lib.py:133] step: 85750, training_loss: 2.19438e-02
I0215 05:36:27.953962 23126066861888 run_lib.py:133] step: 85800, training_loss: 2.13482e-02
I0215 05:36:28.106757 23126066861888 run_lib.py:146] step: 85800, eval_loss: 2.46759e-02
I0215 05:36:45.362356 23126066861888 run_lib.py:133] step: 85850, training_loss: 2.14432e-02
I0215 05:37:02.774292 23126066861888 run_lib.py:133] step: 85900, training_loss: 2.19849e-02
I0215 05:37:02.927009 23126066861888 run_lib.py:146] step: 85900, eval_loss: 2.57868e-02
I0215 05:37:20.303493 23126066861888 run_lib.py:133] step: 85950, training_loss: 2.10947e-02
I0215 05:37:37.773452 23126066861888 run_lib.py:133] step: 86000, training_loss: 2.23759e-02
I0215 05:37:37.928213 23126066861888 run_lib.py:146] step: 86000, eval_loss: 2.49398e-02
I0215 05:37:55.198984 23126066861888 run_lib.py:133] step: 86050, training_loss: 2.20669e-02
I0215 05:38:12.456937 23126066861888 run_lib.py:133] step: 86100, training_loss: 2.12229e-02
I0215 05:38:12.609919 23126066861888 run_lib.py:146] step: 86100, eval_loss: 2.48289e-02
I0215 05:38:30.043870 23126066861888 run_lib.py:133] step: 86150, training_loss: 2.13055e-02
I0215 05:38:47.299928 23126066861888 run_lib.py:133] step: 86200, training_loss: 2.15076e-02
I0215 05:38:47.453251 23126066861888 run_lib.py:146] step: 86200, eval_loss: 2.51457e-02
I0215 05:39:04.708769 23126066861888 run_lib.py:133] step: 86250, training_loss: 2.20280e-02
I0215 05:39:22.221643 23126066861888 run_lib.py:133] step: 86300, training_loss: 2.09125e-02
I0215 05:39:22.375874 23126066861888 run_lib.py:146] step: 86300, eval_loss: 2.48091e-02
I0215 05:39:39.632848 23126066861888 run_lib.py:133] step: 86350, training_loss: 2.11040e-02
I0215 05:39:56.892788 23126066861888 run_lib.py:133] step: 86400, training_loss: 2.08890e-02
I0215 05:39:57.049219 23126066861888 run_lib.py:146] step: 86400, eval_loss: 2.46518e-02
I0215 05:40:14.374858 23126066861888 run_lib.py:133] step: 86450, training_loss: 2.17287e-02
I0215 05:40:31.623012 23126066861888 run_lib.py:133] step: 86500, training_loss: 2.21425e-02
I0215 05:40:31.775954 23126066861888 run_lib.py:146] step: 86500, eval_loss: 2.56706e-02
I0215 05:40:49.018212 23126066861888 run_lib.py:133] step: 86550, training_loss: 2.15728e-02
I0215 05:41:06.307625 23126066861888 run_lib.py:133] step: 86600, training_loss: 2.11841e-02
I0215 05:41:06.466172 23126066861888 run_lib.py:146] step: 86600, eval_loss: 2.46488e-02
I0215 05:41:23.970201 23126066861888 run_lib.py:133] step: 86650, training_loss: 2.14065e-02
I0215 05:41:41.315986 23126066861888 run_lib.py:133] step: 86700, training_loss: 2.14777e-02
I0215 05:41:41.471014 23126066861888 run_lib.py:146] step: 86700, eval_loss: 2.45581e-02
I0215 05:41:58.694339 23126066861888 run_lib.py:133] step: 86750, training_loss: 2.07179e-02
I0215 05:42:16.015458 23126066861888 run_lib.py:133] step: 86800, training_loss: 2.10877e-02
I0215 05:42:16.188076 23126066861888 run_lib.py:146] step: 86800, eval_loss: 2.44441e-02
I0215 05:42:33.778111 23126066861888 run_lib.py:133] step: 86850, training_loss: 2.19936e-02
I0215 05:42:51.081321 23126066861888 run_lib.py:133] step: 86900, training_loss: 2.19261e-02
I0215 05:42:51.243353 23126066861888 run_lib.py:146] step: 86900, eval_loss: 2.48573e-02
I0215 05:43:08.491602 23126066861888 run_lib.py:133] step: 86950, training_loss: 2.20094e-02
I0215 05:43:25.862940 23126066861888 run_lib.py:133] step: 87000, training_loss: 2.19843e-02
I0215 05:43:26.016723 23126066861888 run_lib.py:146] step: 87000, eval_loss: 2.41901e-02
I0215 05:43:43.253947 23126066861888 run_lib.py:133] step: 87050, training_loss: 2.17476e-02
I0215 05:44:00.695954 23126066861888 run_lib.py:133] step: 87100, training_loss: 2.09307e-02
I0215 05:44:00.855432 23126066861888 run_lib.py:146] step: 87100, eval_loss: 2.44522e-02
I0215 05:44:18.145249 23126066861888 run_lib.py:133] step: 87150, training_loss: 2.17453e-02
I0215 05:44:35.387042 23126066861888 run_lib.py:133] step: 87200, training_loss: 2.21263e-02
I0215 05:44:35.541931 23126066861888 run_lib.py:146] step: 87200, eval_loss: 2.43783e-02
I0215 05:44:52.943888 23126066861888 run_lib.py:133] step: 87250, training_loss: 2.19400e-02
I0215 05:45:10.220228 23126066861888 run_lib.py:133] step: 87300, training_loss: 2.17822e-02
I0215 05:45:10.377139 23126066861888 run_lib.py:146] step: 87300, eval_loss: 2.48257e-02
I0215 05:45:27.668309 23126066861888 run_lib.py:133] step: 87350, training_loss: 2.18289e-02
I0215 05:45:45.175085 23126066861888 run_lib.py:133] step: 87400, training_loss: 2.21439e-02
I0215 05:45:45.329196 23126066861888 run_lib.py:146] step: 87400, eval_loss: 2.43439e-02
I0215 05:46:02.601747 23126066861888 run_lib.py:133] step: 87450, training_loss: 2.19822e-02
I0215 05:46:19.896801 23126066861888 run_lib.py:133] step: 87500, training_loss: 2.21409e-02
I0215 05:46:20.051044 23126066861888 run_lib.py:146] step: 87500, eval_loss: 2.45939e-02
I0215 05:46:37.403273 23126066861888 run_lib.py:133] step: 87550, training_loss: 2.21308e-02
I0215 05:46:54.666704 23126066861888 run_lib.py:133] step: 87600, training_loss: 2.13214e-02
I0215 05:46:54.824210 23126066861888 run_lib.py:146] step: 87600, eval_loss: 2.57500e-02
I0215 05:47:12.147104 23126066861888 run_lib.py:133] step: 87650, training_loss: 2.12051e-02
I0215 05:47:29.425085 23126066861888 run_lib.py:133] step: 87700, training_loss: 2.19423e-02
I0215 05:47:29.581180 23126066861888 run_lib.py:146] step: 87700, eval_loss: 2.53318e-02
I0215 05:47:47.008955 23126066861888 run_lib.py:133] step: 87750, training_loss: 2.14295e-02
I0215 05:48:04.331240 23126066861888 run_lib.py:133] step: 87800, training_loss: 2.17303e-02
I0215 05:48:04.488331 23126066861888 run_lib.py:146] step: 87800, eval_loss: 2.41686e-02
I0215 05:48:21.735224 23126066861888 run_lib.py:133] step: 87850, training_loss: 2.09711e-02
I0215 05:48:38.997733 23126066861888 run_lib.py:133] step: 87900, training_loss: 2.15392e-02
I0215 05:48:39.162913 23126066861888 run_lib.py:146] step: 87900, eval_loss: 2.59223e-02
I0215 05:48:56.642795 23126066861888 run_lib.py:133] step: 87950, training_loss: 2.08386e-02
I0215 05:49:13.934102 23126066861888 run_lib.py:133] step: 88000, training_loss: 2.09536e-02
I0215 05:49:14.086708 23126066861888 run_lib.py:146] step: 88000, eval_loss: 2.48363e-02
I0215 05:49:31.370356 23126066861888 run_lib.py:133] step: 88050, training_loss: 2.20629e-02
I0215 05:49:48.783291 23126066861888 run_lib.py:133] step: 88100, training_loss: 2.29436e-02
I0215 05:49:48.930045 23126066861888 run_lib.py:146] step: 88100, eval_loss: 2.49162e-02
I0215 05:50:06.170079 23126066861888 run_lib.py:133] step: 88150, training_loss: 2.10042e-02
I0215 05:50:23.604552 23126066861888 run_lib.py:133] step: 88200, training_loss: 2.14320e-02
I0215 05:50:23.771977 23126066861888 run_lib.py:146] step: 88200, eval_loss: 2.39353e-02
I0215 05:50:41.120931 23126066861888 run_lib.py:133] step: 88250, training_loss: 2.18927e-02
I0215 05:50:58.448227 23126066861888 run_lib.py:133] step: 88300, training_loss: 2.09842e-02
I0215 05:50:58.604154 23126066861888 run_lib.py:146] step: 88300, eval_loss: 2.45733e-02
I0215 05:51:16.057887 23126066861888 run_lib.py:133] step: 88350, training_loss: 2.12508e-02
I0215 05:51:33.292969 23126066861888 run_lib.py:133] step: 88400, training_loss: 2.20117e-02
I0215 05:51:33.448959 23126066861888 run_lib.py:146] step: 88400, eval_loss: 2.47677e-02
I0215 05:51:50.688745 23126066861888 run_lib.py:133] step: 88450, training_loss: 2.21054e-02
I0215 05:52:08.207900 23126066861888 run_lib.py:133] step: 88500, training_loss: 2.07856e-02
I0215 05:52:08.359782 23126066861888 run_lib.py:146] step: 88500, eval_loss: 2.49374e-02
I0215 05:52:25.681993 23126066861888 run_lib.py:133] step: 88550, training_loss: 2.17359e-02
I0215 05:52:42.938088 23126066861888 run_lib.py:133] step: 88600, training_loss: 2.17192e-02
I0215 05:52:43.089937 23126066861888 run_lib.py:146] step: 88600, eval_loss: 2.44736e-02
I0215 05:53:00.399695 23126066861888 run_lib.py:133] step: 88650, training_loss: 2.11213e-02
I0215 05:53:17.669213 23126066861888 run_lib.py:133] step: 88700, training_loss: 2.15614e-02
I0215 05:53:17.828185 23126066861888 run_lib.py:146] step: 88700, eval_loss: 2.59565e-02
I0215 05:53:35.100212 23126066861888 run_lib.py:133] step: 88750, training_loss: 2.15930e-02
I0215 05:53:52.426547 23126066861888 run_lib.py:133] step: 88800, training_loss: 2.26029e-02
I0215 05:53:52.581288 23126066861888 run_lib.py:146] step: 88800, eval_loss: 2.46069e-02
I0215 05:54:10.058623 23126066861888 run_lib.py:133] step: 88850, training_loss: 2.19186e-02
I0215 05:54:27.339639 23126066861888 run_lib.py:133] step: 88900, training_loss: 2.15084e-02
I0215 05:54:27.493752 23126066861888 run_lib.py:146] step: 88900, eval_loss: 2.57828e-02
I0215 05:54:44.781151 23126066861888 run_lib.py:133] step: 88950, training_loss: 2.15954e-02
I0215 05:55:02.081370 23126066861888 run_lib.py:133] step: 89000, training_loss: 2.13111e-02
I0215 05:55:02.230710 23126066861888 run_lib.py:146] step: 89000, eval_loss: 2.42909e-02
I0215 05:55:19.706224 23126066861888 run_lib.py:133] step: 89050, training_loss: 2.19420e-02
I0215 05:55:36.955046 23126066861888 run_lib.py:133] step: 89100, training_loss: 2.22414e-02
I0215 05:55:37.109225 23126066861888 run_lib.py:146] step: 89100, eval_loss: 2.47559e-02
I0215 05:55:54.378330 23126066861888 run_lib.py:133] step: 89150, training_loss: 2.15901e-02
I0215 05:56:11.836660 23126066861888 run_lib.py:133] step: 89200, training_loss: 2.07999e-02
I0215 05:56:11.996126 23126066861888 run_lib.py:146] step: 89200, eval_loss: 2.57947e-02
I0215 05:56:29.248015 23126066861888 run_lib.py:133] step: 89250, training_loss: 2.16566e-02
I0215 05:56:46.649347 23126066861888 run_lib.py:133] step: 89300, training_loss: 2.08732e-02
I0215 05:56:46.814920 23126066861888 run_lib.py:146] step: 89300, eval_loss: 2.40529e-02
I0215 05:57:04.078883 23126066861888 run_lib.py:133] step: 89350, training_loss: 2.13103e-02
I0215 05:57:21.380053 23126066861888 run_lib.py:133] step: 89400, training_loss: 2.26031e-02
I0215 05:57:21.534227 23126066861888 run_lib.py:146] step: 89400, eval_loss: 2.52081e-02
I0215 05:57:39.039351 23126066861888 run_lib.py:133] step: 89450, training_loss: 2.08834e-02
I0215 05:57:56.261634 23126066861888 run_lib.py:133] step: 89500, training_loss: 2.20375e-02
I0215 05:57:56.414960 23126066861888 run_lib.py:146] step: 89500, eval_loss: 2.50487e-02
I0215 05:58:13.661373 23126066861888 run_lib.py:133] step: 89550, training_loss: 2.16598e-02
I0215 05:58:31.091232 23126066861888 run_lib.py:133] step: 89600, training_loss: 2.25315e-02
I0215 05:58:31.260144 23126066861888 run_lib.py:146] step: 89600, eval_loss: 2.59511e-02
I0215 05:58:48.603511 23126066861888 run_lib.py:133] step: 89650, training_loss: 2.10268e-02
I0215 05:59:05.913459 23126066861888 run_lib.py:133] step: 89700, training_loss: 2.16400e-02
I0215 05:59:06.069879 23126066861888 run_lib.py:146] step: 89700, eval_loss: 2.40756e-02
I0215 05:59:23.459980 23126066861888 run_lib.py:133] step: 89750, training_loss: 2.08673e-02
I0215 05:59:40.718598 23126066861888 run_lib.py:133] step: 89800, training_loss: 2.17145e-02
I0215 05:59:40.871042 23126066861888 run_lib.py:146] step: 89800, eval_loss: 2.48692e-02
I0215 05:59:58.157537 23126066861888 run_lib.py:133] step: 89850, training_loss: 2.12947e-02
I0215 06:00:15.521796 23126066861888 run_lib.py:133] step: 89900, training_loss: 2.14971e-02
I0215 06:00:15.676217 23126066861888 run_lib.py:146] step: 89900, eval_loss: 2.42207e-02
I0215 06:00:33.154502 23126066861888 run_lib.py:133] step: 89950, training_loss: 2.17086e-02
I0215 06:00:50.512201 23126066861888 run_lib.py:133] step: 90000, training_loss: 2.11661e-02
I0215 06:00:51.227592 23126066861888 run_lib.py:146] step: 90000, eval_loss: 2.49915e-02
I0215 06:01:10.992653 23126066861888 run_lib.py:133] step: 90050, training_loss: 2.21571e-02
I0215 06:01:28.255531 23126066861888 run_lib.py:133] step: 90100, training_loss: 2.11296e-02
I0215 06:01:28.406233 23126066861888 run_lib.py:146] step: 90100, eval_loss: 2.51123e-02
I0215 06:01:45.690501 23126066861888 run_lib.py:133] step: 90150, training_loss: 2.16997e-02
I0215 06:02:03.185355 23126066861888 run_lib.py:133] step: 90200, training_loss: 2.12197e-02
I0215 06:02:03.346971 23126066861888 run_lib.py:146] step: 90200, eval_loss: 2.46174e-02
I0215 06:02:20.587584 23126066861888 run_lib.py:133] step: 90250, training_loss: 2.11890e-02
I0215 06:02:37.902109 23126066861888 run_lib.py:133] step: 90300, training_loss: 2.17105e-02
I0215 06:02:38.054955 23126066861888 run_lib.py:146] step: 90300, eval_loss: 2.38648e-02
I0215 06:02:55.314191 23126066861888 run_lib.py:133] step: 90350, training_loss: 2.15611e-02
I0215 06:03:12.607305 23126066861888 run_lib.py:133] step: 90400, training_loss: 2.08308e-02
I0215 06:03:12.766154 23126066861888 run_lib.py:146] step: 90400, eval_loss: 2.51632e-02
I0215 06:03:30.231491 23126066861888 run_lib.py:133] step: 90450, training_loss: 2.16668e-02
I0215 06:03:47.527738 23126066861888 run_lib.py:133] step: 90500, training_loss: 2.19390e-02
I0215 06:03:47.677043 23126066861888 run_lib.py:146] step: 90500, eval_loss: 2.48596e-02
I0215 06:04:05.179677 23126066861888 run_lib.py:133] step: 90550, training_loss: 2.09512e-02
I0215 06:04:22.458267 23126066861888 run_lib.py:133] step: 90600, training_loss: 2.23069e-02
I0215 06:04:22.611019 23126066861888 run_lib.py:146] step: 90600, eval_loss: 2.51232e-02
I0215 06:04:39.977854 23126066861888 run_lib.py:133] step: 90650, training_loss: 2.08217e-02
I0215 06:04:57.260186 23126066861888 run_lib.py:133] step: 90700, training_loss: 2.17342e-02
I0215 06:04:57.431977 23126066861888 run_lib.py:146] step: 90700, eval_loss: 2.48802e-02
I0215 06:05:14.710742 23126066861888 run_lib.py:133] step: 90750, training_loss: 2.14236e-02
I0215 06:05:32.011965 23126066861888 run_lib.py:133] step: 90800, training_loss: 2.13964e-02
I0215 06:05:32.166291 23126066861888 run_lib.py:146] step: 90800, eval_loss: 2.49495e-02
I0215 06:05:49.644142 23126066861888 run_lib.py:133] step: 90850, training_loss: 2.19608e-02
I0215 06:06:07.015031 23126066861888 run_lib.py:133] step: 90900, training_loss: 2.17580e-02
I0215 06:06:07.177748 23126066861888 run_lib.py:146] step: 90900, eval_loss: 2.49426e-02
I0215 06:06:24.450009 23126066861888 run_lib.py:133] step: 90950, training_loss: 2.17242e-02
I0215 06:06:41.774227 23126066861888 run_lib.py:133] step: 91000, training_loss: 2.11834e-02
I0215 06:06:41.927179 23126066861888 run_lib.py:146] step: 91000, eval_loss: 2.55627e-02
I0215 06:06:59.199214 23126066861888 run_lib.py:133] step: 91050, training_loss: 2.15046e-02
I0215 06:07:16.676364 23126066861888 run_lib.py:133] step: 91100, training_loss: 2.09347e-02
I0215 06:07:16.833059 23126066861888 run_lib.py:146] step: 91100, eval_loss: 2.54540e-02
I0215 06:07:34.097035 23126066861888 run_lib.py:133] step: 91150, training_loss: 2.08444e-02
I0215 06:07:51.377601 23126066861888 run_lib.py:133] step: 91200, training_loss: 2.16075e-02
I0215 06:07:51.534165 23126066861888 run_lib.py:146] step: 91200, eval_loss: 2.56183e-02
I0215 06:08:08.839554 23126066861888 run_lib.py:133] step: 91250, training_loss: 2.09335e-02
I0215 06:08:26.327194 23126066861888 run_lib.py:133] step: 91300, training_loss: 2.08795e-02
I0215 06:08:26.481212 23126066861888 run_lib.py:146] step: 91300, eval_loss: 2.43530e-02
I0215 06:08:43.750727 23126066861888 run_lib.py:133] step: 91350, training_loss: 2.17693e-02
I0215 06:09:01.086937 23126066861888 run_lib.py:133] step: 91400, training_loss: 2.18741e-02
I0215 06:09:01.242944 23126066861888 run_lib.py:146] step: 91400, eval_loss: 2.47263e-02
I0215 06:09:18.540230 23126066861888 run_lib.py:133] step: 91450, training_loss: 2.09250e-02
I0215 06:09:35.835097 23126066861888 run_lib.py:133] step: 91500, training_loss: 2.03195e-02
I0215 06:09:35.987185 23126066861888 run_lib.py:146] step: 91500, eval_loss: 2.50648e-02
I0215 06:09:53.453151 23126066861888 run_lib.py:133] step: 91550, training_loss: 2.15053e-02
I0215 06:10:10.755424 23126066861888 run_lib.py:133] step: 91600, training_loss: 2.12684e-02
I0215 06:10:10.908043 23126066861888 run_lib.py:146] step: 91600, eval_loss: 2.46038e-02
I0215 06:10:28.328999 23126066861888 run_lib.py:133] step: 91650, training_loss: 2.06396e-02
I0215 06:10:45.596046 23126066861888 run_lib.py:133] step: 91700, training_loss: 2.19754e-02
I0215 06:10:45.750335 23126066861888 run_lib.py:146] step: 91700, eval_loss: 2.48173e-02
I0215 06:11:03.200063 23126066861888 run_lib.py:133] step: 91750, training_loss: 2.20433e-02
I0215 06:11:20.497593 23126066861888 run_lib.py:133] step: 91800, training_loss: 2.08365e-02
I0215 06:11:20.657820 23126066861888 run_lib.py:146] step: 91800, eval_loss: 2.58016e-02
I0215 06:11:37.957277 23126066861888 run_lib.py:133] step: 91850, training_loss: 2.09618e-02
I0215 06:11:55.279316 23126066861888 run_lib.py:133] step: 91900, training_loss: 2.13623e-02
I0215 06:11:55.431270 23126066861888 run_lib.py:146] step: 91900, eval_loss: 2.50738e-02
I0215 06:12:12.928552 23126066861888 run_lib.py:133] step: 91950, training_loss: 2.12279e-02
I0215 06:12:30.348217 23126066861888 run_lib.py:133] step: 92000, training_loss: 2.12834e-02
I0215 06:12:30.499898 23126066861888 run_lib.py:146] step: 92000, eval_loss: 2.43342e-02
I0215 06:12:47.721146 23126066861888 run_lib.py:133] step: 92050, training_loss: 2.13748e-02
I0215 06:13:04.989727 23126066861888 run_lib.py:133] step: 92100, training_loss: 1.96053e-02
I0215 06:13:05.158931 23126066861888 run_lib.py:146] step: 92100, eval_loss: 2.40094e-02
I0215 06:13:22.487568 23126066861888 run_lib.py:133] step: 92150, training_loss: 2.09062e-02
I0215 06:13:39.954819 23126066861888 run_lib.py:133] step: 92200, training_loss: 2.09617e-02
I0215 06:13:40.109173 23126066861888 run_lib.py:146] step: 92200, eval_loss: 2.44782e-02
I0215 06:13:57.350839 23126066861888 run_lib.py:133] step: 92250, training_loss: 2.17114e-02
I0215 06:14:14.610554 23126066861888 run_lib.py:133] step: 92300, training_loss: 2.16566e-02
I0215 06:14:14.764132 23126066861888 run_lib.py:146] step: 92300, eval_loss: 2.46281e-02
I0215 06:14:32.020980 23126066861888 run_lib.py:133] step: 92350, training_loss: 2.11670e-02
I0215 06:14:49.503314 23126066861888 run_lib.py:133] step: 92400, training_loss: 2.13719e-02
I0215 06:14:49.654284 23126066861888 run_lib.py:146] step: 92400, eval_loss: 2.46618e-02
I0215 06:15:06.961533 23126066861888 run_lib.py:133] step: 92450, training_loss: 2.14587e-02
I0215 06:15:24.319197 23126066861888 run_lib.py:133] step: 92500, training_loss: 2.12936e-02
I0215 06:15:24.486973 23126066861888 run_lib.py:146] step: 92500, eval_loss: 2.45025e-02
I0215 06:15:41.756971 23126066861888 run_lib.py:133] step: 92550, training_loss: 2.11829e-02
I0215 06:15:59.065535 23126066861888 run_lib.py:133] step: 92600, training_loss: 2.12898e-02
I0215 06:15:59.221278 23126066861888 run_lib.py:146] step: 92600, eval_loss: 2.49353e-02
I0215 06:16:16.675199 23126066861888 run_lib.py:133] step: 92650, training_loss: 2.06930e-02
I0215 06:16:34.042780 23126066861888 run_lib.py:133] step: 92700, training_loss: 2.12327e-02
I0215 06:16:34.196228 23126066861888 run_lib.py:146] step: 92700, eval_loss: 2.54708e-02
I0215 06:16:51.723569 23126066861888 run_lib.py:133] step: 92750, training_loss: 2.18057e-02
I0215 06:17:08.973600 23126066861888 run_lib.py:133] step: 92800, training_loss: 2.14468e-02
I0215 06:17:09.129974 23126066861888 run_lib.py:146] step: 92800, eval_loss: 2.60388e-02
I0215 06:17:26.544027 23126066861888 run_lib.py:133] step: 92850, training_loss: 2.19777e-02
I0215 06:17:43.838986 23126066861888 run_lib.py:133] step: 92900, training_loss: 2.14679e-02
I0215 06:17:43.996842 23126066861888 run_lib.py:146] step: 92900, eval_loss: 2.47727e-02
I0215 06:18:01.296194 23126066861888 run_lib.py:133] step: 92950, training_loss: 2.14097e-02
I0215 06:18:18.563248 23126066861888 run_lib.py:133] step: 93000, training_loss: 2.20209e-02
I0215 06:18:18.724508 23126066861888 run_lib.py:146] step: 93000, eval_loss: 2.62657e-02
I0215 06:18:36.211803 23126066861888 run_lib.py:133] step: 93050, training_loss: 2.11565e-02
I0215 06:18:53.611531 23126066861888 run_lib.py:133] step: 93100, training_loss: 2.13287e-02
I0215 06:18:53.767292 23126066861888 run_lib.py:146] step: 93100, eval_loss: 2.50995e-02
I0215 06:19:11.026235 23126066861888 run_lib.py:133] step: 93150, training_loss: 2.04198e-02
I0215 06:19:28.267396 23126066861888 run_lib.py:133] step: 93200, training_loss: 2.16419e-02
I0215 06:19:28.428026 23126066861888 run_lib.py:146] step: 93200, eval_loss: 2.48453e-02
I0215 06:19:45.716338 23126066861888 run_lib.py:133] step: 93250, training_loss: 2.13861e-02
I0215 06:20:03.191799 23126066861888 run_lib.py:133] step: 93300, training_loss: 2.11385e-02
I0215 06:20:03.343611 23126066861888 run_lib.py:146] step: 93300, eval_loss: 2.45061e-02
I0215 06:20:20.617141 23126066861888 run_lib.py:133] step: 93350, training_loss: 2.10585e-02
I0215 06:20:37.882059 23126066861888 run_lib.py:133] step: 93400, training_loss: 2.15089e-02
I0215 06:20:38.034930 23126066861888 run_lib.py:146] step: 93400, eval_loss: 2.51392e-02
I0215 06:20:55.261300 23126066861888 run_lib.py:133] step: 93450, training_loss: 2.22020e-02
I0215 06:21:12.709649 23126066861888 run_lib.py:133] step: 93500, training_loss: 2.07389e-02
I0215 06:21:12.887077 23126066861888 run_lib.py:146] step: 93500, eval_loss: 2.48114e-02
I0215 06:21:30.208870 23126066861888 run_lib.py:133] step: 93550, training_loss: 2.19192e-02
I0215 06:21:47.568078 23126066861888 run_lib.py:133] step: 93600, training_loss: 2.12872e-02
I0215 06:21:47.724008 23126066861888 run_lib.py:146] step: 93600, eval_loss: 2.63505e-02
I0215 06:22:05.027894 23126066861888 run_lib.py:133] step: 93650, training_loss: 2.16745e-02
I0215 06:22:22.251849 23126066861888 run_lib.py:133] step: 93700, training_loss: 2.15260e-02
I0215 06:22:22.406045 23126066861888 run_lib.py:146] step: 93700, eval_loss: 2.55212e-02
I0215 06:22:39.863900 23126066861888 run_lib.py:133] step: 93750, training_loss: 2.15721e-02
I0215 06:22:57.198565 23126066861888 run_lib.py:133] step: 93800, training_loss: 2.12271e-02
I0215 06:22:57.350739 23126066861888 run_lib.py:146] step: 93800, eval_loss: 2.39316e-02
I0215 06:23:14.857737 23126066861888 run_lib.py:133] step: 93850, training_loss: 2.15244e-02
I0215 06:23:32.110458 23126066861888 run_lib.py:133] step: 93900, training_loss: 2.14733e-02
I0215 06:23:32.262921 23126066861888 run_lib.py:146] step: 93900, eval_loss: 2.52871e-02
I0215 06:23:49.746730 23126066861888 run_lib.py:133] step: 93950, training_loss: 2.11716e-02
I0215 06:24:07.004947 23126066861888 run_lib.py:133] step: 94000, training_loss: 2.11846e-02
I0215 06:24:07.161142 23126066861888 run_lib.py:146] step: 94000, eval_loss: 2.47907e-02
I0215 06:24:24.437205 23126066861888 run_lib.py:133] step: 94050, training_loss: 2.13127e-02
I0215 06:24:41.749554 23126066861888 run_lib.py:133] step: 94100, training_loss: 2.10619e-02
I0215 06:24:41.919070 23126066861888 run_lib.py:146] step: 94100, eval_loss: 2.42347e-02
I0215 06:24:59.402555 23126066861888 run_lib.py:133] step: 94150, training_loss: 2.11300e-02
I0215 06:25:16.802077 23126066861888 run_lib.py:133] step: 94200, training_loss: 2.04550e-02
I0215 06:25:16.954971 23126066861888 run_lib.py:146] step: 94200, eval_loss: 2.54900e-02
I0215 06:25:34.233548 23126066861888 run_lib.py:133] step: 94250, training_loss: 2.14393e-02
I0215 06:25:51.507326 23126066861888 run_lib.py:133] step: 94300, training_loss: 2.13680e-02
I0215 06:25:51.659114 23126066861888 run_lib.py:146] step: 94300, eval_loss: 2.54660e-02
I0215 06:26:08.994968 23126066861888 run_lib.py:133] step: 94350, training_loss: 2.21951e-02
I0215 06:26:26.441628 23126066861888 run_lib.py:133] step: 94400, training_loss: 2.09427e-02
I0215 06:26:26.601138 23126066861888 run_lib.py:146] step: 94400, eval_loss: 2.56112e-02
I0215 06:26:43.840391 23126066861888 run_lib.py:133] step: 94450, training_loss: 2.10840e-02
I0215 06:27:01.098974 23126066861888 run_lib.py:133] step: 94500, training_loss: 2.13870e-02
I0215 06:27:01.263213 23126066861888 run_lib.py:146] step: 94500, eval_loss: 2.48383e-02
I0215 06:27:18.542104 23126066861888 run_lib.py:133] step: 94550, training_loss: 2.06552e-02
I0215 06:27:36.026079 23126066861888 run_lib.py:133] step: 94600, training_loss: 2.12521e-02
I0215 06:27:36.179278 23126066861888 run_lib.py:146] step: 94600, eval_loss: 2.59440e-02
I0215 06:27:53.445893 23126066861888 run_lib.py:133] step: 94650, training_loss: 2.12235e-02
I0215 06:28:10.833377 23126066861888 run_lib.py:133] step: 94700, training_loss: 2.15288e-02
I0215 06:28:10.986973 23126066861888 run_lib.py:146] step: 94700, eval_loss: 2.45584e-02
I0215 06:28:28.244903 23126066861888 run_lib.py:133] step: 94750, training_loss: 2.06428e-02
I0215 06:28:45.532073 23126066861888 run_lib.py:133] step: 94800, training_loss: 2.06745e-02
I0215 06:28:45.682962 23126066861888 run_lib.py:146] step: 94800, eval_loss: 2.52452e-02
I0215 06:29:03.067145 23126066861888 run_lib.py:133] step: 94850, training_loss: 2.08090e-02
I0215 06:29:20.394977 23126066861888 run_lib.py:133] step: 94900, training_loss: 2.08636e-02
I0215 06:29:20.559118 23126066861888 run_lib.py:146] step: 94900, eval_loss: 2.41712e-02
I0215 06:29:38.055693 23126066861888 run_lib.py:133] step: 94950, training_loss: 2.11898e-02
I0215 06:29:55.346880 23126066861888 run_lib.py:133] step: 95000, training_loss: 2.17818e-02
I0215 06:29:55.503494 23126066861888 run_lib.py:146] step: 95000, eval_loss: 2.50064e-02
I0215 06:30:12.910491 23126066861888 run_lib.py:133] step: 95050, training_loss: 2.17251e-02
I0215 06:30:30.161996 23126066861888 run_lib.py:133] step: 95100, training_loss: 2.19802e-02
I0215 06:30:30.315996 23126066861888 run_lib.py:146] step: 95100, eval_loss: 2.53138e-02
I0215 06:30:47.562192 23126066861888 run_lib.py:133] step: 95150, training_loss: 2.16217e-02
I0215 06:31:04.880593 23126066861888 run_lib.py:133] step: 95200, training_loss: 2.15689e-02
I0215 06:31:05.033176 23126066861888 run_lib.py:146] step: 95200, eval_loss: 2.44287e-02
I0215 06:31:22.523428 23126066861888 run_lib.py:133] step: 95250, training_loss: 2.09451e-02
I0215 06:31:39.934348 23126066861888 run_lib.py:133] step: 95300, training_loss: 2.12821e-02
I0215 06:31:40.083341 23126066861888 run_lib.py:146] step: 95300, eval_loss: 2.46592e-02
I0215 06:31:57.325650 23126066861888 run_lib.py:133] step: 95350, training_loss: 2.07557e-02
I0215 06:32:14.594016 23126066861888 run_lib.py:133] step: 95400, training_loss: 2.09554e-02
I0215 06:32:14.754822 23126066861888 run_lib.py:146] step: 95400, eval_loss: 2.52452e-02
I0215 06:32:32.063734 23126066861888 run_lib.py:133] step: 95450, training_loss: 2.15155e-02
I0215 06:32:49.547426 23126066861888 run_lib.py:133] step: 95500, training_loss: 2.24542e-02
I0215 06:32:49.700984 23126066861888 run_lib.py:146] step: 95500, eval_loss: 2.41899e-02
I0215 06:33:06.944954 23126066861888 run_lib.py:133] step: 95550, training_loss: 2.09358e-02
I0215 06:33:24.182819 23126066861888 run_lib.py:133] step: 95600, training_loss: 2.07584e-02
I0215 06:33:24.335705 23126066861888 run_lib.py:146] step: 95600, eval_loss: 2.49989e-02
I0215 06:33:41.603594 23126066861888 run_lib.py:133] step: 95650, training_loss: 2.09617e-02
I0215 06:33:59.040371 23126066861888 run_lib.py:133] step: 95700, training_loss: 2.13236e-02
I0215 06:33:59.194247 23126066861888 run_lib.py:146] step: 95700, eval_loss: 2.49488e-02
I0215 06:34:16.521130 23126066861888 run_lib.py:133] step: 95750, training_loss: 2.04315e-02
I0215 06:34:33.934151 23126066861888 run_lib.py:133] step: 95800, training_loss: 2.11341e-02
I0215 06:34:34.092703 23126066861888 run_lib.py:146] step: 95800, eval_loss: 2.51972e-02
I0215 06:34:51.342600 23126066861888 run_lib.py:133] step: 95850, training_loss: 2.12154e-02
I0215 06:35:08.615411 23126066861888 run_lib.py:133] step: 95900, training_loss: 2.11398e-02
I0215 06:35:08.771147 23126066861888 run_lib.py:146] step: 95900, eval_loss: 2.48186e-02
I0215 06:35:26.184172 23126066861888 run_lib.py:133] step: 95950, training_loss: 2.12728e-02
I0215 06:35:43.440351 23126066861888 run_lib.py:133] step: 96000, training_loss: 2.11036e-02
I0215 06:35:43.603987 23126066861888 run_lib.py:146] step: 96000, eval_loss: 2.44538e-02
I0215 06:36:01.028844 23126066861888 run_lib.py:133] step: 96050, training_loss: 2.09025e-02
I0215 06:36:18.318544 23126066861888 run_lib.py:133] step: 96100, training_loss: 2.10432e-02
I0215 06:36:18.472750 23126066861888 run_lib.py:146] step: 96100, eval_loss: 2.55227e-02
I0215 06:36:35.929189 23126066861888 run_lib.py:133] step: 96150, training_loss: 2.20882e-02
I0215 06:36:53.175235 23126066861888 run_lib.py:133] step: 96200, training_loss: 2.20803e-02
I0215 06:36:53.324769 23126066861888 run_lib.py:146] step: 96200, eval_loss: 2.55106e-02
I0215 06:37:10.576907 23126066861888 run_lib.py:133] step: 96250, training_loss: 2.10209e-02
I0215 06:37:27.848390 23126066861888 run_lib.py:133] step: 96300, training_loss: 2.11380e-02
I0215 06:37:28.013151 23126066861888 run_lib.py:146] step: 96300, eval_loss: 2.57530e-02
I0215 06:37:45.467850 23126066861888 run_lib.py:133] step: 96350, training_loss: 2.11331e-02
I0215 06:38:02.910699 23126066861888 run_lib.py:133] step: 96400, training_loss: 2.14093e-02
I0215 06:38:03.066178 23126066861888 run_lib.py:146] step: 96400, eval_loss: 2.43169e-02
I0215 06:38:20.346177 23126066861888 run_lib.py:133] step: 96450, training_loss: 2.15578e-02
I0215 06:38:37.607256 23126066861888 run_lib.py:133] step: 96500, training_loss: 2.17019e-02
I0215 06:38:37.760043 23126066861888 run_lib.py:146] step: 96500, eval_loss: 2.52268e-02
I0215 06:38:55.021505 23126066861888 run_lib.py:133] step: 96550, training_loss: 2.19576e-02
I0215 06:39:12.521533 23126066861888 run_lib.py:133] step: 96600, training_loss: 2.15878e-02
I0215 06:39:12.674784 23126066861888 run_lib.py:146] step: 96600, eval_loss: 2.51464e-02
I0215 06:39:29.980819 23126066861888 run_lib.py:133] step: 96650, training_loss: 2.13131e-02
I0215 06:39:47.252846 23126066861888 run_lib.py:133] step: 96700, training_loss: 2.06354e-02
I0215 06:39:47.402910 23126066861888 run_lib.py:146] step: 96700, eval_loss: 2.54792e-02
I0215 06:40:04.658571 23126066861888 run_lib.py:133] step: 96750, training_loss: 2.20657e-02
I0215 06:40:22.090786 23126066861888 run_lib.py:133] step: 96800, training_loss: 2.09541e-02
I0215 06:40:22.246495 23126066861888 run_lib.py:146] step: 96800, eval_loss: 2.46650e-02
I0215 06:40:39.592680 23126066861888 run_lib.py:133] step: 96850, training_loss: 2.13733e-02
I0215 06:40:56.970742 23126066861888 run_lib.py:133] step: 96900, training_loss: 2.15143e-02
I0215 06:40:57.126890 23126066861888 run_lib.py:146] step: 96900, eval_loss: 2.49279e-02
I0215 06:41:14.356010 23126066861888 run_lib.py:133] step: 96950, training_loss: 2.10266e-02
I0215 06:41:31.575371 23126066861888 run_lib.py:133] step: 97000, training_loss: 2.09391e-02
I0215 06:41:31.729971 23126066861888 run_lib.py:146] step: 97000, eval_loss: 2.47944e-02
I0215 06:41:49.135477 23126066861888 run_lib.py:133] step: 97050, training_loss: 2.13167e-02
I0215 06:42:06.399281 23126066861888 run_lib.py:133] step: 97100, training_loss: 2.18629e-02
I0215 06:42:06.559614 23126066861888 run_lib.py:146] step: 97100, eval_loss: 2.58786e-02
I0215 06:42:24.016072 23126066861888 run_lib.py:133] step: 97150, training_loss: 2.08577e-02
I0215 06:42:41.300447 23126066861888 run_lib.py:133] step: 97200, training_loss: 2.17012e-02
I0215 06:42:41.466984 23126066861888 run_lib.py:146] step: 97200, eval_loss: 2.54381e-02
I0215 06:42:58.958753 23126066861888 run_lib.py:133] step: 97250, training_loss: 2.04570e-02
I0215 06:43:16.222396 23126066861888 run_lib.py:133] step: 97300, training_loss: 2.14247e-02
I0215 06:43:16.383226 23126066861888 run_lib.py:146] step: 97300, eval_loss: 2.51687e-02
I0215 06:43:33.671513 23126066861888 run_lib.py:133] step: 97350, training_loss: 2.11656e-02
I0215 06:43:50.973965 23126066861888 run_lib.py:133] step: 97400, training_loss: 2.11505e-02
I0215 06:43:51.126981 23126066861888 run_lib.py:146] step: 97400, eval_loss: 2.52304e-02
I0215 06:44:08.582129 23126066861888 run_lib.py:133] step: 97450, training_loss: 2.13365e-02
I0215 06:44:26.015999 23126066861888 run_lib.py:133] step: 97500, training_loss: 2.05775e-02
I0215 06:44:26.174174 23126066861888 run_lib.py:146] step: 97500, eval_loss: 2.50798e-02
I0215 06:44:43.439935 23126066861888 run_lib.py:133] step: 97550, training_loss: 2.14627e-02
I0215 06:45:00.685707 23126066861888 run_lib.py:133] step: 97600, training_loss: 2.16487e-02
I0215 06:45:00.836022 23126066861888 run_lib.py:146] step: 97600, eval_loss: 2.46096e-02
I0215 06:45:18.141906 23126066861888 run_lib.py:133] step: 97650, training_loss: 2.12444e-02
I0215 06:45:35.567043 23126066861888 run_lib.py:133] step: 97700, training_loss: 2.06335e-02
I0215 06:45:35.726307 23126066861888 run_lib.py:146] step: 97700, eval_loss: 2.58827e-02
I0215 06:45:53.045602 23126066861888 run_lib.py:133] step: 97750, training_loss: 2.13276e-02
I0215 06:46:10.307825 23126066861888 run_lib.py:133] step: 97800, training_loss: 2.13256e-02
I0215 06:46:10.464226 23126066861888 run_lib.py:146] step: 97800, eval_loss: 2.50626e-02
I0215 06:46:27.716376 23126066861888 run_lib.py:133] step: 97850, training_loss: 2.15564e-02
I0215 06:46:45.174026 23126066861888 run_lib.py:133] step: 97900, training_loss: 2.18893e-02
I0215 06:46:45.338983 23126066861888 run_lib.py:146] step: 97900, eval_loss: 2.50207e-02
I0215 06:47:02.666398 23126066861888 run_lib.py:133] step: 97950, training_loss: 2.14749e-02
I0215 06:47:20.067723 23126066861888 run_lib.py:133] step: 98000, training_loss: 2.07533e-02
I0215 06:47:20.221273 23126066861888 run_lib.py:146] step: 98000, eval_loss: 2.46277e-02
I0215 06:47:37.516444 23126066861888 run_lib.py:133] step: 98050, training_loss: 2.22579e-02
I0215 06:47:54.747452 23126066861888 run_lib.py:133] step: 98100, training_loss: 2.02648e-02
I0215 06:47:54.897079 23126066861888 run_lib.py:146] step: 98100, eval_loss: 2.59639e-02
I0215 06:48:12.264062 23126066861888 run_lib.py:133] step: 98150, training_loss: 2.12067e-02
I0215 06:48:29.587588 23126066861888 run_lib.py:133] step: 98200, training_loss: 2.11561e-02
I0215 06:48:29.757270 23126066861888 run_lib.py:146] step: 98200, eval_loss: 2.48733e-02
I0215 06:48:47.224384 23126066861888 run_lib.py:133] step: 98250, training_loss: 2.10498e-02
I0215 06:49:04.492119 23126066861888 run_lib.py:133] step: 98300, training_loss: 2.07898e-02
I0215 06:49:04.647861 23126066861888 run_lib.py:146] step: 98300, eval_loss: 2.53238e-02
I0215 06:49:22.063061 23126066861888 run_lib.py:133] step: 98350, training_loss: 2.04112e-02
I0215 06:49:39.307610 23126066861888 run_lib.py:133] step: 98400, training_loss: 2.08244e-02
I0215 06:49:39.460932 23126066861888 run_lib.py:146] step: 98400, eval_loss: 2.48698e-02
I0215 06:49:56.760756 23126066861888 run_lib.py:133] step: 98450, training_loss: 2.06620e-02
I0215 06:50:14.076946 23126066861888 run_lib.py:133] step: 98500, training_loss: 2.14047e-02
I0215 06:50:14.229731 23126066861888 run_lib.py:146] step: 98500, eval_loss: 2.57231e-02
I0215 06:50:31.709609 23126066861888 run_lib.py:133] step: 98550, training_loss: 2.05970e-02
I0215 06:50:49.121146 23126066861888 run_lib.py:133] step: 98600, training_loss: 2.09390e-02
I0215 06:50:49.271937 23126066861888 run_lib.py:146] step: 98600, eval_loss: 2.54947e-02
I0215 06:51:06.497766 23126066861888 run_lib.py:133] step: 98650, training_loss: 2.14572e-02
I0215 06:51:23.737388 23126066861888 run_lib.py:133] step: 98700, training_loss: 2.10977e-02
I0215 06:51:23.912784 23126066861888 run_lib.py:146] step: 98700, eval_loss: 2.59755e-02
I0215 06:51:41.209518 23126066861888 run_lib.py:133] step: 98750, training_loss: 2.06775e-02
I0215 06:51:58.699056 23126066861888 run_lib.py:133] step: 98800, training_loss: 2.12222e-02
I0215 06:51:58.855003 23126066861888 run_lib.py:146] step: 98800, eval_loss: 2.53152e-02
I0215 06:52:16.097537 23126066861888 run_lib.py:133] step: 98850, training_loss: 2.12381e-02
I0215 06:52:33.359116 23126066861888 run_lib.py:133] step: 98900, training_loss: 2.10725e-02
I0215 06:52:33.517964 23126066861888 run_lib.py:146] step: 98900, eval_loss: 2.60812e-02
I0215 06:52:50.778978 23126066861888 run_lib.py:133] step: 98950, training_loss: 2.09236e-02
I0215 06:53:08.248256 23126066861888 run_lib.py:133] step: 99000, training_loss: 2.15083e-02
I0215 06:53:08.407681 23126066861888 run_lib.py:146] step: 99000, eval_loss: 2.56362e-02
I0215 06:53:25.729768 23126066861888 run_lib.py:133] step: 99050, training_loss: 2.09004e-02
I0215 06:53:43.130594 23126066861888 run_lib.py:133] step: 99100, training_loss: 2.08794e-02
I0215 06:53:43.285162 23126066861888 run_lib.py:146] step: 99100, eval_loss: 2.47683e-02
I0215 06:54:00.565881 23126066861888 run_lib.py:133] step: 99150, training_loss: 2.14473e-02
I0215 06:54:17.889703 23126066861888 run_lib.py:133] step: 99200, training_loss: 2.15465e-02
I0215 06:54:18.046301 23126066861888 run_lib.py:146] step: 99200, eval_loss: 2.54298e-02
I0215 06:54:35.491157 23126066861888 run_lib.py:133] step: 99250, training_loss: 2.15888e-02
I0215 06:54:52.740883 23126066861888 run_lib.py:133] step: 99300, training_loss: 2.10869e-02
I0215 06:54:52.906713 23126066861888 run_lib.py:146] step: 99300, eval_loss: 2.51475e-02
I0215 06:55:10.331229 23126066861888 run_lib.py:133] step: 99350, training_loss: 2.14415e-02
I0215 06:55:27.591645 23126066861888 run_lib.py:133] step: 99400, training_loss: 2.19460e-02
I0215 06:55:27.744773 23126066861888 run_lib.py:146] step: 99400, eval_loss: 2.47532e-02
I0215 06:55:45.189356 23126066861888 run_lib.py:133] step: 99450, training_loss: 2.03793e-02
I0215 06:56:02.432070 23126066861888 run_lib.py:133] step: 99500, training_loss: 2.07372e-02
I0215 06:56:02.586052 23126066861888 run_lib.py:146] step: 99500, eval_loss: 2.49932e-02
I0215 06:56:19.914998 23126066861888 run_lib.py:133] step: 99550, training_loss: 2.14776e-02
I0215 06:56:37.231723 23126066861888 run_lib.py:133] step: 99600, training_loss: 2.13862e-02
I0215 06:56:37.388227 23126066861888 run_lib.py:146] step: 99600, eval_loss: 2.42019e-02
I0215 06:56:54.853979 23126066861888 run_lib.py:133] step: 99650, training_loss: 2.02123e-02
I0215 06:57:12.325309 23126066861888 run_lib.py:133] step: 99700, training_loss: 2.11461e-02
I0215 06:57:12.480063 23126066861888 run_lib.py:146] step: 99700, eval_loss: 2.50991e-02
I0215 06:57:29.743328 23126066861888 run_lib.py:133] step: 99750, training_loss: 2.07876e-02
I0215 06:57:46.987129 23126066861888 run_lib.py:133] step: 99800, training_loss: 2.16191e-02
I0215 06:57:47.140921 23126066861888 run_lib.py:146] step: 99800, eval_loss: 2.62796e-02
I0215 06:58:04.390048 23126066861888 run_lib.py:133] step: 99850, training_loss: 2.08075e-02
I0215 06:58:21.830620 23126066861888 run_lib.py:133] step: 99900, training_loss: 2.17071e-02
I0215 06:58:21.984221 23126066861888 run_lib.py:146] step: 99900, eval_loss: 2.59358e-02
I0215 06:58:39.303338 23126066861888 run_lib.py:133] step: 99950, training_loss: 2.06165e-02
I0215 06:58:56.578029 23126066861888 run_lib.py:133] step: 100000, training_loss: 2.07339e-02
I0215 06:58:57.252771 23126066861888 run_lib.py:146] step: 100000, eval_loss: 2.52590e-02
I0215 06:59:17.074939 23126066861888 run_lib.py:133] step: 100050, training_loss: 2.10279e-02
I0215 06:59:34.356758 23126066861888 run_lib.py:133] step: 100100, training_loss: 2.20002e-02
I0215 06:59:34.508058 23126066861888 run_lib.py:146] step: 100100, eval_loss: 2.48706e-02
I0215 06:59:51.953960 23126066861888 run_lib.py:133] step: 100150, training_loss: 2.09701e-02
I0215 07:00:09.265685 23126066861888 run_lib.py:133] step: 100200, training_loss: 2.07086e-02
I0215 07:00:09.435021 23126066861888 run_lib.py:146] step: 100200, eval_loss: 2.35995e-02
I0215 07:00:26.824431 23126066861888 run_lib.py:133] step: 100250, training_loss: 2.14911e-02
I0215 07:00:44.089181 23126066861888 run_lib.py:133] step: 100300, training_loss: 2.09935e-02
I0215 07:00:44.252039 23126066861888 run_lib.py:146] step: 100300, eval_loss: 2.59302e-02
I0215 07:01:01.505842 23126066861888 run_lib.py:133] step: 100350, training_loss: 2.12493e-02
I0215 07:01:18.759040 23126066861888 run_lib.py:133] step: 100400, training_loss: 2.07938e-02
I0215 07:01:18.925856 23126066861888 run_lib.py:146] step: 100400, eval_loss: 2.58328e-02
I0215 07:01:36.396632 23126066861888 run_lib.py:133] step: 100450, training_loss: 2.20554e-02
I0215 07:01:53.826630 23126066861888 run_lib.py:133] step: 100500, training_loss: 2.03058e-02
I0215 07:01:53.979683 23126066861888 run_lib.py:146] step: 100500, eval_loss: 2.56392e-02
I0215 07:02:11.289386 23126066861888 run_lib.py:133] step: 100550, training_loss: 2.10681e-02
I0215 07:02:28.563306 23126066861888 run_lib.py:133] step: 100600, training_loss: 2.11084e-02
I0215 07:02:28.715949 23126066861888 run_lib.py:146] step: 100600, eval_loss: 2.60657e-02
I0215 07:02:46.116328 23126066861888 run_lib.py:133] step: 100650, training_loss: 2.10628e-02
I0215 07:03:03.406618 23126066861888 run_lib.py:133] step: 100700, training_loss: 2.07243e-02
I0215 07:03:03.576896 23126066861888 run_lib.py:146] step: 100700, eval_loss: 2.55810e-02
I0215 07:03:20.891548 23126066861888 run_lib.py:133] step: 100750, training_loss: 2.06404e-02
I0215 07:03:38.325275 23126066861888 run_lib.py:133] step: 100800, training_loss: 2.18759e-02
I0215 07:03:38.483139 23126066861888 run_lib.py:146] step: 100800, eval_loss: 2.46814e-02
I0215 07:03:55.770271 23126066861888 run_lib.py:133] step: 100850, training_loss: 2.12452e-02
I0215 07:04:13.199970 23126066861888 run_lib.py:133] step: 100900, training_loss: 2.19765e-02
I0215 07:04:13.353167 23126066861888 run_lib.py:146] step: 100900, eval_loss: 2.55407e-02
I0215 07:04:30.679544 23126066861888 run_lib.py:133] step: 100950, training_loss: 2.08547e-02
I0215 07:04:47.977594 23126066861888 run_lib.py:133] step: 101000, training_loss: 2.05100e-02
I0215 07:04:48.131194 23126066861888 run_lib.py:146] step: 101000, eval_loss: 2.44759e-02
I0215 07:05:05.620427 23126066861888 run_lib.py:133] step: 101050, training_loss: 2.22232e-02
I0215 07:05:22.911494 23126066861888 run_lib.py:133] step: 101100, training_loss: 2.16391e-02
I0215 07:05:23.067000 23126066861888 run_lib.py:146] step: 101100, eval_loss: 2.51909e-02
I0215 07:05:40.329442 23126066861888 run_lib.py:133] step: 101150, training_loss: 2.06540e-02
I0215 07:05:57.741972 23126066861888 run_lib.py:133] step: 101200, training_loss: 2.04222e-02
I0215 07:05:57.923319 23126066861888 run_lib.py:146] step: 101200, eval_loss: 2.46800e-02
I0215 07:06:15.239598 23126066861888 run_lib.py:133] step: 101250, training_loss: 2.11837e-02
I0215 07:06:32.523327 23126066861888 run_lib.py:133] step: 101300, training_loss: 2.14393e-02
I0215 07:06:32.680919 23126066861888 run_lib.py:146] step: 101300, eval_loss: 2.47673e-02
I0215 07:06:50.051706 23126066861888 run_lib.py:133] step: 101350, training_loss: 2.10589e-02
I0215 07:07:07.297053 23126066861888 run_lib.py:133] step: 101400, training_loss: 2.13584e-02
I0215 07:07:07.449944 23126066861888 run_lib.py:146] step: 101400, eval_loss: 2.52877e-02
I0215 07:07:24.705385 23126066861888 run_lib.py:133] step: 101450, training_loss: 2.06432e-02
I0215 07:07:41.967277 23126066861888 run_lib.py:133] step: 101500, training_loss: 2.10335e-02
I0215 07:07:42.120230 23126066861888 run_lib.py:146] step: 101500, eval_loss: 2.55373e-02
I0215 07:07:59.580663 23126066861888 run_lib.py:133] step: 101550, training_loss: 2.16151e-02
I0215 07:08:16.969391 23126066861888 run_lib.py:133] step: 101600, training_loss: 2.09868e-02
I0215 07:08:17.124685 23126066861888 run_lib.py:146] step: 101600, eval_loss: 2.53107e-02
I0215 07:08:34.375353 23126066861888 run_lib.py:133] step: 101650, training_loss: 2.12327e-02
I0215 07:08:51.655809 23126066861888 run_lib.py:133] step: 101700, training_loss: 2.13536e-02
I0215 07:08:51.812215 23126066861888 run_lib.py:146] step: 101700, eval_loss: 2.50415e-02
I0215 07:09:09.220169 23126066861888 run_lib.py:133] step: 101750, training_loss: 2.19907e-02
I0215 07:09:26.505758 23126066861888 run_lib.py:133] step: 101800, training_loss: 2.11223e-02
I0215 07:09:26.660198 23126066861888 run_lib.py:146] step: 101800, eval_loss: 2.51919e-02
I0215 07:09:43.955585 23126066861888 run_lib.py:133] step: 101850, training_loss: 2.11982e-02
I0215 07:10:01.401628 23126066861888 run_lib.py:133] step: 101900, training_loss: 2.13438e-02
I0215 07:10:01.554140 23126066861888 run_lib.py:146] step: 101900, eval_loss: 2.44981e-02
I0215 07:10:18.836408 23126066861888 run_lib.py:133] step: 101950, training_loss: 2.15502e-02
I0215 07:10:36.219483 23126066861888 run_lib.py:133] step: 102000, training_loss: 2.11697e-02
I0215 07:10:36.372949 23126066861888 run_lib.py:146] step: 102000, eval_loss: 2.56301e-02
I0215 07:10:53.632876 23126066861888 run_lib.py:133] step: 102050, training_loss: 2.09149e-02
I0215 07:11:10.911722 23126066861888 run_lib.py:133] step: 102100, training_loss: 2.12370e-02
I0215 07:11:11.083018 23126066861888 run_lib.py:146] step: 102100, eval_loss: 2.51153e-02
I0215 07:11:28.553462 23126066861888 run_lib.py:133] step: 102150, training_loss: 2.07507e-02
I0215 07:11:45.815165 23126066861888 run_lib.py:133] step: 102200, training_loss: 2.09869e-02
I0215 07:11:45.969310 23126066861888 run_lib.py:146] step: 102200, eval_loss: 2.45039e-02
I0215 07:12:03.232868 23126066861888 run_lib.py:133] step: 102250, training_loss: 2.11339e-02
I0215 07:12:20.645983 23126066861888 run_lib.py:133] step: 102300, training_loss: 2.08388e-02
I0215 07:12:20.799949 23126066861888 run_lib.py:146] step: 102300, eval_loss: 2.49148e-02
I0215 07:12:38.076930 23126066861888 run_lib.py:133] step: 102350, training_loss: 2.08963e-02
I0215 07:12:55.441501 23126066861888 run_lib.py:133] step: 102400, training_loss: 2.06358e-02
I0215 07:12:55.595759 23126066861888 run_lib.py:146] step: 102400, eval_loss: 2.59196e-02
I0215 07:13:13.010872 23126066861888 run_lib.py:133] step: 102450, training_loss: 2.12454e-02
I0215 07:13:30.331049 23126066861888 run_lib.py:133] step: 102500, training_loss: 2.05862e-02
I0215 07:13:30.482919 23126066861888 run_lib.py:146] step: 102500, eval_loss: 2.49548e-02
I0215 07:13:47.752312 23126066861888 run_lib.py:133] step: 102550, training_loss: 2.14560e-02
I0215 07:14:05.013591 23126066861888 run_lib.py:133] step: 102600, training_loss: 2.04766e-02
I0215 07:14:05.170939 23126066861888 run_lib.py:146] step: 102600, eval_loss: 2.46339e-02
I0215 07:14:22.644201 23126066861888 run_lib.py:133] step: 102650, training_loss: 2.10801e-02
I0215 07:14:40.146858 23126066861888 run_lib.py:133] step: 102700, training_loss: 2.12803e-02
I0215 07:14:40.306262 23126066861888 run_lib.py:146] step: 102700, eval_loss: 2.42020e-02
I0215 07:14:57.534719 23126066861888 run_lib.py:133] step: 102750, training_loss: 2.12951e-02
I0215 07:15:14.804185 23126066861888 run_lib.py:133] step: 102800, training_loss: 2.09986e-02
I0215 07:15:14.965176 23126066861888 run_lib.py:146] step: 102800, eval_loss: 2.48209e-02
I0215 07:15:32.378360 23126066861888 run_lib.py:133] step: 102850, training_loss: 2.11673e-02
I0215 07:15:49.664237 23126066861888 run_lib.py:133] step: 102900, training_loss: 2.12738e-02
I0215 07:15:49.814530 23126066861888 run_lib.py:146] step: 102900, eval_loss: 2.48636e-02
I0215 07:16:07.104036 23126066861888 run_lib.py:133] step: 102950, training_loss: 2.09637e-02
I0215 07:16:24.584011 23126066861888 run_lib.py:133] step: 103000, training_loss: 2.11907e-02
I0215 07:16:24.745255 23126066861888 run_lib.py:146] step: 103000, eval_loss: 2.52703e-02
I0215 07:16:42.008125 23126066861888 run_lib.py:133] step: 103050, training_loss: 2.12796e-02
I0215 07:16:59.458810 23126066861888 run_lib.py:133] step: 103100, training_loss: 2.14648e-02
I0215 07:16:59.615224 23126066861888 run_lib.py:146] step: 103100, eval_loss: 2.49775e-02
I0215 07:17:16.862358 23126066861888 run_lib.py:133] step: 103150, training_loss: 2.13825e-02
I0215 07:17:34.214499 23126066861888 run_lib.py:133] step: 103200, training_loss: 2.03803e-02
I0215 07:17:34.369261 23126066861888 run_lib.py:146] step: 103200, eval_loss: 2.56562e-02
I0215 07:17:51.853353 23126066861888 run_lib.py:133] step: 103250, training_loss: 2.06382e-02
I0215 07:18:09.152097 23126066861888 run_lib.py:133] step: 103300, training_loss: 2.11365e-02
I0215 07:18:09.304911 23126066861888 run_lib.py:146] step: 103300, eval_loss: 2.62904e-02
I0215 07:18:26.601316 23126066861888 run_lib.py:133] step: 103350, training_loss: 2.16304e-02
I0215 07:18:44.000688 23126066861888 run_lib.py:133] step: 103400, training_loss: 2.08903e-02
I0215 07:18:44.149973 23126066861888 run_lib.py:146] step: 103400, eval_loss: 2.70252e-02
I0215 07:19:01.379988 23126066861888 run_lib.py:133] step: 103450, training_loss: 2.15289e-02
I0215 07:19:18.691929 23126066861888 run_lib.py:133] step: 103500, training_loss: 2.07767e-02
I0215 07:19:18.865877 23126066861888 run_lib.py:146] step: 103500, eval_loss: 2.46658e-02
I0215 07:19:36.219801 23126066861888 run_lib.py:133] step: 103550, training_loss: 2.16658e-02
I0215 07:19:53.529388 23126066861888 run_lib.py:133] step: 103600, training_loss: 2.10596e-02
I0215 07:19:53.685195 23126066861888 run_lib.py:146] step: 103600, eval_loss: 2.58454e-02
I0215 07:20:10.945913 23126066861888 run_lib.py:133] step: 103650, training_loss: 2.10247e-02
I0215 07:20:28.205719 23126066861888 run_lib.py:133] step: 103700, training_loss: 2.02208e-02
I0215 07:20:28.362955 23126066861888 run_lib.py:146] step: 103700, eval_loss: 2.56891e-02
I0215 07:20:45.770769 23126066861888 run_lib.py:133] step: 103750, training_loss: 2.09776e-02
I0215 07:21:03.221435 23126066861888 run_lib.py:133] step: 103800, training_loss: 2.10153e-02
I0215 07:21:03.375177 23126066861888 run_lib.py:146] step: 103800, eval_loss: 2.54318e-02
I0215 07:21:20.640669 23126066861888 run_lib.py:133] step: 103850, training_loss: 2.12461e-02
I0215 07:21:37.917540 23126066861888 run_lib.py:133] step: 103900, training_loss: 2.21027e-02
I0215 07:21:38.067968 23126066861888 run_lib.py:146] step: 103900, eval_loss: 2.45535e-02
I0215 07:21:55.470770 23126066861888 run_lib.py:133] step: 103950, training_loss: 2.24031e-02
I0215 07:22:12.732654 23126066861888 run_lib.py:133] step: 104000, training_loss: 2.12163e-02
I0215 07:22:12.893917 23126066861888 run_lib.py:146] step: 104000, eval_loss: 2.60131e-02
I0215 07:22:30.197498 23126066861888 run_lib.py:133] step: 104050, training_loss: 2.16860e-02
I0215 07:22:47.656578 23126066861888 run_lib.py:133] step: 104100, training_loss: 2.17176e-02
I0215 07:22:47.812006 23126066861888 run_lib.py:146] step: 104100, eval_loss: 2.42577e-02
I0215 07:23:05.047960 23126066861888 run_lib.py:133] step: 104150, training_loss: 2.06405e-02
I0215 07:23:22.461237 23126066861888 run_lib.py:133] step: 104200, training_loss: 2.07087e-02
I0215 07:23:22.616193 23126066861888 run_lib.py:146] step: 104200, eval_loss: 2.49305e-02
I0215 07:23:39.877470 23126066861888 run_lib.py:133] step: 104250, training_loss: 2.07923e-02
I0215 07:23:57.175263 23126066861888 run_lib.py:133] step: 104300, training_loss: 2.08904e-02
I0215 07:23:57.325399 23126066861888 run_lib.py:146] step: 104300, eval_loss: 2.51216e-02
I0215 07:24:14.790202 23126066861888 run_lib.py:133] step: 104350, training_loss: 2.09264e-02
I0215 07:24:32.022019 23126066861888 run_lib.py:133] step: 104400, training_loss: 2.05298e-02
I0215 07:24:32.174982 23126066861888 run_lib.py:146] step: 104400, eval_loss: 2.57813e-02
I0215 07:24:49.400167 23126066861888 run_lib.py:133] step: 104450, training_loss: 2.07626e-02
I0215 07:25:06.843589 23126066861888 run_lib.py:133] step: 104500, training_loss: 2.10454e-02
I0215 07:25:07.000171 23126066861888 run_lib.py:146] step: 104500, eval_loss: 2.55458e-02
I0215 07:25:24.253945 23126066861888 run_lib.py:133] step: 104550, training_loss: 2.12207e-02
I0215 07:25:41.579026 23126066861888 run_lib.py:133] step: 104600, training_loss: 2.08960e-02
I0215 07:25:41.764131 23126066861888 run_lib.py:146] step: 104600, eval_loss: 2.53156e-02
I0215 07:25:59.160696 23126066861888 run_lib.py:133] step: 104650, training_loss: 2.15515e-02
I0215 07:26:16.395051 23126066861888 run_lib.py:133] step: 104700, training_loss: 2.09794e-02
I0215 07:26:16.549066 23126066861888 run_lib.py:146] step: 104700, eval_loss: 2.51174e-02
I0215 07:26:33.817307 23126066861888 run_lib.py:133] step: 104750, training_loss: 2.11908e-02
I0215 07:26:51.070356 23126066861888 run_lib.py:133] step: 104800, training_loss: 2.01064e-02
I0215 07:26:51.219913 23126066861888 run_lib.py:146] step: 104800, eval_loss: 2.45575e-02
I0215 07:27:08.686654 23126066861888 run_lib.py:133] step: 104850, training_loss: 2.04231e-02
I0215 07:27:26.080408 23126066861888 run_lib.py:133] step: 104900, training_loss: 2.10982e-02
I0215 07:27:26.242209 23126066861888 run_lib.py:146] step: 104900, eval_loss: 2.50536e-02
I0215 07:27:43.490329 23126066861888 run_lib.py:133] step: 104950, training_loss: 2.05670e-02
I0215 07:28:00.780381 23126066861888 run_lib.py:133] step: 105000, training_loss: 2.21141e-02
I0215 07:28:00.936298 23126066861888 run_lib.py:146] step: 105000, eval_loss: 2.52104e-02
I0215 07:28:18.369292 23126066861888 run_lib.py:133] step: 105050, training_loss: 2.14260e-02
I0215 07:28:35.634057 23126066861888 run_lib.py:133] step: 105100, training_loss: 2.10230e-02
I0215 07:28:35.790022 23126066861888 run_lib.py:146] step: 105100, eval_loss: 2.53764e-02
I0215 07:28:53.089570 23126066861888 run_lib.py:133] step: 105150, training_loss: 2.04304e-02
I0215 07:29:10.541887 23126066861888 run_lib.py:133] step: 105200, training_loss: 2.12432e-02
I0215 07:29:10.696243 23126066861888 run_lib.py:146] step: 105200, eval_loss: 2.43043e-02
I0215 07:29:27.989378 23126066861888 run_lib.py:133] step: 105250, training_loss: 2.09738e-02
I0215 07:29:45.410888 23126066861888 run_lib.py:133] step: 105300, training_loss: 2.12714e-02
I0215 07:29:45.560899 23126066861888 run_lib.py:146] step: 105300, eval_loss: 2.51683e-02
I0215 07:30:02.848399 23126066861888 run_lib.py:133] step: 105350, training_loss: 2.12767e-02
I0215 07:30:20.118319 23126066861888 run_lib.py:133] step: 105400, training_loss: 2.12103e-02
I0215 07:30:20.289211 23126066861888 run_lib.py:146] step: 105400, eval_loss: 2.58924e-02
I0215 07:30:37.817081 23126066861888 run_lib.py:133] step: 105450, training_loss: 2.09027e-02
I0215 07:30:55.082543 23126066861888 run_lib.py:133] step: 105500, training_loss: 2.09217e-02
I0215 07:30:55.243016 23126066861888 run_lib.py:146] step: 105500, eval_loss: 2.51018e-02
I0215 07:31:12.478815 23126066861888 run_lib.py:133] step: 105550, training_loss: 2.07692e-02
I0215 07:31:29.899501 23126066861888 run_lib.py:133] step: 105600, training_loss: 2.08637e-02
I0215 07:31:30.059983 23126066861888 run_lib.py:146] step: 105600, eval_loss: 2.45759e-02
I0215 07:31:47.331697 23126066861888 run_lib.py:133] step: 105650, training_loss: 2.12543e-02
I0215 07:32:04.659125 23126066861888 run_lib.py:133] step: 105700, training_loss: 2.02321e-02
I0215 07:32:04.811715 23126066861888 run_lib.py:146] step: 105700, eval_loss: 2.54719e-02
I0215 07:32:22.239020 23126066861888 run_lib.py:133] step: 105750, training_loss: 2.11371e-02
I0215 07:32:39.462033 23126066861888 run_lib.py:133] step: 105800, training_loss: 2.20324e-02
I0215 07:32:39.614032 23126066861888 run_lib.py:146] step: 105800, eval_loss: 2.49809e-02
I0215 07:32:56.875102 23126066861888 run_lib.py:133] step: 105850, training_loss: 2.11140e-02
I0215 07:33:14.123496 23126066861888 run_lib.py:133] step: 105900, training_loss: 2.09968e-02
I0215 07:33:14.280378 23126066861888 run_lib.py:146] step: 105900, eval_loss: 2.53544e-02
I0215 07:33:31.722109 23126066861888 run_lib.py:133] step: 105950, training_loss: 2.08519e-02
I0215 07:33:49.137135 23126066861888 run_lib.py:133] step: 106000, training_loss: 2.07525e-02
I0215 07:33:49.290971 23126066861888 run_lib.py:146] step: 106000, eval_loss: 2.50625e-02
I0215 07:34:06.547042 23126066861888 run_lib.py:133] step: 106050, training_loss: 2.06780e-02
I0215 07:34:23.839089 23126066861888 run_lib.py:133] step: 106100, training_loss: 2.17162e-02
I0215 07:34:23.993015 23126066861888 run_lib.py:146] step: 106100, eval_loss: 2.45787e-02
I0215 07:34:41.362190 23126066861888 run_lib.py:133] step: 106150, training_loss: 2.03776e-02
I0215 07:34:58.596893 23126066861888 run_lib.py:133] step: 106200, training_loss: 2.07337e-02
I0215 07:34:58.744003 23126066861888 run_lib.py:146] step: 106200, eval_loss: 2.53322e-02
I0215 07:35:16.067818 23126066861888 run_lib.py:133] step: 106250, training_loss: 2.10272e-02
I0215 07:35:33.507327 23126066861888 run_lib.py:133] step: 106300, training_loss: 2.11041e-02
I0215 07:35:33.662243 23126066861888 run_lib.py:146] step: 106300, eval_loss: 2.41218e-02
I0215 07:35:50.944977 23126066861888 run_lib.py:133] step: 106350, training_loss: 2.09750e-02
I0215 07:36:08.378054 23126066861888 run_lib.py:133] step: 106400, training_loss: 2.03001e-02
I0215 07:36:08.540153 23126066861888 run_lib.py:146] step: 106400, eval_loss: 2.53488e-02
I0215 07:36:25.830521 23126066861888 run_lib.py:133] step: 106450, training_loss: 2.03973e-02
I0215 07:36:43.055146 23126066861888 run_lib.py:133] step: 106500, training_loss: 2.05169e-02
I0215 07:36:43.209052 23126066861888 run_lib.py:146] step: 106500, eval_loss: 2.57919e-02
I0215 07:37:00.677139 23126066861888 run_lib.py:133] step: 106550, training_loss: 2.12896e-02
I0215 07:37:18.049240 23126066861888 run_lib.py:133] step: 106600, training_loss: 2.04478e-02
I0215 07:37:18.199599 23126066861888 run_lib.py:146] step: 106600, eval_loss: 2.52959e-02
I0215 07:37:35.489535 23126066861888 run_lib.py:133] step: 106650, training_loss: 2.15350e-02
I0215 07:37:52.936095 23126066861888 run_lib.py:133] step: 106700, training_loss: 2.09726e-02
I0215 07:37:53.086963 23126066861888 run_lib.py:146] step: 106700, eval_loss: 2.41275e-02
I0215 07:38:10.320055 23126066861888 run_lib.py:133] step: 106750, training_loss: 2.15293e-02
I0215 07:38:27.598863 23126066861888 run_lib.py:133] step: 106800, training_loss: 2.13376e-02
I0215 07:38:27.766201 23126066861888 run_lib.py:146] step: 106800, eval_loss: 2.59872e-02
I0215 07:38:45.158369 23126066861888 run_lib.py:133] step: 106850, training_loss: 2.08584e-02
I0215 07:39:02.444763 23126066861888 run_lib.py:133] step: 106900, training_loss: 2.07981e-02
I0215 07:39:02.601472 23126066861888 run_lib.py:146] step: 106900, eval_loss: 2.63031e-02
I0215 07:39:19.868623 23126066861888 run_lib.py:133] step: 106950, training_loss: 2.07811e-02
I0215 07:39:37.181227 23126066861888 run_lib.py:133] step: 107000, training_loss: 2.15592e-02
I0215 07:39:37.334893 23126066861888 run_lib.py:146] step: 107000, eval_loss: 2.61703e-02
I0215 07:39:54.807303 23126066861888 run_lib.py:133] step: 107050, training_loss: 2.16712e-02
I0215 07:40:12.109537 23126066861888 run_lib.py:133] step: 107100, training_loss: 2.14634e-02
I0215 07:40:12.261031 23126066861888 run_lib.py:146] step: 107100, eval_loss: 2.63062e-02
I0215 07:40:29.554824 23126066861888 run_lib.py:133] step: 107150, training_loss: 2.05049e-02
I0215 07:40:46.893732 23126066861888 run_lib.py:133] step: 107200, training_loss: 2.13207e-02
I0215 07:40:47.047339 23126066861888 run_lib.py:146] step: 107200, eval_loss: 2.61270e-02
I0215 07:41:04.520336 23126066861888 run_lib.py:133] step: 107250, training_loss: 2.07525e-02
I0215 07:41:21.813677 23126066861888 run_lib.py:133] step: 107300, training_loss: 2.12355e-02
I0215 07:41:21.968102 23126066861888 run_lib.py:146] step: 107300, eval_loss: 2.46656e-02
I0215 07:41:39.215221 23126066861888 run_lib.py:133] step: 107350, training_loss: 2.10023e-02
I0215 07:41:56.613348 23126066861888 run_lib.py:133] step: 107400, training_loss: 2.07598e-02
I0215 07:41:56.775274 23126066861888 run_lib.py:146] step: 107400, eval_loss: 2.45995e-02
I0215 07:42:14.075578 23126066861888 run_lib.py:133] step: 107450, training_loss: 2.01146e-02
I0215 07:42:31.535211 23126066861888 run_lib.py:133] step: 107500, training_loss: 2.14626e-02
I0215 07:42:31.692193 23126066861888 run_lib.py:146] step: 107500, eval_loss: 2.56357e-02
I0215 07:42:48.947990 23126066861888 run_lib.py:133] step: 107550, training_loss: 2.11788e-02
I0215 07:43:06.240234 23126066861888 run_lib.py:133] step: 107600, training_loss: 2.08561e-02
I0215 07:43:06.391944 23126066861888 run_lib.py:146] step: 107600, eval_loss: 2.49036e-02
I0215 07:43:23.850538 23126066861888 run_lib.py:133] step: 107650, training_loss: 2.11659e-02
I0215 07:43:41.172660 23126066861888 run_lib.py:133] step: 107700, training_loss: 2.09718e-02
I0215 07:43:41.326294 23126066861888 run_lib.py:146] step: 107700, eval_loss: 2.64055e-02
I0215 07:43:58.647325 23126066861888 run_lib.py:133] step: 107750, training_loss: 2.10194e-02
I0215 07:44:16.145336 23126066861888 run_lib.py:133] step: 107800, training_loss: 1.97208e-02
I0215 07:44:16.306525 23126066861888 run_lib.py:146] step: 107800, eval_loss: 2.49760e-02
I0215 07:44:33.566460 23126066861888 run_lib.py:133] step: 107850, training_loss: 2.09998e-02
I0215 07:44:50.806279 23126066861888 run_lib.py:133] step: 107900, training_loss: 2.07649e-02
I0215 07:44:50.963222 23126066861888 run_lib.py:146] step: 107900, eval_loss: 2.50270e-02
I0215 07:45:08.345494 23126066861888 run_lib.py:133] step: 107950, training_loss: 2.08507e-02
I0215 07:45:25.705038 23126066861888 run_lib.py:133] step: 108000, training_loss: 2.13535e-02
I0215 07:45:25.856720 23126066861888 run_lib.py:146] step: 108000, eval_loss: 2.45769e-02
I0215 07:45:43.111082 23126066861888 run_lib.py:133] step: 108050, training_loss: 2.04967e-02
I0215 07:46:00.360523 23126066861888 run_lib.py:133] step: 108100, training_loss: 2.10420e-02
I0215 07:46:00.510973 23126066861888 run_lib.py:146] step: 108100, eval_loss: 2.50698e-02
I0215 07:46:17.957888 23126066861888 run_lib.py:133] step: 108150, training_loss: 2.09574e-02
I0215 07:46:35.281682 23126066861888 run_lib.py:133] step: 108200, training_loss: 2.02801e-02
I0215 07:46:35.441198 23126066861888 run_lib.py:146] step: 108200, eval_loss: 2.59544e-02
I0215 07:46:52.767186 23126066861888 run_lib.py:133] step: 108250, training_loss: 2.09027e-02
I0215 07:47:10.038135 23126066861888 run_lib.py:133] step: 108300, training_loss: 2.07291e-02
I0215 07:47:10.194986 23126066861888 run_lib.py:146] step: 108300, eval_loss: 2.50924e-02
I0215 07:47:27.638085 23126066861888 run_lib.py:133] step: 108350, training_loss: 2.15573e-02
I0215 07:47:44.881510 23126066861888 run_lib.py:133] step: 108400, training_loss: 2.12120e-02
I0215 07:47:45.035959 23126066861888 run_lib.py:146] step: 108400, eval_loss: 2.47143e-02
I0215 07:48:02.283244 23126066861888 run_lib.py:133] step: 108450, training_loss: 2.08092e-02
I0215 07:48:19.744485 23126066861888 run_lib.py:133] step: 108500, training_loss: 2.13502e-02
I0215 07:48:19.901755 23126066861888 run_lib.py:146] step: 108500, eval_loss: 2.66224e-02
I0215 07:48:37.214824 23126066861888 run_lib.py:133] step: 108550, training_loss: 2.06250e-02
I0215 07:48:54.643468 23126066861888 run_lib.py:133] step: 108600, training_loss: 2.17205e-02
I0215 07:48:54.792759 23126066861888 run_lib.py:146] step: 108600, eval_loss: 2.50855e-02
I0215 07:49:12.060054 23126066861888 run_lib.py:133] step: 108650, training_loss: 2.04523e-02
I0215 07:49:29.340763 23126066861888 run_lib.py:133] step: 108700, training_loss: 2.12480e-02
I0215 07:49:29.497997 23126066861888 run_lib.py:146] step: 108700, eval_loss: 2.48639e-02
I0215 07:49:46.893846 23126066861888 run_lib.py:133] step: 108750, training_loss: 2.06269e-02
I0215 07:50:04.204781 23126066861888 run_lib.py:133] step: 108800, training_loss: 2.19629e-02
I0215 07:50:04.365893 23126066861888 run_lib.py:146] step: 108800, eval_loss: 2.57692e-02
I0215 07:50:21.621381 23126066861888 run_lib.py:133] step: 108850, training_loss: 2.19867e-02
I0215 07:50:39.077427 23126066861888 run_lib.py:133] step: 108900, training_loss: 2.14435e-02
I0215 07:50:39.230939 23126066861888 run_lib.py:146] step: 108900, eval_loss: 2.51920e-02
I0215 07:50:56.511924 23126066861888 run_lib.py:133] step: 108950, training_loss: 2.08562e-02
I0215 07:51:13.774845 23126066861888 run_lib.py:133] step: 109000, training_loss: 2.12617e-02
I0215 07:51:13.930951 23126066861888 run_lib.py:146] step: 109000, eval_loss: 2.56273e-02
I0215 07:51:31.285490 23126066861888 run_lib.py:133] step: 109050, training_loss: 2.04275e-02
I0215 07:51:48.615812 23126066861888 run_lib.py:133] step: 109100, training_loss: 2.07302e-02
I0215 07:51:48.769178 23126066861888 run_lib.py:146] step: 109100, eval_loss: 2.55185e-02
I0215 07:52:06.063828 23126066861888 run_lib.py:133] step: 109150, training_loss: 2.06844e-02
I0215 07:52:23.337082 23126066861888 run_lib.py:133] step: 109200, training_loss: 2.06056e-02
I0215 07:52:23.490972 23126066861888 run_lib.py:146] step: 109200, eval_loss: 2.52902e-02
I0215 07:52:40.953310 23126066861888 run_lib.py:133] step: 109250, training_loss: 2.02282e-02
I0215 07:52:58.265946 23126066861888 run_lib.py:133] step: 109300, training_loss: 2.14394e-02
I0215 07:52:58.422977 23126066861888 run_lib.py:146] step: 109300, eval_loss: 2.49410e-02
I0215 07:53:15.748116 23126066861888 run_lib.py:133] step: 109350, training_loss: 2.13820e-02
I0215 07:53:33.037500 23126066861888 run_lib.py:133] step: 109400, training_loss: 2.14094e-02
I0215 07:53:33.191702 23126066861888 run_lib.py:146] step: 109400, eval_loss: 2.59756e-02
I0215 07:53:50.636151 23126066861888 run_lib.py:133] step: 109450, training_loss: 2.11082e-02
I0215 07:54:07.891049 23126066861888 run_lib.py:133] step: 109500, training_loss: 2.17274e-02
I0215 07:54:08.045014 23126066861888 run_lib.py:146] step: 109500, eval_loss: 2.55899e-02
I0215 07:54:25.286233 23126066861888 run_lib.py:133] step: 109550, training_loss: 2.14241e-02
I0215 07:54:42.700895 23126066861888 run_lib.py:133] step: 109600, training_loss: 2.10000e-02
I0215 07:54:42.854284 23126066861888 run_lib.py:146] step: 109600, eval_loss: 2.66849e-02
I0215 07:55:00.174473 23126066861888 run_lib.py:133] step: 109650, training_loss: 2.16301e-02
I0215 07:55:17.632435 23126066861888 run_lib.py:133] step: 109700, training_loss: 2.06762e-02
I0215 07:55:17.787971 23126066861888 run_lib.py:146] step: 109700, eval_loss: 2.45385e-02
I0215 07:55:35.044110 23126066861888 run_lib.py:133] step: 109750, training_loss: 2.05657e-02
I0215 07:55:52.289031 23126066861888 run_lib.py:133] step: 109800, training_loss: 1.96100e-02
I0215 07:55:52.443791 23126066861888 run_lib.py:146] step: 109800, eval_loss: 2.56804e-02
I0215 07:56:09.901904 23126066861888 run_lib.py:133] step: 109850, training_loss: 2.13118e-02
I0215 07:56:27.236892 23126066861888 run_lib.py:133] step: 109900, training_loss: 2.08939e-02
I0215 07:56:27.391423 23126066861888 run_lib.py:146] step: 109900, eval_loss: 2.49191e-02
I0215 07:56:44.720500 23126066861888 run_lib.py:133] step: 109950, training_loss: 2.17048e-02
I0215 07:57:02.179007 23126066861888 run_lib.py:133] step: 110000, training_loss: 2.04134e-02
I0215 07:57:02.851720 23126066861888 run_lib.py:146] step: 110000, eval_loss: 2.49530e-02
I0215 07:57:22.678411 23126066861888 run_lib.py:133] step: 110050, training_loss: 2.11629e-02
I0215 07:57:39.976109 23126066861888 run_lib.py:133] step: 110100, training_loss: 2.11643e-02
I0215 07:57:40.132106 23126066861888 run_lib.py:146] step: 110100, eval_loss: 2.42696e-02
I0215 07:57:57.427101 23126066861888 run_lib.py:133] step: 110150, training_loss: 2.18006e-02
I0215 07:58:14.916800 23126066861888 run_lib.py:133] step: 110200, training_loss: 2.13524e-02
I0215 07:58:15.084196 23126066861888 run_lib.py:146] step: 110200, eval_loss: 2.54803e-02
I0215 07:58:32.350493 23126066861888 run_lib.py:133] step: 110250, training_loss: 2.13350e-02
I0215 07:58:49.691543 23126066861888 run_lib.py:133] step: 110300, training_loss: 2.09294e-02
I0215 07:58:49.848227 23126066861888 run_lib.py:146] step: 110300, eval_loss: 2.55314e-02
I0215 07:59:07.101421 23126066861888 run_lib.py:133] step: 110350, training_loss: 2.07368e-02
I0215 07:59:24.533313 23126066861888 run_lib.py:133] step: 110400, training_loss: 2.12446e-02
I0215 07:59:24.686975 23126066861888 run_lib.py:146] step: 110400, eval_loss: 2.45235e-02
I0215 07:59:42.043688 23126066861888 run_lib.py:133] step: 110450, training_loss: 2.07531e-02
I0215 07:59:59.386886 23126066861888 run_lib.py:133] step: 110500, training_loss: 2.10651e-02
I0215 07:59:59.557134 23126066861888 run_lib.py:146] step: 110500, eval_loss: 2.47399e-02
I0215 08:00:16.845191 23126066861888 run_lib.py:133] step: 110550, training_loss: 2.09893e-02
I0215 08:00:34.065190 23126066861888 run_lib.py:133] step: 110600, training_loss: 2.03782e-02
I0215 08:00:34.219532 23126066861888 run_lib.py:146] step: 110600, eval_loss: 2.55750e-02
I0215 08:00:51.685099 23126066861888 run_lib.py:133] step: 110650, training_loss: 2.06490e-02
I0215 08:01:08.980587 23126066861888 run_lib.py:133] step: 110700, training_loss: 2.02075e-02
I0215 08:01:09.139679 23126066861888 run_lib.py:146] step: 110700, eval_loss: 2.56756e-02
I0215 08:01:26.601408 23126066861888 run_lib.py:133] step: 110750, training_loss: 2.00029e-02
I0215 08:01:43.903319 23126066861888 run_lib.py:133] step: 110800, training_loss: 2.08526e-02
I0215 08:01:44.060155 23126066861888 run_lib.py:146] step: 110800, eval_loss: 2.53065e-02
I0215 08:02:01.536975 23126066861888 run_lib.py:133] step: 110850, training_loss: 2.08329e-02
I0215 08:02:18.789979 23126066861888 run_lib.py:133] step: 110900, training_loss: 2.10126e-02
I0215 08:02:18.950981 23126066861888 run_lib.py:146] step: 110900, eval_loss: 2.50130e-02
I0215 08:02:36.214440 23126066861888 run_lib.py:133] step: 110950, training_loss: 2.00327e-02
I0215 08:02:53.642760 23126066861888 run_lib.py:133] step: 111000, training_loss: 2.06082e-02
I0215 08:02:53.804221 23126066861888 run_lib.py:146] step: 111000, eval_loss: 2.64282e-02
I0215 08:03:11.135399 23126066861888 run_lib.py:133] step: 111050, training_loss: 2.10833e-02
I0215 08:03:28.590226 23126066861888 run_lib.py:133] step: 111100, training_loss: 2.04945e-02
I0215 08:03:28.741923 23126066861888 run_lib.py:146] step: 111100, eval_loss: 2.51243e-02
I0215 08:03:45.963363 23126066861888 run_lib.py:133] step: 111150, training_loss: 2.09062e-02
I0215 08:04:03.253638 23126066861888 run_lib.py:133] step: 111200, training_loss: 2.01719e-02
I0215 08:04:03.412221 23126066861888 run_lib.py:146] step: 111200, eval_loss: 2.51029e-02
I0215 08:04:20.707043 23126066861888 run_lib.py:133] step: 111250, training_loss: 2.03289e-02
I0215 08:04:38.160443 23126066861888 run_lib.py:133] step: 111300, training_loss: 2.07578e-02
I0215 08:04:38.315198 23126066861888 run_lib.py:146] step: 111300, eval_loss: 2.45166e-02
I0215 08:04:55.600417 23126066861888 run_lib.py:133] step: 111350, training_loss: 2.10891e-02
I0215 08:05:12.817272 23126066861888 run_lib.py:133] step: 111400, training_loss: 2.06903e-02
I0215 08:05:12.976024 23126066861888 run_lib.py:146] step: 111400, eval_loss: 2.59117e-02
I0215 08:05:30.427960 23126066861888 run_lib.py:133] step: 111450, training_loss: 2.12731e-02
I0215 08:05:47.662472 23126066861888 run_lib.py:133] step: 111500, training_loss: 2.06893e-02
I0215 08:05:47.811670 23126066861888 run_lib.py:146] step: 111500, eval_loss: 2.58925e-02
I0215 08:06:05.112866 23126066861888 run_lib.py:133] step: 111550, training_loss: 2.03072e-02
I0215 08:06:22.427607 23126066861888 run_lib.py:133] step: 111600, training_loss: 2.01824e-02
I0215 08:06:22.587155 23126066861888 run_lib.py:146] step: 111600, eval_loss: 2.54609e-02
I0215 08:06:39.889393 23126066861888 run_lib.py:133] step: 111650, training_loss: 2.10015e-02
I0215 08:06:57.225047 23126066861888 run_lib.py:133] step: 111700, training_loss: 2.07711e-02
I0215 08:06:57.402078 23126066861888 run_lib.py:146] step: 111700, eval_loss: 2.55175e-02
I0215 08:07:14.849573 23126066861888 run_lib.py:133] step: 111750, training_loss: 2.04976e-02
I0215 08:07:32.169100 23126066861888 run_lib.py:133] step: 111800, training_loss: 2.03482e-02
I0215 08:07:32.321970 23126066861888 run_lib.py:146] step: 111800, eval_loss: 2.51724e-02
I0215 08:07:49.575202 23126066861888 run_lib.py:133] step: 111850, training_loss: 2.16202e-02
I0215 08:08:06.936788 23126066861888 run_lib.py:133] step: 111900, training_loss: 2.15659e-02
I0215 08:08:07.091241 23126066861888 run_lib.py:146] step: 111900, eval_loss: 2.52604e-02
I0215 08:08:24.538356 23126066861888 run_lib.py:133] step: 111950, training_loss: 2.02946e-02
I0215 08:08:41.809274 23126066861888 run_lib.py:133] step: 112000, training_loss: 2.11819e-02
I0215 08:08:41.967226 23126066861888 run_lib.py:146] step: 112000, eval_loss: 2.46324e-02
I0215 08:08:59.245956 23126066861888 run_lib.py:133] step: 112050, training_loss: 2.03476e-02
I0215 08:09:16.680064 23126066861888 run_lib.py:133] step: 112100, training_loss: 2.04847e-02
I0215 08:09:16.846250 23126066861888 run_lib.py:146] step: 112100, eval_loss: 2.63337e-02
I0215 08:09:34.188689 23126066861888 run_lib.py:133] step: 112150, training_loss: 2.04548e-02
I0215 08:09:51.657881 23126066861888 run_lib.py:133] step: 112200, training_loss: 2.08157e-02
I0215 08:09:51.812917 23126066861888 run_lib.py:146] step: 112200, eval_loss: 2.62661e-02
I0215 08:10:09.066415 23126066861888 run_lib.py:133] step: 112250, training_loss: 2.07325e-02
I0215 08:10:26.344618 23126066861888 run_lib.py:133] step: 112300, training_loss: 2.08757e-02
I0215 08:10:26.497987 23126066861888 run_lib.py:146] step: 112300, eval_loss: 2.55312e-02
I0215 08:10:43.911081 23126066861888 run_lib.py:133] step: 112350, training_loss: 2.06184e-02
I0215 08:11:01.216100 23126066861888 run_lib.py:133] step: 112400, training_loss: 2.07289e-02
I0215 08:11:01.368767 23126066861888 run_lib.py:146] step: 112400, eval_loss: 2.49767e-02
I0215 08:11:18.696305 23126066861888 run_lib.py:133] step: 112450, training_loss: 2.05092e-02
I0215 08:11:35.968200 23126066861888 run_lib.py:133] step: 112500, training_loss: 2.10945e-02
I0215 08:11:36.118945 23126066861888 run_lib.py:146] step: 112500, eval_loss: 2.54581e-02
I0215 08:11:53.575826 23126066861888 run_lib.py:133] step: 112550, training_loss: 2.06545e-02
I0215 08:12:10.828583 23126066861888 run_lib.py:133] step: 112600, training_loss: 2.13308e-02
I0215 08:12:10.983108 23126066861888 run_lib.py:146] step: 112600, eval_loss: 2.58570e-02
I0215 08:12:28.322645 23126066861888 run_lib.py:133] step: 112650, training_loss: 2.13007e-02
I0215 08:12:45.603261 23126066861888 run_lib.py:133] step: 112700, training_loss: 2.06339e-02
I0215 08:12:45.773926 23126066861888 run_lib.py:146] step: 112700, eval_loss: 2.52352e-02
I0215 08:13:03.074331 23126066861888 run_lib.py:133] step: 112750, training_loss: 2.08293e-02
I0215 08:13:20.361395 23126066861888 run_lib.py:133] step: 112800, training_loss: 2.04812e-02
I0215 08:13:20.516086 23126066861888 run_lib.py:146] step: 112800, eval_loss: 2.60547e-02
I0215 08:13:37.975494 23126066861888 run_lib.py:133] step: 112850, training_loss: 2.10093e-02
I0215 08:13:55.287095 23126066861888 run_lib.py:133] step: 112900, training_loss: 2.10151e-02
I0215 08:13:55.441737 23126066861888 run_lib.py:146] step: 112900, eval_loss: 2.54436e-02
I0215 08:14:12.682117 23126066861888 run_lib.py:133] step: 112950, training_loss: 2.14648e-02
I0215 08:14:29.987227 23126066861888 run_lib.py:133] step: 113000, training_loss: 2.13293e-02
I0215 08:14:30.144209 23126066861888 run_lib.py:146] step: 113000, eval_loss: 2.48792e-02
I0215 08:14:47.659579 23126066861888 run_lib.py:133] step: 113050, training_loss: 2.06661e-02
I0215 08:15:04.972993 23126066861888 run_lib.py:133] step: 113100, training_loss: 2.08284e-02
I0215 08:15:05.129140 23126066861888 run_lib.py:146] step: 113100, eval_loss: 2.50240e-02
I0215 08:15:22.369402 23126066861888 run_lib.py:133] step: 113150, training_loss: 2.08766e-02
I0215 08:15:39.745520 23126066861888 run_lib.py:133] step: 113200, training_loss: 2.04603e-02
I0215 08:15:39.903960 23126066861888 run_lib.py:146] step: 113200, eval_loss: 2.62695e-02
I0215 08:15:57.253702 23126066861888 run_lib.py:133] step: 113250, training_loss: 2.08162e-02
I0215 08:16:14.723668 23126066861888 run_lib.py:133] step: 113300, training_loss: 2.15138e-02
I0215 08:16:14.910745 23126066861888 run_lib.py:146] step: 113300, eval_loss: 2.58245e-02
I0215 08:16:32.194325 23126066861888 run_lib.py:133] step: 113350, training_loss: 2.08393e-02
I0215 08:16:49.446378 23126066861888 run_lib.py:133] step: 113400, training_loss: 2.07969e-02
I0215 08:16:49.600735 23126066861888 run_lib.py:146] step: 113400, eval_loss: 2.54189e-02
I0215 08:17:07.022057 23126066861888 run_lib.py:133] step: 113450, training_loss: 2.08897e-02
I0215 08:17:24.307560 23126066861888 run_lib.py:133] step: 113500, training_loss: 2.11778e-02
I0215 08:17:24.471181 23126066861888 run_lib.py:146] step: 113500, eval_loss: 2.71094e-02
I0215 08:17:41.734941 23126066861888 run_lib.py:133] step: 113550, training_loss: 2.13541e-02
I0215 08:17:59.217849 23126066861888 run_lib.py:133] step: 113600, training_loss: 2.12696e-02
I0215 08:17:59.376209 23126066861888 run_lib.py:146] step: 113600, eval_loss: 2.63994e-02
I0215 08:18:16.673076 23126066861888 run_lib.py:133] step: 113650, training_loss: 2.13062e-02
I0215 08:18:33.886708 23126066861888 run_lib.py:133] step: 113700, training_loss: 2.15351e-02
I0215 08:18:34.039996 23126066861888 run_lib.py:146] step: 113700, eval_loss: 2.50045e-02
I0215 08:18:51.351250 23126066861888 run_lib.py:133] step: 113750, training_loss: 2.13169e-02
I0215 08:19:08.664878 23126066861888 run_lib.py:133] step: 113800, training_loss: 2.06951e-02
I0215 08:19:08.819200 23126066861888 run_lib.py:146] step: 113800, eval_loss: 2.53687e-02
I0215 08:19:26.091684 23126066861888 run_lib.py:133] step: 113850, training_loss: 2.09840e-02
I0215 08:19:43.313129 23126066861888 run_lib.py:133] step: 113900, training_loss: 2.01396e-02
I0215 08:19:43.470032 23126066861888 run_lib.py:146] step: 113900, eval_loss: 2.65878e-02
I0215 08:20:00.886075 23126066861888 run_lib.py:133] step: 113950, training_loss: 2.08328e-02
I0215 08:20:18.219134 23126066861888 run_lib.py:133] step: 114000, training_loss: 2.08107e-02
I0215 08:20:18.372986 23126066861888 run_lib.py:146] step: 114000, eval_loss: 2.48235e-02
I0215 08:20:35.614542 23126066861888 run_lib.py:133] step: 114050, training_loss: 2.11279e-02
I0215 08:20:52.900525 23126066861888 run_lib.py:133] step: 114100, training_loss: 2.02743e-02
I0215 08:20:53.060933 23126066861888 run_lib.py:146] step: 114100, eval_loss: 2.50975e-02
I0215 08:21:10.520560 23126066861888 run_lib.py:133] step: 114150, training_loss: 2.06413e-02
I0215 08:21:27.771331 23126066861888 run_lib.py:133] step: 114200, training_loss: 2.08413e-02
I0215 08:21:27.924959 23126066861888 run_lib.py:146] step: 114200, eval_loss: 2.48028e-02
I0215 08:21:45.180137 23126066861888 run_lib.py:133] step: 114250, training_loss: 2.11331e-02
I0215 08:22:02.562625 23126066861888 run_lib.py:133] step: 114300, training_loss: 2.08714e-02
I0215 08:22:02.715014 23126066861888 run_lib.py:146] step: 114300, eval_loss: 2.69315e-02
I0215 08:22:19.961361 23126066861888 run_lib.py:133] step: 114350, training_loss: 1.97938e-02
I0215 08:22:37.416195 23126066861888 run_lib.py:133] step: 114400, training_loss: 2.14552e-02
I0215 08:22:37.570168 23126066861888 run_lib.py:146] step: 114400, eval_loss: 2.52187e-02
I0215 08:22:54.830781 23126066861888 run_lib.py:133] step: 114450, training_loss: 2.11316e-02
I0215 08:23:12.125456 23126066861888 run_lib.py:133] step: 114500, training_loss: 2.12838e-02
I0215 08:23:12.281279 23126066861888 run_lib.py:146] step: 114500, eval_loss: 2.46738e-02
I0215 08:23:29.737227 23126066861888 run_lib.py:133] step: 114550, training_loss: 2.08682e-02
I0215 08:23:46.978281 23126066861888 run_lib.py:133] step: 114600, training_loss: 2.07985e-02
I0215 08:23:47.134029 23126066861888 run_lib.py:146] step: 114600, eval_loss: 2.54893e-02
I0215 08:24:04.418922 23126066861888 run_lib.py:133] step: 114650, training_loss: 1.99058e-02
I0215 08:24:21.949866 23126066861888 run_lib.py:133] step: 114700, training_loss: 2.08656e-02
I0215 08:24:22.104162 23126066861888 run_lib.py:146] step: 114700, eval_loss: 2.53320e-02
I0215 08:24:39.395345 23126066861888 run_lib.py:133] step: 114750, training_loss: 2.02644e-02
I0215 08:24:56.616984 23126066861888 run_lib.py:133] step: 114800, training_loss: 2.14661e-02
I0215 08:24:56.769718 23126066861888 run_lib.py:146] step: 114800, eval_loss: 2.52670e-02
I0215 08:25:14.059951 23126066861888 run_lib.py:133] step: 114850, training_loss: 2.08386e-02
I0215 08:25:31.308128 23126066861888 run_lib.py:133] step: 114900, training_loss: 2.10047e-02
I0215 08:25:31.479156 23126066861888 run_lib.py:146] step: 114900, eval_loss: 2.60293e-02
I0215 08:25:48.827789 23126066861888 run_lib.py:133] step: 114950, training_loss: 2.13158e-02
I0215 08:26:06.106452 23126066861888 run_lib.py:133] step: 115000, training_loss: 2.10352e-02
I0215 08:26:06.261922 23126066861888 run_lib.py:146] step: 115000, eval_loss: 2.68337e-02
I0215 08:26:23.703277 23126066861888 run_lib.py:133] step: 115050, training_loss: 2.05567e-02
I0215 08:26:41.005967 23126066861888 run_lib.py:133] step: 115100, training_loss: 2.16292e-02
I0215 08:26:41.159000 23126066861888 run_lib.py:146] step: 115100, eval_loss: 2.52263e-02
I0215 08:26:58.406033 23126066861888 run_lib.py:133] step: 115150, training_loss: 2.13186e-02
I0215 08:27:15.691656 23126066861888 run_lib.py:133] step: 115200, training_loss: 2.07144e-02
I0215 08:27:15.845382 23126066861888 run_lib.py:146] step: 115200, eval_loss: 2.58811e-02
I0215 08:27:33.299274 23126066861888 run_lib.py:133] step: 115250, training_loss: 2.09480e-02
I0215 08:27:50.580188 23126066861888 run_lib.py:133] step: 115300, training_loss: 2.02606e-02
I0215 08:27:50.729022 23126066861888 run_lib.py:146] step: 115300, eval_loss: 2.52721e-02
I0215 08:28:07.980436 23126066861888 run_lib.py:133] step: 115350, training_loss: 2.09380e-02
I0215 08:28:25.442845 23126066861888 run_lib.py:133] step: 115400, training_loss: 2.16356e-02
I0215 08:28:25.597136 23126066861888 run_lib.py:146] step: 115400, eval_loss: 2.55577e-02
I0215 08:28:42.840052 23126066861888 run_lib.py:133] step: 115450, training_loss: 2.05829e-02
I0215 08:29:00.268747 23126066861888 run_lib.py:133] step: 115500, training_loss: 2.05680e-02
I0215 08:29:00.438978 23126066861888 run_lib.py:146] step: 115500, eval_loss: 2.59856e-02
I0215 08:29:17.736705 23126066861888 run_lib.py:133] step: 115550, training_loss: 2.12999e-02
I0215 08:29:35.035304 23126066861888 run_lib.py:133] step: 115600, training_loss: 2.08798e-02
I0215 08:29:35.189155 23126066861888 run_lib.py:146] step: 115600, eval_loss: 2.54710e-02
I0215 08:29:52.687448 23126066861888 run_lib.py:133] step: 115650, training_loss: 2.12525e-02
I0215 08:30:09.942535 23126066861888 run_lib.py:133] step: 115700, training_loss: 2.08869e-02
I0215 08:30:10.094738 23126066861888 run_lib.py:146] step: 115700, eval_loss: 2.54909e-02
I0215 08:30:27.335601 23126066861888 run_lib.py:133] step: 115750, training_loss: 2.04483e-02
I0215 08:30:44.817497 23126066861888 run_lib.py:133] step: 115800, training_loss: 2.00329e-02
I0215 08:30:44.971190 23126066861888 run_lib.py:146] step: 115800, eval_loss: 2.55242e-02
I0215 08:31:02.259590 23126066861888 run_lib.py:133] step: 115850, training_loss: 2.05277e-02
I0215 08:31:19.519830 23126066861888 run_lib.py:133] step: 115900, training_loss: 2.02542e-02
I0215 08:31:19.679965 23126066861888 run_lib.py:146] step: 115900, eval_loss: 2.51175e-02
I0215 08:31:37.044200 23126066861888 run_lib.py:133] step: 115950, training_loss: 2.06601e-02
I0215 08:31:54.321968 23126066861888 run_lib.py:133] step: 116000, training_loss: 2.06996e-02
I0215 08:31:54.481151 23126066861888 run_lib.py:146] step: 116000, eval_loss: 2.46359e-02
I0215 08:32:11.753960 23126066861888 run_lib.py:133] step: 116050, training_loss: 2.18653e-02
I0215 08:32:29.077950 23126066861888 run_lib.py:133] step: 116100, training_loss: 2.05143e-02
I0215 08:32:29.234174 23126066861888 run_lib.py:146] step: 116100, eval_loss: 2.51537e-02
I0215 08:32:46.705222 23126066861888 run_lib.py:133] step: 116150, training_loss: 2.06305e-02
I0215 08:33:04.105627 23126066861888 run_lib.py:133] step: 116200, training_loss: 2.13501e-02
I0215 08:33:04.256898 23126066861888 run_lib.py:146] step: 116200, eval_loss: 2.56689e-02
I0215 08:33:21.507009 23126066861888 run_lib.py:133] step: 116250, training_loss: 2.08003e-02
I0215 08:33:38.761450 23126066861888 run_lib.py:133] step: 116300, training_loss: 2.14026e-02
I0215 08:33:38.911989 23126066861888 run_lib.py:146] step: 116300, eval_loss: 2.49802e-02
I0215 08:33:56.321551 23126066861888 run_lib.py:133] step: 116350, training_loss: 2.05827e-02
I0215 08:34:13.640262 23126066861888 run_lib.py:133] step: 116400, training_loss: 2.10079e-02
I0215 08:34:13.823997 23126066861888 run_lib.py:146] step: 116400, eval_loss: 2.55121e-02
I0215 08:34:31.106454 23126066861888 run_lib.py:133] step: 116450, training_loss: 2.06832e-02
I0215 08:34:48.630500 23126066861888 run_lib.py:133] step: 116500, training_loss: 1.94368e-02
I0215 08:34:48.800081 23126066861888 run_lib.py:146] step: 116500, eval_loss: 2.54969e-02
I0215 08:35:06.084649 23126066861888 run_lib.py:133] step: 116550, training_loss: 2.07770e-02
I0215 08:35:23.508905 23126066861888 run_lib.py:133] step: 116600, training_loss: 2.09481e-02
I0215 08:35:23.662784 23126066861888 run_lib.py:146] step: 116600, eval_loss: 2.57849e-02
I0215 08:35:40.989880 23126066861888 run_lib.py:133] step: 116650, training_loss: 2.00786e-02
I0215 08:35:58.290490 23126066861888 run_lib.py:133] step: 116700, training_loss: 1.96012e-02
I0215 08:35:58.442717 23126066861888 run_lib.py:146] step: 116700, eval_loss: 2.53425e-02
I0215 08:36:15.912482 23126066861888 run_lib.py:133] step: 116750, training_loss: 2.03855e-02
I0215 08:36:33.195106 23126066861888 run_lib.py:133] step: 116800, training_loss: 2.07801e-02
I0215 08:36:33.350853 23126066861888 run_lib.py:146] step: 116800, eval_loss: 2.51989e-02
I0215 08:36:50.586472 23126066861888 run_lib.py:133] step: 116850, training_loss: 2.07341e-02
I0215 08:37:08.000917 23126066861888 run_lib.py:133] step: 116900, training_loss: 2.08290e-02
I0215 08:37:08.156973 23126066861888 run_lib.py:146] step: 116900, eval_loss: 2.51732e-02
I0215 08:37:25.535531 23126066861888 run_lib.py:133] step: 116950, training_loss: 2.05479e-02
I0215 08:37:42.830463 23126066861888 run_lib.py:133] step: 117000, training_loss: 2.11132e-02
I0215 08:37:42.989207 23126066861888 run_lib.py:146] step: 117000, eval_loss: 2.65963e-02
I0215 08:38:00.310501 23126066861888 run_lib.py:133] step: 117050, training_loss: 2.12458e-02
I0215 08:38:17.574652 23126066861888 run_lib.py:133] step: 117100, training_loss: 2.07112e-02
I0215 08:38:17.728120 23126066861888 run_lib.py:146] step: 117100, eval_loss: 2.55764e-02
I0215 08:38:35.012550 23126066861888 run_lib.py:133] step: 117150, training_loss: 2.06517e-02
I0215 08:38:52.305762 23126066861888 run_lib.py:133] step: 117200, training_loss: 2.14957e-02
I0215 08:38:52.456746 23126066861888 run_lib.py:146] step: 117200, eval_loss: 2.59688e-02
I0215 08:39:09.915808 23126066861888 run_lib.py:133] step: 117250, training_loss: 2.08246e-02
I0215 08:39:27.308563 23126066861888 run_lib.py:133] step: 117300, training_loss: 2.08668e-02
I0215 08:39:27.462236 23126066861888 run_lib.py:146] step: 117300, eval_loss: 2.54240e-02
I0215 08:39:44.748014 23126066861888 run_lib.py:133] step: 117350, training_loss: 2.03339e-02
I0215 08:40:02.014354 23126066861888 run_lib.py:133] step: 117400, training_loss: 2.03334e-02
I0215 08:40:02.171143 23126066861888 run_lib.py:146] step: 117400, eval_loss: 2.54243e-02
I0215 08:40:19.567932 23126066861888 run_lib.py:133] step: 117450, training_loss: 2.07058e-02
I0215 08:40:36.852153 23126066861888 run_lib.py:133] step: 117500, training_loss: 2.06615e-02
I0215 08:40:37.018574 23126066861888 run_lib.py:146] step: 117500, eval_loss: 2.56490e-02
I0215 08:40:54.344522 23126066861888 run_lib.py:133] step: 117550, training_loss: 2.07719e-02
I0215 08:41:11.809942 23126066861888 run_lib.py:133] step: 117600, training_loss: 2.15815e-02
I0215 08:41:11.962214 23126066861888 run_lib.py:146] step: 117600, eval_loss: 2.53781e-02
I0215 08:41:29.186277 23126066861888 run_lib.py:133] step: 117650, training_loss: 2.09601e-02
I0215 08:41:46.570497 23126066861888 run_lib.py:133] step: 117700, training_loss: 2.12256e-02
I0215 08:41:46.720981 23126066861888 run_lib.py:146] step: 117700, eval_loss: 2.43867e-02
I0215 08:42:03.961509 23126066861888 run_lib.py:133] step: 117750, training_loss: 2.08946e-02
I0215 08:42:21.225927 23126066861888 run_lib.py:133] step: 117800, training_loss: 2.09585e-02
I0215 08:42:21.391933 23126066861888 run_lib.py:146] step: 117800, eval_loss: 2.54225e-02
I0215 08:42:38.871994 23126066861888 run_lib.py:133] step: 117850, training_loss: 2.08227e-02
I0215 08:42:56.153190 23126066861888 run_lib.py:133] step: 117900, training_loss: 2.13756e-02
I0215 08:42:56.308975 23126066861888 run_lib.py:146] step: 117900, eval_loss: 2.58193e-02
I0215 08:43:13.565277 23126066861888 run_lib.py:133] step: 117950, training_loss: 2.03827e-02
I0215 08:43:30.959068 23126066861888 run_lib.py:133] step: 118000, training_loss: 2.00992e-02
I0215 08:43:31.113037 23126066861888 run_lib.py:146] step: 118000, eval_loss: 2.55873e-02
I0215 08:43:48.359629 23126066861888 run_lib.py:133] step: 118050, training_loss: 2.09824e-02
I0215 08:44:05.658569 23126066861888 run_lib.py:133] step: 118100, training_loss: 2.07692e-02
I0215 08:44:05.825217 23126066861888 run_lib.py:146] step: 118100, eval_loss: 2.47178e-02
I0215 08:44:23.221492 23126066861888 run_lib.py:133] step: 118150, training_loss: 1.99292e-02
I0215 08:44:40.486598 23126066861888 run_lib.py:133] step: 118200, training_loss: 2.07268e-02
I0215 08:44:40.637002 23126066861888 run_lib.py:146] step: 118200, eval_loss: 2.65040e-02
I0215 08:44:57.890892 23126066861888 run_lib.py:133] step: 118250, training_loss: 2.12714e-02
I0215 08:45:15.148346 23126066861888 run_lib.py:133] step: 118300, training_loss: 2.03916e-02
I0215 08:45:15.305448 23126066861888 run_lib.py:146] step: 118300, eval_loss: 2.58643e-02
I0215 08:45:32.692088 23126066861888 run_lib.py:133] step: 118350, training_loss: 2.09820e-02
I0215 08:45:50.126169 23126066861888 run_lib.py:133] step: 118400, training_loss: 2.01741e-02
I0215 08:45:50.280039 23126066861888 run_lib.py:146] step: 118400, eval_loss: 2.65132e-02
I0215 08:46:07.561846 23126066861888 run_lib.py:133] step: 118450, training_loss: 2.03988e-02
I0215 08:46:24.803119 23126066861888 run_lib.py:133] step: 118500, training_loss: 1.99763e-02
I0215 08:46:24.957944 23126066861888 run_lib.py:146] step: 118500, eval_loss: 2.56843e-02
I0215 08:46:42.423156 23126066861888 run_lib.py:133] step: 118550, training_loss: 2.07022e-02
I0215 08:46:59.683166 23126066861888 run_lib.py:133] step: 118600, training_loss: 2.06837e-02
I0215 08:46:59.834667 23126066861888 run_lib.py:146] step: 118600, eval_loss: 2.50863e-02
I0215 08:47:17.147976 23126066861888 run_lib.py:133] step: 118650, training_loss: 2.07839e-02
I0215 08:47:34.609607 23126066861888 run_lib.py:133] step: 118700, training_loss: 2.11884e-02
I0215 08:47:34.761955 23126066861888 run_lib.py:146] step: 118700, eval_loss: 2.52090e-02
I0215 08:47:52.011255 23126066861888 run_lib.py:133] step: 118750, training_loss: 2.05129e-02
I0215 08:48:09.423186 23126066861888 run_lib.py:133] step: 118800, training_loss: 1.97299e-02
I0215 08:48:09.587090 23126066861888 run_lib.py:146] step: 118800, eval_loss: 2.58179e-02
I0215 08:48:26.801965 23126066861888 run_lib.py:133] step: 118850, training_loss: 2.06510e-02
I0215 08:48:44.034057 23126066861888 run_lib.py:133] step: 118900, training_loss: 2.04580e-02
I0215 08:48:44.199918 23126066861888 run_lib.py:146] step: 118900, eval_loss: 2.62910e-02
I0215 08:49:01.718182 23126066861888 run_lib.py:133] step: 118950, training_loss: 2.02337e-02
I0215 08:49:18.997285 23126066861888 run_lib.py:133] step: 119000, training_loss: 1.98763e-02
I0215 08:49:19.151182 23126066861888 run_lib.py:146] step: 119000, eval_loss: 2.46922e-02
I0215 08:49:36.437826 23126066861888 run_lib.py:133] step: 119050, training_loss: 2.09863e-02
I0215 08:49:53.892771 23126066861888 run_lib.py:133] step: 119100, training_loss: 2.08658e-02
I0215 08:49:54.040409 23126066861888 run_lib.py:146] step: 119100, eval_loss: 2.59587e-02
I0215 08:50:11.280380 23126066861888 run_lib.py:133] step: 119150, training_loss: 2.02137e-02
I0215 08:50:28.539450 23126066861888 run_lib.py:133] step: 119200, training_loss: 2.02084e-02
I0215 08:50:28.706206 23126066861888 run_lib.py:146] step: 119200, eval_loss: 2.43786e-02
I0215 08:50:46.094365 23126066861888 run_lib.py:133] step: 119250, training_loss: 2.05272e-02
I0215 08:51:03.413938 23126066861888 run_lib.py:133] step: 119300, training_loss: 2.07902e-02
I0215 08:51:03.569008 23126066861888 run_lib.py:146] step: 119300, eval_loss: 2.53369e-02
I0215 08:51:20.833917 23126066861888 run_lib.py:133] step: 119350, training_loss: 2.06787e-02
I0215 08:51:38.081509 23126066861888 run_lib.py:133] step: 119400, training_loss: 2.08990e-02
I0215 08:51:38.239007 23126066861888 run_lib.py:146] step: 119400, eval_loss: 2.67450e-02
I0215 08:51:55.694425 23126066861888 run_lib.py:133] step: 119450, training_loss: 2.08811e-02
I0215 08:52:13.053150 23126066861888 run_lib.py:133] step: 119500, training_loss: 2.02997e-02
I0215 08:52:13.207344 23126066861888 run_lib.py:146] step: 119500, eval_loss: 2.52207e-02
I0215 08:52:30.497745 23126066861888 run_lib.py:133] step: 119550, training_loss: 2.06379e-02
I0215 08:52:47.761996 23126066861888 run_lib.py:133] step: 119600, training_loss: 2.11403e-02
I0215 08:52:47.917968 23126066861888 run_lib.py:146] step: 119600, eval_loss: 2.56883e-02
I0215 08:53:05.362055 23126066861888 run_lib.py:133] step: 119650, training_loss: 2.03776e-02
I0215 08:53:22.640312 23126066861888 run_lib.py:133] step: 119700, training_loss: 2.06791e-02
I0215 08:53:22.843921 23126066861888 run_lib.py:146] step: 119700, eval_loss: 2.54795e-02
I0215 08:53:40.090766 23126066861888 run_lib.py:133] step: 119750, training_loss: 2.11718e-02
I0215 08:53:57.500641 23126066861888 run_lib.py:133] step: 119800, training_loss: 2.05118e-02
I0215 08:53:57.676970 23126066861888 run_lib.py:146] step: 119800, eval_loss: 2.47813e-02
I0215 08:54:15.010293 23126066861888 run_lib.py:133] step: 119850, training_loss: 2.12669e-02
I0215 08:54:32.472837 23126066861888 run_lib.py:133] step: 119900, training_loss: 2.12308e-02
I0215 08:54:32.629144 23126066861888 run_lib.py:146] step: 119900, eval_loss: 2.49277e-02
I0215 08:54:49.908283 23126066861888 run_lib.py:133] step: 119950, training_loss: 2.12688e-02
I0215 08:55:07.147216 23126066861888 run_lib.py:133] step: 120000, training_loss: 2.06365e-02
I0215 08:55:07.820806 23126066861888 run_lib.py:146] step: 120000, eval_loss: 2.53389e-02
I0215 08:55:27.868945 23126066861888 run_lib.py:133] step: 120050, training_loss: 2.13369e-02
I0215 08:55:45.189667 23126066861888 run_lib.py:133] step: 120100, training_loss: 2.08655e-02
I0215 08:55:45.342122 23126066861888 run_lib.py:146] step: 120100, eval_loss: 2.53304e-02
I0215 08:56:02.617197 23126066861888 run_lib.py:133] step: 120150, training_loss: 2.05613e-02
I0215 08:56:20.095460 23126066861888 run_lib.py:133] step: 120200, training_loss: 2.05037e-02
I0215 08:56:20.255557 23126066861888 run_lib.py:146] step: 120200, eval_loss: 2.37033e-02
I0215 08:56:37.498676 23126066861888 run_lib.py:133] step: 120250, training_loss: 2.01187e-02
I0215 08:56:54.790251 23126066861888 run_lib.py:133] step: 120300, training_loss: 2.05424e-02
I0215 08:56:54.944389 23126066861888 run_lib.py:146] step: 120300, eval_loss: 2.56260e-02
I0215 08:57:12.370936 23126066861888 run_lib.py:133] step: 120350, training_loss: 2.08113e-02
I0215 08:57:29.719661 23126066861888 run_lib.py:133] step: 120400, training_loss: 2.02926e-02
I0215 08:57:29.874182 23126066861888 run_lib.py:146] step: 120400, eval_loss: 2.55886e-02
I0215 08:57:47.378312 23126066861888 run_lib.py:133] step: 120450, training_loss: 2.12513e-02
I0215 08:58:04.664643 23126066861888 run_lib.py:133] step: 120500, training_loss: 2.01367e-02
I0215 08:58:04.817744 23126066861888 run_lib.py:146] step: 120500, eval_loss: 2.52891e-02
I0215 08:58:22.147245 23126066861888 run_lib.py:133] step: 120550, training_loss: 2.04707e-02
I0215 08:58:39.539221 23126066861888 run_lib.py:133] step: 120600, training_loss: 2.10654e-02
I0215 08:58:39.688702 23126066861888 run_lib.py:146] step: 120600, eval_loss: 2.62789e-02
I0215 08:58:56.954280 23126066861888 run_lib.py:133] step: 120650, training_loss: 2.02902e-02
I0215 08:59:14.255971 23126066861888 run_lib.py:133] step: 120700, training_loss: 2.00179e-02
I0215 08:59:14.425219 23126066861888 run_lib.py:146] step: 120700, eval_loss: 2.56554e-02
I0215 08:59:31.703455 23126066861888 run_lib.py:133] step: 120750, training_loss: 2.01751e-02
I0215 08:59:48.981437 23126066861888 run_lib.py:133] step: 120800, training_loss: 2.02489e-02
I0215 08:59:49.146139 23126066861888 run_lib.py:146] step: 120800, eval_loss: 2.59772e-02
I0215 09:00:06.565462 23126066861888 run_lib.py:133] step: 120850, training_loss: 2.15719e-02
I0215 09:00:23.880886 23126066861888 run_lib.py:133] step: 120900, training_loss: 2.04711e-02
I0215 09:00:24.039036 23126066861888 run_lib.py:146] step: 120900, eval_loss: 2.62068e-02
I0215 09:00:41.323260 23126066861888 run_lib.py:133] step: 120950, training_loss: 2.03480e-02
I0215 09:00:58.650150 23126066861888 run_lib.py:133] step: 121000, training_loss: 2.01860e-02
I0215 09:00:58.801321 23126066861888 run_lib.py:146] step: 121000, eval_loss: 2.57414e-02
I0215 09:01:16.277934 23126066861888 run_lib.py:133] step: 121050, training_loss: 2.02669e-02
I0215 09:01:33.533088 23126066861888 run_lib.py:133] step: 121100, training_loss: 2.01605e-02
I0215 09:01:33.685016 23126066861888 run_lib.py:146] step: 121100, eval_loss: 2.63066e-02
I0215 09:01:51.041815 23126066861888 run_lib.py:133] step: 121150, training_loss: 1.97705e-02
I0215 09:02:08.288399 23126066861888 run_lib.py:133] step: 121200, training_loss: 2.05359e-02
I0215 09:02:08.446218 23126066861888 run_lib.py:146] step: 121200, eval_loss: 2.58025e-02
I0215 09:02:25.788088 23126066861888 run_lib.py:133] step: 121250, training_loss: 2.04067e-02
I0215 09:02:43.250416 23126066861888 run_lib.py:133] step: 121300, training_loss: 2.03933e-02
I0215 09:02:43.405979 23126066861888 run_lib.py:146] step: 121300, eval_loss: 2.54182e-02
I0215 09:03:00.657930 23126066861888 run_lib.py:133] step: 121350, training_loss: 2.02098e-02
I0215 09:03:17.899181 23126066861888 run_lib.py:133] step: 121400, training_loss: 2.06222e-02
I0215 09:03:18.052885 23126066861888 run_lib.py:146] step: 121400, eval_loss: 2.65212e-02
I0215 09:03:35.482500 23126066861888 run_lib.py:133] step: 121450, training_loss: 2.11322e-02
I0215 09:03:52.724814 23126066861888 run_lib.py:133] step: 121500, training_loss: 2.07514e-02
I0215 09:03:52.878244 23126066861888 run_lib.py:146] step: 121500, eval_loss: 2.65458e-02
I0215 09:04:10.179306 23126066861888 run_lib.py:133] step: 121550, training_loss: 2.04543e-02
I0215 09:04:27.652843 23126066861888 run_lib.py:133] step: 121600, training_loss: 2.04144e-02
I0215 09:04:27.800106 23126066861888 run_lib.py:146] step: 121600, eval_loss: 2.48976e-02
I0215 09:04:45.074822 23126066861888 run_lib.py:133] step: 121650, training_loss: 2.10200e-02
I0215 09:05:02.318418 23126066861888 run_lib.py:133] step: 121700, training_loss: 2.12674e-02
I0215 09:05:02.472211 23126066861888 run_lib.py:146] step: 121700, eval_loss: 2.57056e-02
I0215 09:05:19.767438 23126066861888 run_lib.py:133] step: 121750, training_loss: 2.22706e-02
I0215 09:05:37.029004 23126066861888 run_lib.py:133] step: 121800, training_loss: 2.04031e-02
I0215 09:05:37.194025 23126066861888 run_lib.py:146] step: 121800, eval_loss: 2.60128e-02
I0215 09:05:54.533293 23126066861888 run_lib.py:133] step: 121850, training_loss: 2.05710e-02
I0215 09:06:11.781283 23126066861888 run_lib.py:133] step: 121900, training_loss: 2.00507e-02
I0215 09:06:11.935056 23126066861888 run_lib.py:146] step: 121900, eval_loss: 2.56835e-02
I0215 09:06:29.367440 23126066861888 run_lib.py:133] step: 121950, training_loss: 2.03409e-02
I0215 09:06:46.698296 23126066861888 run_lib.py:133] step: 122000, training_loss: 2.04319e-02
I0215 09:06:46.848033 23126066861888 run_lib.py:146] step: 122000, eval_loss: 2.50437e-02
I0215 09:07:04.088559 23126066861888 run_lib.py:133] step: 122050, training_loss: 2.01355e-02
I0215 09:07:21.369128 23126066861888 run_lib.py:133] step: 122100, training_loss: 2.10029e-02
I0215 09:07:21.530233 23126066861888 run_lib.py:146] step: 122100, eval_loss: 2.58185e-02
I0215 09:07:38.983596 23126066861888 run_lib.py:133] step: 122150, training_loss: 2.04478e-02
I0215 09:07:56.263372 23126066861888 run_lib.py:133] step: 122200, training_loss: 2.02431e-02
I0215 09:07:56.419197 23126066861888 run_lib.py:146] step: 122200, eval_loss: 2.52180e-02
I0215 09:08:13.667494 23126066861888 run_lib.py:133] step: 122250, training_loss: 2.10702e-02
I0215 09:08:31.074629 23126066861888 run_lib.py:133] step: 122300, training_loss: 2.08755e-02
I0215 09:08:31.248096 23126066861888 run_lib.py:146] step: 122300, eval_loss: 2.56762e-02
I0215 09:08:48.541092 23126066861888 run_lib.py:133] step: 122350, training_loss: 1.96437e-02
I0215 09:09:05.969663 23126066861888 run_lib.py:133] step: 122400, training_loss: 2.00634e-02
I0215 09:09:06.124197 23126066861888 run_lib.py:146] step: 122400, eval_loss: 2.60847e-02
I0215 09:09:23.409626 23126066861888 run_lib.py:133] step: 122450, training_loss: 2.02700e-02
I0215 09:09:40.670992 23126066861888 run_lib.py:133] step: 122500, training_loss: 1.98727e-02
I0215 09:09:40.821036 23126066861888 run_lib.py:146] step: 122500, eval_loss: 2.67801e-02
I0215 09:09:58.314034 23126066861888 run_lib.py:133] step: 122550, training_loss: 2.00686e-02
I0215 09:10:15.572045 23126066861888 run_lib.py:133] step: 122600, training_loss: 2.08850e-02
I0215 09:10:15.726153 23126066861888 run_lib.py:146] step: 122600, eval_loss: 2.52682e-02
I0215 09:10:33.016126 23126066861888 run_lib.py:133] step: 122650, training_loss: 2.08603e-02
I0215 09:10:50.474564 23126066861888 run_lib.py:133] step: 122700, training_loss: 2.02343e-02
I0215 09:10:50.630017 23126066861888 run_lib.py:146] step: 122700, eval_loss: 2.51686e-02
I0215 09:11:07.855118 23126066861888 run_lib.py:133] step: 122750, training_loss: 2.04628e-02
I0215 09:11:25.121726 23126066861888 run_lib.py:133] step: 122800, training_loss: 2.06699e-02
I0215 09:11:25.274969 23126066861888 run_lib.py:146] step: 122800, eval_loss: 2.49555e-02
I0215 09:11:42.621183 23126066861888 run_lib.py:133] step: 122850, training_loss: 2.11237e-02
I0215 09:11:59.882383 23126066861888 run_lib.py:133] step: 122900, training_loss: 2.07952e-02
I0215 09:12:00.043050 23126066861888 run_lib.py:146] step: 122900, eval_loss: 2.58665e-02
I0215 09:12:17.332050 23126066861888 run_lib.py:133] step: 122950, training_loss: 2.06038e-02
I0215 09:12:34.627366 23126066861888 run_lib.py:133] step: 123000, training_loss: 2.02954e-02
I0215 09:12:34.781121 23126066861888 run_lib.py:146] step: 123000, eval_loss: 2.52356e-02
I0215 09:12:52.233034 23126066861888 run_lib.py:133] step: 123050, training_loss: 2.06560e-02
I0215 09:13:09.551739 23126066861888 run_lib.py:133] step: 123100, training_loss: 2.07722e-02
I0215 09:13:09.704769 23126066861888 run_lib.py:146] step: 123100, eval_loss: 2.51401e-02
I0215 09:13:26.939937 23126066861888 run_lib.py:133] step: 123150, training_loss: 2.11242e-02
I0215 09:13:44.240293 23126066861888 run_lib.py:133] step: 123200, training_loss: 2.06756e-02
I0215 09:13:44.412942 23126066861888 run_lib.py:146] step: 123200, eval_loss: 2.58802e-02
I0215 09:14:01.894469 23126066861888 run_lib.py:133] step: 123250, training_loss: 2.04690e-02
I0215 09:14:19.111769 23126066861888 run_lib.py:133] step: 123300, training_loss: 2.08497e-02
I0215 09:14:19.266164 23126066861888 run_lib.py:146] step: 123300, eval_loss: 2.55972e-02
I0215 09:14:36.521302 23126066861888 run_lib.py:133] step: 123350, training_loss: 2.11577e-02
I0215 09:14:53.923181 23126066861888 run_lib.py:133] step: 123400, training_loss: 1.99042e-02
I0215 09:14:54.074971 23126066861888 run_lib.py:146] step: 123400, eval_loss: 2.55332e-02
I0215 09:15:11.327947 23126066861888 run_lib.py:133] step: 123450, training_loss: 2.01594e-02
I0215 09:15:28.763168 23126066861888 run_lib.py:133] step: 123500, training_loss: 2.13462e-02
I0215 09:15:28.924199 23126066861888 run_lib.py:146] step: 123500, eval_loss: 2.44492e-02
I0215 09:15:46.203614 23126066861888 run_lib.py:133] step: 123550, training_loss: 2.02610e-02
I0215 09:16:03.488666 23126066861888 run_lib.py:133] step: 123600, training_loss: 2.07480e-02
I0215 09:16:03.644060 23126066861888 run_lib.py:146] step: 123600, eval_loss: 2.54244e-02
I0215 09:16:21.078060 23126066861888 run_lib.py:133] step: 123650, training_loss: 2.01650e-02
I0215 09:16:38.335932 23126066861888 run_lib.py:133] step: 123700, training_loss: 2.07877e-02
I0215 09:16:38.490021 23126066861888 run_lib.py:146] step: 123700, eval_loss: 2.60073e-02
I0215 09:16:55.753401 23126066861888 run_lib.py:133] step: 123750, training_loss: 2.05872e-02
I0215 09:17:13.321197 23126066861888 run_lib.py:133] step: 123800, training_loss: 2.00189e-02
I0215 09:17:13.473508 23126066861888 run_lib.py:146] step: 123800, eval_loss: 2.56932e-02
I0215 09:17:30.764924 23126066861888 run_lib.py:133] step: 123850, training_loss: 2.01715e-02
I0215 09:17:48.017166 23126066861888 run_lib.py:133] step: 123900, training_loss: 2.01524e-02
I0215 09:17:48.170036 23126066861888 run_lib.py:146] step: 123900, eval_loss: 2.48736e-02
I0215 09:18:05.535249 23126066861888 run_lib.py:133] step: 123950, training_loss: 2.07996e-02
I0215 09:18:22.830777 23126066861888 run_lib.py:133] step: 124000, training_loss: 2.09571e-02
I0215 09:18:22.987965 23126066861888 run_lib.py:146] step: 124000, eval_loss: 2.51106e-02
I0215 09:18:40.250053 23126066861888 run_lib.py:133] step: 124050, training_loss: 1.97502e-02
I0215 09:18:57.552201 23126066861888 run_lib.py:133] step: 124100, training_loss: 2.03115e-02
I0215 09:18:57.724016 23126066861888 run_lib.py:146] step: 124100, eval_loss: 2.58610e-02
I0215 09:19:15.188310 23126066861888 run_lib.py:133] step: 124150, training_loss: 2.06402e-02
I0215 09:19:32.583039 23126066861888 run_lib.py:133] step: 124200, training_loss: 2.07638e-02
I0215 09:19:32.736202 23126066861888 run_lib.py:146] step: 124200, eval_loss: 2.64004e-02
I0215 09:19:50.003301 23126066861888 run_lib.py:133] step: 124250, training_loss: 2.03735e-02
I0215 09:20:07.252187 23126066861888 run_lib.py:133] step: 124300, training_loss: 2.00591e-02
I0215 09:20:07.408045 23126066861888 run_lib.py:146] step: 124300, eval_loss: 2.55167e-02
I0215 09:20:24.872539 23126066861888 run_lib.py:133] step: 124350, training_loss: 2.09309e-02
I0215 09:20:42.155225 23126066861888 run_lib.py:133] step: 124400, training_loss: 2.07158e-02
I0215 09:20:42.314319 23126066861888 run_lib.py:146] step: 124400, eval_loss: 2.62860e-02
I0215 09:20:59.586662 23126066861888 run_lib.py:133] step: 124450, training_loss: 2.08332e-02
I0215 09:21:17.024068 23126066861888 run_lib.py:133] step: 124500, training_loss: 2.07846e-02
I0215 09:21:17.177974 23126066861888 run_lib.py:146] step: 124500, eval_loss: 2.52421e-02
I0215 09:21:34.400050 23126066861888 run_lib.py:133] step: 124550, training_loss: 2.06039e-02
I0215 09:21:51.830154 23126066861888 run_lib.py:133] step: 124600, training_loss: 2.08652e-02
I0215 09:21:52.003984 23126066861888 run_lib.py:146] step: 124600, eval_loss: 2.60229e-02
I0215 09:22:09.285379 23126066861888 run_lib.py:133] step: 124650, training_loss: 2.00459e-02
I0215 09:22:26.597794 23126066861888 run_lib.py:133] step: 124700, training_loss: 2.03387e-02
I0215 09:22:26.754252 23126066861888 run_lib.py:146] step: 124700, eval_loss: 2.63661e-02
I0215 09:22:44.226504 23126066861888 run_lib.py:133] step: 124750, training_loss: 2.07648e-02
I0215 09:23:01.511289 23126066861888 run_lib.py:133] step: 124800, training_loss: 2.04990e-02
I0215 09:23:01.669944 23126066861888 run_lib.py:146] step: 124800, eval_loss: 2.46865e-02
I0215 09:23:18.941455 23126066861888 run_lib.py:133] step: 124850, training_loss: 2.10636e-02
I0215 09:23:36.365311 23126066861888 run_lib.py:133] step: 124900, training_loss: 2.09294e-02
I0215 09:23:36.518273 23126066861888 run_lib.py:146] step: 124900, eval_loss: 2.52090e-02
I0215 09:23:53.817515 23126066861888 run_lib.py:133] step: 124950, training_loss: 2.17135e-02
I0215 09:24:11.092690 23126066861888 run_lib.py:133] step: 125000, training_loss: 2.06197e-02
I0215 09:24:11.246032 23126066861888 run_lib.py:146] step: 125000, eval_loss: 2.48705e-02
I0215 09:24:28.612336 23126066861888 run_lib.py:133] step: 125050, training_loss: 2.03203e-02
I0215 09:24:45.850830 23126066861888 run_lib.py:133] step: 125100, training_loss: 2.03899e-02
I0215 09:24:46.006333 23126066861888 run_lib.py:146] step: 125100, eval_loss: 2.65522e-02
I0215 09:25:03.289107 23126066861888 run_lib.py:133] step: 125150, training_loss: 2.13631e-02
I0215 09:25:20.543442 23126066861888 run_lib.py:133] step: 125200, training_loss: 2.07281e-02
I0215 09:25:20.700984 23126066861888 run_lib.py:146] step: 125200, eval_loss: 2.57663e-02
I0215 09:25:38.159981 23126066861888 run_lib.py:133] step: 125250, training_loss: 1.99142e-02
I0215 09:25:55.572003 23126066861888 run_lib.py:133] step: 125300, training_loss: 2.00396e-02
I0215 09:25:55.723691 23126066861888 run_lib.py:146] step: 125300, eval_loss: 2.64676e-02
I0215 09:26:13.042767 23126066861888 run_lib.py:133] step: 125350, training_loss: 2.07798e-02
I0215 09:26:30.295712 23126066861888 run_lib.py:133] step: 125400, training_loss: 2.03212e-02
I0215 09:26:30.443997 23126066861888 run_lib.py:146] step: 125400, eval_loss: 2.61231e-02
I0215 09:26:47.842965 23126066861888 run_lib.py:133] step: 125450, training_loss: 1.98678e-02
I0215 09:27:05.088675 23126066861888 run_lib.py:133] step: 125500, training_loss: 1.97396e-02
I0215 09:27:05.268014 23126066861888 run_lib.py:146] step: 125500, eval_loss: 2.47744e-02
I0215 09:27:22.587483 23126066861888 run_lib.py:133] step: 125550, training_loss: 2.04673e-02
I0215 09:27:40.064518 23126066861888 run_lib.py:133] step: 125600, training_loss: 2.02389e-02
I0215 09:27:40.218237 23126066861888 run_lib.py:146] step: 125600, eval_loss: 2.61482e-02
I0215 09:27:57.466046 23126066861888 run_lib.py:133] step: 125650, training_loss: 2.02910e-02
I0215 09:28:14.861438 23126066861888 run_lib.py:133] step: 125700, training_loss: 1.99628e-02
I0215 09:28:15.013743 23126066861888 run_lib.py:146] step: 125700, eval_loss: 2.52546e-02
I0215 09:28:32.320414 23126066861888 run_lib.py:133] step: 125750, training_loss: 2.09421e-02
I0215 09:28:49.661717 23126066861888 run_lib.py:133] step: 125800, training_loss: 2.01163e-02
I0215 09:28:49.813050 23126066861888 run_lib.py:146] step: 125800, eval_loss: 2.61317e-02
I0215 09:29:07.387288 23126066861888 run_lib.py:133] step: 125850, training_loss: 1.99242e-02
I0215 09:29:24.779543 23126066861888 run_lib.py:133] step: 125900, training_loss: 2.10597e-02
I0215 09:29:24.931986 23126066861888 run_lib.py:146] step: 125900, eval_loss: 2.58521e-02
I0215 09:29:42.298359 23126066861888 run_lib.py:133] step: 125950, training_loss: 2.05854e-02
I0215 09:29:59.834589 23126066861888 run_lib.py:133] step: 126000, training_loss: 2.07391e-02
I0215 09:29:59.988352 23126066861888 run_lib.py:146] step: 126000, eval_loss: 2.56494e-02
I0215 09:30:17.381830 23126066861888 run_lib.py:133] step: 126050, training_loss: 1.96825e-02
I0215 09:30:34.865174 23126066861888 run_lib.py:133] step: 126100, training_loss: 2.10027e-02
I0215 09:30:35.022477 23126066861888 run_lib.py:146] step: 126100, eval_loss: 2.56296e-02
I0215 09:30:52.561600 23126066861888 run_lib.py:133] step: 126150, training_loss: 2.03056e-02
I0215 09:31:09.974985 23126066861888 run_lib.py:133] step: 126200, training_loss: 1.99850e-02
I0215 09:31:10.134914 23126066861888 run_lib.py:146] step: 126200, eval_loss: 2.52288e-02
I0215 09:31:27.526295 23126066861888 run_lib.py:133] step: 126250, training_loss: 2.07392e-02
I0215 09:31:44.940011 23126066861888 run_lib.py:133] step: 126300, training_loss: 2.03613e-02
I0215 09:31:45.090930 23126066861888 run_lib.py:146] step: 126300, eval_loss: 2.45081e-02
I0215 09:32:02.597548 23126066861888 run_lib.py:133] step: 126350, training_loss: 2.02809e-02
I0215 09:32:20.097030 23126066861888 run_lib.py:133] step: 126400, training_loss: 2.06698e-02
I0215 09:32:20.262631 23126066861888 run_lib.py:146] step: 126400, eval_loss: 2.62436e-02
I0215 09:32:37.665453 23126066861888 run_lib.py:133] step: 126450, training_loss: 2.10726e-02
I0215 09:32:55.045974 23126066861888 run_lib.py:133] step: 126500, training_loss: 2.15306e-02
I0215 09:32:55.202042 23126066861888 run_lib.py:146] step: 126500, eval_loss: 2.52632e-02
I0215 09:33:12.743227 23126066861888 run_lib.py:133] step: 126550, training_loss: 2.00964e-02
I0215 09:33:30.066341 23126066861888 run_lib.py:133] step: 126600, training_loss: 1.98339e-02
I0215 09:33:30.222030 23126066861888 run_lib.py:146] step: 126600, eval_loss: 2.58339e-02
I0215 09:33:47.569542 23126066861888 run_lib.py:133] step: 126650, training_loss: 2.09233e-02
I0215 09:34:05.091671 23126066861888 run_lib.py:133] step: 126700, training_loss: 2.05810e-02
I0215 09:34:05.279737 23126066861888 run_lib.py:146] step: 126700, eval_loss: 2.58516e-02
I0215 09:34:22.710299 23126066861888 run_lib.py:133] step: 126750, training_loss: 2.02910e-02
I0215 09:34:40.241832 23126066861888 run_lib.py:133] step: 126800, training_loss: 2.04788e-02
I0215 09:34:40.393095 23126066861888 run_lib.py:146] step: 126800, eval_loss: 2.66415e-02
I0215 09:34:57.759339 23126066861888 run_lib.py:133] step: 126850, training_loss: 2.09759e-02
I0215 09:35:15.176409 23126066861888 run_lib.py:133] step: 126900, training_loss: 2.00762e-02
I0215 09:35:15.338206 23126066861888 run_lib.py:146] step: 126900, eval_loss: 2.59682e-02
I0215 09:35:32.881823 23126066861888 run_lib.py:133] step: 126950, training_loss: 2.07727e-02
I0215 09:35:50.278066 23126066861888 run_lib.py:133] step: 127000, training_loss: 2.04094e-02
I0215 09:35:50.446186 23126066861888 run_lib.py:146] step: 127000, eval_loss: 2.62055e-02
I0215 09:36:07.859465 23126066861888 run_lib.py:133] step: 127050, training_loss: 2.10375e-02
I0215 09:36:25.476505 23126066861888 run_lib.py:133] step: 127100, training_loss: 2.00329e-02
I0215 09:36:25.627462 23126066861888 run_lib.py:146] step: 127100, eval_loss: 2.63809e-02
I0215 09:36:43.026478 23126066861888 run_lib.py:133] step: 127150, training_loss: 1.98972e-02
I0215 09:37:00.365901 23126066861888 run_lib.py:133] step: 127200, training_loss: 2.01432e-02
I0215 09:37:00.522321 23126066861888 run_lib.py:146] step: 127200, eval_loss: 2.46527e-02
I0215 09:37:17.958977 23126066861888 run_lib.py:133] step: 127250, training_loss: 2.02992e-02
I0215 09:37:35.385131 23126066861888 run_lib.py:133] step: 127300, training_loss: 2.08044e-02
I0215 09:37:35.541270 23126066861888 run_lib.py:146] step: 127300, eval_loss: 2.54615e-02
I0215 09:37:52.995656 23126066861888 run_lib.py:133] step: 127350, training_loss: 2.03490e-02
I0215 09:38:10.372482 23126066861888 run_lib.py:133] step: 127400, training_loss: 2.12380e-02
I0215 09:38:10.528031 23126066861888 run_lib.py:146] step: 127400, eval_loss: 2.56041e-02
I0215 09:38:28.130917 23126066861888 run_lib.py:133] step: 127450, training_loss: 2.04628e-02
I0215 09:38:45.546302 23126066861888 run_lib.py:133] step: 127500, training_loss: 1.98393e-02
I0215 09:38:45.703417 23126066861888 run_lib.py:146] step: 127500, eval_loss: 2.49764e-02
I0215 09:39:03.077616 23126066861888 run_lib.py:133] step: 127550, training_loss: 2.01682e-02
I0215 09:39:20.488218 23126066861888 run_lib.py:133] step: 127600, training_loss: 2.06253e-02
I0215 09:39:20.654217 23126066861888 run_lib.py:146] step: 127600, eval_loss: 2.57756e-02
I0215 09:39:38.299976 23126066861888 run_lib.py:133] step: 127650, training_loss: 2.07129e-02
I0215 09:39:55.748591 23126066861888 run_lib.py:133] step: 127700, training_loss: 2.05728e-02
I0215 09:39:55.901980 23126066861888 run_lib.py:146] step: 127700, eval_loss: 2.56654e-02
I0215 09:40:13.250646 23126066861888 run_lib.py:133] step: 127750, training_loss: 2.00698e-02
I0215 09:40:30.802768 23126066861888 run_lib.py:133] step: 127800, training_loss: 1.99902e-02
I0215 09:40:30.958068 23126066861888 run_lib.py:146] step: 127800, eval_loss: 2.59234e-02
I0215 09:40:48.351762 23126066861888 run_lib.py:133] step: 127850, training_loss: 2.03362e-02
I0215 09:41:05.986323 23126066861888 run_lib.py:133] step: 127900, training_loss: 2.04774e-02
I0215 09:41:06.143140 23126066861888 run_lib.py:146] step: 127900, eval_loss: 2.52771e-02
I0215 09:41:23.555857 23126066861888 run_lib.py:133] step: 127950, training_loss: 2.03410e-02
I0215 09:41:40.941112 23126066861888 run_lib.py:133] step: 128000, training_loss: 2.03626e-02
I0215 09:41:41.096252 23126066861888 run_lib.py:146] step: 128000, eval_loss: 2.55728e-02
I0215 09:41:58.702317 23126066861888 run_lib.py:133] step: 128050, training_loss: 2.08893e-02
I0215 09:42:16.121726 23126066861888 run_lib.py:133] step: 128100, training_loss: 2.10647e-02
I0215 09:42:16.275221 23126066861888 run_lib.py:146] step: 128100, eval_loss: 2.63986e-02
I0215 09:42:33.662039 23126066861888 run_lib.py:133] step: 128150, training_loss: 2.09269e-02
I0215 09:42:51.263639 23126066861888 run_lib.py:133] step: 128200, training_loss: 1.92953e-02
I0215 09:42:51.421798 23126066861888 run_lib.py:146] step: 128200, eval_loss: 2.54224e-02
I0215 09:43:08.886810 23126066861888 run_lib.py:133] step: 128250, training_loss: 1.98231e-02
I0215 09:43:26.277540 23126066861888 run_lib.py:133] step: 128300, training_loss: 2.01438e-02
I0215 09:43:26.431058 23126066861888 run_lib.py:146] step: 128300, eval_loss: 2.52722e-02
I0215 09:43:43.958027 23126066861888 run_lib.py:133] step: 128350, training_loss: 2.00137e-02
I0215 09:44:01.324064 23126066861888 run_lib.py:133] step: 128400, training_loss: 1.97293e-02
I0215 09:44:01.481221 23126066861888 run_lib.py:146] step: 128400, eval_loss: 2.61278e-02
I0215 09:44:18.886786 23126066861888 run_lib.py:133] step: 128450, training_loss: 2.04889e-02
I0215 09:44:36.337086 23126066861888 run_lib.py:133] step: 128500, training_loss: 2.03600e-02
I0215 09:44:36.492524 23126066861888 run_lib.py:146] step: 128500, eval_loss: 2.49836e-02
I0215 09:44:54.048326 23126066861888 run_lib.py:133] step: 128550, training_loss: 2.02291e-02
I0215 09:45:11.506479 23126066861888 run_lib.py:133] step: 128600, training_loss: 2.02473e-02
I0215 09:45:11.659819 23126066861888 run_lib.py:146] step: 128600, eval_loss: 2.51292e-02
I0215 09:45:29.091945 23126066861888 run_lib.py:133] step: 128650, training_loss: 2.03157e-02
I0215 09:45:46.485647 23126066861888 run_lib.py:133] step: 128700, training_loss: 2.09161e-02
I0215 09:45:46.645085 23126066861888 run_lib.py:146] step: 128700, eval_loss: 2.60230e-02
I0215 09:46:04.147546 23126066861888 run_lib.py:133] step: 128750, training_loss: 2.00946e-02
I0215 09:46:21.566193 23126066861888 run_lib.py:133] step: 128800, training_loss: 2.05638e-02
I0215 09:46:21.739345 23126066861888 run_lib.py:146] step: 128800, eval_loss: 2.65413e-02
I0215 09:46:39.154855 23126066861888 run_lib.py:133] step: 128850, training_loss: 2.07376e-02
I0215 09:46:56.794197 23126066861888 run_lib.py:133] step: 128900, training_loss: 2.09546e-02
I0215 09:46:56.951155 23126066861888 run_lib.py:146] step: 128900, eval_loss: 2.62545e-02
I0215 09:47:14.333380 23126066861888 run_lib.py:133] step: 128950, training_loss: 1.99923e-02
I0215 09:47:31.834663 23126066861888 run_lib.py:133] step: 129000, training_loss: 2.02614e-02
I0215 09:47:31.991852 23126066861888 run_lib.py:146] step: 129000, eval_loss: 2.56044e-02
I0215 09:47:49.385007 23126066861888 run_lib.py:133] step: 129050, training_loss: 2.05393e-02
I0215 09:48:06.810442 23126066861888 run_lib.py:133] step: 129100, training_loss: 2.04336e-02
I0215 09:48:06.966620 23126066861888 run_lib.py:146] step: 129100, eval_loss: 2.63304e-02
I0215 09:48:24.574008 23126066861888 run_lib.py:133] step: 129150, training_loss: 2.01397e-02
I0215 09:48:41.960927 23126066861888 run_lib.py:133] step: 129200, training_loss: 2.06001e-02
I0215 09:48:42.113198 23126066861888 run_lib.py:146] step: 129200, eval_loss: 2.53365e-02
I0215 09:48:59.525632 23126066861888 run_lib.py:133] step: 129250, training_loss: 2.00613e-02
I0215 09:49:17.075843 23126066861888 run_lib.py:133] step: 129300, training_loss: 2.13760e-02
I0215 09:49:17.231004 23126066861888 run_lib.py:146] step: 129300, eval_loss: 2.53793e-02
I0215 09:49:34.628583 23126066861888 run_lib.py:133] step: 129350, training_loss: 2.05447e-02
I0215 09:49:52.072263 23126066861888 run_lib.py:133] step: 129400, training_loss: 1.99316e-02
I0215 09:49:52.224431 23126066861888 run_lib.py:146] step: 129400, eval_loss: 2.53081e-02
I0215 09:50:09.707367 23126066861888 run_lib.py:133] step: 129450, training_loss: 2.07992e-02
I0215 09:50:27.065308 23126066861888 run_lib.py:133] step: 129500, training_loss: 2.08374e-02
I0215 09:50:27.227930 23126066861888 run_lib.py:146] step: 129500, eval_loss: 2.58094e-02
I0215 09:50:44.595753 23126066861888 run_lib.py:133] step: 129550, training_loss: 1.98471e-02
I0215 09:51:01.961010 23126066861888 run_lib.py:133] step: 129600, training_loss: 2.07559e-02
I0215 09:51:02.117822 23126066861888 run_lib.py:146] step: 129600, eval_loss: 2.45868e-02
I0215 09:51:19.745232 23126066861888 run_lib.py:133] step: 129650, training_loss: 2.02959e-02
I0215 09:51:37.266290 23126066861888 run_lib.py:133] step: 129700, training_loss: 2.01479e-02
I0215 09:51:37.424026 23126066861888 run_lib.py:146] step: 129700, eval_loss: 2.65265e-02
I0215 09:51:54.832280 23126066861888 run_lib.py:133] step: 129750, training_loss: 2.06246e-02
I0215 09:52:12.241115 23126066861888 run_lib.py:133] step: 129800, training_loss: 2.12610e-02
I0215 09:52:12.398435 23126066861888 run_lib.py:146] step: 129800, eval_loss: 2.59231e-02
I0215 09:52:29.916316 23126066861888 run_lib.py:133] step: 129850, training_loss: 2.10085e-02
I0215 09:52:47.307139 23126066861888 run_lib.py:133] step: 129900, training_loss: 2.04378e-02
I0215 09:52:47.467265 23126066861888 run_lib.py:146] step: 129900, eval_loss: 2.61737e-02
I0215 09:53:04.895217 23126066861888 run_lib.py:133] step: 129950, training_loss: 2.06272e-02
I0215 09:53:22.454710 23126066861888 run_lib.py:133] step: 130000, training_loss: 2.05366e-02
I0215 09:53:23.137946 23126066861888 run_lib.py:146] step: 130000, eval_loss: 2.55357e-02
I0215 09:53:43.631405 23126066861888 run_lib.py:133] step: 130050, training_loss: 2.01133e-02
I0215 09:54:00.976236 23126066861888 run_lib.py:133] step: 130100, training_loss: 2.02411e-02
I0215 09:54:01.128000 23126066861888 run_lib.py:146] step: 130100, eval_loss: 2.47950e-02
I0215 09:54:18.623804 23126066861888 run_lib.py:133] step: 130150, training_loss: 1.97722e-02
I0215 09:54:36.128365 23126066861888 run_lib.py:133] step: 130200, training_loss: 2.07097e-02
I0215 09:54:36.283444 23126066861888 run_lib.py:146] step: 130200, eval_loss: 2.56103e-02
I0215 09:54:53.717794 23126066861888 run_lib.py:133] step: 130250, training_loss: 2.04574e-02
I0215 09:55:11.112176 23126066861888 run_lib.py:133] step: 130300, training_loss: 2.06420e-02
I0215 09:55:11.275766 23126066861888 run_lib.py:146] step: 130300, eval_loss: 2.49711e-02
I0215 09:55:28.834687 23126066861888 run_lib.py:133] step: 130350, training_loss: 2.02537e-02
I0215 09:55:46.194795 23126066861888 run_lib.py:133] step: 130400, training_loss: 2.01104e-02
I0215 09:55:46.350505 23126066861888 run_lib.py:146] step: 130400, eval_loss: 2.64445e-02
I0215 09:56:03.927195 23126066861888 run_lib.py:133] step: 130450, training_loss: 2.03915e-02
I0215 09:56:21.382578 23126066861888 run_lib.py:133] step: 130500, training_loss: 1.95910e-02
I0215 09:56:21.538164 23126066861888 run_lib.py:146] step: 130500, eval_loss: 2.48062e-02
I0215 09:56:38.924132 23126066861888 run_lib.py:133] step: 130550, training_loss: 2.11837e-02
I0215 09:56:56.478384 23126066861888 run_lib.py:133] step: 130600, training_loss: 2.06673e-02
I0215 09:56:56.630112 23126066861888 run_lib.py:146] step: 130600, eval_loss: 2.67001e-02
I0215 09:57:14.036130 23126066861888 run_lib.py:133] step: 130650, training_loss: 2.06034e-02
I0215 09:57:31.400882 23126066861888 run_lib.py:133] step: 130700, training_loss: 1.97166e-02
I0215 09:57:31.555376 23126066861888 run_lib.py:146] step: 130700, eval_loss: 2.57365e-02
I0215 09:57:49.149712 23126066861888 run_lib.py:133] step: 130750, training_loss: 2.04916e-02
I0215 09:58:06.545096 23126066861888 run_lib.py:133] step: 130800, training_loss: 2.04420e-02
I0215 09:58:06.701322 23126066861888 run_lib.py:146] step: 130800, eval_loss: 2.45768e-02
I0215 09:58:24.292176 23126066861888 run_lib.py:133] step: 130850, training_loss: 2.03336e-02
I0215 09:58:41.681387 23126066861888 run_lib.py:133] step: 130900, training_loss: 2.05349e-02
I0215 09:58:41.835357 23126066861888 run_lib.py:146] step: 130900, eval_loss: 2.56495e-02
I0215 09:58:59.227058 23126066861888 run_lib.py:133] step: 130950, training_loss: 2.05284e-02
I0215 09:59:16.754096 23126066861888 run_lib.py:133] step: 131000, training_loss: 1.98575e-02
I0215 09:59:16.917049 23126066861888 run_lib.py:146] step: 131000, eval_loss: 2.64360e-02
I0215 09:59:34.394560 23126066861888 run_lib.py:133] step: 131050, training_loss: 2.01621e-02
I0215 09:59:51.763164 23126066861888 run_lib.py:133] step: 131100, training_loss: 2.06326e-02
I0215 09:59:51.918279 23126066861888 run_lib.py:146] step: 131100, eval_loss: 2.52123e-02
I0215 10:00:09.338854 23126066861888 run_lib.py:133] step: 131150, training_loss: 1.95433e-02
I0215 10:00:26.686497 23126066861888 run_lib.py:133] step: 131200, training_loss: 2.06574e-02
I0215 10:00:26.839965 23126066861888 run_lib.py:146] step: 131200, eval_loss: 2.57629e-02
I0215 10:00:44.389722 23126066861888 run_lib.py:133] step: 131250, training_loss: 1.98555e-02
I0215 10:01:01.857561 23126066861888 run_lib.py:133] step: 131300, training_loss: 2.05575e-02
I0215 10:01:02.030287 23126066861888 run_lib.py:146] step: 131300, eval_loss: 2.58290e-02
I0215 10:01:19.489004 23126066861888 run_lib.py:133] step: 131350, training_loss: 2.02086e-02
I0215 10:01:36.876770 23126066861888 run_lib.py:133] step: 131400, training_loss: 2.02460e-02
I0215 10:01:37.031349 23126066861888 run_lib.py:146] step: 131400, eval_loss: 2.48387e-02
I0215 10:01:54.626770 23126066861888 run_lib.py:133] step: 131450, training_loss: 2.07827e-02
I0215 10:02:11.990295 23126066861888 run_lib.py:133] step: 131500, training_loss: 2.04377e-02
I0215 10:02:12.143080 23126066861888 run_lib.py:146] step: 131500, eval_loss: 2.54249e-02
I0215 10:02:29.669136 23126066861888 run_lib.py:133] step: 131550, training_loss: 2.04843e-02
I0215 10:02:47.123341 23126066861888 run_lib.py:133] step: 131600, training_loss: 2.02386e-02
I0215 10:02:47.278157 23126066861888 run_lib.py:146] step: 131600, eval_loss: 2.66834e-02
I0215 10:03:04.659359 23126066861888 run_lib.py:133] step: 131650, training_loss: 2.08455e-02
I0215 10:03:22.228436 23126066861888 run_lib.py:133] step: 131700, training_loss: 2.01735e-02
I0215 10:03:22.384247 23126066861888 run_lib.py:146] step: 131700, eval_loss: 2.60887e-02
I0215 10:03:39.732945 23126066861888 run_lib.py:133] step: 131750, training_loss: 2.04654e-02
I0215 10:03:57.096771 23126066861888 run_lib.py:133] step: 131800, training_loss: 2.00139e-02
I0215 10:03:57.254515 23126066861888 run_lib.py:146] step: 131800, eval_loss: 2.53709e-02
I0215 10:04:14.785260 23126066861888 run_lib.py:133] step: 131850, training_loss: 2.07793e-02
I0215 10:04:32.255215 23126066861888 run_lib.py:133] step: 131900, training_loss: 2.04510e-02
I0215 10:04:32.408132 23126066861888 run_lib.py:146] step: 131900, eval_loss: 2.58708e-02
I0215 10:04:49.775769 23126066861888 run_lib.py:133] step: 131950, training_loss: 2.01436e-02
I0215 10:05:07.370383 23126066861888 run_lib.py:133] step: 132000, training_loss: 2.05324e-02
I0215 10:05:07.523064 23126066861888 run_lib.py:146] step: 132000, eval_loss: 2.55244e-02
I0215 10:05:24.913067 23126066861888 run_lib.py:133] step: 132050, training_loss: 2.08854e-02
I0215 10:05:42.310303 23126066861888 run_lib.py:133] step: 132100, training_loss: 2.01208e-02
I0215 10:05:42.461958 23126066861888 run_lib.py:146] step: 132100, eval_loss: 2.71268e-02
I0215 10:05:59.976107 23126066861888 run_lib.py:133] step: 132150, training_loss: 2.08799e-02
I0215 10:06:17.385941 23126066861888 run_lib.py:133] step: 132200, training_loss: 2.07418e-02
I0215 10:06:17.543008 23126066861888 run_lib.py:146] step: 132200, eval_loss: 2.54890e-02
I0215 10:06:34.950474 23126066861888 run_lib.py:133] step: 132250, training_loss: 2.01556e-02
I0215 10:06:52.315815 23126066861888 run_lib.py:133] step: 132300, training_loss: 1.98182e-02
I0215 10:06:52.472421 23126066861888 run_lib.py:146] step: 132300, eval_loss: 2.58369e-02
I0215 10:07:10.027658 23126066861888 run_lib.py:133] step: 132350, training_loss: 2.00148e-02
I0215 10:07:27.532648 23126066861888 run_lib.py:133] step: 132400, training_loss: 2.03239e-02
I0215 10:07:27.691083 23126066861888 run_lib.py:146] step: 132400, eval_loss: 2.59703e-02
I0215 10:07:45.107351 23126066861888 run_lib.py:133] step: 132450, training_loss: 2.08125e-02
I0215 10:08:02.526945 23126066861888 run_lib.py:133] step: 132500, training_loss: 2.07229e-02
I0215 10:08:02.691738 23126066861888 run_lib.py:146] step: 132500, eval_loss: 2.47031e-02
I0215 10:08:20.289105 23126066861888 run_lib.py:133] step: 132550, training_loss: 1.99351e-02
I0215 10:08:37.731143 23126066861888 run_lib.py:133] step: 132600, training_loss: 2.07107e-02
I0215 10:08:37.908986 23126066861888 run_lib.py:146] step: 132600, eval_loss: 2.60918e-02
I0215 10:08:55.239949 23126066861888 run_lib.py:133] step: 132650, training_loss: 2.06803e-02
I0215 10:09:12.760286 23126066861888 run_lib.py:133] step: 132700, training_loss: 2.08284e-02
I0215 10:09:12.921090 23126066861888 run_lib.py:146] step: 132700, eval_loss: 2.62817e-02
I0215 10:09:30.355904 23126066861888 run_lib.py:133] step: 132750, training_loss: 2.03492e-02
I0215 10:09:47.986453 23126066861888 run_lib.py:133] step: 132800, training_loss: 1.97860e-02
I0215 10:09:48.140474 23126066861888 run_lib.py:146] step: 132800, eval_loss: 2.43264e-02
I0215 10:10:05.486889 23126066861888 run_lib.py:133] step: 132850, training_loss: 2.06711e-02
I0215 10:10:22.834364 23126066861888 run_lib.py:133] step: 132900, training_loss: 1.95365e-02
I0215 10:10:22.987103 23126066861888 run_lib.py:146] step: 132900, eval_loss: 2.62550e-02
I0215 10:10:40.497622 23126066861888 run_lib.py:133] step: 132950, training_loss: 1.98929e-02
I0215 10:10:57.893528 23126066861888 run_lib.py:133] step: 133000, training_loss: 1.96688e-02
I0215 10:10:58.045846 23126066861888 run_lib.py:146] step: 133000, eval_loss: 2.72610e-02
I0215 10:11:15.485533 23126066861888 run_lib.py:133] step: 133050, training_loss: 2.02736e-02
I0215 10:11:33.057255 23126066861888 run_lib.py:133] step: 133100, training_loss: 1.96974e-02
I0215 10:11:33.211012 23126066861888 run_lib.py:146] step: 133100, eval_loss: 2.52721e-02
I0215 10:11:50.557046 23126066861888 run_lib.py:133] step: 133150, training_loss: 2.01821e-02
I0215 10:12:07.959280 23126066861888 run_lib.py:133] step: 133200, training_loss: 2.02460e-02
I0215 10:12:08.115381 23126066861888 run_lib.py:146] step: 133200, eval_loss: 2.54807e-02
I0215 10:12:25.556933 23126066861888 run_lib.py:133] step: 133250, training_loss: 2.03955e-02
I0215 10:12:42.931672 23126066861888 run_lib.py:133] step: 133300, training_loss: 2.05695e-02
I0215 10:12:43.096458 23126066861888 run_lib.py:146] step: 133300, eval_loss: 2.57415e-02
I0215 10:13:00.527147 23126066861888 run_lib.py:133] step: 133350, training_loss: 2.08975e-02
I0215 10:13:17.945521 23126066861888 run_lib.py:133] step: 133400, training_loss: 2.06098e-02
I0215 10:13:18.102473 23126066861888 run_lib.py:146] step: 133400, eval_loss: 2.57724e-02
I0215 10:13:35.713392 23126066861888 run_lib.py:133] step: 133450, training_loss: 2.02663e-02
I0215 10:13:53.155468 23126066861888 run_lib.py:133] step: 133500, training_loss: 2.01018e-02
I0215 10:13:53.306286 23126066861888 run_lib.py:146] step: 133500, eval_loss: 2.49547e-02
I0215 10:14:10.707556 23126066861888 run_lib.py:133] step: 133550, training_loss: 1.98118e-02
I0215 10:14:28.115465 23126066861888 run_lib.py:133] step: 133600, training_loss: 2.04818e-02
I0215 10:14:28.280225 23126066861888 run_lib.py:146] step: 133600, eval_loss: 2.62881e-02
I0215 10:14:45.884243 23126066861888 run_lib.py:133] step: 133650, training_loss: 2.03857e-02
I0215 10:15:03.287317 23126066861888 run_lib.py:133] step: 133700, training_loss: 2.11567e-02
I0215 10:15:03.450785 23126066861888 run_lib.py:146] step: 133700, eval_loss: 2.59480e-02
I0215 10:15:20.855553 23126066861888 run_lib.py:133] step: 133750, training_loss: 2.15807e-02
I0215 10:15:38.455113 23126066861888 run_lib.py:133] step: 133800, training_loss: 2.05080e-02
I0215 10:15:38.611302 23126066861888 run_lib.py:146] step: 133800, eval_loss: 2.48959e-02
I0215 10:15:56.022136 23126066861888 run_lib.py:133] step: 133850, training_loss: 2.08146e-02
I0215 10:16:13.515109 23126066861888 run_lib.py:133] step: 133900, training_loss: 2.07829e-02
I0215 10:16:13.668467 23126066861888 run_lib.py:146] step: 133900, eval_loss: 2.54604e-02
I0215 10:16:31.125339 23126066861888 run_lib.py:133] step: 133950, training_loss: 1.95004e-02
I0215 10:16:48.527885 23126066861888 run_lib.py:133] step: 134000, training_loss: 2.06387e-02
I0215 10:16:48.679309 23126066861888 run_lib.py:146] step: 134000, eval_loss: 2.53830e-02
I0215 10:17:06.265664 23126066861888 run_lib.py:133] step: 134050, training_loss: 2.02332e-02
I0215 10:17:23.644852 23126066861888 run_lib.py:133] step: 134100, training_loss: 1.93039e-02
I0215 10:17:23.801205 23126066861888 run_lib.py:146] step: 134100, eval_loss: 2.57258e-02
I0215 10:17:41.190274 23126066861888 run_lib.py:133] step: 134150, training_loss: 2.02489e-02
I0215 10:17:58.686011 23126066861888 run_lib.py:133] step: 134200, training_loss: 2.08969e-02
I0215 10:17:58.853397 23126066861888 run_lib.py:146] step: 134200, eval_loss: 2.62721e-02
I0215 10:18:16.264686 23126066861888 run_lib.py:133] step: 134250, training_loss: 2.07482e-02
I0215 10:18:33.688355 23126066861888 run_lib.py:133] step: 134300, training_loss: 2.02551e-02
I0215 10:18:33.848166 23126066861888 run_lib.py:146] step: 134300, eval_loss: 2.66220e-02
I0215 10:18:51.441386 23126066861888 run_lib.py:133] step: 134350, training_loss: 2.09746e-02
I0215 10:19:08.802991 23126066861888 run_lib.py:133] step: 134400, training_loss: 2.02824e-02
I0215 10:19:08.954340 23126066861888 run_lib.py:146] step: 134400, eval_loss: 2.65621e-02
I0215 10:19:26.366773 23126066861888 run_lib.py:133] step: 134450, training_loss: 2.06991e-02
I0215 10:19:43.784678 23126066861888 run_lib.py:133] step: 134500, training_loss: 2.05347e-02
I0215 10:19:43.947212 23126066861888 run_lib.py:146] step: 134500, eval_loss: 2.42372e-02
I0215 10:20:01.518841 23126066861888 run_lib.py:133] step: 134550, training_loss: 2.01345e-02
I0215 10:20:19.044500 23126066861888 run_lib.py:133] step: 134600, training_loss: 2.00241e-02
I0215 10:20:19.197001 23126066861888 run_lib.py:146] step: 134600, eval_loss: 2.47930e-02
I0215 10:20:36.560020 23126066861888 run_lib.py:133] step: 134650, training_loss: 2.00401e-02
I0215 10:20:53.935189 23126066861888 run_lib.py:133] step: 134700, training_loss: 2.00946e-02
I0215 10:20:54.089373 23126066861888 run_lib.py:146] step: 134700, eval_loss: 2.54647e-02
I0215 10:21:11.618133 23126066861888 run_lib.py:133] step: 134750, training_loss: 1.97990e-02
I0215 10:21:28.987902 23126066861888 run_lib.py:133] step: 134800, training_loss: 2.04800e-02
I0215 10:21:29.144452 23126066861888 run_lib.py:146] step: 134800, eval_loss: 2.56347e-02
I0215 10:21:46.617626 23126066861888 run_lib.py:133] step: 134850, training_loss: 1.97821e-02
I0215 10:22:04.207661 23126066861888 run_lib.py:133] step: 134900, training_loss: 2.06207e-02
I0215 10:22:04.365452 23126066861888 run_lib.py:146] step: 134900, eval_loss: 2.61503e-02
I0215 10:22:21.751933 23126066861888 run_lib.py:133] step: 134950, training_loss: 2.03247e-02
I0215 10:22:39.285728 23126066861888 run_lib.py:133] step: 135000, training_loss: 2.00701e-02
I0215 10:22:39.439102 23126066861888 run_lib.py:146] step: 135000, eval_loss: 2.63699e-02
I0215 10:22:56.802752 23126066861888 run_lib.py:133] step: 135050, training_loss: 2.00899e-02
I0215 10:23:14.166347 23126066861888 run_lib.py:133] step: 135100, training_loss: 2.01848e-02
I0215 10:23:14.338059 23126066861888 run_lib.py:146] step: 135100, eval_loss: 2.54490e-02
I0215 10:23:31.948430 23126066861888 run_lib.py:133] step: 135150, training_loss: 2.12435e-02
I0215 10:23:49.329825 23126066861888 run_lib.py:133] step: 135200, training_loss: 2.03911e-02
I0215 10:23:49.484831 23126066861888 run_lib.py:146] step: 135200, eval_loss: 2.55967e-02
I0215 10:24:06.849035 23126066861888 run_lib.py:133] step: 135250, training_loss: 2.07088e-02
I0215 10:24:24.378848 23126066861888 run_lib.py:133] step: 135300, training_loss: 2.02674e-02
I0215 10:24:24.532252 23126066861888 run_lib.py:146] step: 135300, eval_loss: 2.60081e-02
I0215 10:24:41.936900 23126066861888 run_lib.py:133] step: 135350, training_loss: 2.12581e-02
I0215 10:24:59.338135 23126066861888 run_lib.py:133] step: 135400, training_loss: 2.00537e-02
I0215 10:24:59.491601 23126066861888 run_lib.py:146] step: 135400, eval_loss: 2.56785e-02
I0215 10:25:17.000968 23126066861888 run_lib.py:133] step: 135450, training_loss: 2.01803e-02
I0215 10:25:34.426248 23126066861888 run_lib.py:133] step: 135500, training_loss: 2.07736e-02
I0215 10:25:34.580836 23126066861888 run_lib.py:146] step: 135500, eval_loss: 2.53783e-02
I0215 10:25:51.988610 23126066861888 run_lib.py:133] step: 135550, training_loss: 1.97622e-02
I0215 10:26:09.340535 23126066861888 run_lib.py:133] step: 135600, training_loss: 2.00394e-02
I0215 10:26:09.505088 23126066861888 run_lib.py:146] step: 135600, eval_loss: 2.64121e-02
I0215 10:26:27.094682 23126066861888 run_lib.py:133] step: 135650, training_loss: 1.94863e-02
I0215 10:26:44.516572 23126066861888 run_lib.py:133] step: 135700, training_loss: 2.05826e-02
I0215 10:26:44.672324 23126066861888 run_lib.py:146] step: 135700, eval_loss: 2.58848e-02
I0215 10:27:02.055853 23126066861888 run_lib.py:133] step: 135750, training_loss: 1.94448e-02
I0215 10:27:19.510715 23126066861888 run_lib.py:133] step: 135800, training_loss: 2.05667e-02
I0215 10:27:19.664447 23126066861888 run_lib.py:146] step: 135800, eval_loss: 2.57507e-02
I0215 10:27:37.249294 23126066861888 run_lib.py:133] step: 135850, training_loss: 2.05375e-02
I0215 10:27:54.586972 23126066861888 run_lib.py:133] step: 135900, training_loss: 2.02132e-02
I0215 10:27:54.736191 23126066861888 run_lib.py:146] step: 135900, eval_loss: 2.59570e-02
I0215 10:28:12.100360 23126066861888 run_lib.py:133] step: 135950, training_loss: 2.01467e-02
I0215 10:28:29.658991 23126066861888 run_lib.py:133] step: 136000, training_loss: 2.05238e-02
I0215 10:28:29.830966 23126066861888 run_lib.py:146] step: 136000, eval_loss: 2.58757e-02
I0215 10:28:47.266217 23126066861888 run_lib.py:133] step: 136050, training_loss: 1.98239e-02
I0215 10:29:04.871711 23126066861888 run_lib.py:133] step: 136100, training_loss: 2.01451e-02
I0215 10:29:05.029482 23126066861888 run_lib.py:146] step: 136100, eval_loss: 2.61185e-02
I0215 10:29:22.382584 23126066861888 run_lib.py:133] step: 136150, training_loss: 2.03642e-02
I0215 10:29:39.743055 23126066861888 run_lib.py:133] step: 136200, training_loss: 2.02865e-02
I0215 10:29:39.898861 23126066861888 run_lib.py:146] step: 136200, eval_loss: 2.53252e-02
I0215 10:29:57.407038 23126066861888 run_lib.py:133] step: 136250, training_loss: 2.06651e-02
I0215 10:30:14.881639 23126066861888 run_lib.py:133] step: 136300, training_loss: 2.04357e-02
I0215 10:30:15.029156 23126066861888 run_lib.py:146] step: 136300, eval_loss: 2.61087e-02
I0215 10:30:32.499374 23126066861888 run_lib.py:133] step: 136350, training_loss: 2.04086e-02
I0215 10:30:50.068375 23126066861888 run_lib.py:133] step: 136400, training_loss: 2.04222e-02
I0215 10:30:50.226102 23126066861888 run_lib.py:146] step: 136400, eval_loss: 2.65555e-02
I0215 10:31:07.617840 23126066861888 run_lib.py:133] step: 136450, training_loss: 1.97899e-02
I0215 10:31:24.977359 23126066861888 run_lib.py:133] step: 136500, training_loss: 2.01342e-02
I0215 10:31:25.134201 23126066861888 run_lib.py:146] step: 136500, eval_loss: 2.54950e-02
I0215 10:31:42.670168 23126066861888 run_lib.py:133] step: 136550, training_loss: 2.08918e-02
I0215 10:32:00.164621 23126066861888 run_lib.py:133] step: 136600, training_loss: 2.04356e-02
I0215 10:32:00.320556 23126066861888 run_lib.py:146] step: 136600, eval_loss: 2.62804e-02
I0215 10:32:17.731844 23126066861888 run_lib.py:133] step: 136650, training_loss: 2.06746e-02
I0215 10:32:35.117897 23126066861888 run_lib.py:133] step: 136700, training_loss: 2.01751e-02
I0215 10:32:35.273206 23126066861888 run_lib.py:146] step: 136700, eval_loss: 2.51528e-02
I0215 10:32:52.851971 23126066861888 run_lib.py:133] step: 136750, training_loss: 1.98379e-02
I0215 10:33:10.291584 23126066861888 run_lib.py:133] step: 136800, training_loss: 2.07317e-02
I0215 10:33:10.440947 23126066861888 run_lib.py:146] step: 136800, eval_loss: 2.59709e-02
I0215 10:33:27.848258 23126066861888 run_lib.py:133] step: 136850, training_loss: 2.06359e-02
I0215 10:33:45.267252 23126066861888 run_lib.py:133] step: 136900, training_loss: 1.97369e-02
I0215 10:33:45.427221 23126066861888 run_lib.py:146] step: 136900, eval_loss: 2.54330e-02
I0215 10:34:03.004433 23126066861888 run_lib.py:133] step: 136950, training_loss: 2.02276e-02
I0215 10:34:20.400291 23126066861888 run_lib.py:133] step: 137000, training_loss: 1.99980e-02
I0215 10:34:20.558620 23126066861888 run_lib.py:146] step: 137000, eval_loss: 2.59695e-02
I0215 10:34:37.949408 23126066861888 run_lib.py:133] step: 137050, training_loss: 2.09354e-02
I0215 10:34:55.503399 23126066861888 run_lib.py:133] step: 137100, training_loss: 2.00151e-02
I0215 10:34:55.673655 23126066861888 run_lib.py:146] step: 137100, eval_loss: 2.66839e-02
I0215 10:35:13.105436 23126066861888 run_lib.py:133] step: 137150, training_loss: 2.00512e-02
I0215 10:35:30.703282 23126066861888 run_lib.py:133] step: 137200, training_loss: 2.02682e-02
I0215 10:35:30.874228 23126066861888 run_lib.py:146] step: 137200, eval_loss: 2.63770e-02
I0215 10:35:48.292031 23126066861888 run_lib.py:133] step: 137250, training_loss: 2.07258e-02
I0215 10:36:05.677024 23126066861888 run_lib.py:133] step: 137300, training_loss: 2.00139e-02
I0215 10:36:05.835407 23126066861888 run_lib.py:146] step: 137300, eval_loss: 2.70545e-02
I0215 10:36:23.344985 23126066861888 run_lib.py:133] step: 137350, training_loss: 2.05377e-02
I0215 10:36:40.754120 23126066861888 run_lib.py:133] step: 137400, training_loss: 1.98953e-02
I0215 10:36:40.927532 23126066861888 run_lib.py:146] step: 137400, eval_loss: 2.52415e-02
I0215 10:36:58.350599 23126066861888 run_lib.py:133] step: 137450, training_loss: 2.03815e-02
I0215 10:37:15.964208 23126066861888 run_lib.py:133] step: 137500, training_loss: 2.04234e-02
I0215 10:37:16.120260 23126066861888 run_lib.py:146] step: 137500, eval_loss: 2.57799e-02
I0215 10:37:33.502005 23126066861888 run_lib.py:133] step: 137550, training_loss: 2.01543e-02
I0215 10:37:50.891785 23126066861888 run_lib.py:133] step: 137600, training_loss: 2.00822e-02
I0215 10:37:51.046273 23126066861888 run_lib.py:146] step: 137600, eval_loss: 2.54321e-02
I0215 10:38:08.542847 23126066861888 run_lib.py:133] step: 137650, training_loss: 2.08588e-02
I0215 10:38:25.967824 23126066861888 run_lib.py:133] step: 137700, training_loss: 2.02335e-02
I0215 10:38:26.120646 23126066861888 run_lib.py:146] step: 137700, eval_loss: 2.56707e-02
I0215 10:38:43.529434 23126066861888 run_lib.py:133] step: 137750, training_loss: 1.97708e-02
I0215 10:39:00.950538 23126066861888 run_lib.py:133] step: 137800, training_loss: 2.03538e-02
I0215 10:39:01.104821 23126066861888 run_lib.py:146] step: 137800, eval_loss: 2.60659e-02
I0215 10:39:18.671771 23126066861888 run_lib.py:133] step: 137850, training_loss: 2.01794e-02
I0215 10:39:36.116233 23126066861888 run_lib.py:133] step: 137900, training_loss: 1.98861e-02
I0215 10:39:36.277269 23126066861888 run_lib.py:146] step: 137900, eval_loss: 2.63652e-02
I0215 10:39:53.614868 23126066861888 run_lib.py:133] step: 137950, training_loss: 2.03414e-02
I0215 10:40:11.044179 23126066861888 run_lib.py:133] step: 138000, training_loss: 2.09345e-02
I0215 10:40:11.206414 23126066861888 run_lib.py:146] step: 138000, eval_loss: 2.63332e-02
I0215 10:40:28.819823 23126066861888 run_lib.py:133] step: 138050, training_loss: 2.04680e-02
I0215 10:40:46.236950 23126066861888 run_lib.py:133] step: 138100, training_loss: 2.05562e-02
I0215 10:40:46.398604 23126066861888 run_lib.py:146] step: 138100, eval_loss: 2.54719e-02
I0215 10:41:03.790591 23126066861888 run_lib.py:133] step: 138150, training_loss: 2.07297e-02
I0215 10:41:21.355815 23126066861888 run_lib.py:133] step: 138200, training_loss: 2.02342e-02
I0215 10:41:21.505782 23126066861888 run_lib.py:146] step: 138200, eval_loss: 2.56502e-02
I0215 10:41:38.923694 23126066861888 run_lib.py:133] step: 138250, training_loss: 2.00343e-02
I0215 10:41:56.434407 23126066861888 run_lib.py:133] step: 138300, training_loss: 2.01783e-02
I0215 10:41:56.605458 23126066861888 run_lib.py:146] step: 138300, eval_loss: 2.57376e-02
I0215 10:42:14.021286 23126066861888 run_lib.py:133] step: 138350, training_loss: 1.94867e-02
I0215 10:42:31.442796 23126066861888 run_lib.py:133] step: 138400, training_loss: 2.10094e-02
I0215 10:42:31.601341 23126066861888 run_lib.py:146] step: 138400, eval_loss: 2.62590e-02
I0215 10:42:49.153893 23126066861888 run_lib.py:133] step: 138450, training_loss: 2.07429e-02
I0215 10:43:06.555683 23126066861888 run_lib.py:133] step: 138500, training_loss: 2.07830e-02
I0215 10:43:06.732058 23126066861888 run_lib.py:146] step: 138500, eval_loss: 2.55741e-02
I0215 10:43:24.170933 23126066861888 run_lib.py:133] step: 138550, training_loss: 2.09247e-02
I0215 10:43:41.754889 23126066861888 run_lib.py:133] step: 138600, training_loss: 2.04814e-02
I0215 10:43:41.908212 23126066861888 run_lib.py:146] step: 138600, eval_loss: 2.59501e-02
I0215 10:43:59.351442 23126066861888 run_lib.py:133] step: 138650, training_loss: 2.06720e-02
I0215 10:44:16.708419 23126066861888 run_lib.py:133] step: 138700, training_loss: 2.04818e-02
I0215 10:44:16.859507 23126066861888 run_lib.py:146] step: 138700, eval_loss: 2.67477e-02
I0215 10:44:34.348480 23126066861888 run_lib.py:133] step: 138750, training_loss: 2.08063e-02
I0215 10:44:51.765325 23126066861888 run_lib.py:133] step: 138800, training_loss: 2.00263e-02
I0215 10:44:51.929288 23126066861888 run_lib.py:146] step: 138800, eval_loss: 2.60418e-02
I0215 10:45:09.393902 23126066861888 run_lib.py:133] step: 138850, training_loss: 1.96054e-02
I0215 10:45:26.807869 23126066861888 run_lib.py:133] step: 138900, training_loss: 1.98779e-02
I0215 10:45:26.964152 23126066861888 run_lib.py:146] step: 138900, eval_loss: 2.63642e-02
I0215 10:45:44.550045 23126066861888 run_lib.py:133] step: 138950, training_loss: 2.07511e-02
I0215 10:46:02.026181 23126066861888 run_lib.py:133] step: 139000, training_loss: 2.09028e-02
I0215 10:46:02.179018 23126066861888 run_lib.py:146] step: 139000, eval_loss: 2.63307e-02
I0215 10:46:19.571155 23126066861888 run_lib.py:133] step: 139050, training_loss: 2.02082e-02
I0215 10:46:36.947804 23126066861888 run_lib.py:133] step: 139100, training_loss: 2.09674e-02
I0215 10:46:37.109817 23126066861888 run_lib.py:146] step: 139100, eval_loss: 2.65973e-02
I0215 10:46:54.654373 23126066861888 run_lib.py:133] step: 139150, training_loss: 2.01916e-02
I0215 10:47:12.083743 23126066861888 run_lib.py:133] step: 139200, training_loss: 2.05943e-02
I0215 10:47:12.236513 23126066861888 run_lib.py:146] step: 139200, eval_loss: 2.57971e-02
I0215 10:47:29.666845 23126066861888 run_lib.py:133] step: 139250, training_loss: 2.04872e-02
I0215 10:47:47.332111 23126066861888 run_lib.py:133] step: 139300, training_loss: 2.01697e-02
I0215 10:47:47.489217 23126066861888 run_lib.py:146] step: 139300, eval_loss: 2.43866e-02
I0215 10:48:04.849549 23126066861888 run_lib.py:133] step: 139350, training_loss: 2.06699e-02
I0215 10:48:22.356012 23126066861888 run_lib.py:133] step: 139400, training_loss: 1.97062e-02
I0215 10:48:22.517650 23126066861888 run_lib.py:146] step: 139400, eval_loss: 2.46247e-02
I0215 10:48:39.930717 23126066861888 run_lib.py:133] step: 139450, training_loss: 2.01064e-02
I0215 10:48:57.402792 23126066861888 run_lib.py:133] step: 139500, training_loss: 1.99551e-02
I0215 10:48:57.556299 23126066861888 run_lib.py:146] step: 139500, eval_loss: 2.58060e-02
I0215 10:49:15.162326 23126066861888 run_lib.py:133] step: 139550, training_loss: 1.97421e-02
I0215 10:49:32.544934 23126066861888 run_lib.py:133] step: 139600, training_loss: 2.00141e-02
I0215 10:49:32.696031 23126066861888 run_lib.py:146] step: 139600, eval_loss: 2.62842e-02
I0215 10:49:50.061968 23126066861888 run_lib.py:133] step: 139650, training_loss: 2.00651e-02
I0215 10:50:07.601027 23126066861888 run_lib.py:133] step: 139700, training_loss: 1.95575e-02
I0215 10:50:07.756252 23126066861888 run_lib.py:146] step: 139700, eval_loss: 2.50854e-02
I0215 10:50:25.219176 23126066861888 run_lib.py:133] step: 139750, training_loss: 2.04371e-02
I0215 10:50:42.611531 23126066861888 run_lib.py:133] step: 139800, training_loss: 2.02732e-02
I0215 10:50:42.768966 23126066861888 run_lib.py:146] step: 139800, eval_loss: 2.57534e-02
I0215 10:51:00.258530 23126066861888 run_lib.py:133] step: 139850, training_loss: 2.05901e-02
I0215 10:51:17.630503 23126066861888 run_lib.py:133] step: 139900, training_loss: 2.06434e-02
I0215 10:51:17.785013 23126066861888 run_lib.py:146] step: 139900, eval_loss: 2.61456e-02
I0215 10:51:35.157764 23126066861888 run_lib.py:133] step: 139950, training_loss: 2.01675e-02
I0215 10:51:52.664761 23126066861888 run_lib.py:133] step: 140000, training_loss: 2.01940e-02
I0215 10:51:53.758136 23126066861888 run_lib.py:146] step: 140000, eval_loss: 2.55543e-02
I0215 10:52:13.875169 23126066861888 run_lib.py:133] step: 140050, training_loss: 2.05564e-02
I0215 10:52:31.293588 23126066861888 run_lib.py:133] step: 140100, training_loss: 2.05147e-02
I0215 10:52:31.447539 23126066861888 run_lib.py:146] step: 140100, eval_loss: 2.63354e-02
I0215 10:52:48.931681 23126066861888 run_lib.py:133] step: 140150, training_loss: 2.07314e-02
I0215 10:53:06.306085 23126066861888 run_lib.py:133] step: 140200, training_loss: 2.05271e-02
I0215 10:53:06.456990 23126066861888 run_lib.py:146] step: 140200, eval_loss: 2.73565e-02
I0215 10:53:23.827724 23126066861888 run_lib.py:133] step: 140250, training_loss: 2.05591e-02
I0215 10:53:41.222404 23126066861888 run_lib.py:133] step: 140300, training_loss: 2.01322e-02
I0215 10:53:41.383178 23126066861888 run_lib.py:146] step: 140300, eval_loss: 2.67162e-02
I0215 10:53:58.917227 23126066861888 run_lib.py:133] step: 140350, training_loss: 2.03323e-02
I0215 10:54:16.485225 23126066861888 run_lib.py:133] step: 140400, training_loss: 1.96677e-02
I0215 10:54:16.659253 23126066861888 run_lib.py:146] step: 140400, eval_loss: 2.49410e-02
I0215 10:54:34.134224 23126066861888 run_lib.py:133] step: 140450, training_loss: 2.14133e-02
I0215 10:54:51.539357 23126066861888 run_lib.py:133] step: 140500, training_loss: 2.02997e-02
I0215 10:54:51.694282 23126066861888 run_lib.py:146] step: 140500, eval_loss: 2.58259e-02
I0215 10:55:09.236208 23126066861888 run_lib.py:133] step: 140550, training_loss: 2.02577e-02
I0215 10:55:26.659154 23126066861888 run_lib.py:133] step: 140600, training_loss: 2.13424e-02
I0215 10:55:26.820258 23126066861888 run_lib.py:146] step: 140600, eval_loss: 2.68579e-02
I0215 10:55:44.255840 23126066861888 run_lib.py:133] step: 140650, training_loss: 2.02247e-02
I0215 10:56:01.808365 23126066861888 run_lib.py:133] step: 140700, training_loss: 2.01121e-02
I0215 10:56:01.960268 23126066861888 run_lib.py:146] step: 140700, eval_loss: 2.62492e-02
I0215 10:56:19.388571 23126066861888 run_lib.py:133] step: 140750, training_loss: 2.02111e-02
I0215 10:56:36.981299 23126066861888 run_lib.py:133] step: 140800, training_loss: 2.03117e-02
I0215 10:56:37.141530 23126066861888 run_lib.py:146] step: 140800, eval_loss: 2.63159e-02
I0215 10:56:54.498273 23126066861888 run_lib.py:133] step: 140850, training_loss: 1.98245e-02
I0215 10:57:11.892001 23126066861888 run_lib.py:133] step: 140900, training_loss: 1.97296e-02
I0215 10:57:12.063317 23126066861888 run_lib.py:146] step: 140900, eval_loss: 2.54856e-02
I0215 10:57:29.672826 23126066861888 run_lib.py:133] step: 140950, training_loss: 2.02307e-02
I0215 10:57:47.131348 23126066861888 run_lib.py:133] step: 141000, training_loss: 2.07857e-02
I0215 10:57:47.286127 23126066861888 run_lib.py:146] step: 141000, eval_loss: 2.66042e-02
I0215 10:58:04.665859 23126066861888 run_lib.py:133] step: 141050, training_loss: 2.01648e-02
I0215 10:58:22.176838 23126066861888 run_lib.py:133] step: 141100, training_loss: 2.01220e-02
I0215 10:58:22.336000 23126066861888 run_lib.py:146] step: 141100, eval_loss: 2.57710e-02
I0215 10:58:39.751914 23126066861888 run_lib.py:133] step: 141150, training_loss: 1.95770e-02
I0215 10:58:57.211041 23126066861888 run_lib.py:133] step: 141200, training_loss: 1.98925e-02
I0215 10:58:57.371291 23126066861888 run_lib.py:146] step: 141200, eval_loss: 2.45401e-02
I0215 10:59:14.876388 23126066861888 run_lib.py:133] step: 141250, training_loss: 1.92436e-02
I0215 10:59:32.291530 23126066861888 run_lib.py:133] step: 141300, training_loss: 2.01284e-02
I0215 10:59:32.448018 23126066861888 run_lib.py:146] step: 141300, eval_loss: 2.51347e-02
I0215 10:59:49.850930 23126066861888 run_lib.py:133] step: 141350, training_loss: 2.01779e-02
I0215 11:00:07.239057 23126066861888 run_lib.py:133] step: 141400, training_loss: 2.00828e-02
I0215 11:00:07.395333 23126066861888 run_lib.py:146] step: 141400, eval_loss: 2.56411e-02
I0215 11:00:25.057517 23126066861888 run_lib.py:133] step: 141450, training_loss: 2.04437e-02
I0215 11:00:42.529229 23126066861888 run_lib.py:133] step: 141500, training_loss: 2.01960e-02
I0215 11:00:42.692172 23126066861888 run_lib.py:146] step: 141500, eval_loss: 2.71254e-02
I0215 11:01:00.119419 23126066861888 run_lib.py:133] step: 141550, training_loss: 2.06933e-02
I0215 11:01:17.549525 23126066861888 run_lib.py:133] step: 141600, training_loss: 2.01101e-02
I0215 11:01:17.699904 23126066861888 run_lib.py:146] step: 141600, eval_loss: 2.49271e-02
I0215 11:01:35.261210 23126066861888 run_lib.py:133] step: 141650, training_loss: 1.95850e-02
I0215 11:01:52.651551 23126066861888 run_lib.py:133] step: 141700, training_loss: 1.92780e-02
I0215 11:01:52.812905 23126066861888 run_lib.py:146] step: 141700, eval_loss: 2.64833e-02
I0215 11:02:10.176457 23126066861888 run_lib.py:133] step: 141750, training_loss: 2.08082e-02
I0215 11:02:27.716983 23126066861888 run_lib.py:133] step: 141800, training_loss: 1.97584e-02
I0215 11:02:27.888134 23126066861888 run_lib.py:146] step: 141800, eval_loss: 2.63506e-02
I0215 11:02:45.336984 23126066861888 run_lib.py:133] step: 141850, training_loss: 1.99017e-02
I0215 11:03:02.988425 23126066861888 run_lib.py:133] step: 141900, training_loss: 1.99701e-02
I0215 11:03:03.142374 23126066861888 run_lib.py:146] step: 141900, eval_loss: 2.51988e-02
I0215 11:03:20.599689 23126066861888 run_lib.py:133] step: 141950, training_loss: 2.08274e-02
I0215 11:03:37.956569 23126066861888 run_lib.py:133] step: 142000, training_loss: 2.01007e-02
I0215 11:03:38.128119 23126066861888 run_lib.py:146] step: 142000, eval_loss: 2.48004e-02
I0215 11:03:55.697612 23126066861888 run_lib.py:133] step: 142050, training_loss: 2.00066e-02
I0215 11:04:13.165636 23126066861888 run_lib.py:133] step: 142100, training_loss: 2.03699e-02
I0215 11:04:13.319090 23126066861888 run_lib.py:146] step: 142100, eval_loss: 2.65554e-02
I0215 11:04:30.736446 23126066861888 run_lib.py:133] step: 142150, training_loss: 2.02884e-02
I0215 11:04:48.319880 23126066861888 run_lib.py:133] step: 142200, training_loss: 1.96990e-02
I0215 11:04:48.477291 23126066861888 run_lib.py:146] step: 142200, eval_loss: 2.64417e-02
I0215 11:05:05.857429 23126066861888 run_lib.py:133] step: 142250, training_loss: 1.97963e-02
I0215 11:05:23.246015 23126066861888 run_lib.py:133] step: 142300, training_loss: 2.04595e-02
I0215 11:05:23.411647 23126066861888 run_lib.py:146] step: 142300, eval_loss: 2.55656e-02
I0215 11:05:40.926561 23126066861888 run_lib.py:133] step: 142350, training_loss: 1.99777e-02
I0215 11:05:58.341593 23126066861888 run_lib.py:133] step: 142400, training_loss: 2.04212e-02
I0215 11:05:58.497503 23126066861888 run_lib.py:146] step: 142400, eval_loss: 2.67851e-02
I0215 11:06:15.916119 23126066861888 run_lib.py:133] step: 142450, training_loss: 1.98113e-02
I0215 11:06:33.316033 23126066861888 run_lib.py:133] step: 142500, training_loss: 2.04726e-02
I0215 11:06:33.468003 23126066861888 run_lib.py:146] step: 142500, eval_loss: 2.51488e-02
I0215 11:06:51.020073 23126066861888 run_lib.py:133] step: 142550, training_loss: 1.91273e-02
I0215 11:07:08.506942 23126066861888 run_lib.py:133] step: 142600, training_loss: 1.98234e-02
I0215 11:07:08.655981 23126066861888 run_lib.py:146] step: 142600, eval_loss: 2.62154e-02
I0215 11:07:26.026309 23126066861888 run_lib.py:133] step: 142650, training_loss: 2.00978e-02
I0215 11:07:43.472147 23126066861888 run_lib.py:133] step: 142700, training_loss: 1.98870e-02
I0215 11:07:43.634282 23126066861888 run_lib.py:146] step: 142700, eval_loss: 2.62676e-02
I0215 11:08:01.226549 23126066861888 run_lib.py:133] step: 142750, training_loss: 2.00653e-02
I0215 11:08:18.605166 23126066861888 run_lib.py:133] step: 142800, training_loss: 1.93578e-02
I0215 11:08:18.760789 23126066861888 run_lib.py:146] step: 142800, eval_loss: 2.51666e-02
I0215 11:08:36.132517 23126066861888 run_lib.py:133] step: 142850, training_loss: 2.00696e-02
I0215 11:08:53.661587 23126066861888 run_lib.py:133] step: 142900, training_loss: 1.95293e-02
I0215 11:08:53.836192 23126066861888 run_lib.py:146] step: 142900, eval_loss: 2.70133e-02
I0215 11:09:11.212956 23126066861888 run_lib.py:133] step: 142950, training_loss: 2.09870e-02
I0215 11:09:28.817424 23126066861888 run_lib.py:133] step: 143000, training_loss: 1.94888e-02
I0215 11:09:28.969796 23126066861888 run_lib.py:146] step: 143000, eval_loss: 2.53195e-02
I0215 11:09:46.371540 23126066861888 run_lib.py:133] step: 143050, training_loss: 2.01192e-02
I0215 11:10:03.817189 23126066861888 run_lib.py:133] step: 143100, training_loss: 2.02391e-02
I0215 11:10:03.977851 23126066861888 run_lib.py:146] step: 143100, eval_loss: 2.57624e-02
I0215 11:10:21.548223 23126066861888 run_lib.py:133] step: 143150, training_loss: 1.94331e-02
I0215 11:10:38.946750 23126066861888 run_lib.py:133] step: 143200, training_loss: 2.00125e-02
I0215 11:10:39.115120 23126066861888 run_lib.py:146] step: 143200, eval_loss: 2.54530e-02
I0215 11:10:56.507277 23126066861888 run_lib.py:133] step: 143250, training_loss: 2.00116e-02
I0215 11:11:14.106894 23126066861888 run_lib.py:133] step: 143300, training_loss: 1.97829e-02
I0215 11:11:14.261618 23126066861888 run_lib.py:146] step: 143300, eval_loss: 2.66692e-02
I0215 11:11:31.628334 23126066861888 run_lib.py:133] step: 143350, training_loss: 2.03521e-02
I0215 11:11:48.949638 23126066861888 run_lib.py:133] step: 143400, training_loss: 2.00448e-02
I0215 11:11:49.105215 23126066861888 run_lib.py:146] step: 143400, eval_loss: 2.61611e-02
I0215 11:12:06.578530 23126066861888 run_lib.py:133] step: 143450, training_loss: 2.11267e-02
I0215 11:12:23.961361 23126066861888 run_lib.py:133] step: 143500, training_loss: 2.03477e-02
I0215 11:12:24.112249 23126066861888 run_lib.py:146] step: 143500, eval_loss: 2.63879e-02
I0215 11:12:41.585067 23126066861888 run_lib.py:133] step: 143550, training_loss: 1.98144e-02
I0215 11:12:58.976494 23126066861888 run_lib.py:133] step: 143600, training_loss: 2.03265e-02
I0215 11:12:59.155976 23126066861888 run_lib.py:146] step: 143600, eval_loss: 2.56173e-02
I0215 11:13:16.733335 23126066861888 run_lib.py:133] step: 143650, training_loss: 2.08083e-02
I0215 11:13:34.203145 23126066861888 run_lib.py:133] step: 143700, training_loss: 1.97705e-02
I0215 11:13:34.360505 23126066861888 run_lib.py:146] step: 143700, eval_loss: 2.59582e-02
I0215 11:13:51.740721 23126066861888 run_lib.py:133] step: 143750, training_loss: 1.94544e-02
I0215 11:14:09.110410 23126066861888 run_lib.py:133] step: 143800, training_loss: 2.00489e-02
I0215 11:14:09.275226 23126066861888 run_lib.py:146] step: 143800, eval_loss: 2.62728e-02
I0215 11:14:26.840475 23126066861888 run_lib.py:133] step: 143850, training_loss: 2.11603e-02
I0215 11:14:44.239140 23126066861888 run_lib.py:133] step: 143900, training_loss: 1.97713e-02
I0215 11:14:44.393230 23126066861888 run_lib.py:146] step: 143900, eval_loss: 2.66565e-02
I0215 11:15:01.809660 23126066861888 run_lib.py:133] step: 143950, training_loss: 2.05012e-02
I0215 11:15:19.355808 23126066861888 run_lib.py:133] step: 144000, training_loss: 2.05930e-02
I0215 11:15:19.505969 23126066861888 run_lib.py:146] step: 144000, eval_loss: 2.63249e-02
I0215 11:15:36.895636 23126066861888 run_lib.py:133] step: 144050, training_loss: 1.93498e-02
I0215 11:15:54.465894 23126066861888 run_lib.py:133] step: 144100, training_loss: 2.04495e-02
I0215 11:15:54.642267 23126066861888 run_lib.py:146] step: 144100, eval_loss: 2.59592e-02
I0215 11:16:12.033008 23126066861888 run_lib.py:133] step: 144150, training_loss: 1.97946e-02
I0215 11:16:29.459560 23126066861888 run_lib.py:133] step: 144200, training_loss: 2.02361e-02
I0215 11:16:29.616209 23126066861888 run_lib.py:146] step: 144200, eval_loss: 2.65414e-02
I0215 11:16:47.184960 23126066861888 run_lib.py:133] step: 144250, training_loss: 1.98852e-02
I0215 11:17:04.567599 23126066861888 run_lib.py:133] step: 144300, training_loss: 2.03872e-02
I0215 11:17:04.720969 23126066861888 run_lib.py:146] step: 144300, eval_loss: 2.59387e-02
I0215 11:17:22.082341 23126066861888 run_lib.py:133] step: 144350, training_loss: 1.98611e-02
I0215 11:17:39.674018 23126066861888 run_lib.py:133] step: 144400, training_loss: 2.12029e-02
I0215 11:17:39.848209 23126066861888 run_lib.py:146] step: 144400, eval_loss: 2.53014e-02
I0215 11:17:57.349499 23126066861888 run_lib.py:133] step: 144450, training_loss: 2.03858e-02
I0215 11:18:14.740978 23126066861888 run_lib.py:133] step: 144500, training_loss: 2.02411e-02
I0215 11:18:14.894025 23126066861888 run_lib.py:146] step: 144500, eval_loss: 2.56990e-02
I0215 11:18:32.438123 23126066861888 run_lib.py:133] step: 144550, training_loss: 1.95981e-02
I0215 11:18:49.847692 23126066861888 run_lib.py:133] step: 144600, training_loss: 2.05071e-02
I0215 11:18:50.012524 23126066861888 run_lib.py:146] step: 144600, eval_loss: 2.56944e-02
I0215 11:19:07.399801 23126066861888 run_lib.py:133] step: 144650, training_loss: 1.98235e-02
I0215 11:19:24.808803 23126066861888 run_lib.py:133] step: 144700, training_loss: 2.03250e-02
I0215 11:19:24.967165 23126066861888 run_lib.py:146] step: 144700, eval_loss: 2.59568e-02
I0215 11:19:42.534974 23126066861888 run_lib.py:133] step: 144750, training_loss: 1.99352e-02
I0215 11:20:00.069537 23126066861888 run_lib.py:133] step: 144800, training_loss: 1.99103e-02
I0215 11:20:00.222806 23126066861888 run_lib.py:146] step: 144800, eval_loss: 2.51109e-02
I0215 11:20:17.611701 23126066861888 run_lib.py:133] step: 144850, training_loss: 2.04270e-02
I0215 11:20:35.037144 23126066861888 run_lib.py:133] step: 144900, training_loss: 2.03589e-02
I0215 11:20:35.190104 23126066861888 run_lib.py:146] step: 144900, eval_loss: 2.54421e-02
I0215 11:20:52.731101 23126066861888 run_lib.py:133] step: 144950, training_loss: 1.98640e-02
I0215 11:21:10.135839 23126066861888 run_lib.py:133] step: 145000, training_loss: 1.96231e-02
I0215 11:21:10.294274 23126066861888 run_lib.py:146] step: 145000, eval_loss: 2.49674e-02
I0215 11:21:27.711297 23126066861888 run_lib.py:133] step: 145050, training_loss: 1.99335e-02
I0215 11:21:45.320957 23126066861888 run_lib.py:133] step: 145100, training_loss: 2.00370e-02
I0215 11:21:45.483355 23126066861888 run_lib.py:146] step: 145100, eval_loss: 2.63955e-02
I0215 11:22:02.911638 23126066861888 run_lib.py:133] step: 145150, training_loss: 1.98078e-02
I0215 11:22:20.452896 23126066861888 run_lib.py:133] step: 145200, training_loss: 2.00478e-02
I0215 11:22:20.630914 23126066861888 run_lib.py:146] step: 145200, eval_loss: 2.65389e-02
I0215 11:22:38.045171 23126066861888 run_lib.py:133] step: 145250, training_loss: 1.89553e-02
I0215 11:22:55.545130 23126066861888 run_lib.py:133] step: 145300, training_loss: 2.00761e-02
I0215 11:22:55.697992 23126066861888 run_lib.py:146] step: 145300, eval_loss: 2.54964e-02
I0215 11:23:13.351921 23126066861888 run_lib.py:133] step: 145350, training_loss: 2.02406e-02
I0215 11:23:30.735747 23126066861888 run_lib.py:133] step: 145400, training_loss: 2.04131e-02
I0215 11:23:30.886981 23126066861888 run_lib.py:146] step: 145400, eval_loss: 2.58342e-02
I0215 11:23:48.294197 23126066861888 run_lib.py:133] step: 145450, training_loss: 2.00310e-02
I0215 11:24:05.892012 23126066861888 run_lib.py:133] step: 145500, training_loss: 1.98938e-02
I0215 11:24:06.045015 23126066861888 run_lib.py:146] step: 145500, eval_loss: 2.55867e-02
I0215 11:24:23.484999 23126066861888 run_lib.py:133] step: 145550, training_loss: 2.02196e-02
I0215 11:24:40.957042 23126066861888 run_lib.py:133] step: 145600, training_loss: 2.04842e-02
I0215 11:24:41.113254 23126066861888 run_lib.py:146] step: 145600, eval_loss: 2.54334e-02
I0215 11:24:58.638106 23126066861888 run_lib.py:133] step: 145650, training_loss: 1.97688e-02
I0215 11:25:16.067736 23126066861888 run_lib.py:133] step: 145700, training_loss: 1.93180e-02
I0215 11:25:16.220882 23126066861888 run_lib.py:146] step: 145700, eval_loss: 2.48737e-02
I0215 11:25:33.650553 23126066861888 run_lib.py:133] step: 145750, training_loss: 1.96544e-02
I0215 11:25:51.099409 23126066861888 run_lib.py:133] step: 145800, training_loss: 2.05598e-02
I0215 11:25:51.252012 23126066861888 run_lib.py:146] step: 145800, eval_loss: 2.58098e-02
I0215 11:26:08.763351 23126066861888 run_lib.py:133] step: 145850, training_loss: 2.01080e-02
I0215 11:26:26.308331 23126066861888 run_lib.py:133] step: 145900, training_loss: 2.01126e-02
I0215 11:26:26.462416 23126066861888 run_lib.py:146] step: 145900, eval_loss: 2.55677e-02
I0215 11:26:43.864748 23126066861888 run_lib.py:133] step: 145950, training_loss: 2.00261e-02
I0215 11:27:01.282204 23126066861888 run_lib.py:133] step: 146000, training_loss: 2.09092e-02
I0215 11:27:01.436269 23126066861888 run_lib.py:146] step: 146000, eval_loss: 2.60760e-02
I0215 11:27:18.933329 23126066861888 run_lib.py:133] step: 146050, training_loss: 2.02456e-02
I0215 11:27:36.363238 23126066861888 run_lib.py:133] step: 146100, training_loss: 2.06336e-02
I0215 11:27:36.519250 23126066861888 run_lib.py:146] step: 146100, eval_loss: 2.60341e-02
I0215 11:27:53.856892 23126066861888 run_lib.py:133] step: 146150, training_loss: 2.05689e-02
I0215 11:28:11.451949 23126066861888 run_lib.py:133] step: 146200, training_loss: 2.06803e-02
I0215 11:28:11.607516 23126066861888 run_lib.py:146] step: 146200, eval_loss: 2.46234e-02
I0215 11:28:29.023613 23126066861888 run_lib.py:133] step: 146250, training_loss: 2.00244e-02
I0215 11:28:46.603390 23126066861888 run_lib.py:133] step: 146300, training_loss: 1.97966e-02
I0215 11:28:46.756011 23126066861888 run_lib.py:146] step: 146300, eval_loss: 2.70491e-02
I0215 11:29:04.119664 23126066861888 run_lib.py:133] step: 146350, training_loss: 2.08520e-02
I0215 11:29:21.511941 23126066861888 run_lib.py:133] step: 146400, training_loss: 1.96900e-02
I0215 11:29:21.663028 23126066861888 run_lib.py:146] step: 146400, eval_loss: 2.53674e-02
I0215 11:29:39.254268 23126066861888 run_lib.py:133] step: 146450, training_loss: 2.04549e-02
I0215 11:29:56.699643 23126066861888 run_lib.py:133] step: 146500, training_loss: 1.99136e-02
I0215 11:29:56.863137 23126066861888 run_lib.py:146] step: 146500, eval_loss: 2.67308e-02
I0215 11:30:14.250557 23126066861888 run_lib.py:133] step: 146550, training_loss: 2.00827e-02
I0215 11:30:31.818721 23126066861888 run_lib.py:133] step: 146600, training_loss: 2.02330e-02
I0215 11:30:31.973278 23126066861888 run_lib.py:146] step: 146600, eval_loss: 2.65450e-02
I0215 11:30:49.379909 23126066861888 run_lib.py:133] step: 146650, training_loss: 2.00008e-02
I0215 11:31:06.741186 23126066861888 run_lib.py:133] step: 146700, training_loss: 1.96077e-02
I0215 11:31:06.898033 23126066861888 run_lib.py:146] step: 146700, eval_loss: 2.67392e-02
I0215 11:31:24.361153 23126066861888 run_lib.py:133] step: 146750, training_loss: 1.96747e-02
I0215 11:31:41.774174 23126066861888 run_lib.py:133] step: 146800, training_loss: 1.98593e-02
I0215 11:31:41.926290 23126066861888 run_lib.py:146] step: 146800, eval_loss: 2.57918e-02
I0215 11:31:59.365580 23126066861888 run_lib.py:133] step: 146850, training_loss: 2.00398e-02
I0215 11:32:16.764126 23126066861888 run_lib.py:133] step: 146900, training_loss: 2.03074e-02
I0215 11:32:16.917083 23126066861888 run_lib.py:146] step: 146900, eval_loss: 2.63697e-02
I0215 11:32:34.467854 23126066861888 run_lib.py:133] step: 146950, training_loss: 1.92162e-02
I0215 11:32:51.889307 23126066861888 run_lib.py:133] step: 147000, training_loss: 1.96071e-02
I0215 11:32:52.054183 23126066861888 run_lib.py:146] step: 147000, eval_loss: 2.52844e-02
I0215 11:33:09.464501 23126066861888 run_lib.py:133] step: 147050, training_loss: 1.97653e-02
I0215 11:33:26.914298 23126066861888 run_lib.py:133] step: 147100, training_loss: 1.95891e-02
I0215 11:33:27.069366 23126066861888 run_lib.py:146] step: 147100, eval_loss: 2.73943e-02
I0215 11:33:44.627814 23126066861888 run_lib.py:133] step: 147150, training_loss: 2.01526e-02
I0215 11:34:01.996374 23126066861888 run_lib.py:133] step: 147200, training_loss: 1.93497e-02
I0215 11:34:02.151037 23126066861888 run_lib.py:146] step: 147200, eval_loss: 2.54621e-02
I0215 11:34:19.511274 23126066861888 run_lib.py:133] step: 147250, training_loss: 2.10534e-02
I0215 11:34:37.008533 23126066861888 run_lib.py:133] step: 147300, training_loss: 1.95086e-02
I0215 11:34:37.157575 23126066861888 run_lib.py:146] step: 147300, eval_loss: 2.63603e-02
I0215 11:34:54.571059 23126066861888 run_lib.py:133] step: 147350, training_loss: 2.04153e-02
I0215 11:35:12.123365 23126066861888 run_lib.py:133] step: 147400, training_loss: 1.98212e-02
I0215 11:35:12.289604 23126066861888 run_lib.py:146] step: 147400, eval_loss: 2.57295e-02
I0215 11:35:29.707434 23126066861888 run_lib.py:133] step: 147450, training_loss: 1.98564e-02
I0215 11:35:47.091451 23126066861888 run_lib.py:133] step: 147500, training_loss: 1.99378e-02
I0215 11:35:47.248545 23126066861888 run_lib.py:146] step: 147500, eval_loss: 2.64980e-02
I0215 11:36:04.788856 23126066861888 run_lib.py:133] step: 147550, training_loss: 2.01050e-02
I0215 11:36:22.169191 23126066861888 run_lib.py:133] step: 147600, training_loss: 2.02711e-02
I0215 11:36:22.334064 23126066861888 run_lib.py:146] step: 147600, eval_loss: 2.56072e-02
I0215 11:36:39.752871 23126066861888 run_lib.py:133] step: 147650, training_loss: 1.94448e-02
I0215 11:36:57.418382 23126066861888 run_lib.py:133] step: 147700, training_loss: 1.96493e-02
I0215 11:36:57.576310 23126066861888 run_lib.py:146] step: 147700, eval_loss: 2.55052e-02
I0215 11:37:14.967322 23126066861888 run_lib.py:133] step: 147750, training_loss: 1.97125e-02
I0215 11:37:32.344060 23126066861888 run_lib.py:133] step: 147800, training_loss: 1.99074e-02
I0215 11:37:32.496237 23126066861888 run_lib.py:146] step: 147800, eval_loss: 2.62240e-02
I0215 11:37:49.930410 23126066861888 run_lib.py:133] step: 147850, training_loss: 2.05352e-02
I0215 11:38:07.282246 23126066861888 run_lib.py:133] step: 147900, training_loss: 1.98253e-02
I0215 11:38:07.449988 23126066861888 run_lib.py:146] step: 147900, eval_loss: 2.72941e-02
I0215 11:38:24.892611 23126066861888 run_lib.py:133] step: 147950, training_loss: 1.93267e-02
I0215 11:38:42.335451 23126066861888 run_lib.py:133] step: 148000, training_loss: 2.00637e-02
I0215 11:38:42.492281 23126066861888 run_lib.py:146] step: 148000, eval_loss: 2.56546e-02
I0215 11:39:00.045079 23126066861888 run_lib.py:133] step: 148050, training_loss: 1.94396e-02
I0215 11:39:17.445814 23126066861888 run_lib.py:133] step: 148100, training_loss: 2.03839e-02
I0215 11:39:17.602948 23126066861888 run_lib.py:146] step: 148100, eval_loss: 2.54736e-02
I0215 11:39:34.978171 23126066861888 run_lib.py:133] step: 148150, training_loss: 2.02607e-02
I0215 11:39:52.405643 23126066861888 run_lib.py:133] step: 148200, training_loss: 2.01507e-02
I0215 11:39:52.558187 23126066861888 run_lib.py:146] step: 148200, eval_loss: 2.57185e-02
I0215 11:40:10.163597 23126066861888 run_lib.py:133] step: 148250, training_loss: 2.04498e-02
I0215 11:40:27.535523 23126066861888 run_lib.py:133] step: 148300, training_loss: 1.98465e-02
I0215 11:40:27.687927 23126066861888 run_lib.py:146] step: 148300, eval_loss: 2.53982e-02
I0215 11:40:45.063851 23126066861888 run_lib.py:133] step: 148350, training_loss: 1.96176e-02
I0215 11:41:02.670147 23126066861888 run_lib.py:133] step: 148400, training_loss: 1.99652e-02
I0215 11:41:02.827466 23126066861888 run_lib.py:146] step: 148400, eval_loss: 2.62672e-02
I0215 11:41:20.158937 23126066861888 run_lib.py:133] step: 148450, training_loss: 2.05107e-02
I0215 11:41:37.721758 23126066861888 run_lib.py:133] step: 148500, training_loss: 2.00957e-02
I0215 11:41:37.887179 23126066861888 run_lib.py:146] step: 148500, eval_loss: 2.61463e-02
I0215 11:41:55.280268 23126066861888 run_lib.py:133] step: 148550, training_loss: 2.05526e-02
I0215 11:42:12.680909 23126066861888 run_lib.py:133] step: 148600, training_loss: 1.99600e-02
I0215 11:42:12.834741 23126066861888 run_lib.py:146] step: 148600, eval_loss: 2.56090e-02
I0215 11:42:30.425693 23126066861888 run_lib.py:133] step: 148650, training_loss: 1.92086e-02
I0215 11:42:47.811767 23126066861888 run_lib.py:133] step: 148700, training_loss: 2.00409e-02
I0215 11:42:47.970343 23126066861888 run_lib.py:146] step: 148700, eval_loss: 2.59923e-02
I0215 11:43:05.349301 23126066861888 run_lib.py:133] step: 148750, training_loss: 2.03943e-02
I0215 11:43:22.925328 23126066861888 run_lib.py:133] step: 148800, training_loss: 1.91919e-02
I0215 11:43:23.102143 23126066861888 run_lib.py:146] step: 148800, eval_loss: 2.61217e-02
I0215 11:43:40.541165 23126066861888 run_lib.py:133] step: 148850, training_loss: 1.95622e-02
I0215 11:43:57.935735 23126066861888 run_lib.py:133] step: 148900, training_loss: 1.99107e-02
I0215 11:43:58.092282 23126066861888 run_lib.py:146] step: 148900, eval_loss: 2.49906e-02
I0215 11:44:15.569710 23126066861888 run_lib.py:133] step: 148950, training_loss: 2.04277e-02
I0215 11:44:32.971951 23126066861888 run_lib.py:133] step: 149000, training_loss: 2.02318e-02
I0215 11:44:33.127075 23126066861888 run_lib.py:146] step: 149000, eval_loss: 2.53533e-02
I0215 11:44:50.512969 23126066861888 run_lib.py:133] step: 149050, training_loss: 2.02244e-02
I0215 11:45:07.930104 23126066861888 run_lib.py:133] step: 149100, training_loss: 2.07979e-02
I0215 11:45:08.084148 23126066861888 run_lib.py:146] step: 149100, eval_loss: 2.68444e-02
I0215 11:45:25.712215 23126066861888 run_lib.py:133] step: 149150, training_loss: 1.98951e-02
I0215 11:45:43.176213 23126066861888 run_lib.py:133] step: 149200, training_loss: 1.99171e-02
I0215 11:45:43.328134 23126066861888 run_lib.py:146] step: 149200, eval_loss: 2.61459e-02
I0215 11:46:00.677738 23126066861888 run_lib.py:133] step: 149250, training_loss: 2.05043e-02
I0215 11:46:18.050293 23126066861888 run_lib.py:133] step: 149300, training_loss: 1.92063e-02
I0215 11:46:18.207054 23126066861888 run_lib.py:146] step: 149300, eval_loss: 2.58567e-02
I0215 11:46:35.750650 23126066861888 run_lib.py:133] step: 149350, training_loss: 1.94313e-02
I0215 11:46:53.181776 23126066861888 run_lib.py:133] step: 149400, training_loss: 1.97774e-02
I0215 11:46:53.358188 23126066861888 run_lib.py:146] step: 149400, eval_loss: 2.57170e-02
I0215 11:47:10.750200 23126066861888 run_lib.py:133] step: 149450, training_loss: 1.97834e-02
I0215 11:47:28.301692 23126066861888 run_lib.py:133] step: 149500, training_loss: 2.00141e-02
I0215 11:47:28.456210 23126066861888 run_lib.py:146] step: 149500, eval_loss: 2.59971e-02
I0215 11:47:45.875537 23126066861888 run_lib.py:133] step: 149550, training_loss: 2.00755e-02
I0215 11:48:03.393473 23126066861888 run_lib.py:133] step: 149600, training_loss: 1.99719e-02
I0215 11:48:03.551983 23126066861888 run_lib.py:146] step: 149600, eval_loss: 2.56587e-02
I0215 11:48:20.938280 23126066861888 run_lib.py:133] step: 149650, training_loss: 2.03213e-02
I0215 11:48:38.347251 23126066861888 run_lib.py:133] step: 149700, training_loss: 1.96769e-02
I0215 11:48:38.510448 23126066861888 run_lib.py:146] step: 149700, eval_loss: 2.74563e-02
I0215 11:48:56.125166 23126066861888 run_lib.py:133] step: 149750, training_loss: 2.04903e-02
I0215 11:49:13.510133 23126066861888 run_lib.py:133] step: 149800, training_loss: 1.98192e-02
I0215 11:49:13.664177 23126066861888 run_lib.py:146] step: 149800, eval_loss: 2.67974e-02
I0215 11:49:31.020471 23126066861888 run_lib.py:133] step: 149850, training_loss: 2.01695e-02
I0215 11:49:48.542548 23126066861888 run_lib.py:133] step: 149900, training_loss: 2.01973e-02
I0215 11:49:48.705793 23126066861888 run_lib.py:146] step: 149900, eval_loss: 2.48638e-02
I0215 11:50:06.104643 23126066861888 run_lib.py:133] step: 149950, training_loss: 2.02768e-02
I0215 11:50:23.556801 23126066861888 run_lib.py:133] step: 150000, training_loss: 1.96714e-02
I0215 11:50:24.269237 23126066861888 run_lib.py:146] step: 150000, eval_loss: 2.61226e-02
I0215 11:50:44.783554 23126066861888 run_lib.py:133] step: 150050, training_loss: 2.00740e-02
I0215 11:51:02.307278 23126066861888 run_lib.py:133] step: 150100, training_loss: 1.97771e-02
I0215 11:51:02.462020 23126066861888 run_lib.py:146] step: 150100, eval_loss: 2.73636e-02
I0215 11:51:19.812057 23126066861888 run_lib.py:133] step: 150150, training_loss: 2.04943e-02
I0215 11:51:37.199548 23126066861888 run_lib.py:133] step: 150200, training_loss: 2.00628e-02
I0215 11:51:37.351035 23126066861888 run_lib.py:146] step: 150200, eval_loss: 2.53125e-02
I0215 11:51:54.793385 23126066861888 run_lib.py:133] step: 150250, training_loss: 1.98014e-02
I0215 11:52:12.385791 23126066861888 run_lib.py:133] step: 150300, training_loss: 2.01350e-02
I0215 11:52:12.539234 23126066861888 run_lib.py:146] step: 150300, eval_loss: 2.57126e-02
I0215 11:52:29.948148 23126066861888 run_lib.py:133] step: 150350, training_loss: 2.01843e-02
I0215 11:52:47.341130 23126066861888 run_lib.py:133] step: 150400, training_loss: 2.04205e-02
I0215 11:52:47.496179 23126066861888 run_lib.py:146] step: 150400, eval_loss: 2.61931e-02
I0215 11:53:05.022065 23126066861888 run_lib.py:133] step: 150450, training_loss: 2.01454e-02
I0215 11:53:22.385748 23126066861888 run_lib.py:133] step: 150500, training_loss: 2.01303e-02
I0215 11:53:22.563050 23126066861888 run_lib.py:146] step: 150500, eval_loss: 2.54311e-02
I0215 11:53:40.103329 23126066861888 run_lib.py:133] step: 150550, training_loss: 1.97788e-02
I0215 11:53:57.486440 23126066861888 run_lib.py:133] step: 150600, training_loss: 1.96925e-02
I0215 11:53:57.648393 23126066861888 run_lib.py:146] step: 150600, eval_loss: 2.53867e-02
I0215 11:54:15.019963 23126066861888 run_lib.py:133] step: 150650, training_loss: 2.01249e-02
I0215 11:54:32.381523 23126066861888 run_lib.py:133] step: 150700, training_loss: 2.05714e-02
I0215 11:54:32.534178 23126066861888 run_lib.py:146] step: 150700, eval_loss: 2.49401e-02
I0215 11:54:50.053165 23126066861888 run_lib.py:133] step: 150750, training_loss: 1.97681e-02
I0215 11:55:07.562415 23126066861888 run_lib.py:133] step: 150800, training_loss: 2.02371e-02
I0215 11:55:07.736920 23126066861888 run_lib.py:146] step: 150800, eval_loss: 2.74184e-02
I0215 11:55:25.183390 23126066861888 run_lib.py:133] step: 150850, training_loss: 1.98550e-02
I0215 11:55:42.579784 23126066861888 run_lib.py:133] step: 150900, training_loss: 2.05015e-02
I0215 11:55:42.742235 23126066861888 run_lib.py:146] step: 150900, eval_loss: 2.61837e-02
I0215 11:56:00.285390 23126066861888 run_lib.py:133] step: 150950, training_loss: 2.02655e-02
I0215 11:56:17.685664 23126066861888 run_lib.py:133] step: 151000, training_loss: 2.00525e-02
I0215 11:56:17.839241 23126066861888 run_lib.py:146] step: 151000, eval_loss: 2.66031e-02
I0215 11:56:35.225255 23126066861888 run_lib.py:133] step: 151050, training_loss: 2.01264e-02
I0215 11:56:52.802624 23126066861888 run_lib.py:133] step: 151100, training_loss: 2.02602e-02
I0215 11:56:52.955719 23126066861888 run_lib.py:146] step: 151100, eval_loss: 2.69461e-02
I0215 11:57:10.392142 23126066861888 run_lib.py:133] step: 151150, training_loss: 1.96539e-02
I0215 11:57:27.927306 23126066861888 run_lib.py:133] step: 151200, training_loss: 1.94330e-02
I0215 11:57:28.078030 23126066861888 run_lib.py:146] step: 151200, eval_loss: 2.64188e-02
I0215 11:57:45.427055 23126066861888 run_lib.py:133] step: 151250, training_loss: 2.02298e-02
I0215 11:58:02.802386 23126066861888 run_lib.py:133] step: 151300, training_loss: 2.02964e-02
I0215 11:58:02.965200 23126066861888 run_lib.py:146] step: 151300, eval_loss: 2.64913e-02
I0215 11:58:20.521741 23126066861888 run_lib.py:133] step: 151350, training_loss: 1.93692e-02
I0215 11:58:38.002830 23126066861888 run_lib.py:133] step: 151400, training_loss: 1.99051e-02
I0215 11:58:38.158286 23126066861888 run_lib.py:146] step: 151400, eval_loss: 2.67665e-02
I0215 11:58:55.560704 23126066861888 run_lib.py:133] step: 151450, training_loss: 2.01043e-02
I0215 11:59:12.911504 23126066861888 run_lib.py:133] step: 151500, training_loss: 1.89636e-02
I0215 11:59:13.065283 23126066861888 run_lib.py:146] step: 151500, eval_loss: 2.57868e-02
I0215 11:59:30.701242 23126066861888 run_lib.py:133] step: 151550, training_loss: 2.02668e-02
I0215 11:59:48.103662 23126066861888 run_lib.py:133] step: 151600, training_loss: 2.03080e-02
I0215 11:59:48.255100 23126066861888 run_lib.py:146] step: 151600, eval_loss: 2.53330e-02
I0215 12:00:05.724946 23126066861888 run_lib.py:133] step: 151650, training_loss: 2.02269e-02
I0215 12:00:23.136171 23126066861888 run_lib.py:133] step: 151700, training_loss: 1.95233e-02
I0215 12:00:23.296163 23126066861888 run_lib.py:146] step: 151700, eval_loss: 2.52095e-02
I0215 12:00:40.716453 23126066861888 run_lib.py:133] step: 151750, training_loss: 1.94483e-02
I0215 12:00:58.147472 23126066861888 run_lib.py:133] step: 151800, training_loss: 1.98260e-02
I0215 12:00:58.299906 23126066861888 run_lib.py:146] step: 151800, eval_loss: 2.52995e-02
I0215 12:01:15.842431 23126066861888 run_lib.py:133] step: 151850, training_loss: 1.91731e-02
I0215 12:01:33.255992 23126066861888 run_lib.py:133] step: 151900, training_loss: 2.03045e-02
I0215 12:01:33.413178 23126066861888 run_lib.py:146] step: 151900, eval_loss: 2.69040e-02
I0215 12:01:50.850854 23126066861888 run_lib.py:133] step: 151950, training_loss: 2.02121e-02
I0215 12:02:08.290330 23126066861888 run_lib.py:133] step: 152000, training_loss: 2.03725e-02
I0215 12:02:08.448620 23126066861888 run_lib.py:146] step: 152000, eval_loss: 2.68871e-02
I0215 12:02:26.090816 23126066861888 run_lib.py:133] step: 152050, training_loss: 1.96120e-02
I0215 12:02:43.465376 23126066861888 run_lib.py:133] step: 152100, training_loss: 1.93855e-02
I0215 12:02:43.615753 23126066861888 run_lib.py:146] step: 152100, eval_loss: 2.68840e-02
I0215 12:03:00.989387 23126066861888 run_lib.py:133] step: 152150, training_loss: 2.03094e-02
I0215 12:03:18.519302 23126066861888 run_lib.py:133] step: 152200, training_loss: 1.98662e-02
I0215 12:03:18.673619 23126066861888 run_lib.py:146] step: 152200, eval_loss: 2.54605e-02
I0215 12:03:36.095228 23126066861888 run_lib.py:133] step: 152250, training_loss: 1.93886e-02
I0215 12:03:53.654741 23126066861888 run_lib.py:133] step: 152300, training_loss: 1.93068e-02
I0215 12:03:53.815323 23126066861888 run_lib.py:146] step: 152300, eval_loss: 2.68878e-02
I0215 12:04:11.252199 23126066861888 run_lib.py:133] step: 152350, training_loss: 2.04260e-02
I0215 12:04:28.699360 23126066861888 run_lib.py:133] step: 152400, training_loss: 2.00789e-02
I0215 12:04:28.854090 23126066861888 run_lib.py:146] step: 152400, eval_loss: 2.66050e-02
I0215 12:04:46.419707 23126066861888 run_lib.py:133] step: 152450, training_loss: 1.95532e-02
I0215 12:05:03.857379 23126066861888 run_lib.py:133] step: 152500, training_loss: 2.01058e-02
I0215 12:05:04.010863 23126066861888 run_lib.py:146] step: 152500, eval_loss: 2.51772e-02
I0215 12:05:21.395553 23126066861888 run_lib.py:133] step: 152550, training_loss: 2.10520e-02
I0215 12:05:38.986306 23126066861888 run_lib.py:133] step: 152600, training_loss: 1.98283e-02
I0215 12:05:39.140518 23126066861888 run_lib.py:146] step: 152600, eval_loss: 2.61888e-02
I0215 12:05:56.543624 23126066861888 run_lib.py:133] step: 152650, training_loss: 2.07992e-02
I0215 12:06:13.924030 23126066861888 run_lib.py:133] step: 152700, training_loss: 1.92431e-02
I0215 12:06:14.078213 23126066861888 run_lib.py:146] step: 152700, eval_loss: 2.56404e-02
I0215 12:06:31.503964 23126066861888 run_lib.py:133] step: 152750, training_loss: 2.00654e-02
I0215 12:06:48.890522 23126066861888 run_lib.py:133] step: 152800, training_loss: 2.00296e-02
I0215 12:06:49.047637 23126066861888 run_lib.py:146] step: 152800, eval_loss: 2.57870e-02
I0215 12:07:06.464276 23126066861888 run_lib.py:133] step: 152850, training_loss: 1.92714e-02
I0215 12:07:23.938507 23126066861888 run_lib.py:133] step: 152900, training_loss: 1.96962e-02
I0215 12:07:24.101293 23126066861888 run_lib.py:146] step: 152900, eval_loss: 2.66447e-02
I0215 12:07:41.674857 23126066861888 run_lib.py:133] step: 152950, training_loss: 1.97062e-02
I0215 12:07:59.114403 23126066861888 run_lib.py:133] step: 153000, training_loss: 2.00655e-02
I0215 12:07:59.267070 23126066861888 run_lib.py:146] step: 153000, eval_loss: 2.57955e-02
I0215 12:08:16.628093 23126066861888 run_lib.py:133] step: 153050, training_loss: 2.02769e-02
I0215 12:08:34.017203 23126066861888 run_lib.py:133] step: 153100, training_loss: 1.95161e-02
I0215 12:08:34.168342 23126066861888 run_lib.py:146] step: 153100, eval_loss: 2.59677e-02
I0215 12:08:51.702038 23126066861888 run_lib.py:133] step: 153150, training_loss: 2.01128e-02
I0215 12:09:09.153297 23126066861888 run_lib.py:133] step: 153200, training_loss: 2.00286e-02
I0215 12:09:09.322324 23126066861888 run_lib.py:146] step: 153200, eval_loss: 2.57441e-02
I0215 12:09:26.719309 23126066861888 run_lib.py:133] step: 153250, training_loss: 1.98658e-02
I0215 12:09:44.301287 23126066861888 run_lib.py:133] step: 153300, training_loss: 1.90675e-02
I0215 12:09:44.456193 23126066861888 run_lib.py:146] step: 153300, eval_loss: 2.56011e-02
I0215 12:10:01.846478 23126066861888 run_lib.py:133] step: 153350, training_loss: 1.97171e-02
I0215 12:10:19.390743 23126066861888 run_lib.py:133] step: 153400, training_loss: 1.97977e-02
I0215 12:10:19.544787 23126066861888 run_lib.py:146] step: 153400, eval_loss: 2.60112e-02
I0215 12:10:36.925456 23126066861888 run_lib.py:133] step: 153450, training_loss: 2.00645e-02
I0215 12:10:54.404908 23126066861888 run_lib.py:133] step: 153500, training_loss: 2.01422e-02
I0215 12:10:54.563360 23126066861888 run_lib.py:146] step: 153500, eval_loss: 2.62584e-02
I0215 12:11:12.166275 23126066861888 run_lib.py:133] step: 153550, training_loss: 2.02772e-02
I0215 12:11:29.525571 23126066861888 run_lib.py:133] step: 153600, training_loss: 2.00166e-02
I0215 12:11:29.678348 23126066861888 run_lib.py:146] step: 153600, eval_loss: 2.60092e-02
I0215 12:11:47.053548 23126066861888 run_lib.py:133] step: 153650, training_loss: 1.99781e-02
I0215 12:12:04.583321 23126066861888 run_lib.py:133] step: 153700, training_loss: 1.98467e-02
I0215 12:12:04.743865 23126066861888 run_lib.py:146] step: 153700, eval_loss: 2.62381e-02
I0215 12:12:22.158754 23126066861888 run_lib.py:133] step: 153750, training_loss: 2.02885e-02
I0215 12:12:39.613791 23126066861888 run_lib.py:133] step: 153800, training_loss: 2.07833e-02
I0215 12:12:39.768193 23126066861888 run_lib.py:146] step: 153800, eval_loss: 2.56518e-02
I0215 12:12:57.318595 23126066861888 run_lib.py:133] step: 153850, training_loss: 2.03570e-02
I0215 12:13:14.705637 23126066861888 run_lib.py:133] step: 153900, training_loss: 2.07684e-02
I0215 12:13:14.860365 23126066861888 run_lib.py:146] step: 153900, eval_loss: 2.59832e-02
I0215 12:13:32.249821 23126066861888 run_lib.py:133] step: 153950, training_loss: 1.91755e-02
I0215 12:13:49.759577 23126066861888 run_lib.py:133] step: 154000, training_loss: 1.97039e-02
I0215 12:13:49.915117 23126066861888 run_lib.py:146] step: 154000, eval_loss: 2.54265e-02
I0215 12:14:07.531455 23126066861888 run_lib.py:133] step: 154050, training_loss: 1.92044e-02
I0215 12:14:25.079637 23126066861888 run_lib.py:133] step: 154100, training_loss: 1.95096e-02
I0215 12:14:25.234979 23126066861888 run_lib.py:146] step: 154100, eval_loss: 2.58294e-02
I0215 12:14:42.619262 23126066861888 run_lib.py:133] step: 154150, training_loss: 1.99370e-02
I0215 12:15:00.010355 23126066861888 run_lib.py:133] step: 154200, training_loss: 1.94088e-02
I0215 12:15:00.162913 23126066861888 run_lib.py:146] step: 154200, eval_loss: 2.59554e-02
I0215 12:15:17.725216 23126066861888 run_lib.py:133] step: 154250, training_loss: 2.00714e-02
I0215 12:15:35.179628 23126066861888 run_lib.py:133] step: 154300, training_loss: 1.96414e-02
I0215 12:15:35.338110 23126066861888 run_lib.py:146] step: 154300, eval_loss: 2.59338e-02
I0215 12:15:52.760983 23126066861888 run_lib.py:133] step: 154350, training_loss: 1.99869e-02
I0215 12:16:10.368871 23126066861888 run_lib.py:133] step: 154400, training_loss: 2.02421e-02
I0215 12:16:10.525933 23126066861888 run_lib.py:146] step: 154400, eval_loss: 2.54030e-02
I0215 12:16:27.986877 23126066861888 run_lib.py:133] step: 154450, training_loss: 1.90977e-02
I0215 12:16:45.481707 23126066861888 run_lib.py:133] step: 154500, training_loss: 1.99618e-02
I0215 12:16:45.632992 23126066861888 run_lib.py:146] step: 154500, eval_loss: 2.56760e-02
I0215 12:17:03.004012 23126066861888 run_lib.py:133] step: 154550, training_loss: 1.98742e-02
I0215 12:17:20.422808 23126066861888 run_lib.py:133] step: 154600, training_loss: 2.01555e-02
I0215 12:17:20.597451 23126066861888 run_lib.py:146] step: 154600, eval_loss: 2.62513e-02
I0215 12:17:38.209800 23126066861888 run_lib.py:133] step: 154650, training_loss: 1.97372e-02
I0215 12:17:55.638478 23126066861888 run_lib.py:133] step: 154700, training_loss: 2.01705e-02
I0215 12:17:55.829969 23126066861888 run_lib.py:146] step: 154700, eval_loss: 2.77648e-02
I0215 12:18:13.203085 23126066861888 run_lib.py:133] step: 154750, training_loss: 2.01690e-02
I0215 12:18:30.697694 23126066861888 run_lib.py:133] step: 154800, training_loss: 1.97383e-02
I0215 12:18:30.852261 23126066861888 run_lib.py:146] step: 154800, eval_loss: 2.78656e-02
I0215 12:18:48.259010 23126066861888 run_lib.py:133] step: 154850, training_loss: 1.99991e-02
I0215 12:19:05.685097 23126066861888 run_lib.py:133] step: 154900, training_loss: 2.03666e-02
I0215 12:19:05.839251 23126066861888 run_lib.py:146] step: 154900, eval_loss: 2.57894e-02
I0215 12:19:23.349238 23126066861888 run_lib.py:133] step: 154950, training_loss: 2.03072e-02
I0215 12:19:40.718718 23126066861888 run_lib.py:133] step: 155000, training_loss: 1.92363e-02
I0215 12:19:40.870025 23126066861888 run_lib.py:146] step: 155000, eval_loss: 2.68588e-02
I0215 12:19:58.268673 23126066861888 run_lib.py:133] step: 155050, training_loss: 2.04259e-02
I0215 12:20:15.670465 23126066861888 run_lib.py:133] step: 155100, training_loss: 2.01448e-02
I0215 12:20:15.830323 23126066861888 run_lib.py:146] step: 155100, eval_loss: 2.65684e-02
I0215 12:20:33.405584 23126066861888 run_lib.py:133] step: 155150, training_loss: 1.99722e-02
I0215 12:20:50.956479 23126066861888 run_lib.py:133] step: 155200, training_loss: 1.99465e-02
I0215 12:20:51.108368 23126066861888 run_lib.py:146] step: 155200, eval_loss: 2.53568e-02
I0215 12:21:08.510695 23126066861888 run_lib.py:133] step: 155250, training_loss: 1.97560e-02
I0215 12:21:25.868005 23126066861888 run_lib.py:133] step: 155300, training_loss: 1.99139e-02
I0215 12:21:26.022179 23126066861888 run_lib.py:146] step: 155300, eval_loss: 2.64092e-02
I0215 12:21:43.583931 23126066861888 run_lib.py:133] step: 155350, training_loss: 2.07927e-02
I0215 12:22:00.976049 23126066861888 run_lib.py:133] step: 155400, training_loss: 2.02095e-02
I0215 12:22:01.129697 23126066861888 run_lib.py:146] step: 155400, eval_loss: 2.63659e-02
I0215 12:22:18.568060 23126066861888 run_lib.py:133] step: 155450, training_loss: 2.00109e-02
I0215 12:22:36.124374 23126066861888 run_lib.py:133] step: 155500, training_loss: 1.99551e-02
I0215 12:22:36.283072 23126066861888 run_lib.py:146] step: 155500, eval_loss: 2.63908e-02
I0215 12:22:53.632451 23126066861888 run_lib.py:133] step: 155550, training_loss: 1.97738e-02
I0215 12:23:11.150052 23126066861888 run_lib.py:133] step: 155600, training_loss: 2.03985e-02
I0215 12:23:11.307451 23126066861888 run_lib.py:146] step: 155600, eval_loss: 2.73347e-02
I0215 12:23:28.734716 23126066861888 run_lib.py:133] step: 155650, training_loss: 2.03719e-02
I0215 12:23:46.164837 23126066861888 run_lib.py:133] step: 155700, training_loss: 2.02654e-02
I0215 12:23:46.329539 23126066861888 run_lib.py:146] step: 155700, eval_loss: 2.57846e-02
I0215 12:24:03.960825 23126066861888 run_lib.py:133] step: 155750, training_loss: 1.96257e-02
I0215 12:24:21.436280 23126066861888 run_lib.py:133] step: 155800, training_loss: 1.96056e-02
I0215 12:24:21.587852 23126066861888 run_lib.py:146] step: 155800, eval_loss: 2.62780e-02
I0215 12:24:38.985582 23126066861888 run_lib.py:133] step: 155850, training_loss: 2.04262e-02
I0215 12:24:56.525791 23126066861888 run_lib.py:133] step: 155900, training_loss: 2.01438e-02
I0215 12:24:56.679404 23126066861888 run_lib.py:146] step: 155900, eval_loss: 2.48910e-02
I0215 12:25:14.084388 23126066861888 run_lib.py:133] step: 155950, training_loss: 2.03483e-02
I0215 12:25:31.480283 23126066861888 run_lib.py:133] step: 156000, training_loss: 2.01509e-02
I0215 12:25:31.645381 23126066861888 run_lib.py:146] step: 156000, eval_loss: 2.71078e-02
I0215 12:25:49.229196 23126066861888 run_lib.py:133] step: 156050, training_loss: 1.97157e-02
I0215 12:26:06.677708 23126066861888 run_lib.py:133] step: 156100, training_loss: 2.03513e-02
I0215 12:26:06.834287 23126066861888 run_lib.py:146] step: 156100, eval_loss: 2.59392e-02
I0215 12:26:24.214983 23126066861888 run_lib.py:133] step: 156150, training_loss: 1.96223e-02
I0215 12:26:41.630009 23126066861888 run_lib.py:133] step: 156200, training_loss: 1.95322e-02
I0215 12:26:41.781221 23126066861888 run_lib.py:146] step: 156200, eval_loss: 2.58853e-02
I0215 12:26:59.367177 23126066861888 run_lib.py:133] step: 156250, training_loss: 1.99447e-02
I0215 12:27:16.893531 23126066861888 run_lib.py:133] step: 156300, training_loss: 2.05083e-02
I0215 12:27:17.048260 23126066861888 run_lib.py:146] step: 156300, eval_loss: 2.58679e-02
I0215 12:27:34.510839 23126066861888 run_lib.py:133] step: 156350, training_loss: 2.07030e-02
I0215 12:27:51.865262 23126066861888 run_lib.py:133] step: 156400, training_loss: 1.92451e-02
I0215 12:27:52.018296 23126066861888 run_lib.py:146] step: 156400, eval_loss: 2.54245e-02
I0215 12:28:09.572897 23126066861888 run_lib.py:133] step: 156450, training_loss: 2.02504e-02
I0215 12:28:26.928125 23126066861888 run_lib.py:133] step: 156500, training_loss: 1.91856e-02
I0215 12:28:27.081103 23126066861888 run_lib.py:146] step: 156500, eval_loss: 2.68704e-02
I0215 12:28:44.469553 23126066861888 run_lib.py:133] step: 156550, training_loss: 1.97628e-02
I0215 12:29:02.078522 23126066861888 run_lib.py:133] step: 156600, training_loss: 2.09134e-02
I0215 12:29:02.235057 23126066861888 run_lib.py:146] step: 156600, eval_loss: 2.51076e-02
I0215 12:29:19.583726 23126066861888 run_lib.py:133] step: 156650, training_loss: 1.97978e-02
I0215 12:29:37.147301 23126066861888 run_lib.py:133] step: 156700, training_loss: 2.04073e-02
I0215 12:29:37.298871 23126066861888 run_lib.py:146] step: 156700, eval_loss: 2.63039e-02
I0215 12:29:54.643876 23126066861888 run_lib.py:133] step: 156750, training_loss: 1.97499e-02
I0215 12:30:12.003384 23126066861888 run_lib.py:133] step: 156800, training_loss: 1.99469e-02
I0215 12:30:12.156950 23126066861888 run_lib.py:146] step: 156800, eval_loss: 2.68936e-02
I0215 12:30:29.696277 23126066861888 run_lib.py:133] step: 156850, training_loss: 1.94050e-02
I0215 12:30:47.096942 23126066861888 run_lib.py:133] step: 156900, training_loss: 1.98496e-02
I0215 12:30:47.255636 23126066861888 run_lib.py:146] step: 156900, eval_loss: 2.55084e-02
I0215 12:31:04.718363 23126066861888 run_lib.py:133] step: 156950, training_loss: 2.03186e-02
I0215 12:31:22.314968 23126066861888 run_lib.py:133] step: 157000, training_loss: 2.04986e-02
I0215 12:31:22.472204 23126066861888 run_lib.py:146] step: 157000, eval_loss: 2.56146e-02
I0215 12:31:39.846501 23126066861888 run_lib.py:133] step: 157050, training_loss: 1.96467e-02
I0215 12:31:57.240152 23126066861888 run_lib.py:133] step: 157100, training_loss: 1.99982e-02
I0215 12:31:57.394807 23126066861888 run_lib.py:146] step: 157100, eval_loss: 2.65322e-02
I0215 12:32:14.930452 23126066861888 run_lib.py:133] step: 157150, training_loss: 1.96515e-02
I0215 12:32:32.385043 23126066861888 run_lib.py:133] step: 157200, training_loss: 2.07159e-02
I0215 12:32:32.539779 23126066861888 run_lib.py:146] step: 157200, eval_loss: 2.70214e-02
I0215 12:32:49.879736 23126066861888 run_lib.py:133] step: 157250, training_loss: 1.98326e-02
I0215 12:33:07.260669 23126066861888 run_lib.py:133] step: 157300, training_loss: 1.97581e-02
I0215 12:33:07.412974 23126066861888 run_lib.py:146] step: 157300, eval_loss: 2.61292e-02
I0215 12:33:24.970098 23126066861888 run_lib.py:133] step: 157350, training_loss: 2.01169e-02
I0215 12:33:42.464595 23126066861888 run_lib.py:133] step: 157400, training_loss: 2.04201e-02
I0215 12:33:42.616245 23126066861888 run_lib.py:146] step: 157400, eval_loss: 2.53683e-02
I0215 12:34:00.045015 23126066861888 run_lib.py:133] step: 157450, training_loss: 1.96516e-02
I0215 12:34:17.477255 23126066861888 run_lib.py:133] step: 157500, training_loss: 1.94189e-02
I0215 12:34:17.634244 23126066861888 run_lib.py:146] step: 157500, eval_loss: 2.53589e-02
I0215 12:34:35.201391 23126066861888 run_lib.py:133] step: 157550, training_loss: 1.95810e-02
I0215 12:34:52.560811 23126066861888 run_lib.py:133] step: 157600, training_loss: 2.01409e-02
I0215 12:34:52.721923 23126066861888 run_lib.py:146] step: 157600, eval_loss: 2.56582e-02
I0215 12:35:10.137820 23126066861888 run_lib.py:133] step: 157650, training_loss: 1.94854e-02
I0215 12:35:27.638067 23126066861888 run_lib.py:133] step: 157700, training_loss: 1.94618e-02
I0215 12:35:27.797740 23126066861888 run_lib.py:146] step: 157700, eval_loss: 2.62699e-02
I0215 12:35:45.232302 23126066861888 run_lib.py:133] step: 157750, training_loss: 1.97248e-02
I0215 12:36:02.833918 23126066861888 run_lib.py:133] step: 157800, training_loss: 1.97729e-02
I0215 12:36:02.989992 23126066861888 run_lib.py:146] step: 157800, eval_loss: 2.60063e-02
I0215 12:36:20.393201 23126066861888 run_lib.py:133] step: 157850, training_loss: 1.98605e-02
I0215 12:36:37.747694 23126066861888 run_lib.py:133] step: 157900, training_loss: 1.98332e-02
I0215 12:36:37.898401 23126066861888 run_lib.py:146] step: 157900, eval_loss: 2.73278e-02
I0215 12:36:55.528529 23126066861888 run_lib.py:133] step: 157950, training_loss: 2.00956e-02
I0215 12:37:12.955672 23126066861888 run_lib.py:133] step: 158000, training_loss: 1.99094e-02
I0215 12:37:13.130007 23126066861888 run_lib.py:146] step: 158000, eval_loss: 2.61231e-02
I0215 12:37:30.517442 23126066861888 run_lib.py:133] step: 158050, training_loss: 2.07856e-02
I0215 12:37:48.151058 23126066861888 run_lib.py:133] step: 158100, training_loss: 2.06582e-02
I0215 12:37:48.305268 23126066861888 run_lib.py:146] step: 158100, eval_loss: 2.69163e-02
I0215 12:38:05.706150 23126066861888 run_lib.py:133] step: 158150, training_loss: 1.98317e-02
I0215 12:38:23.099585 23126066861888 run_lib.py:133] step: 158200, training_loss: 2.00894e-02
I0215 12:38:23.255254 23126066861888 run_lib.py:146] step: 158200, eval_loss: 2.58307e-02
I0215 12:38:40.698323 23126066861888 run_lib.py:133] step: 158250, training_loss: 2.01854e-02
I0215 12:38:58.109324 23126066861888 run_lib.py:133] step: 158300, training_loss: 2.02341e-02
I0215 12:38:58.271305 23126066861888 run_lib.py:146] step: 158300, eval_loss: 2.56451e-02
I0215 12:39:15.681111 23126066861888 run_lib.py:133] step: 158350, training_loss: 1.99839e-02
I0215 12:39:33.102934 23126066861888 run_lib.py:133] step: 158400, training_loss: 1.94198e-02
I0215 12:39:33.257296 23126066861888 run_lib.py:146] step: 158400, eval_loss: 2.53876e-02
I0215 12:39:50.792191 23126066861888 run_lib.py:133] step: 158450, training_loss: 1.90481e-02
I0215 12:40:08.198288 23126066861888 run_lib.py:133] step: 158500, training_loss: 1.98002e-02
I0215 12:40:08.356138 23126066861888 run_lib.py:146] step: 158500, eval_loss: 2.68936e-02
I0215 12:40:25.782441 23126066861888 run_lib.py:133] step: 158550, training_loss: 2.01249e-02
I0215 12:40:43.209872 23126066861888 run_lib.py:133] step: 158600, training_loss: 2.00208e-02
I0215 12:40:43.365169 23126066861888 run_lib.py:146] step: 158600, eval_loss: 2.56507e-02
I0215 12:41:00.960170 23126066861888 run_lib.py:133] step: 158650, training_loss: 2.10488e-02
I0215 12:41:18.365897 23126066861888 run_lib.py:133] step: 158700, training_loss: 1.95772e-02
I0215 12:41:18.529231 23126066861888 run_lib.py:146] step: 158700, eval_loss: 2.57009e-02
I0215 12:41:35.919480 23126066861888 run_lib.py:133] step: 158750, training_loss: 2.02855e-02
I0215 12:41:53.467310 23126066861888 run_lib.py:133] step: 158800, training_loss: 2.00400e-02
I0215 12:41:53.616049 23126066861888 run_lib.py:146] step: 158800, eval_loss: 2.73229e-02
I0215 12:42:10.971615 23126066861888 run_lib.py:133] step: 158850, training_loss: 2.00824e-02
I0215 12:42:28.530306 23126066861888 run_lib.py:133] step: 158900, training_loss: 1.93513e-02
I0215 12:42:28.711037 23126066861888 run_lib.py:146] step: 158900, eval_loss: 2.63688e-02
I0215 12:42:46.155287 23126066861888 run_lib.py:133] step: 158950, training_loss: 2.07083e-02
I0215 12:43:03.576880 23126066861888 run_lib.py:133] step: 159000, training_loss: 1.98161e-02
I0215 12:43:03.739294 23126066861888 run_lib.py:146] step: 159000, eval_loss: 2.57261e-02
I0215 12:43:21.322666 23126066861888 run_lib.py:133] step: 159050, training_loss: 2.00230e-02
I0215 12:43:38.701179 23126066861888 run_lib.py:133] step: 159100, training_loss: 1.99132e-02
I0215 12:43:38.860130 23126066861888 run_lib.py:146] step: 159100, eval_loss: 2.65943e-02
I0215 12:43:56.278541 23126066861888 run_lib.py:133] step: 159150, training_loss: 2.00592e-02
I0215 12:44:13.891478 23126066861888 run_lib.py:133] step: 159200, training_loss: 1.93718e-02
I0215 12:44:14.051944 23126066861888 run_lib.py:146] step: 159200, eval_loss: 2.52649e-02
I0215 12:44:31.490770 23126066861888 run_lib.py:133] step: 159250, training_loss: 2.04043e-02
I0215 12:44:48.887136 23126066861888 run_lib.py:133] step: 159300, training_loss: 2.02803e-02
I0215 12:44:49.036336 23126066861888 run_lib.py:146] step: 159300, eval_loss: 2.48936e-02
I0215 12:45:06.481316 23126066861888 run_lib.py:133] step: 159350, training_loss: 2.04603e-02
I0215 12:45:23.853459 23126066861888 run_lib.py:133] step: 159400, training_loss: 1.94373e-02
I0215 12:45:24.010217 23126066861888 run_lib.py:146] step: 159400, eval_loss: 2.54739e-02
I0215 12:45:41.410409 23126066861888 run_lib.py:133] step: 159450, training_loss: 1.99108e-02
I0215 12:45:58.830346 23126066861888 run_lib.py:133] step: 159500, training_loss: 1.98677e-02
I0215 12:45:58.993255 23126066861888 run_lib.py:146] step: 159500, eval_loss: 2.46430e-02
I0215 12:46:16.600639 23126066861888 run_lib.py:133] step: 159550, training_loss: 1.87501e-02
I0215 12:46:34.022126 23126066861888 run_lib.py:133] step: 159600, training_loss: 1.93538e-02
I0215 12:46:34.174281 23126066861888 run_lib.py:146] step: 159600, eval_loss: 2.70532e-02
I0215 12:46:51.565500 23126066861888 run_lib.py:133] step: 159650, training_loss: 1.96508e-02
I0215 12:47:08.983237 23126066861888 run_lib.py:133] step: 159700, training_loss: 1.95954e-02
I0215 12:47:09.133218 23126066861888 run_lib.py:146] step: 159700, eval_loss: 2.58040e-02
I0215 12:47:26.730722 23126066861888 run_lib.py:133] step: 159750, training_loss: 1.99216e-02
I0215 12:47:44.221692 23126066861888 run_lib.py:133] step: 159800, training_loss: 1.96586e-02
I0215 12:47:44.380341 23126066861888 run_lib.py:146] step: 159800, eval_loss: 2.66666e-02
I0215 12:48:01.759063 23126066861888 run_lib.py:133] step: 159850, training_loss: 1.95930e-02
I0215 12:48:19.331060 23126066861888 run_lib.py:133] step: 159900, training_loss: 2.01031e-02
I0215 12:48:19.489470 23126066861888 run_lib.py:146] step: 159900, eval_loss: 2.58397e-02
I0215 12:48:36.876654 23126066861888 run_lib.py:133] step: 159950, training_loss: 1.92674e-02
I0215 12:48:54.378627 23126066861888 run_lib.py:133] step: 160000, training_loss: 1.91755e-02
I0215 12:48:55.614287 23126066861888 run_lib.py:146] step: 160000, eval_loss: 2.65180e-02
I0215 12:49:16.230663 23126066861888 run_lib.py:133] step: 160050, training_loss: 2.00295e-02
I0215 12:49:33.627438 23126066861888 run_lib.py:133] step: 160100, training_loss: 1.97884e-02
I0215 12:49:33.782475 23126066861888 run_lib.py:146] step: 160100, eval_loss: 2.54488e-02
I0215 12:49:51.157884 23126066861888 run_lib.py:133] step: 160150, training_loss: 2.04471e-02
I0215 12:50:08.523122 23126066861888 run_lib.py:133] step: 160200, training_loss: 1.94265e-02
I0215 12:50:08.675246 23126066861888 run_lib.py:146] step: 160200, eval_loss: 2.53735e-02
I0215 12:50:26.207600 23126066861888 run_lib.py:133] step: 160250, training_loss: 1.99877e-02
I0215 12:50:43.701626 23126066861888 run_lib.py:133] step: 160300, training_loss: 2.05649e-02
I0215 12:50:43.861332 23126066861888 run_lib.py:146] step: 160300, eval_loss: 2.61977e-02
I0215 12:51:01.299947 23126066861888 run_lib.py:133] step: 160350, training_loss: 2.01368e-02
I0215 12:51:18.668446 23126066861888 run_lib.py:133] step: 160400, training_loss: 2.02963e-02
I0215 12:51:18.833007 23126066861888 run_lib.py:146] step: 160400, eval_loss: 2.60760e-02
I0215 12:51:36.386916 23126066861888 run_lib.py:133] step: 160450, training_loss: 1.98068e-02
I0215 12:51:53.743867 23126066861888 run_lib.py:133] step: 160500, training_loss: 2.01722e-02
I0215 12:51:53.901968 23126066861888 run_lib.py:146] step: 160500, eval_loss: 2.62013e-02
I0215 12:52:11.307981 23126066861888 run_lib.py:133] step: 160550, training_loss: 2.04758e-02
I0215 12:52:28.910601 23126066861888 run_lib.py:133] step: 160600, training_loss: 2.03789e-02
I0215 12:52:29.092008 23126066861888 run_lib.py:146] step: 160600, eval_loss: 2.55571e-02
I0215 12:52:46.512683 23126066861888 run_lib.py:133] step: 160650, training_loss: 2.03284e-02
I0215 12:53:04.051984 23126066861888 run_lib.py:133] step: 160700, training_loss: 2.00562e-02
I0215 12:53:04.200980 23126066861888 run_lib.py:146] step: 160700, eval_loss: 2.65651e-02
I0215 12:53:21.589184 23126066861888 run_lib.py:133] step: 160750, training_loss: 1.94463e-02
I0215 12:53:38.982905 23126066861888 run_lib.py:133] step: 160800, training_loss: 1.95440e-02
I0215 12:53:39.135882 23126066861888 run_lib.py:146] step: 160800, eval_loss: 2.64581e-02
I0215 12:53:56.674484 23126066861888 run_lib.py:133] step: 160850, training_loss: 1.98047e-02
I0215 12:54:14.153253 23126066861888 run_lib.py:133] step: 160900, training_loss: 1.98313e-02
I0215 12:54:14.313046 23126066861888 run_lib.py:146] step: 160900, eval_loss: 2.73989e-02
I0215 12:54:31.706390 23126066861888 run_lib.py:133] step: 160950, training_loss: 1.96502e-02
I0215 12:54:49.268401 23126066861888 run_lib.py:133] step: 161000, training_loss: 1.98243e-02
I0215 12:54:49.422192 23126066861888 run_lib.py:146] step: 161000, eval_loss: 2.57560e-02
I0215 12:55:06.807452 23126066861888 run_lib.py:133] step: 161050, training_loss: 2.01349e-02
I0215 12:55:24.170269 23126066861888 run_lib.py:133] step: 161100, training_loss: 2.08099e-02
I0215 12:55:24.326208 23126066861888 run_lib.py:146] step: 161100, eval_loss: 2.57047e-02
I0215 12:55:41.779195 23126066861888 run_lib.py:133] step: 161150, training_loss: 1.96911e-02
I0215 12:55:59.169667 23126066861888 run_lib.py:133] step: 161200, training_loss: 1.92075e-02
I0215 12:55:59.330055 23126066861888 run_lib.py:146] step: 161200, eval_loss: 2.63476e-02
I0215 12:56:16.771594 23126066861888 run_lib.py:133] step: 161250, training_loss: 1.98298e-02
I0215 12:56:34.139234 23126066861888 run_lib.py:133] step: 161300, training_loss: 2.00292e-02
I0215 12:56:34.293019 23126066861888 run_lib.py:146] step: 161300, eval_loss: 2.58951e-02
I0215 12:56:51.884708 23126066861888 run_lib.py:133] step: 161350, training_loss: 1.96355e-02
I0215 12:57:09.294851 23126066861888 run_lib.py:133] step: 161400, training_loss: 2.02632e-02
I0215 12:57:09.452219 23126066861888 run_lib.py:146] step: 161400, eval_loss: 2.62824e-02
I0215 12:57:26.950076 23126066861888 run_lib.py:133] step: 161450, training_loss: 1.94439e-02
I0215 12:57:44.420342 23126066861888 run_lib.py:133] step: 161500, training_loss: 1.93321e-02
I0215 12:57:44.576481 23126066861888 run_lib.py:146] step: 161500, eval_loss: 2.51895e-02
I0215 12:58:02.152767 23126066861888 run_lib.py:133] step: 161550, training_loss: 1.95839e-02
I0215 12:58:19.511407 23126066861888 run_lib.py:133] step: 161600, training_loss: 1.99080e-02
I0215 12:58:19.664279 23126066861888 run_lib.py:146] step: 161600, eval_loss: 2.68651e-02
I0215 12:58:37.034577 23126066861888 run_lib.py:133] step: 161650, training_loss: 1.91526e-02
I0215 12:58:54.584442 23126066861888 run_lib.py:133] step: 161700, training_loss: 2.04902e-02
I0215 12:58:54.743257 23126066861888 run_lib.py:146] step: 161700, eval_loss: 2.62392e-02
I0215 12:59:12.139095 23126066861888 run_lib.py:133] step: 161750, training_loss: 1.93925e-02
I0215 12:59:29.690346 23126066861888 run_lib.py:133] step: 161800, training_loss: 2.01493e-02
I0215 12:59:29.845231 23126066861888 run_lib.py:146] step: 161800, eval_loss: 2.56988e-02
I0215 12:59:47.251976 23126066861888 run_lib.py:133] step: 161850, training_loss: 2.02771e-02
I0215 13:00:04.658204 23126066861888 run_lib.py:133] step: 161900, training_loss: 2.05224e-02
I0215 13:00:04.815799 23126066861888 run_lib.py:146] step: 161900, eval_loss: 2.52399e-02
I0215 13:00:22.375374 23126066861888 run_lib.py:133] step: 161950, training_loss: 1.94939e-02
I0215 13:00:39.708470 23126066861888 run_lib.py:133] step: 162000, training_loss: 1.98072e-02
I0215 13:00:39.862210 23126066861888 run_lib.py:146] step: 162000, eval_loss: 2.72361e-02
I0215 13:00:57.250621 23126066861888 run_lib.py:133] step: 162050, training_loss: 1.92327e-02
I0215 13:01:14.921469 23126066861888 run_lib.py:133] step: 162100, training_loss: 1.96161e-02
I0215 13:01:15.074590 23126066861888 run_lib.py:146] step: 162100, eval_loss: 2.70805e-02
I0215 13:01:32.435202 23126066861888 run_lib.py:133] step: 162150, training_loss: 1.97208e-02
I0215 13:01:49.816381 23126066861888 run_lib.py:133] step: 162200, training_loss: 2.06698e-02
I0215 13:01:49.968045 23126066861888 run_lib.py:146] step: 162200, eval_loss: 2.56538e-02
I0215 13:02:07.405150 23126066861888 run_lib.py:133] step: 162250, training_loss: 2.02784e-02
I0215 13:02:24.803150 23126066861888 run_lib.py:133] step: 162300, training_loss: 1.97639e-02
I0215 13:02:24.960196 23126066861888 run_lib.py:146] step: 162300, eval_loss: 2.73823e-02
I0215 13:02:42.349343 23126066861888 run_lib.py:133] step: 162350, training_loss: 2.00322e-02
I0215 13:02:59.756079 23126066861888 run_lib.py:133] step: 162400, training_loss: 1.95415e-02
I0215 13:02:59.914542 23126066861888 run_lib.py:146] step: 162400, eval_loss: 2.55943e-02
I0215 13:03:17.499942 23126066861888 run_lib.py:133] step: 162450, training_loss: 1.96947e-02
I0215 13:03:34.950001 23126066861888 run_lib.py:133] step: 162500, training_loss: 1.99446e-02
I0215 13:03:35.104009 23126066861888 run_lib.py:146] step: 162500, eval_loss: 2.64951e-02
I0215 13:03:52.516233 23126066861888 run_lib.py:133] step: 162550, training_loss: 1.98989e-02
I0215 13:04:09.874718 23126066861888 run_lib.py:133] step: 162600, training_loss: 2.03958e-02
I0215 13:04:10.024999 23126066861888 run_lib.py:146] step: 162600, eval_loss: 2.54012e-02
I0215 13:04:27.548598 23126066861888 run_lib.py:133] step: 162650, training_loss: 2.01453e-02
I0215 13:04:44.948783 23126066861888 run_lib.py:133] step: 162700, training_loss: 2.02678e-02
I0215 13:04:45.122323 23126066861888 run_lib.py:146] step: 162700, eval_loss: 2.73435e-02
I0215 13:05:02.561176 23126066861888 run_lib.py:133] step: 162750, training_loss: 1.96740e-02
I0215 13:05:20.177108 23126066861888 run_lib.py:133] step: 162800, training_loss: 2.00227e-02
I0215 13:05:20.335554 23126066861888 run_lib.py:146] step: 162800, eval_loss: 2.62118e-02
I0215 13:05:37.722879 23126066861888 run_lib.py:133] step: 162850, training_loss: 1.99982e-02
I0215 13:05:55.239194 23126066861888 run_lib.py:133] step: 162900, training_loss: 1.84961e-02
I0215 13:05:55.393237 23126066861888 run_lib.py:146] step: 162900, eval_loss: 2.64671e-02
I0215 13:06:12.790466 23126066861888 run_lib.py:133] step: 162950, training_loss: 2.01321e-02
I0215 13:06:30.197775 23126066861888 run_lib.py:133] step: 163000, training_loss: 1.98942e-02
I0215 13:06:30.353427 23126066861888 run_lib.py:146] step: 163000, eval_loss: 2.58228e-02
I0215 13:06:47.993165 23126066861888 run_lib.py:133] step: 163050, training_loss: 2.00528e-02
I0215 13:07:05.362488 23126066861888 run_lib.py:133] step: 163100, training_loss: 1.93233e-02
I0215 13:07:05.513121 23126066861888 run_lib.py:146] step: 163100, eval_loss: 2.59791e-02
I0215 13:07:22.858584 23126066861888 run_lib.py:133] step: 163150, training_loss: 1.97713e-02
I0215 13:07:40.401048 23126066861888 run_lib.py:133] step: 163200, training_loss: 2.03551e-02
I0215 13:07:40.555050 23126066861888 run_lib.py:146] step: 163200, eval_loss: 2.54030e-02
I0215 13:07:57.918090 23126066861888 run_lib.py:133] step: 163250, training_loss: 2.03947e-02
I0215 13:08:15.333989 23126066861888 run_lib.py:133] step: 163300, training_loss: 1.94198e-02
I0215 13:08:15.500105 23126066861888 run_lib.py:146] step: 163300, eval_loss: 2.62465e-02
I0215 13:08:33.042724 23126066861888 run_lib.py:133] step: 163350, training_loss: 1.97484e-02
I0215 13:08:50.497299 23126066861888 run_lib.py:133] step: 163400, training_loss: 2.01703e-02
I0215 13:08:50.651236 23126066861888 run_lib.py:146] step: 163400, eval_loss: 2.60566e-02
I0215 13:09:08.077816 23126066861888 run_lib.py:133] step: 163450, training_loss: 2.04094e-02
I0215 13:09:25.448838 23126066861888 run_lib.py:133] step: 163500, training_loss: 2.01065e-02
I0215 13:09:25.601154 23126066861888 run_lib.py:146] step: 163500, eval_loss: 2.65823e-02
I0215 13:09:43.154625 23126066861888 run_lib.py:133] step: 163550, training_loss: 2.05297e-02
I0215 13:10:00.704843 23126066861888 run_lib.py:133] step: 163600, training_loss: 1.99306e-02
I0215 13:10:00.859195 23126066861888 run_lib.py:146] step: 163600, eval_loss: 2.70031e-02
I0215 13:10:18.371657 23126066861888 run_lib.py:133] step: 163650, training_loss: 1.89754e-02
I0215 13:10:35.769878 23126066861888 run_lib.py:133] step: 163700, training_loss: 1.96086e-02
I0215 13:10:35.931290 23126066861888 run_lib.py:146] step: 163700, eval_loss: 2.55314e-02
I0215 13:10:53.502673 23126066861888 run_lib.py:133] step: 163750, training_loss: 1.94802e-02
I0215 13:11:10.856532 23126066861888 run_lib.py:133] step: 163800, training_loss: 1.90268e-02
I0215 13:11:11.009535 23126066861888 run_lib.py:146] step: 163800, eval_loss: 2.59665e-02
I0215 13:11:28.414126 23126066861888 run_lib.py:133] step: 163850, training_loss: 1.94558e-02
I0215 13:11:45.988666 23126066861888 run_lib.py:133] step: 163900, training_loss: 1.98011e-02
I0215 13:11:46.143220 23126066861888 run_lib.py:146] step: 163900, eval_loss: 2.59952e-02
I0215 13:12:03.527895 23126066861888 run_lib.py:133] step: 163950, training_loss: 1.93981e-02
I0215 13:12:21.125367 23126066861888 run_lib.py:133] step: 164000, training_loss: 1.94640e-02
I0215 13:12:21.276727 23126066861888 run_lib.py:146] step: 164000, eval_loss: 2.68571e-02
I0215 13:12:38.710298 23126066861888 run_lib.py:133] step: 164050, training_loss: 1.98933e-02
I0215 13:12:56.105869 23126066861888 run_lib.py:133] step: 164100, training_loss: 1.94288e-02
I0215 13:12:56.257028 23126066861888 run_lib.py:146] step: 164100, eval_loss: 2.56147e-02
I0215 13:13:13.767433 23126066861888 run_lib.py:133] step: 164150, training_loss: 2.07121e-02
I0215 13:13:31.216308 23126066861888 run_lib.py:133] step: 164200, training_loss: 2.09453e-02
I0215 13:13:31.385145 23126066861888 run_lib.py:146] step: 164200, eval_loss: 2.63181e-02
I0215 13:13:48.816804 23126066861888 run_lib.py:133] step: 164250, training_loss: 1.98211e-02
I0215 13:14:06.397697 23126066861888 run_lib.py:133] step: 164300, training_loss: 1.97804e-02
I0215 13:14:06.568510 23126066861888 run_lib.py:146] step: 164300, eval_loss: 2.57663e-02
I0215 13:14:23.925590 23126066861888 run_lib.py:133] step: 164350, training_loss: 1.94484e-02
I0215 13:14:41.304683 23126066861888 run_lib.py:133] step: 164400, training_loss: 1.98346e-02
I0215 13:14:41.458085 23126066861888 run_lib.py:146] step: 164400, eval_loss: 2.63309e-02
I0215 13:14:58.919177 23126066861888 run_lib.py:133] step: 164450, training_loss: 1.92998e-02
I0215 13:15:16.354380 23126066861888 run_lib.py:133] step: 164500, training_loss: 2.03815e-02
I0215 13:15:16.505787 23126066861888 run_lib.py:146] step: 164500, eval_loss: 2.57475e-02
I0215 13:15:33.860288 23126066861888 run_lib.py:133] step: 164550, training_loss: 1.96498e-02
I0215 13:15:51.257285 23126066861888 run_lib.py:133] step: 164600, training_loss: 2.00568e-02
I0215 13:15:51.412394 23126066861888 run_lib.py:146] step: 164600, eval_loss: 2.57507e-02
I0215 13:16:08.986933 23126066861888 run_lib.py:133] step: 164650, training_loss: 2.00660e-02
I0215 13:16:26.454969 23126066861888 run_lib.py:133] step: 164700, training_loss: 1.94529e-02
I0215 13:16:26.612514 23126066861888 run_lib.py:146] step: 164700, eval_loss: 2.64379e-02
I0215 13:16:44.021572 23126066861888 run_lib.py:133] step: 164750, training_loss: 2.04155e-02
I0215 13:17:01.437501 23126066861888 run_lib.py:133] step: 164800, training_loss: 1.92626e-02
I0215 13:17:01.589165 23126066861888 run_lib.py:146] step: 164800, eval_loss: 2.71908e-02
I0215 13:17:19.200645 23126066861888 run_lib.py:133] step: 164850, training_loss: 1.94576e-02
I0215 13:17:36.581449 23126066861888 run_lib.py:133] step: 164900, training_loss: 1.93881e-02
I0215 13:17:36.733760 23126066861888 run_lib.py:146] step: 164900, eval_loss: 2.63979e-02
I0215 13:17:54.115716 23126066861888 run_lib.py:133] step: 164950, training_loss: 1.94437e-02
I0215 13:18:11.639988 23126066861888 run_lib.py:133] step: 165000, training_loss: 1.96757e-02
I0215 13:18:11.807368 23126066861888 run_lib.py:146] step: 165000, eval_loss: 2.54399e-02
I0215 13:18:29.187833 23126066861888 run_lib.py:133] step: 165050, training_loss: 2.01796e-02
I0215 13:18:46.711768 23126066861888 run_lib.py:133] step: 165100, training_loss: 1.89059e-02
I0215 13:18:46.880485 23126066861888 run_lib.py:146] step: 165100, eval_loss: 2.64765e-02
I0215 13:19:04.306252 23126066861888 run_lib.py:133] step: 165150, training_loss: 1.95249e-02
I0215 13:19:21.739569 23126066861888 run_lib.py:133] step: 165200, training_loss: 1.93269e-02
I0215 13:19:21.902081 23126066861888 run_lib.py:146] step: 165200, eval_loss: 2.67163e-02
I0215 13:19:39.458157 23126066861888 run_lib.py:133] step: 165250, training_loss: 2.02527e-02
I0215 13:19:56.837750 23126066861888 run_lib.py:133] step: 165300, training_loss: 2.03796e-02
I0215 13:19:56.991976 23126066861888 run_lib.py:146] step: 165300, eval_loss: 2.63475e-02
I0215 13:20:14.421914 23126066861888 run_lib.py:133] step: 165350, training_loss: 1.90301e-02
I0215 13:20:32.044332 23126066861888 run_lib.py:133] step: 165400, training_loss: 1.90400e-02
I0215 13:20:32.197120 23126066861888 run_lib.py:146] step: 165400, eval_loss: 2.69941e-02
I0215 13:20:49.616296 23126066861888 run_lib.py:133] step: 165450, training_loss: 1.97979e-02
I0215 13:21:07.040261 23126066861888 run_lib.py:133] step: 165500, training_loss: 1.92414e-02
I0215 13:21:07.192272 23126066861888 run_lib.py:146] step: 165500, eval_loss: 2.61108e-02
I0215 13:21:24.671624 23126066861888 run_lib.py:133] step: 165550, training_loss: 2.08192e-02
I0215 13:21:42.055414 23126066861888 run_lib.py:133] step: 165600, training_loss: 1.96629e-02
I0215 13:21:42.212075 23126066861888 run_lib.py:146] step: 165600, eval_loss: 2.56680e-02
I0215 13:21:59.577567 23126066861888 run_lib.py:133] step: 165650, training_loss: 1.99129e-02
I0215 13:22:17.006098 23126066861888 run_lib.py:133] step: 165700, training_loss: 2.00371e-02
I0215 13:22:17.165858 23126066861888 run_lib.py:146] step: 165700, eval_loss: 2.56832e-02
I0215 13:22:34.792363 23126066861888 run_lib.py:133] step: 165750, training_loss: 1.90500e-02
I0215 13:22:52.332023 23126066861888 run_lib.py:133] step: 165800, training_loss: 1.94197e-02
I0215 13:22:52.486022 23126066861888 run_lib.py:146] step: 165800, eval_loss: 2.67799e-02
I0215 13:23:09.927410 23126066861888 run_lib.py:133] step: 165850, training_loss: 1.91315e-02
I0215 13:23:27.335090 23126066861888 run_lib.py:133] step: 165900, training_loss: 1.96764e-02
I0215 13:23:27.501144 23126066861888 run_lib.py:146] step: 165900, eval_loss: 2.68596e-02
I0215 13:23:45.050542 23126066861888 run_lib.py:133] step: 165950, training_loss: 2.02823e-02
I0215 13:24:02.478351 23126066861888 run_lib.py:133] step: 166000, training_loss: 1.96772e-02
I0215 13:24:02.644014 23126066861888 run_lib.py:146] step: 166000, eval_loss: 2.60856e-02
I0215 13:24:20.117809 23126066861888 run_lib.py:133] step: 166050, training_loss: 2.00181e-02
I0215 13:24:37.724488 23126066861888 run_lib.py:133] step: 166100, training_loss: 1.85205e-02
I0215 13:24:37.888044 23126066861888 run_lib.py:146] step: 166100, eval_loss: 2.69319e-02
I0215 13:24:55.256023 23126066861888 run_lib.py:133] step: 166150, training_loss: 1.92624e-02
I0215 13:25:12.801280 23126066861888 run_lib.py:133] step: 166200, training_loss: 1.93400e-02
I0215 13:25:12.956332 23126066861888 run_lib.py:146] step: 166200, eval_loss: 2.54627e-02
I0215 13:25:30.358806 23126066861888 run_lib.py:133] step: 166250, training_loss: 1.93642e-02
I0215 13:25:47.783467 23126066861888 run_lib.py:133] step: 166300, training_loss: 2.01714e-02
I0215 13:25:47.937650 23126066861888 run_lib.py:146] step: 166300, eval_loss: 2.63701e-02
I0215 13:26:05.580580 23126066861888 run_lib.py:133] step: 166350, training_loss: 1.97150e-02
I0215 13:26:23.001743 23126066861888 run_lib.py:133] step: 166400, training_loss: 1.92106e-02
I0215 13:26:23.151626 23126066861888 run_lib.py:146] step: 166400, eval_loss: 2.59310e-02
I0215 13:26:40.496280 23126066861888 run_lib.py:133] step: 166450, training_loss: 1.89984e-02
I0215 13:26:57.963553 23126066861888 run_lib.py:133] step: 166500, training_loss: 2.01112e-02
I0215 13:26:58.135264 23126066861888 run_lib.py:146] step: 166500, eval_loss: 2.51483e-02
I0215 13:27:15.479710 23126066861888 run_lib.py:133] step: 166550, training_loss: 2.02147e-02
I0215 13:27:32.914006 23126066861888 run_lib.py:133] step: 166600, training_loss: 1.97249e-02
I0215 13:27:33.088300 23126066861888 run_lib.py:146] step: 166600, eval_loss: 2.65543e-02
I0215 13:27:50.631201 23126066861888 run_lib.py:133] step: 166650, training_loss: 1.91290e-02
I0215 13:28:08.022312 23126066861888 run_lib.py:133] step: 166700, training_loss: 1.98144e-02
I0215 13:28:08.177372 23126066861888 run_lib.py:146] step: 166700, eval_loss: 2.60539e-02
I0215 13:28:25.574986 23126066861888 run_lib.py:133] step: 166750, training_loss: 1.93827e-02
I0215 13:28:42.940330 23126066861888 run_lib.py:133] step: 166800, training_loss: 1.98170e-02
I0215 13:28:43.094259 23126066861888 run_lib.py:146] step: 166800, eval_loss: 2.55058e-02
I0215 13:29:00.603501 23126066861888 run_lib.py:133] step: 166850, training_loss: 1.96674e-02
I0215 13:29:18.106469 23126066861888 run_lib.py:133] step: 166900, training_loss: 1.96329e-02
I0215 13:29:18.260131 23126066861888 run_lib.py:146] step: 166900, eval_loss: 2.61219e-02
I0215 13:29:35.645902 23126066861888 run_lib.py:133] step: 166950, training_loss: 1.99770e-02
I0215 13:29:53.039416 23126066861888 run_lib.py:133] step: 167000, training_loss: 1.97777e-02
I0215 13:29:53.193929 23126066861888 run_lib.py:146] step: 167000, eval_loss: 2.56986e-02
I0215 13:30:10.670278 23126066861888 run_lib.py:133] step: 167050, training_loss: 1.98642e-02
I0215 13:30:28.037678 23126066861888 run_lib.py:133] step: 167100, training_loss: 2.01841e-02
I0215 13:30:28.200465 23126066861888 run_lib.py:146] step: 167100, eval_loss: 2.60575e-02
I0215 13:30:45.688000 23126066861888 run_lib.py:133] step: 167150, training_loss: 2.00579e-02
I0215 13:31:03.281333 23126066861888 run_lib.py:133] step: 167200, training_loss: 1.98842e-02
I0215 13:31:03.435398 23126066861888 run_lib.py:146] step: 167200, eval_loss: 2.61934e-02
I0215 13:31:20.858405 23126066861888 run_lib.py:133] step: 167250, training_loss: 1.96968e-02
I0215 13:31:38.457195 23126066861888 run_lib.py:133] step: 167300, training_loss: 1.96703e-02
I0215 13:31:38.611928 23126066861888 run_lib.py:146] step: 167300, eval_loss: 2.67296e-02
I0215 13:31:55.999382 23126066861888 run_lib.py:133] step: 167350, training_loss: 2.04036e-02
I0215 13:32:13.425217 23126066861888 run_lib.py:133] step: 167400, training_loss: 1.92885e-02
I0215 13:32:13.580167 23126066861888 run_lib.py:146] step: 167400, eval_loss: 2.68526e-02
I0215 13:32:31.313672 23126066861888 run_lib.py:133] step: 167450, training_loss: 1.93535e-02
I0215 13:32:48.701395 23126066861888 run_lib.py:133] step: 167500, training_loss: 2.01949e-02
I0215 13:32:48.878187 23126066861888 run_lib.py:146] step: 167500, eval_loss: 2.70774e-02
I0215 13:33:06.246850 23126066861888 run_lib.py:133] step: 167550, training_loss: 1.91550e-02
I0215 13:33:23.736921 23126066861888 run_lib.py:133] step: 167600, training_loss: 2.00054e-02
I0215 13:33:23.898900 23126066861888 run_lib.py:146] step: 167600, eval_loss: 2.59528e-02
I0215 13:33:41.317929 23126066861888 run_lib.py:133] step: 167650, training_loss: 1.95877e-02
I0215 13:33:58.776900 23126066861888 run_lib.py:133] step: 167700, training_loss: 1.92846e-02
I0215 13:33:58.935333 23126066861888 run_lib.py:146] step: 167700, eval_loss: 2.51661e-02
I0215 13:34:16.524153 23126066861888 run_lib.py:133] step: 167750, training_loss: 1.98057e-02
I0215 13:34:33.860232 23126066861888 run_lib.py:133] step: 167800, training_loss: 1.95975e-02
I0215 13:34:34.011726 23126066861888 run_lib.py:146] step: 167800, eval_loss: 2.57464e-02
I0215 13:34:51.391656 23126066861888 run_lib.py:133] step: 167850, training_loss: 1.95636e-02
I0215 13:35:08.782660 23126066861888 run_lib.py:133] step: 167900, training_loss: 1.95014e-02
I0215 13:35:08.935299 23126066861888 run_lib.py:146] step: 167900, eval_loss: 2.60486e-02
I0215 13:35:26.471333 23126066861888 run_lib.py:133] step: 167950, training_loss: 1.95162e-02
I0215 13:35:44.021268 23126066861888 run_lib.py:133] step: 168000, training_loss: 2.03320e-02
I0215 13:35:44.185172 23126066861888 run_lib.py:146] step: 168000, eval_loss: 2.69380e-02
I0215 13:36:01.603739 23126066861888 run_lib.py:133] step: 168050, training_loss: 1.93783e-02
I0215 13:36:19.031840 23126066861888 run_lib.py:133] step: 168100, training_loss: 1.93641e-02
I0215 13:36:19.186076 23126066861888 run_lib.py:146] step: 168100, eval_loss: 2.58900e-02
I0215 13:36:36.759222 23126066861888 run_lib.py:133] step: 168150, training_loss: 1.88283e-02
I0215 13:36:54.121665 23126066861888 run_lib.py:133] step: 168200, training_loss: 1.94720e-02
I0215 13:36:54.275961 23126066861888 run_lib.py:146] step: 168200, eval_loss: 2.58635e-02
I0215 13:37:11.678206 23126066861888 run_lib.py:133] step: 168250, training_loss: 2.05248e-02
I0215 13:37:29.278060 23126066861888 run_lib.py:133] step: 168300, training_loss: 1.91401e-02
I0215 13:37:29.441667 23126066861888 run_lib.py:146] step: 168300, eval_loss: 2.76850e-02
I0215 13:37:46.839943 23126066861888 run_lib.py:133] step: 168350, training_loss: 1.93664e-02
I0215 13:38:04.411904 23126066861888 run_lib.py:133] step: 168400, training_loss: 1.96258e-02
I0215 13:38:04.567398 23126066861888 run_lib.py:146] step: 168400, eval_loss: 2.59033e-02
I0215 13:38:21.910041 23126066861888 run_lib.py:133] step: 168450, training_loss: 1.99205e-02
I0215 13:38:39.293061 23126066861888 run_lib.py:133] step: 168500, training_loss: 2.01157e-02
I0215 13:38:39.450397 23126066861888 run_lib.py:146] step: 168500, eval_loss: 2.65582e-02
I0215 13:38:57.040379 23126066861888 run_lib.py:133] step: 168550, training_loss: 1.95630e-02
I0215 13:39:14.460766 23126066861888 run_lib.py:133] step: 168600, training_loss: 1.91098e-02
I0215 13:39:14.616280 23126066861888 run_lib.py:146] step: 168600, eval_loss: 2.63916e-02
I0215 13:39:32.018520 23126066861888 run_lib.py:133] step: 168650, training_loss: 2.03108e-02
I0215 13:39:49.574781 23126066861888 run_lib.py:133] step: 168700, training_loss: 1.94243e-02
I0215 13:39:49.739192 23126066861888 run_lib.py:146] step: 168700, eval_loss: 2.65514e-02
I0215 13:40:07.119643 23126066861888 run_lib.py:133] step: 168750, training_loss: 2.01861e-02
I0215 13:40:24.496073 23126066861888 run_lib.py:133] step: 168800, training_loss: 2.01737e-02
I0215 13:40:24.648254 23126066861888 run_lib.py:146] step: 168800, eval_loss: 2.64433e-02
I0215 13:40:42.142330 23126066861888 run_lib.py:133] step: 168850, training_loss: 1.97626e-02
I0215 13:40:59.549153 23126066861888 run_lib.py:133] step: 168900, training_loss: 2.06940e-02
I0215 13:40:59.714407 23126066861888 run_lib.py:146] step: 168900, eval_loss: 2.54720e-02
I0215 13:41:17.151085 23126066861888 run_lib.py:133] step: 168950, training_loss: 1.97001e-02
I0215 13:41:34.532351 23126066861888 run_lib.py:133] step: 169000, training_loss: 2.03148e-02
I0215 13:41:34.695266 23126066861888 run_lib.py:146] step: 169000, eval_loss: 2.67582e-02
I0215 13:41:52.289090 23126066861888 run_lib.py:133] step: 169050, training_loss: 1.91271e-02
I0215 13:42:09.760934 23126066861888 run_lib.py:133] step: 169100, training_loss: 1.97364e-02
I0215 13:42:09.956997 23126066861888 run_lib.py:146] step: 169100, eval_loss: 2.58517e-02
I0215 13:42:27.395385 23126066861888 run_lib.py:133] step: 169150, training_loss: 1.97074e-02
I0215 13:42:44.836411 23126066861888 run_lib.py:133] step: 169200, training_loss: 1.90831e-02
I0215 13:42:44.995887 23126066861888 run_lib.py:146] step: 169200, eval_loss: 2.65267e-02
I0215 13:43:02.642321 23126066861888 run_lib.py:133] step: 169250, training_loss: 2.01065e-02
I0215 13:43:20.043783 23126066861888 run_lib.py:133] step: 169300, training_loss: 2.00316e-02
I0215 13:43:20.197204 23126066861888 run_lib.py:146] step: 169300, eval_loss: 2.74609e-02
I0215 13:43:37.586214 23126066861888 run_lib.py:133] step: 169350, training_loss: 1.96405e-02
I0215 13:43:55.152656 23126066861888 run_lib.py:133] step: 169400, training_loss: 1.93084e-02
I0215 13:43:55.320509 23126066861888 run_lib.py:146] step: 169400, eval_loss: 2.66346e-02
I0215 13:44:12.812472 23126066861888 run_lib.py:133] step: 169450, training_loss: 1.99555e-02
I0215 13:44:30.448843 23126066861888 run_lib.py:133] step: 169500, training_loss: 1.94257e-02
I0215 13:44:30.606336 23126066861888 run_lib.py:146] step: 169500, eval_loss: 2.66071e-02
I0215 13:44:48.029925 23126066861888 run_lib.py:133] step: 169550, training_loss: 1.97493e-02
I0215 13:45:05.443686 23126066861888 run_lib.py:133] step: 169600, training_loss: 1.97688e-02
I0215 13:45:05.603093 23126066861888 run_lib.py:146] step: 169600, eval_loss: 2.62093e-02
I0215 13:45:23.155409 23126066861888 run_lib.py:133] step: 169650, training_loss: 1.94418e-02
I0215 13:45:40.671520 23126066861888 run_lib.py:133] step: 169700, training_loss: 1.94949e-02
I0215 13:45:40.824229 23126066861888 run_lib.py:146] step: 169700, eval_loss: 2.64183e-02
I0215 13:45:58.258622 23126066861888 run_lib.py:133] step: 169750, training_loss: 1.96496e-02
I0215 13:46:15.841520 23126066861888 run_lib.py:133] step: 169800, training_loss: 2.01701e-02
I0215 13:46:15.995421 23126066861888 run_lib.py:146] step: 169800, eval_loss: 2.64405e-02
I0215 13:46:33.393231 23126066861888 run_lib.py:133] step: 169850, training_loss: 2.01301e-02
I0215 13:46:50.778873 23126066861888 run_lib.py:133] step: 169900, training_loss: 1.93015e-02
I0215 13:46:50.938219 23126066861888 run_lib.py:146] step: 169900, eval_loss: 2.73154e-02
I0215 13:47:08.376745 23126066861888 run_lib.py:133] step: 169950, training_loss: 1.91356e-02
I0215 13:47:25.805147 23126066861888 run_lib.py:133] step: 170000, training_loss: 1.96103e-02
I0215 13:47:26.929913 23126066861888 run_lib.py:146] step: 170000, eval_loss: 2.69901e-02
I0215 13:47:47.148823 23126066861888 run_lib.py:133] step: 170050, training_loss: 1.94334e-02
I0215 13:48:04.546733 23126066861888 run_lib.py:133] step: 170100, training_loss: 1.98402e-02
I0215 13:48:04.702073 23126066861888 run_lib.py:146] step: 170100, eval_loss: 2.63468e-02
I0215 13:48:22.072373 23126066861888 run_lib.py:133] step: 170150, training_loss: 1.99893e-02
I0215 13:48:39.610740 23126066861888 run_lib.py:133] step: 170200, training_loss: 1.88558e-02
I0215 13:48:39.769244 23126066861888 run_lib.py:146] step: 170200, eval_loss: 2.67063e-02
I0215 13:48:57.208567 23126066861888 run_lib.py:133] step: 170250, training_loss: 1.98720e-02
I0215 13:49:14.637966 23126066861888 run_lib.py:133] step: 170300, training_loss: 1.98367e-02
I0215 13:49:14.792536 23126066861888 run_lib.py:146] step: 170300, eval_loss: 2.65512e-02
I0215 13:49:32.160112 23126066861888 run_lib.py:133] step: 170350, training_loss: 2.00757e-02
I0215 13:49:49.588596 23126066861888 run_lib.py:133] step: 170400, training_loss: 2.00997e-02
I0215 13:49:49.743236 23126066861888 run_lib.py:146] step: 170400, eval_loss: 2.59458e-02
I0215 13:50:07.307879 23126066861888 run_lib.py:133] step: 170450, training_loss: 1.97977e-02
I0215 13:50:24.700361 23126066861888 run_lib.py:133] step: 170500, training_loss: 1.97141e-02
I0215 13:50:24.852997 23126066861888 run_lib.py:146] step: 170500, eval_loss: 2.65537e-02
I0215 13:50:42.451259 23126066861888 run_lib.py:133] step: 170550, training_loss: 1.95220e-02
I0215 13:50:59.871644 23126066861888 run_lib.py:133] step: 170600, training_loss: 1.91373e-02
I0215 13:51:00.038438 23126066861888 run_lib.py:146] step: 170600, eval_loss: 2.61381e-02
I0215 13:51:17.585101 23126066861888 run_lib.py:133] step: 170650, training_loss: 1.97648e-02
I0215 13:51:34.954016 23126066861888 run_lib.py:133] step: 170700, training_loss: 1.90833e-02
I0215 13:51:35.129926 23126066861888 run_lib.py:146] step: 170700, eval_loss: 2.69505e-02
I0215 13:51:52.530301 23126066861888 run_lib.py:133] step: 170750, training_loss: 1.99028e-02
I0215 13:52:10.081913 23126066861888 run_lib.py:133] step: 170800, training_loss: 1.99624e-02
I0215 13:52:10.234367 23126066861888 run_lib.py:146] step: 170800, eval_loss: 2.55374e-02
I0215 13:52:27.672408 23126066861888 run_lib.py:133] step: 170850, training_loss: 1.98597e-02
I0215 13:52:45.272195 23126066861888 run_lib.py:133] step: 170900, training_loss: 1.91402e-02
I0215 13:52:45.442058 23126066861888 run_lib.py:146] step: 170900, eval_loss: 2.54650e-02
I0215 13:53:02.814860 23126066861888 run_lib.py:133] step: 170950, training_loss: 1.99713e-02
I0215 13:53:20.199154 23126066861888 run_lib.py:133] step: 171000, training_loss: 2.00624e-02
I0215 13:53:20.353148 23126066861888 run_lib.py:146] step: 171000, eval_loss: 2.75156e-02
I0215 13:53:37.716241 23126066861888 run_lib.py:133] step: 171050, training_loss: 2.02673e-02
I0215 13:53:55.211596 23126066861888 run_lib.py:133] step: 171100, training_loss: 1.94831e-02
I0215 13:53:55.369089 23126066861888 run_lib.py:146] step: 171100, eval_loss: 2.62768e-02
I0215 13:54:12.768539 23126066861888 run_lib.py:133] step: 171150, training_loss: 1.97042e-02
I0215 13:54:30.236545 23126066861888 run_lib.py:133] step: 171200, training_loss: 1.89270e-02
I0215 13:54:30.386657 23126066861888 run_lib.py:146] step: 171200, eval_loss: 2.62921e-02
I0215 13:54:48.045782 23126066861888 run_lib.py:133] step: 171250, training_loss: 1.96026e-02
I0215 13:55:05.447335 23126066861888 run_lib.py:133] step: 171300, training_loss: 2.05519e-02
I0215 13:55:05.600961 23126066861888 run_lib.py:146] step: 171300, eval_loss: 2.60947e-02
I0215 13:55:23.098855 23126066861888 run_lib.py:133] step: 171350, training_loss: 1.98317e-02
I0215 13:55:40.445634 23126066861888 run_lib.py:133] step: 171400, training_loss: 1.95413e-02
I0215 13:55:40.607015 23126066861888 run_lib.py:146] step: 171400, eval_loss: 2.56649e-02
I0215 13:55:58.070104 23126066861888 run_lib.py:133] step: 171450, training_loss: 1.98285e-02
I0215 13:56:15.470409 23126066861888 run_lib.py:133] step: 171500, training_loss: 2.01877e-02
I0215 13:56:15.629599 23126066861888 run_lib.py:146] step: 171500, eval_loss: 2.57924e-02
I0215 13:56:33.177837 23126066861888 run_lib.py:133] step: 171550, training_loss: 1.94758e-02
I0215 13:56:50.629007 23126066861888 run_lib.py:133] step: 171600, training_loss: 1.94761e-02
I0215 13:56:50.783271 23126066861888 run_lib.py:146] step: 171600, eval_loss: 2.56778e-02
I0215 13:57:08.217682 23126066861888 run_lib.py:133] step: 171650, training_loss: 1.87438e-02
I0215 13:57:25.596091 23126066861888 run_lib.py:133] step: 171700, training_loss: 1.97493e-02
I0215 13:57:25.748657 23126066861888 run_lib.py:146] step: 171700, eval_loss: 2.64113e-02
I0215 13:57:43.336346 23126066861888 run_lib.py:133] step: 171750, training_loss: 1.96351e-02
I0215 13:58:00.735353 23126066861888 run_lib.py:133] step: 171800, training_loss: 2.03344e-02
I0215 13:58:00.889320 23126066861888 run_lib.py:146] step: 171800, eval_loss: 2.66862e-02
I0215 13:58:18.272495 23126066861888 run_lib.py:133] step: 171850, training_loss: 1.99110e-02
I0215 13:58:35.873427 23126066861888 run_lib.py:133] step: 171900, training_loss: 1.92296e-02
I0215 13:58:36.029382 23126066861888 run_lib.py:146] step: 171900, eval_loss: 2.66518e-02
I0215 13:58:53.394841 23126066861888 run_lib.py:133] step: 171950, training_loss: 1.95356e-02
I0215 13:59:10.917720 23126066861888 run_lib.py:133] step: 172000, training_loss: 1.95019e-02
I0215 13:59:11.077233 23126066861888 run_lib.py:146] step: 172000, eval_loss: 2.61184e-02
I0215 13:59:28.486784 23126066861888 run_lib.py:133] step: 172050, training_loss: 1.95757e-02
I0215 13:59:45.938277 23126066861888 run_lib.py:133] step: 172100, training_loss: 1.95736e-02
I0215 13:59:46.092539 23126066861888 run_lib.py:146] step: 172100, eval_loss: 2.69172e-02
I0215 14:00:03.724207 23126066861888 run_lib.py:133] step: 172150, training_loss: 1.97152e-02
I0215 14:00:21.110130 23126066861888 run_lib.py:133] step: 172200, training_loss: 1.96833e-02
I0215 14:00:21.265007 23126066861888 run_lib.py:146] step: 172200, eval_loss: 2.62764e-02
I0215 14:00:38.614867 23126066861888 run_lib.py:133] step: 172250, training_loss: 1.94323e-02
I0215 14:00:55.997459 23126066861888 run_lib.py:133] step: 172300, training_loss: 1.97920e-02
I0215 14:00:56.150846 23126066861888 run_lib.py:146] step: 172300, eval_loss: 2.59822e-02
I0215 14:01:13.752479 23126066861888 run_lib.py:133] step: 172350, training_loss: 1.88451e-02
I0215 14:01:31.248989 23126066861888 run_lib.py:133] step: 172400, training_loss: 1.95338e-02
I0215 14:01:31.406232 23126066861888 run_lib.py:146] step: 172400, eval_loss: 2.67455e-02
I0215 14:01:48.932782 23126066861888 run_lib.py:133] step: 172450, training_loss: 1.90571e-02
I0215 14:02:06.355746 23126066861888 run_lib.py:133] step: 172500, training_loss: 1.96920e-02
I0215 14:02:06.517583 23126066861888 run_lib.py:146] step: 172500, eval_loss: 2.56784e-02
I0215 14:02:23.878403 23126066861888 run_lib.py:133] step: 172550, training_loss: 1.97630e-02
I0215 14:02:41.246967 23126066861888 run_lib.py:133] step: 172600, training_loss: 2.03925e-02
I0215 14:02:41.405964 23126066861888 run_lib.py:146] step: 172600, eval_loss: 2.57706e-02
I0215 14:02:58.993458 23126066861888 run_lib.py:133] step: 172650, training_loss: 2.02675e-02
I0215 14:03:16.509913 23126066861888 run_lib.py:133] step: 172700, training_loss: 1.97543e-02
I0215 14:03:16.670433 23126066861888 run_lib.py:146] step: 172700, eval_loss: 2.65794e-02
I0215 14:03:34.058249 23126066861888 run_lib.py:133] step: 172750, training_loss: 1.91327e-02
I0215 14:03:51.461174 23126066861888 run_lib.py:133] step: 172800, training_loss: 1.96234e-02
I0215 14:03:51.623534 23126066861888 run_lib.py:146] step: 172800, eval_loss: 2.57613e-02
I0215 14:04:09.152831 23126066861888 run_lib.py:133] step: 172850, training_loss: 1.89591e-02
I0215 14:04:26.494962 23126066861888 run_lib.py:133] step: 172900, training_loss: 1.96885e-02
I0215 14:04:26.653170 23126066861888 run_lib.py:146] step: 172900, eval_loss: 2.66108e-02
I0215 14:04:44.078080 23126066861888 run_lib.py:133] step: 172950, training_loss: 1.84899e-02
I0215 14:05:01.707301 23126066861888 run_lib.py:133] step: 173000, training_loss: 1.98463e-02
I0215 14:05:01.857282 23126066861888 run_lib.py:146] step: 173000, eval_loss: 2.62827e-02
I0215 14:05:19.248565 23126066861888 run_lib.py:133] step: 173050, training_loss: 1.98091e-02
I0215 14:05:36.752949 23126066861888 run_lib.py:133] step: 173100, training_loss: 1.94959e-02
I0215 14:05:36.902686 23126066861888 run_lib.py:146] step: 173100, eval_loss: 2.76503e-02
I0215 14:05:54.261554 23126066861888 run_lib.py:133] step: 173150, training_loss: 1.91854e-02
I0215 14:06:11.716198 23126066861888 run_lib.py:133] step: 173200, training_loss: 1.99567e-02
I0215 14:06:11.873146 23126066861888 run_lib.py:146] step: 173200, eval_loss: 2.59716e-02
I0215 14:06:29.414925 23126066861888 run_lib.py:133] step: 173250, training_loss: 1.94183e-02
I0215 14:06:46.811791 23126066861888 run_lib.py:133] step: 173300, training_loss: 1.97224e-02
I0215 14:06:46.968114 23126066861888 run_lib.py:146] step: 173300, eval_loss: 2.66998e-02
I0215 14:07:04.308040 23126066861888 run_lib.py:133] step: 173350, training_loss: 1.97767e-02
I0215 14:07:21.841535 23126066861888 run_lib.py:133] step: 173400, training_loss: 1.91560e-02
I0215 14:07:21.996273 23126066861888 run_lib.py:146] step: 173400, eval_loss: 2.64273e-02
I0215 14:07:39.394801 23126066861888 run_lib.py:133] step: 173450, training_loss: 1.85502e-02
I0215 14:07:56.806856 23126066861888 run_lib.py:133] step: 173500, training_loss: 1.98237e-02
I0215 14:07:56.962295 23126066861888 run_lib.py:146] step: 173500, eval_loss: 2.64962e-02
I0215 14:08:14.558178 23126066861888 run_lib.py:133] step: 173550, training_loss: 1.94577e-02
I0215 14:08:31.950898 23126066861888 run_lib.py:133] step: 173600, training_loss: 2.04004e-02
I0215 14:08:32.101023 23126066861888 run_lib.py:146] step: 173600, eval_loss: 2.53325e-02
I0215 14:08:49.465839 23126066861888 run_lib.py:133] step: 173650, training_loss: 1.95797e-02
I0215 14:09:06.817436 23126066861888 run_lib.py:133] step: 173700, training_loss: 1.94488e-02
I0215 14:09:06.970049 23126066861888 run_lib.py:146] step: 173700, eval_loss: 2.80513e-02
I0215 14:09:24.582609 23126066861888 run_lib.py:133] step: 173750, training_loss: 1.96907e-02
I0215 14:09:42.143851 23126066861888 run_lib.py:133] step: 173800, training_loss: 1.91154e-02
I0215 14:09:42.301245 23126066861888 run_lib.py:146] step: 173800, eval_loss: 2.62762e-02
I0215 14:09:59.699391 23126066861888 run_lib.py:133] step: 173850, training_loss: 1.95720e-02
I0215 14:10:17.162528 23126066861888 run_lib.py:133] step: 173900, training_loss: 1.95018e-02
I0215 14:10:17.316204 23126066861888 run_lib.py:146] step: 173900, eval_loss: 2.63387e-02
I0215 14:10:34.902825 23126066861888 run_lib.py:133] step: 173950, training_loss: 1.98771e-02
I0215 14:10:52.287997 23126066861888 run_lib.py:133] step: 174000, training_loss: 1.98955e-02
I0215 14:10:52.449016 23126066861888 run_lib.py:146] step: 174000, eval_loss: 2.61927e-02
I0215 14:11:09.824292 23126066861888 run_lib.py:133] step: 174050, training_loss: 1.95113e-02
I0215 14:11:27.389783 23126066861888 run_lib.py:133] step: 174100, training_loss: 1.95137e-02
I0215 14:11:27.543281 23126066861888 run_lib.py:146] step: 174100, eval_loss: 2.56427e-02
I0215 14:11:44.961670 23126066861888 run_lib.py:133] step: 174150, training_loss: 2.03202e-02
I0215 14:12:02.512227 23126066861888 run_lib.py:133] step: 174200, training_loss: 1.95560e-02
I0215 14:12:02.669255 23126066861888 run_lib.py:146] step: 174200, eval_loss: 2.68048e-02
I0215 14:12:20.039366 23126066861888 run_lib.py:133] step: 174250, training_loss: 1.99902e-02
I0215 14:12:37.414049 23126066861888 run_lib.py:133] step: 174300, training_loss: 2.02237e-02
I0215 14:12:37.578555 23126066861888 run_lib.py:146] step: 174300, eval_loss: 2.63597e-02
I0215 14:12:55.136523 23126066861888 run_lib.py:133] step: 174350, training_loss: 1.99314e-02
I0215 14:13:12.562593 23126066861888 run_lib.py:133] step: 174400, training_loss: 1.93513e-02
I0215 14:13:12.718422 23126066861888 run_lib.py:146] step: 174400, eval_loss: 2.62278e-02
I0215 14:13:30.136112 23126066861888 run_lib.py:133] step: 174450, training_loss: 1.98640e-02
I0215 14:13:47.733691 23126066861888 run_lib.py:133] step: 174500, training_loss: 2.00049e-02
I0215 14:13:47.881824 23126066861888 run_lib.py:146] step: 174500, eval_loss: 2.67803e-02
I0215 14:14:05.263577 23126066861888 run_lib.py:133] step: 174550, training_loss: 1.90380e-02
I0215 14:14:22.684473 23126066861888 run_lib.py:133] step: 174600, training_loss: 1.97610e-02
I0215 14:14:22.836053 23126066861888 run_lib.py:146] step: 174600, eval_loss: 2.66068e-02
I0215 14:14:40.287122 23126066861888 run_lib.py:133] step: 174650, training_loss: 2.01078e-02
I0215 14:14:57.695066 23126066861888 run_lib.py:133] step: 174700, training_loss: 1.96389e-02
I0215 14:14:57.870207 23126066861888 run_lib.py:146] step: 174700, eval_loss: 2.59400e-02
I0215 14:15:15.298655 23126066861888 run_lib.py:133] step: 174750, training_loss: 1.97030e-02
I0215 14:15:32.750521 23126066861888 run_lib.py:133] step: 174800, training_loss: 1.92656e-02
I0215 14:15:32.910460 23126066861888 run_lib.py:146] step: 174800, eval_loss: 2.56542e-02
I0215 14:15:50.428530 23126066861888 run_lib.py:133] step: 174850, training_loss: 1.88456e-02
I0215 14:16:07.901822 23126066861888 run_lib.py:133] step: 174900, training_loss: 1.95441e-02
I0215 14:16:08.054730 23126066861888 run_lib.py:146] step: 174900, eval_loss: 2.63667e-02
I0215 14:16:25.424839 23126066861888 run_lib.py:133] step: 174950, training_loss: 1.90889e-02
I0215 14:16:42.857567 23126066861888 run_lib.py:133] step: 175000, training_loss: 2.04541e-02
I0215 14:16:43.018037 23126066861888 run_lib.py:146] step: 175000, eval_loss: 2.64442e-02
I0215 14:17:00.621190 23126066861888 run_lib.py:133] step: 175050, training_loss: 1.93639e-02
I0215 14:17:17.972951 23126066861888 run_lib.py:133] step: 175100, training_loss: 1.95754e-02
I0215 14:17:18.127030 23126066861888 run_lib.py:146] step: 175100, eval_loss: 2.52833e-02
I0215 14:17:35.488116 23126066861888 run_lib.py:133] step: 175150, training_loss: 1.94175e-02
I0215 14:17:53.054646 23126066861888 run_lib.py:133] step: 175200, training_loss: 1.97690e-02
I0215 14:17:53.212597 23126066861888 run_lib.py:146] step: 175200, eval_loss: 2.61002e-02
I0215 14:18:10.614373 23126066861888 run_lib.py:133] step: 175250, training_loss: 1.96406e-02
I0215 14:18:28.156725 23126066861888 run_lib.py:133] step: 175300, training_loss: 1.91986e-02
I0215 14:18:28.311457 23126066861888 run_lib.py:146] step: 175300, eval_loss: 2.58311e-02
I0215 14:18:45.747146 23126066861888 run_lib.py:133] step: 175350, training_loss: 2.04814e-02
I0215 14:19:03.122832 23126066861888 run_lib.py:133] step: 175400, training_loss: 1.91677e-02
I0215 14:19:03.277698 23126066861888 run_lib.py:146] step: 175400, eval_loss: 2.57946e-02
I0215 14:19:20.853701 23126066861888 run_lib.py:133] step: 175450, training_loss: 1.96824e-02
I0215 14:19:38.283474 23126066861888 run_lib.py:133] step: 175500, training_loss: 1.95725e-02
I0215 14:19:38.432987 23126066861888 run_lib.py:146] step: 175500, eval_loss: 2.71083e-02
I0215 14:19:55.810701 23126066861888 run_lib.py:133] step: 175550, training_loss: 1.95889e-02
I0215 14:20:13.379438 23126066861888 run_lib.py:133] step: 175600, training_loss: 1.91698e-02
I0215 14:20:13.548161 23126066861888 run_lib.py:146] step: 175600, eval_loss: 2.63978e-02
I0215 14:20:30.979323 23126066861888 run_lib.py:133] step: 175650, training_loss: 2.00940e-02
I0215 14:20:48.413634 23126066861888 run_lib.py:133] step: 175700, training_loss: 2.02953e-02
I0215 14:20:48.571310 23126066861888 run_lib.py:146] step: 175700, eval_loss: 2.60974e-02
I0215 14:21:06.088724 23126066861888 run_lib.py:133] step: 175750, training_loss: 2.02199e-02
I0215 14:21:23.480838 23126066861888 run_lib.py:133] step: 175800, training_loss: 1.98622e-02
I0215 14:21:23.637417 23126066861888 run_lib.py:146] step: 175800, eval_loss: 2.76024e-02
I0215 14:21:41.017948 23126066861888 run_lib.py:133] step: 175850, training_loss: 1.94515e-02
I0215 14:21:58.497305 23126066861888 run_lib.py:133] step: 175900, training_loss: 2.01074e-02
I0215 14:21:58.651319 23126066861888 run_lib.py:146] step: 175900, eval_loss: 2.62393e-02
I0215 14:22:16.271684 23126066861888 run_lib.py:133] step: 175950, training_loss: 1.93364e-02
I0215 14:22:33.686826 23126066861888 run_lib.py:133] step: 176000, training_loss: 2.02664e-02
I0215 14:22:33.842949 23126066861888 run_lib.py:146] step: 176000, eval_loss: 2.71924e-02
I0215 14:22:51.202574 23126066861888 run_lib.py:133] step: 176050, training_loss: 1.94581e-02
I0215 14:23:08.619359 23126066861888 run_lib.py:133] step: 176100, training_loss: 1.86899e-02
I0215 14:23:08.786585 23126066861888 run_lib.py:146] step: 176100, eval_loss: 2.65796e-02
I0215 14:23:26.385794 23126066861888 run_lib.py:133] step: 176150, training_loss: 1.97263e-02
I0215 14:23:43.833628 23126066861888 run_lib.py:133] step: 176200, training_loss: 2.00571e-02
I0215 14:23:43.989286 23126066861888 run_lib.py:146] step: 176200, eval_loss: 2.62750e-02
I0215 14:24:01.407587 23126066861888 run_lib.py:133] step: 176250, training_loss: 1.91308e-02
I0215 14:24:18.967647 23126066861888 run_lib.py:133] step: 176300, training_loss: 2.04910e-02
I0215 14:24:19.122001 23126066861888 run_lib.py:146] step: 176300, eval_loss: 2.67987e-02
I0215 14:24:36.530575 23126066861888 run_lib.py:133] step: 176350, training_loss: 1.97800e-02
I0215 14:24:54.071612 23126066861888 run_lib.py:133] step: 176400, training_loss: 1.99290e-02
I0215 14:24:54.222834 23126066861888 run_lib.py:146] step: 176400, eval_loss: 2.62387e-02
I0215 14:25:11.629222 23126066861888 run_lib.py:133] step: 176450, training_loss: 1.93614e-02
I0215 14:25:29.057531 23126066861888 run_lib.py:133] step: 176500, training_loss: 1.98352e-02
I0215 14:25:29.219516 23126066861888 run_lib.py:146] step: 176500, eval_loss: 2.64427e-02
I0215 14:25:46.874118 23126066861888 run_lib.py:133] step: 176550, training_loss: 1.96111e-02
I0215 14:26:04.343566 23126066861888 run_lib.py:133] step: 176600, training_loss: 1.85728e-02
I0215 14:26:04.508712 23126066861888 run_lib.py:146] step: 176600, eval_loss: 2.60038e-02
I0215 14:26:21.890277 23126066861888 run_lib.py:133] step: 176650, training_loss: 1.93300e-02
I0215 14:26:39.437004 23126066861888 run_lib.py:133] step: 176700, training_loss: 1.99056e-02
I0215 14:26:39.603170 23126066861888 run_lib.py:146] step: 176700, eval_loss: 2.57341e-02
I0215 14:26:57.046098 23126066861888 run_lib.py:133] step: 176750, training_loss: 1.96822e-02
I0215 14:27:14.448889 23126066861888 run_lib.py:133] step: 176800, training_loss: 1.88790e-02
I0215 14:27:14.631401 23126066861888 run_lib.py:146] step: 176800, eval_loss: 2.66665e-02
I0215 14:27:32.152631 23126066861888 run_lib.py:133] step: 176850, training_loss: 1.90063e-02
I0215 14:27:49.512890 23126066861888 run_lib.py:133] step: 176900, training_loss: 2.04149e-02
I0215 14:27:49.671710 23126066861888 run_lib.py:146] step: 176900, eval_loss: 2.76023e-02
I0215 14:28:07.075535 23126066861888 run_lib.py:133] step: 176950, training_loss: 1.98261e-02
I0215 14:28:24.476047 23126066861888 run_lib.py:133] step: 177000, training_loss: 1.90494e-02
I0215 14:28:24.640546 23126066861888 run_lib.py:146] step: 177000, eval_loss: 2.53692e-02
I0215 14:28:42.217945 23126066861888 run_lib.py:133] step: 177050, training_loss: 1.95211e-02
I0215 14:28:59.728579 23126066861888 run_lib.py:133] step: 177100, training_loss: 2.04619e-02
I0215 14:28:59.883977 23126066861888 run_lib.py:146] step: 177100, eval_loss: 2.66410e-02
I0215 14:29:17.268868 23126066861888 run_lib.py:133] step: 177150, training_loss: 1.89038e-02
I0215 14:29:34.650256 23126066861888 run_lib.py:133] step: 177200, training_loss: 1.89960e-02
I0215 14:29:34.804010 23126066861888 run_lib.py:146] step: 177200, eval_loss: 2.59632e-02
I0215 14:29:52.370481 23126066861888 run_lib.py:133] step: 177250, training_loss: 1.94963e-02
I0215 14:30:09.835239 23126066861888 run_lib.py:133] step: 177300, training_loss: 1.99194e-02
I0215 14:30:09.991880 23126066861888 run_lib.py:146] step: 177300, eval_loss: 2.64785e-02
I0215 14:30:27.427568 23126066861888 run_lib.py:133] step: 177350, training_loss: 1.94695e-02
I0215 14:30:44.989737 23126066861888 run_lib.py:133] step: 177400, training_loss: 1.92411e-02
I0215 14:30:45.141205 23126066861888 run_lib.py:146] step: 177400, eval_loss: 2.59620e-02
I0215 14:31:02.511916 23126066861888 run_lib.py:133] step: 177450, training_loss: 1.92519e-02
I0215 14:31:20.032630 23126066861888 run_lib.py:133] step: 177500, training_loss: 1.93390e-02
I0215 14:31:20.186013 23126066861888 run_lib.py:146] step: 177500, eval_loss: 2.61684e-02
I0215 14:31:37.577805 23126066861888 run_lib.py:133] step: 177550, training_loss: 1.99736e-02
I0215 14:31:54.998402 23126066861888 run_lib.py:133] step: 177600, training_loss: 1.97146e-02
I0215 14:31:55.161950 23126066861888 run_lib.py:146] step: 177600, eval_loss: 2.58635e-02
I0215 14:32:12.779118 23126066861888 run_lib.py:133] step: 177650, training_loss: 1.95809e-02
I0215 14:32:30.194468 23126066861888 run_lib.py:133] step: 177700, training_loss: 1.96634e-02
I0215 14:32:30.351239 23126066861888 run_lib.py:146] step: 177700, eval_loss: 2.69009e-02
I0215 14:32:47.731334 23126066861888 run_lib.py:133] step: 177750, training_loss: 1.90319e-02
I0215 14:33:05.243243 23126066861888 run_lib.py:133] step: 177800, training_loss: 2.01541e-02
I0215 14:33:05.397322 23126066861888 run_lib.py:146] step: 177800, eval_loss: 2.63027e-02
I0215 14:33:22.789799 23126066861888 run_lib.py:133] step: 177850, training_loss: 1.94602e-02
I0215 14:33:40.266005 23126066861888 run_lib.py:133] step: 177900, training_loss: 2.05143e-02
I0215 14:33:40.421343 23126066861888 run_lib.py:146] step: 177900, eval_loss: 2.60294e-02
I0215 14:33:57.946151 23126066861888 run_lib.py:133] step: 177950, training_loss: 2.00474e-02
I0215 14:34:15.334395 23126066861888 run_lib.py:133] step: 178000, training_loss: 2.02680e-02
I0215 14:34:15.491203 23126066861888 run_lib.py:146] step: 178000, eval_loss: 2.65644e-02
I0215 14:34:32.837090 23126066861888 run_lib.py:133] step: 178050, training_loss: 1.99473e-02
I0215 14:34:50.204830 23126066861888 run_lib.py:133] step: 178100, training_loss: 1.92973e-02
I0215 14:34:50.373499 23126066861888 run_lib.py:146] step: 178100, eval_loss: 2.66741e-02
I0215 14:35:07.896994 23126066861888 run_lib.py:133] step: 178150, training_loss: 1.88822e-02
I0215 14:35:25.428263 23126066861888 run_lib.py:133] step: 178200, training_loss: 1.94287e-02
I0215 14:35:25.581968 23126066861888 run_lib.py:146] step: 178200, eval_loss: 2.62290e-02
I0215 14:35:42.968282 23126066861888 run_lib.py:133] step: 178250, training_loss: 1.88949e-02
I0215 14:36:00.386792 23126066861888 run_lib.py:133] step: 178300, training_loss: 1.91675e-02
I0215 14:36:00.538076 23126066861888 run_lib.py:146] step: 178300, eval_loss: 2.77180e-02
I0215 14:36:18.046967 23126066861888 run_lib.py:133] step: 178350, training_loss: 2.01309e-02
I0215 14:36:35.425058 23126066861888 run_lib.py:133] step: 178400, training_loss: 1.90546e-02
I0215 14:36:35.581187 23126066861888 run_lib.py:146] step: 178400, eval_loss: 2.52521e-02
I0215 14:36:53.052261 23126066861888 run_lib.py:133] step: 178450, training_loss: 2.00790e-02
I0215 14:37:10.608209 23126066861888 run_lib.py:133] step: 178500, training_loss: 1.94090e-02
I0215 14:37:10.763984 23126066861888 run_lib.py:146] step: 178500, eval_loss: 2.64192e-02
I0215 14:37:28.151760 23126066861888 run_lib.py:133] step: 178550, training_loss: 2.02012e-02
I0215 14:37:45.672026 23126066861888 run_lib.py:133] step: 178600, training_loss: 1.95069e-02
I0215 14:37:45.829149 23126066861888 run_lib.py:146] step: 178600, eval_loss: 2.68613e-02
I0215 14:38:03.226860 23126066861888 run_lib.py:133] step: 178650, training_loss: 1.95345e-02
I0215 14:38:20.691020 23126066861888 run_lib.py:133] step: 178700, training_loss: 1.94250e-02
I0215 14:38:20.849643 23126066861888 run_lib.py:146] step: 178700, eval_loss: 2.65461e-02
I0215 14:38:38.450476 23126066861888 run_lib.py:133] step: 178750, training_loss: 1.95793e-02
I0215 14:38:55.820577 23126066861888 run_lib.py:133] step: 178800, training_loss: 1.96640e-02
I0215 14:38:55.970926 23126066861888 run_lib.py:146] step: 178800, eval_loss: 2.62572e-02
I0215 14:39:13.352507 23126066861888 run_lib.py:133] step: 178850, training_loss: 1.88470e-02
I0215 14:39:30.908422 23126066861888 run_lib.py:133] step: 178900, training_loss: 1.87928e-02
I0215 14:39:31.069452 23126066861888 run_lib.py:146] step: 178900, eval_loss: 2.56555e-02
I0215 14:39:48.472493 23126066861888 run_lib.py:133] step: 178950, training_loss: 1.96336e-02
I0215 14:40:05.909777 23126066861888 run_lib.py:133] step: 179000, training_loss: 2.01020e-02
I0215 14:40:06.066012 23126066861888 run_lib.py:146] step: 179000, eval_loss: 2.58393e-02
I0215 14:40:23.582485 23126066861888 run_lib.py:133] step: 179050, training_loss: 1.87530e-02
I0215 14:40:40.989421 23126066861888 run_lib.py:133] step: 179100, training_loss: 2.03544e-02
I0215 14:40:41.146215 23126066861888 run_lib.py:146] step: 179100, eval_loss: 2.62074e-02
I0215 14:40:58.545606 23126066861888 run_lib.py:133] step: 179150, training_loss: 1.82463e-02
I0215 14:41:15.917941 23126066861888 run_lib.py:133] step: 179200, training_loss: 1.94756e-02
I0215 14:41:16.075974 23126066861888 run_lib.py:146] step: 179200, eval_loss: 2.59986e-02
I0215 14:41:33.625107 23126066861888 run_lib.py:133] step: 179250, training_loss: 1.97669e-02
I0215 14:41:51.206667 23126066861888 run_lib.py:133] step: 179300, training_loss: 1.95919e-02
I0215 14:41:51.367760 23126066861888 run_lib.py:146] step: 179300, eval_loss: 2.64707e-02
I0215 14:42:08.765908 23126066861888 run_lib.py:133] step: 179350, training_loss: 1.93178e-02
I0215 14:42:26.195339 23126066861888 run_lib.py:133] step: 179400, training_loss: 1.97073e-02
I0215 14:42:26.350079 23126066861888 run_lib.py:146] step: 179400, eval_loss: 2.58621e-02
I0215 14:42:43.887123 23126066861888 run_lib.py:133] step: 179450, training_loss: 1.82206e-02
I0215 14:43:01.265689 23126066861888 run_lib.py:133] step: 179500, training_loss: 1.99368e-02
I0215 14:43:01.422597 23126066861888 run_lib.py:146] step: 179500, eval_loss: 2.55283e-02
I0215 14:43:18.851810 23126066861888 run_lib.py:133] step: 179550, training_loss: 2.01336e-02
I0215 14:43:36.433879 23126066861888 run_lib.py:133] step: 179600, training_loss: 2.03082e-02
I0215 14:43:36.588525 23126066861888 run_lib.py:146] step: 179600, eval_loss: 2.65095e-02
I0215 14:43:53.977254 23126066861888 run_lib.py:133] step: 179650, training_loss: 1.90961e-02
I0215 14:44:11.550500 23126066861888 run_lib.py:133] step: 179700, training_loss: 1.99232e-02
I0215 14:44:11.702955 23126066861888 run_lib.py:146] step: 179700, eval_loss: 2.51404e-02
I0215 14:44:29.081532 23126066861888 run_lib.py:133] step: 179750, training_loss: 1.98742e-02
I0215 14:44:46.440340 23126066861888 run_lib.py:133] step: 179800, training_loss: 1.90013e-02
I0215 14:44:46.588812 23126066861888 run_lib.py:146] step: 179800, eval_loss: 2.68229e-02
I0215 14:45:04.118879 23126066861888 run_lib.py:133] step: 179850, training_loss: 1.99894e-02
I0215 14:45:21.577318 23126066861888 run_lib.py:133] step: 179900, training_loss: 1.93753e-02
I0215 14:45:21.742062 23126066861888 run_lib.py:146] step: 179900, eval_loss: 2.67513e-02
I0215 14:45:39.131512 23126066861888 run_lib.py:133] step: 179950, training_loss: 1.95623e-02
I0215 14:45:56.745954 23126066861888 run_lib.py:133] step: 180000, training_loss: 1.99166e-02
I0215 14:45:58.817344 23126066861888 run_lib.py:146] step: 180000, eval_loss: 2.74400e-02
I0215 14:46:19.965150 23126066861888 run_lib.py:133] step: 180050, training_loss: 1.94684e-02
I0215 14:46:37.336390 23126066861888 run_lib.py:133] step: 180100, training_loss: 1.91560e-02
I0215 14:46:37.493264 23126066861888 run_lib.py:146] step: 180100, eval_loss: 2.68696e-02
I0215 14:46:54.865705 23126066861888 run_lib.py:133] step: 180150, training_loss: 1.92680e-02
I0215 14:47:12.454235 23126066861888 run_lib.py:133] step: 180200, training_loss: 1.93172e-02
I0215 14:47:12.615725 23126066861888 run_lib.py:146] step: 180200, eval_loss: 2.74929e-02
I0215 14:47:30.094126 23126066861888 run_lib.py:133] step: 180250, training_loss: 1.99398e-02
I0215 14:47:47.528904 23126066861888 run_lib.py:133] step: 180300, training_loss: 2.01834e-02
I0215 14:47:47.680122 23126066861888 run_lib.py:146] step: 180300, eval_loss: 2.65087e-02
I0215 14:48:05.034615 23126066861888 run_lib.py:133] step: 180350, training_loss: 1.97158e-02
I0215 14:48:22.666074 23126066861888 run_lib.py:133] step: 180400, training_loss: 1.91437e-02
I0215 14:48:22.827921 23126066861888 run_lib.py:146] step: 180400, eval_loss: 2.66068e-02
I0215 14:48:40.325248 23126066861888 run_lib.py:133] step: 180450, training_loss: 1.94850e-02
I0215 14:48:57.747346 23126066861888 run_lib.py:133] step: 180500, training_loss: 1.95823e-02
I0215 14:48:57.908292 23126066861888 run_lib.py:146] step: 180500, eval_loss: 2.61260e-02
I0215 14:49:15.311501 23126066861888 run_lib.py:133] step: 180550, training_loss: 1.93456e-02
I0215 14:49:32.753342 23126066861888 run_lib.py:133] step: 180600, training_loss: 1.99683e-02
I0215 14:49:32.908373 23126066861888 run_lib.py:146] step: 180600, eval_loss: 2.73904e-02
I0215 14:49:50.502409 23126066861888 run_lib.py:133] step: 180650, training_loss: 1.95896e-02
I0215 14:50:07.867493 23126066861888 run_lib.py:133] step: 180700, training_loss: 2.04611e-02
I0215 14:50:08.020934 23126066861888 run_lib.py:146] step: 180700, eval_loss: 2.55827e-02
I0215 14:50:25.571418 23126066861888 run_lib.py:133] step: 180750, training_loss: 1.94258e-02
I0215 14:50:42.999173 23126066861888 run_lib.py:133] step: 180800, training_loss: 1.93013e-02
I0215 14:50:43.162689 23126066861888 run_lib.py:146] step: 180800, eval_loss: 2.49447e-02
I0215 14:51:00.791375 23126066861888 run_lib.py:133] step: 180850, training_loss: 1.91852e-02
I0215 14:51:18.244693 23126066861888 run_lib.py:133] step: 180900, training_loss: 1.91159e-02
I0215 14:51:18.399256 23126066861888 run_lib.py:146] step: 180900, eval_loss: 2.68862e-02
I0215 14:51:35.745465 23126066861888 run_lib.py:133] step: 180950, training_loss: 2.00480e-02
I0215 14:51:53.278566 23126066861888 run_lib.py:133] step: 181000, training_loss: 1.97246e-02
I0215 14:51:53.433298 23126066861888 run_lib.py:146] step: 181000, eval_loss: 2.59947e-02
I0215 14:52:10.850399 23126066861888 run_lib.py:133] step: 181050, training_loss: 1.96945e-02
I0215 14:52:28.438169 23126066861888 run_lib.py:133] step: 181100, training_loss: 1.94530e-02
I0215 14:52:28.589056 23126066861888 run_lib.py:146] step: 181100, eval_loss: 2.61818e-02
I0215 14:52:45.972578 23126066861888 run_lib.py:133] step: 181150, training_loss: 1.99412e-02
I0215 14:53:03.320322 23126066861888 run_lib.py:133] step: 181200, training_loss: 1.93012e-02
I0215 14:53:03.471805 23126066861888 run_lib.py:146] step: 181200, eval_loss: 2.63823e-02
I0215 14:53:20.863962 23126066861888 run_lib.py:133] step: 181250, training_loss: 1.87876e-02
I0215 14:53:38.464863 23126066861888 run_lib.py:133] step: 181300, training_loss: 1.93925e-02
I0215 14:53:38.612223 23126066861888 run_lib.py:146] step: 181300, eval_loss: 2.65897e-02
I0215 14:53:55.996920 23126066861888 run_lib.py:133] step: 181350, training_loss: 2.00475e-02
I0215 14:54:13.395421 23126066861888 run_lib.py:133] step: 181400, training_loss: 1.97026e-02
I0215 14:54:13.555273 23126066861888 run_lib.py:146] step: 181400, eval_loss: 2.60707e-02
I0215 14:54:31.217036 23126066861888 run_lib.py:133] step: 181450, training_loss: 1.88200e-02
I0215 14:54:48.592906 23126066861888 run_lib.py:133] step: 181500, training_loss: 1.91942e-02
I0215 14:54:48.746237 23126066861888 run_lib.py:146] step: 181500, eval_loss: 2.64896e-02
I0215 14:55:06.187433 23126066861888 run_lib.py:133] step: 181550, training_loss: 1.97457e-02
I0215 14:55:23.564508 23126066861888 run_lib.py:133] step: 181600, training_loss: 1.89790e-02
I0215 14:55:23.718743 23126066861888 run_lib.py:146] step: 181600, eval_loss: 2.70462e-02
I0215 14:55:41.095273 23126066861888 run_lib.py:133] step: 181650, training_loss: 1.99922e-02
I0215 14:55:58.576227 23126066861888 run_lib.py:133] step: 181700, training_loss: 1.89268e-02
I0215 14:55:58.737176 23126066861888 run_lib.py:146] step: 181700, eval_loss: 2.59447e-02
I0215 14:56:16.334740 23126066861888 run_lib.py:133] step: 181750, training_loss: 1.99539e-02
I0215 14:56:33.794386 23126066861888 run_lib.py:133] step: 181800, training_loss: 2.00093e-02
I0215 14:56:33.948257 23126066861888 run_lib.py:146] step: 181800, eval_loss: 2.68055e-02
I0215 14:56:51.365750 23126066861888 run_lib.py:133] step: 181850, training_loss: 1.97084e-02
I0215 14:57:08.757723 23126066861888 run_lib.py:133] step: 181900, training_loss: 1.94282e-02
I0215 14:57:08.938347 23126066861888 run_lib.py:146] step: 181900, eval_loss: 2.60679e-02
I0215 14:57:26.485276 23126066861888 run_lib.py:133] step: 181950, training_loss: 1.98323e-02
I0215 14:57:43.885208 23126066861888 run_lib.py:133] step: 182000, training_loss: 1.89140e-02
I0215 14:57:44.040215 23126066861888 run_lib.py:146] step: 182000, eval_loss: 2.63588e-02
I0215 14:58:01.453331 23126066861888 run_lib.py:133] step: 182050, training_loss: 1.86610e-02
I0215 14:58:19.000399 23126066861888 run_lib.py:133] step: 182100, training_loss: 1.93904e-02
I0215 14:58:19.157539 23126066861888 run_lib.py:146] step: 182100, eval_loss: 2.59100e-02
I0215 14:58:36.520244 23126066861888 run_lib.py:133] step: 182150, training_loss: 1.97093e-02
I0215 14:58:54.059962 23126066861888 run_lib.py:133] step: 182200, training_loss: 1.88239e-02
I0215 14:58:54.213071 23126066861888 run_lib.py:146] step: 182200, eval_loss: 2.59266e-02
I0215 14:59:11.652515 23126066861888 run_lib.py:133] step: 182250, training_loss: 1.96755e-02
I0215 14:59:29.068328 23126066861888 run_lib.py:133] step: 182300, training_loss: 1.95810e-02
I0215 14:59:29.219722 23126066861888 run_lib.py:146] step: 182300, eval_loss: 2.61896e-02
I0215 14:59:46.778213 23126066861888 run_lib.py:133] step: 182350, training_loss: 1.91443e-02
I0215 15:00:04.156525 23126066861888 run_lib.py:133] step: 182400, training_loss: 1.91589e-02
I0215 15:00:04.311823 23126066861888 run_lib.py:146] step: 182400, eval_loss: 2.55534e-02
I0215 15:00:21.679787 23126066861888 run_lib.py:133] step: 182450, training_loss: 1.90055e-02
I0215 15:00:39.060559 23126066861888 run_lib.py:133] step: 182500, training_loss: 2.00262e-02
I0215 15:00:39.225059 23126066861888 run_lib.py:146] step: 182500, eval_loss: 2.64406e-02
I0215 15:00:56.835236 23126066861888 run_lib.py:133] step: 182550, training_loss: 1.95982e-02
I0215 15:01:14.275864 23126066861888 run_lib.py:133] step: 182600, training_loss: 2.01530e-02
I0215 15:01:14.429564 23126066861888 run_lib.py:146] step: 182600, eval_loss: 2.60907e-02
I0215 15:01:31.920910 23126066861888 run_lib.py:133] step: 182650, training_loss: 1.97577e-02
I0215 15:01:49.337023 23126066861888 run_lib.py:133] step: 182700, training_loss: 1.87614e-02
I0215 15:01:49.501214 23126066861888 run_lib.py:146] step: 182700, eval_loss: 2.72881e-02
I0215 15:02:06.858084 23126066861888 run_lib.py:133] step: 182750, training_loss: 1.97060e-02
I0215 15:02:24.295057 23126066861888 run_lib.py:133] step: 182800, training_loss: 2.00231e-02
I0215 15:02:24.461315 23126066861888 run_lib.py:146] step: 182800, eval_loss: 2.71140e-02
I0215 15:02:42.023612 23126066861888 run_lib.py:133] step: 182850, training_loss: 1.93775e-02
I0215 15:02:59.560979 23126066861888 run_lib.py:133] step: 182900, training_loss: 1.93078e-02
I0215 15:02:59.717238 23126066861888 run_lib.py:146] step: 182900, eval_loss: 2.68225e-02
I0215 15:03:17.095122 23126066861888 run_lib.py:133] step: 182950, training_loss: 1.99192e-02
I0215 15:03:34.469799 23126066861888 run_lib.py:133] step: 183000, training_loss: 2.01223e-02
I0215 15:03:34.625347 23126066861888 run_lib.py:146] step: 183000, eval_loss: 2.79951e-02
I0215 15:03:52.151517 23126066861888 run_lib.py:133] step: 183050, training_loss: 2.05888e-02
I0215 15:04:09.537923 23126066861888 run_lib.py:133] step: 183100, training_loss: 1.95969e-02
I0215 15:04:09.701176 23126066861888 run_lib.py:146] step: 183100, eval_loss: 2.59063e-02
I0215 15:04:27.169688 23126066861888 run_lib.py:133] step: 183150, training_loss: 1.96137e-02
I0215 15:04:44.768028 23126066861888 run_lib.py:133] step: 183200, training_loss: 1.93073e-02
I0215 15:04:44.922205 23126066861888 run_lib.py:146] step: 183200, eval_loss: 2.69104e-02
I0215 15:05:02.292265 23126066861888 run_lib.py:133] step: 183250, training_loss: 1.99353e-02
I0215 15:05:19.790344 23126066861888 run_lib.py:133] step: 183300, training_loss: 1.96757e-02
I0215 15:05:19.947178 23126066861888 run_lib.py:146] step: 183300, eval_loss: 2.54131e-02
I0215 15:05:37.326235 23126066861888 run_lib.py:133] step: 183350, training_loss: 1.93914e-02
I0215 15:05:54.746009 23126066861888 run_lib.py:133] step: 183400, training_loss: 1.89912e-02
I0215 15:05:54.909299 23126066861888 run_lib.py:146] step: 183400, eval_loss: 2.61659e-02
I0215 15:06:12.562959 23126066861888 run_lib.py:133] step: 183450, training_loss: 1.94071e-02
I0215 15:06:29.965191 23126066861888 run_lib.py:133] step: 183500, training_loss: 2.01009e-02
I0215 15:06:30.119554 23126066861888 run_lib.py:146] step: 183500, eval_loss: 2.65782e-02
I0215 15:06:47.515529 23126066861888 run_lib.py:133] step: 183550, training_loss: 1.93231e-02
I0215 15:07:05.031733 23126066861888 run_lib.py:133] step: 183600, training_loss: 1.91719e-02
I0215 15:07:05.188773 23126066861888 run_lib.py:146] step: 183600, eval_loss: 2.63661e-02
I0215 15:07:22.589209 23126066861888 run_lib.py:133] step: 183650, training_loss: 1.96018e-02
I0215 15:07:40.018391 23126066861888 run_lib.py:133] step: 183700, training_loss: 1.91489e-02
I0215 15:07:40.187672 23126066861888 run_lib.py:146] step: 183700, eval_loss: 2.51809e-02
I0215 15:07:57.739910 23126066861888 run_lib.py:133] step: 183750, training_loss: 1.97596e-02
I0215 15:08:15.152579 23126066861888 run_lib.py:133] step: 183800, training_loss: 1.93957e-02
I0215 15:08:15.309285 23126066861888 run_lib.py:146] step: 183800, eval_loss: 2.64802e-02
I0215 15:08:32.682266 23126066861888 run_lib.py:133] step: 183850, training_loss: 1.87856e-02
I0215 15:08:50.060945 23126066861888 run_lib.py:133] step: 183900, training_loss: 1.99249e-02
I0215 15:08:50.216503 23126066861888 run_lib.py:146] step: 183900, eval_loss: 2.70498e-02
I0215 15:09:07.793889 23126066861888 run_lib.py:133] step: 183950, training_loss: 1.99049e-02
I0215 15:09:25.362582 23126066861888 run_lib.py:133] step: 184000, training_loss: 1.93582e-02
I0215 15:09:25.525841 23126066861888 run_lib.py:146] step: 184000, eval_loss: 2.75750e-02
I0215 15:09:42.913260 23126066861888 run_lib.py:133] step: 184050, training_loss: 2.00356e-02
I0215 15:10:00.321056 23126066861888 run_lib.py:133] step: 184100, training_loss: 1.97173e-02
I0215 15:10:00.472156 23126066861888 run_lib.py:146] step: 184100, eval_loss: 2.69371e-02
I0215 15:10:18.013753 23126066861888 run_lib.py:133] step: 184150, training_loss: 1.92947e-02
I0215 15:10:35.421169 23126066861888 run_lib.py:133] step: 184200, training_loss: 1.94265e-02
I0215 15:10:35.587231 23126066861888 run_lib.py:146] step: 184200, eval_loss: 2.61128e-02
I0215 15:10:53.038307 23126066861888 run_lib.py:133] step: 184250, training_loss: 1.95185e-02
I0215 15:11:10.662384 23126066861888 run_lib.py:133] step: 184300, training_loss: 1.93890e-02
I0215 15:11:10.828228 23126066861888 run_lib.py:146] step: 184300, eval_loss: 2.65994e-02
I0215 15:11:28.253831 23126066861888 run_lib.py:133] step: 184350, training_loss: 1.93610e-02
I0215 15:11:45.778666 23126066861888 run_lib.py:133] step: 184400, training_loss: 2.03629e-02
I0215 15:11:45.933358 23126066861888 run_lib.py:146] step: 184400, eval_loss: 2.59096e-02
I0215 15:12:03.312708 23126066861888 run_lib.py:133] step: 184450, training_loss: 2.03283e-02
I0215 15:12:20.762443 23126066861888 run_lib.py:133] step: 184500, training_loss: 1.88843e-02
I0215 15:12:20.916279 23126066861888 run_lib.py:146] step: 184500, eval_loss: 2.63918e-02
I0215 15:12:38.585008 23126066861888 run_lib.py:133] step: 184550, training_loss: 1.98386e-02
I0215 15:12:55.961294 23126066861888 run_lib.py:133] step: 184600, training_loss: 2.00133e-02
I0215 15:12:56.112035 23126066861888 run_lib.py:146] step: 184600, eval_loss: 2.67189e-02
I0215 15:13:13.502435 23126066861888 run_lib.py:133] step: 184650, training_loss: 1.90850e-02
I0215 15:13:31.078037 23126066861888 run_lib.py:133] step: 184700, training_loss: 1.98267e-02
I0215 15:13:31.231140 23126066861888 run_lib.py:146] step: 184700, eval_loss: 2.69253e-02
I0215 15:13:48.624725 23126066861888 run_lib.py:133] step: 184750, training_loss: 2.02199e-02
I0215 15:14:06.056128 23126066861888 run_lib.py:133] step: 184800, training_loss: 1.95203e-02
I0215 15:14:06.215361 23126066861888 run_lib.py:146] step: 184800, eval_loss: 2.64334e-02
I0215 15:14:23.725510 23126066861888 run_lib.py:133] step: 184850, training_loss: 1.95830e-02
I0215 15:14:41.110111 23126066861888 run_lib.py:133] step: 184900, training_loss: 1.90732e-02
I0215 15:14:41.272963 23126066861888 run_lib.py:146] step: 184900, eval_loss: 2.64606e-02
I0215 15:14:58.713335 23126066861888 run_lib.py:133] step: 184950, training_loss: 2.00729e-02
I0215 15:15:16.123103 23126066861888 run_lib.py:133] step: 185000, training_loss: 1.96369e-02
I0215 15:15:16.276032 23126066861888 run_lib.py:146] step: 185000, eval_loss: 2.65710e-02
I0215 15:15:33.854845 23126066861888 run_lib.py:133] step: 185050, training_loss: 1.87400e-02
I0215 15:15:51.442679 23126066861888 run_lib.py:133] step: 185100, training_loss: 1.90093e-02
I0215 15:15:51.601592 23126066861888 run_lib.py:146] step: 185100, eval_loss: 2.59889e-02
I0215 15:16:09.057326 23126066861888 run_lib.py:133] step: 185150, training_loss: 1.94557e-02
I0215 15:16:26.510462 23126066861888 run_lib.py:133] step: 185200, training_loss: 1.95078e-02
I0215 15:16:26.667478 23126066861888 run_lib.py:146] step: 185200, eval_loss: 2.63600e-02
I0215 15:16:44.216532 23126066861888 run_lib.py:133] step: 185250, training_loss: 1.97251e-02
I0215 15:17:01.631569 23126066861888 run_lib.py:133] step: 185300, training_loss: 1.84445e-02
I0215 15:17:01.793798 23126066861888 run_lib.py:146] step: 185300, eval_loss: 2.64883e-02
I0215 15:17:19.222794 23126066861888 run_lib.py:133] step: 185350, training_loss: 1.92541e-02
I0215 15:17:36.854704 23126066861888 run_lib.py:133] step: 185400, training_loss: 1.85014e-02
I0215 15:17:37.010917 23126066861888 run_lib.py:146] step: 185400, eval_loss: 2.66864e-02
I0215 15:17:54.442465 23126066861888 run_lib.py:133] step: 185450, training_loss: 1.91403e-02
I0215 15:18:11.961537 23126066861888 run_lib.py:133] step: 185500, training_loss: 1.93577e-02
I0215 15:18:12.118983 23126066861888 run_lib.py:146] step: 185500, eval_loss: 2.57731e-02
I0215 15:18:29.505581 23126066861888 run_lib.py:133] step: 185550, training_loss: 2.03624e-02
I0215 15:18:46.905346 23126066861888 run_lib.py:133] step: 185600, training_loss: 1.91982e-02
I0215 15:18:47.066541 23126066861888 run_lib.py:146] step: 185600, eval_loss: 2.69900e-02
I0215 15:19:04.728009 23126066861888 run_lib.py:133] step: 185650, training_loss: 1.99617e-02
I0215 15:19:22.168248 23126066861888 run_lib.py:133] step: 185700, training_loss: 1.91075e-02
I0215 15:19:22.324016 23126066861888 run_lib.py:146] step: 185700, eval_loss: 2.67177e-02
I0215 15:19:39.717000 23126066861888 run_lib.py:133] step: 185750, training_loss: 1.89612e-02
I0215 15:19:57.215245 23126066861888 run_lib.py:133] step: 185800, training_loss: 1.91362e-02
I0215 15:19:57.370227 23126066861888 run_lib.py:146] step: 185800, eval_loss: 2.74032e-02
I0215 15:20:14.788787 23126066861888 run_lib.py:133] step: 185850, training_loss: 1.92555e-02
I0215 15:20:32.268782 23126066861888 run_lib.py:133] step: 185900, training_loss: 1.96251e-02
I0215 15:20:32.422670 23126066861888 run_lib.py:146] step: 185900, eval_loss: 2.62772e-02
I0215 15:20:49.961611 23126066861888 run_lib.py:133] step: 185950, training_loss: 1.91423e-02
I0215 15:21:07.339437 23126066861888 run_lib.py:133] step: 186000, training_loss: 1.91473e-02
I0215 15:21:07.491963 23126066861888 run_lib.py:146] step: 186000, eval_loss: 2.66772e-02
I0215 15:21:24.896888 23126066861888 run_lib.py:133] step: 186050, training_loss: 1.87387e-02
I0215 15:21:42.364581 23126066861888 run_lib.py:133] step: 186100, training_loss: 1.95597e-02
I0215 15:21:42.518224 23126066861888 run_lib.py:146] step: 186100, eval_loss: 2.66941e-02
I0215 15:22:00.051597 23126066861888 run_lib.py:133] step: 186150, training_loss: 1.91685e-02
I0215 15:22:17.573565 23126066861888 run_lib.py:133] step: 186200, training_loss: 2.02792e-02
I0215 15:22:17.739568 23126066861888 run_lib.py:146] step: 186200, eval_loss: 2.68698e-02
I0215 15:22:35.250857 23126066861888 run_lib.py:133] step: 186250, training_loss: 1.97018e-02
I0215 15:22:52.679503 23126066861888 run_lib.py:133] step: 186300, training_loss: 1.99253e-02
I0215 15:22:52.834092 23126066861888 run_lib.py:146] step: 186300, eval_loss: 2.45688e-02
I0215 15:23:10.433578 23126066861888 run_lib.py:133] step: 186350, training_loss: 1.89916e-02
I0215 15:23:27.815034 23126066861888 run_lib.py:133] step: 186400, training_loss: 1.96821e-02
I0215 15:23:27.971052 23126066861888 run_lib.py:146] step: 186400, eval_loss: 2.73015e-02
I0215 15:23:45.388575 23126066861888 run_lib.py:133] step: 186450, training_loss: 1.90617e-02
I0215 15:24:02.977375 23126066861888 run_lib.py:133] step: 186500, training_loss: 1.92978e-02
I0215 15:24:03.131029 23126066861888 run_lib.py:146] step: 186500, eval_loss: 2.71156e-02
I0215 15:24:20.584842 23126066861888 run_lib.py:133] step: 186550, training_loss: 1.93548e-02
I0215 15:24:38.153619 23126066861888 run_lib.py:133] step: 186600, training_loss: 1.89328e-02
I0215 15:24:38.308591 23126066861888 run_lib.py:146] step: 186600, eval_loss: 2.66871e-02
I0215 15:24:55.721403 23126066861888 run_lib.py:133] step: 186650, training_loss: 1.98650e-02
I0215 15:25:13.153917 23126066861888 run_lib.py:133] step: 186700, training_loss: 1.89796e-02
I0215 15:25:13.310017 23126066861888 run_lib.py:146] step: 186700, eval_loss: 2.70056e-02
I0215 15:25:30.885959 23126066861888 run_lib.py:133] step: 186750, training_loss: 1.87265e-02
I0215 15:25:48.287743 23126066861888 run_lib.py:133] step: 186800, training_loss: 1.96808e-02
I0215 15:25:48.442137 23126066861888 run_lib.py:146] step: 186800, eval_loss: 2.66418e-02
I0215 15:26:05.760672 23126066861888 run_lib.py:133] step: 186850, training_loss: 1.95641e-02
I0215 15:26:23.349305 23126066861888 run_lib.py:133] step: 186900, training_loss: 1.89426e-02
I0215 15:26:23.501812 23126066861888 run_lib.py:146] step: 186900, eval_loss: 2.58306e-02
I0215 15:26:40.885498 23126066861888 run_lib.py:133] step: 186950, training_loss: 2.00275e-02
I0215 15:26:58.349146 23126066861888 run_lib.py:133] step: 187000, training_loss: 2.02691e-02
I0215 15:26:58.505547 23126066861888 run_lib.py:146] step: 187000, eval_loss: 2.71743e-02
I0215 15:27:16.010326 23126066861888 run_lib.py:133] step: 187050, training_loss: 1.92080e-02
I0215 15:27:33.397152 23126066861888 run_lib.py:133] step: 187100, training_loss: 1.98793e-02
I0215 15:27:33.569155 23126066861888 run_lib.py:146] step: 187100, eval_loss: 2.61878e-02
I0215 15:27:50.947801 23126066861888 run_lib.py:133] step: 187150, training_loss: 1.90469e-02
I0215 15:28:08.339513 23126066861888 run_lib.py:133] step: 187200, training_loss: 1.92636e-02
I0215 15:28:08.494995 23126066861888 run_lib.py:146] step: 187200, eval_loss: 2.69800e-02
I0215 15:28:26.055233 23126066861888 run_lib.py:133] step: 187250, training_loss: 1.94146e-02
I0215 15:28:43.584819 23126066861888 run_lib.py:133] step: 187300, training_loss: 1.90762e-02
I0215 15:28:43.738725 23126066861888 run_lib.py:146] step: 187300, eval_loss: 2.71985e-02
I0215 15:29:01.155164 23126066861888 run_lib.py:133] step: 187350, training_loss: 1.92167e-02
I0215 15:29:18.565816 23126066861888 run_lib.py:133] step: 187400, training_loss: 1.97830e-02
I0215 15:29:18.714197 23126066861888 run_lib.py:146] step: 187400, eval_loss: 2.62382e-02
I0215 15:29:36.275156 23126066861888 run_lib.py:133] step: 187450, training_loss: 1.99123e-02
I0215 15:29:53.659457 23126066861888 run_lib.py:133] step: 187500, training_loss: 1.97256e-02
I0215 15:29:53.813203 23126066861888 run_lib.py:146] step: 187500, eval_loss: 2.62863e-02
I0215 15:30:11.211822 23126066861888 run_lib.py:133] step: 187550, training_loss: 1.95050e-02
I0215 15:30:28.770408 23126066861888 run_lib.py:133] step: 187600, training_loss: 1.90476e-02
I0215 15:30:28.945039 23126066861888 run_lib.py:146] step: 187600, eval_loss: 2.74430e-02
I0215 15:30:46.363582 23126066861888 run_lib.py:133] step: 187650, training_loss: 1.86768e-02
I0215 15:31:03.963457 23126066861888 run_lib.py:133] step: 187700, training_loss: 1.89815e-02
I0215 15:31:04.118217 23126066861888 run_lib.py:146] step: 187700, eval_loss: 2.62403e-02
I0215 15:31:21.551339 23126066861888 run_lib.py:133] step: 187750, training_loss: 1.92128e-02
I0215 15:31:38.938260 23126066861888 run_lib.py:133] step: 187800, training_loss: 1.92560e-02
I0215 15:31:39.092072 23126066861888 run_lib.py:146] step: 187800, eval_loss: 2.64453e-02
I0215 15:31:56.645987 23126066861888 run_lib.py:133] step: 187850, training_loss: 1.96903e-02
I0215 15:32:14.055757 23126066861888 run_lib.py:133] step: 187900, training_loss: 1.92861e-02
I0215 15:32:14.209423 23126066861888 run_lib.py:146] step: 187900, eval_loss: 2.67823e-02
I0215 15:32:31.652942 23126066861888 run_lib.py:133] step: 187950, training_loss: 1.97927e-02
I0215 15:32:49.265599 23126066861888 run_lib.py:133] step: 188000, training_loss: 1.93693e-02
I0215 15:32:49.419915 23126066861888 run_lib.py:146] step: 188000, eval_loss: 2.56941e-02
I0215 15:33:06.804480 23126066861888 run_lib.py:133] step: 188050, training_loss: 1.97760e-02
I0215 15:33:24.188803 23126066861888 run_lib.py:133] step: 188100, training_loss: 1.95716e-02
I0215 15:33:24.346216 23126066861888 run_lib.py:146] step: 188100, eval_loss: 2.70792e-02
I0215 15:33:41.851639 23126066861888 run_lib.py:133] step: 188150, training_loss: 1.99593e-02
I0215 15:33:59.271504 23126066861888 run_lib.py:133] step: 188200, training_loss: 1.94529e-02
I0215 15:33:59.444198 23126066861888 run_lib.py:146] step: 188200, eval_loss: 2.56748e-02
I0215 15:34:16.860063 23126066861888 run_lib.py:133] step: 188250, training_loss: 1.92369e-02
I0215 15:34:34.231295 23126066861888 run_lib.py:133] step: 188300, training_loss: 1.94169e-02
I0215 15:34:34.388256 23126066861888 run_lib.py:146] step: 188300, eval_loss: 2.64004e-02
I0215 15:34:51.952104 23126066861888 run_lib.py:133] step: 188350, training_loss: 2.02774e-02
I0215 15:35:09.378383 23126066861888 run_lib.py:133] step: 188400, training_loss: 1.99860e-02
I0215 15:35:09.529273 23126066861888 run_lib.py:146] step: 188400, eval_loss: 2.71481e-02
I0215 15:35:26.939481 23126066861888 run_lib.py:133] step: 188450, training_loss: 1.94725e-02
I0215 15:35:44.377772 23126066861888 run_lib.py:133] step: 188500, training_loss: 2.04122e-02
I0215 15:35:44.544189 23126066861888 run_lib.py:146] step: 188500, eval_loss: 2.75294e-02
I0215 15:36:02.163886 23126066861888 run_lib.py:133] step: 188550, training_loss: 1.86358e-02
I0215 15:36:19.556302 23126066861888 run_lib.py:133] step: 188600, training_loss: 1.94784e-02
I0215 15:36:19.725113 23126066861888 run_lib.py:146] step: 188600, eval_loss: 2.67010e-02
I0215 15:36:37.129184 23126066861888 run_lib.py:133] step: 188650, training_loss: 1.89748e-02
I0215 15:36:54.661969 23126066861888 run_lib.py:133] step: 188700, training_loss: 1.92934e-02
I0215 15:36:54.817329 23126066861888 run_lib.py:146] step: 188700, eval_loss: 2.69008e-02
I0215 15:37:12.211776 23126066861888 run_lib.py:133] step: 188750, training_loss: 1.98299e-02
I0215 15:37:29.771973 23126066861888 run_lib.py:133] step: 188800, training_loss: 1.96228e-02
I0215 15:37:29.926826 23126066861888 run_lib.py:146] step: 188800, eval_loss: 2.66984e-02
I0215 15:37:47.342594 23126066861888 run_lib.py:133] step: 188850, training_loss: 1.89654e-02
I0215 15:38:04.785051 23126066861888 run_lib.py:133] step: 188900, training_loss: 1.98536e-02
I0215 15:38:04.937161 23126066861888 run_lib.py:146] step: 188900, eval_loss: 2.70846e-02
I0215 15:38:22.480084 23126066861888 run_lib.py:133] step: 188950, training_loss: 1.95822e-02
I0215 15:38:39.902289 23126066861888 run_lib.py:133] step: 189000, training_loss: 1.95105e-02
I0215 15:38:40.059243 23126066861888 run_lib.py:146] step: 189000, eval_loss: 2.58004e-02
I0215 15:38:57.437570 23126066861888 run_lib.py:133] step: 189050, training_loss: 1.95069e-02
I0215 15:39:15.050093 23126066861888 run_lib.py:133] step: 189100, training_loss: 1.93291e-02
I0215 15:39:15.216328 23126066861888 run_lib.py:146] step: 189100, eval_loss: 2.63128e-02
I0215 15:39:32.580459 23126066861888 run_lib.py:133] step: 189150, training_loss: 1.83959e-02
I0215 15:39:49.929691 23126066861888 run_lib.py:133] step: 189200, training_loss: 1.93345e-02
I0215 15:39:50.085368 23126066861888 run_lib.py:146] step: 189200, eval_loss: 2.68925e-02
I0215 15:40:07.546887 23126066861888 run_lib.py:133] step: 189250, training_loss: 1.88259e-02
I0215 15:40:24.911022 23126066861888 run_lib.py:133] step: 189300, training_loss: 1.94899e-02
I0215 15:40:25.061365 23126066861888 run_lib.py:146] step: 189300, eval_loss: 2.70988e-02
I0215 15:40:42.398151 23126066861888 run_lib.py:133] step: 189350, training_loss: 1.95513e-02
I0215 15:40:59.810969 23126066861888 run_lib.py:133] step: 189400, training_loss: 1.94490e-02
I0215 15:40:59.981417 23126066861888 run_lib.py:146] step: 189400, eval_loss: 2.70518e-02
I0215 15:41:17.615186 23126066861888 run_lib.py:133] step: 189450, training_loss: 1.99919e-02
I0215 15:41:35.126674 23126066861888 run_lib.py:133] step: 189500, training_loss: 1.86787e-02
I0215 15:41:35.283222 23126066861888 run_lib.py:146] step: 189500, eval_loss: 2.70186e-02
I0215 15:41:52.665579 23126066861888 run_lib.py:133] step: 189550, training_loss: 1.89061e-02
I0215 15:42:10.012557 23126066861888 run_lib.py:133] step: 189600, training_loss: 1.97067e-02
I0215 15:42:10.166088 23126066861888 run_lib.py:146] step: 189600, eval_loss: 2.57822e-02
I0215 15:42:27.697241 23126066861888 run_lib.py:133] step: 189650, training_loss: 1.98299e-02
I0215 15:42:45.148009 23126066861888 run_lib.py:133] step: 189700, training_loss: 1.91073e-02
I0215 15:42:45.304037 23126066861888 run_lib.py:146] step: 189700, eval_loss: 2.69101e-02
I0215 15:43:02.687891 23126066861888 run_lib.py:133] step: 189750, training_loss: 1.96245e-02
I0215 15:43:20.240373 23126066861888 run_lib.py:133] step: 189800, training_loss: 1.93531e-02
I0215 15:43:20.409222 23126066861888 run_lib.py:146] step: 189800, eval_loss: 2.60539e-02
I0215 15:43:37.792692 23126066861888 run_lib.py:133] step: 189850, training_loss: 2.01848e-02
I0215 15:43:55.324049 23126066861888 run_lib.py:133] step: 189900, training_loss: 1.92807e-02
I0215 15:43:55.476963 23126066861888 run_lib.py:146] step: 189900, eval_loss: 2.58181e-02
I0215 15:44:12.833865 23126066861888 run_lib.py:133] step: 189950, training_loss: 1.95224e-02
I0215 15:44:30.286170 23126066861888 run_lib.py:133] step: 190000, training_loss: 1.92232e-02
I0215 15:44:31.119140 23126066861888 run_lib.py:146] step: 190000, eval_loss: 2.74386e-02
I0215 15:44:51.963377 23126066861888 run_lib.py:133] step: 190050, training_loss: 1.97674e-02
I0215 15:45:09.338484 23126066861888 run_lib.py:133] step: 190100, training_loss: 1.92795e-02
I0215 15:45:09.494246 23126066861888 run_lib.py:146] step: 190100, eval_loss: 2.65073e-02
I0215 15:45:26.872292 23126066861888 run_lib.py:133] step: 190150, training_loss: 1.92239e-02
I0215 15:45:44.407357 23126066861888 run_lib.py:133] step: 190200, training_loss: 1.93906e-02
I0215 15:45:44.562188 23126066861888 run_lib.py:146] step: 190200, eval_loss: 2.61634e-02
I0215 15:46:01.950330 23126066861888 run_lib.py:133] step: 190250, training_loss: 1.90202e-02
I0215 15:46:19.418788 23126066861888 run_lib.py:133] step: 190300, training_loss: 1.96726e-02
I0215 15:46:19.571559 23126066861888 run_lib.py:146] step: 190300, eval_loss: 2.59451e-02
I0215 15:46:37.190578 23126066861888 run_lib.py:133] step: 190350, training_loss: 1.98275e-02
I0215 15:46:54.633039 23126066861888 run_lib.py:133] step: 190400, training_loss: 1.98281e-02
I0215 15:46:54.784710 23126066861888 run_lib.py:146] step: 190400, eval_loss: 2.62391e-02
I0215 15:47:12.343619 23126066861888 run_lib.py:133] step: 190450, training_loss: 1.98301e-02
I0215 15:47:29.733641 23126066861888 run_lib.py:133] step: 190500, training_loss: 1.92826e-02
I0215 15:47:29.898934 23126066861888 run_lib.py:146] step: 190500, eval_loss: 2.72790e-02
I0215 15:47:47.359457 23126066861888 run_lib.py:133] step: 190550, training_loss: 1.99795e-02
I0215 15:48:05.011629 23126066861888 run_lib.py:133] step: 190600, training_loss: 1.98697e-02
I0215 15:48:05.166834 23126066861888 run_lib.py:146] step: 190600, eval_loss: 2.56569e-02
I0215 15:48:22.518815 23126066861888 run_lib.py:133] step: 190650, training_loss: 1.99025e-02
I0215 15:48:39.878615 23126066861888 run_lib.py:133] step: 190700, training_loss: 1.96132e-02
I0215 15:48:40.033443 23126066861888 run_lib.py:146] step: 190700, eval_loss: 2.72977e-02
I0215 15:48:57.426232 23126066861888 run_lib.py:133] step: 190750, training_loss: 1.96365e-02
I0215 15:49:14.882696 23126066861888 run_lib.py:133] step: 190800, training_loss: 1.97775e-02
I0215 15:49:15.035670 23126066861888 run_lib.py:146] step: 190800, eval_loss: 2.55325e-02
I0215 15:49:32.577099 23126066861888 run_lib.py:133] step: 190850, training_loss: 1.97883e-02
I0215 15:49:50.059560 23126066861888 run_lib.py:133] step: 190900, training_loss: 1.87629e-02
I0215 15:49:50.220874 23126066861888 run_lib.py:146] step: 190900, eval_loss: 2.61436e-02
I0215 15:50:07.582558 23126066861888 run_lib.py:133] step: 190950, training_loss: 1.95084e-02
I0215 15:50:24.979620 23126066861888 run_lib.py:133] step: 191000, training_loss: 1.89568e-02
I0215 15:50:25.136344 23126066861888 run_lib.py:146] step: 191000, eval_loss: 2.65053e-02
I0215 15:50:42.634967 23126066861888 run_lib.py:133] step: 191050, training_loss: 1.92125e-02
I0215 15:51:00.025487 23126066861888 run_lib.py:133] step: 191100, training_loss: 1.96453e-02
I0215 15:51:00.187307 23126066861888 run_lib.py:146] step: 191100, eval_loss: 2.64388e-02
I0215 15:51:17.812750 23126066861888 run_lib.py:133] step: 191150, training_loss: 1.84256e-02
I0215 15:51:35.246892 23126066861888 run_lib.py:133] step: 191200, training_loss: 1.96648e-02
I0215 15:51:35.400326 23126066861888 run_lib.py:146] step: 191200, eval_loss: 2.66208e-02
I0215 15:51:52.807204 23126066861888 run_lib.py:133] step: 191250, training_loss: 1.88394e-02
I0215 15:52:10.344935 23126066861888 run_lib.py:133] step: 191300, training_loss: 1.90491e-02
I0215 15:52:10.495066 23126066861888 run_lib.py:146] step: 191300, eval_loss: 2.59795e-02
I0215 15:52:27.893868 23126066861888 run_lib.py:133] step: 191350, training_loss: 1.78699e-02
I0215 15:52:45.320443 23126066861888 run_lib.py:133] step: 191400, training_loss: 1.90075e-02
I0215 15:52:45.509419 23126066861888 run_lib.py:146] step: 191400, eval_loss: 2.64762e-02
I0215 15:53:03.131532 23126066861888 run_lib.py:133] step: 191450, training_loss: 1.99020e-02
I0215 15:53:20.578129 23126066861888 run_lib.py:133] step: 191500, training_loss: 1.95603e-02
I0215 15:53:20.737272 23126066861888 run_lib.py:146] step: 191500, eval_loss: 2.67395e-02
I0215 15:53:38.233690 23126066861888 run_lib.py:133] step: 191550, training_loss: 1.95350e-02
I0215 15:53:55.782797 23126066861888 run_lib.py:133] step: 191600, training_loss: 1.90275e-02
I0215 15:53:55.944270 23126066861888 run_lib.py:146] step: 191600, eval_loss: 2.68628e-02
I0215 15:54:13.316730 23126066861888 run_lib.py:133] step: 191650, training_loss: 1.98555e-02
I0215 15:54:30.790766 23126066861888 run_lib.py:133] step: 191700, training_loss: 1.91915e-02
I0215 15:54:30.944215 23126066861888 run_lib.py:146] step: 191700, eval_loss: 2.50172e-02
I0215 15:54:48.464063 23126066861888 run_lib.py:133] step: 191750, training_loss: 1.98304e-02
I0215 15:55:05.842363 23126066861888 run_lib.py:133] step: 191800, training_loss: 1.90465e-02
I0215 15:55:05.992998 23126066861888 run_lib.py:146] step: 191800, eval_loss: 2.74587e-02
I0215 15:55:23.349637 23126066861888 run_lib.py:133] step: 191850, training_loss: 1.88776e-02
I0215 15:55:40.699635 23126066861888 run_lib.py:133] step: 191900, training_loss: 1.96022e-02
I0215 15:55:40.855473 23126066861888 run_lib.py:146] step: 191900, eval_loss: 2.83300e-02
I0215 15:55:58.420886 23126066861888 run_lib.py:133] step: 191950, training_loss: 1.97767e-02
I0215 15:56:15.879538 23126066861888 run_lib.py:133] step: 192000, training_loss: 1.97506e-02
I0215 15:56:16.034365 23126066861888 run_lib.py:146] step: 192000, eval_loss: 2.73215e-02
I0215 15:56:33.454981 23126066861888 run_lib.py:133] step: 192050, training_loss: 1.96225e-02
I0215 15:56:50.850209 23126066861888 run_lib.py:133] step: 192100, training_loss: 1.89050e-02
I0215 15:56:51.004383 23126066861888 run_lib.py:146] step: 192100, eval_loss: 2.64853e-02
I0215 15:57:08.599676 23126066861888 run_lib.py:133] step: 192150, training_loss: 1.91564e-02
I0215 15:57:25.969950 23126066861888 run_lib.py:133] step: 192200, training_loss: 1.88632e-02
I0215 15:57:26.120735 23126066861888 run_lib.py:146] step: 192200, eval_loss: 2.78350e-02
I0215 15:57:43.478618 23126066861888 run_lib.py:133] step: 192250, training_loss: 1.90941e-02
I0215 15:58:01.079675 23126066861888 run_lib.py:133] step: 192300, training_loss: 1.88262e-02
I0215 15:58:01.238230 23126066861888 run_lib.py:146] step: 192300, eval_loss: 2.59469e-02
I0215 15:58:18.691550 23126066861888 run_lib.py:133] step: 192350, training_loss: 1.91261e-02
I0215 15:58:36.266069 23126066861888 run_lib.py:133] step: 192400, training_loss: 1.85364e-02
I0215 15:58:36.423303 23126066861888 run_lib.py:146] step: 192400, eval_loss: 2.66572e-02
I0215 15:58:53.806226 23126066861888 run_lib.py:133] step: 192450, training_loss: 1.91397e-02
I0215 15:59:11.208792 23126066861888 run_lib.py:133] step: 192500, training_loss: 1.88980e-02
I0215 15:59:11.363245 23126066861888 run_lib.py:146] step: 192500, eval_loss: 2.64041e-02
I0215 15:59:28.923254 23126066861888 run_lib.py:133] step: 192550, training_loss: 1.97456e-02
I0215 15:59:46.434566 23126066861888 run_lib.py:133] step: 192600, training_loss: 1.95977e-02
I0215 15:59:46.589134 23126066861888 run_lib.py:146] step: 192600, eval_loss: 2.57433e-02
I0215 16:00:04.026640 23126066861888 run_lib.py:133] step: 192650, training_loss: 1.98176e-02
I0215 16:00:21.609199 23126066861888 run_lib.py:133] step: 192700, training_loss: 1.91100e-02
I0215 16:00:21.764151 23126066861888 run_lib.py:146] step: 192700, eval_loss: 2.70739e-02
I0215 16:00:39.147022 23126066861888 run_lib.py:133] step: 192750, training_loss: 1.92712e-02
I0215 16:00:56.521481 23126066861888 run_lib.py:133] step: 192800, training_loss: 1.91130e-02
I0215 16:00:56.683042 23126066861888 run_lib.py:146] step: 192800, eval_loss: 2.71454e-02
I0215 16:01:14.128274 23126066861888 run_lib.py:133] step: 192850, training_loss: 1.91071e-02
I0215 16:01:31.578635 23126066861888 run_lib.py:133] step: 192900, training_loss: 1.96784e-02
I0215 16:01:31.739191 23126066861888 run_lib.py:146] step: 192900, eval_loss: 2.70558e-02
I0215 16:01:49.180029 23126066861888 run_lib.py:133] step: 192950, training_loss: 1.92265e-02
I0215 16:02:06.569127 23126066861888 run_lib.py:133] step: 193000, training_loss: 2.02137e-02
I0215 16:02:06.764559 23126066861888 run_lib.py:146] step: 193000, eval_loss: 2.63084e-02
I0215 16:02:24.323257 23126066861888 run_lib.py:133] step: 193050, training_loss: 1.96344e-02
I0215 16:02:41.716245 23126066861888 run_lib.py:133] step: 193100, training_loss: 1.94101e-02
I0215 16:02:41.872989 23126066861888 run_lib.py:146] step: 193100, eval_loss: 2.58427e-02
I0215 16:02:59.339993 23126066861888 run_lib.py:133] step: 193150, training_loss: 1.96648e-02
I0215 16:03:16.811540 23126066861888 run_lib.py:133] step: 193200, training_loss: 1.92232e-02
I0215 16:03:16.974203 23126066861888 run_lib.py:146] step: 193200, eval_loss: 2.57861e-02
I0215 16:03:34.538673 23126066861888 run_lib.py:133] step: 193250, training_loss: 1.95145e-02
I0215 16:03:51.951941 23126066861888 run_lib.py:133] step: 193300, training_loss: 1.97178e-02
I0215 16:03:52.111243 23126066861888 run_lib.py:146] step: 193300, eval_loss: 2.72157e-02
I0215 16:04:09.509733 23126066861888 run_lib.py:133] step: 193350, training_loss: 1.90041e-02
I0215 16:04:27.069085 23126066861888 run_lib.py:133] step: 193400, training_loss: 1.98825e-02
I0215 16:04:27.226206 23126066861888 run_lib.py:146] step: 193400, eval_loss: 2.80272e-02
I0215 16:04:44.630941 23126066861888 run_lib.py:133] step: 193450, training_loss: 1.82431e-02
I0215 16:05:02.189253 23126066861888 run_lib.py:133] step: 193500, training_loss: 1.86813e-02
I0215 16:05:02.351812 23126066861888 run_lib.py:146] step: 193500, eval_loss: 2.66159e-02
I0215 16:05:19.749047 23126066861888 run_lib.py:133] step: 193550, training_loss: 2.00435e-02
I0215 16:05:37.115947 23126066861888 run_lib.py:133] step: 193600, training_loss: 1.95262e-02
I0215 16:05:37.270132 23126066861888 run_lib.py:146] step: 193600, eval_loss: 2.61817e-02
I0215 16:05:54.820850 23126066861888 run_lib.py:133] step: 193650, training_loss: 2.00979e-02
I0215 16:06:12.213971 23126066861888 run_lib.py:133] step: 193700, training_loss: 1.87925e-02
I0215 16:06:12.367453 23126066861888 run_lib.py:146] step: 193700, eval_loss: 2.67090e-02
I0215 16:06:29.806261 23126066861888 run_lib.py:133] step: 193750, training_loss: 2.01020e-02
I0215 16:06:47.408589 23126066861888 run_lib.py:133] step: 193800, training_loss: 1.90992e-02
I0215 16:06:47.573464 23126066861888 run_lib.py:146] step: 193800, eval_loss: 2.55725e-02
I0215 16:07:04.923883 23126066861888 run_lib.py:133] step: 193850, training_loss: 1.89298e-02
I0215 16:07:22.290414 23126066861888 run_lib.py:133] step: 193900, training_loss: 1.94379e-02
I0215 16:07:22.444251 23126066861888 run_lib.py:146] step: 193900, eval_loss: 2.63930e-02
I0215 16:07:39.912823 23126066861888 run_lib.py:133] step: 193950, training_loss: 1.99160e-02
I0215 16:07:57.248075 23126066861888 run_lib.py:133] step: 194000, training_loss: 1.91984e-02
I0215 16:07:57.404786 23126066861888 run_lib.py:146] step: 194000, eval_loss: 2.72927e-02
I0215 16:08:14.811328 23126066861888 run_lib.py:133] step: 194050, training_loss: 1.90622e-02
I0215 16:08:32.224471 23126066861888 run_lib.py:133] step: 194100, training_loss: 2.00141e-02
I0215 16:08:32.384284 23126066861888 run_lib.py:146] step: 194100, eval_loss: 2.72058e-02
I0215 16:08:49.983468 23126066861888 run_lib.py:133] step: 194150, training_loss: 1.97657e-02
I0215 16:09:07.409937 23126066861888 run_lib.py:133] step: 194200, training_loss: 1.96568e-02
I0215 16:09:07.564312 23126066861888 run_lib.py:146] step: 194200, eval_loss: 2.60825e-02
I0215 16:09:24.881035 23126066861888 run_lib.py:133] step: 194250, training_loss: 1.95895e-02
I0215 16:09:42.317207 23126066861888 run_lib.py:133] step: 194300, training_loss: 1.93949e-02
I0215 16:09:42.489172 23126066861888 run_lib.py:146] step: 194300, eval_loss: 2.69023e-02
I0215 16:10:00.119550 23126066861888 run_lib.py:133] step: 194350, training_loss: 1.89486e-02
I0215 16:10:17.513103 23126066861888 run_lib.py:133] step: 194400, training_loss: 1.86042e-02
I0215 16:10:17.668241 23126066861888 run_lib.py:146] step: 194400, eval_loss: 2.70942e-02
I0215 16:10:35.069216 23126066861888 run_lib.py:133] step: 194450, training_loss: 1.92615e-02
I0215 16:10:52.605059 23126066861888 run_lib.py:133] step: 194500, training_loss: 1.99237e-02
I0215 16:10:52.758868 23126066861888 run_lib.py:146] step: 194500, eval_loss: 2.61690e-02
I0215 16:11:10.159075 23126066861888 run_lib.py:133] step: 194550, training_loss: 1.92657e-02
I0215 16:11:27.687626 23126066861888 run_lib.py:133] step: 194600, training_loss: 1.94728e-02
I0215 16:11:27.857123 23126066861888 run_lib.py:146] step: 194600, eval_loss: 2.61006e-02
I0215 16:11:45.280864 23126066861888 run_lib.py:133] step: 194650, training_loss: 1.96558e-02
I0215 16:12:02.661723 23126066861888 run_lib.py:133] step: 194700, training_loss: 2.00988e-02
I0215 16:12:02.816204 23126066861888 run_lib.py:146] step: 194700, eval_loss: 2.72303e-02
I0215 16:12:20.363800 23126066861888 run_lib.py:133] step: 194750, training_loss: 1.95652e-02
I0215 16:12:37.738083 23126066861888 run_lib.py:133] step: 194800, training_loss: 1.91312e-02
I0215 16:12:37.895202 23126066861888 run_lib.py:146] step: 194800, eval_loss: 2.65487e-02
I0215 16:12:55.262326 23126066861888 run_lib.py:133] step: 194850, training_loss: 1.96824e-02
I0215 16:13:12.785679 23126066861888 run_lib.py:133] step: 194900, training_loss: 1.91236e-02
I0215 16:13:12.942041 23126066861888 run_lib.py:146] step: 194900, eval_loss: 2.55535e-02
I0215 16:13:30.399955 23126066861888 run_lib.py:133] step: 194950, training_loss: 1.96414e-02
I0215 16:13:47.789460 23126066861888 run_lib.py:133] step: 195000, training_loss: 1.94466e-02
I0215 16:13:47.949297 23126066861888 run_lib.py:146] step: 195000, eval_loss: 2.72140e-02
I0215 16:14:05.471151 23126066861888 run_lib.py:133] step: 195050, training_loss: 1.90666e-02
I0215 16:14:22.881181 23126066861888 run_lib.py:133] step: 195100, training_loss: 1.91561e-02
I0215 16:14:23.033250 23126066861888 run_lib.py:146] step: 195100, eval_loss: 2.62530e-02
I0215 16:14:40.419081 23126066861888 run_lib.py:133] step: 195150, training_loss: 1.96248e-02
I0215 16:14:57.789456 23126066861888 run_lib.py:133] step: 195200, training_loss: 1.84372e-02
I0215 16:14:57.959571 23126066861888 run_lib.py:146] step: 195200, eval_loss: 2.64007e-02
I0215 16:15:15.593649 23126066861888 run_lib.py:133] step: 195250, training_loss: 1.95652e-02
I0215 16:15:33.131665 23126066861888 run_lib.py:133] step: 195300, training_loss: 1.97287e-02
I0215 16:15:33.287139 23126066861888 run_lib.py:146] step: 195300, eval_loss: 2.69739e-02
I0215 16:15:50.703389 23126066861888 run_lib.py:133] step: 195350, training_loss: 1.98567e-02
I0215 16:16:08.085015 23126066861888 run_lib.py:133] step: 195400, training_loss: 1.93221e-02
I0215 16:16:08.236038 23126066861888 run_lib.py:146] step: 195400, eval_loss: 2.65135e-02
I0215 16:16:25.757537 23126066861888 run_lib.py:133] step: 195450, training_loss: 1.94221e-02
I0215 16:16:43.187623 23126066861888 run_lib.py:133] step: 195500, training_loss: 1.91948e-02
I0215 16:16:43.342461 23126066861888 run_lib.py:146] step: 195500, eval_loss: 2.70821e-02
I0215 16:17:00.806248 23126066861888 run_lib.py:133] step: 195550, training_loss: 1.97492e-02
I0215 16:17:18.395554 23126066861888 run_lib.py:133] step: 195600, training_loss: 1.97415e-02
I0215 16:17:18.545922 23126066861888 run_lib.py:146] step: 195600, eval_loss: 2.61930e-02
I0215 16:17:35.907825 23126066861888 run_lib.py:133] step: 195650, training_loss: 1.99833e-02
I0215 16:17:53.437350 23126066861888 run_lib.py:133] step: 195700, training_loss: 1.87364e-02
I0215 16:17:53.601731 23126066861888 run_lib.py:146] step: 195700, eval_loss: 2.68102e-02
I0215 16:18:10.967436 23126066861888 run_lib.py:133] step: 195750, training_loss: 2.06048e-02
I0215 16:18:28.330791 23126066861888 run_lib.py:133] step: 195800, training_loss: 1.93339e-02
I0215 16:18:28.494906 23126066861888 run_lib.py:146] step: 195800, eval_loss: 2.64503e-02
I0215 16:18:46.112473 23126066861888 run_lib.py:133] step: 195850, training_loss: 1.96602e-02
I0215 16:19:03.523235 23126066861888 run_lib.py:133] step: 195900, training_loss: 1.88109e-02
I0215 16:19:03.678220 23126066861888 run_lib.py:146] step: 195900, eval_loss: 2.66328e-02
I0215 16:19:21.078166 23126066861888 run_lib.py:133] step: 195950, training_loss: 1.91681e-02
I0215 16:19:38.677943 23126066861888 run_lib.py:133] step: 196000, training_loss: 1.85910e-02
I0215 16:19:38.836127 23126066861888 run_lib.py:146] step: 196000, eval_loss: 2.79264e-02
I0215 16:19:56.198861 23126066861888 run_lib.py:133] step: 196050, training_loss: 1.94548e-02
I0215 16:20:13.595010 23126066861888 run_lib.py:133] step: 196100, training_loss: 2.01714e-02
I0215 16:20:13.755220 23126066861888 run_lib.py:146] step: 196100, eval_loss: 2.69239e-02
I0215 16:20:31.291238 23126066861888 run_lib.py:133] step: 196150, training_loss: 1.92758e-02
I0215 16:20:48.688882 23126066861888 run_lib.py:133] step: 196200, training_loss: 1.95998e-02
I0215 16:20:48.851005 23126066861888 run_lib.py:146] step: 196200, eval_loss: 2.56338e-02
I0215 16:21:06.264024 23126066861888 run_lib.py:133] step: 196250, training_loss: 1.91670e-02
I0215 16:21:23.584707 23126066861888 run_lib.py:133] step: 196300, training_loss: 1.89762e-02
I0215 16:21:23.738914 23126066861888 run_lib.py:146] step: 196300, eval_loss: 2.64915e-02
I0215 16:21:41.295573 23126066861888 run_lib.py:133] step: 196350, training_loss: 1.96470e-02
I0215 16:21:58.787038 23126066861888 run_lib.py:133] step: 196400, training_loss: 1.96625e-02
I0215 16:21:58.941452 23126066861888 run_lib.py:146] step: 196400, eval_loss: 2.64535e-02
I0215 16:22:16.357351 23126066861888 run_lib.py:133] step: 196450, training_loss: 1.86190e-02
I0215 16:22:33.690326 23126066861888 run_lib.py:133] step: 196500, training_loss: 2.00009e-02
I0215 16:22:33.849301 23126066861888 run_lib.py:146] step: 196500, eval_loss: 2.69457e-02
I0215 16:22:51.396156 23126066861888 run_lib.py:133] step: 196550, training_loss: 1.94366e-02
I0215 16:23:08.806192 23126066861888 run_lib.py:133] step: 196600, training_loss: 1.90960e-02
I0215 16:23:08.965012 23126066861888 run_lib.py:146] step: 196600, eval_loss: 2.63613e-02
I0215 16:23:26.352311 23126066861888 run_lib.py:133] step: 196650, training_loss: 1.91133e-02
I0215 16:23:43.904888 23126066861888 run_lib.py:133] step: 196700, training_loss: 1.95385e-02
I0215 16:23:44.078997 23126066861888 run_lib.py:146] step: 196700, eval_loss: 2.75273e-02
I0215 16:24:01.519920 23126066861888 run_lib.py:133] step: 196750, training_loss: 1.92631e-02
I0215 16:24:19.097182 23126066861888 run_lib.py:133] step: 196800, training_loss: 1.91920e-02
I0215 16:24:19.252446 23126066861888 run_lib.py:146] step: 196800, eval_loss: 2.66452e-02
I0215 16:24:36.706621 23126066861888 run_lib.py:133] step: 196850, training_loss: 1.97777e-02
I0215 16:24:54.089926 23126066861888 run_lib.py:133] step: 196900, training_loss: 1.95385e-02
I0215 16:24:54.244258 23126066861888 run_lib.py:146] step: 196900, eval_loss: 2.61494e-02
I0215 16:25:11.748171 23126066861888 run_lib.py:133] step: 196950, training_loss: 1.92384e-02
I0215 16:25:29.171046 23126066861888 run_lib.py:133] step: 197000, training_loss: 1.94100e-02
I0215 16:25:29.329197 23126066861888 run_lib.py:146] step: 197000, eval_loss: 2.72981e-02
I0215 16:25:46.788190 23126066861888 run_lib.py:133] step: 197050, training_loss: 1.91897e-02
I0215 16:26:04.372954 23126066861888 run_lib.py:133] step: 197100, training_loss: 2.00707e-02
I0215 16:26:04.526885 23126066861888 run_lib.py:146] step: 197100, eval_loss: 2.69332e-02
I0215 16:26:21.882379 23126066861888 run_lib.py:133] step: 197150, training_loss: 1.84689e-02
I0215 16:26:39.240677 23126066861888 run_lib.py:133] step: 197200, training_loss: 1.89747e-02
I0215 16:26:39.396638 23126066861888 run_lib.py:146] step: 197200, eval_loss: 2.58304e-02
I0215 16:26:56.835925 23126066861888 run_lib.py:133] step: 197250, training_loss: 1.93955e-02
I0215 16:27:14.258933 23126066861888 run_lib.py:133] step: 197300, training_loss: 1.95401e-02
I0215 16:27:14.416294 23126066861888 run_lib.py:146] step: 197300, eval_loss: 2.62696e-02
I0215 16:27:31.807411 23126066861888 run_lib.py:133] step: 197350, training_loss: 1.89771e-02
I0215 16:27:49.198537 23126066861888 run_lib.py:133] step: 197400, training_loss: 1.92400e-02
I0215 16:27:49.359294 23126066861888 run_lib.py:146] step: 197400, eval_loss: 2.62246e-02
I0215 16:28:06.935940 23126066861888 run_lib.py:133] step: 197450, training_loss: 1.92790e-02
I0215 16:28:24.392466 23126066861888 run_lib.py:133] step: 197500, training_loss: 1.93676e-02
I0215 16:28:24.542103 23126066861888 run_lib.py:146] step: 197500, eval_loss: 2.63533e-02
I0215 16:28:41.891593 23126066861888 run_lib.py:133] step: 197550, training_loss: 1.86734e-02
I0215 16:28:59.311463 23126066861888 run_lib.py:133] step: 197600, training_loss: 1.95415e-02
I0215 16:28:59.482490 23126066861888 run_lib.py:146] step: 197600, eval_loss: 2.63980e-02
I0215 16:29:17.083020 23126066861888 run_lib.py:133] step: 197650, training_loss: 1.87792e-02
I0215 16:29:34.474734 23126066861888 run_lib.py:133] step: 197700, training_loss: 1.92342e-02
I0215 16:29:34.629319 23126066861888 run_lib.py:146] step: 197700, eval_loss: 2.79119e-02
I0215 16:29:52.019678 23126066861888 run_lib.py:133] step: 197750, training_loss: 1.94890e-02
I0215 16:30:09.537517 23126066861888 run_lib.py:133] step: 197800, training_loss: 1.98129e-02
I0215 16:30:09.692023 23126066861888 run_lib.py:146] step: 197800, eval_loss: 2.83327e-02
I0215 16:30:27.077136 23126066861888 run_lib.py:133] step: 197850, training_loss: 1.94246e-02
I0215 16:30:44.661434 23126066861888 run_lib.py:133] step: 197900, training_loss: 1.81626e-02
I0215 16:30:44.813376 23126066861888 run_lib.py:146] step: 197900, eval_loss: 2.65118e-02
I0215 16:31:02.265502 23126066861888 run_lib.py:133] step: 197950, training_loss: 1.96472e-02
I0215 16:31:19.647653 23126066861888 run_lib.py:133] step: 198000, training_loss: 1.97182e-02
I0215 16:31:19.800071 23126066861888 run_lib.py:146] step: 198000, eval_loss: 2.56727e-02
I0215 16:31:37.424456 23126066861888 run_lib.py:133] step: 198050, training_loss: 1.85086e-02
I0215 16:31:54.855716 23126066861888 run_lib.py:133] step: 198100, training_loss: 1.92324e-02
I0215 16:31:55.012181 23126066861888 run_lib.py:146] step: 198100, eval_loss: 2.70135e-02
I0215 16:32:12.404968 23126066861888 run_lib.py:133] step: 198150, training_loss: 1.90546e-02
I0215 16:32:29.981604 23126066861888 run_lib.py:133] step: 198200, training_loss: 1.90404e-02
I0215 16:32:30.135037 23126066861888 run_lib.py:146] step: 198200, eval_loss: 2.62375e-02
I0215 16:32:47.507982 23126066861888 run_lib.py:133] step: 198250, training_loss: 1.89855e-02
I0215 16:33:04.881897 23126066861888 run_lib.py:133] step: 198300, training_loss: 1.94847e-02
I0215 16:33:05.036284 23126066861888 run_lib.py:146] step: 198300, eval_loss: 2.80165e-02
I0215 16:33:22.506468 23126066861888 run_lib.py:133] step: 198350, training_loss: 1.95401e-02
I0215 16:33:39.928997 23126066861888 run_lib.py:133] step: 198400, training_loss: 1.87186e-02
I0215 16:33:40.082982 23126066861888 run_lib.py:146] step: 198400, eval_loss: 2.65445e-02
I0215 16:33:57.459763 23126066861888 run_lib.py:133] step: 198450, training_loss: 1.89476e-02
I0215 16:34:14.868708 23126066861888 run_lib.py:133] step: 198500, training_loss: 1.82428e-02
I0215 16:34:15.040259 23126066861888 run_lib.py:146] step: 198500, eval_loss: 2.63290e-02
I0215 16:34:32.626283 23126066861888 run_lib.py:133] step: 198550, training_loss: 1.90947e-02
I0215 16:34:50.091552 23126066861888 run_lib.py:133] step: 198600, training_loss: 1.94737e-02
I0215 16:34:50.247357 23126066861888 run_lib.py:146] step: 198600, eval_loss: 2.70630e-02
I0215 16:35:07.627733 23126066861888 run_lib.py:133] step: 198650, training_loss: 1.95631e-02
I0215 16:35:25.009014 23126066861888 run_lib.py:133] step: 198700, training_loss: 1.93382e-02
I0215 16:35:25.166191 23126066861888 run_lib.py:146] step: 198700, eval_loss: 2.62384e-02
I0215 16:35:42.713004 23126066861888 run_lib.py:133] step: 198750, training_loss: 1.93794e-02
I0215 16:36:00.163524 23126066861888 run_lib.py:133] step: 198800, training_loss: 1.99139e-02
I0215 16:36:00.317440 23126066861888 run_lib.py:146] step: 198800, eval_loss: 2.58770e-02
I0215 16:36:17.739150 23126066861888 run_lib.py:133] step: 198850, training_loss: 1.91004e-02
I0215 16:36:35.282430 23126066861888 run_lib.py:133] step: 198900, training_loss: 1.94504e-02
I0215 16:36:35.446967 23126066861888 run_lib.py:146] step: 198900, eval_loss: 2.74341e-02
I0215 16:36:52.845337 23126066861888 run_lib.py:133] step: 198950, training_loss: 1.96746e-02
I0215 16:37:10.413137 23126066861888 run_lib.py:133] step: 199000, training_loss: 1.96129e-02
I0215 16:37:10.567132 23126066861888 run_lib.py:146] step: 199000, eval_loss: 2.70224e-02
I0215 16:37:27.960106 23126066861888 run_lib.py:133] step: 199050, training_loss: 2.00282e-02
I0215 16:37:45.443738 23126066861888 run_lib.py:133] step: 199100, training_loss: 1.85972e-02
I0215 16:37:45.601247 23126066861888 run_lib.py:146] step: 199100, eval_loss: 2.60573e-02
I0215 16:38:03.194407 23126066861888 run_lib.py:133] step: 199150, training_loss: 1.95979e-02
I0215 16:38:20.580897 23126066861888 run_lib.py:133] step: 199200, training_loss: 2.04635e-02
I0215 16:38:20.735242 23126066861888 run_lib.py:146] step: 199200, eval_loss: 2.71572e-02
I0215 16:38:38.139813 23126066861888 run_lib.py:133] step: 199250, training_loss: 1.82606e-02
I0215 16:38:55.632332 23126066861888 run_lib.py:133] step: 199300, training_loss: 1.90517e-02
I0215 16:38:55.785798 23126066861888 run_lib.py:146] step: 199300, eval_loss: 2.72850e-02
I0215 16:39:13.178393 23126066861888 run_lib.py:133] step: 199350, training_loss: 1.95070e-02
I0215 16:39:30.643788 23126066861888 run_lib.py:133] step: 199400, training_loss: 1.96753e-02
I0215 16:39:30.798344 23126066861888 run_lib.py:146] step: 199400, eval_loss: 2.64530e-02
I0215 16:39:48.326119 23126066861888 run_lib.py:133] step: 199450, training_loss: 1.94598e-02
I0215 16:40:05.728975 23126066861888 run_lib.py:133] step: 199500, training_loss: 1.93961e-02
I0215 16:40:05.886584 23126066861888 run_lib.py:146] step: 199500, eval_loss: 2.58516e-02
I0215 16:40:23.283929 23126066861888 run_lib.py:133] step: 199550, training_loss: 1.86651e-02
I0215 16:40:40.661476 23126066861888 run_lib.py:133] step: 199600, training_loss: 1.91164e-02
I0215 16:40:40.830182 23126066861888 run_lib.py:146] step: 199600, eval_loss: 2.75701e-02
I0215 16:40:58.365928 23126066861888 run_lib.py:133] step: 199650, training_loss: 2.02399e-02
I0215 16:41:15.913035 23126066861888 run_lib.py:133] step: 199700, training_loss: 1.89050e-02
I0215 16:41:16.066978 23126066861888 run_lib.py:146] step: 199700, eval_loss: 2.76413e-02
I0215 16:41:33.477136 23126066861888 run_lib.py:133] step: 199750, training_loss: 1.91621e-02
I0215 16:41:50.857986 23126066861888 run_lib.py:133] step: 199800, training_loss: 2.00077e-02
I0215 16:41:51.007704 23126066861888 run_lib.py:146] step: 199800, eval_loss: 2.63575e-02
I0215 16:42:08.508697 23126066861888 run_lib.py:133] step: 199850, training_loss: 1.90228e-02
I0215 16:42:25.879425 23126066861888 run_lib.py:133] step: 199900, training_loss: 1.89944e-02
I0215 16:42:26.042211 23126066861888 run_lib.py:146] step: 199900, eval_loss: 2.62759e-02
I0215 16:42:43.479822 23126066861888 run_lib.py:133] step: 199950, training_loss: 1.95294e-02
I0215 16:43:01.065083 23126066861888 run_lib.py:133] step: 200000, training_loss: 1.91524e-02
I0215 16:43:02.134013 23126066861888 run_lib.py:146] step: 200000, eval_loss: 2.57747e-02
I0215 16:43:22.124692 23126066861888 run_lib.py:133] step: 200050, training_loss: 1.87332e-02
I0215 16:43:39.500038 23126066861888 run_lib.py:133] step: 200100, training_loss: 1.93794e-02
I0215 16:43:39.654091 23126066861888 run_lib.py:146] step: 200100, eval_loss: 2.70101e-02
I0215 16:43:57.150670 23126066861888 run_lib.py:133] step: 200150, training_loss: 1.89722e-02
I0215 16:44:14.605583 23126066861888 run_lib.py:133] step: 200200, training_loss: 1.98055e-02
I0215 16:44:14.776093 23126066861888 run_lib.py:146] step: 200200, eval_loss: 2.78233e-02
I0215 16:44:32.182137 23126066861888 run_lib.py:133] step: 200250, training_loss: 1.92466e-02
I0215 16:44:49.613258 23126066861888 run_lib.py:133] step: 200300, training_loss: 1.90332e-02
I0215 16:44:49.765351 23126066861888 run_lib.py:146] step: 200300, eval_loss: 2.62002e-02
I0215 16:45:07.372865 23126066861888 run_lib.py:133] step: 200350, training_loss: 1.99789e-02
I0215 16:45:24.806391 23126066861888 run_lib.py:133] step: 200400, training_loss: 1.84296e-02
I0215 16:45:24.957275 23126066861888 run_lib.py:146] step: 200400, eval_loss: 2.67411e-02
I0215 16:45:42.440851 23126066861888 run_lib.py:133] step: 200450, training_loss: 1.89583e-02
I0215 16:45:59.771751 23126066861888 run_lib.py:133] step: 200500, training_loss: 1.98337e-02
I0215 16:45:59.942309 23126066861888 run_lib.py:146] step: 200500, eval_loss: 2.64401e-02
I0215 16:46:17.433604 23126066861888 run_lib.py:133] step: 200550, training_loss: 1.98589e-02
I0215 16:46:34.971681 23126066861888 run_lib.py:133] step: 200600, training_loss: 1.97369e-02
I0215 16:46:35.122137 23126066861888 run_lib.py:146] step: 200600, eval_loss: 2.74945e-02
I0215 16:46:52.543943 23126066861888 run_lib.py:133] step: 200650, training_loss: 1.94440e-02
I0215 16:47:09.895601 23126066861888 run_lib.py:133] step: 200700, training_loss: 1.95880e-02
I0215 16:47:10.048139 23126066861888 run_lib.py:146] step: 200700, eval_loss: 2.64246e-02
I0215 16:47:27.623647 23126066861888 run_lib.py:133] step: 200750, training_loss: 1.92197e-02
I0215 16:47:45.032921 23126066861888 run_lib.py:133] step: 200800, training_loss: 1.95511e-02
I0215 16:47:45.188963 23126066861888 run_lib.py:146] step: 200800, eval_loss: 2.73411e-02
I0215 16:48:02.846469 23126066861888 run_lib.py:133] step: 200850, training_loss: 1.89083e-02
I0215 16:48:20.232053 23126066861888 run_lib.py:133] step: 200900, training_loss: 1.97179e-02
I0215 16:48:20.391842 23126066861888 run_lib.py:146] step: 200900, eval_loss: 2.80216e-02
I0215 16:48:37.777055 23126066861888 run_lib.py:133] step: 200950, training_loss: 1.86905e-02
I0215 16:48:55.341706 23126066861888 run_lib.py:133] step: 201000, training_loss: 1.93269e-02
I0215 16:48:55.497336 23126066861888 run_lib.py:146] step: 201000, eval_loss: 2.70803e-02
I0215 16:49:12.879683 23126066861888 run_lib.py:133] step: 201050, training_loss: 1.93367e-02
I0215 16:49:30.283624 23126066861888 run_lib.py:133] step: 201100, training_loss: 1.92915e-02
I0215 16:49:30.439194 23126066861888 run_lib.py:146] step: 201100, eval_loss: 2.65596e-02
I0215 16:49:47.895386 23126066861888 run_lib.py:133] step: 201150, training_loss: 1.93650e-02
I0215 16:50:05.253491 23126066861888 run_lib.py:133] step: 201200, training_loss: 1.92341e-02
I0215 16:50:05.408327 23126066861888 run_lib.py:146] step: 201200, eval_loss: 2.49211e-02
I0215 16:50:22.973450 23126066861888 run_lib.py:133] step: 201250, training_loss: 1.94537e-02
I0215 16:50:40.433151 23126066861888 run_lib.py:133] step: 201300, training_loss: 1.94462e-02
I0215 16:50:40.583994 23126066861888 run_lib.py:146] step: 201300, eval_loss: 2.52658e-02
I0215 16:50:57.953818 23126066861888 run_lib.py:133] step: 201350, training_loss: 1.95831e-02
I0215 16:51:15.360592 23126066861888 run_lib.py:133] step: 201400, training_loss: 1.94125e-02
I0215 16:51:15.525321 23126066861888 run_lib.py:146] step: 201400, eval_loss: 2.73825e-02
I0215 16:51:33.130269 23126066861888 run_lib.py:133] step: 201450, training_loss: 1.93744e-02
I0215 16:51:50.542989 23126066861888 run_lib.py:133] step: 201500, training_loss: 1.94598e-02
I0215 16:51:50.698971 23126066861888 run_lib.py:146] step: 201500, eval_loss: 2.70690e-02
I0215 16:52:08.251471 23126066861888 run_lib.py:133] step: 201550, training_loss: 1.98889e-02
I0215 16:52:25.598940 23126066861888 run_lib.py:133] step: 201600, training_loss: 1.92903e-02
I0215 16:52:25.755367 23126066861888 run_lib.py:146] step: 201600, eval_loss: 2.72248e-02
I0215 16:52:43.212624 23126066861888 run_lib.py:133] step: 201650, training_loss: 1.96128e-02
I0215 16:53:00.793874 23126066861888 run_lib.py:133] step: 201700, training_loss: 1.84141e-02
I0215 16:53:00.945234 23126066861888 run_lib.py:146] step: 201700, eval_loss: 2.60542e-02
I0215 16:53:18.410689 23126066861888 run_lib.py:133] step: 201750, training_loss: 1.84040e-02
I0215 16:53:35.787814 23126066861888 run_lib.py:133] step: 201800, training_loss: 1.90528e-02
I0215 16:53:35.938047 23126066861888 run_lib.py:146] step: 201800, eval_loss: 2.71944e-02
I0215 16:53:53.504024 23126066861888 run_lib.py:133] step: 201850, training_loss: 1.96247e-02
I0215 16:54:10.928271 23126066861888 run_lib.py:133] step: 201900, training_loss: 1.86642e-02
I0215 16:54:11.081998 23126066861888 run_lib.py:146] step: 201900, eval_loss: 2.60795e-02
I0215 16:54:28.493436 23126066861888 run_lib.py:133] step: 201950, training_loss: 1.88005e-02
I0215 16:54:46.050462 23126066861888 run_lib.py:133] step: 202000, training_loss: 1.97420e-02
I0215 16:54:46.222296 23126066861888 run_lib.py:146] step: 202000, eval_loss: 2.64485e-02
I0215 16:55:03.635906 23126066861888 run_lib.py:133] step: 202050, training_loss: 1.96531e-02
I0215 16:55:21.030929 23126066861888 run_lib.py:133] step: 202100, training_loss: 1.93572e-02
I0215 16:55:21.186404 23126066861888 run_lib.py:146] step: 202100, eval_loss: 2.63475e-02
I0215 16:55:38.723654 23126066861888 run_lib.py:133] step: 202150, training_loss: 1.93615e-02
I0215 16:55:56.049134 23126066861888 run_lib.py:133] step: 202200, training_loss: 1.91583e-02
I0215 16:55:56.201019 23126066861888 run_lib.py:146] step: 202200, eval_loss: 2.68625e-02
I0215 16:56:13.598786 23126066861888 run_lib.py:133] step: 202250, training_loss: 1.88224e-02
I0215 16:56:30.970874 23126066861888 run_lib.py:133] step: 202300, training_loss: 1.98316e-02
I0215 16:56:31.133179 23126066861888 run_lib.py:146] step: 202300, eval_loss: 2.62711e-02
I0215 16:56:48.734869 23126066861888 run_lib.py:133] step: 202350, training_loss: 1.93934e-02
I0215 16:57:06.230107 23126066861888 run_lib.py:133] step: 202400, training_loss: 1.82021e-02
I0215 16:57:06.386246 23126066861888 run_lib.py:146] step: 202400, eval_loss: 2.61412e-02
I0215 16:57:23.742480 23126066861888 run_lib.py:133] step: 202450, training_loss: 1.89600e-02
I0215 16:57:41.136002 23126066861888 run_lib.py:133] step: 202500, training_loss: 1.83784e-02
I0215 16:57:41.294556 23126066861888 run_lib.py:146] step: 202500, eval_loss: 2.76290e-02
I0215 16:57:58.815558 23126066861888 run_lib.py:133] step: 202550, training_loss: 1.89860e-02
I0215 16:58:16.204931 23126066861888 run_lib.py:133] step: 202600, training_loss: 1.84427e-02
I0215 16:58:16.366968 23126066861888 run_lib.py:146] step: 202600, eval_loss: 2.58838e-02
I0215 16:58:33.778372 23126066861888 run_lib.py:133] step: 202650, training_loss: 1.94654e-02
I0215 16:58:51.483197 23126066861888 run_lib.py:133] step: 202700, training_loss: 1.98214e-02
I0215 16:58:51.635020 23126066861888 run_lib.py:146] step: 202700, eval_loss: 2.82492e-02
I0215 16:59:09.014446 23126066861888 run_lib.py:133] step: 202750, training_loss: 1.83973e-02
I0215 16:59:26.550259 23126066861888 run_lib.py:133] step: 202800, training_loss: 2.04843e-02
I0215 16:59:26.713064 23126066861888 run_lib.py:146] step: 202800, eval_loss: 2.62920e-02
I0215 16:59:44.104120 23126066861888 run_lib.py:133] step: 202850, training_loss: 1.97573e-02
I0215 17:00:01.546988 23126066861888 run_lib.py:133] step: 202900, training_loss: 1.91614e-02
I0215 17:00:01.721164 23126066861888 run_lib.py:146] step: 202900, eval_loss: 2.64735e-02
I0215 17:00:19.305242 23126066861888 run_lib.py:133] step: 202950, training_loss: 1.84293e-02
I0215 17:00:36.699658 23126066861888 run_lib.py:133] step: 203000, training_loss: 1.88989e-02
I0215 17:00:36.854459 23126066861888 run_lib.py:146] step: 203000, eval_loss: 2.56392e-02
I0215 17:00:54.257967 23126066861888 run_lib.py:133] step: 203050, training_loss: 1.93364e-02
I0215 17:01:11.812382 23126066861888 run_lib.py:133] step: 203100, training_loss: 2.00545e-02
I0215 17:01:11.967211 23126066861888 run_lib.py:146] step: 203100, eval_loss: 2.70704e-02
I0215 17:01:29.380632 23126066861888 run_lib.py:133] step: 203150, training_loss: 1.93202e-02
I0215 17:01:46.831607 23126066861888 run_lib.py:133] step: 203200, training_loss: 1.92870e-02
I0215 17:01:46.983430 23126066861888 run_lib.py:146] step: 203200, eval_loss: 2.69025e-02
I0215 17:02:04.490400 23126066861888 run_lib.py:133] step: 203250, training_loss: 1.90215e-02
I0215 17:02:21.894428 23126066861888 run_lib.py:133] step: 203300, training_loss: 1.95337e-02
I0215 17:02:22.050206 23126066861888 run_lib.py:146] step: 203300, eval_loss: 2.66340e-02
I0215 17:02:39.438971 23126066861888 run_lib.py:133] step: 203350, training_loss: 1.88432e-02
I0215 17:02:56.792132 23126066861888 run_lib.py:133] step: 203400, training_loss: 1.86595e-02
I0215 17:02:56.961272 23126066861888 run_lib.py:146] step: 203400, eval_loss: 2.64819e-02
I0215 17:03:14.534435 23126066861888 run_lib.py:133] step: 203450, training_loss: 1.94243e-02
I0215 17:03:32.063655 23126066861888 run_lib.py:133] step: 203500, training_loss: 1.86173e-02
I0215 17:03:32.218451 23126066861888 run_lib.py:146] step: 203500, eval_loss: 2.59053e-02
I0215 17:03:49.583832 23126066861888 run_lib.py:133] step: 203550, training_loss: 1.90895e-02
I0215 17:04:06.940869 23126066861888 run_lib.py:133] step: 203600, training_loss: 1.93888e-02
I0215 17:04:07.093059 23126066861888 run_lib.py:146] step: 203600, eval_loss: 2.75580e-02
I0215 17:04:24.606454 23126066861888 run_lib.py:133] step: 203650, training_loss: 1.93361e-02
I0215 17:04:41.972074 23126066861888 run_lib.py:133] step: 203700, training_loss: 1.95259e-02
I0215 17:04:42.125220 23126066861888 run_lib.py:146] step: 203700, eval_loss: 2.64720e-02
I0215 17:04:59.589922 23126066861888 run_lib.py:133] step: 203750, training_loss: 1.92842e-02
I0215 17:05:17.178707 23126066861888 run_lib.py:133] step: 203800, training_loss: 1.85212e-02
I0215 17:05:17.332244 23126066861888 run_lib.py:146] step: 203800, eval_loss: 2.59018e-02
I0215 17:05:34.710624 23126066861888 run_lib.py:133] step: 203850, training_loss: 1.94383e-02
I0215 17:05:52.271002 23126066861888 run_lib.py:133] step: 203900, training_loss: 1.98396e-02
I0215 17:05:52.427446 23126066861888 run_lib.py:146] step: 203900, eval_loss: 2.73692e-02
I0215 17:06:09.783900 23126066861888 run_lib.py:133] step: 203950, training_loss: 1.92200e-02
I0215 17:06:27.159951 23126066861888 run_lib.py:133] step: 204000, training_loss: 1.90686e-02
I0215 17:06:27.331946 23126066861888 run_lib.py:146] step: 204000, eval_loss: 2.59473e-02
I0215 17:06:44.916878 23126066861888 run_lib.py:133] step: 204050, training_loss: 1.89023e-02
I0215 17:07:02.354662 23126066861888 run_lib.py:133] step: 204100, training_loss: 1.95385e-02
I0215 17:07:02.506705 23126066861888 run_lib.py:146] step: 204100, eval_loss: 2.68651e-02
I0215 17:07:19.900483 23126066861888 run_lib.py:133] step: 204150, training_loss: 1.86379e-02
I0215 17:07:37.509703 23126066861888 run_lib.py:133] step: 204200, training_loss: 1.99730e-02
I0215 17:07:37.661255 23126066861888 run_lib.py:146] step: 204200, eval_loss: 2.67990e-02
I0215 17:07:55.028514 23126066861888 run_lib.py:133] step: 204250, training_loss: 1.95836e-02
I0215 17:08:12.473498 23126066861888 run_lib.py:133] step: 204300, training_loss: 1.88727e-02
I0215 17:08:12.647218 23126066861888 run_lib.py:146] step: 204300, eval_loss: 2.67243e-02
I0215 17:08:30.128859 23126066861888 run_lib.py:133] step: 204350, training_loss: 1.93186e-02
I0215 17:08:47.527776 23126066861888 run_lib.py:133] step: 204400, training_loss: 1.94172e-02
I0215 17:08:47.682037 23126066861888 run_lib.py:146] step: 204400, eval_loss: 2.70334e-02
I0215 17:09:05.066759 23126066861888 run_lib.py:133] step: 204450, training_loss: 1.91679e-02
I0215 17:09:22.397308 23126066861888 run_lib.py:133] step: 204500, training_loss: 1.91965e-02
I0215 17:09:22.551069 23126066861888 run_lib.py:146] step: 204500, eval_loss: 2.64967e-02
I0215 17:09:40.131152 23126066861888 run_lib.py:133] step: 204550, training_loss: 1.87234e-02
I0215 17:09:57.619410 23126066861888 run_lib.py:133] step: 204600, training_loss: 1.84730e-02
I0215 17:09:57.772995 23126066861888 run_lib.py:146] step: 204600, eval_loss: 2.67032e-02
I0215 17:10:15.242096 23126066861888 run_lib.py:133] step: 204650, training_loss: 1.96678e-02
I0215 17:10:32.601093 23126066861888 run_lib.py:133] step: 204700, training_loss: 1.98868e-02
I0215 17:10:32.756276 23126066861888 run_lib.py:146] step: 204700, eval_loss: 2.62364e-02
I0215 17:10:50.288921 23126066861888 run_lib.py:133] step: 204750, training_loss: 1.98347e-02
I0215 17:11:07.656404 23126066861888 run_lib.py:133] step: 204800, training_loss: 1.97042e-02
I0215 17:11:07.835815 23126066861888 run_lib.py:146] step: 204800, eval_loss: 2.60417e-02
I0215 17:11:25.259863 23126066861888 run_lib.py:133] step: 204850, training_loss: 1.87557e-02
I0215 17:11:42.841594 23126066861888 run_lib.py:133] step: 204900, training_loss: 1.82160e-02
I0215 17:11:42.996292 23126066861888 run_lib.py:146] step: 204900, eval_loss: 2.68367e-02
I0215 17:12:00.394024 23126066861888 run_lib.py:133] step: 204950, training_loss: 1.93349e-02
I0215 17:12:17.955106 23126066861888 run_lib.py:133] step: 205000, training_loss: 1.96887e-02
I0215 17:12:18.114054 23126066861888 run_lib.py:146] step: 205000, eval_loss: 2.68410e-02
I0215 17:12:35.472686 23126066861888 run_lib.py:133] step: 205050, training_loss: 1.90404e-02
I0215 17:12:52.872370 23126066861888 run_lib.py:133] step: 205100, training_loss: 1.91678e-02
I0215 17:12:53.024293 23126066861888 run_lib.py:146] step: 205100, eval_loss: 2.71766e-02
I0215 17:13:10.553035 23126066861888 run_lib.py:133] step: 205150, training_loss: 1.89361e-02
I0215 17:13:27.967976 23126066861888 run_lib.py:133] step: 205200, training_loss: 1.93937e-02
I0215 17:13:28.135448 23126066861888 run_lib.py:146] step: 205200, eval_loss: 2.67046e-02
I0215 17:13:45.567206 23126066861888 run_lib.py:133] step: 205250, training_loss: 1.97047e-02
I0215 17:14:03.162476 23126066861888 run_lib.py:133] step: 205300, training_loss: 1.92488e-02
I0215 17:14:03.318319 23126066861888 run_lib.py:146] step: 205300, eval_loss: 2.70620e-02
I0215 17:14:20.681563 23126066861888 run_lib.py:133] step: 205350, training_loss: 1.93724e-02
I0215 17:14:38.084741 23126066861888 run_lib.py:133] step: 205400, training_loss: 1.89013e-02
I0215 17:14:38.236205 23126066861888 run_lib.py:146] step: 205400, eval_loss: 2.47058e-02
I0215 17:14:55.724922 23126066861888 run_lib.py:133] step: 205450, training_loss: 1.93240e-02
I0215 17:15:13.148736 23126066861888 run_lib.py:133] step: 205500, training_loss: 1.89958e-02
I0215 17:15:13.301835 23126066861888 run_lib.py:146] step: 205500, eval_loss: 2.65908e-02
I0215 17:15:30.725407 23126066861888 run_lib.py:133] step: 205550, training_loss: 1.97022e-02
I0215 17:15:48.090302 23126066861888 run_lib.py:133] step: 205600, training_loss: 1.98517e-02
I0215 17:15:48.246212 23126066861888 run_lib.py:146] step: 205600, eval_loss: 2.61631e-02
I0215 17:16:05.850397 23126066861888 run_lib.py:133] step: 205650, training_loss: 2.01190e-02
I0215 17:16:23.310519 23126066861888 run_lib.py:133] step: 205700, training_loss: 1.96381e-02
I0215 17:16:23.465792 23126066861888 run_lib.py:146] step: 205700, eval_loss: 2.70164e-02
I0215 17:16:40.901189 23126066861888 run_lib.py:133] step: 205750, training_loss: 1.93169e-02
I0215 17:16:58.308175 23126066861888 run_lib.py:133] step: 205800, training_loss: 1.88110e-02
I0215 17:16:58.464908 23126066861888 run_lib.py:146] step: 205800, eval_loss: 2.68942e-02
I0215 17:17:16.040350 23126066861888 run_lib.py:133] step: 205850, training_loss: 1.88993e-02
I0215 17:17:33.437151 23126066861888 run_lib.py:133] step: 205900, training_loss: 1.93128e-02
I0215 17:17:33.588780 23126066861888 run_lib.py:146] step: 205900, eval_loss: 2.74968e-02
I0215 17:17:50.971115 23126066861888 run_lib.py:133] step: 205950, training_loss: 1.97172e-02
I0215 17:18:08.501513 23126066861888 run_lib.py:133] step: 206000, training_loss: 1.89478e-02
I0215 17:18:08.656497 23126066861888 run_lib.py:146] step: 206000, eval_loss: 2.70560e-02
I0215 17:18:26.113968 23126066861888 run_lib.py:133] step: 206050, training_loss: 1.99535e-02
I0215 17:18:43.728607 23126066861888 run_lib.py:133] step: 206100, training_loss: 1.96857e-02
I0215 17:18:43.886065 23126066861888 run_lib.py:146] step: 206100, eval_loss: 2.67695e-02
I0215 17:19:01.262690 23126066861888 run_lib.py:133] step: 206150, training_loss: 2.00008e-02
I0215 17:19:18.660812 23126066861888 run_lib.py:133] step: 206200, training_loss: 1.97714e-02
I0215 17:19:18.817512 23126066861888 run_lib.py:146] step: 206200, eval_loss: 2.64798e-02
I0215 17:19:36.366322 23126066861888 run_lib.py:133] step: 206250, training_loss: 1.93254e-02
I0215 17:19:53.792595 23126066861888 run_lib.py:133] step: 206300, training_loss: 1.94907e-02
I0215 17:19:53.956936 23126066861888 run_lib.py:146] step: 206300, eval_loss: 2.59081e-02
I0215 17:20:11.371021 23126066861888 run_lib.py:133] step: 206350, training_loss: 1.94803e-02
I0215 17:20:29.021841 23126066861888 run_lib.py:133] step: 206400, training_loss: 1.92935e-02
I0215 17:20:29.175744 23126066861888 run_lib.py:146] step: 206400, eval_loss: 2.74014e-02
I0215 17:20:46.613958 23126066861888 run_lib.py:133] step: 206450, training_loss: 1.97952e-02
I0215 17:21:04.054015 23126066861888 run_lib.py:133] step: 206500, training_loss: 1.85826e-02
I0215 17:21:04.205209 23126066861888 run_lib.py:146] step: 206500, eval_loss: 2.76696e-02
I0215 17:21:21.678389 23126066861888 run_lib.py:133] step: 206550, training_loss: 1.83551e-02
I0215 17:21:39.117048 23126066861888 run_lib.py:133] step: 206600, training_loss: 1.89069e-02
I0215 17:21:39.268364 23126066861888 run_lib.py:146] step: 206600, eval_loss: 2.66504e-02
I0215 17:21:56.767065 23126066861888 run_lib.py:133] step: 206650, training_loss: 1.90740e-02
I0215 17:22:14.228032 23126066861888 run_lib.py:133] step: 206700, training_loss: 1.89056e-02
I0215 17:22:14.388165 23126066861888 run_lib.py:146] step: 206700, eval_loss: 2.71929e-02
I0215 17:22:32.015553 23126066861888 run_lib.py:133] step: 206750, training_loss: 1.94730e-02
I0215 17:22:49.492878 23126066861888 run_lib.py:133] step: 206800, training_loss: 1.96857e-02
I0215 17:22:49.648262 23126066861888 run_lib.py:146] step: 206800, eval_loss: 2.65138e-02
I0215 17:23:07.057391 23126066861888 run_lib.py:133] step: 206850, training_loss: 1.93312e-02
I0215 17:23:24.437823 23126066861888 run_lib.py:133] step: 206900, training_loss: 1.90178e-02
I0215 17:23:24.601801 23126066861888 run_lib.py:146] step: 206900, eval_loss: 2.62461e-02
I0215 17:23:42.164606 23126066861888 run_lib.py:133] step: 206950, training_loss: 1.94285e-02
I0215 17:23:59.667898 23126066861888 run_lib.py:133] step: 207000, training_loss: 1.95622e-02
I0215 17:23:59.818774 23126066861888 run_lib.py:146] step: 207000, eval_loss: 2.59209e-02
I0215 17:24:17.231051 23126066861888 run_lib.py:133] step: 207050, training_loss: 1.97959e-02
I0215 17:24:34.871370 23126066861888 run_lib.py:133] step: 207100, training_loss: 1.95319e-02
I0215 17:24:35.026055 23126066861888 run_lib.py:146] step: 207100, eval_loss: 2.65825e-02
I0215 17:24:52.377963 23126066861888 run_lib.py:133] step: 207150, training_loss: 1.93602e-02
I0215 17:25:09.786927 23126066861888 run_lib.py:133] step: 207200, training_loss: 1.90358e-02
I0215 17:25:09.944286 23126066861888 run_lib.py:146] step: 207200, eval_loss: 2.70488e-02
I0215 17:25:27.294700 23126066861888 run_lib.py:133] step: 207250, training_loss: 1.89586e-02
I0215 17:25:44.769619 23126066861888 run_lib.py:133] step: 207300, training_loss: 1.87907e-02
I0215 17:25:44.924377 23126066861888 run_lib.py:146] step: 207300, eval_loss: 2.68981e-02
I0215 17:26:02.486785 23126066861888 run_lib.py:133] step: 207350, training_loss: 1.94195e-02
I0215 17:26:19.879102 23126066861888 run_lib.py:133] step: 207400, training_loss: 1.96322e-02
I0215 17:26:20.033241 23126066861888 run_lib.py:146] step: 207400, eval_loss: 2.63527e-02
I0215 17:26:37.410037 23126066861888 run_lib.py:133] step: 207450, training_loss: 1.92124e-02
I0215 17:26:54.938816 23126066861888 run_lib.py:133] step: 207500, training_loss: 1.92626e-02
I0215 17:26:55.090001 23126066861888 run_lib.py:146] step: 207500, eval_loss: 2.67148e-02
I0215 17:27:12.512580 23126066861888 run_lib.py:133] step: 207550, training_loss: 1.93334e-02
I0215 17:27:29.946780 23126066861888 run_lib.py:133] step: 207600, training_loss: 1.93141e-02
I0215 17:27:30.101206 23126066861888 run_lib.py:146] step: 207600, eval_loss: 2.65854e-02
I0215 17:27:47.577901 23126066861888 run_lib.py:133] step: 207650, training_loss: 1.93965e-02
I0215 17:28:04.940343 23126066861888 run_lib.py:133] step: 207700, training_loss: 1.87082e-02
I0215 17:28:05.104259 23126066861888 run_lib.py:146] step: 207700, eval_loss: 2.64835e-02
I0215 17:28:22.515474 23126066861888 run_lib.py:133] step: 207750, training_loss: 1.87818e-02
I0215 17:28:39.874033 23126066861888 run_lib.py:133] step: 207800, training_loss: 1.93687e-02
I0215 17:28:40.037153 23126066861888 run_lib.py:146] step: 207800, eval_loss: 2.59180e-02
I0215 17:28:57.597176 23126066861888 run_lib.py:133] step: 207850, training_loss: 1.93493e-02
I0215 17:29:15.115194 23126066861888 run_lib.py:133] step: 207900, training_loss: 1.93525e-02
I0215 17:29:15.277307 23126066861888 run_lib.py:146] step: 207900, eval_loss: 2.76070e-02
I0215 17:29:32.710584 23126066861888 run_lib.py:133] step: 207950, training_loss: 1.92000e-02
I0215 17:29:50.096490 23126066861888 run_lib.py:133] step: 208000, training_loss: 1.90856e-02
I0215 17:29:50.253954 23126066861888 run_lib.py:146] step: 208000, eval_loss: 2.69372e-02
I0215 17:30:07.770349 23126066861888 run_lib.py:133] step: 208050, training_loss: 1.93014e-02
I0215 17:30:25.191708 23126066861888 run_lib.py:133] step: 208100, training_loss: 1.88798e-02
I0215 17:30:25.353140 23126066861888 run_lib.py:146] step: 208100, eval_loss: 2.71691e-02
I0215 17:30:42.766431 23126066861888 run_lib.py:133] step: 208150, training_loss: 1.98470e-02
I0215 17:31:00.335052 23126066861888 run_lib.py:133] step: 208200, training_loss: 1.94044e-02
I0215 17:31:00.491467 23126066861888 run_lib.py:146] step: 208200, eval_loss: 2.64471e-02
I0215 17:31:17.865066 23126066861888 run_lib.py:133] step: 208250, training_loss: 1.96285e-02
I0215 17:31:35.447024 23126066861888 run_lib.py:133] step: 208300, training_loss: 1.86620e-02
I0215 17:31:35.600703 23126066861888 run_lib.py:146] step: 208300, eval_loss: 2.60115e-02
I0215 17:31:52.984125 23126066861888 run_lib.py:133] step: 208350, training_loss: 1.97075e-02
I0215 17:32:10.395781 23126066861888 run_lib.py:133] step: 208400, training_loss: 1.94643e-02
I0215 17:32:10.548268 23126066861888 run_lib.py:146] step: 208400, eval_loss: 2.62659e-02
I0215 17:32:28.174734 23126066861888 run_lib.py:133] step: 208450, training_loss: 1.98649e-02
I0215 17:32:45.567463 23126066861888 run_lib.py:133] step: 208500, training_loss: 1.87611e-02
I0215 17:32:45.720247 23126066861888 run_lib.py:146] step: 208500, eval_loss: 2.67996e-02
I0215 17:33:03.095664 23126066861888 run_lib.py:133] step: 208550, training_loss: 1.85382e-02
I0215 17:33:20.681080 23126066861888 run_lib.py:133] step: 208600, training_loss: 1.98219e-02
I0215 17:33:20.841440 23126066861888 run_lib.py:146] step: 208600, eval_loss: 2.67940e-02
I0215 17:33:38.245383 23126066861888 run_lib.py:133] step: 208650, training_loss: 1.86389e-02
I0215 17:33:55.627258 23126066861888 run_lib.py:133] step: 208700, training_loss: 1.93763e-02
I0215 17:33:55.794274 23126066861888 run_lib.py:146] step: 208700, eval_loss: 2.64859e-02
I0215 17:34:13.286327 23126066861888 run_lib.py:133] step: 208750, training_loss: 1.91526e-02
I0215 17:34:30.633777 23126066861888 run_lib.py:133] step: 208800, training_loss: 1.93470e-02
I0215 17:34:30.796423 23126066861888 run_lib.py:146] step: 208800, eval_loss: 2.68311e-02
I0215 17:34:48.214323 23126066861888 run_lib.py:133] step: 208850, training_loss: 1.91499e-02
I0215 17:35:05.584013 23126066861888 run_lib.py:133] step: 208900, training_loss: 1.92885e-02
I0215 17:35:05.734081 23126066861888 run_lib.py:146] step: 208900, eval_loss: 2.63399e-02
I0215 17:35:23.348722 23126066861888 run_lib.py:133] step: 208950, training_loss: 1.97996e-02
I0215 17:35:40.817734 23126066861888 run_lib.py:133] step: 209000, training_loss: 1.84030e-02
I0215 17:35:40.983568 23126066861888 run_lib.py:146] step: 209000, eval_loss: 2.63367e-02
I0215 17:35:58.433096 23126066861888 run_lib.py:133] step: 209050, training_loss: 1.90330e-02
I0215 17:36:15.862605 23126066861888 run_lib.py:133] step: 209100, training_loss: 1.95795e-02
I0215 17:36:16.019288 23126066861888 run_lib.py:146] step: 209100, eval_loss: 2.62600e-02
I0215 17:36:33.623398 23126066861888 run_lib.py:133] step: 209150, training_loss: 1.97903e-02
I0215 17:36:51.012983 23126066861888 run_lib.py:133] step: 209200, training_loss: 1.85444e-02
I0215 17:36:51.184685 23126066861888 run_lib.py:146] step: 209200, eval_loss: 2.70680e-02
I0215 17:37:08.559322 23126066861888 run_lib.py:133] step: 209250, training_loss: 2.01014e-02
I0215 17:37:26.165399 23126066861888 run_lib.py:133] step: 209300, training_loss: 1.88261e-02
I0215 17:37:26.319281 23126066861888 run_lib.py:146] step: 209300, eval_loss: 2.76253e-02
I0215 17:37:43.802812 23126066861888 run_lib.py:133] step: 209350, training_loss: 1.95963e-02
I0215 17:38:01.384639 23126066861888 run_lib.py:133] step: 209400, training_loss: 1.90698e-02
I0215 17:38:01.537170 23126066861888 run_lib.py:146] step: 209400, eval_loss: 2.58189e-02
I0215 17:38:18.893551 23126066861888 run_lib.py:133] step: 209450, training_loss: 1.94290e-02
I0215 17:38:36.265025 23126066861888 run_lib.py:133] step: 209500, training_loss: 1.89396e-02
I0215 17:38:36.421167 23126066861888 run_lib.py:146] step: 209500, eval_loss: 2.64064e-02
I0215 17:38:53.957659 23126066861888 run_lib.py:133] step: 209550, training_loss: 1.94021e-02
I0215 17:39:11.316290 23126066861888 run_lib.py:133] step: 209600, training_loss: 1.88445e-02
I0215 17:39:11.490162 23126066861888 run_lib.py:146] step: 209600, eval_loss: 2.71657e-02
I0215 17:39:28.972025 23126066861888 run_lib.py:133] step: 209650, training_loss: 1.93558e-02
I0215 17:39:46.555199 23126066861888 run_lib.py:133] step: 209700, training_loss: 1.92053e-02
I0215 17:39:46.710237 23126066861888 run_lib.py:146] step: 209700, eval_loss: 2.69268e-02
I0215 17:40:04.150286 23126066861888 run_lib.py:133] step: 209750, training_loss: 1.97054e-02
I0215 17:40:21.564838 23126066861888 run_lib.py:133] step: 209800, training_loss: 1.91956e-02
I0215 17:40:21.717330 23126066861888 run_lib.py:146] step: 209800, eval_loss: 2.64413e-02
I0215 17:40:39.190683 23126066861888 run_lib.py:133] step: 209850, training_loss: 1.86999e-02
I0215 17:40:56.639418 23126066861888 run_lib.py:133] step: 209900, training_loss: 1.88349e-02
I0215 17:40:56.792229 23126066861888 run_lib.py:146] step: 209900, eval_loss: 2.71239e-02
I0215 17:41:14.237684 23126066861888 run_lib.py:133] step: 209950, training_loss: 1.97087e-02
I0215 17:41:31.598274 23126066861888 run_lib.py:133] step: 210000, training_loss: 1.93877e-02
I0215 17:41:35.781129 23126066861888 run_lib.py:146] step: 210000, eval_loss: 2.71919e-02
I0215 17:41:59.483513 23126066861888 run_lib.py:133] step: 210050, training_loss: 1.93694e-02
I0215 17:42:16.893585 23126066861888 run_lib.py:133] step: 210100, training_loss: 1.98855e-02
I0215 17:42:17.049608 23126066861888 run_lib.py:146] step: 210100, eval_loss: 2.76701e-02
I0215 17:42:34.500343 23126066861888 run_lib.py:133] step: 210150, training_loss: 1.95934e-02
I0215 17:42:51.935080 23126066861888 run_lib.py:133] step: 210200, training_loss: 1.94676e-02
I0215 17:42:52.090487 23126066861888 run_lib.py:146] step: 210200, eval_loss: 2.75898e-02
I0215 17:43:09.466790 23126066861888 run_lib.py:133] step: 210250, training_loss: 1.95712e-02
I0215 17:43:26.820901 23126066861888 run_lib.py:133] step: 210300, training_loss: 1.83968e-02
I0215 17:43:26.975229 23126066861888 run_lib.py:146] step: 210300, eval_loss: 2.82001e-02
I0215 17:43:44.583760 23126066861888 run_lib.py:133] step: 210350, training_loss: 1.89225e-02
I0215 17:44:02.053251 23126066861888 run_lib.py:133] step: 210400, training_loss: 1.89616e-02
I0215 17:44:02.203163 23126066861888 run_lib.py:146] step: 210400, eval_loss: 2.69322e-02
I0215 17:44:19.615189 23126066861888 run_lib.py:133] step: 210450, training_loss: 1.88993e-02
I0215 17:44:37.001047 23126066861888 run_lib.py:133] step: 210500, training_loss: 1.86050e-02
I0215 17:44:37.165308 23126066861888 run_lib.py:146] step: 210500, eval_loss: 2.68186e-02
I0215 17:44:54.788137 23126066861888 run_lib.py:133] step: 210550, training_loss: 1.97299e-02
I0215 17:45:12.163185 23126066861888 run_lib.py:133] step: 210600, training_loss: 1.96973e-02
I0215 17:45:12.328418 23126066861888 run_lib.py:146] step: 210600, eval_loss: 2.67382e-02
I0215 17:45:29.707794 23126066861888 run_lib.py:133] step: 210650, training_loss: 1.95930e-02
I0215 17:45:47.215075 23126066861888 run_lib.py:133] step: 210700, training_loss: 1.91883e-02
I0215 17:45:47.506210 23126066861888 run_lib.py:146] step: 210700, eval_loss: 2.72766e-02
I0215 17:46:04.909072 23126066861888 run_lib.py:133] step: 210750, training_loss: 1.88110e-02
I0215 17:46:22.502484 23126066861888 run_lib.py:133] step: 210800, training_loss: 1.92105e-02
I0215 17:46:22.657265 23126066861888 run_lib.py:146] step: 210800, eval_loss: 2.80598e-02
I0215 17:46:40.088602 23126066861888 run_lib.py:133] step: 210850, training_loss: 1.87918e-02
I0215 17:46:57.511211 23126066861888 run_lib.py:133] step: 210900, training_loss: 1.93506e-02
I0215 17:46:57.667048 23126066861888 run_lib.py:146] step: 210900, eval_loss: 2.72558e-02
I0215 17:47:15.247599 23126066861888 run_lib.py:133] step: 210950, training_loss: 1.90308e-02
I0215 17:47:32.666620 23126066861888 run_lib.py:133] step: 211000, training_loss: 1.86502e-02
I0215 17:47:32.821463 23126066861888 run_lib.py:146] step: 211000, eval_loss: 2.65894e-02
I0215 17:47:50.257861 23126066861888 run_lib.py:133] step: 211050, training_loss: 1.98262e-02
I0215 17:48:07.951241 23126066861888 run_lib.py:133] step: 211100, training_loss: 1.89035e-02
I0215 17:48:08.107975 23126066861888 run_lib.py:146] step: 211100, eval_loss: 2.63674e-02
I0215 17:48:25.470552 23126066861888 run_lib.py:133] step: 211150, training_loss: 1.94020e-02
I0215 17:48:42.831671 23126066861888 run_lib.py:133] step: 211200, training_loss: 1.87134e-02
I0215 17:48:42.986057 23126066861888 run_lib.py:146] step: 211200, eval_loss: 2.57262e-02
I0215 17:49:00.468530 23126066861888 run_lib.py:133] step: 211250, training_loss: 1.91544e-02
I0215 17:49:17.867484 23126066861888 run_lib.py:133] step: 211300, training_loss: 1.86032e-02
I0215 17:49:18.020929 23126066861888 run_lib.py:146] step: 211300, eval_loss: 2.72759e-02
I0215 17:49:35.474350 23126066861888 run_lib.py:133] step: 211350, training_loss: 1.89970e-02
I0215 17:49:52.861888 23126066861888 run_lib.py:133] step: 211400, training_loss: 1.89002e-02
I0215 17:49:53.015271 23126066861888 run_lib.py:146] step: 211400, eval_loss: 2.81649e-02
I0215 17:50:10.589192 23126066861888 run_lib.py:133] step: 211450, training_loss: 1.93910e-02
I0215 17:50:28.075756 23126066861888 run_lib.py:133] step: 211500, training_loss: 1.92937e-02
I0215 17:50:28.232687 23126066861888 run_lib.py:146] step: 211500, eval_loss: 2.65752e-02
I0215 17:50:45.611604 23126066861888 run_lib.py:133] step: 211550, training_loss: 1.84522e-02
I0215 17:51:03.052046 23126066861888 run_lib.py:133] step: 211600, training_loss: 1.92337e-02
I0215 17:51:03.205989 23126066861888 run_lib.py:146] step: 211600, eval_loss: 2.63959e-02
I0215 17:51:20.720858 23126066861888 run_lib.py:133] step: 211650, training_loss: 1.90528e-02
I0215 17:51:38.185034 23126066861888 run_lib.py:133] step: 211700, training_loss: 1.99899e-02
I0215 17:51:38.336003 23126066861888 run_lib.py:146] step: 211700, eval_loss: 2.55151e-02
I0215 17:51:55.754362 23126066861888 run_lib.py:133] step: 211750, training_loss: 1.96902e-02
I0215 17:52:13.324649 23126066861888 run_lib.py:133] step: 211800, training_loss: 1.92927e-02
I0215 17:52:13.477080 23126066861888 run_lib.py:146] step: 211800, eval_loss: 2.68004e-02
I0215 17:52:30.868270 23126066861888 run_lib.py:133] step: 211850, training_loss: 1.87201e-02
I0215 17:52:48.434269 23126066861888 run_lib.py:133] step: 211900, training_loss: 1.84888e-02
I0215 17:52:48.588474 23126066861888 run_lib.py:146] step: 211900, eval_loss: 2.72834e-02
I0215 17:53:06.018851 23126066861888 run_lib.py:133] step: 211950, training_loss: 1.92694e-02
I0215 17:53:23.439737 23126066861888 run_lib.py:133] step: 212000, training_loss: 1.95823e-02
I0215 17:53:23.601165 23126066861888 run_lib.py:146] step: 212000, eval_loss: 2.69115e-02
I0215 17:53:41.263932 23126066861888 run_lib.py:133] step: 212050, training_loss: 1.87355e-02
I0215 17:53:58.754907 23126066861888 run_lib.py:133] step: 212100, training_loss: 1.99877e-02
I0215 17:53:58.905325 23126066861888 run_lib.py:146] step: 212100, eval_loss: 2.62956e-02
I0215 17:54:16.369770 23126066861888 run_lib.py:133] step: 212150, training_loss: 1.90017e-02
I0215 17:54:34.008601 23126066861888 run_lib.py:133] step: 212200, training_loss: 1.93870e-02
I0215 17:54:34.160767 23126066861888 run_lib.py:146] step: 212200, eval_loss: 2.67561e-02
I0215 17:54:51.598591 23126066861888 run_lib.py:133] step: 212250, training_loss: 2.02285e-02
I0215 17:55:08.993366 23126066861888 run_lib.py:133] step: 212300, training_loss: 1.95359e-02
I0215 17:55:09.144067 23126066861888 run_lib.py:146] step: 212300, eval_loss: 2.63350e-02
I0215 17:55:26.689092 23126066861888 run_lib.py:133] step: 212350, training_loss: 1.90250e-02
I0215 17:55:44.069282 23126066861888 run_lib.py:133] step: 212400, training_loss: 1.83968e-02
I0215 17:55:44.223095 23126066861888 run_lib.py:146] step: 212400, eval_loss: 2.77012e-02
I0215 17:56:01.652271 23126066861888 run_lib.py:133] step: 212450, training_loss: 1.96498e-02
I0215 17:56:19.053124 23126066861888 run_lib.py:133] step: 212500, training_loss: 1.89032e-02
I0215 17:56:19.226076 23126066861888 run_lib.py:146] step: 212500, eval_loss: 2.69542e-02
I0215 17:56:36.821462 23126066861888 run_lib.py:133] step: 212550, training_loss: 1.96744e-02
I0215 17:56:54.321327 23126066861888 run_lib.py:133] step: 212600, training_loss: 1.89917e-02
I0215 17:56:54.476538 23126066861888 run_lib.py:146] step: 212600, eval_loss: 2.68463e-02
I0215 17:57:11.962919 23126066861888 run_lib.py:133] step: 212650, training_loss: 1.90038e-02
I0215 17:57:29.355204 23126066861888 run_lib.py:133] step: 212700, training_loss: 2.01962e-02
I0215 17:57:29.508012 23126066861888 run_lib.py:146] step: 212700, eval_loss: 2.65834e-02
I0215 17:57:47.062541 23126066861888 run_lib.py:133] step: 212750, training_loss: 1.87914e-02
I0215 17:58:04.486274 23126066861888 run_lib.py:133] step: 212800, training_loss: 1.90754e-02
I0215 17:58:04.639444 23126066861888 run_lib.py:146] step: 212800, eval_loss: 2.62725e-02
I0215 17:58:22.055711 23126066861888 run_lib.py:133] step: 212850, training_loss: 1.90678e-02
I0215 17:58:39.609354 23126066861888 run_lib.py:133] step: 212900, training_loss: 1.94739e-02
I0215 17:58:39.766265 23126066861888 run_lib.py:146] step: 212900, eval_loss: 2.67275e-02
I0215 17:58:57.162994 23126066861888 run_lib.py:133] step: 212950, training_loss: 1.98356e-02
I0215 17:59:14.709537 23126066861888 run_lib.py:133] step: 213000, training_loss: 1.97774e-02
I0215 17:59:14.864242 23126066861888 run_lib.py:146] step: 213000, eval_loss: 2.68418e-02
I0215 17:59:32.264674 23126066861888 run_lib.py:133] step: 213050, training_loss: 1.92721e-02
I0215 17:59:49.711858 23126066861888 run_lib.py:133] step: 213100, training_loss: 1.89948e-02
I0215 17:59:49.867990 23126066861888 run_lib.py:146] step: 213100, eval_loss: 2.59731e-02
I0215 18:00:07.497229 23126066861888 run_lib.py:133] step: 213150, training_loss: 1.85860e-02
I0215 18:00:24.908406 23126066861888 run_lib.py:133] step: 213200, training_loss: 2.00618e-02
I0215 18:00:25.062006 23126066861888 run_lib.py:146] step: 213200, eval_loss: 2.64626e-02
I0215 18:00:42.438998 23126066861888 run_lib.py:133] step: 213250, training_loss: 1.90083e-02
I0215 18:00:59.958376 23126066861888 run_lib.py:133] step: 213300, training_loss: 1.98892e-02
I0215 18:01:00.111326 23126066861888 run_lib.py:146] step: 213300, eval_loss: 2.69565e-02
I0215 18:01:17.500121 23126066861888 run_lib.py:133] step: 213350, training_loss: 1.93400e-02
I0215 18:01:34.865680 23126066861888 run_lib.py:133] step: 213400, training_loss: 1.85257e-02
I0215 18:01:35.039216 23126066861888 run_lib.py:146] step: 213400, eval_loss: 2.59705e-02
I0215 18:01:52.567808 23126066861888 run_lib.py:133] step: 213450, training_loss: 2.07386e-02
I0215 18:02:09.950114 23126066861888 run_lib.py:133] step: 213500, training_loss: 1.87581e-02
I0215 18:02:10.101931 23126066861888 run_lib.py:146] step: 213500, eval_loss: 2.68066e-02
I0215 18:02:27.520918 23126066861888 run_lib.py:133] step: 213550, training_loss: 1.89741e-02
I0215 18:02:44.867752 23126066861888 run_lib.py:133] step: 213600, training_loss: 1.90491e-02
I0215 18:02:45.021314 23126066861888 run_lib.py:146] step: 213600, eval_loss: 2.60103e-02
I0215 18:03:02.814956 23126066861888 run_lib.py:133] step: 213650, training_loss: 1.94633e-02
I0215 18:03:20.307854 23126066861888 run_lib.py:133] step: 213700, training_loss: 1.95633e-02
I0215 18:03:20.483978 23126066861888 run_lib.py:146] step: 213700, eval_loss: 2.71135e-02
I0215 18:03:37.940719 23126066861888 run_lib.py:133] step: 213750, training_loss: 1.91365e-02
I0215 18:03:55.393916 23126066861888 run_lib.py:133] step: 213800, training_loss: 1.88256e-02
I0215 18:03:55.549098 23126066861888 run_lib.py:146] step: 213800, eval_loss: 2.77823e-02
I0215 18:04:13.156222 23126066861888 run_lib.py:133] step: 213850, training_loss: 1.83412e-02
I0215 18:04:30.580558 23126066861888 run_lib.py:133] step: 213900, training_loss: 1.90072e-02
I0215 18:04:30.733349 23126066861888 run_lib.py:146] step: 213900, eval_loss: 2.70617e-02
I0215 18:04:48.097187 23126066861888 run_lib.py:133] step: 213950, training_loss: 1.92844e-02
I0215 18:05:05.727457 23126066861888 run_lib.py:133] step: 214000, training_loss: 1.90040e-02
I0215 18:05:05.882525 23126066861888 run_lib.py:146] step: 214000, eval_loss: 2.66092e-02
I0215 18:05:23.291283 23126066861888 run_lib.py:133] step: 214050, training_loss: 1.90265e-02
I0215 18:05:40.843119 23126066861888 run_lib.py:133] step: 214100, training_loss: 1.92270e-02
I0215 18:05:40.996906 23126066861888 run_lib.py:146] step: 214100, eval_loss: 2.68184e-02
I0215 18:05:58.376419 23126066861888 run_lib.py:133] step: 214150, training_loss: 1.85862e-02
I0215 18:06:15.765276 23126066861888 run_lib.py:133] step: 214200, training_loss: 1.87460e-02
I0215 18:06:15.916096 23126066861888 run_lib.py:146] step: 214200, eval_loss: 2.77291e-02
I0215 18:06:33.472179 23126066861888 run_lib.py:133] step: 214250, training_loss: 1.99232e-02
I0215 18:06:50.872349 23126066861888 run_lib.py:133] step: 214300, training_loss: 1.87607e-02
I0215 18:06:51.041426 23126066861888 run_lib.py:146] step: 214300, eval_loss: 2.67712e-02
I0215 18:07:08.444912 23126066861888 run_lib.py:133] step: 214350, training_loss: 1.85059e-02
I0215 18:07:26.036603 23126066861888 run_lib.py:133] step: 214400, training_loss: 1.86293e-02
I0215 18:07:26.189333 23126066861888 run_lib.py:146] step: 214400, eval_loss: 2.69734e-02
I0215 18:07:43.574745 23126066861888 run_lib.py:133] step: 214450, training_loss: 1.91089e-02
I0215 18:08:01.010876 23126066861888 run_lib.py:133] step: 214500, training_loss: 1.86989e-02
I0215 18:08:01.169301 23126066861888 run_lib.py:146] step: 214500, eval_loss: 2.68379e-02
I0215 18:08:18.623720 23126066861888 run_lib.py:133] step: 214550, training_loss: 1.85408e-02
I0215 18:08:36.130429 23126066861888 run_lib.py:133] step: 214600, training_loss: 1.95984e-02
I0215 18:08:36.286245 23126066861888 run_lib.py:146] step: 214600, eval_loss: 2.60428e-02
I0215 18:08:53.686534 23126066861888 run_lib.py:133] step: 214650, training_loss: 1.82823e-02
I0215 18:09:11.051173 23126066861888 run_lib.py:133] step: 214700, training_loss: 1.96150e-02
I0215 18:09:11.201989 23126066861888 run_lib.py:146] step: 214700, eval_loss: 2.64620e-02
I0215 18:09:28.755624 23126066861888 run_lib.py:133] step: 214750, training_loss: 1.95506e-02
I0215 18:09:46.212631 23126066861888 run_lib.py:133] step: 214800, training_loss: 1.83652e-02
I0215 18:09:46.371467 23126066861888 run_lib.py:146] step: 214800, eval_loss: 2.68897e-02
I0215 18:10:03.833436 23126066861888 run_lib.py:133] step: 214850, training_loss: 1.84719e-02
I0215 18:10:21.284259 23126066861888 run_lib.py:133] step: 214900, training_loss: 1.91449e-02
I0215 18:10:21.441249 23126066861888 run_lib.py:146] step: 214900, eval_loss: 2.75175e-02
I0215 18:10:39.016240 23126066861888 run_lib.py:133] step: 214950, training_loss: 1.94841e-02
I0215 18:10:56.430586 23126066861888 run_lib.py:133] step: 215000, training_loss: 1.76612e-02
I0215 18:10:56.583849 23126066861888 run_lib.py:146] step: 215000, eval_loss: 2.70315e-02
I0215 18:11:13.948039 23126066861888 run_lib.py:133] step: 215050, training_loss: 1.86908e-02
I0215 18:11:31.480170 23126066861888 run_lib.py:133] step: 215100, training_loss: 1.93903e-02
I0215 18:11:31.787938 23126066861888 run_lib.py:146] step: 215100, eval_loss: 2.71103e-02
I0215 18:11:49.234321 23126066861888 run_lib.py:133] step: 215150, training_loss: 1.93370e-02
I0215 18:12:06.853191 23126066861888 run_lib.py:133] step: 215200, training_loss: 1.92315e-02
I0215 18:12:07.005523 23126066861888 run_lib.py:146] step: 215200, eval_loss: 2.73299e-02
I0215 18:12:24.367462 23126066861888 run_lib.py:133] step: 215250, training_loss: 1.95446e-02
I0215 18:12:41.754881 23126066861888 run_lib.py:133] step: 215300, training_loss: 1.86503e-02
I0215 18:12:41.940403 23126066861888 run_lib.py:146] step: 215300, eval_loss: 2.72182e-02
I0215 18:12:59.472302 23126066861888 run_lib.py:133] step: 215350, training_loss: 1.93669e-02
I0215 18:13:16.875004 23126066861888 run_lib.py:133] step: 215400, training_loss: 1.94598e-02
I0215 18:13:17.042026 23126066861888 run_lib.py:146] step: 215400, eval_loss: 2.68411e-02
I0215 18:13:34.474408 23126066861888 run_lib.py:133] step: 215450, training_loss: 1.87661e-02
I0215 18:13:52.030390 23126066861888 run_lib.py:133] step: 215500, training_loss: 1.92299e-02
I0215 18:13:52.188478 23126066861888 run_lib.py:146] step: 215500, eval_loss: 2.65324e-02
I0215 18:14:09.614719 23126066861888 run_lib.py:133] step: 215550, training_loss: 1.88186e-02
I0215 18:14:27.015150 23126066861888 run_lib.py:133] step: 215600, training_loss: 1.91290e-02
I0215 18:14:27.166100 23126066861888 run_lib.py:146] step: 215600, eval_loss: 2.69039e-02
I0215 18:14:44.593891 23126066861888 run_lib.py:133] step: 215650, training_loss: 1.98105e-02
I0215 18:15:01.992913 23126066861888 run_lib.py:133] step: 215700, training_loss: 1.92688e-02
I0215 18:15:02.155729 23126066861888 run_lib.py:146] step: 215700, eval_loss: 2.66424e-02
I0215 18:15:19.560507 23126066861888 run_lib.py:133] step: 215750, training_loss: 1.94133e-02
I0215 18:15:36.998044 23126066861888 run_lib.py:133] step: 215800, training_loss: 1.94980e-02
I0215 18:15:37.154038 23126066861888 run_lib.py:146] step: 215800, eval_loss: 2.73409e-02
I0215 18:15:54.688392 23126066861888 run_lib.py:133] step: 215850, training_loss: 1.94960e-02
I0215 18:16:12.126343 23126066861888 run_lib.py:133] step: 215900, training_loss: 1.93940e-02
I0215 18:16:12.279991 23126066861888 run_lib.py:146] step: 215900, eval_loss: 2.66607e-02
I0215 18:16:29.646384 23126066861888 run_lib.py:133] step: 215950, training_loss: 1.90813e-02
I0215 18:16:47.094687 23126066861888 run_lib.py:133] step: 216000, training_loss: 1.89623e-02
I0215 18:16:47.248619 23126066861888 run_lib.py:146] step: 216000, eval_loss: 2.65992e-02
I0215 18:17:04.869487 23126066861888 run_lib.py:133] step: 216050, training_loss: 1.92747e-02
I0215 18:17:22.261557 23126066861888 run_lib.py:133] step: 216100, training_loss: 1.91318e-02
I0215 18:17:22.412162 23126066861888 run_lib.py:146] step: 216100, eval_loss: 2.60612e-02
I0215 18:17:39.777265 23126066861888 run_lib.py:133] step: 216150, training_loss: 1.95608e-02
I0215 18:17:57.394653 23126066861888 run_lib.py:133] step: 216200, training_loss: 1.91173e-02
I0215 18:17:57.549049 23126066861888 run_lib.py:146] step: 216200, eval_loss: 2.73574e-02
I0215 18:18:14.932960 23126066861888 run_lib.py:133] step: 216250, training_loss: 1.87449e-02
I0215 18:18:32.472105 23126066861888 run_lib.py:133] step: 216300, training_loss: 1.92564e-02
I0215 18:18:32.646101 23126066861888 run_lib.py:146] step: 216300, eval_loss: 2.69801e-02
I0215 18:18:50.078152 23126066861888 run_lib.py:133] step: 216350, training_loss: 1.91538e-02
I0215 18:19:07.513680 23126066861888 run_lib.py:133] step: 216400, training_loss: 1.88172e-02
I0215 18:19:07.667361 23126066861888 run_lib.py:146] step: 216400, eval_loss: 2.61770e-02
I0215 18:19:25.263491 23126066861888 run_lib.py:133] step: 216450, training_loss: 1.87517e-02
I0215 18:19:42.657179 23126066861888 run_lib.py:133] step: 216500, training_loss: 1.93051e-02
I0215 18:19:42.815247 23126066861888 run_lib.py:146] step: 216500, eval_loss: 2.66189e-02
I0215 18:20:00.229567 23126066861888 run_lib.py:133] step: 216550, training_loss: 1.97441e-02
I0215 18:20:17.891793 23126066861888 run_lib.py:133] step: 216600, training_loss: 1.93360e-02
I0215 18:20:18.045239 23126066861888 run_lib.py:146] step: 216600, eval_loss: 2.74356e-02
I0215 18:20:35.499336 23126066861888 run_lib.py:133] step: 216650, training_loss: 1.90778e-02
I0215 18:20:52.887957 23126066861888 run_lib.py:133] step: 216700, training_loss: 1.99689e-02
I0215 18:20:53.044996 23126066861888 run_lib.py:146] step: 216700, eval_loss: 2.63417e-02
I0215 18:21:10.530396 23126066861888 run_lib.py:133] step: 216750, training_loss: 1.91072e-02
I0215 18:21:27.960454 23126066861888 run_lib.py:133] step: 216800, training_loss: 1.91941e-02
I0215 18:21:28.116532 23126066861888 run_lib.py:146] step: 216800, eval_loss: 2.64174e-02
I0215 18:21:45.514227 23126066861888 run_lib.py:133] step: 216850, training_loss: 1.91512e-02
I0215 18:22:02.943433 23126066861888 run_lib.py:133] step: 216900, training_loss: 1.93464e-02
I0215 18:22:03.125564 23126066861888 run_lib.py:146] step: 216900, eval_loss: 2.68424e-02
I0215 18:22:20.719079 23126066861888 run_lib.py:133] step: 216950, training_loss: 1.89579e-02
I0215 18:22:38.233424 23126066861888 run_lib.py:133] step: 217000, training_loss: 1.91566e-02
I0215 18:22:38.383874 23126066861888 run_lib.py:146] step: 217000, eval_loss: 2.52976e-02
I0215 18:22:55.724238 23126066861888 run_lib.py:133] step: 217050, training_loss: 1.94942e-02
I0215 18:23:13.136572 23126066861888 run_lib.py:133] step: 217100, training_loss: 1.88997e-02
I0215 18:23:13.288947 23126066861888 run_lib.py:146] step: 217100, eval_loss: 2.64415e-02
I0215 18:23:30.857632 23126066861888 run_lib.py:133] step: 217150, training_loss: 1.99096e-02
I0215 18:23:48.275850 23126066861888 run_lib.py:133] step: 217200, training_loss: 1.90543e-02
I0215 18:23:48.436245 23126066861888 run_lib.py:146] step: 217200, eval_loss: 2.71450e-02
I0215 18:24:05.845635 23126066861888 run_lib.py:133] step: 217250, training_loss: 1.96013e-02
I0215 18:24:23.424731 23126066861888 run_lib.py:133] step: 217300, training_loss: 1.90684e-02
I0215 18:24:23.579162 23126066861888 run_lib.py:146] step: 217300, eval_loss: 2.75169e-02
I0215 18:24:41.010183 23126066861888 run_lib.py:133] step: 217350, training_loss: 1.88456e-02
I0215 18:24:58.525232 23126066861888 run_lib.py:133] step: 217400, training_loss: 1.85653e-02
I0215 18:24:58.679250 23126066861888 run_lib.py:146] step: 217400, eval_loss: 2.63987e-02
I0215 18:25:16.048100 23126066861888 run_lib.py:133] step: 217450, training_loss: 1.90391e-02
I0215 18:25:33.497600 23126066861888 run_lib.py:133] step: 217500, training_loss: 1.90883e-02
I0215 18:25:33.649268 23126066861888 run_lib.py:146] step: 217500, eval_loss: 2.63597e-02
I0215 18:25:51.281809 23126066861888 run_lib.py:133] step: 217550, training_loss: 1.93600e-02
I0215 18:26:08.672942 23126066861888 run_lib.py:133] step: 217600, training_loss: 1.88619e-02
I0215 18:26:08.827250 23126066861888 run_lib.py:146] step: 217600, eval_loss: 2.62107e-02
I0215 18:26:26.182559 23126066861888 run_lib.py:133] step: 217650, training_loss: 1.97410e-02
I0215 18:26:43.710227 23126066861888 run_lib.py:133] step: 217700, training_loss: 1.96176e-02
I0215 18:26:43.864030 23126066861888 run_lib.py:146] step: 217700, eval_loss: 2.75188e-02
I0215 18:27:01.310309 23126066861888 run_lib.py:133] step: 217750, training_loss: 1.91256e-02
I0215 18:27:18.741615 23126066861888 run_lib.py:133] step: 217800, training_loss: 1.90548e-02
I0215 18:27:18.897207 23126066861888 run_lib.py:146] step: 217800, eval_loss: 2.86120e-02
I0215 18:27:36.415247 23126066861888 run_lib.py:133] step: 217850, training_loss: 1.86031e-02
I0215 18:27:53.817488 23126066861888 run_lib.py:133] step: 217900, training_loss: 1.94768e-02
I0215 18:27:53.970901 23126066861888 run_lib.py:146] step: 217900, eval_loss: 2.67688e-02
I0215 18:28:11.396711 23126066861888 run_lib.py:133] step: 217950, training_loss: 1.91222e-02
I0215 18:28:28.782634 23126066861888 run_lib.py:133] step: 218000, training_loss: 1.95272e-02
I0215 18:28:28.937095 23126066861888 run_lib.py:146] step: 218000, eval_loss: 2.59043e-02
I0215 18:28:46.466935 23126066861888 run_lib.py:133] step: 218050, training_loss: 1.89117e-02
I0215 18:29:03.992886 23126066861888 run_lib.py:133] step: 218100, training_loss: 1.87325e-02
I0215 18:29:04.166269 23126066861888 run_lib.py:146] step: 218100, eval_loss: 2.64163e-02
I0215 18:29:21.612995 23126066861888 run_lib.py:133] step: 218150, training_loss: 1.92701e-02
I0215 18:29:39.078658 23126066861888 run_lib.py:133] step: 218200, training_loss: 1.93101e-02
I0215 18:29:39.234361 23126066861888 run_lib.py:146] step: 218200, eval_loss: 2.71723e-02
I0215 18:29:56.801987 23126066861888 run_lib.py:133] step: 218250, training_loss: 1.92581e-02
I0215 18:30:14.147583 23126066861888 run_lib.py:133] step: 218300, training_loss: 1.94633e-02
I0215 18:30:14.300200 23126066861888 run_lib.py:146] step: 218300, eval_loss: 2.67766e-02
I0215 18:30:31.719053 23126066861888 run_lib.py:133] step: 218350, training_loss: 1.89777e-02
I0215 18:30:49.287525 23126066861888 run_lib.py:133] step: 218400, training_loss: 1.89794e-02
I0215 18:30:49.446520 23126066861888 run_lib.py:146] step: 218400, eval_loss: 2.71159e-02
I0215 18:31:06.889589 23126066861888 run_lib.py:133] step: 218450, training_loss: 1.91547e-02
I0215 18:31:24.461288 23126066861888 run_lib.py:133] step: 218500, training_loss: 1.86553e-02
I0215 18:31:24.671073 23126066861888 run_lib.py:146] step: 218500, eval_loss: 2.68479e-02
I0215 18:31:42.051689 23126066861888 run_lib.py:133] step: 218550, training_loss: 1.89835e-02
I0215 18:31:59.461881 23126066861888 run_lib.py:133] step: 218600, training_loss: 1.94808e-02
I0215 18:31:59.635012 23126066861888 run_lib.py:146] step: 218600, eval_loss: 2.68138e-02
I0215 18:32:17.201026 23126066861888 run_lib.py:133] step: 218650, training_loss: 1.89360e-02
I0215 18:32:34.653619 23126066861888 run_lib.py:133] step: 218700, training_loss: 1.86200e-02
I0215 18:32:34.807191 23126066861888 run_lib.py:146] step: 218700, eval_loss: 2.68436e-02
I0215 18:32:52.159956 23126066861888 run_lib.py:133] step: 218750, training_loss: 1.87771e-02
I0215 18:33:09.714407 23126066861888 run_lib.py:133] step: 218800, training_loss: 1.87966e-02
I0215 18:33:09.870076 23126066861888 run_lib.py:146] step: 218800, eval_loss: 2.71993e-02
I0215 18:33:27.257641 23126066861888 run_lib.py:133] step: 218850, training_loss: 2.00452e-02
I0215 18:33:44.654914 23126066861888 run_lib.py:133] step: 218900, training_loss: 1.88223e-02
I0215 18:33:44.815174 23126066861888 run_lib.py:146] step: 218900, eval_loss: 2.80700e-02
I0215 18:34:02.363436 23126066861888 run_lib.py:133] step: 218950, training_loss: 1.87961e-02
I0215 18:34:19.731507 23126066861888 run_lib.py:133] step: 219000, training_loss: 1.85176e-02
I0215 18:34:19.886029 23126066861888 run_lib.py:146] step: 219000, eval_loss: 2.65551e-02
I0215 18:34:37.267818 23126066861888 run_lib.py:133] step: 219050, training_loss: 1.92323e-02
I0215 18:34:54.722399 23126066861888 run_lib.py:133] step: 219100, training_loss: 1.89763e-02
I0215 18:34:54.879516 23126066861888 run_lib.py:146] step: 219100, eval_loss: 2.62346e-02
I0215 18:35:12.440296 23126066861888 run_lib.py:133] step: 219150, training_loss: 1.79821e-02
I0215 18:35:29.868041 23126066861888 run_lib.py:133] step: 219200, training_loss: 1.93504e-02
I0215 18:35:30.031323 23126066861888 run_lib.py:146] step: 219200, eval_loss: 2.72291e-02
I0215 18:35:47.446410 23126066861888 run_lib.py:133] step: 219250, training_loss: 1.91256e-02
I0215 18:36:04.861376 23126066861888 run_lib.py:133] step: 219300, training_loss: 1.93595e-02
I0215 18:36:05.015119 23126066861888 run_lib.py:146] step: 219300, eval_loss: 2.67680e-02
I0215 18:36:22.639391 23126066861888 run_lib.py:133] step: 219350, training_loss: 1.88362e-02
I0215 18:36:40.007566 23126066861888 run_lib.py:133] step: 219400, training_loss: 1.83961e-02
I0215 18:36:40.157822 23126066861888 run_lib.py:146] step: 219400, eval_loss: 2.64284e-02
I0215 18:36:57.518550 23126066861888 run_lib.py:133] step: 219450, training_loss: 1.87065e-02
I0215 18:37:15.081155 23126066861888 run_lib.py:133] step: 219500, training_loss: 1.91161e-02
I0215 18:37:15.247473 23126066861888 run_lib.py:146] step: 219500, eval_loss: 2.73395e-02
I0215 18:37:32.675699 23126066861888 run_lib.py:133] step: 219550, training_loss: 2.02834e-02
I0215 18:37:50.225652 23126066861888 run_lib.py:133] step: 219600, training_loss: 1.86793e-02
I0215 18:37:50.381309 23126066861888 run_lib.py:146] step: 219600, eval_loss: 2.70000e-02
I0215 18:38:07.765885 23126066861888 run_lib.py:133] step: 219650, training_loss: 1.90248e-02
I0215 18:38:25.159968 23126066861888 run_lib.py:133] step: 219700, training_loss: 1.88324e-02
I0215 18:38:25.314252 23126066861888 run_lib.py:146] step: 219700, eval_loss: 2.65807e-02
I0215 18:38:42.881375 23126066861888 run_lib.py:133] step: 219750, training_loss: 1.87931e-02
I0215 18:39:00.308092 23126066861888 run_lib.py:133] step: 219800, training_loss: 1.86374e-02
I0215 18:39:00.462319 23126066861888 run_lib.py:146] step: 219800, eval_loss: 2.66756e-02
I0215 18:39:17.892634 23126066861888 run_lib.py:133] step: 219850, training_loss: 1.92811e-02
I0215 18:39:35.471124 23126066861888 run_lib.py:133] step: 219900, training_loss: 1.88678e-02
I0215 18:39:35.629297 23126066861888 run_lib.py:146] step: 219900, eval_loss: 2.65775e-02
I0215 18:39:53.001498 23126066861888 run_lib.py:133] step: 219950, training_loss: 1.80584e-02
I0215 18:40:10.404342 23126066861888 run_lib.py:133] step: 220000, training_loss: 1.95347e-02
I0215 18:40:11.841444 23126066861888 run_lib.py:146] step: 220000, eval_loss: 2.69079e-02
I0215 18:40:34.184992 23126066861888 run_lib.py:133] step: 220050, training_loss: 1.86002e-02
I0215 18:40:51.853122 23126066861888 run_lib.py:133] step: 220100, training_loss: 1.90741e-02
I0215 18:40:52.021875 23126066861888 run_lib.py:146] step: 220100, eval_loss: 2.67323e-02
I0215 18:41:09.377774 23126066861888 run_lib.py:133] step: 220150, training_loss: 1.90347e-02
I0215 18:41:26.725463 23126066861888 run_lib.py:133] step: 220200, training_loss: 1.88052e-02
I0215 18:41:26.879092 23126066861888 run_lib.py:146] step: 220200, eval_loss: 2.67608e-02
I0215 18:41:44.308073 23126066861888 run_lib.py:133] step: 220250, training_loss: 1.86581e-02
I0215 18:42:01.851911 23126066861888 run_lib.py:133] step: 220300, training_loss: 1.83172e-02
I0215 18:42:02.011287 23126066861888 run_lib.py:146] step: 220300, eval_loss: 2.58981e-02
I0215 18:42:19.456390 23126066861888 run_lib.py:133] step: 220350, training_loss: 1.88675e-02
I0215 18:42:36.874242 23126066861888 run_lib.py:133] step: 220400, training_loss: 1.85105e-02
I0215 18:42:37.026542 23126066861888 run_lib.py:146] step: 220400, eval_loss: 2.70259e-02
I0215 18:42:54.632607 23126066861888 run_lib.py:133] step: 220450, training_loss: 1.93332e-02
I0215 18:43:12.008590 23126066861888 run_lib.py:133] step: 220500, training_loss: 1.92631e-02
I0215 18:43:12.162059 23126066861888 run_lib.py:146] step: 220500, eval_loss: 2.80714e-02
I0215 18:43:29.585487 23126066861888 run_lib.py:133] step: 220550, training_loss: 1.92136e-02
I0215 18:43:46.976093 23126066861888 run_lib.py:133] step: 220600, training_loss: 1.92222e-02
I0215 18:43:47.149063 23126066861888 run_lib.py:146] step: 220600, eval_loss: 2.65050e-02
I0215 18:44:04.590367 23126066861888 run_lib.py:133] step: 220650, training_loss: 1.92807e-02
I0215 18:44:22.044388 23126066861888 run_lib.py:133] step: 220700, training_loss: 1.94734e-02
I0215 18:44:22.211211 23126066861888 run_lib.py:146] step: 220700, eval_loss: 2.70189e-02
I0215 18:44:39.778711 23126066861888 run_lib.py:133] step: 220750, training_loss: 1.92271e-02
I0215 18:44:57.211929 23126066861888 run_lib.py:133] step: 220800, training_loss: 1.94428e-02
I0215 18:44:57.372102 23126066861888 run_lib.py:146] step: 220800, eval_loss: 2.69203e-02
I0215 18:45:14.748270 23126066861888 run_lib.py:133] step: 220850, training_loss: 1.86596e-02
I0215 18:45:32.182492 23126066861888 run_lib.py:133] step: 220900, training_loss: 1.85803e-02
I0215 18:45:32.338288 23126066861888 run_lib.py:146] step: 220900, eval_loss: 2.77245e-02
I0215 18:45:49.942588 23126066861888 run_lib.py:133] step: 220950, training_loss: 1.94034e-02
I0215 18:46:07.326293 23126066861888 run_lib.py:133] step: 221000, training_loss: 1.97891e-02
I0215 18:46:07.503304 23126066861888 run_lib.py:146] step: 221000, eval_loss: 2.65426e-02
I0215 18:46:24.855571 23126066861888 run_lib.py:133] step: 221050, training_loss: 1.92681e-02
I0215 18:46:42.427328 23126066861888 run_lib.py:133] step: 221100, training_loss: 1.86228e-02
I0215 18:46:42.585022 23126066861888 run_lib.py:146] step: 221100, eval_loss: 2.74983e-02
I0215 18:46:59.998793 23126066861888 run_lib.py:133] step: 221150, training_loss: 1.85481e-02
I0215 18:47:17.547902 23126066861888 run_lib.py:133] step: 221200, training_loss: 1.96786e-02
I0215 18:47:17.713342 23126066861888 run_lib.py:146] step: 221200, eval_loss: 2.75088e-02
I0215 18:47:35.131695 23126066861888 run_lib.py:133] step: 221250, training_loss: 1.93686e-02
I0215 18:47:52.533403 23126066861888 run_lib.py:133] step: 221300, training_loss: 1.88356e-02
I0215 18:47:52.685692 23126066861888 run_lib.py:146] step: 221300, eval_loss: 2.72412e-02
I0215 18:48:10.264585 23126066861888 run_lib.py:133] step: 221350, training_loss: 1.91041e-02
I0215 18:48:27.639258 23126066861888 run_lib.py:133] step: 221400, training_loss: 1.85219e-02
I0215 18:48:27.790096 23126066861888 run_lib.py:146] step: 221400, eval_loss: 2.65823e-02
I0215 18:48:45.194987 23126066861888 run_lib.py:133] step: 221450, training_loss: 1.95913e-02
I0215 18:49:02.588214 23126066861888 run_lib.py:133] step: 221500, training_loss: 1.86786e-02
I0215 18:49:02.758086 23126066861888 run_lib.py:146] step: 221500, eval_loss: 2.66829e-02
I0215 18:49:20.348508 23126066861888 run_lib.py:133] step: 221550, training_loss: 1.97846e-02
I0215 18:49:37.794707 23126066861888 run_lib.py:133] step: 221600, training_loss: 1.96112e-02
I0215 18:49:37.950967 23126066861888 run_lib.py:146] step: 221600, eval_loss: 2.68699e-02
I0215 18:49:55.440638 23126066861888 run_lib.py:133] step: 221650, training_loss: 1.82766e-02
I0215 18:50:12.830850 23126066861888 run_lib.py:133] step: 221700, training_loss: 1.89049e-02
I0215 18:50:13.001039 23126066861888 run_lib.py:146] step: 221700, eval_loss: 2.72670e-02
I0215 18:50:30.388077 23126066861888 run_lib.py:133] step: 221750, training_loss: 1.92139e-02
I0215 18:50:47.900193 23126066861888 run_lib.py:133] step: 221800, training_loss: 1.91301e-02
I0215 18:50:48.053540 23126066861888 run_lib.py:146] step: 221800, eval_loss: 2.70346e-02
I0215 18:51:05.655091 23126066861888 run_lib.py:133] step: 221850, training_loss: 1.91446e-02
I0215 18:51:23.102154 23126066861888 run_lib.py:133] step: 221900, training_loss: 1.92100e-02
I0215 18:51:23.254204 23126066861888 run_lib.py:146] step: 221900, eval_loss: 2.70449e-02
I0215 18:51:40.615884 23126066861888 run_lib.py:133] step: 221950, training_loss: 1.85131e-02
I0215 18:51:57.983478 23126066861888 run_lib.py:133] step: 222000, training_loss: 1.90718e-02
I0215 18:51:58.140464 23126066861888 run_lib.py:146] step: 222000, eval_loss: 2.67362e-02
I0215 18:52:15.698865 23126066861888 run_lib.py:133] step: 222050, training_loss: 1.89581e-02
I0215 18:52:33.096476 23126066861888 run_lib.py:133] step: 222100, training_loss: 1.89869e-02
I0215 18:52:33.263045 23126066861888 run_lib.py:146] step: 222100, eval_loss: 2.57754e-02
I0215 18:52:50.674571 23126066861888 run_lib.py:133] step: 222150, training_loss: 1.82029e-02
I0215 18:53:08.270225 23126066861888 run_lib.py:133] step: 222200, training_loss: 1.93124e-02
I0215 18:53:08.425031 23126066861888 run_lib.py:146] step: 222200, eval_loss: 2.68839e-02
I0215 18:53:25.844352 23126066861888 run_lib.py:133] step: 222250, training_loss: 1.89091e-02
I0215 18:53:43.386564 23126066861888 run_lib.py:133] step: 222300, training_loss: 1.87952e-02
I0215 18:53:43.541380 23126066861888 run_lib.py:146] step: 222300, eval_loss: 2.67000e-02
I0215 18:54:00.910346 23126066861888 run_lib.py:133] step: 222350, training_loss: 1.95964e-02
I0215 18:54:18.321661 23126066861888 run_lib.py:133] step: 222400, training_loss: 1.86911e-02
I0215 18:54:18.482520 23126066861888 run_lib.py:146] step: 222400, eval_loss: 2.63677e-02
I0215 18:54:36.129702 23126066861888 run_lib.py:133] step: 222450, training_loss: 1.93756e-02
I0215 18:54:53.613651 23126066861888 run_lib.py:133] step: 222500, training_loss: 1.85144e-02
I0215 18:54:53.770289 23126066861888 run_lib.py:146] step: 222500, eval_loss: 2.80343e-02
I0215 18:55:11.156088 23126066861888 run_lib.py:133] step: 222550, training_loss: 1.80316e-02
I0215 18:55:28.696899 23126066861888 run_lib.py:133] step: 222600, training_loss: 1.97475e-02
I0215 18:55:28.853082 23126066861888 run_lib.py:146] step: 222600, eval_loss: 2.76377e-02
I0215 18:55:46.266788 23126066861888 run_lib.py:133] step: 222650, training_loss: 1.94012e-02
I0215 18:56:03.693359 23126066861888 run_lib.py:133] step: 222700, training_loss: 1.89633e-02
I0215 18:56:03.848443 23126066861888 run_lib.py:146] step: 222700, eval_loss: 2.66918e-02
I0215 18:56:21.427975 23126066861888 run_lib.py:133] step: 222750, training_loss: 1.92526e-02
I0215 18:56:38.861242 23126066861888 run_lib.py:133] step: 222800, training_loss: 1.98525e-02
I0215 18:56:39.013142 23126066861888 run_lib.py:146] step: 222800, eval_loss: 2.65805e-02
I0215 18:56:56.417771 23126066861888 run_lib.py:133] step: 222850, training_loss: 1.88171e-02
I0215 18:57:13.844461 23126066861888 run_lib.py:133] step: 222900, training_loss: 1.88557e-02
I0215 18:57:13.997922 23126066861888 run_lib.py:146] step: 222900, eval_loss: 2.61446e-02
I0215 18:57:31.535636 23126066861888 run_lib.py:133] step: 222950, training_loss: 1.94329e-02
I0215 18:57:49.040213 23126066861888 run_lib.py:133] step: 223000, training_loss: 1.89299e-02
I0215 18:57:49.199238 23126066861888 run_lib.py:146] step: 223000, eval_loss: 2.72264e-02
I0215 18:58:06.589311 23126066861888 run_lib.py:133] step: 223050, training_loss: 1.95649e-02
I0215 18:58:23.955295 23126066861888 run_lib.py:133] step: 223100, training_loss: 1.93945e-02
I0215 18:58:24.112283 23126066861888 run_lib.py:146] step: 223100, eval_loss: 2.68888e-02
I0215 18:58:41.681266 23126066861888 run_lib.py:133] step: 223150, training_loss: 1.88002e-02
I0215 18:58:59.041733 23126066861888 run_lib.py:133] step: 223200, training_loss: 1.92897e-02
I0215 18:58:59.194113 23126066861888 run_lib.py:146] step: 223200, eval_loss: 2.72981e-02
I0215 18:59:16.589473 23126066861888 run_lib.py:133] step: 223250, training_loss: 1.92901e-02
I0215 18:59:34.178016 23126066861888 run_lib.py:133] step: 223300, training_loss: 1.91526e-02
I0215 18:59:34.333157 23126066861888 run_lib.py:146] step: 223300, eval_loss: 2.70962e-02
I0215 18:59:51.735817 23126066861888 run_lib.py:133] step: 223350, training_loss: 1.86034e-02
I0215 19:00:09.344833 23126066861888 run_lib.py:133] step: 223400, training_loss: 1.89002e-02
I0215 19:00:09.509337 23126066861888 run_lib.py:146] step: 223400, eval_loss: 2.74532e-02
I0215 19:00:26.873263 23126066861888 run_lib.py:133] step: 223450, training_loss: 1.82648e-02
I0215 19:00:44.248750 23126066861888 run_lib.py:133] step: 223500, training_loss: 1.93825e-02
I0215 19:00:44.413350 23126066861888 run_lib.py:146] step: 223500, eval_loss: 2.61514e-02
I0215 19:01:02.004338 23126066861888 run_lib.py:133] step: 223550, training_loss: 1.99596e-02
I0215 19:01:19.427987 23126066861888 run_lib.py:133] step: 223600, training_loss: 1.89078e-02
I0215 19:01:19.583528 23126066861888 run_lib.py:146] step: 223600, eval_loss: 2.68182e-02
I0215 19:01:36.954129 23126066861888 run_lib.py:133] step: 223650, training_loss: 1.86480e-02
I0215 19:01:54.501222 23126066861888 run_lib.py:133] step: 223700, training_loss: 1.91060e-02
I0215 19:01:54.654746 23126066861888 run_lib.py:146] step: 223700, eval_loss: 2.64538e-02
I0215 19:02:12.031719 23126066861888 run_lib.py:133] step: 223750, training_loss: 1.91989e-02
I0215 19:02:29.461139 23126066861888 run_lib.py:133] step: 223800, training_loss: 1.91752e-02
I0215 19:02:29.616288 23126066861888 run_lib.py:146] step: 223800, eval_loss: 2.69265e-02
I0215 19:02:47.133933 23126066861888 run_lib.py:133] step: 223850, training_loss: 1.82997e-02
I0215 19:03:04.523766 23126066861888 run_lib.py:133] step: 223900, training_loss: 1.89435e-02
I0215 19:03:04.683225 23126066861888 run_lib.py:146] step: 223900, eval_loss: 2.70885e-02
I0215 19:03:22.050608 23126066861888 run_lib.py:133] step: 223950, training_loss: 1.89236e-02
I0215 19:03:39.441376 23126066861888 run_lib.py:133] step: 224000, training_loss: 1.89753e-02
I0215 19:03:39.598774 23126066861888 run_lib.py:146] step: 224000, eval_loss: 2.73441e-02
I0215 19:03:57.145811 23126066861888 run_lib.py:133] step: 224050, training_loss: 1.85334e-02
I0215 19:04:14.655941 23126066861888 run_lib.py:133] step: 224100, training_loss: 1.87285e-02
I0215 19:04:14.816869 23126066861888 run_lib.py:146] step: 224100, eval_loss: 2.70251e-02
I0215 19:04:32.250191 23126066861888 run_lib.py:133] step: 224150, training_loss: 1.92306e-02
I0215 19:04:49.641598 23126066861888 run_lib.py:133] step: 224200, training_loss: 1.88159e-02
I0215 19:04:49.791982 23126066861888 run_lib.py:146] step: 224200, eval_loss: 2.73566e-02
I0215 19:05:07.340150 23126066861888 run_lib.py:133] step: 224250, training_loss: 1.88320e-02
I0215 19:05:24.743607 23126066861888 run_lib.py:133] step: 224300, training_loss: 1.95351e-02
I0215 19:05:24.897237 23126066861888 run_lib.py:146] step: 224300, eval_loss: 2.82186e-02
I0215 19:05:42.267828 23126066861888 run_lib.py:133] step: 224350, training_loss: 1.88020e-02
I0215 19:05:59.805453 23126066861888 run_lib.py:133] step: 224400, training_loss: 1.89781e-02
I0215 19:05:59.981354 23126066861888 run_lib.py:146] step: 224400, eval_loss: 2.70231e-02
I0215 19:06:17.426787 23126066861888 run_lib.py:133] step: 224450, training_loss: 1.86978e-02
I0215 19:06:35.036983 23126066861888 run_lib.py:133] step: 224500, training_loss: 1.97512e-02
I0215 19:06:35.191299 23126066861888 run_lib.py:146] step: 224500, eval_loss: 2.72337e-02
I0215 19:06:52.570306 23126066861888 run_lib.py:133] step: 224550, training_loss: 1.90397e-02
I0215 19:07:09.923666 23126066861888 run_lib.py:133] step: 224600, training_loss: 1.91121e-02
I0215 19:07:10.083980 23126066861888 run_lib.py:146] step: 224600, eval_loss: 2.70412e-02
I0215 19:07:27.659835 23126066861888 run_lib.py:133] step: 224650, training_loss: 1.88061e-02
I0215 19:07:45.100302 23126066861888 run_lib.py:133] step: 224700, training_loss: 1.83907e-02
I0215 19:07:45.261506 23126066861888 run_lib.py:146] step: 224700, eval_loss: 2.63298e-02
I0215 19:08:02.704943 23126066861888 run_lib.py:133] step: 224750, training_loss: 1.90909e-02
I0215 19:08:20.325051 23126066861888 run_lib.py:133] step: 224800, training_loss: 1.85779e-02
I0215 19:08:20.476057 23126066861888 run_lib.py:146] step: 224800, eval_loss: 2.77061e-02
I0215 19:08:37.815571 23126066861888 run_lib.py:133] step: 224850, training_loss: 1.89942e-02
I0215 19:08:55.264085 23126066861888 run_lib.py:133] step: 224900, training_loss: 1.92709e-02
I0215 19:08:55.427225 23126066861888 run_lib.py:146] step: 224900, eval_loss: 2.55498e-02
I0215 19:09:12.861207 23126066861888 run_lib.py:133] step: 224950, training_loss: 1.93461e-02
I0215 19:09:30.329386 23126066861888 run_lib.py:133] step: 225000, training_loss: 1.90614e-02
I0215 19:09:30.484364 23126066861888 run_lib.py:146] step: 225000, eval_loss: 2.70374e-02
I0215 19:09:47.934250 23126066861888 run_lib.py:133] step: 225050, training_loss: 1.92830e-02
I0215 19:10:05.352356 23126066861888 run_lib.py:133] step: 225100, training_loss: 1.92501e-02
I0215 19:10:05.503156 23126066861888 run_lib.py:146] step: 225100, eval_loss: 2.65094e-02
I0215 19:10:23.104267 23126066861888 run_lib.py:133] step: 225150, training_loss: 1.96331e-02
I0215 19:10:40.610497 23126066861888 run_lib.py:133] step: 225200, training_loss: 1.87582e-02
I0215 19:10:40.762145 23126066861888 run_lib.py:146] step: 225200, eval_loss: 2.67565e-02
I0215 19:10:58.159699 23126066861888 run_lib.py:133] step: 225250, training_loss: 1.95664e-02
I0215 19:11:15.583858 23126066861888 run_lib.py:133] step: 225300, training_loss: 1.90317e-02
I0215 19:11:15.761014 23126066861888 run_lib.py:146] step: 225300, eval_loss: 2.50370e-02
I0215 19:11:33.422420 23126066861888 run_lib.py:133] step: 225350, training_loss: 1.90244e-02
I0215 19:11:50.818230 23126066861888 run_lib.py:133] step: 225400, training_loss: 1.91000e-02
I0215 19:11:50.976202 23126066861888 run_lib.py:146] step: 225400, eval_loss: 2.69771e-02
I0215 19:12:08.391611 23126066861888 run_lib.py:133] step: 225450, training_loss: 1.92785e-02
I0215 19:12:25.953621 23126066861888 run_lib.py:133] step: 225500, training_loss: 1.97427e-02
I0215 19:12:26.113266 23126066861888 run_lib.py:146] step: 225500, eval_loss: 2.65083e-02
I0215 19:12:43.513280 23126066861888 run_lib.py:133] step: 225550, training_loss: 1.97428e-02
I0215 19:13:01.088226 23126066861888 run_lib.py:133] step: 225600, training_loss: 1.88877e-02
I0215 19:13:01.246764 23126066861888 run_lib.py:146] step: 225600, eval_loss: 2.82155e-02
I0215 19:13:18.719284 23126066861888 run_lib.py:133] step: 225650, training_loss: 1.97848e-02
I0215 19:13:36.092739 23126066861888 run_lib.py:133] step: 225700, training_loss: 1.89531e-02
I0215 19:13:36.249358 23126066861888 run_lib.py:146] step: 225700, eval_loss: 2.63454e-02
I0215 19:13:53.850996 23126066861888 run_lib.py:133] step: 225750, training_loss: 1.90046e-02
I0215 19:14:11.223953 23126066861888 run_lib.py:133] step: 225800, training_loss: 1.92861e-02
I0215 19:14:11.388782 23126066861888 run_lib.py:146] step: 225800, eval_loss: 2.63493e-02
I0215 19:14:28.755029 23126066861888 run_lib.py:133] step: 225850, training_loss: 1.91891e-02
I0215 19:14:46.333907 23126066861888 run_lib.py:133] step: 225900, training_loss: 1.87752e-02
I0215 19:14:46.490339 23126066861888 run_lib.py:146] step: 225900, eval_loss: 2.63663e-02
I0215 19:15:03.940255 23126066861888 run_lib.py:133] step: 225950, training_loss: 1.97086e-02
I0215 19:15:21.375444 23126066861888 run_lib.py:133] step: 226000, training_loss: 1.90392e-02
I0215 19:15:21.537663 23126066861888 run_lib.py:146] step: 226000, eval_loss: 2.67669e-02
I0215 19:15:39.063373 23126066861888 run_lib.py:133] step: 226050, training_loss: 1.89829e-02
I0215 19:15:56.458378 23126066861888 run_lib.py:133] step: 226100, training_loss: 1.92907e-02
I0215 19:15:56.613909 23126066861888 run_lib.py:146] step: 226100, eval_loss: 2.66283e-02
I0215 19:16:14.025521 23126066861888 run_lib.py:133] step: 226150, training_loss: 1.90867e-02
I0215 19:16:31.430130 23126066861888 run_lib.py:133] step: 226200, training_loss: 1.88775e-02
I0215 19:16:31.598448 23126066861888 run_lib.py:146] step: 226200, eval_loss: 2.68013e-02
I0215 19:16:49.224146 23126066861888 run_lib.py:133] step: 226250, training_loss: 1.93121e-02
I0215 19:17:06.734139 23126066861888 run_lib.py:133] step: 226300, training_loss: 1.98659e-02
I0215 19:17:06.890988 23126066861888 run_lib.py:146] step: 226300, eval_loss: 2.67111e-02
I0215 19:17:24.287393 23126066861888 run_lib.py:133] step: 226350, training_loss: 1.95544e-02
I0215 19:17:41.663739 23126066861888 run_lib.py:133] step: 226400, training_loss: 1.85548e-02
I0215 19:17:41.816951 23126066861888 run_lib.py:146] step: 226400, eval_loss: 2.62019e-02
I0215 19:17:59.337003 23126066861888 run_lib.py:133] step: 226450, training_loss: 1.86892e-02
I0215 19:18:16.771836 23126066861888 run_lib.py:133] step: 226500, training_loss: 1.89602e-02
I0215 19:18:16.925974 23126066861888 run_lib.py:146] step: 226500, eval_loss: 2.69296e-02
I0215 19:18:34.384526 23126066861888 run_lib.py:133] step: 226550, training_loss: 1.87333e-02
I0215 19:18:51.997872 23126066861888 run_lib.py:133] step: 226600, training_loss: 1.87333e-02
I0215 19:18:52.148297 23126066861888 run_lib.py:146] step: 226600, eval_loss: 2.74260e-02
I0215 19:19:09.553320 23126066861888 run_lib.py:133] step: 226650, training_loss: 1.93751e-02
I0215 19:19:27.096571 23126066861888 run_lib.py:133] step: 226700, training_loss: 1.88330e-02
I0215 19:19:27.256327 23126066861888 run_lib.py:146] step: 226700, eval_loss: 2.71323e-02
I0215 19:19:44.644677 23126066861888 run_lib.py:133] step: 226750, training_loss: 1.90417e-02
I0215 19:20:02.010700 23126066861888 run_lib.py:133] step: 226800, training_loss: 1.93367e-02
I0215 19:20:02.186259 23126066861888 run_lib.py:146] step: 226800, eval_loss: 2.62931e-02
I0215 19:20:19.789887 23126066861888 run_lib.py:133] step: 226850, training_loss: 1.89995e-02
I0215 19:20:37.187550 23126066861888 run_lib.py:133] step: 226900, training_loss: 1.87056e-02
I0215 19:20:37.357421 23126066861888 run_lib.py:146] step: 226900, eval_loss: 2.74832e-02
I0215 19:20:54.766026 23126066861888 run_lib.py:133] step: 226950, training_loss: 1.92759e-02
I0215 19:21:12.314934 23126066861888 run_lib.py:133] step: 227000, training_loss: 1.94062e-02
I0215 19:21:12.472257 23126066861888 run_lib.py:146] step: 227000, eval_loss: 2.65325e-02
I0215 19:21:29.860520 23126066861888 run_lib.py:133] step: 227050, training_loss: 1.97869e-02
I0215 19:21:47.325990 23126066861888 run_lib.py:133] step: 227100, training_loss: 1.87290e-02
I0215 19:21:47.481288 23126066861888 run_lib.py:146] step: 227100, eval_loss: 2.72258e-02
I0215 19:22:05.001969 23126066861888 run_lib.py:133] step: 227150, training_loss: 1.89502e-02
I0215 19:22:22.369087 23126066861888 run_lib.py:133] step: 227200, training_loss: 1.88668e-02
I0215 19:22:22.531481 23126066861888 run_lib.py:146] step: 227200, eval_loss: 2.66522e-02
I0215 19:22:39.918496 23126066861888 run_lib.py:133] step: 227250, training_loss: 1.87797e-02
I0215 19:22:57.353988 23126066861888 run_lib.py:133] step: 227300, training_loss: 1.86077e-02
I0215 19:22:57.513256 23126066861888 run_lib.py:146] step: 227300, eval_loss: 2.72300e-02
I0215 19:23:15.096515 23126066861888 run_lib.py:133] step: 227350, training_loss: 1.85369e-02
I0215 19:23:32.556541 23126066861888 run_lib.py:133] step: 227400, training_loss: 1.88429e-02
I0215 19:23:32.716758 23126066861888 run_lib.py:146] step: 227400, eval_loss: 2.70641e-02
I0215 19:23:50.157077 23126066861888 run_lib.py:133] step: 227450, training_loss: 1.96291e-02
I0215 19:24:07.546884 23126066861888 run_lib.py:133] step: 227500, training_loss: 1.90839e-02
I0215 19:24:07.697114 23126066861888 run_lib.py:146] step: 227500, eval_loss: 2.67261e-02
I0215 19:24:25.227232 23126066861888 run_lib.py:133] step: 227550, training_loss: 1.86776e-02
I0215 19:24:42.574587 23126066861888 run_lib.py:133] step: 227600, training_loss: 1.86071e-02
I0215 19:24:42.727053 23126066861888 run_lib.py:146] step: 227600, eval_loss: 2.72799e-02
I0215 19:25:00.065933 23126066861888 run_lib.py:133] step: 227650, training_loss: 1.93092e-02
I0215 19:25:17.644872 23126066861888 run_lib.py:133] step: 227700, training_loss: 1.87799e-02
I0215 19:25:17.816318 23126066861888 run_lib.py:146] step: 227700, eval_loss: 2.69285e-02
I0215 19:25:35.243312 23126066861888 run_lib.py:133] step: 227750, training_loss: 1.88715e-02
I0215 19:25:52.828133 23126066861888 run_lib.py:133] step: 227800, training_loss: 1.94819e-02
I0215 19:25:52.983444 23126066861888 run_lib.py:146] step: 227800, eval_loss: 2.71958e-02
I0215 19:26:10.375631 23126066861888 run_lib.py:133] step: 227850, training_loss: 1.89086e-02
I0215 19:26:27.731494 23126066861888 run_lib.py:133] step: 227900, training_loss: 1.89263e-02
I0215 19:26:27.886171 23126066861888 run_lib.py:146] step: 227900, eval_loss: 2.76526e-02
I0215 19:26:45.385376 23126066861888 run_lib.py:133] step: 227950, training_loss: 1.88992e-02
I0215 19:27:02.778537 23126066861888 run_lib.py:133] step: 228000, training_loss: 1.84653e-02
I0215 19:27:02.931301 23126066861888 run_lib.py:146] step: 228000, eval_loss: 2.71511e-02
I0215 19:27:20.325823 23126066861888 run_lib.py:133] step: 228050, training_loss: 1.87305e-02
I0215 19:27:37.903708 23126066861888 run_lib.py:133] step: 228100, training_loss: 1.90314e-02
I0215 19:27:38.061312 23126066861888 run_lib.py:146] step: 228100, eval_loss: 2.78367e-02
I0215 19:27:55.488868 23126066861888 run_lib.py:133] step: 228150, training_loss: 1.89221e-02
I0215 19:28:12.895804 23126066861888 run_lib.py:133] step: 228200, training_loss: 1.92452e-02
I0215 19:28:13.052505 23126066861888 run_lib.py:146] step: 228200, eval_loss: 2.83323e-02
I0215 19:28:30.477587 23126066861888 run_lib.py:133] step: 228250, training_loss: 1.97506e-02
I0215 19:28:47.955373 23126066861888 run_lib.py:133] step: 228300, training_loss: 1.87625e-02
I0215 19:28:48.110220 23126066861888 run_lib.py:146] step: 228300, eval_loss: 2.73771e-02
I0215 19:29:05.514755 23126066861888 run_lib.py:133] step: 228350, training_loss: 1.89330e-02
I0215 19:29:22.916272 23126066861888 run_lib.py:133] step: 228400, training_loss: 1.85610e-02
I0215 19:29:23.069027 23126066861888 run_lib.py:146] step: 228400, eval_loss: 2.62180e-02
I0215 19:29:40.662663 23126066861888 run_lib.py:133] step: 228450, training_loss: 1.76655e-02
I0215 19:29:58.135405 23126066861888 run_lib.py:133] step: 228500, training_loss: 1.92209e-02
I0215 19:29:58.288386 23126066861888 run_lib.py:146] step: 228500, eval_loss: 2.67794e-02
I0215 19:30:15.653772 23126066861888 run_lib.py:133] step: 228550, training_loss: 1.97598e-02
I0215 19:30:33.096492 23126066861888 run_lib.py:133] step: 228600, training_loss: 1.91683e-02
I0215 19:30:33.261599 23126066861888 run_lib.py:146] step: 228600, eval_loss: 2.73128e-02
I0215 19:30:50.868677 23126066861888 run_lib.py:133] step: 228650, training_loss: 1.89178e-02
I0215 19:31:08.271972 23126066861888 run_lib.py:133] step: 228700, training_loss: 1.94976e-02
I0215 19:31:08.428424 23126066861888 run_lib.py:146] step: 228700, eval_loss: 2.63943e-02
I0215 19:31:25.846365 23126066861888 run_lib.py:133] step: 228750, training_loss: 1.85054e-02
I0215 19:31:43.371291 23126066861888 run_lib.py:133] step: 228800, training_loss: 1.82741e-02
I0215 19:31:43.525044 23126066861888 run_lib.py:146] step: 228800, eval_loss: 2.70413e-02
I0215 19:32:00.892117 23126066861888 run_lib.py:133] step: 228850, training_loss: 1.93217e-02
I0215 19:32:18.495497 23126066861888 run_lib.py:133] step: 228900, training_loss: 1.96424e-02
I0215 19:32:18.651614 23126066861888 run_lib.py:146] step: 228900, eval_loss: 2.69953e-02
I0215 19:32:36.021147 23126066861888 run_lib.py:133] step: 228950, training_loss: 1.91272e-02
I0215 19:32:53.388538 23126066861888 run_lib.py:133] step: 229000, training_loss: 1.87318e-02
I0215 19:32:53.544258 23126066861888 run_lib.py:146] step: 229000, eval_loss: 2.76025e-02
I0215 19:33:11.137168 23126066861888 run_lib.py:133] step: 229050, training_loss: 1.92833e-02
I0215 19:33:28.541290 23126066861888 run_lib.py:133] step: 229100, training_loss: 1.82664e-02
I0215 19:33:28.702474 23126066861888 run_lib.py:146] step: 229100, eval_loss: 2.73447e-02
I0215 19:33:46.154822 23126066861888 run_lib.py:133] step: 229150, training_loss: 1.87706e-02
I0215 19:34:03.788662 23126066861888 run_lib.py:133] step: 229200, training_loss: 1.93454e-02
I0215 19:34:03.941956 23126066861888 run_lib.py:146] step: 229200, eval_loss: 2.79794e-02
I0215 19:34:21.317270 23126066861888 run_lib.py:133] step: 229250, training_loss: 1.90326e-02
I0215 19:34:38.702996 23126066861888 run_lib.py:133] step: 229300, training_loss: 1.88010e-02
I0215 19:34:38.862334 23126066861888 run_lib.py:146] step: 229300, eval_loss: 2.66664e-02
I0215 19:34:56.320520 23126066861888 run_lib.py:133] step: 229350, training_loss: 1.91242e-02
I0215 19:35:13.749241 23126066861888 run_lib.py:133] step: 229400, training_loss: 1.93065e-02
I0215 19:35:13.902119 23126066861888 run_lib.py:146] step: 229400, eval_loss: 2.87663e-02
I0215 19:35:31.365796 23126066861888 run_lib.py:133] step: 229450, training_loss: 1.87156e-02
I0215 19:35:48.764871 23126066861888 run_lib.py:133] step: 229500, training_loss: 1.86153e-02
I0215 19:35:48.918294 23126066861888 run_lib.py:146] step: 229500, eval_loss: 2.72521e-02
I0215 19:36:06.483551 23126066861888 run_lib.py:133] step: 229550, training_loss: 1.88129e-02
I0215 19:36:23.958492 23126066861888 run_lib.py:133] step: 229600, training_loss: 1.88371e-02
I0215 19:36:24.115267 23126066861888 run_lib.py:146] step: 229600, eval_loss: 2.65867e-02
I0215 19:36:41.478539 23126066861888 run_lib.py:133] step: 229650, training_loss: 1.87934e-02
I0215 19:36:58.932892 23126066861888 run_lib.py:133] step: 229700, training_loss: 1.93771e-02
I0215 19:36:59.099163 23126066861888 run_lib.py:146] step: 229700, eval_loss: 2.60555e-02
I0215 19:37:16.688808 23126066861888 run_lib.py:133] step: 229750, training_loss: 1.90127e-02
I0215 19:37:34.100771 23126066861888 run_lib.py:133] step: 229800, training_loss: 1.88900e-02
I0215 19:37:34.257551 23126066861888 run_lib.py:146] step: 229800, eval_loss: 2.66974e-02
I0215 19:37:51.724398 23126066861888 run_lib.py:133] step: 229850, training_loss: 1.89647e-02
I0215 19:38:09.248747 23126066861888 run_lib.py:133] step: 229900, training_loss: 1.85325e-02
I0215 19:38:09.398206 23126066861888 run_lib.py:146] step: 229900, eval_loss: 2.63509e-02
I0215 19:38:26.802086 23126066861888 run_lib.py:133] step: 229950, training_loss: 1.85526e-02
I0215 19:38:44.361309 23126066861888 run_lib.py:133] step: 230000, training_loss: 1.86123e-02
I0215 19:38:45.186369 23126066861888 run_lib.py:146] step: 230000, eval_loss: 2.66815e-02
I0215 19:39:05.557925 23126066861888 run_lib.py:133] step: 230050, training_loss: 1.88282e-02
I0215 19:39:22.943082 23126066861888 run_lib.py:133] step: 230100, training_loss: 1.91619e-02
I0215 19:39:23.100994 23126066861888 run_lib.py:146] step: 230100, eval_loss: 2.73722e-02
I0215 19:39:40.484381 23126066861888 run_lib.py:133] step: 230150, training_loss: 1.91895e-02
I0215 19:39:57.850961 23126066861888 run_lib.py:133] step: 230200, training_loss: 1.90909e-02
I0215 19:39:58.007248 23126066861888 run_lib.py:146] step: 230200, eval_loss: 2.73740e-02
I0215 19:40:15.592241 23126066861888 run_lib.py:133] step: 230250, training_loss: 1.94981e-02
I0215 19:40:33.178797 23126066861888 run_lib.py:133] step: 230300, training_loss: 1.90816e-02
I0215 19:40:33.336491 23126066861888 run_lib.py:146] step: 230300, eval_loss: 2.63584e-02
I0215 19:40:50.745848 23126066861888 run_lib.py:133] step: 230350, training_loss: 1.94750e-02
I0215 19:41:08.165437 23126066861888 run_lib.py:133] step: 230400, training_loss: 1.89333e-02
I0215 19:41:08.319338 23126066861888 run_lib.py:146] step: 230400, eval_loss: 2.67624e-02
I0215 19:41:25.860253 23126066861888 run_lib.py:133] step: 230450, training_loss: 1.90535e-02
I0215 19:41:43.242856 23126066861888 run_lib.py:133] step: 230500, training_loss: 1.89960e-02
I0215 19:41:43.393954 23126066861888 run_lib.py:146] step: 230500, eval_loss: 2.58854e-02
I0215 19:42:00.758961 23126066861888 run_lib.py:133] step: 230550, training_loss: 1.92603e-02
I0215 19:42:18.311194 23126066861888 run_lib.py:133] step: 230600, training_loss: 1.87326e-02
I0215 19:42:18.484013 23126066861888 run_lib.py:146] step: 230600, eval_loss: 2.75733e-02
I0215 19:42:35.895994 23126066861888 run_lib.py:133] step: 230650, training_loss: 1.90122e-02
I0215 19:42:53.480924 23126066861888 run_lib.py:133] step: 230700, training_loss: 1.81359e-02
I0215 19:42:53.634565 23126066861888 run_lib.py:146] step: 230700, eval_loss: 2.77954e-02
I0215 19:43:11.029000 23126066861888 run_lib.py:133] step: 230750, training_loss: 1.92864e-02
I0215 19:43:28.405565 23126066861888 run_lib.py:133] step: 230800, training_loss: 1.84698e-02
I0215 19:43:28.563227 23126066861888 run_lib.py:146] step: 230800, eval_loss: 2.57409e-02
I0215 19:43:46.173466 23126066861888 run_lib.py:133] step: 230850, training_loss: 1.84959e-02
I0215 19:44:03.599405 23126066861888 run_lib.py:133] step: 230900, training_loss: 1.89683e-02
I0215 19:44:03.752209 23126066861888 run_lib.py:146] step: 230900, eval_loss: 2.70722e-02
I0215 19:44:21.180230 23126066861888 run_lib.py:133] step: 230950, training_loss: 1.95419e-02
I0215 19:44:38.723690 23126066861888 run_lib.py:133] step: 231000, training_loss: 1.84927e-02
I0215 19:44:38.876929 23126066861888 run_lib.py:146] step: 231000, eval_loss: 2.73857e-02
I0215 19:44:56.225023 23126066861888 run_lib.py:133] step: 231050, training_loss: 1.92608e-02
I0215 19:45:13.603228 23126066861888 run_lib.py:133] step: 231100, training_loss: 1.89703e-02
I0215 19:45:13.776965 23126066861888 run_lib.py:146] step: 231100, eval_loss: 2.72589e-02
I0215 19:45:31.278562 23126066861888 run_lib.py:133] step: 231150, training_loss: 1.87097e-02
I0215 19:45:48.694928 23126066861888 run_lib.py:133] step: 231200, training_loss: 1.81060e-02
I0215 19:45:48.851535 23126066861888 run_lib.py:146] step: 231200, eval_loss: 2.75100e-02
I0215 19:46:06.262110 23126066861888 run_lib.py:133] step: 231250, training_loss: 1.83599e-02
I0215 19:46:23.630125 23126066861888 run_lib.py:133] step: 231300, training_loss: 1.94339e-02
I0215 19:46:23.797972 23126066861888 run_lib.py:146] step: 231300, eval_loss: 2.72175e-02
I0215 19:46:41.341184 23126066861888 run_lib.py:133] step: 231350, training_loss: 1.90237e-02
I0215 19:46:58.833478 23126066861888 run_lib.py:133] step: 231400, training_loss: 1.91038e-02
I0215 19:46:58.990796 23126066861888 run_lib.py:146] step: 231400, eval_loss: 2.62363e-02
I0215 19:47:16.458025 23126066861888 run_lib.py:133] step: 231450, training_loss: 1.85780e-02
I0215 19:47:33.860972 23126066861888 run_lib.py:133] step: 231500, training_loss: 1.93110e-02
I0215 19:47:34.016056 23126066861888 run_lib.py:146] step: 231500, eval_loss: 2.79948e-02
I0215 19:47:51.627945 23126066861888 run_lib.py:133] step: 231550, training_loss: 1.92336e-02
I0215 19:48:09.042010 23126066861888 run_lib.py:133] step: 231600, training_loss: 1.85250e-02
I0215 19:48:09.198500 23126066861888 run_lib.py:146] step: 231600, eval_loss: 2.71453e-02
I0215 19:48:26.598057 23126066861888 run_lib.py:133] step: 231650, training_loss: 1.92425e-02
I0215 19:48:44.150594 23126066861888 run_lib.py:133] step: 231700, training_loss: 1.90890e-02
I0215 19:48:44.311119 23126066861888 run_lib.py:146] step: 231700, eval_loss: 2.61854e-02
I0215 19:49:01.751034 23126066861888 run_lib.py:133] step: 231750, training_loss: 1.86594e-02
I0215 19:49:19.371447 23126066861888 run_lib.py:133] step: 231800, training_loss: 1.90302e-02
I0215 19:49:19.525254 23126066861888 run_lib.py:146] step: 231800, eval_loss: 2.76370e-02
I0215 19:49:36.926286 23126066861888 run_lib.py:133] step: 231850, training_loss: 1.93955e-02
I0215 19:49:54.293398 23126066861888 run_lib.py:133] step: 231900, training_loss: 1.91991e-02
I0215 19:49:54.444071 23126066861888 run_lib.py:146] step: 231900, eval_loss: 2.63658e-02
I0215 19:50:11.963991 23126066861888 run_lib.py:133] step: 231950, training_loss: 1.85703e-02
I0215 19:50:29.389661 23126066861888 run_lib.py:133] step: 232000, training_loss: 1.88660e-02
I0215 19:50:29.556622 23126066861888 run_lib.py:146] step: 232000, eval_loss: 2.75663e-02
I0215 19:50:47.019177 23126066861888 run_lib.py:133] step: 232050, training_loss: 1.96974e-02
I0215 19:51:04.594344 23126066861888 run_lib.py:133] step: 232100, training_loss: 1.97470e-02
I0215 19:51:04.750073 23126066861888 run_lib.py:146] step: 232100, eval_loss: 2.60646e-02
I0215 19:51:22.120565 23126066861888 run_lib.py:133] step: 232150, training_loss: 1.88083e-02
I0215 19:51:39.506650 23126066861888 run_lib.py:133] step: 232200, training_loss: 1.88571e-02
I0215 19:51:39.669502 23126066861888 run_lib.py:146] step: 232200, eval_loss: 2.67202e-02
I0215 19:51:57.129138 23126066861888 run_lib.py:133] step: 232250, training_loss: 1.93314e-02
I0215 19:52:14.545279 23126066861888 run_lib.py:133] step: 232300, training_loss: 1.89433e-02
I0215 19:52:14.697428 23126066861888 run_lib.py:146] step: 232300, eval_loss: 2.66789e-02
I0215 19:52:32.137611 23126066861888 run_lib.py:133] step: 232350, training_loss: 1.83839e-02
I0215 19:52:49.533462 23126066861888 run_lib.py:133] step: 232400, training_loss: 1.87980e-02
I0215 19:52:49.685267 23126066861888 run_lib.py:146] step: 232400, eval_loss: 2.72858e-02
I0215 19:53:07.301846 23126066861888 run_lib.py:133] step: 232450, training_loss: 1.88671e-02
I0215 19:53:24.832422 23126066861888 run_lib.py:133] step: 232500, training_loss: 1.84400e-02
I0215 19:53:24.996200 23126066861888 run_lib.py:146] step: 232500, eval_loss: 2.56410e-02
I0215 19:53:42.341716 23126066861888 run_lib.py:133] step: 232550, training_loss: 1.90505e-02
I0215 19:53:59.788661 23126066861888 run_lib.py:133] step: 232600, training_loss: 1.94153e-02
I0215 19:53:59.954303 23126066861888 run_lib.py:146] step: 232600, eval_loss: 2.71992e-02
I0215 19:54:17.561593 23126066861888 run_lib.py:133] step: 232650, training_loss: 1.88901e-02
I0215 19:54:34.962351 23126066861888 run_lib.py:133] step: 232700, training_loss: 1.95023e-02
I0215 19:54:35.119247 23126066861888 run_lib.py:146] step: 232700, eval_loss: 2.66906e-02
I0215 19:54:52.492916 23126066861888 run_lib.py:133] step: 232750, training_loss: 1.95146e-02
I0215 19:55:10.075003 23126066861888 run_lib.py:133] step: 232800, training_loss: 1.94904e-02
I0215 19:55:10.263339 23126066861888 run_lib.py:146] step: 232800, eval_loss: 2.71357e-02
I0215 19:55:27.682493 23126066861888 run_lib.py:133] step: 232850, training_loss: 1.97854e-02
I0215 19:55:45.270043 23126066861888 run_lib.py:133] step: 232900, training_loss: 1.88177e-02
I0215 19:55:45.433291 23126066861888 run_lib.py:146] step: 232900, eval_loss: 2.76703e-02
I0215 19:56:02.817834 23126066861888 run_lib.py:133] step: 232950, training_loss: 1.88393e-02
I0215 19:56:20.268612 23126066861888 run_lib.py:133] step: 233000, training_loss: 1.89327e-02
I0215 19:56:20.425343 23126066861888 run_lib.py:146] step: 233000, eval_loss: 2.63187e-02
I0215 19:56:37.991571 23126066861888 run_lib.py:133] step: 233050, training_loss: 1.84383e-02
I0215 19:56:55.395732 23126066861888 run_lib.py:133] step: 233100, training_loss: 1.93929e-02
I0215 19:56:55.551244 23126066861888 run_lib.py:146] step: 233100, eval_loss: 2.68623e-02
I0215 19:57:13.083148 23126066861888 run_lib.py:133] step: 233150, training_loss: 1.93975e-02
I0215 19:57:30.733499 23126066861888 run_lib.py:133] step: 233200, training_loss: 1.98116e-02
I0215 19:57:30.888322 23126066861888 run_lib.py:146] step: 233200, eval_loss: 2.68107e-02
I0215 19:57:48.330378 23126066861888 run_lib.py:133] step: 233250, training_loss: 1.89755e-02
I0215 19:58:05.735654 23126066861888 run_lib.py:133] step: 233300, training_loss: 1.90687e-02
I0215 19:58:05.885106 23126066861888 run_lib.py:146] step: 233300, eval_loss: 2.76854e-02
I0215 19:58:23.340119 23126066861888 run_lib.py:133] step: 233350, training_loss: 1.91016e-02
I0215 19:58:40.734880 23126066861888 run_lib.py:133] step: 233400, training_loss: 1.85104e-02
I0215 19:58:40.888279 23126066861888 run_lib.py:146] step: 233400, eval_loss: 2.73825e-02
I0215 19:58:58.304601 23126066861888 run_lib.py:133] step: 233450, training_loss: 1.88335e-02
I0215 19:59:15.720714 23126066861888 run_lib.py:133] step: 233500, training_loss: 1.84588e-02
I0215 19:59:15.886137 23126066861888 run_lib.py:146] step: 233500, eval_loss: 2.69079e-02
I0215 19:59:33.463844 23126066861888 run_lib.py:133] step: 233550, training_loss: 1.92019e-02
I0215 19:59:50.925259 23126066861888 run_lib.py:133] step: 233600, training_loss: 1.91531e-02
I0215 19:59:51.084992 23126066861888 run_lib.py:146] step: 233600, eval_loss: 2.66698e-02
I0215 20:00:08.470563 23126066861888 run_lib.py:133] step: 233650, training_loss: 1.97085e-02
I0215 20:00:25.857658 23126066861888 run_lib.py:133] step: 233700, training_loss: 1.85562e-02
I0215 20:00:26.017182 23126066861888 run_lib.py:146] step: 233700, eval_loss: 2.78387e-02
I0215 20:00:43.552560 23126066861888 run_lib.py:133] step: 233750, training_loss: 1.91652e-02
I0215 20:01:01.005788 23126066861888 run_lib.py:133] step: 233800, training_loss: 1.85569e-02
I0215 20:01:01.162356 23126066861888 run_lib.py:146] step: 233800, eval_loss: 2.60659e-02
I0215 20:01:18.531408 23126066861888 run_lib.py:133] step: 233850, training_loss: 1.94535e-02
I0215 20:01:36.122500 23126066861888 run_lib.py:133] step: 233900, training_loss: 1.86456e-02
I0215 20:01:36.277290 23126066861888 run_lib.py:146] step: 233900, eval_loss: 2.70809e-02
I0215 20:01:53.710449 23126066861888 run_lib.py:133] step: 233950, training_loss: 1.84223e-02
I0215 20:02:11.209117 23126066861888 run_lib.py:133] step: 234000, training_loss: 1.92571e-02
I0215 20:02:11.380214 23126066861888 run_lib.py:146] step: 234000, eval_loss: 2.81465e-02
I0215 20:02:28.803832 23126066861888 run_lib.py:133] step: 234050, training_loss: 1.91547e-02
I0215 20:02:46.216070 23126066861888 run_lib.py:133] step: 234100, training_loss: 1.91670e-02
I0215 20:02:46.370238 23126066861888 run_lib.py:146] step: 234100, eval_loss: 2.72793e-02
I0215 20:03:03.983180 23126066861888 run_lib.py:133] step: 234150, training_loss: 1.82933e-02
I0215 20:03:21.344616 23126066861888 run_lib.py:133] step: 234200, training_loss: 1.90496e-02
I0215 20:03:21.497326 23126066861888 run_lib.py:146] step: 234200, eval_loss: 2.78352e-02
I0215 20:03:38.833902 23126066861888 run_lib.py:133] step: 234250, training_loss: 1.85868e-02
I0215 20:03:56.371673 23126066861888 run_lib.py:133] step: 234300, training_loss: 1.87667e-02
I0215 20:03:56.526409 23126066861888 run_lib.py:146] step: 234300, eval_loss: 2.62803e-02
I0215 20:04:13.978749 23126066861888 run_lib.py:133] step: 234350, training_loss: 1.91484e-02
I0215 20:04:31.394710 23126066861888 run_lib.py:133] step: 234400, training_loss: 1.88254e-02
I0215 20:04:31.558241 23126066861888 run_lib.py:146] step: 234400, eval_loss: 2.66762e-02
I0215 20:04:49.066699 23126066861888 run_lib.py:133] step: 234450, training_loss: 1.84130e-02
I0215 20:05:06.481165 23126066861888 run_lib.py:133] step: 234500, training_loss: 1.87285e-02
I0215 20:05:06.635009 23126066861888 run_lib.py:146] step: 234500, eval_loss: 2.70929e-02
I0215 20:05:24.044692 23126066861888 run_lib.py:133] step: 234550, training_loss: 1.91923e-02
I0215 20:05:41.424981 23126066861888 run_lib.py:133] step: 234600, training_loss: 1.95511e-02
I0215 20:05:41.578724 23126066861888 run_lib.py:146] step: 234600, eval_loss: 2.67752e-02
I0215 20:05:59.149428 23126066861888 run_lib.py:133] step: 234650, training_loss: 1.90165e-02
I0215 20:06:16.620927 23126066861888 run_lib.py:133] step: 234700, training_loss: 1.87982e-02
I0215 20:06:16.770933 23126066861888 run_lib.py:146] step: 234700, eval_loss: 2.68385e-02
I0215 20:06:34.133602 23126066861888 run_lib.py:133] step: 234750, training_loss: 1.88243e-02
I0215 20:06:51.544140 23126066861888 run_lib.py:133] step: 234800, training_loss: 1.87709e-02
I0215 20:06:51.697206 23126066861888 run_lib.py:146] step: 234800, eval_loss: 2.76765e-02
I0215 20:07:09.201525 23126066861888 run_lib.py:133] step: 234850, training_loss: 1.90697e-02
I0215 20:07:26.603630 23126066861888 run_lib.py:133] step: 234900, training_loss: 1.83892e-02
I0215 20:07:26.776929 23126066861888 run_lib.py:146] step: 234900, eval_loss: 2.60116e-02
I0215 20:07:44.204787 23126066861888 run_lib.py:133] step: 234950, training_loss: 1.84252e-02
I0215 20:08:01.802412 23126066861888 run_lib.py:133] step: 235000, training_loss: 1.90947e-02
I0215 20:08:01.957123 23126066861888 run_lib.py:146] step: 235000, eval_loss: 2.65386e-02
I0215 20:08:19.320493 23126066861888 run_lib.py:133] step: 235050, training_loss: 1.85275e-02
I0215 20:08:36.842387 23126066861888 run_lib.py:133] step: 235100, training_loss: 1.82676e-02
I0215 20:08:36.998194 23126066861888 run_lib.py:146] step: 235100, eval_loss: 2.69122e-02
I0215 20:08:54.363411 23126066861888 run_lib.py:133] step: 235150, training_loss: 1.82976e-02
I0215 20:09:11.835148 23126066861888 run_lib.py:133] step: 235200, training_loss: 1.97278e-02
I0215 20:09:11.994544 23126066861888 run_lib.py:146] step: 235200, eval_loss: 2.68836e-02
I0215 20:09:29.655066 23126066861888 run_lib.py:133] step: 235250, training_loss: 1.93262e-02
I0215 20:09:47.057829 23126066861888 run_lib.py:133] step: 235300, training_loss: 1.95479e-02
I0215 20:09:47.212085 23126066861888 run_lib.py:146] step: 235300, eval_loss: 2.63099e-02
I0215 20:10:04.583017 23126066861888 run_lib.py:133] step: 235350, training_loss: 1.92968e-02
I0215 20:10:22.158559 23126066861888 run_lib.py:133] step: 235400, training_loss: 1.84756e-02
I0215 20:10:22.321206 23126066861888 run_lib.py:146] step: 235400, eval_loss: 2.74972e-02
I0215 20:10:39.735465 23126066861888 run_lib.py:133] step: 235450, training_loss: 1.82055e-02
I0215 20:10:57.182657 23126066861888 run_lib.py:133] step: 235500, training_loss: 1.90303e-02
I0215 20:10:57.339888 23126066861888 run_lib.py:146] step: 235500, eval_loss: 2.82820e-02
I0215 20:11:14.869319 23126066861888 run_lib.py:133] step: 235550, training_loss: 1.89658e-02
I0215 20:11:32.261075 23126066861888 run_lib.py:133] step: 235600, training_loss: 1.91609e-02
I0215 20:11:32.412514 23126066861888 run_lib.py:146] step: 235600, eval_loss: 2.83618e-02
I0215 20:11:49.793139 23126066861888 run_lib.py:133] step: 235650, training_loss: 1.91635e-02
I0215 20:12:07.207761 23126066861888 run_lib.py:133] step: 235700, training_loss: 1.89000e-02
I0215 20:12:07.360264 23126066861888 run_lib.py:146] step: 235700, eval_loss: 2.73289e-02
I0215 20:12:24.922963 23126066861888 run_lib.py:133] step: 235750, training_loss: 1.87818e-02
I0215 20:12:42.449934 23126066861888 run_lib.py:133] step: 235800, training_loss: 1.92171e-02
I0215 20:12:42.600917 23126066861888 run_lib.py:146] step: 235800, eval_loss: 2.61222e-02
I0215 20:13:00.011636 23126066861888 run_lib.py:133] step: 235850, training_loss: 1.78340e-02
I0215 20:13:17.444334 23126066861888 run_lib.py:133] step: 235900, training_loss: 1.98399e-02
I0215 20:13:17.606582 23126066861888 run_lib.py:146] step: 235900, eval_loss: 2.61320e-02
I0215 20:13:35.162823 23126066861888 run_lib.py:133] step: 235950, training_loss: 1.89093e-02
I0215 20:13:52.530010 23126066861888 run_lib.py:133] step: 236000, training_loss: 1.90733e-02
I0215 20:13:52.684237 23126066861888 run_lib.py:146] step: 236000, eval_loss: 2.66047e-02
I0215 20:14:10.106937 23126066861888 run_lib.py:133] step: 236050, training_loss: 1.91883e-02
I0215 20:14:27.696175 23126066861888 run_lib.py:133] step: 236100, training_loss: 1.94794e-02
I0215 20:14:27.848886 23126066861888 run_lib.py:146] step: 236100, eval_loss: 2.76251e-02
I0215 20:14:45.249998 23126066861888 run_lib.py:133] step: 236150, training_loss: 1.83502e-02
I0215 20:15:02.847460 23126066861888 run_lib.py:133] step: 236200, training_loss: 1.89784e-02
I0215 20:15:02.999139 23126066861888 run_lib.py:146] step: 236200, eval_loss: 2.65066e-02
I0215 20:15:20.368778 23126066861888 run_lib.py:133] step: 236250, training_loss: 1.84383e-02
I0215 20:15:37.776545 23126066861888 run_lib.py:133] step: 236300, training_loss: 1.85639e-02
I0215 20:15:37.948115 23126066861888 run_lib.py:146] step: 236300, eval_loss: 2.75558e-02
I0215 20:15:55.536190 23126066861888 run_lib.py:133] step: 236350, training_loss: 1.91910e-02
I0215 20:16:12.963941 23126066861888 run_lib.py:133] step: 236400, training_loss: 1.90603e-02
I0215 20:16:13.119474 23126066861888 run_lib.py:146] step: 236400, eval_loss: 2.70281e-02
I0215 20:16:30.457597 23126066861888 run_lib.py:133] step: 236450, training_loss: 1.87099e-02
I0215 20:16:48.034288 23126066861888 run_lib.py:133] step: 236500, training_loss: 1.90665e-02
I0215 20:16:48.187770 23126066861888 run_lib.py:146] step: 236500, eval_loss: 2.69608e-02
I0215 20:17:05.585107 23126066861888 run_lib.py:133] step: 236550, training_loss: 1.88306e-02
I0215 20:17:22.990199 23126066861888 run_lib.py:133] step: 236600, training_loss: 1.92285e-02
I0215 20:17:23.134792 23126066861888 run_lib.py:146] step: 236600, eval_loss: 2.67248e-02
I0215 20:17:40.636112 23126066861888 run_lib.py:133] step: 236650, training_loss: 1.91823e-02
I0215 20:17:58.076915 23126066861888 run_lib.py:133] step: 236700, training_loss: 1.92386e-02
I0215 20:17:58.240047 23126066861888 run_lib.py:146] step: 236700, eval_loss: 2.69882e-02
I0215 20:18:15.654736 23126066861888 run_lib.py:133] step: 236750, training_loss: 1.90016e-02
I0215 20:18:33.031669 23126066861888 run_lib.py:133] step: 236800, training_loss: 1.90871e-02
I0215 20:18:33.189489 23126066861888 run_lib.py:146] step: 236800, eval_loss: 2.69434e-02
I0215 20:18:50.751640 23126066861888 run_lib.py:133] step: 236850, training_loss: 1.88606e-02
I0215 20:19:08.245414 23126066861888 run_lib.py:133] step: 236900, training_loss: 1.87697e-02
I0215 20:19:08.414123 23126066861888 run_lib.py:146] step: 236900, eval_loss: 2.67697e-02
I0215 20:19:25.830307 23126066861888 run_lib.py:133] step: 236950, training_loss: 1.89495e-02
I0215 20:19:43.246138 23126066861888 run_lib.py:133] step: 237000, training_loss: 1.89858e-02
I0215 20:19:43.399191 23126066861888 run_lib.py:146] step: 237000, eval_loss: 2.65157e-02
I0215 20:20:01.007171 23126066861888 run_lib.py:133] step: 237050, training_loss: 1.98287e-02
I0215 20:20:18.398290 23126066861888 run_lib.py:133] step: 237100, training_loss: 1.90434e-02
I0215 20:20:18.549239 23126066861888 run_lib.py:146] step: 237100, eval_loss: 2.72780e-02
I0215 20:20:35.940989 23126066861888 run_lib.py:133] step: 237150, training_loss: 1.83809e-02
I0215 20:20:53.578296 23126066861888 run_lib.py:133] step: 237200, training_loss: 1.93479e-02
I0215 20:20:53.776285 23126066861888 run_lib.py:146] step: 237200, eval_loss: 2.59631e-02
I0215 20:21:11.222050 23126066861888 run_lib.py:133] step: 237250, training_loss: 1.84185e-02
I0215 20:21:28.857049 23126066861888 run_lib.py:133] step: 237300, training_loss: 1.95494e-02
I0215 20:21:29.014263 23126066861888 run_lib.py:146] step: 237300, eval_loss: 2.64964e-02
I0215 20:21:46.380285 23126066861888 run_lib.py:133] step: 237350, training_loss: 1.87951e-02
I0215 20:22:03.738729 23126066861888 run_lib.py:133] step: 237400, training_loss: 1.88757e-02
I0215 20:22:03.894462 23126066861888 run_lib.py:146] step: 237400, eval_loss: 2.76172e-02
I0215 20:22:21.393756 23126066861888 run_lib.py:133] step: 237450, training_loss: 1.89306e-02
I0215 20:22:38.905587 23126066861888 run_lib.py:133] step: 237500, training_loss: 1.95066e-02
I0215 20:22:39.061550 23126066861888 run_lib.py:146] step: 237500, eval_loss: 2.69225e-02
I0215 20:22:56.447518 23126066861888 run_lib.py:133] step: 237550, training_loss: 1.81417e-02
I0215 20:23:14.056786 23126066861888 run_lib.py:133] step: 237600, training_loss: 1.85845e-02
I0215 20:23:14.209084 23126066861888 run_lib.py:146] step: 237600, eval_loss: 2.73209e-02
I0215 20:23:31.608422 23126066861888 run_lib.py:133] step: 237650, training_loss: 1.88702e-02
I0215 20:23:49.004219 23126066861888 run_lib.py:133] step: 237700, training_loss: 1.99056e-02
I0215 20:23:49.168275 23126066861888 run_lib.py:146] step: 237700, eval_loss: 2.82167e-02
I0215 20:24:06.635438 23126066861888 run_lib.py:133] step: 237750, training_loss: 1.89536e-02
I0215 20:24:24.064053 23126066861888 run_lib.py:133] step: 237800, training_loss: 1.85984e-02
I0215 20:24:24.217031 23126066861888 run_lib.py:146] step: 237800, eval_loss: 2.64882e-02
I0215 20:24:41.613739 23126066861888 run_lib.py:133] step: 237850, training_loss: 1.92846e-02
I0215 20:24:58.964620 23126066861888 run_lib.py:133] step: 237900, training_loss: 1.78158e-02
I0215 20:24:59.125137 23126066861888 run_lib.py:146] step: 237900, eval_loss: 2.78778e-02
I0215 20:25:16.690657 23126066861888 run_lib.py:133] step: 237950, training_loss: 1.88663e-02
I0215 20:25:34.121766 23126066861888 run_lib.py:133] step: 238000, training_loss: 1.94663e-02
I0215 20:25:34.272983 23126066861888 run_lib.py:146] step: 238000, eval_loss: 2.55570e-02
I0215 20:25:51.666602 23126066861888 run_lib.py:133] step: 238050, training_loss: 1.92749e-02
I0215 20:26:09.105390 23126066861888 run_lib.py:133] step: 238100, training_loss: 1.88062e-02
I0215 20:26:09.261247 23126066861888 run_lib.py:146] step: 238100, eval_loss: 2.61868e-02
I0215 20:26:26.902934 23126066861888 run_lib.py:133] step: 238150, training_loss: 1.87018e-02
I0215 20:26:44.327539 23126066861888 run_lib.py:133] step: 238200, training_loss: 1.93316e-02
I0215 20:26:44.483528 23126066861888 run_lib.py:146] step: 238200, eval_loss: 2.73377e-02
I0215 20:27:01.857195 23126066861888 run_lib.py:133] step: 238250, training_loss: 1.88694e-02
I0215 20:27:19.381580 23126066861888 run_lib.py:133] step: 238300, training_loss: 1.97431e-02
I0215 20:27:19.534200 23126066861888 run_lib.py:146] step: 238300, eval_loss: 2.77932e-02
I0215 20:27:36.971118 23126066861888 run_lib.py:133] step: 238350, training_loss: 1.88650e-02
I0215 20:27:54.560974 23126066861888 run_lib.py:133] step: 238400, training_loss: 1.85119e-02
I0215 20:27:54.716487 23126066861888 run_lib.py:146] step: 238400, eval_loss: 2.83527e-02
I0215 20:28:12.123252 23126066861888 run_lib.py:133] step: 238450, training_loss: 1.89348e-02
I0215 20:28:29.494629 23126066861888 run_lib.py:133] step: 238500, training_loss: 1.90701e-02
I0215 20:28:29.645815 23126066861888 run_lib.py:146] step: 238500, eval_loss: 2.59941e-02
I0215 20:28:47.202506 23126066861888 run_lib.py:133] step: 238550, training_loss: 1.83870e-02
I0215 20:29:04.601792 23126066861888 run_lib.py:133] step: 238600, training_loss: 1.80024e-02
I0215 20:29:04.759475 23126066861888 run_lib.py:146] step: 238600, eval_loss: 2.72919e-02
I0215 20:29:22.251610 23126066861888 run_lib.py:133] step: 238650, training_loss: 1.93096e-02
I0215 20:29:39.882789 23126066861888 run_lib.py:133] step: 238700, training_loss: 1.90043e-02
I0215 20:29:40.039169 23126066861888 run_lib.py:146] step: 238700, eval_loss: 2.64835e-02
I0215 20:29:57.439593 23126066861888 run_lib.py:133] step: 238750, training_loss: 1.90482e-02
I0215 20:30:14.834680 23126066861888 run_lib.py:133] step: 238800, training_loss: 1.83821e-02
I0215 20:30:14.993011 23126066861888 run_lib.py:146] step: 238800, eval_loss: 2.76369e-02
I0215 20:30:32.505503 23126066861888 run_lib.py:133] step: 238850, training_loss: 1.87998e-02
I0215 20:30:49.978428 23126066861888 run_lib.py:133] step: 238900, training_loss: 1.84543e-02
I0215 20:30:50.133425 23126066861888 run_lib.py:146] step: 238900, eval_loss: 2.79196e-02
I0215 20:31:07.562887 23126066861888 run_lib.py:133] step: 238950, training_loss: 1.81967e-02
I0215 20:31:25.006440 23126066861888 run_lib.py:133] step: 239000, training_loss: 1.89632e-02
I0215 20:31:25.162325 23126066861888 run_lib.py:146] step: 239000, eval_loss: 2.67208e-02
I0215 20:31:42.726999 23126066861888 run_lib.py:133] step: 239050, training_loss: 1.91537e-02
I0215 20:32:00.196353 23126066861888 run_lib.py:133] step: 239100, training_loss: 1.93078e-02
I0215 20:32:00.351275 23126066861888 run_lib.py:146] step: 239100, eval_loss: 2.96041e-02
I0215 20:32:17.720297 23126066861888 run_lib.py:133] step: 239150, training_loss: 1.86106e-02
I0215 20:32:35.157230 23126066861888 run_lib.py:133] step: 239200, training_loss: 1.88165e-02
I0215 20:32:35.331021 23126066861888 run_lib.py:146] step: 239200, eval_loss: 2.78515e-02
I0215 20:32:52.958327 23126066861888 run_lib.py:133] step: 239250, training_loss: 1.89250e-02
I0215 20:33:10.380408 23126066861888 run_lib.py:133] step: 239300, training_loss: 1.88984e-02
I0215 20:33:10.536307 23126066861888 run_lib.py:146] step: 239300, eval_loss: 2.72764e-02
I0215 20:33:27.918092 23126066861888 run_lib.py:133] step: 239350, training_loss: 1.93160e-02
I0215 20:33:45.432956 23126066861888 run_lib.py:133] step: 239400, training_loss: 1.87714e-02
I0215 20:33:45.585330 23126066861888 run_lib.py:146] step: 239400, eval_loss: 2.73463e-02
I0215 20:34:02.975476 23126066861888 run_lib.py:133] step: 239450, training_loss: 1.85562e-02
I0215 20:34:20.526558 23126066861888 run_lib.py:133] step: 239500, training_loss: 1.83642e-02
I0215 20:34:20.687476 23126066861888 run_lib.py:146] step: 239500, eval_loss: 2.69808e-02
I0215 20:34:38.128608 23126066861888 run_lib.py:133] step: 239550, training_loss: 1.86523e-02
I0215 20:34:55.520419 23126066861888 run_lib.py:133] step: 239600, training_loss: 1.86353e-02
I0215 20:34:55.679066 23126066861888 run_lib.py:146] step: 239600, eval_loss: 2.68999e-02
I0215 20:35:13.249973 23126066861888 run_lib.py:133] step: 239650, training_loss: 1.86572e-02
I0215 20:35:30.658074 23126066861888 run_lib.py:133] step: 239700, training_loss: 1.94446e-02
I0215 20:35:30.817424 23126066861888 run_lib.py:146] step: 239700, eval_loss: 2.81172e-02
I0215 20:35:48.257737 23126066861888 run_lib.py:133] step: 239750, training_loss: 1.85584e-02
I0215 20:36:05.869986 23126066861888 run_lib.py:133] step: 239800, training_loss: 1.86010e-02
I0215 20:36:06.025038 23126066861888 run_lib.py:146] step: 239800, eval_loss: 2.67930e-02
I0215 20:36:23.456408 23126066861888 run_lib.py:133] step: 239850, training_loss: 1.83241e-02
I0215 20:36:40.833794 23126066861888 run_lib.py:133] step: 239900, training_loss: 1.84311e-02
I0215 20:36:40.984222 23126066861888 run_lib.py:146] step: 239900, eval_loss: 2.74560e-02
I0215 20:36:58.486063 23126066861888 run_lib.py:133] step: 239950, training_loss: 1.94715e-02
I0215 20:37:15.945320 23126066861888 run_lib.py:133] step: 240000, training_loss: 1.85011e-02
I0215 20:37:16.657148 23126066861888 run_lib.py:146] step: 240000, eval_loss: 2.70880e-02
I0215 20:37:37.055814 23126066861888 run_lib.py:133] step: 240050, training_loss: 1.85887e-02
I0215 20:37:54.485068 23126066861888 run_lib.py:133] step: 240100, training_loss: 1.88164e-02
I0215 20:37:54.644550 23126066861888 run_lib.py:146] step: 240100, eval_loss: 2.64660e-02
I0215 20:38:12.016360 23126066861888 run_lib.py:133] step: 240150, training_loss: 1.89086e-02
I0215 20:38:29.638311 23126066861888 run_lib.py:133] step: 240200, training_loss: 1.96204e-02
I0215 20:38:29.794294 23126066861888 run_lib.py:146] step: 240200, eval_loss: 2.63214e-02
I0215 20:38:47.253329 23126066861888 run_lib.py:133] step: 240250, training_loss: 1.89793e-02
I0215 20:39:04.625509 23126066861888 run_lib.py:133] step: 240300, training_loss: 1.82312e-02
I0215 20:39:04.786058 23126066861888 run_lib.py:146] step: 240300, eval_loss: 2.60968e-02
I0215 20:39:22.163677 23126066861888 run_lib.py:133] step: 240350, training_loss: 1.85889e-02
I0215 20:39:39.604058 23126066861888 run_lib.py:133] step: 240400, training_loss: 1.91618e-02
I0215 20:39:39.757325 23126066861888 run_lib.py:146] step: 240400, eval_loss: 2.79722e-02
I0215 20:39:57.358656 23126066861888 run_lib.py:133] step: 240450, training_loss: 1.88386e-02
I0215 20:40:14.765447 23126066861888 run_lib.py:133] step: 240500, training_loss: 1.85937e-02
I0215 20:40:14.917296 23126066861888 run_lib.py:146] step: 240500, eval_loss: 2.78248e-02
I0215 20:40:32.471830 23126066861888 run_lib.py:133] step: 240550, training_loss: 1.93801e-02
I0215 20:40:49.874439 23126066861888 run_lib.py:133] step: 240600, training_loss: 1.89859e-02
I0215 20:40:50.027346 23126066861888 run_lib.py:146] step: 240600, eval_loss: 2.74172e-02
I0215 20:41:07.640040 23126066861888 run_lib.py:133] step: 240650, training_loss: 1.87858e-02
I0215 20:41:25.065423 23126066861888 run_lib.py:133] step: 240700, training_loss: 1.86645e-02
I0215 20:41:25.223053 23126066861888 run_lib.py:146] step: 240700, eval_loss: 2.77004e-02
I0215 20:41:42.584003 23126066861888 run_lib.py:133] step: 240750, training_loss: 1.90151e-02
I0215 20:42:00.164679 23126066861888 run_lib.py:133] step: 240800, training_loss: 1.90262e-02
I0215 20:42:00.340198 23126066861888 run_lib.py:146] step: 240800, eval_loss: 2.60860e-02
I0215 20:42:17.717390 23126066861888 run_lib.py:133] step: 240850, training_loss: 1.84551e-02
I0215 20:42:35.242406 23126066861888 run_lib.py:133] step: 240900, training_loss: 1.87496e-02
I0215 20:42:35.398917 23126066861888 run_lib.py:146] step: 240900, eval_loss: 2.71616e-02
I0215 20:42:52.836212 23126066861888 run_lib.py:133] step: 240950, training_loss: 1.88806e-02
I0215 20:43:10.263130 23126066861888 run_lib.py:133] step: 241000, training_loss: 1.90605e-02
I0215 20:43:10.414204 23126066861888 run_lib.py:146] step: 241000, eval_loss: 2.68036e-02
I0215 20:43:27.808280 23126066861888 run_lib.py:133] step: 241050, training_loss: 1.90446e-02
I0215 20:43:45.372202 23126066861888 run_lib.py:133] step: 241100, training_loss: 1.89158e-02
I0215 20:43:45.526685 23126066861888 run_lib.py:146] step: 241100, eval_loss: 2.66030e-02
I0215 20:44:02.855180 23126066861888 run_lib.py:133] step: 241150, training_loss: 1.82592e-02
I0215 20:44:20.222529 23126066861888 run_lib.py:133] step: 241200, training_loss: 1.84933e-02
I0215 20:44:20.389428 23126066861888 run_lib.py:146] step: 241200, eval_loss: 2.66554e-02
I0215 20:44:37.968880 23126066861888 run_lib.py:133] step: 241250, training_loss: 1.86980e-02
I0215 20:44:55.396792 23126066861888 run_lib.py:133] step: 241300, training_loss: 1.88518e-02
I0215 20:44:55.552462 23126066861888 run_lib.py:146] step: 241300, eval_loss: 2.81737e-02
I0215 20:45:13.039115 23126066861888 run_lib.py:133] step: 241350, training_loss: 1.93004e-02
I0215 20:45:30.427739 23126066861888 run_lib.py:133] step: 241400, training_loss: 1.90821e-02
I0215 20:45:30.578680 23126066861888 run_lib.py:146] step: 241400, eval_loss: 2.77540e-02
I0215 20:45:47.958380 23126066861888 run_lib.py:133] step: 241450, training_loss: 1.91386e-02
I0215 20:46:05.391638 23126066861888 run_lib.py:133] step: 241500, training_loss: 1.95231e-02
I0215 20:46:05.549274 23126066861888 run_lib.py:146] step: 241500, eval_loss: 2.58584e-02
I0215 20:46:23.184418 23126066861888 run_lib.py:133] step: 241550, training_loss: 1.86563e-02
I0215 20:46:40.686890 23126066861888 run_lib.py:133] step: 241600, training_loss: 1.88997e-02
I0215 20:46:40.845144 23126066861888 run_lib.py:146] step: 241600, eval_loss: 2.74295e-02
I0215 20:46:58.290278 23126066861888 run_lib.py:133] step: 241650, training_loss: 1.87133e-02
I0215 20:47:15.657123 23126066861888 run_lib.py:133] step: 241700, training_loss: 1.93069e-02
I0215 20:47:15.811206 23126066861888 run_lib.py:146] step: 241700, eval_loss: 2.68427e-02
I0215 20:47:33.349402 23126066861888 run_lib.py:133] step: 241750, training_loss: 1.86686e-02
I0215 20:47:50.794420 23126066861888 run_lib.py:133] step: 241800, training_loss: 1.89356e-02
I0215 20:47:50.953374 23126066861888 run_lib.py:146] step: 241800, eval_loss: 2.59975e-02
I0215 20:48:08.407703 23126066861888 run_lib.py:133] step: 241850, training_loss: 1.87114e-02
I0215 20:48:26.013170 23126066861888 run_lib.py:133] step: 241900, training_loss: 1.81474e-02
I0215 20:48:26.164667 23126066861888 run_lib.py:146] step: 241900, eval_loss: 2.75977e-02
I0215 20:48:43.553900 23126066861888 run_lib.py:133] step: 241950, training_loss: 1.94119e-02
I0215 20:49:01.110155 23126066861888 run_lib.py:133] step: 242000, training_loss: 1.91947e-02
I0215 20:49:01.266059 23126066861888 run_lib.py:146] step: 242000, eval_loss: 2.74101e-02
I0215 20:49:18.684727 23126066861888 run_lib.py:133] step: 242050, training_loss: 1.91143e-02
I0215 20:49:36.133243 23126066861888 run_lib.py:133] step: 242100, training_loss: 1.84993e-02
I0215 20:49:36.292326 23126066861888 run_lib.py:146] step: 242100, eval_loss: 2.62696e-02
I0215 20:49:53.917035 23126066861888 run_lib.py:133] step: 242150, training_loss: 1.90243e-02
I0215 20:50:11.310702 23126066861888 run_lib.py:133] step: 242200, training_loss: 1.89473e-02
I0215 20:50:11.472806 23126066861888 run_lib.py:146] step: 242200, eval_loss: 2.72096e-02
I0215 20:50:28.883552 23126066861888 run_lib.py:133] step: 242250, training_loss: 1.87455e-02
I0215 20:50:46.225277 23126066861888 run_lib.py:133] step: 242300, training_loss: 1.85970e-02
I0215 20:50:46.378055 23126066861888 run_lib.py:146] step: 242300, eval_loss: 2.63116e-02
I0215 20:51:03.934223 23126066861888 run_lib.py:133] step: 242350, training_loss: 1.91678e-02
I0215 20:51:21.425904 23126066861888 run_lib.py:133] step: 242400, training_loss: 1.79881e-02
I0215 20:51:21.589345 23126066861888 run_lib.py:146] step: 242400, eval_loss: 2.75904e-02
I0215 20:51:39.099046 23126066861888 run_lib.py:133] step: 242450, training_loss: 1.82923e-02
I0215 20:51:56.483762 23126066861888 run_lib.py:133] step: 242500, training_loss: 1.81172e-02
I0215 20:51:56.638096 23126066861888 run_lib.py:146] step: 242500, eval_loss: 2.74073e-02
I0215 20:52:13.998104 23126066861888 run_lib.py:133] step: 242550, training_loss: 1.88508e-02
I0215 20:52:31.351946 23126066861888 run_lib.py:133] step: 242600, training_loss: 1.87022e-02
I0215 20:52:31.512321 23126066861888 run_lib.py:146] step: 242600, eval_loss: 2.74312e-02
I0215 20:52:49.065506 23126066861888 run_lib.py:133] step: 242650, training_loss: 1.92886e-02
I0215 20:53:06.582682 23126066861888 run_lib.py:133] step: 242700, training_loss: 1.90016e-02
I0215 20:53:06.737230 23126066861888 run_lib.py:146] step: 242700, eval_loss: 2.70199e-02
I0215 20:53:24.176091 23126066861888 run_lib.py:133] step: 242750, training_loss: 1.84759e-02
I0215 20:53:41.537380 23126066861888 run_lib.py:133] step: 242800, training_loss: 1.88873e-02
I0215 20:53:41.694264 23126066861888 run_lib.py:146] step: 242800, eval_loss: 2.57246e-02
I0215 20:53:59.252892 23126066861888 run_lib.py:133] step: 242850, training_loss: 1.91919e-02
I0215 20:54:16.628041 23126066861888 run_lib.py:133] step: 242900, training_loss: 1.91195e-02
I0215 20:54:16.780193 23126066861888 run_lib.py:146] step: 242900, eval_loss: 2.61234e-02
I0215 20:54:34.162192 23126066861888 run_lib.py:133] step: 242950, training_loss: 1.85981e-02
I0215 20:54:51.772459 23126066861888 run_lib.py:133] step: 243000, training_loss: 1.82557e-02
I0215 20:54:51.942265 23126066861888 run_lib.py:146] step: 243000, eval_loss: 2.66377e-02
I0215 20:55:09.364123 23126066861888 run_lib.py:133] step: 243050, training_loss: 1.95715e-02
I0215 20:55:26.956436 23126066861888 run_lib.py:133] step: 243100, training_loss: 1.93280e-02
I0215 20:55:27.126425 23126066861888 run_lib.py:146] step: 243100, eval_loss: 2.73573e-02
I0215 20:55:44.524817 23126066861888 run_lib.py:133] step: 243150, training_loss: 1.88234e-02
I0215 20:56:01.856473 23126066861888 run_lib.py:133] step: 243200, training_loss: 2.02372e-02
I0215 20:56:02.007718 23126066861888 run_lib.py:146] step: 243200, eval_loss: 2.69937e-02
I0215 20:56:19.529331 23126066861888 run_lib.py:133] step: 243250, training_loss: 1.87695e-02
I0215 20:56:36.966594 23126066861888 run_lib.py:133] step: 243300, training_loss: 1.95554e-02
I0215 20:56:37.119466 23126066861888 run_lib.py:146] step: 243300, eval_loss: 2.68832e-02
I0215 20:56:54.585717 23126066861888 run_lib.py:133] step: 243350, training_loss: 1.82949e-02
I0215 20:57:12.139567 23126066861888 run_lib.py:133] step: 243400, training_loss: 1.91154e-02
I0215 20:57:12.288027 23126066861888 run_lib.py:146] step: 243400, eval_loss: 2.65175e-02
I0215 20:57:29.657643 23126066861888 run_lib.py:133] step: 243450, training_loss: 1.83134e-02
I0215 20:57:47.020825 23126066861888 run_lib.py:133] step: 243500, training_loss: 1.93508e-02
I0215 20:57:47.182601 23126066861888 run_lib.py:146] step: 243500, eval_loss: 2.71174e-02
I0215 20:58:04.663544 23126066861888 run_lib.py:133] step: 243550, training_loss: 1.90591e-02
I0215 20:58:22.091698 23126066861888 run_lib.py:133] step: 243600, training_loss: 1.85348e-02
I0215 20:58:22.246543 23126066861888 run_lib.py:146] step: 243600, eval_loss: 2.54202e-02
I0215 20:58:39.686356 23126066861888 run_lib.py:133] step: 243650, training_loss: 1.80865e-02
I0215 20:58:57.110414 23126066861888 run_lib.py:133] step: 243700, training_loss: 1.86970e-02
I0215 20:58:57.271399 23126066861888 run_lib.py:146] step: 243700, eval_loss: 2.70310e-02
I0215 20:59:14.839476 23126066861888 run_lib.py:133] step: 243750, training_loss: 1.93368e-02
I0215 20:59:32.300715 23126066861888 run_lib.py:133] step: 243800, training_loss: 1.88509e-02
I0215 20:59:32.447942 23126066861888 run_lib.py:146] step: 243800, eval_loss: 2.70139e-02
I0215 20:59:49.834685 23126066861888 run_lib.py:133] step: 243850, training_loss: 1.86227e-02
I0215 21:00:07.271246 23126066861888 run_lib.py:133] step: 243900, training_loss: 1.85532e-02
I0215 21:00:07.438300 23126066861888 run_lib.py:146] step: 243900, eval_loss: 2.84396e-02
I0215 21:00:25.037186 23126066861888 run_lib.py:133] step: 243950, training_loss: 1.84400e-02
I0215 21:00:42.452517 23126066861888 run_lib.py:133] step: 244000, training_loss: 1.96543e-02
I0215 21:00:42.631756 23126066861888 run_lib.py:146] step: 244000, eval_loss: 2.64158e-02
I0215 21:01:00.046693 23126066861888 run_lib.py:133] step: 244050, training_loss: 1.86141e-02
I0215 21:01:17.578837 23126066861888 run_lib.py:133] step: 244100, training_loss: 1.85160e-02
I0215 21:01:17.736322 23126066861888 run_lib.py:146] step: 244100, eval_loss: 2.61092e-02
I0215 21:01:35.102034 23126066861888 run_lib.py:133] step: 244150, training_loss: 1.88669e-02
I0215 21:01:52.675817 23126066861888 run_lib.py:133] step: 244200, training_loss: 1.87349e-02
I0215 21:01:52.830068 23126066861888 run_lib.py:146] step: 244200, eval_loss: 2.63862e-02
I0215 21:02:10.233507 23126066861888 run_lib.py:133] step: 244250, training_loss: 1.90646e-02
I0215 21:02:27.601686 23126066861888 run_lib.py:133] step: 244300, training_loss: 1.88229e-02
I0215 21:02:27.753250 23126066861888 run_lib.py:146] step: 244300, eval_loss: 2.69198e-02
I0215 21:02:45.380071 23126066861888 run_lib.py:133] step: 244350, training_loss: 1.93188e-02
I0215 21:03:02.783494 23126066861888 run_lib.py:133] step: 244400, training_loss: 1.89275e-02
I0215 21:03:02.939271 23126066861888 run_lib.py:146] step: 244400, eval_loss: 2.67552e-02
I0215 21:03:20.375959 23126066861888 run_lib.py:133] step: 244450, training_loss: 1.95090e-02
I0215 21:03:38.047560 23126066861888 run_lib.py:133] step: 244500, training_loss: 1.86698e-02
I0215 21:03:38.204004 23126066861888 run_lib.py:146] step: 244500, eval_loss: 2.73219e-02
I0215 21:03:55.634571 23126066861888 run_lib.py:133] step: 244550, training_loss: 1.87963e-02
I0215 21:04:13.096854 23126066861888 run_lib.py:133] step: 244600, training_loss: 1.75627e-02
I0215 21:04:13.254334 23126066861888 run_lib.py:146] step: 244600, eval_loss: 2.82131e-02
I0215 21:04:30.691744 23126066861888 run_lib.py:133] step: 244650, training_loss: 1.91228e-02
I0215 21:04:48.093146 23126066861888 run_lib.py:133] step: 244700, training_loss: 1.92334e-02
I0215 21:04:48.249246 23126066861888 run_lib.py:146] step: 244700, eval_loss: 2.66569e-02
I0215 21:05:05.675612 23126066861888 run_lib.py:133] step: 244750, training_loss: 1.86139e-02
I0215 21:05:23.118082 23126066861888 run_lib.py:133] step: 244800, training_loss: 1.80283e-02
I0215 21:05:23.287258 23126066861888 run_lib.py:146] step: 244800, eval_loss: 2.77004e-02
I0215 21:05:40.911457 23126066861888 run_lib.py:133] step: 244850, training_loss: 1.87890e-02
I0215 21:05:58.400522 23126066861888 run_lib.py:133] step: 244900, training_loss: 1.82680e-02
I0215 21:05:58.557311 23126066861888 run_lib.py:146] step: 244900, eval_loss: 2.77607e-02
I0215 21:06:15.954081 23126066861888 run_lib.py:133] step: 244950, training_loss: 1.89474e-02
I0215 21:06:33.296470 23126066861888 run_lib.py:133] step: 245000, training_loss: 1.94460e-02
I0215 21:06:33.454097 23126066861888 run_lib.py:146] step: 245000, eval_loss: 2.75169e-02
I0215 21:06:50.981466 23126066861888 run_lib.py:133] step: 245050, training_loss: 1.83763e-02
I0215 21:07:08.430069 23126066861888 run_lib.py:133] step: 245100, training_loss: 1.88438e-02
I0215 21:07:08.587663 23126066861888 run_lib.py:146] step: 245100, eval_loss: 2.67947e-02
I0215 21:07:25.983369 23126066861888 run_lib.py:133] step: 245150, training_loss: 1.94808e-02
I0215 21:07:43.523400 23126066861888 run_lib.py:133] step: 245200, training_loss: 1.80902e-02
I0215 21:07:43.675326 23126066861888 run_lib.py:146] step: 245200, eval_loss: 2.76312e-02
I0215 21:08:01.069994 23126066861888 run_lib.py:133] step: 245250, training_loss: 1.92050e-02
I0215 21:08:18.673133 23126066861888 run_lib.py:133] step: 245300, training_loss: 1.95287e-02
I0215 21:08:18.825877 23126066861888 run_lib.py:146] step: 245300, eval_loss: 2.62628e-02
I0215 21:08:36.229447 23126066861888 run_lib.py:133] step: 245350, training_loss: 1.89850e-02
I0215 21:08:53.629885 23126066861888 run_lib.py:133] step: 245400, training_loss: 1.88385e-02
I0215 21:08:53.786149 23126066861888 run_lib.py:146] step: 245400, eval_loss: 2.70136e-02
I0215 21:09:11.370151 23126066861888 run_lib.py:133] step: 245450, training_loss: 1.91097e-02
I0215 21:09:28.783045 23126066861888 run_lib.py:133] step: 245500, training_loss: 1.85745e-02
I0215 21:09:28.948332 23126066861888 run_lib.py:146] step: 245500, eval_loss: 2.68440e-02
I0215 21:09:46.305678 23126066861888 run_lib.py:133] step: 245550, training_loss: 1.79434e-02
I0215 21:10:03.793999 23126066861888 run_lib.py:133] step: 245600, training_loss: 1.90028e-02
I0215 21:10:03.966283 23126066861888 run_lib.py:146] step: 245600, eval_loss: 2.62825e-02
I0215 21:10:21.378784 23126066861888 run_lib.py:133] step: 245650, training_loss: 1.87857e-02
I0215 21:10:38.801027 23126066861888 run_lib.py:133] step: 245700, training_loss: 1.92636e-02
I0215 21:10:38.959980 23126066861888 run_lib.py:146] step: 245700, eval_loss: 2.78937e-02
I0215 21:10:56.450731 23126066861888 run_lib.py:133] step: 245750, training_loss: 1.88372e-02
I0215 21:11:13.852322 23126066861888 run_lib.py:133] step: 245800, training_loss: 1.90376e-02
I0215 21:11:14.008072 23126066861888 run_lib.py:146] step: 245800, eval_loss: 2.68121e-02
I0215 21:11:31.385348 23126066861888 run_lib.py:133] step: 245850, training_loss: 1.86481e-02
I0215 21:11:48.785632 23126066861888 run_lib.py:133] step: 245900, training_loss: 1.87309e-02
I0215 21:11:48.957985 23126066861888 run_lib.py:146] step: 245900, eval_loss: 2.78341e-02
I0215 21:12:06.644515 23126066861888 run_lib.py:133] step: 245950, training_loss: 1.83424e-02
I0215 21:12:24.159736 23126066861888 run_lib.py:133] step: 246000, training_loss: 1.86586e-02
I0215 21:12:24.320277 23126066861888 run_lib.py:146] step: 246000, eval_loss: 2.60552e-02
I0215 21:12:41.756642 23126066861888 run_lib.py:133] step: 246050, training_loss: 1.83436e-02
I0215 21:12:59.128716 23126066861888 run_lib.py:133] step: 246100, training_loss: 1.86944e-02
I0215 21:12:59.282030 23126066861888 run_lib.py:146] step: 246100, eval_loss: 2.71338e-02
I0215 21:13:16.826169 23126066861888 run_lib.py:133] step: 246150, training_loss: 1.84180e-02
I0215 21:13:34.232184 23126066861888 run_lib.py:133] step: 246200, training_loss: 1.89486e-02
I0215 21:13:34.386307 23126066861888 run_lib.py:146] step: 246200, eval_loss: 2.77232e-02
I0215 21:13:51.815840 23126066861888 run_lib.py:133] step: 246250, training_loss: 1.85427e-02
I0215 21:14:09.406133 23126066861888 run_lib.py:133] step: 246300, training_loss: 1.95728e-02
I0215 21:14:09.563317 23126066861888 run_lib.py:146] step: 246300, eval_loss: 2.73756e-02
I0215 21:14:26.927202 23126066861888 run_lib.py:133] step: 246350, training_loss: 1.87891e-02
I0215 21:14:44.454864 23126066861888 run_lib.py:133] step: 246400, training_loss: 1.95093e-02
I0215 21:14:44.611644 23126066861888 run_lib.py:146] step: 246400, eval_loss: 2.77526e-02
I0215 21:15:02.030540 23126066861888 run_lib.py:133] step: 246450, training_loss: 1.85194e-02
I0215 21:15:19.458746 23126066861888 run_lib.py:133] step: 246500, training_loss: 1.86120e-02
I0215 21:15:19.614198 23126066861888 run_lib.py:146] step: 246500, eval_loss: 2.64927e-02
I0215 21:15:37.156587 23126066861888 run_lib.py:133] step: 246550, training_loss: 1.88893e-02
I0215 21:15:54.558048 23126066861888 run_lib.py:133] step: 246600, training_loss: 1.87838e-02
I0215 21:15:54.711056 23126066861888 run_lib.py:146] step: 246600, eval_loss: 2.64851e-02
I0215 21:16:12.139076 23126066861888 run_lib.py:133] step: 246650, training_loss: 1.87602e-02
I0215 21:16:29.705474 23126066861888 run_lib.py:133] step: 246700, training_loss: 1.87247e-02
I0215 21:16:29.857215 23126066861888 run_lib.py:146] step: 246700, eval_loss: 2.74593e-02
I0215 21:16:47.340968 23126066861888 run_lib.py:133] step: 246750, training_loss: 1.87852e-02
I0215 21:17:04.777566 23126066861888 run_lib.py:133] step: 246800, training_loss: 1.91489e-02
I0215 21:17:04.935279 23126066861888 run_lib.py:146] step: 246800, eval_loss: 2.61962e-02
I0215 21:17:22.470613 23126066861888 run_lib.py:133] step: 246850, training_loss: 1.91285e-02
I0215 21:17:39.857112 23126066861888 run_lib.py:133] step: 246900, training_loss: 1.91273e-02
I0215 21:17:40.009325 23126066861888 run_lib.py:146] step: 246900, eval_loss: 2.71490e-02
I0215 21:17:57.416169 23126066861888 run_lib.py:133] step: 246950, training_loss: 1.83415e-02
I0215 21:18:14.774247 23126066861888 run_lib.py:133] step: 247000, training_loss: 1.89821e-02
I0215 21:18:14.933033 23126066861888 run_lib.py:146] step: 247000, eval_loss: 2.84265e-02
I0215 21:18:32.469057 23126066861888 run_lib.py:133] step: 247050, training_loss: 1.90214e-02
I0215 21:18:50.006194 23126066861888 run_lib.py:133] step: 247100, training_loss: 1.85769e-02
I0215 21:18:50.157595 23126066861888 run_lib.py:146] step: 247100, eval_loss: 2.81614e-02
I0215 21:19:07.596761 23126066861888 run_lib.py:133] step: 247150, training_loss: 1.88322e-02
I0215 21:19:24.996480 23126066861888 run_lib.py:133] step: 247200, training_loss: 1.90217e-02
I0215 21:19:25.387842 23126066861888 run_lib.py:146] step: 247200, eval_loss: 2.59607e-02
I0215 21:19:42.899651 23126066861888 run_lib.py:133] step: 247250, training_loss: 1.89634e-02
I0215 21:20:00.307742 23126066861888 run_lib.py:133] step: 247300, training_loss: 1.88822e-02
I0215 21:20:00.465250 23126066861888 run_lib.py:146] step: 247300, eval_loss: 2.70787e-02
I0215 21:20:17.846652 23126066861888 run_lib.py:133] step: 247350, training_loss: 1.97228e-02
I0215 21:20:35.429419 23126066861888 run_lib.py:133] step: 247400, training_loss: 1.86626e-02
I0215 21:20:35.584393 23126066861888 run_lib.py:146] step: 247400, eval_loss: 2.65646e-02
I0215 21:20:53.009472 23126066861888 run_lib.py:133] step: 247450, training_loss: 1.83085e-02
I0215 21:21:10.619122 23126066861888 run_lib.py:133] step: 247500, training_loss: 1.83404e-02
I0215 21:21:10.773184 23126066861888 run_lib.py:146] step: 247500, eval_loss: 2.73662e-02
I0215 21:21:28.271955 23126066861888 run_lib.py:133] step: 247550, training_loss: 1.84718e-02
I0215 21:21:45.650514 23126066861888 run_lib.py:133] step: 247600, training_loss: 1.83625e-02
I0215 21:21:45.800992 23126066861888 run_lib.py:146] step: 247600, eval_loss: 2.74039e-02
I0215 21:22:03.343677 23126066861888 run_lib.py:133] step: 247650, training_loss: 1.88515e-02
I0215 21:22:20.782770 23126066861888 run_lib.py:133] step: 247700, training_loss: 1.83151e-02
I0215 21:22:20.949421 23126066861888 run_lib.py:146] step: 247700, eval_loss: 2.83410e-02
I0215 21:22:38.338025 23126066861888 run_lib.py:133] step: 247750, training_loss: 1.89240e-02
I0215 21:22:55.914416 23126066861888 run_lib.py:133] step: 247800, training_loss: 1.86216e-02
I0215 21:22:56.071178 23126066861888 run_lib.py:146] step: 247800, eval_loss: 2.63222e-02
I0215 21:23:13.456123 23126066861888 run_lib.py:133] step: 247850, training_loss: 1.90362e-02
I0215 21:23:30.821529 23126066861888 run_lib.py:133] step: 247900, training_loss: 1.87566e-02
I0215 21:23:30.976248 23126066861888 run_lib.py:146] step: 247900, eval_loss: 2.67682e-02
I0215 21:23:48.385667 23126066861888 run_lib.py:133] step: 247950, training_loss: 1.97602e-02
I0215 21:24:05.787237 23126066861888 run_lib.py:133] step: 248000, training_loss: 1.85036e-02
I0215 21:24:05.943854 23126066861888 run_lib.py:146] step: 248000, eval_loss: 2.81242e-02
I0215 21:24:23.343598 23126066861888 run_lib.py:133] step: 248050, training_loss: 1.94063e-02
I0215 21:24:40.703681 23126066861888 run_lib.py:133] step: 248100, training_loss: 1.86635e-02
I0215 21:24:40.863419 23126066861888 run_lib.py:146] step: 248100, eval_loss: 2.81116e-02
I0215 21:24:58.405211 23126066861888 run_lib.py:133] step: 248150, training_loss: 1.83916e-02
I0215 21:25:15.872494 23126066861888 run_lib.py:133] step: 248200, training_loss: 1.84828e-02
I0215 21:25:16.034621 23126066861888 run_lib.py:146] step: 248200, eval_loss: 2.67371e-02
I0215 21:25:33.402574 23126066861888 run_lib.py:133] step: 248250, training_loss: 1.88857e-02
I0215 21:25:50.861712 23126066861888 run_lib.py:133] step: 248300, training_loss: 1.93514e-02
I0215 21:25:51.019176 23126066861888 run_lib.py:146] step: 248300, eval_loss: 2.61640e-02
I0215 21:26:08.602896 23126066861888 run_lib.py:133] step: 248350, training_loss: 1.84708e-02
I0215 21:26:26.015835 23126066861888 run_lib.py:133] step: 248400, training_loss: 1.87353e-02
I0215 21:26:26.170261 23126066861888 run_lib.py:146] step: 248400, eval_loss: 2.63421e-02
I0215 21:26:43.532606 23126066861888 run_lib.py:133] step: 248450, training_loss: 1.85478e-02
I0215 21:27:01.095272 23126066861888 run_lib.py:133] step: 248500, training_loss: 1.85731e-02
I0215 21:27:01.246756 23126066861888 run_lib.py:146] step: 248500, eval_loss: 2.80949e-02
I0215 21:27:18.634386 23126066861888 run_lib.py:133] step: 248550, training_loss: 1.91009e-02
I0215 21:27:36.259687 23126066861888 run_lib.py:133] step: 248600, training_loss: 1.94543e-02
I0215 21:27:36.417450 23126066861888 run_lib.py:146] step: 248600, eval_loss: 2.75733e-02
I0215 21:27:53.833602 23126066861888 run_lib.py:133] step: 248650, training_loss: 1.82204e-02
I0215 21:28:11.257305 23126066861888 run_lib.py:133] step: 248700, training_loss: 1.96603e-02
I0215 21:28:11.413468 23126066861888 run_lib.py:146] step: 248700, eval_loss: 2.70688e-02
I0215 21:28:28.935630 23126066861888 run_lib.py:133] step: 248750, training_loss: 1.87452e-02
I0215 21:28:46.344273 23126066861888 run_lib.py:133] step: 248800, training_loss: 1.82799e-02
I0215 21:28:46.507814 23126066861888 run_lib.py:146] step: 248800, eval_loss: 2.76157e-02
I0215 21:29:03.915807 23126066861888 run_lib.py:133] step: 248850, training_loss: 1.88616e-02
I0215 21:29:21.513490 23126066861888 run_lib.py:133] step: 248900, training_loss: 1.91718e-02
I0215 21:29:21.667352 23126066861888 run_lib.py:146] step: 248900, eval_loss: 2.62022e-02
I0215 21:29:39.083224 23126066861888 run_lib.py:133] step: 248950, training_loss: 1.88708e-02
I0215 21:29:56.453296 23126066861888 run_lib.py:133] step: 249000, training_loss: 1.89234e-02
I0215 21:29:56.610156 23126066861888 run_lib.py:146] step: 249000, eval_loss: 2.70554e-02
I0215 21:30:14.055296 23126066861888 run_lib.py:133] step: 249050, training_loss: 1.92406e-02
I0215 21:30:31.440217 23126066861888 run_lib.py:133] step: 249100, training_loss: 1.87337e-02
I0215 21:30:31.604312 23126066861888 run_lib.py:146] step: 249100, eval_loss: 2.68682e-02
I0215 21:30:48.991282 23126066861888 run_lib.py:133] step: 249150, training_loss: 1.92284e-02
I0215 21:31:06.459346 23126066861888 run_lib.py:133] step: 249200, training_loss: 1.85375e-02
I0215 21:31:06.616130 23126066861888 run_lib.py:146] step: 249200, eval_loss: 2.72244e-02
I0215 21:31:24.158060 23126066861888 run_lib.py:133] step: 249250, training_loss: 1.91416e-02
I0215 21:31:41.557999 23126066861888 run_lib.py:133] step: 249300, training_loss: 1.88178e-02
I0215 21:31:41.712172 23126066861888 run_lib.py:146] step: 249300, eval_loss: 2.62941e-02
I0215 21:31:59.073830 23126066861888 run_lib.py:133] step: 249350, training_loss: 1.99894e-02
I0215 21:32:16.454348 23126066861888 run_lib.py:133] step: 249400, training_loss: 1.84943e-02
I0215 21:32:16.606055 23126066861888 run_lib.py:146] step: 249400, eval_loss: 2.78018e-02
I0215 21:32:34.119053 23126066861888 run_lib.py:133] step: 249450, training_loss: 1.90473e-02
I0215 21:32:51.550599 23126066861888 run_lib.py:133] step: 249500, training_loss: 1.85893e-02
I0215 21:32:51.706314 23126066861888 run_lib.py:146] step: 249500, eval_loss: 2.76628e-02
I0215 21:33:09.121405 23126066861888 run_lib.py:133] step: 249550, training_loss: 1.88531e-02
I0215 21:33:26.732413 23126066861888 run_lib.py:133] step: 249600, training_loss: 1.92972e-02
I0215 21:33:26.894376 23126066861888 run_lib.py:146] step: 249600, eval_loss: 2.72249e-02
I0215 21:33:44.278958 23126066861888 run_lib.py:133] step: 249650, training_loss: 1.79182e-02
I0215 21:34:01.806188 23126066861888 run_lib.py:133] step: 249700, training_loss: 1.91745e-02
I0215 21:34:01.966126 23126066861888 run_lib.py:146] step: 249700, eval_loss: 2.69704e-02
I0215 21:34:19.375589 23126066861888 run_lib.py:133] step: 249750, training_loss: 1.89684e-02
I0215 21:34:36.804960 23126066861888 run_lib.py:133] step: 249800, training_loss: 1.89223e-02
I0215 21:34:36.956959 23126066861888 run_lib.py:146] step: 249800, eval_loss: 2.71893e-02
I0215 21:34:54.526779 23126066861888 run_lib.py:133] step: 249850, training_loss: 1.93980e-02
I0215 21:35:11.914122 23126066861888 run_lib.py:133] step: 249900, training_loss: 1.82818e-02
I0215 21:35:12.065981 23126066861888 run_lib.py:146] step: 249900, eval_loss: 2.71389e-02
I0215 21:35:29.425017 23126066861888 run_lib.py:133] step: 249950, training_loss: 1.88761e-02
I0215 21:35:46.981850 23126066861888 run_lib.py:133] step: 250000, training_loss: 1.89187e-02
I0215 21:35:48.201067 23126066861888 run_lib.py:146] step: 250000, eval_loss: 2.62215e-02
I0215 21:36:08.264836 23126066861888 run_lib.py:133] step: 250050, training_loss: 1.90436e-02
I0215 21:36:25.672017 23126066861888 run_lib.py:133] step: 250100, training_loss: 1.86200e-02
I0215 21:36:25.824139 23126066861888 run_lib.py:146] step: 250100, eval_loss: 2.66106e-02
I0215 21:36:43.211057 23126066861888 run_lib.py:133] step: 250150, training_loss: 1.84691e-02
I0215 21:37:00.830792 23126066861888 run_lib.py:133] step: 250200, training_loss: 1.89402e-02
I0215 21:37:00.990613 23126066861888 run_lib.py:146] step: 250200, eval_loss: 2.74310e-02
I0215 21:37:18.384119 23126066861888 run_lib.py:133] step: 250250, training_loss: 1.87988e-02
I0215 21:37:35.793111 23126066861888 run_lib.py:133] step: 250300, training_loss: 1.87888e-02
I0215 21:37:35.955354 23126066861888 run_lib.py:146] step: 250300, eval_loss: 2.69128e-02
I0215 21:37:53.445173 23126066861888 run_lib.py:133] step: 250350, training_loss: 1.89592e-02
I0215 21:38:11.060245 23126066861888 run_lib.py:133] step: 250400, training_loss: 1.94241e-02
I0215 21:38:11.212306 23126066861888 run_lib.py:146] step: 250400, eval_loss: 2.71879e-02
I0215 21:38:28.682924 23126066861888 run_lib.py:133] step: 250450, training_loss: 1.84281e-02
I0215 21:38:46.069714 23126066861888 run_lib.py:133] step: 250500, training_loss: 1.83363e-02
I0215 21:38:46.218778 23126066861888 run_lib.py:146] step: 250500, eval_loss: 2.73517e-02
I0215 21:39:03.576562 23126066861888 run_lib.py:133] step: 250550, training_loss: 1.90764e-02
I0215 21:39:21.017179 23126066861888 run_lib.py:133] step: 250600, training_loss: 1.90876e-02
I0215 21:39:21.180324 23126066861888 run_lib.py:146] step: 250600, eval_loss: 2.69147e-02
I0215 21:39:38.783120 23126066861888 run_lib.py:133] step: 250650, training_loss: 1.82118e-02
I0215 21:39:56.178686 23126066861888 run_lib.py:133] step: 250700, training_loss: 1.82212e-02
I0215 21:39:56.335460 23126066861888 run_lib.py:146] step: 250700, eval_loss: 2.62094e-02
I0215 21:40:13.870901 23126066861888 run_lib.py:133] step: 250750, training_loss: 1.92769e-02
I0215 21:40:31.261850 23126066861888 run_lib.py:133] step: 250800, training_loss: 1.89863e-02
I0215 21:40:31.423020 23126066861888 run_lib.py:146] step: 250800, eval_loss: 2.63303e-02
I0215 21:40:48.936398 23126066861888 run_lib.py:133] step: 250850, training_loss: 1.84612e-02
I0215 21:41:06.389143 23126066861888 run_lib.py:133] step: 250900, training_loss: 1.85711e-02
I0215 21:41:06.551390 23126066861888 run_lib.py:146] step: 250900, eval_loss: 2.66697e-02
I0215 21:41:24.007460 23126066861888 run_lib.py:133] step: 250950, training_loss: 1.89255e-02
I0215 21:41:41.566812 23126066861888 run_lib.py:133] step: 251000, training_loss: 1.88417e-02
I0215 21:41:41.717928 23126066861888 run_lib.py:146] step: 251000, eval_loss: 2.65085e-02
I0215 21:41:59.127130 23126066861888 run_lib.py:133] step: 251050, training_loss: 1.92901e-02
I0215 21:42:16.658443 23126066861888 run_lib.py:133] step: 251100, training_loss: 1.93063e-02
I0215 21:42:16.816246 23126066861888 run_lib.py:146] step: 251100, eval_loss: 2.70434e-02
I0215 21:42:34.267838 23126066861888 run_lib.py:133] step: 251150, training_loss: 1.81165e-02
I0215 21:42:51.686570 23126066861888 run_lib.py:133] step: 251200, training_loss: 1.76765e-02
I0215 21:42:51.844296 23126066861888 run_lib.py:146] step: 251200, eval_loss: 2.64079e-02
I0215 21:43:09.277613 23126066861888 run_lib.py:133] step: 251250, training_loss: 1.84225e-02
I0215 21:43:26.804939 23126066861888 run_lib.py:133] step: 251300, training_loss: 1.74891e-02
I0215 21:43:26.962984 23126066861888 run_lib.py:146] step: 251300, eval_loss: 2.68876e-02
I0215 21:43:44.356853 23126066861888 run_lib.py:133] step: 251350, training_loss: 1.88820e-02
I0215 21:44:01.738950 23126066861888 run_lib.py:133] step: 251400, training_loss: 1.85107e-02
I0215 21:44:01.889104 23126066861888 run_lib.py:146] step: 251400, eval_loss: 2.78465e-02
I0215 21:44:19.479169 23126066861888 run_lib.py:133] step: 251450, training_loss: 1.87132e-02
I0215 21:44:36.911069 23126066861888 run_lib.py:133] step: 251500, training_loss: 1.83119e-02
I0215 21:44:37.066315 23126066861888 run_lib.py:146] step: 251500, eval_loss: 2.71346e-02
I0215 21:44:54.644707 23126066861888 run_lib.py:133] step: 251550, training_loss: 1.92250e-02
I0215 21:45:12.065743 23126066861888 run_lib.py:133] step: 251600, training_loss: 1.77208e-02
I0215 21:45:12.222654 23126066861888 run_lib.py:146] step: 251600, eval_loss: 2.75813e-02
I0215 21:45:29.597352 23126066861888 run_lib.py:133] step: 251650, training_loss: 1.86919e-02
I0215 21:45:46.957433 23126066861888 run_lib.py:133] step: 251700, training_loss: 1.78760e-02
I0215 21:45:47.114553 23126066861888 run_lib.py:146] step: 251700, eval_loss: 2.73718e-02
I0215 21:46:04.646777 23126066861888 run_lib.py:133] step: 251750, training_loss: 1.91883e-02
I0215 21:46:22.184711 23126066861888 run_lib.py:133] step: 251800, training_loss: 1.83134e-02
I0215 21:46:22.338886 23126066861888 run_lib.py:146] step: 251800, eval_loss: 2.67596e-02
I0215 21:46:39.701422 23126066861888 run_lib.py:133] step: 251850, training_loss: 1.91440e-02
I0215 21:46:57.099456 23126066861888 run_lib.py:133] step: 251900, training_loss: 1.77090e-02
I0215 21:46:57.255004 23126066861888 run_lib.py:146] step: 251900, eval_loss: 2.73300e-02
I0215 21:47:14.803241 23126066861888 run_lib.py:133] step: 251950, training_loss: 1.95417e-02
I0215 21:47:32.208008 23126066861888 run_lib.py:133] step: 252000, training_loss: 1.84865e-02
I0215 21:47:32.364979 23126066861888 run_lib.py:146] step: 252000, eval_loss: 2.81922e-02
I0215 21:47:49.757704 23126066861888 run_lib.py:133] step: 252050, training_loss: 1.87591e-02
I0215 21:48:07.331537 23126066861888 run_lib.py:133] step: 252100, training_loss: 1.89453e-02
I0215 21:48:07.489359 23126066861888 run_lib.py:146] step: 252100, eval_loss: 2.67493e-02
I0215 21:48:24.856734 23126066861888 run_lib.py:133] step: 252150, training_loss: 1.88828e-02
I0215 21:48:42.413064 23126066861888 run_lib.py:133] step: 252200, training_loss: 1.80711e-02
I0215 21:48:42.567025 23126066861888 run_lib.py:146] step: 252200, eval_loss: 2.67795e-02
I0215 21:48:59.969476 23126066861888 run_lib.py:133] step: 252250, training_loss: 1.89822e-02
I0215 21:49:17.328185 23126066861888 run_lib.py:133] step: 252300, training_loss: 1.87679e-02
I0215 21:49:17.481266 23126066861888 run_lib.py:146] step: 252300, eval_loss: 2.56436e-02
I0215 21:49:35.066373 23126066861888 run_lib.py:133] step: 252350, training_loss: 1.80483e-02
I0215 21:49:52.467957 23126066861888 run_lib.py:133] step: 252400, training_loss: 1.90206e-02
I0215 21:49:52.616374 23126066861888 run_lib.py:146] step: 252400, eval_loss: 2.68797e-02
I0215 21:50:09.990301 23126066861888 run_lib.py:133] step: 252450, training_loss: 1.91770e-02
I0215 21:50:27.373512 23126066861888 run_lib.py:133] step: 252500, training_loss: 1.90544e-02
I0215 21:50:27.528165 23126066861888 run_lib.py:146] step: 252500, eval_loss: 2.76186e-02
I0215 21:50:45.161314 23126066861888 run_lib.py:133] step: 252550, training_loss: 1.82350e-02
I0215 21:51:02.570547 23126066861888 run_lib.py:133] step: 252600, training_loss: 1.84902e-02
I0215 21:51:02.728291 23126066861888 run_lib.py:146] step: 252600, eval_loss: 2.77149e-02
I0215 21:51:20.207032 23126066861888 run_lib.py:133] step: 252650, training_loss: 1.83775e-02
I0215 21:51:37.678721 23126066861888 run_lib.py:133] step: 252700, training_loss: 1.91055e-02
I0215 21:51:37.837145 23126066861888 run_lib.py:146] step: 252700, eval_loss: 2.65344e-02
I0215 21:51:55.218244 23126066861888 run_lib.py:133] step: 252750, training_loss: 1.86869e-02
I0215 21:52:12.629169 23126066861888 run_lib.py:133] step: 252800, training_loss: 1.89985e-02
I0215 21:52:12.782082 23126066861888 run_lib.py:146] step: 252800, eval_loss: 2.60885e-02
I0215 21:52:30.349948 23126066861888 run_lib.py:133] step: 252850, training_loss: 1.90327e-02
I0215 21:52:47.844193 23126066861888 run_lib.py:133] step: 252900, training_loss: 1.90705e-02
I0215 21:52:47.997596 23126066861888 run_lib.py:146] step: 252900, eval_loss: 2.71616e-02
I0215 21:53:05.394109 23126066861888 run_lib.py:133] step: 252950, training_loss: 1.92215e-02
I0215 21:53:22.821221 23126066861888 run_lib.py:133] step: 253000, training_loss: 1.88700e-02
I0215 21:53:22.976307 23126066861888 run_lib.py:146] step: 253000, eval_loss: 2.71959e-02
I0215 21:53:40.549528 23126066861888 run_lib.py:133] step: 253050, training_loss: 1.86771e-02
I0215 21:53:57.949005 23126066861888 run_lib.py:133] step: 253100, training_loss: 1.95196e-02
I0215 21:53:58.106388 23126066861888 run_lib.py:146] step: 253100, eval_loss: 2.70392e-02
I0215 21:54:15.470553 23126066861888 run_lib.py:133] step: 253150, training_loss: 1.95052e-02
I0215 21:54:33.009582 23126066861888 run_lib.py:133] step: 253200, training_loss: 1.88340e-02
I0215 21:54:33.164173 23126066861888 run_lib.py:146] step: 253200, eval_loss: 2.67384e-02
I0215 21:54:50.569817 23126066861888 run_lib.py:133] step: 253250, training_loss: 1.91553e-02
I0215 21:55:08.182576 23126066861888 run_lib.py:133] step: 253300, training_loss: 1.83241e-02
I0215 21:55:08.340047 23126066861888 run_lib.py:146] step: 253300, eval_loss: 2.74191e-02
I0215 21:55:25.806653 23126066861888 run_lib.py:133] step: 253350, training_loss: 1.81632e-02
I0215 21:55:43.203577 23126066861888 run_lib.py:133] step: 253400, training_loss: 1.87361e-02
I0215 21:55:43.370033 23126066861888 run_lib.py:146] step: 253400, eval_loss: 2.80978e-02
I0215 21:56:00.905447 23126066861888 run_lib.py:133] step: 253450, training_loss: 1.80924e-02
I0215 21:56:18.308109 23126066861888 run_lib.py:133] step: 253500, training_loss: 1.87966e-02
I0215 21:56:18.479270 23126066861888 run_lib.py:146] step: 253500, eval_loss: 2.71547e-02
I0215 21:56:35.931181 23126066861888 run_lib.py:133] step: 253550, training_loss: 1.90841e-02
I0215 21:56:53.536117 23126066861888 run_lib.py:133] step: 253600, training_loss: 1.82306e-02
I0215 21:56:53.693232 23126066861888 run_lib.py:146] step: 253600, eval_loss: 2.80506e-02
I0215 21:57:11.082112 23126066861888 run_lib.py:133] step: 253650, training_loss: 1.94541e-02
I0215 21:57:28.456851 23126066861888 run_lib.py:133] step: 253700, training_loss: 1.85155e-02
I0215 21:57:28.611288 23126066861888 run_lib.py:146] step: 253700, eval_loss: 2.71534e-02
I0215 21:57:46.068519 23126066861888 run_lib.py:133] step: 253750, training_loss: 1.84932e-02
I0215 21:58:03.416700 23126066861888 run_lib.py:133] step: 253800, training_loss: 1.87124e-02
I0215 21:58:03.567919 23126066861888 run_lib.py:146] step: 253800, eval_loss: 2.77643e-02
I0215 21:58:20.970755 23126066861888 run_lib.py:133] step: 253850, training_loss: 1.85555e-02
I0215 21:58:38.364166 23126066861888 run_lib.py:133] step: 253900, training_loss: 1.91242e-02
I0215 21:58:38.517967 23126066861888 run_lib.py:146] step: 253900, eval_loss: 2.72255e-02
I0215 21:58:56.129396 23126066861888 run_lib.py:133] step: 253950, training_loss: 1.89212e-02
I0215 21:59:13.567477 23126066861888 run_lib.py:133] step: 254000, training_loss: 1.86641e-02
I0215 21:59:13.724271 23126066861888 run_lib.py:146] step: 254000, eval_loss: 2.69531e-02
I0215 21:59:31.070040 23126066861888 run_lib.py:133] step: 254050, training_loss: 1.87263e-02
I0215 21:59:48.451420 23126066861888 run_lib.py:133] step: 254100, training_loss: 1.90337e-02
I0215 21:59:48.627481 23126066861888 run_lib.py:146] step: 254100, eval_loss: 2.58888e-02
I0215 22:00:06.182333 23126066861888 run_lib.py:133] step: 254150, training_loss: 1.92712e-02
I0215 22:00:23.580818 23126066861888 run_lib.py:133] step: 254200, training_loss: 1.86802e-02
I0215 22:00:23.744347 23126066861888 run_lib.py:146] step: 254200, eval_loss: 2.72831e-02
I0215 22:00:41.169123 23126066861888 run_lib.py:133] step: 254250, training_loss: 1.94903e-02
I0215 22:00:58.774613 23126066861888 run_lib.py:133] step: 254300, training_loss: 1.86238e-02
I0215 22:00:58.925988 23126066861888 run_lib.py:146] step: 254300, eval_loss: 2.82117e-02
I0215 22:01:16.316293 23126066861888 run_lib.py:133] step: 254350, training_loss: 1.80334e-02
I0215 22:01:33.865835 23126066861888 run_lib.py:133] step: 254400, training_loss: 1.88760e-02
I0215 22:01:34.033628 23126066861888 run_lib.py:146] step: 254400, eval_loss: 2.58498e-02
I0215 22:01:51.484926 23126066861888 run_lib.py:133] step: 254450, training_loss: 1.86779e-02
I0215 22:02:08.870280 23126066861888 run_lib.py:133] step: 254500, training_loss: 1.88456e-02
I0215 22:02:09.026216 23126066861888 run_lib.py:146] step: 254500, eval_loss: 2.73168e-02
I0215 22:02:26.586667 23126066861888 run_lib.py:133] step: 254550, training_loss: 1.90396e-02
I0215 22:02:43.913083 23126066861888 run_lib.py:133] step: 254600, training_loss: 1.83009e-02
I0215 22:02:44.075751 23126066861888 run_lib.py:146] step: 254600, eval_loss: 2.70948e-02
I0215 22:03:01.465148 23126066861888 run_lib.py:133] step: 254650, training_loss: 1.94647e-02
I0215 22:03:18.965073 23126066861888 run_lib.py:133] step: 254700, training_loss: 1.86361e-02
I0215 22:03:19.118382 23126066861888 run_lib.py:146] step: 254700, eval_loss: 2.65050e-02
I0215 22:03:36.537307 23126066861888 run_lib.py:133] step: 254750, training_loss: 1.85428e-02
I0215 22:03:53.941609 23126066861888 run_lib.py:133] step: 254800, training_loss: 1.80309e-02
I0215 22:03:54.094211 23126066861888 run_lib.py:146] step: 254800, eval_loss: 2.64902e-02
I0215 22:04:11.637094 23126066861888 run_lib.py:133] step: 254850, training_loss: 1.94016e-02
I0215 22:04:29.006606 23126066861888 run_lib.py:133] step: 254900, training_loss: 1.90017e-02
I0215 22:04:29.176335 23126066861888 run_lib.py:146] step: 254900, eval_loss: 2.72293e-02
I0215 22:04:46.533826 23126066861888 run_lib.py:133] step: 254950, training_loss: 1.90663e-02
I0215 22:05:03.952297 23126066861888 run_lib.py:133] step: 255000, training_loss: 1.93970e-02
I0215 22:05:04.128268 23126066861888 run_lib.py:146] step: 255000, eval_loss: 2.76610e-02
I0215 22:05:21.741972 23126066861888 run_lib.py:133] step: 255050, training_loss: 1.85981e-02
I0215 22:05:39.224152 23126066861888 run_lib.py:133] step: 255100, training_loss: 1.89746e-02
I0215 22:05:39.378238 23126066861888 run_lib.py:146] step: 255100, eval_loss: 2.79352e-02
I0215 22:05:56.759395 23126066861888 run_lib.py:133] step: 255150, training_loss: 1.81682e-02
I0215 22:06:14.139467 23126066861888 run_lib.py:133] step: 255200, training_loss: 1.85953e-02
I0215 22:06:14.291968 23126066861888 run_lib.py:146] step: 255200, eval_loss: 2.78237e-02
I0215 22:06:31.832237 23126066861888 run_lib.py:133] step: 255250, training_loss: 1.90456e-02
I0215 22:06:49.234384 23126066861888 run_lib.py:133] step: 255300, training_loss: 1.83437e-02
I0215 22:06:49.390689 23126066861888 run_lib.py:146] step: 255300, eval_loss: 2.69875e-02
I0215 22:07:06.895487 23126066861888 run_lib.py:133] step: 255350, training_loss: 1.82912e-02
I0215 22:07:24.485063 23126066861888 run_lib.py:133] step: 255400, training_loss: 1.87026e-02
I0215 22:07:24.642338 23126066861888 run_lib.py:146] step: 255400, eval_loss: 2.74287e-02
I0215 22:07:42.033378 23126066861888 run_lib.py:133] step: 255450, training_loss: 1.88318e-02
I0215 22:07:59.541099 23126066861888 run_lib.py:133] step: 255500, training_loss: 1.88185e-02
I0215 22:07:59.697976 23126066861888 run_lib.py:146] step: 255500, eval_loss: 2.75112e-02
I0215 22:08:17.109573 23126066861888 run_lib.py:133] step: 255550, training_loss: 1.89287e-02
I0215 22:08:34.539710 23126066861888 run_lib.py:133] step: 255600, training_loss: 1.91142e-02
I0215 22:08:34.701543 23126066861888 run_lib.py:146] step: 255600, eval_loss: 2.73700e-02
I0215 22:08:52.321932 23126066861888 run_lib.py:133] step: 255650, training_loss: 1.89675e-02
I0215 22:09:09.704228 23126066861888 run_lib.py:133] step: 255700, training_loss: 1.81587e-02
I0215 22:09:09.857309 23126066861888 run_lib.py:146] step: 255700, eval_loss: 2.66148e-02
I0215 22:09:27.255145 23126066861888 run_lib.py:133] step: 255750, training_loss: 1.85568e-02
I0215 22:09:44.819633 23126066861888 run_lib.py:133] step: 255800, training_loss: 1.84880e-02
I0215 22:09:44.973341 23126066861888 run_lib.py:146] step: 255800, eval_loss: 2.76855e-02
I0215 22:10:02.347728 23126066861888 run_lib.py:133] step: 255850, training_loss: 1.85756e-02
I0215 22:10:19.759428 23126066861888 run_lib.py:133] step: 255900, training_loss: 1.91583e-02
I0215 22:10:19.935040 23126066861888 run_lib.py:146] step: 255900, eval_loss: 2.68863e-02
I0215 22:10:37.451979 23126066861888 run_lib.py:133] step: 255950, training_loss: 1.77839e-02
I0215 22:10:54.852488 23126066861888 run_lib.py:133] step: 256000, training_loss: 1.85928e-02
I0215 22:10:55.007285 23126066861888 run_lib.py:146] step: 256000, eval_loss: 2.65409e-02
I0215 22:11:12.397876 23126066861888 run_lib.py:133] step: 256050, training_loss: 1.89694e-02
I0215 22:11:29.737410 23126066861888 run_lib.py:133] step: 256100, training_loss: 1.85047e-02
I0215 22:11:29.888717 23126066861888 run_lib.py:146] step: 256100, eval_loss: 2.63571e-02
I0215 22:11:47.422464 23126066861888 run_lib.py:133] step: 256150, training_loss: 1.82090e-02
I0215 22:12:04.915859 23126066861888 run_lib.py:133] step: 256200, training_loss: 1.91921e-02
I0215 22:12:05.077253 23126066861888 run_lib.py:146] step: 256200, eval_loss: 2.68949e-02
I0215 22:12:22.509731 23126066861888 run_lib.py:133] step: 256250, training_loss: 1.90513e-02
I0215 22:12:39.876822 23126066861888 run_lib.py:133] step: 256300, training_loss: 1.80798e-02
I0215 22:12:40.031231 23126066861888 run_lib.py:146] step: 256300, eval_loss: 2.66444e-02
I0215 22:12:57.567108 23126066861888 run_lib.py:133] step: 256350, training_loss: 1.88653e-02
I0215 22:13:14.960794 23126066861888 run_lib.py:133] step: 256400, training_loss: 1.87149e-02
I0215 22:13:15.118020 23126066861888 run_lib.py:146] step: 256400, eval_loss: 2.78927e-02
I0215 22:13:32.543254 23126066861888 run_lib.py:133] step: 256450, training_loss: 1.93804e-02
I0215 22:13:50.123606 23126066861888 run_lib.py:133] step: 256500, training_loss: 1.82343e-02
I0215 22:13:50.285710 23126066861888 run_lib.py:146] step: 256500, eval_loss: 2.85129e-02
I0215 22:14:07.701455 23126066861888 run_lib.py:133] step: 256550, training_loss: 1.94003e-02
I0215 22:14:25.241087 23126066861888 run_lib.py:133] step: 256600, training_loss: 1.81497e-02
I0215 22:14:25.403468 23126066861888 run_lib.py:146] step: 256600, eval_loss: 2.72726e-02
I0215 22:14:42.770030 23126066861888 run_lib.py:133] step: 256650, training_loss: 1.93149e-02
I0215 22:15:00.129094 23126066861888 run_lib.py:133] step: 256700, training_loss: 1.85843e-02
I0215 22:15:00.285459 23126066861888 run_lib.py:146] step: 256700, eval_loss: 2.71460e-02
I0215 22:15:17.922852 23126066861888 run_lib.py:133] step: 256750, training_loss: 1.92696e-02
I0215 22:15:35.371703 23126066861888 run_lib.py:133] step: 256800, training_loss: 1.90830e-02
I0215 22:15:35.526325 23126066861888 run_lib.py:146] step: 256800, eval_loss: 2.66879e-02
I0215 22:15:52.896403 23126066861888 run_lib.py:133] step: 256850, training_loss: 1.82535e-02
I0215 22:16:10.552680 23126066861888 run_lib.py:133] step: 256900, training_loss: 1.82771e-02
I0215 22:16:10.712503 23126066861888 run_lib.py:146] step: 256900, eval_loss: 2.75584e-02
I0215 22:16:28.141612 23126066861888 run_lib.py:133] step: 256950, training_loss: 1.82257e-02
I0215 22:16:45.542380 23126066861888 run_lib.py:133] step: 257000, training_loss: 1.91953e-02
I0215 22:16:45.697413 23126066861888 run_lib.py:146] step: 257000, eval_loss: 2.73393e-02
I0215 22:17:03.177038 23126066861888 run_lib.py:133] step: 257050, training_loss: 1.88848e-02
I0215 22:17:20.615631 23126066861888 run_lib.py:133] step: 257100, training_loss: 1.88148e-02
I0215 22:17:20.767504 23126066861888 run_lib.py:146] step: 257100, eval_loss: 2.79524e-02
I0215 22:17:38.253029 23126066861888 run_lib.py:133] step: 257150, training_loss: 1.84173e-02
I0215 22:17:55.687122 23126066861888 run_lib.py:133] step: 257200, training_loss: 1.80803e-02
I0215 22:17:55.846075 23126066861888 run_lib.py:146] step: 257200, eval_loss: 2.75967e-02
I0215 22:18:13.439118 23126066861888 run_lib.py:133] step: 257250, training_loss: 1.91578e-02
I0215 22:18:30.881049 23126066861888 run_lib.py:133] step: 257300, training_loss: 1.86279e-02
I0215 22:18:31.055238 23126066861888 run_lib.py:146] step: 257300, eval_loss: 2.75891e-02
I0215 22:18:48.494636 23126066861888 run_lib.py:133] step: 257350, training_loss: 1.79256e-02
I0215 22:19:05.935638 23126066861888 run_lib.py:133] step: 257400, training_loss: 1.88727e-02
I0215 22:19:06.088660 23126066861888 run_lib.py:146] step: 257400, eval_loss: 2.71497e-02
I0215 22:19:23.656186 23126066861888 run_lib.py:133] step: 257450, training_loss: 1.85468e-02
I0215 22:19:41.025047 23126066861888 run_lib.py:133] step: 257500, training_loss: 1.88922e-02
I0215 22:19:41.181982 23126066861888 run_lib.py:146] step: 257500, eval_loss: 2.74106e-02
I0215 22:19:58.586844 23126066861888 run_lib.py:133] step: 257550, training_loss: 1.92290e-02
I0215 22:20:16.163520 23126066861888 run_lib.py:133] step: 257600, training_loss: 1.83469e-02
I0215 22:20:16.317306 23126066861888 run_lib.py:146] step: 257600, eval_loss: 2.72626e-02
I0215 22:20:33.819154 23126066861888 run_lib.py:133] step: 257650, training_loss: 1.74880e-02
I0215 22:20:51.474787 23126066861888 run_lib.py:133] step: 257700, training_loss: 1.86511e-02
I0215 22:20:51.629003 23126066861888 run_lib.py:146] step: 257700, eval_loss: 2.82979e-02
I0215 22:21:09.016605 23126066861888 run_lib.py:133] step: 257750, training_loss: 1.77108e-02
I0215 22:21:26.395947 23126066861888 run_lib.py:133] step: 257800, training_loss: 1.92504e-02
I0215 22:21:26.556884 23126066861888 run_lib.py:146] step: 257800, eval_loss: 2.68365e-02
I0215 22:21:44.100749 23126066861888 run_lib.py:133] step: 257850, training_loss: 1.89387e-02
I0215 22:22:01.517878 23126066861888 run_lib.py:133] step: 257900, training_loss: 1.84034e-02
I0215 22:22:01.685258 23126066861888 run_lib.py:146] step: 257900, eval_loss: 2.68248e-02
I0215 22:22:19.099906 23126066861888 run_lib.py:133] step: 257950, training_loss: 1.82204e-02
I0215 22:22:36.816237 23126066861888 run_lib.py:133] step: 258000, training_loss: 1.78808e-02
I0215 22:22:36.971529 23126066861888 run_lib.py:146] step: 258000, eval_loss: 2.72172e-02
I0215 22:22:54.365136 23126066861888 run_lib.py:133] step: 258050, training_loss: 1.81060e-02
I0215 22:23:11.727655 23126066861888 run_lib.py:133] step: 258100, training_loss: 1.78532e-02
I0215 22:23:11.879272 23126066861888 run_lib.py:146] step: 258100, eval_loss: 2.83470e-02
I0215 22:23:29.327757 23126066861888 run_lib.py:133] step: 258150, training_loss: 1.92914e-02
I0215 22:23:46.767311 23126066861888 run_lib.py:133] step: 258200, training_loss: 1.88179e-02
I0215 22:23:46.930011 23126066861888 run_lib.py:146] step: 258200, eval_loss: 2.70182e-02
I0215 22:24:04.328250 23126066861888 run_lib.py:133] step: 258250, training_loss: 1.81868e-02
I0215 22:24:21.742993 23126066861888 run_lib.py:133] step: 258300, training_loss: 1.93599e-02
I0215 22:24:21.906824 23126066861888 run_lib.py:146] step: 258300, eval_loss: 2.70713e-02
I0215 22:24:39.500942 23126066861888 run_lib.py:133] step: 258350, training_loss: 1.84646e-02
I0215 22:24:56.951968 23126066861888 run_lib.py:133] step: 258400, training_loss: 1.91294e-02
I0215 22:24:57.107102 23126066861888 run_lib.py:146] step: 258400, eval_loss: 2.72478e-02
I0215 22:25:14.452141 23126066861888 run_lib.py:133] step: 258450, training_loss: 1.88187e-02
I0215 22:25:31.851842 23126066861888 run_lib.py:133] step: 258500, training_loss: 1.85156e-02
I0215 22:25:32.009647 23126066861888 run_lib.py:146] step: 258500, eval_loss: 2.67515e-02
I0215 22:25:49.600749 23126066861888 run_lib.py:133] step: 258550, training_loss: 1.84701e-02
I0215 22:26:06.995113 23126066861888 run_lib.py:133] step: 258600, training_loss: 1.86635e-02
I0215 22:26:07.146080 23126066861888 run_lib.py:146] step: 258600, eval_loss: 2.75370e-02
I0215 22:26:24.515126 23126066861888 run_lib.py:133] step: 258650, training_loss: 1.87612e-02
I0215 22:26:42.083537 23126066861888 run_lib.py:133] step: 258700, training_loss: 1.91490e-02
I0215 22:26:42.237839 23126066861888 run_lib.py:146] step: 258700, eval_loss: 2.71450e-02
I0215 22:26:59.591028 23126066861888 run_lib.py:133] step: 258750, training_loss: 1.85062e-02
I0215 22:27:17.131848 23126066861888 run_lib.py:133] step: 258800, training_loss: 1.84541e-02
I0215 22:27:17.309305 23126066861888 run_lib.py:146] step: 258800, eval_loss: 2.75280e-02
I0215 22:27:34.696387 23126066861888 run_lib.py:133] step: 258850, training_loss: 1.87380e-02
I0215 22:27:52.106391 23126066861888 run_lib.py:133] step: 258900, training_loss: 1.88192e-02
I0215 22:27:52.261230 23126066861888 run_lib.py:146] step: 258900, eval_loss: 2.63801e-02
I0215 22:28:09.847946 23126066861888 run_lib.py:133] step: 258950, training_loss: 1.85290e-02
I0215 22:28:27.214210 23126066861888 run_lib.py:133] step: 259000, training_loss: 1.90880e-02
I0215 22:28:27.366234 23126066861888 run_lib.py:146] step: 259000, eval_loss: 2.74163e-02
I0215 22:28:44.736739 23126066861888 run_lib.py:133] step: 259050, training_loss: 1.92736e-02
I0215 22:29:02.272742 23126066861888 run_lib.py:133] step: 259100, training_loss: 1.85345e-02
I0215 22:29:02.429508 23126066861888 run_lib.py:146] step: 259100, eval_loss: 2.67471e-02
I0215 22:29:19.901347 23126066861888 run_lib.py:133] step: 259150, training_loss: 1.86557e-02
I0215 22:29:37.335077 23126066861888 run_lib.py:133] step: 259200, training_loss: 1.94028e-02
I0215 22:29:37.489769 23126066861888 run_lib.py:146] step: 259200, eval_loss: 2.71120e-02
I0215 22:29:54.929100 23126066861888 run_lib.py:133] step: 259250, training_loss: 1.92857e-02
I0215 22:30:12.313878 23126066861888 run_lib.py:133] step: 259300, training_loss: 1.88010e-02
I0215 22:30:12.486977 23126066861888 run_lib.py:146] step: 259300, eval_loss: 2.72698e-02
I0215 22:30:29.910677 23126066861888 run_lib.py:133] step: 259350, training_loss: 1.85492e-02
I0215 22:30:47.331291 23126066861888 run_lib.py:133] step: 259400, training_loss: 1.88160e-02
I0215 22:30:47.487948 23126066861888 run_lib.py:146] step: 259400, eval_loss: 2.75237e-02
I0215 22:31:05.070014 23126066861888 run_lib.py:133] step: 259450, training_loss: 1.91227e-02
I0215 22:31:22.586549 23126066861888 run_lib.py:133] step: 259500, training_loss: 1.83179e-02
I0215 22:31:22.737375 23126066861888 run_lib.py:146] step: 259500, eval_loss: 2.67621e-02
I0215 22:31:40.110131 23126066861888 run_lib.py:133] step: 259550, training_loss: 1.86094e-02
I0215 22:31:57.515555 23126066861888 run_lib.py:133] step: 259600, training_loss: 1.88657e-02
I0215 22:31:57.669952 23126066861888 run_lib.py:146] step: 259600, eval_loss: 2.59890e-02
I0215 22:32:15.199457 23126066861888 run_lib.py:133] step: 259650, training_loss: 1.90859e-02
I0215 22:32:32.608928 23126066861888 run_lib.py:133] step: 259700, training_loss: 1.83709e-02
I0215 22:32:32.783180 23126066861888 run_lib.py:146] step: 259700, eval_loss: 2.73452e-02
I0215 22:32:50.233487 23126066861888 run_lib.py:133] step: 259750, training_loss: 1.83647e-02
I0215 22:33:07.807556 23126066861888 run_lib.py:133] step: 259800, training_loss: 1.85050e-02
I0215 22:33:07.962342 23126066861888 run_lib.py:146] step: 259800, eval_loss: 2.64661e-02
I0215 22:33:25.329067 23126066861888 run_lib.py:133] step: 259850, training_loss: 1.84065e-02
I0215 22:33:42.858304 23126066861888 run_lib.py:133] step: 259900, training_loss: 1.88726e-02
I0215 22:33:43.012039 23126066861888 run_lib.py:146] step: 259900, eval_loss: 2.67165e-02
I0215 22:34:00.422992 23126066861888 run_lib.py:133] step: 259950, training_loss: 1.92899e-02
I0215 22:34:17.853475 23126066861888 run_lib.py:133] step: 260000, training_loss: 1.89151e-02
I0215 22:34:18.792355 23126066861888 run_lib.py:146] step: 260000, eval_loss: 2.65675e-02
I0215 22:34:39.317167 23126066861888 run_lib.py:133] step: 260050, training_loss: 1.93906e-02
I0215 22:34:56.728353 23126066861888 run_lib.py:133] step: 260100, training_loss: 1.85221e-02
I0215 22:34:56.880073 23126066861888 run_lib.py:146] step: 260100, eval_loss: 2.81240e-02
I0215 22:35:14.269500 23126066861888 run_lib.py:133] step: 260150, training_loss: 1.91703e-02
I0215 22:35:31.883927 23126066861888 run_lib.py:133] step: 260200, training_loss: 1.79105e-02
I0215 22:35:32.035684 23126066861888 run_lib.py:146] step: 260200, eval_loss: 2.83704e-02
I0215 22:35:49.439240 23126066861888 run_lib.py:133] step: 260250, training_loss: 1.94222e-02
I0215 22:36:06.897034 23126066861888 run_lib.py:133] step: 260300, training_loss: 1.85436e-02
I0215 22:36:07.054487 23126066861888 run_lib.py:146] step: 260300, eval_loss: 2.77854e-02
I0215 22:36:24.659200 23126066861888 run_lib.py:133] step: 260350, training_loss: 1.84216e-02
I0215 22:36:42.080084 23126066861888 run_lib.py:133] step: 260400, training_loss: 1.87815e-02
I0215 22:36:42.234086 23126066861888 run_lib.py:146] step: 260400, eval_loss: 2.72973e-02
I0215 22:36:59.806313 23126066861888 run_lib.py:133] step: 260450, training_loss: 1.89726e-02
I0215 22:37:17.162307 23126066861888 run_lib.py:133] step: 260500, training_loss: 1.86662e-02
I0215 22:37:17.312880 23126066861888 run_lib.py:146] step: 260500, eval_loss: 2.61305e-02
I0215 22:37:34.697552 23126066861888 run_lib.py:133] step: 260550, training_loss: 1.84721e-02
I0215 22:37:52.337888 23126066861888 run_lib.py:133] step: 260600, training_loss: 1.84421e-02
I0215 22:37:52.495520 23126066861888 run_lib.py:146] step: 260600, eval_loss: 2.74592e-02
I0215 22:38:09.945545 23126066861888 run_lib.py:133] step: 260650, training_loss: 1.85206e-02
I0215 22:38:27.368370 23126066861888 run_lib.py:133] step: 260700, training_loss: 1.92212e-02
I0215 22:38:27.528448 23126066861888 run_lib.py:146] step: 260700, eval_loss: 2.68144e-02
I0215 22:38:44.911752 23126066861888 run_lib.py:133] step: 260750, training_loss: 1.79644e-02
I0215 22:39:02.257640 23126066861888 run_lib.py:133] step: 260800, training_loss: 1.95987e-02
I0215 22:39:02.420032 23126066861888 run_lib.py:146] step: 260800, eval_loss: 2.69239e-02
I0215 22:39:19.922152 23126066861888 run_lib.py:133] step: 260850, training_loss: 1.91495e-02
I0215 22:39:37.463323 23126066861888 run_lib.py:133] step: 260900, training_loss: 1.88007e-02
I0215 22:39:37.615950 23126066861888 run_lib.py:146] step: 260900, eval_loss: 2.73359e-02
I0215 22:39:54.988242 23126066861888 run_lib.py:133] step: 260950, training_loss: 1.79767e-02
I0215 22:40:12.348319 23126066861888 run_lib.py:133] step: 261000, training_loss: 1.94134e-02
I0215 22:40:12.500306 23126066861888 run_lib.py:146] step: 261000, eval_loss: 2.79976e-02
I0215 22:40:30.009086 23126066861888 run_lib.py:133] step: 261050, training_loss: 1.84742e-02
I0215 22:40:47.434507 23126066861888 run_lib.py:133] step: 261100, training_loss: 1.86229e-02
I0215 22:40:47.605300 23126066861888 run_lib.py:146] step: 261100, eval_loss: 2.67496e-02
I0215 22:41:05.211798 23126066861888 run_lib.py:133] step: 261150, training_loss: 1.83465e-02
I0215 22:41:22.647372 23126066861888 run_lib.py:133] step: 261200, training_loss: 1.90203e-02
I0215 22:41:22.803151 23126066861888 run_lib.py:146] step: 261200, eval_loss: 2.70271e-02
I0215 22:41:40.222244 23126066861888 run_lib.py:133] step: 261250, training_loss: 1.84728e-02
I0215 22:41:57.782243 23126066861888 run_lib.py:133] step: 261300, training_loss: 1.84459e-02
I0215 22:41:57.936276 23126066861888 run_lib.py:146] step: 261300, eval_loss: 2.64230e-02
I0215 22:42:15.307403 23126066861888 run_lib.py:133] step: 261350, training_loss: 1.82325e-02
I0215 22:42:32.700958 23126066861888 run_lib.py:133] step: 261400, training_loss: 1.83562e-02
I0215 22:42:32.854580 23126066861888 run_lib.py:146] step: 261400, eval_loss: 2.72742e-02
I0215 22:42:50.459531 23126066861888 run_lib.py:133] step: 261450, training_loss: 1.81651e-02
I0215 22:43:07.850512 23126066861888 run_lib.py:133] step: 261500, training_loss: 1.85561e-02
I0215 22:43:08.001306 23126066861888 run_lib.py:146] step: 261500, eval_loss: 2.80786e-02
I0215 22:43:25.466410 23126066861888 run_lib.py:133] step: 261550, training_loss: 1.83567e-02
I0215 22:43:43.032953 23126066861888 run_lib.py:133] step: 261600, training_loss: 1.82652e-02
I0215 22:43:43.187012 23126066861888 run_lib.py:146] step: 261600, eval_loss: 2.69800e-02
I0215 22:44:00.551553 23126066861888 run_lib.py:133] step: 261650, training_loss: 1.94311e-02
I0215 22:44:17.967460 23126066861888 run_lib.py:133] step: 261700, training_loss: 1.92287e-02
I0215 22:44:18.146052 23126066861888 run_lib.py:146] step: 261700, eval_loss: 2.60219e-02
I0215 22:44:35.655513 23126066861888 run_lib.py:133] step: 261750, training_loss: 1.83178e-02
I0215 22:44:53.060645 23126066861888 run_lib.py:133] step: 261800, training_loss: 1.88809e-02
I0215 22:44:53.222916 23126066861888 run_lib.py:146] step: 261800, eval_loss: 2.85024e-02
I0215 22:45:10.667696 23126066861888 run_lib.py:133] step: 261850, training_loss: 1.84560e-02
I0215 22:45:28.075028 23126066861888 run_lib.py:133] step: 261900, training_loss: 1.87795e-02
I0215 22:45:28.228252 23126066861888 run_lib.py:146] step: 261900, eval_loss: 2.60632e-02
I0215 22:45:45.765247 23126066861888 run_lib.py:133] step: 261950, training_loss: 1.77052e-02
I0215 22:46:03.283926 23126066861888 run_lib.py:133] step: 262000, training_loss: 1.91267e-02
I0215 22:46:03.437771 23126066861888 run_lib.py:146] step: 262000, eval_loss: 2.75089e-02
I0215 22:46:20.874515 23126066861888 run_lib.py:133] step: 262050, training_loss: 1.88699e-02
I0215 22:46:38.282679 23126066861888 run_lib.py:133] step: 262100, training_loss: 1.78897e-02
I0215 22:46:38.439456 23126066861888 run_lib.py:146] step: 262100, eval_loss: 2.60143e-02
I0215 22:46:55.981393 23126066861888 run_lib.py:133] step: 262150, training_loss: 1.83755e-02
I0215 22:47:13.310880 23126066861888 run_lib.py:133] step: 262200, training_loss: 1.87195e-02
I0215 22:47:13.467461 23126066861888 run_lib.py:146] step: 262200, eval_loss: 2.62741e-02
I0215 22:47:30.864931 23126066861888 run_lib.py:133] step: 262250, training_loss: 1.87730e-02
I0215 22:47:48.453968 23126066861888 run_lib.py:133] step: 262300, training_loss: 1.87402e-02
I0215 22:47:48.615561 23126066861888 run_lib.py:146] step: 262300, eval_loss: 2.82612e-02
I0215 22:48:05.990133 23126066861888 run_lib.py:133] step: 262350, training_loss: 1.78425e-02
I0215 22:48:23.511141 23126066861888 run_lib.py:133] step: 262400, training_loss: 1.90289e-02
I0215 22:48:23.663750 23126066861888 run_lib.py:146] step: 262400, eval_loss: 2.60251e-02
I0215 22:48:41.025078 23126066861888 run_lib.py:133] step: 262450, training_loss: 1.87532e-02
I0215 22:48:58.421404 23126066861888 run_lib.py:133] step: 262500, training_loss: 1.89174e-02
I0215 22:48:58.572049 23126066861888 run_lib.py:146] step: 262500, eval_loss: 2.78747e-02
I0215 22:49:16.127959 23126066861888 run_lib.py:133] step: 262550, training_loss: 1.86393e-02
I0215 22:49:33.573123 23126066861888 run_lib.py:133] step: 262600, training_loss: 1.86901e-02
I0215 22:49:33.730234 23126066861888 run_lib.py:146] step: 262600, eval_loss: 2.67061e-02
I0215 22:49:51.121104 23126066861888 run_lib.py:133] step: 262650, training_loss: 1.85324e-02
I0215 22:50:08.694720 23126066861888 run_lib.py:133] step: 262700, training_loss: 1.93271e-02
I0215 22:50:08.846396 23126066861888 run_lib.py:146] step: 262700, eval_loss: 2.70976e-02
I0215 22:50:26.186308 23126066861888 run_lib.py:133] step: 262750, training_loss: 1.87406e-02
I0215 22:50:43.543643 23126066861888 run_lib.py:133] step: 262800, training_loss: 1.85259e-02
I0215 22:50:43.698192 23126066861888 run_lib.py:146] step: 262800, eval_loss: 2.67928e-02
I0215 22:51:01.154337 23126066861888 run_lib.py:133] step: 262850, training_loss: 1.84628e-02
I0215 22:51:18.609331 23126066861888 run_lib.py:133] step: 262900, training_loss: 1.92137e-02
I0215 22:51:18.760812 23126066861888 run_lib.py:146] step: 262900, eval_loss: 2.67636e-02
I0215 22:51:36.166542 23126066861888 run_lib.py:133] step: 262950, training_loss: 1.88177e-02
I0215 22:51:53.550310 23126066861888 run_lib.py:133] step: 263000, training_loss: 1.88934e-02
I0215 22:51:53.703958 23126066861888 run_lib.py:146] step: 263000, eval_loss: 2.71814e-02
I0215 22:52:11.294349 23126066861888 run_lib.py:133] step: 263050, training_loss: 1.88738e-02
I0215 22:52:28.725469 23126066861888 run_lib.py:133] step: 263100, training_loss: 1.87893e-02
I0215 22:52:28.884470 23126066861888 run_lib.py:146] step: 263100, eval_loss: 2.73346e-02
I0215 22:52:46.293351 23126066861888 run_lib.py:133] step: 263150, training_loss: 1.88534e-02
I0215 22:53:03.711489 23126066861888 run_lib.py:133] step: 263200, training_loss: 1.77972e-02
I0215 22:53:03.867579 23126066861888 run_lib.py:146] step: 263200, eval_loss: 2.86049e-02
I0215 22:53:21.463996 23126066861888 run_lib.py:133] step: 263250, training_loss: 1.82787e-02
I0215 22:53:38.831935 23126066861888 run_lib.py:133] step: 263300, training_loss: 1.80173e-02
I0215 22:53:38.987267 23126066861888 run_lib.py:146] step: 263300, eval_loss: 2.88858e-02
I0215 22:53:56.327392 23126066861888 run_lib.py:133] step: 263350, training_loss: 1.86023e-02
I0215 22:54:13.884474 23126066861888 run_lib.py:133] step: 263400, training_loss: 1.81806e-02
I0215 22:54:14.035468 23126066861888 run_lib.py:146] step: 263400, eval_loss: 2.74715e-02
I0215 22:54:31.464117 23126066861888 run_lib.py:133] step: 263450, training_loss: 1.86666e-02
I0215 22:54:49.063033 23126066861888 run_lib.py:133] step: 263500, training_loss: 1.90910e-02
I0215 22:54:49.220521 23126066861888 run_lib.py:146] step: 263500, eval_loss: 2.70369e-02
I0215 22:55:06.624707 23126066861888 run_lib.py:133] step: 263550, training_loss: 1.91569e-02
I0215 22:55:24.032286 23126066861888 run_lib.py:133] step: 263600, training_loss: 1.87771e-02
I0215 22:55:24.196694 23126066861888 run_lib.py:146] step: 263600, eval_loss: 2.67650e-02
I0215 22:55:41.762561 23126066861888 run_lib.py:133] step: 263650, training_loss: 1.90059e-02
I0215 22:55:59.150439 23126066861888 run_lib.py:133] step: 263700, training_loss: 1.84651e-02
I0215 22:55:59.308084 23126066861888 run_lib.py:146] step: 263700, eval_loss: 2.70248e-02
I0215 22:56:16.751179 23126066861888 run_lib.py:133] step: 263750, training_loss: 1.84642e-02
I0215 22:56:34.433072 23126066861888 run_lib.py:133] step: 263800, training_loss: 1.91531e-02
I0215 22:56:34.586608 23126066861888 run_lib.py:146] step: 263800, eval_loss: 2.75548e-02
I0215 22:56:52.032986 23126066861888 run_lib.py:133] step: 263850, training_loss: 1.87766e-02
I0215 22:57:09.403313 23126066861888 run_lib.py:133] step: 263900, training_loss: 1.81927e-02
I0215 22:57:09.552360 23126066861888 run_lib.py:146] step: 263900, eval_loss: 2.77404e-02
I0215 22:57:26.979004 23126066861888 run_lib.py:133] step: 263950, training_loss: 1.93834e-02
I0215 22:57:44.369745 23126066861888 run_lib.py:133] step: 264000, training_loss: 1.88091e-02
I0215 22:57:44.550062 23126066861888 run_lib.py:146] step: 264000, eval_loss: 2.71008e-02
I0215 22:58:02.009182 23126066861888 run_lib.py:133] step: 264050, training_loss: 1.89284e-02
I0215 22:58:19.395986 23126066861888 run_lib.py:133] step: 264100, training_loss: 1.84696e-02
I0215 22:58:19.552060 23126066861888 run_lib.py:146] step: 264100, eval_loss: 2.70885e-02
I0215 22:58:37.098347 23126066861888 run_lib.py:133] step: 264150, training_loss: 1.87186e-02
I0215 22:58:54.549225 23126066861888 run_lib.py:133] step: 264200, training_loss: 1.88496e-02
I0215 22:58:54.707077 23126066861888 run_lib.py:146] step: 264200, eval_loss: 2.81844e-02
I0215 22:59:12.108834 23126066861888 run_lib.py:133] step: 264250, training_loss: 1.92009e-02
I0215 22:59:29.524824 23126066861888 run_lib.py:133] step: 264300, training_loss: 1.80435e-02
I0215 22:59:29.678004 23126066861888 run_lib.py:146] step: 264300, eval_loss: 2.79010e-02
I0215 22:59:47.328391 23126066861888 run_lib.py:133] step: 264350, training_loss: 1.79595e-02
I0215 23:00:04.725391 23126066861888 run_lib.py:133] step: 264400, training_loss: 1.90765e-02
I0215 23:00:04.884253 23126066861888 run_lib.py:146] step: 264400, eval_loss: 2.80299e-02
I0215 23:00:22.324850 23126066861888 run_lib.py:133] step: 264450, training_loss: 1.88975e-02
I0215 23:00:39.861726 23126066861888 run_lib.py:133] step: 264500, training_loss: 1.91169e-02
I0215 23:00:40.018231 23126066861888 run_lib.py:146] step: 264500, eval_loss: 2.73021e-02
I0215 23:00:57.400936 23126066861888 run_lib.py:133] step: 264550, training_loss: 1.87194e-02
I0215 23:01:14.945050 23126066861888 run_lib.py:133] step: 264600, training_loss: 1.93632e-02
I0215 23:01:15.106566 23126066861888 run_lib.py:146] step: 264600, eval_loss: 2.65809e-02
I0215 23:01:32.642403 23126066861888 run_lib.py:133] step: 264650, training_loss: 1.86670e-02
I0215 23:01:50.045003 23126066861888 run_lib.py:133] step: 264700, training_loss: 1.85158e-02
I0215 23:01:50.199630 23126066861888 run_lib.py:146] step: 264700, eval_loss: 2.71108e-02
I0215 23:02:07.808690 23126066861888 run_lib.py:133] step: 264750, training_loss: 1.89383e-02
I0215 23:02:25.199890 23126066861888 run_lib.py:133] step: 264800, training_loss: 1.86392e-02
I0215 23:02:25.345184 23126066861888 run_lib.py:146] step: 264800, eval_loss: 2.67743e-02
I0215 23:02:42.732516 23126066861888 run_lib.py:133] step: 264850, training_loss: 1.88823e-02
I0215 23:03:00.308927 23126066861888 run_lib.py:133] step: 264900, training_loss: 1.85428e-02
I0215 23:03:00.475425 23126066861888 run_lib.py:146] step: 264900, eval_loss: 2.66525e-02
I0215 23:03:17.899901 23126066861888 run_lib.py:133] step: 264950, training_loss: 1.84837e-02
I0215 23:03:35.339400 23126066861888 run_lib.py:133] step: 265000, training_loss: 1.90316e-02
I0215 23:03:35.503650 23126066861888 run_lib.py:146] step: 265000, eval_loss: 2.75815e-02
I0215 23:03:53.011029 23126066861888 run_lib.py:133] step: 265050, training_loss: 1.88406e-02
I0215 23:04:10.385476 23126066861888 run_lib.py:133] step: 265100, training_loss: 1.89987e-02
I0215 23:04:10.539182 23126066861888 run_lib.py:146] step: 265100, eval_loss: 2.58860e-02
I0215 23:04:27.945140 23126066861888 run_lib.py:133] step: 265150, training_loss: 1.87285e-02
I0215 23:04:45.389720 23126066861888 run_lib.py:133] step: 265200, training_loss: 1.91370e-02
I0215 23:04:45.550013 23126066861888 run_lib.py:146] step: 265200, eval_loss: 2.72804e-02
I0215 23:05:03.170381 23126066861888 run_lib.py:133] step: 265250, training_loss: 1.85815e-02
I0215 23:05:20.622492 23126066861888 run_lib.py:133] step: 265300, training_loss: 1.85625e-02
I0215 23:05:20.777458 23126066861888 run_lib.py:146] step: 265300, eval_loss: 2.81603e-02
I0215 23:05:38.155924 23126066861888 run_lib.py:133] step: 265350, training_loss: 1.89642e-02
I0215 23:05:55.618247 23126066861888 run_lib.py:133] step: 265400, training_loss: 1.80550e-02
I0215 23:05:55.776360 23126066861888 run_lib.py:146] step: 265400, eval_loss: 2.70282e-02
I0215 23:06:13.340916 23126066861888 run_lib.py:133] step: 265450, training_loss: 1.86228e-02
I0215 23:06:30.785955 23126066861888 run_lib.py:133] step: 265500, training_loss: 1.96648e-02
I0215 23:06:30.943157 23126066861888 run_lib.py:146] step: 265500, eval_loss: 2.66724e-02
I0215 23:06:48.342109 23126066861888 run_lib.py:133] step: 265550, training_loss: 1.90974e-02
I0215 23:07:05.931454 23126066861888 run_lib.py:133] step: 265600, training_loss: 1.85101e-02
I0215 23:07:06.085054 23126066861888 run_lib.py:146] step: 265600, eval_loss: 2.61982e-02
I0215 23:07:23.483542 23126066861888 run_lib.py:133] step: 265650, training_loss: 1.84808e-02
I0215 23:07:40.983265 23126066861888 run_lib.py:133] step: 265700, training_loss: 1.84088e-02
I0215 23:07:41.141389 23126066861888 run_lib.py:146] step: 265700, eval_loss: 2.76402e-02
I0215 23:07:58.530319 23126066861888 run_lib.py:133] step: 265750, training_loss: 1.83167e-02
I0215 23:08:16.010477 23126066861888 run_lib.py:133] step: 265800, training_loss: 1.88819e-02
I0215 23:08:16.164581 23126066861888 run_lib.py:146] step: 265800, eval_loss: 2.76852e-02
I0215 23:08:33.848367 23126066861888 run_lib.py:133] step: 265850, training_loss: 1.84177e-02
I0215 23:08:51.260955 23126066861888 run_lib.py:133] step: 265900, training_loss: 1.85857e-02
I0215 23:08:51.418531 23126066861888 run_lib.py:146] step: 265900, eval_loss: 2.70646e-02
I0215 23:09:08.832181 23126066861888 run_lib.py:133] step: 265950, training_loss: 1.87521e-02
I0215 23:09:26.468618 23126066861888 run_lib.py:133] step: 266000, training_loss: 1.93786e-02
I0215 23:09:26.624763 23126066861888 run_lib.py:146] step: 266000, eval_loss: 2.74209e-02
I0215 23:09:44.067436 23126066861888 run_lib.py:133] step: 266050, training_loss: 1.81764e-02
I0215 23:10:01.529960 23126066861888 run_lib.py:133] step: 266100, training_loss: 1.84278e-02
I0215 23:10:01.684495 23126066861888 run_lib.py:146] step: 266100, eval_loss: 2.75872e-02
I0215 23:10:19.201705 23126066861888 run_lib.py:133] step: 266150, training_loss: 1.83015e-02
I0215 23:10:36.614490 23126066861888 run_lib.py:133] step: 266200, training_loss: 1.84333e-02
I0215 23:10:36.764056 23126066861888 run_lib.py:146] step: 266200, eval_loss: 2.75899e-02
I0215 23:10:54.135120 23126066861888 run_lib.py:133] step: 266250, training_loss: 1.81025e-02
I0215 23:11:11.531523 23126066861888 run_lib.py:133] step: 266300, training_loss: 1.76492e-02
I0215 23:11:11.698257 23126066861888 run_lib.py:146] step: 266300, eval_loss: 2.70959e-02
I0215 23:11:29.285516 23126066861888 run_lib.py:133] step: 266350, training_loss: 1.78081e-02
I0215 23:11:46.787851 23126066861888 run_lib.py:133] step: 266400, training_loss: 1.77334e-02
I0215 23:11:46.944361 23126066861888 run_lib.py:146] step: 266400, eval_loss: 2.77338e-02
I0215 23:12:04.338988 23126066861888 run_lib.py:133] step: 266450, training_loss: 1.85437e-02
I0215 23:12:21.694900 23126066861888 run_lib.py:133] step: 266500, training_loss: 1.85882e-02
I0215 23:12:21.852370 23126066861888 run_lib.py:146] step: 266500, eval_loss: 2.77419e-02
I0215 23:12:39.358168 23126066861888 run_lib.py:133] step: 266550, training_loss: 1.80294e-02
I0215 23:12:56.809317 23126066861888 run_lib.py:133] step: 266600, training_loss: 1.90990e-02
I0215 23:12:56.964684 23126066861888 run_lib.py:146] step: 266600, eval_loss: 2.79903e-02
I0215 23:13:14.375739 23126066861888 run_lib.py:133] step: 266650, training_loss: 1.89525e-02
I0215 23:13:32.013716 23126066861888 run_lib.py:133] step: 266700, training_loss: 1.84296e-02
I0215 23:13:32.171655 23126066861888 run_lib.py:146] step: 266700, eval_loss: 2.67731e-02
I0215 23:13:49.578988 23126066861888 run_lib.py:133] step: 266750, training_loss: 1.89025e-02
I0215 23:14:07.155286 23126066861888 run_lib.py:133] step: 266800, training_loss: 1.89161e-02
I0215 23:14:07.311405 23126066861888 run_lib.py:146] step: 266800, eval_loss: 2.74397e-02
I0215 23:14:24.712605 23126066861888 run_lib.py:133] step: 266850, training_loss: 1.88032e-02
I0215 23:14:42.137891 23126066861888 run_lib.py:133] step: 266900, training_loss: 1.85488e-02
I0215 23:14:42.301132 23126066861888 run_lib.py:146] step: 266900, eval_loss: 2.68354e-02
I0215 23:14:59.922250 23126066861888 run_lib.py:133] step: 266950, training_loss: 1.89447e-02
I0215 23:15:17.330357 23126066861888 run_lib.py:133] step: 267000, training_loss: 1.85220e-02
I0215 23:15:17.483043 23126066861888 run_lib.py:146] step: 267000, eval_loss: 2.68977e-02
I0215 23:15:34.896411 23126066861888 run_lib.py:133] step: 267050, training_loss: 1.87789e-02
I0215 23:15:52.437217 23126066861888 run_lib.py:133] step: 267100, training_loss: 1.86469e-02
I0215 23:15:52.597153 23126066861888 run_lib.py:146] step: 267100, eval_loss: 2.67722e-02
I0215 23:16:10.053581 23126066861888 run_lib.py:133] step: 267150, training_loss: 1.86327e-02
I0215 23:16:27.484627 23126066861888 run_lib.py:133] step: 267200, training_loss: 1.81393e-02
I0215 23:16:27.640545 23126066861888 run_lib.py:146] step: 267200, eval_loss: 2.72892e-02
I0215 23:16:45.187346 23126066861888 run_lib.py:133] step: 267250, training_loss: 1.86943e-02
I0215 23:17:02.592181 23126066861888 run_lib.py:133] step: 267300, training_loss: 1.87132e-02
I0215 23:17:02.746253 23126066861888 run_lib.py:146] step: 267300, eval_loss: 2.73054e-02
I0215 23:17:20.119387 23126066861888 run_lib.py:133] step: 267350, training_loss: 1.84422e-02
I0215 23:17:37.535689 23126066861888 run_lib.py:133] step: 267400, training_loss: 1.91895e-02
I0215 23:17:37.703943 23126066861888 run_lib.py:146] step: 267400, eval_loss: 2.70671e-02
I0215 23:17:55.286638 23126066861888 run_lib.py:133] step: 267450, training_loss: 1.96059e-02
I0215 23:18:12.842220 23126066861888 run_lib.py:133] step: 267500, training_loss: 1.82788e-02
I0215 23:18:12.996190 23126066861888 run_lib.py:146] step: 267500, eval_loss: 2.81234e-02
I0215 23:18:30.447579 23126066861888 run_lib.py:133] step: 267550, training_loss: 1.90200e-02
I0215 23:18:47.792893 23126066861888 run_lib.py:133] step: 267600, training_loss: 1.85639e-02
I0215 23:18:47.945138 23126066861888 run_lib.py:146] step: 267600, eval_loss: 2.72456e-02
I0215 23:19:05.514687 23126066861888 run_lib.py:133] step: 267650, training_loss: 1.82185e-02
I0215 23:19:22.922827 23126066861888 run_lib.py:133] step: 267700, training_loss: 1.86951e-02
I0215 23:19:23.083966 23126066861888 run_lib.py:146] step: 267700, eval_loss: 2.71633e-02
I0215 23:19:40.582863 23126066861888 run_lib.py:133] step: 267750, training_loss: 1.87105e-02
I0215 23:19:58.139064 23126066861888 run_lib.py:133] step: 267800, training_loss: 1.86979e-02
I0215 23:19:58.296060 23126066861888 run_lib.py:146] step: 267800, eval_loss: 2.78343e-02
I0215 23:20:15.696781 23126066861888 run_lib.py:133] step: 267850, training_loss: 1.89647e-02
I0215 23:20:33.272317 23126066861888 run_lib.py:133] step: 267900, training_loss: 1.88952e-02
I0215 23:20:33.439203 23126066861888 run_lib.py:146] step: 267900, eval_loss: 2.67722e-02
I0215 23:20:50.848638 23126066861888 run_lib.py:133] step: 267950, training_loss: 1.79400e-02
I0215 23:21:08.222353 23126066861888 run_lib.py:133] step: 268000, training_loss: 1.84216e-02
I0215 23:21:08.378102 23126066861888 run_lib.py:146] step: 268000, eval_loss: 2.73759e-02
I0215 23:21:25.940245 23126066861888 run_lib.py:133] step: 268050, training_loss: 1.81145e-02
I0215 23:21:43.401578 23126066861888 run_lib.py:133] step: 268100, training_loss: 1.89514e-02
I0215 23:21:43.554270 23126066861888 run_lib.py:146] step: 268100, eval_loss: 2.78523e-02
I0215 23:22:00.854866 23126066861888 run_lib.py:133] step: 268150, training_loss: 1.94278e-02
I0215 23:22:18.413701 23126066861888 run_lib.py:133] step: 268200, training_loss: 1.91511e-02
I0215 23:22:18.566034 23126066861888 run_lib.py:146] step: 268200, eval_loss: 2.72474e-02
I0215 23:22:35.936354 23126066861888 run_lib.py:133] step: 268250, training_loss: 1.87809e-02
I0215 23:22:53.373241 23126066861888 run_lib.py:133] step: 268300, training_loss: 1.85704e-02
I0215 23:22:53.530445 23126066861888 run_lib.py:146] step: 268300, eval_loss: 2.70373e-02
I0215 23:23:11.040817 23126066861888 run_lib.py:133] step: 268350, training_loss: 1.80337e-02
I0215 23:23:28.472839 23126066861888 run_lib.py:133] step: 268400, training_loss: 1.90952e-02
I0215 23:23:28.629643 23126066861888 run_lib.py:146] step: 268400, eval_loss: 2.85620e-02
I0215 23:23:46.071033 23126066861888 run_lib.py:133] step: 268450, training_loss: 1.91928e-02
I0215 23:24:03.505837 23126066861888 run_lib.py:133] step: 268500, training_loss: 1.87948e-02
I0215 23:24:03.659759 23126066861888 run_lib.py:146] step: 268500, eval_loss: 2.80428e-02
I0215 23:24:21.239794 23126066861888 run_lib.py:133] step: 268550, training_loss: 1.79657e-02
I0215 23:24:38.741967 23126066861888 run_lib.py:133] step: 268600, training_loss: 1.92642e-02
I0215 23:24:38.893929 23126066861888 run_lib.py:146] step: 268600, eval_loss: 2.63620e-02
I0215 23:24:56.320918 23126066861888 run_lib.py:133] step: 268650, training_loss: 1.88932e-02
I0215 23:25:13.769439 23126066861888 run_lib.py:133] step: 268700, training_loss: 1.92640e-02
I0215 23:25:13.928328 23126066861888 run_lib.py:146] step: 268700, eval_loss: 2.78827e-02
I0215 23:25:31.535567 23126066861888 run_lib.py:133] step: 268750, training_loss: 1.89406e-02
I0215 23:25:48.954214 23126066861888 run_lib.py:133] step: 268800, training_loss: 1.82619e-02
I0215 23:25:49.109507 23126066861888 run_lib.py:146] step: 268800, eval_loss: 2.74747e-02
I0215 23:26:06.477995 23126066861888 run_lib.py:133] step: 268850, training_loss: 1.83309e-02
I0215 23:26:24.038048 23126066861888 run_lib.py:133] step: 268900, training_loss: 1.80872e-02
I0215 23:26:24.193041 23126066861888 run_lib.py:146] step: 268900, eval_loss: 2.67264e-02
I0215 23:26:41.570999 23126066861888 run_lib.py:133] step: 268950, training_loss: 1.87220e-02
I0215 23:26:59.185948 23126066861888 run_lib.py:133] step: 269000, training_loss: 1.87580e-02
I0215 23:26:59.340513 23126066861888 run_lib.py:146] step: 269000, eval_loss: 2.71013e-02
I0215 23:27:16.747554 23126066861888 run_lib.py:133] step: 269050, training_loss: 1.80489e-02
I0215 23:27:34.126282 23126066861888 run_lib.py:133] step: 269100, training_loss: 1.87081e-02
I0215 23:27:34.277287 23126066861888 run_lib.py:146] step: 269100, eval_loss: 2.79470e-02
I0215 23:27:51.849441 23126066861888 run_lib.py:133] step: 269150, training_loss: 1.84172e-02
I0215 23:28:09.259007 23126066861888 run_lib.py:133] step: 269200, training_loss: 1.87636e-02
I0215 23:28:09.416008 23126066861888 run_lib.py:146] step: 269200, eval_loss: 2.72600e-02
I0215 23:28:26.835547 23126066861888 run_lib.py:133] step: 269250, training_loss: 1.83184e-02
I0215 23:28:44.329869 23126066861888 run_lib.py:133] step: 269300, training_loss: 1.81777e-02
I0215 23:28:44.495042 23126066861888 run_lib.py:146] step: 269300, eval_loss: 2.73285e-02
I0215 23:29:01.931768 23126066861888 run_lib.py:133] step: 269350, training_loss: 1.85683e-02
I0215 23:29:19.372233 23126066861888 run_lib.py:133] step: 269400, training_loss: 1.83210e-02
I0215 23:29:19.528373 23126066861888 run_lib.py:146] step: 269400, eval_loss: 2.72399e-02
I0215 23:29:37.132290 23126066861888 run_lib.py:133] step: 269450, training_loss: 1.87000e-02
I0215 23:29:54.603867 23126066861888 run_lib.py:133] step: 269500, training_loss: 1.84761e-02
I0215 23:29:54.776281 23126066861888 run_lib.py:146] step: 269500, eval_loss: 2.78683e-02
I0215 23:30:12.246613 23126066861888 run_lib.py:133] step: 269550, training_loss: 1.84829e-02
I0215 23:30:29.791246 23126066861888 run_lib.py:133] step: 269600, training_loss: 1.79059e-02
I0215 23:30:29.947702 23126066861888 run_lib.py:146] step: 269600, eval_loss: 2.72112e-02
I0215 23:30:47.772453 23126066861888 run_lib.py:133] step: 269650, training_loss: 1.88287e-02
I0215 23:31:05.390719 23126066861888 run_lib.py:133] step: 269700, training_loss: 1.84797e-02
I0215 23:31:05.555442 23126066861888 run_lib.py:146] step: 269700, eval_loss: 2.75982e-02
I0215 23:31:22.983670 23126066861888 run_lib.py:133] step: 269750, training_loss: 1.79999e-02
I0215 23:31:40.437263 23126066861888 run_lib.py:133] step: 269800, training_loss: 1.82388e-02
I0215 23:31:40.604229 23126066861888 run_lib.py:146] step: 269800, eval_loss: 2.72457e-02
I0215 23:31:58.278401 23126066861888 run_lib.py:133] step: 269850, training_loss: 1.94772e-02
I0215 23:32:15.808252 23126066861888 run_lib.py:133] step: 269900, training_loss: 1.83561e-02
I0215 23:32:15.965182 23126066861888 run_lib.py:146] step: 269900, eval_loss: 2.72696e-02
I0215 23:32:33.350422 23126066861888 run_lib.py:133] step: 269950, training_loss: 1.84761e-02
I0215 23:32:50.899230 23126066861888 run_lib.py:133] step: 270000, training_loss: 1.79147e-02
I0215 23:32:51.610975 23126066861888 run_lib.py:146] step: 270000, eval_loss: 2.74437e-02
I0215 23:33:11.542994 23126066861888 run_lib.py:133] step: 270050, training_loss: 1.89237e-02
I0215 23:33:28.920336 23126066861888 run_lib.py:133] step: 270100, training_loss: 1.79733e-02
I0215 23:33:29.074289 23126066861888 run_lib.py:146] step: 270100, eval_loss: 2.73234e-02
I0215 23:33:46.657561 23126066861888 run_lib.py:133] step: 270150, training_loss: 1.87330e-02
I0215 23:34:04.226860 23126066861888 run_lib.py:133] step: 270200, training_loss: 1.86723e-02
I0215 23:34:04.382166 23126066861888 run_lib.py:146] step: 270200, eval_loss: 2.67739e-02
I0215 23:34:21.790292 23126066861888 run_lib.py:133] step: 270250, training_loss: 1.82931e-02
I0215 23:34:39.223400 23126066861888 run_lib.py:133] step: 270300, training_loss: 1.85744e-02
I0215 23:34:39.386389 23126066861888 run_lib.py:146] step: 270300, eval_loss: 2.72488e-02
I0215 23:34:56.956948 23126066861888 run_lib.py:133] step: 270350, training_loss: 1.87907e-02
I0215 23:35:14.391530 23126066861888 run_lib.py:133] step: 270400, training_loss: 1.91731e-02
I0215 23:35:14.548262 23126066861888 run_lib.py:146] step: 270400, eval_loss: 2.77115e-02
I0215 23:35:32.179379 23126066861888 run_lib.py:133] step: 270450, training_loss: 1.94534e-02
I0215 23:35:49.592614 23126066861888 run_lib.py:133] step: 270500, training_loss: 1.86099e-02
I0215 23:35:49.745117 23126066861888 run_lib.py:146] step: 270500, eval_loss: 2.69457e-02
I0215 23:36:07.178272 23126066861888 run_lib.py:133] step: 270550, training_loss: 1.86235e-02
I0215 23:36:24.747706 23126066861888 run_lib.py:133] step: 270600, training_loss: 1.78978e-02
I0215 23:36:24.908193 23126066861888 run_lib.py:146] step: 270600, eval_loss: 2.68577e-02
I0215 23:36:42.350214 23126066861888 run_lib.py:133] step: 270650, training_loss: 1.86192e-02
I0215 23:36:59.830605 23126066861888 run_lib.py:133] step: 270700, training_loss: 1.89003e-02
I0215 23:36:59.990836 23126066861888 run_lib.py:146] step: 270700, eval_loss: 2.66680e-02
I0215 23:37:17.623284 23126066861888 run_lib.py:133] step: 270750, training_loss: 1.81044e-02
I0215 23:37:35.068875 23126066861888 run_lib.py:133] step: 270800, training_loss: 1.85299e-02
I0215 23:37:35.228225 23126066861888 run_lib.py:146] step: 270800, eval_loss: 2.78048e-02
I0215 23:37:52.711322 23126066861888 run_lib.py:133] step: 270850, training_loss: 1.88812e-02
I0215 23:38:10.054465 23126066861888 run_lib.py:133] step: 270900, training_loss: 1.87850e-02
I0215 23:38:10.213849 23126066861888 run_lib.py:146] step: 270900, eval_loss: 2.75697e-02
I0215 23:38:27.584928 23126066861888 run_lib.py:133] step: 270950, training_loss: 1.85657e-02
I0215 23:38:45.177644 23126066861888 run_lib.py:133] step: 271000, training_loss: 1.83840e-02
I0215 23:38:45.333229 23126066861888 run_lib.py:146] step: 271000, eval_loss: 2.76629e-02
I0215 23:39:02.708491 23126066861888 run_lib.py:133] step: 271050, training_loss: 1.81406e-02
I0215 23:39:20.027450 23126066861888 run_lib.py:133] step: 271100, training_loss: 1.81429e-02
I0215 23:39:20.228309 23126066861888 run_lib.py:146] step: 271100, eval_loss: 2.77617e-02
I0215 23:39:37.545558 23126066861888 run_lib.py:133] step: 271150, training_loss: 1.83187e-02
I0215 23:39:54.917834 23126066861888 run_lib.py:133] step: 271200, training_loss: 1.88958e-02
I0215 23:39:55.088287 23126066861888 run_lib.py:146] step: 271200, eval_loss: 2.67889e-02
I0215 23:40:12.754194 23126066861888 run_lib.py:133] step: 271250, training_loss: 1.88216e-02
I0215 23:40:30.269928 23126066861888 run_lib.py:133] step: 271300, training_loss: 1.81531e-02
I0215 23:40:30.427243 23126066861888 run_lib.py:146] step: 271300, eval_loss: 2.72205e-02
I0215 23:40:47.801961 23126066861888 run_lib.py:133] step: 271350, training_loss: 1.91823e-02
I0215 23:41:05.152540 23126066861888 run_lib.py:133] step: 271400, training_loss: 1.84526e-02
I0215 23:41:05.307747 23126066861888 run_lib.py:146] step: 271400, eval_loss: 2.80776e-02
I0215 23:41:22.804507 23126066861888 run_lib.py:133] step: 271450, training_loss: 1.88803e-02
I0215 23:41:40.114255 23126066861888 run_lib.py:133] step: 271500, training_loss: 1.86467e-02
I0215 23:41:40.270810 23126066861888 run_lib.py:146] step: 271500, eval_loss: 2.77572e-02
I0215 23:41:57.810781 23126066861888 run_lib.py:133] step: 271550, training_loss: 1.87982e-02
I0215 23:42:15.163536 23126066861888 run_lib.py:133] step: 271600, training_loss: 1.91460e-02
I0215 23:42:15.324556 23126066861888 run_lib.py:146] step: 271600, eval_loss: 2.81525e-02
I0215 23:42:32.731730 23126066861888 run_lib.py:133] step: 271650, training_loss: 1.86680e-02
I0215 23:42:50.249221 23126066861888 run_lib.py:133] step: 271700, training_loss: 1.87162e-02
I0215 23:42:50.406438 23126066861888 run_lib.py:146] step: 271700, eval_loss: 2.65080e-02
I0215 23:43:07.724618 23126066861888 run_lib.py:133] step: 271750, training_loss: 1.85156e-02
I0215 23:43:25.034093 23126066861888 run_lib.py:133] step: 271800, training_loss: 1.87951e-02
I0215 23:43:25.197007 23126066861888 run_lib.py:146] step: 271800, eval_loss: 2.92329e-02
I0215 23:43:42.697868 23126066861888 run_lib.py:133] step: 271850, training_loss: 1.80166e-02
I0215 23:44:00.051933 23126066861888 run_lib.py:133] step: 271900, training_loss: 1.87738e-02
I0215 23:44:00.208109 23126066861888 run_lib.py:146] step: 271900, eval_loss: 2.76975e-02
I0215 23:44:17.564687 23126066861888 run_lib.py:133] step: 271950, training_loss: 1.88263e-02
I0215 23:44:35.067050 23126066861888 run_lib.py:133] step: 272000, training_loss: 1.89607e-02
I0215 23:44:35.220943 23126066861888 run_lib.py:146] step: 272000, eval_loss: 2.67262e-02
I0215 23:44:52.523408 23126066861888 run_lib.py:133] step: 272050, training_loss: 1.88954e-02
I0215 23:45:09.874142 23126066861888 run_lib.py:133] step: 272100, training_loss: 1.91197e-02
I0215 23:45:10.028924 23126066861888 run_lib.py:146] step: 272100, eval_loss: 2.67132e-02
I0215 23:45:27.471138 23126066861888 run_lib.py:133] step: 272150, training_loss: 1.78395e-02
I0215 23:45:44.867291 23126066861888 run_lib.py:133] step: 272200, training_loss: 1.80029e-02
I0215 23:45:45.024860 23126066861888 run_lib.py:146] step: 272200, eval_loss: 2.83064e-02
I0215 23:46:02.385784 23126066861888 run_lib.py:133] step: 272250, training_loss: 1.75121e-02
I0215 23:46:19.710997 23126066861888 run_lib.py:133] step: 272300, training_loss: 1.82277e-02
I0215 23:46:19.868012 23126066861888 run_lib.py:146] step: 272300, eval_loss: 2.75670e-02
I0215 23:46:37.380095 23126066861888 run_lib.py:133] step: 272350, training_loss: 1.85766e-02
I0215 23:46:54.781035 23126066861888 run_lib.py:133] step: 272400, training_loss: 1.84805e-02
I0215 23:46:54.946956 23126066861888 run_lib.py:146] step: 272400, eval_loss: 2.68399e-02
I0215 23:47:12.328687 23126066861888 run_lib.py:133] step: 272450, training_loss: 1.94480e-02
I0215 23:47:29.645960 23126066861888 run_lib.py:133] step: 272500, training_loss: 1.89850e-02
I0215 23:47:29.799204 23126066861888 run_lib.py:146] step: 272500, eval_loss: 2.69656e-02
I0215 23:47:47.289820 23126066861888 run_lib.py:133] step: 272550, training_loss: 1.90658e-02
I0215 23:48:04.636065 23126066861888 run_lib.py:133] step: 272600, training_loss: 1.92335e-02
I0215 23:48:04.790147 23126066861888 run_lib.py:146] step: 272600, eval_loss: 2.91931e-02
I0215 23:48:22.100984 23126066861888 run_lib.py:133] step: 272650, training_loss: 1.79656e-02
I0215 23:48:39.587983 23126066861888 run_lib.py:133] step: 272700, training_loss: 1.83932e-02
I0215 23:48:39.768839 23126066861888 run_lib.py:146] step: 272700, eval_loss: 2.84488e-02
I0215 23:48:57.159204 23126066861888 run_lib.py:133] step: 272750, training_loss: 1.91495e-02
I0215 23:49:14.739809 23126066861888 run_lib.py:133] step: 272800, training_loss: 1.77378e-02
I0215 23:49:14.896294 23126066861888 run_lib.py:146] step: 272800, eval_loss: 2.75719e-02
I0215 23:49:32.324271 23126066861888 run_lib.py:133] step: 272850, training_loss: 1.84161e-02
I0215 23:49:49.699629 23126066861888 run_lib.py:133] step: 272900, training_loss: 1.85151e-02
I0215 23:49:49.852828 23126066861888 run_lib.py:146] step: 272900, eval_loss: 2.71427e-02
I0215 23:50:07.381658 23126066861888 run_lib.py:133] step: 272950, training_loss: 1.90414e-02
I0215 23:50:24.757943 23126066861888 run_lib.py:133] step: 273000, training_loss: 1.83794e-02
I0215 23:50:24.911148 23126066861888 run_lib.py:146] step: 273000, eval_loss: 2.73582e-02
I0215 23:50:42.315451 23126066861888 run_lib.py:133] step: 273050, training_loss: 1.91416e-02
I0215 23:50:59.882694 23126066861888 run_lib.py:133] step: 273100, training_loss: 1.81546e-02
I0215 23:51:00.043842 23126066861888 run_lib.py:146] step: 273100, eval_loss: 2.70145e-02
I0215 23:51:17.341885 23126066861888 run_lib.py:133] step: 273150, training_loss: 1.87834e-02
I0215 23:51:34.683582 23126066861888 run_lib.py:133] step: 273200, training_loss: 1.87115e-02
I0215 23:51:34.837954 23126066861888 run_lib.py:146] step: 273200, eval_loss: 2.75191e-02
I0215 23:51:52.304973 23126066861888 run_lib.py:133] step: 273250, training_loss: 1.85577e-02
I0215 23:52:09.612314 23126066861888 run_lib.py:133] step: 273300, training_loss: 1.93948e-02
I0215 23:52:09.770804 23126066861888 run_lib.py:146] step: 273300, eval_loss: 2.65513e-02
I0215 23:52:27.193058 23126066861888 run_lib.py:133] step: 273350, training_loss: 1.86257e-02
I0215 23:52:44.537958 23126066861888 run_lib.py:133] step: 273400, training_loss: 1.88346e-02
I0215 23:52:44.694951 23126066861888 run_lib.py:146] step: 273400, eval_loss: 2.82076e-02
I0215 23:53:02.229510 23126066861888 run_lib.py:133] step: 273450, training_loss: 1.83401e-02
I0215 23:53:19.628622 23126066861888 run_lib.py:133] step: 273500, training_loss: 1.91097e-02
I0215 23:53:19.786914 23126066861888 run_lib.py:146] step: 273500, eval_loss: 2.64122e-02
I0215 23:53:37.079619 23126066861888 run_lib.py:133] step: 273550, training_loss: 1.82811e-02
I0215 23:53:54.461733 23126066861888 run_lib.py:133] step: 273600, training_loss: 1.86228e-02
I0215 23:53:54.635836 23126066861888 run_lib.py:146] step: 273600, eval_loss: 2.78494e-02
I0215 23:54:12.162682 23126066861888 run_lib.py:133] step: 273650, training_loss: 1.82754e-02
I0215 23:54:29.496841 23126066861888 run_lib.py:133] step: 273700, training_loss: 1.81340e-02
I0215 23:54:29.651190 23126066861888 run_lib.py:146] step: 273700, eval_loss: 2.75660e-02
I0215 23:54:46.995606 23126066861888 run_lib.py:133] step: 273750, training_loss: 1.85082e-02
I0215 23:55:04.495718 23126066861888 run_lib.py:133] step: 273800, training_loss: 1.85220e-02
I0215 23:55:04.654046 23126066861888 run_lib.py:146] step: 273800, eval_loss: 2.76185e-02
I0215 23:55:22.017914 23126066861888 run_lib.py:133] step: 273850, training_loss: 1.75011e-02
I0215 23:55:39.544571 23126066861888 run_lib.py:133] step: 273900, training_loss: 1.85759e-02
I0215 23:55:39.698141 23126066861888 run_lib.py:146] step: 273900, eval_loss: 2.76334e-02
I0215 23:55:57.093096 23126066861888 run_lib.py:133] step: 273950, training_loss: 1.88231e-02
I0215 23:56:14.447710 23126066861888 run_lib.py:133] step: 274000, training_loss: 1.83518e-02
I0215 23:56:14.603827 23126066861888 run_lib.py:146] step: 274000, eval_loss: 2.81283e-02
I0215 23:56:32.118545 23126066861888 run_lib.py:133] step: 274050, training_loss: 1.84561e-02
I0215 23:56:49.450991 23126066861888 run_lib.py:133] step: 274100, training_loss: 1.82126e-02
I0215 23:56:49.616147 23126066861888 run_lib.py:146] step: 274100, eval_loss: 2.82842e-02
I0215 23:57:06.943135 23126066861888 run_lib.py:133] step: 274150, training_loss: 1.83380e-02
I0215 23:57:24.498702 23126066861888 run_lib.py:133] step: 274200, training_loss: 1.82570e-02
I0215 23:57:24.653205 23126066861888 run_lib.py:146] step: 274200, eval_loss: 2.56867e-02
I0215 23:57:41.967242 23126066861888 run_lib.py:133] step: 274250, training_loss: 1.83504e-02
I0215 23:57:59.293701 23126066861888 run_lib.py:133] step: 274300, training_loss: 1.83313e-02
I0215 23:57:59.447746 23126066861888 run_lib.py:146] step: 274300, eval_loss: 2.74477e-02
I0215 23:58:16.803141 23126066861888 run_lib.py:133] step: 274350, training_loss: 1.84079e-02
I0215 23:58:34.214251 23126066861888 run_lib.py:133] step: 274400, training_loss: 1.91164e-02
I0215 23:58:34.370253 23126066861888 run_lib.py:146] step: 274400, eval_loss: 2.72189e-02
I0215 23:58:51.834514 23126066861888 run_lib.py:133] step: 274450, training_loss: 1.87523e-02
I0215 23:59:09.242860 23126066861888 run_lib.py:133] step: 274500, training_loss: 1.86828e-02
I0215 23:59:09.399110 23126066861888 run_lib.py:146] step: 274500, eval_loss: 2.75664e-02
I0215 23:59:26.953796 23126066861888 run_lib.py:133] step: 274550, training_loss: 1.92797e-02
I0215 23:59:44.303133 23126066861888 run_lib.py:133] step: 274600, training_loss: 1.97932e-02
I0215 23:59:44.465979 23126066861888 run_lib.py:146] step: 274600, eval_loss: 2.80267e-02
I0216 00:00:01.768512 23126066861888 run_lib.py:133] step: 274650, training_loss: 1.86130e-02
I0216 00:00:19.111942 23126066861888 run_lib.py:133] step: 274700, training_loss: 1.91978e-02
I0216 00:00:19.274067 23126066861888 run_lib.py:146] step: 274700, eval_loss: 2.76294e-02
I0216 00:00:36.816701 23126066861888 run_lib.py:133] step: 274750, training_loss: 1.81191e-02
I0216 00:00:54.186525 23126066861888 run_lib.py:133] step: 274800, training_loss: 1.84088e-02
I0216 00:00:54.340017 23126066861888 run_lib.py:146] step: 274800, eval_loss: 2.77371e-02
I0216 00:01:11.737284 23126066861888 run_lib.py:133] step: 274850, training_loss: 1.79484e-02
I0216 00:01:29.205816 23126066861888 run_lib.py:133] step: 274900, training_loss: 1.83516e-02
I0216 00:01:29.361908 23126066861888 run_lib.py:146] step: 274900, eval_loss: 2.78980e-02
I0216 00:01:46.667792 23126066861888 run_lib.py:133] step: 274950, training_loss: 1.81269e-02
I0216 00:02:04.174633 23126066861888 run_lib.py:133] step: 275000, training_loss: 1.94024e-02
I0216 00:02:04.345481 23126066861888 run_lib.py:146] step: 275000, eval_loss: 2.71887e-02
I0216 00:02:21.682284 23126066861888 run_lib.py:133] step: 275050, training_loss: 1.82895e-02
I0216 00:02:39.014171 23126066861888 run_lib.py:133] step: 275100, training_loss: 1.84519e-02
I0216 00:02:39.168095 23126066861888 run_lib.py:146] step: 275100, eval_loss: 2.59594e-02
I0216 00:02:56.708597 23126066861888 run_lib.py:133] step: 275150, training_loss: 1.85685e-02
I0216 00:03:14.031280 23126066861888 run_lib.py:133] step: 275200, training_loss: 1.83706e-02
I0216 00:03:14.186025 23126066861888 run_lib.py:146] step: 275200, eval_loss: 2.68078e-02
I0216 00:03:31.449246 23126066861888 run_lib.py:133] step: 275250, training_loss: 1.80422e-02
I0216 00:03:49.025115 23126066861888 run_lib.py:133] step: 275300, training_loss: 1.79478e-02
I0216 00:03:49.176599 23126066861888 run_lib.py:146] step: 275300, eval_loss: 2.79655e-02
I0216 00:04:06.576094 23126066861888 run_lib.py:133] step: 275350, training_loss: 1.82451e-02
I0216 00:04:23.849128 23126066861888 run_lib.py:133] step: 275400, training_loss: 1.80330e-02
I0216 00:04:24.001844 23126066861888 run_lib.py:146] step: 275400, eval_loss: 2.66360e-02
I0216 00:04:41.346841 23126066861888 run_lib.py:133] step: 275450, training_loss: 1.87991e-02
I0216 00:04:58.692835 23126066861888 run_lib.py:133] step: 275500, training_loss: 1.83588e-02
I0216 00:04:58.894798 23126066861888 run_lib.py:146] step: 275500, eval_loss: 2.73318e-02
I0216 00:05:16.320878 23126066861888 run_lib.py:133] step: 275550, training_loss: 1.85667e-02
I0216 00:05:33.695853 23126066861888 run_lib.py:133] step: 275600, training_loss: 1.94329e-02
I0216 00:05:33.857154 23126066861888 run_lib.py:146] step: 275600, eval_loss: 2.73955e-02
I0216 00:05:51.380656 23126066861888 run_lib.py:133] step: 275650, training_loss: 1.83981e-02
I0216 00:06:08.763396 23126066861888 run_lib.py:133] step: 275700, training_loss: 1.85992e-02
I0216 00:06:08.918748 23126066861888 run_lib.py:146] step: 275700, eval_loss: 2.90046e-02
I0216 00:06:26.255518 23126066861888 run_lib.py:133] step: 275750, training_loss: 1.79219e-02
I0216 00:06:43.607183 23126066861888 run_lib.py:133] step: 275800, training_loss: 1.88133e-02
I0216 00:06:43.758957 23126066861888 run_lib.py:146] step: 275800, eval_loss: 2.76329e-02
I0216 00:07:01.229670 23126066861888 run_lib.py:133] step: 275850, training_loss: 1.86086e-02
I0216 00:07:18.628861 23126066861888 run_lib.py:133] step: 275900, training_loss: 1.77699e-02
I0216 00:07:18.791246 23126066861888 run_lib.py:146] step: 275900, eval_loss: 2.67387e-02
I0216 00:07:36.132925 23126066861888 run_lib.py:133] step: 275950, training_loss: 1.84046e-02
I0216 00:07:53.693166 23126066861888 run_lib.py:133] step: 276000, training_loss: 1.80964e-02
I0216 00:07:53.851177 23126066861888 run_lib.py:146] step: 276000, eval_loss: 2.63466e-02
I0216 00:08:11.238992 23126066861888 run_lib.py:133] step: 276050, training_loss: 1.89079e-02
I0216 00:08:28.782089 23126066861888 run_lib.py:133] step: 276100, training_loss: 1.89015e-02
I0216 00:08:28.936877 23126066861888 run_lib.py:146] step: 276100, eval_loss: 2.72572e-02
I0216 00:08:46.297941 23126066861888 run_lib.py:133] step: 276150, training_loss: 1.89992e-02
I0216 00:09:03.697185 23126066861888 run_lib.py:133] step: 276200, training_loss: 1.84274e-02
I0216 00:09:03.850906 23126066861888 run_lib.py:146] step: 276200, eval_loss: 2.64048e-02
I0216 00:09:21.423885 23126066861888 run_lib.py:133] step: 276250, training_loss: 1.84388e-02
I0216 00:09:38.722620 23126066861888 run_lib.py:133] step: 276300, training_loss: 1.75420e-02
I0216 00:09:38.883701 23126066861888 run_lib.py:146] step: 276300, eval_loss: 2.68570e-02
I0216 00:09:56.220415 23126066861888 run_lib.py:133] step: 276350, training_loss: 1.90690e-02
I0216 00:10:13.713321 23126066861888 run_lib.py:133] step: 276400, training_loss: 1.74347e-02
I0216 00:10:13.870169 23126066861888 run_lib.py:146] step: 276400, eval_loss: 2.80842e-02
I0216 00:10:31.210101 23126066861888 run_lib.py:133] step: 276450, training_loss: 1.80316e-02
I0216 00:10:48.639006 23126066861888 run_lib.py:133] step: 276500, training_loss: 1.85514e-02
I0216 00:10:48.804934 23126066861888 run_lib.py:146] step: 276500, eval_loss: 2.69078e-02
I0216 00:11:06.329257 23126066861888 run_lib.py:133] step: 276550, training_loss: 1.82736e-02
I0216 00:11:23.669510 23126066861888 run_lib.py:133] step: 276600, training_loss: 1.82145e-02
I0216 00:11:23.823940 23126066861888 run_lib.py:146] step: 276600, eval_loss: 2.75792e-02
I0216 00:11:41.195449 23126066861888 run_lib.py:133] step: 276650, training_loss: 1.88763e-02
I0216 00:11:58.518745 23126066861888 run_lib.py:133] step: 276700, training_loss: 1.88321e-02
I0216 00:11:58.670852 23126066861888 run_lib.py:146] step: 276700, eval_loss: 2.69866e-02
I0216 00:12:16.194699 23126066861888 run_lib.py:133] step: 276750, training_loss: 1.85149e-02
I0216 00:12:33.680660 23126066861888 run_lib.py:133] step: 276800, training_loss: 1.80587e-02
I0216 00:12:33.844196 23126066861888 run_lib.py:146] step: 276800, eval_loss: 2.65920e-02
I0216 00:12:51.238666 23126066861888 run_lib.py:133] step: 276850, training_loss: 1.93204e-02
I0216 00:13:08.671135 23126066861888 run_lib.py:133] step: 276900, training_loss: 1.89099e-02
I0216 00:13:08.838187 23126066861888 run_lib.py:146] step: 276900, eval_loss: 2.80651e-02
I0216 00:13:26.419205 23126066861888 run_lib.py:133] step: 276950, training_loss: 1.80398e-02
I0216 00:13:43.830803 23126066861888 run_lib.py:133] step: 277000, training_loss: 1.89300e-02
I0216 00:13:44.011917 23126066861888 run_lib.py:146] step: 277000, eval_loss: 2.65427e-02
I0216 00:14:01.453566 23126066861888 run_lib.py:133] step: 277050, training_loss: 1.86494e-02
I0216 00:14:19.055855 23126066861888 run_lib.py:133] step: 277100, training_loss: 1.84763e-02
I0216 00:14:19.212675 23126066861888 run_lib.py:146] step: 277100, eval_loss: 2.67483e-02
I0216 00:14:36.594367 23126066861888 run_lib.py:133] step: 277150, training_loss: 1.86967e-02
I0216 00:14:54.197578 23126066861888 run_lib.py:133] step: 277200, training_loss: 1.82327e-02
I0216 00:14:54.346009 23126066861888 run_lib.py:146] step: 277200, eval_loss: 2.66015e-02
I0216 00:15:11.652780 23126066861888 run_lib.py:133] step: 277250, training_loss: 1.80666e-02
I0216 00:15:29.023909 23126066861888 run_lib.py:133] step: 277300, training_loss: 1.80628e-02
I0216 00:15:29.186213 23126066861888 run_lib.py:146] step: 277300, eval_loss: 2.78014e-02
I0216 00:15:46.746323 23126066861888 run_lib.py:133] step: 277350, training_loss: 1.87564e-02
I0216 00:16:04.116914 23126066861888 run_lib.py:133] step: 277400, training_loss: 1.88824e-02
I0216 00:16:04.273983 23126066861888 run_lib.py:146] step: 277400, eval_loss: 2.70122e-02
I0216 00:16:21.582869 23126066861888 run_lib.py:133] step: 277450, training_loss: 1.87924e-02
I0216 00:16:39.096588 23126066861888 run_lib.py:133] step: 277500, training_loss: 1.89631e-02
I0216 00:16:39.252038 23126066861888 run_lib.py:146] step: 277500, eval_loss: 2.83582e-02
I0216 00:16:56.596118 23126066861888 run_lib.py:133] step: 277550, training_loss: 1.88653e-02
I0216 00:17:13.907087 23126066861888 run_lib.py:133] step: 277600, training_loss: 1.87902e-02
I0216 00:17:14.059879 23126066861888 run_lib.py:146] step: 277600, eval_loss: 2.72582e-02
I0216 00:17:31.569417 23126066861888 run_lib.py:133] step: 277650, training_loss: 1.81159e-02
I0216 00:17:49.018051 23126066861888 run_lib.py:133] step: 277700, training_loss: 1.83141e-02
I0216 00:17:49.179938 23126066861888 run_lib.py:146] step: 277700, eval_loss: 2.74633e-02
I0216 00:18:06.584772 23126066861888 run_lib.py:133] step: 277750, training_loss: 1.84794e-02
I0216 00:18:23.982999 23126066861888 run_lib.py:133] step: 277800, training_loss: 1.94012e-02
I0216 00:18:24.137959 23126066861888 run_lib.py:146] step: 277800, eval_loss: 2.84268e-02
I0216 00:18:41.599215 23126066861888 run_lib.py:133] step: 277850, training_loss: 1.75167e-02
I0216 00:18:59.042680 23126066861888 run_lib.py:133] step: 277900, training_loss: 1.87493e-02
I0216 00:18:59.201818 23126066861888 run_lib.py:146] step: 277900, eval_loss: 2.78229e-02
I0216 00:19:16.514399 23126066861888 run_lib.py:133] step: 277950, training_loss: 1.89153e-02
I0216 00:19:33.883976 23126066861888 run_lib.py:133] step: 278000, training_loss: 1.91166e-02
I0216 00:19:34.039115 23126066861888 run_lib.py:146] step: 278000, eval_loss: 2.75907e-02
I0216 00:19:51.526463 23126066861888 run_lib.py:133] step: 278050, training_loss: 1.78613e-02
I0216 00:20:08.839693 23126066861888 run_lib.py:133] step: 278100, training_loss: 1.80967e-02
I0216 00:20:08.993986 23126066861888 run_lib.py:146] step: 278100, eval_loss: 2.55835e-02
I0216 00:20:26.284103 23126066861888 run_lib.py:133] step: 278150, training_loss: 1.92815e-02
I0216 00:20:43.765078 23126066861888 run_lib.py:133] step: 278200, training_loss: 1.89885e-02
I0216 00:20:43.917819 23126066861888 run_lib.py:146] step: 278200, eval_loss: 2.71457e-02
I0216 00:21:01.241004 23126066861888 run_lib.py:133] step: 278250, training_loss: 1.88430e-02
I0216 00:21:18.788227 23126066861888 run_lib.py:133] step: 278300, training_loss: 1.89602e-02
I0216 00:21:18.947896 23126066861888 run_lib.py:146] step: 278300, eval_loss: 2.72651e-02
I0216 00:21:36.264062 23126066861888 run_lib.py:133] step: 278350, training_loss: 1.86279e-02
I0216 00:21:53.572067 23126066861888 run_lib.py:133] step: 278400, training_loss: 1.81382e-02
I0216 00:21:53.727194 23126066861888 run_lib.py:146] step: 278400, eval_loss: 2.70956e-02
I0216 00:22:11.216285 23126066861888 run_lib.py:133] step: 278450, training_loss: 1.85716e-02
I0216 00:22:28.535947 23126066861888 run_lib.py:133] step: 278500, training_loss: 1.86834e-02
I0216 00:22:28.689801 23126066861888 run_lib.py:146] step: 278500, eval_loss: 2.80652e-02
I0216 00:22:46.035441 23126066861888 run_lib.py:133] step: 278550, training_loss: 1.96113e-02
I0216 00:23:03.602067 23126066861888 run_lib.py:133] step: 278600, training_loss: 1.86632e-02
I0216 00:23:03.754600 23126066861888 run_lib.py:146] step: 278600, eval_loss: 2.72638e-02
I0216 00:23:21.088010 23126066861888 run_lib.py:133] step: 278650, training_loss: 1.84257e-02
I0216 00:23:38.428213 23126066861888 run_lib.py:133] step: 278700, training_loss: 1.81881e-02
I0216 00:23:38.582497 23126066861888 run_lib.py:146] step: 278700, eval_loss: 2.75989e-02
I0216 00:23:55.952408 23126066861888 run_lib.py:133] step: 278750, training_loss: 1.83718e-02
I0216 00:24:13.316347 23126066861888 run_lib.py:133] step: 278800, training_loss: 1.85840e-02
I0216 00:24:13.474152 23126066861888 run_lib.py:146] step: 278800, eval_loss: 2.63170e-02
I0216 00:24:30.783682 23126066861888 run_lib.py:133] step: 278850, training_loss: 1.85284e-02
I0216 00:24:48.156083 23126066861888 run_lib.py:133] step: 278900, training_loss: 1.80141e-02
I0216 00:24:48.319665 23126066861888 run_lib.py:146] step: 278900, eval_loss: 2.69533e-02
I0216 00:25:05.803232 23126066861888 run_lib.py:133] step: 278950, training_loss: 1.90362e-02
I0216 00:25:23.197720 23126066861888 run_lib.py:133] step: 279000, training_loss: 1.89766e-02
I0216 00:25:23.351666 23126066861888 run_lib.py:146] step: 279000, eval_loss: 2.74389e-02
I0216 00:25:40.684904 23126066861888 run_lib.py:133] step: 279050, training_loss: 1.86560e-02
I0216 00:25:58.111868 23126066861888 run_lib.py:133] step: 279100, training_loss: 1.90136e-02
I0216 00:25:58.265196 23126066861888 run_lib.py:146] step: 279100, eval_loss: 2.73596e-02
I0216 00:26:15.830229 23126066861888 run_lib.py:133] step: 279150, training_loss: 1.90354e-02
I0216 00:26:33.157133 23126066861888 run_lib.py:133] step: 279200, training_loss: 1.85369e-02
I0216 00:26:33.311944 23126066861888 run_lib.py:146] step: 279200, eval_loss: 2.77181e-02
I0216 00:26:50.697565 23126066861888 run_lib.py:133] step: 279250, training_loss: 1.89847e-02
I0216 00:27:08.269393 23126066861888 run_lib.py:133] step: 279300, training_loss: 1.83051e-02
I0216 00:27:08.433164 23126066861888 run_lib.py:146] step: 279300, eval_loss: 2.75191e-02
I0216 00:27:25.796130 23126066861888 run_lib.py:133] step: 279350, training_loss: 1.84463e-02
I0216 00:27:43.248705 23126066861888 run_lib.py:133] step: 279400, training_loss: 1.84530e-02
I0216 00:27:43.411020 23126066861888 run_lib.py:146] step: 279400, eval_loss: 2.61693e-02
I0216 00:28:00.827022 23126066861888 run_lib.py:133] step: 279450, training_loss: 1.80959e-02
I0216 00:28:18.112409 23126066861888 run_lib.py:133] step: 279500, training_loss: 1.82197e-02
I0216 00:28:18.265607 23126066861888 run_lib.py:146] step: 279500, eval_loss: 2.64285e-02
I0216 00:28:35.830614 23126066861888 run_lib.py:133] step: 279550, training_loss: 1.87554e-02
I0216 00:28:53.162524 23126066861888 run_lib.py:133] step: 279600, training_loss: 1.83304e-02
I0216 00:28:53.312818 23126066861888 run_lib.py:146] step: 279600, eval_loss: 2.85870e-02
I0216 00:29:10.634355 23126066861888 run_lib.py:133] step: 279650, training_loss: 1.83526e-02
I0216 00:29:28.132929 23126066861888 run_lib.py:133] step: 279700, training_loss: 1.89092e-02
I0216 00:29:28.300047 23126066861888 run_lib.py:146] step: 279700, eval_loss: 2.78508e-02
I0216 00:29:45.718205 23126066861888 run_lib.py:133] step: 279750, training_loss: 1.78227e-02
I0216 00:30:03.056821 23126066861888 run_lib.py:133] step: 279800, training_loss: 1.84528e-02
I0216 00:30:03.212795 23126066861888 run_lib.py:146] step: 279800, eval_loss: 2.57091e-02
I0216 00:30:20.688672 23126066861888 run_lib.py:133] step: 279850, training_loss: 1.92093e-02
I0216 00:30:38.005728 23126066861888 run_lib.py:133] step: 279900, training_loss: 1.91988e-02
I0216 00:30:38.163885 23126066861888 run_lib.py:146] step: 279900, eval_loss: 2.75956e-02
I0216 00:30:55.483744 23126066861888 run_lib.py:133] step: 279950, training_loss: 1.80485e-02
I0216 00:31:12.908876 23126066861888 run_lib.py:133] step: 280000, training_loss: 1.81523e-02
I0216 00:31:13.597390 23126066861888 run_lib.py:146] step: 280000, eval_loss: 2.79670e-02
I0216 00:31:33.712530 23126066861888 run_lib.py:133] step: 280050, training_loss: 1.83172e-02
I0216 00:31:51.020510 23126066861888 run_lib.py:133] step: 280100, training_loss: 1.87170e-02
I0216 00:31:51.176162 23126066861888 run_lib.py:146] step: 280100, eval_loss: 2.64313e-02
I0216 00:32:08.558082 23126066861888 run_lib.py:133] step: 280150, training_loss: 1.86588e-02
I0216 00:32:25.963500 23126066861888 run_lib.py:133] step: 280200, training_loss: 1.82689e-02
I0216 00:32:26.117855 23126066861888 run_lib.py:146] step: 280200, eval_loss: 2.68809e-02
I0216 00:32:43.519790 23126066861888 run_lib.py:133] step: 280250, training_loss: 1.87603e-02
I0216 00:33:00.886240 23126066861888 run_lib.py:133] step: 280300, training_loss: 1.76996e-02
I0216 00:33:01.041217 23126066861888 run_lib.py:146] step: 280300, eval_loss: 2.76866e-02
I0216 00:33:18.542682 23126066861888 run_lib.py:133] step: 280350, training_loss: 1.87035e-02
I0216 00:33:35.950147 23126066861888 run_lib.py:133] step: 280400, training_loss: 1.83614e-02
I0216 00:33:36.105886 23126066861888 run_lib.py:146] step: 280400, eval_loss: 2.71463e-02
I0216 00:33:53.449187 23126066861888 run_lib.py:133] step: 280450, training_loss: 1.86789e-02
I0216 00:34:10.755703 23126066861888 run_lib.py:133] step: 280500, training_loss: 1.84002e-02
I0216 00:34:10.912689 23126066861888 run_lib.py:146] step: 280500, eval_loss: 2.77491e-02
I0216 00:34:28.405343 23126066861888 run_lib.py:133] step: 280550, training_loss: 1.87058e-02
I0216 00:34:45.746201 23126066861888 run_lib.py:133] step: 280600, training_loss: 1.89805e-02
I0216 00:34:45.897760 23126066861888 run_lib.py:146] step: 280600, eval_loss: 2.70587e-02
I0216 00:35:03.271236 23126066861888 run_lib.py:133] step: 280650, training_loss: 1.92411e-02
I0216 00:35:20.867753 23126066861888 run_lib.py:133] step: 280700, training_loss: 1.80666e-02
I0216 00:35:21.021887 23126066861888 run_lib.py:146] step: 280700, eval_loss: 2.80530e-02
I0216 00:35:38.313271 23126066861888 run_lib.py:133] step: 280750, training_loss: 1.84640e-02
I0216 00:35:55.761981 23126066861888 run_lib.py:133] step: 280800, training_loss: 1.88891e-02
I0216 00:35:55.933798 23126066861888 run_lib.py:146] step: 280800, eval_loss: 2.74035e-02
I0216 00:36:13.378921 23126066861888 run_lib.py:133] step: 280850, training_loss: 1.87345e-02
I0216 00:36:30.773716 23126066861888 run_lib.py:133] step: 280900, training_loss: 1.79161e-02
I0216 00:36:30.932209 23126066861888 run_lib.py:146] step: 280900, eval_loss: 2.64050e-02
I0216 00:36:48.511365 23126066861888 run_lib.py:133] step: 280950, training_loss: 1.84250e-02
I0216 00:37:05.799550 23126066861888 run_lib.py:133] step: 281000, training_loss: 1.84391e-02
I0216 00:37:05.955499 23126066861888 run_lib.py:146] step: 281000, eval_loss: 2.78714e-02
I0216 00:37:23.277152 23126066861888 run_lib.py:133] step: 281050, training_loss: 1.82822e-02
I0216 00:37:40.840268 23126066861888 run_lib.py:133] step: 281100, training_loss: 1.80137e-02
I0216 00:37:40.994179 23126066861888 run_lib.py:146] step: 281100, eval_loss: 2.84634e-02
I0216 00:37:58.338712 23126066861888 run_lib.py:133] step: 281150, training_loss: 1.88762e-02
I0216 00:38:15.678977 23126066861888 run_lib.py:133] step: 281200, training_loss: 1.80557e-02
I0216 00:38:15.832326 23126066861888 run_lib.py:146] step: 281200, eval_loss: 2.87906e-02
I0216 00:38:33.292540 23126066861888 run_lib.py:133] step: 281250, training_loss: 1.81233e-02
I0216 00:38:50.599774 23126066861888 run_lib.py:133] step: 281300, training_loss: 1.87655e-02
I0216 00:38:50.763131 23126066861888 run_lib.py:146] step: 281300, eval_loss: 2.85751e-02
I0216 00:39:08.109094 23126066861888 run_lib.py:133] step: 281350, training_loss: 1.89868e-02
I0216 00:39:25.518203 23126066861888 run_lib.py:133] step: 281400, training_loss: 1.88032e-02
I0216 00:39:25.691029 23126066861888 run_lib.py:146] step: 281400, eval_loss: 2.80020e-02
I0216 00:39:43.203670 23126066861888 run_lib.py:133] step: 281450, training_loss: 1.86276e-02
I0216 00:40:00.601928 23126066861888 run_lib.py:133] step: 281500, training_loss: 1.83559e-02
I0216 00:40:00.755995 23126066861888 run_lib.py:146] step: 281500, eval_loss: 2.63772e-02
I0216 00:40:18.070971 23126066861888 run_lib.py:133] step: 281550, training_loss: 1.82012e-02
I0216 00:40:35.410387 23126066861888 run_lib.py:133] step: 281600, training_loss: 1.89948e-02
I0216 00:40:35.570163 23126066861888 run_lib.py:146] step: 281600, eval_loss: 2.71589e-02
I0216 00:40:53.127562 23126066861888 run_lib.py:133] step: 281650, training_loss: 1.83186e-02
I0216 00:41:10.489189 23126066861888 run_lib.py:133] step: 281700, training_loss: 1.79643e-02
I0216 00:41:10.646832 23126066861888 run_lib.py:146] step: 281700, eval_loss: 2.80894e-02
I0216 00:41:27.932391 23126066861888 run_lib.py:133] step: 281750, training_loss: 1.86772e-02
I0216 00:41:45.471762 23126066861888 run_lib.py:133] step: 281800, training_loss: 1.85049e-02
I0216 00:41:45.628832 23126066861888 run_lib.py:146] step: 281800, eval_loss: 2.75556e-02
I0216 00:42:02.946939 23126066861888 run_lib.py:133] step: 281850, training_loss: 1.89213e-02
I0216 00:42:20.435195 23126066861888 run_lib.py:133] step: 281900, training_loss: 1.91492e-02
I0216 00:42:20.601287 23126066861888 run_lib.py:146] step: 281900, eval_loss: 2.79680e-02
I0216 00:42:37.965629 23126066861888 run_lib.py:133] step: 281950, training_loss: 1.76844e-02
I0216 00:42:55.326425 23126066861888 run_lib.py:133] step: 282000, training_loss: 1.82459e-02
I0216 00:42:55.480001 23126066861888 run_lib.py:146] step: 282000, eval_loss: 2.73544e-02
I0216 00:43:12.959814 23126066861888 run_lib.py:133] step: 282050, training_loss: 1.82684e-02
I0216 00:43:30.263526 23126066861888 run_lib.py:133] step: 282100, training_loss: 1.85410e-02
I0216 00:43:30.416849 23126066861888 run_lib.py:146] step: 282100, eval_loss: 2.84327e-02
I0216 00:43:47.700740 23126066861888 run_lib.py:133] step: 282150, training_loss: 1.91434e-02
I0216 00:44:05.202959 23126066861888 run_lib.py:133] step: 282200, training_loss: 1.90868e-02
I0216 00:44:05.376874 23126066861888 run_lib.py:146] step: 282200, eval_loss: 2.67719e-02
I0216 00:44:22.771989 23126066861888 run_lib.py:133] step: 282250, training_loss: 1.82846e-02
I0216 00:44:40.107281 23126066861888 run_lib.py:133] step: 282300, training_loss: 1.81863e-02
I0216 00:44:40.264141 23126066861888 run_lib.py:146] step: 282300, eval_loss: 2.69517e-02
I0216 00:44:57.686954 23126066861888 run_lib.py:133] step: 282350, training_loss: 1.88934e-02
I0216 00:45:15.011360 23126066861888 run_lib.py:133] step: 282400, training_loss: 1.81565e-02
I0216 00:45:15.167009 23126066861888 run_lib.py:146] step: 282400, eval_loss: 2.70673e-02
I0216 00:45:32.570263 23126066861888 run_lib.py:133] step: 282450, training_loss: 1.85158e-02
I0216 00:45:49.995914 23126066861888 run_lib.py:133] step: 282500, training_loss: 1.79904e-02
I0216 00:45:50.150219 23126066861888 run_lib.py:146] step: 282500, eval_loss: 2.62213e-02
I0216 00:46:07.759819 23126066861888 run_lib.py:133] step: 282550, training_loss: 1.77509e-02
I0216 00:46:25.174901 23126066861888 run_lib.py:133] step: 282600, training_loss: 1.82036e-02
I0216 00:46:25.329892 23126066861888 run_lib.py:146] step: 282600, eval_loss: 2.70962e-02
I0216 00:46:42.630797 23126066861888 run_lib.py:133] step: 282650, training_loss: 1.82523e-02
I0216 00:46:59.963848 23126066861888 run_lib.py:133] step: 282700, training_loss: 1.82153e-02
I0216 00:47:00.128043 23126066861888 run_lib.py:146] step: 282700, eval_loss: 2.80133e-02
I0216 00:47:17.596698 23126066861888 run_lib.py:133] step: 282750, training_loss: 1.79532e-02
I0216 00:47:34.972362 23126066861888 run_lib.py:133] step: 282800, training_loss: 1.83319e-02
I0216 00:47:35.128228 23126066861888 run_lib.py:146] step: 282800, eval_loss: 2.71078e-02
I0216 00:47:52.437806 23126066861888 run_lib.py:133] step: 282850, training_loss: 1.90090e-02
I0216 00:48:09.951407 23126066861888 run_lib.py:133] step: 282900, training_loss: 1.83519e-02
I0216 00:48:10.120675 23126066861888 run_lib.py:146] step: 282900, eval_loss: 2.78898e-02
I0216 00:48:27.488233 23126066861888 run_lib.py:133] step: 282950, training_loss: 1.89073e-02
I0216 00:48:44.976024 23126066861888 run_lib.py:133] step: 283000, training_loss: 1.83913e-02
I0216 00:48:45.136451 23126066861888 run_lib.py:146] step: 283000, eval_loss: 2.71766e-02
I0216 00:49:02.459923 23126066861888 run_lib.py:133] step: 283050, training_loss: 1.86742e-02
I0216 00:49:19.788112 23126066861888 run_lib.py:133] step: 283100, training_loss: 1.87733e-02
I0216 00:49:19.954764 23126066861888 run_lib.py:146] step: 283100, eval_loss: 2.74477e-02
I0216 00:49:37.509220 23126066861888 run_lib.py:133] step: 283150, training_loss: 1.85386e-02
I0216 00:49:54.869207 23126066861888 run_lib.py:133] step: 283200, training_loss: 1.86942e-02
I0216 00:49:55.026195 23126066861888 run_lib.py:146] step: 283200, eval_loss: 2.79477e-02
I0216 00:50:12.330701 23126066861888 run_lib.py:133] step: 283250, training_loss: 1.85691e-02
I0216 00:50:29.801593 23126066861888 run_lib.py:133] step: 283300, training_loss: 1.81481e-02
I0216 00:50:29.955827 23126066861888 run_lib.py:146] step: 283300, eval_loss: 2.75439e-02
I0216 00:50:47.260220 23126066861888 run_lib.py:133] step: 283350, training_loss: 1.83921e-02
I0216 00:51:04.666739 23126066861888 run_lib.py:133] step: 283400, training_loss: 1.88410e-02
I0216 00:51:04.821170 23126066861888 run_lib.py:146] step: 283400, eval_loss: 2.74957e-02
I0216 00:51:22.313734 23126066861888 run_lib.py:133] step: 283450, training_loss: 1.83467e-02
I0216 00:51:39.642106 23126066861888 run_lib.py:133] step: 283500, training_loss: 1.89879e-02
I0216 00:51:39.795888 23126066861888 run_lib.py:146] step: 283500, eval_loss: 2.72308e-02
I0216 00:51:57.062383 23126066861888 run_lib.py:133] step: 283550, training_loss: 1.83310e-02
I0216 00:52:14.418790 23126066861888 run_lib.py:133] step: 283600, training_loss: 1.85131e-02
I0216 00:52:14.577175 23126066861888 run_lib.py:146] step: 283600, eval_loss: 2.67720e-02
I0216 00:52:32.137529 23126066861888 run_lib.py:133] step: 283650, training_loss: 1.89461e-02
I0216 00:52:49.698336 23126066861888 run_lib.py:133] step: 283700, training_loss: 1.84919e-02
I0216 00:52:49.854213 23126066861888 run_lib.py:146] step: 283700, eval_loss: 2.69960e-02
I0216 00:53:07.202172 23126066861888 run_lib.py:133] step: 283750, training_loss: 1.92253e-02
I0216 00:53:24.565879 23126066861888 run_lib.py:133] step: 283800, training_loss: 1.82095e-02
I0216 00:53:24.721812 23126066861888 run_lib.py:146] step: 283800, eval_loss: 2.82974e-02
I0216 00:53:42.192359 23126066861888 run_lib.py:133] step: 283850, training_loss: 1.87883e-02
I0216 00:53:59.521694 23126066861888 run_lib.py:133] step: 283900, training_loss: 1.90351e-02
I0216 00:53:59.677235 23126066861888 run_lib.py:146] step: 283900, eval_loss: 2.66947e-02
I0216 00:54:17.081384 23126066861888 run_lib.py:133] step: 283950, training_loss: 1.87711e-02
I0216 00:54:34.582624 23126066861888 run_lib.py:133] step: 284000, training_loss: 1.84479e-02
I0216 00:54:34.737013 23126066861888 run_lib.py:146] step: 284000, eval_loss: 2.76383e-02
I0216 00:54:52.096606 23126066861888 run_lib.py:133] step: 284050, training_loss: 1.87321e-02
I0216 00:55:09.668167 23126066861888 run_lib.py:133] step: 284100, training_loss: 1.83443e-02
I0216 00:55:09.826231 23126066861888 run_lib.py:146] step: 284100, eval_loss: 2.63506e-02
I0216 00:55:27.240358 23126066861888 run_lib.py:133] step: 284150, training_loss: 1.80793e-02
I0216 00:55:44.519454 23126066861888 run_lib.py:133] step: 284200, training_loss: 1.87481e-02
I0216 00:55:44.684959 23126066861888 run_lib.py:146] step: 284200, eval_loss: 2.81211e-02
I0216 00:56:02.274321 23126066861888 run_lib.py:133] step: 284250, training_loss: 1.80174e-02
I0216 00:56:19.717416 23126066861888 run_lib.py:133] step: 284300, training_loss: 1.86639e-02
I0216 00:56:19.882989 23126066861888 run_lib.py:146] step: 284300, eval_loss: 2.69902e-02
I0216 00:56:37.276631 23126066861888 run_lib.py:133] step: 284350, training_loss: 1.87155e-02
I0216 00:56:54.878570 23126066861888 run_lib.py:133] step: 284400, training_loss: 1.85821e-02
I0216 00:56:55.036787 23126066861888 run_lib.py:146] step: 284400, eval_loss: 2.87214e-02
I0216 00:57:12.466484 23126066861888 run_lib.py:133] step: 284450, training_loss: 1.90510e-02
I0216 00:57:29.859021 23126066861888 run_lib.py:133] step: 284500, training_loss: 1.84939e-02
I0216 00:57:30.030291 23126066861888 run_lib.py:146] step: 284500, eval_loss: 2.70193e-02
I0216 00:57:47.582047 23126066861888 run_lib.py:133] step: 284550, training_loss: 1.83457e-02
I0216 00:58:04.963374 23126066861888 run_lib.py:133] step: 284600, training_loss: 1.80557e-02
I0216 00:58:05.120841 23126066861888 run_lib.py:146] step: 284600, eval_loss: 2.69275e-02
I0216 00:58:22.466991 23126066861888 run_lib.py:133] step: 284650, training_loss: 1.87294e-02
I0216 00:58:39.785562 23126066861888 run_lib.py:133] step: 284700, training_loss: 1.86154e-02
I0216 00:58:39.941991 23126066861888 run_lib.py:146] step: 284700, eval_loss: 2.76251e-02
I0216 00:58:57.496408 23126066861888 run_lib.py:133] step: 284750, training_loss: 1.82237e-02
I0216 00:59:14.980608 23126066861888 run_lib.py:133] step: 284800, training_loss: 1.82090e-02
I0216 00:59:15.146121 23126066861888 run_lib.py:146] step: 284800, eval_loss: 2.75307e-02
I0216 00:59:32.515131 23126066861888 run_lib.py:133] step: 284850, training_loss: 1.91888e-02
I0216 00:59:49.831837 23126066861888 run_lib.py:133] step: 284900, training_loss: 1.82039e-02
I0216 00:59:49.983905 23126066861888 run_lib.py:146] step: 284900, eval_loss: 2.66250e-02
I0216 01:00:07.506984 23126066861888 run_lib.py:133] step: 284950, training_loss: 1.86972e-02
I0216 01:00:24.813310 23126066861888 run_lib.py:133] step: 285000, training_loss: 1.87824e-02
I0216 01:00:24.967055 23126066861888 run_lib.py:146] step: 285000, eval_loss: 2.88117e-02
I0216 01:00:42.289164 23126066861888 run_lib.py:133] step: 285050, training_loss: 1.85918e-02
I0216 01:00:59.848244 23126066861888 run_lib.py:133] step: 285100, training_loss: 1.91549e-02
I0216 01:01:00.004980 23126066861888 run_lib.py:146] step: 285100, eval_loss: 2.75530e-02
I0216 01:01:17.347485 23126066861888 run_lib.py:133] step: 285150, training_loss: 1.84811e-02
I0216 01:01:34.817429 23126066861888 run_lib.py:133] step: 285200, training_loss: 1.82948e-02
I0216 01:01:34.980991 23126066861888 run_lib.py:146] step: 285200, eval_loss: 2.84183e-02
I0216 01:01:52.300769 23126066861888 run_lib.py:133] step: 285250, training_loss: 1.87566e-02
I0216 01:02:09.607449 23126066861888 run_lib.py:133] step: 285300, training_loss: 1.89404e-02
I0216 01:02:09.760784 23126066861888 run_lib.py:146] step: 285300, eval_loss: 2.71470e-02
I0216 01:02:27.278366 23126066861888 run_lib.py:133] step: 285350, training_loss: 1.85050e-02
I0216 01:02:44.617348 23126066861888 run_lib.py:133] step: 285400, training_loss: 1.84605e-02
I0216 01:02:44.770265 23126066861888 run_lib.py:146] step: 285400, eval_loss: 2.69788e-02
I0216 01:03:02.135825 23126066861888 run_lib.py:133] step: 285450, training_loss: 1.84619e-02
I0216 01:03:19.690250 23126066861888 run_lib.py:133] step: 285500, training_loss: 1.90713e-02
I0216 01:03:19.848308 23126066861888 run_lib.py:146] step: 285500, eval_loss: 2.71169e-02
I0216 01:03:37.191575 23126066861888 run_lib.py:133] step: 285550, training_loss: 1.84402e-02
I0216 01:03:54.515045 23126066861888 run_lib.py:133] step: 285600, training_loss: 1.90045e-02
I0216 01:03:54.680832 23126066861888 run_lib.py:146] step: 285600, eval_loss: 2.68704e-02
I0216 01:04:12.187224 23126066861888 run_lib.py:133] step: 285650, training_loss: 1.87872e-02
I0216 01:04:29.660085 23126066861888 run_lib.py:133] step: 285700, training_loss: 1.81470e-02
I0216 01:04:29.814753 23126066861888 run_lib.py:146] step: 285700, eval_loss: 2.66948e-02
I0216 01:04:47.225612 23126066861888 run_lib.py:133] step: 285750, training_loss: 1.86671e-02
I0216 01:05:04.563594 23126066861888 run_lib.py:133] step: 285800, training_loss: 1.85923e-02
I0216 01:05:04.715687 23126066861888 run_lib.py:146] step: 285800, eval_loss: 2.62325e-02
I0216 01:05:22.313886 23126066861888 run_lib.py:133] step: 285850, training_loss: 1.83824e-02
I0216 01:05:39.858493 23126066861888 run_lib.py:133] step: 285900, training_loss: 1.78263e-02
I0216 01:05:40.025154 23126066861888 run_lib.py:146] step: 285900, eval_loss: 2.74798e-02
I0216 01:05:57.331570 23126066861888 run_lib.py:133] step: 285950, training_loss: 1.83626e-02
I0216 01:06:14.711767 23126066861888 run_lib.py:133] step: 286000, training_loss: 1.86453e-02
I0216 01:06:14.877056 23126066861888 run_lib.py:146] step: 286000, eval_loss: 2.82503e-02
I0216 01:06:32.415961 23126066861888 run_lib.py:133] step: 286050, training_loss: 1.82533e-02
I0216 01:06:49.739539 23126066861888 run_lib.py:133] step: 286100, training_loss: 1.88573e-02
I0216 01:06:49.901248 23126066861888 run_lib.py:146] step: 286100, eval_loss: 2.65861e-02
I0216 01:07:07.229827 23126066861888 run_lib.py:133] step: 286150, training_loss: 1.87366e-02
I0216 01:07:24.811481 23126066861888 run_lib.py:133] step: 286200, training_loss: 1.86363e-02
I0216 01:07:24.967454 23126066861888 run_lib.py:146] step: 286200, eval_loss: 2.64297e-02
I0216 01:07:42.328596 23126066861888 run_lib.py:133] step: 286250, training_loss: 1.89794e-02
I0216 01:07:59.853508 23126066861888 run_lib.py:133] step: 286300, training_loss: 1.90210e-02
I0216 01:08:00.004985 23126066861888 run_lib.py:146] step: 286300, eval_loss: 2.81910e-02
I0216 01:08:17.300895 23126066861888 run_lib.py:133] step: 286350, training_loss: 1.85055e-02
I0216 01:08:34.601219 23126066861888 run_lib.py:133] step: 286400, training_loss: 1.82148e-02
I0216 01:08:34.755872 23126066861888 run_lib.py:146] step: 286400, eval_loss: 2.75486e-02
I0216 01:08:52.274517 23126066861888 run_lib.py:133] step: 286450, training_loss: 1.85557e-02
I0216 01:09:09.655059 23126066861888 run_lib.py:133] step: 286500, training_loss: 1.74433e-02
I0216 01:09:09.818930 23126066861888 run_lib.py:146] step: 286500, eval_loss: 2.71837e-02
I0216 01:09:27.134905 23126066861888 run_lib.py:133] step: 286550, training_loss: 1.78014e-02
I0216 01:09:44.651573 23126066861888 run_lib.py:133] step: 286600, training_loss: 1.81898e-02
I0216 01:09:44.806908 23126066861888 run_lib.py:146] step: 286600, eval_loss: 2.76282e-02
I0216 01:10:02.174855 23126066861888 run_lib.py:133] step: 286650, training_loss: 1.79724e-02
I0216 01:10:19.487440 23126066861888 run_lib.py:133] step: 286700, training_loss: 1.93072e-02
I0216 01:10:19.643091 23126066861888 run_lib.py:146] step: 286700, eval_loss: 2.64309e-02
I0216 01:10:37.098399 23126066861888 run_lib.py:133] step: 286750, training_loss: 1.84871e-02
I0216 01:10:54.453417 23126066861888 run_lib.py:133] step: 286800, training_loss: 1.79816e-02
I0216 01:10:54.606930 23126066861888 run_lib.py:146] step: 286800, eval_loss: 2.73230e-02
I0216 01:11:11.937098 23126066861888 run_lib.py:133] step: 286850, training_loss: 1.83322e-02
I0216 01:11:29.318644 23126066861888 run_lib.py:133] step: 286900, training_loss: 1.82535e-02
I0216 01:11:29.482560 23126066861888 run_lib.py:146] step: 286900, eval_loss: 2.81418e-02
I0216 01:11:46.958313 23126066861888 run_lib.py:133] step: 286950, training_loss: 1.88544e-02
I0216 01:12:04.323750 23126066861888 run_lib.py:133] step: 287000, training_loss: 1.85503e-02
I0216 01:12:04.489846 23126066861888 run_lib.py:146] step: 287000, eval_loss: 2.90809e-02
I0216 01:12:21.961055 23126066861888 run_lib.py:133] step: 287050, training_loss: 1.81358e-02
I0216 01:12:39.332871 23126066861888 run_lib.py:133] step: 287100, training_loss: 1.81291e-02
I0216 01:12:39.488144 23126066861888 run_lib.py:146] step: 287100, eval_loss: 2.65878e-02
I0216 01:12:57.051542 23126066861888 run_lib.py:133] step: 287150, training_loss: 1.87930e-02
I0216 01:13:14.339997 23126066861888 run_lib.py:133] step: 287200, training_loss: 1.89427e-02
I0216 01:13:14.493008 23126066861888 run_lib.py:146] step: 287200, eval_loss: 2.81018e-02
I0216 01:13:31.829990 23126066861888 run_lib.py:133] step: 287250, training_loss: 1.84030e-02
I0216 01:13:49.428961 23126066861888 run_lib.py:133] step: 287300, training_loss: 1.83867e-02
I0216 01:13:49.601401 23126066861888 run_lib.py:146] step: 287300, eval_loss: 2.75305e-02
I0216 01:14:07.011680 23126066861888 run_lib.py:133] step: 287350, training_loss: 1.81590e-02
I0216 01:14:24.574635 23126066861888 run_lib.py:133] step: 287400, training_loss: 1.87350e-02
I0216 01:14:24.740916 23126066861888 run_lib.py:146] step: 287400, eval_loss: 2.81192e-02
I0216 01:14:42.104202 23126066861888 run_lib.py:133] step: 287450, training_loss: 1.83513e-02
I0216 01:14:59.451430 23126066861888 run_lib.py:133] step: 287500, training_loss: 1.89401e-02
I0216 01:14:59.606919 23126066861888 run_lib.py:146] step: 287500, eval_loss: 2.77149e-02
I0216 01:15:17.152622 23126066861888 run_lib.py:133] step: 287550, training_loss: 1.80916e-02
I0216 01:15:34.507060 23126066861888 run_lib.py:133] step: 287600, training_loss: 1.82117e-02
I0216 01:15:34.662683 23126066861888 run_lib.py:146] step: 287600, eval_loss: 2.70138e-02
I0216 01:15:52.105217 23126066861888 run_lib.py:133] step: 287650, training_loss: 1.83800e-02
I0216 01:16:09.677548 23126066861888 run_lib.py:133] step: 287700, training_loss: 1.73927e-02
I0216 01:16:09.832625 23126066861888 run_lib.py:146] step: 287700, eval_loss: 2.73934e-02
I0216 01:16:27.149455 23126066861888 run_lib.py:133] step: 287750, training_loss: 1.76070e-02
I0216 01:16:44.473069 23126066861888 run_lib.py:133] step: 287800, training_loss: 1.91637e-02
I0216 01:16:44.629083 23126066861888 run_lib.py:146] step: 287800, eval_loss: 2.79947e-02
I0216 01:17:02.089544 23126066861888 run_lib.py:133] step: 287850, training_loss: 1.82810e-02
I0216 01:17:19.465309 23126066861888 run_lib.py:133] step: 287900, training_loss: 1.81413e-02
I0216 01:17:19.629174 23126066861888 run_lib.py:146] step: 287900, eval_loss: 2.82107e-02
I0216 01:17:36.993072 23126066861888 run_lib.py:133] step: 287950, training_loss: 1.78504e-02
I0216 01:17:54.361753 23126066861888 run_lib.py:133] step: 288000, training_loss: 1.86347e-02
I0216 01:17:54.518088 23126066861888 run_lib.py:146] step: 288000, eval_loss: 2.58770e-02
I0216 01:18:12.057088 23126066861888 run_lib.py:133] step: 288050, training_loss: 1.79613e-02
I0216 01:18:29.476957 23126066861888 run_lib.py:133] step: 288100, training_loss: 1.79484e-02
I0216 01:18:29.638325 23126066861888 run_lib.py:146] step: 288100, eval_loss: 2.82023e-02
I0216 01:18:47.077673 23126066861888 run_lib.py:133] step: 288150, training_loss: 1.78095e-02
I0216 01:19:04.475648 23126066861888 run_lib.py:133] step: 288200, training_loss: 1.90249e-02
I0216 01:19:04.636180 23126066861888 run_lib.py:146] step: 288200, eval_loss: 2.74491e-02
I0216 01:19:22.184494 23126066861888 run_lib.py:133] step: 288250, training_loss: 1.79990e-02
I0216 01:19:39.524811 23126066861888 run_lib.py:133] step: 288300, training_loss: 1.86415e-02
I0216 01:19:39.686929 23126066861888 run_lib.py:146] step: 288300, eval_loss: 2.79684e-02
I0216 01:19:56.986506 23126066861888 run_lib.py:133] step: 288350, training_loss: 1.88663e-02
I0216 01:20:14.479019 23126066861888 run_lib.py:133] step: 288400, training_loss: 1.83182e-02
I0216 01:20:14.650902 23126066861888 run_lib.py:146] step: 288400, eval_loss: 2.62557e-02
I0216 01:20:32.081966 23126066861888 run_lib.py:133] step: 288450, training_loss: 1.79967e-02
I0216 01:20:49.614737 23126066861888 run_lib.py:133] step: 288500, training_loss: 1.84595e-02
I0216 01:20:49.771273 23126066861888 run_lib.py:146] step: 288500, eval_loss: 2.71967e-02
I0216 01:21:07.096165 23126066861888 run_lib.py:133] step: 288550, training_loss: 1.85635e-02
I0216 01:21:24.434102 23126066861888 run_lib.py:133] step: 288600, training_loss: 1.83383e-02
I0216 01:21:24.587056 23126066861888 run_lib.py:146] step: 288600, eval_loss: 2.78114e-02
I0216 01:21:42.117193 23126066861888 run_lib.py:133] step: 288650, training_loss: 1.82185e-02
I0216 01:21:59.500715 23126066861888 run_lib.py:133] step: 288700, training_loss: 1.84412e-02
I0216 01:21:59.661326 23126066861888 run_lib.py:146] step: 288700, eval_loss: 2.77743e-02
I0216 01:22:17.037808 23126066861888 run_lib.py:133] step: 288750, training_loss: 1.86673e-02
I0216 01:22:34.624712 23126066861888 run_lib.py:133] step: 288800, training_loss: 1.83489e-02
I0216 01:22:34.782220 23126066861888 run_lib.py:146] step: 288800, eval_loss: 2.74082e-02
I0216 01:22:52.153726 23126066861888 run_lib.py:133] step: 288850, training_loss: 1.80651e-02
I0216 01:23:09.551386 23126066861888 run_lib.py:133] step: 288900, training_loss: 1.88499e-02
I0216 01:23:09.719879 23126066861888 run_lib.py:146] step: 288900, eval_loss: 2.69814e-02
I0216 01:23:27.245258 23126066861888 run_lib.py:133] step: 288950, training_loss: 1.88589e-02
I0216 01:23:44.638766 23126066861888 run_lib.py:133] step: 289000, training_loss: 1.86458e-02
I0216 01:23:44.799654 23126066861888 run_lib.py:146] step: 289000, eval_loss: 2.73629e-02
I0216 01:24:02.158133 23126066861888 run_lib.py:133] step: 289050, training_loss: 1.81612e-02
I0216 01:24:19.498135 23126066861888 run_lib.py:133] step: 289100, training_loss: 1.79234e-02
I0216 01:24:19.652912 23126066861888 run_lib.py:146] step: 289100, eval_loss: 2.82340e-02
I0216 01:24:37.177466 23126066861888 run_lib.py:133] step: 289150, training_loss: 1.84565e-02
I0216 01:24:54.582704 23126066861888 run_lib.py:133] step: 289200, training_loss: 1.78665e-02
I0216 01:24:54.737049 23126066861888 run_lib.py:146] step: 289200, eval_loss: 2.74690e-02
I0216 01:25:12.157581 23126066861888 run_lib.py:133] step: 289250, training_loss: 1.83132e-02
I0216 01:25:29.545800 23126066861888 run_lib.py:133] step: 289300, training_loss: 1.86276e-02
I0216 01:25:29.702845 23126066861888 run_lib.py:146] step: 289300, eval_loss: 2.75137e-02
I0216 01:25:47.229108 23126066861888 run_lib.py:133] step: 289350, training_loss: 1.80715e-02
I0216 01:26:04.542716 23126066861888 run_lib.py:133] step: 289400, training_loss: 1.80829e-02
I0216 01:26:04.696012 23126066861888 run_lib.py:146] step: 289400, eval_loss: 2.74774e-02
I0216 01:26:22.027392 23126066861888 run_lib.py:133] step: 289450, training_loss: 1.81422e-02
I0216 01:26:39.469147 23126066861888 run_lib.py:133] step: 289500, training_loss: 1.79553e-02
I0216 01:26:39.630129 23126066861888 run_lib.py:146] step: 289500, eval_loss: 2.65335e-02
I0216 01:26:56.969043 23126066861888 run_lib.py:133] step: 289550, training_loss: 1.84606e-02
I0216 01:27:14.504864 23126066861888 run_lib.py:133] step: 289600, training_loss: 1.86724e-02
I0216 01:27:14.654640 23126066861888 run_lib.py:146] step: 289600, eval_loss: 2.66776e-02
I0216 01:27:32.001828 23126066861888 run_lib.py:133] step: 289650, training_loss: 1.79936e-02
I0216 01:27:49.351674 23126066861888 run_lib.py:133] step: 289700, training_loss: 1.79217e-02
I0216 01:27:49.505832 23126066861888 run_lib.py:146] step: 289700, eval_loss: 2.73263e-02
I0216 01:28:06.995428 23126066861888 run_lib.py:133] step: 289750, training_loss: 1.84134e-02
I0216 01:28:24.297576 23126066861888 run_lib.py:133] step: 289800, training_loss: 1.81270e-02
I0216 01:28:24.468954 23126066861888 run_lib.py:146] step: 289800, eval_loss: 2.81206e-02
I0216 01:28:41.865924 23126066861888 run_lib.py:133] step: 289850, training_loss: 1.89577e-02
I0216 01:28:59.379893 23126066861888 run_lib.py:133] step: 289900, training_loss: 1.78159e-02
I0216 01:28:59.537092 23126066861888 run_lib.py:146] step: 289900, eval_loss: 2.77458e-02
I0216 01:29:16.882890 23126066861888 run_lib.py:133] step: 289950, training_loss: 1.79226e-02
I0216 01:29:34.192622 23126066861888 run_lib.py:133] step: 290000, training_loss: 1.84645e-02
I0216 01:29:34.957516 23126066861888 run_lib.py:146] step: 290000, eval_loss: 2.74402e-02
I0216 01:29:54.937536 23126066861888 run_lib.py:133] step: 290050, training_loss: 1.90349e-02
I0216 01:30:12.473471 23126066861888 run_lib.py:133] step: 290100, training_loss: 1.93184e-02
I0216 01:30:12.626125 23126066861888 run_lib.py:146] step: 290100, eval_loss: 2.72160e-02
I0216 01:30:29.995250 23126066861888 run_lib.py:133] step: 290150, training_loss: 1.84118e-02
I0216 01:30:47.312239 23126066861888 run_lib.py:133] step: 290200, training_loss: 1.80917e-02
I0216 01:30:47.464911 23126066861888 run_lib.py:146] step: 290200, eval_loss: 2.84663e-02
I0216 01:31:04.924402 23126066861888 run_lib.py:133] step: 290250, training_loss: 1.91357e-02
I0216 01:31:22.473264 23126066861888 run_lib.py:133] step: 290300, training_loss: 1.88105e-02
I0216 01:31:22.632419 23126066861888 run_lib.py:146] step: 290300, eval_loss: 2.74476e-02
I0216 01:31:39.981240 23126066861888 run_lib.py:133] step: 290350, training_loss: 1.84571e-02
I0216 01:31:57.397259 23126066861888 run_lib.py:133] step: 290400, training_loss: 1.90766e-02
I0216 01:31:57.550164 23126066861888 run_lib.py:146] step: 290400, eval_loss: 2.77632e-02
I0216 01:32:15.123786 23126066861888 run_lib.py:133] step: 290450, training_loss: 1.78730e-02
I0216 01:32:32.508492 23126066861888 run_lib.py:133] step: 290500, training_loss: 1.87544e-02
I0216 01:32:32.669046 23126066861888 run_lib.py:146] step: 290500, eval_loss: 2.70960e-02
I0216 01:32:50.139973 23126066861888 run_lib.py:133] step: 290550, training_loss: 1.82809e-02
I0216 01:33:07.496009 23126066861888 run_lib.py:133] step: 290600, training_loss: 1.88615e-02
I0216 01:33:07.655957 23126066861888 run_lib.py:146] step: 290600, eval_loss: 2.79583e-02
I0216 01:33:24.978375 23126066861888 run_lib.py:133] step: 290650, training_loss: 1.82935e-02
I0216 01:33:42.362732 23126066861888 run_lib.py:133] step: 290700, training_loss: 1.75594e-02
I0216 01:33:42.528222 23126066861888 run_lib.py:146] step: 290700, eval_loss: 2.63071e-02
I0216 01:34:00.086679 23126066861888 run_lib.py:133] step: 290750, training_loss: 1.83070e-02
I0216 01:34:17.547560 23126066861888 run_lib.py:133] step: 290800, training_loss: 1.88578e-02
I0216 01:34:17.708129 23126066861888 run_lib.py:146] step: 290800, eval_loss: 2.79433e-02
I0216 01:34:35.005698 23126066861888 run_lib.py:133] step: 290850, training_loss: 1.88879e-02
I0216 01:34:52.296604 23126066861888 run_lib.py:133] step: 290900, training_loss: 1.75420e-02
I0216 01:34:52.463072 23126066861888 run_lib.py:146] step: 290900, eval_loss: 2.75722e-02
I0216 01:35:09.953308 23126066861888 run_lib.py:133] step: 290950, training_loss: 1.81974e-02
I0216 01:35:27.328558 23126066861888 run_lib.py:133] step: 291000, training_loss: 1.88189e-02
I0216 01:35:27.484276 23126066861888 run_lib.py:146] step: 291000, eval_loss: 2.76759e-02
I0216 01:35:44.846229 23126066861888 run_lib.py:133] step: 291050, training_loss: 1.92115e-02
I0216 01:36:02.391117 23126066861888 run_lib.py:133] step: 291100, training_loss: 1.82815e-02
I0216 01:36:02.544084 23126066861888 run_lib.py:146] step: 291100, eval_loss: 2.75909e-02
I0216 01:36:19.936553 23126066861888 run_lib.py:133] step: 291150, training_loss: 1.87308e-02
I0216 01:36:37.458769 23126066861888 run_lib.py:133] step: 291200, training_loss: 1.85937e-02
I0216 01:36:37.630204 23126066861888 run_lib.py:146] step: 291200, eval_loss: 2.77096e-02
I0216 01:36:55.044903 23126066861888 run_lib.py:133] step: 291250, training_loss: 1.90352e-02
I0216 01:37:12.451624 23126066861888 run_lib.py:133] step: 291300, training_loss: 1.83551e-02
I0216 01:37:12.611005 23126066861888 run_lib.py:146] step: 291300, eval_loss: 2.61751e-02
I0216 01:37:30.150033 23126066861888 run_lib.py:133] step: 291350, training_loss: 1.75459e-02
I0216 01:37:47.473250 23126066861888 run_lib.py:133] step: 291400, training_loss: 1.77494e-02
I0216 01:37:47.628952 23126066861888 run_lib.py:146] step: 291400, eval_loss: 2.74622e-02
I0216 01:38:05.005488 23126066861888 run_lib.py:133] step: 291450, training_loss: 1.85700e-02
I0216 01:38:22.324666 23126066861888 run_lib.py:133] step: 291500, training_loss: 1.86686e-02
I0216 01:38:22.478670 23126066861888 run_lib.py:146] step: 291500, eval_loss: 2.82943e-02
I0216 01:38:40.027721 23126066861888 run_lib.py:133] step: 291550, training_loss: 1.80456e-02
I0216 01:38:57.395512 23126066861888 run_lib.py:133] step: 291600, training_loss: 1.81355e-02
I0216 01:38:57.547008 23126066861888 run_lib.py:146] step: 291600, eval_loss: 2.76229e-02
I0216 01:39:14.940610 23126066861888 run_lib.py:133] step: 291650, training_loss: 1.83534e-02
I0216 01:39:32.256063 23126066861888 run_lib.py:133] step: 291700, training_loss: 1.82774e-02
I0216 01:39:32.409877 23126066861888 run_lib.py:146] step: 291700, eval_loss: 2.76569e-02
I0216 01:39:49.743470 23126066861888 run_lib.py:133] step: 291750, training_loss: 1.78615e-02
I0216 01:40:07.163933 23126066861888 run_lib.py:133] step: 291800, training_loss: 1.84755e-02
I0216 01:40:07.355022 23126066861888 run_lib.py:146] step: 291800, eval_loss: 2.75703e-02
I0216 01:40:24.940545 23126066861888 run_lib.py:133] step: 291850, training_loss: 1.82587e-02
I0216 01:40:42.423058 23126066861888 run_lib.py:133] step: 291900, training_loss: 1.78637e-02
I0216 01:40:42.579326 23126066861888 run_lib.py:146] step: 291900, eval_loss: 2.73815e-02
I0216 01:41:00.040041 23126066861888 run_lib.py:133] step: 291950, training_loss: 1.84643e-02
I0216 01:41:17.432661 23126066861888 run_lib.py:133] step: 292000, training_loss: 1.84715e-02
I0216 01:41:17.586975 23126066861888 run_lib.py:146] step: 292000, eval_loss: 2.66755e-02
I0216 01:41:35.132589 23126066861888 run_lib.py:133] step: 292050, training_loss: 1.85255e-02
I0216 01:41:52.618854 23126066861888 run_lib.py:133] step: 292100, training_loss: 1.90609e-02
I0216 01:41:52.776234 23126066861888 run_lib.py:146] step: 292100, eval_loss: 2.74724e-02
I0216 01:42:10.244420 23126066861888 run_lib.py:133] step: 292150, training_loss: 1.89944e-02
I0216 01:42:27.817189 23126066861888 run_lib.py:133] step: 292200, training_loss: 1.78838e-02
I0216 01:42:27.975105 23126066861888 run_lib.py:146] step: 292200, eval_loss: 2.80743e-02
I0216 01:42:45.337074 23126066861888 run_lib.py:133] step: 292250, training_loss: 1.78320e-02
I0216 01:43:02.857889 23126066861888 run_lib.py:133] step: 292300, training_loss: 1.80364e-02
I0216 01:43:03.013274 23126066861888 run_lib.py:146] step: 292300, eval_loss: 2.77772e-02
I0216 01:43:20.337888 23126066861888 run_lib.py:133] step: 292350, training_loss: 1.79726e-02
I0216 01:43:37.731615 23126066861888 run_lib.py:133] step: 292400, training_loss: 1.84427e-02
I0216 01:43:37.886696 23126066861888 run_lib.py:146] step: 292400, eval_loss: 2.74879e-02
I0216 01:43:55.410700 23126066861888 run_lib.py:133] step: 292450, training_loss: 1.82628e-02
I0216 01:44:12.711695 23126066861888 run_lib.py:133] step: 292500, training_loss: 1.78843e-02
I0216 01:44:12.863944 23126066861888 run_lib.py:146] step: 292500, eval_loss: 2.66794e-02
I0216 01:44:30.180486 23126066861888 run_lib.py:133] step: 292550, training_loss: 1.80948e-02
I0216 01:44:47.662338 23126066861888 run_lib.py:133] step: 292600, training_loss: 1.80609e-02
I0216 01:44:47.817362 23126066861888 run_lib.py:146] step: 292600, eval_loss: 2.80815e-02
I0216 01:45:05.127548 23126066861888 run_lib.py:133] step: 292650, training_loss: 1.83883e-02
I0216 01:45:22.509591 23126066861888 run_lib.py:133] step: 292700, training_loss: 1.80943e-02
I0216 01:45:22.670937 23126066861888 run_lib.py:146] step: 292700, eval_loss: 2.73412e-02
I0216 01:45:40.158067 23126066861888 run_lib.py:133] step: 292750, training_loss: 1.90000e-02
I0216 01:45:57.489322 23126066861888 run_lib.py:133] step: 292800, training_loss: 1.83844e-02
I0216 01:45:57.644112 23126066861888 run_lib.py:146] step: 292800, eval_loss: 2.77406e-02
I0216 01:46:14.958830 23126066861888 run_lib.py:133] step: 292850, training_loss: 1.79402e-02
I0216 01:46:32.261517 23126066861888 run_lib.py:133] step: 292900, training_loss: 1.89729e-02
I0216 01:46:32.415610 23126066861888 run_lib.py:146] step: 292900, eval_loss: 2.83369e-02
I0216 01:46:49.935004 23126066861888 run_lib.py:133] step: 292950, training_loss: 1.78647e-02
I0216 01:47:07.480472 23126066861888 run_lib.py:133] step: 293000, training_loss: 1.81072e-02
I0216 01:47:07.633825 23126066861888 run_lib.py:146] step: 293000, eval_loss: 2.60876e-02
I0216 01:47:25.019765 23126066861888 run_lib.py:133] step: 293050, training_loss: 1.88805e-02
I0216 01:47:42.321957 23126066861888 run_lib.py:133] step: 293100, training_loss: 1.78455e-02
I0216 01:47:42.483780 23126066861888 run_lib.py:146] step: 293100, eval_loss: 2.68146e-02
I0216 01:47:59.946876 23126066861888 run_lib.py:133] step: 293150, training_loss: 1.84482e-02
I0216 01:48:17.259102 23126066861888 run_lib.py:133] step: 293200, training_loss: 1.89430e-02
I0216 01:48:17.446014 23126066861888 run_lib.py:146] step: 293200, eval_loss: 2.79095e-02
I0216 01:48:34.806251 23126066861888 run_lib.py:133] step: 293250, training_loss: 1.81773e-02
I0216 01:48:52.335746 23126066861888 run_lib.py:133] step: 293300, training_loss: 1.81687e-02
I0216 01:48:52.499984 23126066861888 run_lib.py:146] step: 293300, eval_loss: 2.74795e-02
I0216 01:49:09.835928 23126066861888 run_lib.py:133] step: 293350, training_loss: 1.87579e-02
I0216 01:49:27.315345 23126066861888 run_lib.py:133] step: 293400, training_loss: 1.81796e-02
I0216 01:49:27.497985 23126066861888 run_lib.py:146] step: 293400, eval_loss: 2.83843e-02
I0216 01:49:44.830112 23126066861888 run_lib.py:133] step: 293450, training_loss: 1.87401e-02
I0216 01:50:02.186442 23126066861888 run_lib.py:133] step: 293500, training_loss: 1.81354e-02
I0216 01:50:02.339151 23126066861888 run_lib.py:146] step: 293500, eval_loss: 2.80154e-02
I0216 01:50:19.913141 23126066861888 run_lib.py:133] step: 293550, training_loss: 1.73252e-02
I0216 01:50:37.228069 23126066861888 run_lib.py:133] step: 293600, training_loss: 1.84844e-02
I0216 01:50:37.382917 23126066861888 run_lib.py:146] step: 293600, eval_loss: 2.78335e-02
I0216 01:50:54.708460 23126066861888 run_lib.py:133] step: 293650, training_loss: 1.82151e-02
I0216 01:51:12.274718 23126066861888 run_lib.py:133] step: 293700, training_loss: 1.86436e-02
I0216 01:51:12.432763 23126066861888 run_lib.py:146] step: 293700, eval_loss: 2.55201e-02
I0216 01:51:29.835319 23126066861888 run_lib.py:133] step: 293750, training_loss: 1.86565e-02
I0216 01:51:47.265739 23126066861888 run_lib.py:133] step: 293800, training_loss: 1.84912e-02
I0216 01:51:47.422192 23126066861888 run_lib.py:146] step: 293800, eval_loss: 2.76438e-02
I0216 01:52:04.852388 23126066861888 run_lib.py:133] step: 293850, training_loss: 1.86151e-02
I0216 01:52:22.161627 23126066861888 run_lib.py:133] step: 293900, training_loss: 1.82482e-02
I0216 01:52:22.314926 23126066861888 run_lib.py:146] step: 293900, eval_loss: 2.82328e-02
I0216 01:52:39.696726 23126066861888 run_lib.py:133] step: 293950, training_loss: 1.83326e-02
I0216 01:52:57.027877 23126066861888 run_lib.py:133] step: 294000, training_loss: 1.86952e-02
I0216 01:52:57.179951 23126066861888 run_lib.py:146] step: 294000, eval_loss: 2.65878e-02
I0216 01:53:14.632482 23126066861888 run_lib.py:133] step: 294050, training_loss: 1.83193e-02
I0216 01:53:32.115871 23126066861888 run_lib.py:133] step: 294100, training_loss: 1.87632e-02
I0216 01:53:32.290926 23126066861888 run_lib.py:146] step: 294100, eval_loss: 2.70845e-02
I0216 01:53:49.611013 23126066861888 run_lib.py:133] step: 294150, training_loss: 1.81272e-02
I0216 01:54:06.932956 23126066861888 run_lib.py:133] step: 294200, training_loss: 1.93041e-02
I0216 01:54:07.087135 23126066861888 run_lib.py:146] step: 294200, eval_loss: 2.72107e-02
I0216 01:54:24.563069 23126066861888 run_lib.py:133] step: 294250, training_loss: 1.89878e-02
I0216 01:54:41.851567 23126066861888 run_lib.py:133] step: 294300, training_loss: 1.86419e-02
I0216 01:54:42.005851 23126066861888 run_lib.py:146] step: 294300, eval_loss: 2.60896e-02
I0216 01:54:59.355110 23126066861888 run_lib.py:133] step: 294350, training_loss: 1.94158e-02
I0216 01:55:16.856073 23126066861888 run_lib.py:133] step: 294400, training_loss: 1.78649e-02
I0216 01:55:17.010083 23126066861888 run_lib.py:146] step: 294400, eval_loss: 2.80218e-02
I0216 01:55:34.363996 23126066861888 run_lib.py:133] step: 294450, training_loss: 1.89861e-02
I0216 01:55:51.881775 23126066861888 run_lib.py:133] step: 294500, training_loss: 1.85434e-02
I0216 01:55:52.038964 23126066861888 run_lib.py:146] step: 294500, eval_loss: 2.70583e-02
I0216 01:56:09.348721 23126066861888 run_lib.py:133] step: 294550, training_loss: 1.85207e-02
I0216 01:56:26.657598 23126066861888 run_lib.py:133] step: 294600, training_loss: 1.74726e-02
I0216 01:56:26.823178 23126066861888 run_lib.py:146] step: 294600, eval_loss: 2.70174e-02
I0216 01:56:44.302678 23126066861888 run_lib.py:133] step: 294650, training_loss: 1.83402e-02
I0216 01:57:01.708580 23126066861888 run_lib.py:133] step: 294700, training_loss: 1.82845e-02
I0216 01:57:01.870262 23126066861888 run_lib.py:146] step: 294700, eval_loss: 2.70342e-02
I0216 01:57:19.183229 23126066861888 run_lib.py:133] step: 294750, training_loss: 1.83844e-02
I0216 01:57:36.683511 23126066861888 run_lib.py:133] step: 294800, training_loss: 1.86183e-02
I0216 01:57:36.838973 23126066861888 run_lib.py:146] step: 294800, eval_loss: 2.78047e-02
I0216 01:57:54.184419 23126066861888 run_lib.py:133] step: 294850, training_loss: 1.78890e-02
I0216 01:58:11.565828 23126066861888 run_lib.py:133] step: 294900, training_loss: 1.89582e-02
I0216 01:58:11.717026 23126066861888 run_lib.py:146] step: 294900, eval_loss: 2.86006e-02
I0216 01:58:29.137238 23126066861888 run_lib.py:133] step: 294950, training_loss: 1.82843e-02
I0216 01:58:46.539237 23126066861888 run_lib.py:133] step: 295000, training_loss: 1.88110e-02
I0216 01:58:46.710122 23126066861888 run_lib.py:146] step: 295000, eval_loss: 2.83191e-02
I0216 01:59:04.086056 23126066861888 run_lib.py:133] step: 295050, training_loss: 1.86726e-02
I0216 01:59:21.424996 23126066861888 run_lib.py:133] step: 295100, training_loss: 1.89805e-02
I0216 01:59:21.583333 23126066861888 run_lib.py:146] step: 295100, eval_loss: 2.71515e-02
I0216 01:59:39.088225 23126066861888 run_lib.py:133] step: 295150, training_loss: 1.79078e-02
I0216 01:59:56.496469 23126066861888 run_lib.py:133] step: 295200, training_loss: 1.80566e-02
I0216 01:59:56.650976 23126066861888 run_lib.py:146] step: 295200, eval_loss: 2.68232e-02
I0216 02:00:14.028904 23126066861888 run_lib.py:133] step: 295250, training_loss: 1.83646e-02
I0216 02:00:31.480030 23126066861888 run_lib.py:133] step: 295300, training_loss: 1.88862e-02
I0216 02:00:31.635595 23126066861888 run_lib.py:146] step: 295300, eval_loss: 2.77303e-02
I0216 02:00:49.239290 23126066861888 run_lib.py:133] step: 295350, training_loss: 1.83227e-02
I0216 02:01:06.650290 23126066861888 run_lib.py:133] step: 295400, training_loss: 1.79978e-02
I0216 02:01:06.803920 23126066861888 run_lib.py:146] step: 295400, eval_loss: 2.85585e-02
I0216 02:01:24.107490 23126066861888 run_lib.py:133] step: 295450, training_loss: 1.85043e-02
I0216 02:01:41.574725 23126066861888 run_lib.py:133] step: 295500, training_loss: 1.82488e-02
I0216 02:01:41.743762 23126066861888 run_lib.py:146] step: 295500, eval_loss: 2.62073e-02
I0216 02:01:59.128722 23126066861888 run_lib.py:133] step: 295550, training_loss: 1.76783e-02
I0216 02:02:16.691169 23126066861888 run_lib.py:133] step: 295600, training_loss: 1.86367e-02
I0216 02:02:16.847924 23126066861888 run_lib.py:146] step: 295600, eval_loss: 2.75532e-02
I0216 02:02:34.158762 23126066861888 run_lib.py:133] step: 295650, training_loss: 1.88878e-02
I0216 02:02:51.491921 23126066861888 run_lib.py:133] step: 295700, training_loss: 1.83587e-02
I0216 02:02:51.646392 23126066861888 run_lib.py:146] step: 295700, eval_loss: 2.65703e-02
I0216 02:03:09.137064 23126066861888 run_lib.py:133] step: 295750, training_loss: 1.81925e-02
I0216 02:03:26.485194 23126066861888 run_lib.py:133] step: 295800, training_loss: 1.84447e-02
I0216 02:03:26.648000 23126066861888 run_lib.py:146] step: 295800, eval_loss: 2.73175e-02
I0216 02:03:44.057093 23126066861888 run_lib.py:133] step: 295850, training_loss: 1.94435e-02
I0216 02:04:01.609430 23126066861888 run_lib.py:133] step: 295900, training_loss: 1.88015e-02
I0216 02:04:01.766938 23126066861888 run_lib.py:146] step: 295900, eval_loss: 2.73630e-02
I0216 02:04:19.058895 23126066861888 run_lib.py:133] step: 295950, training_loss: 1.84551e-02
I0216 02:04:36.366404 23126066861888 run_lib.py:133] step: 296000, training_loss: 1.81890e-02
I0216 02:04:36.524269 23126066861888 run_lib.py:146] step: 296000, eval_loss: 2.88303e-02
I0216 02:04:53.919638 23126066861888 run_lib.py:133] step: 296050, training_loss: 1.89725e-02
I0216 02:05:11.296805 23126066861888 run_lib.py:133] step: 296100, training_loss: 1.82790e-02
I0216 02:05:11.454051 23126066861888 run_lib.py:146] step: 296100, eval_loss: 2.75194e-02
I0216 02:05:28.817193 23126066861888 run_lib.py:133] step: 296150, training_loss: 1.87058e-02
I0216 02:05:46.155374 23126066861888 run_lib.py:133] step: 296200, training_loss: 1.74479e-02
I0216 02:05:46.310655 23126066861888 run_lib.py:146] step: 296200, eval_loss: 2.74613e-02
I0216 02:06:03.895215 23126066861888 run_lib.py:133] step: 296250, training_loss: 1.84843e-02
I0216 02:06:21.276223 23126066861888 run_lib.py:133] step: 296300, training_loss: 1.82137e-02
I0216 02:06:21.428724 23126066861888 run_lib.py:146] step: 296300, eval_loss: 2.65099e-02
I0216 02:06:38.763771 23126066861888 run_lib.py:133] step: 296350, training_loss: 1.79252e-02
I0216 02:06:56.210061 23126066861888 run_lib.py:133] step: 296400, training_loss: 1.86413e-02
I0216 02:06:56.371130 23126066861888 run_lib.py:146] step: 296400, eval_loss: 2.81771e-02
I0216 02:07:14.031167 23126066861888 run_lib.py:133] step: 296450, training_loss: 1.80509e-02
I0216 02:07:31.444621 23126066861888 run_lib.py:133] step: 296500, training_loss: 1.84164e-02
I0216 02:07:31.607175 23126066861888 run_lib.py:146] step: 296500, eval_loss: 2.76256e-02
I0216 02:07:48.973587 23126066861888 run_lib.py:133] step: 296550, training_loss: 1.85225e-02
I0216 02:08:06.477999 23126066861888 run_lib.py:133] step: 296600, training_loss: 1.88151e-02
I0216 02:08:06.644025 23126066861888 run_lib.py:146] step: 296600, eval_loss: 2.80639e-02
I0216 02:08:24.086951 23126066861888 run_lib.py:133] step: 296650, training_loss: 1.79030e-02
I0216 02:08:41.709146 23126066861888 run_lib.py:133] step: 296700, training_loss: 1.78366e-02
I0216 02:08:41.872345 23126066861888 run_lib.py:146] step: 296700, eval_loss: 2.69081e-02
I0216 02:08:59.218650 23126066861888 run_lib.py:133] step: 296750, training_loss: 1.78853e-02
I0216 02:09:16.549079 23126066861888 run_lib.py:133] step: 296800, training_loss: 1.81501e-02
I0216 02:09:16.699898 23126066861888 run_lib.py:146] step: 296800, eval_loss: 2.84025e-02
I0216 02:09:34.274978 23126066861888 run_lib.py:133] step: 296850, training_loss: 1.81451e-02
I0216 02:09:51.680863 23126066861888 run_lib.py:133] step: 296900, training_loss: 1.84425e-02
I0216 02:09:51.840291 23126066861888 run_lib.py:146] step: 296900, eval_loss: 2.72904e-02
I0216 02:10:09.233716 23126066861888 run_lib.py:133] step: 296950, training_loss: 1.84474e-02
I0216 02:10:26.830365 23126066861888 run_lib.py:133] step: 297000, training_loss: 1.87478e-02
I0216 02:10:26.984113 23126066861888 run_lib.py:146] step: 297000, eval_loss: 2.78898e-02
I0216 02:10:44.347277 23126066861888 run_lib.py:133] step: 297050, training_loss: 1.82209e-02
I0216 02:11:01.680047 23126066861888 run_lib.py:133] step: 297100, training_loss: 1.84142e-02
I0216 02:11:01.835069 23126066861888 run_lib.py:146] step: 297100, eval_loss: 2.70816e-02
I0216 02:11:19.303604 23126066861888 run_lib.py:133] step: 297150, training_loss: 1.87400e-02
I0216 02:11:36.676300 23126066861888 run_lib.py:133] step: 297200, training_loss: 1.75681e-02
I0216 02:11:36.832888 23126066861888 run_lib.py:146] step: 297200, eval_loss: 2.69091e-02
I0216 02:11:54.201614 23126066861888 run_lib.py:133] step: 297250, training_loss: 1.88888e-02
I0216 02:12:11.592265 23126066861888 run_lib.py:133] step: 297300, training_loss: 1.81563e-02
I0216 02:12:11.748154 23126066861888 run_lib.py:146] step: 297300, eval_loss: 2.73898e-02
I0216 02:12:29.350193 23126066861888 run_lib.py:133] step: 297350, training_loss: 1.87753e-02
I0216 02:12:46.776900 23126066861888 run_lib.py:133] step: 297400, training_loss: 1.86162e-02
I0216 02:12:46.931169 23126066861888 run_lib.py:146] step: 297400, eval_loss: 2.75700e-02
I0216 02:13:04.282330 23126066861888 run_lib.py:133] step: 297450, training_loss: 1.84088e-02
I0216 02:13:21.644038 23126066861888 run_lib.py:133] step: 297500, training_loss: 1.84607e-02
I0216 02:13:21.815072 23126066861888 run_lib.py:146] step: 297500, eval_loss: 2.67824e-02
I0216 02:13:39.376546 23126066861888 run_lib.py:133] step: 297550, training_loss: 1.84473e-02
I0216 02:13:56.752263 23126066861888 run_lib.py:133] step: 297600, training_loss: 1.77797e-02
I0216 02:13:56.910061 23126066861888 run_lib.py:146] step: 297600, eval_loss: 2.80060e-02
I0216 02:14:14.367240 23126066861888 run_lib.py:133] step: 297650, training_loss: 1.79249e-02
I0216 02:14:31.883890 23126066861888 run_lib.py:133] step: 297700, training_loss: 1.81259e-02
I0216 02:14:32.036710 23126066861888 run_lib.py:146] step: 297700, eval_loss: 2.67645e-02
I0216 02:14:49.372894 23126066861888 run_lib.py:133] step: 297750, training_loss: 1.82676e-02
I0216 02:15:06.910501 23126066861888 run_lib.py:133] step: 297800, training_loss: 1.83645e-02
I0216 02:15:07.067077 23126066861888 run_lib.py:146] step: 297800, eval_loss: 2.86622e-02
I0216 02:15:24.490868 23126066861888 run_lib.py:133] step: 297850, training_loss: 1.77880e-02
I0216 02:15:41.836488 23126066861888 run_lib.py:133] step: 297900, training_loss: 1.83408e-02
I0216 02:15:42.001366 23126066861888 run_lib.py:146] step: 297900, eval_loss: 2.78102e-02
I0216 02:15:59.521235 23126066861888 run_lib.py:133] step: 297950, training_loss: 1.84303e-02
I0216 02:16:16.861580 23126066861888 run_lib.py:133] step: 298000, training_loss: 1.75790e-02
I0216 02:16:17.019881 23126066861888 run_lib.py:146] step: 298000, eval_loss: 2.68477e-02
I0216 02:16:34.376577 23126066861888 run_lib.py:133] step: 298050, training_loss: 1.75109e-02
I0216 02:16:51.913272 23126066861888 run_lib.py:133] step: 298100, training_loss: 1.82928e-02
I0216 02:16:52.073105 23126066861888 run_lib.py:146] step: 298100, eval_loss: 2.81408e-02
I0216 02:17:09.471674 23126066861888 run_lib.py:133] step: 298150, training_loss: 1.83932e-02
I0216 02:17:26.817484 23126066861888 run_lib.py:133] step: 298200, training_loss: 1.81301e-02
I0216 02:17:27.006700 23126066861888 run_lib.py:146] step: 298200, eval_loss: 2.71798e-02
I0216 02:17:44.478270 23126066861888 run_lib.py:133] step: 298250, training_loss: 1.82824e-02
I0216 02:18:01.860815 23126066861888 run_lib.py:133] step: 298300, training_loss: 1.88174e-02
I0216 02:18:02.016966 23126066861888 run_lib.py:146] step: 298300, eval_loss: 2.85120e-02
I0216 02:18:19.383803 23126066861888 run_lib.py:133] step: 298350, training_loss: 1.80769e-02
I0216 02:18:36.816701 23126066861888 run_lib.py:133] step: 298400, training_loss: 1.84166e-02
I0216 02:18:36.975989 23126066861888 run_lib.py:146] step: 298400, eval_loss: 2.75792e-02
I0216 02:18:54.501393 23126066861888 run_lib.py:133] step: 298450, training_loss: 1.88058e-02
I0216 02:19:11.980998 23126066861888 run_lib.py:133] step: 298500, training_loss: 1.82304e-02
I0216 02:19:12.136262 23126066861888 run_lib.py:146] step: 298500, eval_loss: 2.71311e-02
I0216 02:19:29.512456 23126066861888 run_lib.py:133] step: 298550, training_loss: 1.80650e-02
I0216 02:19:46.893835 23126066861888 run_lib.py:133] step: 298600, training_loss: 1.82751e-02
I0216 02:19:47.052110 23126066861888 run_lib.py:146] step: 298600, eval_loss: 2.72808e-02
I0216 02:20:04.524686 23126066861888 run_lib.py:133] step: 298650, training_loss: 1.83924e-02
I0216 02:20:21.906765 23126066861888 run_lib.py:133] step: 298700, training_loss: 1.84685e-02
I0216 02:20:22.060451 23126066861888 run_lib.py:146] step: 298700, eval_loss: 2.79116e-02
I0216 02:20:39.430211 23126066861888 run_lib.py:133] step: 298750, training_loss: 1.84464e-02
I0216 02:20:57.043467 23126066861888 run_lib.py:133] step: 298800, training_loss: 1.84887e-02
I0216 02:20:57.196556 23126066861888 run_lib.py:146] step: 298800, eval_loss: 2.72314e-02
I0216 02:21:14.503615 23126066861888 run_lib.py:133] step: 298850, training_loss: 1.90679e-02
I0216 02:21:31.957983 23126066861888 run_lib.py:133] step: 298900, training_loss: 1.78174e-02
I0216 02:21:32.127914 23126066861888 run_lib.py:146] step: 298900, eval_loss: 2.84339e-02
I0216 02:21:49.526477 23126066861888 run_lib.py:133] step: 298950, training_loss: 1.79889e-02
I0216 02:22:06.910705 23126066861888 run_lib.py:133] step: 299000, training_loss: 1.85882e-02
I0216 02:22:07.069335 23126066861888 run_lib.py:146] step: 299000, eval_loss: 2.78014e-02
I0216 02:22:24.661822 23126066861888 run_lib.py:133] step: 299050, training_loss: 1.81356e-02
I0216 02:22:41.979274 23126066861888 run_lib.py:133] step: 299100, training_loss: 1.86424e-02
I0216 02:22:42.168793 23126066861888 run_lib.py:146] step: 299100, eval_loss: 2.65518e-02
I0216 02:22:59.472135 23126066861888 run_lib.py:133] step: 299150, training_loss: 1.86191e-02
I0216 02:23:17.090759 23126066861888 run_lib.py:133] step: 299200, training_loss: 1.84380e-02
I0216 02:23:17.254262 23126066861888 run_lib.py:146] step: 299200, eval_loss: 2.79065e-02
I0216 02:23:34.692425 23126066861888 run_lib.py:133] step: 299250, training_loss: 1.82545e-02
I0216 02:23:52.073780 23126066861888 run_lib.py:133] step: 299300, training_loss: 1.80280e-02
I0216 02:23:52.230091 23126066861888 run_lib.py:146] step: 299300, eval_loss: 2.68742e-02
I0216 02:24:09.737572 23126066861888 run_lib.py:133] step: 299350, training_loss: 1.79731e-02
I0216 02:24:27.149802 23126066861888 run_lib.py:133] step: 299400, training_loss: 1.78053e-02
I0216 02:24:27.305180 23126066861888 run_lib.py:146] step: 299400, eval_loss: 2.89569e-02
I0216 02:24:44.700878 23126066861888 run_lib.py:133] step: 299450, training_loss: 1.86464e-02
I0216 02:25:02.137001 23126066861888 run_lib.py:133] step: 299500, training_loss: 1.89494e-02
I0216 02:25:02.293260 23126066861888 run_lib.py:146] step: 299500, eval_loss: 2.69981e-02
I0216 02:25:19.893738 23126066861888 run_lib.py:133] step: 299550, training_loss: 1.82773e-02
I0216 02:25:37.339234 23126066861888 run_lib.py:133] step: 299600, training_loss: 1.83363e-02
I0216 02:25:37.492089 23126066861888 run_lib.py:146] step: 299600, eval_loss: 2.74661e-02
I0216 02:25:54.809767 23126066861888 run_lib.py:133] step: 299650, training_loss: 1.83043e-02
I0216 02:26:12.191723 23126066861888 run_lib.py:133] step: 299700, training_loss: 1.82089e-02
I0216 02:26:12.352190 23126066861888 run_lib.py:146] step: 299700, eval_loss: 2.70787e-02
I0216 02:26:29.960334 23126066861888 run_lib.py:133] step: 299750, training_loss: 1.80576e-02
I0216 02:26:47.393694 23126066861888 run_lib.py:133] step: 299800, training_loss: 1.78194e-02
I0216 02:26:47.551947 23126066861888 run_lib.py:146] step: 299800, eval_loss: 2.79464e-02
I0216 02:27:04.866944 23126066861888 run_lib.py:133] step: 299850, training_loss: 1.79927e-02
I0216 02:27:22.369863 23126066861888 run_lib.py:133] step: 299900, training_loss: 1.82834e-02
I0216 02:27:22.524978 23126066861888 run_lib.py:146] step: 299900, eval_loss: 2.65814e-02
I0216 02:27:39.874303 23126066861888 run_lib.py:133] step: 299950, training_loss: 1.75491e-02
I0216 02:27:57.385932 23126066861888 run_lib.py:133] step: 300000, training_loss: 1.87245e-02
I0216 02:27:58.090545 23126066861888 run_lib.py:146] step: 300000, eval_loss: 2.80470e-02
I0216 02:28:18.177560 23126066861888 run_lib.py:133] step: 300050, training_loss: 1.83736e-02
I0216 02:28:35.621693 23126066861888 run_lib.py:133] step: 300100, training_loss: 1.83853e-02
I0216 02:28:35.780044 23126066861888 run_lib.py:146] step: 300100, eval_loss: 2.71779e-02
I0216 02:28:53.163878 23126066861888 run_lib.py:133] step: 300150, training_loss: 1.89905e-02
I0216 02:29:10.532615 23126066861888 run_lib.py:133] step: 300200, training_loss: 1.77174e-02
I0216 02:29:10.684021 23126066861888 run_lib.py:146] step: 300200, eval_loss: 2.78330e-02
I0216 02:29:28.223535 23126066861888 run_lib.py:133] step: 300250, training_loss: 1.79547e-02
I0216 02:29:45.669492 23126066861888 run_lib.py:133] step: 300300, training_loss: 1.84771e-02
I0216 02:29:45.837127 23126066861888 run_lib.py:146] step: 300300, eval_loss: 2.75902e-02
I0216 02:30:03.253950 23126066861888 run_lib.py:133] step: 300350, training_loss: 1.83129e-02
I0216 02:30:20.637275 23126066861888 run_lib.py:133] step: 300400, training_loss: 1.77025e-02
I0216 02:30:20.798987 23126066861888 run_lib.py:146] step: 300400, eval_loss: 2.80348e-02
I0216 02:30:38.306477 23126066861888 run_lib.py:133] step: 300450, training_loss: 1.85075e-02
I0216 02:30:55.617754 23126066861888 run_lib.py:133] step: 300500, training_loss: 1.80270e-02
I0216 02:30:55.772464 23126066861888 run_lib.py:146] step: 300500, eval_loss: 2.73310e-02
I0216 02:31:13.135023 23126066861888 run_lib.py:133] step: 300550, training_loss: 1.79209e-02
I0216 02:31:30.668214 23126066861888 run_lib.py:133] step: 300600, training_loss: 1.84132e-02
I0216 02:31:30.822173 23126066861888 run_lib.py:146] step: 300600, eval_loss: 2.74512e-02
I0216 02:31:48.186621 23126066861888 run_lib.py:133] step: 300650, training_loss: 1.84895e-02
I0216 02:32:05.697496 23126066861888 run_lib.py:133] step: 300700, training_loss: 1.79274e-02
I0216 02:32:05.848920 23126066861888 run_lib.py:146] step: 300700, eval_loss: 2.79971e-02
I0216 02:32:23.171635 23126066861888 run_lib.py:133] step: 300750, training_loss: 1.84728e-02
I0216 02:32:40.500959 23126066861888 run_lib.py:133] step: 300800, training_loss: 1.83753e-02
I0216 02:32:40.662036 23126066861888 run_lib.py:146] step: 300800, eval_loss: 2.77725e-02
I0216 02:32:58.220345 23126066861888 run_lib.py:133] step: 300850, training_loss: 1.86897e-02
I0216 02:33:15.617072 23126066861888 run_lib.py:133] step: 300900, training_loss: 1.80522e-02
I0216 02:33:15.772928 23126066861888 run_lib.py:146] step: 300900, eval_loss: 2.65431e-02
I0216 02:33:33.087796 23126066861888 run_lib.py:133] step: 300950, training_loss: 1.75506e-02
I0216 02:33:50.599542 23126066861888 run_lib.py:133] step: 301000, training_loss: 1.84557e-02
I0216 02:33:50.754607 23126066861888 run_lib.py:146] step: 301000, eval_loss: 2.77835e-02
I0216 02:34:08.083470 23126066861888 run_lib.py:133] step: 301050, training_loss: 1.86073e-02
I0216 02:34:25.470428 23126066861888 run_lib.py:133] step: 301100, training_loss: 1.80809e-02
I0216 02:34:25.628769 23126066861888 run_lib.py:146] step: 301100, eval_loss: 2.75782e-02
I0216 02:34:43.130569 23126066861888 run_lib.py:133] step: 301150, training_loss: 1.83516e-02
I0216 02:35:00.466928 23126066861888 run_lib.py:133] step: 301200, training_loss: 1.85485e-02
I0216 02:35:00.628816 23126066861888 run_lib.py:146] step: 301200, eval_loss: 2.72395e-02
I0216 02:35:17.958348 23126066861888 run_lib.py:133] step: 301250, training_loss: 1.79968e-02
I0216 02:35:35.302538 23126066861888 run_lib.py:133] step: 301300, training_loss: 1.82857e-02
I0216 02:35:35.467993 23126066861888 run_lib.py:146] step: 301300, eval_loss: 2.67837e-02
I0216 02:35:52.965311 23126066861888 run_lib.py:133] step: 301350, training_loss: 1.76548e-02
I0216 02:36:10.354960 23126066861888 run_lib.py:133] step: 301400, training_loss: 1.81747e-02
I0216 02:36:10.522958 23126066861888 run_lib.py:146] step: 301400, eval_loss: 2.75801e-02
I0216 02:36:27.920610 23126066861888 run_lib.py:133] step: 301450, training_loss: 1.79735e-02
I0216 02:36:45.266866 23126066861888 run_lib.py:133] step: 301500, training_loss: 1.74012e-02
I0216 02:36:45.422330 23126066861888 run_lib.py:146] step: 301500, eval_loss: 2.84835e-02
I0216 02:37:02.967741 23126066861888 run_lib.py:133] step: 301550, training_loss: 1.83142e-02
I0216 02:37:20.247780 23126066861888 run_lib.py:133] step: 301600, training_loss: 1.93262e-02
I0216 02:37:20.398070 23126066861888 run_lib.py:146] step: 301600, eval_loss: 2.71316e-02
I0216 02:37:37.731788 23126066861888 run_lib.py:133] step: 301650, training_loss: 1.83926e-02
I0216 02:37:55.309957 23126066861888 run_lib.py:133] step: 301700, training_loss: 1.83721e-02
I0216 02:37:55.476290 23126066861888 run_lib.py:146] step: 301700, eval_loss: 2.78605e-02
I0216 02:38:12.917866 23126066861888 run_lib.py:133] step: 301750, training_loss: 1.76669e-02
I0216 02:38:30.469427 23126066861888 run_lib.py:133] step: 301800, training_loss: 1.85560e-02
I0216 02:38:30.624289 23126066861888 run_lib.py:146] step: 301800, eval_loss: 2.72677e-02
I0216 02:38:47.980670 23126066861888 run_lib.py:133] step: 301850, training_loss: 1.84946e-02
I0216 02:39:05.295981 23126066861888 run_lib.py:133] step: 301900, training_loss: 1.90053e-02
I0216 02:39:05.447964 23126066861888 run_lib.py:146] step: 301900, eval_loss: 2.70891e-02
I0216 02:39:22.937436 23126066861888 run_lib.py:133] step: 301950, training_loss: 1.85881e-02
I0216 02:39:40.333957 23126066861888 run_lib.py:133] step: 302000, training_loss: 1.80333e-02
I0216 02:39:40.489324 23126066861888 run_lib.py:146] step: 302000, eval_loss: 2.67518e-02
I0216 02:39:57.881876 23126066861888 run_lib.py:133] step: 302050, training_loss: 1.81951e-02
I0216 02:40:15.426145 23126066861888 run_lib.py:133] step: 302100, training_loss: 1.82012e-02
I0216 02:40:15.579003 23126066861888 run_lib.py:146] step: 302100, eval_loss: 2.79030e-02
I0216 02:40:32.928625 23126066861888 run_lib.py:133] step: 302150, training_loss: 1.74563e-02
I0216 02:40:50.240735 23126066861888 run_lib.py:133] step: 302200, training_loss: 1.81773e-02
I0216 02:40:50.403610 23126066861888 run_lib.py:146] step: 302200, eval_loss: 2.81641e-02
I0216 02:41:07.887434 23126066861888 run_lib.py:133] step: 302250, training_loss: 1.83648e-02
I0216 02:41:25.292503 23126066861888 run_lib.py:133] step: 302300, training_loss: 1.83951e-02
I0216 02:41:25.448930 23126066861888 run_lib.py:146] step: 302300, eval_loss: 2.64295e-02
I0216 02:41:42.799855 23126066861888 run_lib.py:133] step: 302350, training_loss: 1.89529e-02
I0216 02:42:00.113261 23126066861888 run_lib.py:133] step: 302400, training_loss: 1.84392e-02
I0216 02:42:00.271940 23126066861888 run_lib.py:146] step: 302400, eval_loss: 2.78797e-02
I0216 02:42:17.789756 23126066861888 run_lib.py:133] step: 302450, training_loss: 1.85348e-02
I0216 02:42:35.205832 23126066861888 run_lib.py:133] step: 302500, training_loss: 1.84698e-02
I0216 02:42:35.358955 23126066861888 run_lib.py:146] step: 302500, eval_loss: 2.78472e-02
I0216 02:42:52.766087 23126066861888 run_lib.py:133] step: 302550, training_loss: 1.78557e-02
I0216 02:43:10.133059 23126066861888 run_lib.py:133] step: 302600, training_loss: 1.89118e-02
I0216 02:43:10.287212 23126066861888 run_lib.py:146] step: 302600, eval_loss: 2.62265e-02
I0216 02:43:27.845233 23126066861888 run_lib.py:133] step: 302650, training_loss: 1.79616e-02
I0216 02:43:45.194156 23126066861888 run_lib.py:133] step: 302700, training_loss: 1.84471e-02
I0216 02:43:45.350254 23126066861888 run_lib.py:146] step: 302700, eval_loss: 2.78524e-02
I0216 02:44:02.660538 23126066861888 run_lib.py:133] step: 302750, training_loss: 1.84462e-02
I0216 02:44:20.159603 23126066861888 run_lib.py:133] step: 302800, training_loss: 1.89578e-02
I0216 02:44:20.325908 23126066861888 run_lib.py:146] step: 302800, eval_loss: 2.75779e-02
I0216 02:44:37.684628 23126066861888 run_lib.py:133] step: 302850, training_loss: 1.82605e-02
I0216 02:44:55.329027 23126066861888 run_lib.py:133] step: 302900, training_loss: 1.83353e-02
I0216 02:44:55.483239 23126066861888 run_lib.py:146] step: 302900, eval_loss: 2.69422e-02
I0216 02:45:12.812014 23126066861888 run_lib.py:133] step: 302950, training_loss: 1.81038e-02
I0216 02:45:30.112750 23126066861888 run_lib.py:133] step: 303000, training_loss: 1.84107e-02
I0216 02:45:30.272841 23126066861888 run_lib.py:146] step: 303000, eval_loss: 2.91103e-02
I0216 02:45:47.739526 23126066861888 run_lib.py:133] step: 303050, training_loss: 1.83775e-02
I0216 02:46:05.080597 23126066861888 run_lib.py:133] step: 303100, training_loss: 1.78340e-02
I0216 02:46:05.240164 23126066861888 run_lib.py:146] step: 303100, eval_loss: 2.74301e-02
I0216 02:46:22.628813 23126066861888 run_lib.py:133] step: 303150, training_loss: 1.92364e-02
I0216 02:46:40.172582 23126066861888 run_lib.py:133] step: 303200, training_loss: 1.88242e-02
I0216 02:46:40.330944 23126066861888 run_lib.py:146] step: 303200, eval_loss: 2.71797e-02
I0216 02:46:57.650695 23126066861888 run_lib.py:133] step: 303250, training_loss: 1.84843e-02
I0216 02:47:15.041912 23126066861888 run_lib.py:133] step: 303300, training_loss: 1.81305e-02
I0216 02:47:15.196236 23126066861888 run_lib.py:146] step: 303300, eval_loss: 2.81360e-02
I0216 02:47:32.653623 23126066861888 run_lib.py:133] step: 303350, training_loss: 1.88490e-02
I0216 02:47:50.058592 23126066861888 run_lib.py:133] step: 303400, training_loss: 1.76967e-02
I0216 02:47:50.216267 23126066861888 run_lib.py:146] step: 303400, eval_loss: 2.79310e-02
I0216 02:48:07.569702 23126066861888 run_lib.py:133] step: 303450, training_loss: 1.87160e-02
I0216 02:48:24.921841 23126066861888 run_lib.py:133] step: 303500, training_loss: 1.84309e-02
I0216 02:48:25.108840 23126066861888 run_lib.py:146] step: 303500, eval_loss: 2.78880e-02
I0216 02:48:42.598589 23126066861888 run_lib.py:133] step: 303550, training_loss: 1.89586e-02
I0216 02:49:00.034610 23126066861888 run_lib.py:133] step: 303600, training_loss: 1.79439e-02
I0216 02:49:00.190207 23126066861888 run_lib.py:146] step: 303600, eval_loss: 2.81667e-02
I0216 02:49:17.533949 23126066861888 run_lib.py:133] step: 303650, training_loss: 1.84619e-02
I0216 02:49:34.903810 23126066861888 run_lib.py:133] step: 303700, training_loss: 1.89127e-02
I0216 02:49:35.065228 23126066861888 run_lib.py:146] step: 303700, eval_loss: 2.77284e-02
I0216 02:49:52.607635 23126066861888 run_lib.py:133] step: 303750, training_loss: 1.75458e-02
I0216 02:50:09.944981 23126066861888 run_lib.py:133] step: 303800, training_loss: 1.78952e-02
I0216 02:50:10.101154 23126066861888 run_lib.py:146] step: 303800, eval_loss: 2.81035e-02
I0216 02:50:27.458767 23126066861888 run_lib.py:133] step: 303850, training_loss: 1.91051e-02
I0216 02:50:44.940135 23126066861888 run_lib.py:133] step: 303900, training_loss: 1.89589e-02
I0216 02:50:45.094939 23126066861888 run_lib.py:146] step: 303900, eval_loss: 2.88739e-02
I0216 02:51:02.436243 23126066861888 run_lib.py:133] step: 303950, training_loss: 1.76640e-02
I0216 02:51:19.968003 23126066861888 run_lib.py:133] step: 304000, training_loss: 1.88569e-02
I0216 02:51:20.123084 23126066861888 run_lib.py:146] step: 304000, eval_loss: 2.70828e-02
I0216 02:51:37.490271 23126066861888 run_lib.py:133] step: 304050, training_loss: 1.76737e-02
I0216 02:51:54.851292 23126066861888 run_lib.py:133] step: 304100, training_loss: 1.86603e-02
I0216 02:51:55.004986 23126066861888 run_lib.py:146] step: 304100, eval_loss: 2.70487e-02
I0216 02:52:12.521065 23126066861888 run_lib.py:133] step: 304150, training_loss: 1.81822e-02
I0216 02:52:29.911564 23126066861888 run_lib.py:133] step: 304200, training_loss: 1.83168e-02
I0216 02:52:30.070137 23126066861888 run_lib.py:146] step: 304200, eval_loss: 2.78484e-02
I0216 02:52:47.419493 23126066861888 run_lib.py:133] step: 304250, training_loss: 1.82307e-02
I0216 02:53:05.041459 23126066861888 run_lib.py:133] step: 304300, training_loss: 1.91697e-02
I0216 02:53:05.204524 23126066861888 run_lib.py:146] step: 304300, eval_loss: 2.63988e-02
I0216 02:53:22.565818 23126066861888 run_lib.py:133] step: 304350, training_loss: 1.86891e-02
I0216 02:53:39.876920 23126066861888 run_lib.py:133] step: 304400, training_loss: 1.85389e-02
I0216 02:53:40.030785 23126066861888 run_lib.py:146] step: 304400, eval_loss: 2.79746e-02
I0216 02:53:57.494037 23126066861888 run_lib.py:133] step: 304450, training_loss: 1.85381e-02
I0216 02:54:14.878513 23126066861888 run_lib.py:133] step: 304500, training_loss: 1.87852e-02
I0216 02:54:15.036099 23126066861888 run_lib.py:146] step: 304500, eval_loss: 2.63824e-02
I0216 02:54:32.469320 23126066861888 run_lib.py:133] step: 304550, training_loss: 1.84583e-02
I0216 02:54:49.840261 23126066861888 run_lib.py:133] step: 304600, training_loss: 1.89023e-02
I0216 02:54:49.998965 23126066861888 run_lib.py:146] step: 304600, eval_loss: 2.79877e-02
I0216 02:55:07.531302 23126066861888 run_lib.py:133] step: 304650, training_loss: 1.81620e-02
I0216 02:55:24.930480 23126066861888 run_lib.py:133] step: 304700, training_loss: 1.81107e-02
I0216 02:55:25.085173 23126066861888 run_lib.py:146] step: 304700, eval_loss: 2.80181e-02
I0216 02:55:42.434378 23126066861888 run_lib.py:133] step: 304750, training_loss: 1.80673e-02
I0216 02:55:59.717832 23126066861888 run_lib.py:133] step: 304800, training_loss: 1.79007e-02
I0216 02:55:59.875681 23126066861888 run_lib.py:146] step: 304800, eval_loss: 2.73958e-02
I0216 02:56:17.410642 23126066861888 run_lib.py:133] step: 304850, training_loss: 1.80888e-02
I0216 02:56:34.819065 23126066861888 run_lib.py:133] step: 304900, training_loss: 1.75267e-02
I0216 02:56:34.973303 23126066861888 run_lib.py:146] step: 304900, eval_loss: 2.74610e-02
I0216 02:56:52.393971 23126066861888 run_lib.py:133] step: 304950, training_loss: 1.79614e-02
I0216 02:57:09.989761 23126066861888 run_lib.py:133] step: 305000, training_loss: 1.80454e-02
I0216 02:57:10.158973 23126066861888 run_lib.py:146] step: 305000, eval_loss: 2.76915e-02
I0216 02:57:27.533017 23126066861888 run_lib.py:133] step: 305050, training_loss: 1.83625e-02
I0216 02:57:45.006423 23126066861888 run_lib.py:133] step: 305100, training_loss: 1.77124e-02
I0216 02:57:45.176679 23126066861888 run_lib.py:146] step: 305100, eval_loss: 2.72411e-02
I0216 02:58:02.589490 23126066861888 run_lib.py:133] step: 305150, training_loss: 1.80941e-02
I0216 02:58:19.975754 23126066861888 run_lib.py:133] step: 305200, training_loss: 1.82670e-02
I0216 02:58:20.138402 23126066861888 run_lib.py:146] step: 305200, eval_loss: 2.76284e-02
I0216 02:58:37.661085 23126066861888 run_lib.py:133] step: 305250, training_loss: 1.90809e-02
I0216 02:58:54.984285 23126066861888 run_lib.py:133] step: 305300, training_loss: 1.78599e-02
I0216 02:58:55.141093 23126066861888 run_lib.py:146] step: 305300, eval_loss: 2.68748e-02
I0216 02:59:12.523577 23126066861888 run_lib.py:133] step: 305350, training_loss: 1.78456e-02
I0216 02:59:30.149588 23126066861888 run_lib.py:133] step: 305400, training_loss: 1.86497e-02
I0216 02:59:30.301092 23126066861888 run_lib.py:146] step: 305400, eval_loss: 2.80075e-02
I0216 02:59:47.717465 23126066861888 run_lib.py:133] step: 305450, training_loss: 1.77036e-02
I0216 03:00:05.062476 23126066861888 run_lib.py:133] step: 305500, training_loss: 1.80586e-02
I0216 03:00:05.216930 23126066861888 run_lib.py:146] step: 305500, eval_loss: 2.81762e-02
I0216 03:00:22.652015 23126066861888 run_lib.py:133] step: 305550, training_loss: 1.79821e-02
I0216 03:00:39.962208 23126066861888 run_lib.py:133] step: 305600, training_loss: 1.80670e-02
I0216 03:00:40.120156 23126066861888 run_lib.py:146] step: 305600, eval_loss: 2.88591e-02
I0216 03:00:57.441014 23126066861888 run_lib.py:133] step: 305650, training_loss: 1.84664e-02
I0216 03:01:14.844960 23126066861888 run_lib.py:133] step: 305700, training_loss: 1.80128e-02
I0216 03:01:15.003229 23126066861888 run_lib.py:146] step: 305700, eval_loss: 2.71750e-02
I0216 03:01:32.527817 23126066861888 run_lib.py:133] step: 305750, training_loss: 1.81979e-02
I0216 03:01:49.957382 23126066861888 run_lib.py:133] step: 305800, training_loss: 1.85356e-02
I0216 03:01:50.114614 23126066861888 run_lib.py:146] step: 305800, eval_loss: 2.67364e-02
I0216 03:02:07.420788 23126066861888 run_lib.py:133] step: 305850, training_loss: 1.87002e-02
I0216 03:02:24.755666 23126066861888 run_lib.py:133] step: 305900, training_loss: 1.86919e-02
I0216 03:02:24.906867 23126066861888 run_lib.py:146] step: 305900, eval_loss: 2.71974e-02
I0216 03:02:42.385463 23126066861888 run_lib.py:133] step: 305950, training_loss: 1.84291e-02
I0216 03:02:59.747839 23126066861888 run_lib.py:133] step: 306000, training_loss: 1.88813e-02
I0216 03:02:59.913231 23126066861888 run_lib.py:146] step: 306000, eval_loss: 2.69701e-02
I0216 03:03:17.315517 23126066861888 run_lib.py:133] step: 306050, training_loss: 1.81477e-02
I0216 03:03:34.958404 23126066861888 run_lib.py:133] step: 306100, training_loss: 1.81966e-02
I0216 03:03:35.124323 23126066861888 run_lib.py:146] step: 306100, eval_loss: 2.66837e-02
I0216 03:03:52.436273 23126066861888 run_lib.py:133] step: 306150, training_loss: 1.84427e-02
I0216 03:04:09.928242 23126066861888 run_lib.py:133] step: 306200, training_loss: 1.82571e-02
I0216 03:04:10.082856 23126066861888 run_lib.py:146] step: 306200, eval_loss: 2.74361e-02
I0216 03:04:27.451927 23126066861888 run_lib.py:133] step: 306250, training_loss: 1.78167e-02
I0216 03:04:44.850327 23126066861888 run_lib.py:133] step: 306300, training_loss: 1.84794e-02
I0216 03:04:45.004852 23126066861888 run_lib.py:146] step: 306300, eval_loss: 2.69032e-02
I0216 03:05:02.621856 23126066861888 run_lib.py:133] step: 306350, training_loss: 1.85586e-02
I0216 03:05:19.935952 23126066861888 run_lib.py:133] step: 306400, training_loss: 1.80717e-02
I0216 03:05:20.087913 23126066861888 run_lib.py:146] step: 306400, eval_loss: 2.66752e-02
I0216 03:05:37.400767 23126066861888 run_lib.py:133] step: 306450, training_loss: 1.93898e-02
I0216 03:05:55.019959 23126066861888 run_lib.py:133] step: 306500, training_loss: 1.80182e-02
I0216 03:05:55.194948 23126066861888 run_lib.py:146] step: 306500, eval_loss: 2.65134e-02
I0216 03:06:12.621558 23126066861888 run_lib.py:133] step: 306550, training_loss: 1.72574e-02
I0216 03:06:30.047550 23126066861888 run_lib.py:133] step: 306600, training_loss: 1.80819e-02
I0216 03:06:30.203091 23126066861888 run_lib.py:146] step: 306600, eval_loss: 2.76853e-02
I0216 03:06:47.704886 23126066861888 run_lib.py:133] step: 306650, training_loss: 1.84522e-02
I0216 03:07:05.067129 23126066861888 run_lib.py:133] step: 306700, training_loss: 1.83230e-02
I0216 03:07:05.223859 23126066861888 run_lib.py:146] step: 306700, eval_loss: 2.72813e-02
I0216 03:07:22.645720 23126066861888 run_lib.py:133] step: 306750, training_loss: 1.81313e-02
I0216 03:07:40.088733 23126066861888 run_lib.py:133] step: 306800, training_loss: 1.78147e-02
I0216 03:07:40.246471 23126066861888 run_lib.py:146] step: 306800, eval_loss: 2.77511e-02
I0216 03:07:57.905974 23126066861888 run_lib.py:133] step: 306850, training_loss: 1.80610e-02
I0216 03:08:15.430698 23126066861888 run_lib.py:133] step: 306900, training_loss: 1.82455e-02
I0216 03:08:15.587147 23126066861888 run_lib.py:146] step: 306900, eval_loss: 2.75207e-02
I0216 03:08:32.971879 23126066861888 run_lib.py:133] step: 306950, training_loss: 1.85839e-02
I0216 03:08:50.367823 23126066861888 run_lib.py:133] step: 307000, training_loss: 1.85813e-02
I0216 03:08:50.532214 23126066861888 run_lib.py:146] step: 307000, eval_loss: 2.65220e-02
I0216 03:09:08.099936 23126066861888 run_lib.py:133] step: 307050, training_loss: 1.83431e-02
I0216 03:09:25.531867 23126066861888 run_lib.py:133] step: 307100, training_loss: 1.83574e-02
I0216 03:09:25.688250 23126066861888 run_lib.py:146] step: 307100, eval_loss: 2.79280e-02
I0216 03:09:43.115371 23126066861888 run_lib.py:133] step: 307150, training_loss: 1.85928e-02
I0216 03:10:00.708890 23126066861888 run_lib.py:133] step: 307200, training_loss: 1.86222e-02
I0216 03:10:00.863981 23126066861888 run_lib.py:146] step: 307200, eval_loss: 2.78636e-02
I0216 03:10:18.206201 23126066861888 run_lib.py:133] step: 307250, training_loss: 1.83064e-02
I0216 03:10:35.673938 23126066861888 run_lib.py:133] step: 307300, training_loss: 1.78409e-02
I0216 03:10:35.826018 23126066861888 run_lib.py:146] step: 307300, eval_loss: 2.71437e-02
I0216 03:10:53.163670 23126066861888 run_lib.py:133] step: 307350, training_loss: 1.85191e-02
I0216 03:11:10.529498 23126066861888 run_lib.py:133] step: 307400, training_loss: 1.82148e-02
I0216 03:11:10.688179 23126066861888 run_lib.py:146] step: 307400, eval_loss: 2.74291e-02
I0216 03:11:28.217839 23126066861888 run_lib.py:133] step: 307450, training_loss: 1.85143e-02
I0216 03:11:45.550712 23126066861888 run_lib.py:133] step: 307500, training_loss: 1.83521e-02
I0216 03:11:45.715178 23126066861888 run_lib.py:146] step: 307500, eval_loss: 2.77512e-02
I0216 03:12:03.042479 23126066861888 run_lib.py:133] step: 307550, training_loss: 1.80501e-02
I0216 03:12:20.525454 23126066861888 run_lib.py:133] step: 307600, training_loss: 1.81757e-02
I0216 03:12:20.683868 23126066861888 run_lib.py:146] step: 307600, eval_loss: 2.80435e-02
I0216 03:12:38.009939 23126066861888 run_lib.py:133] step: 307650, training_loss: 1.84865e-02
I0216 03:12:55.384944 23126066861888 run_lib.py:133] step: 307700, training_loss: 1.92833e-02
I0216 03:12:55.539188 23126066861888 run_lib.py:146] step: 307700, eval_loss: 2.72899e-02
I0216 03:13:12.989787 23126066861888 run_lib.py:133] step: 307750, training_loss: 1.75675e-02
I0216 03:13:30.374536 23126066861888 run_lib.py:133] step: 307800, training_loss: 1.81578e-02
I0216 03:13:30.533770 23126066861888 run_lib.py:146] step: 307800, eval_loss: 2.84498e-02
I0216 03:13:47.829590 23126066861888 run_lib.py:133] step: 307850, training_loss: 1.76498e-02
I0216 03:14:05.161729 23126066861888 run_lib.py:133] step: 307900, training_loss: 1.83133e-02
I0216 03:14:05.327776 23126066861888 run_lib.py:146] step: 307900, eval_loss: 2.74518e-02
I0216 03:14:22.872723 23126066861888 run_lib.py:133] step: 307950, training_loss: 1.86074e-02
I0216 03:14:40.296669 23126066861888 run_lib.py:133] step: 308000, training_loss: 1.81722e-02
I0216 03:14:40.451019 23126066861888 run_lib.py:146] step: 308000, eval_loss: 2.80029e-02
I0216 03:14:57.770144 23126066861888 run_lib.py:133] step: 308050, training_loss: 1.88857e-02
I0216 03:15:15.134595 23126066861888 run_lib.py:133] step: 308100, training_loss: 1.80443e-02
I0216 03:15:15.293069 23126066861888 run_lib.py:146] step: 308100, eval_loss: 2.79073e-02
I0216 03:15:32.829201 23126066861888 run_lib.py:133] step: 308150, training_loss: 1.85647e-02
I0216 03:15:50.232717 23126066861888 run_lib.py:133] step: 308200, training_loss: 1.82926e-02
I0216 03:15:50.391220 23126066861888 run_lib.py:146] step: 308200, eval_loss: 2.70208e-02
I0216 03:16:07.770510 23126066861888 run_lib.py:133] step: 308250, training_loss: 1.82274e-02
I0216 03:16:25.313966 23126066861888 run_lib.py:133] step: 308300, training_loss: 1.81554e-02
I0216 03:16:25.467005 23126066861888 run_lib.py:146] step: 308300, eval_loss: 2.72671e-02
I0216 03:16:42.790509 23126066861888 run_lib.py:133] step: 308350, training_loss: 1.87184e-02
I0216 03:17:00.322539 23126066861888 run_lib.py:133] step: 308400, training_loss: 1.84827e-02
I0216 03:17:00.480174 23126066861888 run_lib.py:146] step: 308400, eval_loss: 2.74347e-02
I0216 03:17:17.867521 23126066861888 run_lib.py:133] step: 308450, training_loss: 1.81348e-02
I0216 03:17:35.257392 23126066861888 run_lib.py:133] step: 308500, training_loss: 1.84194e-02
I0216 03:17:35.413207 23126066861888 run_lib.py:146] step: 308500, eval_loss: 2.80279e-02
I0216 03:17:52.952351 23126066861888 run_lib.py:133] step: 308550, training_loss: 1.79438e-02
I0216 03:18:10.283560 23126066861888 run_lib.py:133] step: 308600, training_loss: 1.83285e-02
I0216 03:18:10.442775 23126066861888 run_lib.py:146] step: 308600, eval_loss: 2.82602e-02
I0216 03:18:27.788655 23126066861888 run_lib.py:133] step: 308650, training_loss: 1.77040e-02
I0216 03:18:45.251173 23126066861888 run_lib.py:133] step: 308700, training_loss: 1.75919e-02
I0216 03:18:45.402920 23126066861888 run_lib.py:146] step: 308700, eval_loss: 2.78128e-02
I0216 03:19:02.802047 23126066861888 run_lib.py:133] step: 308750, training_loss: 1.85404e-02
I0216 03:19:20.130697 23126066861888 run_lib.py:133] step: 308800, training_loss: 1.81438e-02
I0216 03:19:20.286930 23126066861888 run_lib.py:146] step: 308800, eval_loss: 2.71829e-02
I0216 03:19:37.739542 23126066861888 run_lib.py:133] step: 308850, training_loss: 1.85305e-02
I0216 03:19:55.079114 23126066861888 run_lib.py:133] step: 308900, training_loss: 1.76662e-02
I0216 03:19:55.244301 23126066861888 run_lib.py:146] step: 308900, eval_loss: 2.80385e-02
I0216 03:20:12.572139 23126066861888 run_lib.py:133] step: 308950, training_loss: 1.77483e-02
I0216 03:20:29.889436 23126066861888 run_lib.py:133] step: 309000, training_loss: 1.78085e-02
I0216 03:20:30.055058 23126066861888 run_lib.py:146] step: 309000, eval_loss: 2.67699e-02
I0216 03:20:47.577454 23126066861888 run_lib.py:133] step: 309050, training_loss: 1.82590e-02
I0216 03:21:05.082601 23126066861888 run_lib.py:133] step: 309100, training_loss: 1.80207e-02
I0216 03:21:05.237210 23126066861888 run_lib.py:146] step: 309100, eval_loss: 2.79968e-02
I0216 03:21:22.616281 23126066861888 run_lib.py:133] step: 309150, training_loss: 1.86917e-02
I0216 03:21:39.956295 23126066861888 run_lib.py:133] step: 309200, training_loss: 1.85178e-02
I0216 03:21:40.105943 23126066861888 run_lib.py:146] step: 309200, eval_loss: 2.75134e-02
I0216 03:21:57.584394 23126066861888 run_lib.py:133] step: 309250, training_loss: 1.71252e-02
I0216 03:22:14.895255 23126066861888 run_lib.py:133] step: 309300, training_loss: 1.76119e-02
I0216 03:22:15.066692 23126066861888 run_lib.py:146] step: 309300, eval_loss: 2.82137e-02
I0216 03:22:32.487883 23126066861888 run_lib.py:133] step: 309350, training_loss: 1.81872e-02
I0216 03:22:50.033027 23126066861888 run_lib.py:133] step: 309400, training_loss: 1.81678e-02
I0216 03:22:50.204828 23126066861888 run_lib.py:146] step: 309400, eval_loss: 2.83102e-02
I0216 03:23:07.520804 23126066861888 run_lib.py:133] step: 309450, training_loss: 1.87862e-02
I0216 03:23:25.017903 23126066861888 run_lib.py:133] step: 309500, training_loss: 1.81090e-02
I0216 03:23:25.173973 23126066861888 run_lib.py:146] step: 309500, eval_loss: 2.80561e-02
I0216 03:23:42.544207 23126066861888 run_lib.py:133] step: 309550, training_loss: 1.77645e-02
I0216 03:23:59.896889 23126066861888 run_lib.py:133] step: 309600, training_loss: 1.88546e-02
I0216 03:24:00.050677 23126066861888 run_lib.py:146] step: 309600, eval_loss: 2.63513e-02
I0216 03:24:17.633917 23126066861888 run_lib.py:133] step: 309650, training_loss: 1.83567e-02
I0216 03:24:35.026499 23126066861888 run_lib.py:133] step: 309700, training_loss: 1.81504e-02
I0216 03:24:35.178270 23126066861888 run_lib.py:146] step: 309700, eval_loss: 2.74094e-02
I0216 03:24:52.640639 23126066861888 run_lib.py:133] step: 309750, training_loss: 1.79321e-02
I0216 03:25:10.125241 23126066861888 run_lib.py:133] step: 309800, training_loss: 1.85333e-02
I0216 03:25:10.280895 23126066861888 run_lib.py:146] step: 309800, eval_loss: 2.70032e-02
I0216 03:25:27.672657 23126066861888 run_lib.py:133] step: 309850, training_loss: 1.81467e-02
I0216 03:25:45.096978 23126066861888 run_lib.py:133] step: 309900, training_loss: 1.85781e-02
I0216 03:25:45.255947 23126066861888 run_lib.py:146] step: 309900, eval_loss: 2.80347e-02
I0216 03:26:02.702379 23126066861888 run_lib.py:133] step: 309950, training_loss: 1.81717e-02
I0216 03:26:20.002840 23126066861888 run_lib.py:133] step: 310000, training_loss: 1.86387e-02
I0216 03:26:20.711745 23126066861888 run_lib.py:146] step: 310000, eval_loss: 2.77392e-02
I0216 03:26:40.623672 23126066861888 run_lib.py:133] step: 310050, training_loss: 1.76226e-02
I0216 03:26:57.926393 23126066861888 run_lib.py:133] step: 310100, training_loss: 1.87570e-02
I0216 03:26:58.091595 23126066861888 run_lib.py:146] step: 310100, eval_loss: 2.80180e-02
I0216 03:27:15.441834 23126066861888 run_lib.py:133] step: 310150, training_loss: 1.89486e-02
I0216 03:27:33.033051 23126066861888 run_lib.py:133] step: 310200, training_loss: 1.90032e-02
I0216 03:27:33.183772 23126066861888 run_lib.py:146] step: 310200, eval_loss: 2.72080e-02
I0216 03:27:50.593139 23126066861888 run_lib.py:133] step: 310250, training_loss: 1.76419e-02
I0216 03:28:07.996910 23126066861888 run_lib.py:133] step: 310300, training_loss: 1.79062e-02
I0216 03:28:08.151894 23126066861888 run_lib.py:146] step: 310300, eval_loss: 2.77627e-02
I0216 03:28:25.504801 23126066861888 run_lib.py:133] step: 310350, training_loss: 1.82648e-02
I0216 03:28:42.828829 23126066861888 run_lib.py:133] step: 310400, training_loss: 1.82745e-02
I0216 03:28:43.002923 23126066861888 run_lib.py:146] step: 310400, eval_loss: 2.83108e-02
I0216 03:29:00.562741 23126066861888 run_lib.py:133] step: 310450, training_loss: 1.86032e-02
I0216 03:29:17.921692 23126066861888 run_lib.py:133] step: 310500, training_loss: 1.77166e-02
I0216 03:29:18.076197 23126066861888 run_lib.py:146] step: 310500, eval_loss: 2.72062e-02
I0216 03:29:35.585710 23126066861888 run_lib.py:133] step: 310550, training_loss: 1.93078e-02
I0216 03:29:52.918111 23126066861888 run_lib.py:133] step: 310600, training_loss: 1.74441e-02
I0216 03:29:53.072669 23126066861888 run_lib.py:146] step: 310600, eval_loss: 2.62746e-02
I0216 03:30:10.564275 23126066861888 run_lib.py:133] step: 310650, training_loss: 1.86571e-02
I0216 03:30:27.959782 23126066861888 run_lib.py:133] step: 310700, training_loss: 1.82504e-02
I0216 03:30:28.118092 23126066861888 run_lib.py:146] step: 310700, eval_loss: 2.75849e-02
I0216 03:30:45.483248 23126066861888 run_lib.py:133] step: 310750, training_loss: 1.86657e-02
I0216 03:31:03.051587 23126066861888 run_lib.py:133] step: 310800, training_loss: 1.78695e-02
I0216 03:31:03.207937 23126066861888 run_lib.py:146] step: 310800, eval_loss: 2.73084e-02
I0216 03:31:20.521842 23126066861888 run_lib.py:133] step: 310850, training_loss: 1.81687e-02
I0216 03:31:38.003766 23126066861888 run_lib.py:133] step: 310900, training_loss: 1.83490e-02
I0216 03:31:38.161901 23126066861888 run_lib.py:146] step: 310900, eval_loss: 2.80018e-02
I0216 03:31:55.582800 23126066861888 run_lib.py:133] step: 310950, training_loss: 1.77041e-02
I0216 03:32:12.985117 23126066861888 run_lib.py:133] step: 311000, training_loss: 1.84601e-02
I0216 03:32:13.140137 23126066861888 run_lib.py:146] step: 311000, eval_loss: 2.77038e-02
I0216 03:32:30.501009 23126066861888 run_lib.py:133] step: 311050, training_loss: 1.87472e-02
I0216 03:32:48.001940 23126066861888 run_lib.py:133] step: 311100, training_loss: 1.79748e-02
I0216 03:32:48.155825 23126066861888 run_lib.py:146] step: 311100, eval_loss: 2.70021e-02
I0216 03:33:05.506704 23126066861888 run_lib.py:133] step: 311150, training_loss: 1.82029e-02
I0216 03:33:22.809488 23126066861888 run_lib.py:133] step: 311200, training_loss: 1.87252e-02
I0216 03:33:22.963829 23126066861888 run_lib.py:146] step: 311200, eval_loss: 2.83141e-02
I0216 03:33:40.537508 23126066861888 run_lib.py:133] step: 311250, training_loss: 1.81404e-02
I0216 03:33:57.947010 23126066861888 run_lib.py:133] step: 311300, training_loss: 1.87852e-02
I0216 03:33:58.104007 23126066861888 run_lib.py:146] step: 311300, eval_loss: 2.82970e-02
I0216 03:34:15.547101 23126066861888 run_lib.py:133] step: 311350, training_loss: 1.77737e-02
I0216 03:34:32.879685 23126066861888 run_lib.py:133] step: 311400, training_loss: 1.88395e-02
I0216 03:34:33.034049 23126066861888 run_lib.py:146] step: 311400, eval_loss: 2.68956e-02
I0216 03:34:50.352628 23126066861888 run_lib.py:133] step: 311450, training_loss: 1.80326e-02
I0216 03:35:07.754664 23126066861888 run_lib.py:133] step: 311500, training_loss: 1.88155e-02
I0216 03:35:07.911199 23126066861888 run_lib.py:146] step: 311500, eval_loss: 2.84905e-02
I0216 03:35:25.441448 23126066861888 run_lib.py:133] step: 311550, training_loss: 1.82394e-02
I0216 03:35:42.970746 23126066861888 run_lib.py:133] step: 311600, training_loss: 1.87362e-02
I0216 03:35:43.122658 23126066861888 run_lib.py:146] step: 311600, eval_loss: 2.79463e-02
I0216 03:36:00.449846 23126066861888 run_lib.py:133] step: 311650, training_loss: 1.84216e-02
I0216 03:36:17.812057 23126066861888 run_lib.py:133] step: 311700, training_loss: 1.83138e-02
I0216 03:36:17.970907 23126066861888 run_lib.py:146] step: 311700, eval_loss: 2.75443e-02
I0216 03:36:35.429305 23126066861888 run_lib.py:133] step: 311750, training_loss: 1.73555e-02
I0216 03:36:52.789397 23126066861888 run_lib.py:133] step: 311800, training_loss: 1.78912e-02
I0216 03:36:52.964039 23126066861888 run_lib.py:146] step: 311800, eval_loss: 2.79587e-02
I0216 03:37:10.312606 23126066861888 run_lib.py:133] step: 311850, training_loss: 1.82872e-02
I0216 03:37:27.869895 23126066861888 run_lib.py:133] step: 311900, training_loss: 1.88024e-02
I0216 03:37:28.026142 23126066861888 run_lib.py:146] step: 311900, eval_loss: 2.78031e-02
I0216 03:37:45.351055 23126066861888 run_lib.py:133] step: 311950, training_loss: 1.89538e-02
I0216 03:38:02.789703 23126066861888 run_lib.py:133] step: 312000, training_loss: 1.81741e-02
I0216 03:38:02.944117 23126066861888 run_lib.py:146] step: 312000, eval_loss: 2.73383e-02
I0216 03:38:20.267817 23126066861888 run_lib.py:133] step: 312050, training_loss: 1.80281e-02
I0216 03:38:37.629431 23126066861888 run_lib.py:133] step: 312100, training_loss: 1.81991e-02
I0216 03:38:37.781682 23126066861888 run_lib.py:146] step: 312100, eval_loss: 2.73119e-02
I0216 03:38:55.342175 23126066861888 run_lib.py:133] step: 312150, training_loss: 1.81307e-02
I0216 03:39:12.699594 23126066861888 run_lib.py:133] step: 312200, training_loss: 1.91909e-02
I0216 03:39:12.856740 23126066861888 run_lib.py:146] step: 312200, eval_loss: 2.75836e-02
I0216 03:39:30.171763 23126066861888 run_lib.py:133] step: 312250, training_loss: 1.76344e-02
I0216 03:39:47.525663 23126066861888 run_lib.py:133] step: 312300, training_loss: 1.78834e-02
I0216 03:39:47.684152 23126066861888 run_lib.py:146] step: 312300, eval_loss: 2.66248e-02
I0216 03:40:05.200807 23126066861888 run_lib.py:133] step: 312350, training_loss: 1.84144e-02
I0216 03:40:22.621172 23126066861888 run_lib.py:133] step: 312400, training_loss: 1.79459e-02
I0216 03:40:22.780192 23126066861888 run_lib.py:146] step: 312400, eval_loss: 2.78325e-02
I0216 03:40:40.185544 23126066861888 run_lib.py:133] step: 312450, training_loss: 1.79844e-02
I0216 03:40:57.519403 23126066861888 run_lib.py:133] step: 312500, training_loss: 1.79093e-02
I0216 03:40:57.674825 23126066861888 run_lib.py:146] step: 312500, eval_loss: 2.78449e-02
I0216 03:41:14.992858 23126066861888 run_lib.py:133] step: 312550, training_loss: 1.84604e-02
I0216 03:41:32.359525 23126066861888 run_lib.py:133] step: 312600, training_loss: 1.84970e-02
I0216 03:41:32.511928 23126066861888 run_lib.py:146] step: 312600, eval_loss: 2.77432e-02
I0216 03:41:50.002467 23126066861888 run_lib.py:133] step: 312650, training_loss: 1.82205e-02
I0216 03:42:07.499292 23126066861888 run_lib.py:133] step: 312700, training_loss: 1.80804e-02
I0216 03:42:07.661267 23126066861888 run_lib.py:146] step: 312700, eval_loss: 2.71228e-02
I0216 03:42:25.042602 23126066861888 run_lib.py:133] step: 312750, training_loss: 1.73970e-02
I0216 03:42:42.348641 23126066861888 run_lib.py:133] step: 312800, training_loss: 1.80918e-02
I0216 03:42:42.505109 23126066861888 run_lib.py:146] step: 312800, eval_loss: 2.73098e-02
I0216 03:42:59.998356 23126066861888 run_lib.py:133] step: 312850, training_loss: 1.82906e-02
I0216 03:43:17.405118 23126066861888 run_lib.py:133] step: 312900, training_loss: 1.87031e-02
I0216 03:43:17.568131 23126066861888 run_lib.py:146] step: 312900, eval_loss: 2.74576e-02
I0216 03:43:35.006504 23126066861888 run_lib.py:133] step: 312950, training_loss: 1.84669e-02
I0216 03:43:52.627855 23126066861888 run_lib.py:133] step: 313000, training_loss: 1.85088e-02
I0216 03:43:52.782117 23126066861888 run_lib.py:146] step: 313000, eval_loss: 2.68780e-02
I0216 03:44:10.190380 23126066861888 run_lib.py:133] step: 313050, training_loss: 1.86387e-02
I0216 03:44:27.716343 23126066861888 run_lib.py:133] step: 313100, training_loss: 1.82335e-02
I0216 03:44:27.868878 23126066861888 run_lib.py:146] step: 313100, eval_loss: 2.74307e-02
I0216 03:44:45.163479 23126066861888 run_lib.py:133] step: 313150, training_loss: 1.84986e-02
I0216 03:45:02.535848 23126066861888 run_lib.py:133] step: 313200, training_loss: 1.87495e-02
I0216 03:45:02.710972 23126066861888 run_lib.py:146] step: 313200, eval_loss: 2.82247e-02
I0216 03:45:20.297186 23126066861888 run_lib.py:133] step: 313250, training_loss: 1.75510e-02
I0216 03:45:37.668367 23126066861888 run_lib.py:133] step: 313300, training_loss: 1.84527e-02
I0216 03:45:37.824064 23126066861888 run_lib.py:146] step: 313300, eval_loss: 2.75110e-02
I0216 03:45:55.175737 23126066861888 run_lib.py:133] step: 313350, training_loss: 1.87515e-02
I0216 03:46:12.637793 23126066861888 run_lib.py:133] step: 313400, training_loss: 1.75690e-02
I0216 03:46:12.792768 23126066861888 run_lib.py:146] step: 313400, eval_loss: 2.73544e-02
I0216 03:46:30.157254 23126066861888 run_lib.py:133] step: 313450, training_loss: 1.84638e-02
I0216 03:46:47.549696 23126066861888 run_lib.py:133] step: 313500, training_loss: 1.84624e-02
I0216 03:46:47.704169 23126066861888 run_lib.py:146] step: 313500, eval_loss: 2.65318e-02
I0216 03:47:05.176236 23126066861888 run_lib.py:133] step: 313550, training_loss: 1.85937e-02
I0216 03:47:22.533890 23126066861888 run_lib.py:133] step: 313600, training_loss: 1.81444e-02
I0216 03:47:22.686818 23126066861888 run_lib.py:146] step: 313600, eval_loss: 2.79161e-02
I0216 03:47:40.011448 23126066861888 run_lib.py:133] step: 313650, training_loss: 1.90809e-02
I0216 03:47:57.378818 23126066861888 run_lib.py:133] step: 313700, training_loss: 1.80742e-02
I0216 03:47:57.535129 23126066861888 run_lib.py:146] step: 313700, eval_loss: 2.72057e-02
I0216 03:48:15.060820 23126066861888 run_lib.py:133] step: 313750, training_loss: 1.82270e-02
I0216 03:48:32.544661 23126066861888 run_lib.py:133] step: 313800, training_loss: 1.82496e-02
I0216 03:48:32.700198 23126066861888 run_lib.py:146] step: 313800, eval_loss: 2.93174e-02
I0216 03:48:50.090560 23126066861888 run_lib.py:133] step: 313850, training_loss: 1.84510e-02
I0216 03:49:07.415578 23126066861888 run_lib.py:133] step: 313900, training_loss: 1.80072e-02
I0216 03:49:07.570024 23126066861888 run_lib.py:146] step: 313900, eval_loss: 2.76587e-02
I0216 03:49:25.047836 23126066861888 run_lib.py:133] step: 313950, training_loss: 1.85062e-02
I0216 03:49:42.418549 23126066861888 run_lib.py:133] step: 314000, training_loss: 1.81091e-02
I0216 03:49:42.567619 23126066861888 run_lib.py:146] step: 314000, eval_loss: 2.77161e-02
I0216 03:49:59.909382 23126066861888 run_lib.py:133] step: 314050, training_loss: 1.82307e-02
I0216 03:50:17.465243 23126066861888 run_lib.py:133] step: 314100, training_loss: 1.77749e-02
I0216 03:50:17.635242 23126066861888 run_lib.py:146] step: 314100, eval_loss: 2.80898e-02
I0216 03:50:35.059342 23126066861888 run_lib.py:133] step: 314150, training_loss: 1.79632e-02
I0216 03:50:52.688499 23126066861888 run_lib.py:133] step: 314200, training_loss: 1.77550e-02
I0216 03:50:52.849222 23126066861888 run_lib.py:146] step: 314200, eval_loss: 2.72754e-02
I0216 03:51:10.217381 23126066861888 run_lib.py:133] step: 314250, training_loss: 1.83676e-02
I0216 03:51:27.615875 23126066861888 run_lib.py:133] step: 314300, training_loss: 1.81642e-02
I0216 03:51:27.771934 23126066861888 run_lib.py:146] step: 314300, eval_loss: 2.84692e-02
I0216 03:51:45.342111 23126066861888 run_lib.py:133] step: 314350, training_loss: 1.81992e-02
I0216 03:52:02.774803 23126066861888 run_lib.py:133] step: 314400, training_loss: 1.80317e-02
I0216 03:52:02.929086 23126066861888 run_lib.py:146] step: 314400, eval_loss: 2.61792e-02
I0216 03:52:20.347404 23126066861888 run_lib.py:133] step: 314450, training_loss: 1.88435e-02
I0216 03:52:37.885146 23126066861888 run_lib.py:133] step: 314500, training_loss: 1.84580e-02
I0216 03:52:38.039019 23126066861888 run_lib.py:146] step: 314500, eval_loss: 2.74341e-02
I0216 03:52:55.410030 23126066861888 run_lib.py:133] step: 314550, training_loss: 1.84252e-02
I0216 03:53:12.803235 23126066861888 run_lib.py:133] step: 314600, training_loss: 1.86475e-02
I0216 03:53:12.967693 23126066861888 run_lib.py:146] step: 314600, eval_loss: 2.83485e-02
I0216 03:53:30.486849 23126066861888 run_lib.py:133] step: 314650, training_loss: 1.82701e-02
I0216 03:53:47.886499 23126066861888 run_lib.py:133] step: 314700, training_loss: 1.85467e-02
I0216 03:53:48.043934 23126066861888 run_lib.py:146] step: 314700, eval_loss: 2.70229e-02
I0216 03:54:05.367523 23126066861888 run_lib.py:133] step: 314750, training_loss: 1.83641e-02
I0216 03:54:22.729420 23126066861888 run_lib.py:133] step: 314800, training_loss: 1.91156e-02
I0216 03:54:22.893488 23126066861888 run_lib.py:146] step: 314800, eval_loss: 2.65731e-02
I0216 03:54:40.414424 23126066861888 run_lib.py:133] step: 314850, training_loss: 1.86549e-02
I0216 03:54:57.837575 23126066861888 run_lib.py:133] step: 314900, training_loss: 1.81014e-02
I0216 03:54:57.993147 23126066861888 run_lib.py:146] step: 314900, eval_loss: 2.75942e-02
I0216 03:55:15.318824 23126066861888 run_lib.py:133] step: 314950, training_loss: 1.84349e-02
I0216 03:55:32.691008 23126066861888 run_lib.py:133] step: 315000, training_loss: 1.76294e-02
I0216 03:55:32.843857 23126066861888 run_lib.py:146] step: 315000, eval_loss: 2.67214e-02
I0216 03:55:50.354969 23126066861888 run_lib.py:133] step: 315050, training_loss: 1.87035e-02
I0216 03:56:07.656773 23126066861888 run_lib.py:133] step: 315100, training_loss: 1.88084e-02
I0216 03:56:07.813649 23126066861888 run_lib.py:146] step: 315100, eval_loss: 2.76838e-02
I0216 03:56:25.078795 23126066861888 run_lib.py:133] step: 315150, training_loss: 1.78099e-02
I0216 03:56:42.571846 23126066861888 run_lib.py:133] step: 315200, training_loss: 1.84153e-02
I0216 03:56:42.737945 23126066861888 run_lib.py:146] step: 315200, eval_loss: 2.75176e-02
I0216 03:57:00.099067 23126066861888 run_lib.py:133] step: 315250, training_loss: 1.81623e-02
I0216 03:57:17.652921 23126066861888 run_lib.py:133] step: 315300, training_loss: 1.80752e-02
I0216 03:57:17.826144 23126066861888 run_lib.py:146] step: 315300, eval_loss: 2.68929e-02
I0216 03:57:35.152769 23126066861888 run_lib.py:133] step: 315350, training_loss: 1.86104e-02
I0216 03:57:52.450047 23126066861888 run_lib.py:133] step: 315400, training_loss: 1.77514e-02
I0216 03:57:52.601622 23126066861888 run_lib.py:146] step: 315400, eval_loss: 2.89422e-02
I0216 03:58:10.042093 23126066861888 run_lib.py:133] step: 315450, training_loss: 1.87132e-02
I0216 03:58:27.387548 23126066861888 run_lib.py:133] step: 315500, training_loss: 1.79114e-02
I0216 03:58:27.547113 23126066861888 run_lib.py:146] step: 315500, eval_loss: 2.89999e-02
I0216 03:58:44.927804 23126066861888 run_lib.py:133] step: 315550, training_loss: 1.86378e-02
I0216 03:59:02.491182 23126066861888 run_lib.py:133] step: 315600, training_loss: 1.83652e-02
I0216 03:59:02.648894 23126066861888 run_lib.py:146] step: 315600, eval_loss: 2.69451e-02
I0216 03:59:20.026248 23126066861888 run_lib.py:133] step: 315650, training_loss: 1.83383e-02
I0216 03:59:37.379709 23126066861888 run_lib.py:133] step: 315700, training_loss: 1.78737e-02
I0216 03:59:37.554818 23126066861888 run_lib.py:146] step: 315700, eval_loss: 2.79647e-02
I0216 03:59:54.994294 23126066861888 run_lib.py:133] step: 315750, training_loss: 1.77113e-02
I0216 04:00:12.416125 23126066861888 run_lib.py:133] step: 315800, training_loss: 1.82865e-02
I0216 04:00:12.580238 23126066861888 run_lib.py:146] step: 315800, eval_loss: 2.71813e-02
I0216 04:00:29.926930 23126066861888 run_lib.py:133] step: 315850, training_loss: 1.81439e-02
I0216 04:00:47.238323 23126066861888 run_lib.py:133] step: 315900, training_loss: 1.79101e-02
I0216 04:00:47.390971 23126066861888 run_lib.py:146] step: 315900, eval_loss: 2.74654e-02
I0216 04:01:04.945202 23126066861888 run_lib.py:133] step: 315950, training_loss: 1.78637e-02
I0216 04:01:22.325236 23126066861888 run_lib.py:133] step: 316000, training_loss: 1.77448e-02
I0216 04:01:22.480796 23126066861888 run_lib.py:146] step: 316000, eval_loss: 2.63336e-02
I0216 04:01:39.800036 23126066861888 run_lib.py:133] step: 316050, training_loss: 1.86141e-02
I0216 04:01:57.197582 23126066861888 run_lib.py:133] step: 316100, training_loss: 1.81761e-02
I0216 04:01:57.360621 23126066861888 run_lib.py:146] step: 316100, eval_loss: 2.74796e-02
I0216 04:02:14.975123 23126066861888 run_lib.py:133] step: 316150, training_loss: 1.86215e-02
I0216 04:02:32.349522 23126066861888 run_lib.py:133] step: 316200, training_loss: 1.83647e-02
I0216 04:02:32.506315 23126066861888 run_lib.py:146] step: 316200, eval_loss: 2.83322e-02
I0216 04:02:49.867933 23126066861888 run_lib.py:133] step: 316250, training_loss: 1.83079e-02
I0216 04:03:07.320947 23126066861888 run_lib.py:133] step: 316300, training_loss: 1.82433e-02
I0216 04:03:07.473892 23126066861888 run_lib.py:146] step: 316300, eval_loss: 2.72217e-02
I0216 04:03:24.817258 23126066861888 run_lib.py:133] step: 316350, training_loss: 1.81011e-02
I0216 04:03:42.404568 23126066861888 run_lib.py:133] step: 316400, training_loss: 1.93214e-02
I0216 04:03:42.565156 23126066861888 run_lib.py:146] step: 316400, eval_loss: 2.68037e-02
I0216 04:03:59.915914 23126066861888 run_lib.py:133] step: 316450, training_loss: 1.76570e-02
I0216 04:04:17.256619 23126066861888 run_lib.py:133] step: 316500, training_loss: 1.80825e-02
I0216 04:04:17.409996 23126066861888 run_lib.py:146] step: 316500, eval_loss: 2.78417e-02
I0216 04:04:34.949215 23126066861888 run_lib.py:133] step: 316550, training_loss: 1.89984e-02
I0216 04:04:52.321537 23126066861888 run_lib.py:133] step: 316600, training_loss: 1.83319e-02
I0216 04:04:52.477136 23126066861888 run_lib.py:146] step: 316600, eval_loss: 2.81905e-02
I0216 04:05:09.835764 23126066861888 run_lib.py:133] step: 316650, training_loss: 1.77037e-02
I0216 04:05:27.396429 23126066861888 run_lib.py:133] step: 316700, training_loss: 1.82474e-02
I0216 04:05:27.553240 23126066861888 run_lib.py:146] step: 316700, eval_loss: 2.76264e-02
I0216 04:05:44.925003 23126066861888 run_lib.py:133] step: 316750, training_loss: 1.88914e-02
I0216 04:06:02.352562 23126066861888 run_lib.py:133] step: 316800, training_loss: 1.82230e-02
I0216 04:06:02.505909 23126066861888 run_lib.py:146] step: 316800, eval_loss: 2.86764e-02
I0216 04:06:19.927244 23126066861888 run_lib.py:133] step: 316850, training_loss: 1.68793e-02
I0216 04:06:37.277354 23126066861888 run_lib.py:133] step: 316900, training_loss: 1.82649e-02
I0216 04:06:37.432866 23126066861888 run_lib.py:146] step: 316900, eval_loss: 2.79022e-02
I0216 04:06:54.830283 23126066861888 run_lib.py:133] step: 316950, training_loss: 1.87333e-02
I0216 04:07:12.204475 23126066861888 run_lib.py:133] step: 317000, training_loss: 1.76159e-02
I0216 04:07:12.361952 23126066861888 run_lib.py:146] step: 317000, eval_loss: 2.76854e-02
I0216 04:07:29.927017 23126066861888 run_lib.py:133] step: 317050, training_loss: 1.77594e-02
I0216 04:07:47.349509 23126066861888 run_lib.py:133] step: 317100, training_loss: 1.83403e-02
I0216 04:07:47.505229 23126066861888 run_lib.py:146] step: 317100, eval_loss: 2.78714e-02
I0216 04:08:04.886125 23126066861888 run_lib.py:133] step: 317150, training_loss: 1.84182e-02
I0216 04:08:22.193772 23126066861888 run_lib.py:133] step: 317200, training_loss: 1.82077e-02
I0216 04:08:22.358575 23126066861888 run_lib.py:146] step: 317200, eval_loss: 2.77477e-02
I0216 04:08:39.927547 23126066861888 run_lib.py:133] step: 317250, training_loss: 1.88184e-02
I0216 04:08:57.304107 23126066861888 run_lib.py:133] step: 317300, training_loss: 1.90211e-02
I0216 04:08:57.470200 23126066861888 run_lib.py:146] step: 317300, eval_loss: 2.70497e-02
I0216 04:09:14.858078 23126066861888 run_lib.py:133] step: 317350, training_loss: 1.85980e-02
I0216 04:09:32.372724 23126066861888 run_lib.py:133] step: 317400, training_loss: 1.85098e-02
I0216 04:09:32.525940 23126066861888 run_lib.py:146] step: 317400, eval_loss: 2.65763e-02
I0216 04:09:49.875444 23126066861888 run_lib.py:133] step: 317450, training_loss: 1.80496e-02
I0216 04:10:07.361397 23126066861888 run_lib.py:133] step: 317500, training_loss: 1.83055e-02
I0216 04:10:07.538023 23126066861888 run_lib.py:146] step: 317500, eval_loss: 2.75470e-02
I0216 04:10:25.028219 23126066861888 run_lib.py:133] step: 317550, training_loss: 1.82586e-02
I0216 04:10:42.332321 23126066861888 run_lib.py:133] step: 317600, training_loss: 1.88504e-02
I0216 04:10:42.486799 23126066861888 run_lib.py:146] step: 317600, eval_loss: 2.66867e-02
I0216 04:10:59.966061 23126066861888 run_lib.py:133] step: 317650, training_loss: 1.75672e-02
I0216 04:11:17.285710 23126066861888 run_lib.py:133] step: 317700, training_loss: 1.84055e-02
I0216 04:11:17.441738 23126066861888 run_lib.py:146] step: 317700, eval_loss: 2.56234e-02
I0216 04:11:34.852130 23126066861888 run_lib.py:133] step: 317750, training_loss: 1.81288e-02
I0216 04:11:52.454920 23126066861888 run_lib.py:133] step: 317800, training_loss: 1.77080e-02
I0216 04:11:52.609820 23126066861888 run_lib.py:146] step: 317800, eval_loss: 2.88725e-02
I0216 04:12:10.042538 23126066861888 run_lib.py:133] step: 317850, training_loss: 1.80594e-02
I0216 04:12:27.426065 23126066861888 run_lib.py:133] step: 317900, training_loss: 1.88679e-02
I0216 04:12:27.581964 23126066861888 run_lib.py:146] step: 317900, eval_loss: 2.81007e-02
I0216 04:12:45.075584 23126066861888 run_lib.py:133] step: 317950, training_loss: 1.83590e-02
I0216 04:13:02.438040 23126066861888 run_lib.py:133] step: 318000, training_loss: 1.83156e-02
I0216 04:13:02.603284 23126066861888 run_lib.py:146] step: 318000, eval_loss: 2.79221e-02
I0216 04:13:20.034013 23126066861888 run_lib.py:133] step: 318050, training_loss: 1.83574e-02
I0216 04:13:37.480337 23126066861888 run_lib.py:133] step: 318100, training_loss: 1.84827e-02
I0216 04:13:37.637878 23126066861888 run_lib.py:146] step: 318100, eval_loss: 2.87181e-02
I0216 04:13:55.239486 23126066861888 run_lib.py:133] step: 318150, training_loss: 1.78180e-02
I0216 04:14:12.714596 23126066861888 run_lib.py:133] step: 318200, training_loss: 1.86367e-02
I0216 04:14:12.870702 23126066861888 run_lib.py:146] step: 318200, eval_loss: 2.84919e-02
I0216 04:14:30.330812 23126066861888 run_lib.py:133] step: 318250, training_loss: 1.76267e-02
I0216 04:14:47.710420 23126066861888 run_lib.py:133] step: 318300, training_loss: 1.81428e-02
I0216 04:14:47.862960 23126066861888 run_lib.py:146] step: 318300, eval_loss: 2.84293e-02
I0216 04:15:05.458807 23126066861888 run_lib.py:133] step: 318350, training_loss: 1.85144e-02
I0216 04:15:22.849899 23126066861888 run_lib.py:133] step: 318400, training_loss: 1.84477e-02
I0216 04:15:23.005124 23126066861888 run_lib.py:146] step: 318400, eval_loss: 2.74819e-02
I0216 04:15:40.338936 23126066861888 run_lib.py:133] step: 318450, training_loss: 1.80657e-02
I0216 04:15:57.887613 23126066861888 run_lib.py:133] step: 318500, training_loss: 1.85493e-02
I0216 04:15:58.045205 23126066861888 run_lib.py:146] step: 318500, eval_loss: 2.74087e-02
I0216 04:16:15.443028 23126066861888 run_lib.py:133] step: 318550, training_loss: 1.76228e-02
I0216 04:16:32.949683 23126066861888 run_lib.py:133] step: 318600, training_loss: 1.88459e-02
I0216 04:16:33.118929 23126066861888 run_lib.py:146] step: 318600, eval_loss: 2.75410e-02
I0216 04:16:50.530439 23126066861888 run_lib.py:133] step: 318650, training_loss: 1.83842e-02
I0216 04:17:07.939041 23126066861888 run_lib.py:133] step: 318700, training_loss: 1.81783e-02
I0216 04:17:08.093107 23126066861888 run_lib.py:146] step: 318700, eval_loss: 2.86056e-02
I0216 04:17:25.734485 23126066861888 run_lib.py:133] step: 318750, training_loss: 1.79603e-02
I0216 04:17:43.135820 23126066861888 run_lib.py:133] step: 318800, training_loss: 1.82083e-02
I0216 04:17:43.294983 23126066861888 run_lib.py:146] step: 318800, eval_loss: 2.67445e-02
I0216 04:18:00.664273 23126066861888 run_lib.py:133] step: 318850, training_loss: 1.84715e-02
I0216 04:18:18.184600 23126066861888 run_lib.py:133] step: 318900, training_loss: 1.78814e-02
I0216 04:18:18.374964 23126066861888 run_lib.py:146] step: 318900, eval_loss: 2.83286e-02
I0216 04:18:35.802896 23126066861888 run_lib.py:133] step: 318950, training_loss: 1.77802e-02
I0216 04:18:53.156244 23126066861888 run_lib.py:133] step: 319000, training_loss: 1.84388e-02
I0216 04:18:53.310873 23126066861888 run_lib.py:146] step: 319000, eval_loss: 2.74908e-02
I0216 04:19:10.720470 23126066861888 run_lib.py:133] step: 319050, training_loss: 1.83043e-02
I0216 04:19:28.047664 23126066861888 run_lib.py:133] step: 319100, training_loss: 1.83809e-02
I0216 04:19:28.210696 23126066861888 run_lib.py:146] step: 319100, eval_loss: 2.72690e-02
I0216 04:19:45.573492 23126066861888 run_lib.py:133] step: 319150, training_loss: 1.83028e-02
I0216 04:20:03.017557 23126066861888 run_lib.py:133] step: 319200, training_loss: 1.81788e-02
I0216 04:20:03.171068 23126066861888 run_lib.py:146] step: 319200, eval_loss: 2.67492e-02
I0216 04:20:20.709728 23126066861888 run_lib.py:133] step: 319250, training_loss: 1.77053e-02
I0216 04:20:38.153596 23126066861888 run_lib.py:133] step: 319300, training_loss: 1.79942e-02
I0216 04:20:38.308994 23126066861888 run_lib.py:146] step: 319300, eval_loss: 2.71276e-02
I0216 04:20:55.693058 23126066861888 run_lib.py:133] step: 319350, training_loss: 1.84023e-02
I0216 04:21:13.074174 23126066861888 run_lib.py:133] step: 319400, training_loss: 1.87035e-02
I0216 04:21:13.233282 23126066861888 run_lib.py:146] step: 319400, eval_loss: 2.64924e-02
I0216 04:21:30.789172 23126066861888 run_lib.py:133] step: 319450, training_loss: 1.79133e-02
I0216 04:21:48.199109 23126066861888 run_lib.py:133] step: 319500, training_loss: 1.78955e-02
I0216 04:21:48.356315 23126066861888 run_lib.py:146] step: 319500, eval_loss: 2.74759e-02
I0216 04:22:05.680009 23126066861888 run_lib.py:133] step: 319550, training_loss: 1.86338e-02
I0216 04:22:23.250076 23126066861888 run_lib.py:133] step: 319600, training_loss: 1.85005e-02
I0216 04:22:23.404872 23126066861888 run_lib.py:146] step: 319600, eval_loss: 2.73997e-02
I0216 04:22:40.805038 23126066861888 run_lib.py:133] step: 319650, training_loss: 1.80778e-02
I0216 04:22:58.324424 23126066861888 run_lib.py:133] step: 319700, training_loss: 1.80546e-02
I0216 04:22:58.477212 23126066861888 run_lib.py:146] step: 319700, eval_loss: 2.80934e-02
I0216 04:23:15.871242 23126066861888 run_lib.py:133] step: 319750, training_loss: 1.82001e-02
I0216 04:23:33.241402 23126066861888 run_lib.py:133] step: 319800, training_loss: 1.71155e-02
I0216 04:23:33.413998 23126066861888 run_lib.py:146] step: 319800, eval_loss: 2.73783e-02
I0216 04:23:51.030354 23126066861888 run_lib.py:133] step: 319850, training_loss: 1.83266e-02
I0216 04:24:08.401276 23126066861888 run_lib.py:133] step: 319900, training_loss: 1.82499e-02
I0216 04:24:08.559294 23126066861888 run_lib.py:146] step: 319900, eval_loss: 2.81711e-02
I0216 04:24:25.921539 23126066861888 run_lib.py:133] step: 319950, training_loss: 1.83627e-02
I0216 04:24:43.464209 23126066861888 run_lib.py:133] step: 320000, training_loss: 1.77374e-02
I0216 04:24:44.197857 23126066861888 run_lib.py:146] step: 320000, eval_loss: 2.66730e-02
I0216 04:25:04.201528 23126066861888 run_lib.py:133] step: 320050, training_loss: 1.89407e-02
I0216 04:25:21.640595 23126066861888 run_lib.py:133] step: 320100, training_loss: 1.80606e-02
I0216 04:25:21.797174 23126066861888 run_lib.py:146] step: 320100, eval_loss: 2.65288e-02
I0216 04:25:39.154105 23126066861888 run_lib.py:133] step: 320150, training_loss: 1.79061e-02
I0216 04:25:56.697851 23126066861888 run_lib.py:133] step: 320200, training_loss: 1.75691e-02
I0216 04:25:56.855923 23126066861888 run_lib.py:146] step: 320200, eval_loss: 2.60010e-02
I0216 04:26:14.186445 23126066861888 run_lib.py:133] step: 320250, training_loss: 1.85651e-02
I0216 04:26:31.556978 23126066861888 run_lib.py:133] step: 320300, training_loss: 1.89496e-02
I0216 04:26:31.719230 23126066861888 run_lib.py:146] step: 320300, eval_loss: 2.79875e-02
I0216 04:26:49.091836 23126066861888 run_lib.py:133] step: 320350, training_loss: 1.87069e-02
I0216 04:27:06.639362 23126066861888 run_lib.py:133] step: 320400, training_loss: 1.87945e-02
I0216 04:27:06.797856 23126066861888 run_lib.py:146] step: 320400, eval_loss: 2.63809e-02
I0216 04:27:24.196309 23126066861888 run_lib.py:133] step: 320450, training_loss: 1.80123e-02
I0216 04:27:41.572955 23126066861888 run_lib.py:133] step: 320500, training_loss: 1.87893e-02
I0216 04:27:41.732786 23126066861888 run_lib.py:146] step: 320500, eval_loss: 2.89610e-02
I0216 04:27:59.067565 23126066861888 run_lib.py:133] step: 320550, training_loss: 1.80445e-02
I0216 04:28:16.396717 23126066861888 run_lib.py:133] step: 320600, training_loss: 1.74238e-02
I0216 04:28:16.552777 23126066861888 run_lib.py:146] step: 320600, eval_loss: 2.64730e-02
I0216 04:28:34.104084 23126066861888 run_lib.py:133] step: 320650, training_loss: 1.77981e-02
I0216 04:28:51.478308 23126066861888 run_lib.py:133] step: 320700, training_loss: 1.78470e-02
I0216 04:28:51.636764 23126066861888 run_lib.py:146] step: 320700, eval_loss: 2.71831e-02
I0216 04:29:09.150022 23126066861888 run_lib.py:133] step: 320750, training_loss: 1.75609e-02
I0216 04:29:26.452435 23126066861888 run_lib.py:133] step: 320800, training_loss: 1.86101e-02
I0216 04:29:26.604873 23126066861888 run_lib.py:146] step: 320800, eval_loss: 2.76841e-02
I0216 04:29:44.003743 23126066861888 run_lib.py:133] step: 320850, training_loss: 1.79385e-02
I0216 04:30:01.386878 23126066861888 run_lib.py:133] step: 320900, training_loss: 1.80595e-02
I0216 04:30:01.563400 23126066861888 run_lib.py:146] step: 320900, eval_loss: 2.79914e-02
I0216 04:30:19.058119 23126066861888 run_lib.py:133] step: 320950, training_loss: 1.84750e-02
I0216 04:30:36.697129 23126066861888 run_lib.py:133] step: 321000, training_loss: 1.85728e-02
I0216 04:30:36.853441 23126066861888 run_lib.py:146] step: 321000, eval_loss: 2.78810e-02
I0216 04:30:54.235611 23126066861888 run_lib.py:133] step: 321050, training_loss: 1.79685e-02
I0216 04:31:11.696395 23126066861888 run_lib.py:133] step: 321100, training_loss: 1.83020e-02
I0216 04:31:11.850902 23126066861888 run_lib.py:146] step: 321100, eval_loss: 2.74185e-02
I0216 04:31:29.180453 23126066861888 run_lib.py:133] step: 321150, training_loss: 1.78285e-02
I0216 04:31:46.554748 23126066861888 run_lib.py:133] step: 321200, training_loss: 1.72957e-02
I0216 04:31:46.731261 23126066861888 run_lib.py:146] step: 321200, eval_loss: 2.65979e-02
I0216 04:32:04.123876 23126066861888 run_lib.py:133] step: 321250, training_loss: 1.80605e-02
I0216 04:32:21.721525 23126066861888 run_lib.py:133] step: 321300, training_loss: 1.83684e-02
I0216 04:32:21.875842 23126066861888 run_lib.py:146] step: 321300, eval_loss: 2.74286e-02
I0216 04:32:39.237243 23126066861888 run_lib.py:133] step: 321350, training_loss: 1.84195e-02
I0216 04:32:56.552491 23126066861888 run_lib.py:133] step: 321400, training_loss: 1.85915e-02
I0216 04:32:56.710423 23126066861888 run_lib.py:146] step: 321400, eval_loss: 2.86736e-02
I0216 04:33:14.273870 23126066861888 run_lib.py:133] step: 321450, training_loss: 1.82317e-02
I0216 04:33:31.598607 23126066861888 run_lib.py:133] step: 321500, training_loss: 1.80299e-02
I0216 04:33:31.755017 23126066861888 run_lib.py:146] step: 321500, eval_loss: 2.77431e-02
I0216 04:33:49.193033 23126066861888 run_lib.py:133] step: 321550, training_loss: 1.85833e-02
I0216 04:34:06.471551 23126066861888 run_lib.py:133] step: 321600, training_loss: 1.79113e-02
I0216 04:34:06.624758 23126066861888 run_lib.py:146] step: 321600, eval_loss: 2.72962e-02
I0216 04:34:23.960599 23126066861888 run_lib.py:133] step: 321650, training_loss: 1.82616e-02
I0216 04:34:41.302663 23126066861888 run_lib.py:133] step: 321700, training_loss: 1.85240e-02
I0216 04:34:41.457269 23126066861888 run_lib.py:146] step: 321700, eval_loss: 2.69581e-02
I0216 04:34:58.966615 23126066861888 run_lib.py:133] step: 321750, training_loss: 1.87971e-02
I0216 04:35:16.404258 23126066861888 run_lib.py:133] step: 321800, training_loss: 1.89404e-02
I0216 04:35:16.557744 23126066861888 run_lib.py:146] step: 321800, eval_loss: 2.86650e-02
I0216 04:35:33.863068 23126066861888 run_lib.py:133] step: 321850, training_loss: 1.83460e-02
I0216 04:35:51.161085 23126066861888 run_lib.py:133] step: 321900, training_loss: 1.84198e-02
I0216 04:35:51.322252 23126066861888 run_lib.py:146] step: 321900, eval_loss: 2.76849e-02
I0216 04:36:08.782253 23126066861888 run_lib.py:133] step: 321950, training_loss: 1.79366e-02
I0216 04:36:26.061442 23126066861888 run_lib.py:133] step: 322000, training_loss: 1.86604e-02
I0216 04:36:26.218970 23126066861888 run_lib.py:146] step: 322000, eval_loss: 2.71254e-02
I0216 04:36:43.611411 23126066861888 run_lib.py:133] step: 322050, training_loss: 1.82308e-02
I0216 04:37:01.134163 23126066861888 run_lib.py:133] step: 322100, training_loss: 1.81627e-02
I0216 04:37:01.303258 23126066861888 run_lib.py:146] step: 322100, eval_loss: 2.79164e-02
I0216 04:37:18.616853 23126066861888 run_lib.py:133] step: 322150, training_loss: 1.77781e-02
I0216 04:37:36.101986 23126066861888 run_lib.py:133] step: 322200, training_loss: 1.78934e-02
I0216 04:37:36.254916 23126066861888 run_lib.py:146] step: 322200, eval_loss: 2.81933e-02
I0216 04:37:53.573513 23126066861888 run_lib.py:133] step: 322250, training_loss: 1.81468e-02
I0216 04:38:10.855968 23126066861888 run_lib.py:133] step: 322300, training_loss: 1.85182e-02
I0216 04:38:11.025869 23126066861888 run_lib.py:146] step: 322300, eval_loss: 2.73382e-02
I0216 04:38:28.543832 23126066861888 run_lib.py:133] step: 322350, training_loss: 1.81751e-02
I0216 04:38:45.844642 23126066861888 run_lib.py:133] step: 322400, training_loss: 1.79629e-02
I0216 04:38:45.999005 23126066861888 run_lib.py:146] step: 322400, eval_loss: 2.79526e-02
I0216 04:39:03.207939 23126066861888 run_lib.py:133] step: 322450, training_loss: 1.79537e-02
I0216 04:39:20.506358 23126066861888 run_lib.py:133] step: 322500, training_loss: 1.84429e-02
I0216 04:39:20.662823 23126066861888 run_lib.py:146] step: 322500, eval_loss: 2.73349e-02
I0216 04:39:38.228322 23126066861888 run_lib.py:133] step: 322550, training_loss: 1.81807e-02
I0216 04:39:55.594042 23126066861888 run_lib.py:133] step: 322600, training_loss: 1.83243e-02
I0216 04:39:55.740996 23126066861888 run_lib.py:146] step: 322600, eval_loss: 2.69964e-02
I0216 04:40:13.260723 23126066861888 run_lib.py:133] step: 322650, training_loss: 1.87358e-02
I0216 04:40:30.553246 23126066861888 run_lib.py:133] step: 322700, training_loss: 1.82623e-02
I0216 04:40:30.705775 23126066861888 run_lib.py:146] step: 322700, eval_loss: 2.80811e-02
I0216 04:40:47.957903 23126066861888 run_lib.py:133] step: 322750, training_loss: 1.85792e-02
I0216 04:41:05.263454 23126066861888 run_lib.py:133] step: 322800, training_loss: 1.78595e-02
I0216 04:41:05.419189 23126066861888 run_lib.py:146] step: 322800, eval_loss: 2.78046e-02
I0216 04:41:22.926771 23126066861888 run_lib.py:133] step: 322850, training_loss: 1.81182e-02
I0216 04:41:40.286211 23126066861888 run_lib.py:133] step: 322900, training_loss: 1.88160e-02
I0216 04:41:40.451977 23126066861888 run_lib.py:146] step: 322900, eval_loss: 2.87545e-02
I0216 04:41:57.774399 23126066861888 run_lib.py:133] step: 322950, training_loss: 1.78653e-02
I0216 04:42:15.116006 23126066861888 run_lib.py:133] step: 323000, training_loss: 1.80170e-02
I0216 04:42:15.272142 23126066861888 run_lib.py:146] step: 323000, eval_loss: 2.88335e-02
I0216 04:42:32.817797 23126066861888 run_lib.py:133] step: 323050, training_loss: 1.84175e-02
I0216 04:42:50.122670 23126066861888 run_lib.py:133] step: 323100, training_loss: 1.86674e-02
I0216 04:42:50.274974 23126066861888 run_lib.py:146] step: 323100, eval_loss: 2.83903e-02
I0216 04:43:07.561796 23126066861888 run_lib.py:133] step: 323150, training_loss: 1.84687e-02
I0216 04:43:25.080268 23126066861888 run_lib.py:133] step: 323200, training_loss: 1.90459e-02
I0216 04:43:25.245076 23126066861888 run_lib.py:146] step: 323200, eval_loss: 2.80479e-02
I0216 04:43:42.568800 23126066861888 run_lib.py:133] step: 323250, training_loss: 1.80208e-02
I0216 04:44:00.091900 23126066861888 run_lib.py:133] step: 323300, training_loss: 1.83694e-02
I0216 04:44:00.249108 23126066861888 run_lib.py:146] step: 323300, eval_loss: 2.67589e-02
I0216 04:44:17.560600 23126066861888 run_lib.py:133] step: 323350, training_loss: 1.86883e-02
I0216 04:44:34.843491 23126066861888 run_lib.py:133] step: 323400, training_loss: 1.92876e-02
I0216 04:44:35.000949 23126066861888 run_lib.py:146] step: 323400, eval_loss: 2.80144e-02
I0216 04:44:52.512078 23126066861888 run_lib.py:133] step: 323450, training_loss: 1.81176e-02
I0216 04:45:09.906197 23126066861888 run_lib.py:133] step: 323500, training_loss: 1.76959e-02
I0216 04:45:10.062241 23126066861888 run_lib.py:146] step: 323500, eval_loss: 2.77759e-02
I0216 04:45:27.395292 23126066861888 run_lib.py:133] step: 323550, training_loss: 1.83890e-02
I0216 04:45:44.848591 23126066861888 run_lib.py:133] step: 323600, training_loss: 1.76905e-02
I0216 04:45:45.006598 23126066861888 run_lib.py:146] step: 323600, eval_loss: 2.71722e-02
I0216 04:46:02.297906 23126066861888 run_lib.py:133] step: 323650, training_loss: 1.86248e-02
I0216 04:46:19.722212 23126066861888 run_lib.py:133] step: 323700, training_loss: 1.79326e-02
I0216 04:46:19.909051 23126066861888 run_lib.py:146] step: 323700, eval_loss: 2.79824e-02
I0216 04:46:37.417056 23126066861888 run_lib.py:133] step: 323750, training_loss: 1.77101e-02
I0216 04:46:54.790551 23126066861888 run_lib.py:133] step: 323800, training_loss: 1.80922e-02
I0216 04:46:54.943601 23126066861888 run_lib.py:146] step: 323800, eval_loss: 2.72944e-02
I0216 04:47:12.327542 23126066861888 run_lib.py:133] step: 323850, training_loss: 1.85815e-02
I0216 04:47:29.730178 23126066861888 run_lib.py:133] step: 323900, training_loss: 1.80521e-02
I0216 04:47:29.889185 23126066861888 run_lib.py:146] step: 323900, eval_loss: 2.68301e-02
I0216 04:47:47.497600 23126066861888 run_lib.py:133] step: 323950, training_loss: 1.82394e-02
I0216 04:48:04.975267 23126066861888 run_lib.py:133] step: 324000, training_loss: 1.83556e-02
I0216 04:48:05.131830 23126066861888 run_lib.py:146] step: 324000, eval_loss: 2.77984e-02
I0216 04:48:22.553383 23126066861888 run_lib.py:133] step: 324050, training_loss: 1.85865e-02
I0216 04:48:39.987715 23126066861888 run_lib.py:133] step: 324100, training_loss: 1.86331e-02
I0216 04:48:40.141292 23126066861888 run_lib.py:146] step: 324100, eval_loss: 2.81653e-02
I0216 04:48:57.744862 23126066861888 run_lib.py:133] step: 324150, training_loss: 1.75045e-02
I0216 04:49:15.087339 23126066861888 run_lib.py:133] step: 324200, training_loss: 1.85659e-02
I0216 04:49:15.244213 23126066861888 run_lib.py:146] step: 324200, eval_loss: 2.64137e-02
I0216 04:49:32.571604 23126066861888 run_lib.py:133] step: 324250, training_loss: 1.77129e-02
I0216 04:49:50.121637 23126066861888 run_lib.py:133] step: 324300, training_loss: 1.73049e-02
I0216 04:49:50.279313 23126066861888 run_lib.py:146] step: 324300, eval_loss: 2.78007e-02
I0216 04:50:07.572715 23126066861888 run_lib.py:133] step: 324350, training_loss: 1.86283e-02
I0216 04:50:25.092934 23126066861888 run_lib.py:133] step: 324400, training_loss: 1.79159e-02
I0216 04:50:25.246091 23126066861888 run_lib.py:146] step: 324400, eval_loss: 2.80311e-02
I0216 04:50:42.564475 23126066861888 run_lib.py:133] step: 324450, training_loss: 1.84915e-02
I0216 04:50:59.859935 23126066861888 run_lib.py:133] step: 324500, training_loss: 1.78208e-02
I0216 04:51:00.010722 23126066861888 run_lib.py:146] step: 324500, eval_loss: 2.85402e-02
I0216 04:51:17.514236 23126066861888 run_lib.py:133] step: 324550, training_loss: 1.82744e-02
I0216 04:51:34.880188 23126066861888 run_lib.py:133] step: 324600, training_loss: 1.74981e-02
I0216 04:51:35.044425 23126066861888 run_lib.py:146] step: 324600, eval_loss: 2.87316e-02
I0216 04:51:52.403583 23126066861888 run_lib.py:133] step: 324650, training_loss: 1.77651e-02
I0216 04:52:09.920633 23126066861888 run_lib.py:133] step: 324700, training_loss: 1.91744e-02
I0216 04:52:10.081244 23126066861888 run_lib.py:146] step: 324700, eval_loss: 2.72406e-02
I0216 04:52:27.401362 23126066861888 run_lib.py:133] step: 324750, training_loss: 1.80077e-02
I0216 04:52:44.702746 23126066861888 run_lib.py:133] step: 324800, training_loss: 1.81654e-02
I0216 04:52:44.856999 23126066861888 run_lib.py:146] step: 324800, eval_loss: 2.78826e-02
I0216 04:53:02.262951 23126066861888 run_lib.py:133] step: 324850, training_loss: 1.74347e-02
I0216 04:53:19.602146 23126066861888 run_lib.py:133] step: 324900, training_loss: 1.85064e-02
I0216 04:53:19.754978 23126066861888 run_lib.py:146] step: 324900, eval_loss: 2.79784e-02
I0216 04:53:37.125724 23126066861888 run_lib.py:133] step: 324950, training_loss: 1.78329e-02
I0216 04:53:54.449006 23126066861888 run_lib.py:133] step: 325000, training_loss: 1.78815e-02
I0216 04:53:54.601919 23126066861888 run_lib.py:146] step: 325000, eval_loss: 2.78501e-02
I0216 04:54:12.094650 23126066861888 run_lib.py:133] step: 325050, training_loss: 1.85521e-02
I0216 04:54:29.442593 23126066861888 run_lib.py:133] step: 325100, training_loss: 1.90942e-02
I0216 04:54:29.609344 23126066861888 run_lib.py:146] step: 325100, eval_loss: 2.95858e-02
I0216 04:54:47.002585 23126066861888 run_lib.py:133] step: 325150, training_loss: 1.85588e-02
I0216 04:55:04.401139 23126066861888 run_lib.py:133] step: 325200, training_loss: 1.82341e-02
I0216 04:55:04.558853 23126066861888 run_lib.py:146] step: 325200, eval_loss: 2.80868e-02
I0216 04:55:22.050966 23126066861888 run_lib.py:133] step: 325250, training_loss: 1.84899e-02
I0216 04:55:39.363094 23126066861888 run_lib.py:133] step: 325300, training_loss: 1.81109e-02
I0216 04:55:39.518920 23126066861888 run_lib.py:146] step: 325300, eval_loss: 2.74790e-02
I0216 04:55:56.844355 23126066861888 run_lib.py:133] step: 325350, training_loss: 1.82904e-02
I0216 04:56:14.291865 23126066861888 run_lib.py:133] step: 325400, training_loss: 1.77579e-02
I0216 04:56:14.442634 23126066861888 run_lib.py:146] step: 325400, eval_loss: 2.66319e-02
I0216 04:56:31.815340 23126066861888 run_lib.py:133] step: 325450, training_loss: 1.80408e-02
I0216 04:56:49.298996 23126066861888 run_lib.py:133] step: 325500, training_loss: 1.88070e-02
I0216 04:56:49.455171 23126066861888 run_lib.py:146] step: 325500, eval_loss: 2.76458e-02
I0216 04:57:06.810987 23126066861888 run_lib.py:133] step: 325550, training_loss: 1.78661e-02
I0216 04:57:24.111965 23126066861888 run_lib.py:133] step: 325600, training_loss: 1.82186e-02
I0216 04:57:24.287202 23126066861888 run_lib.py:146] step: 325600, eval_loss: 2.74121e-02
I0216 04:57:41.716679 23126066861888 run_lib.py:133] step: 325650, training_loss: 1.82654e-02
I0216 04:57:59.125947 23126066861888 run_lib.py:133] step: 325700, training_loss: 1.84296e-02
I0216 04:57:59.299011 23126066861888 run_lib.py:146] step: 325700, eval_loss: 2.71242e-02
I0216 04:58:16.725615 23126066861888 run_lib.py:133] step: 325750, training_loss: 1.78395e-02
I0216 04:58:34.288764 23126066861888 run_lib.py:133] step: 325800, training_loss: 1.85244e-02
I0216 04:58:34.443768 23126066861888 run_lib.py:146] step: 325800, eval_loss: 2.78756e-02
I0216 04:58:51.753271 23126066861888 run_lib.py:133] step: 325850, training_loss: 1.80949e-02
I0216 04:59:09.093575 23126066861888 run_lib.py:133] step: 325900, training_loss: 1.82432e-02
I0216 04:59:09.245867 23126066861888 run_lib.py:146] step: 325900, eval_loss: 2.81218e-02
I0216 04:59:26.606290 23126066861888 run_lib.py:133] step: 325950, training_loss: 1.75549e-02
I0216 04:59:44.005434 23126066861888 run_lib.py:133] step: 326000, training_loss: 1.71052e-02
I0216 04:59:44.163195 23126066861888 run_lib.py:146] step: 326000, eval_loss: 2.75960e-02
I0216 05:00:01.525095 23126066861888 run_lib.py:133] step: 326050, training_loss: 1.88020e-02
I0216 05:00:18.849108 23126066861888 run_lib.py:133] step: 326100, training_loss: 1.77011e-02
I0216 05:00:19.004898 23126066861888 run_lib.py:146] step: 326100, eval_loss: 2.87447e-02
I0216 05:00:36.491139 23126066861888 run_lib.py:133] step: 326150, training_loss: 1.77413e-02
I0216 05:00:53.849965 23126066861888 run_lib.py:133] step: 326200, training_loss: 1.85072e-02
I0216 05:00:54.002828 23126066861888 run_lib.py:146] step: 326200, eval_loss: 2.64938e-02
I0216 05:01:11.358653 23126066861888 run_lib.py:133] step: 326250, training_loss: 1.74423e-02
I0216 05:01:28.757433 23126066861888 run_lib.py:133] step: 326300, training_loss: 1.84245e-02
I0216 05:01:28.914897 23126066861888 run_lib.py:146] step: 326300, eval_loss: 2.90493e-02
I0216 05:01:46.455299 23126066861888 run_lib.py:133] step: 326350, training_loss: 1.82738e-02
I0216 05:02:03.741857 23126066861888 run_lib.py:133] step: 326400, training_loss: 1.77275e-02
I0216 05:02:03.892691 23126066861888 run_lib.py:146] step: 326400, eval_loss: 2.89459e-02
I0216 05:02:21.187186 23126066861888 run_lib.py:133] step: 326450, training_loss: 1.79255e-02
I0216 05:02:38.702455 23126066861888 run_lib.py:133] step: 326500, training_loss: 1.82250e-02
I0216 05:02:38.856803 23126066861888 run_lib.py:146] step: 326500, eval_loss: 2.87958e-02
I0216 05:02:56.155656 23126066861888 run_lib.py:133] step: 326550, training_loss: 1.84161e-02
I0216 05:03:13.645131 23126066861888 run_lib.py:133] step: 326600, training_loss: 1.81406e-02
I0216 05:03:13.817774 23126066861888 run_lib.py:146] step: 326600, eval_loss: 2.81033e-02
I0216 05:03:31.162511 23126066861888 run_lib.py:133] step: 326650, training_loss: 1.77698e-02
I0216 05:03:48.521797 23126066861888 run_lib.py:133] step: 326700, training_loss: 1.75551e-02
I0216 05:03:48.680190 23126066861888 run_lib.py:146] step: 326700, eval_loss: 2.77595e-02
I0216 05:04:06.254960 23126066861888 run_lib.py:133] step: 326750, training_loss: 1.85254e-02
I0216 05:04:23.541252 23126066861888 run_lib.py:133] step: 326800, training_loss: 1.77909e-02
I0216 05:04:23.694893 23126066861888 run_lib.py:146] step: 326800, eval_loss: 2.81811e-02
I0216 05:04:41.005734 23126066861888 run_lib.py:133] step: 326850, training_loss: 1.77769e-02
I0216 05:04:58.553504 23126066861888 run_lib.py:133] step: 326900, training_loss: 1.75768e-02
I0216 05:04:58.707051 23126066861888 run_lib.py:146] step: 326900, eval_loss: 2.72459e-02
I0216 05:05:16.103003 23126066861888 run_lib.py:133] step: 326950, training_loss: 1.83908e-02
I0216 05:05:33.404414 23126066861888 run_lib.py:133] step: 327000, training_loss: 1.86147e-02
I0216 05:05:33.557899 23126066861888 run_lib.py:146] step: 327000, eval_loss: 2.75639e-02
I0216 05:05:50.933350 23126066861888 run_lib.py:133] step: 327050, training_loss: 1.83924e-02
I0216 05:06:08.197810 23126066861888 run_lib.py:133] step: 327100, training_loss: 1.79247e-02
I0216 05:06:08.399064 23126066861888 run_lib.py:146] step: 327100, eval_loss: 2.92318e-02
I0216 05:06:25.716064 23126066861888 run_lib.py:133] step: 327150, training_loss: 1.78032e-02
I0216 05:06:43.063556 23126066861888 run_lib.py:133] step: 327200, training_loss: 1.81144e-02
I0216 05:06:43.219063 23126066861888 run_lib.py:146] step: 327200, eval_loss: 2.73958e-02
I0216 05:07:00.725073 23126066861888 run_lib.py:133] step: 327250, training_loss: 1.78771e-02
I0216 05:07:18.190525 23126066861888 run_lib.py:133] step: 327300, training_loss: 1.87882e-02
I0216 05:07:18.352106 23126066861888 run_lib.py:146] step: 327300, eval_loss: 2.74532e-02
I0216 05:07:35.779464 23126066861888 run_lib.py:133] step: 327350, training_loss: 1.82374e-02
I0216 05:07:53.112240 23126066861888 run_lib.py:133] step: 327400, training_loss: 1.85233e-02
I0216 05:07:53.263746 23126066861888 run_lib.py:146] step: 327400, eval_loss: 2.86417e-02
I0216 05:08:10.729143 23126066861888 run_lib.py:133] step: 327450, training_loss: 1.82801e-02
I0216 05:08:28.134078 23126066861888 run_lib.py:133] step: 327500, training_loss: 1.87831e-02
I0216 05:08:28.308029 23126066861888 run_lib.py:146] step: 327500, eval_loss: 2.65648e-02
I0216 05:08:45.603132 23126066861888 run_lib.py:133] step: 327550, training_loss: 1.78757e-02
I0216 05:09:03.082723 23126066861888 run_lib.py:133] step: 327600, training_loss: 1.82299e-02
I0216 05:09:03.238164 23126066861888 run_lib.py:146] step: 327600, eval_loss: 2.71588e-02
I0216 05:09:20.544863 23126066861888 run_lib.py:133] step: 327650, training_loss: 1.78917e-02
I0216 05:09:37.991915 23126066861888 run_lib.py:133] step: 327700, training_loss: 1.91259e-02
I0216 05:09:38.145907 23126066861888 run_lib.py:146] step: 327700, eval_loss: 2.76244e-02
I0216 05:09:55.384500 23126066861888 run_lib.py:133] step: 327750, training_loss: 1.76438e-02
I0216 05:10:12.770589 23126066861888 run_lib.py:133] step: 327800, training_loss: 1.79025e-02
I0216 05:10:12.927586 23126066861888 run_lib.py:146] step: 327800, eval_loss: 2.75869e-02
I0216 05:10:30.472658 23126066861888 run_lib.py:133] step: 327850, training_loss: 1.83301e-02
I0216 05:10:47.754461 23126066861888 run_lib.py:133] step: 327900, training_loss: 1.83570e-02
I0216 05:10:47.904866 23126066861888 run_lib.py:146] step: 327900, eval_loss: 2.63745e-02
I0216 05:11:05.148805 23126066861888 run_lib.py:133] step: 327950, training_loss: 1.84571e-02
I0216 05:11:22.603730 23126066861888 run_lib.py:133] step: 328000, training_loss: 1.83714e-02
I0216 05:11:22.762154 23126066861888 run_lib.py:146] step: 328000, eval_loss: 2.78411e-02
I0216 05:11:40.088295 23126066861888 run_lib.py:133] step: 328050, training_loss: 1.83412e-02
I0216 05:11:57.469347 23126066861888 run_lib.py:133] step: 328100, training_loss: 1.81155e-02
I0216 05:11:57.629145 23126066861888 run_lib.py:146] step: 328100, eval_loss: 2.75367e-02
I0216 05:12:15.022312 23126066861888 run_lib.py:133] step: 328150, training_loss: 1.81610e-02
I0216 05:12:32.296416 23126066861888 run_lib.py:133] step: 328200, training_loss: 1.83603e-02
I0216 05:12:32.458925 23126066861888 run_lib.py:146] step: 328200, eval_loss: 2.77227e-02
I0216 05:12:49.721908 23126066861888 run_lib.py:133] step: 328250, training_loss: 1.87369e-02
I0216 05:13:07.058722 23126066861888 run_lib.py:133] step: 328300, training_loss: 1.88674e-02
I0216 05:13:07.211108 23126066861888 run_lib.py:146] step: 328300, eval_loss: 2.75619e-02
I0216 05:13:24.748458 23126066861888 run_lib.py:133] step: 328350, training_loss: 1.80603e-02
I0216 05:13:42.184595 23126066861888 run_lib.py:133] step: 328400, training_loss: 1.77073e-02
I0216 05:13:42.339207 23126066861888 run_lib.py:146] step: 328400, eval_loss: 2.81490e-02
I0216 05:13:59.621317 23126066861888 run_lib.py:133] step: 328450, training_loss: 1.88747e-02
I0216 05:14:16.946580 23126066861888 run_lib.py:133] step: 328500, training_loss: 1.81975e-02
I0216 05:14:17.105329 23126066861888 run_lib.py:146] step: 328500, eval_loss: 2.75620e-02
I0216 05:14:34.582739 23126066861888 run_lib.py:133] step: 328550, training_loss: 1.83400e-02
I0216 05:14:51.981317 23126066861888 run_lib.py:133] step: 328600, training_loss: 1.75553e-02
I0216 05:14:52.141131 23126066861888 run_lib.py:146] step: 328600, eval_loss: 2.79789e-02
I0216 05:15:09.437200 23126066861888 run_lib.py:133] step: 328650, training_loss: 1.83126e-02
I0216 05:15:26.934142 23126066861888 run_lib.py:133] step: 328700, training_loss: 1.75164e-02
I0216 05:15:27.090870 23126066861888 run_lib.py:146] step: 328700, eval_loss: 2.67327e-02
I0216 05:15:44.388669 23126066861888 run_lib.py:133] step: 328750, training_loss: 1.82752e-02
I0216 05:16:01.836297 23126066861888 run_lib.py:133] step: 328800, training_loss: 1.78184e-02
I0216 05:16:01.988900 23126066861888 run_lib.py:146] step: 328800, eval_loss: 2.80434e-02
I0216 05:16:19.262333 23126066861888 run_lib.py:133] step: 328850, training_loss: 1.83652e-02
I0216 05:16:36.672824 23126066861888 run_lib.py:133] step: 328900, training_loss: 1.78966e-02
I0216 05:16:36.841294 23126066861888 run_lib.py:146] step: 328900, eval_loss: 2.76766e-02
I0216 05:16:54.442166 23126066861888 run_lib.py:133] step: 328950, training_loss: 1.79427e-02
I0216 05:17:11.805814 23126066861888 run_lib.py:133] step: 329000, training_loss: 1.82106e-02
I0216 05:17:11.963061 23126066861888 run_lib.py:146] step: 329000, eval_loss: 2.71628e-02
I0216 05:17:29.284292 23126066861888 run_lib.py:133] step: 329050, training_loss: 1.79150e-02
I0216 05:17:46.704772 23126066861888 run_lib.py:133] step: 329100, training_loss: 1.81764e-02
I0216 05:17:46.855242 23126066861888 run_lib.py:146] step: 329100, eval_loss: 2.76180e-02
I0216 05:18:04.197245 23126066861888 run_lib.py:133] step: 329150, training_loss: 1.77967e-02
I0216 05:18:21.572481 23126066861888 run_lib.py:133] step: 329200, training_loss: 1.81207e-02
I0216 05:18:21.732096 23126066861888 run_lib.py:146] step: 329200, eval_loss: 2.78445e-02
I0216 05:18:39.218433 23126066861888 run_lib.py:133] step: 329250, training_loss: 1.80875e-02
I0216 05:18:56.505258 23126066861888 run_lib.py:133] step: 329300, training_loss: 1.77411e-02
I0216 05:18:56.655453 23126066861888 run_lib.py:146] step: 329300, eval_loss: 2.74720e-02
I0216 05:19:13.926987 23126066861888 run_lib.py:133] step: 329350, training_loss: 1.83271e-02
I0216 05:19:31.213132 23126066861888 run_lib.py:133] step: 329400, training_loss: 1.79138e-02
I0216 05:19:31.376117 23126066861888 run_lib.py:146] step: 329400, eval_loss: 2.68677e-02
I0216 05:19:48.947760 23126066861888 run_lib.py:133] step: 329450, training_loss: 1.82798e-02
I0216 05:20:06.431204 23126066861888 run_lib.py:133] step: 329500, training_loss: 1.78424e-02
I0216 05:20:06.584897 23126066861888 run_lib.py:146] step: 329500, eval_loss: 2.82731e-02
I0216 05:20:23.885316 23126066861888 run_lib.py:133] step: 329550, training_loss: 1.79789e-02
I0216 05:20:41.181947 23126066861888 run_lib.py:133] step: 329600, training_loss: 1.84956e-02
I0216 05:20:41.339699 23126066861888 run_lib.py:146] step: 329600, eval_loss: 2.78277e-02
I0216 05:20:58.780592 23126066861888 run_lib.py:133] step: 329650, training_loss: 1.88421e-02
I0216 05:21:16.118140 23126066861888 run_lib.py:133] step: 329700, training_loss: 1.75666e-02
I0216 05:21:16.276065 23126066861888 run_lib.py:146] step: 329700, eval_loss: 2.81501e-02
I0216 05:21:33.651246 23126066861888 run_lib.py:133] step: 329750, training_loss: 1.83424e-02
I0216 05:21:51.153485 23126066861888 run_lib.py:133] step: 329800, training_loss: 1.85104e-02
I0216 05:21:51.306906 23126066861888 run_lib.py:146] step: 329800, eval_loss: 2.85632e-02
I0216 05:22:08.624593 23126066861888 run_lib.py:133] step: 329850, training_loss: 1.75714e-02
I0216 05:22:26.078871 23126066861888 run_lib.py:133] step: 329900, training_loss: 1.79762e-02
I0216 05:22:26.238005 23126066861888 run_lib.py:146] step: 329900, eval_loss: 2.76168e-02
I0216 05:22:43.539918 23126066861888 run_lib.py:133] step: 329950, training_loss: 1.82616e-02
I0216 05:23:00.842175 23126066861888 run_lib.py:133] step: 330000, training_loss: 1.87184e-02
I0216 05:23:01.523891 23126066861888 run_lib.py:146] step: 330000, eval_loss: 2.80662e-02
I0216 05:23:21.687659 23126066861888 run_lib.py:133] step: 330050, training_loss: 1.79422e-02
I0216 05:23:39.051706 23126066861888 run_lib.py:133] step: 330100, training_loss: 1.95320e-02
I0216 05:23:39.206167 23126066861888 run_lib.py:146] step: 330100, eval_loss: 2.73076e-02
I0216 05:23:56.470029 23126066861888 run_lib.py:133] step: 330150, training_loss: 1.72246e-02
I0216 05:24:13.909226 23126066861888 run_lib.py:133] step: 330200, training_loss: 1.80982e-02
I0216 05:24:14.069747 23126066861888 run_lib.py:146] step: 330200, eval_loss: 2.76725e-02
I0216 05:24:31.388958 23126066861888 run_lib.py:133] step: 330250, training_loss: 1.78448e-02
I0216 05:24:48.730387 23126066861888 run_lib.py:133] step: 330300, training_loss: 1.80853e-02
I0216 05:24:48.886207 23126066861888 run_lib.py:146] step: 330300, eval_loss: 2.70538e-02
I0216 05:25:06.417224 23126066861888 run_lib.py:133] step: 330350, training_loss: 1.80238e-02
I0216 05:25:23.728748 23126066861888 run_lib.py:133] step: 330400, training_loss: 1.87830e-02
I0216 05:25:23.883094 23126066861888 run_lib.py:146] step: 330400, eval_loss: 2.74085e-02
I0216 05:25:41.340861 23126066861888 run_lib.py:133] step: 330450, training_loss: 1.79916e-02
I0216 05:25:58.709716 23126066861888 run_lib.py:133] step: 330500, training_loss: 1.86923e-02
I0216 05:25:58.867290 23126066861888 run_lib.py:146] step: 330500, eval_loss: 2.77827e-02
I0216 05:26:16.284043 23126066861888 run_lib.py:133] step: 330550, training_loss: 1.82501e-02
I0216 05:26:33.894923 23126066861888 run_lib.py:133] step: 330600, training_loss: 1.79411e-02
I0216 05:26:34.052232 23126066861888 run_lib.py:146] step: 330600, eval_loss: 2.84352e-02
I0216 05:26:51.390137 23126066861888 run_lib.py:133] step: 330650, training_loss: 1.89392e-02
I0216 05:27:08.662604 23126066861888 run_lib.py:133] step: 330700, training_loss: 1.82391e-02
I0216 05:27:08.815857 23126066861888 run_lib.py:146] step: 330700, eval_loss: 2.75978e-02
I0216 05:27:26.103619 23126066861888 run_lib.py:133] step: 330750, training_loss: 1.79577e-02
I0216 05:27:43.520632 23126066861888 run_lib.py:133] step: 330800, training_loss: 1.82350e-02
I0216 05:27:43.673038 23126066861888 run_lib.py:146] step: 330800, eval_loss: 2.79316e-02
I0216 05:28:01.202384 23126066861888 run_lib.py:133] step: 330850, training_loss: 1.81559e-02
I0216 05:28:18.713018 23126066861888 run_lib.py:133] step: 330900, training_loss: 1.73367e-02
I0216 05:28:18.871058 23126066861888 run_lib.py:146] step: 330900, eval_loss: 2.76312e-02
I0216 05:28:36.199298 23126066861888 run_lib.py:133] step: 330950, training_loss: 1.78372e-02
I0216 05:28:53.518666 23126066861888 run_lib.py:133] step: 331000, training_loss: 1.79101e-02
I0216 05:28:53.672314 23126066861888 run_lib.py:146] step: 331000, eval_loss: 2.55476e-02
I0216 05:29:11.125836 23126066861888 run_lib.py:133] step: 331050, training_loss: 1.77698e-02
I0216 05:29:28.472632 23126066861888 run_lib.py:133] step: 331100, training_loss: 1.82037e-02
I0216 05:29:28.629467 23126066861888 run_lib.py:146] step: 331100, eval_loss: 2.68640e-02
I0216 05:29:46.147763 23126066861888 run_lib.py:133] step: 331150, training_loss: 1.86425e-02
I0216 05:30:03.479069 23126066861888 run_lib.py:133] step: 331200, training_loss: 1.81292e-02
I0216 05:30:03.630903 23126066861888 run_lib.py:146] step: 331200, eval_loss: 2.80507e-02
I0216 05:30:20.949630 23126066861888 run_lib.py:133] step: 331250, training_loss: 1.87274e-02
I0216 05:30:38.389107 23126066861888 run_lib.py:133] step: 331300, training_loss: 1.79380e-02
I0216 05:30:38.545946 23126066861888 run_lib.py:146] step: 331300, eval_loss: 2.87998e-02
I0216 05:30:55.830604 23126066861888 run_lib.py:133] step: 331350, training_loss: 1.80792e-02
I0216 05:31:13.153140 23126066861888 run_lib.py:133] step: 331400, training_loss: 1.76039e-02
I0216 05:31:13.329983 23126066861888 run_lib.py:146] step: 331400, eval_loss: 2.82778e-02
I0216 05:31:30.905595 23126066861888 run_lib.py:133] step: 331450, training_loss: 1.78482e-02
I0216 05:31:48.229077 23126066861888 run_lib.py:133] step: 331500, training_loss: 1.76202e-02
I0216 05:31:48.400145 23126066861888 run_lib.py:146] step: 331500, eval_loss: 2.84660e-02
I0216 05:32:05.726458 23126066861888 run_lib.py:133] step: 331550, training_loss: 1.89614e-02
I0216 05:32:23.203296 23126066861888 run_lib.py:133] step: 331600, training_loss: 1.72610e-02
I0216 05:32:23.358911 23126066861888 run_lib.py:146] step: 331600, eval_loss: 2.76954e-02
I0216 05:32:40.668020 23126066861888 run_lib.py:133] step: 331650, training_loss: 1.70599e-02
I0216 05:32:58.041145 23126066861888 run_lib.py:133] step: 331700, training_loss: 1.84655e-02
I0216 05:32:58.208309 23126066861888 run_lib.py:146] step: 331700, eval_loss: 2.73168e-02
I0216 05:33:15.691065 23126066861888 run_lib.py:133] step: 331750, training_loss: 1.79913e-02
I0216 05:33:33.068442 23126066861888 run_lib.py:133] step: 331800, training_loss: 1.75448e-02
I0216 05:33:33.223931 23126066861888 run_lib.py:146] step: 331800, eval_loss: 2.86707e-02
I0216 05:33:50.546955 23126066861888 run_lib.py:133] step: 331850, training_loss: 1.76089e-02
I0216 05:34:07.845637 23126066861888 run_lib.py:133] step: 331900, training_loss: 1.82292e-02
I0216 05:34:08.019984 23126066861888 run_lib.py:146] step: 331900, eval_loss: 2.75920e-02
I0216 05:34:25.546586 23126066861888 run_lib.py:133] step: 331950, training_loss: 1.83723e-02
I0216 05:34:43.073293 23126066861888 run_lib.py:133] step: 332000, training_loss: 1.76254e-02
I0216 05:34:43.227118 23126066861888 run_lib.py:146] step: 332000, eval_loss: 2.82682e-02
I0216 05:35:00.518949 23126066861888 run_lib.py:133] step: 332050, training_loss: 1.82140e-02
I0216 05:35:17.789768 23126066861888 run_lib.py:133] step: 332100, training_loss: 1.71436e-02
I0216 05:35:17.945103 23126066861888 run_lib.py:146] step: 332100, eval_loss: 2.73403e-02
I0216 05:35:35.497694 23126066861888 run_lib.py:133] step: 332150, training_loss: 1.84231e-02
I0216 05:35:52.931920 23126066861888 run_lib.py:133] step: 332200, training_loss: 1.83706e-02
I0216 05:35:53.089192 23126066861888 run_lib.py:146] step: 332200, eval_loss: 2.80366e-02
I0216 05:36:10.463486 23126066861888 run_lib.py:133] step: 332250, training_loss: 1.70584e-02
I0216 05:36:27.984029 23126066861888 run_lib.py:133] step: 332300, training_loss: 1.80849e-02
I0216 05:36:28.137692 23126066861888 run_lib.py:146] step: 332300, eval_loss: 2.70310e-02
I0216 05:36:45.422320 23126066861888 run_lib.py:133] step: 332350, training_loss: 1.79943e-02
I0216 05:37:02.866488 23126066861888 run_lib.py:133] step: 332400, training_loss: 1.78727e-02
I0216 05:37:03.025196 23126066861888 run_lib.py:146] step: 332400, eval_loss: 2.69797e-02
I0216 05:37:20.346447 23126066861888 run_lib.py:133] step: 332450, training_loss: 1.74783e-02
I0216 05:37:37.721489 23126066861888 run_lib.py:133] step: 332500, training_loss: 1.88493e-02
I0216 05:37:37.878314 23126066861888 run_lib.py:146] step: 332500, eval_loss: 2.77756e-02
I0216 05:37:55.371262 23126066861888 run_lib.py:133] step: 332550, training_loss: 1.77541e-02
I0216 05:38:12.743652 23126066861888 run_lib.py:133] step: 332600, training_loss: 1.78078e-02
I0216 05:38:12.896926 23126066861888 run_lib.py:146] step: 332600, eval_loss: 2.82625e-02
I0216 05:38:30.187784 23126066861888 run_lib.py:133] step: 332650, training_loss: 1.79364e-02
I0216 05:38:47.696625 23126066861888 run_lib.py:133] step: 332700, training_loss: 1.82808e-02
I0216 05:38:47.857576 23126066861888 run_lib.py:146] step: 332700, eval_loss: 2.55694e-02
I0216 05:39:05.226308 23126066861888 run_lib.py:133] step: 332750, training_loss: 1.78239e-02
I0216 05:39:22.620096 23126066861888 run_lib.py:133] step: 332800, training_loss: 1.86529e-02
I0216 05:39:22.779105 23126066861888 run_lib.py:146] step: 332800, eval_loss: 2.80887e-02
I0216 05:39:40.220551 23126066861888 run_lib.py:133] step: 332850, training_loss: 1.85505e-02
I0216 05:39:57.510628 23126066861888 run_lib.py:133] step: 332900, training_loss: 1.86291e-02
I0216 05:39:57.671993 23126066861888 run_lib.py:146] step: 332900, eval_loss: 2.75517e-02
I0216 05:40:14.976225 23126066861888 run_lib.py:133] step: 332950, training_loss: 1.86172e-02
I0216 05:40:32.325523 23126066861888 run_lib.py:133] step: 333000, training_loss: 1.75262e-02
I0216 05:40:32.484302 23126066861888 run_lib.py:146] step: 333000, eval_loss: 2.60374e-02
I0216 05:40:49.951178 23126066861888 run_lib.py:133] step: 333050, training_loss: 1.75749e-02
I0216 05:41:07.433516 23126066861888 run_lib.py:133] step: 333100, training_loss: 1.76829e-02
I0216 05:41:07.585196 23126066861888 run_lib.py:146] step: 333100, eval_loss: 2.83916e-02
I0216 05:41:24.947384 23126066861888 run_lib.py:133] step: 333150, training_loss: 1.78988e-02
I0216 05:41:42.277717 23126066861888 run_lib.py:133] step: 333200, training_loss: 1.78726e-02
I0216 05:41:42.433938 23126066861888 run_lib.py:146] step: 333200, eval_loss: 2.80322e-02
I0216 05:41:59.888958 23126066861888 run_lib.py:133] step: 333250, training_loss: 1.81600e-02
I0216 05:42:17.212204 23126066861888 run_lib.py:133] step: 333300, training_loss: 1.86390e-02
I0216 05:42:17.379994 23126066861888 run_lib.py:146] step: 333300, eval_loss: 2.69193e-02
I0216 05:42:34.751450 23126066861888 run_lib.py:133] step: 333350, training_loss: 1.81010e-02
I0216 05:42:52.280741 23126066861888 run_lib.py:133] step: 333400, training_loss: 1.77406e-02
I0216 05:42:52.436033 23126066861888 run_lib.py:146] step: 333400, eval_loss: 2.77130e-02
I0216 05:43:09.735389 23126066861888 run_lib.py:133] step: 333450, training_loss: 1.83584e-02
I0216 05:43:27.237559 23126066861888 run_lib.py:133] step: 333500, training_loss: 1.83079e-02
I0216 05:43:27.390883 23126066861888 run_lib.py:146] step: 333500, eval_loss: 2.78654e-02
I0216 05:43:44.691774 23126066861888 run_lib.py:133] step: 333550, training_loss: 1.83486e-02
I0216 05:44:02.073685 23126066861888 run_lib.py:133] step: 333600, training_loss: 1.79445e-02
I0216 05:44:02.233208 23126066861888 run_lib.py:146] step: 333600, eval_loss: 2.64005e-02
I0216 05:44:19.773405 23126066861888 run_lib.py:133] step: 333650, training_loss: 1.91581e-02
I0216 05:44:37.088274 23126066861888 run_lib.py:133] step: 333700, training_loss: 1.78377e-02
I0216 05:44:37.243981 23126066861888 run_lib.py:146] step: 333700, eval_loss: 2.73827e-02
I0216 05:44:54.644564 23126066861888 run_lib.py:133] step: 333750, training_loss: 1.86486e-02
I0216 05:45:12.213598 23126066861888 run_lib.py:133] step: 333800, training_loss: 1.82545e-02
I0216 05:45:12.370577 23126066861888 run_lib.py:146] step: 333800, eval_loss: 2.80455e-02
I0216 05:45:29.736336 23126066861888 run_lib.py:133] step: 333850, training_loss: 1.79461e-02
I0216 05:45:47.065206 23126066861888 run_lib.py:133] step: 333900, training_loss: 1.82598e-02
I0216 05:45:47.221924 23126066861888 run_lib.py:146] step: 333900, eval_loss: 2.77002e-02
I0216 05:46:04.645345 23126066861888 run_lib.py:133] step: 333950, training_loss: 1.77989e-02
I0216 05:46:21.963171 23126066861888 run_lib.py:133] step: 334000, training_loss: 1.85079e-02
I0216 05:46:22.115676 23126066861888 run_lib.py:146] step: 334000, eval_loss: 2.80581e-02
I0216 05:46:39.411120 23126066861888 run_lib.py:133] step: 334050, training_loss: 1.73298e-02
I0216 05:46:56.707048 23126066861888 run_lib.py:133] step: 334100, training_loss: 1.79608e-02
I0216 05:46:56.859310 23126066861888 run_lib.py:146] step: 334100, eval_loss: 2.78924e-02
I0216 05:47:14.340764 23126066861888 run_lib.py:133] step: 334150, training_loss: 1.75057e-02
I0216 05:47:31.759402 23126066861888 run_lib.py:133] step: 334200, training_loss: 1.86880e-02
I0216 05:47:31.936506 23126066861888 run_lib.py:146] step: 334200, eval_loss: 2.81450e-02
I0216 05:47:49.299343 23126066861888 run_lib.py:133] step: 334250, training_loss: 1.80773e-02
I0216 05:48:06.642389 23126066861888 run_lib.py:133] step: 334300, training_loss: 1.84209e-02
I0216 05:48:06.807977 23126066861888 run_lib.py:146] step: 334300, eval_loss: 2.70323e-02
I0216 05:48:24.310046 23126066861888 run_lib.py:133] step: 334350, training_loss: 1.79880e-02
I0216 05:48:41.595290 23126066861888 run_lib.py:133] step: 334400, training_loss: 1.81443e-02
I0216 05:48:41.753959 23126066861888 run_lib.py:146] step: 334400, eval_loss: 2.86882e-02
I0216 05:48:59.053227 23126066861888 run_lib.py:133] step: 334450, training_loss: 1.80553e-02
I0216 05:49:16.623015 23126066861888 run_lib.py:133] step: 334500, training_loss: 1.86736e-02
I0216 05:49:16.776674 23126066861888 run_lib.py:146] step: 334500, eval_loss: 2.60431e-02
I0216 05:49:34.096703 23126066861888 run_lib.py:133] step: 334550, training_loss: 1.82304e-02
I0216 05:49:51.575854 23126066861888 run_lib.py:133] step: 334600, training_loss: 1.85403e-02
I0216 05:49:51.727794 23126066861888 run_lib.py:146] step: 334600, eval_loss: 2.70752e-02
I0216 05:50:09.003911 23126066861888 run_lib.py:133] step: 334650, training_loss: 1.82429e-02
I0216 05:50:26.289605 23126066861888 run_lib.py:133] step: 334700, training_loss: 1.82179e-02
I0216 05:50:26.446146 23126066861888 run_lib.py:146] step: 334700, eval_loss: 2.85784e-02
I0216 05:50:43.963764 23126066861888 run_lib.py:133] step: 334750, training_loss: 1.87209e-02
I0216 05:51:01.320044 23126066861888 run_lib.py:133] step: 334800, training_loss: 1.71121e-02
I0216 05:51:01.484941 23126066861888 run_lib.py:146] step: 334800, eval_loss: 2.91887e-02
I0216 05:51:18.802328 23126066861888 run_lib.py:133] step: 334850, training_loss: 1.83809e-02
I0216 05:51:36.279446 23126066861888 run_lib.py:133] step: 334900, training_loss: 1.82632e-02
I0216 05:51:36.434801 23126066861888 run_lib.py:146] step: 334900, eval_loss: 2.82206e-02
I0216 05:51:53.734611 23126066861888 run_lib.py:133] step: 334950, training_loss: 1.78984e-02
I0216 05:52:11.032559 23126066861888 run_lib.py:133] step: 335000, training_loss: 1.82245e-02
I0216 05:52:11.183238 23126066861888 run_lib.py:146] step: 335000, eval_loss: 2.78875e-02
I0216 05:52:28.619853 23126066861888 run_lib.py:133] step: 335050, training_loss: 1.83118e-02
I0216 05:52:45.933601 23126066861888 run_lib.py:133] step: 335100, training_loss: 1.76327e-02
I0216 05:52:46.088168 23126066861888 run_lib.py:146] step: 335100, eval_loss: 2.77952e-02
I0216 05:53:03.403281 23126066861888 run_lib.py:133] step: 335150, training_loss: 1.76552e-02
I0216 05:53:20.727650 23126066861888 run_lib.py:133] step: 335200, training_loss: 1.78216e-02
I0216 05:53:20.883800 23126066861888 run_lib.py:146] step: 335200, eval_loss: 2.77261e-02
I0216 05:53:38.359517 23126066861888 run_lib.py:133] step: 335250, training_loss: 1.81033e-02
I0216 05:53:55.782374 23126066861888 run_lib.py:133] step: 335300, training_loss: 1.80131e-02
I0216 05:53:55.949891 23126066861888 run_lib.py:146] step: 335300, eval_loss: 2.90649e-02
I0216 05:54:13.354600 23126066861888 run_lib.py:133] step: 335350, training_loss: 1.80872e-02
I0216 05:54:30.782801 23126066861888 run_lib.py:133] step: 335400, training_loss: 1.83230e-02
I0216 05:54:30.937811 23126066861888 run_lib.py:146] step: 335400, eval_loss: 2.74106e-02
I0216 05:54:48.573912 23126066861888 run_lib.py:133] step: 335450, training_loss: 1.78123e-02
I0216 05:55:05.882302 23126066861888 run_lib.py:133] step: 335500, training_loss: 1.83585e-02
I0216 05:55:06.033909 23126066861888 run_lib.py:146] step: 335500, eval_loss: 2.78125e-02
I0216 05:55:23.337005 23126066861888 run_lib.py:133] step: 335550, training_loss: 1.95129e-02
I0216 05:55:40.816088 23126066861888 run_lib.py:133] step: 335600, training_loss: 1.79418e-02
I0216 05:55:40.987131 23126066861888 run_lib.py:146] step: 335600, eval_loss: 2.85171e-02
I0216 05:55:58.356885 23126066861888 run_lib.py:133] step: 335650, training_loss: 1.76333e-02
I0216 05:56:15.890506 23126066861888 run_lib.py:133] step: 335700, training_loss: 1.84281e-02
I0216 05:56:16.045341 23126066861888 run_lib.py:146] step: 335700, eval_loss: 2.76771e-02
I0216 05:56:33.332097 23126066861888 run_lib.py:133] step: 335750, training_loss: 1.74170e-02
I0216 05:56:50.632686 23126066861888 run_lib.py:133] step: 335800, training_loss: 1.74431e-02
I0216 05:56:50.786982 23126066861888 run_lib.py:146] step: 335800, eval_loss: 2.81987e-02
I0216 05:57:08.269069 23126066861888 run_lib.py:133] step: 335850, training_loss: 1.78580e-02
I0216 05:57:25.625707 23126066861888 run_lib.py:133] step: 335900, training_loss: 1.85519e-02
I0216 05:57:25.780034 23126066861888 run_lib.py:146] step: 335900, eval_loss: 2.80428e-02
I0216 05:57:43.153637 23126066861888 run_lib.py:133] step: 335950, training_loss: 1.81914e-02
I0216 05:58:00.685035 23126066861888 run_lib.py:133] step: 336000, training_loss: 1.77264e-02
I0216 05:58:00.838812 23126066861888 run_lib.py:146] step: 336000, eval_loss: 2.73187e-02
I0216 05:58:18.116088 23126066861888 run_lib.py:133] step: 336050, training_loss: 1.74459e-02
I0216 05:58:35.444961 23126066861888 run_lib.py:133] step: 336100, training_loss: 1.78850e-02
I0216 05:58:35.601313 23126066861888 run_lib.py:146] step: 336100, eval_loss: 2.75975e-02
I0216 05:58:52.988011 23126066861888 run_lib.py:133] step: 336150, training_loss: 1.78229e-02
I0216 05:59:10.339313 23126066861888 run_lib.py:133] step: 336200, training_loss: 1.84341e-02
I0216 05:59:10.508892 23126066861888 run_lib.py:146] step: 336200, eval_loss: 2.72929e-02
I0216 05:59:27.892499 23126066861888 run_lib.py:133] step: 336250, training_loss: 1.80825e-02
I0216 05:59:45.202332 23126066861888 run_lib.py:133] step: 336300, training_loss: 1.87856e-02
I0216 05:59:45.356016 23126066861888 run_lib.py:146] step: 336300, eval_loss: 2.82037e-02
I0216 06:00:02.880274 23126066861888 run_lib.py:133] step: 336350, training_loss: 1.72524e-02
I0216 06:00:20.220858 23126066861888 run_lib.py:133] step: 336400, training_loss: 1.81014e-02
I0216 06:00:20.373733 23126066861888 run_lib.py:146] step: 336400, eval_loss: 2.73289e-02
I0216 06:00:37.687909 23126066861888 run_lib.py:133] step: 336450, training_loss: 1.85890e-02
I0216 06:00:55.071532 23126066861888 run_lib.py:133] step: 336500, training_loss: 1.78879e-02
I0216 06:00:55.231352 23126066861888 run_lib.py:146] step: 336500, eval_loss: 2.72342e-02
I0216 06:01:12.737010 23126066861888 run_lib.py:133] step: 336550, training_loss: 1.75512e-02
I0216 06:01:30.061894 23126066861888 run_lib.py:133] step: 336600, training_loss: 1.77501e-02
I0216 06:01:30.218137 23126066861888 run_lib.py:146] step: 336600, eval_loss: 2.74590e-02
I0216 06:01:47.488875 23126066861888 run_lib.py:133] step: 336650, training_loss: 1.81709e-02
I0216 06:02:04.969427 23126066861888 run_lib.py:133] step: 336700, training_loss: 1.82761e-02
I0216 06:02:05.123117 23126066861888 run_lib.py:146] step: 336700, eval_loss: 2.72719e-02
I0216 06:02:22.469793 23126066861888 run_lib.py:133] step: 336750, training_loss: 1.78338e-02
I0216 06:02:40.038312 23126066861888 run_lib.py:133] step: 336800, training_loss: 1.74731e-02
I0216 06:02:40.194399 23126066861888 run_lib.py:146] step: 336800, eval_loss: 2.74223e-02
I0216 06:02:57.567792 23126066861888 run_lib.py:133] step: 336850, training_loss: 1.75522e-02
I0216 06:03:14.865470 23126066861888 run_lib.py:133] step: 336900, training_loss: 1.79573e-02
I0216 06:03:15.017600 23126066861888 run_lib.py:146] step: 336900, eval_loss: 2.82791e-02
I0216 06:03:32.480768 23126066861888 run_lib.py:133] step: 336950, training_loss: 1.82551e-02
I0216 06:03:49.909686 23126066861888 run_lib.py:133] step: 337000, training_loss: 1.81104e-02
I0216 06:03:50.078155 23126066861888 run_lib.py:146] step: 337000, eval_loss: 2.80963e-02
I0216 06:04:07.477402 23126066861888 run_lib.py:133] step: 337050, training_loss: 1.80463e-02
I0216 06:04:25.032444 23126066861888 run_lib.py:133] step: 337100, training_loss: 1.73151e-02
I0216 06:04:25.189980 23126066861888 run_lib.py:146] step: 337100, eval_loss: 2.85169e-02
I0216 06:04:42.526201 23126066861888 run_lib.py:133] step: 337150, training_loss: 1.82250e-02
I0216 06:04:59.844019 23126066861888 run_lib.py:133] step: 337200, training_loss: 1.77474e-02
I0216 06:04:59.997940 23126066861888 run_lib.py:146] step: 337200, eval_loss: 2.86438e-02
I0216 06:05:17.442194 23126066861888 run_lib.py:133] step: 337250, training_loss: 1.78519e-02
I0216 06:05:34.851849 23126066861888 run_lib.py:133] step: 337300, training_loss: 1.82258e-02
I0216 06:05:35.007784 23126066861888 run_lib.py:146] step: 337300, eval_loss: 2.78817e-02
I0216 06:05:52.401331 23126066861888 run_lib.py:133] step: 337350, training_loss: 1.78639e-02
I0216 06:06:09.725212 23126066861888 run_lib.py:133] step: 337400, training_loss: 1.77159e-02
I0216 06:06:09.888963 23126066861888 run_lib.py:146] step: 337400, eval_loss: 2.90932e-02
I0216 06:06:27.402040 23126066861888 run_lib.py:133] step: 337450, training_loss: 1.89722e-02
I0216 06:06:44.809933 23126066861888 run_lib.py:133] step: 337500, training_loss: 1.83318e-02
I0216 06:06:44.970144 23126066861888 run_lib.py:146] step: 337500, eval_loss: 2.74340e-02
I0216 06:07:02.310506 23126066861888 run_lib.py:133] step: 337550, training_loss: 1.73700e-02
I0216 06:07:19.684570 23126066861888 run_lib.py:133] step: 337600, training_loss: 1.77321e-02
I0216 06:07:19.843910 23126066861888 run_lib.py:146] step: 337600, eval_loss: 2.70583e-02
I0216 06:07:37.358572 23126066861888 run_lib.py:133] step: 337650, training_loss: 1.79391e-02
I0216 06:07:54.652426 23126066861888 run_lib.py:133] step: 337700, training_loss: 1.79185e-02
I0216 06:07:54.809072 23126066861888 run_lib.py:146] step: 337700, eval_loss: 2.70474e-02
I0216 06:08:12.146460 23126066861888 run_lib.py:133] step: 337750, training_loss: 1.78024e-02
I0216 06:08:29.567587 23126066861888 run_lib.py:133] step: 337800, training_loss: 1.86391e-02
I0216 06:08:29.721136 23126066861888 run_lib.py:146] step: 337800, eval_loss: 2.74762e-02
I0216 06:08:47.050547 23126066861888 run_lib.py:133] step: 337850, training_loss: 1.78701e-02
I0216 06:09:04.519736 23126066861888 run_lib.py:133] step: 337900, training_loss: 1.74084e-02
I0216 06:09:04.677229 23126066861888 run_lib.py:146] step: 337900, eval_loss: 2.84646e-02
I0216 06:09:22.000696 23126066861888 run_lib.py:133] step: 337950, training_loss: 1.77401e-02
I0216 06:09:39.337829 23126066861888 run_lib.py:133] step: 338000, training_loss: 1.81473e-02
I0216 06:09:39.493392 23126066861888 run_lib.py:146] step: 338000, eval_loss: 2.83861e-02
I0216 06:09:57.050490 23126066861888 run_lib.py:133] step: 338050, training_loss: 1.78524e-02
I0216 06:10:14.348900 23126066861888 run_lib.py:133] step: 338100, training_loss: 1.79743e-02
I0216 06:10:14.511128 23126066861888 run_lib.py:146] step: 338100, eval_loss: 2.77990e-02
I0216 06:10:31.872695 23126066861888 run_lib.py:133] step: 338150, training_loss: 1.81135e-02
I0216 06:10:49.426124 23126066861888 run_lib.py:133] step: 338200, training_loss: 1.82111e-02
I0216 06:10:49.584741 23126066861888 run_lib.py:146] step: 338200, eval_loss: 2.91077e-02
I0216 06:11:06.965621 23126066861888 run_lib.py:133] step: 338250, training_loss: 1.78394e-02
I0216 06:11:24.219107 23126066861888 run_lib.py:133] step: 338300, training_loss: 1.80504e-02
I0216 06:11:24.372674 23126066861888 run_lib.py:146] step: 338300, eval_loss: 2.67285e-02
I0216 06:11:41.718193 23126066861888 run_lib.py:133] step: 338350, training_loss: 1.86226e-02
I0216 06:11:59.048258 23126066861888 run_lib.py:133] step: 338400, training_loss: 1.81522e-02
I0216 06:11:59.202069 23126066861888 run_lib.py:146] step: 338400, eval_loss: 2.79382e-02
I0216 06:12:16.586698 23126066861888 run_lib.py:133] step: 338450, training_loss: 1.80680e-02
I0216 06:12:33.875060 23126066861888 run_lib.py:133] step: 338500, training_loss: 1.71213e-02
I0216 06:12:34.031778 23126066861888 run_lib.py:146] step: 338500, eval_loss: 2.82998e-02
I0216 06:12:51.516981 23126066861888 run_lib.py:133] step: 338550, training_loss: 1.83030e-02
I0216 06:13:08.991397 23126066861888 run_lib.py:133] step: 338600, training_loss: 1.79656e-02
I0216 06:13:09.144145 23126066861888 run_lib.py:146] step: 338600, eval_loss: 2.78231e-02
I0216 06:13:26.502695 23126066861888 run_lib.py:133] step: 338650, training_loss: 1.76321e-02
I0216 06:13:43.841429 23126066861888 run_lib.py:133] step: 338700, training_loss: 1.92041e-02
I0216 06:13:43.998019 23126066861888 run_lib.py:146] step: 338700, eval_loss: 2.82697e-02
I0216 06:14:01.452172 23126066861888 run_lib.py:133] step: 338750, training_loss: 1.76612e-02
I0216 06:14:18.816830 23126066861888 run_lib.py:133] step: 338800, training_loss: 1.76238e-02
I0216 06:14:18.967556 23126066861888 run_lib.py:146] step: 338800, eval_loss: 2.76431e-02
I0216 06:14:36.343679 23126066861888 run_lib.py:133] step: 338850, training_loss: 1.79125e-02
I0216 06:14:53.890862 23126066861888 run_lib.py:133] step: 338900, training_loss: 1.82564e-02
I0216 06:14:54.046051 23126066861888 run_lib.py:146] step: 338900, eval_loss: 2.83072e-02
I0216 06:15:11.313585 23126066861888 run_lib.py:133] step: 338950, training_loss: 1.80353e-02
I0216 06:15:28.758151 23126066861888 run_lib.py:133] step: 339000, training_loss: 1.78761e-02
I0216 06:15:28.917945 23126066861888 run_lib.py:146] step: 339000, eval_loss: 2.75679e-02
I0216 06:15:46.271514 23126066861888 run_lib.py:133] step: 339050, training_loss: 1.79166e-02
I0216 06:16:03.649171 23126066861888 run_lib.py:133] step: 339100, training_loss: 1.80508e-02
I0216 06:16:03.813166 23126066861888 run_lib.py:146] step: 339100, eval_loss: 2.71810e-02
I0216 06:16:21.361461 23126066861888 run_lib.py:133] step: 339150, training_loss: 1.78085e-02
I0216 06:16:38.679205 23126066861888 run_lib.py:133] step: 339200, training_loss: 1.81910e-02
I0216 06:16:38.831849 23126066861888 run_lib.py:146] step: 339200, eval_loss: 2.78454e-02
I0216 06:16:56.132911 23126066861888 run_lib.py:133] step: 339250, training_loss: 1.80492e-02
I0216 06:17:13.637481 23126066861888 run_lib.py:133] step: 339300, training_loss: 1.83151e-02
I0216 06:17:13.791135 23126066861888 run_lib.py:146] step: 339300, eval_loss: 2.67753e-02
I0216 06:17:31.179694 23126066861888 run_lib.py:133] step: 339350, training_loss: 1.76328e-02
I0216 06:17:48.491238 23126066861888 run_lib.py:133] step: 339400, training_loss: 1.84857e-02
I0216 06:17:48.646969 23126066861888 run_lib.py:146] step: 339400, eval_loss: 2.70081e-02
I0216 06:18:06.040213 23126066861888 run_lib.py:133] step: 339450, training_loss: 1.77752e-02
I0216 06:18:23.314621 23126066861888 run_lib.py:133] step: 339500, training_loss: 1.75774e-02
I0216 06:18:23.476194 23126066861888 run_lib.py:146] step: 339500, eval_loss: 2.67322e-02
I0216 06:18:40.802820 23126066861888 run_lib.py:133] step: 339550, training_loss: 1.70073e-02
I0216 06:18:58.054431 23126066861888 run_lib.py:133] step: 339600, training_loss: 1.83445e-02
I0216 06:18:58.211841 23126066861888 run_lib.py:146] step: 339600, eval_loss: 2.71711e-02
I0216 06:19:15.743224 23126066861888 run_lib.py:133] step: 339650, training_loss: 1.78035e-02
I0216 06:19:33.198595 23126066861888 run_lib.py:133] step: 339700, training_loss: 1.81695e-02
I0216 06:19:33.352126 23126066861888 run_lib.py:146] step: 339700, eval_loss: 2.87156e-02
I0216 06:19:50.658430 23126066861888 run_lib.py:133] step: 339750, training_loss: 1.84015e-02
I0216 06:20:07.978425 23126066861888 run_lib.py:133] step: 339800, training_loss: 1.82676e-02
I0216 06:20:08.128885 23126066861888 run_lib.py:146] step: 339800, eval_loss: 2.69928e-02
I0216 06:20:25.570597 23126066861888 run_lib.py:133] step: 339850, training_loss: 1.82753e-02
I0216 06:20:42.909473 23126066861888 run_lib.py:133] step: 339900, training_loss: 1.80923e-02
I0216 06:20:43.087953 23126066861888 run_lib.py:146] step: 339900, eval_loss: 2.84179e-02
I0216 06:21:00.419841 23126066861888 run_lib.py:133] step: 339950, training_loss: 1.80485e-02
I0216 06:21:17.960668 23126066861888 run_lib.py:133] step: 340000, training_loss: 1.86123e-02
I0216 06:21:18.632747 23126066861888 run_lib.py:146] step: 340000, eval_loss: 2.81899e-02
I0216 06:21:38.570433 23126066861888 run_lib.py:133] step: 340050, training_loss: 1.86596e-02
I0216 06:21:55.878873 23126066861888 run_lib.py:133] step: 340100, training_loss: 1.78526e-02
I0216 06:21:56.033997 23126066861888 run_lib.py:146] step: 340100, eval_loss: 2.78087e-02
I0216 06:22:13.475081 23126066861888 run_lib.py:133] step: 340150, training_loss: 1.81897e-02
I0216 06:22:31.037095 23126066861888 run_lib.py:133] step: 340200, training_loss: 1.84970e-02
I0216 06:22:31.194396 23126066861888 run_lib.py:146] step: 340200, eval_loss: 2.81110e-02
I0216 06:22:48.608978 23126066861888 run_lib.py:133] step: 340250, training_loss: 1.82470e-02
I0216 06:23:05.982416 23126066861888 run_lib.py:133] step: 340300, training_loss: 1.82236e-02
I0216 06:23:06.140043 23126066861888 run_lib.py:146] step: 340300, eval_loss: 2.78835e-02
I0216 06:23:23.698773 23126066861888 run_lib.py:133] step: 340350, training_loss: 1.76426e-02
I0216 06:23:41.007500 23126066861888 run_lib.py:133] step: 340400, training_loss: 1.76979e-02
I0216 06:23:41.162948 23126066861888 run_lib.py:146] step: 340400, eval_loss: 2.82502e-02
I0216 06:23:58.643093 23126066861888 run_lib.py:133] step: 340450, training_loss: 1.82062e-02
I0216 06:24:16.040652 23126066861888 run_lib.py:133] step: 340500, training_loss: 1.74318e-02
I0216 06:24:16.204567 23126066861888 run_lib.py:146] step: 340500, eval_loss: 2.78360e-02
I0216 06:24:33.501663 23126066861888 run_lib.py:133] step: 340550, training_loss: 1.81595e-02
I0216 06:24:51.018268 23126066861888 run_lib.py:133] step: 340600, training_loss: 1.78409e-02
I0216 06:24:51.171793 23126066861888 run_lib.py:146] step: 340600, eval_loss: 2.71502e-02
I0216 06:25:08.485204 23126066861888 run_lib.py:133] step: 340650, training_loss: 1.76119e-02
I0216 06:25:25.753684 23126066861888 run_lib.py:133] step: 340700, training_loss: 1.76052e-02
I0216 06:25:25.907944 23126066861888 run_lib.py:146] step: 340700, eval_loss: 2.74232e-02
I0216 06:25:43.370584 23126066861888 run_lib.py:133] step: 340750, training_loss: 1.77785e-02
I0216 06:26:00.784934 23126066861888 run_lib.py:133] step: 340800, training_loss: 1.72736e-02
I0216 06:26:00.944292 23126066861888 run_lib.py:146] step: 340800, eval_loss: 2.85274e-02
I0216 06:26:18.450206 23126066861888 run_lib.py:133] step: 340850, training_loss: 1.82832e-02
I0216 06:26:35.780366 23126066861888 run_lib.py:133] step: 340900, training_loss: 1.81944e-02
I0216 06:26:35.935980 23126066861888 run_lib.py:146] step: 340900, eval_loss: 2.74376e-02
I0216 06:26:53.291175 23126066861888 run_lib.py:133] step: 340950, training_loss: 1.78885e-02
I0216 06:27:10.734798 23126066861888 run_lib.py:133] step: 341000, training_loss: 1.87305e-02
I0216 06:27:10.907782 23126066861888 run_lib.py:146] step: 341000, eval_loss: 2.81344e-02
I0216 06:27:28.306314 23126066861888 run_lib.py:133] step: 341050, training_loss: 1.77092e-02
I0216 06:27:45.674121 23126066861888 run_lib.py:133] step: 341100, training_loss: 1.86888e-02
I0216 06:27:45.829337 23126066861888 run_lib.py:146] step: 341100, eval_loss: 2.80941e-02
I0216 06:28:03.146991 23126066861888 run_lib.py:133] step: 341150, training_loss: 1.81468e-02
I0216 06:28:20.450275 23126066861888 run_lib.py:133] step: 341200, training_loss: 1.79099e-02
I0216 06:28:20.604918 23126066861888 run_lib.py:146] step: 341200, eval_loss: 2.87191e-02
I0216 06:28:38.092196 23126066861888 run_lib.py:133] step: 341250, training_loss: 1.81575e-02
I0216 06:28:55.508191 23126066861888 run_lib.py:133] step: 341300, training_loss: 1.81963e-02
I0216 06:28:55.663077 23126066861888 run_lib.py:146] step: 341300, eval_loss: 2.68716e-02
I0216 06:29:13.018051 23126066861888 run_lib.py:133] step: 341350, training_loss: 1.79071e-02
I0216 06:29:30.341629 23126066861888 run_lib.py:133] step: 341400, training_loss: 1.77321e-02
I0216 06:29:30.496135 23126066861888 run_lib.py:146] step: 341400, eval_loss: 2.89366e-02
I0216 06:29:47.974810 23126066861888 run_lib.py:133] step: 341450, training_loss: 1.80614e-02
I0216 06:30:05.310466 23126066861888 run_lib.py:133] step: 341500, training_loss: 1.79820e-02
I0216 06:30:05.464063 23126066861888 run_lib.py:146] step: 341500, eval_loss: 2.80619e-02
I0216 06:30:22.953410 23126066861888 run_lib.py:133] step: 341550, training_loss: 1.87084e-02
I0216 06:30:40.306727 23126066861888 run_lib.py:133] step: 341600, training_loss: 1.84033e-02
I0216 06:30:40.462782 23126066861888 run_lib.py:146] step: 341600, eval_loss: 2.72631e-02
I0216 06:30:57.817859 23126066861888 run_lib.py:133] step: 341650, training_loss: 1.82959e-02
I0216 06:31:15.346098 23126066861888 run_lib.py:133] step: 341700, training_loss: 1.85773e-02
I0216 06:31:15.496834 23126066861888 run_lib.py:146] step: 341700, eval_loss: 2.71708e-02
I0216 06:31:32.801530 23126066861888 run_lib.py:133] step: 341750, training_loss: 1.78520e-02
I0216 06:31:50.205557 23126066861888 run_lib.py:133] step: 341800, training_loss: 1.86325e-02
I0216 06:31:50.359989 23126066861888 run_lib.py:146] step: 341800, eval_loss: 2.82300e-02
I0216 06:32:07.960024 23126066861888 run_lib.py:133] step: 341850, training_loss: 1.81253e-02
I0216 06:32:25.320187 23126066861888 run_lib.py:133] step: 341900, training_loss: 1.77396e-02
I0216 06:32:25.495030 23126066861888 run_lib.py:146] step: 341900, eval_loss: 2.83200e-02
I0216 06:32:42.872973 23126066861888 run_lib.py:133] step: 341950, training_loss: 1.73006e-02
I0216 06:33:00.432003 23126066861888 run_lib.py:133] step: 342000, training_loss: 1.84800e-02
I0216 06:33:00.589106 23126066861888 run_lib.py:146] step: 342000, eval_loss: 2.79306e-02
I0216 06:33:17.958672 23126066861888 run_lib.py:133] step: 342050, training_loss: 1.81337e-02
I0216 06:33:35.261538 23126066861888 run_lib.py:133] step: 342100, training_loss: 1.74645e-02
I0216 06:33:35.415648 23126066861888 run_lib.py:146] step: 342100, eval_loss: 2.62336e-02
I0216 06:33:52.839034 23126066861888 run_lib.py:133] step: 342150, training_loss: 1.82360e-02
I0216 06:34:10.190818 23126066861888 run_lib.py:133] step: 342200, training_loss: 1.74253e-02
I0216 06:34:10.344683 23126066861888 run_lib.py:146] step: 342200, eval_loss: 2.69230e-02
I0216 06:34:27.674889 23126066861888 run_lib.py:133] step: 342250, training_loss: 1.77487e-02
I0216 06:34:45.034367 23126066861888 run_lib.py:133] step: 342300, training_loss: 1.81322e-02
I0216 06:34:45.188761 23126066861888 run_lib.py:146] step: 342300, eval_loss: 2.86847e-02
I0216 06:35:02.692503 23126066861888 run_lib.py:133] step: 342350, training_loss: 1.81632e-02
I0216 06:35:20.098230 23126066861888 run_lib.py:133] step: 342400, training_loss: 1.79800e-02
I0216 06:35:20.267817 23126066861888 run_lib.py:146] step: 342400, eval_loss: 2.62431e-02
I0216 06:35:37.684800 23126066861888 run_lib.py:133] step: 342450, training_loss: 1.78141e-02
I0216 06:35:55.055263 23126066861888 run_lib.py:133] step: 342500, training_loss: 1.82285e-02
I0216 06:35:55.211153 23126066861888 run_lib.py:146] step: 342500, eval_loss: 2.67574e-02
I0216 06:36:12.716212 23126066861888 run_lib.py:133] step: 342550, training_loss: 1.82645e-02
I0216 06:36:29.998939 23126066861888 run_lib.py:133] step: 342600, training_loss: 1.81298e-02
I0216 06:36:30.152977 23126066861888 run_lib.py:146] step: 342600, eval_loss: 2.71993e-02
I0216 06:36:47.452789 23126066861888 run_lib.py:133] step: 342650, training_loss: 1.79138e-02
I0216 06:37:04.957416 23126066861888 run_lib.py:133] step: 342700, training_loss: 1.79246e-02
I0216 06:37:05.112167 23126066861888 run_lib.py:146] step: 342700, eval_loss: 2.76684e-02
I0216 06:37:22.494585 23126066861888 run_lib.py:133] step: 342750, training_loss: 1.78877e-02
I0216 06:37:39.969026 23126066861888 run_lib.py:133] step: 342800, training_loss: 1.80006e-02
I0216 06:37:40.147908 23126066861888 run_lib.py:146] step: 342800, eval_loss: 2.77942e-02
I0216 06:37:57.462399 23126066861888 run_lib.py:133] step: 342850, training_loss: 1.74069e-02
I0216 06:38:14.767885 23126066861888 run_lib.py:133] step: 342900, training_loss: 1.86240e-02
I0216 06:38:14.926183 23126066861888 run_lib.py:146] step: 342900, eval_loss: 2.81609e-02
I0216 06:38:32.431617 23126066861888 run_lib.py:133] step: 342950, training_loss: 1.80478e-02
I0216 06:38:49.757824 23126066861888 run_lib.py:133] step: 343000, training_loss: 1.76011e-02
I0216 06:38:49.914175 23126066861888 run_lib.py:146] step: 343000, eval_loss: 2.74225e-02
I0216 06:39:07.235239 23126066861888 run_lib.py:133] step: 343050, training_loss: 1.80979e-02
I0216 06:39:24.770754 23126066861888 run_lib.py:133] step: 343100, training_loss: 1.76527e-02
I0216 06:39:24.932839 23126066861888 run_lib.py:146] step: 343100, eval_loss: 2.80673e-02
I0216 06:39:42.223055 23126066861888 run_lib.py:133] step: 343150, training_loss: 1.81242e-02
I0216 06:39:59.536910 23126066861888 run_lib.py:133] step: 343200, training_loss: 1.80606e-02
I0216 06:39:59.687960 23126066861888 run_lib.py:146] step: 343200, eval_loss: 2.72505e-02
I0216 06:40:17.100492 23126066861888 run_lib.py:133] step: 343250, training_loss: 1.78870e-02
I0216 06:40:34.461372 23126066861888 run_lib.py:133] step: 343300, training_loss: 1.86670e-02
I0216 06:40:34.650871 23126066861888 run_lib.py:146] step: 343300, eval_loss: 2.81557e-02
I0216 06:40:52.025995 23126066861888 run_lib.py:133] step: 343350, training_loss: 1.93009e-02
I0216 06:41:09.374698 23126066861888 run_lib.py:133] step: 343400, training_loss: 1.77033e-02
I0216 06:41:09.534267 23126066861888 run_lib.py:146] step: 343400, eval_loss: 2.79369e-02
I0216 06:41:27.177419 23126066861888 run_lib.py:133] step: 343450, training_loss: 1.82524e-02
I0216 06:41:44.642260 23126066861888 run_lib.py:133] step: 343500, training_loss: 1.76427e-02
I0216 06:41:44.798110 23126066861888 run_lib.py:146] step: 343500, eval_loss: 2.81696e-02
I0216 06:42:02.170173 23126066861888 run_lib.py:133] step: 343550, training_loss: 1.89879e-02
I0216 06:42:19.523698 23126066861888 run_lib.py:133] step: 343600, training_loss: 1.75873e-02
I0216 06:42:19.681298 23126066861888 run_lib.py:146] step: 343600, eval_loss: 2.72032e-02
I0216 06:42:37.241439 23126066861888 run_lib.py:133] step: 343650, training_loss: 1.76197e-02
I0216 06:42:54.536775 23126066861888 run_lib.py:133] step: 343700, training_loss: 1.76993e-02
I0216 06:42:54.689792 23126066861888 run_lib.py:146] step: 343700, eval_loss: 2.65363e-02
I0216 06:43:12.006963 23126066861888 run_lib.py:133] step: 343750, training_loss: 1.83544e-02
I0216 06:43:29.501040 23126066861888 run_lib.py:133] step: 343800, training_loss: 1.78596e-02
I0216 06:43:29.658172 23126066861888 run_lib.py:146] step: 343800, eval_loss: 2.83334e-02
I0216 06:43:46.995376 23126066861888 run_lib.py:133] step: 343850, training_loss: 1.84500e-02
I0216 06:44:04.473276 23126066861888 run_lib.py:133] step: 343900, training_loss: 1.70450e-02
I0216 06:44:04.630194 23126066861888 run_lib.py:146] step: 343900, eval_loss: 2.89576e-02
I0216 06:44:21.956093 23126066861888 run_lib.py:133] step: 343950, training_loss: 1.80648e-02
I0216 06:44:39.267646 23126066861888 run_lib.py:133] step: 344000, training_loss: 1.81495e-02
I0216 06:44:39.423982 23126066861888 run_lib.py:146] step: 344000, eval_loss: 2.77334e-02
I0216 06:44:56.984436 23126066861888 run_lib.py:133] step: 344050, training_loss: 1.85017e-02
I0216 06:45:14.272055 23126066861888 run_lib.py:133] step: 344100, training_loss: 1.81632e-02
I0216 06:45:14.421981 23126066861888 run_lib.py:146] step: 344100, eval_loss: 2.85209e-02
I0216 06:45:31.708306 23126066861888 run_lib.py:133] step: 344150, training_loss: 1.75316e-02
I0216 06:45:49.248317 23126066861888 run_lib.py:133] step: 344200, training_loss: 1.80359e-02
I0216 06:45:49.415070 23126066861888 run_lib.py:146] step: 344200, eval_loss: 2.76952e-02
I0216 06:46:06.805462 23126066861888 run_lib.py:133] step: 344250, training_loss: 1.77896e-02
I0216 06:46:24.156103 23126066861888 run_lib.py:133] step: 344300, training_loss: 1.75649e-02
I0216 06:46:24.314291 23126066861888 run_lib.py:146] step: 344300, eval_loss: 2.87404e-02
I0216 06:46:41.714387 23126066861888 run_lib.py:133] step: 344350, training_loss: 1.84349e-02
I0216 06:46:59.021641 23126066861888 run_lib.py:133] step: 344400, training_loss: 1.80765e-02
I0216 06:46:59.191940 23126066861888 run_lib.py:146] step: 344400, eval_loss: 2.70615e-02
I0216 06:47:16.475257 23126066861888 run_lib.py:133] step: 344450, training_loss: 1.73000e-02
I0216 06:47:33.854476 23126066861888 run_lib.py:133] step: 344500, training_loss: 1.84881e-02
I0216 06:47:34.019146 23126066861888 run_lib.py:146] step: 344500, eval_loss: 2.87630e-02
I0216 06:47:51.536411 23126066861888 run_lib.py:133] step: 344550, training_loss: 1.75655e-02
I0216 06:48:08.902430 23126066861888 run_lib.py:133] step: 344600, training_loss: 1.86259e-02
I0216 06:48:09.052908 23126066861888 run_lib.py:146] step: 344600, eval_loss: 2.82754e-02
I0216 06:48:26.390224 23126066861888 run_lib.py:133] step: 344650, training_loss: 1.77985e-02
I0216 06:48:43.751706 23126066861888 run_lib.py:133] step: 344700, training_loss: 1.72653e-02
I0216 06:48:43.905920 23126066861888 run_lib.py:146] step: 344700, eval_loss: 2.81807e-02
I0216 06:49:01.417542 23126066861888 run_lib.py:133] step: 344750, training_loss: 1.92319e-02
I0216 06:49:18.790235 23126066861888 run_lib.py:133] step: 344800, training_loss: 1.87448e-02
I0216 06:49:18.948896 23126066861888 run_lib.py:146] step: 344800, eval_loss: 2.76049e-02
I0216 06:49:36.219532 23126066861888 run_lib.py:133] step: 344850, training_loss: 1.78907e-02
I0216 06:49:53.766987 23126066861888 run_lib.py:133] step: 344900, training_loss: 1.83957e-02
I0216 06:49:53.921900 23126066861888 run_lib.py:146] step: 344900, eval_loss: 2.83661e-02
I0216 06:50:11.243274 23126066861888 run_lib.py:133] step: 344950, training_loss: 1.85804e-02
I0216 06:50:28.693019 23126066861888 run_lib.py:133] step: 345000, training_loss: 1.80096e-02
I0216 06:50:28.849301 23126066861888 run_lib.py:146] step: 345000, eval_loss: 2.87828e-02
I0216 06:50:46.332921 23126066861888 run_lib.py:133] step: 345050, training_loss: 1.78468e-02
I0216 06:51:03.763401 23126066861888 run_lib.py:133] step: 345100, training_loss: 1.87336e-02
I0216 06:51:03.918112 23126066861888 run_lib.py:146] step: 345100, eval_loss: 2.75383e-02
I0216 06:51:21.497852 23126066861888 run_lib.py:133] step: 345150, training_loss: 1.76696e-02
I0216 06:51:38.804061 23126066861888 run_lib.py:133] step: 345200, training_loss: 1.80216e-02
I0216 06:51:38.961133 23126066861888 run_lib.py:146] step: 345200, eval_loss: 2.78348e-02
I0216 06:51:56.239682 23126066861888 run_lib.py:133] step: 345250, training_loss: 1.77556e-02
I0216 06:52:13.763501 23126066861888 run_lib.py:133] step: 345300, training_loss: 1.81666e-02
I0216 06:52:13.936052 23126066861888 run_lib.py:146] step: 345300, eval_loss: 2.81762e-02
I0216 06:52:31.292857 23126066861888 run_lib.py:133] step: 345350, training_loss: 1.78995e-02
I0216 06:52:48.628545 23126066861888 run_lib.py:133] step: 345400, training_loss: 1.81719e-02
I0216 06:52:48.782609 23126066861888 run_lib.py:146] step: 345400, eval_loss: 2.77030e-02
I0216 06:53:06.265722 23126066861888 run_lib.py:133] step: 345450, training_loss: 1.79205e-02
I0216 06:53:23.598417 23126066861888 run_lib.py:133] step: 345500, training_loss: 1.74647e-02
I0216 06:53:23.749750 23126066861888 run_lib.py:146] step: 345500, eval_loss: 2.81314e-02
I0216 06:53:41.027075 23126066861888 run_lib.py:133] step: 345550, training_loss: 1.79966e-02
I0216 06:53:58.344500 23126066861888 run_lib.py:133] step: 345600, training_loss: 1.80223e-02
I0216 06:53:58.514901 23126066861888 run_lib.py:146] step: 345600, eval_loss: 2.70807e-02
I0216 06:54:16.089042 23126066861888 run_lib.py:133] step: 345650, training_loss: 1.80500e-02
I0216 06:54:33.518524 23126066861888 run_lib.py:133] step: 345700, training_loss: 1.72757e-02
I0216 06:54:33.675132 23126066861888 run_lib.py:146] step: 345700, eval_loss: 2.71887e-02
I0216 06:54:50.977708 23126066861888 run_lib.py:133] step: 345750, training_loss: 1.87760e-02
I0216 06:55:08.231462 23126066861888 run_lib.py:133] step: 345800, training_loss: 1.77369e-02
I0216 06:55:08.384951 23126066861888 run_lib.py:146] step: 345800, eval_loss: 2.80992e-02
I0216 06:55:25.864467 23126066861888 run_lib.py:133] step: 345850, training_loss: 1.80510e-02
I0216 06:55:43.220489 23126066861888 run_lib.py:133] step: 345900, training_loss: 1.81673e-02
I0216 06:55:43.374252 23126066861888 run_lib.py:146] step: 345900, eval_loss: 2.78499e-02
I0216 06:56:00.699920 23126066861888 run_lib.py:133] step: 345950, training_loss: 1.73565e-02
I0216 06:56:18.210531 23126066861888 run_lib.py:133] step: 346000, training_loss: 1.82225e-02
I0216 06:56:18.380393 23126066861888 run_lib.py:146] step: 346000, eval_loss: 2.86473e-02
I0216 06:56:35.731126 23126066861888 run_lib.py:133] step: 346050, training_loss: 1.81361e-02
I0216 06:56:53.246203 23126066861888 run_lib.py:133] step: 346100, training_loss: 1.81081e-02
I0216 06:56:53.406177 23126066861888 run_lib.py:146] step: 346100, eval_loss: 2.64602e-02
I0216 06:57:10.720926 23126066861888 run_lib.py:133] step: 346150, training_loss: 1.74744e-02
I0216 06:57:28.119547 23126066861888 run_lib.py:133] step: 346200, training_loss: 1.85617e-02
I0216 06:57:28.275789 23126066861888 run_lib.py:146] step: 346200, eval_loss: 2.84603e-02
I0216 06:57:45.809091 23126066861888 run_lib.py:133] step: 346250, training_loss: 1.80400e-02
I0216 06:58:03.113477 23126066861888 run_lib.py:133] step: 346300, training_loss: 1.81449e-02
I0216 06:58:03.266824 23126066861888 run_lib.py:146] step: 346300, eval_loss: 2.94016e-02
I0216 06:58:20.573575 23126066861888 run_lib.py:133] step: 346350, training_loss: 1.83160e-02
I0216 06:58:38.022804 23126066861888 run_lib.py:133] step: 346400, training_loss: 1.84019e-02
I0216 06:58:38.178437 23126066861888 run_lib.py:146] step: 346400, eval_loss: 2.80067e-02
I0216 06:58:55.594167 23126066861888 run_lib.py:133] step: 346450, training_loss: 1.84181e-02
I0216 06:59:12.912782 23126066861888 run_lib.py:133] step: 346500, training_loss: 1.82352e-02
I0216 06:59:13.065272 23126066861888 run_lib.py:146] step: 346500, eval_loss: 2.85541e-02
I0216 06:59:30.463759 23126066861888 run_lib.py:133] step: 346550, training_loss: 1.80336e-02
I0216 06:59:47.765625 23126066861888 run_lib.py:133] step: 346600, training_loss: 1.80886e-02
I0216 06:59:47.918465 23126066861888 run_lib.py:146] step: 346600, eval_loss: 2.74785e-02
I0216 07:00:05.308073 23126066861888 run_lib.py:133] step: 346650, training_loss: 1.83365e-02
I0216 07:00:22.732007 23126066861888 run_lib.py:133] step: 346700, training_loss: 1.86303e-02
I0216 07:00:22.905918 23126066861888 run_lib.py:146] step: 346700, eval_loss: 2.66593e-02
I0216 07:00:40.497812 23126066861888 run_lib.py:133] step: 346750, training_loss: 1.83338e-02
I0216 07:00:57.953862 23126066861888 run_lib.py:133] step: 346800, training_loss: 1.80734e-02
I0216 07:00:58.110219 23126066861888 run_lib.py:146] step: 346800, eval_loss: 2.83519e-02
I0216 07:01:15.432467 23126066861888 run_lib.py:133] step: 346850, training_loss: 1.86426e-02
I0216 07:01:32.741473 23126066861888 run_lib.py:133] step: 346900, training_loss: 1.83569e-02
I0216 07:01:32.894742 23126066861888 run_lib.py:146] step: 346900, eval_loss: 2.81504e-02
I0216 07:01:50.370435 23126066861888 run_lib.py:133] step: 346950, training_loss: 1.68429e-02
I0216 07:02:07.698286 23126066861888 run_lib.py:133] step: 347000, training_loss: 1.86547e-02
I0216 07:02:07.852136 23126066861888 run_lib.py:146] step: 347000, eval_loss: 2.85515e-02
I0216 07:02:25.216979 23126066861888 run_lib.py:133] step: 347050, training_loss: 1.81969e-02
I0216 07:02:42.770657 23126066861888 run_lib.py:133] step: 347100, training_loss: 1.82238e-02
I0216 07:02:42.926872 23126066861888 run_lib.py:146] step: 347100, eval_loss: 2.83952e-02
I0216 07:03:00.236585 23126066861888 run_lib.py:133] step: 347150, training_loss: 1.79747e-02
I0216 07:03:17.678465 23126066861888 run_lib.py:133] step: 347200, training_loss: 1.79985e-02
I0216 07:03:17.833935 23126066861888 run_lib.py:146] step: 347200, eval_loss: 2.68929e-02
I0216 07:03:35.168216 23126066861888 run_lib.py:133] step: 347250, training_loss: 1.87595e-02
I0216 07:03:52.476933 23126066861888 run_lib.py:133] step: 347300, training_loss: 1.86475e-02
I0216 07:03:52.644781 23126066861888 run_lib.py:146] step: 347300, eval_loss: 2.80664e-02
I0216 07:04:10.161793 23126066861888 run_lib.py:133] step: 347350, training_loss: 1.84774e-02
I0216 07:04:27.473813 23126066861888 run_lib.py:133] step: 347400, training_loss: 1.87243e-02
I0216 07:04:27.628947 23126066861888 run_lib.py:146] step: 347400, eval_loss: 2.72165e-02
I0216 07:04:44.955021 23126066861888 run_lib.py:133] step: 347450, training_loss: 1.74878e-02
I0216 07:05:02.454449 23126066861888 run_lib.py:133] step: 347500, training_loss: 1.80937e-02
I0216 07:05:02.607843 23126066861888 run_lib.py:146] step: 347500, eval_loss: 2.74469e-02
I0216 07:05:19.915401 23126066861888 run_lib.py:133] step: 347550, training_loss: 1.80878e-02
I0216 07:05:37.208914 23126066861888 run_lib.py:133] step: 347600, training_loss: 1.81087e-02
I0216 07:05:37.404002 23126066861888 run_lib.py:146] step: 347600, eval_loss: 2.70924e-02
I0216 07:05:54.897460 23126066861888 run_lib.py:133] step: 347650, training_loss: 1.77694e-02
I0216 07:06:12.201951 23126066861888 run_lib.py:133] step: 347700, training_loss: 1.80291e-02
I0216 07:06:12.374938 23126066861888 run_lib.py:146] step: 347700, eval_loss: 2.84064e-02
I0216 07:06:29.694569 23126066861888 run_lib.py:133] step: 347750, training_loss: 1.79233e-02
I0216 07:06:46.975929 23126066861888 run_lib.py:133] step: 347800, training_loss: 1.80839e-02
I0216 07:06:47.130895 23126066861888 run_lib.py:146] step: 347800, eval_loss: 2.73840e-02
I0216 07:07:04.665477 23126066861888 run_lib.py:133] step: 347850, training_loss: 1.81755e-02
I0216 07:07:22.086874 23126066861888 run_lib.py:133] step: 347900, training_loss: 1.82045e-02
I0216 07:07:22.238200 23126066861888 run_lib.py:146] step: 347900, eval_loss: 2.75672e-02
I0216 07:07:39.630433 23126066861888 run_lib.py:133] step: 347950, training_loss: 1.77711e-02
I0216 07:07:56.946715 23126066861888 run_lib.py:133] step: 348000, training_loss: 1.80313e-02
I0216 07:07:57.102964 23126066861888 run_lib.py:146] step: 348000, eval_loss: 2.87111e-02
I0216 07:08:14.631425 23126066861888 run_lib.py:133] step: 348050, training_loss: 1.86149e-02
I0216 07:08:31.997364 23126066861888 run_lib.py:133] step: 348100, training_loss: 1.77358e-02
I0216 07:08:32.155141 23126066861888 run_lib.py:146] step: 348100, eval_loss: 2.78306e-02
I0216 07:08:49.436670 23126066861888 run_lib.py:133] step: 348150, training_loss: 1.81899e-02
I0216 07:09:06.899146 23126066861888 run_lib.py:133] step: 348200, training_loss: 1.80577e-02
I0216 07:09:07.066807 23126066861888 run_lib.py:146] step: 348200, eval_loss: 2.66668e-02
I0216 07:09:24.434507 23126066861888 run_lib.py:133] step: 348250, training_loss: 1.87445e-02
I0216 07:09:42.077373 23126066861888 run_lib.py:133] step: 348300, training_loss: 1.80784e-02
I0216 07:09:42.232374 23126066861888 run_lib.py:146] step: 348300, eval_loss: 2.90092e-02
I0216 07:09:59.615135 23126066861888 run_lib.py:133] step: 348350, training_loss: 1.71846e-02
I0216 07:10:16.994376 23126066861888 run_lib.py:133] step: 348400, training_loss: 1.82725e-02
I0216 07:10:17.146877 23126066861888 run_lib.py:146] step: 348400, eval_loss: 2.79834e-02
I0216 07:10:34.616302 23126066861888 run_lib.py:133] step: 348450, training_loss: 1.78694e-02
I0216 07:10:51.984600 23126066861888 run_lib.py:133] step: 348500, training_loss: 1.81300e-02
I0216 07:10:52.159854 23126066861888 run_lib.py:146] step: 348500, eval_loss: 2.78793e-02
I0216 07:11:09.531701 23126066861888 run_lib.py:133] step: 348550, training_loss: 1.85366e-02
I0216 07:11:27.072620 23126066861888 run_lib.py:133] step: 348600, training_loss: 1.84075e-02
I0216 07:11:27.229237 23126066861888 run_lib.py:146] step: 348600, eval_loss: 2.84196e-02
I0216 07:11:44.535383 23126066861888 run_lib.py:133] step: 348650, training_loss: 1.75591e-02
I0216 07:12:01.855209 23126066861888 run_lib.py:133] step: 348700, training_loss: 1.81331e-02
I0216 07:12:02.013019 23126066861888 run_lib.py:146] step: 348700, eval_loss: 2.81236e-02
I0216 07:12:19.386228 23126066861888 run_lib.py:133] step: 348750, training_loss: 1.74297e-02
I0216 07:12:36.768872 23126066861888 run_lib.py:133] step: 348800, training_loss: 1.86497e-02
I0216 07:12:36.922740 23126066861888 run_lib.py:146] step: 348800, eval_loss: 2.81191e-02
I0216 07:12:54.309637 23126066861888 run_lib.py:133] step: 348850, training_loss: 1.82063e-02
I0216 07:13:11.607524 23126066861888 run_lib.py:133] step: 348900, training_loss: 1.80840e-02
I0216 07:13:11.759850 23126066861888 run_lib.py:146] step: 348900, eval_loss: 2.74047e-02
I0216 07:13:29.233323 23126066861888 run_lib.py:133] step: 348950, training_loss: 1.77940e-02
I0216 07:13:46.613738 23126066861888 run_lib.py:133] step: 349000, training_loss: 1.82668e-02
I0216 07:13:46.778228 23126066861888 run_lib.py:146] step: 349000, eval_loss: 2.80571e-02
I0216 07:14:04.105724 23126066861888 run_lib.py:133] step: 349050, training_loss: 1.82016e-02
I0216 07:14:21.493040 23126066861888 run_lib.py:133] step: 349100, training_loss: 1.90415e-02
I0216 07:14:21.649234 23126066861888 run_lib.py:146] step: 349100, eval_loss: 2.79160e-02
I0216 07:14:39.185797 23126066861888 run_lib.py:133] step: 349150, training_loss: 1.83354e-02
I0216 07:14:56.523151 23126066861888 run_lib.py:133] step: 349200, training_loss: 1.78266e-02
I0216 07:14:56.716127 23126066861888 run_lib.py:146] step: 349200, eval_loss: 2.75147e-02
I0216 07:15:14.053021 23126066861888 run_lib.py:133] step: 349250, training_loss: 1.79235e-02
I0216 07:15:31.536720 23126066861888 run_lib.py:133] step: 349300, training_loss: 1.75452e-02
I0216 07:15:31.690676 23126066861888 run_lib.py:146] step: 349300, eval_loss: 2.76729e-02
I0216 07:15:49.009659 23126066861888 run_lib.py:133] step: 349350, training_loss: 1.80714e-02
I0216 07:16:06.539346 23126066861888 run_lib.py:133] step: 349400, training_loss: 1.83024e-02
I0216 07:16:06.703234 23126066861888 run_lib.py:146] step: 349400, eval_loss: 2.68928e-02
I0216 07:16:23.990132 23126066861888 run_lib.py:133] step: 349450, training_loss: 1.79300e-02
I0216 07:16:41.308500 23126066861888 run_lib.py:133] step: 349500, training_loss: 1.74583e-02
I0216 07:16:41.467238 23126066861888 run_lib.py:146] step: 349500, eval_loss: 2.73720e-02
I0216 07:16:58.935792 23126066861888 run_lib.py:133] step: 349550, training_loss: 1.77432e-02
I0216 07:17:16.252097 23126066861888 run_lib.py:133] step: 349600, training_loss: 1.78533e-02
I0216 07:17:16.418967 23126066861888 run_lib.py:146] step: 349600, eval_loss: 2.77998e-02
I0216 07:17:33.729800 23126066861888 run_lib.py:133] step: 349650, training_loss: 1.73489e-02
I0216 07:17:51.294651 23126066861888 run_lib.py:133] step: 349700, training_loss: 1.74897e-02
I0216 07:17:51.448669 23126066861888 run_lib.py:146] step: 349700, eval_loss: 2.96989e-02
I0216 07:18:08.829462 23126066861888 run_lib.py:133] step: 349750, training_loss: 1.87469e-02
I0216 07:18:26.131505 23126066861888 run_lib.py:133] step: 349800, training_loss: 1.79041e-02
I0216 07:18:26.290038 23126066861888 run_lib.py:146] step: 349800, eval_loss: 2.81074e-02
I0216 07:18:43.658941 23126066861888 run_lib.py:133] step: 349850, training_loss: 1.80990e-02
I0216 07:19:01.021378 23126066861888 run_lib.py:133] step: 349900, training_loss: 1.81667e-02
I0216 07:19:01.189207 23126066861888 run_lib.py:146] step: 349900, eval_loss: 2.78448e-02
I0216 07:19:18.599500 23126066861888 run_lib.py:133] step: 349950, training_loss: 1.86282e-02
I0216 07:19:36.026793 23126066861888 run_lib.py:133] step: 350000, training_loss: 1.80527e-02
I0216 07:19:36.716863 23126066861888 run_lib.py:146] step: 350000, eval_loss: 2.78461e-02
I0216 07:19:56.757427 23126066861888 run_lib.py:133] step: 350050, training_loss: 1.78621e-02
I0216 07:20:14.055097 23126066861888 run_lib.py:133] step: 350100, training_loss: 1.78691e-02
I0216 07:20:14.211080 23126066861888 run_lib.py:146] step: 350100, eval_loss: 2.74300e-02
I0216 07:20:31.651124 23126066861888 run_lib.py:133] step: 350150, training_loss: 1.77776e-02
I0216 07:20:48.996942 23126066861888 run_lib.py:133] step: 350200, training_loss: 1.81799e-02
I0216 07:20:49.152671 23126066861888 run_lib.py:146] step: 350200, eval_loss: 2.72389e-02
I0216 07:21:06.487946 23126066861888 run_lib.py:133] step: 350250, training_loss: 1.79598e-02
I0216 07:21:23.801300 23126066861888 run_lib.py:133] step: 350300, training_loss: 1.82232e-02
I0216 07:21:23.953946 23126066861888 run_lib.py:146] step: 350300, eval_loss: 2.78126e-02
I0216 07:21:41.468096 23126066861888 run_lib.py:133] step: 350350, training_loss: 1.81894e-02
I0216 07:21:58.874627 23126066861888 run_lib.py:133] step: 350400, training_loss: 1.75807e-02
I0216 07:21:59.026890 23126066861888 run_lib.py:146] step: 350400, eval_loss: 2.85712e-02
I0216 07:22:16.326605 23126066861888 run_lib.py:133] step: 350450, training_loss: 1.80580e-02
I0216 07:22:33.682568 23126066861888 run_lib.py:133] step: 350500, training_loss: 1.77293e-02
I0216 07:22:33.855856 23126066861888 run_lib.py:146] step: 350500, eval_loss: 2.77425e-02
I0216 07:22:51.437296 23126066861888 run_lib.py:133] step: 350550, training_loss: 1.74145e-02
I0216 07:23:08.754314 23126066861888 run_lib.py:133] step: 350600, training_loss: 1.76712e-02
I0216 07:23:08.910284 23126066861888 run_lib.py:146] step: 350600, eval_loss: 2.85091e-02
I0216 07:23:26.223986 23126066861888 run_lib.py:133] step: 350650, training_loss: 1.82277e-02
I0216 07:23:43.667490 23126066861888 run_lib.py:133] step: 350700, training_loss: 1.83456e-02
I0216 07:23:43.824162 23126066861888 run_lib.py:146] step: 350700, eval_loss: 2.75649e-02
I0216 07:24:01.204910 23126066861888 run_lib.py:133] step: 350750, training_loss: 1.83286e-02
I0216 07:24:18.803927 23126066861888 run_lib.py:133] step: 350800, training_loss: 1.79952e-02
I0216 07:24:18.958225 23126066861888 run_lib.py:146] step: 350800, eval_loss: 2.70394e-02
I0216 07:24:36.295112 23126066861888 run_lib.py:133] step: 350850, training_loss: 1.81614e-02
I0216 07:24:53.613239 23126066861888 run_lib.py:133] step: 350900, training_loss: 1.80043e-02
I0216 07:24:53.768860 23126066861888 run_lib.py:146] step: 350900, eval_loss: 2.89758e-02
I0216 07:25:11.270894 23126066861888 run_lib.py:133] step: 350950, training_loss: 1.82101e-02
I0216 07:25:28.596516 23126066861888 run_lib.py:133] step: 351000, training_loss: 1.76246e-02
I0216 07:25:28.761094 23126066861888 run_lib.py:146] step: 351000, eval_loss: 2.88492e-02
I0216 07:25:46.230594 23126066861888 run_lib.py:133] step: 351050, training_loss: 1.78450e-02
I0216 07:26:03.811135 23126066861888 run_lib.py:133] step: 351100, training_loss: 1.80643e-02
I0216 07:26:03.971252 23126066861888 run_lib.py:146] step: 351100, eval_loss: 2.71235e-02
I0216 07:26:21.325982 23126066861888 run_lib.py:133] step: 351150, training_loss: 1.80898e-02
I0216 07:26:38.724014 23126066861888 run_lib.py:133] step: 351200, training_loss: 1.74446e-02
I0216 07:26:38.891041 23126066861888 run_lib.py:146] step: 351200, eval_loss: 2.79353e-02
I0216 07:26:56.403575 23126066861888 run_lib.py:133] step: 351250, training_loss: 1.84566e-02
I0216 07:27:13.715413 23126066861888 run_lib.py:133] step: 351300, training_loss: 1.81936e-02
I0216 07:27:13.872619 23126066861888 run_lib.py:146] step: 351300, eval_loss: 2.79302e-02
I0216 07:27:31.310427 23126066861888 run_lib.py:133] step: 351350, training_loss: 1.77029e-02
I0216 07:27:48.764920 23126066861888 run_lib.py:133] step: 351400, training_loss: 1.81626e-02
I0216 07:27:48.928032 23126066861888 run_lib.py:146] step: 351400, eval_loss: 2.82798e-02
I0216 07:28:06.537312 23126066861888 run_lib.py:133] step: 351450, training_loss: 1.77393e-02
I0216 07:28:23.980814 23126066861888 run_lib.py:133] step: 351500, training_loss: 1.76853e-02
I0216 07:28:24.137424 23126066861888 run_lib.py:146] step: 351500, eval_loss: 2.75561e-02
I0216 07:28:41.422417 23126066861888 run_lib.py:133] step: 351550, training_loss: 1.77658e-02
I0216 07:28:58.707869 23126066861888 run_lib.py:133] step: 351600, training_loss: 1.81569e-02
I0216 07:28:58.867964 23126066861888 run_lib.py:146] step: 351600, eval_loss: 2.83514e-02
I0216 07:29:16.371471 23126066861888 run_lib.py:133] step: 351650, training_loss: 1.86466e-02
I0216 07:29:33.670433 23126066861888 run_lib.py:133] step: 351700, training_loss: 1.73411e-02
I0216 07:29:33.828056 23126066861888 run_lib.py:146] step: 351700, eval_loss: 2.80987e-02
I0216 07:29:51.120534 23126066861888 run_lib.py:133] step: 351750, training_loss: 1.78337e-02
I0216 07:30:08.577415 23126066861888 run_lib.py:133] step: 351800, training_loss: 1.84075e-02
I0216 07:30:08.728859 23126066861888 run_lib.py:146] step: 351800, eval_loss: 2.67575e-02
I0216 07:30:26.025523 23126066861888 run_lib.py:133] step: 351850, training_loss: 1.87675e-02
I0216 07:30:43.458603 23126066861888 run_lib.py:133] step: 351900, training_loss: 1.80168e-02
I0216 07:30:43.631844 23126066861888 run_lib.py:146] step: 351900, eval_loss: 2.77746e-02
I0216 07:31:00.975303 23126066861888 run_lib.py:133] step: 351950, training_loss: 1.83397e-02
I0216 07:31:18.227004 23126066861888 run_lib.py:133] step: 352000, training_loss: 1.82388e-02
I0216 07:31:18.380095 23126066861888 run_lib.py:146] step: 352000, eval_loss: 2.84892e-02
I0216 07:31:35.850084 23126066861888 run_lib.py:133] step: 352050, training_loss: 1.74714e-02
I0216 07:31:53.141668 23126066861888 run_lib.py:133] step: 352100, training_loss: 1.84734e-02
I0216 07:31:53.299773 23126066861888 run_lib.py:146] step: 352100, eval_loss: 2.75659e-02
I0216 07:32:10.640449 23126066861888 run_lib.py:133] step: 352150, training_loss: 1.78097e-02
I0216 07:32:28.142883 23126066861888 run_lib.py:133] step: 352200, training_loss: 1.85491e-02
I0216 07:32:28.296783 23126066861888 run_lib.py:146] step: 352200, eval_loss: 2.84651e-02
I0216 07:32:45.584857 23126066861888 run_lib.py:133] step: 352250, training_loss: 1.83990e-02
I0216 07:33:02.830954 23126066861888 run_lib.py:133] step: 352300, training_loss: 1.83059e-02
I0216 07:33:02.983899 23126066861888 run_lib.py:146] step: 352300, eval_loss: 2.78333e-02
I0216 07:33:20.309535 23126066861888 run_lib.py:133] step: 352350, training_loss: 1.80471e-02
I0216 07:33:37.579267 23126066861888 run_lib.py:133] step: 352400, training_loss: 1.79869e-02
I0216 07:33:37.752906 23126066861888 run_lib.py:146] step: 352400, eval_loss: 2.81397e-02
I0216 07:33:55.029702 23126066861888 run_lib.py:133] step: 352450, training_loss: 1.76320e-02
I0216 07:34:12.335186 23126066861888 run_lib.py:133] step: 352500, training_loss: 1.77754e-02
I0216 07:34:12.490126 23126066861888 run_lib.py:146] step: 352500, eval_loss: 2.75083e-02
I0216 07:34:29.937511 23126066861888 run_lib.py:133] step: 352550, training_loss: 1.75311e-02
I0216 07:34:47.239031 23126066861888 run_lib.py:133] step: 352600, training_loss: 1.77485e-02
I0216 07:34:47.392884 23126066861888 run_lib.py:146] step: 352600, eval_loss: 2.75766e-02
I0216 07:35:04.639888 23126066861888 run_lib.py:133] step: 352650, training_loss: 1.90168e-02
I0216 07:35:21.916098 23126066861888 run_lib.py:133] step: 352700, training_loss: 1.85128e-02
I0216 07:35:22.068100 23126066861888 run_lib.py:146] step: 352700, eval_loss: 2.74520e-02
I0216 07:35:39.549498 23126066861888 run_lib.py:133] step: 352750, training_loss: 1.78958e-02
I0216 07:35:56.807034 23126066861888 run_lib.py:133] step: 352800, training_loss: 1.80295e-02
I0216 07:35:56.961802 23126066861888 run_lib.py:146] step: 352800, eval_loss: 2.85456e-02
I0216 07:36:14.232563 23126066861888 run_lib.py:133] step: 352850, training_loss: 1.84616e-02
I0216 07:36:31.713214 23126066861888 run_lib.py:133] step: 352900, training_loss: 1.77205e-02
I0216 07:36:31.871119 23126066861888 run_lib.py:146] step: 352900, eval_loss: 2.70442e-02
I0216 07:36:49.237643 23126066861888 run_lib.py:133] step: 352950, training_loss: 1.79743e-02
I0216 07:37:06.886542 23126066861888 run_lib.py:133] step: 353000, training_loss: 1.77038e-02
I0216 07:37:07.039876 23126066861888 run_lib.py:146] step: 353000, eval_loss: 2.74408e-02
I0216 07:37:24.436520 23126066861888 run_lib.py:133] step: 353050, training_loss: 1.84791e-02
I0216 07:37:41.766454 23126066861888 run_lib.py:133] step: 353100, training_loss: 1.78534e-02
I0216 07:37:41.918560 23126066861888 run_lib.py:146] step: 353100, eval_loss: 2.75114e-02
I0216 07:37:59.399873 23126066861888 run_lib.py:133] step: 353150, training_loss: 1.86357e-02
I0216 07:38:16.680459 23126066861888 run_lib.py:133] step: 353200, training_loss: 1.78782e-02
I0216 07:38:16.839060 23126066861888 run_lib.py:146] step: 353200, eval_loss: 2.72881e-02
I0216 07:38:34.145990 23126066861888 run_lib.py:133] step: 353250, training_loss: 1.81069e-02
I0216 07:38:51.623996 23126066861888 run_lib.py:133] step: 353300, training_loss: 1.86004e-02
I0216 07:38:51.774217 23126066861888 run_lib.py:146] step: 353300, eval_loss: 2.82711e-02
I0216 07:39:09.060189 23126066861888 run_lib.py:133] step: 353350, training_loss: 1.78552e-02
I0216 07:39:26.384112 23126066861888 run_lib.py:133] step: 353400, training_loss: 1.71452e-02
I0216 07:39:26.542224 23126066861888 run_lib.py:146] step: 353400, eval_loss: 2.75779e-02
I0216 07:39:43.872959 23126066861888 run_lib.py:133] step: 353450, training_loss: 1.84104e-02
I0216 07:40:01.175228 23126066861888 run_lib.py:133] step: 353500, training_loss: 1.87538e-02
I0216 07:40:01.331044 23126066861888 run_lib.py:146] step: 353500, eval_loss: 2.71402e-02
I0216 07:40:18.586979 23126066861888 run_lib.py:133] step: 353550, training_loss: 1.70922e-02
I0216 07:40:35.885368 23126066861888 run_lib.py:133] step: 353600, training_loss: 1.70680e-02
I0216 07:40:36.055816 23126066861888 run_lib.py:146] step: 353600, eval_loss: 2.88463e-02
I0216 07:40:53.538957 23126066861888 run_lib.py:133] step: 353650, training_loss: 1.79164e-02
I0216 07:41:10.904111 23126066861888 run_lib.py:133] step: 353700, training_loss: 1.74087e-02
I0216 07:41:11.054854 23126066861888 run_lib.py:146] step: 353700, eval_loss: 2.75738e-02
I0216 07:41:28.359343 23126066861888 run_lib.py:133] step: 353750, training_loss: 1.75974e-02
I0216 07:41:45.652458 23126066861888 run_lib.py:133] step: 353800, training_loss: 1.79784e-02
I0216 07:41:45.816734 23126066861888 run_lib.py:146] step: 353800, eval_loss: 2.75507e-02
I0216 07:42:03.258227 23126066861888 run_lib.py:133] step: 353850, training_loss: 1.87401e-02
I0216 07:42:20.496096 23126066861888 run_lib.py:133] step: 353900, training_loss: 1.79203e-02
I0216 07:42:20.649139 23126066861888 run_lib.py:146] step: 353900, eval_loss: 2.74714e-02
I0216 07:42:37.906462 23126066861888 run_lib.py:133] step: 353950, training_loss: 1.80258e-02
I0216 07:42:55.319467 23126066861888 run_lib.py:133] step: 354000, training_loss: 1.80630e-02
I0216 07:42:55.482523 23126066861888 run_lib.py:146] step: 354000, eval_loss: 2.80805e-02
I0216 07:43:12.789886 23126066861888 run_lib.py:133] step: 354050, training_loss: 1.84027e-02
I0216 07:43:30.299065 23126066861888 run_lib.py:133] step: 354100, training_loss: 1.82999e-02
I0216 07:43:30.452117 23126066861888 run_lib.py:146] step: 354100, eval_loss: 2.82573e-02
I0216 07:43:47.741343 23126066861888 run_lib.py:133] step: 354150, training_loss: 1.78210e-02
I0216 07:44:05.052978 23126066861888 run_lib.py:133] step: 354200, training_loss: 1.86162e-02
I0216 07:44:05.204772 23126066861888 run_lib.py:146] step: 354200, eval_loss: 2.72433e-02
I0216 07:44:22.613736 23126066861888 run_lib.py:133] step: 354250, training_loss: 1.85504e-02
I0216 07:44:39.882907 23126066861888 run_lib.py:133] step: 354300, training_loss: 1.75689e-02
I0216 07:44:40.050901 23126066861888 run_lib.py:146] step: 354300, eval_loss: 2.76164e-02
I0216 07:44:57.346376 23126066861888 run_lib.py:133] step: 354350, training_loss: 1.76577e-02
I0216 07:45:14.811904 23126066861888 run_lib.py:133] step: 354400, training_loss: 1.80698e-02
I0216 07:45:14.971247 23126066861888 run_lib.py:146] step: 354400, eval_loss: 2.83080e-02
I0216 07:45:32.274259 23126066861888 run_lib.py:133] step: 354450, training_loss: 1.76571e-02
I0216 07:45:49.582766 23126066861888 run_lib.py:133] step: 354500, training_loss: 1.82961e-02
I0216 07:45:49.737697 23126066861888 run_lib.py:146] step: 354500, eval_loss: 2.70744e-02
I0216 07:46:07.100184 23126066861888 run_lib.py:133] step: 354550, training_loss: 1.80426e-02
I0216 07:46:24.477244 23126066861888 run_lib.py:133] step: 354600, training_loss: 1.79172e-02
I0216 07:46:24.630851 23126066861888 run_lib.py:146] step: 354600, eval_loss: 2.84290e-02
I0216 07:46:42.108904 23126066861888 run_lib.py:133] step: 354650, training_loss: 1.80326e-02
I0216 07:46:59.421579 23126066861888 run_lib.py:133] step: 354700, training_loss: 1.78843e-02
I0216 07:46:59.577924 23126066861888 run_lib.py:146] step: 354700, eval_loss: 2.86937e-02
I0216 07:47:17.027664 23126066861888 run_lib.py:133] step: 354750, training_loss: 1.82696e-02
I0216 07:47:34.397626 23126066861888 run_lib.py:133] step: 354800, training_loss: 1.83340e-02
I0216 07:47:34.556119 23126066861888 run_lib.py:146] step: 354800, eval_loss: 2.73482e-02
I0216 07:47:51.835532 23126066861888 run_lib.py:133] step: 354850, training_loss: 1.83054e-02
I0216 07:48:09.058291 23126066861888 run_lib.py:133] step: 354900, training_loss: 1.79459e-02
I0216 07:48:09.224869 23126066861888 run_lib.py:146] step: 354900, eval_loss: 2.79480e-02
I0216 07:48:26.646520 23126066861888 run_lib.py:133] step: 354950, training_loss: 1.85857e-02
I0216 07:48:43.943409 23126066861888 run_lib.py:133] step: 355000, training_loss: 1.78877e-02
I0216 07:48:44.097602 23126066861888 run_lib.py:146] step: 355000, eval_loss: 2.83542e-02
I0216 07:49:01.388567 23126066861888 run_lib.py:133] step: 355050, training_loss: 1.76117e-02
I0216 07:49:18.895591 23126066861888 run_lib.py:133] step: 355100, training_loss: 1.84922e-02
I0216 07:49:19.050985 23126066861888 run_lib.py:146] step: 355100, eval_loss: 2.84215e-02
I0216 07:49:36.299041 23126066861888 run_lib.py:133] step: 355150, training_loss: 1.82341e-02
I0216 07:49:53.702298 23126066861888 run_lib.py:133] step: 355200, training_loss: 1.83889e-02
I0216 07:49:53.860047 23126066861888 run_lib.py:146] step: 355200, eval_loss: 2.80672e-02
I0216 07:50:11.150883 23126066861888 run_lib.py:133] step: 355250, training_loss: 1.82898e-02
I0216 07:50:28.475061 23126066861888 run_lib.py:133] step: 355300, training_loss: 1.78134e-02
I0216 07:50:28.631792 23126066861888 run_lib.py:146] step: 355300, eval_loss: 2.77917e-02
I0216 07:50:46.070717 23126066861888 run_lib.py:133] step: 355350, training_loss: 1.76948e-02
I0216 07:51:03.357678 23126066861888 run_lib.py:133] step: 355400, training_loss: 1.80834e-02
I0216 07:51:03.511863 23126066861888 run_lib.py:146] step: 355400, eval_loss: 2.85400e-02
I0216 07:51:20.769544 23126066861888 run_lib.py:133] step: 355450, training_loss: 1.87251e-02
I0216 07:51:38.221412 23126066861888 run_lib.py:133] step: 355500, training_loss: 1.81799e-02
I0216 07:51:38.374980 23126066861888 run_lib.py:146] step: 355500, eval_loss: 2.74018e-02
I0216 07:51:55.732445 23126066861888 run_lib.py:133] step: 355550, training_loss: 1.85253e-02
I0216 07:52:13.018715 23126066861888 run_lib.py:133] step: 355600, training_loss: 1.77727e-02
I0216 07:52:13.170812 23126066861888 run_lib.py:146] step: 355600, eval_loss: 2.74014e-02
I0216 07:52:30.536694 23126066861888 run_lib.py:133] step: 355650, training_loss: 1.78909e-02
I0216 07:52:47.801506 23126066861888 run_lib.py:133] step: 355700, training_loss: 1.74309e-02
I0216 07:52:47.959154 23126066861888 run_lib.py:146] step: 355700, eval_loss: 2.76823e-02
I0216 07:53:05.214166 23126066861888 run_lib.py:133] step: 355750, training_loss: 1.79358e-02
I0216 07:53:22.459985 23126066861888 run_lib.py:133] step: 355800, training_loss: 1.82797e-02
I0216 07:53:22.629961 23126066861888 run_lib.py:146] step: 355800, eval_loss: 2.72905e-02
I0216 07:53:40.074379 23126066861888 run_lib.py:133] step: 355850, training_loss: 1.87890e-02
I0216 07:53:57.496490 23126066861888 run_lib.py:133] step: 355900, training_loss: 1.77113e-02
I0216 07:53:57.650956 23126066861888 run_lib.py:146] step: 355900, eval_loss: 2.78297e-02
I0216 07:54:14.939463 23126066861888 run_lib.py:133] step: 355950, training_loss: 1.80344e-02
I0216 07:54:32.216570 23126066861888 run_lib.py:133] step: 356000, training_loss: 1.80497e-02
I0216 07:54:32.368968 23126066861888 run_lib.py:146] step: 356000, eval_loss: 2.82697e-02
I0216 07:54:49.790353 23126066861888 run_lib.py:133] step: 356050, training_loss: 1.83585e-02
I0216 07:55:07.114149 23126066861888 run_lib.py:133] step: 356100, training_loss: 1.80112e-02
I0216 07:55:07.274115 23126066861888 run_lib.py:146] step: 356100, eval_loss: 2.74219e-02
I0216 07:55:24.663024 23126066861888 run_lib.py:133] step: 356150, training_loss: 1.84880e-02
I0216 07:55:42.272248 23126066861888 run_lib.py:133] step: 356200, training_loss: 1.77110e-02
I0216 07:55:42.430040 23126066861888 run_lib.py:146] step: 356200, eval_loss: 2.88248e-02
I0216 07:55:59.843523 23126066861888 run_lib.py:133] step: 356250, training_loss: 1.82790e-02
I0216 07:56:17.296386 23126066861888 run_lib.py:133] step: 356300, training_loss: 1.74867e-02
I0216 07:56:17.450854 23126066861888 run_lib.py:146] step: 356300, eval_loss: 2.67531e-02
I0216 07:56:34.724791 23126066861888 run_lib.py:133] step: 356350, training_loss: 1.79062e-02
I0216 07:56:51.978440 23126066861888 run_lib.py:133] step: 356400, training_loss: 1.79077e-02
I0216 07:56:52.134342 23126066861888 run_lib.py:146] step: 356400, eval_loss: 2.86516e-02
I0216 07:57:09.596492 23126066861888 run_lib.py:133] step: 356450, training_loss: 1.75368e-02
I0216 07:57:26.869672 23126066861888 run_lib.py:133] step: 356500, training_loss: 1.77315e-02
I0216 07:57:27.019949 23126066861888 run_lib.py:146] step: 356500, eval_loss: 2.79749e-02
I0216 07:57:44.266715 23126066861888 run_lib.py:133] step: 356550, training_loss: 1.80385e-02
I0216 07:58:01.786212 23126066861888 run_lib.py:133] step: 356600, training_loss: 1.81317e-02
I0216 07:58:01.939807 23126066861888 run_lib.py:146] step: 356600, eval_loss: 2.68940e-02
I0216 07:58:19.162960 23126066861888 run_lib.py:133] step: 356650, training_loss: 1.82586e-02
I0216 07:58:36.436891 23126066861888 run_lib.py:133] step: 356700, training_loss: 1.84527e-02
I0216 07:58:36.607941 23126066861888 run_lib.py:146] step: 356700, eval_loss: 2.76967e-02
I0216 07:58:53.988113 23126066861888 run_lib.py:133] step: 356750, training_loss: 1.82230e-02
I0216 07:59:11.264229 23126066861888 run_lib.py:133] step: 356800, training_loss: 1.80932e-02
I0216 07:59:11.418003 23126066861888 run_lib.py:146] step: 356800, eval_loss: 2.86510e-02
I0216 07:59:28.691769 23126066861888 run_lib.py:133] step: 356850, training_loss: 1.81013e-02
I0216 07:59:45.924271 23126066861888 run_lib.py:133] step: 356900, training_loss: 1.81404e-02
I0216 07:59:46.076934 23126066861888 run_lib.py:146] step: 356900, eval_loss: 2.76131e-02
I0216 08:00:03.495635 23126066861888 run_lib.py:133] step: 356950, training_loss: 1.84183e-02
I0216 08:00:20.911394 23126066861888 run_lib.py:133] step: 357000, training_loss: 1.74643e-02
I0216 08:00:21.067233 23126066861888 run_lib.py:146] step: 357000, eval_loss: 2.78614e-02
I0216 08:00:38.351063 23126066861888 run_lib.py:133] step: 357050, training_loss: 1.83378e-02
I0216 08:00:55.636540 23126066861888 run_lib.py:133] step: 357100, training_loss: 1.85852e-02
I0216 08:00:55.791753 23126066861888 run_lib.py:146] step: 357100, eval_loss: 2.84238e-02
I0216 08:01:13.216358 23126066861888 run_lib.py:133] step: 357150, training_loss: 1.77614e-02
I0216 08:01:30.525708 23126066861888 run_lib.py:133] step: 357200, training_loss: 1.74315e-02
I0216 08:01:30.685854 23126066861888 run_lib.py:146] step: 357200, eval_loss: 2.66595e-02
I0216 08:01:47.962678 23126066861888 run_lib.py:133] step: 357250, training_loss: 1.79829e-02
I0216 08:02:05.416464 23126066861888 run_lib.py:133] step: 357300, training_loss: 1.82740e-02
I0216 08:02:05.571093 23126066861888 run_lib.py:146] step: 357300, eval_loss: 2.88106e-02
I0216 08:02:22.842267 23126066861888 run_lib.py:133] step: 357350, training_loss: 1.76746e-02
I0216 08:02:40.271218 23126066861888 run_lib.py:133] step: 357400, training_loss: 1.78808e-02
I0216 08:02:40.429770 23126066861888 run_lib.py:146] step: 357400, eval_loss: 2.85401e-02
I0216 08:02:57.668809 23126066861888 run_lib.py:133] step: 357450, training_loss: 1.75837e-02
I0216 08:03:14.933268 23126066861888 run_lib.py:133] step: 357500, training_loss: 1.70034e-02
I0216 08:03:15.087028 23126066861888 run_lib.py:146] step: 357500, eval_loss: 2.66365e-02
I0216 08:03:32.594836 23126066861888 run_lib.py:133] step: 357550, training_loss: 1.76265e-02
I0216 08:03:49.867333 23126066861888 run_lib.py:133] step: 357600, training_loss: 1.91618e-02
I0216 08:03:50.025844 23126066861888 run_lib.py:146] step: 357600, eval_loss: 2.71266e-02
I0216 08:04:07.254111 23126066861888 run_lib.py:133] step: 357650, training_loss: 1.86441e-02
I0216 08:04:24.728601 23126066861888 run_lib.py:133] step: 357700, training_loss: 1.79366e-02
I0216 08:04:24.881880 23126066861888 run_lib.py:146] step: 357700, eval_loss: 2.89981e-02
I0216 08:04:42.171352 23126066861888 run_lib.py:133] step: 357750, training_loss: 1.84440e-02
I0216 08:04:59.516629 23126066861888 run_lib.py:133] step: 357800, training_loss: 1.81505e-02
I0216 08:04:59.672885 23126066861888 run_lib.py:146] step: 357800, eval_loss: 2.70381e-02
I0216 08:05:17.203579 23126066861888 run_lib.py:133] step: 357850, training_loss: 1.78057e-02
I0216 08:05:34.600350 23126066861888 run_lib.py:133] step: 357900, training_loss: 1.74884e-02
I0216 08:05:34.752978 23126066861888 run_lib.py:146] step: 357900, eval_loss: 2.82979e-02
I0216 08:05:52.037787 23126066861888 run_lib.py:133] step: 357950, training_loss: 1.77328e-02
I0216 08:06:09.347574 23126066861888 run_lib.py:133] step: 358000, training_loss: 1.75573e-02
I0216 08:06:09.500848 23126066861888 run_lib.py:146] step: 358000, eval_loss: 2.68668e-02
I0216 08:06:26.978346 23126066861888 run_lib.py:133] step: 358050, training_loss: 1.82791e-02
I0216 08:06:44.305464 23126066861888 run_lib.py:133] step: 358100, training_loss: 1.78002e-02
I0216 08:06:44.478904 23126066861888 run_lib.py:146] step: 358100, eval_loss: 2.79251e-02
I0216 08:07:01.789380 23126066861888 run_lib.py:133] step: 358150, training_loss: 1.84493e-02
I0216 08:07:19.153400 23126066861888 run_lib.py:133] step: 358200, training_loss: 1.82189e-02
I0216 08:07:19.307056 23126066861888 run_lib.py:146] step: 358200, eval_loss: 2.58724e-02
I0216 08:07:36.757148 23126066861888 run_lib.py:133] step: 358250, training_loss: 1.82229e-02
I0216 08:07:53.983334 23126066861888 run_lib.py:133] step: 358300, training_loss: 1.77713e-02
I0216 08:07:54.137709 23126066861888 run_lib.py:146] step: 358300, eval_loss: 2.86737e-02
I0216 08:08:11.461455 23126066861888 run_lib.py:133] step: 358350, training_loss: 1.82105e-02
I0216 08:08:28.940728 23126066861888 run_lib.py:133] step: 358400, training_loss: 1.80951e-02
I0216 08:08:29.094010 23126066861888 run_lib.py:146] step: 358400, eval_loss: 2.81775e-02
I0216 08:08:46.401263 23126066861888 run_lib.py:133] step: 358450, training_loss: 1.75410e-02
I0216 08:09:03.889074 23126066861888 run_lib.py:133] step: 358500, training_loss: 1.75478e-02
I0216 08:09:04.042842 23126066861888 run_lib.py:146] step: 358500, eval_loss: 2.81456e-02
I0216 08:09:21.336712 23126066861888 run_lib.py:133] step: 358550, training_loss: 1.80620e-02
I0216 08:09:38.652138 23126066861888 run_lib.py:133] step: 358600, training_loss: 1.86970e-02
I0216 08:09:38.811963 23126066861888 run_lib.py:146] step: 358600, eval_loss: 2.75264e-02
I0216 08:09:56.309890 23126066861888 run_lib.py:133] step: 358650, training_loss: 1.79939e-02
I0216 08:10:13.597255 23126066861888 run_lib.py:133] step: 358700, training_loss: 1.81430e-02
I0216 08:10:13.753164 23126066861888 run_lib.py:146] step: 358700, eval_loss: 2.89555e-02
I0216 08:10:31.037261 23126066861888 run_lib.py:133] step: 358750, training_loss: 1.78694e-02
I0216 08:10:48.471001 23126066861888 run_lib.py:133] step: 358800, training_loss: 1.81636e-02
I0216 08:10:48.629000 23126066861888 run_lib.py:146] step: 358800, eval_loss: 2.84127e-02
I0216 08:11:05.877943 23126066861888 run_lib.py:133] step: 358850, training_loss: 1.79679e-02
I0216 08:11:23.171087 23126066861888 run_lib.py:133] step: 358900, training_loss: 1.79323e-02
I0216 08:11:23.327025 23126066861888 run_lib.py:146] step: 358900, eval_loss: 2.75755e-02
I0216 08:11:40.764789 23126066861888 run_lib.py:133] step: 358950, training_loss: 1.79285e-02
I0216 08:11:58.009865 23126066861888 run_lib.py:133] step: 359000, training_loss: 1.76424e-02
I0216 08:11:58.166896 23126066861888 run_lib.py:146] step: 359000, eval_loss: 2.75575e-02
I0216 08:12:15.396560 23126066861888 run_lib.py:133] step: 359050, training_loss: 1.82024e-02
I0216 08:12:32.658507 23126066861888 run_lib.py:133] step: 359100, training_loss: 1.83019e-02
I0216 08:12:32.811046 23126066861888 run_lib.py:146] step: 359100, eval_loss: 2.80117e-02
I0216 08:12:50.292296 23126066861888 run_lib.py:133] step: 359150, training_loss: 1.75035e-02
I0216 08:13:07.604494 23126066861888 run_lib.py:133] step: 359200, training_loss: 1.84880e-02
I0216 08:13:07.757801 23126066861888 run_lib.py:146] step: 359200, eval_loss: 2.66095e-02
I0216 08:13:25.019757 23126066861888 run_lib.py:133] step: 359250, training_loss: 1.77422e-02
I0216 08:13:42.350245 23126066861888 run_lib.py:133] step: 359300, training_loss: 1.70508e-02
I0216 08:13:42.504747 23126066861888 run_lib.py:146] step: 359300, eval_loss: 2.85315e-02
I0216 08:14:00.042678 23126066861888 run_lib.py:133] step: 359350, training_loss: 1.84224e-02
I0216 08:14:17.342368 23126066861888 run_lib.py:133] step: 359400, training_loss: 1.81588e-02
I0216 08:14:17.493937 23126066861888 run_lib.py:146] step: 359400, eval_loss: 2.79068e-02
I0216 08:14:34.890282 23126066861888 run_lib.py:133] step: 359450, training_loss: 1.76537e-02
I0216 08:14:52.455612 23126066861888 run_lib.py:133] step: 359500, training_loss: 1.76765e-02
I0216 08:14:52.638047 23126066861888 run_lib.py:146] step: 359500, eval_loss: 2.79036e-02
I0216 08:15:09.984096 23126066861888 run_lib.py:133] step: 359550, training_loss: 1.89296e-02
I0216 08:15:27.425908 23126066861888 run_lib.py:133] step: 359600, training_loss: 1.70685e-02
I0216 08:15:27.579984 23126066861888 run_lib.py:146] step: 359600, eval_loss: 2.85071e-02
I0216 08:15:44.838807 23126066861888 run_lib.py:133] step: 359650, training_loss: 1.80062e-02
I0216 08:16:02.063202 23126066861888 run_lib.py:133] step: 359700, training_loss: 1.85765e-02
I0216 08:16:02.216593 23126066861888 run_lib.py:146] step: 359700, eval_loss: 2.82910e-02
I0216 08:16:19.611569 23126066861888 run_lib.py:133] step: 359750, training_loss: 1.82498e-02
I0216 08:16:36.918682 23126066861888 run_lib.py:133] step: 359800, training_loss: 1.78557e-02
I0216 08:16:37.073157 23126066861888 run_lib.py:146] step: 359800, eval_loss: 2.80328e-02
I0216 08:16:54.377319 23126066861888 run_lib.py:133] step: 359850, training_loss: 1.84678e-02
I0216 08:17:11.816834 23126066861888 run_lib.py:133] step: 359900, training_loss: 1.86126e-02
I0216 08:17:11.970837 23126066861888 run_lib.py:146] step: 359900, eval_loss: 2.69786e-02
I0216 08:17:29.211201 23126066861888 run_lib.py:133] step: 359950, training_loss: 1.73052e-02
I0216 08:17:46.495970 23126066861888 run_lib.py:133] step: 360000, training_loss: 1.84962e-02
I0216 08:17:47.177894 23126066861888 run_lib.py:146] step: 360000, eval_loss: 2.85855e-02
I0216 08:18:07.248713 23126066861888 run_lib.py:133] step: 360050, training_loss: 1.75082e-02
I0216 08:18:24.750778 23126066861888 run_lib.py:133] step: 360100, training_loss: 1.77042e-02
I0216 08:18:24.905803 23126066861888 run_lib.py:146] step: 360100, eval_loss: 2.76768e-02
I0216 08:18:42.186743 23126066861888 run_lib.py:133] step: 360150, training_loss: 1.83021e-02
I0216 08:18:59.432538 23126066861888 run_lib.py:133] step: 360200, training_loss: 1.82407e-02
I0216 08:18:59.585736 23126066861888 run_lib.py:146] step: 360200, eval_loss: 2.79178e-02
I0216 08:19:16.850111 23126066861888 run_lib.py:133] step: 360250, training_loss: 1.78852e-02
I0216 08:19:34.275236 23126066861888 run_lib.py:133] step: 360300, training_loss: 1.85833e-02
I0216 08:19:34.434080 23126066861888 run_lib.py:146] step: 360300, eval_loss: 2.79178e-02
I0216 08:19:51.755129 23126066861888 run_lib.py:133] step: 360350, training_loss: 1.80222e-02
I0216 08:20:09.006385 23126066861888 run_lib.py:133] step: 360400, training_loss: 1.82219e-02
I0216 08:20:09.157894 23126066861888 run_lib.py:146] step: 360400, eval_loss: 2.81710e-02
I0216 08:20:26.590961 23126066861888 run_lib.py:133] step: 360450, training_loss: 1.78520e-02
I0216 08:20:43.879982 23126066861888 run_lib.py:133] step: 360500, training_loss: 1.79477e-02
I0216 08:20:44.037196 23126066861888 run_lib.py:146] step: 360500, eval_loss: 2.73208e-02
I0216 08:21:01.344779 23126066861888 run_lib.py:133] step: 360550, training_loss: 1.79970e-02
I0216 08:21:18.611829 23126066861888 run_lib.py:133] step: 360600, training_loss: 1.80513e-02
I0216 08:21:18.778364 23126066861888 run_lib.py:146] step: 360600, eval_loss: 2.90208e-02
I0216 08:21:36.085361 23126066861888 run_lib.py:133] step: 360650, training_loss: 1.82422e-02
I0216 08:21:53.364873 23126066861888 run_lib.py:133] step: 360700, training_loss: 1.70098e-02
I0216 08:21:53.519146 23126066861888 run_lib.py:146] step: 360700, eval_loss: 2.66292e-02
I0216 08:22:11.002788 23126066861888 run_lib.py:133] step: 360750, training_loss: 1.78217e-02
I0216 08:22:28.327224 23126066861888 run_lib.py:133] step: 360800, training_loss: 1.79573e-02
I0216 08:22:28.483635 23126066861888 run_lib.py:146] step: 360800, eval_loss: 2.69582e-02
I0216 08:22:45.721124 23126066861888 run_lib.py:133] step: 360850, training_loss: 1.75007e-02
I0216 08:23:03.165979 23126066861888 run_lib.py:133] step: 360900, training_loss: 1.80664e-02
I0216 08:23:03.333068 23126066861888 run_lib.py:146] step: 360900, eval_loss: 2.75366e-02
I0216 08:23:20.840460 23126066861888 run_lib.py:133] step: 360950, training_loss: 1.77009e-02
I0216 08:23:38.201750 23126066861888 run_lib.py:133] step: 361000, training_loss: 1.77609e-02
I0216 08:23:38.359325 23126066861888 run_lib.py:146] step: 361000, eval_loss: 2.74988e-02
I0216 08:23:55.741422 23126066861888 run_lib.py:133] step: 361050, training_loss: 1.80816e-02
I0216 08:24:13.265966 23126066861888 run_lib.py:133] step: 361100, training_loss: 1.79771e-02
I0216 08:24:13.424060 23126066861888 run_lib.py:146] step: 361100, eval_loss: 2.80289e-02
I0216 08:24:30.731743 23126066861888 run_lib.py:133] step: 361150, training_loss: 1.74556e-02
I0216 08:24:48.210551 23126066861888 run_lib.py:133] step: 361200, training_loss: 1.77753e-02
I0216 08:24:48.365364 23126066861888 run_lib.py:146] step: 361200, eval_loss: 2.77826e-02
I0216 08:25:05.630810 23126066861888 run_lib.py:133] step: 361250, training_loss: 1.79950e-02
I0216 08:25:22.881336 23126066861888 run_lib.py:133] step: 361300, training_loss: 1.81847e-02
I0216 08:25:23.031615 23126066861888 run_lib.py:146] step: 361300, eval_loss: 2.88407e-02
I0216 08:25:40.436883 23126066861888 run_lib.py:133] step: 361350, training_loss: 1.69398e-02
I0216 08:25:57.720970 23126066861888 run_lib.py:133] step: 361400, training_loss: 1.79418e-02
I0216 08:25:57.884106 23126066861888 run_lib.py:146] step: 361400, eval_loss: 2.80337e-02
I0216 08:26:15.197608 23126066861888 run_lib.py:133] step: 361450, training_loss: 1.87355e-02
I0216 08:26:32.504426 23126066861888 run_lib.py:133] step: 361500, training_loss: 1.79675e-02
I0216 08:26:32.659899 23126066861888 run_lib.py:146] step: 361500, eval_loss: 2.73547e-02
I0216 08:26:50.101810 23126066861888 run_lib.py:133] step: 361550, training_loss: 1.80759e-02
I0216 08:27:07.370337 23126066861888 run_lib.py:133] step: 361600, training_loss: 1.80957e-02
I0216 08:27:07.524894 23126066861888 run_lib.py:146] step: 361600, eval_loss: 2.72258e-02
I0216 08:27:24.864304 23126066861888 run_lib.py:133] step: 361650, training_loss: 1.78764e-02
I0216 08:27:42.161649 23126066861888 run_lib.py:133] step: 361700, training_loss: 1.81340e-02
I0216 08:27:42.315766 23126066861888 run_lib.py:146] step: 361700, eval_loss: 2.79294e-02
I0216 08:27:59.636221 23126066861888 run_lib.py:133] step: 361750, training_loss: 1.75151e-02
I0216 08:28:16.857346 23126066861888 run_lib.py:133] step: 361800, training_loss: 1.80388e-02
I0216 08:28:17.008973 23126066861888 run_lib.py:146] step: 361800, eval_loss: 2.82235e-02
I0216 08:28:34.434966 23126066861888 run_lib.py:133] step: 361850, training_loss: 1.79895e-02
I0216 08:28:51.815952 23126066861888 run_lib.py:133] step: 361900, training_loss: 1.83127e-02
I0216 08:28:51.974473 23126066861888 run_lib.py:146] step: 361900, eval_loss: 2.74340e-02
I0216 08:29:09.241465 23126066861888 run_lib.py:133] step: 361950, training_loss: 1.79347e-02
I0216 08:29:26.531605 23126066861888 run_lib.py:133] step: 362000, training_loss: 1.76431e-02
I0216 08:29:26.704820 23126066861888 run_lib.py:146] step: 362000, eval_loss: 2.67899e-02
I0216 08:29:44.187383 23126066861888 run_lib.py:133] step: 362050, training_loss: 1.79675e-02
I0216 08:30:01.490500 23126066861888 run_lib.py:133] step: 362100, training_loss: 1.76989e-02
I0216 08:30:01.649066 23126066861888 run_lib.py:146] step: 362100, eval_loss: 2.89581e-02
I0216 08:30:18.896453 23126066861888 run_lib.py:133] step: 362150, training_loss: 1.77064e-02
I0216 08:30:36.295975 23126066861888 run_lib.py:133] step: 362200, training_loss: 1.81119e-02
I0216 08:30:36.452030 23126066861888 run_lib.py:146] step: 362200, eval_loss: 2.76216e-02
I0216 08:30:53.767021 23126066861888 run_lib.py:133] step: 362250, training_loss: 1.86986e-02
I0216 08:31:11.260114 23126066861888 run_lib.py:133] step: 362300, training_loss: 1.78078e-02
I0216 08:31:11.415009 23126066861888 run_lib.py:146] step: 362300, eval_loss: 2.70180e-02
I0216 08:31:28.695788 23126066861888 run_lib.py:133] step: 362350, training_loss: 1.72089e-02
I0216 08:31:45.970647 23126066861888 run_lib.py:133] step: 362400, training_loss: 1.73530e-02
I0216 08:31:46.134113 23126066861888 run_lib.py:146] step: 362400, eval_loss: 2.74348e-02
I0216 08:32:03.591753 23126066861888 run_lib.py:133] step: 362450, training_loss: 1.82371e-02
I0216 08:32:20.939105 23126066861888 run_lib.py:133] step: 362500, training_loss: 1.86585e-02
I0216 08:32:21.106668 23126066861888 run_lib.py:146] step: 362500, eval_loss: 2.87967e-02
I0216 08:32:38.416815 23126066861888 run_lib.py:133] step: 362550, training_loss: 1.80257e-02
I0216 08:32:55.990726 23126066861888 run_lib.py:133] step: 362600, training_loss: 1.80330e-02
I0216 08:32:56.142987 23126066861888 run_lib.py:146] step: 362600, eval_loss: 2.75915e-02
I0216 08:33:13.554962 23126066861888 run_lib.py:133] step: 362650, training_loss: 1.80749e-02
I0216 08:33:30.910541 23126066861888 run_lib.py:133] step: 362700, training_loss: 1.86852e-02
I0216 08:33:31.066002 23126066861888 run_lib.py:146] step: 362700, eval_loss: 2.77727e-02
I0216 08:33:48.468694 23126066861888 run_lib.py:133] step: 362750, training_loss: 1.80358e-02
I0216 08:34:05.791553 23126066861888 run_lib.py:133] step: 362800, training_loss: 1.77603e-02
I0216 08:34:05.952379 23126066861888 run_lib.py:146] step: 362800, eval_loss: 2.85274e-02
I0216 08:34:23.315398 23126066861888 run_lib.py:133] step: 362850, training_loss: 1.77564e-02
I0216 08:34:40.624075 23126066861888 run_lib.py:133] step: 362900, training_loss: 1.80713e-02
I0216 08:34:40.791902 23126066861888 run_lib.py:146] step: 362900, eval_loss: 2.73141e-02
I0216 08:34:58.242123 23126066861888 run_lib.py:133] step: 362950, training_loss: 1.81857e-02
I0216 08:35:15.555722 23126066861888 run_lib.py:133] step: 363000, training_loss: 1.80186e-02
I0216 08:35:15.708817 23126066861888 run_lib.py:146] step: 363000, eval_loss: 2.76770e-02
I0216 08:35:32.964391 23126066861888 run_lib.py:133] step: 363050, training_loss: 1.89143e-02
I0216 08:35:50.266928 23126066861888 run_lib.py:133] step: 363100, training_loss: 1.76509e-02
I0216 08:35:50.421586 23126066861888 run_lib.py:146] step: 363100, eval_loss: 2.80833e-02
I0216 08:36:07.903292 23126066861888 run_lib.py:133] step: 363150, training_loss: 1.80821e-02
I0216 08:36:25.145881 23126066861888 run_lib.py:133] step: 363200, training_loss: 1.80581e-02
I0216 08:36:25.297572 23126066861888 run_lib.py:146] step: 363200, eval_loss: 2.83466e-02
I0216 08:36:42.606098 23126066861888 run_lib.py:133] step: 363250, training_loss: 1.77641e-02
I0216 08:36:59.976177 23126066861888 run_lib.py:133] step: 363300, training_loss: 1.79815e-02
I0216 08:37:00.128903 23126066861888 run_lib.py:146] step: 363300, eval_loss: 2.87937e-02
I0216 08:37:17.412698 23126066861888 run_lib.py:133] step: 363350, training_loss: 1.82959e-02
I0216 08:37:34.885599 23126066861888 run_lib.py:133] step: 363400, training_loss: 1.83965e-02
I0216 08:37:35.043990 23126066861888 run_lib.py:146] step: 363400, eval_loss: 2.73232e-02
I0216 08:37:52.300448 23126066861888 run_lib.py:133] step: 363450, training_loss: 1.78415e-02
I0216 08:38:09.534421 23126066861888 run_lib.py:133] step: 363500, training_loss: 1.71947e-02
I0216 08:38:09.688851 23126066861888 run_lib.py:146] step: 363500, eval_loss: 2.88197e-02
I0216 08:38:27.146152 23126066861888 run_lib.py:133] step: 363550, training_loss: 1.80490e-02
I0216 08:38:44.419527 23126066861888 run_lib.py:133] step: 363600, training_loss: 1.84331e-02
I0216 08:38:44.572513 23126066861888 run_lib.py:146] step: 363600, eval_loss: 2.86982e-02
I0216 08:39:01.912876 23126066861888 run_lib.py:133] step: 363650, training_loss: 1.74643e-02
I0216 08:39:19.453743 23126066861888 run_lib.py:133] step: 363700, training_loss: 1.84822e-02
I0216 08:39:19.602875 23126066861888 run_lib.py:146] step: 363700, eval_loss: 2.84475e-02
I0216 08:39:36.892740 23126066861888 run_lib.py:133] step: 363750, training_loss: 1.83734e-02
I0216 08:39:54.142924 23126066861888 run_lib.py:133] step: 363800, training_loss: 1.81232e-02
I0216 08:39:54.296910 23126066861888 run_lib.py:146] step: 363800, eval_loss: 2.84883e-02
I0216 08:40:11.634594 23126066861888 run_lib.py:133] step: 363850, training_loss: 1.80870e-02
I0216 08:40:28.914797 23126066861888 run_lib.py:133] step: 363900, training_loss: 1.81045e-02
I0216 08:40:29.094845 23126066861888 run_lib.py:146] step: 363900, eval_loss: 2.71009e-02
I0216 08:40:46.402975 23126066861888 run_lib.py:133] step: 363950, training_loss: 1.74485e-02
I0216 08:41:03.693680 23126066861888 run_lib.py:133] step: 364000, training_loss: 1.77896e-02
I0216 08:41:03.849242 23126066861888 run_lib.py:146] step: 364000, eval_loss: 2.85836e-02
I0216 08:41:21.367104 23126066861888 run_lib.py:133] step: 364050, training_loss: 1.71335e-02
I0216 08:41:38.781949 23126066861888 run_lib.py:133] step: 364100, training_loss: 1.75199e-02
I0216 08:41:38.935539 23126066861888 run_lib.py:146] step: 364100, eval_loss: 2.69239e-02
I0216 08:41:56.207725 23126066861888 run_lib.py:133] step: 364150, training_loss: 1.80551e-02
I0216 08:42:13.533826 23126066861888 run_lib.py:133] step: 364200, training_loss: 1.87896e-02
I0216 08:42:13.693082 23126066861888 run_lib.py:146] step: 364200, eval_loss: 2.96315e-02
I0216 08:42:31.321342 23126066861888 run_lib.py:133] step: 364250, training_loss: 1.78168e-02
I0216 08:42:48.721589 23126066861888 run_lib.py:133] step: 364300, training_loss: 1.75025e-02
I0216 08:42:48.876614 23126066861888 run_lib.py:146] step: 364300, eval_loss: 2.84321e-02
I0216 08:43:06.190244 23126066861888 run_lib.py:133] step: 364350, training_loss: 1.82892e-02
I0216 08:43:23.591426 23126066861888 run_lib.py:133] step: 364400, training_loss: 1.75083e-02
I0216 08:43:23.745140 23126066861888 run_lib.py:146] step: 364400, eval_loss: 2.86618e-02
I0216 08:43:41.016214 23126066861888 run_lib.py:133] step: 364450, training_loss: 1.76023e-02
I0216 08:43:58.506817 23126066861888 run_lib.py:133] step: 364500, training_loss: 1.71707e-02
I0216 08:43:58.661187 23126066861888 run_lib.py:146] step: 364500, eval_loss: 2.73543e-02
I0216 08:44:15.933065 23126066861888 run_lib.py:133] step: 364550, training_loss: 1.87225e-02
I0216 08:44:33.193366 23126066861888 run_lib.py:133] step: 364600, training_loss: 1.79751e-02
I0216 08:44:33.345765 23126066861888 run_lib.py:146] step: 364600, eval_loss: 2.74421e-02
I0216 08:44:50.816714 23126066861888 run_lib.py:133] step: 364650, training_loss: 1.81354e-02
I0216 08:45:08.088573 23126066861888 run_lib.py:133] step: 364700, training_loss: 1.73518e-02
I0216 08:45:08.249028 23126066861888 run_lib.py:146] step: 364700, eval_loss: 2.71421e-02
I0216 08:45:25.592391 23126066861888 run_lib.py:133] step: 364750, training_loss: 1.79587e-02
I0216 08:45:43.118455 23126066861888 run_lib.py:133] step: 364800, training_loss: 1.80148e-02
I0216 08:45:43.274823 23126066861888 run_lib.py:146] step: 364800, eval_loss: 2.82759e-02
I0216 08:46:00.548326 23126066861888 run_lib.py:133] step: 364850, training_loss: 1.76916e-02
I0216 08:46:17.775278 23126066861888 run_lib.py:133] step: 364900, training_loss: 1.79423e-02
I0216 08:46:17.928923 23126066861888 run_lib.py:146] step: 364900, eval_loss: 2.89495e-02
I0216 08:46:35.255366 23126066861888 run_lib.py:133] step: 364950, training_loss: 1.86974e-02
I0216 08:46:52.523338 23126066861888 run_lib.py:133] step: 365000, training_loss: 1.79399e-02
I0216 08:46:52.678080 23126066861888 run_lib.py:146] step: 365000, eval_loss: 2.82683e-02
I0216 08:47:10.001804 23126066861888 run_lib.py:133] step: 365050, training_loss: 1.74904e-02
I0216 08:47:27.285095 23126066861888 run_lib.py:133] step: 365100, training_loss: 1.82805e-02
I0216 08:47:27.435018 23126066861888 run_lib.py:146] step: 365100, eval_loss: 2.89134e-02
I0216 08:47:44.852472 23126066861888 run_lib.py:133] step: 365150, training_loss: 1.74509e-02
I0216 08:48:02.269471 23126066861888 run_lib.py:133] step: 365200, training_loss: 1.78795e-02
I0216 08:48:02.423871 23126066861888 run_lib.py:146] step: 365200, eval_loss: 2.82290e-02
I0216 08:48:19.671926 23126066861888 run_lib.py:133] step: 365250, training_loss: 1.77054e-02
I0216 08:48:36.998794 23126066861888 run_lib.py:133] step: 365300, training_loss: 1.88754e-02
I0216 08:48:37.179101 23126066861888 run_lib.py:146] step: 365300, eval_loss: 2.78437e-02
I0216 08:48:54.652481 23126066861888 run_lib.py:133] step: 365350, training_loss: 1.81781e-02
I0216 08:49:12.023184 23126066861888 run_lib.py:133] step: 365400, training_loss: 1.79335e-02
I0216 08:49:12.195997 23126066861888 run_lib.py:146] step: 365400, eval_loss: 2.87584e-02
I0216 08:49:29.466481 23126066861888 run_lib.py:133] step: 365450, training_loss: 1.73445e-02
I0216 08:49:46.870472 23126066861888 run_lib.py:133] step: 365500, training_loss: 1.83384e-02
I0216 08:49:47.022584 23126066861888 run_lib.py:146] step: 365500, eval_loss: 2.82557e-02
I0216 08:50:04.262691 23126066861888 run_lib.py:133] step: 365550, training_loss: 1.78623e-02
I0216 08:50:21.781223 23126066861888 run_lib.py:133] step: 365600, training_loss: 1.82745e-02
I0216 08:50:21.939227 23126066861888 run_lib.py:146] step: 365600, eval_loss: 2.84823e-02
I0216 08:50:39.205525 23126066861888 run_lib.py:133] step: 365650, training_loss: 1.76356e-02
I0216 08:50:56.551219 23126066861888 run_lib.py:133] step: 365700, training_loss: 1.79120e-02
I0216 08:50:56.705979 23126066861888 run_lib.py:146] step: 365700, eval_loss: 2.79097e-02
I0216 08:51:14.221833 23126066861888 run_lib.py:133] step: 365750, training_loss: 1.77644e-02
I0216 08:51:31.541609 23126066861888 run_lib.py:133] step: 365800, training_loss: 1.74376e-02
I0216 08:51:31.700258 23126066861888 run_lib.py:146] step: 365800, eval_loss: 2.62533e-02
I0216 08:51:49.067823 23126066861888 run_lib.py:133] step: 365850, training_loss: 1.78640e-02
I0216 08:52:06.685604 23126066861888 run_lib.py:133] step: 365900, training_loss: 1.74962e-02
I0216 08:52:06.840105 23126066861888 run_lib.py:146] step: 365900, eval_loss: 2.67958e-02
I0216 08:52:24.140036 23126066861888 run_lib.py:133] step: 365950, training_loss: 1.82266e-02
I0216 08:52:41.378799 23126066861888 run_lib.py:133] step: 366000, training_loss: 1.82300e-02
I0216 08:52:41.531830 23126066861888 run_lib.py:146] step: 366000, eval_loss: 2.82456e-02
I0216 08:52:58.863823 23126066861888 run_lib.py:133] step: 366050, training_loss: 1.83822e-02
I0216 08:53:16.102131 23126066861888 run_lib.py:133] step: 366100, training_loss: 1.79657e-02
I0216 08:53:16.253845 23126066861888 run_lib.py:146] step: 366100, eval_loss: 2.68814e-02
I0216 08:53:33.498066 23126066861888 run_lib.py:133] step: 366150, training_loss: 1.72609e-02
I0216 08:53:50.772591 23126066861888 run_lib.py:133] step: 366200, training_loss: 1.78525e-02
I0216 08:53:50.932876 23126066861888 run_lib.py:146] step: 366200, eval_loss: 2.78292e-02
I0216 08:54:08.353224 23126066861888 run_lib.py:133] step: 366250, training_loss: 1.79332e-02
I0216 08:54:25.684443 23126066861888 run_lib.py:133] step: 366300, training_loss: 1.78574e-02
I0216 08:54:25.843980 23126066861888 run_lib.py:146] step: 366300, eval_loss: 2.77830e-02
I0216 08:54:43.093956 23126066861888 run_lib.py:133] step: 366350, training_loss: 1.80149e-02
I0216 08:55:00.378651 23126066861888 run_lib.py:133] step: 366400, training_loss: 1.72470e-02
I0216 08:55:00.532766 23126066861888 run_lib.py:146] step: 366400, eval_loss: 2.74649e-02
I0216 08:55:17.942612 23126066861888 run_lib.py:133] step: 366450, training_loss: 1.74103e-02
I0216 08:55:35.262993 23126066861888 run_lib.py:133] step: 366500, training_loss: 1.82647e-02
I0216 08:55:35.420188 23126066861888 run_lib.py:146] step: 366500, eval_loss: 2.77021e-02
I0216 08:55:52.694782 23126066861888 run_lib.py:133] step: 366550, training_loss: 1.76005e-02
I0216 08:56:10.156605 23126066861888 run_lib.py:133] step: 366600, training_loss: 1.83321e-02
I0216 08:56:10.309942 23126066861888 run_lib.py:146] step: 366600, eval_loss: 2.81089e-02
I0216 08:56:27.565987 23126066861888 run_lib.py:133] step: 366650, training_loss: 1.69147e-02
I0216 08:56:44.954375 23126066861888 run_lib.py:133] step: 366700, training_loss: 1.80110e-02
I0216 08:56:45.110795 23126066861888 run_lib.py:146] step: 366700, eval_loss: 2.78322e-02
I0216 08:57:02.411826 23126066861888 run_lib.py:133] step: 366750, training_loss: 1.80255e-02
I0216 08:57:19.700793 23126066861888 run_lib.py:133] step: 366800, training_loss: 1.78548e-02
I0216 08:57:19.859021 23126066861888 run_lib.py:146] step: 366800, eval_loss: 2.64263e-02
I0216 08:57:37.331225 23126066861888 run_lib.py:133] step: 366850, training_loss: 1.77900e-02
I0216 08:57:54.601800 23126066861888 run_lib.py:133] step: 366900, training_loss: 1.78995e-02
I0216 08:57:54.756748 23126066861888 run_lib.py:146] step: 366900, eval_loss: 2.82781e-02
I0216 08:58:12.027813 23126066861888 run_lib.py:133] step: 366950, training_loss: 1.79895e-02
I0216 08:58:29.398900 23126066861888 run_lib.py:133] step: 367000, training_loss: 1.76959e-02
I0216 08:58:29.555732 23126066861888 run_lib.py:146] step: 367000, eval_loss: 2.77501e-02
I0216 08:58:46.850416 23126066861888 run_lib.py:133] step: 367050, training_loss: 1.85769e-02
I0216 08:59:04.135919 23126066861888 run_lib.py:133] step: 367100, training_loss: 1.85804e-02
I0216 08:59:04.293886 23126066861888 run_lib.py:146] step: 367100, eval_loss: 2.80662e-02
I0216 08:59:21.714054 23126066861888 run_lib.py:133] step: 367150, training_loss: 1.85630e-02
I0216 08:59:38.968378 23126066861888 run_lib.py:133] step: 367200, training_loss: 1.81311e-02
I0216 08:59:39.126090 23126066861888 run_lib.py:146] step: 367200, eval_loss: 2.80649e-02
I0216 08:59:56.391819 23126066861888 run_lib.py:133] step: 367250, training_loss: 1.78568e-02
I0216 09:00:13.685193 23126066861888 run_lib.py:133] step: 367300, training_loss: 1.73112e-02
I0216 09:00:13.856886 23126066861888 run_lib.py:146] step: 367300, eval_loss: 2.78255e-02
I0216 09:00:31.384976 23126066861888 run_lib.py:133] step: 367350, training_loss: 1.76914e-02
I0216 09:00:48.809262 23126066861888 run_lib.py:133] step: 367400, training_loss: 1.80214e-02
I0216 09:00:48.969401 23126066861888 run_lib.py:146] step: 367400, eval_loss: 2.81317e-02
I0216 09:01:06.381752 23126066861888 run_lib.py:133] step: 367450, training_loss: 1.80195e-02
I0216 09:01:23.801549 23126066861888 run_lib.py:133] step: 367500, training_loss: 1.77650e-02
I0216 09:01:23.955849 23126066861888 run_lib.py:146] step: 367500, eval_loss: 2.80424e-02
I0216 09:01:41.437880 23126066861888 run_lib.py:133] step: 367550, training_loss: 1.84279e-02
I0216 09:01:58.749233 23126066861888 run_lib.py:133] step: 367600, training_loss: 1.77366e-02
I0216 09:01:58.914119 23126066861888 run_lib.py:146] step: 367600, eval_loss: 2.71391e-02
I0216 09:02:16.202701 23126066861888 run_lib.py:133] step: 367650, training_loss: 1.80708e-02
I0216 09:02:33.696033 23126066861888 run_lib.py:133] step: 367700, training_loss: 1.80276e-02
I0216 09:02:33.851834 23126066861888 run_lib.py:146] step: 367700, eval_loss: 2.83606e-02
I0216 09:02:51.108619 23126066861888 run_lib.py:133] step: 367750, training_loss: 1.77714e-02
I0216 09:03:08.507204 23126066861888 run_lib.py:133] step: 367800, training_loss: 1.82908e-02
I0216 09:03:08.664830 23126066861888 run_lib.py:146] step: 367800, eval_loss: 2.83858e-02
I0216 09:03:25.966079 23126066861888 run_lib.py:133] step: 367850, training_loss: 1.79487e-02
I0216 09:03:43.236780 23126066861888 run_lib.py:133] step: 367900, training_loss: 1.76529e-02
I0216 09:03:43.389993 23126066861888 run_lib.py:146] step: 367900, eval_loss: 2.78565e-02
I0216 09:04:00.895703 23126066861888 run_lib.py:133] step: 367950, training_loss: 1.83045e-02
I0216 09:04:18.144908 23126066861888 run_lib.py:133] step: 368000, training_loss: 1.77701e-02
I0216 09:04:18.297878 23126066861888 run_lib.py:146] step: 368000, eval_loss: 2.65286e-02
I0216 09:04:35.532433 23126066861888 run_lib.py:133] step: 368050, training_loss: 1.71735e-02
I0216 09:04:52.926034 23126066861888 run_lib.py:133] step: 368100, training_loss: 1.72576e-02
I0216 09:04:53.083054 23126066861888 run_lib.py:146] step: 368100, eval_loss: 2.75265e-02
I0216 09:05:10.356251 23126066861888 run_lib.py:133] step: 368150, training_loss: 1.79402e-02
I0216 09:05:27.700700 23126066861888 run_lib.py:133] step: 368200, training_loss: 1.73432e-02
I0216 09:05:27.859030 23126066861888 run_lib.py:146] step: 368200, eval_loss: 2.63677e-02
I0216 09:05:45.238406 23126066861888 run_lib.py:133] step: 368250, training_loss: 1.75921e-02
I0216 09:06:02.496011 23126066861888 run_lib.py:133] step: 368300, training_loss: 1.76376e-02
I0216 09:06:02.662873 23126066861888 run_lib.py:146] step: 368300, eval_loss: 2.81040e-02
I0216 09:06:19.966591 23126066861888 run_lib.py:133] step: 368350, training_loss: 1.81666e-02
I0216 09:06:37.229181 23126066861888 run_lib.py:133] step: 368400, training_loss: 1.83318e-02
I0216 09:06:37.380081 23126066861888 run_lib.py:146] step: 368400, eval_loss: 2.74562e-02
I0216 09:06:54.861684 23126066861888 run_lib.py:133] step: 368450, training_loss: 1.80587e-02
I0216 09:07:12.244864 23126066861888 run_lib.py:133] step: 368500, training_loss: 1.79545e-02
I0216 09:07:12.399238 23126066861888 run_lib.py:146] step: 368500, eval_loss: 2.82379e-02
I0216 09:07:29.695729 23126066861888 run_lib.py:133] step: 368550, training_loss: 1.82079e-02
I0216 09:07:46.941796 23126066861888 run_lib.py:133] step: 368600, training_loss: 1.75112e-02
I0216 09:07:47.100301 23126066861888 run_lib.py:146] step: 368600, eval_loss: 2.69928e-02
I0216 09:08:04.483838 23126066861888 run_lib.py:133] step: 368650, training_loss: 1.76760e-02
I0216 09:08:21.707024 23126066861888 run_lib.py:133] step: 368700, training_loss: 1.75724e-02
I0216 09:08:21.869809 23126066861888 run_lib.py:146] step: 368700, eval_loss: 2.82551e-02
I0216 09:08:39.157807 23126066861888 run_lib.py:133] step: 368750, training_loss: 1.85504e-02
I0216 09:08:56.619385 23126066861888 run_lib.py:133] step: 368800, training_loss: 1.76524e-02
I0216 09:08:56.774018 23126066861888 run_lib.py:146] step: 368800, eval_loss: 2.65644e-02
I0216 09:09:14.054956 23126066861888 run_lib.py:133] step: 368850, training_loss: 1.79032e-02
I0216 09:09:31.538134 23126066861888 run_lib.py:133] step: 368900, training_loss: 1.72933e-02
I0216 09:09:31.689019 23126066861888 run_lib.py:146] step: 368900, eval_loss: 2.84471e-02
I0216 09:09:49.004705 23126066861888 run_lib.py:133] step: 368950, training_loss: 1.79667e-02
I0216 09:10:06.310289 23126066861888 run_lib.py:133] step: 369000, training_loss: 1.81484e-02
I0216 09:10:06.471187 23126066861888 run_lib.py:146] step: 369000, eval_loss: 2.89346e-02
I0216 09:10:24.052784 23126066861888 run_lib.py:133] step: 369050, training_loss: 1.79949e-02
I0216 09:10:41.510173 23126066861888 run_lib.py:133] step: 369100, training_loss: 1.80355e-02
I0216 09:10:41.676045 23126066861888 run_lib.py:146] step: 369100, eval_loss: 2.82912e-02
I0216 09:10:58.994868 23126066861888 run_lib.py:133] step: 369150, training_loss: 1.82760e-02
I0216 09:11:16.412405 23126066861888 run_lib.py:133] step: 369200, training_loss: 1.88727e-02
I0216 09:11:16.568906 23126066861888 run_lib.py:146] step: 369200, eval_loss: 2.70527e-02
I0216 09:11:33.834811 23126066861888 run_lib.py:133] step: 369250, training_loss: 1.78464e-02
I0216 09:11:51.085145 23126066861888 run_lib.py:133] step: 369300, training_loss: 1.85759e-02
I0216 09:11:51.237633 23126066861888 run_lib.py:146] step: 369300, eval_loss: 2.87160e-02
I0216 09:12:08.544644 23126066861888 run_lib.py:133] step: 369350, training_loss: 1.79094e-02
I0216 09:12:25.834500 23126066861888 run_lib.py:133] step: 369400, training_loss: 1.79880e-02
I0216 09:12:25.989023 23126066861888 run_lib.py:146] step: 369400, eval_loss: 2.78564e-02
I0216 09:12:43.312709 23126066861888 run_lib.py:133] step: 369450, training_loss: 1.74739e-02
I0216 09:13:00.603886 23126066861888 run_lib.py:133] step: 369500, training_loss: 1.72782e-02
I0216 09:13:00.754657 23126066861888 run_lib.py:146] step: 369500, eval_loss: 2.64018e-02
I0216 09:13:18.168882 23126066861888 run_lib.py:133] step: 369550, training_loss: 1.75274e-02
I0216 09:13:35.492224 23126066861888 run_lib.py:133] step: 369600, training_loss: 1.72979e-02
I0216 09:13:35.653010 23126066861888 run_lib.py:146] step: 369600, eval_loss: 2.70922e-02
I0216 09:13:52.920696 23126066861888 run_lib.py:133] step: 369650, training_loss: 1.82389e-02
I0216 09:14:10.234437 23126066861888 run_lib.py:133] step: 369700, training_loss: 1.78035e-02
I0216 09:14:10.388028 23126066861888 run_lib.py:146] step: 369700, eval_loss: 2.75550e-02
I0216 09:14:27.885699 23126066861888 run_lib.py:133] step: 369750, training_loss: 1.75989e-02
I0216 09:14:45.158272 23126066861888 run_lib.py:133] step: 369800, training_loss: 1.81755e-02
I0216 09:14:45.330931 23126066861888 run_lib.py:146] step: 369800, eval_loss: 2.76012e-02
I0216 09:15:02.578683 23126066861888 run_lib.py:133] step: 369850, training_loss: 1.83762e-02
I0216 09:15:20.031974 23126066861888 run_lib.py:133] step: 369900, training_loss: 1.77246e-02
I0216 09:15:20.205705 23126066861888 run_lib.py:146] step: 369900, eval_loss: 2.74813e-02
I0216 09:15:37.521186 23126066861888 run_lib.py:133] step: 369950, training_loss: 1.81353e-02
I0216 09:15:55.003632 23126066861888 run_lib.py:133] step: 370000, training_loss: 1.75827e-02
I0216 09:15:55.940609 23126066861888 run_lib.py:146] step: 370000, eval_loss: 2.74921e-02
I0216 09:16:16.045747 23126066861888 run_lib.py:133] step: 370050, training_loss: 1.78648e-02
I0216 09:16:33.318670 23126066861888 run_lib.py:133] step: 370100, training_loss: 1.77186e-02
I0216 09:16:33.476301 23126066861888 run_lib.py:146] step: 370100, eval_loss: 2.88328e-02
I0216 09:16:50.745652 23126066861888 run_lib.py:133] step: 370150, training_loss: 1.85039e-02
I0216 09:17:08.053901 23126066861888 run_lib.py:133] step: 370200, training_loss: 1.76475e-02
I0216 09:17:08.211070 23126066861888 run_lib.py:146] step: 370200, eval_loss: 2.82121e-02
I0216 09:17:25.663404 23126066861888 run_lib.py:133] step: 370250, training_loss: 1.75011e-02
I0216 09:17:42.995923 23126066861888 run_lib.py:133] step: 370300, training_loss: 1.79914e-02
I0216 09:17:43.153763 23126066861888 run_lib.py:146] step: 370300, eval_loss: 2.77192e-02
I0216 09:18:00.409998 23126066861888 run_lib.py:133] step: 370350, training_loss: 1.78766e-02
I0216 09:18:17.648343 23126066861888 run_lib.py:133] step: 370400, training_loss: 1.83056e-02
I0216 09:18:17.802921 23126066861888 run_lib.py:146] step: 370400, eval_loss: 2.77034e-02
I0216 09:18:35.215522 23126066861888 run_lib.py:133] step: 370450, training_loss: 1.81058e-02
I0216 09:18:52.586208 23126066861888 run_lib.py:133] step: 370500, training_loss: 1.79551e-02
I0216 09:18:52.754197 23126066861888 run_lib.py:146] step: 370500, eval_loss: 2.73971e-02
I0216 09:19:10.113235 23126066861888 run_lib.py:133] step: 370550, training_loss: 1.84494e-02
I0216 09:19:27.687456 23126066861888 run_lib.py:133] step: 370600, training_loss: 1.74928e-02
I0216 09:19:27.843148 23126066861888 run_lib.py:146] step: 370600, eval_loss: 2.85038e-02
I0216 09:19:45.200889 23126066861888 run_lib.py:133] step: 370650, training_loss: 1.74233e-02
I0216 09:20:02.781681 23126066861888 run_lib.py:133] step: 370700, training_loss: 1.72098e-02
I0216 09:20:02.942821 23126066861888 run_lib.py:146] step: 370700, eval_loss: 2.90311e-02
I0216 09:20:20.275861 23126066861888 run_lib.py:133] step: 370750, training_loss: 1.71405e-02
I0216 09:20:37.581953 23126066861888 run_lib.py:133] step: 370800, training_loss: 1.84083e-02
I0216 09:20:37.734763 23126066861888 run_lib.py:146] step: 370800, eval_loss: 2.84384e-02
I0216 09:20:55.236028 23126066861888 run_lib.py:133] step: 370850, training_loss: 1.75269e-02
I0216 09:21:12.518625 23126066861888 run_lib.py:133] step: 370900, training_loss: 1.71842e-02
I0216 09:21:12.669944 23126066861888 run_lib.py:146] step: 370900, eval_loss: 2.75799e-02
I0216 09:21:29.910552 23126066861888 run_lib.py:133] step: 370950, training_loss: 1.77190e-02
I0216 09:21:47.325260 23126066861888 run_lib.py:133] step: 371000, training_loss: 1.75990e-02
I0216 09:21:47.492769 23126066861888 run_lib.py:146] step: 371000, eval_loss: 2.84085e-02
I0216 09:22:04.777550 23126066861888 run_lib.py:133] step: 371050, training_loss: 1.74060e-02
I0216 09:22:22.057352 23126066861888 run_lib.py:133] step: 371100, training_loss: 1.71338e-02
I0216 09:22:22.213896 23126066861888 run_lib.py:146] step: 371100, eval_loss: 2.94562e-02
I0216 09:22:39.580515 23126066861888 run_lib.py:133] step: 371150, training_loss: 1.79538e-02
I0216 09:22:56.801437 23126066861888 run_lib.py:133] step: 371200, training_loss: 1.83327e-02
I0216 09:22:56.953813 23126066861888 run_lib.py:146] step: 371200, eval_loss: 2.89278e-02
I0216 09:23:14.223717 23126066861888 run_lib.py:133] step: 371250, training_loss: 1.79789e-02
I0216 09:23:31.533125 23126066861888 run_lib.py:133] step: 371300, training_loss: 1.79421e-02
I0216 09:23:31.713792 23126066861888 run_lib.py:146] step: 371300, eval_loss: 2.73300e-02
I0216 09:23:49.186844 23126066861888 run_lib.py:133] step: 371350, training_loss: 1.82186e-02
I0216 09:24:06.508841 23126066861888 run_lib.py:133] step: 371400, training_loss: 1.84069e-02
I0216 09:24:06.661896 23126066861888 run_lib.py:146] step: 371400, eval_loss: 2.93300e-02
I0216 09:24:23.928429 23126066861888 run_lib.py:133] step: 371450, training_loss: 1.76580e-02
I0216 09:24:41.152071 23126066861888 run_lib.py:133] step: 371500, training_loss: 1.80638e-02
I0216 09:24:41.334795 23126066861888 run_lib.py:146] step: 371500, eval_loss: 2.73450e-02
I0216 09:24:58.740243 23126066861888 run_lib.py:133] step: 371550, training_loss: 1.85176e-02
I0216 09:25:16.025153 23126066861888 run_lib.py:133] step: 371600, training_loss: 1.72639e-02
I0216 09:25:16.180028 23126066861888 run_lib.py:146] step: 371600, eval_loss: 2.77608e-02
I0216 09:25:33.438737 23126066861888 run_lib.py:133] step: 371650, training_loss: 1.76034e-02
I0216 09:25:50.837867 23126066861888 run_lib.py:133] step: 371700, training_loss: 1.76980e-02
I0216 09:25:50.991707 23126066861888 run_lib.py:146] step: 371700, eval_loss: 2.80988e-02
I0216 09:26:08.258772 23126066861888 run_lib.py:133] step: 371750, training_loss: 1.77588e-02
I0216 09:26:25.670184 23126066861888 run_lib.py:133] step: 371800, training_loss: 1.76339e-02
I0216 09:26:25.822790 23126066861888 run_lib.py:146] step: 371800, eval_loss: 2.69944e-02
I0216 09:26:43.184064 23126066861888 run_lib.py:133] step: 371850, training_loss: 1.82104e-02
I0216 09:27:00.416839 23126066861888 run_lib.py:133] step: 371900, training_loss: 1.78380e-02
I0216 09:27:00.570197 23126066861888 run_lib.py:146] step: 371900, eval_loss: 2.75025e-02
I0216 09:27:18.018295 23126066861888 run_lib.py:133] step: 371950, training_loss: 1.75367e-02
I0216 09:27:35.273753 23126066861888 run_lib.py:133] step: 372000, training_loss: 1.77911e-02
I0216 09:27:35.431032 23126066861888 run_lib.py:146] step: 372000, eval_loss: 2.88058e-02
I0216 09:27:52.681009 23126066861888 run_lib.py:133] step: 372050, training_loss: 1.74972e-02
I0216 09:28:10.148317 23126066861888 run_lib.py:133] step: 372100, training_loss: 1.80529e-02
I0216 09:28:10.315958 23126066861888 run_lib.py:146] step: 372100, eval_loss: 2.76404e-02
I0216 09:28:27.648725 23126066861888 run_lib.py:133] step: 372150, training_loss: 1.78274e-02
I0216 09:28:45.004910 23126066861888 run_lib.py:133] step: 372200, training_loss: 1.81898e-02
I0216 09:28:45.159025 23126066861888 run_lib.py:146] step: 372200, eval_loss: 2.74133e-02
I0216 09:29:02.675181 23126066861888 run_lib.py:133] step: 372250, training_loss: 1.84285e-02
I0216 09:29:20.107119 23126066861888 run_lib.py:133] step: 372300, training_loss: 1.75547e-02
I0216 09:29:20.263121 23126066861888 run_lib.py:146] step: 372300, eval_loss: 2.80090e-02
I0216 09:29:37.563569 23126066861888 run_lib.py:133] step: 372350, training_loss: 1.76372e-02
I0216 09:29:54.848470 23126066861888 run_lib.py:133] step: 372400, training_loss: 1.74676e-02
I0216 09:29:55.018077 23126066861888 run_lib.py:146] step: 372400, eval_loss: 2.71638e-02
I0216 09:30:12.439978 23126066861888 run_lib.py:133] step: 372450, training_loss: 1.81280e-02
I0216 09:30:29.756471 23126066861888 run_lib.py:133] step: 372500, training_loss: 1.77205e-02
I0216 09:30:29.914178 23126066861888 run_lib.py:146] step: 372500, eval_loss: 2.79108e-02
I0216 09:30:47.185550 23126066861888 run_lib.py:133] step: 372550, training_loss: 1.77129e-02
I0216 09:31:04.400069 23126066861888 run_lib.py:133] step: 372600, training_loss: 1.75036e-02
I0216 09:31:04.554914 23126066861888 run_lib.py:146] step: 372600, eval_loss: 2.91557e-02
I0216 09:31:21.960872 23126066861888 run_lib.py:133] step: 372650, training_loss: 1.75199e-02
I0216 09:31:39.277292 23126066861888 run_lib.py:133] step: 372700, training_loss: 1.78238e-02
I0216 09:31:39.431321 23126066861888 run_lib.py:146] step: 372700, eval_loss: 2.81822e-02
I0216 09:31:56.720329 23126066861888 run_lib.py:133] step: 372750, training_loss: 1.78005e-02
I0216 09:32:14.193603 23126066861888 run_lib.py:133] step: 372800, training_loss: 1.79326e-02
I0216 09:32:14.342320 23126066861888 run_lib.py:146] step: 372800, eval_loss: 2.82498e-02
I0216 09:32:31.602509 23126066861888 run_lib.py:133] step: 372850, training_loss: 1.81577e-02
I0216 09:32:49.081928 23126066861888 run_lib.py:133] step: 372900, training_loss: 1.82052e-02
I0216 09:32:49.252005 23126066861888 run_lib.py:146] step: 372900, eval_loss: 2.81455e-02
I0216 09:33:06.606088 23126066861888 run_lib.py:133] step: 372950, training_loss: 1.72476e-02
I0216 09:33:23.864384 23126066861888 run_lib.py:133] step: 373000, training_loss: 1.79744e-02
I0216 09:33:24.019025 23126066861888 run_lib.py:146] step: 373000, eval_loss: 2.72664e-02
I0216 09:33:41.499014 23126066861888 run_lib.py:133] step: 373050, training_loss: 1.78730e-02
I0216 09:33:58.741386 23126066861888 run_lib.py:133] step: 373100, training_loss: 1.77286e-02
I0216 09:33:58.904131 23126066861888 run_lib.py:146] step: 373100, eval_loss: 2.86881e-02
I0216 09:34:16.167401 23126066861888 run_lib.py:133] step: 373150, training_loss: 1.79453e-02
I0216 09:34:33.723722 23126066861888 run_lib.py:133] step: 373200, training_loss: 1.80218e-02
I0216 09:34:33.876746 23126066861888 run_lib.py:146] step: 373200, eval_loss: 2.76478e-02
I0216 09:34:51.154345 23126066861888 run_lib.py:133] step: 373250, training_loss: 1.78013e-02
I0216 09:35:08.401683 23126066861888 run_lib.py:133] step: 373300, training_loss: 1.77850e-02
I0216 09:35:08.554013 23126066861888 run_lib.py:146] step: 373300, eval_loss: 2.83091e-02
I0216 09:35:25.842503 23126066861888 run_lib.py:133] step: 373350, training_loss: 1.84824e-02
I0216 09:35:43.117027 23126066861888 run_lib.py:133] step: 373400, training_loss: 1.77738e-02
I0216 09:35:43.284120 23126066861888 run_lib.py:146] step: 373400, eval_loss: 2.83069e-02
I0216 09:36:00.583817 23126066861888 run_lib.py:133] step: 373450, training_loss: 1.73228e-02
I0216 09:36:17.893770 23126066861888 run_lib.py:133] step: 373500, training_loss: 1.80229e-02
I0216 09:36:18.048209 23126066861888 run_lib.py:146] step: 373500, eval_loss: 2.81945e-02
I0216 09:36:35.505657 23126066861888 run_lib.py:133] step: 373550, training_loss: 1.79559e-02
I0216 09:36:52.830425 23126066861888 run_lib.py:133] step: 373600, training_loss: 1.78059e-02
I0216 09:36:52.983147 23126066861888 run_lib.py:146] step: 373600, eval_loss: 2.80332e-02
I0216 09:37:10.265070 23126066861888 run_lib.py:133] step: 373650, training_loss: 1.77773e-02
I0216 09:37:27.538293 23126066861888 run_lib.py:133] step: 373700, training_loss: 1.89236e-02
I0216 09:37:27.688863 23126066861888 run_lib.py:146] step: 373700, eval_loss: 2.76769e-02
I0216 09:37:45.213203 23126066861888 run_lib.py:133] step: 373750, training_loss: 1.74809e-02
I0216 09:38:02.496348 23126066861888 run_lib.py:133] step: 373800, training_loss: 1.78291e-02
I0216 09:38:02.649034 23126066861888 run_lib.py:146] step: 373800, eval_loss: 2.83845e-02
I0216 09:38:19.885213 23126066861888 run_lib.py:133] step: 373850, training_loss: 1.75444e-02
I0216 09:38:37.309474 23126066861888 run_lib.py:133] step: 373900, training_loss: 1.86029e-02
I0216 09:38:37.465323 23126066861888 run_lib.py:146] step: 373900, eval_loss: 2.75849e-02
I0216 09:38:54.740762 23126066861888 run_lib.py:133] step: 373950, training_loss: 1.81131e-02
I0216 09:39:12.133585 23126066861888 run_lib.py:133] step: 374000, training_loss: 1.79917e-02
I0216 09:39:12.300750 23126066861888 run_lib.py:146] step: 374000, eval_loss: 2.91477e-02
I0216 09:39:29.570104 23126066861888 run_lib.py:133] step: 374050, training_loss: 1.76957e-02
I0216 09:39:46.833338 23126066861888 run_lib.py:133] step: 374100, training_loss: 1.81044e-02
I0216 09:39:46.994168 23126066861888 run_lib.py:146] step: 374100, eval_loss: 2.76023e-02
I0216 09:40:04.491454 23126066861888 run_lib.py:133] step: 374150, training_loss: 1.81099e-02
I0216 09:40:21.784312 23126066861888 run_lib.py:133] step: 374200, training_loss: 1.84111e-02
I0216 09:40:21.935088 23126066861888 run_lib.py:146] step: 374200, eval_loss: 2.75122e-02
I0216 09:40:39.247558 23126066861888 run_lib.py:133] step: 374250, training_loss: 1.71346e-02
I0216 09:40:56.716043 23126066861888 run_lib.py:133] step: 374300, training_loss: 1.77719e-02
I0216 09:40:56.881297 23126066861888 run_lib.py:146] step: 374300, eval_loss: 2.93633e-02
I0216 09:41:14.206778 23126066861888 run_lib.py:133] step: 374350, training_loss: 1.73756e-02
I0216 09:41:31.502275 23126066861888 run_lib.py:133] step: 374400, training_loss: 1.75018e-02
I0216 09:41:31.656203 23126066861888 run_lib.py:146] step: 374400, eval_loss: 2.92386e-02
I0216 09:41:48.988832 23126066861888 run_lib.py:133] step: 374450, training_loss: 1.72454e-02
I0216 09:42:06.294231 23126066861888 run_lib.py:133] step: 374500, training_loss: 1.75174e-02
I0216 09:42:06.448292 23126066861888 run_lib.py:146] step: 374500, eval_loss: 2.89418e-02
I0216 09:42:23.714578 23126066861888 run_lib.py:133] step: 374550, training_loss: 1.76794e-02
I0216 09:42:40.989809 23126066861888 run_lib.py:133] step: 374600, training_loss: 1.78548e-02
I0216 09:42:41.142715 23126066861888 run_lib.py:146] step: 374600, eval_loss: 2.73806e-02
I0216 09:42:58.563176 23126066861888 run_lib.py:133] step: 374650, training_loss: 1.70269e-02
I0216 09:43:15.875558 23126066861888 run_lib.py:133] step: 374700, training_loss: 1.79026e-02
I0216 09:43:16.045004 23126066861888 run_lib.py:146] step: 374700, eval_loss: 2.83357e-02
I0216 09:43:33.347668 23126066861888 run_lib.py:133] step: 374750, training_loss: 1.82355e-02
I0216 09:43:50.664264 23126066861888 run_lib.py:133] step: 374800, training_loss: 1.78203e-02
I0216 09:43:50.828972 23126066861888 run_lib.py:146] step: 374800, eval_loss: 2.79642e-02
I0216 09:44:08.256824 23126066861888 run_lib.py:133] step: 374850, training_loss: 1.84611e-02
I0216 09:44:25.525265 23126066861888 run_lib.py:133] step: 374900, training_loss: 1.78367e-02
I0216 09:44:25.680249 23126066861888 run_lib.py:146] step: 374900, eval_loss: 2.80210e-02
I0216 09:44:42.911438 23126066861888 run_lib.py:133] step: 374950, training_loss: 1.76683e-02
I0216 09:45:00.326324 23126066861888 run_lib.py:133] step: 375000, training_loss: 1.81179e-02
I0216 09:45:00.482767 23126066861888 run_lib.py:146] step: 375000, eval_loss: 2.76333e-02
I0216 09:45:17.776266 23126066861888 run_lib.py:133] step: 375050, training_loss: 1.71869e-02
I0216 09:45:35.221165 23126066861888 run_lib.py:133] step: 375100, training_loss: 1.75305e-02
I0216 09:45:35.374738 23126066861888 run_lib.py:146] step: 375100, eval_loss: 2.67707e-02
I0216 09:45:52.643491 23126066861888 run_lib.py:133] step: 375150, training_loss: 1.78420e-02
I0216 09:46:09.902995 23126066861888 run_lib.py:133] step: 375200, training_loss: 1.79105e-02
I0216 09:46:10.054962 23126066861888 run_lib.py:146] step: 375200, eval_loss: 2.87525e-02
I0216 09:46:27.449103 23126066861888 run_lib.py:133] step: 375250, training_loss: 1.79656e-02
I0216 09:46:44.718191 23126066861888 run_lib.py:133] step: 375300, training_loss: 1.84378e-02
I0216 09:46:44.878256 23126066861888 run_lib.py:146] step: 375300, eval_loss: 2.78699e-02
I0216 09:47:02.191208 23126066861888 run_lib.py:133] step: 375350, training_loss: 1.78059e-02
I0216 09:47:19.677503 23126066861888 run_lib.py:133] step: 375400, training_loss: 1.78737e-02
I0216 09:47:19.831177 23126066861888 run_lib.py:146] step: 375400, eval_loss: 2.89779e-02
I0216 09:47:37.121358 23126066861888 run_lib.py:133] step: 375450, training_loss: 1.81371e-02
I0216 09:47:54.365607 23126066861888 run_lib.py:133] step: 375500, training_loss: 1.77208e-02
I0216 09:47:54.519201 23126066861888 run_lib.py:146] step: 375500, eval_loss: 2.75977e-02
I0216 09:48:11.859406 23126066861888 run_lib.py:133] step: 375550, training_loss: 1.76727e-02
I0216 09:48:29.165715 23126066861888 run_lib.py:133] step: 375600, training_loss: 1.74563e-02
I0216 09:48:29.315778 23126066861888 run_lib.py:146] step: 375600, eval_loss: 2.73718e-02
I0216 09:48:46.622581 23126066861888 run_lib.py:133] step: 375650, training_loss: 1.79546e-02
I0216 09:49:03.858992 23126066861888 run_lib.py:133] step: 375700, training_loss: 1.79707e-02
I0216 09:49:04.040072 23126066861888 run_lib.py:146] step: 375700, eval_loss: 2.75096e-02
I0216 09:49:21.533577 23126066861888 run_lib.py:133] step: 375750, training_loss: 1.78601e-02
I0216 09:49:38.832856 23126066861888 run_lib.py:133] step: 375800, training_loss: 1.83755e-02
I0216 09:49:38.988106 23126066861888 run_lib.py:146] step: 375800, eval_loss: 2.79142e-02
I0216 09:49:56.234296 23126066861888 run_lib.py:133] step: 375850, training_loss: 1.78729e-02
I0216 09:50:13.506874 23126066861888 run_lib.py:133] step: 375900, training_loss: 1.83857e-02
I0216 09:50:13.663005 23126066861888 run_lib.py:146] step: 375900, eval_loss: 2.67858e-02
I0216 09:50:31.161893 23126066861888 run_lib.py:133] step: 375950, training_loss: 1.75725e-02
I0216 09:50:48.415000 23126066861888 run_lib.py:133] step: 376000, training_loss: 1.76061e-02
I0216 09:50:48.566746 23126066861888 run_lib.py:146] step: 376000, eval_loss: 2.79069e-02
I0216 09:51:05.833591 23126066861888 run_lib.py:133] step: 376050, training_loss: 1.80085e-02
I0216 09:51:23.279467 23126066861888 run_lib.py:133] step: 376100, training_loss: 1.78882e-02
I0216 09:51:23.429054 23126066861888 run_lib.py:146] step: 376100, eval_loss: 2.87912e-02
I0216 09:51:40.705524 23126066861888 run_lib.py:133] step: 376150, training_loss: 1.74659e-02
I0216 09:51:58.135224 23126066861888 run_lib.py:133] step: 376200, training_loss: 1.76227e-02
I0216 09:51:58.301269 23126066861888 run_lib.py:146] step: 376200, eval_loss: 2.81248e-02
I0216 09:52:15.583800 23126066861888 run_lib.py:133] step: 376250, training_loss: 1.72717e-02
I0216 09:52:32.883890 23126066861888 run_lib.py:133] step: 376300, training_loss: 1.78426e-02
I0216 09:52:33.041192 23126066861888 run_lib.py:146] step: 376300, eval_loss: 2.78850e-02
I0216 09:52:50.494961 23126066861888 run_lib.py:133] step: 376350, training_loss: 1.85028e-02
I0216 09:53:07.750083 23126066861888 run_lib.py:133] step: 376400, training_loss: 1.77508e-02
I0216 09:53:07.907058 23126066861888 run_lib.py:146] step: 376400, eval_loss: 2.71693e-02
I0216 09:53:25.264232 23126066861888 run_lib.py:133] step: 376450, training_loss: 1.84239e-02
I0216 09:53:42.749897 23126066861888 run_lib.py:133] step: 376500, training_loss: 1.83590e-02
I0216 09:53:42.903253 23126066861888 run_lib.py:146] step: 376500, eval_loss: 2.78658e-02
I0216 09:54:00.271822 23126066861888 run_lib.py:133] step: 376550, training_loss: 1.75751e-02
I0216 09:54:17.571295 23126066861888 run_lib.py:133] step: 376600, training_loss: 1.79603e-02
I0216 09:54:17.722034 23126066861888 run_lib.py:146] step: 376600, eval_loss: 2.79939e-02
I0216 09:54:35.011060 23126066861888 run_lib.py:133] step: 376650, training_loss: 1.80304e-02
I0216 09:54:52.266862 23126066861888 run_lib.py:133] step: 376700, training_loss: 1.75746e-02
I0216 09:54:52.441157 23126066861888 run_lib.py:146] step: 376700, eval_loss: 2.76692e-02
I0216 09:55:09.801958 23126066861888 run_lib.py:133] step: 376750, training_loss: 1.76411e-02
I0216 09:55:27.062707 23126066861888 run_lib.py:133] step: 376800, training_loss: 1.91275e-02
I0216 09:55:27.217033 23126066861888 run_lib.py:146] step: 376800, eval_loss: 2.79555e-02
I0216 09:55:44.681498 23126066861888 run_lib.py:133] step: 376850, training_loss: 1.77841e-02
I0216 09:56:02.011128 23126066861888 run_lib.py:133] step: 376900, training_loss: 1.74307e-02
I0216 09:56:02.166005 23126066861888 run_lib.py:146] step: 376900, eval_loss: 2.76333e-02
I0216 09:56:19.445705 23126066861888 run_lib.py:133] step: 376950, training_loss: 1.85350e-02
I0216 09:56:36.769073 23126066861888 run_lib.py:133] step: 377000, training_loss: 1.76668e-02
I0216 09:56:36.920850 23126066861888 run_lib.py:146] step: 377000, eval_loss: 2.87685e-02
I0216 09:56:54.452337 23126066861888 run_lib.py:133] step: 377050, training_loss: 1.87376e-02
I0216 09:57:11.702995 23126066861888 run_lib.py:133] step: 377100, training_loss: 1.82279e-02
I0216 09:57:11.855083 23126066861888 run_lib.py:146] step: 377100, eval_loss: 2.66015e-02
I0216 09:57:29.101213 23126066861888 run_lib.py:133] step: 377150, training_loss: 1.76771e-02
I0216 09:57:46.571465 23126066861888 run_lib.py:133] step: 377200, training_loss: 1.76765e-02
I0216 09:57:46.735138 23126066861888 run_lib.py:146] step: 377200, eval_loss: 2.73304e-02
I0216 09:58:04.006792 23126066861888 run_lib.py:133] step: 377250, training_loss: 1.75071e-02
I0216 09:58:21.559629 23126066861888 run_lib.py:133] step: 377300, training_loss: 1.81823e-02
I0216 09:58:21.720229 23126066861888 run_lib.py:146] step: 377300, eval_loss: 2.77013e-02
I0216 09:58:39.010438 23126066861888 run_lib.py:133] step: 377350, training_loss: 1.67761e-02
I0216 09:58:56.240264 23126066861888 run_lib.py:133] step: 377400, training_loss: 1.82303e-02
I0216 09:58:56.395074 23126066861888 run_lib.py:146] step: 377400, eval_loss: 2.85745e-02
I0216 09:59:13.831350 23126066861888 run_lib.py:133] step: 377450, training_loss: 1.73011e-02
I0216 09:59:31.053031 23126066861888 run_lib.py:133] step: 377500, training_loss: 1.81692e-02
I0216 09:59:31.203986 23126066861888 run_lib.py:146] step: 377500, eval_loss: 2.81171e-02
I0216 09:59:48.436294 23126066861888 run_lib.py:133] step: 377550, training_loss: 1.75567e-02
I0216 10:00:06.039681 23126066861888 run_lib.py:133] step: 377600, training_loss: 1.73400e-02
I0216 10:00:06.213022 23126066861888 run_lib.py:146] step: 377600, eval_loss: 2.92811e-02
I0216 10:00:23.641356 23126066861888 run_lib.py:133] step: 377650, training_loss: 1.85539e-02
I0216 10:00:41.067497 23126066861888 run_lib.py:133] step: 377700, training_loss: 1.73805e-02
I0216 10:00:41.225425 23126066861888 run_lib.py:146] step: 377700, eval_loss: 2.73084e-02
I0216 10:00:58.731647 23126066861888 run_lib.py:133] step: 377750, training_loss: 1.74197e-02
I0216 10:01:16.197075 23126066861888 run_lib.py:133] step: 377800, training_loss: 1.84360e-02
I0216 10:01:16.351056 23126066861888 run_lib.py:146] step: 377800, eval_loss: 2.71861e-02
I0216 10:01:33.673207 23126066861888 run_lib.py:133] step: 377850, training_loss: 1.79486e-02
I0216 10:01:51.342981 23126066861888 run_lib.py:133] step: 377900, training_loss: 1.78486e-02
I0216 10:01:51.501539 23126066861888 run_lib.py:146] step: 377900, eval_loss: 2.90121e-02
I0216 10:02:09.236852 23126066861888 run_lib.py:133] step: 377950, training_loss: 1.74146e-02
I0216 10:02:26.833827 23126066861888 run_lib.py:133] step: 378000, training_loss: 1.72626e-02
I0216 10:02:26.988189 23126066861888 run_lib.py:146] step: 378000, eval_loss: 2.82220e-02
I0216 10:02:44.481045 23126066861888 run_lib.py:133] step: 378050, training_loss: 1.76654e-02
I0216 10:03:01.994556 23126066861888 run_lib.py:133] step: 378100, training_loss: 1.79903e-02
I0216 10:03:02.163544 23126066861888 run_lib.py:146] step: 378100, eval_loss: 2.96822e-02
I0216 10:03:19.919111 23126066861888 run_lib.py:133] step: 378150, training_loss: 1.73824e-02
I0216 10:03:37.480059 23126066861888 run_lib.py:133] step: 378200, training_loss: 1.80035e-02
I0216 10:03:37.641355 23126066861888 run_lib.py:146] step: 378200, eval_loss: 2.64959e-02
I0216 10:03:55.153499 23126066861888 run_lib.py:133] step: 378250, training_loss: 1.77599e-02
I0216 10:04:12.863959 23126066861888 run_lib.py:133] step: 378300, training_loss: 1.84147e-02
I0216 10:04:13.021287 23126066861888 run_lib.py:146] step: 378300, eval_loss: 2.80069e-02
I0216 10:04:30.539151 23126066861888 run_lib.py:133] step: 378350, training_loss: 1.76656e-02
I0216 10:04:48.297583 23126066861888 run_lib.py:133] step: 378400, training_loss: 1.76046e-02
I0216 10:04:48.458830 23126066861888 run_lib.py:146] step: 378400, eval_loss: 2.79639e-02
I0216 10:05:06.031133 23126066861888 run_lib.py:133] step: 378450, training_loss: 1.80284e-02
I0216 10:05:23.573029 23126066861888 run_lib.py:133] step: 378500, training_loss: 1.83933e-02
I0216 10:05:23.728275 23126066861888 run_lib.py:146] step: 378500, eval_loss: 2.90636e-02
I0216 10:05:41.506050 23126066861888 run_lib.py:133] step: 378550, training_loss: 1.79202e-02
I0216 10:05:59.104234 23126066861888 run_lib.py:133] step: 378600, training_loss: 1.82561e-02
I0216 10:05:59.266431 23126066861888 run_lib.py:146] step: 378600, eval_loss: 2.80954e-02
I0216 10:06:16.772598 23126066861888 run_lib.py:133] step: 378650, training_loss: 1.82536e-02
I0216 10:06:34.519402 23126066861888 run_lib.py:133] step: 378700, training_loss: 1.75101e-02
I0216 10:06:34.676174 23126066861888 run_lib.py:146] step: 378700, eval_loss: 2.78617e-02
I0216 10:06:52.207418 23126066861888 run_lib.py:133] step: 378750, training_loss: 1.74345e-02
I0216 10:07:09.702760 23126066861888 run_lib.py:133] step: 378800, training_loss: 1.75212e-02
I0216 10:07:09.856977 23126066861888 run_lib.py:146] step: 378800, eval_loss: 2.77772e-02
I0216 10:07:27.534745 23126066861888 run_lib.py:133] step: 378850, training_loss: 1.87764e-02
I0216 10:07:45.031827 23126066861888 run_lib.py:133] step: 378900, training_loss: 1.76311e-02
I0216 10:07:45.182617 23126066861888 run_lib.py:146] step: 378900, eval_loss: 2.92675e-02
I0216 10:08:02.689064 23126066861888 run_lib.py:133] step: 378950, training_loss: 1.76621e-02
I0216 10:08:20.219569 23126066861888 run_lib.py:133] step: 379000, training_loss: 1.77117e-02
I0216 10:08:20.383273 23126066861888 run_lib.py:146] step: 379000, eval_loss: 2.82891e-02
I0216 10:08:38.094706 23126066861888 run_lib.py:133] step: 379050, training_loss: 1.84869e-02
I0216 10:08:55.720659 23126066861888 run_lib.py:133] step: 379100, training_loss: 1.75747e-02
I0216 10:08:55.881246 23126066861888 run_lib.py:146] step: 379100, eval_loss: 2.90273e-02
I0216 10:09:13.344221 23126066861888 run_lib.py:133] step: 379150, training_loss: 1.84405e-02
I0216 10:09:30.831695 23126066861888 run_lib.py:133] step: 379200, training_loss: 1.77809e-02
I0216 10:09:30.991021 23126066861888 run_lib.py:146] step: 379200, eval_loss: 2.82387e-02
I0216 10:09:48.716304 23126066861888 run_lib.py:133] step: 379250, training_loss: 1.76425e-02
I0216 10:10:06.237152 23126066861888 run_lib.py:133] step: 379300, training_loss: 1.87589e-02
I0216 10:10:06.399886 23126066861888 run_lib.py:146] step: 379300, eval_loss: 2.80446e-02
I0216 10:10:23.910437 23126066861888 run_lib.py:133] step: 379350, training_loss: 1.83637e-02
I0216 10:10:41.654766 23126066861888 run_lib.py:133] step: 379400, training_loss: 1.72785e-02
I0216 10:10:41.807997 23126066861888 run_lib.py:146] step: 379400, eval_loss: 2.78507e-02
I0216 10:10:59.299901 23126066861888 run_lib.py:133] step: 379450, training_loss: 1.82804e-02
I0216 10:11:16.973098 23126066861888 run_lib.py:133] step: 379500, training_loss: 1.81705e-02
I0216 10:11:17.148301 23126066861888 run_lib.py:146] step: 379500, eval_loss: 2.81687e-02
I0216 10:11:34.666186 23126066861888 run_lib.py:133] step: 379550, training_loss: 1.79827e-02
I0216 10:11:52.170354 23126066861888 run_lib.py:133] step: 379600, training_loss: 1.71983e-02
I0216 10:11:52.329860 23126066861888 run_lib.py:146] step: 379600, eval_loss: 2.76102e-02
I0216 10:12:10.070391 23126066861888 run_lib.py:133] step: 379650, training_loss: 1.84859e-02
I0216 10:12:27.545959 23126066861888 run_lib.py:133] step: 379700, training_loss: 1.85740e-02
I0216 10:12:27.703195 23126066861888 run_lib.py:146] step: 379700, eval_loss: 2.80589e-02
I0216 10:12:45.162615 23126066861888 run_lib.py:133] step: 379750, training_loss: 1.72880e-02
I0216 10:13:02.884093 23126066861888 run_lib.py:133] step: 379800, training_loss: 1.76794e-02
I0216 10:13:03.041331 23126066861888 run_lib.py:146] step: 379800, eval_loss: 2.68689e-02
I0216 10:13:20.603312 23126066861888 run_lib.py:133] step: 379850, training_loss: 1.76562e-02
I0216 10:13:38.104063 23126066861888 run_lib.py:133] step: 379900, training_loss: 1.82304e-02
I0216 10:13:38.254841 23126066861888 run_lib.py:146] step: 379900, eval_loss: 2.76994e-02
I0216 10:13:55.856933 23126066861888 run_lib.py:133] step: 379950, training_loss: 1.78126e-02
I0216 10:14:13.333378 23126066861888 run_lib.py:133] step: 380000, training_loss: 1.76736e-02
I0216 10:14:14.085237 23126066861888 run_lib.py:146] step: 380000, eval_loss: 2.79839e-02
I0216 10:14:34.312365 23126066861888 run_lib.py:133] step: 380050, training_loss: 1.76483e-02
I0216 10:14:51.832352 23126066861888 run_lib.py:133] step: 380100, training_loss: 1.76829e-02
I0216 10:14:51.993100 23126066861888 run_lib.py:146] step: 380100, eval_loss: 2.81804e-02
I0216 10:15:09.436753 23126066861888 run_lib.py:133] step: 380150, training_loss: 1.84746e-02
I0216 10:15:27.136435 23126066861888 run_lib.py:133] step: 380200, training_loss: 1.71948e-02
I0216 10:15:27.295217 23126066861888 run_lib.py:146] step: 380200, eval_loss: 2.80358e-02
I0216 10:15:44.906807 23126066861888 run_lib.py:133] step: 380250, training_loss: 1.80964e-02
I0216 10:16:02.403646 23126066861888 run_lib.py:133] step: 380300, training_loss: 1.76292e-02
I0216 10:16:02.566251 23126066861888 run_lib.py:146] step: 380300, eval_loss: 2.92457e-02
I0216 10:16:20.067891 23126066861888 run_lib.py:133] step: 380350, training_loss: 1.73828e-02
I0216 10:16:37.610676 23126066861888 run_lib.py:133] step: 380400, training_loss: 1.77552e-02
I0216 10:16:37.775323 23126066861888 run_lib.py:146] step: 380400, eval_loss: 2.77487e-02
I0216 10:16:55.560416 23126066861888 run_lib.py:133] step: 380450, training_loss: 1.81580e-02
I0216 10:17:13.087942 23126066861888 run_lib.py:133] step: 380500, training_loss: 1.78720e-02
I0216 10:17:13.252030 23126066861888 run_lib.py:146] step: 380500, eval_loss: 2.74606e-02
I0216 10:17:30.918321 23126066861888 run_lib.py:133] step: 380550, training_loss: 1.71111e-02
I0216 10:17:48.415789 23126066861888 run_lib.py:133] step: 380600, training_loss: 1.76964e-02
I0216 10:17:48.583115 23126066861888 run_lib.py:146] step: 380600, eval_loss: 2.86927e-02
I0216 10:18:06.297882 23126066861888 run_lib.py:133] step: 380650, training_loss: 1.82723e-02
I0216 10:18:23.831250 23126066861888 run_lib.py:133] step: 380700, training_loss: 1.87739e-02
I0216 10:18:23.992228 23126066861888 run_lib.py:146] step: 380700, eval_loss: 2.86105e-02
I0216 10:18:41.474286 23126066861888 run_lib.py:133] step: 380750, training_loss: 1.74150e-02
I0216 10:18:59.180948 23126066861888 run_lib.py:133] step: 380800, training_loss: 1.80768e-02
I0216 10:18:59.338067 23126066861888 run_lib.py:146] step: 380800, eval_loss: 2.87754e-02
I0216 10:19:16.849905 23126066861888 run_lib.py:133] step: 380850, training_loss: 1.76385e-02
I0216 10:19:34.553260 23126066861888 run_lib.py:133] step: 380900, training_loss: 1.87915e-02
I0216 10:19:34.711164 23126066861888 run_lib.py:146] step: 380900, eval_loss: 2.76081e-02
I0216 10:19:52.259555 23126066861888 run_lib.py:133] step: 380950, training_loss: 1.76476e-02
I0216 10:20:09.740851 23126066861888 run_lib.py:133] step: 381000, training_loss: 1.73047e-02
I0216 10:20:09.900350 23126066861888 run_lib.py:146] step: 381000, eval_loss: 2.72545e-02
I0216 10:20:27.401223 23126066861888 run_lib.py:133] step: 381050, training_loss: 1.77506e-02
I0216 10:20:45.158995 23126066861888 run_lib.py:133] step: 381100, training_loss: 1.74714e-02
I0216 10:20:45.319452 23126066861888 run_lib.py:146] step: 381100, eval_loss: 2.79485e-02
I0216 10:21:02.794590 23126066861888 run_lib.py:133] step: 381150, training_loss: 1.82104e-02
I0216 10:21:20.343892 23126066861888 run_lib.py:133] step: 381200, training_loss: 1.81990e-02
I0216 10:21:20.502344 23126066861888 run_lib.py:146] step: 381200, eval_loss: 2.71599e-02
I0216 10:21:38.245882 23126066861888 run_lib.py:133] step: 381250, training_loss: 1.86426e-02
I0216 10:21:55.740252 23126066861888 run_lib.py:133] step: 381300, training_loss: 1.68549e-02
I0216 10:21:55.897261 23126066861888 run_lib.py:146] step: 381300, eval_loss: 2.86416e-02
I0216 10:22:13.484790 23126066861888 run_lib.py:133] step: 381350, training_loss: 1.80018e-02
I0216 10:22:30.998439 23126066861888 run_lib.py:133] step: 381400, training_loss: 1.86383e-02
I0216 10:22:31.153255 23126066861888 run_lib.py:146] step: 381400, eval_loss: 2.72392e-02
I0216 10:22:48.726144 23126066861888 run_lib.py:133] step: 381450, training_loss: 1.74147e-02
I0216 10:23:06.240681 23126066861888 run_lib.py:133] step: 381500, training_loss: 1.79654e-02
I0216 10:23:06.398962 23126066861888 run_lib.py:146] step: 381500, eval_loss: 2.74803e-02
I0216 10:23:24.141469 23126066861888 run_lib.py:133] step: 381550, training_loss: 1.79896e-02
I0216 10:23:41.785848 23126066861888 run_lib.py:133] step: 381600, training_loss: 1.72168e-02
I0216 10:23:41.987712 23126066861888 run_lib.py:146] step: 381600, eval_loss: 2.73330e-02
I0216 10:23:59.475198 23126066861888 run_lib.py:133] step: 381650, training_loss: 1.82143e-02
I0216 10:24:16.970883 23126066861888 run_lib.py:133] step: 381700, training_loss: 1.78294e-02
I0216 10:24:17.129126 23126066861888 run_lib.py:146] step: 381700, eval_loss: 2.79937e-02
I0216 10:24:34.823969 23126066861888 run_lib.py:133] step: 381750, training_loss: 1.85789e-02
I0216 10:24:52.388662 23126066861888 run_lib.py:133] step: 381800, training_loss: 1.83920e-02
I0216 10:24:52.552408 23126066861888 run_lib.py:146] step: 381800, eval_loss: 2.84495e-02
I0216 10:25:10.062293 23126066861888 run_lib.py:133] step: 381850, training_loss: 1.73979e-02
I0216 10:25:27.818680 23126066861888 run_lib.py:133] step: 381900, training_loss: 1.82073e-02
I0216 10:25:27.974785 23126066861888 run_lib.py:146] step: 381900, eval_loss: 2.76980e-02
I0216 10:25:45.476018 23126066861888 run_lib.py:133] step: 381950, training_loss: 1.75208e-02
I0216 10:26:03.165817 23126066861888 run_lib.py:133] step: 382000, training_loss: 1.77457e-02
I0216 10:26:03.330172 23126066861888 run_lib.py:146] step: 382000, eval_loss: 2.68985e-02
I0216 10:26:20.915685 23126066861888 run_lib.py:133] step: 382050, training_loss: 1.79129e-02
I0216 10:26:38.501678 23126066861888 run_lib.py:133] step: 382100, training_loss: 1.76335e-02
I0216 10:26:38.659426 23126066861888 run_lib.py:146] step: 382100, eval_loss: 2.88317e-02
I0216 10:26:56.420546 23126066861888 run_lib.py:133] step: 382150, training_loss: 1.76903e-02
I0216 10:27:13.915627 23126066861888 run_lib.py:133] step: 382200, training_loss: 1.79816e-02
I0216 10:27:14.077950 23126066861888 run_lib.py:146] step: 382200, eval_loss: 2.79256e-02
I0216 10:27:31.572976 23126066861888 run_lib.py:133] step: 382250, training_loss: 1.75604e-02
I0216 10:27:49.113257 23126066861888 run_lib.py:133] step: 382300, training_loss: 1.78645e-02
I0216 10:27:49.268911 23126066861888 run_lib.py:146] step: 382300, eval_loss: 2.79107e-02
I0216 10:28:07.051801 23126066861888 run_lib.py:133] step: 382350, training_loss: 1.80834e-02
I0216 10:28:24.584538 23126066861888 run_lib.py:133] step: 382400, training_loss: 1.79936e-02
I0216 10:28:24.741162 23126066861888 run_lib.py:146] step: 382400, eval_loss: 2.81405e-02
I0216 10:28:42.316859 23126066861888 run_lib.py:133] step: 382450, training_loss: 1.80233e-02
I0216 10:28:59.832377 23126066861888 run_lib.py:133] step: 382500, training_loss: 1.74067e-02
I0216 10:29:00.007544 23126066861888 run_lib.py:146] step: 382500, eval_loss: 2.74285e-02
I0216 10:29:17.499709 23126066861888 run_lib.py:133] step: 382550, training_loss: 1.78128e-02
I0216 10:29:35.040610 23126066861888 run_lib.py:133] step: 382600, training_loss: 1.80472e-02
I0216 10:29:35.217239 23126066861888 run_lib.py:146] step: 382600, eval_loss: 2.66314e-02
I0216 10:29:52.933479 23126066861888 run_lib.py:133] step: 382650, training_loss: 1.78098e-02
I0216 10:30:10.589074 23126066861888 run_lib.py:133] step: 382700, training_loss: 1.78437e-02
I0216 10:30:10.747958 23126066861888 run_lib.py:146] step: 382700, eval_loss: 2.80926e-02
I0216 10:30:28.251236 23126066861888 run_lib.py:133] step: 382750, training_loss: 1.75644e-02
I0216 10:30:45.764186 23126066861888 run_lib.py:133] step: 382800, training_loss: 1.82493e-02
I0216 10:30:45.918317 23126066861888 run_lib.py:146] step: 382800, eval_loss: 2.68658e-02
I0216 10:31:03.641983 23126066861888 run_lib.py:133] step: 382850, training_loss: 1.75585e-02
I0216 10:31:21.159100 23126066861888 run_lib.py:133] step: 382900, training_loss: 1.85144e-02
I0216 10:31:21.318410 23126066861888 run_lib.py:146] step: 382900, eval_loss: 2.77923e-02
I0216 10:31:38.831909 23126066861888 run_lib.py:133] step: 382950, training_loss: 1.78475e-02
I0216 10:31:56.578779 23126066861888 run_lib.py:133] step: 383000, training_loss: 1.82202e-02
I0216 10:31:56.739333 23126066861888 run_lib.py:146] step: 383000, eval_loss: 2.92262e-02
I0216 10:32:14.234015 23126066861888 run_lib.py:133] step: 383050, training_loss: 1.81382e-02
I0216 10:32:31.935824 23126066861888 run_lib.py:133] step: 383100, training_loss: 1.73305e-02
I0216 10:32:32.092132 23126066861888 run_lib.py:146] step: 383100, eval_loss: 2.87295e-02
I0216 10:32:49.611535 23126066861888 run_lib.py:133] step: 383150, training_loss: 1.78319e-02
I0216 10:33:07.214962 23126066861888 run_lib.py:133] step: 383200, training_loss: 1.78286e-02
I0216 10:33:07.377655 23126066861888 run_lib.py:146] step: 383200, eval_loss: 2.80483e-02
I0216 10:33:25.118561 23126066861888 run_lib.py:133] step: 383250, training_loss: 1.70380e-02
I0216 10:33:42.601398 23126066861888 run_lib.py:133] step: 383300, training_loss: 1.72269e-02
I0216 10:33:42.755115 23126066861888 run_lib.py:146] step: 383300, eval_loss: 2.87556e-02
I0216 10:34:00.231328 23126066861888 run_lib.py:133] step: 383350, training_loss: 1.77864e-02
I0216 10:34:17.952999 23126066861888 run_lib.py:133] step: 383400, training_loss: 1.81035e-02
I0216 10:34:18.119181 23126066861888 run_lib.py:146] step: 383400, eval_loss: 2.76026e-02
I0216 10:34:35.648926 23126066861888 run_lib.py:133] step: 383450, training_loss: 1.85333e-02
I0216 10:34:53.172913 23126066861888 run_lib.py:133] step: 383500, training_loss: 1.74192e-02
I0216 10:34:53.333339 23126066861888 run_lib.py:146] step: 383500, eval_loss: 2.75948e-02
I0216 10:35:10.979343 23126066861888 run_lib.py:133] step: 383550, training_loss: 1.78198e-02
I0216 10:35:28.502926 23126066861888 run_lib.py:133] step: 383600, training_loss: 1.79438e-02
I0216 10:35:28.661198 23126066861888 run_lib.py:146] step: 383600, eval_loss: 2.91295e-02
I0216 10:35:46.170777 23126066861888 run_lib.py:133] step: 383650, training_loss: 1.78208e-02
I0216 10:36:03.706088 23126066861888 run_lib.py:133] step: 383700, training_loss: 1.80639e-02
I0216 10:36:03.864004 23126066861888 run_lib.py:146] step: 383700, eval_loss: 2.85480e-02
I0216 10:36:21.601055 23126066861888 run_lib.py:133] step: 383750, training_loss: 1.78976e-02
I0216 10:36:39.191684 23126066861888 run_lib.py:133] step: 383800, training_loss: 1.73079e-02
I0216 10:36:39.346151 23126066861888 run_lib.py:146] step: 383800, eval_loss: 2.69833e-02
I0216 10:36:56.841834 23126066861888 run_lib.py:133] step: 383850, training_loss: 1.72587e-02
I0216 10:37:14.363539 23126066861888 run_lib.py:133] step: 383900, training_loss: 1.82535e-02
I0216 10:37:14.524374 23126066861888 run_lib.py:146] step: 383900, eval_loss: 2.82533e-02
I0216 10:37:32.193511 23126066861888 run_lib.py:133] step: 383950, training_loss: 1.77128e-02
I0216 10:37:49.689206 23126066861888 run_lib.py:133] step: 384000, training_loss: 1.74692e-02
I0216 10:37:49.857249 23126066861888 run_lib.py:146] step: 384000, eval_loss: 2.75072e-02
I0216 10:38:07.400307 23126066861888 run_lib.py:133] step: 384050, training_loss: 1.83269e-02
I0216 10:38:25.154405 23126066861888 run_lib.py:133] step: 384100, training_loss: 1.83115e-02
I0216 10:38:25.309180 23126066861888 run_lib.py:146] step: 384100, eval_loss: 2.66785e-02
I0216 10:38:42.840242 23126066861888 run_lib.py:133] step: 384150, training_loss: 1.75865e-02
I0216 10:39:00.532684 23126066861888 run_lib.py:133] step: 384200, training_loss: 1.78782e-02
I0216 10:39:00.686233 23126066861888 run_lib.py:146] step: 384200, eval_loss: 2.88514e-02
I0216 10:39:18.195352 23126066861888 run_lib.py:133] step: 384250, training_loss: 1.85641e-02
I0216 10:39:35.756986 23126066861888 run_lib.py:133] step: 384300, training_loss: 1.77787e-02
I0216 10:39:35.922487 23126066861888 run_lib.py:146] step: 384300, eval_loss: 2.93425e-02
I0216 10:39:53.701083 23126066861888 run_lib.py:133] step: 384350, training_loss: 1.74425e-02
I0216 10:40:11.228187 23126066861888 run_lib.py:133] step: 384400, training_loss: 1.74894e-02
I0216 10:40:11.389367 23126066861888 run_lib.py:146] step: 384400, eval_loss: 2.73039e-02
I0216 10:40:28.873569 23126066861888 run_lib.py:133] step: 384450, training_loss: 1.73276e-02
I0216 10:40:46.532071 23126066861888 run_lib.py:133] step: 384500, training_loss: 1.77803e-02
I0216 10:40:46.691190 23126066861888 run_lib.py:146] step: 384500, eval_loss: 2.79243e-02
I0216 10:41:04.280257 23126066861888 run_lib.py:133] step: 384550, training_loss: 1.79651e-02
I0216 10:41:21.837273 23126066861888 run_lib.py:133] step: 384600, training_loss: 1.80657e-02
I0216 10:41:21.994504 23126066861888 run_lib.py:146] step: 384600, eval_loss: 2.73332e-02
I0216 10:41:39.661678 23126066861888 run_lib.py:133] step: 384650, training_loss: 1.78028e-02
I0216 10:41:57.155922 23126066861888 run_lib.py:133] step: 384700, training_loss: 1.81843e-02
I0216 10:41:57.312244 23126066861888 run_lib.py:146] step: 384700, eval_loss: 2.85792e-02
I0216 10:42:14.838828 23126066861888 run_lib.py:133] step: 384750, training_loss: 1.79878e-02
I0216 10:42:32.306252 23126066861888 run_lib.py:133] step: 384800, training_loss: 1.80055e-02
I0216 10:42:32.474365 23126066861888 run_lib.py:146] step: 384800, eval_loss: 2.78796e-02
I0216 10:42:50.183451 23126066861888 run_lib.py:133] step: 384850, training_loss: 1.83913e-02
I0216 10:43:07.855498 23126066861888 run_lib.py:133] step: 384900, training_loss: 1.79148e-02
I0216 10:43:08.016130 23126066861888 run_lib.py:146] step: 384900, eval_loss: 2.75550e-02
I0216 10:43:25.519796 23126066861888 run_lib.py:133] step: 384950, training_loss: 1.82472e-02
I0216 10:43:42.996892 23126066861888 run_lib.py:133] step: 385000, training_loss: 1.78201e-02
I0216 10:43:43.154193 23126066861888 run_lib.py:146] step: 385000, eval_loss: 2.84147e-02
I0216 10:44:00.833657 23126066861888 run_lib.py:133] step: 385050, training_loss: 1.77959e-02
I0216 10:44:18.355781 23126066861888 run_lib.py:133] step: 385100, training_loss: 1.76049e-02
I0216 10:44:18.513507 23126066861888 run_lib.py:146] step: 385100, eval_loss: 2.87089e-02
I0216 10:44:36.063350 23126066861888 run_lib.py:133] step: 385150, training_loss: 1.87974e-02
I0216 10:44:53.780704 23126066861888 run_lib.py:133] step: 385200, training_loss: 1.75592e-02
I0216 10:44:53.934276 23126066861888 run_lib.py:146] step: 385200, eval_loss: 2.69721e-02
I0216 10:45:11.447493 23126066861888 run_lib.py:133] step: 385250, training_loss: 1.75539e-02
I0216 10:45:29.112946 23126066861888 run_lib.py:133] step: 385300, training_loss: 1.84588e-02
I0216 10:45:29.271381 23126066861888 run_lib.py:146] step: 385300, eval_loss: 2.85561e-02
I0216 10:45:46.803537 23126066861888 run_lib.py:133] step: 385350, training_loss: 1.78733e-02
I0216 10:46:04.400711 23126066861888 run_lib.py:133] step: 385400, training_loss: 1.81296e-02
I0216 10:46:04.565228 23126066861888 run_lib.py:146] step: 385400, eval_loss: 2.88734e-02
I0216 10:46:22.309659 23126066861888 run_lib.py:133] step: 385450, training_loss: 1.76623e-02
I0216 10:46:39.840453 23126066861888 run_lib.py:133] step: 385500, training_loss: 1.79735e-02
I0216 10:46:39.998226 23126066861888 run_lib.py:146] step: 385500, eval_loss: 2.78802e-02
I0216 10:46:57.514990 23126066861888 run_lib.py:133] step: 385550, training_loss: 1.71758e-02
I0216 10:47:15.192505 23126066861888 run_lib.py:133] step: 385600, training_loss: 1.83675e-02
I0216 10:47:15.347937 23126066861888 run_lib.py:146] step: 385600, eval_loss: 2.82551e-02
I0216 10:47:32.842641 23126066861888 run_lib.py:133] step: 385650, training_loss: 1.78118e-02
I0216 10:47:50.423756 23126066861888 run_lib.py:133] step: 385700, training_loss: 1.86576e-02
I0216 10:47:50.589049 23126066861888 run_lib.py:146] step: 385700, eval_loss: 2.82672e-02
I0216 10:48:08.263336 23126066861888 run_lib.py:133] step: 385750, training_loss: 1.78259e-02
I0216 10:48:25.864558 23126066861888 run_lib.py:133] step: 385800, training_loss: 1.77101e-02
I0216 10:48:26.026911 23126066861888 run_lib.py:146] step: 385800, eval_loss: 2.79724e-02
I0216 10:48:43.538027 23126066861888 run_lib.py:133] step: 385850, training_loss: 1.83832e-02
I0216 10:49:01.075607 23126066861888 run_lib.py:133] step: 385900, training_loss: 1.84481e-02
I0216 10:49:01.232342 23126066861888 run_lib.py:146] step: 385900, eval_loss: 2.76534e-02
I0216 10:49:18.919004 23126066861888 run_lib.py:133] step: 385950, training_loss: 1.73600e-02
I0216 10:49:36.650037 23126066861888 run_lib.py:133] step: 386000, training_loss: 1.81421e-02
I0216 10:49:36.807638 23126066861888 run_lib.py:146] step: 386000, eval_loss: 2.76565e-02
I0216 10:49:54.363234 23126066861888 run_lib.py:133] step: 386050, training_loss: 1.77279e-02
I0216 10:50:11.898480 23126066861888 run_lib.py:133] step: 386100, training_loss: 1.78943e-02
I0216 10:50:12.052957 23126066861888 run_lib.py:146] step: 386100, eval_loss: 2.83832e-02
I0216 10:50:29.748456 23126066861888 run_lib.py:133] step: 386150, training_loss: 1.80875e-02
I0216 10:50:47.282918 23126066861888 run_lib.py:133] step: 386200, training_loss: 1.81058e-02
I0216 10:50:47.451381 23126066861888 run_lib.py:146] step: 386200, eval_loss: 2.73849e-02
I0216 10:51:04.996522 23126066861888 run_lib.py:133] step: 386250, training_loss: 1.82018e-02
I0216 10:51:22.791942 23126066861888 run_lib.py:133] step: 386300, training_loss: 1.84723e-02
I0216 10:51:22.952179 23126066861888 run_lib.py:146] step: 386300, eval_loss: 2.88712e-02
I0216 10:51:40.458003 23126066861888 run_lib.py:133] step: 386350, training_loss: 1.75213e-02
I0216 10:51:58.106030 23126066861888 run_lib.py:133] step: 386400, training_loss: 1.76571e-02
I0216 10:51:58.267478 23126066861888 run_lib.py:146] step: 386400, eval_loss: 2.73387e-02
I0216 10:52:15.770391 23126066861888 run_lib.py:133] step: 386450, training_loss: 1.76860e-02
I0216 10:52:33.371964 23126066861888 run_lib.py:133] step: 386500, training_loss: 1.73484e-02
I0216 10:52:33.530930 23126066861888 run_lib.py:146] step: 386500, eval_loss: 2.77746e-02
I0216 10:52:51.309611 23126066861888 run_lib.py:133] step: 386550, training_loss: 1.79449e-02
I0216 10:53:08.832597 23126066861888 run_lib.py:133] step: 386600, training_loss: 1.75719e-02
I0216 10:53:08.985109 23126066861888 run_lib.py:146] step: 386600, eval_loss: 2.81214e-02
I0216 10:53:26.487638 23126066861888 run_lib.py:133] step: 386650, training_loss: 1.75417e-02
I0216 10:53:44.197610 23126066861888 run_lib.py:133] step: 386700, training_loss: 1.79268e-02
I0216 10:53:44.354220 23126066861888 run_lib.py:146] step: 386700, eval_loss: 2.77962e-02
I0216 10:54:01.835531 23126066861888 run_lib.py:133] step: 386750, training_loss: 1.85520e-02
I0216 10:54:19.397211 23126066861888 run_lib.py:133] step: 386800, training_loss: 1.78327e-02
I0216 10:54:19.559183 23126066861888 run_lib.py:146] step: 386800, eval_loss: 2.80250e-02
I0216 10:54:37.232405 23126066861888 run_lib.py:133] step: 386850, training_loss: 1.75929e-02
I0216 10:54:54.778645 23126066861888 run_lib.py:133] step: 386900, training_loss: 1.79028e-02
I0216 10:54:54.937411 23126066861888 run_lib.py:146] step: 386900, eval_loss: 2.74048e-02
I0216 10:55:12.486085 23126066861888 run_lib.py:133] step: 386950, training_loss: 1.72186e-02
I0216 10:55:29.961381 23126066861888 run_lib.py:133] step: 387000, training_loss: 1.73930e-02
I0216 10:55:30.118124 23126066861888 run_lib.py:146] step: 387000, eval_loss: 2.78057e-02
I0216 10:55:47.832095 23126066861888 run_lib.py:133] step: 387050, training_loss: 1.79682e-02
I0216 10:56:05.554479 23126066861888 run_lib.py:133] step: 387100, training_loss: 1.82615e-02
I0216 10:56:05.712391 23126066861888 run_lib.py:146] step: 387100, eval_loss: 2.82866e-02
I0216 10:56:23.247989 23126066861888 run_lib.py:133] step: 387150, training_loss: 1.70637e-02
I0216 10:56:40.776440 23126066861888 run_lib.py:133] step: 387200, training_loss: 1.76070e-02
I0216 10:56:40.936470 23126066861888 run_lib.py:146] step: 387200, eval_loss: 2.84719e-02
I0216 10:56:58.585993 23126066861888 run_lib.py:133] step: 387250, training_loss: 1.80492e-02
I0216 10:57:16.075248 23126066861888 run_lib.py:133] step: 387300, training_loss: 1.73612e-02
I0216 10:57:16.249233 23126066861888 run_lib.py:146] step: 387300, eval_loss: 2.83851e-02
I0216 10:57:33.815971 23126066861888 run_lib.py:133] step: 387350, training_loss: 1.76693e-02
I0216 10:57:51.565936 23126066861888 run_lib.py:133] step: 387400, training_loss: 1.73664e-02
I0216 10:57:51.727361 23126066861888 run_lib.py:146] step: 387400, eval_loss: 2.88218e-02
I0216 10:58:09.301797 23126066861888 run_lib.py:133] step: 387450, training_loss: 1.93462e-02
I0216 10:58:26.985903 23126066861888 run_lib.py:133] step: 387500, training_loss: 1.80481e-02
I0216 10:58:27.163921 23126066861888 run_lib.py:146] step: 387500, eval_loss: 2.85212e-02
I0216 10:58:44.656112 23126066861888 run_lib.py:133] step: 387550, training_loss: 1.80688e-02
I0216 10:59:02.193547 23126066861888 run_lib.py:133] step: 387600, training_loss: 1.80386e-02
I0216 10:59:02.352411 23126066861888 run_lib.py:146] step: 387600, eval_loss: 2.87171e-02
I0216 10:59:20.106240 23126066861888 run_lib.py:133] step: 387650, training_loss: 1.77575e-02
I0216 10:59:37.660491 23126066861888 run_lib.py:133] step: 387700, training_loss: 1.84667e-02
I0216 10:59:37.816765 23126066861888 run_lib.py:146] step: 387700, eval_loss: 2.75327e-02
I0216 10:59:55.305311 23126066861888 run_lib.py:133] step: 387750, training_loss: 1.77805e-02
I0216 11:00:12.967703 23126066861888 run_lib.py:133] step: 387800, training_loss: 1.77358e-02
I0216 11:00:13.127457 23126066861888 run_lib.py:146] step: 387800, eval_loss: 2.76384e-02
I0216 11:00:30.650736 23126066861888 run_lib.py:133] step: 387850, training_loss: 1.75990e-02
I0216 11:00:48.211375 23126066861888 run_lib.py:133] step: 387900, training_loss: 1.83339e-02
I0216 11:00:48.369932 23126066861888 run_lib.py:146] step: 387900, eval_loss: 2.78745e-02
I0216 11:01:06.016098 23126066861888 run_lib.py:133] step: 387950, training_loss: 1.72318e-02
I0216 11:01:23.515008 23126066861888 run_lib.py:133] step: 388000, training_loss: 1.80993e-02
I0216 11:01:23.667521 23126066861888 run_lib.py:146] step: 388000, eval_loss: 2.70338e-02
I0216 11:01:41.189780 23126066861888 run_lib.py:133] step: 388050, training_loss: 1.74517e-02
I0216 11:01:58.705005 23126066861888 run_lib.py:133] step: 388100, training_loss: 1.83355e-02
I0216 11:01:58.862415 23126066861888 run_lib.py:146] step: 388100, eval_loss: 2.76762e-02
I0216 11:02:16.595891 23126066861888 run_lib.py:133] step: 388150, training_loss: 1.78046e-02
I0216 11:02:34.260755 23126066861888 run_lib.py:133] step: 388200, training_loss: 1.84650e-02
I0216 11:02:34.429117 23126066861888 run_lib.py:146] step: 388200, eval_loss: 2.84685e-02
I0216 11:02:51.932632 23126066861888 run_lib.py:133] step: 388250, training_loss: 1.74247e-02
I0216 11:03:09.428568 23126066861888 run_lib.py:133] step: 388300, training_loss: 1.73732e-02
I0216 11:03:09.585292 23126066861888 run_lib.py:146] step: 388300, eval_loss: 2.74701e-02
I0216 11:03:27.284556 23126066861888 run_lib.py:133] step: 388350, training_loss: 1.72897e-02
I0216 11:03:44.765889 23126066861888 run_lib.py:133] step: 388400, training_loss: 1.77233e-02
I0216 11:03:44.925190 23126066861888 run_lib.py:146] step: 388400, eval_loss: 2.87173e-02
I0216 11:04:02.488866 23126066861888 run_lib.py:133] step: 388450, training_loss: 1.82170e-02
I0216 11:04:20.252876 23126066861888 run_lib.py:133] step: 388500, training_loss: 1.86707e-02
I0216 11:04:20.408497 23126066861888 run_lib.py:146] step: 388500, eval_loss: 2.61788e-02
I0216 11:04:37.959345 23126066861888 run_lib.py:133] step: 388550, training_loss: 1.75330e-02
I0216 11:04:55.650832 23126066861888 run_lib.py:133] step: 388600, training_loss: 1.80255e-02
I0216 11:04:55.808506 23126066861888 run_lib.py:146] step: 388600, eval_loss: 2.74858e-02
I0216 11:05:13.307994 23126066861888 run_lib.py:133] step: 388650, training_loss: 1.76069e-02
I0216 11:05:30.867469 23126066861888 run_lib.py:133] step: 388700, training_loss: 1.72939e-02
I0216 11:05:31.045137 23126066861888 run_lib.py:146] step: 388700, eval_loss: 2.83660e-02
I0216 11:05:48.791990 23126066861888 run_lib.py:133] step: 388750, training_loss: 1.77193e-02
I0216 11:06:06.339040 23126066861888 run_lib.py:133] step: 388800, training_loss: 1.73797e-02
I0216 11:06:06.502417 23126066861888 run_lib.py:146] step: 388800, eval_loss: 2.83153e-02
I0216 11:06:24.088382 23126066861888 run_lib.py:133] step: 388850, training_loss: 1.82149e-02
I0216 11:06:41.755120 23126066861888 run_lib.py:133] step: 388900, training_loss: 1.83873e-02
I0216 11:06:41.916177 23126066861888 run_lib.py:146] step: 388900, eval_loss: 2.69662e-02
I0216 11:06:59.410064 23126066861888 run_lib.py:133] step: 388950, training_loss: 1.75067e-02
I0216 11:07:16.932764 23126066861888 run_lib.py:133] step: 389000, training_loss: 1.82073e-02
I0216 11:07:17.091386 23126066861888 run_lib.py:146] step: 389000, eval_loss: 2.81154e-02
I0216 11:07:34.785825 23126066861888 run_lib.py:133] step: 389050, training_loss: 1.73597e-02
I0216 11:07:52.296611 23126066861888 run_lib.py:133] step: 389100, training_loss: 1.85108e-02
I0216 11:07:52.457559 23126066861888 run_lib.py:146] step: 389100, eval_loss: 2.75399e-02
I0216 11:08:09.947378 23126066861888 run_lib.py:133] step: 389150, training_loss: 1.69825e-02
I0216 11:08:27.434334 23126066861888 run_lib.py:133] step: 389200, training_loss: 1.79036e-02
I0216 11:08:27.600783 23126066861888 run_lib.py:146] step: 389200, eval_loss: 2.79376e-02
I0216 11:08:45.305929 23126066861888 run_lib.py:133] step: 389250, training_loss: 1.83262e-02
I0216 11:09:02.992003 23126066861888 run_lib.py:133] step: 389300, training_loss: 1.80356e-02
I0216 11:09:03.150541 23126066861888 run_lib.py:146] step: 389300, eval_loss: 2.83039e-02
I0216 11:09:20.709401 23126066861888 run_lib.py:133] step: 389350, training_loss: 1.81277e-02
I0216 11:09:38.225758 23126066861888 run_lib.py:133] step: 389400, training_loss: 1.75572e-02
I0216 11:09:38.380901 23126066861888 run_lib.py:146] step: 389400, eval_loss: 2.69599e-02
I0216 11:09:56.119788 23126066861888 run_lib.py:133] step: 389450, training_loss: 1.75217e-02
I0216 11:10:13.632491 23126066861888 run_lib.py:133] step: 389500, training_loss: 1.75172e-02
I0216 11:10:13.791435 23126066861888 run_lib.py:146] step: 389500, eval_loss: 2.91760e-02
I0216 11:10:31.311376 23126066861888 run_lib.py:133] step: 389550, training_loss: 1.78966e-02
I0216 11:10:49.021492 23126066861888 run_lib.py:133] step: 389600, training_loss: 1.71369e-02
I0216 11:10:49.191144 23126066861888 run_lib.py:146] step: 389600, eval_loss: 2.81546e-02
I0216 11:11:06.734198 23126066861888 run_lib.py:133] step: 389650, training_loss: 1.78081e-02
I0216 11:11:24.460874 23126066861888 run_lib.py:133] step: 389700, training_loss: 1.81721e-02
I0216 11:11:24.627985 23126066861888 run_lib.py:146] step: 389700, eval_loss: 2.72724e-02
I0216 11:11:42.136744 23126066861888 run_lib.py:133] step: 389750, training_loss: 1.84757e-02
I0216 11:11:59.597063 23126066861888 run_lib.py:133] step: 389800, training_loss: 1.79049e-02
I0216 11:11:59.754245 23126066861888 run_lib.py:146] step: 389800, eval_loss: 2.77944e-02
I0216 11:12:17.490835 23126066861888 run_lib.py:133] step: 389850, training_loss: 1.72149e-02
I0216 11:12:35.039414 23126066861888 run_lib.py:133] step: 389900, training_loss: 1.73434e-02
I0216 11:12:35.199454 23126066861888 run_lib.py:146] step: 389900, eval_loss: 2.87002e-02
I0216 11:12:52.752640 23126066861888 run_lib.py:133] step: 389950, training_loss: 1.74909e-02
I0216 11:13:10.521374 23126066861888 run_lib.py:133] step: 390000, training_loss: 1.75215e-02
I0216 11:13:11.275869 23126066861888 run_lib.py:146] step: 390000, eval_loss: 2.80694e-02
I0216 11:13:31.505751 23126066861888 run_lib.py:133] step: 390050, training_loss: 1.73372e-02
I0216 11:13:49.003286 23126066861888 run_lib.py:133] step: 390100, training_loss: 1.78419e-02
I0216 11:13:49.165486 23126066861888 run_lib.py:146] step: 390100, eval_loss: 2.83796e-02
I0216 11:14:06.700700 23126066861888 run_lib.py:133] step: 390150, training_loss: 1.79725e-02
I0216 11:14:24.483042 23126066861888 run_lib.py:133] step: 390200, training_loss: 1.83256e-02
I0216 11:14:24.643163 23126066861888 run_lib.py:146] step: 390200, eval_loss: 2.88749e-02
I0216 11:14:42.137045 23126066861888 run_lib.py:133] step: 390250, training_loss: 1.83118e-02
I0216 11:14:59.624887 23126066861888 run_lib.py:133] step: 390300, training_loss: 1.76413e-02
I0216 11:14:59.784362 23126066861888 run_lib.py:146] step: 390300, eval_loss: 2.87800e-02
I0216 11:15:17.294637 23126066861888 run_lib.py:133] step: 390350, training_loss: 1.67520e-02
I0216 11:15:34.985678 23126066861888 run_lib.py:133] step: 390400, training_loss: 1.82504e-02
I0216 11:15:35.151885 23126066861888 run_lib.py:146] step: 390400, eval_loss: 2.81187e-02
I0216 11:15:52.854422 23126066861888 run_lib.py:133] step: 390450, training_loss: 1.74482e-02
I0216 11:16:10.362790 23126066861888 run_lib.py:133] step: 390500, training_loss: 1.82879e-02
I0216 11:16:10.516117 23126066861888 run_lib.py:146] step: 390500, eval_loss: 2.82432e-02
I0216 11:16:28.033657 23126066861888 run_lib.py:133] step: 390550, training_loss: 1.78983e-02
I0216 11:16:45.564596 23126066861888 run_lib.py:133] step: 390600, training_loss: 1.81335e-02
I0216 11:16:45.725474 23126066861888 run_lib.py:146] step: 390600, eval_loss: 2.74595e-02
I0216 11:17:03.380673 23126066861888 run_lib.py:133] step: 390650, training_loss: 1.77637e-02
I0216 11:17:20.911717 23126066861888 run_lib.py:133] step: 390700, training_loss: 1.80128e-02
I0216 11:17:21.079206 23126066861888 run_lib.py:146] step: 390700, eval_loss: 2.74348e-02
I0216 11:17:38.805062 23126066861888 run_lib.py:133] step: 390750, training_loss: 1.72337e-02
I0216 11:17:56.428900 23126066861888 run_lib.py:133] step: 390800, training_loss: 1.76287e-02
I0216 11:17:56.587978 23126066861888 run_lib.py:146] step: 390800, eval_loss: 2.86502e-02
I0216 11:18:14.329331 23126066861888 run_lib.py:133] step: 390850, training_loss: 1.76279e-02
I0216 11:18:31.804336 23126066861888 run_lib.py:133] step: 390900, training_loss: 1.82334e-02
I0216 11:18:31.959223 23126066861888 run_lib.py:146] step: 390900, eval_loss: 2.88203e-02
I0216 11:18:49.489859 23126066861888 run_lib.py:133] step: 390950, training_loss: 1.76133e-02
I0216 11:19:07.210365 23126066861888 run_lib.py:133] step: 391000, training_loss: 1.74615e-02
I0216 11:19:07.378176 23126066861888 run_lib.py:146] step: 391000, eval_loss: 2.69142e-02
I0216 11:19:24.942427 23126066861888 run_lib.py:133] step: 391050, training_loss: 1.77577e-02
I0216 11:19:42.670939 23126066861888 run_lib.py:133] step: 391100, training_loss: 1.79636e-02
I0216 11:19:42.833717 23126066861888 run_lib.py:146] step: 391100, eval_loss: 2.93869e-02
I0216 11:20:00.340681 23126066861888 run_lib.py:133] step: 391150, training_loss: 1.71460e-02
I0216 11:20:17.851837 23126066861888 run_lib.py:133] step: 391200, training_loss: 1.71124e-02
I0216 11:20:18.009097 23126066861888 run_lib.py:146] step: 391200, eval_loss: 2.86257e-02
I0216 11:20:35.545526 23126066861888 run_lib.py:133] step: 391250, training_loss: 1.80573e-02
I0216 11:20:53.280474 23126066861888 run_lib.py:133] step: 391300, training_loss: 1.78665e-02
I0216 11:20:53.441828 23126066861888 run_lib.py:146] step: 391300, eval_loss: 2.87211e-02
I0216 11:21:11.035017 23126066861888 run_lib.py:133] step: 391350, training_loss: 1.76928e-02
I0216 11:21:28.540816 23126066861888 run_lib.py:133] step: 391400, training_loss: 1.78450e-02
I0216 11:21:28.693895 23126066861888 run_lib.py:146] step: 391400, eval_loss: 2.82144e-02
I0216 11:21:46.414925 23126066861888 run_lib.py:133] step: 391450, training_loss: 1.70258e-02
I0216 11:22:03.928352 23126066861888 run_lib.py:133] step: 391500, training_loss: 1.74152e-02
I0216 11:22:04.097512 23126066861888 run_lib.py:146] step: 391500, eval_loss: 2.80099e-02
I0216 11:22:21.762393 23126066861888 run_lib.py:133] step: 391550, training_loss: 1.71681e-02
I0216 11:22:39.314773 23126066861888 run_lib.py:133] step: 391600, training_loss: 1.78642e-02
I0216 11:22:39.474177 23126066861888 run_lib.py:146] step: 391600, eval_loss: 2.79594e-02
I0216 11:22:56.956560 23126066861888 run_lib.py:133] step: 391650, training_loss: 1.70851e-02
I0216 11:23:14.430104 23126066861888 run_lib.py:133] step: 391700, training_loss: 1.83120e-02
I0216 11:23:14.586135 23126066861888 run_lib.py:146] step: 391700, eval_loss: 2.87121e-02
I0216 11:23:32.236928 23126066861888 run_lib.py:133] step: 391750, training_loss: 1.83502e-02
I0216 11:23:49.980781 23126066861888 run_lib.py:133] step: 391800, training_loss: 1.80882e-02
I0216 11:23:50.142434 23126066861888 run_lib.py:146] step: 391800, eval_loss: 2.72829e-02
I0216 11:24:07.657809 23126066861888 run_lib.py:133] step: 391850, training_loss: 1.72642e-02
I0216 11:24:25.138208 23126066861888 run_lib.py:133] step: 391900, training_loss: 1.76706e-02
I0216 11:24:25.318260 23126066861888 run_lib.py:146] step: 391900, eval_loss: 2.75395e-02
I0216 11:24:43.016584 23126066861888 run_lib.py:133] step: 391950, training_loss: 1.79682e-02
I0216 11:25:00.546154 23126066861888 run_lib.py:133] step: 392000, training_loss: 1.71180e-02
I0216 11:25:00.702293 23126066861888 run_lib.py:146] step: 392000, eval_loss: 2.84753e-02
I0216 11:25:18.197977 23126066861888 run_lib.py:133] step: 392050, training_loss: 1.74857e-02
I0216 11:25:35.940393 23126066861888 run_lib.py:133] step: 392100, training_loss: 1.82543e-02
I0216 11:25:36.108245 23126066861888 run_lib.py:146] step: 392100, eval_loss: 2.87323e-02
I0216 11:25:53.630982 23126066861888 run_lib.py:133] step: 392150, training_loss: 1.83473e-02
I0216 11:26:11.321289 23126066861888 run_lib.py:133] step: 392200, training_loss: 1.75639e-02
I0216 11:26:11.479243 23126066861888 run_lib.py:146] step: 392200, eval_loss: 2.78220e-02
I0216 11:26:28.979653 23126066861888 run_lib.py:133] step: 392250, training_loss: 1.71293e-02
I0216 11:26:46.485191 23126066861888 run_lib.py:133] step: 392300, training_loss: 1.75474e-02
I0216 11:26:46.641168 23126066861888 run_lib.py:146] step: 392300, eval_loss: 2.79886e-02
I0216 11:27:04.336253 23126066861888 run_lib.py:133] step: 392350, training_loss: 1.73769e-02
I0216 11:27:21.856582 23126066861888 run_lib.py:133] step: 392400, training_loss: 1.74067e-02
I0216 11:27:22.015357 23126066861888 run_lib.py:146] step: 392400, eval_loss: 2.80797e-02
I0216 11:27:39.517539 23126066861888 run_lib.py:133] step: 392450, training_loss: 1.86339e-02
I0216 11:27:57.076006 23126066861888 run_lib.py:133] step: 392500, training_loss: 1.75899e-02
I0216 11:27:57.236428 23126066861888 run_lib.py:146] step: 392500, eval_loss: 2.76722e-02
I0216 11:28:14.952740 23126066861888 run_lib.py:133] step: 392550, training_loss: 1.79921e-02
I0216 11:28:32.419411 23126066861888 run_lib.py:133] step: 392600, training_loss: 1.77125e-02
I0216 11:28:32.576132 23126066861888 run_lib.py:146] step: 392600, eval_loss: 2.84119e-02
I0216 11:28:50.155049 23126066861888 run_lib.py:133] step: 392650, training_loss: 1.79010e-02
I0216 11:29:07.691817 23126066861888 run_lib.py:133] step: 392700, training_loss: 1.79586e-02
I0216 11:29:07.849640 23126066861888 run_lib.py:146] step: 392700, eval_loss: 2.72546e-02
I0216 11:29:25.402627 23126066861888 run_lib.py:133] step: 392750, training_loss: 1.75015e-02
I0216 11:29:42.900271 23126066861888 run_lib.py:133] step: 392800, training_loss: 1.74976e-02
I0216 11:29:43.055143 23126066861888 run_lib.py:146] step: 392800, eval_loss: 2.72796e-02
I0216 11:30:00.747775 23126066861888 run_lib.py:133] step: 392850, training_loss: 1.74891e-02
I0216 11:30:18.374135 23126066861888 run_lib.py:133] step: 392900, training_loss: 1.84915e-02
I0216 11:30:18.530318 23126066861888 run_lib.py:146] step: 392900, eval_loss: 2.79566e-02
I0216 11:30:36.088815 23126066861888 run_lib.py:133] step: 392950, training_loss: 1.86139e-02
I0216 11:30:53.644866 23126066861888 run_lib.py:133] step: 393000, training_loss: 1.78238e-02
I0216 11:30:53.805150 23126066861888 run_lib.py:146] step: 393000, eval_loss: 2.89077e-02
I0216 11:31:11.512833 23126066861888 run_lib.py:133] step: 393050, training_loss: 1.73959e-02
I0216 11:31:29.009690 23126066861888 run_lib.py:133] step: 393100, training_loss: 1.75179e-02
I0216 11:31:29.166214 23126066861888 run_lib.py:146] step: 393100, eval_loss: 2.79696e-02
I0216 11:31:46.670360 23126066861888 run_lib.py:133] step: 393150, training_loss: 1.78239e-02
I0216 11:32:04.327761 23126066861888 run_lib.py:133] step: 393200, training_loss: 1.76458e-02
I0216 11:32:04.488219 23126066861888 run_lib.py:146] step: 393200, eval_loss: 2.84280e-02
I0216 11:32:22.007744 23126066861888 run_lib.py:133] step: 393250, training_loss: 1.75747e-02
I0216 11:32:39.763482 23126066861888 run_lib.py:133] step: 393300, training_loss: 1.79488e-02
I0216 11:32:39.924466 23126066861888 run_lib.py:146] step: 393300, eval_loss: 2.90449e-02
I0216 11:32:57.476875 23126066861888 run_lib.py:133] step: 393350, training_loss: 1.77115e-02
I0216 11:33:15.006668 23126066861888 run_lib.py:133] step: 393400, training_loss: 1.82723e-02
I0216 11:33:15.172130 23126066861888 run_lib.py:146] step: 393400, eval_loss: 2.77014e-02
I0216 11:33:32.810661 23126066861888 run_lib.py:133] step: 393450, training_loss: 1.80984e-02
I0216 11:33:50.319102 23126066861888 run_lib.py:133] step: 393500, training_loss: 1.77674e-02
I0216 11:33:50.491359 23126066861888 run_lib.py:146] step: 393500, eval_loss: 2.75971e-02
I0216 11:34:08.039900 23126066861888 run_lib.py:133] step: 393550, training_loss: 1.72916e-02
I0216 11:34:25.781276 23126066861888 run_lib.py:133] step: 393600, training_loss: 1.79352e-02
I0216 11:34:25.942753 23126066861888 run_lib.py:146] step: 393600, eval_loss: 2.88040e-02
I0216 11:34:43.443106 23126066861888 run_lib.py:133] step: 393650, training_loss: 1.83602e-02
I0216 11:35:00.926091 23126066861888 run_lib.py:133] step: 393700, training_loss: 1.79018e-02
I0216 11:35:01.085020 23126066861888 run_lib.py:146] step: 393700, eval_loss: 2.72884e-02
I0216 11:35:18.698836 23126066861888 run_lib.py:133] step: 393750, training_loss: 1.81563e-02
I0216 11:35:36.212513 23126066861888 run_lib.py:133] step: 393800, training_loss: 1.82388e-02
I0216 11:35:36.389468 23126066861888 run_lib.py:146] step: 393800, eval_loss: 2.83404e-02
I0216 11:35:53.977662 23126066861888 run_lib.py:133] step: 393850, training_loss: 1.78199e-02
I0216 11:36:11.511915 23126066861888 run_lib.py:133] step: 393900, training_loss: 1.78672e-02
I0216 11:36:11.668422 23126066861888 run_lib.py:146] step: 393900, eval_loss: 2.72485e-02
I0216 11:36:29.397909 23126066861888 run_lib.py:133] step: 393950, training_loss: 1.74010e-02
I0216 11:36:46.997323 23126066861888 run_lib.py:133] step: 394000, training_loss: 1.80986e-02
I0216 11:36:47.159531 23126066861888 run_lib.py:146] step: 394000, eval_loss: 2.76022e-02
I0216 11:37:04.677238 23126066861888 run_lib.py:133] step: 394050, training_loss: 1.72143e-02
I0216 11:37:22.226180 23126066861888 run_lib.py:133] step: 394100, training_loss: 1.79327e-02
I0216 11:37:22.386388 23126066861888 run_lib.py:146] step: 394100, eval_loss: 2.89431e-02
I0216 11:37:40.126204 23126066861888 run_lib.py:133] step: 394150, training_loss: 1.81329e-02
I0216 11:37:57.643282 23126066861888 run_lib.py:133] step: 394200, training_loss: 1.74241e-02
I0216 11:37:57.803280 23126066861888 run_lib.py:146] step: 394200, eval_loss: 2.81131e-02
I0216 11:38:15.294047 23126066861888 run_lib.py:133] step: 394250, training_loss: 1.73264e-02
I0216 11:38:33.008605 23126066861888 run_lib.py:133] step: 394300, training_loss: 1.76015e-02
I0216 11:38:33.163226 23126066861888 run_lib.py:146] step: 394300, eval_loss: 2.68362e-02
I0216 11:38:50.635224 23126066861888 run_lib.py:133] step: 394350, training_loss: 1.80227e-02
I0216 11:39:08.311464 23126066861888 run_lib.py:133] step: 394400, training_loss: 1.84480e-02
I0216 11:39:08.489217 23126066861888 run_lib.py:146] step: 394400, eval_loss: 2.79330e-02
I0216 11:39:26.059999 23126066861888 run_lib.py:133] step: 394450, training_loss: 1.84553e-02
I0216 11:39:43.629806 23126066861888 run_lib.py:133] step: 394500, training_loss: 1.79750e-02
I0216 11:39:43.796231 23126066861888 run_lib.py:146] step: 394500, eval_loss: 2.83720e-02
I0216 11:40:01.522016 23126066861888 run_lib.py:133] step: 394550, training_loss: 1.80269e-02
I0216 11:40:19.022526 23126066861888 run_lib.py:133] step: 394600, training_loss: 1.74754e-02
I0216 11:40:19.178952 23126066861888 run_lib.py:146] step: 394600, eval_loss: 2.79765e-02
I0216 11:40:36.685005 23126066861888 run_lib.py:133] step: 394650, training_loss: 1.75127e-02
I0216 11:40:54.454322 23126066861888 run_lib.py:133] step: 394700, training_loss: 1.75896e-02
I0216 11:40:54.611217 23126066861888 run_lib.py:146] step: 394700, eval_loss: 2.85873e-02
I0216 11:41:12.121634 23126066861888 run_lib.py:133] step: 394750, training_loss: 1.80486e-02
I0216 11:41:29.635619 23126066861888 run_lib.py:133] step: 394800, training_loss: 1.73198e-02
I0216 11:41:29.792243 23126066861888 run_lib.py:146] step: 394800, eval_loss: 2.89330e-02
I0216 11:41:47.415270 23126066861888 run_lib.py:133] step: 394850, training_loss: 1.78557e-02
I0216 11:42:04.957044 23126066861888 run_lib.py:133] step: 394900, training_loss: 1.74035e-02
I0216 11:42:05.115630 23126066861888 run_lib.py:146] step: 394900, eval_loss: 2.79947e-02
I0216 11:42:22.681092 23126066861888 run_lib.py:133] step: 394950, training_loss: 1.68641e-02
I0216 11:42:40.270522 23126066861888 run_lib.py:133] step: 395000, training_loss: 1.74698e-02
I0216 11:42:40.426695 23126066861888 run_lib.py:146] step: 395000, eval_loss: 2.73456e-02
I0216 11:42:58.127461 23126066861888 run_lib.py:133] step: 395050, training_loss: 1.69349e-02
I0216 11:43:15.706054 23126066861888 run_lib.py:133] step: 395100, training_loss: 1.75486e-02
I0216 11:43:15.864072 23126066861888 run_lib.py:146] step: 395100, eval_loss: 2.81827e-02
I0216 11:43:33.388760 23126066861888 run_lib.py:133] step: 395150, training_loss: 1.78313e-02
I0216 11:43:50.918695 23126066861888 run_lib.py:133] step: 395200, training_loss: 1.78300e-02
I0216 11:43:51.074417 23126066861888 run_lib.py:146] step: 395200, eval_loss: 2.78181e-02
I0216 11:44:08.912950 23126066861888 run_lib.py:133] step: 395250, training_loss: 1.77898e-02
I0216 11:44:26.455737 23126066861888 run_lib.py:133] step: 395300, training_loss: 1.80583e-02
I0216 11:44:26.613172 23126066861888 run_lib.py:146] step: 395300, eval_loss: 2.76242e-02
I0216 11:44:44.110886 23126066861888 run_lib.py:133] step: 395350, training_loss: 1.71011e-02
I0216 11:45:01.832603 23126066861888 run_lib.py:133] step: 395400, training_loss: 1.78094e-02
I0216 11:45:02.001548 23126066861888 run_lib.py:146] step: 395400, eval_loss: 2.81587e-02
I0216 11:45:19.531399 23126066861888 run_lib.py:133] step: 395450, training_loss: 1.82832e-02
I0216 11:45:37.185354 23126066861888 run_lib.py:133] step: 395500, training_loss: 1.74008e-02
I0216 11:45:37.358659 23126066861888 run_lib.py:146] step: 395500, eval_loss: 2.88673e-02
I0216 11:45:54.907324 23126066861888 run_lib.py:133] step: 395550, training_loss: 1.76224e-02
I0216 11:46:12.438708 23126066861888 run_lib.py:133] step: 395600, training_loss: 1.73568e-02
I0216 11:46:12.593499 23126066861888 run_lib.py:146] step: 395600, eval_loss: 2.79387e-02
I0216 11:46:30.390768 23126066861888 run_lib.py:133] step: 395650, training_loss: 1.78094e-02
I0216 11:46:47.932940 23126066861888 run_lib.py:133] step: 395700, training_loss: 1.71327e-02
I0216 11:46:48.087185 23126066861888 run_lib.py:146] step: 395700, eval_loss: 2.84137e-02
I0216 11:47:05.595523 23126066861888 run_lib.py:133] step: 395750, training_loss: 1.79270e-02
I0216 11:47:23.322665 23126066861888 run_lib.py:133] step: 395800, training_loss: 1.78580e-02
I0216 11:47:23.493115 23126066861888 run_lib.py:146] step: 395800, eval_loss: 2.69381e-02
I0216 11:47:41.044034 23126066861888 run_lib.py:133] step: 395850, training_loss: 1.81750e-02
I0216 11:47:58.586415 23126066861888 run_lib.py:133] step: 395900, training_loss: 1.80656e-02
I0216 11:47:58.750440 23126066861888 run_lib.py:146] step: 395900, eval_loss: 2.76545e-02
I0216 11:48:16.386790 23126066861888 run_lib.py:133] step: 395950, training_loss: 1.82222e-02
I0216 11:48:33.897063 23126066861888 run_lib.py:133] step: 396000, training_loss: 1.81556e-02
I0216 11:48:34.055239 23126066861888 run_lib.py:146] step: 396000, eval_loss: 2.83340e-02
I0216 11:48:51.561640 23126066861888 run_lib.py:133] step: 396050, training_loss: 1.75634e-02
I0216 11:49:09.184925 23126066861888 run_lib.py:133] step: 396100, training_loss: 1.85422e-02
I0216 11:49:09.340977 23126066861888 run_lib.py:146] step: 396100, eval_loss: 2.94806e-02
I0216 11:49:27.121134 23126066861888 run_lib.py:133] step: 396150, training_loss: 1.77929e-02
I0216 11:49:44.727173 23126066861888 run_lib.py:133] step: 396200, training_loss: 1.82302e-02
I0216 11:49:44.885288 23126066861888 run_lib.py:146] step: 396200, eval_loss: 2.79766e-02
I0216 11:50:02.426818 23126066861888 run_lib.py:133] step: 396250, training_loss: 1.75349e-02
I0216 11:50:19.952810 23126066861888 run_lib.py:133] step: 396300, training_loss: 1.79092e-02
I0216 11:50:20.126200 23126066861888 run_lib.py:146] step: 396300, eval_loss: 2.83876e-02
I0216 11:50:37.841431 23126066861888 run_lib.py:133] step: 396350, training_loss: 1.76904e-02
I0216 11:50:55.428607 23126066861888 run_lib.py:133] step: 396400, training_loss: 1.83235e-02
I0216 11:50:55.586426 23126066861888 run_lib.py:146] step: 396400, eval_loss: 2.81857e-02
I0216 11:51:13.118168 23126066861888 run_lib.py:133] step: 396450, training_loss: 1.72309e-02
I0216 11:51:30.840999 23126066861888 run_lib.py:133] step: 396500, training_loss: 1.78462e-02
I0216 11:51:30.998029 23126066861888 run_lib.py:146] step: 396500, eval_loss: 2.97022e-02
I0216 11:51:48.528494 23126066861888 run_lib.py:133] step: 396550, training_loss: 1.78146e-02
I0216 11:52:06.225716 23126066861888 run_lib.py:133] step: 396600, training_loss: 1.80000e-02
I0216 11:52:06.381531 23126066861888 run_lib.py:146] step: 396600, eval_loss: 2.71387e-02
I0216 11:52:24.001763 23126066861888 run_lib.py:133] step: 396650, training_loss: 1.76161e-02
I0216 11:52:41.505104 23126066861888 run_lib.py:133] step: 396700, training_loss: 1.73584e-02
I0216 11:52:41.667222 23126066861888 run_lib.py:146] step: 396700, eval_loss: 2.90535e-02
I0216 11:52:59.399422 23126066861888 run_lib.py:133] step: 396750, training_loss: 1.79460e-02
I0216 11:53:16.933702 23126066861888 run_lib.py:133] step: 396800, training_loss: 1.79676e-02
I0216 11:53:17.092424 23126066861888 run_lib.py:146] step: 396800, eval_loss: 2.72371e-02
I0216 11:53:34.609082 23126066861888 run_lib.py:133] step: 396850, training_loss: 1.75270e-02
I0216 11:53:52.296938 23126066861888 run_lib.py:133] step: 396900, training_loss: 1.81910e-02
I0216 11:53:52.461155 23126066861888 run_lib.py:146] step: 396900, eval_loss: 2.89439e-02
I0216 11:54:10.024173 23126066861888 run_lib.py:133] step: 396950, training_loss: 1.72001e-02
I0216 11:54:27.583384 23126066861888 run_lib.py:133] step: 397000, training_loss: 1.85740e-02
I0216 11:54:27.746925 23126066861888 run_lib.py:146] step: 397000, eval_loss: 2.87241e-02
I0216 11:54:45.405574 23126066861888 run_lib.py:133] step: 397050, training_loss: 1.77245e-02
I0216 11:55:02.900863 23126066861888 run_lib.py:133] step: 397100, training_loss: 1.78448e-02
I0216 11:55:03.054177 23126066861888 run_lib.py:146] step: 397100, eval_loss: 2.87963e-02
I0216 11:55:20.587945 23126066861888 run_lib.py:133] step: 397150, training_loss: 1.78511e-02
I0216 11:55:38.109299 23126066861888 run_lib.py:133] step: 397200, training_loss: 1.81211e-02
I0216 11:55:38.278366 23126066861888 run_lib.py:146] step: 397200, eval_loss: 2.86287e-02
I0216 11:55:56.015503 23126066861888 run_lib.py:133] step: 397250, training_loss: 1.70829e-02
I0216 11:56:13.611507 23126066861888 run_lib.py:133] step: 397300, training_loss: 1.75368e-02
I0216 11:56:13.771151 23126066861888 run_lib.py:146] step: 397300, eval_loss: 2.77059e-02
I0216 11:56:31.281897 23126066861888 run_lib.py:133] step: 397350, training_loss: 1.76292e-02
I0216 11:56:48.786341 23126066861888 run_lib.py:133] step: 397400, training_loss: 1.74921e-02
I0216 11:56:48.943180 23126066861888 run_lib.py:146] step: 397400, eval_loss: 2.94289e-02
I0216 11:57:06.617051 23126066861888 run_lib.py:133] step: 397450, training_loss: 1.73452e-02
I0216 11:57:24.193428 23126066861888 run_lib.py:133] step: 397500, training_loss: 1.76366e-02
I0216 11:57:24.351360 23126066861888 run_lib.py:146] step: 397500, eval_loss: 2.85408e-02
I0216 11:57:41.911745 23126066861888 run_lib.py:133] step: 397550, training_loss: 1.78362e-02
I0216 11:57:59.625746 23126066861888 run_lib.py:133] step: 397600, training_loss: 1.79189e-02
I0216 11:57:59.780194 23126066861888 run_lib.py:146] step: 397600, eval_loss: 2.88488e-02
I0216 11:58:17.308598 23126066861888 run_lib.py:133] step: 397650, training_loss: 1.67939e-02
I0216 11:58:34.964342 23126066861888 run_lib.py:133] step: 397700, training_loss: 1.77297e-02
I0216 11:58:35.132715 23126066861888 run_lib.py:146] step: 397700, eval_loss: 2.76181e-02
I0216 11:58:52.681509 23126066861888 run_lib.py:133] step: 397750, training_loss: 1.73406e-02
I0216 11:59:10.229772 23126066861888 run_lib.py:133] step: 397800, training_loss: 1.82551e-02
I0216 11:59:10.467095 23126066861888 run_lib.py:146] step: 397800, eval_loss: 2.75304e-02
I0216 11:59:28.179008 23126066861888 run_lib.py:133] step: 397850, training_loss: 1.84466e-02
I0216 11:59:45.676910 23126066861888 run_lib.py:133] step: 397900, training_loss: 1.78742e-02
I0216 11:59:45.838125 23126066861888 run_lib.py:146] step: 397900, eval_loss: 2.69320e-02
I0216 12:00:03.381087 23126066861888 run_lib.py:133] step: 397950, training_loss: 1.76836e-02
I0216 12:00:21.053117 23126066861888 run_lib.py:133] step: 398000, training_loss: 1.80651e-02
I0216 12:00:21.215163 23126066861888 run_lib.py:146] step: 398000, eval_loss: 2.84267e-02
I0216 12:00:38.787901 23126066861888 run_lib.py:133] step: 398050, training_loss: 1.73177e-02
I0216 12:00:56.307964 23126066861888 run_lib.py:133] step: 398100, training_loss: 1.72465e-02
I0216 12:00:56.466209 23126066861888 run_lib.py:146] step: 398100, eval_loss: 2.81984e-02
I0216 12:01:14.118001 23126066861888 run_lib.py:133] step: 398150, training_loss: 1.79066e-02
I0216 12:01:31.639899 23126066861888 run_lib.py:133] step: 398200, training_loss: 1.72764e-02
I0216 12:01:31.797561 23126066861888 run_lib.py:146] step: 398200, eval_loss: 2.79064e-02
I0216 12:01:49.357075 23126066861888 run_lib.py:133] step: 398250, training_loss: 1.82595e-02
I0216 12:02:06.975033 23126066861888 run_lib.py:133] step: 398300, training_loss: 1.78084e-02
I0216 12:02:07.132501 23126066861888 run_lib.py:146] step: 398300, eval_loss: 2.73871e-02
I0216 12:02:24.839929 23126066861888 run_lib.py:133] step: 398350, training_loss: 1.78091e-02
I0216 12:02:42.451693 23126066861888 run_lib.py:133] step: 398400, training_loss: 1.77440e-02
I0216 12:02:42.608418 23126066861888 run_lib.py:146] step: 398400, eval_loss: 2.76485e-02
I0216 12:03:00.126385 23126066861888 run_lib.py:133] step: 398450, training_loss: 1.78568e-02
I0216 12:03:17.619626 23126066861888 run_lib.py:133] step: 398500, training_loss: 1.82064e-02
I0216 12:03:17.774958 23126066861888 run_lib.py:146] step: 398500, eval_loss: 2.74511e-02
I0216 12:03:35.529759 23126066861888 run_lib.py:133] step: 398550, training_loss: 1.81169e-02
I0216 12:03:53.066079 23126066861888 run_lib.py:133] step: 398600, training_loss: 1.81724e-02
I0216 12:03:53.229229 23126066861888 run_lib.py:146] step: 398600, eval_loss: 2.75845e-02
I0216 12:04:10.718863 23126066861888 run_lib.py:133] step: 398650, training_loss: 1.78959e-02
I0216 12:04:28.465603 23126066861888 run_lib.py:133] step: 398700, training_loss: 1.79327e-02
I0216 12:04:28.629471 23126066861888 run_lib.py:146] step: 398700, eval_loss: 2.86935e-02
I0216 12:04:46.140577 23126066861888 run_lib.py:133] step: 398750, training_loss: 1.70585e-02
I0216 12:05:03.855141 23126066861888 run_lib.py:133] step: 398800, training_loss: 1.73673e-02
I0216 12:05:04.015218 23126066861888 run_lib.py:146] step: 398800, eval_loss: 2.78009e-02
I0216 12:05:21.533357 23126066861888 run_lib.py:133] step: 398850, training_loss: 1.74037e-02
I0216 12:05:39.057067 23126066861888 run_lib.py:133] step: 398900, training_loss: 1.67267e-02
I0216 12:05:39.224936 23126066861888 run_lib.py:146] step: 398900, eval_loss: 2.74094e-02
I0216 12:05:56.971921 23126066861888 run_lib.py:133] step: 398950, training_loss: 1.78814e-02
I0216 12:06:14.513801 23126066861888 run_lib.py:133] step: 399000, training_loss: 1.71731e-02
I0216 12:06:14.667201 23126066861888 run_lib.py:146] step: 399000, eval_loss: 2.83499e-02
I0216 12:06:32.179489 23126066861888 run_lib.py:133] step: 399050, training_loss: 1.78638e-02
I0216 12:06:49.936810 23126066861888 run_lib.py:133] step: 399100, training_loss: 1.76224e-02
I0216 12:06:50.105861 23126066861888 run_lib.py:146] step: 399100, eval_loss: 2.88180e-02
I0216 12:07:07.633231 23126066861888 run_lib.py:133] step: 399150, training_loss: 1.81049e-02
I0216 12:07:25.220592 23126066861888 run_lib.py:133] step: 399200, training_loss: 1.72067e-02
I0216 12:07:25.389164 23126066861888 run_lib.py:146] step: 399200, eval_loss: 2.83575e-02
I0216 12:07:43.026817 23126066861888 run_lib.py:133] step: 399250, training_loss: 1.80616e-02
I0216 12:08:00.569427 23126066861888 run_lib.py:133] step: 399300, training_loss: 1.70042e-02
I0216 12:08:00.730609 23126066861888 run_lib.py:146] step: 399300, eval_loss: 2.84301e-02
I0216 12:08:18.251544 23126066861888 run_lib.py:133] step: 399350, training_loss: 1.86136e-02
I0216 12:08:35.856486 23126066861888 run_lib.py:133] step: 399400, training_loss: 1.80013e-02
I0216 12:08:36.013499 23126066861888 run_lib.py:146] step: 399400, eval_loss: 2.72725e-02
I0216 12:08:53.769293 23126066861888 run_lib.py:133] step: 399450, training_loss: 1.83873e-02
I0216 12:09:11.386271 23126066861888 run_lib.py:133] step: 399500, training_loss: 1.71383e-02
I0216 12:09:11.545173 23126066861888 run_lib.py:146] step: 399500, eval_loss: 2.67068e-02
I0216 12:09:29.045083 23126066861888 run_lib.py:133] step: 399550, training_loss: 1.76730e-02
I0216 12:09:46.549041 23126066861888 run_lib.py:133] step: 399600, training_loss: 1.81584e-02
I0216 12:09:46.721311 23126066861888 run_lib.py:146] step: 399600, eval_loss: 2.87072e-02
I0216 12:10:04.452069 23126066861888 run_lib.py:133] step: 399650, training_loss: 1.73778e-02
I0216 12:10:21.988732 23126066861888 run_lib.py:133] step: 399700, training_loss: 1.77853e-02
I0216 12:10:22.148419 23126066861888 run_lib.py:146] step: 399700, eval_loss: 2.91717e-02
I0216 12:10:39.660112 23126066861888 run_lib.py:133] step: 399750, training_loss: 1.75152e-02
I0216 12:10:57.417582 23126066861888 run_lib.py:133] step: 399800, training_loss: 1.83463e-02
I0216 12:10:57.573194 23126066861888 run_lib.py:146] step: 399800, eval_loss: 2.74625e-02
I0216 12:11:15.093962 23126066861888 run_lib.py:133] step: 399850, training_loss: 1.75972e-02
I0216 12:11:32.853378 23126066861888 run_lib.py:133] step: 399900, training_loss: 1.83881e-02
I0216 12:11:33.011401 23126066861888 run_lib.py:146] step: 399900, eval_loss: 2.71960e-02
I0216 12:11:50.616170 23126066861888 run_lib.py:133] step: 399950, training_loss: 1.80453e-02
I0216 12:12:08.129692 23126066861888 run_lib.py:133] step: 400000, training_loss: 1.78536e-02
I0216 12:12:08.883864 23126066861888 run_lib.py:146] step: 400000, eval_loss: 2.81853e-02
I0216 12:12:29.437227 23126066861888 run_lib.py:133] step: 400050, training_loss: 1.78107e-02
I0216 12:12:46.909965 23126066861888 run_lib.py:133] step: 400100, training_loss: 1.76251e-02
I0216 12:12:47.072746 23126066861888 run_lib.py:146] step: 400100, eval_loss: 2.86034e-02
I0216 12:13:04.565015 23126066861888 run_lib.py:133] step: 400150, training_loss: 1.74070e-02
I0216 12:13:22.311850 23126066861888 run_lib.py:133] step: 400200, training_loss: 1.77242e-02
I0216 12:13:22.497862 23126066861888 run_lib.py:146] step: 400200, eval_loss: 2.72149e-02
I0216 12:13:39.981316 23126066861888 run_lib.py:133] step: 400250, training_loss: 1.73662e-02
I0216 12:13:57.463870 23126066861888 run_lib.py:133] step: 400300, training_loss: 1.73305e-02
I0216 12:13:57.629112 23126066861888 run_lib.py:146] step: 400300, eval_loss: 2.81653e-02
I0216 12:14:15.370415 23126066861888 run_lib.py:133] step: 400350, training_loss: 1.82500e-02
I0216 12:14:32.864937 23126066861888 run_lib.py:133] step: 400400, training_loss: 1.75489e-02
I0216 12:14:33.024145 23126066861888 run_lib.py:146] step: 400400, eval_loss: 2.83150e-02
I0216 12:14:50.723641 23126066861888 run_lib.py:133] step: 400450, training_loss: 1.72506e-02
I0216 12:15:08.254217 23126066861888 run_lib.py:133] step: 400500, training_loss: 1.79737e-02
I0216 12:15:08.412906 23126066861888 run_lib.py:146] step: 400500, eval_loss: 2.75269e-02
I0216 12:15:25.961684 23126066861888 run_lib.py:133] step: 400550, training_loss: 1.79488e-02
I0216 12:15:43.687013 23126066861888 run_lib.py:133] step: 400600, training_loss: 1.73242e-02
I0216 12:15:43.849733 23126066861888 run_lib.py:146] step: 400600, eval_loss: 2.75027e-02
I0216 12:16:01.324516 23126066861888 run_lib.py:133] step: 400650, training_loss: 1.76667e-02
I0216 12:16:18.866832 23126066861888 run_lib.py:133] step: 400700, training_loss: 1.71063e-02
I0216 12:16:19.045256 23126066861888 run_lib.py:146] step: 400700, eval_loss: 2.81056e-02
I0216 12:16:36.614612 23126066861888 run_lib.py:133] step: 400750, training_loss: 1.84145e-02
I0216 12:16:54.152792 23126066861888 run_lib.py:133] step: 400800, training_loss: 1.80740e-02
I0216 12:16:54.313780 23126066861888 run_lib.py:146] step: 400800, eval_loss: 2.75996e-02
I0216 12:17:12.053523 23126066861888 run_lib.py:133] step: 400850, training_loss: 1.84935e-02
I0216 12:17:29.659011 23126066861888 run_lib.py:133] step: 400900, training_loss: 1.68318e-02
I0216 12:17:29.815257 23126066861888 run_lib.py:146] step: 400900, eval_loss: 2.87926e-02
I0216 12:17:47.334687 23126066861888 run_lib.py:133] step: 400950, training_loss: 1.87440e-02
I0216 12:18:04.919454 23126066861888 run_lib.py:133] step: 401000, training_loss: 1.75084e-02
I0216 12:18:05.078097 23126066861888 run_lib.py:146] step: 401000, eval_loss: 2.68011e-02
I0216 12:18:22.831889 23126066861888 run_lib.py:133] step: 401050, training_loss: 1.82411e-02
I0216 12:18:40.354897 23126066861888 run_lib.py:133] step: 401100, training_loss: 1.84998e-02
I0216 12:18:40.515626 23126066861888 run_lib.py:146] step: 401100, eval_loss: 2.84501e-02
I0216 12:18:58.205430 23126066861888 run_lib.py:133] step: 401150, training_loss: 1.81762e-02
I0216 12:19:15.695779 23126066861888 run_lib.py:133] step: 401200, training_loss: 1.78632e-02
I0216 12:19:15.854384 23126066861888 run_lib.py:146] step: 401200, eval_loss: 2.74412e-02
I0216 12:19:33.351967 23126066861888 run_lib.py:133] step: 401250, training_loss: 1.74673e-02
I0216 12:19:51.102596 23126066861888 run_lib.py:133] step: 401300, training_loss: 1.76572e-02
I0216 12:19:51.263616 23126066861888 run_lib.py:146] step: 401300, eval_loss: 2.94348e-02
I0216 12:20:08.803423 23126066861888 run_lib.py:133] step: 401350, training_loss: 1.81744e-02
I0216 12:20:26.278707 23126066861888 run_lib.py:133] step: 401400, training_loss: 1.80177e-02
I0216 12:20:26.433998 23126066861888 run_lib.py:146] step: 401400, eval_loss: 2.71280e-02
I0216 12:20:44.153839 23126066861888 run_lib.py:133] step: 401450, training_loss: 1.83011e-02
I0216 12:21:01.700975 23126066861888 run_lib.py:133] step: 401500, training_loss: 1.77062e-02
I0216 12:21:01.856256 23126066861888 run_lib.py:146] step: 401500, eval_loss: 2.75348e-02
I0216 12:21:19.372582 23126066861888 run_lib.py:133] step: 401550, training_loss: 1.77082e-02
I0216 12:21:37.100545 23126066861888 run_lib.py:133] step: 401600, training_loss: 1.75385e-02
I0216 12:21:37.277189 23126066861888 run_lib.py:146] step: 401600, eval_loss: 2.83619e-02
I0216 12:21:54.806616 23126066861888 run_lib.py:133] step: 401650, training_loss: 1.81220e-02
I0216 12:22:12.332798 23126066861888 run_lib.py:133] step: 401700, training_loss: 1.74763e-02
I0216 12:22:12.490490 23126066861888 run_lib.py:146] step: 401700, eval_loss: 2.81656e-02
I0216 12:22:30.138149 23126066861888 run_lib.py:133] step: 401750, training_loss: 1.74089e-02
I0216 12:22:47.641856 23126066861888 run_lib.py:133] step: 401800, training_loss: 1.77458e-02
I0216 12:22:47.800266 23126066861888 run_lib.py:146] step: 401800, eval_loss: 2.76785e-02
I0216 12:23:05.309764 23126066861888 run_lib.py:133] step: 401850, training_loss: 1.77099e-02
I0216 12:23:22.879887 23126066861888 run_lib.py:133] step: 401900, training_loss: 1.77788e-02
I0216 12:23:23.035402 23126066861888 run_lib.py:146] step: 401900, eval_loss: 2.72842e-02
I0216 12:23:40.789190 23126066861888 run_lib.py:133] step: 401950, training_loss: 1.78224e-02
I0216 12:23:58.368556 23126066861888 run_lib.py:133] step: 402000, training_loss: 1.76101e-02
I0216 12:23:58.533202 23126066861888 run_lib.py:146] step: 402000, eval_loss: 2.80678e-02
I0216 12:24:16.008805 23126066861888 run_lib.py:133] step: 402050, training_loss: 1.78673e-02
I0216 12:24:33.533534 23126066861888 run_lib.py:133] step: 402100, training_loss: 1.78442e-02
I0216 12:24:33.707383 23126066861888 run_lib.py:146] step: 402100, eval_loss: 2.80423e-02
I0216 12:24:51.439209 23126066861888 run_lib.py:133] step: 402150, training_loss: 1.77310e-02
I0216 12:25:08.949927 23126066861888 run_lib.py:133] step: 402200, training_loss: 1.69088e-02
I0216 12:25:09.107385 23126066861888 run_lib.py:146] step: 402200, eval_loss: 2.76040e-02
I0216 12:25:26.631102 23126066861888 run_lib.py:133] step: 402250, training_loss: 1.73288e-02
I0216 12:25:44.347954 23126066861888 run_lib.py:133] step: 402300, training_loss: 1.72883e-02
I0216 12:25:44.505082 23126066861888 run_lib.py:146] step: 402300, eval_loss: 2.73197e-02
I0216 12:26:02.025282 23126066861888 run_lib.py:133] step: 402350, training_loss: 1.79299e-02
I0216 12:26:19.722891 23126066861888 run_lib.py:133] step: 402400, training_loss: 1.73639e-02
I0216 12:26:19.886772 23126066861888 run_lib.py:146] step: 402400, eval_loss: 2.91137e-02
I0216 12:26:37.461996 23126066861888 run_lib.py:133] step: 402450, training_loss: 1.74328e-02
I0216 12:26:55.002985 23126066861888 run_lib.py:133] step: 402500, training_loss: 1.77882e-02
I0216 12:26:55.162194 23126066861888 run_lib.py:146] step: 402500, eval_loss: 2.85763e-02
I0216 12:27:12.851271 23126066861888 run_lib.py:133] step: 402550, training_loss: 1.75738e-02
I0216 12:27:30.313827 23126066861888 run_lib.py:133] step: 402600, training_loss: 1.75730e-02
I0216 12:27:30.478962 23126066861888 run_lib.py:146] step: 402600, eval_loss: 2.85466e-02
I0216 12:27:48.002526 23126066861888 run_lib.py:133] step: 402650, training_loss: 1.68980e-02
I0216 12:28:05.812893 23126066861888 run_lib.py:133] step: 402700, training_loss: 1.67772e-02
I0216 12:28:05.971374 23126066861888 run_lib.py:146] step: 402700, eval_loss: 2.91092e-02
I0216 12:28:23.476983 23126066861888 run_lib.py:133] step: 402750, training_loss: 1.76075e-02
I0216 12:28:40.954207 23126066861888 run_lib.py:133] step: 402800, training_loss: 1.76741e-02
I0216 12:28:41.116020 23126066861888 run_lib.py:146] step: 402800, eval_loss: 2.72464e-02
I0216 12:28:58.711603 23126066861888 run_lib.py:133] step: 402850, training_loss: 1.80406e-02
I0216 12:29:16.245173 23126066861888 run_lib.py:133] step: 402900, training_loss: 1.83806e-02
I0216 12:29:16.400111 23126066861888 run_lib.py:146] step: 402900, eval_loss: 2.74180e-02
I0216 12:29:33.950594 23126066861888 run_lib.py:133] step: 402950, training_loss: 1.73580e-02
I0216 12:29:51.485507 23126066861888 run_lib.py:133] step: 403000, training_loss: 1.76633e-02
I0216 12:29:51.645622 23126066861888 run_lib.py:146] step: 403000, eval_loss: 2.67327e-02
I0216 12:30:09.325628 23126066861888 run_lib.py:133] step: 403050, training_loss: 1.70697e-02
I0216 12:30:26.946706 23126066861888 run_lib.py:133] step: 403100, training_loss: 1.80614e-02
I0216 12:30:27.103376 23126066861888 run_lib.py:146] step: 403100, eval_loss: 2.67093e-02
I0216 12:30:44.602360 23126066861888 run_lib.py:133] step: 403150, training_loss: 1.81121e-02
I0216 12:31:02.094673 23126066861888 run_lib.py:133] step: 403200, training_loss: 1.75725e-02
I0216 12:31:02.255950 23126066861888 run_lib.py:146] step: 403200, eval_loss: 2.74280e-02
I0216 12:31:19.924426 23126066861888 run_lib.py:133] step: 403250, training_loss: 1.76172e-02
I0216 12:31:37.512555 23126066861888 run_lib.py:133] step: 403300, training_loss: 1.77766e-02
I0216 12:31:37.671320 23126066861888 run_lib.py:146] step: 403300, eval_loss: 2.85316e-02
I0216 12:31:55.200855 23126066861888 run_lib.py:133] step: 403350, training_loss: 1.76326e-02
I0216 12:32:12.925482 23126066861888 run_lib.py:133] step: 403400, training_loss: 1.73674e-02
I0216 12:32:13.082182 23126066861888 run_lib.py:146] step: 403400, eval_loss: 2.86600e-02
I0216 12:32:30.582498 23126066861888 run_lib.py:133] step: 403450, training_loss: 1.73485e-02
I0216 12:32:48.329818 23126066861888 run_lib.py:133] step: 403500, training_loss: 1.77767e-02
I0216 12:32:48.504684 23126066861888 run_lib.py:146] step: 403500, eval_loss: 2.82891e-02
I0216 12:33:06.072702 23126066861888 run_lib.py:133] step: 403550, training_loss: 1.80953e-02
I0216 12:33:23.600380 23126066861888 run_lib.py:133] step: 403600, training_loss: 1.78725e-02
I0216 12:33:23.758290 23126066861888 run_lib.py:146] step: 403600, eval_loss: 2.85916e-02
I0216 12:33:41.464745 23126066861888 run_lib.py:133] step: 403650, training_loss: 1.84342e-02
I0216 12:33:58.980676 23126066861888 run_lib.py:133] step: 403700, training_loss: 1.71955e-02
I0216 12:33:59.167958 23126066861888 run_lib.py:146] step: 403700, eval_loss: 2.71552e-02
I0216 12:34:16.650613 23126066861888 run_lib.py:133] step: 403750, training_loss: 1.81147e-02
I0216 12:34:34.332051 23126066861888 run_lib.py:133] step: 403800, training_loss: 1.78331e-02
I0216 12:34:34.487020 23126066861888 run_lib.py:146] step: 403800, eval_loss: 2.81207e-02
I0216 12:34:52.092375 23126066861888 run_lib.py:133] step: 403850, training_loss: 1.65626e-02
I0216 12:35:09.634837 23126066861888 run_lib.py:133] step: 403900, training_loss: 1.80815e-02
I0216 12:35:09.792078 23126066861888 run_lib.py:146] step: 403900, eval_loss: 2.81506e-02
I0216 12:35:27.403506 23126066861888 run_lib.py:133] step: 403950, training_loss: 1.79444e-02
I0216 12:35:44.900787 23126066861888 run_lib.py:133] step: 404000, training_loss: 1.82255e-02
I0216 12:35:45.061328 23126066861888 run_lib.py:146] step: 404000, eval_loss: 2.82442e-02
I0216 12:36:02.570625 23126066861888 run_lib.py:133] step: 404050, training_loss: 1.84531e-02
I0216 12:36:20.130193 23126066861888 run_lib.py:133] step: 404100, training_loss: 1.69258e-02
I0216 12:36:20.300487 23126066861888 run_lib.py:146] step: 404100, eval_loss: 2.87451e-02
I0216 12:36:38.029292 23126066861888 run_lib.py:133] step: 404150, training_loss: 1.78410e-02
I0216 12:36:55.712216 23126066861888 run_lib.py:133] step: 404200, training_loss: 1.72141e-02
I0216 12:36:55.866548 23126066861888 run_lib.py:146] step: 404200, eval_loss: 2.75110e-02
I0216 12:37:13.377648 23126066861888 run_lib.py:133] step: 404250, training_loss: 1.80059e-02
I0216 12:37:30.915348 23126066861888 run_lib.py:133] step: 404300, training_loss: 1.77583e-02
I0216 12:37:31.068640 23126066861888 run_lib.py:146] step: 404300, eval_loss: 2.75393e-02
I0216 12:37:48.723562 23126066861888 run_lib.py:133] step: 404350, training_loss: 1.78784e-02
I0216 12:38:06.265592 23126066861888 run_lib.py:133] step: 404400, training_loss: 1.81415e-02
I0216 12:38:06.440364 23126066861888 run_lib.py:146] step: 404400, eval_loss: 2.78154e-02
I0216 12:38:24.027231 23126066861888 run_lib.py:133] step: 404450, training_loss: 1.75094e-02
I0216 12:38:41.786074 23126066861888 run_lib.py:133] step: 404500, training_loss: 1.72902e-02
I0216 12:38:41.949517 23126066861888 run_lib.py:146] step: 404500, eval_loss: 2.80798e-02
I0216 12:38:59.477706 23126066861888 run_lib.py:133] step: 404550, training_loss: 1.79537e-02
I0216 12:39:17.163028 23126066861888 run_lib.py:133] step: 404600, training_loss: 1.76572e-02
I0216 12:39:17.319717 23126066861888 run_lib.py:146] step: 404600, eval_loss: 2.84727e-02
I0216 12:39:34.840876 23126066861888 run_lib.py:133] step: 404650, training_loss: 1.80231e-02
I0216 12:39:52.398313 23126066861888 run_lib.py:133] step: 404700, training_loss: 1.82506e-02
I0216 12:39:52.552079 23126066861888 run_lib.py:146] step: 404700, eval_loss: 2.81605e-02
I0216 12:40:10.361023 23126066861888 run_lib.py:133] step: 404750, training_loss: 1.80956e-02
I0216 12:40:27.863716 23126066861888 run_lib.py:133] step: 404800, training_loss: 1.81201e-02
I0216 12:40:28.018221 23126066861888 run_lib.py:146] step: 404800, eval_loss: 2.85584e-02
I0216 12:40:45.517638 23126066861888 run_lib.py:133] step: 404850, training_loss: 1.79288e-02
I0216 12:41:03.180493 23126066861888 run_lib.py:133] step: 404900, training_loss: 1.80579e-02
I0216 12:41:03.359146 23126066861888 run_lib.py:146] step: 404900, eval_loss: 2.87098e-02
I0216 12:41:20.921650 23126066861888 run_lib.py:133] step: 404950, training_loss: 1.80266e-02
I0216 12:41:38.480785 23126066861888 run_lib.py:133] step: 405000, training_loss: 1.80563e-02
I0216 12:41:38.639449 23126066861888 run_lib.py:146] step: 405000, eval_loss: 2.82861e-02
I0216 12:41:56.278673 23126066861888 run_lib.py:133] step: 405050, training_loss: 1.76353e-02
I0216 12:42:13.778222 23126066861888 run_lib.py:133] step: 405100, training_loss: 1.75273e-02
I0216 12:42:13.936084 23126066861888 run_lib.py:146] step: 405100, eval_loss: 2.81770e-02
I0216 12:42:31.448318 23126066861888 run_lib.py:133] step: 405150, training_loss: 1.80636e-02
I0216 12:42:48.997924 23126066861888 run_lib.py:133] step: 405200, training_loss: 1.74799e-02
I0216 12:42:49.162173 23126066861888 run_lib.py:146] step: 405200, eval_loss: 2.71804e-02
I0216 12:43:06.954022 23126066861888 run_lib.py:133] step: 405250, training_loss: 1.71881e-02
I0216 12:43:24.579574 23126066861888 run_lib.py:133] step: 405300, training_loss: 1.80308e-02
I0216 12:43:24.735337 23126066861888 run_lib.py:146] step: 405300, eval_loss: 2.82505e-02
I0216 12:43:42.213747 23126066861888 run_lib.py:133] step: 405350, training_loss: 1.76572e-02
I0216 12:43:59.721709 23126066861888 run_lib.py:133] step: 405400, training_loss: 1.78077e-02
I0216 12:43:59.882682 23126066861888 run_lib.py:146] step: 405400, eval_loss: 2.89611e-02
I0216 12:44:17.549296 23126066861888 run_lib.py:133] step: 405450, training_loss: 1.71543e-02
I0216 12:44:35.048514 23126066861888 run_lib.py:133] step: 405500, training_loss: 1.74178e-02
I0216 12:44:35.216238 23126066861888 run_lib.py:146] step: 405500, eval_loss: 2.81093e-02
I0216 12:44:52.783907 23126066861888 run_lib.py:133] step: 405550, training_loss: 1.76503e-02
I0216 12:45:10.548359 23126066861888 run_lib.py:133] step: 405600, training_loss: 1.83079e-02
I0216 12:45:10.710719 23126066861888 run_lib.py:146] step: 405600, eval_loss: 2.87560e-02
I0216 12:45:28.285924 23126066861888 run_lib.py:133] step: 405650, training_loss: 1.82923e-02
I0216 12:45:45.943980 23126066861888 run_lib.py:133] step: 405700, training_loss: 1.85469e-02
I0216 12:45:46.098764 23126066861888 run_lib.py:146] step: 405700, eval_loss: 2.83081e-02
I0216 12:46:03.654817 23126066861888 run_lib.py:133] step: 405750, training_loss: 1.72427e-02
I0216 12:46:21.180268 23126066861888 run_lib.py:133] step: 405800, training_loss: 1.82050e-02
I0216 12:46:21.341528 23126066861888 run_lib.py:146] step: 405800, eval_loss: 2.69737e-02
I0216 12:46:39.096387 23126066861888 run_lib.py:133] step: 405850, training_loss: 1.82336e-02
I0216 12:46:56.630166 23126066861888 run_lib.py:133] step: 405900, training_loss: 1.74289e-02
I0216 12:46:56.794317 23126066861888 run_lib.py:146] step: 405900, eval_loss: 2.68277e-02
I0216 12:47:14.285960 23126066861888 run_lib.py:133] step: 405950, training_loss: 1.76149e-02
I0216 12:47:31.933072 23126066861888 run_lib.py:133] step: 406000, training_loss: 1.68524e-02
I0216 12:47:32.089280 23126066861888 run_lib.py:146] step: 406000, eval_loss: 2.87587e-02
I0216 12:47:49.626573 23126066861888 run_lib.py:133] step: 406050, training_loss: 1.76003e-02
I0216 12:48:07.184607 23126066861888 run_lib.py:133] step: 406100, training_loss: 1.80318e-02
I0216 12:48:07.347424 23126066861888 run_lib.py:146] step: 406100, eval_loss: 2.80669e-02
I0216 12:48:25.037255 23126066861888 run_lib.py:133] step: 406150, training_loss: 1.84393e-02
I0216 12:48:42.537231 23126066861888 run_lib.py:133] step: 406200, training_loss: 1.75014e-02
I0216 12:48:42.692093 23126066861888 run_lib.py:146] step: 406200, eval_loss: 2.83256e-02
I0216 12:49:00.224050 23126066861888 run_lib.py:133] step: 406250, training_loss: 1.83064e-02
I0216 12:49:17.747715 23126066861888 run_lib.py:133] step: 406300, training_loss: 1.80261e-02
I0216 12:49:17.921187 23126066861888 run_lib.py:146] step: 406300, eval_loss: 2.69824e-02
I0216 12:49:35.640784 23126066861888 run_lib.py:133] step: 406350, training_loss: 1.78785e-02
I0216 12:49:53.320830 23126066861888 run_lib.py:133] step: 406400, training_loss: 1.73577e-02
I0216 12:49:53.480208 23126066861888 run_lib.py:146] step: 406400, eval_loss: 2.86866e-02
I0216 12:50:11.011945 23126066861888 run_lib.py:133] step: 406450, training_loss: 1.81650e-02
I0216 12:50:28.509500 23126066861888 run_lib.py:133] step: 406500, training_loss: 1.79373e-02
I0216 12:50:28.667276 23126066861888 run_lib.py:146] step: 406500, eval_loss: 2.71430e-02
I0216 12:50:46.332824 23126066861888 run_lib.py:133] step: 406550, training_loss: 1.75063e-02
I0216 12:51:03.886210 23126066861888 run_lib.py:133] step: 406600, training_loss: 1.71773e-02
I0216 12:51:04.051469 23126066861888 run_lib.py:146] step: 406600, eval_loss: 2.82531e-02
I0216 12:51:21.669285 23126066861888 run_lib.py:133] step: 406650, training_loss: 1.75123e-02
I0216 12:51:39.399588 23126066861888 run_lib.py:133] step: 406700, training_loss: 1.79557e-02
I0216 12:51:39.554152 23126066861888 run_lib.py:146] step: 406700, eval_loss: 2.65314e-02
I0216 12:51:57.039884 23126066861888 run_lib.py:133] step: 406750, training_loss: 1.71351e-02
I0216 12:52:14.738671 23126066861888 run_lib.py:133] step: 406800, training_loss: 1.74533e-02
I0216 12:52:14.899574 23126066861888 run_lib.py:146] step: 406800, eval_loss: 2.80428e-02
I0216 12:52:32.371854 23126066861888 run_lib.py:133] step: 406850, training_loss: 1.79667e-02
I0216 12:52:49.878223 23126066861888 run_lib.py:133] step: 406900, training_loss: 1.79618e-02
I0216 12:52:50.048189 23126066861888 run_lib.py:146] step: 406900, eval_loss: 2.80649e-02
I0216 12:53:07.780552 23126066861888 run_lib.py:133] step: 406950, training_loss: 1.77338e-02
I0216 12:53:25.345911 23126066861888 run_lib.py:133] step: 407000, training_loss: 1.69576e-02
I0216 12:53:25.509143 23126066861888 run_lib.py:146] step: 407000, eval_loss: 2.77734e-02
I0216 12:53:43.017940 23126066861888 run_lib.py:133] step: 407050, training_loss: 1.82476e-02
I0216 12:54:00.695335 23126066861888 run_lib.py:133] step: 407100, training_loss: 1.78521e-02
I0216 12:54:00.848878 23126066861888 run_lib.py:146] step: 407100, eval_loss: 2.88829e-02
I0216 12:54:18.356956 23126066861888 run_lib.py:133] step: 407150, training_loss: 1.71969e-02
I0216 12:54:35.925709 23126066861888 run_lib.py:133] step: 407200, training_loss: 1.80007e-02
I0216 12:54:36.092398 23126066861888 run_lib.py:146] step: 407200, eval_loss: 2.87501e-02
I0216 12:54:53.751224 23126066861888 run_lib.py:133] step: 407250, training_loss: 1.71135e-02
I0216 12:55:11.316342 23126066861888 run_lib.py:133] step: 407300, training_loss: 1.76849e-02
I0216 12:55:11.476490 23126066861888 run_lib.py:146] step: 407300, eval_loss: 2.81266e-02
I0216 12:55:28.979608 23126066861888 run_lib.py:133] step: 407350, training_loss: 1.79828e-02
I0216 12:55:46.484447 23126066861888 run_lib.py:133] step: 407400, training_loss: 1.72178e-02
I0216 12:55:46.647204 23126066861888 run_lib.py:146] step: 407400, eval_loss: 2.82383e-02
I0216 12:56:04.365027 23126066861888 run_lib.py:133] step: 407450, training_loss: 1.75257e-02
I0216 12:56:22.082003 23126066861888 run_lib.py:133] step: 407500, training_loss: 1.81304e-02
I0216 12:56:22.240427 23126066861888 run_lib.py:146] step: 407500, eval_loss: 2.73446e-02
I0216 12:56:39.758807 23126066861888 run_lib.py:133] step: 407550, training_loss: 1.73817e-02
I0216 12:56:57.286386 23126066861888 run_lib.py:133] step: 407600, training_loss: 1.74889e-02
I0216 12:56:57.440201 23126066861888 run_lib.py:146] step: 407600, eval_loss: 2.85614e-02
I0216 12:57:15.111601 23126066861888 run_lib.py:133] step: 407650, training_loss: 1.81660e-02
I0216 12:57:32.609880 23126066861888 run_lib.py:133] step: 407700, training_loss: 1.73293e-02
I0216 12:57:32.773402 23126066861888 run_lib.py:146] step: 407700, eval_loss: 2.77753e-02
I0216 12:57:50.294805 23126066861888 run_lib.py:133] step: 407750, training_loss: 1.81770e-02
I0216 12:58:08.075959 23126066861888 run_lib.py:133] step: 407800, training_loss: 1.76830e-02
I0216 12:58:08.235734 23126066861888 run_lib.py:146] step: 407800, eval_loss: 2.84933e-02
I0216 12:58:25.745273 23126066861888 run_lib.py:133] step: 407850, training_loss: 1.71237e-02
I0216 12:58:43.452310 23126066861888 run_lib.py:133] step: 407900, training_loss: 1.67501e-02
I0216 12:58:43.609247 23126066861888 run_lib.py:146] step: 407900, eval_loss: 2.76342e-02
I0216 12:59:01.112481 23126066861888 run_lib.py:133] step: 407950, training_loss: 1.71643e-02
I0216 12:59:18.647252 23126066861888 run_lib.py:133] step: 408000, training_loss: 1.72769e-02
I0216 12:59:18.803901 23126066861888 run_lib.py:146] step: 408000, eval_loss: 2.85968e-02
I0216 12:59:36.544270 23126066861888 run_lib.py:133] step: 408050, training_loss: 1.79241e-02
I0216 12:59:54.040787 23126066861888 run_lib.py:133] step: 408100, training_loss: 1.74993e-02
I0216 12:59:54.195216 23126066861888 run_lib.py:146] step: 408100, eval_loss: 2.81733e-02
I0216 13:00:11.709704 23126066861888 run_lib.py:133] step: 408150, training_loss: 1.78546e-02
I0216 13:00:29.428253 23126066861888 run_lib.py:133] step: 408200, training_loss: 1.78665e-02
I0216 13:00:29.587980 23126066861888 run_lib.py:146] step: 408200, eval_loss: 2.90682e-02
I0216 13:00:47.080304 23126066861888 run_lib.py:133] step: 408250, training_loss: 1.73315e-02
I0216 13:01:04.585198 23126066861888 run_lib.py:133] step: 408300, training_loss: 1.73576e-02
I0216 13:01:04.763198 23126066861888 run_lib.py:146] step: 408300, eval_loss: 2.78277e-02
I0216 13:01:22.417814 23126066861888 run_lib.py:133] step: 408350, training_loss: 1.77107e-02
I0216 13:01:39.960229 23126066861888 run_lib.py:133] step: 408400, training_loss: 1.75626e-02
I0216 13:01:40.122380 23126066861888 run_lib.py:146] step: 408400, eval_loss: 2.78000e-02
I0216 13:01:57.621721 23126066861888 run_lib.py:133] step: 408450, training_loss: 1.78386e-02
I0216 13:02:15.105622 23126066861888 run_lib.py:133] step: 408500, training_loss: 1.81742e-02
I0216 13:02:15.261241 23126066861888 run_lib.py:146] step: 408500, eval_loss: 2.72174e-02
I0216 13:02:32.979124 23126066861888 run_lib.py:133] step: 408550, training_loss: 1.79687e-02
I0216 13:02:50.643823 23126066861888 run_lib.py:133] step: 408600, training_loss: 1.81994e-02
I0216 13:02:50.806454 23126066861888 run_lib.py:146] step: 408600, eval_loss: 2.87750e-02
I0216 13:03:08.405340 23126066861888 run_lib.py:133] step: 408650, training_loss: 1.74905e-02
I0216 13:03:25.953363 23126066861888 run_lib.py:133] step: 408700, training_loss: 1.73470e-02
I0216 13:03:26.113218 23126066861888 run_lib.py:146] step: 408700, eval_loss: 2.78931e-02
I0216 13:03:43.835312 23126066861888 run_lib.py:133] step: 408750, training_loss: 1.74385e-02
I0216 13:04:01.327658 23126066861888 run_lib.py:133] step: 408800, training_loss: 1.76333e-02
I0216 13:04:01.485118 23126066861888 run_lib.py:146] step: 408800, eval_loss: 2.73446e-02
I0216 13:04:18.992215 23126066861888 run_lib.py:133] step: 408850, training_loss: 1.83228e-02
I0216 13:04:36.757427 23126066861888 run_lib.py:133] step: 408900, training_loss: 1.75355e-02
I0216 13:04:36.915018 23126066861888 run_lib.py:146] step: 408900, eval_loss: 2.72787e-02
I0216 13:04:54.534508 23126066861888 run_lib.py:133] step: 408950, training_loss: 1.70454e-02
I0216 13:05:12.233577 23126066861888 run_lib.py:133] step: 409000, training_loss: 1.73828e-02
I0216 13:05:12.395502 23126066861888 run_lib.py:146] step: 409000, eval_loss: 2.78654e-02
I0216 13:05:29.886090 23126066861888 run_lib.py:133] step: 409050, training_loss: 1.74494e-02
I0216 13:05:47.407681 23126066861888 run_lib.py:133] step: 409100, training_loss: 1.82834e-02
I0216 13:05:47.564186 23126066861888 run_lib.py:146] step: 409100, eval_loss: 2.82178e-02
I0216 13:06:05.234378 23126066861888 run_lib.py:133] step: 409150, training_loss: 1.80490e-02
I0216 13:06:22.781977 23126066861888 run_lib.py:133] step: 409200, training_loss: 1.81369e-02
I0216 13:06:22.959192 23126066861888 run_lib.py:146] step: 409200, eval_loss: 2.88782e-02
I0216 13:06:40.505738 23126066861888 run_lib.py:133] step: 409250, training_loss: 1.80074e-02
I0216 13:06:58.256852 23126066861888 run_lib.py:133] step: 409300, training_loss: 1.76314e-02
I0216 13:06:58.414503 23126066861888 run_lib.py:146] step: 409300, eval_loss: 2.84635e-02
I0216 13:07:15.963899 23126066861888 run_lib.py:133] step: 409350, training_loss: 1.80049e-02
I0216 13:07:33.461200 23126066861888 run_lib.py:133] step: 409400, training_loss: 1.77022e-02
I0216 13:07:33.618310 23126066861888 run_lib.py:146] step: 409400, eval_loss: 2.80861e-02
I0216 13:07:51.207509 23126066861888 run_lib.py:133] step: 409450, training_loss: 1.68000e-02
I0216 13:08:08.758260 23126066861888 run_lib.py:133] step: 409500, training_loss: 1.83553e-02
I0216 13:08:08.920352 23126066861888 run_lib.py:146] step: 409500, eval_loss: 2.87275e-02
I0216 13:08:26.503183 23126066861888 run_lib.py:133] step: 409550, training_loss: 1.76965e-02
I0216 13:08:44.028854 23126066861888 run_lib.py:133] step: 409600, training_loss: 1.75117e-02
I0216 13:08:44.202368 23126066861888 run_lib.py:146] step: 409600, eval_loss: 2.78095e-02
I0216 13:09:01.886080 23126066861888 run_lib.py:133] step: 409650, training_loss: 1.76235e-02
I0216 13:09:19.487433 23126066861888 run_lib.py:133] step: 409700, training_loss: 1.69315e-02
I0216 13:09:19.650348 23126066861888 run_lib.py:146] step: 409700, eval_loss: 2.78998e-02
I0216 13:09:37.239361 23126066861888 run_lib.py:133] step: 409750, training_loss: 1.75862e-02
I0216 13:09:54.818660 23126066861888 run_lib.py:133] step: 409800, training_loss: 1.72940e-02
I0216 13:09:54.980538 23126066861888 run_lib.py:146] step: 409800, eval_loss: 2.72193e-02
I0216 13:10:12.703123 23126066861888 run_lib.py:133] step: 409850, training_loss: 1.85845e-02
I0216 13:10:30.220049 23126066861888 run_lib.py:133] step: 409900, training_loss: 1.77823e-02
I0216 13:10:30.381359 23126066861888 run_lib.py:146] step: 409900, eval_loss: 2.69149e-02
I0216 13:10:47.920837 23126066861888 run_lib.py:133] step: 409950, training_loss: 1.78360e-02
I0216 13:11:05.581865 23126066861888 run_lib.py:133] step: 410000, training_loss: 1.76073e-02
I0216 13:11:07.915209 23126066861888 run_lib.py:146] step: 410000, eval_loss: 2.92826e-02
I0216 13:11:29.486384 23126066861888 run_lib.py:133] step: 410050, training_loss: 1.71990e-02
I0216 13:11:46.976338 23126066861888 run_lib.py:133] step: 410100, training_loss: 1.74313e-02
I0216 13:11:47.132123 23126066861888 run_lib.py:146] step: 410100, eval_loss: 2.77592e-02
I0216 13:12:04.818720 23126066861888 run_lib.py:133] step: 410150, training_loss: 1.72971e-02
I0216 13:12:22.421348 23126066861888 run_lib.py:133] step: 410200, training_loss: 1.80595e-02
I0216 13:12:22.581397 23126066861888 run_lib.py:146] step: 410200, eval_loss: 2.90524e-02
I0216 13:12:40.078206 23126066861888 run_lib.py:133] step: 410250, training_loss: 1.73845e-02
I0216 13:12:57.587319 23126066861888 run_lib.py:133] step: 410300, training_loss: 1.73194e-02
I0216 13:12:57.757280 23126066861888 run_lib.py:146] step: 410300, eval_loss: 2.86440e-02
I0216 13:13:15.513819 23126066861888 run_lib.py:133] step: 410350, training_loss: 1.80552e-02
I0216 13:13:33.017006 23126066861888 run_lib.py:133] step: 410400, training_loss: 1.80776e-02
I0216 13:13:33.174372 23126066861888 run_lib.py:146] step: 410400, eval_loss: 2.85470e-02
I0216 13:13:50.912102 23126066861888 run_lib.py:133] step: 410450, training_loss: 1.80115e-02
I0216 13:14:08.416353 23126066861888 run_lib.py:133] step: 410500, training_loss: 1.76048e-02
I0216 13:14:08.567889 23126066861888 run_lib.py:146] step: 410500, eval_loss: 2.84079e-02
I0216 13:14:26.065853 23126066861888 run_lib.py:133] step: 410550, training_loss: 1.72356e-02
I0216 13:14:43.804410 23126066861888 run_lib.py:133] step: 410600, training_loss: 1.76257e-02
I0216 13:14:43.968296 23126066861888 run_lib.py:146] step: 410600, eval_loss: 2.81502e-02
I0216 13:15:01.475972 23126066861888 run_lib.py:133] step: 410650, training_loss: 1.77223e-02
I0216 13:15:19.000922 23126066861888 run_lib.py:133] step: 410700, training_loss: 1.74928e-02
I0216 13:15:19.161176 23126066861888 run_lib.py:146] step: 410700, eval_loss: 2.88377e-02
I0216 13:15:36.907818 23126066861888 run_lib.py:133] step: 410750, training_loss: 1.71305e-02
I0216 13:15:54.405899 23126066861888 run_lib.py:133] step: 410800, training_loss: 1.79430e-02
I0216 13:15:54.567120 23126066861888 run_lib.py:146] step: 410800, eval_loss: 2.72125e-02
I0216 13:16:12.259932 23126066861888 run_lib.py:133] step: 410850, training_loss: 1.70847e-02
I0216 13:16:29.888459 23126066861888 run_lib.py:133] step: 410900, training_loss: 1.72758e-02
I0216 13:16:30.045976 23126066861888 run_lib.py:146] step: 410900, eval_loss: 2.82726e-02
I0216 13:16:47.596575 23126066861888 run_lib.py:133] step: 410950, training_loss: 1.71853e-02
I0216 13:17:05.308493 23126066861888 run_lib.py:133] step: 411000, training_loss: 1.74396e-02
I0216 13:17:05.470227 23126066861888 run_lib.py:146] step: 411000, eval_loss: 2.67660e-02
I0216 13:17:22.984279 23126066861888 run_lib.py:133] step: 411050, training_loss: 1.78714e-02
I0216 13:17:40.562801 23126066861888 run_lib.py:133] step: 411100, training_loss: 1.74277e-02
I0216 13:17:40.734415 23126066861888 run_lib.py:146] step: 411100, eval_loss: 2.85101e-02
I0216 13:17:58.353049 23126066861888 run_lib.py:133] step: 411150, training_loss: 1.78739e-02
I0216 13:18:15.946908 23126066861888 run_lib.py:133] step: 411200, training_loss: 1.71435e-02
I0216 13:18:16.109531 23126066861888 run_lib.py:146] step: 411200, eval_loss: 2.84537e-02
I0216 13:18:33.803527 23126066861888 run_lib.py:133] step: 411250, training_loss: 1.75481e-02
I0216 13:18:51.399868 23126066861888 run_lib.py:133] step: 411300, training_loss: 1.73623e-02
I0216 13:18:51.556146 23126066861888 run_lib.py:146] step: 411300, eval_loss: 2.76218e-02
I0216 13:19:09.162442 23126066861888 run_lib.py:133] step: 411350, training_loss: 1.72659e-02
I0216 13:19:26.704052 23126066861888 run_lib.py:133] step: 411400, training_loss: 1.72351e-02
I0216 13:19:26.859234 23126066861888 run_lib.py:146] step: 411400, eval_loss: 2.80614e-02
I0216 13:19:44.559344 23126066861888 run_lib.py:133] step: 411450, training_loss: 1.80395e-02
I0216 13:20:02.110638 23126066861888 run_lib.py:133] step: 411500, training_loss: 1.80510e-02
I0216 13:20:02.267364 23126066861888 run_lib.py:146] step: 411500, eval_loss: 2.92199e-02
I0216 13:20:20.012591 23126066861888 run_lib.py:133] step: 411550, training_loss: 1.71928e-02
I0216 13:20:37.521304 23126066861888 run_lib.py:133] step: 411600, training_loss: 1.77996e-02
I0216 13:20:37.686760 23126066861888 run_lib.py:146] step: 411600, eval_loss: 2.79512e-02
I0216 13:20:55.163623 23126066861888 run_lib.py:133] step: 411650, training_loss: 1.75274e-02
I0216 13:21:12.918793 23126066861888 run_lib.py:133] step: 411700, training_loss: 1.76083e-02
I0216 13:21:13.103208 23126066861888 run_lib.py:146] step: 411700, eval_loss: 2.82273e-02
I0216 13:21:30.672331 23126066861888 run_lib.py:133] step: 411750, training_loss: 1.78488e-02
I0216 13:21:48.209539 23126066861888 run_lib.py:133] step: 411800, training_loss: 1.82350e-02
I0216 13:21:48.366972 23126066861888 run_lib.py:146] step: 411800, eval_loss: 2.75141e-02
I0216 13:22:06.141419 23126066861888 run_lib.py:133] step: 411850, training_loss: 1.69507e-02
I0216 13:22:23.649319 23126066861888 run_lib.py:133] step: 411900, training_loss: 1.71639e-02
I0216 13:22:23.805181 23126066861888 run_lib.py:146] step: 411900, eval_loss: 2.83883e-02
I0216 13:22:41.304912 23126066861888 run_lib.py:133] step: 411950, training_loss: 1.74038e-02
I0216 13:22:59.024466 23126066861888 run_lib.py:133] step: 412000, training_loss: 1.75967e-02
I0216 13:22:59.189284 23126066861888 run_lib.py:146] step: 412000, eval_loss: 2.81612e-02
I0216 13:23:16.776068 23126066861888 run_lib.py:133] step: 412050, training_loss: 1.78175e-02
I0216 13:23:34.307337 23126066861888 run_lib.py:133] step: 412100, training_loss: 1.76788e-02
I0216 13:23:34.469173 23126066861888 run_lib.py:146] step: 412100, eval_loss: 2.94015e-02
I0216 13:23:52.098720 23126066861888 run_lib.py:133] step: 412150, training_loss: 1.75303e-02
I0216 13:24:09.621594 23126066861888 run_lib.py:133] step: 412200, training_loss: 1.73546e-02
I0216 13:24:09.778233 23126066861888 run_lib.py:146] step: 412200, eval_loss: 2.82103e-02
I0216 13:24:27.303342 23126066861888 run_lib.py:133] step: 412250, training_loss: 1.77864e-02
I0216 13:24:44.824858 23126066861888 run_lib.py:133] step: 412300, training_loss: 1.71530e-02
I0216 13:24:44.983097 23126066861888 run_lib.py:146] step: 412300, eval_loss: 2.85851e-02
I0216 13:25:02.742180 23126066861888 run_lib.py:133] step: 412350, training_loss: 1.85227e-02
I0216 13:25:20.415061 23126066861888 run_lib.py:133] step: 412400, training_loss: 1.79901e-02
I0216 13:25:20.568300 23126066861888 run_lib.py:146] step: 412400, eval_loss: 2.60770e-02
I0216 13:25:38.090908 23126066861888 run_lib.py:133] step: 412450, training_loss: 1.79164e-02
I0216 13:25:55.640900 23126066861888 run_lib.py:133] step: 412500, training_loss: 1.74109e-02
I0216 13:25:55.806679 23126066861888 run_lib.py:146] step: 412500, eval_loss: 2.67932e-02
I0216 13:26:13.503555 23126066861888 run_lib.py:133] step: 412550, training_loss: 1.65124e-02
I0216 13:26:31.038559 23126066861888 run_lib.py:133] step: 412600, training_loss: 1.76711e-02
I0216 13:26:31.217152 23126066861888 run_lib.py:146] step: 412600, eval_loss: 2.90422e-02
I0216 13:26:48.772111 23126066861888 run_lib.py:133] step: 412650, training_loss: 1.84160e-02
I0216 13:27:06.545337 23126066861888 run_lib.py:133] step: 412700, training_loss: 1.76667e-02
I0216 13:27:06.703389 23126066861888 run_lib.py:146] step: 412700, eval_loss: 2.95532e-02
I0216 13:27:24.261747 23126066861888 run_lib.py:133] step: 412750, training_loss: 1.79409e-02
I0216 13:27:41.911928 23126066861888 run_lib.py:133] step: 412800, training_loss: 1.77571e-02
I0216 13:27:42.068302 23126066861888 run_lib.py:146] step: 412800, eval_loss: 2.70812e-02
I0216 13:27:59.605329 23126066861888 run_lib.py:133] step: 412850, training_loss: 1.75750e-02
I0216 13:28:17.154733 23126066861888 run_lib.py:133] step: 412900, training_loss: 1.83573e-02
I0216 13:28:17.310483 23126066861888 run_lib.py:146] step: 412900, eval_loss: 2.77208e-02
I0216 13:28:35.112788 23126066861888 run_lib.py:133] step: 412950, training_loss: 1.82541e-02
I0216 13:28:52.602911 23126066861888 run_lib.py:133] step: 413000, training_loss: 1.77318e-02
I0216 13:28:52.760235 23126066861888 run_lib.py:146] step: 413000, eval_loss: 2.80645e-02
I0216 13:29:10.272173 23126066861888 run_lib.py:133] step: 413050, training_loss: 1.83584e-02
I0216 13:29:27.964213 23126066861888 run_lib.py:133] step: 413100, training_loss: 1.81581e-02
I0216 13:29:28.128424 23126066861888 run_lib.py:146] step: 413100, eval_loss: 2.79814e-02
I0216 13:29:45.696840 23126066861888 run_lib.py:133] step: 413150, training_loss: 1.69461e-02
I0216 13:30:03.268554 23126066861888 run_lib.py:133] step: 413200, training_loss: 1.73820e-02
I0216 13:30:03.427408 23126066861888 run_lib.py:146] step: 413200, eval_loss: 2.86743e-02
I0216 13:30:21.113169 23126066861888 run_lib.py:133] step: 413250, training_loss: 1.86311e-02
I0216 13:30:38.601039 23126066861888 run_lib.py:133] step: 413300, training_loss: 1.79418e-02
I0216 13:30:38.760657 23126066861888 run_lib.py:146] step: 413300, eval_loss: 2.75103e-02
I0216 13:30:56.286422 23126066861888 run_lib.py:133] step: 413350, training_loss: 1.77327e-02
I0216 13:31:13.839028 23126066861888 run_lib.py:133] step: 413400, training_loss: 1.82394e-02
I0216 13:31:14.001441 23126066861888 run_lib.py:146] step: 413400, eval_loss: 2.84197e-02
I0216 13:31:31.771218 23126066861888 run_lib.py:133] step: 413450, training_loss: 1.79023e-02
I0216 13:31:49.437618 23126066861888 run_lib.py:133] step: 413500, training_loss: 1.66603e-02
I0216 13:31:49.601199 23126066861888 run_lib.py:146] step: 413500, eval_loss: 2.79712e-02
I0216 13:32:07.127511 23126066861888 run_lib.py:133] step: 413550, training_loss: 1.82667e-02
I0216 13:32:24.631082 23126066861888 run_lib.py:133] step: 413600, training_loss: 1.70179e-02
I0216 13:32:24.789475 23126066861888 run_lib.py:146] step: 413600, eval_loss: 2.82734e-02
I0216 13:32:42.528868 23126066861888 run_lib.py:133] step: 413650, training_loss: 1.72611e-02
I0216 13:33:00.068352 23126066861888 run_lib.py:133] step: 413700, training_loss: 1.69851e-02
I0216 13:33:00.234434 23126066861888 run_lib.py:146] step: 413700, eval_loss: 2.86086e-02
I0216 13:33:17.791733 23126066861888 run_lib.py:133] step: 413750, training_loss: 1.84222e-02
I0216 13:33:35.521147 23126066861888 run_lib.py:133] step: 413800, training_loss: 1.69378e-02
I0216 13:33:35.674938 23126066861888 run_lib.py:146] step: 413800, eval_loss: 2.73048e-02
I0216 13:33:53.196792 23126066861888 run_lib.py:133] step: 413850, training_loss: 1.76531e-02
I0216 13:34:10.853699 23126066861888 run_lib.py:133] step: 413900, training_loss: 1.79771e-02
I0216 13:34:11.009223 23126066861888 run_lib.py:146] step: 413900, eval_loss: 2.75330e-02
I0216 13:34:28.507060 23126066861888 run_lib.py:133] step: 413950, training_loss: 1.83870e-02
I0216 13:34:46.085736 23126066861888 run_lib.py:133] step: 414000, training_loss: 1.79782e-02
I0216 13:34:46.271335 23126066861888 run_lib.py:146] step: 414000, eval_loss: 2.85153e-02
I0216 13:35:04.086828 23126066861888 run_lib.py:133] step: 414050, training_loss: 1.79920e-02
I0216 13:35:21.655132 23126066861888 run_lib.py:133] step: 414100, training_loss: 1.81195e-02
I0216 13:35:21.813483 23126066861888 run_lib.py:146] step: 414100, eval_loss: 2.76284e-02
I0216 13:35:39.339222 23126066861888 run_lib.py:133] step: 414150, training_loss: 1.76357e-02
I0216 13:35:56.995474 23126066861888 run_lib.py:133] step: 414200, training_loss: 1.82344e-02
I0216 13:35:57.159259 23126066861888 run_lib.py:146] step: 414200, eval_loss: 2.78551e-02
I0216 13:36:14.721467 23126066861888 run_lib.py:133] step: 414250, training_loss: 1.79015e-02
I0216 13:36:32.327629 23126066861888 run_lib.py:133] step: 414300, training_loss: 1.82502e-02
I0216 13:36:32.482454 23126066861888 run_lib.py:146] step: 414300, eval_loss: 2.76551e-02
I0216 13:36:50.200842 23126066861888 run_lib.py:133] step: 414350, training_loss: 1.74903e-02
I0216 13:37:07.749756 23126066861888 run_lib.py:133] step: 414400, training_loss: 1.77442e-02
I0216 13:37:07.915143 23126066861888 run_lib.py:146] step: 414400, eval_loss: 2.83337e-02
I0216 13:37:25.424297 23126066861888 run_lib.py:133] step: 414450, training_loss: 1.77552e-02
I0216 13:37:42.953418 23126066861888 run_lib.py:133] step: 414500, training_loss: 1.79786e-02
I0216 13:37:43.115256 23126066861888 run_lib.py:146] step: 414500, eval_loss: 2.89678e-02
I0216 13:38:00.857854 23126066861888 run_lib.py:133] step: 414550, training_loss: 1.80855e-02
I0216 13:38:18.559149 23126066861888 run_lib.py:133] step: 414600, training_loss: 1.75510e-02
I0216 13:38:18.722409 23126066861888 run_lib.py:146] step: 414600, eval_loss: 2.90839e-02
I0216 13:38:36.256591 23126066861888 run_lib.py:133] step: 414650, training_loss: 1.77803e-02
I0216 13:38:53.768824 23126066861888 run_lib.py:133] step: 414700, training_loss: 1.80543e-02
I0216 13:38:53.926195 23126066861888 run_lib.py:146] step: 414700, eval_loss: 2.77109e-02
I0216 13:39:11.611739 23126066861888 run_lib.py:133] step: 414750, training_loss: 1.76086e-02
I0216 13:39:29.133828 23126066861888 run_lib.py:133] step: 414800, training_loss: 1.68567e-02
I0216 13:39:29.288107 23126066861888 run_lib.py:146] step: 414800, eval_loss: 2.70616e-02
I0216 13:39:46.868111 23126066861888 run_lib.py:133] step: 414850, training_loss: 1.80362e-02
I0216 13:40:04.612323 23126066861888 run_lib.py:133] step: 414900, training_loss: 1.77515e-02
I0216 13:40:04.769022 23126066861888 run_lib.py:146] step: 414900, eval_loss: 2.75732e-02
I0216 13:40:22.280813 23126066861888 run_lib.py:133] step: 414950, training_loss: 1.77576e-02
I0216 13:40:40.011529 23126066861888 run_lib.py:133] step: 415000, training_loss: 1.71160e-02
I0216 13:40:40.180943 23126066861888 run_lib.py:146] step: 415000, eval_loss: 2.87007e-02
I0216 13:40:57.712960 23126066861888 run_lib.py:133] step: 415050, training_loss: 1.80913e-02
I0216 13:41:15.265245 23126066861888 run_lib.py:133] step: 415100, training_loss: 1.77436e-02
I0216 13:41:15.423371 23126066861888 run_lib.py:146] step: 415100, eval_loss: 2.84473e-02
I0216 13:41:33.202899 23126066861888 run_lib.py:133] step: 415150, training_loss: 1.70784e-02
I0216 13:41:50.735633 23126066861888 run_lib.py:133] step: 415200, training_loss: 1.75998e-02
I0216 13:41:50.894236 23126066861888 run_lib.py:146] step: 415200, eval_loss: 2.88405e-02
I0216 13:42:08.409868 23126066861888 run_lib.py:133] step: 415250, training_loss: 1.69326e-02
I0216 13:42:26.084982 23126066861888 run_lib.py:133] step: 415300, training_loss: 1.79230e-02
I0216 13:42:26.242326 23126066861888 run_lib.py:146] step: 415300, eval_loss: 2.74284e-02
I0216 13:42:43.775754 23126066861888 run_lib.py:133] step: 415350, training_loss: 1.79628e-02
I0216 13:43:01.364592 23126066861888 run_lib.py:133] step: 415400, training_loss: 1.76288e-02
I0216 13:43:01.523873 23126066861888 run_lib.py:146] step: 415400, eval_loss: 2.82202e-02
I0216 13:43:19.159012 23126066861888 run_lib.py:133] step: 415450, training_loss: 1.72964e-02
I0216 13:43:36.681859 23126066861888 run_lib.py:133] step: 415500, training_loss: 1.74357e-02
I0216 13:43:36.878515 23126066861888 run_lib.py:146] step: 415500, eval_loss: 2.75399e-02
I0216 13:43:54.404584 23126066861888 run_lib.py:133] step: 415550, training_loss: 1.68955e-02
I0216 13:44:11.911250 23126066861888 run_lib.py:133] step: 415600, training_loss: 1.76746e-02
I0216 13:44:12.068029 23126066861888 run_lib.py:146] step: 415600, eval_loss: 2.88195e-02
I0216 13:44:29.757648 23126066861888 run_lib.py:133] step: 415650, training_loss: 1.75809e-02
I0216 13:44:47.455492 23126066861888 run_lib.py:133] step: 415700, training_loss: 1.75709e-02
I0216 13:44:47.611443 23126066861888 run_lib.py:146] step: 415700, eval_loss: 2.81306e-02
I0216 13:45:05.182870 23126066861888 run_lib.py:133] step: 415750, training_loss: 1.77066e-02
I0216 13:45:22.710468 23126066861888 run_lib.py:133] step: 415800, training_loss: 1.82721e-02
I0216 13:45:22.867213 23126066861888 run_lib.py:146] step: 415800, eval_loss: 2.85575e-02
I0216 13:45:40.577957 23126066861888 run_lib.py:133] step: 415850, training_loss: 1.72412e-02
I0216 13:45:58.092367 23126066861888 run_lib.py:133] step: 415900, training_loss: 1.73136e-02
I0216 13:45:58.263246 23126066861888 run_lib.py:146] step: 415900, eval_loss: 2.86163e-02
I0216 13:46:15.834417 23126066861888 run_lib.py:133] step: 415950, training_loss: 1.74990e-02
I0216 13:46:33.592797 23126066861888 run_lib.py:133] step: 416000, training_loss: 1.76180e-02
I0216 13:46:33.750442 23126066861888 run_lib.py:146] step: 416000, eval_loss: 2.76996e-02
I0216 13:46:51.252072 23126066861888 run_lib.py:133] step: 416050, training_loss: 1.74285e-02
I0216 13:47:08.952400 23126066861888 run_lib.py:133] step: 416100, training_loss: 1.76075e-02
I0216 13:47:09.106133 23126066861888 run_lib.py:146] step: 416100, eval_loss: 2.80492e-02
I0216 13:47:26.611797 23126066861888 run_lib.py:133] step: 416150, training_loss: 1.72457e-02
I0216 13:47:44.181992 23126066861888 run_lib.py:133] step: 416200, training_loss: 1.82043e-02
I0216 13:47:44.335291 23126066861888 run_lib.py:146] step: 416200, eval_loss: 2.82079e-02
I0216 13:48:02.079363 23126066861888 run_lib.py:133] step: 416250, training_loss: 1.73261e-02
I0216 13:48:19.581419 23126066861888 run_lib.py:133] step: 416300, training_loss: 1.75043e-02
I0216 13:48:19.738186 23126066861888 run_lib.py:146] step: 416300, eval_loss: 2.79496e-02
I0216 13:48:37.236615 23126066861888 run_lib.py:133] step: 416350, training_loss: 1.75185e-02
I0216 13:48:54.993220 23126066861888 run_lib.py:133] step: 416400, training_loss: 1.85176e-02
I0216 13:48:55.163387 23126066861888 run_lib.py:146] step: 416400, eval_loss: 2.83369e-02
I0216 13:49:12.660108 23126066861888 run_lib.py:133] step: 416450, training_loss: 1.72123e-02
I0216 13:49:30.221727 23126066861888 run_lib.py:133] step: 416500, training_loss: 1.74264e-02
I0216 13:49:30.379195 23126066861888 run_lib.py:146] step: 416500, eval_loss: 2.77114e-02
I0216 13:49:48.009018 23126066861888 run_lib.py:133] step: 416550, training_loss: 1.80038e-02
I0216 13:50:05.581167 23126066861888 run_lib.py:133] step: 416600, training_loss: 1.77505e-02
I0216 13:50:05.737260 23126066861888 run_lib.py:146] step: 416600, eval_loss: 2.94863e-02
I0216 13:50:23.251963 23126066861888 run_lib.py:133] step: 416650, training_loss: 1.76150e-02
I0216 13:50:40.746520 23126066861888 run_lib.py:133] step: 416700, training_loss: 1.71884e-02
I0216 13:50:40.901149 23126066861888 run_lib.py:146] step: 416700, eval_loss: 2.88030e-02
I0216 13:50:58.669895 23126066861888 run_lib.py:133] step: 416750, training_loss: 1.78641e-02
I0216 13:51:16.282684 23126066861888 run_lib.py:133] step: 416800, training_loss: 1.70349e-02
I0216 13:51:16.451533 23126066861888 run_lib.py:146] step: 416800, eval_loss: 2.88673e-02
I0216 13:51:34.013808 23126066861888 run_lib.py:133] step: 416850, training_loss: 1.81316e-02
I0216 13:51:51.543140 23126066861888 run_lib.py:133] step: 416900, training_loss: 1.74198e-02
I0216 13:51:51.702211 23126066861888 run_lib.py:146] step: 416900, eval_loss: 2.71915e-02
I0216 13:52:09.449277 23126066861888 run_lib.py:133] step: 416950, training_loss: 1.83683e-02
I0216 13:52:26.961695 23126066861888 run_lib.py:133] step: 417000, training_loss: 1.72641e-02
I0216 13:52:27.120268 23126066861888 run_lib.py:146] step: 417000, eval_loss: 2.83633e-02
I0216 13:52:44.894923 23126066861888 run_lib.py:133] step: 417050, training_loss: 1.76198e-02
I0216 13:53:02.667351 23126066861888 run_lib.py:133] step: 417100, training_loss: 1.70673e-02
I0216 13:53:02.827411 23126066861888 run_lib.py:146] step: 417100, eval_loss: 2.83483e-02
I0216 13:53:20.439897 23126066861888 run_lib.py:133] step: 417150, training_loss: 1.87819e-02
I0216 13:53:38.133365 23126066861888 run_lib.py:133] step: 417200, training_loss: 1.79111e-02
I0216 13:53:38.294426 23126066861888 run_lib.py:146] step: 417200, eval_loss: 2.78521e-02
I0216 13:53:55.791795 23126066861888 run_lib.py:133] step: 417250, training_loss: 1.77245e-02
I0216 13:54:13.274601 23126066861888 run_lib.py:133] step: 417300, training_loss: 1.84053e-02
I0216 13:54:13.437137 23126066861888 run_lib.py:146] step: 417300, eval_loss: 2.77957e-02
I0216 13:54:31.183565 23126066861888 run_lib.py:133] step: 417350, training_loss: 1.77832e-02
I0216 13:54:48.756576 23126066861888 run_lib.py:133] step: 417400, training_loss: 1.70113e-02
I0216 13:54:48.916462 23126066861888 run_lib.py:146] step: 417400, eval_loss: 2.74751e-02
I0216 13:55:06.424145 23126066861888 run_lib.py:133] step: 417450, training_loss: 1.73208e-02
I0216 13:55:24.159251 23126066861888 run_lib.py:133] step: 417500, training_loss: 1.78203e-02
I0216 13:55:24.317146 23126066861888 run_lib.py:146] step: 417500, eval_loss: 2.78480e-02
I0216 13:55:41.872894 23126066861888 run_lib.py:133] step: 417550, training_loss: 1.75037e-02
I0216 13:55:59.386242 23126066861888 run_lib.py:133] step: 417600, training_loss: 1.76750e-02
I0216 13:55:59.545393 23126066861888 run_lib.py:146] step: 417600, eval_loss: 2.88414e-02
I0216 13:56:17.179539 23126066861888 run_lib.py:133] step: 417650, training_loss: 1.74809e-02
I0216 13:56:34.715339 23126066861888 run_lib.py:133] step: 417700, training_loss: 1.73418e-02
I0216 13:56:34.876401 23126066861888 run_lib.py:146] step: 417700, eval_loss: 2.86124e-02
I0216 13:56:52.452613 23126066861888 run_lib.py:133] step: 417750, training_loss: 1.76368e-02
I0216 13:57:09.997639 23126066861888 run_lib.py:133] step: 417800, training_loss: 1.69826e-02
I0216 13:57:10.157455 23126066861888 run_lib.py:146] step: 417800, eval_loss: 2.66560e-02
I0216 13:57:27.877704 23126066861888 run_lib.py:133] step: 417850, training_loss: 1.71929e-02
I0216 13:57:45.453821 23126066861888 run_lib.py:133] step: 417900, training_loss: 1.70441e-02
I0216 13:57:45.629329 23126066861888 run_lib.py:146] step: 417900, eval_loss: 2.77131e-02
I0216 13:58:03.208376 23126066861888 run_lib.py:133] step: 417950, training_loss: 1.77626e-02
I0216 13:58:20.776263 23126066861888 run_lib.py:133] step: 418000, training_loss: 1.78062e-02
I0216 13:58:20.934458 23126066861888 run_lib.py:146] step: 418000, eval_loss: 2.89072e-02
I0216 13:58:38.688636 23126066861888 run_lib.py:133] step: 418050, training_loss: 1.78962e-02
I0216 13:58:56.192827 23126066861888 run_lib.py:133] step: 418100, training_loss: 1.75689e-02
I0216 13:58:56.349475 23126066861888 run_lib.py:146] step: 418100, eval_loss: 2.81523e-02
I0216 13:59:13.834604 23126066861888 run_lib.py:133] step: 418150, training_loss: 1.83392e-02
I0216 13:59:31.570955 23126066861888 run_lib.py:133] step: 418200, training_loss: 1.72576e-02
I0216 13:59:31.739390 23126066861888 run_lib.py:146] step: 418200, eval_loss: 2.78739e-02
I0216 13:59:49.327728 23126066861888 run_lib.py:133] step: 418250, training_loss: 1.77424e-02
I0216 14:00:07.083644 23126066861888 run_lib.py:133] step: 418300, training_loss: 1.75299e-02
I0216 14:00:07.246543 23126066861888 run_lib.py:146] step: 418300, eval_loss: 2.73243e-02
I0216 14:00:24.737533 23126066861888 run_lib.py:133] step: 418350, training_loss: 1.70807e-02
I0216 14:00:42.230257 23126066861888 run_lib.py:133] step: 418400, training_loss: 1.77241e-02
I0216 14:00:42.387156 23126066861888 run_lib.py:146] step: 418400, eval_loss: 2.77171e-02
I0216 14:01:00.061862 23126066861888 run_lib.py:133] step: 418450, training_loss: 1.73917e-02
I0216 14:01:17.636829 23126066861888 run_lib.py:133] step: 418500, training_loss: 1.73254e-02
I0216 14:01:17.799922 23126066861888 run_lib.py:146] step: 418500, eval_loss: 2.75014e-02
I0216 14:01:35.412114 23126066861888 run_lib.py:133] step: 418550, training_loss: 1.74925e-02
I0216 14:01:53.122097 23126066861888 run_lib.py:133] step: 418600, training_loss: 1.73083e-02
I0216 14:01:53.273164 23126066861888 run_lib.py:146] step: 418600, eval_loss: 2.72329e-02
I0216 14:02:10.784616 23126066861888 run_lib.py:133] step: 418650, training_loss: 1.81243e-02
I0216 14:02:28.307202 23126066861888 run_lib.py:133] step: 418700, training_loss: 1.74333e-02
I0216 14:02:28.464128 23126066861888 run_lib.py:146] step: 418700, eval_loss: 2.72019e-02
I0216 14:02:46.072918 23126066861888 run_lib.py:133] step: 418750, training_loss: 1.75509e-02
I0216 14:03:03.652139 23126066861888 run_lib.py:133] step: 418800, training_loss: 1.81988e-02
I0216 14:03:03.825523 23126066861888 run_lib.py:146] step: 418800, eval_loss: 2.80354e-02
I0216 14:03:21.356674 23126066861888 run_lib.py:133] step: 418850, training_loss: 1.73963e-02
I0216 14:03:38.887594 23126066861888 run_lib.py:133] step: 418900, training_loss: 1.81223e-02
I0216 14:03:39.045337 23126066861888 run_lib.py:146] step: 418900, eval_loss: 2.86773e-02
I0216 14:03:56.810677 23126066861888 run_lib.py:133] step: 418950, training_loss: 1.68323e-02
I0216 14:04:14.397565 23126066861888 run_lib.py:133] step: 419000, training_loss: 1.74865e-02
I0216 14:04:14.553485 23126066861888 run_lib.py:146] step: 419000, eval_loss: 2.87746e-02
I0216 14:04:32.067276 23126066861888 run_lib.py:133] step: 419050, training_loss: 1.73457e-02
I0216 14:04:49.636472 23126066861888 run_lib.py:133] step: 419100, training_loss: 1.78134e-02
I0216 14:04:49.796431 23126066861888 run_lib.py:146] step: 419100, eval_loss: 2.89043e-02
I0216 14:05:07.546855 23126066861888 run_lib.py:133] step: 419150, training_loss: 1.75466e-02
I0216 14:05:25.086241 23126066861888 run_lib.py:133] step: 419200, training_loss: 1.79900e-02
I0216 14:05:25.246449 23126066861888 run_lib.py:146] step: 419200, eval_loss: 2.78113e-02
I0216 14:05:42.707714 23126066861888 run_lib.py:133] step: 419250, training_loss: 1.73287e-02
I0216 14:06:00.391332 23126066861888 run_lib.py:133] step: 419300, training_loss: 1.77303e-02
I0216 14:06:00.573145 23126066861888 run_lib.py:146] step: 419300, eval_loss: 2.88797e-02
I0216 14:06:18.115994 23126066861888 run_lib.py:133] step: 419350, training_loss: 1.69487e-02
I0216 14:06:35.871842 23126066861888 run_lib.py:133] step: 419400, training_loss: 1.76075e-02
I0216 14:06:36.026937 23126066861888 run_lib.py:146] step: 419400, eval_loss: 2.78458e-02
I0216 14:06:53.541471 23126066861888 run_lib.py:133] step: 419450, training_loss: 1.78094e-02
I0216 14:07:11.049266 23126066861888 run_lib.py:133] step: 419500, training_loss: 1.81145e-02
I0216 14:07:11.206190 23126066861888 run_lib.py:146] step: 419500, eval_loss: 2.90692e-02
I0216 14:07:28.916186 23126066861888 run_lib.py:133] step: 419550, training_loss: 1.83603e-02
I0216 14:07:46.432429 23126066861888 run_lib.py:133] step: 419600, training_loss: 1.83236e-02
I0216 14:07:46.601332 23126066861888 run_lib.py:146] step: 419600, eval_loss: 2.85675e-02
I0216 14:08:04.197455 23126066861888 run_lib.py:133] step: 419650, training_loss: 1.68068e-02
I0216 14:08:21.942181 23126066861888 run_lib.py:133] step: 419700, training_loss: 1.84508e-02
I0216 14:08:22.101188 23126066861888 run_lib.py:146] step: 419700, eval_loss: 2.90546e-02
I0216 14:08:39.565199 23126066861888 run_lib.py:133] step: 419750, training_loss: 1.71224e-02
I0216 14:08:57.054146 23126066861888 run_lib.py:133] step: 419800, training_loss: 1.74995e-02
I0216 14:08:57.214427 23126066861888 run_lib.py:146] step: 419800, eval_loss: 2.87891e-02
I0216 14:09:14.803552 23126066861888 run_lib.py:133] step: 419850, training_loss: 1.79222e-02
I0216 14:09:32.341713 23126066861888 run_lib.py:133] step: 419900, training_loss: 1.71966e-02
I0216 14:09:32.520298 23126066861888 run_lib.py:146] step: 419900, eval_loss: 2.86387e-02
I0216 14:09:50.050385 23126066861888 run_lib.py:133] step: 419950, training_loss: 1.74557e-02
I0216 14:10:07.563813 23126066861888 run_lib.py:133] step: 420000, training_loss: 1.80676e-02
I0216 14:10:10.556955 23126066861888 run_lib.py:146] step: 420000, eval_loss: 2.85650e-02
I0216 14:10:34.154053 23126066861888 run_lib.py:133] step: 420050, training_loss: 1.78620e-02
I0216 14:10:51.637010 23126066861888 run_lib.py:133] step: 420100, training_loss: 1.69706e-02
I0216 14:10:51.794394 23126066861888 run_lib.py:146] step: 420100, eval_loss: 2.90279e-02
I0216 14:11:09.369515 23126066861888 run_lib.py:133] step: 420150, training_loss: 1.79255e-02
I0216 14:11:26.906539 23126066861888 run_lib.py:133] step: 420200, training_loss: 1.79463e-02
I0216 14:11:27.068146 23126066861888 run_lib.py:146] step: 420200, eval_loss: 2.80693e-02
I0216 14:11:44.632312 23126066861888 run_lib.py:133] step: 420250, training_loss: 1.75629e-02
I0216 14:12:02.154827 23126066861888 run_lib.py:133] step: 420300, training_loss: 1.72122e-02
I0216 14:12:02.313404 23126066861888 run_lib.py:146] step: 420300, eval_loss: 2.76650e-02
I0216 14:12:19.985541 23126066861888 run_lib.py:133] step: 420350, training_loss: 1.78856e-02
I0216 14:12:37.569248 23126066861888 run_lib.py:133] step: 420400, training_loss: 1.73087e-02
I0216 14:12:37.731979 23126066861888 run_lib.py:146] step: 420400, eval_loss: 2.75602e-02
I0216 14:12:55.321308 23126066861888 run_lib.py:133] step: 420450, training_loss: 1.78034e-02
I0216 14:13:12.884962 23126066861888 run_lib.py:133] step: 420500, training_loss: 1.75133e-02
I0216 14:13:13.042145 23126066861888 run_lib.py:146] step: 420500, eval_loss: 2.78972e-02
I0216 14:13:30.804618 23126066861888 run_lib.py:133] step: 420550, training_loss: 1.79226e-02
I0216 14:13:48.303193 23126066861888 run_lib.py:133] step: 420600, training_loss: 1.79631e-02
I0216 14:13:48.458137 23126066861888 run_lib.py:146] step: 420600, eval_loss: 2.84737e-02
I0216 14:14:05.953850 23126066861888 run_lib.py:133] step: 420650, training_loss: 1.76171e-02
I0216 14:14:23.657883 23126066861888 run_lib.py:133] step: 420700, training_loss: 1.72776e-02
I0216 14:14:23.833287 23126066861888 run_lib.py:146] step: 420700, eval_loss: 2.81091e-02
I0216 14:14:41.401203 23126066861888 run_lib.py:133] step: 420750, training_loss: 1.68126e-02
I0216 14:14:59.128787 23126066861888 run_lib.py:133] step: 420800, training_loss: 1.72280e-02
I0216 14:14:59.287465 23126066861888 run_lib.py:146] step: 420800, eval_loss: 2.73536e-02
I0216 14:15:16.804295 23126066861888 run_lib.py:133] step: 420850, training_loss: 1.83167e-02
I0216 14:15:34.334449 23126066861888 run_lib.py:133] step: 420900, training_loss: 1.77543e-02
I0216 14:15:34.538990 23126066861888 run_lib.py:146] step: 420900, eval_loss: 2.74537e-02
I0216 14:15:52.223197 23126066861888 run_lib.py:133] step: 420950, training_loss: 1.75988e-02
I0216 14:16:09.780872 23126066861888 run_lib.py:133] step: 421000, training_loss: 1.83289e-02
I0216 14:16:09.936716 23126066861888 run_lib.py:146] step: 421000, eval_loss: 2.77949e-02
I0216 14:16:27.489818 23126066861888 run_lib.py:133] step: 421050, training_loss: 1.78593e-02
I0216 14:16:45.226277 23126066861888 run_lib.py:133] step: 421100, training_loss: 1.83898e-02
I0216 14:16:45.384173 23126066861888 run_lib.py:146] step: 421100, eval_loss: 2.89759e-02
I0216 14:17:02.862356 23126066861888 run_lib.py:133] step: 421150, training_loss: 1.74016e-02
I0216 14:17:20.363909 23126066861888 run_lib.py:133] step: 421200, training_loss: 1.71437e-02
I0216 14:17:20.526960 23126066861888 run_lib.py:146] step: 421200, eval_loss: 2.80328e-02
I0216 14:17:38.151965 23126066861888 run_lib.py:133] step: 421250, training_loss: 1.76262e-02
I0216 14:17:55.706156 23126066861888 run_lib.py:133] step: 421300, training_loss: 1.68315e-02
I0216 14:17:55.869439 23126066861888 run_lib.py:146] step: 421300, eval_loss: 2.79927e-02
I0216 14:18:13.376364 23126066861888 run_lib.py:133] step: 421350, training_loss: 1.68753e-02
I0216 14:18:30.904695 23126066861888 run_lib.py:133] step: 421400, training_loss: 1.78277e-02
I0216 14:18:31.067910 23126066861888 run_lib.py:146] step: 421400, eval_loss: 2.83835e-02
I0216 14:18:48.803380 23126066861888 run_lib.py:133] step: 421450, training_loss: 1.77165e-02
I0216 14:19:06.393703 23126066861888 run_lib.py:133] step: 421500, training_loss: 1.76544e-02
I0216 14:19:06.553384 23126066861888 run_lib.py:146] step: 421500, eval_loss: 2.84724e-02
I0216 14:19:24.124834 23126066861888 run_lib.py:133] step: 421550, training_loss: 1.70357e-02
I0216 14:19:41.638492 23126066861888 run_lib.py:133] step: 421600, training_loss: 1.75902e-02
I0216 14:19:41.797309 23126066861888 run_lib.py:146] step: 421600, eval_loss: 2.95411e-02
I0216 14:19:59.535604 23126066861888 run_lib.py:133] step: 421650, training_loss: 1.69840e-02
I0216 14:20:17.031998 23126066861888 run_lib.py:133] step: 421700, training_loss: 1.76210e-02
I0216 14:20:17.201776 23126066861888 run_lib.py:146] step: 421700, eval_loss: 2.79312e-02
I0216 14:20:34.705646 23126066861888 run_lib.py:133] step: 421750, training_loss: 1.77580e-02
I0216 14:20:52.396090 23126066861888 run_lib.py:133] step: 421800, training_loss: 1.77443e-02
I0216 14:20:52.560257 23126066861888 run_lib.py:146] step: 421800, eval_loss: 2.84281e-02
I0216 14:21:10.135553 23126066861888 run_lib.py:133] step: 421850, training_loss: 1.74875e-02
I0216 14:21:27.880378 23126066861888 run_lib.py:133] step: 421900, training_loss: 1.77990e-02
I0216 14:21:28.039463 23126066861888 run_lib.py:146] step: 421900, eval_loss: 2.77249e-02
I0216 14:21:45.580914 23126066861888 run_lib.py:133] step: 421950, training_loss: 1.77063e-02
I0216 14:22:03.101620 23126066861888 run_lib.py:133] step: 422000, training_loss: 1.72549e-02
I0216 14:22:03.256178 23126066861888 run_lib.py:146] step: 422000, eval_loss: 2.84460e-02
I0216 14:22:20.970000 23126066861888 run_lib.py:133] step: 422050, training_loss: 1.79300e-02
I0216 14:22:38.500927 23126066861888 run_lib.py:133] step: 422100, training_loss: 1.75050e-02
I0216 14:22:38.664502 23126066861888 run_lib.py:146] step: 422100, eval_loss: 2.85592e-02
I0216 14:22:56.234929 23126066861888 run_lib.py:133] step: 422150, training_loss: 1.81258e-02
I0216 14:23:14.014782 23126066861888 run_lib.py:133] step: 422200, training_loss: 1.81392e-02
I0216 14:23:14.178194 23126066861888 run_lib.py:146] step: 422200, eval_loss: 2.92466e-02
I0216 14:23:31.721327 23126066861888 run_lib.py:133] step: 422250, training_loss: 1.80992e-02
I0216 14:23:49.235686 23126066861888 run_lib.py:133] step: 422300, training_loss: 1.77510e-02
I0216 14:23:49.394351 23126066861888 run_lib.py:146] step: 422300, eval_loss: 2.88161e-02
I0216 14:24:06.996289 23126066861888 run_lib.py:133] step: 422350, training_loss: 1.80243e-02
I0216 14:24:24.507240 23126066861888 run_lib.py:133] step: 422400, training_loss: 1.74984e-02
I0216 14:24:24.664877 23126066861888 run_lib.py:146] step: 422400, eval_loss: 2.79686e-02
I0216 14:24:42.220870 23126066861888 run_lib.py:133] step: 422450, training_loss: 1.74558e-02
I0216 14:24:59.734989 23126066861888 run_lib.py:133] step: 422500, training_loss: 1.75893e-02
I0216 14:24:59.925542 23126066861888 run_lib.py:146] step: 422500, eval_loss: 2.84244e-02
I0216 14:25:17.651861 23126066861888 run_lib.py:133] step: 422550, training_loss: 1.74908e-02
I0216 14:25:35.260606 23126066861888 run_lib.py:133] step: 422600, training_loss: 1.75317e-02
I0216 14:25:35.429192 23126066861888 run_lib.py:146] step: 422600, eval_loss: 2.74074e-02
I0216 14:25:52.918275 23126066861888 run_lib.py:133] step: 422650, training_loss: 1.79092e-02
I0216 14:26:10.441955 23126066861888 run_lib.py:133] step: 422700, training_loss: 1.79280e-02
I0216 14:26:10.605807 23126066861888 run_lib.py:146] step: 422700, eval_loss: 2.81489e-02
I0216 14:26:28.324759 23126066861888 run_lib.py:133] step: 422750, training_loss: 1.82710e-02
I0216 14:26:45.848044 23126066861888 run_lib.py:133] step: 422800, training_loss: 1.76335e-02
I0216 14:26:46.005498 23126066861888 run_lib.py:146] step: 422800, eval_loss: 2.81759e-02
I0216 14:27:03.569038 23126066861888 run_lib.py:133] step: 422850, training_loss: 1.76788e-02
I0216 14:27:21.273169 23126066861888 run_lib.py:133] step: 422900, training_loss: 1.78440e-02
I0216 14:27:21.426984 23126066861888 run_lib.py:146] step: 422900, eval_loss: 2.94613e-02
I0216 14:27:38.938556 23126066861888 run_lib.py:133] step: 422950, training_loss: 1.78260e-02
I0216 14:27:56.647665 23126066861888 run_lib.py:133] step: 423000, training_loss: 1.76835e-02
I0216 14:27:56.813475 23126066861888 run_lib.py:146] step: 423000, eval_loss: 2.84261e-02
I0216 14:28:14.366550 23126066861888 run_lib.py:133] step: 423050, training_loss: 1.78132e-02
I0216 14:28:31.889415 23126066861888 run_lib.py:133] step: 423100, training_loss: 1.70599e-02
I0216 14:28:32.049329 23126066861888 run_lib.py:146] step: 423100, eval_loss: 2.76508e-02
I0216 14:28:49.765429 23126066861888 run_lib.py:133] step: 423150, training_loss: 1.73018e-02
I0216 14:29:07.262826 23126066861888 run_lib.py:133] step: 423200, training_loss: 1.76783e-02
I0216 14:29:07.421702 23126066861888 run_lib.py:146] step: 423200, eval_loss: 2.77566e-02
I0216 14:29:24.943525 23126066861888 run_lib.py:133] step: 423250, training_loss: 1.71672e-02
I0216 14:29:42.687467 23126066861888 run_lib.py:133] step: 423300, training_loss: 1.74984e-02
I0216 14:29:42.844511 23126066861888 run_lib.py:146] step: 423300, eval_loss: 2.82062e-02
I0216 14:30:00.391458 23126066861888 run_lib.py:133] step: 423350, training_loss: 1.82018e-02
I0216 14:30:17.911706 23126066861888 run_lib.py:133] step: 423400, training_loss: 1.78738e-02
I0216 14:30:18.066309 23126066861888 run_lib.py:146] step: 423400, eval_loss: 2.90988e-02
I0216 14:30:35.677944 23126066861888 run_lib.py:133] step: 423450, training_loss: 1.78787e-02
I0216 14:30:53.224551 23126066861888 run_lib.py:133] step: 423500, training_loss: 1.66548e-02
I0216 14:30:53.386217 23126066861888 run_lib.py:146] step: 423500, eval_loss: 2.92674e-02
I0216 14:31:10.938352 23126066861888 run_lib.py:133] step: 423550, training_loss: 1.79345e-02
I0216 14:31:28.522139 23126066861888 run_lib.py:133] step: 423600, training_loss: 1.73538e-02
I0216 14:31:28.689124 23126066861888 run_lib.py:146] step: 423600, eval_loss: 2.74725e-02
I0216 14:31:46.393918 23126066861888 run_lib.py:133] step: 423650, training_loss: 1.80983e-02
I0216 14:32:03.990217 23126066861888 run_lib.py:133] step: 423700, training_loss: 1.80564e-02
I0216 14:32:04.155205 23126066861888 run_lib.py:146] step: 423700, eval_loss: 2.84742e-02
I0216 14:32:21.706353 23126066861888 run_lib.py:133] step: 423750, training_loss: 1.78518e-02
I0216 14:32:39.193078 23126066861888 run_lib.py:133] step: 423800, training_loss: 1.79638e-02
I0216 14:32:39.360743 23126066861888 run_lib.py:146] step: 423800, eval_loss: 2.84412e-02
I0216 14:32:57.061602 23126066861888 run_lib.py:133] step: 423850, training_loss: 1.71265e-02
I0216 14:33:14.583726 23126066861888 run_lib.py:133] step: 423900, training_loss: 1.81397e-02
I0216 14:33:14.740444 23126066861888 run_lib.py:146] step: 423900, eval_loss: 2.90102e-02
I0216 14:33:32.257230 23126066861888 run_lib.py:133] step: 423950, training_loss: 1.75802e-02
I0216 14:33:50.016398 23126066861888 run_lib.py:133] step: 424000, training_loss: 1.79101e-02
I0216 14:33:50.176389 23126066861888 run_lib.py:146] step: 424000, eval_loss: 2.66642e-02
I0216 14:34:07.647632 23126066861888 run_lib.py:133] step: 424050, training_loss: 1.82037e-02
I0216 14:34:25.379287 23126066861888 run_lib.py:133] step: 424100, training_loss: 1.80224e-02
I0216 14:34:25.565200 23126066861888 run_lib.py:146] step: 424100, eval_loss: 2.86329e-02
I0216 14:34:43.063080 23126066861888 run_lib.py:133] step: 424150, training_loss: 1.72497e-02
I0216 14:35:00.608665 23126066861888 run_lib.py:133] step: 424200, training_loss: 1.65104e-02
I0216 14:35:00.765961 23126066861888 run_lib.py:146] step: 424200, eval_loss: 2.77009e-02
I0216 14:35:18.527340 23126066861888 run_lib.py:133] step: 424250, training_loss: 1.70681e-02
I0216 14:35:36.017972 23126066861888 run_lib.py:133] step: 424300, training_loss: 1.75622e-02
I0216 14:35:36.173183 23126066861888 run_lib.py:146] step: 424300, eval_loss: 2.72897e-02
I0216 14:35:53.736008 23126066861888 run_lib.py:133] step: 424350, training_loss: 1.78250e-02
I0216 14:36:11.512535 23126066861888 run_lib.py:133] step: 424400, training_loss: 1.82314e-02
I0216 14:36:11.676457 23126066861888 run_lib.py:146] step: 424400, eval_loss: 2.79452e-02
I0216 14:36:29.208696 23126066861888 run_lib.py:133] step: 424450, training_loss: 1.76399e-02
I0216 14:36:46.764558 23126066861888 run_lib.py:133] step: 424500, training_loss: 1.80299e-02
I0216 14:36:46.929468 23126066861888 run_lib.py:146] step: 424500, eval_loss: 2.64481e-02
I0216 14:37:04.534001 23126066861888 run_lib.py:133] step: 424550, training_loss: 1.76532e-02
I0216 14:37:22.038012 23126066861888 run_lib.py:133] step: 424600, training_loss: 1.74936e-02
I0216 14:37:22.198156 23126066861888 run_lib.py:146] step: 424600, eval_loss: 2.82733e-02
I0216 14:37:39.728884 23126066861888 run_lib.py:133] step: 424650, training_loss: 1.72707e-02
I0216 14:37:57.318766 23126066861888 run_lib.py:133] step: 424700, training_loss: 1.72880e-02
I0216 14:37:57.478346 23126066861888 run_lib.py:146] step: 424700, eval_loss: 2.68593e-02
I0216 14:38:15.201476 23126066861888 run_lib.py:133] step: 424750, training_loss: 1.76869e-02
I0216 14:38:32.817240 23126066861888 run_lib.py:133] step: 424800, training_loss: 1.76263e-02
I0216 14:38:32.970383 23126066861888 run_lib.py:146] step: 424800, eval_loss: 2.73228e-02
I0216 14:38:50.502182 23126066861888 run_lib.py:133] step: 424850, training_loss: 1.77155e-02
I0216 14:39:08.026767 23126066861888 run_lib.py:133] step: 424900, training_loss: 1.77470e-02
I0216 14:39:08.185007 23126066861888 run_lib.py:146] step: 424900, eval_loss: 2.82477e-02
I0216 14:39:25.956607 23126066861888 run_lib.py:133] step: 424950, training_loss: 1.75933e-02
I0216 14:39:43.558017 23126066861888 run_lib.py:133] step: 425000, training_loss: 1.77136e-02
I0216 14:39:43.720544 23126066861888 run_lib.py:146] step: 425000, eval_loss: 2.90440e-02
I0216 14:40:01.199132 23126066861888 run_lib.py:133] step: 425050, training_loss: 1.80083e-02
I0216 14:40:18.904890 23126066861888 run_lib.py:133] step: 425100, training_loss: 1.81399e-02
I0216 14:40:19.063395 23126066861888 run_lib.py:146] step: 425100, eval_loss: 2.78767e-02
I0216 14:40:36.579587 23126066861888 run_lib.py:133] step: 425150, training_loss: 1.79513e-02
I0216 14:40:54.332924 23126066861888 run_lib.py:133] step: 425200, training_loss: 1.73090e-02
I0216 14:40:54.493563 23126066861888 run_lib.py:146] step: 425200, eval_loss: 2.84863e-02
I0216 14:41:12.058409 23126066861888 run_lib.py:133] step: 425250, training_loss: 1.73856e-02
I0216 14:41:29.551001 23126066861888 run_lib.py:133] step: 425300, training_loss: 1.82828e-02
I0216 14:41:29.704157 23126066861888 run_lib.py:146] step: 425300, eval_loss: 2.80369e-02
I0216 14:41:47.435624 23126066861888 run_lib.py:133] step: 425350, training_loss: 1.71616e-02
I0216 14:42:04.940882 23126066861888 run_lib.py:133] step: 425400, training_loss: 1.78218e-02
I0216 14:42:05.103231 23126066861888 run_lib.py:146] step: 425400, eval_loss: 2.94626e-02
I0216 14:42:22.596535 23126066861888 run_lib.py:133] step: 425450, training_loss: 1.75373e-02
I0216 14:42:40.361033 23126066861888 run_lib.py:133] step: 425500, training_loss: 1.71687e-02
I0216 14:42:40.523333 23126066861888 run_lib.py:146] step: 425500, eval_loss: 2.71885e-02
I0216 14:42:58.091934 23126066861888 run_lib.py:133] step: 425550, training_loss: 1.76256e-02
I0216 14:43:15.589676 23126066861888 run_lib.py:133] step: 425600, training_loss: 1.69223e-02
I0216 14:43:15.746187 23126066861888 run_lib.py:146] step: 425600, eval_loss: 2.79329e-02
I0216 14:43:33.421049 23126066861888 run_lib.py:133] step: 425650, training_loss: 1.82328e-02
I0216 14:43:50.941941 23126066861888 run_lib.py:133] step: 425700, training_loss: 1.79409e-02
I0216 14:43:51.115453 23126066861888 run_lib.py:146] step: 425700, eval_loss: 2.82872e-02
I0216 14:44:08.724227 23126066861888 run_lib.py:133] step: 425750, training_loss: 1.74153e-02
I0216 14:44:26.205315 23126066861888 run_lib.py:133] step: 425800, training_loss: 1.74677e-02
I0216 14:44:26.381099 23126066861888 run_lib.py:146] step: 425800, eval_loss: 2.78974e-02
I0216 14:44:44.114526 23126066861888 run_lib.py:133] step: 425850, training_loss: 1.81725e-02
I0216 14:45:01.734961 23126066861888 run_lib.py:133] step: 425900, training_loss: 1.77687e-02
I0216 14:45:01.896730 23126066861888 run_lib.py:146] step: 425900, eval_loss: 2.74057e-02
I0216 14:45:19.375813 23126066861888 run_lib.py:133] step: 425950, training_loss: 1.71392e-02
I0216 14:45:36.884435 23126066861888 run_lib.py:133] step: 426000, training_loss: 1.74634e-02
I0216 14:45:37.058335 23126066861888 run_lib.py:146] step: 426000, eval_loss: 2.83487e-02
I0216 14:45:54.831733 23126066861888 run_lib.py:133] step: 426050, training_loss: 1.74725e-02
I0216 14:46:12.369946 23126066861888 run_lib.py:133] step: 426100, training_loss: 1.75719e-02
I0216 14:46:12.535473 23126066861888 run_lib.py:146] step: 426100, eval_loss: 2.79997e-02
I0216 14:46:30.063002 23126066861888 run_lib.py:133] step: 426150, training_loss: 1.74766e-02
I0216 14:46:47.740128 23126066861888 run_lib.py:133] step: 426200, training_loss: 1.77346e-02
I0216 14:46:47.898316 23126066861888 run_lib.py:146] step: 426200, eval_loss: 2.81559e-02
I0216 14:47:05.397372 23126066861888 run_lib.py:133] step: 426250, training_loss: 1.70931e-02
I0216 14:47:23.100930 23126066861888 run_lib.py:133] step: 426300, training_loss: 1.79590e-02
I0216 14:47:23.263358 23126066861888 run_lib.py:146] step: 426300, eval_loss: 2.90639e-02
I0216 14:47:40.863208 23126066861888 run_lib.py:133] step: 426350, training_loss: 1.74616e-02
I0216 14:47:58.386384 23126066861888 run_lib.py:133] step: 426400, training_loss: 1.73217e-02
I0216 14:47:58.546444 23126066861888 run_lib.py:146] step: 426400, eval_loss: 2.79751e-02
I0216 14:48:16.259089 23126066861888 run_lib.py:133] step: 426450, training_loss: 1.75574e-02
I0216 14:48:33.764169 23126066861888 run_lib.py:133] step: 426500, training_loss: 1.76691e-02
I0216 14:48:33.936193 23126066861888 run_lib.py:146] step: 426500, eval_loss: 2.92895e-02
I0216 14:48:51.541090 23126066861888 run_lib.py:133] step: 426550, training_loss: 1.74910e-02
I0216 14:49:09.266582 23126066861888 run_lib.py:133] step: 426600, training_loss: 1.78060e-02
I0216 14:49:09.429371 23126066861888 run_lib.py:146] step: 426600, eval_loss: 2.96495e-02
I0216 14:49:27.005921 23126066861888 run_lib.py:133] step: 426650, training_loss: 1.70324e-02
I0216 14:49:44.518299 23126066861888 run_lib.py:133] step: 426700, training_loss: 1.77559e-02
I0216 14:49:44.671155 23126066861888 run_lib.py:146] step: 426700, eval_loss: 2.86297e-02
I0216 14:50:02.253930 23126066861888 run_lib.py:133] step: 426750, training_loss: 1.76349e-02
I0216 14:50:19.780164 23126066861888 run_lib.py:133] step: 426800, training_loss: 1.74947e-02
I0216 14:50:19.958415 23126066861888 run_lib.py:146] step: 426800, eval_loss: 2.88514e-02
I0216 14:50:37.559801 23126066861888 run_lib.py:133] step: 426850, training_loss: 1.82562e-02
I0216 14:50:55.111667 23126066861888 run_lib.py:133] step: 426900, training_loss: 1.78237e-02
I0216 14:50:55.280200 23126066861888 run_lib.py:146] step: 426900, eval_loss: 2.86626e-02
I0216 14:51:13.007487 23126066861888 run_lib.py:133] step: 426950, training_loss: 1.76465e-02
I0216 14:51:30.579058 23126066861888 run_lib.py:133] step: 427000, training_loss: 1.77060e-02
I0216 14:51:30.741463 23126066861888 run_lib.py:146] step: 427000, eval_loss: 2.86302e-02
I0216 14:51:48.231943 23126066861888 run_lib.py:133] step: 427050, training_loss: 1.75005e-02
I0216 14:52:05.775901 23126066861888 run_lib.py:133] step: 427100, training_loss: 1.78136e-02
I0216 14:52:05.930522 23126066861888 run_lib.py:146] step: 427100, eval_loss: 2.81833e-02
I0216 14:52:23.754295 23126066861888 run_lib.py:133] step: 427150, training_loss: 1.77317e-02
I0216 14:52:41.235639 23126066861888 run_lib.py:133] step: 427200, training_loss: 1.76523e-02
I0216 14:52:41.391609 23126066861888 run_lib.py:146] step: 427200, eval_loss: 2.74537e-02
I0216 14:52:58.873871 23126066861888 run_lib.py:133] step: 427250, training_loss: 1.74752e-02
I0216 14:53:16.623430 23126066861888 run_lib.py:133] step: 427300, training_loss: 1.74710e-02
I0216 14:53:16.781192 23126066861888 run_lib.py:146] step: 427300, eval_loss: 2.74226e-02
I0216 14:53:34.345203 23126066861888 run_lib.py:133] step: 427350, training_loss: 1.83530e-02
I0216 14:53:52.121257 23126066861888 run_lib.py:133] step: 427400, training_loss: 1.72687e-02
I0216 14:53:52.282139 23126066861888 run_lib.py:146] step: 427400, eval_loss: 2.81524e-02
I0216 14:54:09.805039 23126066861888 run_lib.py:133] step: 427450, training_loss: 1.70651e-02
I0216 14:54:27.311532 23126066861888 run_lib.py:133] step: 427500, training_loss: 1.74701e-02
I0216 14:54:27.467128 23126066861888 run_lib.py:146] step: 427500, eval_loss: 2.81692e-02
I0216 14:54:45.157727 23126066861888 run_lib.py:133] step: 427550, training_loss: 1.77360e-02
I0216 14:55:02.658901 23126066861888 run_lib.py:133] step: 427600, training_loss: 1.80987e-02
I0216 14:55:02.823187 23126066861888 run_lib.py:146] step: 427600, eval_loss: 2.90002e-02
I0216 14:55:20.333259 23126066861888 run_lib.py:133] step: 427650, training_loss: 1.80338e-02
I0216 14:55:38.104530 23126066861888 run_lib.py:133] step: 427700, training_loss: 1.68610e-02
I0216 14:55:38.263582 23126066861888 run_lib.py:146] step: 427700, eval_loss: 2.81841e-02
I0216 14:55:55.814782 23126066861888 run_lib.py:133] step: 427750, training_loss: 1.81427e-02
I0216 14:56:13.356303 23126066861888 run_lib.py:133] step: 427800, training_loss: 1.76571e-02
I0216 14:56:13.518500 23126066861888 run_lib.py:146] step: 427800, eval_loss: 2.87422e-02
I0216 14:56:31.096683 23126066861888 run_lib.py:133] step: 427850, training_loss: 1.78046e-02
I0216 14:56:48.617487 23126066861888 run_lib.py:133] step: 427900, training_loss: 1.73532e-02
I0216 14:56:48.788565 23126066861888 run_lib.py:146] step: 427900, eval_loss: 2.86520e-02
I0216 14:57:06.292065 23126066861888 run_lib.py:133] step: 427950, training_loss: 1.81419e-02
I0216 14:57:23.809119 23126066861888 run_lib.py:133] step: 428000, training_loss: 1.69131e-02
I0216 14:57:23.967610 23126066861888 run_lib.py:146] step: 428000, eval_loss: 2.86488e-02
I0216 14:57:41.758866 23126066861888 run_lib.py:133] step: 428050, training_loss: 1.77070e-02
I0216 14:57:59.340929 23126066861888 run_lib.py:133] step: 428100, training_loss: 1.78733e-02
I0216 14:57:59.497290 23126066861888 run_lib.py:146] step: 428100, eval_loss: 2.84752e-02
I0216 14:58:16.969541 23126066861888 run_lib.py:133] step: 428150, training_loss: 1.70912e-02
I0216 14:58:34.483322 23126066861888 run_lib.py:133] step: 428200, training_loss: 1.80631e-02
I0216 14:58:34.645403 23126066861888 run_lib.py:146] step: 428200, eval_loss: 2.79978e-02
I0216 14:58:52.426524 23126066861888 run_lib.py:133] step: 428250, training_loss: 1.79442e-02
I0216 14:59:09.947674 23126066861888 run_lib.py:133] step: 428300, training_loss: 1.73219e-02
I0216 14:59:10.107223 23126066861888 run_lib.py:146] step: 428300, eval_loss: 2.94246e-02
I0216 14:59:27.603913 23126066861888 run_lib.py:133] step: 428350, training_loss: 1.76767e-02
I0216 14:59:45.245265 23126066861888 run_lib.py:133] step: 428400, training_loss: 1.78265e-02
I0216 14:59:45.402175 23126066861888 run_lib.py:146] step: 428400, eval_loss: 2.81365e-02
I0216 15:00:02.903772 23126066861888 run_lib.py:133] step: 428450, training_loss: 1.76033e-02
I0216 15:00:20.651979 23126066861888 run_lib.py:133] step: 428500, training_loss: 1.78454e-02
I0216 15:00:20.814855 23126066861888 run_lib.py:146] step: 428500, eval_loss: 2.92013e-02
I0216 15:00:38.375175 23126066861888 run_lib.py:133] step: 428550, training_loss: 1.78645e-02
I0216 15:00:55.878639 23126066861888 run_lib.py:133] step: 428600, training_loss: 1.82002e-02
I0216 15:00:56.031929 23126066861888 run_lib.py:146] step: 428600, eval_loss: 2.82432e-02
I0216 15:01:13.785928 23126066861888 run_lib.py:133] step: 428650, training_loss: 1.72681e-02
I0216 15:01:31.334171 23126066861888 run_lib.py:133] step: 428700, training_loss: 1.71610e-02
I0216 15:01:31.492219 23126066861888 run_lib.py:146] step: 428700, eval_loss: 2.88193e-02
I0216 15:01:49.003811 23126066861888 run_lib.py:133] step: 428750, training_loss: 1.77359e-02
I0216 15:02:06.743607 23126066861888 run_lib.py:133] step: 428800, training_loss: 1.67974e-02
I0216 15:02:06.905956 23126066861888 run_lib.py:146] step: 428800, eval_loss: 2.77555e-02
I0216 15:02:24.429111 23126066861888 run_lib.py:133] step: 428850, training_loss: 1.72593e-02
I0216 15:02:41.983114 23126066861888 run_lib.py:133] step: 428900, training_loss: 1.78966e-02
I0216 15:02:42.139193 23126066861888 run_lib.py:146] step: 428900, eval_loss: 2.93346e-02
I0216 15:02:59.746404 23126066861888 run_lib.py:133] step: 428950, training_loss: 1.73449e-02
I0216 15:03:17.263677 23126066861888 run_lib.py:133] step: 429000, training_loss: 1.74777e-02
I0216 15:03:17.419204 23126066861888 run_lib.py:146] step: 429000, eval_loss: 2.80303e-02
I0216 15:03:34.942020 23126066861888 run_lib.py:133] step: 429050, training_loss: 1.78663e-02
I0216 15:03:52.520235 23126066861888 run_lib.py:133] step: 429100, training_loss: 1.71863e-02
I0216 15:03:52.686375 23126066861888 run_lib.py:146] step: 429100, eval_loss: 2.95148e-02
I0216 15:04:10.429699 23126066861888 run_lib.py:133] step: 429150, training_loss: 1.77182e-02
I0216 15:04:28.047877 23126066861888 run_lib.py:133] step: 429200, training_loss: 1.79885e-02
I0216 15:04:28.205289 23126066861888 run_lib.py:146] step: 429200, eval_loss: 2.73927e-02
I0216 15:04:45.689286 23126066861888 run_lib.py:133] step: 429250, training_loss: 1.74468e-02
I0216 15:05:03.203502 23126066861888 run_lib.py:133] step: 429300, training_loss: 1.71807e-02
I0216 15:05:03.367164 23126066861888 run_lib.py:146] step: 429300, eval_loss: 2.87402e-02
I0216 15:05:21.062847 23126066861888 run_lib.py:133] step: 429350, training_loss: 1.72911e-02
I0216 15:05:38.607563 23126066861888 run_lib.py:133] step: 429400, training_loss: 1.69038e-02
I0216 15:05:38.774420 23126066861888 run_lib.py:146] step: 429400, eval_loss: 2.85334e-02
I0216 15:05:56.314862 23126066861888 run_lib.py:133] step: 429450, training_loss: 1.80175e-02
I0216 15:06:14.066275 23126066861888 run_lib.py:133] step: 429500, training_loss: 1.76291e-02
I0216 15:06:14.222185 23126066861888 run_lib.py:146] step: 429500, eval_loss: 2.79310e-02
I0216 15:06:31.718612 23126066861888 run_lib.py:133] step: 429550, training_loss: 1.72062e-02
I0216 15:06:49.428019 23126066861888 run_lib.py:133] step: 429600, training_loss: 1.74465e-02
I0216 15:06:49.589141 23126066861888 run_lib.py:146] step: 429600, eval_loss: 2.78313e-02
I0216 15:07:07.213461 23126066861888 run_lib.py:133] step: 429650, training_loss: 1.81534e-02
I0216 15:07:24.744076 23126066861888 run_lib.py:133] step: 429700, training_loss: 1.73580e-02
I0216 15:07:24.905591 23126066861888 run_lib.py:146] step: 429700, eval_loss: 2.80035e-02
I0216 15:07:42.591184 23126066861888 run_lib.py:133] step: 429750, training_loss: 1.70083e-02
I0216 15:08:00.082600 23126066861888 run_lib.py:133] step: 429800, training_loss: 1.73843e-02
I0216 15:08:00.236211 23126066861888 run_lib.py:146] step: 429800, eval_loss: 2.73811e-02
I0216 15:08:17.758770 23126066861888 run_lib.py:133] step: 429850, training_loss: 1.76451e-02
I0216 15:08:35.430642 23126066861888 run_lib.py:133] step: 429900, training_loss: 1.75552e-02
I0216 15:08:35.585855 23126066861888 run_lib.py:146] step: 429900, eval_loss: 2.88218e-02
I0216 15:08:53.114484 23126066861888 run_lib.py:133] step: 429950, training_loss: 1.71334e-02
I0216 15:09:10.695709 23126066861888 run_lib.py:133] step: 430000, training_loss: 1.78044e-02
I0216 15:09:12.817900 23126066861888 run_lib.py:146] step: 430000, eval_loss: 2.85801e-02
I0216 15:09:34.441617 23126066861888 run_lib.py:133] step: 430050, training_loss: 1.81613e-02
I0216 15:09:52.082890 23126066861888 run_lib.py:133] step: 430100, training_loss: 1.78143e-02
I0216 15:09:52.236171 23126066861888 run_lib.py:146] step: 430100, eval_loss: 2.81887e-02
I0216 15:10:09.730789 23126066861888 run_lib.py:133] step: 430150, training_loss: 1.76133e-02
I0216 15:10:27.265499 23126066861888 run_lib.py:133] step: 430200, training_loss: 1.81295e-02
I0216 15:10:27.438288 23126066861888 run_lib.py:146] step: 430200, eval_loss: 2.76579e-02
I0216 15:10:45.105927 23126066861888 run_lib.py:133] step: 430250, training_loss: 1.71295e-02
I0216 15:11:02.860896 23126066861888 run_lib.py:133] step: 430300, training_loss: 1.75373e-02
I0216 15:11:03.023781 23126066861888 run_lib.py:146] step: 430300, eval_loss: 2.71890e-02
I0216 15:11:20.517762 23126066861888 run_lib.py:133] step: 430350, training_loss: 1.66545e-02
I0216 15:11:37.992053 23126066861888 run_lib.py:133] step: 430400, training_loss: 1.74485e-02
I0216 15:11:38.148096 23126066861888 run_lib.py:146] step: 430400, eval_loss: 2.70195e-02
I0216 15:11:55.838118 23126066861888 run_lib.py:133] step: 430450, training_loss: 1.81367e-02
I0216 15:12:13.406109 23126066861888 run_lib.py:133] step: 430500, training_loss: 1.70215e-02
I0216 15:12:13.571810 23126066861888 run_lib.py:146] step: 430500, eval_loss: 2.76071e-02
I0216 15:12:31.304308 23126066861888 run_lib.py:133] step: 430550, training_loss: 1.66674e-02
I0216 15:12:48.869441 23126066861888 run_lib.py:133] step: 430600, training_loss: 1.72609e-02
I0216 15:12:49.032067 23126066861888 run_lib.py:146] step: 430600, eval_loss: 2.80647e-02
I0216 15:13:06.531911 23126066861888 run_lib.py:133] step: 430650, training_loss: 1.79255e-02
I0216 15:13:24.025439 23126066861888 run_lib.py:133] step: 430700, training_loss: 1.75280e-02
I0216 15:13:24.196323 23126066861888 run_lib.py:146] step: 430700, eval_loss: 2.83443e-02
I0216 15:13:41.918406 23126066861888 run_lib.py:133] step: 430750, training_loss: 1.75997e-02
I0216 15:13:59.592088 23126066861888 run_lib.py:133] step: 430800, training_loss: 1.67271e-02
I0216 15:13:59.751135 23126066861888 run_lib.py:146] step: 430800, eval_loss: 2.76386e-02
I0216 15:14:17.252058 23126066861888 run_lib.py:133] step: 430850, training_loss: 1.73282e-02
I0216 15:14:34.756965 23126066861888 run_lib.py:133] step: 430900, training_loss: 1.78707e-02
I0216 15:14:34.913165 23126066861888 run_lib.py:146] step: 430900, eval_loss: 2.81309e-02
I0216 15:14:52.586261 23126066861888 run_lib.py:133] step: 430950, training_loss: 1.75432e-02
I0216 15:15:10.130444 23126066861888 run_lib.py:133] step: 431000, training_loss: 1.80468e-02
I0216 15:15:10.286544 23126066861888 run_lib.py:146] step: 431000, eval_loss: 2.71806e-02
I0216 15:15:27.858794 23126066861888 run_lib.py:133] step: 431050, training_loss: 1.82896e-02
I0216 15:15:45.560254 23126066861888 run_lib.py:133] step: 431100, training_loss: 1.72520e-02
I0216 15:15:45.715172 23126066861888 run_lib.py:146] step: 431100, eval_loss: 2.71852e-02
I0216 15:16:03.206458 23126066861888 run_lib.py:133] step: 431150, training_loss: 1.73672e-02
I0216 15:16:20.884917 23126066861888 run_lib.py:133] step: 431200, training_loss: 1.66544e-02
I0216 15:16:21.045573 23126066861888 run_lib.py:146] step: 431200, eval_loss: 2.84011e-02
I0216 15:16:38.563664 23126066861888 run_lib.py:133] step: 431250, training_loss: 1.67579e-02
I0216 15:16:56.121230 23126066861888 run_lib.py:133] step: 431300, training_loss: 1.73025e-02
I0216 15:16:56.281502 23126066861888 run_lib.py:146] step: 431300, eval_loss: 2.77801e-02
I0216 15:17:14.024018 23126066861888 run_lib.py:133] step: 431350, training_loss: 1.70432e-02
I0216 15:17:31.516479 23126066861888 run_lib.py:133] step: 431400, training_loss: 1.72154e-02
I0216 15:17:31.677228 23126066861888 run_lib.py:146] step: 431400, eval_loss: 2.84634e-02
I0216 15:17:49.201514 23126066861888 run_lib.py:133] step: 431450, training_loss: 1.75528e-02
I0216 15:18:06.729675 23126066861888 run_lib.py:133] step: 431500, training_loss: 1.84490e-02
I0216 15:18:06.881627 23126066861888 run_lib.py:146] step: 431500, eval_loss: 2.81512e-02
I0216 15:18:24.622616 23126066861888 run_lib.py:133] step: 431550, training_loss: 1.72203e-02
I0216 15:18:42.148530 23126066861888 run_lib.py:133] step: 431600, training_loss: 1.70475e-02
I0216 15:18:42.305213 23126066861888 run_lib.py:146] step: 431600, eval_loss: 2.65948e-02
I0216 15:18:59.934903 23126066861888 run_lib.py:133] step: 431650, training_loss: 1.76631e-02
I0216 15:19:17.430165 23126066861888 run_lib.py:133] step: 431700, training_loss: 1.73313e-02
I0216 15:19:17.664490 23126066861888 run_lib.py:146] step: 431700, eval_loss: 2.86880e-02
I0216 15:19:35.181805 23126066861888 run_lib.py:133] step: 431750, training_loss: 1.80303e-02
I0216 15:19:52.759255 23126066861888 run_lib.py:133] step: 431800, training_loss: 1.80982e-02
I0216 15:19:52.923437 23126066861888 run_lib.py:146] step: 431800, eval_loss: 2.83049e-02
I0216 15:20:10.644584 23126066861888 run_lib.py:133] step: 431850, training_loss: 1.80913e-02
I0216 15:20:28.240440 23126066861888 run_lib.py:133] step: 431900, training_loss: 1.81321e-02
I0216 15:20:28.402533 23126066861888 run_lib.py:146] step: 431900, eval_loss: 2.85914e-02
I0216 15:20:45.942838 23126066861888 run_lib.py:133] step: 431950, training_loss: 1.76231e-02
I0216 15:21:03.444783 23126066861888 run_lib.py:133] step: 432000, training_loss: 1.80816e-02
I0216 15:21:03.601095 23126066861888 run_lib.py:146] step: 432000, eval_loss: 2.88690e-02
I0216 15:21:21.276738 23126066861888 run_lib.py:133] step: 432050, training_loss: 1.77866e-02
I0216 15:21:38.840066 23126066861888 run_lib.py:133] step: 432100, training_loss: 1.77405e-02
I0216 15:21:39.018322 23126066861888 run_lib.py:146] step: 432100, eval_loss: 2.90002e-02
I0216 15:21:56.538343 23126066861888 run_lib.py:133] step: 432150, training_loss: 1.78606e-02
I0216 15:22:14.312801 23126066861888 run_lib.py:133] step: 432200, training_loss: 1.82120e-02
I0216 15:22:14.477481 23126066861888 run_lib.py:146] step: 432200, eval_loss: 2.73400e-02
I0216 15:22:31.999188 23126066861888 run_lib.py:133] step: 432250, training_loss: 1.72293e-02
I0216 15:22:49.662024 23126066861888 run_lib.py:133] step: 432300, training_loss: 1.74238e-02
I0216 15:22:49.819219 23126066861888 run_lib.py:146] step: 432300, eval_loss: 2.79951e-02
I0216 15:23:07.296695 23126066861888 run_lib.py:133] step: 432350, training_loss: 1.76511e-02
I0216 15:23:24.913808 23126066861888 run_lib.py:133] step: 432400, training_loss: 1.74251e-02
I0216 15:23:25.072412 23126066861888 run_lib.py:146] step: 432400, eval_loss: 2.76777e-02
I0216 15:23:42.855513 23126066861888 run_lib.py:133] step: 432450, training_loss: 1.75983e-02
I0216 15:24:00.358126 23126066861888 run_lib.py:133] step: 432500, training_loss: 1.82903e-02
I0216 15:24:00.513190 23126066861888 run_lib.py:146] step: 432500, eval_loss: 2.71775e-02
I0216 15:24:17.990468 23126066861888 run_lib.py:133] step: 432550, training_loss: 1.77934e-02
I0216 15:24:35.719168 23126066861888 run_lib.py:133] step: 432600, training_loss: 1.72068e-02
I0216 15:24:35.889229 23126066861888 run_lib.py:146] step: 432600, eval_loss: 2.86117e-02
I0216 15:24:53.474016 23126066861888 run_lib.py:133] step: 432650, training_loss: 1.85202e-02
I0216 15:25:11.010744 23126066861888 run_lib.py:133] step: 432700, training_loss: 1.80494e-02
I0216 15:25:11.170227 23126066861888 run_lib.py:146] step: 432700, eval_loss: 2.87084e-02
I0216 15:25:28.804131 23126066861888 run_lib.py:133] step: 432750, training_loss: 1.72501e-02
I0216 15:25:46.335632 23126066861888 run_lib.py:133] step: 432800, training_loss: 1.75260e-02
I0216 15:25:46.493139 23126066861888 run_lib.py:146] step: 432800, eval_loss: 2.82957e-02
I0216 15:26:03.988321 23126066861888 run_lib.py:133] step: 432850, training_loss: 1.73817e-02
I0216 15:26:21.536405 23126066861888 run_lib.py:133] step: 432900, training_loss: 1.76853e-02
I0216 15:26:21.690434 23126066861888 run_lib.py:146] step: 432900, eval_loss: 2.88090e-02
I0216 15:26:39.470998 23126066861888 run_lib.py:133] step: 432950, training_loss: 1.82929e-02
I0216 15:26:57.129620 23126066861888 run_lib.py:133] step: 433000, training_loss: 1.75850e-02
I0216 15:26:57.285182 23126066861888 run_lib.py:146] step: 433000, eval_loss: 2.78590e-02
I0216 15:27:14.801895 23126066861888 run_lib.py:133] step: 433050, training_loss: 1.82505e-02
I0216 15:27:32.324101 23126066861888 run_lib.py:133] step: 433100, training_loss: 1.69733e-02
I0216 15:27:32.484514 23126066861888 run_lib.py:146] step: 433100, eval_loss: 2.81411e-02
I0216 15:27:50.156415 23126066861888 run_lib.py:133] step: 433150, training_loss: 1.78521e-02
I0216 15:28:07.894605 23126066861888 run_lib.py:133] step: 433200, training_loss: 1.75271e-02
I0216 15:28:08.056747 23126066861888 run_lib.py:146] step: 433200, eval_loss: 2.83384e-02
I0216 15:28:25.556410 23126066861888 run_lib.py:133] step: 433250, training_loss: 1.78077e-02
I0216 15:28:43.261227 23126066861888 run_lib.py:133] step: 433300, training_loss: 1.76756e-02
I0216 15:28:43.417924 23126066861888 run_lib.py:146] step: 433300, eval_loss: 2.77267e-02
I0216 15:29:00.935957 23126066861888 run_lib.py:133] step: 433350, training_loss: 1.81009e-02
I0216 15:29:18.581101 23126066861888 run_lib.py:133] step: 433400, training_loss: 1.86556e-02
I0216 15:29:18.739942 23126066861888 run_lib.py:146] step: 433400, eval_loss: 2.89713e-02
I0216 15:29:36.276436 23126066861888 run_lib.py:133] step: 433450, training_loss: 1.73400e-02
I0216 15:29:53.785098 23126066861888 run_lib.py:133] step: 433500, training_loss: 1.70504e-02
I0216 15:29:53.944339 23126066861888 run_lib.py:146] step: 433500, eval_loss: 2.80331e-02
I0216 15:30:11.674994 23126066861888 run_lib.py:133] step: 433550, training_loss: 1.74147e-02
I0216 15:30:29.214536 23126066861888 run_lib.py:133] step: 433600, training_loss: 1.75540e-02
I0216 15:30:29.381901 23126066861888 run_lib.py:146] step: 433600, eval_loss: 2.89840e-02
I0216 15:30:46.856021 23126066861888 run_lib.py:133] step: 433650, training_loss: 1.78223e-02
I0216 15:31:04.544755 23126066861888 run_lib.py:133] step: 433700, training_loss: 1.74367e-02
I0216 15:31:04.716261 23126066861888 run_lib.py:146] step: 433700, eval_loss: 2.87287e-02
I0216 15:31:22.317464 23126066861888 run_lib.py:133] step: 433750, training_loss: 1.73716e-02
I0216 15:31:39.850061 23126066861888 run_lib.py:133] step: 433800, training_loss: 1.72758e-02
I0216 15:31:40.010812 23126066861888 run_lib.py:146] step: 433800, eval_loss: 2.81315e-02
I0216 15:31:57.679867 23126066861888 run_lib.py:133] step: 433850, training_loss: 1.76366e-02
I0216 15:32:15.168958 23126066861888 run_lib.py:133] step: 433900, training_loss: 1.75501e-02
I0216 15:32:15.319555 23126066861888 run_lib.py:146] step: 433900, eval_loss: 2.78902e-02
I0216 15:32:32.910337 23126066861888 run_lib.py:133] step: 433950, training_loss: 1.81091e-02
I0216 15:32:50.428786 23126066861888 run_lib.py:133] step: 434000, training_loss: 1.80201e-02
I0216 15:32:50.601473 23126066861888 run_lib.py:146] step: 434000, eval_loss: 2.87259e-02
I0216 15:33:08.313993 23126066861888 run_lib.py:133] step: 434050, training_loss: 1.73492e-02
I0216 15:33:25.978474 23126066861888 run_lib.py:133] step: 434100, training_loss: 1.83495e-02
I0216 15:33:26.142250 23126066861888 run_lib.py:146] step: 434100, eval_loss: 2.86626e-02
I0216 15:33:43.659991 23126066861888 run_lib.py:133] step: 434150, training_loss: 1.69391e-02
I0216 15:34:01.168928 23126066861888 run_lib.py:133] step: 434200, training_loss: 1.78776e-02
I0216 15:34:01.326232 23126066861888 run_lib.py:146] step: 434200, eval_loss: 2.72013e-02
I0216 15:34:18.995978 23126066861888 run_lib.py:133] step: 434250, training_loss: 1.73820e-02
I0216 15:34:36.501301 23126066861888 run_lib.py:133] step: 434300, training_loss: 1.74627e-02
I0216 15:34:36.658397 23126066861888 run_lib.py:146] step: 434300, eval_loss: 2.87180e-02
I0216 15:34:54.220312 23126066861888 run_lib.py:133] step: 434350, training_loss: 1.70956e-02
I0216 15:35:11.951900 23126066861888 run_lib.py:133] step: 434400, training_loss: 1.75050e-02
I0216 15:35:12.106297 23126066861888 run_lib.py:146] step: 434400, eval_loss: 2.71596e-02
I0216 15:35:29.581260 23126066861888 run_lib.py:133] step: 434450, training_loss: 1.77782e-02
I0216 15:35:47.240346 23126066861888 run_lib.py:133] step: 434500, training_loss: 1.75415e-02
I0216 15:35:47.397834 23126066861888 run_lib.py:146] step: 434500, eval_loss: 2.75272e-02
I0216 15:36:04.877943 23126066861888 run_lib.py:133] step: 434550, training_loss: 1.72364e-02
I0216 15:36:22.412602 23126066861888 run_lib.py:133] step: 434600, training_loss: 1.78449e-02
I0216 15:36:22.583198 23126066861888 run_lib.py:146] step: 434600, eval_loss: 2.82364e-02
I0216 15:36:40.471740 23126066861888 run_lib.py:133] step: 434650, training_loss: 1.75219e-02
I0216 15:36:57.992377 23126066861888 run_lib.py:133] step: 434700, training_loss: 1.73221e-02
I0216 15:36:58.148242 23126066861888 run_lib.py:146] step: 434700, eval_loss: 2.82490e-02
I0216 15:37:15.667970 23126066861888 run_lib.py:133] step: 434750, training_loss: 1.85115e-02
I0216 15:37:33.322648 23126066861888 run_lib.py:133] step: 434800, training_loss: 1.76691e-02
I0216 15:37:33.480076 23126066861888 run_lib.py:146] step: 434800, eval_loss: 2.80386e-02
I0216 15:37:50.988409 23126066861888 run_lib.py:133] step: 434850, training_loss: 1.82365e-02
I0216 15:38:08.534307 23126066861888 run_lib.py:133] step: 434900, training_loss: 1.80874e-02
I0216 15:38:08.693280 23126066861888 run_lib.py:146] step: 434900, eval_loss: 2.78395e-02
I0216 15:38:26.439848 23126066861888 run_lib.py:133] step: 434950, training_loss: 1.74883e-02
I0216 15:38:43.955718 23126066861888 run_lib.py:133] step: 435000, training_loss: 1.84833e-02
I0216 15:38:44.116403 23126066861888 run_lib.py:146] step: 435000, eval_loss: 2.69189e-02
I0216 15:39:01.606960 23126066861888 run_lib.py:133] step: 435050, training_loss: 1.77195e-02
I0216 15:39:19.100471 23126066861888 run_lib.py:133] step: 435100, training_loss: 1.75512e-02
I0216 15:39:19.259213 23126066861888 run_lib.py:146] step: 435100, eval_loss: 2.85961e-02
I0216 15:39:36.972747 23126066861888 run_lib.py:133] step: 435150, training_loss: 1.77139e-02
I0216 15:39:54.646396 23126066861888 run_lib.py:133] step: 435200, training_loss: 1.79734e-02
I0216 15:39:54.802484 23126066861888 run_lib.py:146] step: 435200, eval_loss: 2.85698e-02
I0216 15:40:12.312128 23126066861888 run_lib.py:133] step: 435250, training_loss: 1.62141e-02
I0216 15:40:29.994656 23126066861888 run_lib.py:133] step: 435300, training_loss: 1.77990e-02
I0216 15:40:30.147876 23126066861888 run_lib.py:146] step: 435300, eval_loss: 2.82066e-02
I0216 15:40:47.818388 23126066861888 run_lib.py:133] step: 435350, training_loss: 1.72223e-02
I0216 15:41:05.318545 23126066861888 run_lib.py:133] step: 435400, training_loss: 1.73294e-02
I0216 15:41:05.484465 23126066861888 run_lib.py:146] step: 435400, eval_loss: 2.78060e-02
I0216 15:41:23.036660 23126066861888 run_lib.py:133] step: 435450, training_loss: 1.80536e-02
I0216 15:41:40.803271 23126066861888 run_lib.py:133] step: 435500, training_loss: 1.71933e-02
I0216 15:41:40.963167 23126066861888 run_lib.py:146] step: 435500, eval_loss: 2.84196e-02
I0216 15:41:58.473012 23126066861888 run_lib.py:133] step: 435550, training_loss: 1.75949e-02
I0216 15:42:16.114328 23126066861888 run_lib.py:133] step: 435600, training_loss: 1.74252e-02
I0216 15:42:16.279142 23126066861888 run_lib.py:146] step: 435600, eval_loss: 2.88220e-02
I0216 15:42:33.764733 23126066861888 run_lib.py:133] step: 435650, training_loss: 1.75845e-02
I0216 15:42:51.309602 23126066861888 run_lib.py:133] step: 435700, training_loss: 1.79285e-02
I0216 15:42:51.470333 23126066861888 run_lib.py:146] step: 435700, eval_loss: 2.95932e-02
I0216 15:43:09.211212 23126066861888 run_lib.py:133] step: 435750, training_loss: 1.75536e-02
I0216 15:43:26.709606 23126066861888 run_lib.py:133] step: 435800, training_loss: 1.76070e-02
I0216 15:43:26.872103 23126066861888 run_lib.py:146] step: 435800, eval_loss: 2.86250e-02
I0216 15:43:44.351481 23126066861888 run_lib.py:133] step: 435850, training_loss: 1.76501e-02
I0216 15:44:02.051356 23126066861888 run_lib.py:133] step: 435900, training_loss: 1.71629e-02
I0216 15:44:02.211390 23126066861888 run_lib.py:146] step: 435900, eval_loss: 2.75879e-02
I0216 15:44:19.769620 23126066861888 run_lib.py:133] step: 435950, training_loss: 1.70446e-02
I0216 15:44:37.333210 23126066861888 run_lib.py:133] step: 436000, training_loss: 1.74260e-02
I0216 15:44:37.496270 23126066861888 run_lib.py:146] step: 436000, eval_loss: 2.75968e-02
I0216 15:44:55.103610 23126066861888 run_lib.py:133] step: 436050, training_loss: 1.76795e-02
I0216 15:45:12.628349 23126066861888 run_lib.py:133] step: 436100, training_loss: 1.78314e-02
I0216 15:45:12.994105 23126066861888 run_lib.py:146] step: 436100, eval_loss: 2.82287e-02
I0216 15:45:30.478971 23126066861888 run_lib.py:133] step: 436150, training_loss: 1.79222e-02
I0216 15:45:47.984282 23126066861888 run_lib.py:133] step: 436200, training_loss: 1.73527e-02
I0216 15:45:48.148944 23126066861888 run_lib.py:146] step: 436200, eval_loss: 2.77859e-02
I0216 15:46:05.867141 23126066861888 run_lib.py:133] step: 436250, training_loss: 1.71403e-02
I0216 15:46:23.516373 23126066861888 run_lib.py:133] step: 436300, training_loss: 1.84673e-02
I0216 15:46:23.672704 23126066861888 run_lib.py:146] step: 436300, eval_loss: 2.79243e-02
I0216 15:46:41.193227 23126066861888 run_lib.py:133] step: 436350, training_loss: 1.74514e-02
I0216 15:46:58.682585 23126066861888 run_lib.py:133] step: 436400, training_loss: 1.71788e-02
I0216 15:46:58.846468 23126066861888 run_lib.py:146] step: 436400, eval_loss: 2.77157e-02
I0216 15:47:16.509010 23126066861888 run_lib.py:133] step: 436450, training_loss: 1.75703e-02
I0216 15:47:34.072704 23126066861888 run_lib.py:133] step: 436500, training_loss: 1.78358e-02
I0216 15:47:34.248364 23126066861888 run_lib.py:146] step: 436500, eval_loss: 2.90411e-02
I0216 15:47:51.777442 23126066861888 run_lib.py:133] step: 436550, training_loss: 1.78183e-02
I0216 15:48:09.514152 23126066861888 run_lib.py:133] step: 436600, training_loss: 1.75058e-02
I0216 15:48:09.674026 23126066861888 run_lib.py:146] step: 436600, eval_loss: 2.86225e-02
I0216 15:48:27.201260 23126066861888 run_lib.py:133] step: 436650, training_loss: 1.76556e-02
I0216 15:48:44.863525 23126066861888 run_lib.py:133] step: 436700, training_loss: 1.70173e-02
I0216 15:48:45.018250 23126066861888 run_lib.py:146] step: 436700, eval_loss: 2.87653e-02
I0216 15:49:02.538578 23126066861888 run_lib.py:133] step: 436750, training_loss: 1.77934e-02
I0216 15:49:20.060319 23126066861888 run_lib.py:133] step: 436800, training_loss: 1.73249e-02
I0216 15:49:20.225508 23126066861888 run_lib.py:146] step: 436800, eval_loss: 2.78943e-02
I0216 15:49:38.089761 23126066861888 run_lib.py:133] step: 436850, training_loss: 1.68041e-02
I0216 15:49:55.643289 23126066861888 run_lib.py:133] step: 436900, training_loss: 1.71901e-02
I0216 15:49:55.810230 23126066861888 run_lib.py:146] step: 436900, eval_loss: 2.92814e-02
I0216 15:50:13.301836 23126066861888 run_lib.py:133] step: 436950, training_loss: 1.70226e-02
I0216 15:50:30.973825 23126066861888 run_lib.py:133] step: 437000, training_loss: 1.71233e-02
I0216 15:50:31.131273 23126066861888 run_lib.py:146] step: 437000, eval_loss: 2.73001e-02
I0216 15:50:48.655429 23126066861888 run_lib.py:133] step: 437050, training_loss: 1.79593e-02
I0216 15:51:06.277570 23126066861888 run_lib.py:133] step: 437100, training_loss: 1.75416e-02
I0216 15:51:06.436536 23126066861888 run_lib.py:146] step: 437100, eval_loss: 2.81316e-02
I0216 15:51:24.075595 23126066861888 run_lib.py:133] step: 437150, training_loss: 1.75489e-02
I0216 15:51:41.590810 23126066861888 run_lib.py:133] step: 437200, training_loss: 1.80981e-02
I0216 15:51:41.757085 23126066861888 run_lib.py:146] step: 437200, eval_loss: 2.92052e-02
I0216 15:51:59.248801 23126066861888 run_lib.py:133] step: 437250, training_loss: 1.79435e-02
I0216 15:52:16.752684 23126066861888 run_lib.py:133] step: 437300, training_loss: 1.75917e-02
I0216 15:52:16.909416 23126066861888 run_lib.py:146] step: 437300, eval_loss: 2.81333e-02
I0216 15:52:34.649709 23126066861888 run_lib.py:133] step: 437350, training_loss: 1.76804e-02
I0216 15:52:52.379853 23126066861888 run_lib.py:133] step: 437400, training_loss: 1.78586e-02
I0216 15:52:52.546215 23126066861888 run_lib.py:146] step: 437400, eval_loss: 2.83503e-02
I0216 15:53:10.022311 23126066861888 run_lib.py:133] step: 437450, training_loss: 1.72541e-02
I0216 15:53:27.529457 23126066861888 run_lib.py:133] step: 437500, training_loss: 1.77433e-02
I0216 15:53:27.687167 23126066861888 run_lib.py:146] step: 437500, eval_loss: 2.84358e-02
I0216 15:53:45.343365 23126066861888 run_lib.py:133] step: 437550, training_loss: 1.71196e-02
I0216 15:54:02.831970 23126066861888 run_lib.py:133] step: 437600, training_loss: 1.72325e-02
I0216 15:54:03.017141 23126066861888 run_lib.py:146] step: 437600, eval_loss: 2.89011e-02
I0216 15:54:20.512597 23126066861888 run_lib.py:133] step: 437650, training_loss: 1.77854e-02
I0216 15:54:38.262671 23126066861888 run_lib.py:133] step: 437700, training_loss: 1.74175e-02
I0216 15:54:38.420456 23126066861888 run_lib.py:146] step: 437700, eval_loss: 2.89757e-02
I0216 15:54:55.941932 23126066861888 run_lib.py:133] step: 437750, training_loss: 1.84134e-02
I0216 15:55:13.663589 23126066861888 run_lib.py:133] step: 437800, training_loss: 1.81099e-02
I0216 15:55:13.827674 23126066861888 run_lib.py:146] step: 437800, eval_loss: 2.82623e-02
I0216 15:55:31.312421 23126066861888 run_lib.py:133] step: 437850, training_loss: 1.82220e-02
I0216 15:55:48.831462 23126066861888 run_lib.py:133] step: 437900, training_loss: 1.87662e-02
I0216 15:55:49.012297 23126066861888 run_lib.py:146] step: 437900, eval_loss: 2.82810e-02
I0216 15:56:06.819190 23126066861888 run_lib.py:133] step: 437950, training_loss: 1.72764e-02
I0216 15:56:24.407504 23126066861888 run_lib.py:133] step: 438000, training_loss: 1.79386e-02
I0216 15:56:24.565367 23126066861888 run_lib.py:146] step: 438000, eval_loss: 2.88822e-02
I0216 15:56:42.123594 23126066861888 run_lib.py:133] step: 438050, training_loss: 1.74299e-02
I0216 15:56:59.790444 23126066861888 run_lib.py:133] step: 438100, training_loss: 1.67190e-02
I0216 15:56:59.952882 23126066861888 run_lib.py:146] step: 438100, eval_loss: 2.77722e-02
I0216 15:57:17.448677 23126066861888 run_lib.py:133] step: 438150, training_loss: 1.75332e-02
I0216 15:57:34.968908 23126066861888 run_lib.py:133] step: 438200, training_loss: 1.82779e-02
I0216 15:57:35.127375 23126066861888 run_lib.py:146] step: 438200, eval_loss: 2.75158e-02
I0216 15:57:52.791751 23126066861888 run_lib.py:133] step: 438250, training_loss: 1.82386e-02
I0216 15:58:10.321489 23126066861888 run_lib.py:133] step: 438300, training_loss: 1.83867e-02
I0216 15:58:10.488920 23126066861888 run_lib.py:146] step: 438300, eval_loss: 2.82396e-02
I0216 15:58:27.973319 23126066861888 run_lib.py:133] step: 438350, training_loss: 1.68408e-02
I0216 15:58:45.482187 23126066861888 run_lib.py:133] step: 438400, training_loss: 1.78491e-02
I0216 15:58:45.640403 23126066861888 run_lib.py:146] step: 438400, eval_loss: 2.76740e-02
I0216 15:59:03.399936 23126066861888 run_lib.py:133] step: 438450, training_loss: 1.81918e-02
I0216 15:59:21.036186 23126066861888 run_lib.py:133] step: 438500, training_loss: 1.79848e-02
I0216 15:59:21.195403 23126066861888 run_lib.py:146] step: 438500, eval_loss: 2.77923e-02
I0216 15:59:38.704854 23126066861888 run_lib.py:133] step: 438550, training_loss: 1.67007e-02
I0216 15:59:56.188676 23126066861888 run_lib.py:133] step: 438600, training_loss: 1.71819e-02
I0216 15:59:56.342950 23126066861888 run_lib.py:146] step: 438600, eval_loss: 2.75153e-02
I0216 16:00:14.079058 23126066861888 run_lib.py:133] step: 438650, training_loss: 1.78706e-02
I0216 16:00:31.609253 23126066861888 run_lib.py:133] step: 438700, training_loss: 1.81464e-02
I0216 16:00:31.769144 23126066861888 run_lib.py:146] step: 438700, eval_loss: 2.75574e-02
I0216 16:00:49.293715 23126066861888 run_lib.py:133] step: 438750, training_loss: 1.75246e-02
I0216 16:01:07.034641 23126066861888 run_lib.py:133] step: 438800, training_loss: 1.74552e-02
I0216 16:01:07.204218 23126066861888 run_lib.py:146] step: 438800, eval_loss: 2.84069e-02
I0216 16:01:24.755503 23126066861888 run_lib.py:133] step: 438850, training_loss: 1.85331e-02
I0216 16:01:42.460664 23126066861888 run_lib.py:133] step: 438900, training_loss: 1.69948e-02
I0216 16:01:42.616219 23126066861888 run_lib.py:146] step: 438900, eval_loss: 2.80842e-02
I0216 16:02:00.126548 23126066861888 run_lib.py:133] step: 438950, training_loss: 1.81736e-02
I0216 16:02:17.612557 23126066861888 run_lib.py:133] step: 439000, training_loss: 1.76771e-02
I0216 16:02:17.769228 23126066861888 run_lib.py:146] step: 439000, eval_loss: 2.84243e-02
I0216 16:02:35.450906 23126066861888 run_lib.py:133] step: 439050, training_loss: 1.76924e-02
I0216 16:02:53.001338 23126066861888 run_lib.py:133] step: 439100, training_loss: 1.65509e-02
I0216 16:02:53.162483 23126066861888 run_lib.py:146] step: 439100, eval_loss: 2.83951e-02
I0216 16:03:10.723434 23126066861888 run_lib.py:133] step: 439150, training_loss: 1.81767e-02
I0216 16:03:28.455875 23126066861888 run_lib.py:133] step: 439200, training_loss: 1.70430e-02
I0216 16:03:28.613308 23126066861888 run_lib.py:146] step: 439200, eval_loss: 2.90136e-02
I0216 16:03:46.132215 23126066861888 run_lib.py:133] step: 439250, training_loss: 1.75784e-02
I0216 16:04:03.654874 23126066861888 run_lib.py:133] step: 439300, training_loss: 1.78862e-02
I0216 16:04:03.830274 23126066861888 run_lib.py:146] step: 439300, eval_loss: 2.83380e-02
I0216 16:04:21.471584 23126066861888 run_lib.py:133] step: 439350, training_loss: 1.74128e-02
I0216 16:04:38.989883 23126066861888 run_lib.py:133] step: 439400, training_loss: 1.68097e-02
I0216 16:04:39.147431 23126066861888 run_lib.py:146] step: 439400, eval_loss: 2.73005e-02
I0216 16:04:56.680592 23126066861888 run_lib.py:133] step: 439450, training_loss: 1.69306e-02
I0216 16:05:14.162276 23126066861888 run_lib.py:133] step: 439500, training_loss: 1.67329e-02
I0216 16:05:14.320321 23126066861888 run_lib.py:146] step: 439500, eval_loss: 2.79987e-02
I0216 16:05:32.035262 23126066861888 run_lib.py:133] step: 439550, training_loss: 1.77137e-02
I0216 16:05:49.664261 23126066861888 run_lib.py:133] step: 439600, training_loss: 1.72742e-02
I0216 16:05:49.821426 23126066861888 run_lib.py:146] step: 439600, eval_loss: 2.76060e-02
I0216 16:06:07.428423 23126066861888 run_lib.py:133] step: 439650, training_loss: 1.76890e-02
I0216 16:06:24.958949 23126066861888 run_lib.py:133] step: 439700, training_loss: 1.77167e-02
I0216 16:06:25.116163 23126066861888 run_lib.py:146] step: 439700, eval_loss: 2.81381e-02
I0216 16:06:42.813223 23126066861888 run_lib.py:133] step: 439750, training_loss: 1.69336e-02
I0216 16:07:00.331823 23126066861888 run_lib.py:133] step: 439800, training_loss: 1.77033e-02
I0216 16:07:00.502196 23126066861888 run_lib.py:146] step: 439800, eval_loss: 2.84686e-02
I0216 16:07:18.008305 23126066861888 run_lib.py:133] step: 439850, training_loss: 1.66283e-02
I0216 16:07:35.735181 23126066861888 run_lib.py:133] step: 439900, training_loss: 1.74088e-02
I0216 16:07:35.893457 23126066861888 run_lib.py:146] step: 439900, eval_loss: 2.82347e-02
I0216 16:07:53.401458 23126066861888 run_lib.py:133] step: 439950, training_loss: 1.72815e-02
I0216 16:08:11.136849 23126066861888 run_lib.py:133] step: 440000, training_loss: 1.77697e-02
I0216 16:08:12.353005 23126066861888 run_lib.py:146] step: 440000, eval_loss: 2.93306e-02
I0216 16:08:33.080831 23126066861888 run_lib.py:133] step: 440050, training_loss: 1.72850e-02
I0216 16:08:50.622550 23126066861888 run_lib.py:133] step: 440100, training_loss: 1.73727e-02
I0216 16:08:50.775707 23126066861888 run_lib.py:146] step: 440100, eval_loss: 2.77277e-02
I0216 16:09:08.349705 23126066861888 run_lib.py:133] step: 440150, training_loss: 1.78270e-02
I0216 16:09:25.887375 23126066861888 run_lib.py:133] step: 440200, training_loss: 1.76410e-02
I0216 16:09:26.043220 23126066861888 run_lib.py:146] step: 440200, eval_loss: 2.87040e-02
I0216 16:09:43.746279 23126066861888 run_lib.py:133] step: 440250, training_loss: 1.74607e-02
I0216 16:10:01.353122 23126066861888 run_lib.py:133] step: 440300, training_loss: 1.71167e-02
I0216 16:10:01.514426 23126066861888 run_lib.py:146] step: 440300, eval_loss: 2.79300e-02
I0216 16:10:19.000523 23126066861888 run_lib.py:133] step: 440350, training_loss: 1.74093e-02
I0216 16:10:36.530585 23126066861888 run_lib.py:133] step: 440400, training_loss: 1.81806e-02
I0216 16:10:36.701249 23126066861888 run_lib.py:146] step: 440400, eval_loss: 2.66238e-02
I0216 16:10:54.423298 23126066861888 run_lib.py:133] step: 440450, training_loss: 1.79424e-02
I0216 16:11:11.972929 23126066861888 run_lib.py:133] step: 440500, training_loss: 1.73091e-02
I0216 16:11:12.130330 23126066861888 run_lib.py:146] step: 440500, eval_loss: 2.90913e-02
I0216 16:11:29.695106 23126066861888 run_lib.py:133] step: 440550, training_loss: 1.79939e-02
I0216 16:11:47.377490 23126066861888 run_lib.py:133] step: 440600, training_loss: 1.76147e-02
I0216 16:11:47.529937 23126066861888 run_lib.py:146] step: 440600, eval_loss: 2.80206e-02
I0216 16:12:05.010655 23126066861888 run_lib.py:133] step: 440650, training_loss: 1.69170e-02
I0216 16:12:22.700574 23126066861888 run_lib.py:133] step: 440700, training_loss: 1.73964e-02
I0216 16:12:22.869483 23126066861888 run_lib.py:146] step: 440700, eval_loss: 2.79063e-02
I0216 16:12:40.406580 23126066861888 run_lib.py:133] step: 440750, training_loss: 1.73521e-02
I0216 16:12:57.960711 23126066861888 run_lib.py:133] step: 440800, training_loss: 1.73995e-02
I0216 16:12:58.123502 23126066861888 run_lib.py:146] step: 440800, eval_loss: 2.84113e-02
I0216 16:13:15.891531 23126066861888 run_lib.py:133] step: 440850, training_loss: 1.75925e-02
I0216 16:13:33.436054 23126066861888 run_lib.py:133] step: 440900, training_loss: 1.67628e-02
I0216 16:13:33.601225 23126066861888 run_lib.py:146] step: 440900, eval_loss: 2.84906e-02
I0216 16:13:51.108650 23126066861888 run_lib.py:133] step: 440950, training_loss: 1.70002e-02
I0216 16:14:08.909918 23126066861888 run_lib.py:133] step: 441000, training_loss: 1.74321e-02
I0216 16:14:09.064953 23126066861888 run_lib.py:146] step: 441000, eval_loss: 2.85917e-02
I0216 16:14:26.613281 23126066861888 run_lib.py:133] step: 441050, training_loss: 1.72955e-02
I0216 16:14:44.112396 23126066861888 run_lib.py:133] step: 441100, training_loss: 1.66718e-02
I0216 16:14:44.274217 23126066861888 run_lib.py:146] step: 441100, eval_loss: 2.87503e-02
I0216 16:15:01.904192 23126066861888 run_lib.py:133] step: 441150, training_loss: 1.77976e-02
I0216 16:15:19.413498 23126066861888 run_lib.py:133] step: 441200, training_loss: 1.75776e-02
I0216 16:15:19.573461 23126066861888 run_lib.py:146] step: 441200, eval_loss: 2.79598e-02
I0216 16:15:37.154753 23126066861888 run_lib.py:133] step: 441250, training_loss: 1.75856e-02
I0216 16:15:54.712018 23126066861888 run_lib.py:133] step: 441300, training_loss: 1.73407e-02
I0216 16:15:54.870876 23126066861888 run_lib.py:146] step: 441300, eval_loss: 2.82646e-02
I0216 16:16:12.584984 23126066861888 run_lib.py:133] step: 441350, training_loss: 1.71117e-02
I0216 16:16:30.201868 23126066861888 run_lib.py:133] step: 441400, training_loss: 1.77005e-02
I0216 16:16:30.356217 23126066861888 run_lib.py:146] step: 441400, eval_loss: 2.87330e-02
I0216 16:16:47.855305 23126066861888 run_lib.py:133] step: 441450, training_loss: 1.70264e-02
I0216 16:17:05.364921 23126066861888 run_lib.py:133] step: 441500, training_loss: 1.81155e-02
I0216 16:17:05.531308 23126066861888 run_lib.py:146] step: 441500, eval_loss: 2.88873e-02
I0216 16:17:23.251819 23126066861888 run_lib.py:133] step: 441550, training_loss: 1.73709e-02
I0216 16:17:40.803823 23126066861888 run_lib.py:133] step: 441600, training_loss: 1.77201e-02
I0216 16:17:40.968439 23126066861888 run_lib.py:146] step: 441600, eval_loss: 2.84665e-02
I0216 16:17:58.460626 23126066861888 run_lib.py:133] step: 441650, training_loss: 1.80973e-02
I0216 16:18:16.192010 23126066861888 run_lib.py:133] step: 441700, training_loss: 1.69621e-02
I0216 16:18:16.356653 23126066861888 run_lib.py:146] step: 441700, eval_loss: 2.87927e-02
I0216 16:18:33.852412 23126066861888 run_lib.py:133] step: 441750, training_loss: 1.83266e-02
I0216 16:18:51.539197 23126066861888 run_lib.py:133] step: 441800, training_loss: 1.83211e-02
I0216 16:18:51.708308 23126066861888 run_lib.py:146] step: 441800, eval_loss: 2.90081e-02
I0216 16:19:09.278041 23126066861888 run_lib.py:133] step: 441850, training_loss: 1.77728e-02
I0216 16:19:26.807421 23126066861888 run_lib.py:133] step: 441900, training_loss: 1.78632e-02
I0216 16:19:26.968203 23126066861888 run_lib.py:146] step: 441900, eval_loss: 2.96813e-02
I0216 16:19:44.735488 23126066861888 run_lib.py:133] step: 441950, training_loss: 1.73716e-02
I0216 16:20:02.241717 23126066861888 run_lib.py:133] step: 442000, training_loss: 1.72680e-02
I0216 16:20:02.435152 23126066861888 run_lib.py:146] step: 442000, eval_loss: 2.83920e-02
I0216 16:20:19.986291 23126066861888 run_lib.py:133] step: 442050, training_loss: 1.69913e-02
I0216 16:20:37.769663 23126066861888 run_lib.py:133] step: 442100, training_loss: 1.74119e-02
I0216 16:20:37.935436 23126066861888 run_lib.py:146] step: 442100, eval_loss: 2.78700e-02
I0216 16:20:55.513567 23126066861888 run_lib.py:133] step: 442150, training_loss: 1.77862e-02
I0216 16:21:13.050555 23126066861888 run_lib.py:133] step: 442200, training_loss: 1.70423e-02
I0216 16:21:13.216455 23126066861888 run_lib.py:146] step: 442200, eval_loss: 2.70567e-02
I0216 16:21:30.803840 23126066861888 run_lib.py:133] step: 442250, training_loss: 1.77508e-02
I0216 16:21:48.318118 23126066861888 run_lib.py:133] step: 442300, training_loss: 1.79321e-02
I0216 16:21:48.478238 23126066861888 run_lib.py:146] step: 442300, eval_loss: 2.90573e-02
I0216 16:22:06.010476 23126066861888 run_lib.py:133] step: 442350, training_loss: 1.72576e-02
I0216 16:22:23.547608 23126066861888 run_lib.py:133] step: 442400, training_loss: 1.69435e-02
I0216 16:22:23.706487 23126066861888 run_lib.py:146] step: 442400, eval_loss: 2.78681e-02
I0216 16:22:41.459260 23126066861888 run_lib.py:133] step: 442450, training_loss: 1.77510e-02
I0216 16:22:59.052677 23126066861888 run_lib.py:133] step: 442500, training_loss: 1.75132e-02
I0216 16:22:59.205963 23126066861888 run_lib.py:146] step: 442500, eval_loss: 2.91123e-02
I0216 16:23:16.725221 23126066861888 run_lib.py:133] step: 442550, training_loss: 1.72517e-02
I0216 16:23:34.234485 23126066861888 run_lib.py:133] step: 442600, training_loss: 1.78536e-02
I0216 16:23:34.401472 23126066861888 run_lib.py:146] step: 442600, eval_loss: 2.90016e-02
I0216 16:23:52.130225 23126066861888 run_lib.py:133] step: 442650, training_loss: 1.76652e-02
I0216 16:24:09.690472 23126066861888 run_lib.py:133] step: 442700, training_loss: 1.73174e-02
I0216 16:24:09.851194 23126066861888 run_lib.py:146] step: 442700, eval_loss: 2.69700e-02
I0216 16:24:27.359755 23126066861888 run_lib.py:133] step: 442750, training_loss: 1.72212e-02
I0216 16:24:45.047964 23126066861888 run_lib.py:133] step: 442800, training_loss: 1.72948e-02
I0216 16:24:45.206259 23126066861888 run_lib.py:146] step: 442800, eval_loss: 2.79468e-02
I0216 16:25:02.726566 23126066861888 run_lib.py:133] step: 442850, training_loss: 1.69765e-02
I0216 16:25:20.378012 23126066861888 run_lib.py:133] step: 442900, training_loss: 1.69507e-02
I0216 16:25:20.537441 23126066861888 run_lib.py:146] step: 442900, eval_loss: 2.79532e-02
I0216 16:25:38.126476 23126066861888 run_lib.py:133] step: 442950, training_loss: 1.81624e-02
I0216 16:25:55.655483 23126066861888 run_lib.py:133] step: 443000, training_loss: 1.71672e-02
I0216 16:25:55.811418 23126066861888 run_lib.py:146] step: 443000, eval_loss: 2.86449e-02
I0216 16:26:13.540855 23126066861888 run_lib.py:133] step: 443050, training_loss: 1.71311e-02
I0216 16:26:31.052099 23126066861888 run_lib.py:133] step: 443100, training_loss: 1.74876e-02
I0216 16:26:31.206692 23126066861888 run_lib.py:146] step: 443100, eval_loss: 2.84750e-02
I0216 16:26:48.703729 23126066861888 run_lib.py:133] step: 443150, training_loss: 1.73955e-02
I0216 16:27:06.368557 23126066861888 run_lib.py:133] step: 443200, training_loss: 1.71879e-02
I0216 16:27:06.534113 23126066861888 run_lib.py:146] step: 443200, eval_loss: 2.79524e-02
I0216 16:27:24.111440 23126066861888 run_lib.py:133] step: 443250, training_loss: 1.74255e-02
I0216 16:27:41.676532 23126066861888 run_lib.py:133] step: 443300, training_loss: 1.81152e-02
I0216 16:27:41.835415 23126066861888 run_lib.py:146] step: 443300, eval_loss: 2.87107e-02
I0216 16:27:59.502745 23126066861888 run_lib.py:133] step: 443350, training_loss: 1.74187e-02
I0216 16:28:16.976166 23126066861888 run_lib.py:133] step: 443400, training_loss: 1.79658e-02
I0216 16:28:17.133238 23126066861888 run_lib.py:146] step: 443400, eval_loss: 2.76833e-02
I0216 16:28:34.635436 23126066861888 run_lib.py:133] step: 443450, training_loss: 1.72837e-02
I0216 16:28:52.189871 23126066861888 run_lib.py:133] step: 443500, training_loss: 1.76550e-02
I0216 16:28:52.349398 23126066861888 run_lib.py:146] step: 443500, eval_loss: 2.90360e-02
I0216 16:29:10.082659 23126066861888 run_lib.py:133] step: 443550, training_loss: 1.77568e-02
I0216 16:29:27.756094 23126066861888 run_lib.py:133] step: 443600, training_loss: 1.75062e-02
I0216 16:29:27.918176 23126066861888 run_lib.py:146] step: 443600, eval_loss: 2.86427e-02
I0216 16:29:45.410125 23126066861888 run_lib.py:133] step: 443650, training_loss: 1.78032e-02
I0216 16:30:02.910265 23126066861888 run_lib.py:133] step: 443700, training_loss: 1.73403e-02
I0216 16:30:03.067154 23126066861888 run_lib.py:146] step: 443700, eval_loss: 2.70901e-02
I0216 16:30:20.831971 23126066861888 run_lib.py:133] step: 443750, training_loss: 1.81122e-02
I0216 16:30:38.364172 23126066861888 run_lib.py:133] step: 443800, training_loss: 1.82790e-02
I0216 16:30:38.528022 23126066861888 run_lib.py:146] step: 443800, eval_loss: 2.76790e-02
I0216 16:30:56.059405 23126066861888 run_lib.py:133] step: 443850, training_loss: 1.70125e-02
I0216 16:31:13.780043 23126066861888 run_lib.py:133] step: 443900, training_loss: 1.73272e-02
I0216 16:31:13.934949 23126066861888 run_lib.py:146] step: 443900, eval_loss: 2.75395e-02
I0216 16:31:31.433498 23126066861888 run_lib.py:133] step: 443950, training_loss: 1.81395e-02
I0216 16:31:49.156464 23126066861888 run_lib.py:133] step: 444000, training_loss: 1.81331e-02
I0216 16:31:49.320225 23126066861888 run_lib.py:146] step: 444000, eval_loss: 2.80694e-02
I0216 16:32:06.833273 23126066861888 run_lib.py:133] step: 444050, training_loss: 1.72106e-02
I0216 16:32:24.394253 23126066861888 run_lib.py:133] step: 444100, training_loss: 1.76562e-02
I0216 16:32:24.573126 23126066861888 run_lib.py:146] step: 444100, eval_loss: 2.82871e-02
I0216 16:32:42.286230 23126066861888 run_lib.py:133] step: 444150, training_loss: 1.84259e-02
I0216 16:32:59.780488 23126066861888 run_lib.py:133] step: 444200, training_loss: 1.71241e-02
I0216 16:32:59.938646 23126066861888 run_lib.py:146] step: 444200, eval_loss: 2.77657e-02
I0216 16:33:17.421714 23126066861888 run_lib.py:133] step: 444250, training_loss: 1.77206e-02
I0216 16:33:35.180783 23126066861888 run_lib.py:133] step: 444300, training_loss: 1.72268e-02
I0216 16:33:35.343066 23126066861888 run_lib.py:146] step: 444300, eval_loss: 2.83686e-02
I0216 16:33:52.853283 23126066861888 run_lib.py:133] step: 444350, training_loss: 1.77674e-02
I0216 16:34:10.420291 23126066861888 run_lib.py:133] step: 444400, training_loss: 1.74604e-02
I0216 16:34:10.576487 23126066861888 run_lib.py:146] step: 444400, eval_loss: 2.78193e-02
I0216 16:34:28.251635 23126066861888 run_lib.py:133] step: 444450, training_loss: 1.73578e-02
I0216 16:34:45.769536 23126066861888 run_lib.py:133] step: 444500, training_loss: 1.73371e-02
I0216 16:34:45.927146 23126066861888 run_lib.py:146] step: 444500, eval_loss: 2.83792e-02
I0216 16:35:03.392877 23126066861888 run_lib.py:133] step: 444550, training_loss: 1.76177e-02
I0216 16:35:20.884714 23126066861888 run_lib.py:133] step: 444600, training_loss: 1.78698e-02
I0216 16:35:21.049207 23126066861888 run_lib.py:146] step: 444600, eval_loss: 2.78139e-02
I0216 16:35:38.788271 23126066861888 run_lib.py:133] step: 444650, training_loss: 1.76054e-02
I0216 16:35:56.474770 23126066861888 run_lib.py:133] step: 444700, training_loss: 1.74957e-02
I0216 16:35:56.632441 23126066861888 run_lib.py:146] step: 444700, eval_loss: 2.74794e-02
I0216 16:36:14.099887 23126066861888 run_lib.py:133] step: 444750, training_loss: 1.70682e-02
I0216 16:36:31.550375 23126066861888 run_lib.py:133] step: 444800, training_loss: 1.73390e-02
I0216 16:36:31.734235 23126066861888 run_lib.py:146] step: 444800, eval_loss: 2.86753e-02
I0216 16:36:49.389497 23126066861888 run_lib.py:133] step: 444850, training_loss: 1.80192e-02
I0216 16:37:06.936980 23126066861888 run_lib.py:133] step: 444900, training_loss: 1.77753e-02
I0216 16:37:07.093538 23126066861888 run_lib.py:146] step: 444900, eval_loss: 2.76021e-02
I0216 16:37:24.634699 23126066861888 run_lib.py:133] step: 444950, training_loss: 1.73200e-02
I0216 16:37:42.377228 23126066861888 run_lib.py:133] step: 445000, training_loss: 1.71913e-02
I0216 16:37:42.538126 23126066861888 run_lib.py:146] step: 445000, eval_loss: 2.87547e-02
I0216 16:38:00.032430 23126066861888 run_lib.py:133] step: 445050, training_loss: 1.66190e-02
I0216 16:38:17.737082 23126066861888 run_lib.py:133] step: 445100, training_loss: 1.74539e-02
I0216 16:38:17.901982 23126066861888 run_lib.py:146] step: 445100, eval_loss: 2.88515e-02
I0216 16:38:35.402513 23126066861888 run_lib.py:133] step: 445150, training_loss: 1.77755e-02
I0216 16:38:52.890075 23126066861888 run_lib.py:133] step: 445200, training_loss: 1.73238e-02
I0216 16:38:53.063134 23126066861888 run_lib.py:146] step: 445200, eval_loss: 2.63619e-02
I0216 16:39:10.774625 23126066861888 run_lib.py:133] step: 445250, training_loss: 1.75641e-02
I0216 16:39:28.357679 23126066861888 run_lib.py:133] step: 445300, training_loss: 1.78941e-02
I0216 16:39:28.512857 23126066861888 run_lib.py:146] step: 445300, eval_loss: 2.85282e-02
I0216 16:39:46.034809 23126066861888 run_lib.py:133] step: 445350, training_loss: 1.73681e-02
I0216 16:40:03.727682 23126066861888 run_lib.py:133] step: 445400, training_loss: 1.82438e-02
I0216 16:40:03.886278 23126066861888 run_lib.py:146] step: 445400, eval_loss: 2.83871e-02
I0216 16:40:21.392405 23126066861888 run_lib.py:133] step: 445450, training_loss: 1.82936e-02
I0216 16:40:38.915950 23126066861888 run_lib.py:133] step: 445500, training_loss: 1.83520e-02
I0216 16:40:39.093061 23126066861888 run_lib.py:146] step: 445500, eval_loss: 2.81066e-02
I0216 16:40:56.688944 23126066861888 run_lib.py:133] step: 445550, training_loss: 1.61948e-02
I0216 16:41:14.202996 23126066861888 run_lib.py:133] step: 445600, training_loss: 1.83973e-02
I0216 16:41:14.360396 23126066861888 run_lib.py:146] step: 445600, eval_loss: 2.88322e-02
I0216 16:41:31.835465 23126066861888 run_lib.py:133] step: 445650, training_loss: 1.72330e-02
I0216 16:41:49.318581 23126066861888 run_lib.py:133] step: 445700, training_loss: 1.71658e-02
I0216 16:41:49.474072 23126066861888 run_lib.py:146] step: 445700, eval_loss: 2.70803e-02
I0216 16:42:07.162536 23126066861888 run_lib.py:133] step: 445750, training_loss: 1.74236e-02
I0216 16:42:24.838937 23126066861888 run_lib.py:133] step: 445800, training_loss: 1.77719e-02
I0216 16:42:24.993928 23126066861888 run_lib.py:146] step: 445800, eval_loss: 2.86631e-02
I0216 16:42:42.592598 23126066861888 run_lib.py:133] step: 445850, training_loss: 1.80642e-02
I0216 16:43:00.132811 23126066861888 run_lib.py:133] step: 445900, training_loss: 1.70746e-02
I0216 16:43:00.289239 23126066861888 run_lib.py:146] step: 445900, eval_loss: 2.86547e-02
I0216 16:43:17.977958 23126066861888 run_lib.py:133] step: 445950, training_loss: 1.79666e-02
I0216 16:43:35.490755 23126066861888 run_lib.py:133] step: 446000, training_loss: 1.79821e-02
I0216 16:43:35.650346 23126066861888 run_lib.py:146] step: 446000, eval_loss: 2.87331e-02
I0216 16:43:53.191785 23126066861888 run_lib.py:133] step: 446050, training_loss: 1.76601e-02
I0216 16:44:10.933737 23126066861888 run_lib.py:133] step: 446100, training_loss: 1.70448e-02
I0216 16:44:11.093455 23126066861888 run_lib.py:146] step: 446100, eval_loss: 2.87683e-02
I0216 16:44:28.643334 23126066861888 run_lib.py:133] step: 446150, training_loss: 1.82949e-02
I0216 16:44:46.335576 23126066861888 run_lib.py:133] step: 446200, training_loss: 1.72482e-02
I0216 16:44:46.489223 23126066861888 run_lib.py:146] step: 446200, eval_loss: 2.81582e-02
I0216 16:45:04.021771 23126066861888 run_lib.py:133] step: 446250, training_loss: 1.73114e-02
I0216 16:45:21.545992 23126066861888 run_lib.py:133] step: 446300, training_loss: 1.75391e-02
I0216 16:45:21.706203 23126066861888 run_lib.py:146] step: 446300, eval_loss: 2.86381e-02
I0216 16:45:39.399450 23126066861888 run_lib.py:133] step: 446350, training_loss: 1.70845e-02
I0216 16:45:56.933010 23126066861888 run_lib.py:133] step: 446400, training_loss: 1.69220e-02
I0216 16:45:57.115353 23126066861888 run_lib.py:146] step: 446400, eval_loss: 2.78157e-02
I0216 16:46:14.685228 23126066861888 run_lib.py:133] step: 446450, training_loss: 1.70887e-02
I0216 16:46:32.427541 23126066861888 run_lib.py:133] step: 446500, training_loss: 1.80935e-02
I0216 16:46:32.588455 23126066861888 run_lib.py:146] step: 446500, eval_loss: 2.83154e-02
I0216 16:46:50.076506 23126066861888 run_lib.py:133] step: 446550, training_loss: 1.74080e-02
I0216 16:47:07.578446 23126066861888 run_lib.py:133] step: 446600, training_loss: 1.77508e-02
I0216 16:47:07.746179 23126066861888 run_lib.py:146] step: 446600, eval_loss: 2.88048e-02
I0216 16:47:25.416505 23126066861888 run_lib.py:133] step: 446650, training_loss: 1.72479e-02
I0216 16:47:42.930612 23126066861888 run_lib.py:133] step: 446700, training_loss: 1.82502e-02
I0216 16:47:43.087392 23126066861888 run_lib.py:146] step: 446700, eval_loss: 2.82598e-02
I0216 16:48:00.619408 23126066861888 run_lib.py:133] step: 446750, training_loss: 1.77768e-02
I0216 16:48:18.089588 23126066861888 run_lib.py:133] step: 446800, training_loss: 1.78872e-02
I0216 16:48:18.252082 23126066861888 run_lib.py:146] step: 446800, eval_loss: 2.88618e-02
I0216 16:48:35.966450 23126066861888 run_lib.py:133] step: 446850, training_loss: 1.78654e-02
I0216 16:48:53.585693 23126066861888 run_lib.py:133] step: 446900, training_loss: 1.70590e-02
I0216 16:48:53.757289 23126066861888 run_lib.py:146] step: 446900, eval_loss: 2.84777e-02
I0216 16:49:11.336038 23126066861888 run_lib.py:133] step: 446950, training_loss: 1.79896e-02
I0216 16:49:28.867041 23126066861888 run_lib.py:133] step: 447000, training_loss: 1.76638e-02
I0216 16:49:29.025698 23126066861888 run_lib.py:146] step: 447000, eval_loss: 2.83302e-02
I0216 16:49:46.743875 23126066861888 run_lib.py:133] step: 447050, training_loss: 1.71746e-02
I0216 16:50:04.232675 23126066861888 run_lib.py:133] step: 447100, training_loss: 1.74345e-02
I0216 16:50:04.389121 23126066861888 run_lib.py:146] step: 447100, eval_loss: 2.70635e-02
I0216 16:50:21.877982 23126066861888 run_lib.py:133] step: 447150, training_loss: 1.79255e-02
I0216 16:50:39.620199 23126066861888 run_lib.py:133] step: 447200, training_loss: 1.78293e-02
I0216 16:50:39.775890 23126066861888 run_lib.py:146] step: 447200, eval_loss: 2.80612e-02
I0216 16:50:57.321594 23126066861888 run_lib.py:133] step: 447250, training_loss: 1.75705e-02
I0216 16:51:15.010061 23126066861888 run_lib.py:133] step: 447300, training_loss: 1.76145e-02
I0216 16:51:15.165066 23126066861888 run_lib.py:146] step: 447300, eval_loss: 2.85548e-02
I0216 16:51:32.654403 23126066861888 run_lib.py:133] step: 447350, training_loss: 1.81433e-02
I0216 16:51:50.137653 23126066861888 run_lib.py:133] step: 447400, training_loss: 1.77060e-02
I0216 16:51:50.298363 23126066861888 run_lib.py:146] step: 447400, eval_loss: 2.93698e-02
I0216 16:52:07.963137 23126066861888 run_lib.py:133] step: 447450, training_loss: 1.70635e-02
I0216 16:52:25.504376 23126066861888 run_lib.py:133] step: 447500, training_loss: 1.68919e-02
I0216 16:52:25.665395 23126066861888 run_lib.py:146] step: 447500, eval_loss: 2.89163e-02
I0216 16:52:43.168498 23126066861888 run_lib.py:133] step: 447550, training_loss: 1.76782e-02
I0216 16:53:00.889593 23126066861888 run_lib.py:133] step: 447600, training_loss: 1.79684e-02
I0216 16:53:01.046466 23126066861888 run_lib.py:146] step: 447600, eval_loss: 2.81994e-02
I0216 16:53:18.578395 23126066861888 run_lib.py:133] step: 447650, training_loss: 1.69628e-02
I0216 16:53:36.093477 23126066861888 run_lib.py:133] step: 447700, training_loss: 1.73577e-02
I0216 16:53:36.249225 23126066861888 run_lib.py:146] step: 447700, eval_loss: 2.80453e-02
I0216 16:53:53.818698 23126066861888 run_lib.py:133] step: 447750, training_loss: 1.77581e-02
I0216 16:54:11.353036 23126066861888 run_lib.py:133] step: 447800, training_loss: 1.74600e-02
I0216 16:54:11.519493 23126066861888 run_lib.py:146] step: 447800, eval_loss: 2.79365e-02
I0216 16:54:29.046671 23126066861888 run_lib.py:133] step: 447850, training_loss: 1.79997e-02
I0216 16:54:46.574149 23126066861888 run_lib.py:133] step: 447900, training_loss: 1.72341e-02
I0216 16:54:46.779155 23126066861888 run_lib.py:146] step: 447900, eval_loss: 2.86999e-02
I0216 16:55:04.438542 23126066861888 run_lib.py:133] step: 447950, training_loss: 1.79155e-02
I0216 16:55:22.016496 23126066861888 run_lib.py:133] step: 448000, training_loss: 1.73800e-02
I0216 16:55:22.191226 23126066861888 run_lib.py:146] step: 448000, eval_loss: 2.78732e-02
I0216 16:55:39.710673 23126066861888 run_lib.py:133] step: 448050, training_loss: 1.72546e-02
I0216 16:55:57.254867 23126066861888 run_lib.py:133] step: 448100, training_loss: 1.78196e-02
I0216 16:55:57.416099 23126066861888 run_lib.py:146] step: 448100, eval_loss: 2.79240e-02
I0216 16:56:15.119838 23126066861888 run_lib.py:133] step: 448150, training_loss: 1.76085e-02
I0216 16:56:32.613206 23126066861888 run_lib.py:133] step: 448200, training_loss: 1.71199e-02
I0216 16:56:32.775128 23126066861888 run_lib.py:146] step: 448200, eval_loss: 2.79981e-02
I0216 16:56:50.253232 23126066861888 run_lib.py:133] step: 448250, training_loss: 1.68024e-02
I0216 16:57:07.905454 23126066861888 run_lib.py:133] step: 448300, training_loss: 1.72161e-02
I0216 16:57:08.066344 23126066861888 run_lib.py:146] step: 448300, eval_loss: 2.85676e-02
I0216 16:57:25.594255 23126066861888 run_lib.py:133] step: 448350, training_loss: 1.74746e-02
I0216 16:57:43.314292 23126066861888 run_lib.py:133] step: 448400, training_loss: 1.77667e-02
I0216 16:57:43.471732 23126066861888 run_lib.py:146] step: 448400, eval_loss: 2.82728e-02
I0216 16:58:00.939872 23126066861888 run_lib.py:133] step: 448450, training_loss: 1.70663e-02
I0216 16:58:18.424540 23126066861888 run_lib.py:133] step: 448500, training_loss: 1.73900e-02
I0216 16:58:18.581196 23126066861888 run_lib.py:146] step: 448500, eval_loss: 2.82813e-02
I0216 16:58:36.287142 23126066861888 run_lib.py:133] step: 448550, training_loss: 1.80595e-02
I0216 16:58:53.787936 23126066861888 run_lib.py:133] step: 448600, training_loss: 1.74000e-02
I0216 16:58:53.941103 23126066861888 run_lib.py:146] step: 448600, eval_loss: 2.84600e-02
I0216 16:59:11.520127 23126066861888 run_lib.py:133] step: 448650, training_loss: 1.74087e-02
I0216 16:59:29.232065 23126066861888 run_lib.py:133] step: 448700, training_loss: 1.69292e-02
I0216 16:59:29.387135 23126066861888 run_lib.py:146] step: 448700, eval_loss: 2.97427e-02
I0216 16:59:46.879794 23126066861888 run_lib.py:133] step: 448750, training_loss: 1.80293e-02
I0216 17:00:04.390186 23126066861888 run_lib.py:133] step: 448800, training_loss: 1.76332e-02
I0216 17:00:04.556433 23126066861888 run_lib.py:146] step: 448800, eval_loss: 2.85727e-02
I0216 17:00:22.124256 23126066861888 run_lib.py:133] step: 448850, training_loss: 1.76235e-02
I0216 17:00:39.709894 23126066861888 run_lib.py:133] step: 448900, training_loss: 1.71510e-02
I0216 17:00:39.889761 23126066861888 run_lib.py:146] step: 448900, eval_loss: 2.77158e-02
I0216 17:00:57.463493 23126066861888 run_lib.py:133] step: 448950, training_loss: 1.81581e-02
I0216 17:01:14.972943 23126066861888 run_lib.py:133] step: 449000, training_loss: 1.79095e-02
I0216 17:01:15.129848 23126066861888 run_lib.py:146] step: 449000, eval_loss: 2.82662e-02
I0216 17:01:32.872097 23126066861888 run_lib.py:133] step: 449050, training_loss: 1.74265e-02
I0216 17:01:50.445801 23126066861888 run_lib.py:133] step: 449100, training_loss: 1.73415e-02
I0216 17:01:50.601181 23126066861888 run_lib.py:146] step: 449100, eval_loss: 2.88075e-02
I0216 17:02:08.123621 23126066861888 run_lib.py:133] step: 449150, training_loss: 1.76031e-02
I0216 17:02:25.680740 23126066861888 run_lib.py:133] step: 449200, training_loss: 1.71012e-02
I0216 17:02:25.843460 23126066861888 run_lib.py:146] step: 449200, eval_loss: 2.78433e-02
I0216 17:02:43.578579 23126066861888 run_lib.py:133] step: 449250, training_loss: 1.71880e-02
I0216 17:03:01.076707 23126066861888 run_lib.py:133] step: 449300, training_loss: 1.76479e-02
I0216 17:03:01.234174 23126066861888 run_lib.py:146] step: 449300, eval_loss: 2.92711e-02
I0216 17:03:18.719057 23126066861888 run_lib.py:133] step: 449350, training_loss: 1.73106e-02
I0216 17:03:36.423208 23126066861888 run_lib.py:133] step: 449400, training_loss: 1.74421e-02
I0216 17:03:36.580211 23126066861888 run_lib.py:146] step: 449400, eval_loss: 2.96580e-02
I0216 17:03:54.084245 23126066861888 run_lib.py:133] step: 449450, training_loss: 1.75047e-02
I0216 17:04:11.806237 23126066861888 run_lib.py:133] step: 449500, training_loss: 1.74761e-02
I0216 17:04:11.964617 23126066861888 run_lib.py:146] step: 449500, eval_loss: 2.86121e-02
I0216 17:04:29.468780 23126066861888 run_lib.py:133] step: 449550, training_loss: 1.78803e-02
I0216 17:04:46.932529 23126066861888 run_lib.py:133] step: 449600, training_loss: 1.71156e-02
I0216 17:04:47.103915 23126066861888 run_lib.py:146] step: 449600, eval_loss: 2.77099e-02
I0216 17:05:04.806635 23126066861888 run_lib.py:133] step: 449650, training_loss: 1.65603e-02
I0216 17:05:22.337245 23126066861888 run_lib.py:133] step: 449700, training_loss: 1.68818e-02
I0216 17:05:22.510382 23126066861888 run_lib.py:146] step: 449700, eval_loss: 2.76381e-02
I0216 17:05:40.065867 23126066861888 run_lib.py:133] step: 449750, training_loss: 1.81995e-02
I0216 17:05:57.844221 23126066861888 run_lib.py:133] step: 449800, training_loss: 1.74680e-02
I0216 17:05:58.003017 23126066861888 run_lib.py:146] step: 449800, eval_loss: 2.87337e-02
I0216 17:06:15.500681 23126066861888 run_lib.py:133] step: 449850, training_loss: 1.82273e-02
I0216 17:06:32.996079 23126066861888 run_lib.py:133] step: 449900, training_loss: 1.74632e-02
I0216 17:06:33.152545 23126066861888 run_lib.py:146] step: 449900, eval_loss: 2.77276e-02
I0216 17:06:50.803763 23126066861888 run_lib.py:133] step: 449950, training_loss: 1.74065e-02
I0216 17:07:08.368369 23126066861888 run_lib.py:133] step: 450000, training_loss: 1.77211e-02
I0216 17:07:09.279235 23126066861888 run_lib.py:146] step: 450000, eval_loss: 2.81490e-02
I0216 17:07:29.935365 23126066861888 run_lib.py:133] step: 450050, training_loss: 1.75937e-02
I0216 17:07:47.397671 23126066861888 run_lib.py:133] step: 450100, training_loss: 1.78562e-02
I0216 17:07:47.553186 23126066861888 run_lib.py:146] step: 450100, eval_loss: 2.88747e-02
I0216 17:08:05.026908 23126066861888 run_lib.py:133] step: 450150, training_loss: 1.83566e-02
I0216 17:08:22.786249 23126066861888 run_lib.py:133] step: 450200, training_loss: 1.69226e-02
I0216 17:08:22.939162 23126066861888 run_lib.py:146] step: 450200, eval_loss: 2.77380e-02
I0216 17:08:40.548487 23126066861888 run_lib.py:133] step: 450250, training_loss: 1.72305e-02
I0216 17:08:58.054146 23126066861888 run_lib.py:133] step: 450300, training_loss: 1.69098e-02
I0216 17:08:58.216247 23126066861888 run_lib.py:146] step: 450300, eval_loss: 2.76004e-02
I0216 17:09:15.772248 23126066861888 run_lib.py:133] step: 450350, training_loss: 1.77580e-02
I0216 17:09:33.242529 23126066861888 run_lib.py:133] step: 450400, training_loss: 1.80146e-02
I0216 17:09:33.399388 23126066861888 run_lib.py:146] step: 450400, eval_loss: 2.78636e-02
I0216 17:09:51.102185 23126066861888 run_lib.py:133] step: 450450, training_loss: 1.78548e-02
I0216 17:10:08.572020 23126066861888 run_lib.py:133] step: 450500, training_loss: 1.72271e-02
I0216 17:10:08.730175 23126066861888 run_lib.py:146] step: 450500, eval_loss: 2.80148e-02
I0216 17:10:26.431251 23126066861888 run_lib.py:133] step: 450550, training_loss: 1.77902e-02
I0216 17:10:43.984776 23126066861888 run_lib.py:133] step: 450600, training_loss: 1.75977e-02
I0216 17:10:44.140954 23126066861888 run_lib.py:146] step: 450600, eval_loss: 2.77815e-02
I0216 17:11:01.859963 23126066861888 run_lib.py:133] step: 450650, training_loss: 1.74299e-02
I0216 17:11:19.379023 23126066861888 run_lib.py:133] step: 450700, training_loss: 1.69267e-02
I0216 17:11:19.534226 23126066861888 run_lib.py:146] step: 450700, eval_loss: 2.79402e-02
I0216 17:11:37.016739 23126066861888 run_lib.py:133] step: 450750, training_loss: 1.76475e-02
I0216 17:11:54.683178 23126066861888 run_lib.py:133] step: 450800, training_loss: 1.68695e-02
I0216 17:11:54.856276 23126066861888 run_lib.py:146] step: 450800, eval_loss: 2.80962e-02
I0216 17:12:12.399268 23126066861888 run_lib.py:133] step: 450850, training_loss: 1.69216e-02
I0216 17:12:30.165598 23126066861888 run_lib.py:133] step: 450900, training_loss: 1.75258e-02
I0216 17:12:30.323428 23126066861888 run_lib.py:146] step: 450900, eval_loss: 2.89279e-02
I0216 17:12:47.832507 23126066861888 run_lib.py:133] step: 450950, training_loss: 1.76857e-02
I0216 17:13:05.296845 23126066861888 run_lib.py:133] step: 451000, training_loss: 1.76007e-02
I0216 17:13:05.453241 23126066861888 run_lib.py:146] step: 451000, eval_loss: 2.78468e-02
I0216 17:13:22.971864 23126066861888 run_lib.py:133] step: 451050, training_loss: 1.76579e-02
I0216 17:13:40.676890 23126066861888 run_lib.py:133] step: 451100, training_loss: 1.77492e-02
I0216 17:13:40.832378 23126066861888 run_lib.py:146] step: 451100, eval_loss: 2.98969e-02
I0216 17:13:58.422006 23126066861888 run_lib.py:133] step: 451150, training_loss: 1.72795e-02
I0216 17:14:15.906930 23126066861888 run_lib.py:133] step: 451200, training_loss: 1.69728e-02
I0216 17:14:16.093214 23126066861888 run_lib.py:146] step: 451200, eval_loss: 2.80705e-02
I0216 17:14:33.782726 23126066861888 run_lib.py:133] step: 451250, training_loss: 1.69191e-02
I0216 17:14:51.266984 23126066861888 run_lib.py:133] step: 451300, training_loss: 1.66696e-02
I0216 17:14:51.425310 23126066861888 run_lib.py:146] step: 451300, eval_loss: 2.73943e-02
I0216 17:15:08.999498 23126066861888 run_lib.py:133] step: 451350, training_loss: 1.68720e-02
I0216 17:15:26.568249 23126066861888 run_lib.py:133] step: 451400, training_loss: 1.75772e-02
I0216 17:15:26.726445 23126066861888 run_lib.py:146] step: 451400, eval_loss: 2.85659e-02
I0216 17:15:44.232589 23126066861888 run_lib.py:133] step: 451450, training_loss: 1.78151e-02
I0216 17:16:01.743446 23126066861888 run_lib.py:133] step: 451500, training_loss: 1.77518e-02
I0216 17:16:01.907983 23126066861888 run_lib.py:146] step: 451500, eval_loss: 2.92993e-02
I0216 17:16:19.612684 23126066861888 run_lib.py:133] step: 451550, training_loss: 1.77038e-02
I0216 17:16:37.241476 23126066861888 run_lib.py:133] step: 451600, training_loss: 1.68212e-02
I0216 17:16:37.396217 23126066861888 run_lib.py:146] step: 451600, eval_loss: 2.79560e-02
I0216 17:16:54.936896 23126066861888 run_lib.py:133] step: 451650, training_loss: 1.65642e-02
I0216 17:17:12.453061 23126066861888 run_lib.py:133] step: 451700, training_loss: 1.70374e-02
I0216 17:17:12.611415 23126066861888 run_lib.py:146] step: 451700, eval_loss: 2.94602e-02
I0216 17:17:30.334481 23126066861888 run_lib.py:133] step: 451750, training_loss: 1.79885e-02
I0216 17:17:47.845281 23126066861888 run_lib.py:133] step: 451800, training_loss: 1.74163e-02
I0216 17:17:48.006439 23126066861888 run_lib.py:146] step: 451800, eval_loss: 2.86371e-02
I0216 17:18:05.542759 23126066861888 run_lib.py:133] step: 451850, training_loss: 1.81150e-02
I0216 17:18:23.201830 23126066861888 run_lib.py:133] step: 451900, training_loss: 1.76020e-02
I0216 17:18:23.375927 23126066861888 run_lib.py:146] step: 451900, eval_loss: 2.85683e-02
I0216 17:18:40.944742 23126066861888 run_lib.py:133] step: 451950, training_loss: 1.73502e-02
I0216 17:18:58.676232 23126066861888 run_lib.py:133] step: 452000, training_loss: 1.71502e-02
I0216 17:18:58.835951 23126066861888 run_lib.py:146] step: 452000, eval_loss: 2.84889e-02
I0216 17:19:16.375585 23126066861888 run_lib.py:133] step: 452050, training_loss: 1.73496e-02
I0216 17:19:33.883392 23126066861888 run_lib.py:133] step: 452100, training_loss: 1.75480e-02
I0216 17:19:34.037190 23126066861888 run_lib.py:146] step: 452100, eval_loss: 2.74340e-02
I0216 17:19:51.736588 23126066861888 run_lib.py:133] step: 452150, training_loss: 1.82335e-02
I0216 17:20:09.262447 23126066861888 run_lib.py:133] step: 452200, training_loss: 1.75195e-02
I0216 17:20:09.440201 23126066861888 run_lib.py:146] step: 452200, eval_loss: 2.84952e-02
I0216 17:20:26.945106 23126066861888 run_lib.py:133] step: 452250, training_loss: 1.80320e-02
I0216 17:20:44.454548 23126066861888 run_lib.py:133] step: 452300, training_loss: 1.74705e-02
I0216 17:20:44.610215 23126066861888 run_lib.py:146] step: 452300, eval_loss: 2.99199e-02
I0216 17:21:02.421706 23126066861888 run_lib.py:133] step: 452350, training_loss: 1.72687e-02
I0216 17:21:19.913233 23126066861888 run_lib.py:133] step: 452400, training_loss: 1.76023e-02
I0216 17:21:20.075186 23126066861888 run_lib.py:146] step: 452400, eval_loss: 2.92517e-02
I0216 17:21:37.656249 23126066861888 run_lib.py:133] step: 452450, training_loss: 1.69897e-02
I0216 17:21:55.238002 23126066861888 run_lib.py:133] step: 452500, training_loss: 1.71306e-02
I0216 17:21:55.402316 23126066861888 run_lib.py:146] step: 452500, eval_loss: 2.86234e-02
I0216 17:22:12.976307 23126066861888 run_lib.py:133] step: 452550, training_loss: 1.78852e-02
I0216 17:22:30.472586 23126066861888 run_lib.py:133] step: 452600, training_loss: 1.65200e-02
I0216 17:22:30.629214 23126066861888 run_lib.py:146] step: 452600, eval_loss: 2.78694e-02
I0216 17:22:48.399619 23126066861888 run_lib.py:133] step: 452650, training_loss: 1.74279e-02
I0216 17:23:05.985339 23126066861888 run_lib.py:133] step: 452700, training_loss: 1.64185e-02
I0216 17:23:06.146512 23126066861888 run_lib.py:146] step: 452700, eval_loss: 2.84921e-02
I0216 17:23:23.659636 23126066861888 run_lib.py:133] step: 452750, training_loss: 1.80059e-02
I0216 17:23:41.302763 23126066861888 run_lib.py:133] step: 452800, training_loss: 1.72279e-02
I0216 17:23:41.468382 23126066861888 run_lib.py:146] step: 452800, eval_loss: 2.86267e-02
I0216 17:23:59.166437 23126066861888 run_lib.py:133] step: 452850, training_loss: 1.74020e-02
I0216 17:24:16.724845 23126066861888 run_lib.py:133] step: 452900, training_loss: 1.83869e-02
I0216 17:24:16.881313 23126066861888 run_lib.py:146] step: 452900, eval_loss: 2.91429e-02
I0216 17:24:34.366623 23126066861888 run_lib.py:133] step: 452950, training_loss: 1.70478e-02
I0216 17:24:52.013414 23126066861888 run_lib.py:133] step: 453000, training_loss: 1.79975e-02
I0216 17:24:52.174884 23126066861888 run_lib.py:146] step: 453000, eval_loss: 2.74775e-02
I0216 17:25:09.685572 23126066861888 run_lib.py:133] step: 453050, training_loss: 1.68399e-02
I0216 17:25:27.427370 23126066861888 run_lib.py:133] step: 453100, training_loss: 1.77077e-02
I0216 17:25:27.602346 23126066861888 run_lib.py:146] step: 453100, eval_loss: 2.94876e-02
I0216 17:25:45.097420 23126066861888 run_lib.py:133] step: 453150, training_loss: 1.74975e-02
I0216 17:26:02.608575 23126066861888 run_lib.py:133] step: 453200, training_loss: 1.71715e-02
I0216 17:26:02.769434 23126066861888 run_lib.py:146] step: 453200, eval_loss: 2.69521e-02
I0216 17:26:20.486095 23126066861888 run_lib.py:133] step: 453250, training_loss: 1.79103e-02
I0216 17:26:37.989592 23126066861888 run_lib.py:133] step: 453300, training_loss: 1.71917e-02
I0216 17:26:38.163091 23126066861888 run_lib.py:146] step: 453300, eval_loss: 2.77249e-02
I0216 17:26:55.677651 23126066861888 run_lib.py:133] step: 453350, training_loss: 1.69705e-02
I0216 17:27:13.398785 23126066861888 run_lib.py:133] step: 453400, training_loss: 1.76811e-02
I0216 17:27:13.558145 23126066861888 run_lib.py:146] step: 453400, eval_loss: 2.83953e-02
I0216 17:27:31.073750 23126066861888 run_lib.py:133] step: 453450, training_loss: 1.72852e-02
I0216 17:27:48.586476 23126066861888 run_lib.py:133] step: 453500, training_loss: 1.76741e-02
I0216 17:27:48.740123 23126066861888 run_lib.py:146] step: 453500, eval_loss: 2.93000e-02
I0216 17:28:06.300634 23126066861888 run_lib.py:133] step: 453550, training_loss: 1.85649e-02
I0216 17:28:23.803217 23126066861888 run_lib.py:133] step: 453600, training_loss: 1.70620e-02
I0216 17:28:23.969437 23126066861888 run_lib.py:146] step: 453600, eval_loss: 2.79697e-02
I0216 17:28:41.507295 23126066861888 run_lib.py:133] step: 453650, training_loss: 1.73384e-02
I0216 17:28:59.072715 23126066861888 run_lib.py:133] step: 453700, training_loss: 1.67137e-02
I0216 17:28:59.231122 23126066861888 run_lib.py:146] step: 453700, eval_loss: 2.80677e-02
I0216 17:29:16.905794 23126066861888 run_lib.py:133] step: 453750, training_loss: 1.75567e-02
I0216 17:29:34.469418 23126066861888 run_lib.py:133] step: 453800, training_loss: 1.72503e-02
I0216 17:29:34.641233 23126066861888 run_lib.py:146] step: 453800, eval_loss: 2.64633e-02
I0216 17:29:52.146014 23126066861888 run_lib.py:133] step: 453850, training_loss: 1.70790e-02
I0216 17:30:09.719237 23126066861888 run_lib.py:133] step: 453900, training_loss: 1.75532e-02
I0216 17:30:09.876449 23126066861888 run_lib.py:146] step: 453900, eval_loss: 2.93235e-02
I0216 17:30:27.634386 23126066861888 run_lib.py:133] step: 453950, training_loss: 1.65488e-02
I0216 17:30:45.112707 23126066861888 run_lib.py:133] step: 454000, training_loss: 1.76157e-02
I0216 17:30:45.267167 23126066861888 run_lib.py:146] step: 454000, eval_loss: 2.87096e-02
I0216 17:31:02.752297 23126066861888 run_lib.py:133] step: 454050, training_loss: 1.74161e-02
I0216 17:31:20.451884 23126066861888 run_lib.py:133] step: 454100, training_loss: 1.76743e-02
I0216 17:31:20.616145 23126066861888 run_lib.py:146] step: 454100, eval_loss: 2.89242e-02
I0216 17:31:38.222834 23126066861888 run_lib.py:133] step: 454150, training_loss: 1.74241e-02
I0216 17:31:55.990911 23126066861888 run_lib.py:133] step: 454200, training_loss: 1.73483e-02
I0216 17:31:56.148406 23126066861888 run_lib.py:146] step: 454200, eval_loss: 2.85295e-02
I0216 17:32:13.628424 23126066861888 run_lib.py:133] step: 454250, training_loss: 1.74919e-02
I0216 17:32:31.127516 23126066861888 run_lib.py:133] step: 454300, training_loss: 1.73675e-02
I0216 17:32:31.284597 23126066861888 run_lib.py:146] step: 454300, eval_loss: 2.86117e-02
I0216 17:32:48.995587 23126066861888 run_lib.py:133] step: 454350, training_loss: 1.73142e-02
I0216 17:33:06.545249 23126066861888 run_lib.py:133] step: 454400, training_loss: 1.71151e-02
I0216 17:33:06.703714 23126066861888 run_lib.py:146] step: 454400, eval_loss: 2.90872e-02
I0216 17:33:24.263624 23126066861888 run_lib.py:133] step: 454450, training_loss: 1.74550e-02
I0216 17:33:41.991500 23126066861888 run_lib.py:133] step: 454500, training_loss: 1.74427e-02
I0216 17:33:42.152645 23126066861888 run_lib.py:146] step: 454500, eval_loss: 2.88806e-02
I0216 17:33:59.646322 23126066861888 run_lib.py:133] step: 454550, training_loss: 1.75622e-02
I0216 17:34:17.158413 23126066861888 run_lib.py:133] step: 454600, training_loss: 1.71384e-02
I0216 17:34:17.320544 23126066861888 run_lib.py:146] step: 454600, eval_loss: 2.75161e-02
I0216 17:34:34.887260 23126066861888 run_lib.py:133] step: 454650, training_loss: 1.80653e-02
I0216 17:34:52.371795 23126066861888 run_lib.py:133] step: 454700, training_loss: 1.73757e-02
I0216 17:34:52.540215 23126066861888 run_lib.py:146] step: 454700, eval_loss: 2.89666e-02
I0216 17:35:10.072616 23126066861888 run_lib.py:133] step: 454750, training_loss: 1.86691e-02
I0216 17:35:27.648330 23126066861888 run_lib.py:133] step: 454800, training_loss: 1.71537e-02
I0216 17:35:27.809614 23126066861888 run_lib.py:146] step: 454800, eval_loss: 2.88046e-02
I0216 17:35:45.548233 23126066861888 run_lib.py:133] step: 454850, training_loss: 1.73065e-02
I0216 17:36:03.105927 23126066861888 run_lib.py:133] step: 454900, training_loss: 1.73474e-02
I0216 17:36:03.259233 23126066861888 run_lib.py:146] step: 454900, eval_loss: 2.81714e-02
I0216 17:36:20.761642 23126066861888 run_lib.py:133] step: 454950, training_loss: 1.71478e-02
I0216 17:36:38.272586 23126066861888 run_lib.py:133] step: 455000, training_loss: 1.72343e-02
I0216 17:36:38.442412 23126066861888 run_lib.py:146] step: 455000, eval_loss: 2.72783e-02
I0216 17:36:56.183450 23126066861888 run_lib.py:133] step: 455050, training_loss: 1.71482e-02
I0216 17:37:13.719840 23126066861888 run_lib.py:133] step: 455100, training_loss: 1.71112e-02
I0216 17:37:13.879137 23126066861888 run_lib.py:146] step: 455100, eval_loss: 2.75224e-02
I0216 17:37:31.368579 23126066861888 run_lib.py:133] step: 455150, training_loss: 1.77906e-02
I0216 17:37:49.079802 23126066861888 run_lib.py:133] step: 455200, training_loss: 1.70138e-02
I0216 17:37:49.241145 23126066861888 run_lib.py:146] step: 455200, eval_loss: 2.73208e-02
I0216 17:38:06.746319 23126066861888 run_lib.py:133] step: 455250, training_loss: 1.80108e-02
I0216 17:38:24.532577 23126066861888 run_lib.py:133] step: 455300, training_loss: 1.71551e-02
I0216 17:38:24.690468 23126066861888 run_lib.py:146] step: 455300, eval_loss: 2.77569e-02
I0216 17:38:42.243854 23126066861888 run_lib.py:133] step: 455350, training_loss: 1.74205e-02
I0216 17:38:59.725996 23126066861888 run_lib.py:133] step: 455400, training_loss: 1.66589e-02
I0216 17:38:59.886167 23126066861888 run_lib.py:146] step: 455400, eval_loss: 2.87097e-02
I0216 17:39:17.581357 23126066861888 run_lib.py:133] step: 455450, training_loss: 1.73433e-02
I0216 17:39:35.070651 23126066861888 run_lib.py:133] step: 455500, training_loss: 1.74300e-02
I0216 17:39:35.228096 23126066861888 run_lib.py:146] step: 455500, eval_loss: 2.78485e-02
I0216 17:39:52.740406 23126066861888 run_lib.py:133] step: 455550, training_loss: 1.82809e-02
I0216 17:40:10.513581 23126066861888 run_lib.py:133] step: 455600, training_loss: 1.75770e-02
I0216 17:40:10.673122 23126066861888 run_lib.py:146] step: 455600, eval_loss: 2.78542e-02
I0216 17:40:28.211133 23126066861888 run_lib.py:133] step: 455650, training_loss: 1.74454e-02
I0216 17:40:45.712639 23126066861888 run_lib.py:133] step: 455700, training_loss: 1.68772e-02
I0216 17:40:45.872180 23126066861888 run_lib.py:146] step: 455700, eval_loss: 2.84761e-02
I0216 17:41:03.505230 23126066861888 run_lib.py:133] step: 455750, training_loss: 1.78911e-02
I0216 17:41:20.982378 23126066861888 run_lib.py:133] step: 455800, training_loss: 1.75823e-02
I0216 17:41:21.139191 23126066861888 run_lib.py:146] step: 455800, eval_loss: 2.81107e-02
I0216 17:41:38.643681 23126066861888 run_lib.py:133] step: 455850, training_loss: 1.69976e-02
I0216 17:41:56.183946 23126066861888 run_lib.py:133] step: 455900, training_loss: 1.70550e-02
I0216 17:41:56.349337 23126066861888 run_lib.py:146] step: 455900, eval_loss: 2.86189e-02
I0216 17:42:14.100256 23126066861888 run_lib.py:133] step: 455950, training_loss: 1.78374e-02
I0216 17:42:31.752755 23126066861888 run_lib.py:133] step: 456000, training_loss: 1.79650e-02
I0216 17:42:31.918420 23126066861888 run_lib.py:146] step: 456000, eval_loss: 2.85252e-02
I0216 17:42:49.427772 23126066861888 run_lib.py:133] step: 456050, training_loss: 1.74882e-02
I0216 17:43:06.896768 23126066861888 run_lib.py:133] step: 456100, training_loss: 1.81380e-02
I0216 17:43:07.054118 23126066861888 run_lib.py:146] step: 456100, eval_loss: 2.82743e-02
I0216 17:43:24.764868 23126066861888 run_lib.py:133] step: 456150, training_loss: 1.73310e-02
I0216 17:43:42.307899 23126066861888 run_lib.py:133] step: 456200, training_loss: 1.72453e-02
I0216 17:43:42.472907 23126066861888 run_lib.py:146] step: 456200, eval_loss: 2.91614e-02
I0216 17:43:59.982144 23126066861888 run_lib.py:133] step: 456250, training_loss: 1.69300e-02
I0216 17:44:17.662524 23126066861888 run_lib.py:133] step: 456300, training_loss: 1.80523e-02
I0216 17:44:17.816174 23126066861888 run_lib.py:146] step: 456300, eval_loss: 2.82799e-02
I0216 17:44:35.290657 23126066861888 run_lib.py:133] step: 456350, training_loss: 1.81242e-02
I0216 17:44:52.961413 23126066861888 run_lib.py:133] step: 456400, training_loss: 1.75003e-02
I0216 17:44:53.127445 23126066861888 run_lib.py:146] step: 456400, eval_loss: 2.84488e-02
I0216 17:45:10.636814 23126066861888 run_lib.py:133] step: 456450, training_loss: 1.71274e-02
I0216 17:45:28.196074 23126066861888 run_lib.py:133] step: 456500, training_loss: 1.71471e-02
I0216 17:45:28.362642 23126066861888 run_lib.py:146] step: 456500, eval_loss: 2.90691e-02
I0216 17:45:46.162555 23126066861888 run_lib.py:133] step: 456550, training_loss: 1.82934e-02
I0216 17:46:03.685297 23126066861888 run_lib.py:133] step: 456600, training_loss: 1.72610e-02
I0216 17:46:03.845208 23126066861888 run_lib.py:146] step: 456600, eval_loss: 2.77854e-02
I0216 17:46:21.331733 23126066861888 run_lib.py:133] step: 456650, training_loss: 1.71395e-02
I0216 17:46:38.973584 23126066861888 run_lib.py:133] step: 456700, training_loss: 1.76895e-02
I0216 17:46:39.134173 23126066861888 run_lib.py:146] step: 456700, eval_loss: 2.68038e-02
I0216 17:46:56.661347 23126066861888 run_lib.py:133] step: 456750, training_loss: 1.66808e-02
I0216 17:47:14.238979 23126066861888 run_lib.py:133] step: 456800, training_loss: 1.75114e-02
I0216 17:47:14.394377 23126066861888 run_lib.py:146] step: 456800, eval_loss: 2.95174e-02
I0216 17:47:32.032790 23126066861888 run_lib.py:133] step: 456850, training_loss: 1.71430e-02
I0216 17:47:49.529168 23126066861888 run_lib.py:133] step: 456900, training_loss: 1.71797e-02
I0216 17:47:49.694655 23126066861888 run_lib.py:146] step: 456900, eval_loss: 2.75672e-02
I0216 17:48:07.205559 23126066861888 run_lib.py:133] step: 456950, training_loss: 1.76711e-02
I0216 17:48:24.717758 23126066861888 run_lib.py:133] step: 457000, training_loss: 1.72687e-02
I0216 17:48:24.878461 23126066861888 run_lib.py:146] step: 457000, eval_loss: 2.91753e-02
I0216 17:48:42.584201 23126066861888 run_lib.py:133] step: 457050, training_loss: 1.73110e-02
I0216 17:49:00.277220 23126066861888 run_lib.py:133] step: 457100, training_loss: 1.75978e-02
I0216 17:49:00.435542 23126066861888 run_lib.py:146] step: 457100, eval_loss: 2.96748e-02
I0216 17:49:17.973876 23126066861888 run_lib.py:133] step: 457150, training_loss: 1.77085e-02
I0216 17:49:35.483445 23126066861888 run_lib.py:133] step: 457200, training_loss: 1.74458e-02
I0216 17:49:35.639261 23126066861888 run_lib.py:146] step: 457200, eval_loss: 2.83633e-02
I0216 17:49:53.298281 23126066861888 run_lib.py:133] step: 457250, training_loss: 1.72120e-02
I0216 17:50:10.850223 23126066861888 run_lib.py:133] step: 457300, training_loss: 1.85665e-02
I0216 17:50:11.011091 23126066861888 run_lib.py:146] step: 457300, eval_loss: 2.85434e-02
I0216 17:50:28.587401 23126066861888 run_lib.py:133] step: 457350, training_loss: 1.74706e-02
I0216 17:50:46.341931 23126066861888 run_lib.py:133] step: 457400, training_loss: 1.73906e-02
I0216 17:50:46.499207 23126066861888 run_lib.py:146] step: 457400, eval_loss: 3.02480e-02
I0216 17:51:03.975834 23126066861888 run_lib.py:133] step: 457450, training_loss: 1.74058e-02
I0216 17:51:21.642869 23126066861888 run_lib.py:133] step: 457500, training_loss: 1.74043e-02
I0216 17:51:21.802573 23126066861888 run_lib.py:146] step: 457500, eval_loss: 2.82030e-02
I0216 17:51:39.314749 23126066861888 run_lib.py:133] step: 457550, training_loss: 1.76456e-02
I0216 17:51:56.874395 23126066861888 run_lib.py:133] step: 457600, training_loss: 1.75777e-02
I0216 17:51:57.032438 23126066861888 run_lib.py:146] step: 457600, eval_loss: 2.77540e-02
I0216 17:52:14.794051 23126066861888 run_lib.py:133] step: 457650, training_loss: 1.80680e-02
I0216 17:52:32.306821 23126066861888 run_lib.py:133] step: 457700, training_loss: 1.75145e-02
I0216 17:52:32.461959 23126066861888 run_lib.py:146] step: 457700, eval_loss: 2.83769e-02
I0216 17:52:49.933099 23126066861888 run_lib.py:133] step: 457750, training_loss: 1.79403e-02
I0216 17:53:07.662442 23126066861888 run_lib.py:133] step: 457800, training_loss: 1.78717e-02
I0216 17:53:07.814973 23126066861888 run_lib.py:146] step: 457800, eval_loss: 2.84916e-02
I0216 17:53:25.324397 23126066861888 run_lib.py:133] step: 457850, training_loss: 1.73338e-02
I0216 17:53:42.831117 23126066861888 run_lib.py:133] step: 457900, training_loss: 1.76499e-02
I0216 17:53:43.013262 23126066861888 run_lib.py:146] step: 457900, eval_loss: 2.75836e-02
I0216 17:54:00.688685 23126066861888 run_lib.py:133] step: 457950, training_loss: 1.70040e-02
I0216 17:54:18.249089 23126066861888 run_lib.py:133] step: 458000, training_loss: 1.71954e-02
I0216 17:54:18.406422 23126066861888 run_lib.py:146] step: 458000, eval_loss: 2.87618e-02
I0216 17:54:35.886424 23126066861888 run_lib.py:133] step: 458050, training_loss: 1.71000e-02
I0216 17:54:53.380830 23126066861888 run_lib.py:133] step: 458100, training_loss: 1.72440e-02
I0216 17:54:53.541090 23126066861888 run_lib.py:146] step: 458100, eval_loss: 2.99200e-02
I0216 17:55:11.253180 23126066861888 run_lib.py:133] step: 458150, training_loss: 1.76714e-02
I0216 17:55:28.929933 23126066861888 run_lib.py:133] step: 458200, training_loss: 1.82674e-02
I0216 17:55:29.136829 23126066861888 run_lib.py:146] step: 458200, eval_loss: 2.84049e-02
I0216 17:55:46.636407 23126066861888 run_lib.py:133] step: 458250, training_loss: 1.68084e-02
I0216 17:56:04.118716 23126066861888 run_lib.py:133] step: 458300, training_loss: 1.78172e-02
I0216 17:56:04.273767 23126066861888 run_lib.py:146] step: 458300, eval_loss: 2.80604e-02
I0216 17:56:21.896670 23126066861888 run_lib.py:133] step: 458350, training_loss: 1.80072e-02
I0216 17:56:39.418628 23126066861888 run_lib.py:133] step: 458400, training_loss: 1.80449e-02
I0216 17:56:39.601131 23126066861888 run_lib.py:146] step: 458400, eval_loss: 2.80523e-02
I0216 17:56:57.130582 23126066861888 run_lib.py:133] step: 458450, training_loss: 1.72871e-02
I0216 17:57:14.849900 23126066861888 run_lib.py:133] step: 458500, training_loss: 1.74988e-02
I0216 17:57:15.008394 23126066861888 run_lib.py:146] step: 458500, eval_loss: 2.74163e-02
I0216 17:57:32.505535 23126066861888 run_lib.py:133] step: 458550, training_loss: 1.76525e-02
I0216 17:57:50.163329 23126066861888 run_lib.py:133] step: 458600, training_loss: 1.77555e-02
I0216 17:57:50.321114 23126066861888 run_lib.py:146] step: 458600, eval_loss: 2.82394e-02
I0216 17:58:07.803488 23126066861888 run_lib.py:133] step: 458650, training_loss: 1.81268e-02
I0216 17:58:25.335175 23126066861888 run_lib.py:133] step: 458700, training_loss: 1.70201e-02
I0216 17:58:25.490355 23126066861888 run_lib.py:146] step: 458700, eval_loss: 2.76134e-02
I0216 17:58:43.327558 23126066861888 run_lib.py:133] step: 458750, training_loss: 1.71267e-02
I0216 17:59:00.831274 23126066861888 run_lib.py:133] step: 458800, training_loss: 1.74813e-02
I0216 17:59:00.988136 23126066861888 run_lib.py:146] step: 458800, eval_loss: 2.85517e-02
I0216 17:59:18.446329 23126066861888 run_lib.py:133] step: 458850, training_loss: 1.78715e-02
I0216 17:59:36.081436 23126066861888 run_lib.py:133] step: 458900, training_loss: 1.79394e-02
I0216 17:59:36.249166 23126066861888 run_lib.py:146] step: 458900, eval_loss: 2.74190e-02
I0216 17:59:53.806925 23126066861888 run_lib.py:133] step: 458950, training_loss: 1.72290e-02
I0216 18:00:11.348983 23126066861888 run_lib.py:133] step: 459000, training_loss: 1.77550e-02
I0216 18:00:11.515270 23126066861888 run_lib.py:146] step: 459000, eval_loss: 2.80202e-02
I0216 18:00:29.153326 23126066861888 run_lib.py:133] step: 459050, training_loss: 1.74301e-02
I0216 18:00:46.628776 23126066861888 run_lib.py:133] step: 459100, training_loss: 1.80453e-02
I0216 18:00:46.792229 23126066861888 run_lib.py:146] step: 459100, eval_loss: 2.83042e-02
I0216 18:01:04.315361 23126066861888 run_lib.py:133] step: 459150, training_loss: 1.74701e-02
I0216 18:01:21.852893 23126066861888 run_lib.py:133] step: 459200, training_loss: 1.73421e-02
I0216 18:01:22.006182 23126066861888 run_lib.py:146] step: 459200, eval_loss: 2.74322e-02
I0216 18:01:39.670021 23126066861888 run_lib.py:133] step: 459250, training_loss: 1.66996e-02
I0216 18:01:57.359851 23126066861888 run_lib.py:133] step: 459300, training_loss: 1.69610e-02
I0216 18:01:57.528405 23126066861888 run_lib.py:146] step: 459300, eval_loss: 2.81667e-02
I0216 18:02:15.106943 23126066861888 run_lib.py:133] step: 459350, training_loss: 1.78476e-02
I0216 18:02:32.607744 23126066861888 run_lib.py:133] step: 459400, training_loss: 1.65086e-02
I0216 18:02:32.765389 23126066861888 run_lib.py:146] step: 459400, eval_loss: 2.95664e-02
I0216 18:02:50.424437 23126066861888 run_lib.py:133] step: 459450, training_loss: 1.82158e-02
I0216 18:03:07.906600 23126066861888 run_lib.py:133] step: 459500, training_loss: 1.75153e-02
I0216 18:03:08.076089 23126066861888 run_lib.py:146] step: 459500, eval_loss: 2.81159e-02
I0216 18:03:25.581492 23126066861888 run_lib.py:133] step: 459550, training_loss: 1.75701e-02
I0216 18:03:43.284905 23126066861888 run_lib.py:133] step: 459600, training_loss: 1.69902e-02
I0216 18:03:43.447030 23126066861888 run_lib.py:146] step: 459600, eval_loss: 2.89577e-02
I0216 18:04:00.992924 23126066861888 run_lib.py:133] step: 459650, training_loss: 1.71057e-02
I0216 18:04:18.699196 23126066861888 run_lib.py:133] step: 459700, training_loss: 1.76108e-02
I0216 18:04:18.876169 23126066861888 run_lib.py:146] step: 459700, eval_loss: 2.87822e-02
I0216 18:04:36.401538 23126066861888 run_lib.py:133] step: 459750, training_loss: 1.71586e-02
I0216 18:04:53.901411 23126066861888 run_lib.py:133] step: 459800, training_loss: 1.82177e-02
I0216 18:04:54.078138 23126066861888 run_lib.py:146] step: 459800, eval_loss: 2.72466e-02
I0216 18:05:11.882867 23126066861888 run_lib.py:133] step: 459850, training_loss: 1.77472e-02
I0216 18:05:29.408910 23126066861888 run_lib.py:133] step: 459900, training_loss: 1.73892e-02
I0216 18:05:29.566452 23126066861888 run_lib.py:146] step: 459900, eval_loss: 2.87093e-02
I0216 18:05:47.090903 23126066861888 run_lib.py:133] step: 459950, training_loss: 1.75303e-02
I0216 18:06:04.748788 23126066861888 run_lib.py:133] step: 460000, training_loss: 1.75519e-02
I0216 18:06:05.486146 23126066861888 run_lib.py:146] step: 460000, eval_loss: 2.89790e-02
I0216 18:06:25.647430 23126066861888 run_lib.py:133] step: 460050, training_loss: 1.78975e-02
I0216 18:06:43.189640 23126066861888 run_lib.py:133] step: 460100, training_loss: 1.76995e-02
I0216 18:06:43.346607 23126066861888 run_lib.py:146] step: 460100, eval_loss: 2.86309e-02
I0216 18:07:00.868912 23126066861888 run_lib.py:133] step: 460150, training_loss: 1.77254e-02
I0216 18:07:18.579242 23126066861888 run_lib.py:133] step: 460200, training_loss: 1.72754e-02
I0216 18:07:18.734291 23126066861888 run_lib.py:146] step: 460200, eval_loss: 2.87627e-02
I0216 18:07:36.269445 23126066861888 run_lib.py:133] step: 460250, training_loss: 1.70619e-02
I0216 18:07:53.779775 23126066861888 run_lib.py:133] step: 460300, training_loss: 1.72460e-02
I0216 18:07:53.941602 23126066861888 run_lib.py:146] step: 460300, eval_loss: 2.86310e-02
I0216 18:08:11.476830 23126066861888 run_lib.py:133] step: 460350, training_loss: 1.78443e-02
I0216 18:08:29.231325 23126066861888 run_lib.py:133] step: 460400, training_loss: 1.73091e-02
I0216 18:08:29.391217 23126066861888 run_lib.py:146] step: 460400, eval_loss: 2.80580e-02
I0216 18:08:46.982718 23126066861888 run_lib.py:133] step: 460450, training_loss: 1.72161e-02
I0216 18:09:04.508127 23126066861888 run_lib.py:133] step: 460500, training_loss: 1.64246e-02
I0216 18:09:04.665155 23126066861888 run_lib.py:146] step: 460500, eval_loss: 2.85995e-02
I0216 18:09:22.188322 23126066861888 run_lib.py:133] step: 460550, training_loss: 1.74706e-02
I0216 18:09:39.664628 23126066861888 run_lib.py:133] step: 460600, training_loss: 1.74863e-02
I0216 18:09:39.828234 23126066861888 run_lib.py:146] step: 460600, eval_loss: 2.78812e-02
I0216 18:09:57.512880 23126066861888 run_lib.py:133] step: 460650, training_loss: 1.79075e-02
I0216 18:10:15.059534 23126066861888 run_lib.py:133] step: 460700, training_loss: 1.75056e-02
I0216 18:10:15.216387 23126066861888 run_lib.py:146] step: 460700, eval_loss: 2.72932e-02
I0216 18:10:32.928735 23126066861888 run_lib.py:133] step: 460750, training_loss: 1.72876e-02
I0216 18:10:50.468813 23126066861888 run_lib.py:133] step: 460800, training_loss: 1.69889e-02
I0216 18:10:50.636348 23126066861888 run_lib.py:146] step: 460800, eval_loss: 2.87525e-02
I0216 18:11:08.288900 23126066861888 run_lib.py:133] step: 460850, training_loss: 1.80654e-02
I0216 18:11:25.819011 23126066861888 run_lib.py:133] step: 460900, training_loss: 1.77233e-02
I0216 18:11:26.005717 23126066861888 run_lib.py:146] step: 460900, eval_loss: 2.86911e-02
I0216 18:11:43.537974 23126066861888 run_lib.py:133] step: 460950, training_loss: 1.70536e-02
I0216 18:12:01.275363 23126066861888 run_lib.py:133] step: 461000, training_loss: 1.79421e-02
I0216 18:12:01.433862 23126066861888 run_lib.py:146] step: 461000, eval_loss: 2.74947e-02
I0216 18:12:18.933565 23126066861888 run_lib.py:133] step: 461050, training_loss: 1.78790e-02
I0216 18:12:36.603801 23126066861888 run_lib.py:133] step: 461100, training_loss: 1.79487e-02
I0216 18:12:36.757178 23126066861888 run_lib.py:146] step: 461100, eval_loss: 2.82432e-02
I0216 18:12:54.249342 23126066861888 run_lib.py:133] step: 461150, training_loss: 1.81133e-02
I0216 18:13:11.803552 23126066861888 run_lib.py:133] step: 461200, training_loss: 1.75869e-02
I0216 18:13:11.971575 23126066861888 run_lib.py:146] step: 461200, eval_loss: 2.80159e-02
I0216 18:13:29.511637 23126066861888 run_lib.py:133] step: 461250, training_loss: 1.78513e-02
I0216 18:13:47.248372 23126066861888 run_lib.py:133] step: 461300, training_loss: 1.77360e-02
I0216 18:13:47.407486 23126066861888 run_lib.py:146] step: 461300, eval_loss: 2.88514e-02
I0216 18:14:04.901687 23126066861888 run_lib.py:133] step: 461350, training_loss: 1.76864e-02
I0216 18:14:22.399478 23126066861888 run_lib.py:133] step: 461400, training_loss: 1.73593e-02
I0216 18:14:22.557181 23126066861888 run_lib.py:146] step: 461400, eval_loss: 2.75118e-02
I0216 18:14:40.220146 23126066861888 run_lib.py:133] step: 461450, training_loss: 1.75279e-02
I0216 18:14:57.757277 23126066861888 run_lib.py:133] step: 461500, training_loss: 1.71179e-02
I0216 18:14:57.914553 23126066861888 run_lib.py:146] step: 461500, eval_loss: 2.85377e-02
I0216 18:15:15.568814 23126066861888 run_lib.py:133] step: 461550, training_loss: 1.74801e-02
I0216 18:15:33.042204 23126066861888 run_lib.py:133] step: 461600, training_loss: 1.80437e-02
I0216 18:15:33.196293 23126066861888 run_lib.py:146] step: 461600, eval_loss: 2.86437e-02
I0216 18:15:50.675101 23126066861888 run_lib.py:133] step: 461650, training_loss: 1.74564e-02
I0216 18:16:08.204450 23126066861888 run_lib.py:133] step: 461700, training_loss: 1.76196e-02
I0216 18:16:08.361187 23126066861888 run_lib.py:146] step: 461700, eval_loss: 2.86894e-02
I0216 18:16:25.998039 23126066861888 run_lib.py:133] step: 461750, training_loss: 1.71710e-02
I0216 18:16:43.589204 23126066861888 run_lib.py:133] step: 461800, training_loss: 1.67382e-02
I0216 18:16:43.765258 23126066861888 run_lib.py:146] step: 461800, eval_loss: 2.90408e-02
I0216 18:17:01.313492 23126066861888 run_lib.py:133] step: 461850, training_loss: 1.76729e-02
I0216 18:17:18.871752 23126066861888 run_lib.py:133] step: 461900, training_loss: 1.72845e-02
I0216 18:17:19.029359 23126066861888 run_lib.py:146] step: 461900, eval_loss: 2.84353e-02
I0216 18:17:36.729340 23126066861888 run_lib.py:133] step: 461950, training_loss: 1.73781e-02
I0216 18:17:54.200566 23126066861888 run_lib.py:133] step: 462000, training_loss: 1.72049e-02
I0216 18:17:54.356101 23126066861888 run_lib.py:146] step: 462000, eval_loss: 2.79717e-02
I0216 18:18:11.854082 23126066861888 run_lib.py:133] step: 462050, training_loss: 1.78999e-02
I0216 18:18:29.576598 23126066861888 run_lib.py:133] step: 462100, training_loss: 1.74069e-02
I0216 18:18:29.733309 23126066861888 run_lib.py:146] step: 462100, eval_loss: 2.81424e-02
I0216 18:18:47.253522 23126066861888 run_lib.py:133] step: 462150, training_loss: 1.76360e-02
I0216 18:19:04.965449 23126066861888 run_lib.py:133] step: 462200, training_loss: 1.75224e-02
I0216 18:19:05.129282 23126066861888 run_lib.py:146] step: 462200, eval_loss: 2.78136e-02
I0216 18:19:22.611642 23126066861888 run_lib.py:133] step: 462250, training_loss: 1.76990e-02
I0216 18:19:40.105500 23126066861888 run_lib.py:133] step: 462300, training_loss: 1.73320e-02
I0216 18:19:40.276209 23126066861888 run_lib.py:146] step: 462300, eval_loss: 2.82030e-02
I0216 18:19:58.039954 23126066861888 run_lib.py:133] step: 462350, training_loss: 1.76504e-02
I0216 18:20:15.565549 23126066861888 run_lib.py:133] step: 462400, training_loss: 1.73309e-02
I0216 18:20:15.723417 23126066861888 run_lib.py:146] step: 462400, eval_loss: 2.80373e-02
I0216 18:20:33.231310 23126066861888 run_lib.py:133] step: 462450, training_loss: 1.79627e-02
I0216 18:20:50.698701 23126066861888 run_lib.py:133] step: 462500, training_loss: 1.82999e-02
I0216 18:20:50.854178 23126066861888 run_lib.py:146] step: 462500, eval_loss: 2.80469e-02
I0216 18:21:08.490696 23126066861888 run_lib.py:133] step: 462550, training_loss: 1.75195e-02
I0216 18:21:25.978631 23126066861888 run_lib.py:133] step: 462600, training_loss: 1.72106e-02
I0216 18:21:26.133455 23126066861888 run_lib.py:146] step: 462600, eval_loss: 2.78920e-02
I0216 18:21:43.806698 23126066861888 run_lib.py:133] step: 462650, training_loss: 1.71678e-02
I0216 18:22:01.328213 23126066861888 run_lib.py:133] step: 462700, training_loss: 1.80421e-02
I0216 18:22:01.489583 23126066861888 run_lib.py:146] step: 462700, eval_loss: 2.88412e-02
I0216 18:22:18.973948 23126066861888 run_lib.py:133] step: 462750, training_loss: 1.79224e-02
I0216 18:22:36.451690 23126066861888 run_lib.py:133] step: 462800, training_loss: 1.76668e-02
I0216 18:22:36.608323 23126066861888 run_lib.py:146] step: 462800, eval_loss: 2.86762e-02
I0216 18:22:54.353183 23126066861888 run_lib.py:133] step: 462850, training_loss: 1.76692e-02
I0216 18:23:11.995510 23126066861888 run_lib.py:133] step: 462900, training_loss: 1.73363e-02
I0216 18:23:12.159439 23126066861888 run_lib.py:146] step: 462900, eval_loss: 2.77235e-02
I0216 18:23:29.684379 23126066861888 run_lib.py:133] step: 462950, training_loss: 1.73068e-02
I0216 18:23:47.166751 23126066861888 run_lib.py:133] step: 463000, training_loss: 1.75585e-02
I0216 18:23:47.320867 23126066861888 run_lib.py:146] step: 463000, eval_loss: 2.82102e-02
I0216 18:24:05.040722 23126066861888 run_lib.py:133] step: 463050, training_loss: 1.68391e-02
I0216 18:24:22.516200 23126066861888 run_lib.py:133] step: 463100, training_loss: 1.76560e-02
I0216 18:24:22.671074 23126066861888 run_lib.py:146] step: 463100, eval_loss: 2.82665e-02
I0216 18:24:40.131860 23126066861888 run_lib.py:133] step: 463150, training_loss: 1.72692e-02
I0216 18:24:57.856938 23126066861888 run_lib.py:133] step: 463200, training_loss: 1.79632e-02
I0216 18:24:58.027130 23126066861888 run_lib.py:146] step: 463200, eval_loss: 2.79952e-02
I0216 18:25:15.587724 23126066861888 run_lib.py:133] step: 463250, training_loss: 1.75378e-02
I0216 18:25:33.298785 23126066861888 run_lib.py:133] step: 463300, training_loss: 1.66048e-02
I0216 18:25:33.459697 23126066861888 run_lib.py:146] step: 463300, eval_loss: 2.78068e-02
I0216 18:25:50.938993 23126066861888 run_lib.py:133] step: 463350, training_loss: 1.72861e-02
I0216 18:26:08.397693 23126066861888 run_lib.py:133] step: 463400, training_loss: 1.81612e-02
I0216 18:26:08.557657 23126066861888 run_lib.py:146] step: 463400, eval_loss: 2.78818e-02
I0216 18:26:26.263339 23126066861888 run_lib.py:133] step: 463450, training_loss: 1.74178e-02
I0216 18:26:43.810708 23126066861888 run_lib.py:133] step: 463500, training_loss: 1.74798e-02
I0216 18:26:43.966502 23126066861888 run_lib.py:146] step: 463500, eval_loss: 2.82824e-02
I0216 18:27:01.466280 23126066861888 run_lib.py:133] step: 463550, training_loss: 1.74369e-02
I0216 18:27:19.191106 23126066861888 run_lib.py:133] step: 463600, training_loss: 1.73210e-02
I0216 18:27:19.348188 23126066861888 run_lib.py:146] step: 463600, eval_loss: 2.79971e-02
I0216 18:27:36.837328 23126066861888 run_lib.py:133] step: 463650, training_loss: 1.66514e-02
I0216 18:27:54.333479 23126066861888 run_lib.py:133] step: 463700, training_loss: 1.75305e-02
I0216 18:27:54.498542 23126066861888 run_lib.py:146] step: 463700, eval_loss: 2.91020e-02
I0216 18:28:12.130578 23126066861888 run_lib.py:133] step: 463750, training_loss: 1.71457e-02
I0216 18:28:29.663664 23126066861888 run_lib.py:133] step: 463800, training_loss: 1.80855e-02
I0216 18:28:29.824410 23126066861888 run_lib.py:146] step: 463800, eval_loss: 2.76582e-02
I0216 18:28:47.375005 23126066861888 run_lib.py:133] step: 463850, training_loss: 1.74651e-02
I0216 18:29:04.841137 23126066861888 run_lib.py:133] step: 463900, training_loss: 1.74296e-02
I0216 18:29:04.997877 23126066861888 run_lib.py:146] step: 463900, eval_loss: 2.81301e-02
I0216 18:29:22.764440 23126066861888 run_lib.py:133] step: 463950, training_loss: 1.74389e-02
I0216 18:29:40.351388 23126066861888 run_lib.py:133] step: 464000, training_loss: 1.74320e-02
I0216 18:29:40.506404 23126066861888 run_lib.py:146] step: 464000, eval_loss: 2.80938e-02
I0216 18:29:58.092925 23126066861888 run_lib.py:133] step: 464050, training_loss: 1.75084e-02
I0216 18:30:15.634876 23126066861888 run_lib.py:133] step: 464100, training_loss: 1.71670e-02
I0216 18:30:15.811502 23126066861888 run_lib.py:146] step: 464100, eval_loss: 2.84323e-02
I0216 18:30:33.532934 23126066861888 run_lib.py:133] step: 464150, training_loss: 1.74770e-02
I0216 18:30:51.034490 23126066861888 run_lib.py:133] step: 464200, training_loss: 1.72589e-02
I0216 18:30:51.196428 23126066861888 run_lib.py:146] step: 464200, eval_loss: 2.81990e-02
I0216 18:31:08.703998 23126066861888 run_lib.py:133] step: 464250, training_loss: 1.74670e-02
I0216 18:31:26.430512 23126066861888 run_lib.py:133] step: 464300, training_loss: 1.74754e-02
I0216 18:31:26.601390 23126066861888 run_lib.py:146] step: 464300, eval_loss: 2.86429e-02
I0216 18:31:44.144355 23126066861888 run_lib.py:133] step: 464350, training_loss: 1.83713e-02
I0216 18:32:01.887711 23126066861888 run_lib.py:133] step: 464400, training_loss: 1.72850e-02
I0216 18:32:02.044953 23126066861888 run_lib.py:146] step: 464400, eval_loss: 2.86367e-02
I0216 18:32:19.559431 23126066861888 run_lib.py:133] step: 464450, training_loss: 1.78539e-02
I0216 18:32:37.075358 23126066861888 run_lib.py:133] step: 464500, training_loss: 1.72241e-02
I0216 18:32:37.238108 23126066861888 run_lib.py:146] step: 464500, eval_loss: 2.72992e-02
I0216 18:32:54.886744 23126066861888 run_lib.py:133] step: 464550, training_loss: 1.72729e-02
I0216 18:33:12.413976 23126066861888 run_lib.py:133] step: 464600, training_loss: 1.76158e-02
I0216 18:33:12.589025 23126066861888 run_lib.py:146] step: 464600, eval_loss: 2.71353e-02
I0216 18:33:30.155092 23126066861888 run_lib.py:133] step: 464650, training_loss: 1.72346e-02
I0216 18:33:47.900754 23126066861888 run_lib.py:133] step: 464700, training_loss: 1.78539e-02
I0216 18:33:48.063247 23126066861888 run_lib.py:146] step: 464700, eval_loss: 2.81350e-02
I0216 18:34:05.554604 23126066861888 run_lib.py:133] step: 464750, training_loss: 1.67407e-02
I0216 18:34:23.034504 23126066861888 run_lib.py:133] step: 464800, training_loss: 1.74743e-02
I0216 18:34:23.192449 23126066861888 run_lib.py:146] step: 464800, eval_loss: 2.87818e-02
I0216 18:34:40.821367 23126066861888 run_lib.py:133] step: 464850, training_loss: 1.78035e-02
I0216 18:34:58.334165 23126066861888 run_lib.py:133] step: 464900, training_loss: 1.73052e-02
I0216 18:34:58.489514 23126066861888 run_lib.py:146] step: 464900, eval_loss: 2.76998e-02
I0216 18:35:16.102394 23126066861888 run_lib.py:133] step: 464950, training_loss: 1.74123e-02
I0216 18:35:33.620308 23126066861888 run_lib.py:133] step: 465000, training_loss: 1.70801e-02
I0216 18:35:33.794172 23126066861888 run_lib.py:146] step: 465000, eval_loss: 2.76540e-02
I0216 18:35:51.503561 23126066861888 run_lib.py:133] step: 465050, training_loss: 1.75474e-02
I0216 18:36:09.104913 23126066861888 run_lib.py:133] step: 465100, training_loss: 1.68311e-02
I0216 18:36:09.265426 23126066861888 run_lib.py:146] step: 465100, eval_loss: 2.83893e-02
I0216 18:36:26.761390 23126066861888 run_lib.py:133] step: 465150, training_loss: 1.73849e-02
I0216 18:36:44.341342 23126066861888 run_lib.py:133] step: 465200, training_loss: 1.76354e-02
I0216 18:36:44.499414 23126066861888 run_lib.py:146] step: 465200, eval_loss: 2.85002e-02
I0216 18:37:02.181965 23126066861888 run_lib.py:133] step: 465250, training_loss: 1.74235e-02
I0216 18:37:19.663919 23126066861888 run_lib.py:133] step: 465300, training_loss: 1.70892e-02
I0216 18:37:19.821383 23126066861888 run_lib.py:146] step: 465300, eval_loss: 2.86495e-02
I0216 18:37:37.326262 23126066861888 run_lib.py:133] step: 465350, training_loss: 1.73326e-02
I0216 18:37:54.997546 23126066861888 run_lib.py:133] step: 465400, training_loss: 1.79786e-02
I0216 18:37:55.150958 23126066861888 run_lib.py:146] step: 465400, eval_loss: 2.93993e-02
I0216 18:38:12.660044 23126066861888 run_lib.py:133] step: 465450, training_loss: 1.77353e-02
I0216 18:38:30.356423 23126066861888 run_lib.py:133] step: 465500, training_loss: 1.78321e-02
I0216 18:38:30.534281 23126066861888 run_lib.py:146] step: 465500, eval_loss: 2.82947e-02
I0216 18:38:48.090979 23126066861888 run_lib.py:133] step: 465550, training_loss: 1.67850e-02
I0216 18:39:05.673241 23126066861888 run_lib.py:133] step: 465600, training_loss: 1.72332e-02
I0216 18:39:05.834418 23126066861888 run_lib.py:146] step: 465600, eval_loss: 2.79943e-02
I0216 18:39:23.519662 23126066861888 run_lib.py:133] step: 465650, training_loss: 1.80181e-02
I0216 18:39:41.007044 23126066861888 run_lib.py:133] step: 465700, training_loss: 1.76627e-02
I0216 18:39:41.167094 23126066861888 run_lib.py:146] step: 465700, eval_loss: 2.77096e-02
I0216 18:39:58.649842 23126066861888 run_lib.py:133] step: 465750, training_loss: 1.78624e-02
I0216 18:40:16.417170 23126066861888 run_lib.py:133] step: 465800, training_loss: 1.76265e-02
I0216 18:40:16.574450 23126066861888 run_lib.py:146] step: 465800, eval_loss: 2.87142e-02
I0216 18:40:34.079487 23126066861888 run_lib.py:133] step: 465850, training_loss: 1.72984e-02
I0216 18:40:51.575117 23126066861888 run_lib.py:133] step: 465900, training_loss: 1.81777e-02
I0216 18:40:51.729115 23126066861888 run_lib.py:146] step: 465900, eval_loss: 2.71057e-02
I0216 18:41:09.324705 23126066861888 run_lib.py:133] step: 465950, training_loss: 1.75172e-02
I0216 18:41:26.842091 23126066861888 run_lib.py:133] step: 466000, training_loss: 1.74563e-02
I0216 18:41:27.018189 23126066861888 run_lib.py:146] step: 466000, eval_loss: 2.89787e-02
I0216 18:41:44.539339 23126066861888 run_lib.py:133] step: 466050, training_loss: 1.81056e-02
I0216 18:42:02.081560 23126066861888 run_lib.py:133] step: 466100, training_loss: 1.71342e-02
I0216 18:42:02.242713 23126066861888 run_lib.py:146] step: 466100, eval_loss: 2.82287e-02
I0216 18:42:19.937793 23126066861888 run_lib.py:133] step: 466150, training_loss: 1.74957e-02
I0216 18:42:37.511437 23126066861888 run_lib.py:133] step: 466200, training_loss: 1.77863e-02
I0216 18:42:37.670115 23126066861888 run_lib.py:146] step: 466200, eval_loss: 2.87993e-02
I0216 18:42:55.165808 23126066861888 run_lib.py:133] step: 466250, training_loss: 1.75724e-02
I0216 18:43:12.667522 23126066861888 run_lib.py:133] step: 466300, training_loss: 1.73943e-02
I0216 18:43:12.827399 23126066861888 run_lib.py:146] step: 466300, eval_loss: 2.79466e-02
I0216 18:43:30.570135 23126066861888 run_lib.py:133] step: 466350, training_loss: 1.69586e-02
I0216 18:43:48.137956 23126066861888 run_lib.py:133] step: 466400, training_loss: 1.75512e-02
I0216 18:43:48.293345 23126066861888 run_lib.py:146] step: 466400, eval_loss: 2.77164e-02
I0216 18:44:05.779411 23126066861888 run_lib.py:133] step: 466450, training_loss: 1.72287e-02
I0216 18:44:23.502200 23126066861888 run_lib.py:133] step: 466500, training_loss: 1.76757e-02
I0216 18:44:23.671689 23126066861888 run_lib.py:146] step: 466500, eval_loss: 2.86420e-02
I0216 18:44:41.160851 23126066861888 run_lib.py:133] step: 466550, training_loss: 1.72908e-02
I0216 18:44:58.885133 23126066861888 run_lib.py:133] step: 466600, training_loss: 1.77861e-02
I0216 18:44:59.057245 23126066861888 run_lib.py:146] step: 466600, eval_loss: 2.75859e-02
I0216 18:45:16.581670 23126066861888 run_lib.py:133] step: 466650, training_loss: 1.79529e-02
I0216 18:45:34.108594 23126066861888 run_lib.py:133] step: 466700, training_loss: 1.70581e-02
I0216 18:45:34.265196 23126066861888 run_lib.py:146] step: 466700, eval_loss: 2.86893e-02
I0216 18:45:52.012799 23126066861888 run_lib.py:133] step: 466750, training_loss: 1.70817e-02
I0216 18:46:09.516119 23126066861888 run_lib.py:133] step: 466800, training_loss: 1.78164e-02
I0216 18:46:09.673580 23126066861888 run_lib.py:146] step: 466800, eval_loss: 2.81977e-02
I0216 18:46:27.159111 23126066861888 run_lib.py:133] step: 466850, training_loss: 1.70646e-02
I0216 18:46:44.891349 23126066861888 run_lib.py:133] step: 466900, training_loss: 1.76130e-02
I0216 18:46:45.056522 23126066861888 run_lib.py:146] step: 466900, eval_loss: 2.87524e-02
I0216 18:47:02.578809 23126066861888 run_lib.py:133] step: 466950, training_loss: 1.69644e-02
I0216 18:47:20.103264 23126066861888 run_lib.py:133] step: 467000, training_loss: 1.76750e-02
I0216 18:47:20.266411 23126066861888 run_lib.py:146] step: 467000, eval_loss: 2.84967e-02
I0216 18:47:37.891505 23126066861888 run_lib.py:133] step: 467050, training_loss: 1.78396e-02
I0216 18:47:55.451855 23126066861888 run_lib.py:133] step: 467100, training_loss: 1.74931e-02
I0216 18:47:55.612557 23126066861888 run_lib.py:146] step: 467100, eval_loss: 2.90418e-02
I0216 18:48:13.165002 23126066861888 run_lib.py:133] step: 467150, training_loss: 1.74764e-02
I0216 18:48:30.768387 23126066861888 run_lib.py:133] step: 467200, training_loss: 1.74251e-02
I0216 18:48:30.926448 23126066861888 run_lib.py:146] step: 467200, eval_loss: 2.68922e-02
I0216 18:48:48.664734 23126066861888 run_lib.py:133] step: 467250, training_loss: 1.74899e-02
I0216 18:49:06.253007 23126066861888 run_lib.py:133] step: 467300, training_loss: 1.72615e-02
I0216 18:49:06.407374 23126066861888 run_lib.py:146] step: 467300, eval_loss: 2.81784e-02
I0216 18:49:23.935143 23126066861888 run_lib.py:133] step: 467350, training_loss: 1.70181e-02
I0216 18:49:41.447812 23126066861888 run_lib.py:133] step: 467400, training_loss: 1.72079e-02
I0216 18:49:41.605424 23126066861888 run_lib.py:146] step: 467400, eval_loss: 2.85362e-02
I0216 18:49:59.316152 23126066861888 run_lib.py:133] step: 467450, training_loss: 1.74080e-02
I0216 18:50:16.884550 23126066861888 run_lib.py:133] step: 467500, training_loss: 1.75758e-02
I0216 18:50:17.052037 23126066861888 run_lib.py:146] step: 467500, eval_loss: 2.78488e-02
I0216 18:50:34.551486 23126066861888 run_lib.py:133] step: 467550, training_loss: 1.70570e-02
I0216 18:50:52.250316 23126066861888 run_lib.py:133] step: 467600, training_loss: 1.72703e-02
I0216 18:50:52.407194 23126066861888 run_lib.py:146] step: 467600, eval_loss: 2.95233e-02
I0216 18:51:09.911555 23126066861888 run_lib.py:133] step: 467650, training_loss: 1.67347e-02
I0216 18:51:27.566651 23126066861888 run_lib.py:133] step: 467700, training_loss: 1.70627e-02
I0216 18:51:27.732240 23126066861888 run_lib.py:146] step: 467700, eval_loss: 2.85841e-02
I0216 18:51:45.301672 23126066861888 run_lib.py:133] step: 467750, training_loss: 1.71089e-02
I0216 18:52:02.831539 23126066861888 run_lib.py:133] step: 467800, training_loss: 1.68381e-02
I0216 18:52:02.995390 23126066861888 run_lib.py:146] step: 467800, eval_loss: 2.93201e-02
I0216 18:52:20.769229 23126066861888 run_lib.py:133] step: 467850, training_loss: 1.66939e-02
I0216 18:52:38.285352 23126066861888 run_lib.py:133] step: 467900, training_loss: 1.70016e-02
I0216 18:52:38.443180 23126066861888 run_lib.py:146] step: 467900, eval_loss: 2.86891e-02
I0216 18:52:55.961262 23126066861888 run_lib.py:133] step: 467950, training_loss: 1.76458e-02
I0216 18:53:13.616603 23126066861888 run_lib.py:133] step: 468000, training_loss: 1.70103e-02
I0216 18:53:13.790146 23126066861888 run_lib.py:146] step: 468000, eval_loss: 2.89455e-02
I0216 18:53:31.318452 23126066861888 run_lib.py:133] step: 468050, training_loss: 1.73862e-02
I0216 18:53:48.900189 23126066861888 run_lib.py:133] step: 468100, training_loss: 1.70460e-02
I0216 18:53:49.058429 23126066861888 run_lib.py:146] step: 468100, eval_loss: 2.85728e-02
I0216 18:54:06.720820 23126066861888 run_lib.py:133] step: 468150, training_loss: 1.75690e-02
I0216 18:54:24.179413 23126066861888 run_lib.py:133] step: 468200, training_loss: 1.73370e-02
I0216 18:54:24.334989 23126066861888 run_lib.py:146] step: 468200, eval_loss: 2.75568e-02
I0216 18:54:41.807626 23126066861888 run_lib.py:133] step: 468250, training_loss: 1.78626e-02
I0216 18:54:59.303418 23126066861888 run_lib.py:133] step: 468300, training_loss: 1.81819e-02
I0216 18:54:59.462455 23126066861888 run_lib.py:146] step: 468300, eval_loss: 2.73467e-02
I0216 18:55:17.210361 23126066861888 run_lib.py:133] step: 468350, training_loss: 1.79744e-02
I0216 18:55:34.842472 23126066861888 run_lib.py:133] step: 468400, training_loss: 1.75637e-02
I0216 18:55:35.006312 23126066861888 run_lib.py:146] step: 468400, eval_loss: 2.98157e-02
I0216 18:55:52.484333 23126066861888 run_lib.py:133] step: 468450, training_loss: 1.74831e-02
I0216 18:56:09.983928 23126066861888 run_lib.py:133] step: 468500, training_loss: 1.78416e-02
I0216 18:56:10.145206 23126066861888 run_lib.py:146] step: 468500, eval_loss: 2.99827e-02
I0216 18:56:27.860599 23126066861888 run_lib.py:133] step: 468550, training_loss: 1.74874e-02
I0216 18:56:45.400486 23126066861888 run_lib.py:133] step: 468600, training_loss: 1.71630e-02
I0216 18:56:45.566840 23126066861888 run_lib.py:146] step: 468600, eval_loss: 2.79468e-02
I0216 18:57:03.107316 23126066861888 run_lib.py:133] step: 468650, training_loss: 1.73733e-02
I0216 18:57:20.845698 23126066861888 run_lib.py:133] step: 468700, training_loss: 1.78006e-02
I0216 18:57:20.999077 23126066861888 run_lib.py:146] step: 468700, eval_loss: 2.86789e-02
I0216 18:57:38.551421 23126066861888 run_lib.py:133] step: 468750, training_loss: 1.71436e-02
I0216 18:57:56.210748 23126066861888 run_lib.py:133] step: 468800, training_loss: 1.73588e-02
I0216 18:57:56.368228 23126066861888 run_lib.py:146] step: 468800, eval_loss: 2.81833e-02
I0216 18:58:13.866083 23126066861888 run_lib.py:133] step: 468850, training_loss: 1.71201e-02
I0216 18:58:31.445891 23126066861888 run_lib.py:133] step: 468900, training_loss: 1.70566e-02
I0216 18:58:31.616235 23126066861888 run_lib.py:146] step: 468900, eval_loss: 2.83822e-02
I0216 18:58:49.358835 23126066861888 run_lib.py:133] step: 468950, training_loss: 1.73628e-02
I0216 18:59:06.856155 23126066861888 run_lib.py:133] step: 469000, training_loss: 1.81097e-02
I0216 18:59:07.013278 23126066861888 run_lib.py:146] step: 469000, eval_loss: 2.76974e-02
I0216 18:59:24.548551 23126066861888 run_lib.py:133] step: 469050, training_loss: 1.73611e-02
I0216 18:59:42.192291 23126066861888 run_lib.py:133] step: 469100, training_loss: 1.77941e-02
I0216 18:59:42.354233 23126066861888 run_lib.py:146] step: 469100, eval_loss: 2.85552e-02
I0216 18:59:59.835573 23126066861888 run_lib.py:133] step: 469150, training_loss: 1.80852e-02
I0216 19:00:17.357321 23126066861888 run_lib.py:133] step: 469200, training_loss: 1.81555e-02
I0216 19:00:17.511547 23126066861888 run_lib.py:146] step: 469200, eval_loss: 2.82058e-02
I0216 19:00:35.212860 23126066861888 run_lib.py:133] step: 469250, training_loss: 1.76198e-02
I0216 19:00:52.760143 23126066861888 run_lib.py:133] step: 469300, training_loss: 1.72453e-02
I0216 19:00:52.924212 23126066861888 run_lib.py:146] step: 469300, eval_loss: 2.81242e-02
I0216 19:01:10.398851 23126066861888 run_lib.py:133] step: 469350, training_loss: 1.77204e-02
I0216 19:01:27.880657 23126066861888 run_lib.py:133] step: 469400, training_loss: 1.68512e-02
I0216 19:01:28.042486 23126066861888 run_lib.py:146] step: 469400, eval_loss: 2.72301e-02
I0216 19:01:45.736965 23126066861888 run_lib.py:133] step: 469450, training_loss: 1.74540e-02
I0216 19:02:03.452117 23126066861888 run_lib.py:133] step: 469500, training_loss: 1.82851e-02
I0216 19:02:03.610469 23126066861888 run_lib.py:146] step: 469500, eval_loss: 2.77938e-02
I0216 19:02:21.112491 23126066861888 run_lib.py:133] step: 469550, training_loss: 1.81255e-02
I0216 19:02:38.611193 23126066861888 run_lib.py:133] step: 469600, training_loss: 1.74860e-02
I0216 19:02:38.769259 23126066861888 run_lib.py:146] step: 469600, eval_loss: 3.11612e-02
I0216 19:02:56.457691 23126066861888 run_lib.py:133] step: 469650, training_loss: 1.74199e-02
I0216 19:03:14.013107 23126066861888 run_lib.py:133] step: 469700, training_loss: 1.80643e-02
I0216 19:03:14.173436 23126066861888 run_lib.py:146] step: 469700, eval_loss: 2.83863e-02
I0216 19:03:31.769172 23126066861888 run_lib.py:133] step: 469750, training_loss: 1.76945e-02
I0216 19:03:49.487766 23126066861888 run_lib.py:133] step: 469800, training_loss: 1.78323e-02
I0216 19:03:49.649548 23126066861888 run_lib.py:146] step: 469800, eval_loss: 2.92781e-02
I0216 19:04:07.160620 23126066861888 run_lib.py:133] step: 469850, training_loss: 1.73101e-02
I0216 19:04:24.871694 23126066861888 run_lib.py:133] step: 469900, training_loss: 1.73189e-02
I0216 19:04:25.032613 23126066861888 run_lib.py:146] step: 469900, eval_loss: 2.88109e-02
I0216 19:04:42.534839 23126066861888 run_lib.py:133] step: 469950, training_loss: 1.78624e-02
I0216 19:05:00.062454 23126066861888 run_lib.py:133] step: 470000, training_loss: 1.70360e-02
I0216 19:05:01.030294 23126066861888 run_lib.py:146] step: 470000, eval_loss: 2.80291e-02
I0216 19:05:21.582719 23126066861888 run_lib.py:133] step: 470050, training_loss: 1.74463e-02
I0216 19:05:39.104983 23126066861888 run_lib.py:133] step: 470100, training_loss: 1.77043e-02
I0216 19:05:39.264927 23126066861888 run_lib.py:146] step: 470100, eval_loss: 2.74647e-02
I0216 19:05:56.788899 23126066861888 run_lib.py:133] step: 470150, training_loss: 1.75438e-02
I0216 19:06:14.487280 23126066861888 run_lib.py:133] step: 470200, training_loss: 1.77163e-02
I0216 19:06:14.640945 23126066861888 run_lib.py:146] step: 470200, eval_loss: 2.91826e-02
I0216 19:06:32.133977 23126066861888 run_lib.py:133] step: 470250, training_loss: 1.74058e-02
I0216 19:06:49.683828 23126066861888 run_lib.py:133] step: 470300, training_loss: 1.79662e-02
I0216 19:06:49.923389 23126066861888 run_lib.py:146] step: 470300, eval_loss: 2.85732e-02
I0216 19:07:07.683967 23126066861888 run_lib.py:133] step: 470350, training_loss: 1.67937e-02
I0216 19:07:25.233929 23126066861888 run_lib.py:133] step: 470400, training_loss: 1.71209e-02
I0216 19:07:25.402378 23126066861888 run_lib.py:146] step: 470400, eval_loss: 2.71790e-02
I0216 19:07:43.053673 23126066861888 run_lib.py:133] step: 470450, training_loss: 1.74745e-02
I0216 19:08:00.562870 23126066861888 run_lib.py:133] step: 470500, training_loss: 1.71986e-02
I0216 19:08:00.722151 23126066861888 run_lib.py:146] step: 470500, eval_loss: 2.85225e-02
I0216 19:08:18.211030 23126066861888 run_lib.py:133] step: 470550, training_loss: 1.69544e-02
I0216 19:08:36.011446 23126066861888 run_lib.py:133] step: 470600, training_loss: 1.77793e-02
I0216 19:08:36.174456 23126066861888 run_lib.py:146] step: 470600, eval_loss: 2.90662e-02
I0216 19:08:53.753425 23126066861888 run_lib.py:133] step: 470650, training_loss: 1.69296e-02
I0216 19:09:11.280459 23126066861888 run_lib.py:133] step: 470700, training_loss: 1.69271e-02
I0216 19:09:11.436533 23126066861888 run_lib.py:146] step: 470700, eval_loss: 2.76000e-02
I0216 19:09:28.940960 23126066861888 run_lib.py:133] step: 470750, training_loss: 1.71766e-02
I0216 19:09:46.452928 23126066861888 run_lib.py:133] step: 470800, training_loss: 1.75379e-02
I0216 19:09:46.629441 23126066861888 run_lib.py:146] step: 470800, eval_loss: 2.74967e-02
I0216 19:10:04.344662 23126066861888 run_lib.py:133] step: 470850, training_loss: 1.77136e-02
I0216 19:10:22.041980 23126066861888 run_lib.py:133] step: 470900, training_loss: 1.72138e-02
I0216 19:10:22.203141 23126066861888 run_lib.py:146] step: 470900, eval_loss: 2.99054e-02
I0216 19:10:39.699291 23126066861888 run_lib.py:133] step: 470950, training_loss: 1.72920e-02
I0216 19:10:57.200006 23126066861888 run_lib.py:133] step: 471000, training_loss: 1.73909e-02
I0216 19:10:57.355822 23126066861888 run_lib.py:146] step: 471000, eval_loss: 2.75303e-02
I0216 19:11:15.014517 23126066861888 run_lib.py:133] step: 471050, training_loss: 1.74990e-02
I0216 19:11:32.562461 23126066861888 run_lib.py:133] step: 471100, training_loss: 1.73588e-02
I0216 19:11:32.728462 23126066861888 run_lib.py:146] step: 471100, eval_loss: 2.83305e-02
I0216 19:11:50.518942 23126066861888 run_lib.py:133] step: 471150, training_loss: 1.69425e-02
I0216 19:12:08.033043 23126066861888 run_lib.py:133] step: 471200, training_loss: 1.71833e-02
I0216 19:12:08.188262 23126066861888 run_lib.py:146] step: 471200, eval_loss: 2.66160e-02
I0216 19:12:25.704624 23126066861888 run_lib.py:133] step: 471250, training_loss: 1.65132e-02
I0216 19:12:43.371260 23126066861888 run_lib.py:133] step: 471300, training_loss: 1.68571e-02
I0216 19:12:43.530557 23126066861888 run_lib.py:146] step: 471300, eval_loss: 2.70743e-02
I0216 19:13:01.024145 23126066861888 run_lib.py:133] step: 471350, training_loss: 1.72545e-02
I0216 19:13:18.541997 23126066861888 run_lib.py:133] step: 471400, training_loss: 1.76018e-02
I0216 19:13:18.713515 23126066861888 run_lib.py:146] step: 471400, eval_loss: 2.71635e-02
I0216 19:13:36.515442 23126066861888 run_lib.py:133] step: 471450, training_loss: 1.72985e-02
I0216 19:13:54.020612 23126066861888 run_lib.py:133] step: 471500, training_loss: 1.75329e-02
I0216 19:13:54.178347 23126066861888 run_lib.py:146] step: 471500, eval_loss: 2.76770e-02
I0216 19:14:11.723057 23126066861888 run_lib.py:133] step: 471550, training_loss: 1.69246e-02
I0216 19:14:29.422777 23126066861888 run_lib.py:133] step: 471600, training_loss: 1.74921e-02
I0216 19:14:29.585960 23126066861888 run_lib.py:146] step: 471600, eval_loss: 2.87648e-02
I0216 19:14:47.102946 23126066861888 run_lib.py:133] step: 471650, training_loss: 1.67624e-02
I0216 19:15:04.677071 23126066861888 run_lib.py:133] step: 471700, training_loss: 1.73571e-02
I0216 19:15:04.838528 23126066861888 run_lib.py:146] step: 471700, eval_loss: 2.96511e-02
I0216 19:15:22.521264 23126066861888 run_lib.py:133] step: 471750, training_loss: 1.72658e-02
I0216 19:15:40.075530 23126066861888 run_lib.py:133] step: 471800, training_loss: 1.68673e-02
I0216 19:15:40.235373 23126066861888 run_lib.py:146] step: 471800, eval_loss: 2.69959e-02
I0216 19:15:57.730591 23126066861888 run_lib.py:133] step: 471850, training_loss: 1.67502e-02
I0216 19:16:15.212079 23126066861888 run_lib.py:133] step: 471900, training_loss: 1.74677e-02
I0216 19:16:15.394223 23126066861888 run_lib.py:146] step: 471900, eval_loss: 2.77302e-02
I0216 19:16:33.107639 23126066861888 run_lib.py:133] step: 471950, training_loss: 1.74168e-02
I0216 19:16:50.824453 23126066861888 run_lib.py:133] step: 472000, training_loss: 1.78618e-02
I0216 19:16:50.990852 23126066861888 run_lib.py:146] step: 472000, eval_loss: 2.85655e-02
I0216 19:17:08.562443 23126066861888 run_lib.py:133] step: 472050, training_loss: 1.75358e-02
I0216 19:17:26.059206 23126066861888 run_lib.py:133] step: 472100, training_loss: 1.71603e-02
I0216 19:17:26.213092 23126066861888 run_lib.py:146] step: 472100, eval_loss: 2.88411e-02
I0216 19:17:43.892329 23126066861888 run_lib.py:133] step: 472150, training_loss: 1.74512e-02
I0216 19:18:01.397498 23126066861888 run_lib.py:133] step: 472200, training_loss: 1.69606e-02
I0216 19:18:01.555154 23126066861888 run_lib.py:146] step: 472200, eval_loss: 2.92047e-02
I0216 19:18:19.132866 23126066861888 run_lib.py:133] step: 472250, training_loss: 1.75328e-02
I0216 19:18:36.818540 23126066861888 run_lib.py:133] step: 472300, training_loss: 1.73715e-02
I0216 19:18:36.984144 23126066861888 run_lib.py:146] step: 472300, eval_loss: 2.87096e-02
I0216 19:18:54.483183 23126066861888 run_lib.py:133] step: 472350, training_loss: 1.63679e-02
I0216 19:19:12.182708 23126066861888 run_lib.py:133] step: 472400, training_loss: 1.70702e-02
I0216 19:19:12.341341 23126066861888 run_lib.py:146] step: 472400, eval_loss: 2.84451e-02
I0216 19:19:29.832136 23126066861888 run_lib.py:133] step: 472450, training_loss: 1.79071e-02
I0216 19:19:47.333565 23126066861888 run_lib.py:133] step: 472500, training_loss: 1.76300e-02
I0216 19:19:47.489540 23126066861888 run_lib.py:146] step: 472500, eval_loss: 2.84531e-02
I0216 19:20:05.252753 23126066861888 run_lib.py:133] step: 472550, training_loss: 1.74810e-02
I0216 19:20:22.780704 23126066861888 run_lib.py:133] step: 472600, training_loss: 1.79724e-02
I0216 19:20:22.934238 23126066861888 run_lib.py:146] step: 472600, eval_loss: 2.76618e-02
I0216 19:20:40.453835 23126066861888 run_lib.py:133] step: 472650, training_loss: 1.76538e-02
I0216 19:20:58.183021 23126066861888 run_lib.py:133] step: 472700, training_loss: 1.78868e-02
I0216 19:20:58.340215 23126066861888 run_lib.py:146] step: 472700, eval_loss: 2.81026e-02
I0216 19:21:15.815833 23126066861888 run_lib.py:133] step: 472750, training_loss: 1.69586e-02
I0216 19:21:33.393693 23126066861888 run_lib.py:133] step: 472800, training_loss: 1.73130e-02
I0216 19:21:33.576257 23126066861888 run_lib.py:146] step: 472800, eval_loss: 2.87766e-02
I0216 19:21:51.266879 23126066861888 run_lib.py:133] step: 472850, training_loss: 1.78728e-02
I0216 19:22:08.766245 23126066861888 run_lib.py:133] step: 472900, training_loss: 1.74715e-02
I0216 19:22:08.932392 23126066861888 run_lib.py:146] step: 472900, eval_loss: 2.94467e-02
I0216 19:22:26.488613 23126066861888 run_lib.py:133] step: 472950, training_loss: 1.71564e-02
I0216 19:22:43.998661 23126066861888 run_lib.py:133] step: 473000, training_loss: 1.81949e-02
I0216 19:22:44.154844 23126066861888 run_lib.py:146] step: 473000, eval_loss: 2.87375e-02
I0216 19:23:01.860491 23126066861888 run_lib.py:133] step: 473050, training_loss: 1.81429e-02
I0216 19:23:19.519620 23126066861888 run_lib.py:133] step: 473100, training_loss: 1.70565e-02
I0216 19:23:19.681629 23126066861888 run_lib.py:146] step: 473100, eval_loss: 2.82039e-02
I0216 19:23:37.249856 23126066861888 run_lib.py:133] step: 473150, training_loss: 1.74409e-02
I0216 19:23:54.775235 23126066861888 run_lib.py:133] step: 473200, training_loss: 1.74259e-02
I0216 19:23:54.939384 23126066861888 run_lib.py:146] step: 473200, eval_loss: 2.74983e-02
I0216 19:24:12.623963 23126066861888 run_lib.py:133] step: 473250, training_loss: 1.72416e-02
I0216 19:24:30.120403 23126066861888 run_lib.py:133] step: 473300, training_loss: 1.74967e-02
I0216 19:24:30.286146 23126066861888 run_lib.py:146] step: 473300, eval_loss: 2.77754e-02
I0216 19:24:47.803817 23126066861888 run_lib.py:133] step: 473350, training_loss: 1.79149e-02
I0216 19:25:05.568310 23126066861888 run_lib.py:133] step: 473400, training_loss: 1.79615e-02
I0216 19:25:05.727003 23126066861888 run_lib.py:146] step: 473400, eval_loss: 2.80945e-02
I0216 19:25:23.237616 23126066861888 run_lib.py:133] step: 473450, training_loss: 1.76483e-02
I0216 19:25:40.948736 23126066861888 run_lib.py:133] step: 473500, training_loss: 1.69805e-02
I0216 19:25:41.126183 23126066861888 run_lib.py:146] step: 473500, eval_loss: 2.84537e-02
I0216 19:25:58.627410 23126066861888 run_lib.py:133] step: 473550, training_loss: 1.66399e-02
I0216 19:26:16.171493 23126066861888 run_lib.py:133] step: 473600, training_loss: 1.74988e-02
I0216 19:26:16.333423 23126066861888 run_lib.py:146] step: 473600, eval_loss: 2.87074e-02
I0216 19:26:34.115236 23126066861888 run_lib.py:133] step: 473650, training_loss: 1.72100e-02
I0216 19:26:51.621015 23126066861888 run_lib.py:133] step: 473700, training_loss: 1.74922e-02
I0216 19:26:51.780148 23126066861888 run_lib.py:146] step: 473700, eval_loss: 2.90171e-02
I0216 19:27:09.258874 23126066861888 run_lib.py:133] step: 473750, training_loss: 1.73749e-02
I0216 19:27:26.935969 23126066861888 run_lib.py:133] step: 473800, training_loss: 1.75632e-02
I0216 19:27:27.093151 23126066861888 run_lib.py:146] step: 473800, eval_loss: 2.74703e-02
I0216 19:27:44.583557 23126066861888 run_lib.py:133] step: 473850, training_loss: 1.63935e-02
I0216 19:28:02.125121 23126066861888 run_lib.py:133] step: 473900, training_loss: 1.71677e-02
I0216 19:28:02.283043 23126066861888 run_lib.py:146] step: 473900, eval_loss: 2.78850e-02
I0216 19:28:19.919394 23126066861888 run_lib.py:133] step: 473950, training_loss: 1.75050e-02
I0216 19:28:37.431200 23126066861888 run_lib.py:133] step: 474000, training_loss: 1.75029e-02
I0216 19:28:37.589038 23126066861888 run_lib.py:146] step: 474000, eval_loss: 2.77363e-02
I0216 19:28:55.054756 23126066861888 run_lib.py:133] step: 474050, training_loss: 1.72257e-02
I0216 19:29:12.583748 23126066861888 run_lib.py:133] step: 474100, training_loss: 1.84625e-02
I0216 19:29:12.747156 23126066861888 run_lib.py:146] step: 474100, eval_loss: 2.91188e-02
I0216 19:29:30.427479 23126066861888 run_lib.py:133] step: 474150, training_loss: 1.68867e-02
I0216 19:29:48.101147 23126066861888 run_lib.py:133] step: 474200, training_loss: 1.69412e-02
I0216 19:29:48.273247 23126066861888 run_lib.py:146] step: 474200, eval_loss: 2.84565e-02
I0216 19:30:05.836047 23126066861888 run_lib.py:133] step: 474250, training_loss: 1.80083e-02
I0216 19:30:23.331522 23126066861888 run_lib.py:133] step: 474300, training_loss: 1.78101e-02
I0216 19:30:23.489378 23126066861888 run_lib.py:146] step: 474300, eval_loss: 2.85100e-02
I0216 19:30:41.204888 23126066861888 run_lib.py:133] step: 474350, training_loss: 1.74026e-02
I0216 19:30:58.706312 23126066861888 run_lib.py:133] step: 474400, training_loss: 1.75223e-02
I0216 19:30:58.868330 23126066861888 run_lib.py:146] step: 474400, eval_loss: 2.87356e-02
I0216 19:31:16.397794 23126066861888 run_lib.py:133] step: 474450, training_loss: 1.80054e-02
I0216 19:31:34.155885 23126066861888 run_lib.py:133] step: 474500, training_loss: 1.68469e-02
I0216 19:31:34.324198 23126066861888 run_lib.py:146] step: 474500, eval_loss: 2.78556e-02
I0216 19:31:51.916934 23126066861888 run_lib.py:133] step: 474550, training_loss: 1.74779e-02
I0216 19:32:09.653802 23126066861888 run_lib.py:133] step: 474600, training_loss: 1.72441e-02
I0216 19:32:09.809867 23126066861888 run_lib.py:146] step: 474600, eval_loss: 2.87185e-02
I0216 19:32:27.279092 23126066861888 run_lib.py:133] step: 474650, training_loss: 1.66097e-02
I0216 19:32:44.766548 23126066861888 run_lib.py:133] step: 474700, training_loss: 1.66433e-02
I0216 19:32:44.927377 23126066861888 run_lib.py:146] step: 474700, eval_loss: 2.71568e-02
I0216 19:33:02.603006 23126066861888 run_lib.py:133] step: 474750, training_loss: 1.81973e-02
I0216 19:33:20.168000 23126066861888 run_lib.py:133] step: 474800, training_loss: 1.70838e-02
I0216 19:33:20.325435 23126066861888 run_lib.py:146] step: 474800, eval_loss: 2.71309e-02
I0216 19:33:37.830992 23126066861888 run_lib.py:133] step: 474850, training_loss: 1.75160e-02
I0216 19:33:55.526091 23126066861888 run_lib.py:133] step: 474900, training_loss: 1.67097e-02
I0216 19:33:55.689117 23126066861888 run_lib.py:146] step: 474900, eval_loss: 2.81082e-02
I0216 19:34:13.180390 23126066861888 run_lib.py:133] step: 474950, training_loss: 1.72805e-02
I0216 19:34:30.718243 23126066861888 run_lib.py:133] step: 475000, training_loss: 1.74157e-02
I0216 19:34:30.881324 23126066861888 run_lib.py:146] step: 475000, eval_loss: 2.88783e-02
I0216 19:34:48.514815 23126066861888 run_lib.py:133] step: 475050, training_loss: 1.68891e-02
I0216 19:35:06.036872 23126066861888 run_lib.py:133] step: 475100, training_loss: 1.67908e-02
I0216 19:35:06.219269 23126066861888 run_lib.py:146] step: 475100, eval_loss: 2.69882e-02
I0216 19:35:23.735123 23126066861888 run_lib.py:133] step: 475150, training_loss: 1.78248e-02
I0216 19:35:41.240167 23126066861888 run_lib.py:133] step: 475200, training_loss: 1.69502e-02
I0216 19:35:41.402711 23126066861888 run_lib.py:146] step: 475200, eval_loss: 2.83012e-02
I0216 19:35:59.134512 23126066861888 run_lib.py:133] step: 475250, training_loss: 1.76649e-02
I0216 19:36:16.784062 23126066861888 run_lib.py:133] step: 475300, training_loss: 1.70940e-02
I0216 19:36:16.942401 23126066861888 run_lib.py:146] step: 475300, eval_loss: 2.86551e-02
I0216 19:36:34.510652 23126066861888 run_lib.py:133] step: 475350, training_loss: 1.72196e-02
I0216 19:36:52.030834 23126066861888 run_lib.py:133] step: 475400, training_loss: 1.76690e-02
I0216 19:36:52.184930 23126066861888 run_lib.py:146] step: 475400, eval_loss: 2.93359e-02
I0216 19:37:09.908857 23126066861888 run_lib.py:133] step: 475450, training_loss: 1.72687e-02
I0216 19:37:27.402224 23126066861888 run_lib.py:133] step: 475500, training_loss: 1.68305e-02
I0216 19:37:27.557134 23126066861888 run_lib.py:146] step: 475500, eval_loss: 2.98293e-02
I0216 19:37:45.049715 23126066861888 run_lib.py:133] step: 475550, training_loss: 1.78250e-02
I0216 19:38:02.768109 23126066861888 run_lib.py:133] step: 475600, training_loss: 1.70273e-02
I0216 19:38:02.945212 23126066861888 run_lib.py:146] step: 475600, eval_loss: 2.83466e-02
I0216 19:38:20.557420 23126066861888 run_lib.py:133] step: 475650, training_loss: 1.73903e-02
I0216 19:38:38.294475 23126066861888 run_lib.py:133] step: 475700, training_loss: 1.74051e-02
I0216 19:38:38.451416 23126066861888 run_lib.py:146] step: 475700, eval_loss: 2.81116e-02
I0216 19:38:55.968617 23126066861888 run_lib.py:133] step: 475750, training_loss: 1.74551e-02
I0216 19:39:13.437669 23126066861888 run_lib.py:133] step: 475800, training_loss: 1.71907e-02
I0216 19:39:13.601244 23126066861888 run_lib.py:146] step: 475800, eval_loss: 2.82523e-02
I0216 19:39:31.265897 23126066861888 run_lib.py:133] step: 475850, training_loss: 1.73511e-02
I0216 19:39:48.799211 23126066861888 run_lib.py:133] step: 475900, training_loss: 1.72531e-02
I0216 19:39:49.078006 23126066861888 run_lib.py:146] step: 475900, eval_loss: 2.90629e-02
I0216 19:40:06.666115 23126066861888 run_lib.py:133] step: 475950, training_loss: 1.77764e-02
I0216 19:40:24.403591 23126066861888 run_lib.py:133] step: 476000, training_loss: 1.75057e-02
I0216 19:40:24.560146 23126066861888 run_lib.py:146] step: 476000, eval_loss: 2.80986e-02
I0216 19:40:42.068970 23126066861888 run_lib.py:133] step: 476050, training_loss: 1.72434e-02
I0216 19:40:59.603461 23126066861888 run_lib.py:133] step: 476100, training_loss: 1.77551e-02
I0216 19:40:59.763355 23126066861888 run_lib.py:146] step: 476100, eval_loss: 2.75570e-02
I0216 19:41:17.399200 23126066861888 run_lib.py:133] step: 476150, training_loss: 1.66969e-02
I0216 19:41:34.956707 23126066861888 run_lib.py:133] step: 476200, training_loss: 1.74992e-02
I0216 19:41:35.119477 23126066861888 run_lib.py:146] step: 476200, eval_loss: 2.95504e-02
I0216 19:41:52.642546 23126066861888 run_lib.py:133] step: 476250, training_loss: 1.78093e-02
I0216 19:42:10.133142 23126066861888 run_lib.py:133] step: 476300, training_loss: 1.74216e-02
I0216 19:42:10.290220 23126066861888 run_lib.py:146] step: 476300, eval_loss: 2.73011e-02
I0216 19:42:27.990568 23126066861888 run_lib.py:133] step: 476350, training_loss: 1.73541e-02
I0216 19:42:45.589498 23126066861888 run_lib.py:133] step: 476400, training_loss: 1.76746e-02
I0216 19:42:45.746404 23126066861888 run_lib.py:146] step: 476400, eval_loss: 2.82699e-02
I0216 19:43:03.264407 23126066861888 run_lib.py:133] step: 476450, training_loss: 1.77887e-02
I0216 19:43:20.861519 23126066861888 run_lib.py:133] step: 476500, training_loss: 1.63762e-02
I0216 19:43:21.032462 23126066861888 run_lib.py:146] step: 476500, eval_loss: 2.88654e-02
I0216 19:43:38.792747 23126066861888 run_lib.py:133] step: 476550, training_loss: 1.74730e-02
I0216 19:43:56.311529 23126066861888 run_lib.py:133] step: 476600, training_loss: 1.79002e-02
I0216 19:43:56.472404 23126066861888 run_lib.py:146] step: 476600, eval_loss: 2.90817e-02
I0216 19:44:13.979181 23126066861888 run_lib.py:133] step: 476650, training_loss: 1.77065e-02
I0216 19:44:31.640443 23126066861888 run_lib.py:133] step: 476700, training_loss: 1.74944e-02
I0216 19:44:31.808243 23126066861888 run_lib.py:146] step: 476700, eval_loss: 2.96912e-02
I0216 19:44:49.363200 23126066861888 run_lib.py:133] step: 476750, training_loss: 1.80188e-02
I0216 19:45:07.094675 23126066861888 run_lib.py:133] step: 476800, training_loss: 1.69738e-02
I0216 19:45:07.252107 23126066861888 run_lib.py:146] step: 476800, eval_loss: 2.84902e-02
I0216 19:45:24.835458 23126066861888 run_lib.py:133] step: 476850, training_loss: 1.72850e-02
I0216 19:45:42.330625 23126066861888 run_lib.py:133] step: 476900, training_loss: 1.75077e-02
I0216 19:45:42.487371 23126066861888 run_lib.py:146] step: 476900, eval_loss: 2.71649e-02
I0216 19:46:00.201917 23126066861888 run_lib.py:133] step: 476950, training_loss: 1.75319e-02
I0216 19:46:17.735637 23126066861888 run_lib.py:133] step: 477000, training_loss: 1.69090e-02
I0216 19:46:17.913437 23126066861888 run_lib.py:146] step: 477000, eval_loss: 2.78516e-02
I0216 19:46:35.463614 23126066861888 run_lib.py:133] step: 477050, training_loss: 1.73243e-02
I0216 19:46:53.213676 23126066861888 run_lib.py:133] step: 477100, training_loss: 1.77764e-02
I0216 19:46:53.376105 23126066861888 run_lib.py:146] step: 477100, eval_loss: 2.69813e-02
I0216 19:47:10.878588 23126066861888 run_lib.py:133] step: 477150, training_loss: 1.68819e-02
I0216 19:47:28.385508 23126066861888 run_lib.py:133] step: 477200, training_loss: 1.68200e-02
I0216 19:47:28.542993 23126066861888 run_lib.py:146] step: 477200, eval_loss: 2.90573e-02
I0216 19:47:46.127919 23126066861888 run_lib.py:133] step: 477250, training_loss: 1.71381e-02
I0216 19:48:03.634249 23126066861888 run_lib.py:133] step: 477300, training_loss: 1.76911e-02
I0216 19:48:03.789166 23126066861888 run_lib.py:146] step: 477300, eval_loss: 2.78187e-02
I0216 19:48:21.326109 23126066861888 run_lib.py:133] step: 477350, training_loss: 1.70112e-02
I0216 19:48:39.014635 23126066861888 run_lib.py:133] step: 477400, training_loss: 1.73911e-02
I0216 19:48:39.167226 23126066861888 run_lib.py:146] step: 477400, eval_loss: 2.71105e-02
I0216 19:48:56.909839 23126066861888 run_lib.py:133] step: 477450, training_loss: 1.73069e-02
I0216 19:49:14.547545 23126066861888 run_lib.py:133] step: 477500, training_loss: 1.70394e-02
I0216 19:49:14.708339 23126066861888 run_lib.py:146] step: 477500, eval_loss: 2.94436e-02
I0216 19:49:32.235467 23126066861888 run_lib.py:133] step: 477550, training_loss: 1.68263e-02
I0216 19:49:49.724910 23126066861888 run_lib.py:133] step: 477600, training_loss: 1.75178e-02
I0216 19:49:49.895148 23126066861888 run_lib.py:146] step: 477600, eval_loss: 2.83604e-02
I0216 19:50:07.671730 23126066861888 run_lib.py:133] step: 477650, training_loss: 1.78474e-02
I0216 19:50:25.215672 23126066861888 run_lib.py:133] step: 477700, training_loss: 1.72924e-02
I0216 19:50:25.373415 23126066861888 run_lib.py:146] step: 477700, eval_loss: 2.86156e-02
I0216 19:50:42.897926 23126066861888 run_lib.py:133] step: 477750, training_loss: 1.67840e-02
I0216 19:51:00.587638 23126066861888 run_lib.py:133] step: 477800, training_loss: 1.74046e-02
I0216 19:51:00.740941 23126066861888 run_lib.py:146] step: 477800, eval_loss: 2.96943e-02
I0216 19:51:18.241509 23126066861888 run_lib.py:133] step: 477850, training_loss: 1.75269e-02
I0216 19:51:35.962038 23126066861888 run_lib.py:133] step: 477900, training_loss: 1.69392e-02
I0216 19:51:36.134630 23126066861888 run_lib.py:146] step: 477900, eval_loss: 2.88312e-02
I0216 19:51:53.667653 23126066861888 run_lib.py:133] step: 477950, training_loss: 1.75779e-02
I0216 19:52:11.234127 23126066861888 run_lib.py:133] step: 478000, training_loss: 1.73772e-02
I0216 19:52:11.394455 23126066861888 run_lib.py:146] step: 478000, eval_loss: 2.89385e-02
I0216 19:52:29.127117 23126066861888 run_lib.py:133] step: 478050, training_loss: 1.72825e-02
I0216 19:52:46.643947 23126066861888 run_lib.py:133] step: 478100, training_loss: 1.70917e-02
I0216 19:52:46.800253 23126066861888 run_lib.py:146] step: 478100, eval_loss: 2.82803e-02
I0216 19:53:04.294095 23126066861888 run_lib.py:133] step: 478150, training_loss: 1.71854e-02
I0216 19:53:22.061527 23126066861888 run_lib.py:133] step: 478200, training_loss: 1.71136e-02
I0216 19:53:22.218542 23126066861888 run_lib.py:146] step: 478200, eval_loss: 2.90780e-02
I0216 19:53:39.765247 23126066861888 run_lib.py:133] step: 478250, training_loss: 1.82227e-02
I0216 19:53:57.308674 23126066861888 run_lib.py:133] step: 478300, training_loss: 1.75838e-02
I0216 19:53:57.547150 23126066861888 run_lib.py:146] step: 478300, eval_loss: 2.81823e-02
I0216 19:54:15.131531 23126066861888 run_lib.py:133] step: 478350, training_loss: 1.77003e-02
I0216 19:54:32.667465 23126066861888 run_lib.py:133] step: 478400, training_loss: 1.73058e-02
I0216 19:54:32.824433 23126066861888 run_lib.py:146] step: 478400, eval_loss: 2.89245e-02
I0216 19:54:50.368832 23126066861888 run_lib.py:133] step: 478450, training_loss: 1.75357e-02
I0216 19:55:07.944193 23126066861888 run_lib.py:133] step: 478500, training_loss: 1.71122e-02
I0216 19:55:08.105301 23126066861888 run_lib.py:146] step: 478500, eval_loss: 2.71578e-02
I0216 19:55:25.805693 23126066861888 run_lib.py:133] step: 478550, training_loss: 1.72032e-02
I0216 19:55:43.395560 23126066861888 run_lib.py:133] step: 478600, training_loss: 1.69634e-02
I0216 19:55:43.560151 23126066861888 run_lib.py:146] step: 478600, eval_loss: 2.91268e-02
I0216 19:56:01.081082 23126066861888 run_lib.py:133] step: 478650, training_loss: 1.69834e-02
I0216 19:56:18.585049 23126066861888 run_lib.py:133] step: 478700, training_loss: 1.77618e-02
I0216 19:56:18.742587 23126066861888 run_lib.py:146] step: 478700, eval_loss: 2.80440e-02
I0216 19:56:36.478402 23126066861888 run_lib.py:133] step: 478750, training_loss: 1.78603e-02
I0216 19:56:54.013854 23126066861888 run_lib.py:133] step: 478800, training_loss: 1.70428e-02
I0216 19:56:54.168438 23126066861888 run_lib.py:146] step: 478800, eval_loss: 2.78339e-02
I0216 19:57:11.711333 23126066861888 run_lib.py:133] step: 478850, training_loss: 1.77628e-02
I0216 19:57:29.448146 23126066861888 run_lib.py:133] step: 478900, training_loss: 1.71265e-02
I0216 19:57:29.607605 23126066861888 run_lib.py:146] step: 478900, eval_loss: 2.80210e-02
I0216 19:57:47.114715 23126066861888 run_lib.py:133] step: 478950, training_loss: 1.72834e-02
I0216 19:58:04.859825 23126066861888 run_lib.py:133] step: 479000, training_loss: 1.73934e-02
I0216 19:58:05.018511 23126066861888 run_lib.py:146] step: 479000, eval_loss: 2.82368e-02
I0216 19:58:22.511566 23126066861888 run_lib.py:133] step: 479050, training_loss: 1.78694e-02
I0216 19:58:39.984570 23126066861888 run_lib.py:133] step: 479100, training_loss: 1.78012e-02
I0216 19:58:40.141227 23126066861888 run_lib.py:146] step: 479100, eval_loss: 2.76267e-02
I0216 19:58:57.851846 23126066861888 run_lib.py:133] step: 479150, training_loss: 1.70474e-02
I0216 19:59:15.345144 23126066861888 run_lib.py:133] step: 479200, training_loss: 1.72305e-02
I0216 19:59:15.498272 23126066861888 run_lib.py:146] step: 479200, eval_loss: 2.86725e-02
I0216 19:59:32.978044 23126066861888 run_lib.py:133] step: 479250, training_loss: 1.69771e-02
I0216 19:59:50.765237 23126066861888 run_lib.py:133] step: 479300, training_loss: 1.80433e-02
I0216 19:59:50.935555 23126066861888 run_lib.py:146] step: 479300, eval_loss: 2.83984e-02
I0216 20:00:08.464028 23126066861888 run_lib.py:133] step: 479350, training_loss: 1.70235e-02
I0216 20:00:26.046294 23126066861888 run_lib.py:133] step: 479400, training_loss: 1.75591e-02
I0216 20:00:26.211719 23126066861888 run_lib.py:146] step: 479400, eval_loss: 2.85158e-02
I0216 20:00:43.831234 23126066861888 run_lib.py:133] step: 479450, training_loss: 1.70521e-02
I0216 20:01:01.327118 23126066861888 run_lib.py:133] step: 479500, training_loss: 1.67407e-02
I0216 20:01:01.492325 23126066861888 run_lib.py:146] step: 479500, eval_loss: 2.77136e-02
I0216 20:01:19.025301 23126066861888 run_lib.py:133] step: 479550, training_loss: 1.73368e-02
I0216 20:01:36.583542 23126066861888 run_lib.py:133] step: 479600, training_loss: 1.76311e-02
I0216 20:01:36.742493 23126066861888 run_lib.py:146] step: 479600, eval_loss: 2.79857e-02
I0216 20:01:54.481224 23126066861888 run_lib.py:133] step: 479650, training_loss: 1.80333e-02
I0216 20:02:12.066977 23126066861888 run_lib.py:133] step: 479700, training_loss: 1.68889e-02
I0216 20:02:12.220247 23126066861888 run_lib.py:146] step: 479700, eval_loss: 2.78486e-02
I0216 20:02:29.719652 23126066861888 run_lib.py:133] step: 479750, training_loss: 1.74453e-02
I0216 20:02:47.255739 23126066861888 run_lib.py:133] step: 479800, training_loss: 1.75785e-02
I0216 20:02:47.426401 23126066861888 run_lib.py:146] step: 479800, eval_loss: 2.90736e-02
I0216 20:03:05.218770 23126066861888 run_lib.py:133] step: 479850, training_loss: 1.71926e-02
I0216 20:03:22.746116 23126066861888 run_lib.py:133] step: 479900, training_loss: 1.71311e-02
I0216 20:03:22.906107 23126066861888 run_lib.py:146] step: 479900, eval_loss: 2.80582e-02
I0216 20:03:40.392282 23126066861888 run_lib.py:133] step: 479950, training_loss: 1.71105e-02
I0216 20:03:58.113093 23126066861888 run_lib.py:133] step: 480000, training_loss: 1.75346e-02
I0216 20:03:58.919859 23126066861888 run_lib.py:146] step: 480000, eval_loss: 2.93059e-02
I0216 20:04:19.117506 23126066861888 run_lib.py:133] step: 480050, training_loss: 1.68592e-02
I0216 20:04:36.677148 23126066861888 run_lib.py:133] step: 480100, training_loss: 1.78044e-02
I0216 20:04:36.839422 23126066861888 run_lib.py:146] step: 480100, eval_loss: 2.83852e-02
I0216 20:04:54.516316 23126066861888 run_lib.py:133] step: 480150, training_loss: 1.75614e-02
I0216 20:05:12.153325 23126066861888 run_lib.py:133] step: 480200, training_loss: 1.76137e-02
I0216 20:05:12.312545 23126066861888 run_lib.py:146] step: 480200, eval_loss: 2.95837e-02
I0216 20:05:29.819144 23126066861888 run_lib.py:133] step: 480250, training_loss: 1.73962e-02
I0216 20:05:47.339431 23126066861888 run_lib.py:133] step: 480300, training_loss: 1.61505e-02
I0216 20:05:47.506187 23126066861888 run_lib.py:146] step: 480300, eval_loss: 2.73752e-02
I0216 20:06:05.160384 23126066861888 run_lib.py:133] step: 480350, training_loss: 1.70969e-02
I0216 20:06:22.708947 23126066861888 run_lib.py:133] step: 480400, training_loss: 1.77486e-02
I0216 20:06:22.874251 23126066861888 run_lib.py:146] step: 480400, eval_loss: 2.78875e-02
I0216 20:06:40.642526 23126066861888 run_lib.py:133] step: 480450, training_loss: 1.74563e-02
I0216 20:06:58.137570 23126066861888 run_lib.py:133] step: 480500, training_loss: 1.74835e-02
I0216 20:06:58.295178 23126066861888 run_lib.py:146] step: 480500, eval_loss: 2.80564e-02
I0216 20:07:15.803339 23126066861888 run_lib.py:133] step: 480550, training_loss: 1.71610e-02
I0216 20:07:33.450376 23126066861888 run_lib.py:133] step: 480600, training_loss: 1.63985e-02
I0216 20:07:33.608015 23126066861888 run_lib.py:146] step: 480600, eval_loss: 2.83223e-02
I0216 20:07:51.144133 23126066861888 run_lib.py:133] step: 480650, training_loss: 1.73302e-02
I0216 20:08:08.673031 23126066861888 run_lib.py:133] step: 480700, training_loss: 1.70390e-02
I0216 20:08:08.836942 23126066861888 run_lib.py:146] step: 480700, eval_loss: 2.79382e-02
I0216 20:08:26.590247 23126066861888 run_lib.py:133] step: 480750, training_loss: 1.75908e-02
I0216 20:08:44.101013 23126066861888 run_lib.py:133] step: 480800, training_loss: 1.76191e-02
I0216 20:08:44.257117 23126066861888 run_lib.py:146] step: 480800, eval_loss: 2.83638e-02
I0216 20:09:01.928894 23126066861888 run_lib.py:133] step: 480850, training_loss: 1.80501e-02
I0216 20:09:19.429373 23126066861888 run_lib.py:133] step: 480900, training_loss: 1.73523e-02
I0216 20:09:19.609518 23126066861888 run_lib.py:146] step: 480900, eval_loss: 2.87298e-02
I0216 20:09:37.150697 23126066861888 run_lib.py:133] step: 480950, training_loss: 1.76154e-02
I0216 20:09:54.910463 23126066861888 run_lib.py:133] step: 481000, training_loss: 1.74072e-02
I0216 20:09:55.068476 23126066861888 run_lib.py:146] step: 481000, eval_loss: 2.74095e-02
I0216 20:10:12.582864 23126066861888 run_lib.py:133] step: 481050, training_loss: 1.75992e-02
I0216 20:10:30.079655 23126066861888 run_lib.py:133] step: 481100, training_loss: 1.75201e-02
I0216 20:10:30.237149 23126066861888 run_lib.py:146] step: 481100, eval_loss: 2.83128e-02
I0216 20:10:47.775750 23126066861888 run_lib.py:133] step: 481150, training_loss: 1.73255e-02
I0216 20:11:05.299073 23126066861888 run_lib.py:133] step: 481200, training_loss: 1.78098e-02
I0216 20:11:05.452611 23126066861888 run_lib.py:146] step: 481200, eval_loss: 2.84014e-02
I0216 20:11:23.213153 23126066861888 run_lib.py:133] step: 481250, training_loss: 1.70276e-02
I0216 20:11:40.872182 23126066861888 run_lib.py:133] step: 481300, training_loss: 1.71237e-02
I0216 20:11:41.030138 23126066861888 run_lib.py:146] step: 481300, eval_loss: 2.87690e-02
I0216 20:11:58.501610 23126066861888 run_lib.py:133] step: 481350, training_loss: 1.72792e-02
I0216 20:12:16.007772 23126066861888 run_lib.py:133] step: 481400, training_loss: 1.70680e-02
I0216 20:12:16.168338 23126066861888 run_lib.py:146] step: 481400, eval_loss: 2.80662e-02
I0216 20:12:33.836038 23126066861888 run_lib.py:133] step: 481450, training_loss: 1.69803e-02
I0216 20:12:51.363313 23126066861888 run_lib.py:133] step: 481500, training_loss: 1.70178e-02
I0216 20:12:51.527173 23126066861888 run_lib.py:146] step: 481500, eval_loss: 2.94673e-02
I0216 20:13:09.204367 23126066861888 run_lib.py:133] step: 481550, training_loss: 1.78237e-02
I0216 20:13:26.783874 23126066861888 run_lib.py:133] step: 481600, training_loss: 1.68847e-02
I0216 20:13:26.939945 23126066861888 run_lib.py:146] step: 481600, eval_loss: 2.84918e-02
I0216 20:13:44.453493 23126066861888 run_lib.py:133] step: 481650, training_loss: 1.67784e-02
I0216 20:14:02.151250 23126066861888 run_lib.py:133] step: 481700, training_loss: 1.74345e-02
I0216 20:14:02.304193 23126066861888 run_lib.py:146] step: 481700, eval_loss: 2.84739e-02
I0216 20:14:19.772397 23126066861888 run_lib.py:133] step: 481750, training_loss: 1.81830e-02
I0216 20:14:37.304976 23126066861888 run_lib.py:133] step: 481800, training_loss: 1.78453e-02
I0216 20:14:37.492404 23126066861888 run_lib.py:146] step: 481800, eval_loss: 2.89999e-02
I0216 20:14:55.242541 23126066861888 run_lib.py:133] step: 481850, training_loss: 1.80202e-02
I0216 20:15:12.766654 23126066861888 run_lib.py:133] step: 481900, training_loss: 1.73940e-02
I0216 20:15:12.927784 23126066861888 run_lib.py:146] step: 481900, eval_loss: 2.88961e-02
I0216 20:15:30.428177 23126066861888 run_lib.py:133] step: 481950, training_loss: 1.72426e-02
I0216 20:15:48.171849 23126066861888 run_lib.py:133] step: 482000, training_loss: 1.76551e-02
I0216 20:15:48.329280 23126066861888 run_lib.py:146] step: 482000, eval_loss: 2.96244e-02
I0216 20:16:05.853219 23126066861888 run_lib.py:133] step: 482050, training_loss: 1.66976e-02
I0216 20:16:23.407509 23126066861888 run_lib.py:133] step: 482100, training_loss: 1.71490e-02
I0216 20:16:23.571767 23126066861888 run_lib.py:146] step: 482100, eval_loss: 2.89501e-02
I0216 20:16:41.231067 23126066861888 run_lib.py:133] step: 482150, training_loss: 1.80719e-02
I0216 20:16:58.754015 23126066861888 run_lib.py:133] step: 482200, training_loss: 1.70454e-02
I0216 20:16:58.910243 23126066861888 run_lib.py:146] step: 482200, eval_loss: 2.82594e-02
I0216 20:17:16.409654 23126066861888 run_lib.py:133] step: 482250, training_loss: 1.73010e-02
I0216 20:17:33.957349 23126066861888 run_lib.py:133] step: 482300, training_loss: 1.74649e-02
I0216 20:17:34.116558 23126066861888 run_lib.py:146] step: 482300, eval_loss: 2.91172e-02
I0216 20:17:51.805775 23126066861888 run_lib.py:133] step: 482350, training_loss: 1.76816e-02
slurmstepd: error: *** JOB 47845201 ON gl1524 CANCELLED AT 2023-02-16T20:18:02 ***
