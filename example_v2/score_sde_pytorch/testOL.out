2
WARNING:tensorflow:From /home/yifulu/.conda/envs/dpm/lib/python3.9/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.

I0215 20:41:13.145768 22990530508608 main.py:54] Conditional: True
W0215 20:41:16.561526 22990530508608 utils.py:10] No checkpoint found at experiments/dpm_one_first/checkpoints-meta/checkpoint.pth. Returned the same state as input
I0215 20:41:16.563720 22990530508608 xla_bridge.py:355] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0215 20:41:16.563928 22990530508608 xla_bridge.py:355] Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0215 20:41:16.564004 22990530508608 xla_bridge.py:355] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0215 20:41:16.565377 22990530508608 xla_bridge.py:355] Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.
I0215 20:41:16.565494 22990530508608 xla_bridge.py:355] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
W0215 20:41:16.565584 22990530508608 xla_bridge.py:362] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0215 20:41:16.568537 22990530508608 dataset_info.py:358] Load dataset info from /home/yifulu/tensorflow_datasets/cifar10/3.0.2
W0215 20:41:16.572913 22990530508608 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
W0215 20:41:16.573024 22990530508608 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
I0215 20:41:16.573166 22990530508608 dataset_builder.py:351] Reusing dataset cifar10 (/home/yifulu/tensorflow_datasets/cifar10/3.0.2)
I0215 20:41:16.573265 22990530508608 logging_logger.py:35] Constructing tf.data.Dataset cifar10 for split train, from /home/yifulu/tensorflow_datasets/cifar10/3.0.2
W0215 20:41:16.746545 22990530508608 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
W0215 20:41:16.746802 22990530508608 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
I0215 20:41:16.746936 22990530508608 dataset_builder.py:351] Reusing dataset cifar10 (/home/yifulu/tensorflow_datasets/cifar10/3.0.2)
I0215 20:41:16.747023 22990530508608 logging_logger.py:35] Constructing tf.data.Dataset cifar10 for split test, from /home/yifulu/tensorflow_datasets/cifar10/3.0.2
I0215 20:41:16.856884 22990530508608 losses.py:57] Sde loss
I0215 20:41:16.857143 22990530508608 losses.py:59] Fewer: 2
I0215 20:41:16.857276 22990530508608 losses.py:71] one step set
I0215 20:41:16.857356 22990530508608 losses.py:57] Sde loss
I0215 20:41:16.857415 22990530508608 losses.py:59] Fewer: 2
I0215 20:41:16.857478 22990530508608 losses.py:71] one step set
I0215 20:41:16.857563 22990530508608 sampling.py:98] dpm_solver
I0215 20:41:16.857676 22990530508608 run_lib.py:123] Starting training loop at step 0.
I0215 20:41:25.937844 22990530508608 run_lib.py:133] step: 0, training_loss: 9.98312e-01
I0215 20:41:27.468373 22990530508608 run_lib.py:146] step: 0, eval_loss: 1.00078e+00
I0215 20:41:47.188079 22990530508608 run_lib.py:133] step: 50, training_loss: 9.90975e-01
I0215 20:42:06.769372 22990530508608 run_lib.py:133] step: 100, training_loss: 9.51909e-01
I0215 20:42:06.934826 22990530508608 run_lib.py:146] step: 100, eval_loss: 9.62774e-01
I0215 20:42:26.458180 22990530508608 run_lib.py:133] step: 150, training_loss: 8.83811e-01
I0215 20:42:44.002888 22990530508608 run_lib.py:133] step: 200, training_loss: 7.92597e-01
I0215 20:42:44.158901 22990530508608 run_lib.py:146] step: 200, eval_loss: 8.25693e-01
I0215 20:43:01.857052 22990530508608 run_lib.py:133] step: 250, training_loss: 6.90164e-01
I0215 20:43:19.335291 22990530508608 run_lib.py:133] step: 300, training_loss: 5.75617e-01
I0215 20:43:19.490382 22990530508608 run_lib.py:146] step: 300, eval_loss: 6.36883e-01
I0215 20:43:37.008330 22990530508608 run_lib.py:133] step: 350, training_loss: 4.59737e-01
I0215 20:43:54.668970 22990530508608 run_lib.py:133] step: 400, training_loss: 3.42067e-01
I0215 20:43:54.844132 22990530508608 run_lib.py:146] step: 400, eval_loss: 4.26509e-01
I0215 20:44:12.319072 22990530508608 run_lib.py:133] step: 450, training_loss: 2.32136e-01
I0215 20:44:30.032216 22990530508608 run_lib.py:133] step: 500, training_loss: 1.35055e-01
I0215 20:44:30.191426 22990530508608 run_lib.py:146] step: 500, eval_loss: 2.19808e-01
I0215 20:44:47.748840 22990530508608 run_lib.py:133] step: 550, training_loss: 6.02074e-02
I0215 20:45:05.288612 22990530508608 run_lib.py:133] step: 600, training_loss: 1.93672e-02
I0215 20:45:05.441970 22990530508608 run_lib.py:146] step: 600, eval_loss: 6.71554e-02
I0215 20:45:23.154697 22990530508608 run_lib.py:133] step: 650, training_loss: 6.77022e-03
I0215 20:45:40.692741 22990530508608 run_lib.py:133] step: 700, training_loss: 3.48348e-03
I0215 20:45:40.846071 22990530508608 run_lib.py:146] step: 700, eval_loss: 1.15457e-02
I0215 20:45:58.348223 22990530508608 run_lib.py:133] step: 750, training_loss: 2.24652e-03
I0215 20:46:16.132097 22990530508608 run_lib.py:133] step: 800, training_loss: 1.83004e-03
I0215 20:46:16.295437 22990530508608 run_lib.py:146] step: 800, eval_loss: 2.48712e-03
I0215 20:46:33.873929 22990530508608 run_lib.py:133] step: 850, training_loss: 1.55179e-03
I0215 20:46:51.407101 22990530508608 run_lib.py:133] step: 900, training_loss: 1.54634e-03
I0215 20:46:51.564401 22990530508608 run_lib.py:146] step: 900, eval_loss: 1.19897e-03
I0215 20:47:09.172081 22990530508608 run_lib.py:133] step: 950, training_loss: 1.39998e-03
I0215 20:47:26.671755 22990530508608 run_lib.py:133] step: 1000, training_loss: 1.20973e-03
I0215 20:47:26.840482 22990530508608 run_lib.py:146] step: 1000, eval_loss: 8.72411e-04
I0215 20:47:44.370424 22990530508608 run_lib.py:133] step: 1050, training_loss: 1.08108e-03
I0215 20:48:01.887219 22990530508608 run_lib.py:133] step: 1100, training_loss: 1.01761e-03
I0215 20:48:02.042790 22990530508608 run_lib.py:146] step: 1100, eval_loss: 7.59723e-04
I0215 20:48:19.726092 22990530508608 run_lib.py:133] step: 1150, training_loss: 9.34261e-04
I0215 20:48:37.311368 22990530508608 run_lib.py:133] step: 1200, training_loss: 8.90944e-04
I0215 20:48:37.463319 22990530508608 run_lib.py:146] step: 1200, eval_loss: 6.60652e-04
I0215 20:48:54.960728 22990530508608 run_lib.py:133] step: 1250, training_loss: 8.90581e-04
I0215 20:49:12.463094 22990530508608 run_lib.py:133] step: 1300, training_loss: 8.66402e-04
I0215 20:49:12.629450 22990530508608 run_lib.py:146] step: 1300, eval_loss: 6.33934e-04
I0215 20:49:30.353466 22990530508608 run_lib.py:133] step: 1350, training_loss: 9.55432e-04
I0215 20:49:47.840794 22990530508608 run_lib.py:133] step: 1400, training_loss: 9.45395e-04
I0215 20:49:47.999364 22990530508608 run_lib.py:146] step: 1400, eval_loss: 6.75590e-04
I0215 20:50:05.473340 22990530508608 run_lib.py:133] step: 1450, training_loss: 8.36053e-04
I0215 20:50:23.109761 22990530508608 run_lib.py:133] step: 1500, training_loss: 7.74049e-04
I0215 20:50:23.274860 22990530508608 run_lib.py:146] step: 1500, eval_loss: 6.23249e-04
I0215 20:50:40.826857 22990530508608 run_lib.py:133] step: 1550, training_loss: 7.07982e-04
I0215 20:50:58.597980 22990530508608 run_lib.py:133] step: 1600, training_loss: 6.97379e-04
I0215 20:50:58.754350 22990530508608 run_lib.py:146] step: 1600, eval_loss: 5.47250e-04
I0215 20:51:16.258690 22990530508608 run_lib.py:133] step: 1650, training_loss: 7.54320e-04
I0215 20:51:33.723108 22990530508608 run_lib.py:133] step: 1700, training_loss: 6.45775e-04
I0215 20:51:33.878031 22990530508608 run_lib.py:146] step: 1700, eval_loss: 5.19247e-04
I0215 20:51:51.572135 22990530508608 run_lib.py:133] step: 1750, training_loss: 6.14945e-04
I0215 20:52:09.054288 22990530508608 run_lib.py:133] step: 1800, training_loss: 6.31418e-04
I0215 20:52:09.211126 22990530508608 run_lib.py:146] step: 1800, eval_loss: 4.84248e-04
I0215 20:52:26.718889 22990530508608 run_lib.py:133] step: 1850, training_loss: 7.34181e-04
I0215 20:52:44.470260 22990530508608 run_lib.py:133] step: 1900, training_loss: 5.91197e-04
I0215 20:52:44.627248 22990530508608 run_lib.py:146] step: 1900, eval_loss: 4.39019e-04
I0215 20:53:02.138519 22990530508608 run_lib.py:133] step: 1950, training_loss: 7.48006e-04
I0215 20:53:19.568012 22990530508608 run_lib.py:133] step: 2000, training_loss: 6.95964e-04
I0215 20:53:19.723083 22990530508608 run_lib.py:146] step: 2000, eval_loss: 4.37194e-04
I0215 20:53:37.280141 22990530508608 run_lib.py:133] step: 2050, training_loss: 5.79770e-04
I0215 20:53:54.794281 22990530508608 run_lib.py:133] step: 2100, training_loss: 6.33151e-04
I0215 20:53:54.950360 22990530508608 run_lib.py:146] step: 2100, eval_loss: 4.47386e-04
I0215 20:54:12.532323 22990530508608 run_lib.py:133] step: 2150, training_loss: 5.56331e-04
I0215 20:54:30.042973 22990530508608 run_lib.py:133] step: 2200, training_loss: 5.05419e-04
I0215 20:54:30.195383 22990530508608 run_lib.py:146] step: 2200, eval_loss: 4.44156e-04
I0215 20:54:47.839771 22990530508608 run_lib.py:133] step: 2250, training_loss: 7.50027e-04
I0215 20:55:05.393165 22990530508608 run_lib.py:133] step: 2300, training_loss: 7.27339e-04
I0215 20:55:05.551551 22990530508608 run_lib.py:146] step: 2300, eval_loss: 3.97629e-04
I0215 20:55:23.030175 22990530508608 run_lib.py:133] step: 2350, training_loss: 4.71658e-04
I0215 20:55:40.562105 22990530508608 run_lib.py:133] step: 2400, training_loss: 5.74436e-04
I0215 20:55:40.727489 22990530508608 run_lib.py:146] step: 2400, eval_loss: 4.03061e-04
I0215 20:55:58.417145 22990530508608 run_lib.py:133] step: 2450, training_loss: 4.60020e-04
I0215 20:56:15.954727 22990530508608 run_lib.py:133] step: 2500, training_loss: 4.67727e-04
I0215 20:56:16.108194 22990530508608 run_lib.py:146] step: 2500, eval_loss: 3.70786e-04
I0215 20:56:33.607419 22990530508608 run_lib.py:133] step: 2550, training_loss: 5.00920e-04
I0215 20:56:51.241471 22990530508608 run_lib.py:133] step: 2600, training_loss: 4.34148e-04
I0215 20:56:51.393017 22990530508608 run_lib.py:146] step: 2600, eval_loss: 3.55650e-04
I0215 20:57:08.881456 22990530508608 run_lib.py:133] step: 2650, training_loss: 4.52080e-04
I0215 20:57:26.574208 22990530508608 run_lib.py:133] step: 2700, training_loss: 3.99276e-04
I0215 20:57:26.740506 22990530508608 run_lib.py:146] step: 2700, eval_loss: 3.57277e-04
I0215 20:57:44.222671 22990530508608 run_lib.py:133] step: 2750, training_loss: 4.42239e-04
I0215 20:58:01.689698 22990530508608 run_lib.py:133] step: 2800, training_loss: 3.84228e-04
I0215 20:58:01.846556 22990530508608 run_lib.py:146] step: 2800, eval_loss: 3.31154e-04
I0215 20:58:19.517424 22990530508608 run_lib.py:133] step: 2850, training_loss: 3.79380e-04
I0215 20:58:37.014255 22990530508608 run_lib.py:133] step: 2900, training_loss: 3.64726e-04
I0215 20:58:37.170164 22990530508608 run_lib.py:146] step: 2900, eval_loss: 3.22118e-04
I0215 20:58:54.628208 22990530508608 run_lib.py:133] step: 2950, training_loss: 3.86948e-04
I0215 20:59:12.392741 22990530508608 run_lib.py:133] step: 3000, training_loss: 7.03640e-04
I0215 20:59:12.552457 22990530508608 run_lib.py:146] step: 3000, eval_loss: 3.03042e-04
I0215 20:59:30.062730 22990530508608 run_lib.py:133] step: 3050, training_loss: 3.59734e-04
I0215 20:59:47.554941 22990530508608 run_lib.py:133] step: 3100, training_loss: 3.39789e-04
I0215 20:59:47.707331 22990530508608 run_lib.py:146] step: 3100, eval_loss: 3.05144e-04
I0215 21:00:05.323085 22990530508608 run_lib.py:133] step: 3150, training_loss: 3.80584e-04
I0215 21:00:22.787880 22990530508608 run_lib.py:133] step: 3200, training_loss: 3.72908e-04
I0215 21:00:22.942252 22990530508608 run_lib.py:146] step: 3200, eval_loss: 3.35973e-04
I0215 21:00:40.445809 22990530508608 run_lib.py:133] step: 3250, training_loss: 8.27850e-04
I0215 21:00:58.003418 22990530508608 run_lib.py:133] step: 3300, training_loss: 3.45332e-04
I0215 21:00:58.160224 22990530508608 run_lib.py:146] step: 3300, eval_loss: 3.07442e-04
I0215 21:01:15.816705 22990530508608 run_lib.py:133] step: 3350, training_loss: 3.21572e-04
I0215 21:01:33.411644 22990530508608 run_lib.py:133] step: 3400, training_loss: 5.14248e-04
I0215 21:01:33.574151 22990530508608 run_lib.py:146] step: 3400, eval_loss: 2.78647e-04
I0215 21:01:51.120146 22990530508608 run_lib.py:133] step: 3450, training_loss: 5.35627e-04
I0215 21:02:08.697603 22990530508608 run_lib.py:133] step: 3500, training_loss: 2.70457e-04
I0215 21:02:08.856392 22990530508608 run_lib.py:146] step: 3500, eval_loss: 2.87441e-04
I0215 21:02:26.561926 22990530508608 run_lib.py:133] step: 3550, training_loss: 2.90335e-04
I0215 21:02:44.036941 22990530508608 run_lib.py:133] step: 3600, training_loss: 3.47956e-04
I0215 21:02:44.192401 22990530508608 run_lib.py:146] step: 3600, eval_loss: 2.70602e-04
I0215 21:03:01.699728 22990530508608 run_lib.py:133] step: 3650, training_loss: 5.08353e-04
I0215 21:03:19.364889 22990530508608 run_lib.py:133] step: 3700, training_loss: 2.88529e-04
I0215 21:03:19.520508 22990530508608 run_lib.py:146] step: 3700, eval_loss: 2.59826e-04
I0215 21:03:37.006864 22990530508608 run_lib.py:133] step: 3750, training_loss: 3.22802e-04
I0215 21:03:54.707230 22990530508608 run_lib.py:133] step: 3800, training_loss: 2.66128e-04
I0215 21:03:54.869209 22990530508608 run_lib.py:146] step: 3800, eval_loss: 2.57063e-04
I0215 21:04:12.363932 22990530508608 run_lib.py:133] step: 3850, training_loss: 2.84711e-04
I0215 21:04:29.851361 22990530508608 run_lib.py:133] step: 3900, training_loss: 2.74855e-04
I0215 21:04:30.008476 22990530508608 run_lib.py:146] step: 3900, eval_loss: 2.55091e-04
I0215 21:04:47.693974 22990530508608 run_lib.py:133] step: 3950, training_loss: 6.85016e-04
I0215 21:05:05.170357 22990530508608 run_lib.py:133] step: 4000, training_loss: 2.38573e-04
I0215 21:05:05.325515 22990530508608 run_lib.py:146] step: 4000, eval_loss: 2.19211e-04
I0215 21:05:22.809549 22990530508608 run_lib.py:133] step: 4050, training_loss: 3.20201e-04
I0215 21:05:40.531613 22990530508608 run_lib.py:133] step: 4100, training_loss: 2.89337e-04
I0215 21:05:40.686381 22990530508608 run_lib.py:146] step: 4100, eval_loss: 2.22170e-04
I0215 21:05:58.126630 22990530508608 run_lib.py:133] step: 4150, training_loss: 2.54034e-04
I0215 21:06:15.585268 22990530508608 run_lib.py:133] step: 4200, training_loss: 2.50612e-04
I0215 21:06:15.743482 22990530508608 run_lib.py:146] step: 4200, eval_loss: 2.27089e-04
I0215 21:06:33.233707 22990530508608 run_lib.py:133] step: 4250, training_loss: 4.17168e-04
I0215 21:06:50.744838 22990530508608 run_lib.py:133] step: 4300, training_loss: 2.57208e-04
I0215 21:06:50.912345 22990530508608 run_lib.py:146] step: 4300, eval_loss: 2.15820e-04
I0215 21:07:08.416124 22990530508608 run_lib.py:133] step: 4350, training_loss: 2.38087e-04
I0215 21:07:25.903863 22990530508608 run_lib.py:133] step: 4400, training_loss: 2.46560e-04
I0215 21:07:26.059022 22990530508608 run_lib.py:146] step: 4400, eval_loss: 2.08203e-04
I0215 21:07:43.772301 22990530508608 run_lib.py:133] step: 4450, training_loss: 2.20684e-04
I0215 21:08:01.321032 22990530508608 run_lib.py:133] step: 4500, training_loss: 4.47322e-04
I0215 21:08:01.470405 22990530508608 run_lib.py:146] step: 4500, eval_loss: 2.09378e-04
I0215 21:08:18.934575 22990530508608 run_lib.py:133] step: 4550, training_loss: 2.42159e-04
I0215 21:08:36.438253 22990530508608 run_lib.py:133] step: 4600, training_loss: 2.99122e-04
I0215 21:08:36.603342 22990530508608 run_lib.py:146] step: 4600, eval_loss: 2.10473e-04
I0215 21:08:54.334719 22990530508608 run_lib.py:133] step: 4650, training_loss: 2.25381e-04
I0215 21:09:11.855521 22990530508608 run_lib.py:133] step: 4700, training_loss: 2.03466e-04
I0215 21:09:12.010363 22990530508608 run_lib.py:146] step: 4700, eval_loss: 2.06994e-04
I0215 21:09:29.477994 22990530508608 run_lib.py:133] step: 4750, training_loss: 2.08233e-04
I0215 21:09:47.108786 22990530508608 run_lib.py:133] step: 4800, training_loss: 2.07960e-04
I0215 21:09:47.263188 22990530508608 run_lib.py:146] step: 4800, eval_loss: 2.08629e-04
I0215 21:10:04.738543 22990530508608 run_lib.py:133] step: 4850, training_loss: 2.11901e-04
I0215 21:10:22.426044 22990530508608 run_lib.py:133] step: 4900, training_loss: 1.97565e-04
I0215 21:10:22.580405 22990530508608 run_lib.py:146] step: 4900, eval_loss: 1.82023e-04
I0215 21:10:40.079421 22990530508608 run_lib.py:133] step: 4950, training_loss: 2.02451e-04
I0215 21:10:57.556448 22990530508608 run_lib.py:133] step: 5000, training_loss: 2.88086e-04
I0215 21:10:57.712202 22990530508608 run_lib.py:146] step: 5000, eval_loss: 1.76647e-04
I0215 21:11:15.400340 22990530508608 run_lib.py:133] step: 5050, training_loss: 1.66525e-04
I0215 21:11:32.886555 22990530508608 run_lib.py:133] step: 5100, training_loss: 2.31351e-04
I0215 21:11:33.042172 22990530508608 run_lib.py:146] step: 5100, eval_loss: 1.82311e-04
I0215 21:11:50.485392 22990530508608 run_lib.py:133] step: 5150, training_loss: 2.39341e-04
I0215 21:12:08.071972 22990530508608 run_lib.py:133] step: 5200, training_loss: 1.81448e-04
I0215 21:12:08.250343 22990530508608 run_lib.py:146] step: 5200, eval_loss: 1.68730e-04
I0215 21:12:25.790489 22990530508608 run_lib.py:133] step: 5250, training_loss: 1.76065e-04
I0215 21:12:43.262434 22990530508608 run_lib.py:133] step: 5300, training_loss: 1.66838e-04
I0215 21:12:43.417312 22990530508608 run_lib.py:146] step: 5300, eval_loss: 1.62213e-04
I0215 21:13:01.008294 22990530508608 run_lib.py:133] step: 5350, training_loss: 1.79880e-04
I0215 21:13:18.482421 22990530508608 run_lib.py:133] step: 5400, training_loss: 2.69867e-04
I0215 21:13:18.637294 22990530508608 run_lib.py:146] step: 5400, eval_loss: 1.52968e-04
I0215 21:13:36.126000 22990530508608 run_lib.py:133] step: 5450, training_loss: 1.90367e-04
I0215 21:13:53.582471 22990530508608 run_lib.py:133] step: 5500, training_loss: 2.30445e-04
I0215 21:13:53.733157 22990530508608 run_lib.py:146] step: 5500, eval_loss: 1.70409e-04
I0215 21:14:11.445101 22990530508608 run_lib.py:133] step: 5550, training_loss: 2.29203e-04
I0215 21:14:29.059577 22990530508608 run_lib.py:133] step: 5600, training_loss: 2.40386e-04
I0215 21:14:29.217268 22990530508608 run_lib.py:146] step: 5600, eval_loss: 1.62675e-04
I0215 21:14:46.681600 22990530508608 run_lib.py:133] step: 5650, training_loss: 1.62306e-04
I0215 21:15:04.166865 22990530508608 run_lib.py:133] step: 5700, training_loss: 1.71676e-04
I0215 21:15:04.327476 22990530508608 run_lib.py:146] step: 5700, eval_loss: 1.56566e-04
I0215 21:15:21.980336 22990530508608 run_lib.py:133] step: 5750, training_loss: 2.17754e-04
I0215 21:15:39.439875 22990530508608 run_lib.py:133] step: 5800, training_loss: 1.63406e-04
I0215 21:15:39.603376 22990530508608 run_lib.py:146] step: 5800, eval_loss: 1.55890e-04
I0215 21:15:57.142572 22990530508608 run_lib.py:133] step: 5850, training_loss: 1.50443e-04
I0215 21:16:14.802879 22990530508608 run_lib.py:133] step: 5900, training_loss: 1.31557e-04
I0215 21:16:14.964022 22990530508608 run_lib.py:146] step: 5900, eval_loss: 1.54782e-04
I0215 21:16:32.477305 22990530508608 run_lib.py:133] step: 5950, training_loss: 1.49194e-04
I0215 21:16:50.115593 22990530508608 run_lib.py:133] step: 6000, training_loss: 2.66517e-04
I0215 21:16:50.267897 22990530508608 run_lib.py:146] step: 6000, eval_loss: 1.53316e-04
I0215 21:17:07.727827 22990530508608 run_lib.py:133] step: 6050, training_loss: 1.35032e-04
I0215 21:17:25.258455 22990530508608 run_lib.py:133] step: 6100, training_loss: 1.69567e-04
I0215 21:17:25.434218 22990530508608 run_lib.py:146] step: 6100, eval_loss: 1.42068e-04
I0215 21:17:43.166245 22990530508608 run_lib.py:133] step: 6150, training_loss: 1.43529e-04
I0215 21:18:00.687758 22990530508608 run_lib.py:133] step: 6200, training_loss: 1.31077e-04
I0215 21:18:00.844464 22990530508608 run_lib.py:146] step: 6200, eval_loss: 1.41905e-04
I0215 21:18:18.356178 22990530508608 run_lib.py:133] step: 6250, training_loss: 1.68510e-04
I0215 21:18:35.960597 22990530508608 run_lib.py:133] step: 6300, training_loss: 1.58520e-04
I0215 21:18:36.117540 22990530508608 run_lib.py:146] step: 6300, eval_loss: 1.38967e-04
I0215 21:18:53.570899 22990530508608 run_lib.py:133] step: 6350, training_loss: 1.55096e-04
I0215 21:19:11.073006 22990530508608 run_lib.py:133] step: 6400, training_loss: 1.55262e-04
I0215 21:19:11.234401 22990530508608 run_lib.py:146] step: 6400, eval_loss: 1.31462e-04
I0215 21:19:28.886826 22990530508608 run_lib.py:133] step: 6450, training_loss: 1.60774e-04
I0215 21:19:46.352792 22990530508608 run_lib.py:133] step: 6500, training_loss: 1.31575e-04
I0215 21:19:46.509215 22990530508608 run_lib.py:146] step: 6500, eval_loss: 1.34032e-04
I0215 21:20:04.005003 22990530508608 run_lib.py:133] step: 6550, training_loss: 1.17447e-04
I0215 21:20:21.491595 22990530508608 run_lib.py:133] step: 6600, training_loss: 1.39963e-04
I0215 21:20:21.654487 22990530508608 run_lib.py:146] step: 6600, eval_loss: 1.31184e-04
I0215 21:20:39.334790 22990530508608 run_lib.py:133] step: 6650, training_loss: 2.06448e-04
I0215 21:20:56.972074 22990530508608 run_lib.py:133] step: 6700, training_loss: 7.28481e-04
I0215 21:20:57.129551 22990530508608 run_lib.py:146] step: 6700, eval_loss: 1.30290e-04
I0215 21:21:14.677167 22990530508608 run_lib.py:133] step: 6750, training_loss: 1.31731e-04
I0215 21:21:32.189517 22990530508608 run_lib.py:133] step: 6800, training_loss: 3.22360e-04
I0215 21:21:32.345113 22990530508608 run_lib.py:146] step: 6800, eval_loss: 1.24435e-04
I0215 21:21:50.022677 22990530508608 run_lib.py:133] step: 6850, training_loss: 1.26133e-04
I0215 21:22:07.488720 22990530508608 run_lib.py:133] step: 6900, training_loss: 1.66507e-04
I0215 21:22:07.641187 22990530508608 run_lib.py:146] step: 6900, eval_loss: 1.18541e-04
I0215 21:22:25.121188 22990530508608 run_lib.py:133] step: 6950, training_loss: 1.36506e-04
I0215 21:22:42.806947 22990530508608 run_lib.py:133] step: 7000, training_loss: 1.22732e-04
I0215 21:22:42.978466 22990530508608 run_lib.py:146] step: 7000, eval_loss: 1.18038e-04
I0215 21:23:00.478955 22990530508608 run_lib.py:133] step: 7050, training_loss: 1.44897e-04
I0215 21:23:18.198283 22990530508608 run_lib.py:133] step: 7100, training_loss: 1.41824e-04
I0215 21:23:18.359532 22990530508608 run_lib.py:146] step: 7100, eval_loss: 1.19449e-04
I0215 21:23:35.836155 22990530508608 run_lib.py:133] step: 7150, training_loss: 1.38585e-04
I0215 21:23:53.315301 22990530508608 run_lib.py:133] step: 7200, training_loss: 1.57158e-04
I0215 21:23:53.471281 22990530508608 run_lib.py:146] step: 7200, eval_loss: 1.16700e-04
I0215 21:24:11.109437 22990530508608 run_lib.py:133] step: 7250, training_loss: 1.47720e-04
I0215 21:24:28.646106 22990530508608 run_lib.py:133] step: 7300, training_loss: 1.09713e-04
I0215 21:24:28.802858 22990530508608 run_lib.py:146] step: 7300, eval_loss: 1.17377e-04
I0215 21:24:46.305498 22990530508608 run_lib.py:133] step: 7350, training_loss: 1.50702e-04
I0215 21:25:03.983076 22990530508608 run_lib.py:133] step: 7400, training_loss: 1.50493e-04
I0215 21:25:04.136291 22990530508608 run_lib.py:146] step: 7400, eval_loss: 1.14687e-04
I0215 21:25:21.608831 22990530508608 run_lib.py:133] step: 7450, training_loss: 1.29571e-04
I0215 21:25:39.092276 22990530508608 run_lib.py:133] step: 7500, training_loss: 1.41216e-04
I0215 21:25:39.254163 22990530508608 run_lib.py:146] step: 7500, eval_loss: 1.12197e-04
I0215 21:25:56.844403 22990530508608 run_lib.py:133] step: 7550, training_loss: 1.06445e-04
I0215 21:26:14.375760 22990530508608 run_lib.py:133] step: 7600, training_loss: 1.43091e-04
I0215 21:26:14.531924 22990530508608 run_lib.py:146] step: 7600, eval_loss: 1.15416e-04
I0215 21:26:31.988666 22990530508608 run_lib.py:133] step: 7650, training_loss: 1.37302e-04
I0215 21:26:49.461127 22990530508608 run_lib.py:133] step: 7700, training_loss: 2.82138e-04
I0215 21:26:49.625381 22990530508608 run_lib.py:146] step: 7700, eval_loss: 1.06959e-04
I0215 21:27:07.272214 22990530508608 run_lib.py:133] step: 7750, training_loss: 1.14182e-04
I0215 21:27:24.811306 22990530508608 run_lib.py:133] step: 7800, training_loss: 1.09125e-04
I0215 21:27:24.964144 22990530508608 run_lib.py:146] step: 7800, eval_loss: 1.08507e-04
I0215 21:27:42.437934 22990530508608 run_lib.py:133] step: 7850, training_loss: 1.56737e-04
I0215 21:27:59.935609 22990530508608 run_lib.py:133] step: 7900, training_loss: 1.76947e-04
I0215 21:28:00.098599 22990530508608 run_lib.py:146] step: 7900, eval_loss: 1.08357e-04
I0215 21:28:17.873012 22990530508608 run_lib.py:133] step: 7950, training_loss: 1.15053e-04
I0215 21:28:35.393979 22990530508608 run_lib.py:133] step: 8000, training_loss: 1.08854e-04
I0215 21:28:35.551828 22990530508608 run_lib.py:146] step: 8000, eval_loss: 1.10069e-04
I0215 21:28:53.052021 22990530508608 run_lib.py:133] step: 8050, training_loss: 1.32934e-04
I0215 21:29:10.663592 22990530508608 run_lib.py:133] step: 8100, training_loss: 1.27097e-04
I0215 21:29:10.830173 22990530508608 run_lib.py:146] step: 8100, eval_loss: 1.05330e-04
I0215 21:29:28.333937 22990530508608 run_lib.py:133] step: 8150, training_loss: 1.17830e-04
I0215 21:29:46.060954 22990530508608 run_lib.py:133] step: 8200, training_loss: 1.30970e-04
I0215 21:29:46.218523 22990530508608 run_lib.py:146] step: 8200, eval_loss: 1.10930e-04
I0215 21:30:03.709531 22990530508608 run_lib.py:133] step: 8250, training_loss: 2.59971e-04
I0215 21:30:21.147392 22990530508608 run_lib.py:133] step: 8300, training_loss: 1.16176e-04
I0215 21:30:21.299145 22990530508608 run_lib.py:146] step: 8300, eval_loss: 1.04985e-04
slurmstepd: error: *** JOB 47945539 ON gl1518 CANCELLED AT 2023-02-15T21:30:28 ***
